[
    {
        "index": "#1",
        "title": "Mapis: A Knowledge-Graph Grounded Multi-Agent Framework for Evidence-Based PCOS Diagnosis",
        "link": "/arxiv/2512.15398",
        "arxiv_id": "2512.15398",
        "authors": "Zanxiang He, Meng Li, Liyun Shi, Weiye Daia, Liming Nie",
        "summary": "Polycystic Ovary Syndrome (PCOS) constitutes a significant public health issue affecting 10% of reproductive-aged women, highlighting the critical importance of developing effective diagnostic tools. Previous machine learning and deep learning detection tools are constrained by their reliance on large-scale labeled data and an lack of interpretability. Although multi-agent systems have demonstrated robust capabilities, the potential of such systems for PCOS detection remains largely unexplored. Existing medical multi-agent frameworks are predominantly designed for general medical tasks, suffering from insufficient domain integration and a lack of specific domain knowledge. To address these challenges, we propose Mapis, the first knowledge-grounded multi-agent framework explicitly designed for guideline-based PCOS diagnosis. Specifically, it built upon the 2023 International Guideline into a structured collaborative workflow that simulates the clinical diagnostic process. It decouples complex diagnostic tasks across specialized agents: a gynecological endocrine agent and a radiology agent collaborative to verify inclusion criteria, while an exclusion agent strictly rules out other causes. Furthermore, we construct a comprehensive PCOS knowledge graph to ensure verifiable, evidence-based decision-making. Extensive experiments on public benchmarks and specialized clinical datasets, benchmarking against nine diverse baselines, demonstrate that Mapis significantly outperforms competitive methods. On the clinical dataset, it surpasses traditional machine learning models by 13.56%, single-agent by 6.55%, and previous medical multi-agent systems by 7.05% in Accuracy.",
        "subjects": "Multiagent Systems",
        "date": "2025-12-17",
        "category": "cs.MA",
        "crawl_time": "2025-12-18T11:00:03.713055",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**: 这篇论文的核心贡献是构建了一个名为 \"Mapis\" 的**多智能体框架**。它并非简单地将一个已有的智能体框架（如AutoGen）应用于PCOS诊断，而是提出了一种新的方法论：通过构建知识图谱、设计专门的智能体（妇科内分泌智能体、放射学智能体、排除智能体）并定义它们之间的协作工作流来模拟临床诊断过程。这完全符合“构建、改进...LLM智能体”的核心目标。 - **排除**: 虽然论文的应用领域是医疗（PCOS诊断），但它不属于“非演化型应用”。因为论文的创新点在于**智能体系统的架构和协作机制本身**，而不是解决了某个医疗领域的具体问题。其价值在于为复杂、需要证据支持的诊断任务提供了一种新的多智能体设计范式，这个范式具有通用性。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。 - **多智能体**: 论文详细描述了智能体间的 `Collaboration`（协作）和 `Communication`（通信），通过解耦任务到不同智能体来共同完成诊断。 - **智能体能力**: 框架的设计涉及 `Planning`（规划），因为它模拟了结构化的临床诊断工作流。同时，将知识图谱作为决策依据，可以看作是一种高级的 `Tool Use` 或知识增强形式。 3.  **第三步：排除标准** - 论文没有触及安全与对齐（Safety, Alignment）或多模态（Vision）等排除领域。虽然提到了解决现有方法的 \"lack of interpretability\"（缺乏可解释性），但其主要贡献是提出新的智能体框架，可解释性是该框架设计带来的一个**优点**，而非论文研究的核心主题。因此，不触发排除规则。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的框架本质上是一个复杂的、多步骤的规划和推理系统，它通过多个智能体的协作来完成诊断任务。这完全符合“保留”关于智能体规划和多步推理框架的规则。 - **自我演化的应用**: 该论文不涉及自我演化，因此此条不适用。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种新颖的、基于知识图谱的多智能体协作框架。它深入探讨了智能体如何分工、协作和利用外部知识来解决复杂问题，这与研究课题中的“多智能体”方向高度契合。尽管它以PCOS诊断为应用场景，但其学术价值在于智能体系统的设计方法论，而非应用本身。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#3",
        "title": "SGEMAS: A Self-Growing Ephemeral Multi-Agent System for Unsupervised Online Anomaly Detection via Entropic Homeostasis",
        "link": "/arxiv/2512.14708",
        "arxiv_id": "2512.14708",
        "authors": "Mustapha Hamdi",
        "summary": "Current deep learning approaches for physiological signal monitoring suffer from static topologies and constant energy consumption. We introduce SGEMAS (Self-Growing Ephemeral Multi-Agent System), a bio-inspired architecture that treats intelligence as a dynamic thermodynamic process. By coupling a structural plasticity mechanism (agent birth death) to a variational free energy objective, the system naturally evolves to minimize prediction error with extreme sparsity. An ablation study on the MIT-BIH Arrhythmia Database reveals that adding a multi-scale instability index to the agent dynamics significantly improves performance. In a challenging inter-patient, zero-shot setting, the final SGEMAS v3.3 model achieves a mean AUC of 0.570 +- 0.070, outperforming both its simpler variants and a standard autoencoder baseline. This result validates that a physics-based, energy-constrained model can achieve robust unsupervised anomaly detection, offering a promising direction for efficient biomedical AI.",
        "subjects": "Neural and Evolutionary Computing, Machine Learning, Multiagent Systems",
        "date": "2025-12-08",
        "category": "cs.MA",
        "crawl_time": "2025-12-18T11:00:03.713664",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一个名为 SGEMAS 的新架构，即“自我增长、短暂的多智能体系统”。其关键创新点在于“结构可塑性机制（智能体生死）”，这使得系统能够“自然演化”。这完全符合“构建、改进或演化 LLM智能体”中的“多智能体”和“自我演化”两个核心方向。虽然它没有明确使用LLM作为智能体的大脑，但它提出的是一个关于智能体系统如何动态演化的通用框架，这与研究课题的“演化”本质高度一致。 2.  **第二步：正面指标** - 论文标题和摘要中包含了大量核心关注点：`Multi-Agent System`、`Self-Growing`、`Self-Evolving`（通过“naturally evolves”和“agent birth death”体现）、`Generational Evolution`（智能体的生死可以看作是一种代际演化）。这些指标强烈表明该论文与我的研究范围相关。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐或多模态。它关注的是系统架构和演化机制，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是本案例的关键。论文确实将SGEMAS应用到了一个特定领域——“生理信号监测”和“异常检测”。根据筛选规则，如果论文的核心是提出一种新的“自我演化”机制，即使它被应用在特定领域，也应该保留。本文的核心正是那个“通过智能体生死来实现自我增长和演化”的机制，而不是它在生物医学领域的应用结果。因此，它符合“保留”的例外情况。 **最终决策**: 综合以上分析，尽管这篇论文的应用领域（生物医学AI）看起来比较具体，但其**核心贡献是构建了一个具有自我演化能力的多智能体系统框架**。它探讨了智能体如何通过出生和死亡来动态调整自身结构以适应环境，这直接命中了“多智能体”和“自我演化”的研究焦点。因此，这篇论文是符合筛选要求的前沿研究，应该被保留。"
    },
    {
        "index": "#2",
        "title": "Epistemic diversity across language models mitigates knowledge collapse",
        "link": "/arxiv/2512.15011",
        "arxiv_id": "2512.15011",
        "authors": "Damian Hodel, Jevin D. West",
        "summary": "The growing use of artificial intelligence (AI) raises concerns of knowledge collapse, i.e., a reduction to the most dominant and central set of ideas. Prior work has demonstrated single-model collapse, defined as performance decay in an AI model trained on its own output. Inspired by ecology, we ask whether AI ecosystem diversity, that is, diversity among models, can mitigate such a collapse. We build on the single-model approach but focus on ecosystems of models trained on their collective output. To study the effect of diversity on model performance, we segment the training data across language models and evaluate the resulting ecosystems over ten, self-training iterations. We find that increased epistemic diversity mitigates collapse, but, interestingly, only up to an optimal level. Our results suggest that an ecosystem containing only a few diverse models fails to express the rich mixture of the full, true distribution, resulting in rapid performance decay. Yet distributing the data across too many models reduces each model's approximation capacity on the true distribution, leading to poor performance already in the first iteration step. In the context of AI monoculture, our results suggest the need to monitor diversity across AI systems and to develop policies that incentivize more domain- and community-specific models.",
        "subjects": "Machine Learning, Artificial Intelligence, Computers and Society, Multiagent Systems",
        "date": "2025-12-17",
        "category": "cs.MA",
        "crawl_time": "2025-12-18T11:00:03.713359",
        "filter_reason": "这篇论文符合您的研究范围，其核心贡献与“自我演化”和“多智能体”方向高度相关。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献并非将LLM作为工具应用于某个领域，也不是提升LLM的基础推理能力。它的本质是研究一个由多个语言模型构成的“生态系统”在迭代训练过程中的动态演化现象——“知识崩溃”，并提出“认识多样性”作为缓解这一演化问题的关键机制。 - **判断**: 这完全符合“自我演化”的研究范畴。论文研究的“自我训练迭代”过程，本质上是一种系统级的演化机制。它探讨的不是单个智能体的能力，而是智能体种群（模型生态系统）的长期演化趋势和稳定性。因此，这篇论文应该**保留**。 2.  **第二步：正面指标** - 论文的研究内容与多个核心关注点高度匹配： - `Multi-Agent Systems (MAS)`: 论文研究的“模型生态系统”可以被视为一个广义的多智能体系统，其中每个模型是一个“智能体”，它们通过共享训练数据（集体输出）进行交互和相互影响。 - `Self-Evolving`: 这是论文最核心的标签。它直接研究了模型在“自我训练迭代”中的演化过程，并提出了控制演化方向（防止崩溃）的方法。 - `Generational Evolution` / `Iterative Improvement`: 论文的实验设计明确包含了“十次自我训练迭代”，这清晰地体现了代际演化和迭代改进的思想。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等内容，因此不触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况** - 论文不涉及推理/规划或自我演化的应用等特殊情况，其研究焦点就是演化机制本身。 **最终决策**: 这篇论文的核心贡献在于提出并验证了一种控制LLM生态系统演化的机制。它虽然不讨论单个智能体的规划、工具使用等具体能力，但它从更高维度、更宏观的视角研究了“智能体种群”的演化问题，这正是“LLM智能体及其演化”这一前沿课题的重要组成部分。它探讨了智能体（模型）在相互影响下如何长期存在和发展，属于对Agentic AI系统级演化的深刻洞察。因此，这篇论文与您的研究目标高度契合，应该被筛选出来。"
    },
    {
        "index": "#19",
        "title": "Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues",
        "link": "/arxiv/2512.15302",
        "arxiv_id": "2512.15302",
        "authors": "Xiaotian Zhang, Yuan Wang, Ruizhe Chen, Zeya Wang, Runchen Hou, Zuozhu Liu",
        "summary": "The deployment of Large Language Models (LLMs) in interactive systems necessitates a deep alignment with the nuanced and dynamic preferences of individual users. Current alignment techniques predominantly address universal human values or static, single-turn preferences, thereby failing to address the critical needs of long-term personalization and the initial user cold-start problem. To bridge this gap, we propose PersonalAgent, a novel user-centric lifelong agent designed to continuously infer and adapt to user preferences. PersonalAgent constructs and dynamically refines a unified user profile by decomposing dialogues into single-turn interactions, framing preference inference as a sequential decision-making task. Experiments show that PersonalAgent achieves superior performance over strong prompt-based and policy optimization baselines, not only in idealized but also in noisy conversational contexts, while preserving cross-session preference consistency. Furthermore, human evaluation confirms that PersonalAgent excels at capturing user preferences naturally and coherently. Our findings underscore the importance of lifelong personalization for developing more inclusive and adaptive conversational agents. Our code is available here.",
        "subjects": "Computation and Language",
        "date": "2025-12-17",
        "category": "cs.CL",
        "crawl_time": "2025-12-18T11:00:04.083134",
        "filter_reason": "这篇论文符合我的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文的核心贡献**: 论文提出了一个名为 \"PersonalAgent\" 的新框架，其核心是一个“以用户为中心的终身智能体”。 - **是否符合要求**: 这篇论文的本质**不是**将一个已有的LLM或智能体框架简单地应用到对话领域。相反，它的核心贡献在于**构建了一个具有持续学习和适应能力的新型智能体**。该智能体通过“持续推断并适应用户偏好”和“动态优化一个统一的用户画像”来实现其功能。这完全符合“构建、改进或演化 LLM智能体”的核心目标，特别是落在了“自我演化”的范畴。因此，根据第一步的判断，应**保留**。 2.  **第二步：正面指标** - 论文摘要中包含了多个与我研究焦点高度相关的正面指标： - **核心范式**: `LLM-based Agents` (PersonalAgent), `Self-Evolving` (终身智能体, 持续适应)。 - **智能体能力**: `Memory` (构建和动态优化统一的用户画像), `Self-Improvement` (持续推断并适应, 动态优化)。 - 这些指标进一步确认了论文与我的研究课题高度相关。 3.  **第三步：排除标准** - 论文虽然提到了 \"alignment\"，但指的是与“用户偏好”的对齐，而非关于安全、伦理或价值观的“对齐”研究。其主要贡献并非安全或对齐机制。 - 论文内容完全基于文本对话，不涉及视觉或多模态内容。 - 因此，该论文未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美范例。虽然它的应用场景是“对话个性化”，但其**核心贡献是提出了一种新的“自我演化”机制**——即通过将对话分解并构建用户画像，使智能体能跨会话、持续地演化和适应。根据筛选规则，即使应用在特定领域，只要核心是提出新的自我演化机制，就应该保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个名为PersonalAgent的“终身智能体”，其关键机制在于通过动态优化用户画像来实现持续的自我适应和演化。这直接命中了我研究目标中的“自我演化”和“单智能体（记忆）”方向。它并非简单的应用型论文，而是提出了一个具有演化特性的新智能体框架。因此，最终判断为 **True**，应将其纳入筛选范围。"
    },
    {
        "index": "#30",
        "title": "The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops",
        "link": "/arxiv/2512.15053",
        "arxiv_id": "2512.15053",
        "authors": "Fanzhe Fu",
        "summary": "The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based \"prompt engineering,\" fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for \"Observable Software Engineering\" in the era of probabilistic computing.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Software Engineering",
        "date": "2025-12-17",
        "category": "cs.CL",
        "crawl_time": "2025-12-18T11:00:04.093419",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了“LLM智能体及其演化”的多个关键方向。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质不是将LLM作为工具应用，也不是提升LLM的基础推理能力，而是提出了一种全新的、用于**构建和演化LLM智能体**的理论框架和协议。论文的核心是“Meta-Prompting Protocol”，一个“programmable, self-optimizing system”（可编程、自我优化的系统）。这完全符合“构建、改进或演化 LLM智能体”的核心目标，因此直接进入保留队列。 **第二步：正面指标——高度匹配** 论文包含了大量您关注的核心范式和能力指标： *   **核心范式**: 论文提出的“self-optimizing system”直接对应`Self-Evolving`。其“Adversarial Trinity”架构可以被视为一种特殊的`Multi-Agent Systems (MAS)`或复杂单智能体架构。 *   **自我演化机制**: “Adversarial Feedback Loops”（对抗性反馈循环）、“self-optimizing system”以及利用“textual critiques as gradients”（将文本批评作为梯度）进行优化，这些都是`Self-Improvement`、`Self-Refine`和`Iterative Improvement`的典型体现。 *   **智能体能力**: “Auditor”（审计器）的角色和“textual critiques”（文本批评）机制，是`Self-Correction`和`Self-Reflection`的高级形式。整个系统通过Generator（生成器）、Auditor（审计器）和Optimizer（优化器）的协同工作，实现了复杂的`Planning`和执行循环。 **第三步：排除标准——未触发** *   **安全与对齐**: 论文虽然提到了“mitigates hallucination”（减轻幻觉），但这被明确表述为其自我优化框架所带来的**结果**，而非论文的主要研究贡献。论文的核心是提出这个**演化机制本身**，而不是对幻觉进行专门的安全分析。因此，它不属于被排除的安全与对齐范畴。 *   **多模态与视觉**: 论文未涉及视觉或多模态内容。 **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文不是在研究如何提升LLM的数学或逻辑推理能力，而是在构建一个**智能体框架**来执行复杂任务。这个框架通过Generator和Optimizer的协作，实现了超越简单推理链的规划和优化，符合保留条件。 *   **自我演化的应用**: 这篇论文本身就是提出一种新的“自我演化”机制（Adversarial Trinity），因此完全符合保留的例外情况。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种名为“Meta-Prompting Protocol”的创新框架，该框架通过一个由生成器、审计器和优化器组成的“Adversarial Trinity”结构，利用对抗性反馈循环来实现LLM智能体的自我优化和演化。 这精准地命中了您研究目标的三个核心方向： 1.  **单智能体**: 提出了一种具备高级自我反思和自我修正能力的智能体架构。 2.  **多智能体**: “Adversarial Trinity”本身就是一个多角色协作的系统。 3.  **自我演化**: 论文的灵魂在于其“self-optimizing”和“Adversarial Feedback Loops”机制，是典型的自我演化研究。 因此，这篇论文是您研究课题下的高度相关前沿文献，应予以保留。"
    },
    {
        "index": "#3",
        "title": "Stepwise Think-Critique: A Unified Framework for Robust and Interpretable LLM Reasoning",
        "link": "/arxiv/2512.15662",
        "arxiv_id": "2512.15662",
        "authors": "Jiaqi Xu, Cuiling Lan, Xuejin Chen, Yan LU",
        "summary": "Human beings solve complex problems through critical thinking, where reasoning and evaluation are intertwined to converge toward correct solutions. However, most existing large language models (LLMs) decouple reasoning from verification: they either generate reasoning without explicit self-checking or rely on external verifiers to detect errors post hoc. The former lacks immediate feedback, while the latter increases system complexity and hinders synchronized learning. Motivated by human critical thinking, we propose Stepwise Think-Critique (STC), a unified framework that interleaves reasoning and self-critique at each step within a single model. STC is trained with a hybrid reinforcement learning objective combining reasoning rewards and critique-consistency rewards to jointly optimize reasoning quality and self-evaluation. Experiments on mathematical reasoning benchmarks show that STC demonstrates strong critic-thinking capabilities and produces more interpretable reasoning traces, representing a step toward LLMs with built-in critical thinking.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.844690",
        "filter_reason": "这篇论文的核心贡献是提出了一个名为“Stepwise Think-Critique (STC)”的统一框架，该框架在单一大语言模型内部，将推理过程与逐步的自我批判机制交织在一起。这完全符合您的研究范围。 以下是根据您的筛选标准进行的详细判断过程： 1.  **第一步：核心判断——保留** - **论文本质**: 这篇论文的本质是**构建和改进LLM智能体**。它没有将LLM作为一个黑箱工具去解决某个特定领域（如生物、金融）的问题，而是提出了一个新的**方法论框架（STC）**来增强LLM自身的内在能力。 - **排除项分析**: - 它不是“非演化型应用”，因为其核心是提出一种新的智能体工作机制。 - 它不是“非Agentic的推理”。虽然论文标题和摘要多次提到“Reasoning”，但其核心创新点在于引入了“self-critique”（自我批判）这一机制。这种在推理过程中进行即时自我检查和评估的循环，是智能体“自我反思”和“自我修正”能力的核心体现，超越了单纯提升LLM基础数学或逻辑能力的范畴。它定义了一个新的Agentic推理范式。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文提出的STC框架本质上是一个`LLM-based Agent`框架。 - **智能体能力**: 论文的核心贡献直接对应了多个关键能力： - `Self-Correction` / `Self-Reflection`: “self-critique”是自我反思和自我修正的直接实现。 - `Planning`: 在复杂任务中进行多步推理，并在每一步进行评估，这是一种高级的规划能力。 - 该框架与`ReAct`（Reason+Act）在思想上高度相似，都是通过循环交互来提升任务表现，只是STC将“Act”替换为了内部的“Critique”。 3.  **第三步：排除标准——未触发** - **安全与对齐**: 论文的主要目标是提升推理的鲁棒性和可解释性，但其核心贡献是“批判性思维”这一机制，而非研究Safety、Alignment或可解释性本身。可解释性是STC框架带来的一个积极**结果**，而不是其研究的**核心方法论**。 - **多模态与视觉**: 论文未涉及多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“推理/规划”特殊情况的完美范例。它**应该被保留**，因为它研究的是“智能体如何进行规划或在复杂任务中进行多步推理”，并且提出了一个新的Agentic框架（STC）。它不是简单地通过数据或微调来提升LLM的基础推理能力，而是构建了一个包含自我批判循环的、更自主的推理过程。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个具有内置“自我批判”能力的LLM智能体框架。这直接命中了您研究目标中的**单智能体**方向，特别是**自我反思**和**自我修正**这两个关键子方向。它提出的是一种新的智能体演化（向更稳健、更自主的方向演化）的机制，而非简单的应用或基础能力提升。因此，这篇论文高度符合您的研究范围，应被保留。"
    },
    {
        "index": "#1",
        "title": "Artism: AI-Driven Dual-Engine System for Art Generation and Critique",
        "link": "/arxiv/2512.15710",
        "arxiv_id": "2512.15710",
        "authors": "Shuai Liu, Yiqing Tian, Yang Chen, Mar Canet Sola",
        "summary": "This paper proposes a dual-engine AI architectural method designed to address the complex problem of exploring potential trajectories in the evolution of art. We present two interconnected components: AIDA (an artificial artist social network) and the Ismism Machine, a system for critical analysis. The core innovation lies in leveraging deep learning and multi-agent collaboration to enable multidimensional simulations of art historical developments and conceptual innovation patterns. The framework explores a shift from traditional unidirectional critique toward an intelligent, interactive mode of reflexive practice. We are currently applying this method in experimental studies on contemporary art concepts. This study introduces a general methodology based on AI-driven critical loops, offering new possibilities for computational analysis of art.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.843484",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将AI工具应用于艺术领域，而是提出了一种全新的“双引擎AI架构方法”。其核心创新在于构建了一个由“人工艺术家社交网络”和“批判分析机器”组成的系统。这明确指向了**构建和改进LLM智能体（或更广义的AI智能体）的方法论和新框架**，而非仅仅将其作为工具使用。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **多智能体**: 摘要中明确提到了 `AIDA (an artificial artist social network)` 和 `multi-agent collaboration`。这直接命中了“多智能体”方向，特别是“协作”和“社会学习”的子方向。 - **自我演化**: 论文提出了 `AI-driven critical loops` 和 `reflexive practice`（反思性实践）。这描述了一个智能体（艺术家）生成作品、另一个智能体（评论家）进行批判、然后前者根据反馈进行改进的迭代过程。这完全符合“自我反思”和“自我完善”的演化机制。 - **智能体能力**: “批判循环”和“反思性实践”是 `Self-Correction` 和 `Self-Reflection` 能力的具体体现。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或幻觉，因此不触发排除标准。 - 虽然论文涉及“艺术生成”，可能用到多模态或扩散模型，但摘要明确指出其核心是“架构方法”和“多智能体协作”，而非生成模型本身。因此，这些模型应被视为智能体用于创作的“工具”，而非研究的核心，符合筛选标准中的特殊处理规则。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是本案例的关键。虽然论文的应用领域是“当代艺术概念”，但其核心贡献是提出了一种**新的“自我演化”机制**——即通过多智能体协作和批判循环实现的反思性实践。根据筛选规则第四条的第二点，这种情况应作为例外**保留**。论文的价值在于这个可泛化的“方法论”，而非其在艺术领域的具体应用结果。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的**多智能体系统**，该系统通过**协作与批判循环**实现了**自我反思和迭代改进**。这完美契合了研究课题中的“多智能体”和“自我演化”两个核心方向。尽管它以艺术为应用背景，但其提出的框架和方法论具有普适性，是典型的Agentic AI研究。因此，最终判断为 **True**。"
    },
    {
        "index": "#10",
        "title": "SCOPE: Prompt Evolution for Enhancing Agent Effectiveness",
        "link": "/arxiv/2512.15374",
        "arxiv_id": "2512.15374",
        "authors": "Zehua Pei, Hui-Ling Zhen, Shixiong Kai, Sinno Jialin Pan, Yunhe Wang, Mingxuan Yuan, Bei Yu",
        "summary": "Large Language Model (LLM) agents are increasingly deployed in environments that generate massive, dynamic contexts. However, a critical bottleneck remains: while agents have access to this context, their static prompts lack the mechanisms to manage it effectively, leading to recurring Corrective and Enhancement failures. To address this capability gap, we introduce \\textbf{SCOPE} (Self-evolving Context Optimization via Prompt Evolution). SCOPE frames context management as an \\textit{online optimization} problem, synthesizing guidelines from execution traces to automatically evolve the agent's prompt. We propose a Dual-Stream mechanism that balances tactical specificity (resolving immediate errors) with strategic generality (evolving long-term principles). Furthermore, we introduce Perspective-Driven Exploration to maximize strategy coverage, increasing the likelihood that the agent has the correct strategy for any given task. Experiments on the HLE benchmark show that SCOPE improves task success rates from 14.23\\% to 38.64\\% without human intervention. We make our code publicly available at https://github.com/JarvisPei/SCOPE.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.854910",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的“自我演化”研究方向高度契合。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个特定领域的问题，而是提出了一种名为SCOPE的**新方法论**，用于**改进和演化LLM智能体本身**。论文的核心是解决智能体在动态环境中的“静态提示”瓶颈，通过“自动演化智能体的提示”来提升其能力。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文标题和摘要中明确提到了 `Self-Evolving`，并将其定义为 `Self-evolving Context Optimization via Prompt Evolution`。这直接命中了您的研究焦点。 - **演化机制**: 论文的核心机制是 `Prompt Evolution`（提示演化），这是一种 `Self-Improvement`（自我完善）和 `Iterative Improvement`（迭代改进）的具体实现。它通过从执行轨迹中学习来在线优化，这体现了智能体通过经验和反馈进行自我演化的过程。 - **智能体能力**: 论文提到的“Dual-Stream mechanism”旨在平衡“tactical specificity (resolving immediate errors)”，这本质上是一种高级的 `Self-Correction`（自我修正）能力。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题。 - 论文也未涉及 `Vision`、`MLLMs` 等多模态内容，其焦点完全在文本提示和智能体逻辑的演化上。 - 因此，该论文未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是提出一种**新的自我演化机制**的典型范例。即使它在某个特定基准（HLE）上测试，其核心贡献是SCOPE这个通用框架本身，而不是它在某个领域的应用。根据您的规则，这种情况应明确保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种让LLM智能体通过演化其提示来进行自我完善的新框架（SCOPE）。这精准地命中了您研究课题中的“自我演化”方向，并且不涉及任何排除领域。因此，这篇论文是您需要筛选出的高质量前沿论文。"
    },
    {
        "index": "#15",
        "title": "Beyond Fast and Slow: Cognitive-Inspired Elastic Reasoning for Large Language Models",
        "link": "/arxiv/2512.15089",
        "arxiv_id": "2512.15089",
        "authors": "Jinwu Hu, Dongjin Yang, Langyu Bian, Zhiquan Wen, Yufeng Wang, Yaofo Chen, Bin Xiao, Yuanqing Li, Mingkui Tan",
        "summary": "Large language models (LLMs) have demonstrated impressive performance across various language tasks. However, existing LLM reasoning strategies mainly rely on the LLM itself with fast or slow mode (like o1 thinking) and thus struggle to balance reasoning efficiency and accuracy across queries of varying difficulties. In this paper, we propose Cognitive-Inspired Elastic Reasoning (CogER), a framework inspired by human hierarchical reasoning that dynamically selects the most suitable reasoning strategy for each query. Specifically, CogER first assesses the complexity of incoming queries and assigns them to one of several predefined levels, each corresponding to a tailored processing strategy, thereby addressing the challenge of unobservable query difficulty. To achieve automatic strategy selection, we model the process as a Markov Decision Process and train a CogER-Agent using reinforcement learning. The agent is guided by a reward function that balances solution quality and computational cost, ensuring resource-efficient reasoning. Moreover, for queries requiring external tools, we introduce Cognitive Tool-Assisted Reasoning, which enables the LLM to autonomously invoke external tools within its chain-of-thought. Extensive experiments demonstrate that CogER outperforms state-of-the-art Test-Time scaling methods, achieving at least a 13% relative improvement in average exact match on In-Domain tasks and an 8% relative gain on Out-of-Domain tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.857259",
        "filter_reason": "这篇论文符合筛选标准，应被保留。 **判断过程和核心依据如下：** 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为CogER（Cognitive-Inspired Elastic Reasoning）的框架，用于构建一个能够动态选择最优推理策略的LLM智能体。这并非将现有智能体简单应用于特定领域，而是提出了一种**构建和改进LLM智能体的新方法论**。论文的重点不在于提升LLM底层的数学或逻辑能力，而在于构建一个外部的、基于智能体的决策系统（CogER-Agent）来管理和优化LLM的推理过程，这完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **Agentic AI / LLM-based Agents**: 论文明确提出了一个“CogER-Agent”，通过强化学习训练，使其能够自主决策。 *   **Planning**: 该智能体的核心任务就是评估查询复杂度并规划出最合适的推理路径，这是一种元规划能力。 *   **Tool Use / Tool Augmentation**: 论文专门介绍了“Cognitive Tool-Assisted Reasoning”，使智能体能够自主调用外部工具，这是智能体的关键能力之一。 *   **Self-Improvement / Iterative Improvement**: CogER-Agent通过强化学习进行训练，在奖励函数的引导下不断迭代优化其策略选择，这是一种基于反馈的自我完善过程。 3.  **第三步：排除标准——不触犯** 论文的研究焦点是提升推理的效率和准确性，不涉及安全、对齐、可解释性或视觉等多模态问题，因此不触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 根据第四步的特殊情况处理规则，这篇论文是关于“**智能体如何进行规划或在复杂任务中进行多步推理**”的典型范例。它提出的CogER框架就是一种新的Agentic规划框架，其核心是让一个智能体（CogER-Agent）来决定如何使用另一个智能体（LLM）进行推理。这完全符合“保留”的条件，因为它不是在改进LLM本身的基础推理能力，而是在构建一个更高层次的智能体系统来管理推理过程。 **最终决策：** 综上所述，该论文通过引入一个学习型智能体来动态管理LLM的推理策略和工具使用，其核心贡献在于**构建和改进了LLM智能体的能力**，与研究课题“LLM智能体及其演化”中的“**单智能体**”方向（特别是规划和工具使用）高度契合。因此，应判定为符合要求。"
    },
    {
        "index": "#13",
        "title": "CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications",
        "link": "/arxiv/2512.15231",
        "arxiv_id": "2512.15231",
        "authors": "Zhengchao Chen, Haoran Wang, Jing Yao, Pedram Ghamisi, Jun Zhou, Peter M. Atkinson, Bing Zhang",
        "summary": "The automated and intelligent processing of massive remote sensing (RS) datasets is critical in Earth observation (EO). Existing automated systems are normally task-specific, lacking a unified framework to manage diverse, end-to-end workflows--from data preprocessing to advanced interpretation--across diverse RS applications. To address this gap, this paper introduces CangLing-KnowFlow, a unified intelligent agent framework that integrates a Procedural Knowledge Base (PKB), Dynamic Workflow Adjustment, and an Evolutionary Memory Module. The PKB, comprising 1,008 expert-validated workflow cases across 162 practical RS tasks, guides planning and substantially reduces hallucinations common in general-purpose agents. During runtime failures, the Dynamic Workflow Adjustment autonomously diagnoses and replans recovery strategies, while the Evolutionary Memory Module continuously learns from these events, iteratively enhancing the agent's knowledge and performance. This synergy enables CangLing-KnowFlow to adapt, learn, and operate reliably across diverse, complex tasks. We evaluated CangLing-KnowFlow on the KnowFlow-Bench, a novel benchmark of 324 workflows inspired by real-world applications, testing its performance across 13 top Large Language Model (LLM) backbones, from open-source to commercial. Across all complex tasks, CangLing-KnowFlow surpassed the Reflexion baseline by at least 4% in Task Success Rate. As the first most comprehensive validation along this emerging field, this research demonstrates the great potential of CangLing-KnowFlow as a robust, efficient, and scalable automated solution for complex EO challenges by leveraging expert knowledge (Knowledge) into adaptive and verifiable procedures (Flow).",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.856320",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建了一个具有自我演化能力的LLM智能体框架。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心是提出一个名为 \"CangLing-KnowFlow\" 的**统一智能体框架**。它不是简单地将现有智能体应用于遥感领域，而是构建了一个包含新组件（程序性知识库、动态工作流调整、演化记忆模块）的新方法论。这直接命中了“构建、改进LLM智能体”的核心目标。特别是，论文明确提出了一个“演化记忆模块”，使其具备了自我演化的能力，因此不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了大量与你研究焦点高度相关的正面指标： *   **核心范式**: `LLM-based Agents` (明确提及 \"intelligent agent framework\")。 *   **智能体能力**: `Planning` (\"guides planning\", \"replans recovery strategies\"), `Memory` (\"Procedural Knowledge Base\", \"Evolutionary Memory Module\"), `Self-Correction` (\"Dynamic Workflow Adjustment autonomously diagnoses and replans\")。 *   **演化机制**: `Self-Improvement` (\"iteratively enhancing the agent's knowledge and performance\"), `Iterative Improvement` (\"continuously learns from these events\")。其中的 \"Evolutionary Memory Module\" 是一个非常强烈的信号，直接对应你的“自我演化”研究方向。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于智能体的框架设计和性能提升，而非安全、对齐或可解释性。虽然论文处理的是遥感数据（通常与视觉相关），但视觉数据在这里是智能体感知和处理的**环境输入**，研究的核心是智能体如何利用这些数据进行规划、学习和演化，而不是视觉模型本身。因此，它符合“用作智能体感知环境的工具”的例外情况，不应被排除。 4.  **第四步：处理特殊和模糊情况——适用例外规则** 这篇论文是“自我演化的应用”的完美范例。它的应用领域是遥感，但其**核心贡献是提出了一种新的“自我演化”机制**（即演化记忆模块和动态工作流调整）。根据你的筛选规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 因此，这篇论文应该被保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个集成了规划、记忆和**自我演化**能力的LLM智能体新框架。尽管它在遥感领域进行验证，但其方法论和演化机制是通用且前沿的，完全契合你关于“LLM智能体及其演化”的研究课题，特别是“单智能体”和“自我演化”两个方向。因此，最终判断为 **True**。"
    },
    {
        "index": "#19",
        "title": "AgroAskAI: A Multi-Agentic AI Framework for Supporting Smallholder Farmers' Enquiries Globally",
        "link": "/arxiv/2512.14910",
        "arxiv_id": "2512.14910",
        "authors": "Nadine Angela Cantonjos, Arpita Biswas",
        "summary": "Agricultural regions in rural areas face damage from climate-related risks, including droughts, heavy rainfall, and shifting weather patterns. Prior research calls for adaptive risk-management solutions and decision-making strategies. To this end, artificial intelligence (AI), particularly agentic AI, offers a promising path forward. Agentic AI systems consist of autonomous, specialized agents capable of solving complex, dynamic tasks. While past systems have relied on single-agent models or have used multi-agent frameworks only for static functions, there is a growing need for architectures that support dynamic collaborative reasoning and context-aware outputs. To bridge this gap, we present AgroAskAI, a multi-agent reasoning system for climate adaptation decision support in agriculture, with a focus on vulnerable rural communities. AgroAskAI features a modular, role-specialized architecture that uses a chain-of-responsibility approach to coordinate autonomous agents, integrating real-time tools and datasets. The system has built-in governance mechanisms that mitigate hallucination and enable internal feedback for coherent, locally relevant strategies. The system also supports multilingual interactions, making it accessible to non-English-speaking farmers. Experiments on common agricultural queries related to climate adaptation show that, with additional tools and prompt refinement, AgroAskAI delivers more actionable, grounded, and inclusive outputs. Our experimental results highlight the potential of agentic AI for sustainable and accountable decision support in climate adaptation for agriculture.",
        "subjects": "Artificial Intelligence, Computers and Society",
        "date": "2025-12-16",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.864303",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。 我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个已有的AI框架应用到农业领域。它的核心贡献是提出了一种名为AgroAskAI的**多智能体推理系统**，其核心创新在于一种**模块化、角色专业化的架构**，并采用**责任链模式**来协调自主智能体。这完全符合您筛选标准第一步中的“保留”条件，即论文的核心是关于构建LLM智能体或多智能体系统的方法论或新框架。它是在解决“如何构建一个支持动态协作的多智能体系统”这个Agentic AI的核心问题，而不是“如何用AI解决农业问题”。 2.  **第二步：正面指标** - 论文包含了您关注的核心正面指标，这进一步支持了保留的决定： - **核心范式**: `Agentic AI`, `Multi-Agent Systems (MAS)` 在标题和摘要中被明确提及。 - **多智能体**: `Collaboration`（动态协作推理）是其架构要解决的关键问题。 - **智能体能力**: `Tool Use`（集成实时工具和数据集）是其架构的重要组成部分。摘要中提到的“内部反馈”也暗示了某种形式的`Self-Correction`或`Self-Reflection`机制。 3.  **第三步：排除标准** - **不排除**。论文中提到了“减轻幻觉”和“治理机制”，但这被描述为系统的一个内置特性，是为了保证输出质量，而不是论文的主要研究贡献。论文的核心是架构设计，而非安全或对齐技术本身，因此不触及“安全与对齐”的排除红线。论文也未涉及多模态与视觉。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确提出了一个“多智能体推理系统”，用于“动态协作推理”，这完全属于“保留”的范畴，是关于智能体如何进行规划和推理的框架性研究。 - **自我演化的应用**: 虽然这不直接是“自我演化”论文，但其处理方式与该规则的精神一致。论文的核心是提出一种新的**多智能体协作机制**（一种演化/改进），即使它被应用在特定领域（农业），也应被保留。 **最终决策**: 综合以上分析，该论文的核心贡献在于**提出并验证了一种新颖的多智能体协作架构**，以实现动态推理和工具使用。尽管其应用场景是农业，但其研究本质是推动Agentic AI，特别是多智能体系统（Multi-Agent）方向的方法论进步。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标高度一致。因此，最终判断为 **True**。"
    },
    {
        "index": "#21",
        "title": "GR-Agent: Adaptive Graph Reasoning Agent under Incomplete Knowledge",
        "link": "/arxiv/2512.14766",
        "arxiv_id": "2512.14766",
        "authors": "Dongzhuoran Zhou, Yuqicheng Zhu, Xiaxia Wang, Hongkuan Zhou, Jiaoyan Chen, Steffen Staab, Yuan He, Evgeny Kharlamov",
        "summary": "Large language models (LLMs) achieve strong results on knowledge graph question answering (KGQA), but most benchmarks assume complete knowledge graphs (KGs) where direct supporting triples exist. This reduces evaluation to shallow retrieval and overlooks the reality of incomplete KGs, where many facts are missing and answers must be inferred from existing facts. We bridge this gap by proposing a methodology for constructing benchmarks under KG incompleteness, which removes direct supporting triples while ensuring that alternative reasoning paths required to infer the answer remain. Experiments on benchmarks constructed using our methodology show that existing methods suffer consistent performance degradation under incompleteness, highlighting their limited reasoning ability. To overcome this limitation, we present the Adaptive Graph Reasoning Agent (GR-Agent). It first constructs an interactive environment from the KG, and then formalizes KGQA as agent environment interaction within this environment. GR-Agent operates over an action space comprising graph reasoning tools and maintains a memory of potential supporting reasoning evidence, including relevant relations and reasoning paths. Extensive experiments demonstrate that GR-Agent outperforms non-training baselines and performs comparably to training-based methods under both complete and incomplete settings.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.865286",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建了一个新颖的LLM智能体框架。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于知识图谱问答（KGQA）领域，而是针对现有方法在知识不完整情况下推理能力不足的问题，**提出了一个全新的智能体框架——GR-Agent**。论文的核心是构建这个智能体的方法论，包括它如何与环境交互、如何使用工具、如何维护记忆，这完全符合“构建、改进LLM智能体”的核心目标。它不是非演化型应用，因为其贡献是智能体架构本身，而非应用结果。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文标题和摘要明确提出了 \"Agent\"，并将问题形式化为 \"agent environment interaction\"，这是典型的 `Agentic AI` 范式。 - **智能体能力**: 摘要中明确指出，GR-Agent \"operates over an action space comprising graph reasoning tools\"（**工具使用**）和 \"maintains a memory of potential supporting reasoning evidence\"（**记忆**）。这两个都是单智能体研究的核心能力。 - **推理/规划**: 智能体在不完整的知识图谱中寻找 \"alternative reasoning paths\" 来推断答案，这属于智能体在复杂任务中的多步推理和规划，符合筛选标准第四条中的“保留”情况。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性，也不涉及多模态或视觉。因此，不触及任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 如上所述，这篇论文研究的是智能体如何在特定环境（不完整KG）中进行规划和推理，而不是提升LLM本身的基础数学或逻辑能力。因此，它属于应被保留的范畴。 5.  **第五步：最终决策** - 综合来看，这篇论文的核心贡献是**GR-Agent**，一个具备**工具使用**和**记忆**能力的自适应图推理智能体。它为解决知识图谱推理问题提供了一个新的智能体框架，其研究焦点完全落在你定义的“单智能体”方向上。因此，这篇论文与你的研究课题高度相关，应当保留。"
    },
    {
        "index": "#25",
        "title": "Can LLMs Guide Their Own Exploration? Gradient-Guided Reinforcement Learning for LLM Reasoning",
        "link": "/arxiv/2512.15687",
        "arxiv_id": "2512.15687",
        "authors": "Zhenwen Liang, Sidi Lu, Wenhao Yu, Kishan Panaganti, Yujun Zhou, Haitao Mi, Dong Yu",
        "summary": "Reinforcement learning has become essential for strengthening the reasoning abilities of large language models, yet current exploration mechanisms remain fundamentally misaligned with how these models actually learn. Entropy bonuses and external semantic comparators encourage surface level variation but offer no guarantee that sampled trajectories differ in the update directions that shape optimization. We propose G2RL, a gradient guided reinforcement learning framework in which exploration is driven not by external heuristics but by the model own first order update geometry. For each response, G2RL constructs a sequence level feature from the model final layer sensitivity, obtainable at negligible cost from a standard forward pass, and measures how each trajectory would reshape the policy by comparing these features within a sampled group. Trajectories that introduce novel gradient directions receive a bounded multiplicative reward scaler, while redundant or off manifold updates are deemphasized, yielding a self referential exploration signal that is naturally aligned with PPO style stability and KL control. Across math and general reasoning benchmarks (MATH500, AMC, AIME24, AIME25, GPQA, MMLUpro) on Qwen3 base 1.7B and 4B models, G2RL consistently improves pass@1, maj@16, and pass@k over entropy based GRPO and external embedding methods. Analyzing the induced geometry, we find that G2RL expands exploration into substantially more orthogonal and often opposing gradient directions while maintaining semantic coherence, revealing that a policy own update space provides a far more faithful and effective basis for guiding exploration in large language model reinforcement learning.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.867211",
        "filter_reason": "这篇论文符合我的研究范围，核心依据在于其贡献属于“自我演化”方向。 **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM作为工具去解决某个外部领域的问题，也不是单纯提升LLM的基础推理能力。它的核心贡献是提出了一种名为G2RL的新框架，这是一种**用于强化学习（RL）的元方法**。该框架的核心机制是让LLM通过分析自身的梯度更新几何来引导其探索过程，这是一种典型的**自我完善和自我演化**机制。因此，它符合“构建、改进或演化LLM智能体”的核心目标。 **第二步：正面指标** - 论文与我的核心关注点高度匹配： - **自我演化**: 论文标题中的“Guide Their Own Exploration”和摘要中的“self referential exploration signal”直接点明了其自我演化的特性。G2RL框架让模型根据自身的更新空间来决定探索方向，这是一种内在的、自驱动的演化机制。 - **自我完善**: 整个框架的目标是让模型通过更智能的探索来完善自身的推理策略，这完全符合Self-Improvement的定义。 - **Agentic AI**: 虽然论文没有明确使用“Agent”一词，但通过强化学习来学习多步推理策略，是构建智能体能力（特别是规划和决策能力）的核心技术之一。G2RL可以被看作是一种提升智能体学习效率的新方法。 **第三步：排除标准** - 论文不涉及任何关于安全、对齐、可解释性或视觉多模态的内容，因此不触犯排除标准。 **第四步：处理特殊和模糊情况** - **推理/规划**: 这是本论文最需要辨析的地方。论文确实在数学和通用推理基准上进行了评估，看起来像是在提升LLM的基础推理能力。然而，其核心贡献**并非**一种新的推理提示技巧（如CoT变体）或一个非Agentic的微调数据集。相反，它提出了一种**新的学习范式**——如何让模型在RL训练中更有效地探索和学习推理能力。这种“如何学习”的元机制，正是“自我演化”研究的核心。根据筛选规则第四条的特殊情况：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” 本文的“特定领域”就是“推理任务”，但其核心是G2RL这一自我演化机制，因此应该保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是G2RL，一种让LLM通过分析自身梯度来引导探索的强化学习框架。这是一种新颖的、内在驱动的**自我演化**机制，完全符合我研究课题中的“自我演化”方向。尽管它以推理任务为验证场景，但其方法论的本质是关于智能体如何自我完善和学习，而非简单的应用或基础能力提升。因此，最终判断为符合要求。"
    },
    {
        "index": "#86",
        "title": "Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent",
        "link": "/arxiv/2512.14990",
        "arxiv_id": "2512.14990",
        "authors": "Mehil B Shah, Mohammad Masudur Rahman, Foutse Khomh",
        "summary": "Despite their wide adoption in various domains (e.g., healthcare, finance, software engineering), Deep Learning (DL)-based applications suffer from many bugs, failures, and vulnerabilities. Reproducing these bugs is essential for their resolution, but it is extremely challenging due to the inherent nondeterminism of DL models and their tight coupling with hardware and software environments. According to recent studies, only about 3% of DL bugs can be reliably reproduced using manual approaches. To address these challenges, we present RepGen, a novel, automated, and intelligent approach for reproducing deep learning bugs. RepGen constructs a learning-enhanced context from a project, develops a comprehensive plan for bug reproduction, employs an iterative generate-validate-refine mechanism, and thus generates such code using an LLM that reproduces the bug at hand. We evaluate RepGen on 106 real-world deep learning bugs and achieve a reproduction rate of 80.19%, a 19.81% improvement over the state-of-the-art measure. A developer study involving 27 participants shows that RepGen improves the success rate of DL bug reproduction by 23.35%, reduces the time to reproduce by 56.8%, and lowers participants' cognitive load.",
        "subjects": "Software Engineering, Artificial Intelligence, Machine Learning",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.902864",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于软件工程领域，而是提出了一个名为 **RepGen** 的、具有特定方法论和框架的 **智能体**。其核心贡献在于构建这个智能体的工作机制，而非仅仅是应用结果。论文明确描述了RepGen的四个关键步骤：构建上下文、制定计划、迭代生成-验证-精炼，这构成了一个完整的智能体工作流。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文标题和摘要中明确提到了 \"Intelligent Agent\"，这直接对应 `LLM-based Agents`。 - **智能体能力**: 摘要中提到 \"develops a comprehensive plan\"，这直接命中了 `Planning` 能力。同时，\"employs an iterative generate-validate-refine mechanism\" 完美契合了 `Self-Correction`、`Self-Refine` 和 `Iterative Improvement` 这些自我演化的核心机制。 3.  **第三步：排除标准** - 论文的主要贡献是关于如何构建一个能自动复现Bug的智能体，其焦点在于智能体的能力和效率，而非安全性、可解释性或对齐问题。因此，不触发安全与对齐相关的排除标准。 - 论文处理的是代码和文本，不涉及视觉或多模态内容，因此也不触发多模态相关的排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的核心是智能体如何为复现一个复杂的Bug“制定一个全面的计划”，这属于智能体在复杂任务中的多步规划和推理，符合保留条件。 - **自我演化的应用**: 这是最关键的一点。虽然论文的应用领域是软件工程（一个特定领域），但其核心贡献是提出了一种新的“自我演化”机制——即“迭代的生成-验证-精炼机制”。根据筛选规则第四条的第二点，这种“提出新的自我演化机制”的论文，即使应用在特定领域，也应该被**保留**。RepGen智能体通过验证步骤的反馈来不断精炼其生成的代码，这正是自我完善和迭代的体现。 **最终决策**: 综合以上分析，该论文的核心贡献是构建了一个名为RepGen的LLM智能体，该智能体具备**规划**和通过**迭代反馈进行自我精炼**的能力。这完全符合我研究课题中的“单智能体”和“自我演化”两个核心方向。因此，这篇论文高度相关，应被筛选出来。"
    },
    {
        "index": "#95",
        "title": "Imitation Learning for Multi-turn LM Agents via On-policy Expert Corrections",
        "link": "/arxiv/2512.14895",
        "arxiv_id": "2512.14895",
        "authors": "Niklas Lauffer, Xiang Deng, Srivatsa Kundurthy, Brad Kenstler, Jeff Da",
        "summary": "A popular paradigm for training LM agents relies on imitation learning, fine-tuning on expert trajectories. However, we show that the off-policy nature of imitation learning for multi-turn LM agents suffers from the fundamental limitation known as covariate shift: as the student policy's behavior diverges from the expert's, it encounters states not present in the training data, reducing the effectiveness of fine-tuning. Taking inspiration from the classic DAgger algorithm, we propose a novel data generation methodology for addressing covariate shift for multi-turn LLM training. We introduce on-policy expert corrections (OECs), partially on-policy data generated by starting rollouts with a student model and then switching to an expert model part way through the trajectory. We explore the effectiveness of our data generation technique in the domain of software engineering (SWE) tasks, a multi-turn setting where LLM agents must interact with a development environment to fix software bugs. Our experiments compare OEC data against various other on-policy and imitation learning approaches on SWE agent problems and train models using a common rejection sampling (i.e., using environment reward) combined with supervised fine-tuning technique. Experiments find that OEC trajectories show a relative 14% and 13% improvement over traditional imitation learning in the 7b and 32b setting, respectively, on SWE-bench verified. Our results demonstrate the need for combining expert demonstrations with on-policy data for effective multi-turn LM agent training.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.905709",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM智能体应用到软件工程领域，而是提出了一种**全新的训练方法论**来**改进**多轮LLM智能体的性能。其核心贡献是“On-policy Expert Corrections (OECs)”这一数据生成技术，旨在解决训练智能体时遇到的“协变量偏移”这一根本性问题。这直接对应了您筛选目标中的“**改进** LLM智能体”的论文。 2.  **第二步：正面指标** - 论文明确命中了多个核心关注点： - **核心范式**: `LLM-based Agents` (标题和摘要中多次提及)。 - **智能体能力**: 论文研究的“多轮LM智能体”必然涉及`Planning`（规划多步操作）和`Tool Use`（与开发环境交互来修复bug）。虽然未直接提及`ReAct`，但其交互模式与ReAct范式高度一致。 - **演化机制**: 论文的核心是提出一种更有效的训练方法，使智能体能够更好地从专家和环境中学习，这属于`Iterative Improvement`（迭代改进）的范畴，是提升智能体能力的关键环节。 3.  **第三步：排除标准** - 论文的主要贡献是关于提升智能体的训练效率和性能，不涉及`Safety`、`Alignment`、`Interpretability`等安全与对齐问题。 - 论文的研究对象是基于文本的代码和开发环境，不涉及`Vision`、`MLLMs`等多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文关注的是智能体在复杂、多步骤任务（修复软件bug）中的规划和执行能力，而非提升LLM本身的基础数学或逻辑推理能力。因此，这属于应**保留**的“智能体层面的推理/规划”。 - **自我演化的应用**: 虽然论文在软件工程（SWE）任务上进行验证，但其核心是提出一种通用的智能体训练改进方法（OEC），而不是一个针对特定领域的应用。因此，它不属于“非演化型应用”的排除范畴。 **最终决策**: 该论文的核心贡献在于提出了一种名为“On-policy Expert Corrections”的新颖训练方法，用以**改进**多轮LLM智能体的能力。这完全契合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标。论文聚焦于单智能体的规划和工具使用能力，并且其提出的方法论具有通用性，软件工程任务仅作为其有效性的验证平台。因此，这篇论文是高度相关且应被保留的前沿研究。"
    },
    {
        "index": "#102",
        "title": "Let the Barbarians In: How AI Can Accelerate Systems Performance Research",
        "link": "/arxiv/2512.14806",
        "arxiv_id": "2512.14806",
        "authors": "Audrey Cheng, Shu Liu, Melissa Pan, Zhifei Li, Shubham Agarwal, Mert Cemri, Bowen Wang, Alexander Krentsel, Tian Xia, Jongseok Park, Shuo Yang, Jeff Chen, Lakshya Agrawal, Ashwin Naren, Shulu Li, Ruiying Ma, Aditya Desai, Jiarong Xing, Koushik Sen, Matei Zaharia, Ion Stoica",
        "summary": "Artificial Intelligence (AI) is beginning to transform the research process by automating the discovery of new solutions. This shift depends on the availability of reliable verifiers, which AI-driven approaches require to validate candidate solutions. Research focused on improving systems performance is especially well-suited to this paradigm because system performance problems naturally admit such verifiers: candidates can be implemented in real systems or simulators and evaluated against predefined workloads. We term this iterative cycle of generation, evaluation, and refinement AI-Driven Research for Systems (ADRS). Using several open-source ADRS instances (i.e., OpenEvolve, GEPA, and ShinkaEvolve), we demonstrate across ten case studies (e.g., multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling) that ADRS-generated solutions can match or even outperform human state-of-the-art designs. Based on these findings, we outline best practices (e.g., level of prompt specification, amount of feedback, robust evaluation) for effectively using ADRS, and we discuss future research directions and their implications. Although we do not yet have a universal recipe for applying ADRS across all of systems research, we hope our preliminary findings, together with the challenges we identify, offer meaningful guidance for future work as researcher effort shifts increasingly toward problem formulation and strategic oversight. Note: This paper is an extension of our prior work [14]. It adds extensive evaluation across multiple ADRS frameworks and provides deeper analysis and insights into best practices.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.907906",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用于“系统性能研究”领域。它的核心贡献是提出并系统化分析了一个名为 **AI-Driven Research for Systems (ADRS)** 的研究范式。该范式的核心是“一个由生成、评估和优化组成的迭代循环”。这完全符合“自我演化”的定义，即智能体通过环境反馈（评估）进行自我完善和迭代（优化）。论文的重点是这个**方法论框架本身**，而不是它在某个具体问题上的应用结果。 2.  **第二步：正面指标** - 论文的核心概念与我的研究焦点高度契合。 - **核心范式**: 论文虽然没有直接使用 `Agentic AI` 这个词，但其描述的ADRS范式本质上是一个Agentic系统，它自主地执行任务（生成解决方案）、与环境交互（在模拟器/真实系统中评估）、并根据反馈进行自我调整（优化）。 - **演化机制**: 论文明确包含了 `Self-Evolving` 的核心思想，并具体化为 `Iterative Improvement` 和 `Self-Refine` 的过程。标题中的 \"OpenEvolve\", \"GEPA\", \"ShinkaEvolve\" 等实例名称也直接体现了“演化”的主题。 3.  **第三步：排除标准** - 论文不涉及任何关于安全、对齐、可解释性或视觉多模态的内容，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是判断这篇论文的关键。根据筛选规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” - 本论文正是这一规则的完美范例。它的应用领域是“系统性能研究”（如云调度、负载均衡），但其**核心贡献是ADRS这个自我演化的机制**。论文的重点在于分析这个机制的有效性、最佳实践和未来方向，而不是解决某个特定的系统问题。因此，它完全符合“保留”的例外情况。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建、分析和推广一个名为ADRS的**自我演化研究框架**。它直接对“自我演化”这一研究方向做出了贡献，提供了方法论、实例分析和最佳实践。尽管其应用场景是系统研究，但其研究焦点本身是关于智能体如何通过迭代反馈进行自我完善，这与我的研究目标“LLM智能体及其演化”中的“自我演化”方向完全一致。因此，应予以保留。"
    },
    {
        "index": "#101",
        "title": "MALCDF: A Distributed Multi-Agent LLM Framework for Real-Time Cyber",
        "link": "/arxiv/2512.14846",
        "arxiv_id": "2512.14846",
        "authors": "Arth Bhardwaj, Sia Godika, Yuvam Loonker",
        "summary": "Traditional, centralized security tools often miss adaptive, multi-vector attacks. We present the Multi-Agent LLM Cyber Defense Framework (MALCDF), a practical setup where four large language model (LLM) agents-Detection, Intelligence, Response, and Analysis-work together in real time. Agents communicate over a Secure Communication Layer (SCL) with encrypted, ontology-aligned messages, and produce audit-friendly outputs (e.g., MITRE ATT&CK mappings). For evaluation, we keep the test simple and consistent: all reported metrics come from the same 50-record live stream derived from the CICIDS2017 feature schema. CICIDS2017 is used for configuration (fields/schema) and to train a practical ML baseline. The ML-IDS baseline is a Lightweight Random Forest IDS (LRF-IDS) trained on a subset of CICIDS2017 and tested on the 50-record stream, with no overlap between training and test records. In experiments, MALCDF reaches 90.0% detection accuracy, 85.7% F1-score, and 9.1% false-positive rate, with 6.8s average per-event latency. It outperforms the lightweight ML-IDS baseline and a single-LLM setup on accuracy while keeping end-to-end outputs consistent. Overall, this hands-on build suggests that coordinating simple LLM agents with secure, ontology-aligned messaging can improve practical, real-time cyber defense.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.907460",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出并构建了一个名为“MALCDF”的**分布式多智能体LLM框架**。它不是简单地将一个已有的智能体框架应用到网络安全领域，而是详细设计了四个具有不同职责（Detection, Intelligence, Response, Analysis）的LLM智能体，并定义了它们之间的协作机制和通信协议（Secure Communication Layer）。这完全符合“构建、改进或演化LLM智能体”的核心目标，特别是属于“多智能体”方向。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的标题和核心。 - **多智能体**: 论文明确描述了智能体间的 `Collaboration`（work together）和 `Communication`（communicate over a Secure Communication Layer）。 - 这些正面指标强烈表明该论文与我的研究范围高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 虽然论文的应用领域是网络安全，但其**主要贡献并非安全理论本身**。论文的重点在于“如何通过多智能体协作来实现网络防御”，即提出一种新的Agentic架构。它没有深入探讨智能体的Safety、Alignment或Interpretability等元问题，而是将安全概念（如MITRE ATT&CK）作为智能体输出的一部分。因此，它不属于“安全与对齐”的排除范畴。 - **多模态与视觉**: 论文未涉及相关内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的智能体工作流（Detection -> Intelligence -> Response -> Analysis）本身就是一种任务规划和协作执行的体现，符合保留条件。 - **自我演化的应用**: 不适用，因为论文未提出自我演化机制。 **最终决策**: 综合以上分析，这篇论文的核心是**构建一个新颖的多智能体LLM框架（MALCDF）**，并详细阐述了其架构、智能体分工和通信协作机制。尽管它被应用于网络安全这一特定领域，但其贡献在于**方法论和框架本身**，而非单纯的应用。这完全符合我研究课题中“多智能体”方向的要求，即探索智能体间的协作与通信。因此，最终判断为 **True**，应保留此论文。"
    },
    {
        "index": "#111",
        "title": "Workflows vs Agents for Code Translation",
        "link": "/arxiv/2512.14762",
        "arxiv_id": "2512.14762",
        "authors": "Henry Gray, Tom Yotam, Octavian Udrea",
        "summary": "Translating algorithms from high-level languages like MATLAB to hardware description languages (HDLs) is a resource-intensive but necessary step for deployment on FPGAs and ASICs. While large language models (LLMs) offer a path to automation, their limited training on HDL code makes end-to-end transpilation brittle and prone to syntax errors. We compare two LLM-driven methods for syntax repair in a MATLAB-to-HDL pipeline: a structured, expert-designed flow that follows a fixed sequence of operations, and a more autonomous agentic approach that uses the Model Context Protocol (MCP) \\cite{anthropic2024mcp} to dynamically select its own tools. We study 42 MATLAB signal-processing functions and isolate the syntax-repair stage. Across three model scales, the agentic approach is more effective at resolving initial syntax errors, unblocking a greater number of candidates to proceed through the pipeline. This upstream improvement yields measurable downstream improvements, most notably on mid-sized models, where it increases the simulation reach rate by over 20 percentage points. We hypothesize the gains come from short prompts, aggressive context management, and conditional tool use. Conditional retrieval helps at 8B and 30B; at 235B final-success gains are small and a naive RAG variant attains the highest final success. Our findings suggest that these agentic frameworks, when properly designed, are most effective at compensating for the capacity limits of small and mid-sized models.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-15",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.910719",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献并非简单地将LLM智能体作为工具应用于代码翻译领域。它的核心是**比较和评估两种不同的范式**：一种是固定的、专家设计的“工作流”，另一种是自主的、能够动态选择工具的“智能体”方法。论文通过实证分析，揭示了智能体方法（特别是其动态工具使用能力）在特定任务上优于传统工作流的原因（如短提示、上下文管理、条件性工具使用）。 - **判断**: 这属于对LLM智能体**方法论本身的改进和验证**，而不是一个纯粹的非演化型应用。它研究了智能体的核心机制（自主决策和工具使用），因此符合“保留”标准。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `Agentic AI`, `LLM-based Agents`。论文标题和摘要都直接对比了“Workflows”和“Agents”。 - **智能体能力**: `Tool Use / Tool Augmentation` 是论文的核心。摘要中明确提到智能体“dynamically select its own tools”和“conditional tool use”。此外，`Planning` 体现在智能体动态决策使用哪个工具的流程中，而 `Self-Correction` 则体现在“syntax-repair”这一任务本身。 - 这些指标强烈表明论文与我的“单智能体”研究方向高度相关。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐议题。 - 论文的研究对象是代码，不涉及 `Vision`, `MLLMs` 等多模态内容。 - 因此，论文不触及任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”条件。它不是在研究如何提升LLM的基础数学或逻辑推理能力，而是在研究**智能体如何在一个复杂任务（代码修复）中进行规划和多步推理**（即动态选择工具序列）。这正是Agentic AI研究的核心。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献在于**实证研究和验证了LLM智能体的一个关键能力——动态工具使用**，并将其与传统方法进行对比，从而为如何设计和改进智能体提供了宝贵的见解。这直接服务于我“构建、改进或演化LLM智能体”的核心目标，特别是聚焦于“单智能体”方向下的“工具使用”和“规划”子方向。因此，最终判断为 **True**。"
    },
    {
        "index": "#119",
        "title": "VERAFI: Verified Agentic Financial Intelligence through Neurosymbolic Policy Generation",
        "link": "/arxiv/2512.14744",
        "arxiv_id": "2512.14744",
        "authors": "Adewale Akinfaderin, Shreyas Subramanian",
        "summary": "Financial AI systems suffer from a critical blind spot: while Retrieval-Augmented Generation (RAG) excels at finding relevant documents, language models still generate calculation errors and regulatory violations during reasoning, even with perfect retrieval. This paper introduces VERAFI (Verified Agentic Financial Intelligence), an agentic framework with neurosymbolic policy generation for verified financial intelligence. VERAFI combines state-of-the-art dense retrieval and cross-encoder reranking with financial tool-enabled agents and automated reasoning policies covering GAAP compliance, SEC requirements, and mathematical validation. Our comprehensive evaluation on FinanceBench demonstrates remarkable improvements: while traditional dense retrieval with reranking achieves only 52.4\\% factual correctness, VERAFI's integrated approach reaches 94.7\\%, an 81\\% relative improvement. The neurosymbolic policy layer alone contributes a 4.3 percentage point gain over pure agentic processing, specifically targeting persistent mathematical and logical errors. By integrating financial domain expertise directly into the reasoning process, VERAFI offers a practical pathway toward trustworthy financial AI that meets the stringent accuracy demands of regulatory compliance, investment decisions, and risk management.",
        "subjects": "Computational Finance, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.919306",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了 **VERAFI，一个全新的agentic framework**。它不是简单地将一个已有的智能体框架（如ReAct）应用到金融领域，而是构建了一个包含神经符号策略生成、工具使用和检索增强的综合性智能体架构。其核心创新在于这个框架本身的设计，特别是“neurosymbolic policy generation”这一机制，用于解决智能体在特定任务中的推理错误。因此，它不属于“非演化型应用”，而是关于“构建、改进LLM智能体”的方法论研究。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Agentic AI`, `LLM-based Agents`。 - **智能体能力**: `Tool Use / Tool Augmentation` (明确提到 \"financial tool-enabled agents\"), `Self-Correction` (其神经符号策略层专门用于纠正数学和逻辑错误，是一种自我修正机制)。 - 这些指标强烈表明该论文与我的研究焦点高度相关，特别是“单智能体”方向。 3.  **第三步：排除标准** - **安全与对齐**: 论文虽然提到了 \"regulatory compliance\" 和 \"trustworthy\"，但其主要贡献是**实现合规和可信的技术框架**，而不是研究安全、对齐或可解释性本身。合规性是其智能体在金融领域需要满足的一个功能目标，而不是论文的研究主题。因此，这不触发排除规则。 - **多模态与视觉**: 论文未涉及相关内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文属于**保留**情况。它研究的是智能体如何在一个复杂领域（金融）中进行多步推理，并通过工具和策略来保证推理的正确性。这完全符合“智能体如何进行规划或在复杂任务中进行多步推理”的定义，而不是单纯提升LLM的基础数学或逻辑能力。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建和改进一个LLM智能体框架（VERAFI）**。它通过引入神经符号策略层和工具使用机制，增强了智能体在特定领域（金融）进行自我修正和验证的能力。尽管其应用场景是金融领域，但其方法论贡献是普适的，直接服务于“构建、改进或演化LLM智能体”这一核心目标。因此，这篇论文完全符合我的研究范围，应被保留。"
    },
    {
        "index": "#124",
        "title": "INFORM-CT: INtegrating LLMs and VLMs FOR Incidental Findings Management in Abdominal CT",
        "link": "/arxiv/2512.14732",
        "arxiv_id": "2512.14732",
        "authors": "Idan Tankel, Nir Mazor, Rafi Brada, Christina LeBedis, Guy ben-Yosef",
        "summary": "Incidental findings in CT scans, though often benign, can have significant clinical implications and should be reported following established guidelines. Traditional manual inspection by radiologists is time-consuming and variable. This paper proposes a novel framework that leverages large language models (LLMs) and foundational vision-language models (VLMs) in a plan-and-execute agentic approach to improve the efficiency and precision of incidental findings detection, classification, and reporting for abdominal CT scans. Given medical guidelines for abdominal organs, the process of managing incidental findings is automated through a planner-executor framework. The planner, based on LLM, generates Python scripts using predefined base functions, while the executor runs these scripts to perform the necessary checks and detections, via VLMs, segmentation models, and image processing subroutines. We demonstrate the effectiveness of our approach through experiments on a CT abdominal benchmark for three organs, in a fully automatic end-to-end manner. Our results show that the proposed framework outperforms existing pure VLM-based approaches in terms of accuracy and efficiency.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.921688",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于医疗领域，而是提出了一种**新颖的“plan-and-execute agentic approach”（规划-执行智能体方法）和“planner-executor framework”（规划器-执行器框架）**。其核心贡献在于构建了一个智能体框架，其中LLM作为“规划器”生成可执行的脚本，而“执行器”则调用VLMs、分割模型等工具来完成具体任务。这完全符合“构建LLM智能体的方法论或新框架”的保留标准。它不是非演化型应用，因为其创新点在于智能体的工作流和架构，而非应用本身。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提到了 `agentic approach`，属于 `Agentic AI` 和 `LLM-based Agents` 范畴。 - **智能体能力**: 论文的框架核心就是 `Planning`（规划器生成脚本）和 `Tool Use`（执行器调用VLMs、分割模型等工具）。这与 `ReAct` 等经典智能体范式高度一致。 3.  **第三步：排除标准** - **安全与对齐**: 论文主要关注效率和精确度，未涉及安全、对齐或可解释性等排除项。 - **多模态与视觉**: 论文确实使用了 `VLMs`，但根据筛选规则，它们是作为智能体感知和操作环境的**工具**被使用的，而不是研究的核心。研究的核心是那个能够编排这些工具的智能体框架本身，因此这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”的典型案例。它研究的不是LLM本身的基础推理能力，而是**智能体如何进行规划和执行**。LLM作为规划器，将复杂的医学指南分解为可执行的步骤（生成Python脚本），这正是智能体规划能力的体现。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种新的LLM智能体框架，该框架通过规划-执行模式，实现了对多种工具（包括VLMs）的灵活调用，以解决复杂的现实任务。这完全符合您研究目标中的“单智能体”方向，特别是关于**智能体的规划**和**工具使用**能力的研究。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#123",
        "title": "PyFi: Toward Pyramid-like Financial Image Understanding for VLMs via Adversarial Agents",
        "link": "/arxiv/2512.14735",
        "arxiv_id": "2512.14735",
        "authors": "Yuqun Zhang, Yuxuan Zhao, Sijia Chen",
        "summary": "This paper proposes PyFi, a novel framework for pyramid-like financial image understanding that enables vision language models (VLMs) to reason through question chains in a progressive, simple-to-complex manner. At the core of PyFi is PyFi-600K, a dataset comprising 600K financial question-answer pairs organized into a reasoning pyramid: questions at the base require only basic perception, while those toward the apex demand increasing levels of capability in financial visual understanding and expertise. This data is scalable because it is synthesized without human annotations, using PyFi-adv, a multi-agent adversarial mechanism under the Monte Carlo Tree Search (MCTS) paradigm, in which, for each image, a challenger agent competes with a solver agent by generating question chains that progressively probe deeper capability levels in financial visual reasoning. Leveraging this dataset, we present fine-grained, hierarchical, and comprehensive evaluations of advanced VLMs in the financial domain. Moreover, fine-tuning Qwen2.5-VL-3B and Qwen2.5-VL-7B on the pyramid-structured question chains enables these models to answer complex financial questions by decomposing them into sub-questions with gradually increasing reasoning demands, yielding average accuracy improvements of 19.52% and 8.06%, respectively, on the dataset. All resources of code, dataset and models are available at: https://github.com/AgenticFinLab/PyFi .",
        "subjects": "Computational Finance, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-18T11:00:04.921177",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为 `PyFi-adv` 的多智能体对抗机制，用于自动合成一个大规模的金融问答数据集。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的本质不是简单地将LLM或智能体框架应用于金融领域，而是**构建了一个新的多智能体系统**。这个系统（`PyFi-adv`）通过“挑战者智能体”和“解决者智能体”之间的对抗博弈，来生成具有渐进式推理难度的问题链。这完全符合“构建、改进或演化LLM智能体”的核心目标，特别是属于“多智能体”的范畴。因此，它不是“非演化型应用”，而是提出了新的智能体方法论。 2.  **第二步：正面指标——高度相关** 论文明确包含了多个核心关注点： *   **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心创新点。 *   **多智能体**: `Collaboration`/`博弈` 体现在挑战者与解决者智能体的竞争机制中。 *   **智能体能力**: `Planning` 体现在智能体生成渐进式问题链的过程中，这是一种规划行为。 这些正面指标强烈表明该论文与我的研究范围高度相关。 3.  **第三步：排除标准——不适用** *   **安全与对齐**: 论文不涉及安全、对齐或可解释性问题。 *   **多模态与视觉**: 这是需要仔细辨析的一点。虽然论文的目标是提升VLMs的能力，但研究的**核心贡献并非VLM本身**，而是那个**用于生成训练数据的多智能体框架**。根据规则“除非它们被用作智能体感知环境的工具，而不是研究的核心”，这里的VLM是智能体系统作用的**对象**和**应用场景**，而不是研究的核心方法论。研究的核心是那个多智能体系统，因此不应被排除。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文中智能体生成问题链的行为，属于智能体框架内的规划和推理，符合保留条件。它不是单纯提升LLM基础推理能力，而是通过一个多智能体交互过程来实现数据生成和任务分解。 **最终决策**: 综合以上分析，尽管论文的应用领域是金融图像理解，但其最核心、最本质的贡献是设计并实现了一个新颖的**多智能体对抗框架**。这个框架本身就是一项关于“多智能体”的研究，完全符合我筛选标准中的“多智能体”方向。因此，这篇论文应该被保留。"
    },
    {
        "index": "#48",
        "title": "The Semantic Architect: How FEAML Bridges Structured Data and LLMs for Multi-Label Tasks",
        "link": "/arxiv/2512.15082",
        "arxiv_id": "2512.15082",
        "authors": "Wanfu Gao, Zebin He, Jun Gao",
        "summary": "Existing feature engineering methods based on large language models (LLMs) have not yet been applied to multi-label learning tasks. They lack the ability to model complex label dependencies and are not specifically adapted to the characteristics of multi-label tasks. To address the above issues, we propose Feature Engineering Automation for Multi-Label Learning (FEAML), an automated feature engineering method for multi-label classification which leverages the code generation capabilities of LLMs. By utilizing metadata and label co-occurrence matrices, LLMs are guided to understand the relationships between data features and task objectives, based on which high-quality features are generated. The newly generated features are evaluated in terms of model accuracy to assess their effectiveness, while Pearson correlation coefficients are used to detect redundancy. FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations. By integrating LLMs with a feedback mechanism, FEAML realizes an efficient, interpretable and self-improving feature engineering paradigm. Empirical results on various multi-label datasets demonstrate that our FEAML outperforms other feature engineering methods.",
        "subjects": "Machine Learning",
        "date": "2025-12-17",
        "category": "cs.LG",
        "crawl_time": "2025-12-18T11:00:04.948911",
        "filter_reason": "这篇论文符合筛选标准，应当保留。我的判断过程如下： 1.  **第一步：核心判断** - 论文的标题和摘要初看像是一个应用型论文（将LLM用于多标签分类的特征工程），这通常属于“非演化型应用”的排除范围。然而，仔细阅读摘要后发现，其核心贡献并非简单地将LLM作为工具应用，而是提出了一个带有**反馈机制**的迭代优化框架。 - 摘要中明确提到：“FEAML further incorporates the evaluation results as feedback to drive LLMs to continuously optimize code generation in subsequent iterations.”（FEAML进一步将评估结果作为反馈，驱动LLM在后续迭代中持续优化代码生成。）这表明论文的核心是构建一个能够自我完善和迭代的系统。 - 因此，这篇论文的本质不是简单的应用，而是**提出了一种自我演化的方法论**。它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点的正面指标： - **自我演化**: 摘要中直接使用了“self-improving feature engineering paradigm”（自我改进的特征工程范式）和“continuously optimize”（持续优化）等词语。 - **演化机制**: 明确提到了“Self-Improvement”和“Iterative Improvement”。 - **工具使用**: LLM被用作“code generation capabilities”（代码生成能力）的工具。 - 这些指标强烈表明论文与我的研究焦点“自我演化”高度相关。 3.  **第三步：排除标准** - 论文内容不涉及安全、对齐、多模态等排除标准中的任何一项。 4.  **第四步：处理特殊和模糊情况** - 这篇论文完美地符合“自我演化的应用”这一例外规则。虽然它被应用在“多标签学习”这个特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**——即通过评估反馈来迭代优化LLM的代码生成过程。根据规则，这种情况应该保留。 - 它不是关于提升LLM本身的基础推理能力，而是构建一个围绕LLM的、能够自我演化的智能体框架（尽管这个框架的目标是特征工程）。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献在于构建了一个带有反馈循环的、能够自我迭代优化的LLM系统。这完全符合我研究课题中的“自我演化”方向。它不是对现有智能体的简单应用，而是对智能体如何通过环境反馈（这里是特征评估结果）进行自我完善这一核心问题的探索。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    }
]