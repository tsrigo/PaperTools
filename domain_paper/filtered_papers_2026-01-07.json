[
    {
        "index": "#3",
        "title": "LLM-Enabled Multi-Agent Systems: Empirical Evaluation and Insights into Emerging Design Patterns & Paradigms",
        "link": "/arxiv/2601.03328",
        "arxiv_id": "2601.03328",
        "authors": "Harri Renney, Maxim N Nethercott, Nathan Renney, Peter Hayes",
        "summary": "This paper formalises the literature on emerging design patterns and paradigms for Large Language Model (LLM)-enabled multi-agent systems (MAS), evaluating their practical utility across various domains. We define key architectural components, including agent orchestration, communication mechanisms, and control-flow strategies, and demonstrate how these enable rapid development of modular, domain-adaptive solutions. Three real-world case studies are tested in controlled, containerised pilots in telecommunications security, national heritage asset management, and utilities customer service automation. Initial empirical results show that, for these case studies, prototypes were delivered within two weeks and pilot-ready solutions within one month, suggesting reduced development overhead compared to conventional approaches and improved user accessibility. However, findings also reinforce limitations documented in the literature, including variability in LLM behaviour that leads to challenges in transitioning from prototype to production maturity. We conclude by outlining critical research directions for improving reliability, scalability, and governance in MAS architectures and the further work needed to mature MAS design patterns to mitigate the inherent challenges.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-06",
        "category": "cs.MA",
        "crawl_time": "2026-01-09T11:00:08.133653",
        "filter_reason": "1.  **核心判断 (符合)**: 论文的核心贡献在于形式化了LLM驱动的多智能体系统（MAS）的设计模式和范式，并定义了包括智能体编排、通信机制和控制流策略在内的关键架构组件。这属于“构建”和“改进”LLM智能体（特别是多智能体系统）的方法论研究，符合第一步中关于保留“构建LLM智能体”或“多智能体系统”方法论的要求。 2.  **正面指标 (匹配)**: 论文明确涉及 `Multi-Agent Systems (MAS)` 这一核心范式，并深入探讨了 `Agent Orchestration`（智能体编排）和 `Communication mechanisms`（通信机制），这些都是多智能体研究中的关键能力和正面指标。 3.  **排除标准 (未触发)**: *   **非演化型应用**: 尽管论文使用了电信、遗产管理等领域的案例研究，但其主要目的不是为了解决这些领域的具体业务问题，而是为了评估MAS架构和设计模式的实用性及开发效率。因此，它不属于仅将LLM作为工具应用到特定领域的“非演化型应用”。 *   **安全与对齐**: 论文虽然提到了治理和可靠性，但这并非其核心贡献，核心在于系统架构和设计模式。 *   **多模态与视觉**: 论文未涉及视觉或多模态内容。 4.  **综合结论**: 该论文提供了关于如何构建、设计和评估多智能体系统的实证见解和架构框架，直接服务于“LLM智能体及其演化”中关于多智能体方向的研究目标。"
    },
    {
        "index": "#1",
        "title": "When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents",
        "link": "/arxiv/2601.03846",
        "arxiv_id": "2601.03846",
        "authors": "Alessio Buscemi, Daniele Proverbio, Alessandro Di Stefano, The Anh Han, German Castignani, Pietro Liò",
        "summary": "LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert communication in LLM-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different communication regimes, including explicit, restricted, and absent communication. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2026-01-07",
        "category": "cs.MA",
        "crawl_time": "2026-01-09T11:00:08.133016",
        "filter_reason": "这篇论文完全符合筛选标准，属于“多智能体”方向的核心研究。 1.  **核心判断（第一步）**：论文的本质是研究 LLM 智能体在多智能体环境中的行为机制。它不是将智能体作为工具去解决生物、医疗等特定领域的应用问题，而是深入探讨智能体之间如何进行“隐式协调”和“隐蔽通信”。这属于构建和理解多智能体系统（Multi-Agent Systems）的方法论研究，因此应予以保留。 2.  **正面指标匹配（第二步）**： *   **核心范式**：明确涉及 `Multi-Agent Systems (MAS)`。 *   **多智能体能力**：论文重点研究了智能体间的 `Communication`（特别是非显式的、隐蔽的通信）和 `Collaboration`（协调）。 *   **博弈与互动**：通过博弈论设置分析智能体间的战略互动，这属于多智能体研究中的社会行为和博弈范畴。 3.  **排除标准检查（第三步）**：论文不涉及安全对齐、多模态视觉或图技术等排除项。 **总结**：该论文的核心贡献在于揭示了 LLM 智能体在缺乏显式语言通道时，如何通过行动（如数字信号）进行隐式协调。这直接拓展了对于多智能体通信机制和协作行为的理解，符合“多智能体”这一研究焦点。"
    },
    {
        "index": "#35",
        "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents",
        "link": "/arxiv/2601.03785",
        "arxiv_id": "2601.03785",
        "authors": "Dehao Tao, Guoliang Ma, Yongfeng Huang, Minghu Jiang",
        "summary": "Human-agent dialogues often exhibit topic continuity-a stable thematic frame that evolves through temporally adjacent exchanges-yet most large language model (LLM) agent memory systems fail to preserve it. Existing designs follow a fragmentation-compensation paradigm: they first break dialogue streams into isolated utterances for storage, then attempt to restore coherence via embedding-based retrieval. This process irreversibly damages narrative and causal flow, while biasing retrieval towards lexical similarity. We introduce membox, a hierarchical memory architecture centered on a Topic Loom that continuously monitors dialogue in a sliding-window fashion, grouping consecutive same-topic turns into coherent \"memory boxes\" at storage time. Sealed boxes are then linked by a Trace Weaver into long-range event-timeline traces, recovering macro-topic recurrences across discontinuities. Experiments on LoCoMo demonstrate that Membox achieves up to 68% F1 improvement on temporal reasoning tasks, outperforming competitive baselines (e.g., Mem0, A-MEM). Notably, Membox attains these gains while using only a fraction of the context tokens required by existing methods, highlighting a superior balance between efficiency and effectiveness. By explicitly modeling topic continuity, Membox offers a cognitively motivated mechanism for enhancing both coherence and efficiency in LLM agents.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-07",
        "category": "cs.CL",
        "crawl_time": "2026-01-09T11:00:08.978708",
        "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出了一种名为 \"Membox\" 的分层记忆架构，旨在解决 LLM 智能体在长程记忆中保持主题连续性的问题。这属于对 LLM 智能体核心组件（记忆系统）的构建与改进，而非将智能体作为工具应用到特定领域（非演化型应用），也非基础设施或基础模型推理能力的提升。 2.  **正面指标匹配（第二步）：** *   **核心范式：** 论文明确聚焦于 `LLM-based Agents`。 *   **智能体能力：** 论文的核心贡献点在于 `Memory`（记忆）。它通过引入 \"Topic Loom\" 和 \"Trace Weaver\" 等机制，优化了智能体存储和检索对话历史的能力，这直接对应了筛选标准中单智能体方向下的“记忆”子方向。 3.  **排除标准检查（第三步）：** 论文不涉及安全与对齐、多模态视觉技术或图神经网络，因此未触犯任何排除规则。 4.  **总结：** 该论文致力于通过改进记忆机制来增强 LLM 智能体的连贯性和效率，属于单智能体研究中对基础能力（记忆）的深化，完全符合“构建、改进 LLM 智能体”的核心目标。"
    },
    {
        "index": "#58",
        "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning",
        "link": "/arxiv/2601.03641",
        "arxiv_id": "2601.03641",
        "authors": "Zheng Wu, Xingyu Lou, Xinbei Ma, Yansi Li, Weiwen Liu, Weinan Zhang, Jun Wang, Zhuosheng Zhang",
        "summary": "Large Language Model (LLM)-based agents significantly extend the utility of LLMs by interacting with dynamic environments. However, enabling agents to continually learn new tasks without catastrophic forgetting remains a critical challenge, known as the stability-plasticity dilemma. In this work, we argue that this dilemma fundamentally arises from the failure to explicitly distinguish between common knowledge shared across tasks and conflicting knowledge introduced by task-specific interference. To address this, we propose Agent-Dice, a parameter fusion framework based on directional consensus evaluation. Concretely, Agent-Dice disentangles knowledge updates through a two-stage process: geometric consensus filtering to prune conflicting gradients, and curvature-based importance weighting to amplify shared semantics. We provide a rigorous theoretical analysis that establishes the validity of the proposed fusion scheme and offers insight into the origins of the stability-plasticity dilemma. Extensive experiments on GUI agents and tool-use agent domains demonstrate that Agent-Dice exhibits outstanding continual learning performance with minimal computational overhead and parameter updates.",
        "subjects": "Computation and Language",
        "date": "2026-01-07",
        "category": "cs.CL",
        "crawl_time": "2026-01-09T11:00:09.000273",
        "filter_reason": "这篇论文完全符合我的研究范围，属于“自我演化”方向的核心论文。 1.  **核心贡献判断 (第一步)**: 论文的核心贡献是提出了 **Agent-Dice**，这是一个专门用于解决 **LLM智能体持续学习** 问题的参数融合框架。它旨在解决智能体在动态环境中学习新任务时遇到的“灾难性遗忘”和“稳定性-可塑性困境”。这直接对应了我研究目标中的“自我演化”，即智能体通过经验、反思或环境反馈进行自我完善和迭代。这不是将智能体作为工具的应用，而是对智能体底层学习机制的改进。 2.  **符合正面指标 (第二步)**: *   **核心范式**: 论文明确关注 `LLM-based Agents`。 *   **演化机制**: 论文的核心主题是 `Continual Learning`（持续学习），这是 `Self-Evolving`（自我演化）的重要组成部分。它涉及 `Knowledge Updates`（知识更新）和 `Iterative Improvement`（迭代改进）。 *   **智能体能力**: 论文在 `GUI agents` 和 `tool-use agents` 领域进行了验证，体现了智能体与环境的交互能力。 3.  **排除标准检查 (第三步)**: *   论文不涉及安全、对齐或水印问题。 *   虽然提到了 GUI agents（可能涉及视觉），但视觉仅作为智能体感知环境的工具，而非研究的核心（核心是参数融合和持续学习算法），因此不违反多模态排除规则。 *   不涉及图技术。 4.  **特殊情况处理 (第四步)**: 论文提出了一种新的“自我演化”机制（通过几何共识和曲率加权实现持续学习），即使它在特定的 GUI 或工具使用领域进行了实验，根据规则“如果论文的核心是提出一种新的‘自我演化’机制……也应该保留”，这篇论文应当被保留。 综上所述，Agent-Dice 通过改进智能体的知识更新机制，实现了智能体在连续任务中的自我演化，精准契合“LLM智能体及其演化”这一课题。"
    },
    {
        "index": "#108",
        "title": "DeepResearch-Slice: Bridging the Retrieval-Utilization Gap via Explicit Text Slicing",
        "link": "/arxiv/2601.03261",
        "arxiv_id": "2601.03261",
        "authors": "Shuo Lu, Yinuo Xu, Jianjie Cheng, Lingxiao He, Meng Wang, Jian Liang",
        "summary": "Deep Research agents predominantly optimize search policies to maximize retrieval probability. However, we identify a critical bottleneck: the retrieval-utilization gap, where models fail to use gold evidence even after it is retrieved, due to context blindness in noisy environments. To bridge this gap, we propose DeepResearch-Slice, a simple yet effective neuro-symbolic framework. Unlike implicit attention, our approach predicts precise span indices to perform a deterministic hard filter before reasoning. Extensive evaluations across six benchmarks show substantial robustness gains. Applying our method to frozen backbones yields a 73 percent relative improvement, from 19.1 percent to 33.0 percent, effectively mitigating noise without requiring parameter updates to the reasoning model. These results highlight the need for explicit grounding mechanisms in open-ended research.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2026-01-09T11:00:09.085498",
        "filter_reason": "1.  **核心判断**: 论文明确以 \"Deep Research agents\"（深度研究智能体）为研究对象，提出了 DeepResearch-Slice 这一神经符号框架。这属于构建和改进 LLM 智能体的方法论，符合“单智能体”的研究范畴。 2.  **正面指标**: 论文涉及智能体的核心能力，特别是工具使用后的信息处理。它解决了智能体在嘈杂环境中利用检索证据的瓶颈，改进了智能体的推理鲁棒性，属于对智能体内部机制的优化。 3.  **排除标准**: 论文不涉及安全、对齐、多模态或图技术；也不是针对特定垂直领域（如生物、金融）的单纯应用，而是提出了通用的改进框架。 4.  **特殊处理**: 虽然涉及推理，但这是在智能体框架下对“检索-利用”过程的改进，而非单纯提升模型的基础数学或逻辑预测能力，因此不属于“非Agentic的推理”。"
    },
    {
        "index": "#116",
        "title": "Current Agents Fail to Leverage World Model as Tool for Foresight",
        "link": "/arxiv/2601.03905",
        "arxiv_id": "2601.03905",
        "authors": "Cheng Qian, Emre Can Acikgoz, Bingxuan Li, Xiusi Chen, Yuji Zhang, Bingxiang He, Qinyu Luo, Dilek Hakkani-Tür, Gokhan Tur, Yunzhu Li, Heng Ji, Heng Ji",
        "summary": "Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2026-01-07",
        "category": "cs.CL",
        "crawl_time": "2026-01-09T11:00:09.095223",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献在于实证研究LLM智能体如何利用“世界模型”作为外部工具来进行“前瞻”规划。这直接属于“单智能体”研究范畴中的“工具使用”和“规划”能力。虽然论文主要揭示了当前智能体的局限性（即未能有效利用），但其目的是为了指导未来构建具有更强认知能力的智能体系统，属于对智能体构建和改进机制的探索，而非单纯的应用。 2.  **正面指标匹配（第二步）**：论文高度符合核心关注点。 *   **Agentic AI**: 明确以“Agents”为研究对象。 *   **Tool Use / Tool Augmentation**: 研究的核心是智能体如何将生成式世界模型作为“外部模拟器”工具来使用。 *   **Planning**: 论文聚焦于“anticipating future states”（前瞻）和“foresight”，这是智能体规划能力的高级形式。 3.  **排除标准与特殊情况处理（第三、四步）**： *   **多模态问题**: 尽管摘要提到了“vision-language models”和“visual question answering”，但视觉内容在此处是智能体感知的环境或工具（世界模型）的一部分，而非论文的研究核心。论文的核心在于智能体与该工具的交互机制，而非改进视觉模型本身，因此符合“作为工具使用”的例外情况。 *   **推理/规划**: 论文讨论的是智能体如何通过模拟进行多步推理和决策，属于Agentic层面的规划，而非单纯的LLM内部逻辑推理优化。 综上所述，该论文深入探讨了单智能体在工具使用和前瞻规划方面的关键问题，对构建和改进LLM智能体具有直接的指导意义，完全符合“单智能体”方向的研究目标。"
    },
    {
        "index": "#3",
        "title": "MobileDreamer: Generative Sketch World Model for GUI Agent",
        "link": "/arxiv/2601.04035",
        "arxiv_id": "2601.04035",
        "authors": "Yilin Cao, Yufeng Zhong, Zhixiong Zeng, Liming Zheng, Jing Huang, Haibo Qiu, Peng Shi, Wenji Mao, Wan Guanglu",
        "summary": "Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-07",
        "category": "cs.AI",
        "crawl_time": "2026-01-09T11:00:09.221593",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（符合）**： 论文的核心贡献在于提出了 **MobileDreamer**，这是一个基于世界模型的前瞻框架，旨在装备和增强移动 GUI 智能体。它不仅仅是将现有的智能体框架应用到一个新领域，而是针对现有 GUI 智能体“反应式”的局限性，提出了一种新的架构（包含文本草图世界模型和推演想象策略），以提升智能体的决策能力。这属于构建和改进 LLM 智能体的范畴。 2.  **正面指标（符合）**： *   **Agentic AI**: 论文明确聚焦于 GUI Agent 的构建。 *   **Planning**: 论文的核心在于通过世界模型预测行动结果，从而支持智能体进行更好的决策制定和行动选择，这属于智能体规划能力的增强。 3.  **排除标准（未触发）**： *   **多模态与视觉**: 虽然论文涉及处理屏幕图像和生成草图，但这属于“智能体感知环境的工具”。论文的核心贡献不是提出一种新的视觉算法或图像生成模型，而是利用视觉转换来构建辅助智能体规划的“世界模型”。因此，符合“除非它们被用作智能体感知环境的工具”这一例外条款。 4.  **特殊与模糊情况（符合）**： *   **推理/规划**: 论文通过引入世界模型，让智能体能够进行“前瞻”和“想象”，这属于智能体在复杂任务中进行多步推理和规划的高级形式，符合保留条件。 综上所述，该论文通过引入世界模型机制显著增强了单智能体的规划与决策能力，属于 Agentic AI 的核心研究范畴。"
    },
    {
        "index": "#20",
        "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models",
        "link": "/arxiv/2601.03555",
        "arxiv_id": "2601.03555",
        "authors": "Yuxuan Jiang, Francis Ferraro",
        "summary": "Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance. Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions. Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-07",
        "category": "cs.AI",
        "crawl_time": "2026-01-09T11:00:09.227099",
        "filter_reason": "1.  **核心判断 (第一步)**: *   该论文的核心贡献是提出了 **SCRIBE**，这是一个用于训练**工具增强型智能体** 的强化学习框架。 *   论文明确指出其目标是解决训练可靠智能体时的“信用分配”难题，并致力于提升智能体的“高层规划”和“低层执行”能力。 *   这完全符合“构建、改进或演化 LLM智能体”的核心目标，属于 Agentic AI 的范畴，因此应予以保留。 2.  **正面指标匹配 (第二步)**: *   **智能体能力**: 论文重点涉及 `Tool Use` (工具使用) 和 `Planning` (规划)，特别是区分了高层规划与低层执行。 *   **演化机制**: 摘要中明确提到了“co-evolution across abstraction levels”（跨抽象层的协同演化）以及“emergence of effective high-level planning behaviors”（有效高层规划行为的涌现），这与研究焦点中的“自我演化”高度契合。 3.  **排除标准检查 (第三步)**: *   论文不涉及安全、对齐、多模态视觉或图神经网络等排除领域。 4.  **特殊情况处理 (第四步)**: *   **推理/规划**: 论文虽然涉及推理，但它是通过强化学习框架来训练智能体在多步任务中进行规划和工具使用，属于智能体的架构与训练方法，而非单纯提升LLM基础Token预测能力的数学或逻辑微调，因此符合保留条件。 **结论**: 该论文提出了一种新的训练框架来改进LLM智能体的工具使用和规划能力，并探讨了技能与规划之间的协同演化机制，精准契合“LLM智能体及其演化”的研究课题。"
    },
    {
        "index": "#2",
        "title": "ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows",
        "link": "/arxiv/2601.04060",
        "arxiv_id": "2601.04060",
        "authors": "Jinwei Su, Qizhen Lan, Zeyu Wang, Yinghui Xia, Hairu Wen, Yiqun Duan, Xi Xiao, Tianyu Shi, Yang Jingsong, Lewei He",
        "summary": "AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-07",
        "category": "cs.AI",
        "crawl_time": "2026-01-09T11:00:09.221255",
        "filter_reason": "这篇论文符合我的研究范围，核心依据如下： 1.  **核心贡献符合 Agentic AI 定义 (第一步 & 第二步)**: *   论文明确提出了 \"ComfySearch, an **agentic framework**\"（一个智能体框架）。这不仅仅是将现有的LLM作为工具简单应用，而是构建了一个新的智能体架构来解决特定问题。 *   该框架的核心能力涉及 **Autonomous Exploration**（自主探索）和 **Reasoning**（推理），这直接对应了筛选标准中的“单智能体”方向，特别是 **Planning**（规划）和 **Tool Use**（工具使用，即操作ComfyUI组件）。 2.  **属于智能体规划与构建范畴 (第四步)**: *   论文解决的问题是如何在复杂的图约束下构建长视距的工作流。这属于智能体如何在复杂任务中进行多步规划和决策的研究范畴，而非单纯的LLM基础推理能力提升（如数学或逻辑题）。它关注的是智能体如何通过 \"validation-guided workflow construction\"（验证引导的工作流构建）来完成任务，这是一种典型的 Agentic 行为模式。 3.  **非简单的应用型论文 (第一步 & 第四步)**: *   虽然论文的应用场景是 ComfyUI（一个视觉生成平台），但论文的核心贡献在于**提出了一种能够自主探索组件空间并生成功能性工作流的智能体机制**，而不是仅仅展示LLM在生成图片上的效果。根据第四步的规则，只要核心是提出新的智能体机制（在此处是探索和构建机制），即使应用在特定领域，也应保留。 4.  **排除标准检查 (第三步)**: *   虽然涉及视觉内容生成，但论文的研究焦点不在于改进视觉模型本身，而在于控制生成流程的智能体框架，因此不属于被排除的“多模态与视觉”核心研究。 *   不涉及安全、对齐或基础设施问题。 综上所述，该论文提出了一种新的智能体框架来解决复杂的规划和构建问题，属于 Agentic AI 的核心研究范畴。"
    },
    {
        "index": "#17",
        "title": "Architecting Agentic Communities using Design Patterns",
        "link": "/arxiv/2601.03624",
        "arxiv_id": "2601.03624",
        "authors": "Zoran Milosevic, Fethi Rabhi",
        "summary": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-07",
        "category": "cs.AI",
        "crawl_time": "2026-01-09T11:00:09.226129",
        "filter_reason": "这篇论文完全符合筛选标准，属于“多智能体”方向的核心研究。 1.  **核心判断（第一步）**：论文的核心贡献在于提出了一种用于构建“Agentic Communities”（智能体社区）的架构方法和设计模式。这不仅仅是将LLM作为工具应用，而是构建了一个包含LLM智能体、Agentic AI实体和人类的复杂多智能体系统框架。它定义了智能体社区的组织结构、角色和协议，属于构建和改进LLM智能体系统的方法论。 2.  **正面指标匹配（第二步）**： *   **核心范式**：论文明确涉及 `Agentic AI` 和 `Multi-Agent Systems (MAS)`，特别是提出了“Agentic Communities”这一概念。 *   **多智能体能力**：摘要中详细讨论了智能体之间以及智能体与人类之间的 `Coordination`（协调）、`Communication`（通信）、`Negotiation`（谈判）以及 `Governance`（治理）机制。这些都是多智能体系统研究中的核心议题。 3.  **排除标准检查（第三步）**： *   虽然论文提到了“法律和伦理规则”以及“问责机制”，但其主要贡献是**架构框架**，而非单纯的安全算法或对齐技术研究。 *   虽然使用了“临床试验匹配”作为案例研究，但这仅用于验证框架的有效性，论文本质并非解决医疗领域的特定问题，而是提供通用的系统架构指导。 综上所述，该论文为构建复杂的多智能体协作系统提供了新的架构视角和设计模式，直接契合研究课题中关于“多智能体”的焦点，因此予以保留。"
    },
    {
        "index": "#29",
        "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization",
        "link": "/arxiv/2601.03359",
        "arxiv_id": "2601.03359",
        "authors": "Alberto Purpura, Li Wang, Sahil Badyal, Eugenio Beaufrand, Adam Faulkner",
        "summary": "Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that decouples optimization of the primary task description from its constraints, using quantitative scores as feedback to iteratively rewrite and improve them. Our evaluation demonstrates this method produces revised prompts that yield significantly higher compliance scores from models like Llama 3.1 8B and Mixtral-8x 7B.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-09T11:00:09.230116",
        "filter_reason": "这篇论文完全符合我的研究范围，属于“多智能体”和“自我演化”方向的交叉研究。 1.  **核心判断（符合）**：论文的核心贡献是提出了一种“新颖的多智能体工作流”，用于优化提示词指令。这属于构建和改进 LLM 智能体系统的方法论研究，而非将现有智能体简单应用到特定垂直领域（如医疗、金融）。 2.  **正面指标匹配**： *   **多智能体**：标题和摘要中明确提到了“Multi-Agentic Workflow”，涉及多个智能体协同工作。 *   **自我演化/自我完善**：论文描述了使用“定量分数作为反馈来迭代地重写和改进”提示词，这符合自我演化中的“迭代改进”和“自我修正”机制。 *   **智能体能力**：该工作流体现了智能体的规划（解耦任务描述与约束）和工具使用（利用评估分数）能力。 3.  **排除标准检查**： *   论文不涉及安全、对齐、多模态视觉或图技术等排除项。 *   虽然目标是“指令遵循”，但其手段是构建一个多智能体系统，这属于 Agentic AI 的范畴，而非单纯的非 Agentic 推理或数据集构建。 综上所述，该论文通过构建多智能体协作框架来实现任务的自我迭代优化，精准契合我对“LLM智能体及其演化”的研究课题。"
    },
    {
        "index": "#24",
        "title": "Evolving Programmatic Skill Networks",
        "link": "/arxiv/2601.03509",
        "arxiv_id": "2601.03509",
        "authors": "Haochen Shi, Xingdi Yuan, Bang Liu",
        "summary": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code.",
        "subjects": "Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2026-01-07",
        "category": "cs.AI",
        "crawl_time": "2026-01-09T11:00:09.228393",
        "filter_reason": "这篇论文完全符合研究范围，属于“自我演化”和“单智能体”方向的交叉研究。 1.  **核心贡献符合“自我演化”**: 论文提出了 Programmatic Skill Network (PSN) 框架，其核心在于智能体如何通过经验构建、细化和重用技能库。摘要中明确指出技能库是“evolves through experience”（通过经验演化），并包含“progressive optimization”（渐进式优化）和“structural refactoring”（结构重构）等机制，这直接对应了筛选标准中的“Self-Evolving”、“Self-Improvement”和“Iterative Improvement”。 2.  **具备核心智能体能力**: 论文详细描述了智能体的自我反思和自我修正能力。具体而言，它利用 LLM 实例化了“REFLECT”机制进行结构化故障定位，以及“成熟度感知更新门控”来平衡技能的稳定性与可塑性。这符合筛选标准中的“Self-Correction”、“Self-Reflection”和“Memory”（技能库作为长期记忆）。 3.  **符合特殊处理规则**: 尽管论文是在 MineDojo 和 Crafter（具身/游戏环境）中进行实验，但根据第四步的规则，只要论文的核心贡献是提出一种新的“自我演化”机制（即 PSN 框架），即使应用在特定领域，也应予以保留。该论文并非单纯将 LLM 应用于游戏，而是提出了一套通用的技能演化算法。 综上所述，该论文不仅涉及 LLM 智能体的构建，更深入探讨了智能体如何通过反思和反馈实现自我演化和技能积累，高度契合“LLM智能体及其演化”的研究课题。"
    }
]