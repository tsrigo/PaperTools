[
    {
        "index": "#4",
        "title": "Emergent Coordinated Behaviors in Networked LLM Agents: Modeling the Strategic Dynamics of Information Operations",
        "link": "/arxiv/2510.25003",
        "arxiv_id": "2510.25003",
        "authors": "Gian Marco Orlando, Jinyi Ye, Valerio La Gatta, Mahdi Saeedi, Vincenzo Moscato, Emilio Ferrara, Luca Luceri",
        "summary": "Generative agents are rapidly advancing in sophistication, raising urgent questions about how they might coordinate when deployed in online ecosystems. This is particularly consequential in information operations (IOs), influence campaigns that aim to manipulate public opinion on social media. While traditional IOs have been orchestrated by human operators and relied on manually crafted tactics, agentic AI promises to make campaigns more automated, adaptive, and difficult to detect. This work presents the first systematic study of emergent coordination among generative agents in simulated IO campaigns. Using generative agent-based modeling, we instantiate IO and organic agents in a simulated environment and evaluate coordination across operational regimes, from simple goal alignment to team knowledge and collective decision-making. As operational regimes become more structured, IO networks become denser and more clustered, interactions more reciprocal and positive, narratives more homogeneous, amplification more synchronized, and hashtag adoption faster and more sustained. Remarkably, simply revealing to agents which other agents share their goals can produce coordination levels nearly equivalent to those achieved through explicit deliberation and collective voting. Overall, we show that generative agents, even without human guidance, can reproduce coordination strategies characteristic of real-world IOs, underscoring the societal risks posed by increasingly automated, self-organizing IOs.",
        "subjects": "Multiagent Systems",
        "date": "2025-10-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-30T11:00:04.606031",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献并非将LLM智能体作为工具应用于信息作战（IO）领域，而是**构建了一个基于LLM智能体的多智能体模拟环境**，来系统性研究智能体之间如何涌现出协调行为。它的研究对象是“智能体的协调机制”本身，而非“如何打赢信息战”。这完全符合“构建、改进或演化LLM智能体”的核心目标，特别是**多智能体系统**的构建与分析。 2.  **第二步：正面指标——高度匹配** - 论文摘要中充满了你的核心关注点： - **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)`。论文标题和摘要明确指出研究的是“网络化LLM智能体”和“生成式智能体”。 - **多智能体**: `Collaboration` (协调), `Communication` (隐含在协调和集体决策中), `Agent Society` (模拟环境中的智能体网络)。论文的核心就是研究“emergent coordination”（涌现的协调行为）、“collective decision-making”（集体决策）和“self-organizing”（自组织）。 3.  **第三步：排除标准——未触犯** - **安全与对齐**: 虽然论文的研究背景是信息作战（IO）并提到了“societal risks”（社会风险），但其**主要技术贡献**并非提出新的安全、对齐或检测方法。它是在揭示一种潜在的智能体能力（协调），并分析其动态，属于能力研究而非安全研究。因此，不应被排除。 - **多模态与视觉**: 论文未涉及相关内容。 4.  **第四步：处理特殊和模糊情况** - 这篇论文是**多智能体研究**的典型案例。它不是简单地应用一个已有的多智能体框架，而是通过构建模拟环境来**探索和建模**多智能体间的协作与通信机制。论文发现“简单地告知智能体目标一致就能产生高效协调”，这本身就是对多智能体协作机制的一个重要发现和贡献。 **总结**: 该论文的核心贡献在于**构建并分析了一个LLM多智能体系统，以揭示和理解智能体间的涌现协调行为**。这直接命中了你研究课题中的“多智能体”方向，深入探讨了协作、通信和社会性等子方向。尽管其应用场景是信息作战，但研究的焦点始终是智能体本身的行为动态，因此是一篇高度相关且有价值的前沿论文，应当保留。"
    },
    {
        "index": "#7",
        "title": "From Narrative to Action: A Hierarchical LLM-Agent Framework for Human Mobility Generation",
        "link": "/arxiv/2510.24802",
        "arxiv_id": "2510.24802",
        "authors": "Qiumeng Li, Chunhou Ji, Xinyue Liu",
        "summary": "Understanding and replicating human mobility requires not only spatial-temporal accuracy but also an awareness of the cognitive hierarchy underlying real-world travel decisions. Traditional agent-based or deep learning models can reproduce statistical patterns of movement but fail to capture the semantic coherence and causal logic of human behavior. Large language models (LLMs) show potential, but struggle to balance creative reasoning with strict structural compliance. This study proposes a Hierarchical LLM-Agent Framework, termed Narrative-to-Action, that integrates high-level narrative reasoning, mid-level reflective planning, and low-level behavioral execution within a unified cognitive hierarchy. At the macro level, one agent is employed as a \"creative writer\" to produce diary-style narratives rich in motivation and context, then uses another agent as a \"structural parser\" to convert narratives into machine-readable plans. A dynamic execution module further grounds agents in geographic environments and enables adaptive behavioral adjustments guided by a novel occupation-aware metric, Mobility Entropy by Occupation (MEO), which captures heterogeneous schedule flexibility across different occupational personalities. At the micro level, the agent executes concrete actions-selecting locations, transportation modes, and time intervals-through interaction with an environmental simulation. By embedding this multi-layer cognitive process, the framework produces not only synthetic trajectories that align closely with real-world patterns but also interpretable representations of human decision logic. This research advances synthetic mobility generation from a data-driven paradigm to a cognition-driven simulation, providing a scalable pathway for understanding, predicting, and synthesizing complex urban mobility behaviors through hierarchical LLM agents.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computers and Society",
        "date": "2025-10-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-30T11:00:04.606808",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断依据如下： 1.  **核心判断 (第一步): 论文的核心贡献是构建一个新颖的LLM智能体框架。** 论文的标题和摘要明确指出，其核心贡献是提出一个“分层LLM智能体框架”。这并非简单地将现有智能体框架应用于“人类移动性生成”这一特定领域，而是为了解决该领域问题而**设计和构建了一个全新的、具有认知层级的智能体架构**。因此，它不属于“非演化型应用”的排除范畴，其本质是关于智能体构建的方法论研究。 2.  **正面指标 (第二步): 论文高度契合您的核心关注点。** *   **核心范式**: 论文明确提出了 `LLM-based Agents` 和一个 `Hierarchical` 框架，这直接命中了您的研究焦点。 *   **多智能体**: 论文清晰地描述了一个多智能体协作的范例。在宏观层面，一个“创意写手”智能体负责生成叙事，另一个“结构解析器”智能体负责将叙事转换为计划。这完全符合您对 `Multi-Agent Systems` 中 `Collaboration` 和 `Communication` 的关注。 *   **智能体能力**: 论文框架集成了 `high-level narrative reasoning`、`mid-level reflective planning` 和 `low-level behavioral execution`。这直接对应了您关注的 `Planning` 和 `Self-Reflection` 能力。智能体通过与环境模拟交互来执行具体行动，也体现了智能体的核心交互模式。 3.  **排除标准 (第三步): 论文不触及排除领域。** 论文的主要贡献是智能体框架的设计，而非安全、对齐或多模态技术。虽然提到了“可解释的表示”，但这只是其认知驱动框架带来的一个优点，而非研究的核心主题。 4.  **特殊与模糊情况 (第四步): 论文属于“保留”情况。** *   **推理/规划**: 论文的核心就是关于智能体如何进行分层规划和推理（`reflective planning`, `narrative reasoning`），这完全符合“保留”标准，即研究智能体在复杂任务中的多步推理框架。 *   **自我演化的应用**: 虽然这篇论文不涉及“自我演化”，但它完美地避开了“非演化型应用”的陷阱。关键区别在于：论文的创新点是**智能体框架本身**，而不是它在某个领域的应用结果。它提出了一种新的“认知驱动”范式来构建智能体，这正是您要寻找的关于“构建、改进LLM智能体”的论文。 **总结**: 该论文的核心贡献在于提出了一种创新的、分层的、多智能体协作的LLM智能体框架，以模拟人类的认知决策过程。它直接贡献于“单智能体”（规划、反思）和“多智能体”（协作）两个研究方向，完全符合您筛选“核心贡献在于构建、改进或演化LLM智能体”的论文的目标。因此，最终判断为 **True**。"
    },
    {
        "index": "#6",
        "title": "MASPRM: Multi-Agent System Process Reward Model",
        "link": "/arxiv/2510.24803",
        "arxiv_id": "2510.24803",
        "authors": "Milad Yazdani, Mahdi Mostajabdaveh, Zirui Zhou, Ying Xiong",
        "summary": "Practical deployment of Multi-Agent Systems (MAS) demands strong test-time performance, motivating methods that guide inference-time search and selectively spend compute to improve quality. We present the Multi-Agent System Process Reward Model (MASPRM). It assigns per-action, per-agent values to partial inter-agent transcripts and acts as an inference-time controller. MASPRM is trained from multi-agent Monte Carlo Tree Search (MCTS) rollouts without requiring step-level human annotations, by propagating returns to local targets. At inference, MASPRM guides step-level beam search and MCTS, focusing computation on promising branches and pruning early. On GSM8K and MATH, MASPRM-guided decoding with an outcome reward model (ORM) applied to the final answer, improves exact match (EM) over a single straight-through MAS pass by $+30.7$ and $+22.9$ points, respectively. A MASPRM trained on GSM8K transfers zero-shot to MATH without retraining, adding $8.4$ EM points at the same budget. MASPRM is a plug-in value model that estimates per-agent progress and complements verifier-style decoders, enabling more reliable, compute-aware multi-agent reasoning. Code: https://github.com/milad1378yz/MASPRM",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-30T11:00:04.606545",
        "filter_reason": "这篇论文完全符合您的研究范围，核心贡献在于**改进多智能体系统（Multi-Agent Systems）的推理过程**。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM或智能体作为工具应用到一个新领域，而是提出了一种名为MASPRM的新**方法论/框架**，用于**改进**多智能体系统在推理时的表现。它是一个“inference-time controller”（推理时控制器），直接作用于智能体的决策过程，这完全符合“构建、改进或演化 LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文标题和摘要的核心。 - **智能体能力**: 论文的核心是改进`Planning`（规划）能力。它通过MCTS和beam search引导智能体的多步推理，这可以看作是一种高级的规划和决策过程。 - **多智能体**: 论文明确处理`Collaboration`（协作）和`Communication`（通信），因为它评估的是“partial inter-agent transcripts”（部分智能体间对话记录），并分配“per-agent values”（每个智能体的价值）。 - **演化机制**: 虽然不是模型权重的自我演化，但MASPRM在推理时通过“pruning early”（早期剪枝）和“focusing computation on promising branches”（将计算集中在有希望的分支上），实现了推理路径的**迭代优化**和**自我修正**，这与智能体在任务执行中的动态演化思想一致。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉等多模态问题。它的焦点是提升智能体系统的性能和效率，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”情况的完美范例。它不是在提升LLM本身的基础数学能力，而是在构建一个**Agentic框架**（MASPRM），让多智能体系统在解决数学问题时能进行更有效的规划和搜索。它关注的是“如何让智能体更好地推理”，而不是“如何让LLM模型本身更懂数学”。 **总结**: 该论文的核心贡献是MASPRM，一个用于引导和优化多智能体系统推理过程的新框架。它直接属于您研究焦点中的**“多智能体”**方向，并深刻触及了**“规划”**和**“协作”**等子方向。它提出了一种改进智能体行为和决策能力的方法论，而非简单的应用，因此是您应该保留的前沿论文。"
    },
    {
        "index": "#3",
        "title": "SeeingEye: Agentic Information Flow Unlocks Multimodal Reasoning In Text-only LLMs",
        "link": "/arxiv/2510.25092",
        "arxiv_id": "2510.25092",
        "authors": "Weijia Zhang, Zijia Liu, Haoru Li, Haoqi Chen, Jiaxuan You",
        "summary": "Recent advances in text-only large language models (LLMs), such as DeepSeek-R1, demonstrate remarkable reasoning ability. However, these models remain fragile or entirely incapable when extended to multi-modal tasks. Existing approaches largely rely on single-form captions, which lack diversity and often fail to adapt across different types of Visual Question Answering (VQA) benchmarks. As a result, they provide no principled or efficient channel for transmitting fine-grained visual information. We introduce Seeing Eye, a modular framework that unlocks multimodal reasoning in text-only LLMs through an agent-based small VLM translator. This translator acts as a perception agent: it can invoke specialized tools (e.g., OCR and crop) and iteratively distill multimodal inputs into structured intermediate representations (SIRs) tailored to the question. These SIRs are then passed to the text-only LLM, which serves as a reasoning agent. Crucially, the translator and reasoner engage in multi-round feedback and interaction, enabling the extraction of targeted visual details and yielding more confident answers. Experiments on knowledge-intensive VQA benchmarks, including MMMU and MIA-Bench, demonstrate that Seeing Eye not only reduces inference cost but also surpasses much larger end-to-end VLMs. For example, an instantiation combining a 3B-parameter vision translator with an 8B-parameter language reasoner outperforms a monolithic 32B VLM on challenging knowledge-based questions. Our results highlight that decoupling perception from reasoning via agent information flow offers a scalable and plug-and-play pathway to multimodal reasoning, allowing strong text-only LLMs to fully leverage their reasoning capabilities. Code is available at: https://github.com/ulab-uiuc/SeeingEye",
        "subjects": "Multiagent Systems",
        "date": "2025-10-29",
        "category": "cs.MA",
        "crawl_time": "2025-10-30T11:00:04.605755",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于提出了一种新颖的LLM智能体构建框架。我的判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的本质是构建一个名为 \"SeeingEye\" 的**模块化智能体框架**，而非简单地将现有技术应用于特定领域。它明确地将系统解构为两个核心组件：一个作为“感知智能体”的小型视觉语言模型（VLM）和一个作为“推理智能体”的纯文本LLM。这完全符合“构建LLM智能体的方法论或新框架”的保留标准。 2.  **第二步：正面指标 (高度相关)** 论文包含了您核心关注点的多个关键范式和能力： *   **核心范式**: 论文标题和摘要中多次明确提到 `Agentic`，并描述了一个由两个智能体协作的系统，这属于 `LLM-based Agents` 和 `Multi-Agent Systems (MAS)` 的范畴。 *   **智能体能力**: “感知智能体”能够 `invoke specialized tools` (如OCR和裁剪)，这直接命中了 `Tool Use / Tool Augmentation`。同时，两个智能体之间的 `multi-round feedback and interaction` 暗示了某种形式的规划或迭代决策过程。 *   **多智能体**: 论文的核心机制是“感知智能体”与“推理智能体”之间的 `Communication` 和 `Collaboration`。它们通过多轮交互来共同完成任务，这正是多智能体研究的核心。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文的主要贡献是提升多模态推理能力和效率，不涉及安全、对齐或可解释性等问题。 *   **多模态与视觉**: 这是一个关键点。虽然论文处理的是多模态任务，但它**并未被排除**。根据您的规则，视觉模型在这里是作为“智能体感知环境的工具”而存在的。研究的核心不是视觉模型本身，而是**如何通过智能体架构来组织和利用这个工具**。论文的核心贡献是“通过智能体信息流将感知与推理解耦”，这是一个关于智能体设计的架构创新，而非视觉技术的创新。 4.  **第四步：特殊和模糊情况 (符合保留条件)** *   **推理/规划**: 论文提出的框架是一种全新的Agentic推理框架。它不是在改进LLM底层的CoT能力，而是在构建一个更高层次的、由多个智能体协作完成的推理系统。这完全符合“保留”的条件。 **总结**: 这篇论文的核心贡献是提出了一种创新的智能体架构，通过将感知和推理功能分配给不同的专门智能体，并让它们通过多轮交互进行协作，从而解决了纯文本LLM在多模态任务上的局限性。这直接命中了您研究目标中的“构建、改进LLM智能体”以及“多智能体协作”和“工具使用”等核心方向。因此，这是一篇高度相关且应被保留的前沿论文。"
    },
    {
        "index": "#4",
        "title": "Task Completion Agents are Not Ideal Collaborators",
        "link": "/arxiv/2510.25744",
        "arxiv_id": "2510.25744",
        "authors": "Shannon Zejiang Shen, Valerie Chen, Ken Gu, Alexis Ross, Zixian Ma, Jillian Ross, Alex Gu, Chenglei Si, Wayne Chi, Andi Peng, Jocelyn J Shen, Ameet Talwalkar, Tongshuang Wu, David Sontag",
        "summary": "Current evaluations of agents remain centered around one-shot task completion, failing to account for the inherently iterative and collaborative nature of many real-world problems, where human goals are often underspecified and evolve. We argue for a shift from building and assessing task completion agents to developing collaborative agents, assessed not only by the quality of their final outputs but by how well they engage with and enhance human effort throughout the problem-solving process. To support this shift, we introduce collaborative effort scaling, a framework that captures how an agent's utility grows with increasing user involvement. Through case studies and simulated evaluations, we show that state-of-the-art agents often underperform in multi-turn, real-world scenarios, revealing a missing ingredient in agent design: the ability to sustain engagement and scaffold user understanding. Collaborative effort scaling offers a lens for diagnosing agent behavior and guiding development toward more effective interactions.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.902335",
        "filter_reason": "这篇论文完全符合我的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非将LLM智能体应用于某个特定领域，而是对当前LLM智能体的设计范式（“任务完成智能体”）提出了批判，并提出了一个全新的设计方向和评估框架（“协作智能体”与“协作努力扩展”）。这直接属于“构建、改进或演化LLM智能体的方法论或新框架”，因此符合“保留”条件。它不是非演化型应用，也不是非Agentic的推理或基础设施研究。 2.  **第二步：正面指标——高度匹配** 论文的核心内容与我的研究焦点高度重合： *   **核心范式**: 论文明确讨论 `LLM-based Agents`，并提出了新的智能体范式。 *   **多智能体**: 论文的核心是关于智能体与人类的`协作`（Collaboration）和`通信`（Communication），这是多智能体系统（MAS）研究中的一个重要分支（人机协同）。 *   **智能体能力**: 论文强调智能体在多轮、迭代过程中的`engagement`（参与）和`scaffolding`（脚手架搭建），这涉及到智能体的规划、交互和适应能力，超越了单次任务完成。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于智能体的交互范式和评估框架，不涉及安全、对齐、可解释性或水印等排除项。同时，论文也未提及视觉或多模态内容。 4.  **第四步：特殊和模糊情况——不适用但符合精神** 论文讨论的“多轮、现实世界的场景”和“问题解决过程”属于智能体在复杂任务中的规划和推理，符合“保留”关于智能体推理/规划论文的规则。虽然论文没有直接提出“自我演化”机制，但它倡导的从“任务完成”到“协作”的范式演进，本身就是对智能体能力的一种宏观层面的“演化”和改进方向。 **最终决策**: 这篇论文的核心贡献在于提出了一种新的LLM智能体设计哲学和评估框架，即从“任务完成”转向“人机协作”。这直接触及了“LLM智能体及其演化”的核心议题，特别是在“多智能体”方向的人机协作子领域。它为如何构建更有效、更符合现实需求的智能体提供了新的理论视角和评估工具，具有很高的前沿价值和指导意义。因此，这篇论文与我的研究目标高度相关，应被筛选出来。"
    },
    {
        "index": "#14",
        "title": "Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry",
        "link": "/arxiv/2510.25595",
        "arxiv_id": "2510.25595",
        "authors": "Run Peng, Ziqiao Ma, Amy Pang, Sikai Li, Zhang Xi-Jia, Yingzhuo Yu, Cristian-Paul Bara, Joyce Chai",
        "summary": "While Large Language Model (LLM) agents are often approached from the angle of action planning/generation to accomplish a goal (e.g., given by language descriptions), their abilities to collaborate with each other to achieve a joint goal are not well explored. To address this limitation, this paper studies LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task. We extend Einstein Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two LLM agents must reason, communicate, and act to satisfy spatial and relational constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier framework in which LLM agents are equipped with various communication strategies and verification signals from the environment. Empirical results highlight the critical importance of aligned communication, especially when agents possess both information-seeking and -providing capabilities. Interestingly, agents without communication can still achieve high task performance; however, further analysis reveals a lack of true rule understanding and lower trust from human evaluators. Instead, by integrating an environment-based verifier, we enhance agents' ability to comprehend task rules and complete tasks, promoting both safer and more interpretable collaboration in AI systems. https://github.com/Roihn/EinsteinPuzzles",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.905580",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个外部领域（如生物、金融）的问题，而是**研究LLM智能体本身如何协作**。其核心贡献是提出了一种“微调+验证器”的新框架，旨在**构建和改进**多智能体系统的协作能力。这直接命中了您研究目标中的“构建、改进或演化 LLM智能体”。 2.  **第二步：正面指标** - 论文与您的核心关注点高度匹配： - **核心范式**: 明确涉及 `LLM-based Agents` 和 `Multi-Agent Systems (MAS)`。 - **多智能体**: 论文的主题就是 `Collaboration`（协作）和 `Communication`（通信），并探讨了在信息不对称这一复杂条件下的协作机制。 - **智能体能力**: 论文中的智能体需要 `reason`（推理）、`communicate`（通信）和 `act`（行动），这属于智能体的规划与执行能力。更重要的是，其核心框架中的“verifier”（验证器）是一种 `Self-Correction`（自我修正）机制，使智能体能根据环境反馈进行调整。 3.  **第三步：排除标准** - **安全与对齐**: 论文摘要中提到了“safer and more interpretable collaboration”，但这被描述为其框架带来的**积极结果**，而非论文的**主要贡献**。论文的核心是“如何实现有效协作”，而不是“如何让协作更安全”。因此，它不属于以安全/对齐为主要贡献的论文，不应被排除。 - **多模态与视觉**: 论文未涉及相关内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的推理是智能体在协作框架内为了完成任务而进行的多步推理，属于Agentic AI的范畴，而非提升LLM本身的基础数学或逻辑能力，因此符合保留条件。 **总结**: 该论文的核心贡献在于提出了一种新的多智能体协作框架，重点解决了信息不对称下的通信与验证问题。它直接对齐了您研究课题中的“多智能体”方向，并涉及了智能体的自我修正机制。因此，这是一篇高度相关且应被筛选出来的前沿论文。"
    },
    {
        "index": "#13",
        "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
        "link": "/arxiv/2510.25621",
        "arxiv_id": "2510.25621",
        "authors": "Mohammad Aghajani Asl, Behrooz Minaei Bidgoli",
        "summary": "The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing, yet their application in high-stakes, specialized domains like religious question answering is hindered by challenges like hallucination and unfaithfulness to authoritative sources. This issue is particularly critical for the Persian-speaking Muslim community, where accuracy and trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG) systems, relying on simplistic single-pass pipelines, fall short on complex, multi-hop queries requiring multi-step reasoning and evidence aggregation. To address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful Advanced Question Answering in the Persian Islamic domain. FARSIQA is built upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting process: it adaptively decomposes complex queries, assesses evidence sufficiency, and enters an iterative loop to generate sub-queries, progressively filling information gaps. Operating on a curated knowledge base of over one million authoritative Islamic documents, FARSIQA demonstrates superior performance. Rigorous evaluation on the challenging IslamicPCQA benchmark shows state-of-the-art performance: the system achieves a remarkable 97.0% in Negative Rejection - a 40-point improvement over baselines - and a high Answer Correctness score of 74.3%. Our work establishes a new standard for Persian Islamic QA and validates that our iterative, adaptive architecture is crucial for building faithful, reliable AI systems in sensitive domains.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.905277",
        "filter_reason": "这篇论文符合筛选要求，应被保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。尽管论文的标题和应用领域（伊斯兰问答）看起来像一个特定领域的应用，但其核心贡献并非应用本身，而是其提出的 **FAIR-RAG 架构**。摘要明确指出，FARSIQA 是 \"built upon our innovative FAIR-RAG architecture\"，并且该架构是一个 \"Faithful, Adaptive, Iterative Refinement framework for RAG\"。这表明论文的本质是提出一种构建智能体系统的新方法论或新框架，而非简单地将现有技术应用于一个新领域。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **智能体能力**: FAIR-RAG 架构明确包含了 `Self-Correction`（自我修正）、`Planning`（通过 \"adaptively decomposes complex queries\" 实现）和 `Self-Reflection`（通过 \"assesses evidence sufficiency\" 实现）。 - **演化机制**: 其核心是一个 `Iterative Improvement`（迭代改进）的循环，通过生成子查询来逐步填补信息空白，这属于自我演化的范畴。 - **核心范式**: 整个 FAIR-RAG 框架是一个典型的 `Agentic AI` 实现，其工作流程（分解、评估、迭代）与 `ReAct` 等智能体范式高度相似。 3.  **第三步：排除标准** - **安全与对齐**: 论文虽然提到了 \"hallucination and unfaithfulness\"，但其主要贡献是提出一个**架构**来**解决**这个问题，而不是研究安全、对齐或幻觉本身的技术。因此，它不属于以安全为主要贡献的论文，不应被排除。 - **多模态与视觉**: 论文不涉及多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的核心是关于智能体如何进行规划和多步推理。FAIR-RAG 通过 \"adaptively decomposes complex queries\" 和 \"iterative loop to generate sub-queries\" 实现了复杂任务的分解和逐步解决，这完全符合“保留”关于智能体规划与推理的论文的标准。 - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美例证。虽然它被应用在“波斯语伊斯兰领域”这一特定场景，但其核心贡献是提出了一种新的“自我演化/自我修正”机制（即 FAIR-RAG 框架）。根据筛选规则，这种情况应该被**保留**。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个具备规划、自我反思和迭代修正能力的LLM智能体框架（FAIR-RAG）。尽管它以一个具体的应用（FARSIQA）作为案例展示，但其方法论本身具有通用性，直接对“单智能体”和“自我演化”这两个研究方向做出了贡献。因此，该论文完全符合研究范围，应被保留。"
    },
    {
        "index": "#34",
        "title": "ProMediate: A Socio-cognitive framework for evaluating proactive agents in multi-party negotiation",
        "link": "/arxiv/2510.25224",
        "arxiv_id": "2510.25224",
        "authors": "Ziyi Liu, Bahar Sarrafzadeh, Pei Zhou, Longqi Yang, Jieyu Zhao, Ashish Sharma",
        "summary": "While Large Language Models (LLMs) are increasingly used in agentic frameworks to assist individual users, there is a growing need for agents that can proactively manage complex, multi-party collaboration. Systematic evaluation methods for such proactive agents remain scarce, limiting progress in developing AI that can effectively support multiple people together. Negotiation offers a demanding testbed for this challenge, requiring socio-cognitive intelligence to navigate conflicting interests between multiple participants and multiple topics and build consensus. Here, we present ProMediate, the first framework for evaluating proactive AI mediator agents in complex, multi-topic, multi-party negotiations. ProMediate consists of two core components: (i) a simulation testbed based on realistic negotiation cases and theory-driven difficulty levels (ProMediate-Easy, ProMediate-Medium, and ProMediate-Hard), with a plug-and-play proactive AI mediator grounded in socio-cognitive mediation theories, capable of flexibly deciding when and how to intervene; and (ii) a socio-cognitive evaluation framework with a new suite of metrics to measure consensus changes, intervention latency, mediator effectiveness, and intelligence. Together, these components establish a systematic framework for assessing the socio-cognitive intelligence of proactive AI agents in multi-party settings. Our results show that a socially intelligent mediator agent outperforms a generic baseline, via faster, better-targeted interventions. In the ProMediate-Hard setting, our social mediator increases consensus change by 3.6 percentage points compared to the generic baseline (10.65\\% vs 7.01\\%) while being 77\\% faster in response (15.98s vs. 3.71s). In conclusion, ProMediate provides a rigorous, theory-grounded testbed to advance the development of proactive, socially intelligent agents.",
        "subjects": "Computation and Language",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.926591",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单应用LLM，而是提出了一个全新的**方法论框架**。其核心贡献是 `ProMediate`，一个用于**评估**主动智能体在多方谈判中表现的框架。构建评估框架是推动智能体发展和改进的关键一步，因此这属于“构建、改进或演化LLM智能体”的范畴。论文中还包含了一个“即插即用的主动AI调解智能体”，这本身就是对智能体构建的直接贡献。它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文高度匹配你的核心关注点，尤其是在**多智能体**方向。 - **核心范式**: 明确涉及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems (MAS)`。 - **智能体能力**: 论文中的智能体需要 `deciding when and how to intervene`，这属于 `Planning` 和决策能力。 - **多智能体**: 论文的核心是 `multi-party negotiation`，直接命中了 `Collaboration`, `Communication`, `Negotiation` 等关键词。它研究的是智能体如何在一个由多个参与者（可能是其他智能体或人）组成的复杂社会环境中运作。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐、可解释性或多模态。虽然提到了“社会认知智能”，但其目的是为了更好地进行谈判和调解，而不是为了研究AI安全或伦理。因此，它没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的智能体需要“灵活地决定何时以及如何干预”，这明确是智能体层面的规划和决策，而不是提升LLM本身的基础数学或逻辑推理能力。因此，符合保留条件。 5.  **第五步：最终决策** - 综合来看，这篇论文的核心贡献是提出一个用于**评估和推动**一类新型多智能体（主动调解智能体）发展的**理论框架和测试平台**。它不仅构建了智能体，还定义了衡量其智能和有效性的新指标。这完全契合你“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标，并且精准地落在了“多智能体”这一研究焦点上。因此，最终判断为 **True**。"
    },
    {
        "index": "#30",
        "title": "CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared Memories",
        "link": "/arxiv/2510.25333",
        "arxiv_id": "2510.25333",
        "authors": "Yilong Lai, Yipin Yang, Jialong Wu, Fengran Mo, Zhenglin Wang, Ting Liang, Jianguo Lin, Keping Yang",
        "summary": "Recent years have witnessed the rapid development of LLM-based agents, which shed light on using language agents to solve complex real-world problems. A prominent application lies in business agents, which interact with databases and internal knowledge bases via tool calls to fulfill diverse user requirements. However, this domain is characterized by intricate data relationships and a wide range of heterogeneous tasks, from statistical data queries to knowledge-based question-answering. To address these challenges, we propose CRMWeaver, a novel approach that enhances business agents in such complex settings. To acclimate the agentic model to intricate business environments, we employ a synthesis data generation and RL-based paradigm during training, which significantly improves the model's ability to handle complex data and varied tasks. During inference, a shared memories mechanism is introduced, prompting the agent to learn from task guidelines in similar problems, thereby further boosting its effectiveness and generalization, especially in unseen scenarios. We validate the efficacy of our approach on the CRMArena-Pro dataset, where our lightweight model achieves competitive results in both B2B and B2C business scenarios, underscoring its practical value for real-world applications.",
        "subjects": "Computation and Language",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.920376",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出了一种名为 **CRMWeaver** 的新方法，其本质是**构建和增强LLM智能体**。它不是简单地将现有智能体应用于商业领域，而是提出了新的训练范式（基于智能体强化学习）和推理机制（共享记忆）来提升智能体在复杂环境下的能力。这直接命中了你“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个你的核心关注点： *   **核心范式**: 明确提到了 `LLM-based agents`。 *   **智能体能力**: 提到了 `Tool Use`（通过工具调用与数据库交互）和 `Memory`（引入了共享记忆机制）。 *   **演化机制**: 其训练阶段的 `RL-based paradigm`（基于强化学习的范式）是一种通过环境反馈进行自我改进和迭代的机制，属于 `Self-Improvement` 的范畴。推理阶段的共享记忆机制也是一种让智能体从过往经验中学习、实现 `Iterative Improvement` 的方式。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献不在于安全、对齐、可解释性或多模态。它专注于提升智能体的任务执行能力和泛化能力，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文中的“共享记忆”机制，让智能体“从相似问题的任务指南中学习”，这是一种典型的智能体在复杂任务中进行多步推理和学习的过程，而非单纯提升LLM的基础推理能力，因此符合保留条件。 *   **自我演化的应用**: 尽管论文的应用领域是商业（Business Agent），但其核心贡献在于提出了**新的“自我演化”机制**（RL训练范式和共享记忆）。根据你的规则，即使应用在特定领域，只要核心是提出新的演化机制，就应该保留。这篇论文正是这种情况。 **最终决策**: 该论文的核心贡献在于提出了一种结合了**智能体强化学习**和**共享记忆**的新框架，用以**构建和改进**一个能够处理复杂任务的LLM智能体。这完全符合你研究课题中的“单智能体”方向（改进记忆、学习）和“自我演化”方向（通过RL和经验进行自我完善）。因此，这篇论文是高度相关的前沿研究，应被筛选入内。"
    },
    {
        "index": "#36",
        "title": "Model-Document Protocol for AI Search",
        "link": "/arxiv/2510.25160",
        "arxiv_id": "2510.25160",
        "authors": "Hongjin Qian, Zheng Liu",
        "summary": "AI search depends on linking large language models (LLMs) with vast external knowledge sources. Yet web pages, PDF files, and other raw documents are not inherently LLM-ready: they are long, noisy, and unstructured. Conventional retrieval methods treat these documents as verbatim text and return raw passages, leaving the burden of fragment assembly and contextual reasoning to the LLM. This gap underscores the need for a new retrieval paradigm that redefines how models interact with documents. We introduce the Model-Document Protocol (MDP), a general framework that formalizes how raw text is bridged to LLMs through consumable knowledge representations. Rather than treating retrieval as passage fetching, MDP defines multiple pathways that transform unstructured documents into task-specific, LLM-ready inputs. These include agentic reasoning, which curates raw evidence into coherent context; memory grounding, which accumulates reusable notes to enrich reasoning; and structured leveraging, which encodes documents into formal representations such as graphs or key-value caches. All three pathways share the same goal: ensuring that what reaches the LLM is not raw fragments but compact, structured knowledge directly consumable for reasoning. As an instantiation, we present MDP-Agent, which realizes the protocol through an agentic process: constructing document-level gist memories for global coverage, performing diffusion-based exploration with vertical exploitation to uncover layered dependencies, and applying map-reduce style synthesis to integrate large-scale evidence into compact yet sufficient context. Experiments on information-seeking benchmarks demonstrate that MDP-Agent outperforms baselines, validating both the soundness of the MDP framework and the effectiveness of its agentic instantiation.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.927122",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质是提出一个名为“Model-Document Protocol (MDP)”的新框架，以及一个名为“MDP-Agent”的智能体实例化。其核心贡献并非将现有智能体应用于某个领域，而是**构建和改进LLM智能体与外部知识（文档）交互的方法论**。它解决了智能体在处理长文档、非结构化信息时的根本性挑战，这直接属于“构建、改进LLM智能体”的范畴。因此，它通过了第一步的核心判断。 **第二步：正面指标——高度匹配** 论文中包含了大量与你核心关注点直接相关的正面指标： *   **核心范式**: 论文明确提出了一个 `Agentic AI` 框架（MDP）和一个 `LLM-based Agent` 实例（MDP-Agent）。 *   **智能体能力**: *   `Memory`: 论文的核心机制之一是 `memory grounding`（记忆锚定）和构建 `gist memories`（要点记忆），这直接对应了智能体的记忆能力。 *   `Tool Use`: 整个MDP框架可以被看作是一种高级的、结构化的 `Tool Use`。它不是简单地检索文本，而是将文档“工具化”，通过多种路径（如 `agentic reasoning`）将其转化为LLM可用的知识。 *   `Planning`: MDP-Agent的实现过程，包括“diffusion-based exploration with vertical exploitation”和“map-reduce style synthesis”，描述了一个复杂的多步推理和规划过程，以整合大规模证据。这超越了简单的线性推理，属于智能体规划的范畴。 *   `Agentic reasoning`: 论文明确使用了这一术语，表明其方法的核心是智能体驱动的推理过程。 **第三步：排除标准——未触及** 论文的研究焦点是智能体的信息处理和推理框架，没有涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题，也未涉及 `Vision`、`MLLMs` 等多模态内容。因此，它没有触发任何排除标准。 **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文提出的 `agentic reasoning` 和 MDP-Agent的多步处理流程，是典型的**智能体框架内的规划与推理**。它不是在提升LLM本身的基础数学或逻辑能力，而是在构建一个让智能体能够更好地完成复杂信息整合任务的框架。这完全符合“保留”的条件。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种创新的框架（MDP）和智能体实现（MDP-Agent），用于增强LLM智能体的**记忆**、**工具使用**和**规划**能力，使其能更有效地与复杂的文档知识进行交互。这精准地命中了你研究目标中的“单智能体”方向，特别是其规划、记忆和工具使用等子方向。因此，这篇论文是高度相关且有价值的前沿研究。"
    },
    {
        "index": "#52",
        "title": "Idea2Plan: Exploring AI-Powered Research Planning",
        "link": "/arxiv/2510.24891",
        "arxiv_id": "2510.24891",
        "authors": "Jin Huang, Silviu Cucerzan, Sujay Kumar Jauhar, Ryen W. White",
        "summary": "Large language models (LLMs) have demonstrated significant potential to accelerate scientific discovery as valuable tools for analyzing data, generating hypotheses, and supporting innovative approaches in various scientific fields. In this work, we investigate how LLMs can handle the transition from conceptual research ideas to well-structured research plans. Effective research planning not only supports scientists in advancing their research but also represents a crucial capability for the development of autonomous research agents. Despite its importance, the field lacks a systematic understanding of LLMs' research planning capability. To rigorously measure this capability, we introduce the Idea2Plan task and Idea2Plan Bench, a benchmark built from 200 ICML 2025 Spotlight and Oral papers released after major LLM training cutoffs. Each benchmark instance includes a research idea and a grading rubric capturing the key components of valid plans. We further propose Idea2Plan JudgeEval, a complementary benchmark to assess the reliability of LLM-based judges against expert annotations. Experimental results show that GPT-5 and GPT-5-mini achieve the strongest performance on the benchmark, though substantial headroom remains for future improvement. Our study provides new insights into LLMs' capability for research planning and lay the groundwork for future progress.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.952077",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非将LLM作为工具应用于某个特定领域（如生物、金融），而是**定义并衡量了LLM智能体的一项核心能力——研究规划**。作者提出了“Idea2Plan”这一新任务和相应的基准“Idea2Plan Bench”，其目的是系统性地评估LLM将抽象想法转化为具体计划的能力。这属于构建和改进LLM智能体方法论的基础性工作，因为它为“如何衡量和提升智能体的规划能力”提供了标准和工具。论文明确指出，这种能力是“自主研究智能体发展的关键能力”，因此其本质是围绕Agentic AI的核心能力展开的，而非简单的应用。 2.  **正面指标 (第二步):** 论文高度符合我的核心关注点。 *   **核心范式:** 论文直接关联`Agentic AI`和`LLM-based Agents`，并探讨了`自主研究智能体`。 *   **智能体能力:** 论文的主题是`Planning`（规划），这是单智能体研究的核心子方向之一。它研究的是智能体如何进行复杂的多步推理和任务分解，以实现一个长期目标（从想法到计划）。 3.  **排除标准 (第三步):** 论文未涉及任何排除标准。其主要贡献不是关于安全、对齐或可解释性，也未涉及多模态或视觉模型。 4.  **特殊和模糊情况处理 (第四步):** *   **推理/规划:** 这篇论文是“关于智能体如何进行规划或在复杂任务中进行多步推理”的典型范例。它研究的不是LLM基础的数学或逻辑推理能力，而是其在一个高度复杂的、类似真实世界科研场景下的**自主规划能力**。这完全符合保留条件。 **最终决策 (第五步):** 综合来看，这篇论文虽然不是提出一个全新的智能体架构，但它为LLM智能体的一个核心能力——**规划**——提供了严谨的评估基准和任务定义。这项工作是推动Agentic AI，特别是自主研究智能体发展的关键一步，因为它解决了“如何衡量我们是否进步”的问题。因此，它精准地契合了我研究范围中的“单智能体”方向，特别是“规划”这一子方向，应该被保留。"
    },
    {
        "index": "#65",
        "title": "Dingtalk DeepResearch: A Unified Multi Agent Framework for Adaptive Intelligence in Enterprise Environments",
        "link": "/arxiv/2510.24760",
        "arxiv_id": "2510.24760",
        "authors": "Mengyuan Chen, Chengjun Dai, Xinyang Dong, Chengzhe Feng, Kewei Fu, Jianshe Li, Zhihan Peng, Yongqi Tong, Junshao Zhang, Hong Zhu",
        "summary": "We present Dingtalk DeepResearch, a unified multi agent intelligence framework for real world enterprise environments, delivering deep research, heterogeneous table reasoning, and multimodal report generation.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.956008",
        "filter_reason": "根据您提供的筛选标准，我的判断过程如下： 1.  **第一步：核心判断** - 论文标题明确指出这是一个 \"unified multi agent framework\"（统一多智能体框架），摘要中再次强调其为 \"a unified multi agent intelligence framework\"。 - 这表明论文的核心贡献是**构建和提出一个新的多智能体系统框架**，而不是将已有的框架作为工具应用到一个特定领域。 - 因此，该论文完全符合“保留”标准，其本质是关于构建LLM智能体系统的方法论。 2.  **第二步：正面指标** - 论文直接命中了多个核心正面指标： - **核心范式**: `Multi-Agent Systems (MAS)` 是标题和摘要的核心。 - **智能体能力**: \"deep research\" 和 \"heterogeneous table reasoning\" 暗示了智能体具备复杂的 `Planning` 和 `Tool Use` 能力。 - **多智能体**: 标题和摘要都强调了 `Multi-Agent`。 - **演化机制**: 标题中的 \"Adaptive Intelligence\"（自适应智能）强烈暗示了智能体具备适应环境或任务的能力，这与 `Self-Improvement` 或 `Iterative Improvement` 的演化机制高度相关。 3.  **第三步：排除标准** - 论文摘要中没有提及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐相关的内容。 - 摘要中提到了 \"multimodal report generation\"（多模态报告生成）。根据您的规则，这属于“被用作智能体感知环境的工具，而不是研究的核心”。在这里，多模态生成是智能体框架的一个输出能力，研究的核心是框架本身，而非多模态技术。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文框架所执行的 \"deep research\" 和 \"heterogeneous table reasoning\" 任务，必然涉及到智能体的自主规划和多步推理，这属于Agentic框架的范畴，应予以保留。 - **自我演化的应用**: 论文标题中的 \"Adaptive Intelligence\" 表明其框架可能包含某种适应或演化机制。即使该框架被应用于 \"enterprise environments\" 这一特定领域，但由于其核心贡献是提出这个（可能具备演化能力的）新框架，根据您的例外规则，也应保留。 **最终决策**: 该论文的核心贡献是提出一个**统一的多智能体框架**，旨在实现企业环境下的自适应智能。这完全符合您研究课题中的“多智能体”方向，并可能触及“自我演化”方向。它不是对现有智能体的简单应用，而是对智能体架构本身的构建和改进。因此，这篇论文高度符合您的研究范围。 **结论：保留。**"
    },
    {
        "index": "#66",
        "title": "Iti-Validator: A Guardrail Framework for Validating and Correcting LLM-Generated Itineraries",
        "link": "/arxiv/2510.24719",
        "arxiv_id": "2510.24719",
        "authors": "Shravan Gadbail, Masumi Desai, Kamalakar Karlapalem",
        "summary": "The rapid advancement of Large Language Models (LLMs) has enabled them to generate complex, multi-step plans and itineraries. However, these generated plans often lack temporal and spatial consistency, particularly in scenarios involving physical travel constraints. This research aims to study the temporal performance of different LLMs and presents a validation framework that evaluates and improves the temporal consistency of LLM-generated travel itineraries. The system employs multiple state-of-the-art LLMs to generate travel plans and validates them against real-world flight duration constraints using the AeroDataBox API. This work contributes to the understanding of LLM capabilities in handling complex temporal reasoning tasks like itinerary generation and provides a framework to rectify any temporal inconsistencies like overlapping journeys or unrealistic transit times in the itineraries generated by LLMs before the itinerary is given to the user. Our experiments reveal that while current LLMs frequently produce temporally inconsistent itineraries, these can be systematically and reliably corrected using our framework, enabling their practical deployment in large-scale travel planning.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2025-09-04",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.956281",
        "filter_reason": "这篇论文符合我的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于旅行规划领域，而是提出了一个名为“Iti-Validator”的**验证和修正框架**。这个框架的作用是接收LLM智能体（作为规划器）的输出（行程计划），然后利用外部工具（AeroDataBox API）进行验证和修正。这本质上是一种**改进LLM智能体输出质量和可靠性的方法论**，属于“构建、改进或演化LLM智能体”的范畴。它不是在解决一个旅行领域的特定问题，而是在提供一个通用的、可增强智能体规划能力的“护栏”或“验证器”模块。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文高度符合我的核心关注点： - **智能体能力**: 论文明确涉及 `Planning`（规划），因为它处理的是LLM生成的“多步计划和行程”。 - **工具使用**: 论文的核心机制就是 `Tool Use / Tool Augmentation`，它使用AeroDataBox API作为外部工具来获取真实世界数据，以验证和修正计划。 - **自我修正**: 论文的框架实现了 `Self-Correction` 的功能，虽然这种修正发生在LLM外部，但它是对智能体输出结果的系统性纠错，是构建可靠智能体系统不可或缺的一环。论文标题和摘要中反复强调的“Validating and Correcting”直接对应了这一能力。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。虽然标题中提到了“Guardrail”（护栏），但其核心目标是解决事实和时间上的不一致性，而非研究AI安全、伦理对齐或可解释性。它也没有涉及多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”条件。它不是在提升LLM的基础数学或逻辑推理能力，而是在研究**智能体如何进行规划**，并提出了一个确保规划在现实世界中可行的框架。这属于Agentic AI中规划能力的前沿研究，即如何让智能体的规划不仅仅是文本上的合理，更是事实上的可行。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种用于**改进LLM智能体规划能力**的框架。它通过引入工具使用和自我修正机制，解决了LLM在复杂规划任务中常见的现实一致性问题。这与我的研究目标——“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”——高度契合，特别是在“单智能体”方向下的“规划”、“工具使用”和“自我反思/修正”子方向上。因此，这篇论文应该被保留。"
    },
    {
        "index": "#67",
        "title": "Process-Level Trajectory Evaluation for Environment Configuration in Software Engineering Agents",
        "link": "/arxiv/2510.25694",
        "arxiv_id": "2510.25694",
        "authors": "Jiayi Kuang, Yinghui Li, Xin Zhang, Yangning Li, Di Yin, Xing Sun, Ying Shen, Philip S. Yu",
        "summary": "Large language model-based agents show promise for software engineering, but environment configuration remains a bottleneck due to heavy manual effort and scarce large-scale, high-quality datasets. Existing benchmarks assess only end-to-end build/test success, obscuring where and why agents succeed or fail. We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench, which provides process-level trajectory assessment of fine-grained agent capabilities during environment setup-planning, perception-driven error diagnosis, feedback-driven repair, and action to execute final environment configuration. Our task instances are automatically constructed by injecting realistic README errors and are validated in Docker for scalable, high-quality evaluation. Enconda-bench combines process-level analysis with end-to-end executability to enable capability assessments beyond aggregate success rates. Evaluations across state-of-the-art LLMs and agent frameworks show that while agents can localize errors, they struggle to translate feedback into effective corrections, limiting end-to-end performance. To our knowledge, Enconda-bench is the first framework to provide process-level internal capability assessment for environment configuration, offering actionable insights for improving software engineering agents.",
        "subjects": "Software Engineering, Artificial Intelligence, Computation and Language",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.956610",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - 论文的本质是什么？这篇论文的核心贡献是提出了一个名为 `Enconda-bench` 的**评估基准**，用于精细地诊断和分析软件工程智能体在环境配置任务中的能力。 - **初步判断**：虽然论文的核心是“评估”而非直接“构建”一个新的智能体框架，但它并非简单的应用型论文。它没有将智能体作为黑盒工具去解决一个软件工程问题，而是深入剖析智能体内部的执行过程和能力短板。这种对智能体能力的**诊断性研究**，是推动智能体“改进”和“演化”的关键前置步骤，因此其本质与“构建、改进或演化 LLM智能体”高度相关。它不属于“非演化型应用”或“非Agentic的推理”的排除范畴。 2.  **第二步：正面指标** - 论文包含了大量我的核心关注点： - **核心范式**: `LLM-based Agents` (明确提及)。 - **智能体能力**: 论文评估的核心能力完全符合我的研究方向，包括 `Planning` (环境设置规划)、`Self-Correction` / `Self-Reflection` (通过 \"perception-driven error diagnosis\" 和 \"feedback-driven repair\" 体现)。论文明确指出，其基准能够评估智能体将反馈转化为有效修正的能力，这正是自我反思和修正的核心。 - 这些正面指标强烈表明该论文与我的研究课题直接相关。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐、可解释性或多模态。它聚焦于智能体的任务执行能力和评估方法，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文完全符合“保留”条件。它不是在提升LLM的基础数学或逻辑能力，而是在评估智能体在复杂任务（环境配置）中的多步规划和基于反馈的修正能力，这正是Agentic框架的核心。 - **自我演化的应用**: 虽然论文提出了一个应用于特定领域（软件工程）的基准，但其核心贡献是评估方法本身，而非应用结果。更重要的是，该方法旨在揭示智能体在“反馈驱动修复”上的弱点，这为开发更强的“自我演化”或“自我修正”机制提供了直接的洞见和改进方向。 5.  **第五步：最终决策** - 综合以上分析，尽管这篇论文的直接产出是一个评估基准，但其研究动机、评估内容和最终目标都紧密围绕着“如何理解和改进LLM智能体的核心能力”。它为智能体的“改进”和“演化”提供了不可或缺的诊断工具和量化依据。因此，这篇论文是推动Agentic AI前沿发展的重要研究，完全符合我的筛选要求。**保留**。"
    },
    {
        "index": "#72",
        "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement Learning",
        "link": "/arxiv/2510.25320",
        "arxiv_id": "2510.25320",
        "authors": "Jiaqi Wu, Qinlao Zhao, Zefeng Chen, Kai Qin, Yifei Zhao, Xueqian Wang, Yuhang Yao",
        "summary": "Autonomous agents powered by large language models (LLMs) have shown impressive capabilities in tool manipulation for complex task-solving. However, existing paradigms such as ReAct rely on sequential reasoning and execution, failing to exploit the inherent parallelism among independent sub-tasks. This sequential bottleneck leads to inefficient tool utilization and suboptimal performance in multi-step reasoning scenarios. We introduce Graph-based Agent Planning (GAP), a novel framework that explicitly models inter-task dependencies through graph-based planning to enable adaptive parallel and serial tool execution. Our approach trains agent foundation models to decompose complex tasks into dependency-aware sub-task graphs, autonomously determining which tools can be executed in parallel and which must follow sequential dependencies. This dependency-aware orchestration achieves substantial improvements in both execution efficiency and task accuracy. To train GAP, we construct a high-quality dataset of graph-based planning traces derived from the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage training strategy: supervised fine-tuning (SFT) on the curated dataset, followed by reinforcement learning (RL) with a correctness-based reward function on strategically sampled queries where tool-based reasoning provides maximum value. Experimental results on MHQA datasets demonstrate that GAP significantly outperforms traditional ReAct baselines, particularly on multi-step retrieval tasks, while achieving dramatic improvements in tool invocation efficiency through intelligent parallelization. The project page is available at: https://github.com/WJQ7777/Graph-Agent-Planning.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.963246",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体。以下是详细的判断过程： 1.  **第一步：核心判断——保留** - **论文本质**: 论文的核心是提出一个名为“Graph-based Agent Planning (GAP)”的**新框架**。这个框架旨在解决现有LLM智能体（如ReAct）在规划和工具使用上的效率瓶颈问题。它不是将现有智能体作为工具应用到某个领域，而是**直接改进智能体本身的规划和执行机制**。这完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标——高度匹配** - **核心范式**: 论文明确属于 `Agentic AI` 和 `LLM-based Agents` 范畴。 - **智能体能力**: 论文的核心贡献集中在 `Planning`（图基规划）和 `Tool Use`（并行工具使用）上。它通过构建依赖图来优化智能体的多步推理和工具调用策略，这正是您关注的单智能体方向的核心能力。 - **其他指标**: 论文与 `ReAct` 进行对比，并使用 `Reinforcement Learning` 进行训练，这些都属于智能体研究中的关键技术。 3.  **第三步：排除标准——不涉及** - 论文的主要贡献是提升智能体的效率和性能，不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐议题。 - 论文也未涉及 `Vision` 或多模态内容，其焦点纯粹在智能体的决策和规划逻辑上。 4.  **第四步：处理特殊和模糊情况——符合保留条件** - **推理/规划**: 这篇论文是关于**智能体如何进行规划**的典型案例。它提出的GAP框架是一种新的Agentic规划范式，旨在优化多步推理中的工具执行顺序（并行与串行）。这完全符合“保留”标准，而不是被排除的“非Agentic的推理”。 **总结**: 该论文的核心贡献是提出了一种新颖的图基规划框架（GAP），通过显式建模子任务间的依赖关系，实现了LLM智能体的并行工具使用和自适应执行。这直接命中了您研究焦点中的**“单智能体”**方向，特别是其**“规划”**和**“工具使用”**能力。它不是对现有智能体的简单应用，而是对智能体核心架构和能力的实质性改进，因此是您课题下非常相关和前沿的论文。"
    },
    {
        "index": "#76",
        "title": "StorageXTuner: An LLM Agent-Driven Automatic Tuning Framework for Heterogeneous Storage Systems",
        "link": "/arxiv/2510.25017",
        "arxiv_id": "2510.25017",
        "authors": "Qi Lin, Zhenyu Zhang, Viraj Thakkar, Zhenjie Sun, Mai Zheng, Zhichao Cao",
        "summary": "Automatically configuring storage systems is hard: parameter spaces are large and conditions vary across workloads, deployments, and versions. Heuristic and ML tuners are often system specific, require manual glue, and degrade under changes. Recent LLM-based approaches help but usually treat tuning as a single-shot, system-specific task, which limits cross-system reuse, constrains exploration, and weakens validation. We present StorageXTuner, an LLM agent-driven auto-tuning framework for heterogeneous storage engines. StorageXTuner separates concerns across four agents - Executor (sandboxed benchmarking), Extractor (performance digest), Searcher (insight-guided configuration exploration), and Reflector (insight generation and management). The design couples an insight-driven tree search with layered memory that promotes empirically validated insights and employs lightweight checkers to guard against unsafe actions. We implement a prototype and evaluate it on RocksDB, LevelDB, CacheLib, and MySQL InnoDB with YCSB, MixGraph, and TPC-H/C. Relative to out-of-the-box settings and to ELMo-Tune, StorageXTuner reaches up to 575% and 111% higher throughput, reduces p99 latency by as much as 88% and 56%, and converges with fewer trials.",
        "subjects": "Databases, Artificial Intelligence, Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.964532",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建了一个新颖的多智能体框架，而非仅仅将LLM作为工具应用。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心不是“如何用LLM调优存储系统”，而是“如何设计一个由LLM智能体驱动的、可复用的自动调优框架”。摘要明确指出，该框架“separates concerns across four agents - Executor, Extractor, Searcher, and Reflector”。这清晰地表明，论文的核心贡献是**构建一个多智能体系统（Multi-Agent Systems）**，其设计、分工和协作机制是研究的重点。这直接命中了您研究目标中的“构建、改进或演化 LLM智能体”。 2.  **第二步：正面指标——高度相关** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)`。论文标题和摘要都强调了这一点。 - **智能体能力**: - `Memory`: 摘要中明确提到了“layered memory that promotes empirically validated insights”。 - `Self-Reflection`: `Reflector`智能体的职责是“insight generation and management”，这是一种典型的自我反思机制。 - `Planning`: `Searcher`智能体执行“insight-driven tree search”和“configuration exploration”，这属于智能体的规划和搜索能力。 - **多智能体**: 四个智能体（`Executor`, `Extractor`, `Searcher`, `Reflector`）协同工作，构成了一个完整的多智能体协作系统。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不是关于安全、对齐或可解释性。虽然提到了“lightweight checkers to guard against unsafe actions”，但这只是框架实现中的一个安全特性，而非研究的核心主题。 - 论文不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 论文中的`Searcher`智能体进行的“insight-driven tree search”是智能体在复杂任务（配置调优）中进行规划和多步推理的典型范例，完全符合保留条件。 - **自我演化的应用**: 虽然这篇论文不是典型的“自我演化”论文，但其`Reflector`智能体和`layered memory`机制形成了一个闭环：智能体从过去的经验中提炼洞察，并用这些洞察指导未来的搜索，这体现了迭代改进和从经验中学习的思想，与自我演化的精神内核一致。更重要的是，即使不考虑这一点，其**多智能体框架的设计**本身已经足够成为保留的理由。它属于“提出一种新的机制（多智能体协作框架），即使它被应用在特定领域（存储系统）”的例外情况。 **最终决策**: 这篇论文的核心贡献是提出并实现了一个名为`StorageXTuner`的**LLM多智能体框架**。它详细设计了四个具有不同职责的智能体（执行、提取、搜索、反思），并赋予它们记忆、反思和规划等关键能力。虽然其应用场景是存储系统调优，但论文的精髓在于**这个智能体框架本身的设计、架构和工作流程**，这完全契合您“构建、改进或演化 LLM智能体”的核心研究目标。因此，这篇论文应该被保留。"
    },
    {
        "index": "#75",
        "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome Supervision for KBQA",
        "link": "/arxiv/2510.25101",
        "arxiv_id": "2510.25101",
        "authors": "Zhuo Chen, Fei Wang, Zixuan Li, Zhao Zhang, Weiwei Ding, Chuanguang Yang, Yongjun Xu, Xiaolong Jin, Jiafeng Guo",
        "summary": "Knowledge Base Question Answering (KBQA) aims to answer natural-language questions over a structured Knowledge Base (KB). Recent work improves KBQA by adopting an agentic reasoning paradigm, in which Large Language Models (LLMs) iteratively decompose a question, generate its corresponding logical queries, and interact with the KB to derive the answer. However, these methods typically fine-tune LLMs on reasoning trajectories synthesized via process supervision, which offers weak incentives for exploration and thus fails to strengthen the agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that can autonomously perform agentic reasoning on KBs to obtain answers. To incentivize autonomous exploration, KnowCoder-A1 trains the LLM under outcome-only supervision via a multi-stage curriculum reinforcement learning with an easy-to-hard curriculum. To establish foundational agentic capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of high-quality trajectories obtained through outcome-based rejection sampling. Then, to alleviate the reward sparsity inherent in outcome-only supervision, it applies multi-stage curriculum RL with reward schedules that progress from easy to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful reasoning behaviors and consistently outperforms prior approaches across three mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1 achieves up to an 11.1% relative improvement while using only one-twelfth of the training data, demonstrating strong agentic reasoning capabilities.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-10-30T11:00:04.964244",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于**改进和演化LLM智能体的推理能力**。以下是根据你的筛选标准进行的详细判断： 1.  **第一步：核心判断 (保留)** - 论文的本质不是简单地将LLM智能体作为工具应用到KBQA（知识库问答）这个领域。相反，它的核心贡献是提出了一种名为**KnowCoder-A1的新训练框架**，旨在解决现有智能体推理方法（基于过程监督）的弱点，即“探索激励不足”和“无法有效强化智能体推理能力”。 - 论文的核心是**方法论创新**，即如何通过“结果监督”和“多阶段课程强化学习”来**训练和演化**一个更具自主探索和推理能力的智能体。KBQA只是验证该方法有效性的实验场。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标 (高度相关)** - **核心范式**: 论文明确围绕 `Agentic AI` 和 `LLM-based Agents` 展开，标题和摘要中多次提及“agentic reasoning capability”。 - **智能体能力**: 论文的核心是提升智能体的**规划**（iteratively decompose a question）和**工具使用**（interact with the KB）能力。 - **演化机制**: 这是最关键的匹配点。论文提出的“多阶段课程强化学习”和“从易到难的课程”是一种明确的**自我完善**和**迭代改进**机制。它通过环境反馈（结果监督）来驱动智能体自身能力的演化，完全符合“自我演化”的研究方向。 3.  **第三步：排除标准 (不适用)** - 论文的主要贡献不是关于安全、对齐、可解释性或多模态。它专注于智能体的能力构建，因此不触及任何排除标准。 4.  **第四步：处理特殊和模糊情况 (符合保留规则)** - **推理/规划**: 论文讨论的是智能体如何进行多步推理和与外部工具交互以完成复杂任务，这完全符合“保留”标准，而不是关于提升LLM基础推理能力。 - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。它的核心是提出一种**新的“自我演化”训练机制**（课程强化学习），并将其应用在KBQA领域。根据你的规则，这种情况应该保留。 **最终决策**: 这篇论文的核心贡献是提出了一种通过课程强化学习来**演化LLM智能体自主推理能力**的新框架。它直接命中了你研究目标中的“单智能体”和“自我演化”两个核心方向。虽然论文在KBQA任务上进行验证，但其研究焦点和价值在于智能体方法论本身，而非应用领域。因此，这篇论文是高度相关且应该保留的前沿研究。"
    },
    {
        "index": "#4",
        "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence Gathering in Long Documents",
        "link": "/arxiv/2510.25668",
        "arxiv_id": "2510.25668",
        "authors": "Tianyu Yang, Terry Ruas, Yijun Tian, Jan Philip Wahle, Daniel Kurzawe, Bela Gipp",
        "summary": "Vision-language models (VLMs) excel at interpreting text-rich images but struggle with long, visually complex documents that demand analysis and integration of information spread across multiple pages. Existing approaches typically rely on fixed reasoning templates or rigid pipelines, which force VLMs into a passive role and hinder both efficiency and generalization. We present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement learning framework that fine-tunes VLMs as interactive agents capable of actively navigating long, visually rich documents. ALDEN introduces a novel fetch action that directly accesses the page by index, complementing the classic search action and better exploiting document structure. For dense process supervision and efficient training, we propose a rule-based cross-level reward that provides both turn- and token-level signals. To address the empirically observed training instability caused by numerous visual tokens from long documents, we further propose a visual-semantic anchoring mechanism that applies a dual-path KL-divergence constraint to stabilize visual and textual representations separately during training. Trained on a corpus constructed from three open-source datasets, ALDEN achieves state-of-the-art performance on five long-document benchmarks. Overall, ALDEN marks a step beyond passive document reading toward agents that autonomously navigate and reason across long, visually rich documents, offering a robust path to more accurate and efficient long-document understanding.",
        "subjects": "Artificial Intelligence, Multimedia",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-10-30T11:00:05.497564",
        "filter_reason": "这篇论文完全符合你的研究范围，应该被保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建了一个名为ALDEN的新框架。该框架通过强化学习将视觉语言模型（VLM）微调成一个能够**主动导航和收集证据的交互式智能体**。这完全符合“构建、改进LLM智能体”的核心目标。它不是简单应用已有框架，而是提出了一个新的智能体构建方法论，因此不属于“非演化型应用”的排除范畴。 2.  **正面指标 (第二步):** 论文包含了多个核心关注点。 *   **核心范式:** 论文明确提出了一个`LLM-based Agents`框架（ALDEN），将VLM转变为`interactive agents`。 *   **智能体能力:** 论文的核心是智能体的`Planning`能力（通过`active navigation`实现）和`Tool Use`能力（引入了`fetch`和`search`两种行动/工具）。其多轮交互和决策过程与`ReAct`范式高度相似。 3.  **排除标准 (第三步):** 论文不涉及任何排除标准。 *   **安全与对齐:** 论文焦点是提升智能体的任务执行能力，而非安全、对齐或可解释性。 *   **多模态与视觉:** 这是一个关键点。虽然论文使用了VLM，但它的处理方式符合你的特殊规则。在这里，视觉能力是智能体**感知环境（长文档）的工具**，而不是研究的核心。论文的核心贡献是**智能体的导航和决策框架（ALDEN）**，而不是VLM模型本身。因此，它不应被排除。 4.  **特殊和模糊情况 (第四步):** *   **推理/规划:** 论文的研究内容完美契合“保留”条件。它不是在改进LLM的基础推理能力，而是在构建一个**智能体框架**，让智能体能够在复杂任务（长文档理解）中进行多步推理和规划（决定下一步是`search`还是`fetch`）。 **总结:** 论文的核心贡献是提出了一种通过强化学习训练VLM，使其成为具备主动规划和工具使用能力的单智能体框架。这直接命中了你研究范围中的“单智能体”方向，特别是“规划”和“工具使用”子方向。因此，这篇论文高度相关，应被保留。"
    },
    {
        "index": "#1",
        "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological Counseling",
        "link": "/arxiv/2510.25758",
        "arxiv_id": "2510.25758",
        "authors": "He Hu, Yucheng Zhou, Chiyuan Ma, Qianning Wang, Zheng Zhang, Fei Ma, Laizhong Cui, Qi Tian",
        "summary": "Large language models (LLMs) in psychological counseling have attracted increasing attention. However, existing approaches often lack emotional understanding, adaptive strategies, and the use of therapeutic methods across multiple sessions with long-term memory, leaving them far from real clinical practice. To address these critical gaps, we introduce TheraMind, a strategic and adaptive agent for longitudinal psychological counseling. The cornerstone of TheraMind is a novel dual-loop architecture that decouples the complex counseling process into an Intra-Session Loop for tactical dialogue management and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session Loop perceives the patient's emotional state to dynamically select response strategies while leveraging cross-session memory to ensure continuity. Crucially, the Cross-Session Loop empowers the agent with long-term adaptability by evaluating the efficacy of the applied therapy after each session and adjusting the method for subsequent interactions. We validate our approach in a high-fidelity simulation environment grounded in real clinical cases. Extensive evaluations show that TheraMind outperforms other methods, especially on multi-session metrics like Coherence, Flexibility, and Therapeutic Attunement, validating the effectiveness of its dual-loop design in emulating strategic, adaptive, and longitudinal therapeutic behavior. The code is publicly available at https://0mwwm0.github.io/TheraMind/.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-10-30T11:00:05.496708",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建和演化一个具有高级能力的LLM智能体。我的判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心并非简单地将LLM应用于心理咨询领域，而是提出了一种**全新的智能体架构**。其核心贡献是“一种新颖的双循环架构”，用于解决现有方法在适应性、策略性和长期记忆方面的不足。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。它不是一个简单的“非演化型应用”，因为其创新点在于智能体本身的设计和演化机制，而非应用本身。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个你关注的核心范式和能力： *   **Agentic AI / LLM-based Agents**: 论文明确将TheraMind定义为一个“strategic and adaptive agent”。 *   **Planning**: 论文的核心是“strategic therapeutic planning”（跨会话循环的战略规划）和“tactical dialogue management”（会话内的战术管理），这直接对应了智能体的规划能力。 *   **Memory**: 论文明确提出了“cross-session memory”（跨会话记忆）来确保对话的连续性，这是智能体记忆能力的关键体现。 *   **Self-Evolving / Self-Improvement**: 这是最关键的匹配点。论文的“Cross-Session Loop”通过“评估每次会话后所应用疗法的有效性，并调整后续互动的方法”，实现了一个明确的**自我完善和迭代**的闭环。这完全符合你“自我演化”研究方向的定义，即“智能体通过经验、反思或环境反馈进行自我完善和迭代”。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献是关于智能体的架构和能力，而非安全、对齐或可解释性。虽然心理咨询涉及伦理，但论文的焦点是技术实现，因此不触及排除标准。 4.  **第四步：处理特殊和模糊情况 (完美契合)** 这篇论文是“自我演化的应用”这一特殊情况的绝佳范例。虽然它被应用在“心理咨询”这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**（即双循环架构中的跨会话评估与调整）。根据你的规则，即使应用在特定领域，只要核心是新的自我演化机制，就应该保留。 **总结**: TheraMind论文的核心是设计了一个具备长期记忆、战略规划和**跨会话自我演化能力**的新型LLM智能体。它不仅触及了“单智能体”的规划与记忆，更在“自我演化”方向上做出了明确的方法论贡献。因此，它与你关于“LLM智能体及其演化”的研究课题高度相关，应当被保留。"
    },
    {
        "index": "#9",
        "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation",
        "link": "/arxiv/2510.25518",
        "arxiv_id": "2510.25518",
        "authors": "Thomas Cook, Richard Osuagwu, Liman Tsatiashvili, Vrynsia Vrynsia, Koustav Ghosal, Maraim Masoud, Riccardo Mattivi",
        "summary": "Retrieval-Augmented Generation (RAG) systems often face limitations in specialized domains such as fintech, where domain-specific ontologies, dense terminology, and acronyms complicate effective retrieval and synthesis. This paper introduces an agentic RAG architecture designed to address these challenges through a modular pipeline of specialized agents. The proposed system supports intelligent query reformulation, iterative sub-query decomposition guided by keyphrase extraction, contextual acronym resolution, and cross-encoder-based context re-ranking. We evaluate our approach against a standard RAG baseline using a curated dataset of 85 question--answer--reference triples derived from an enterprise fintech knowledge base. Experimental results demonstrate that the agentic RAG system outperforms the baseline in retrieval precision and relevance, albeit with increased latency. These findings suggest that structured, multi-agent methodologies offer a promising direction for enhancing retrieval robustness in complex, domain-specific settings.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-10-30T11:00:05.499070",
        "filter_reason": "这篇论文符合您的研究范围，核心依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将RAG技术应用于金融科技领域。其核心贡献在于提出了一种**新的“智能体RAG架构”**。摘要明确指出，这是一个“由专业化智能体组成的模块化流水线”，并称之为“结构化的多智能体方法论”。这表明论文的重点是**构建和改进一个多智能体系统**，而非仅仅将其作为工具解决领域问题。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文标题和摘要中反复出现 `Agentic Design`、`agentic RAG architecture`、`multi-agent methodologies`，直接命中 `Agentic AI` 和 `Multi-Agent Systems (MAS)`。 - **智能体能力**: 系统的“智能查询重述”和“迭代子查询分解”体现了**规划**能力；整个流水线是**工具使用**的体现，每个智能体模块都是一个专用工具。 - **多智能体**: 论文明确提出了“模块化流水线”和“专业化智能体”，这些智能体协同工作以完成复杂的检索任务，这完全符合**协作**的定义。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐或可解释性，也未聚焦于多模态或视觉技术。因此，它没有触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文是关于智能体如何进行规划的典型例子。它描述了一个智能体系统如何将一个复杂的用户查询分解为多个子任务（查询重述、分解、解析、重排序），并按顺序执行，这是一种高级的规划和推理过程，完全符合保留条件。 **最终决策**: 综合以上分析，这篇论文的核心贡献是**构建一个新颖的多智能体框架来增强RAG系统**。它详细描述了智能体之间的分工与协作机制，这直接对齐了您研究目标中的“多智能体”方向。尽管其应用场景是金融科技，但其研究本质是Agentic AI方法论的创新，而非单纯的应用。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#11",
        "title": "MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning for Text-to-SQL",
        "link": "/arxiv/2510.25510",
        "arxiv_id": "2510.25510",
        "authors": "Zekun Xu, Siyu Xia, Chuhuai Yue, Jiajun Chai, Mingxue Tian, Xiaohan Wang, Wei Lin, Haoxuan Li, Guojun Yin",
        "summary": "As large language models (LLMs) are increasingly used in Text-to-SQL tasks, Reinforcement Learning (RL) has become a common method for improving performance. Existing methods primarily rely on static execution feedback, which restricts real-time error correction. However, integrating multi-turn tool invocation along with dynamic feedback could significantly improve adaptability and robustness, ultimately enhancing model performance. To address these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated Reasoning reinforcement learning framework for Text-to-SQL. Our approach introduces an execution-aware multi-turn reasoning paradigm that seamlessly incorporates database execution feedback at each reasoning step, enabling context-sensitive query generation and progressive refinement throughout the reasoning process. The framework extends the GRPO algorithm to accommodate complex multi-turn interaction scenarios. Considering the training instability characteristics of MTIR and the potential for significant Deviation of model distribution from the initial model, we enhance the GRPO algorithm by adding a trajectory filtering mechanism and removing KL loss constraints. Experimental results demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\% accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev, significantly outperforming existing approaches.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-10-30T11:00:05.499656",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进一个具有自我演化能力的LLM智能体。 1.  **核心判断 (第一步):** 论文的核心是提出一个名为 **MTIR-SQL** 的**新框架**，而不是简单地将现有技术应用于Text-to-SQL领域。该框架的本质是一个**多轮、工具集成、具备动态反馈和自我修正能力的智能体系统**。它通过引入“执行感知的多轮推理范式”，让智能体在每一步都能利用工具（数据库执行）的反馈来调整和优化下一步的行动。这完全符合“构建、改进或演化LLM智能体”的核心目标，因此应**保留**。它不属于“非演化型应用”，因为其核心创新点在于智能体的工作机制本身，而非应用结果。 2.  **正面指标 (第二步):** 论文命中了多个核心关注点： *   **智能体能力:** 明确提到了 `Tool Use / Tool Augmentation` (工具集成)、`Self-Correction` / `Self-Refine` (渐进式完善、实时错误修正) 和 `Reasoning` (多轮推理范式)。其工作流程（生成查询 -> 执行获取反馈 -> 修正查询）与 `ReAct` 范式高度一致。 *   **演化机制:** 论文的“多轮推理”和“渐进式完善”机制，本质上是一种**自我演化**的形式。智能体通过与环境的交互（数据库执行反馈）来迭代改进自身的行为（SQL查询），这符合“通过环境反馈进行自我完善和迭代”的定义。 3.  **排除标准 (第三步):** 论文的主要贡献是提升智能体的性能和鲁棒性，不涉及安全、对齐、可解释性或多模态等排除领域。 4.  **特殊和模糊情况 (第四步):** *   **推理/规划:** 这篇论文是关于智能体如何进行规划和多步推理的典型案例。它不是在改进LLM的基础数学或逻辑能力，而是在构建一个**Agentic框架**来指导LLM在复杂任务中进行多步决策和修正。这完全符合“保留”的条件。 *   **自我演化的应用:** 尽管论文的应用领域是Text-to-SQL，但其核心贡献是提出了一种新的“自我演化/自我修正”机制。根据您的规则，这种情况下应该**保留**。 **总结:** 论文的核心贡献是MTIR-SQL框架，它通过引入多轮工具调用和动态反馈机制，显著增强了LLM智能体的自我修正和迭代优化能力。这直接对应了您研究目标中的“单智能体”和“自我演化”两个方向，因此是一篇高度相关的前沿论文。"
    },
    {
        "index": "#18",
        "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of Industrial Event Log Data",
        "link": "/arxiv/2510.25223",
        "arxiv_id": "2510.25223",
        "authors": "Kun ouyang, Haoyu Wang, Dong Fang",
        "summary": "Event log data, recording fine-grained user actions and system events, represent one of the most valuable assets for modern digital services. However, the complexity and heterogeneity of industrial event logs--characterized by large scale, high dimensionality, diverse data types, and intricate temporal or relational structures--make feature engineering extremely challenging. Existing automatic feature engineering approaches, such as AutoML or genetic methods, often suffer from limited explainability, rigid predefined operations, and poor adaptability to complicated heterogeneous data. In this paper, we propose FELA (Feature Engineering LLM Agents), a multi-agent evolutionary system that autonomously extracts meaningful and high-performing features from complex industrial event log data. FELA integrates the reasoning and coding capabilities of large language models (LLMs) with an insight-guided self-evolution paradigm. Specifically, FELA employs specialized agents--Idea Agents, Code Agents, and Critic Agents--to collaboratively generate, validate, and implement novel feature ideas. An Evaluation Agent summarizes feedback and updates a hierarchical knowledge base and dual-memory system to enable continual improvement. Moreover, FELA introduces an agentic evolution algorithm, combining reinforcement learning and genetic algorithm principles to balance exploration and exploitation across the idea space. Extensive experiments on real industrial datasets demonstrate that FELA can generate explainable, domain-relevant features that significantly improve model performance while reducing manual effort. Our results highlight the potential of LLM-based multi-agent systems as a general framework for automated, interpretable, and adaptive feature engineering in complex real-world environments.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-10-30T11:00:05.506719",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM或智能体作为工具应用于特征工程领域。其核心贡献是提出了一种名为FELA的**新颖方法论和框架**——一个“多智能体演化系统”。论文详细描述了这个系统的架构、工作原理和演化算法，这完全符合您“构建、改进或演化LLM智能体”的核心目标。它不是在解决一个特征工程问题，而是在**发明一种解决此类问题的智能体范式**。 2.  **第二步：正面指标** - 论文摘要中包含了大量您关注的核心关键词和概念，表明其与您的研究方向高度相关： - **核心范式**: `Multi-Agent Evolutionary System`, `LLM-based multi-agent systems` - **多智能体**: 明确提出了 `specialized agents` (Idea, Code, Critic, Evaluation Agents) 之间的 `collaboration`。 - **自我演化**: 提出了 `insight-guided self-evolution paradigm` 和 `agentic evolution algorithm`，目标是 `continual improvement`。 - **智能体能力**: 提到了 `reasoning` 能力，以及通过 `dual-memory system` 实现的 `Memory` 机制。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性（虽然提到了可解释性，但这是其方法带来的结果，而非研究核心）或多模态技术。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - 这篇论文是“自我演化的应用”这一特殊情况的完美范例。虽然它被应用在“工业事件日志数据”这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**（`agentic evolution algorithm`）和一个新的多智能体协作框架。根据您的规则，这种情况下应该保留。论文作者自己也强调，他们的工作是提出了一个“通用框架”，这进一步证明了其贡献超越了单一应用领域。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个由多个专业化LLM智能体组成的、具备自我演化能力的系统。它直接命中了您研究焦点的“多智能体”和“自我演化”两个核心方向，并提出了一种新颖的“智能体演化算法”。因此，这篇论文是您课题下的高质量前沿研究，必须保留。"
    }
]