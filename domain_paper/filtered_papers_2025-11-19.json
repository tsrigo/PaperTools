[
    {
        "index": "#4",
        "title": "NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework",
        "link": "/arxiv/2511.15408",
        "arxiv_id": "2511.15408",
        "authors": "Shanlin Zhou, Xinpeng Wang, Jianxun Lian, Zhenghao Liu, Laks V. S. Lakshmanan, Xiaoyuan Yi, Yongtao Hao",
        "summary": "Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval, Multiagent Systems, Neural and Evolutionary Computing",
        "date": "2025-11-19",
        "category": "cs.MA",
        "crawl_time": "2025-11-20T11:00:04.056627",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非简单地将LLM应用于起名这一特定领域，而是提出了一个名为 **NAMeGEn 的新颖多智能体优化框架**。摘要明确指出这是一个“novel multi-agent optimization framework”，其核心是方法论和框架的创新，而非应用本身。该框架通过“iteratively alternates between objective extraction, name generation, and evaluation”的循环机制来工作，这直接命中了您研究范围中的“多智能体”和“自我演化”方向。 2.  **第二步：正面指标 (高度匹配)** - **核心范式**: 论文明确包含 `Multi-Agent Systems (MAS)` 和 `Agent-based` 框架。 - **智能体能力**: 框架的“目标提取、生成、评估”循环体现了 `Planning` 和 `Self-Correction`/`Self-Reflection` 的能力。评估环节的反馈用于指导下一轮生成，这是一种自我修正机制。 - **演化机制**: “iteratively alternates”（迭代交替）是典型的 `Iterative Improvement`（迭代改进）机制，属于“自我演化”的范畴。它不是一次性生成，而是通过多轮循环优化结果。 3.  **第三步：排除标准 (未触发)** 论文虽然提到了“提供有意义的解释”，但其目的是为了“增强用户的审美感知”，属于应用层面的功能，而非研究模型本身的 `Interpretability` (可解释性) 或 `Explainability (XAI)`。论文也未涉及安全、对齐或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况 (关键判断点)** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美范例。虽然它的应用场景是“中文起名”（一个特定领域），但其**核心贡献是提出了一种新的“自我演化”机制**——即那个多智能体迭代优化框架。根据您的规则，这种情况应该被保留。这篇论文的价值在于其框架的通用性和新颖性，起名只是验证其有效性的一个具体任务。 **总结**: 该论文的本质是提出了一种新的多智能体协作与自我演化的框架（NAMeGEn），用以解决多目标优化问题。它完全符合您对“构建、改进或演化LLM智能体”的核心目标，特别是在“多智能体”和“自我演化”两个方向上做出了明确的方法论贡献。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#30",
        "title": "From Solving to Verifying: A Unified Objective for Robust Reasoning in LLMs",
        "link": "/arxiv/2511.15137",
        "arxiv_id": "2511.15137",
        "authors": "Xiaoxuan Wang, Bo Liu, Song Jiang, Jingzhou Liu, Jingyuan Qi, Xia Chen, Baosheng He",
        "summary": "The reasoning capabilities of large language models (LLMs) have been significantly improved through reinforcement learning (RL). Nevertheless, LLMs still struggle to consistently verify their own reasoning traces. This raises the research question of how to enhance the self-verification ability of LLMs and whether such an ability can further improve reasoning performance. In this work, we propose GRPO-Verif, an algorithm that jointly optimizes solution generation and self-verification within a unified loss function, with an adjustable hyperparameter controlling the weight of the verification signal. Experimental results demonstrate that our method enhances self-verification capability while maintaining comparable performance in reasoning.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-19",
        "category": "cs.LG",
        "crawl_time": "2025-11-20T11:00:04.770077",
        "filter_reason": "这篇论文符合我的研究范围，核心判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了一种名为 `GRPO-Verif` 的新算法。该算法的本质并非简单地将LLM应用于某个领域，而是通过一个统一的损失函数，**联合优化LLM的“解决方案生成”和“自我验证”能力**。这里的“自我验证”是关键，它直接对应了LLM智能体核心能力中的**自我反思**和**自我纠正**。这属于对LLM智能体基础能力的构建和改进，而非简单的应用或基础推理能力提升。 2.  **第二步：正面指标** - 论文的核心贡献与多个正面指标高度相关： - **智能体能力**: 论文明确聚焦于 `Self-Verification`（自我验证），这是 `Self-Correction`（自我纠正）和 `Self-Reflection`（自我反思）的直接前提和核心组成部分。这些能力是构建高级LLM智能体的基石。 - **演化机制**: 虽然不是跨代际的演化，但通过联合优化来“增强”自身能力，体现了 `Self-Improvement`（自我完善）的思想。 3.  **第三步：排除标准** - 论文的研究目标是“Robust Reasoning”（鲁棒推理），主要贡献是方法论层面的算法创新，**不涉及** `Safety`（安全）、`Alignment`（对齐）、`Interpretability`（可解释性）等排除领域。 - 论文是纯文本推理，**不涉及** `Vision`（视觉）等多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这是最关键的判断点。论文虽然研究“推理”，但它并非简单地提出一个新的CoT变体来提升LLM在数学或逻辑任务上的准确率。它的核心是**构建一个包含“验证”环节的推理框架**。这种让模型生成方案后，再由自身进行验证和评估的闭环过程，是典型的Agentic行为模式，与ReAct（Reason+Act）范式在思想上是一致的，即构建一个更复杂的、包含多个步骤和内部反馈的推理流程。因此，它属于“关于智能体如何进行规划或在复杂任务中进行多步推理”的范畴，应予以保留。 **总结**: 该论文的核心贡献在于提出了一种增强LLM**自我验证**能力的新算法。自我验证是智能体实现**自我反思**和**自我纠正**的关键环节，属于构建和改进LLM智能体的核心方法论。它并非简单的应用或基础模型能力提升，而是对智能体内部工作机制的优化，完全符合我关于“LLM智能体及其演化”的研究目标，特别是“单智能体”和“自我演化”方向。因此，应保留此论文。"
    },
    {
        "index": "#48",
        "title": "Empowering Multi-Turn Tool-Integrated Reasoning with Group Turn Policy Optimization",
        "link": "/arxiv/2511.14846",
        "arxiv_id": "2511.14846",
        "authors": "Yifeng Ding, Hung Le, Songyang Han, Kangrui Ruan, Zhenghui Jin, Varun Kumar, Zijian Wang, Anoop Deoras",
        "summary": "Training Large Language Models (LLMs) for multi-turn Tool-Integrated Reasoning (TIR) - where models iteratively reason, generate code, and verify through execution - remains challenging for existing reinforcement learning (RL) approaches. Current RL methods, exemplified by Group Relative Policy Optimization (GRPO), suffer from coarse-grained, trajectory-level rewards that provide insufficient learning signals for complex multi-turn interactions, leading to training stagnation. To address this issue, we propose Group Turn Policy Optimization (GTPO), a novel RL algorithm specifically designed for training LLMs on multi-turn TIR tasks. GTPO introduces three key innovations: (1) turn-level reward assignment that provides fine-grained feedback for individual turns, (2) return-based advantage estimation where normalized discounted returns are calculated as advantages, and (3) self-supervised reward shaping that exploits self-supervision signals from generated code to densify sparse binary outcome-based rewards. Our comprehensive evaluation demonstrates that GTPO outperforms GRPO by 3.0% on average across diverse reasoning benchmarks, establishing its effectiveness for advancing complex mathematical reasoning in the real world.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-11-18",
        "category": "cs.LG",
        "crawl_time": "2025-11-20T11:00:04.788606",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **核心判断依据:** 1.  **核心贡献完全匹配 (第一步):** 论文的核心贡献是提出了一种名为GTPO（Group Turn Policy Optimization）的新型强化学习算法，专门用于训练和改进LLM在多轮、工具集成推理任务中的表现。这完全符合筛选标准第一步中的“保留”条件：论文的本质是关于“构建、改进或演化LLM智能体”的方法论。它并非将现有智能体作为工具应用到特定领域，而是直接改进智能体本身的核心能力。 2.  **精准命中研究焦点 (第二步):** 论文的研究焦点精准地命中了您关注的“单智能体”方向，特别是其中的“工具使用”和“规划/推理”子方向。摘要中描述的“iteratively reason, generate code, and verify through execution”（迭代推理、生成代码、通过执行验证）正是典型的智能体循环，与ReAct等范式高度相关。论文提出的“turn-level reward assignment”等创新，都是为了优化这个智能体循环的学习过程。 3.  **不触及排除标准 (第三步):** 论文的研究内容是提升智能体的任务执行能力，不涉及安全、对齐、可解释性或多模态等排除标准中的主题。 4.  **符合特殊情况处理规则 (第四步):** 根据第四步的特殊规则，这篇论文是关于“智能体如何进行规划或在复杂任务中进行多步推理”的典型范例，因此应该保留。它不是单纯提升LLM的基础数学能力，而是训练LLM掌握一种更高级的、与工具交互的推理框架。论文提出的GTPO算法，正是为了解决现有方法在训练这种复杂智能体行为时的不足，属于对智能体框架本身的改进。 **总结:** 该论文通过提出一种新的训练算法来增强LLM智能体的工具使用和复杂推理能力，其核心贡献在于“改进LLM智能体”，与您的研究目标“构建、改进或演化LLM智能体”高度契合。因此，这是一篇非常相关且应被筛选出来的前沿论文。"
    },
    {
        "index": "#44",
        "title": "It's LIT! Reliability-Optimized LLMs with Inspectable Tools",
        "link": "/arxiv/2511.14903",
        "arxiv_id": "2511.14903",
        "authors": "Ruixin Zhang, Jon Donnelly, Zhicheng Guo, Ghazal Khalighinejad, Haiyang Huang, Alina Jade Barnett, Cynthia Rudin",
        "summary": "Large language models (LLMs) have exhibited remarkable capabilities across various domains. The ability to call external tools further expands their capability to handle real-world tasks. However, LLMs often follow an opaque reasoning process, which limits their usefulness in high-stakes domains where solutions need to be trustworthy to end users. LLMs can choose solutions that are unreliable and difficult to troubleshoot, even if better options are available. We address this issue by forcing LLMs to use external -- more reliable -- tools to solve problems when possible. We present a framework built on the tool-calling capabilities of existing LLMs to enable them to select the most reliable and easy-to-troubleshoot solution path, which may involve multiple sequential tool calls. We refer to this framework as LIT (LLMs with Inspectable Tools). In order to support LIT, we introduce a new and challenging benchmark dataset of 1,300 questions and a customizable set of reliability cost functions associated with a collection of specialized tools. These cost functions summarize how reliable each tool is and how easy it is to troubleshoot. For instance, a calculator is reliable across domains, whereas a linear prediction model is not reliable if there is distribution shift, but it is easy to troubleshoot. A tool that constructs a random forest is neither reliable nor easy to troubleshoot. These tools interact with the Harvard USPTO Patent Dataset and a new dataset of NeurIPS 2023 papers to solve mathematical, coding, and modeling problems of varying difficulty levels. We demonstrate that LLMs can achieve more reliable and informed problem-solving while maintaining task performance using our framework.",
        "subjects": "Machine Learning, Software Engineering",
        "date": "2025-11-18",
        "category": "cs.LG",
        "crawl_time": "2025-11-20T11:00:04.781686",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM作为工具应用到一个新领域，而是提出了一个名为LIT的新**框架**。这个框架的核心贡献在于**改进LLM智能体的行为方式**，具体来说是优化其工具使用策略。它不是简单地让LLM使用工具，而是教它如何根据“可靠性”和“可检查性”来**规划和选择**最优的工具调用序列。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **智能体能力**: `Tool Use / Tool Augmentation` 是论文的绝对核心。`Planning` 体现在智能体需要“选择最可靠的解决方案路径，这可能涉及多个顺序的工具调用”，这是一个典型的多步规划过程。 - **核心范式**: 论文的研究对象是 `LLM-based Agents`，并提出了一个改进其能力的框架。 3.  **第三步：排除标准** - **安全与对齐**: 论文虽然提到了“可靠性”和“可检查性”，但其目的并非研究AI安全、对齐或可解释性理论本身。相反，它将这些概念作为**优化目标**（通过“可靠性成本函数”），来构建一个更高效的智能体框架。论文的焦点是**如何构建**，而不是**如何分析或保证安全**。因此，它不属于被排除的类别。 - **多模态与视觉**: 论文未涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”的条件。它不是在提升LLM底层的数学或逻辑推理能力，而是在构建一个**Agentic框架**，让智能体在解决复杂问题时能进行更好的规划和工具选择。这与ReAct等范式在精神上是相通的，都是关于智能体的行为框架。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种新的方法论（LIT框架），用于**改进LLM智能体的工具使用和规划能力**。它直接对准了研究课题中的“单智能体”方向，特别是工具使用和规划这两个子方向。尽管它触及了可靠性和可解释性，但这些是作为构建更好智能体的手段，而非研究本身。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#49",
        "title": "Dynamic Nested Hierarchies: Pioneering Self-Evolution in Machine Learning Architectures for Lifelong Intelligence",
        "link": "/arxiv/2511.14823",
        "arxiv_id": "2511.14823",
        "authors": "Akbar Anbar Jafari, Cagri Ozcinar, Gholamreza Anbarjafari",
        "summary": "Contemporary machine learning models, including large language models, exhibit remarkable capabilities in static tasks yet falter in non-stationary environments due to rigid architectures that hinder continual adaptation and lifelong learning. Building upon the nested learning paradigm, which decomposes models into multi-level optimization problems with fixed update frequencies, this work proposes dynamic nested hierarchies as the next evolutionary step in advancing artificial intelligence and machine learning. Dynamic nested hierarchies empower models to autonomously adjust the number of optimization levels, their nesting structures, and update frequencies during training or inference, inspired by neuroplasticity to enable self-evolution without predefined constraints. This innovation addresses the anterograde amnesia in existing models, facilitating true lifelong learning by dynamically compressing context flows and adapting to distribution shifts. Through rigorous mathematical formulations, theoretical proofs of convergence, expressivity bounds, and sublinear regret in varying regimes, alongside empirical demonstrations of superior performance in language modeling, continual learning, and long-context reasoning, dynamic nested hierarchies establish a foundational advancement toward adaptive, general-purpose intelligence.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-11-18",
        "category": "cs.LG",
        "crawl_time": "2025-11-20T11:00:04.789039",
        "filter_reason": "这篇论文符合研究范围，应被保留。 **判断过程和核心依据如下：** 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一种全新的机器学习架构范式——“动态嵌套层次结构”。其核心贡献并非将现有模型应用于某个领域，而是构建了一种能够**自主调整自身结构**（优化层次、嵌套方式、更新频率）的机制。这种机制旨在实现模型的“自我演化”和“终身学习”，这完全符合筛选标准中关于“自我演化”方法论或新框架的定义。它不是非演化型应用，也不是基础设施研究。 2.  **第二步：正面指标** - 论文摘要中明确包含了多个核心关注点的关键词和概念： - **核心范式**: `Self-Evolution`（自我演化）被直接提出，并作为论文的核心创新点。 - **演化机制**: `Self-Improvement`（自我完善）、`Iterative Improvement`（迭代改进）的概念通过“autonomously adjust”（自主调整）和“lifelong learning”（终身学习）得到了充分体现。论文旨在让模型通过适应环境反馈（分布偏移）来迭代自身，这正是自我演化的核心。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐（Safety, Alignment）、可解释性（Interpretability）或多模态（Vision, MLLMs）等排除领域。其焦点是模型架构的动态适应能力，与这些排除标准无关。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是判断此论文的关键。虽然论文的实证部分是在“语言建模、持续学习和长上下文推理”等任务上进行的，但根据筛选规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 这篇论文的核心正是提出“动态嵌套层次结构”这一**新的自我演化机制**。因此，尽管它看起来更像一篇基础架构论文，但其贡献直接赋能了智能体的自我演化能力，属于研究范围内的“例外保留”情况。 **最终决策：** 综合以上分析，这篇论文的核心贡献是提出了一种实现模型“自我演化”的基础性架构方法。它直接命中了研究课题的第三个核心方向“自我演化”。虽然论文没有直接使用“智能体”一词，但其提出的“终身智能”和“自主适应”能力是构建高级LLM智能体的基石。一个能够自我演化、终身学习的模型，是迈向真正智能体的关键一步。因此，这篇论文不仅符合，而且是高度相关的前沿研究，应被保留。"
    },
    {
        "index": "#75",
        "title": "Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs",
        "link": "/arxiv/2511.15163",
        "arxiv_id": "2511.15163",
        "authors": "Yang Wu, Rujing Yao, Tong Zhang, Yufei Shi, Zhuoren Jiang, Zhushan Li, Xiaozhong Liu",
        "summary": "Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.",
        "subjects": "Computation and Language, Artificial Intelligence, Human-Computer Interaction, Machine Learning",
        "date": "2025-11-19",
        "category": "cs.LG",
        "crawl_time": "2025-11-20T11:00:04.810874",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于数学领域，而是提出了一个名为TASA的**新框架**。该框架的核心贡献在于构建了一个具有特定能力的LLM智能体，具体来说，是一个能够模拟学生状态（人设）、记录交互历史（记忆）并动态追踪其知识遗忘与掌握情况的智能体。这完全符合“构建、改进LLM智能体”的核心目标，而非“非演化型应用”。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **Agentic AI / LLM-based Agents**: 论文明确提出了一个“student-aware tutoring framework”，这是一个典型的LLM智能体。 - **Memory**: 论文的核心机制之一是“event memory recording prior learning interactions”，直接命中了“记忆”这一关键能力。 - **Self-Evolving**: 论文通过“incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state”。这描述了智能体根据环境反馈（学生的表现）来更新其内部状态（对学生模型的认知），这是一种通过经验进行自我完善和迭代的机制，符合“自我演化”的定义。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态技术。它的焦点是智能体的内部机制和交互范式，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美例证。虽然它被应用在“数学辅导”这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**——即结合遗忘曲线和知识追踪来动态更新智能体对环境的理解（学生模型）。根据筛选规则，这种情况应该被保留。 - **推理/规划**: 论文中的智能体会根据其内部状态生成“难度校准的问题和解释”，这是一种基于内部模型进行规划和行动的Agentic行为，而非单纯提升LLM的基础数学推理能力。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个具备记忆和动态演化能力的LLM智能体框架（TASA）。它直接命中了研究课题中的“单智能体”和“自我演化”两个核心方向。尽管其应用场景是数学教育，但其方法论和框架本身具有普适性，完全符合“LLM智能体及其演化”的研究范围。因此，最终判断为 **True**。"
    },
    {
        "index": "#84",
        "title": "Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs for Enhanced Genomic Question Answering",
        "link": "/arxiv/2511.15061",
        "arxiv_id": "2511.15061",
        "authors": "Haodong Chen, Guido Zuccon, Teerapong Leelanupab",
        "summary": "Genomic question answering often requires complex reasoning and integration across diverse biomedical sources. GeneGPT addressed this challenge by combining domain-specific APIs with OpenAI's code-davinci-002 large language model to enable natural language interaction with genomic databases. However, its reliance on a proprietary model limits scalability, increases operational costs, and raises concerns about data privacy and generalization. In this work, we revisit and reproduce GeneGPT in a pilot study using open source models, including Llama 3.1, Qwen2.5, and Qwen2.5 Coder, within a monolithic architecture; this allows us to identify the limitations of this approach. Building on this foundation, we then develop OpenBioLLM, a modular multi-agent framework that extends GeneGPT by introducing agent specialization for tool routing, query generation, and response validation. This enables coordinated reasoning and role-based task execution. OpenBioLLM matches or outperforms GeneGPT on over 90% of the benchmark tasks, achieving average scores of 0.849 on Gene-Turing and 0.830 on GeneHop, while using smaller open-source models without additional fine-tuning or tool-specific pretraining. OpenBioLLM's modular multi-agent design reduces latency by 40-50% across benchmark tasks, significantly improving efficiency without compromising model capability. The results of our comprehensive evaluation highlight the potential of open-source multi-agent systems for genomic question answering. Code and resources are available at https://github.com/ielab/OpenBioLLM.",
        "subjects": "Artificial Intelligence, Information Retrieval, Machine Learning",
        "date": "2025-11-19",
        "category": "cs.LG",
        "crawl_time": "2025-11-20T11:00:04.820239",
        "filter_reason": "这篇论文完全符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM智能体作为工具应用到基因组学领域，而是**提出了一种新的多智能体架构**。其核心贡献是构建和改进LLM智能体系统，具体来说，是从一个单体架构演进到一个模块化的多智能体框架。这直接命中了你“构建、改进或演化LLM智能体”的核心目标。它不是一篇“非演化型应用”论文，因为其创新点在于智能体的组织形式和协作机制，而非应用本身。 2.  **第二步：正面指标** - 论文包含了大量你的核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心，标题和摘要中反复强调。 - **多智能体**: 论文明确提到了 `agent specialization` (智能体专业化)、`coordinated reasoning` (协调推理) 和 `role-based task execution` (基于角色的任务执行)，这些都是多智能体协作和通信的关键体现。 - **智能体能力**: `Tool Use / Tool Augmentation` 是其架构的一部分，通过专门的智能体进行 `tool routing` (工具路由)。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或幻觉，因此不触发安全与对齐的排除标准。 - 论文不涉及视觉或多模态内容，因此不触发多模态的排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的 `coordinated reasoning` 和 `query generation` 属于智能体在复杂任务中的多步推理和规划过程，符合保留条件。 - **自我演化的应用**: 虽然这篇论文不直接关于“自我演化”，但它触及了“演化”的另一个层面——**架构的演化**。论文通过对比“单体架构”和“多智能体架构”，展示了智能体系统设计思想的演进和优化。更重要的是，它完美地诠释了“核心贡献是提出新框架，即使应用在特定领域也应保留”的原则。基因组学问答是验证其多智能体架构有效性的实验场，而非研究的终点。 **核心依据总结**: 该论文的核心贡献是**OpenBioLLM，一个新颖的模块化多智能体框架**。它通过引入智能体专业化、协调推理和基于角色的任务执行，改进了现有的单智能体工具使用范式。这完全符合你研究课题中的“多智能体”方向，特别是关于智能体协作、通信和系统架构的子方向。尽管论文的应用领域是基因组学，但其研究焦点和核心创新在于Agentic AI的架构设计本身，因此是一篇高度相关的前沿论文。"
    },
    {
        "index": "#1",
        "title": "What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity",
        "link": "/arxiv/2511.15593",
        "arxiv_id": "2511.15593",
        "authors": "Alexis Audran-Reiss, Jordi Armengol Estapé, Karen Hambardzumyan, Amar Budhiraja, Martin Josifoski, Edan Toledo, Rishi Hazra, Despoina Magka, Michael Shvartsman, Parth Pathak, Justine T Kao, Lucia Cipolina-Kun, Bhavul Gauri, Jean-Christophe Gagnon-Audet, Emanuel Tewolde, Jenny Zhang, Taco Cohen, Yossi Adi, Tatiana Shavrina, Yoram Bachrach",
        "summary": "AI research agents offer the promise to accelerate scientific progress by automating the design, implementation, and training of machine learning models. However, the field is still in its infancy, and the key factors driving the success or failure of agent trajectories are not fully understood. We examine the role that ideation diversity plays in agent performance. First, we analyse agent trajectories on MLE-bench, a well-known benchmark to evaluate AI research agents, across different models and agent scaffolds. Our analysis reveals that different models and agent scaffolds yield varying degrees of ideation diversity, and that higher-performing agents tend to have increased ideation diversity. Further, we run a controlled experiment where we modify the degree of ideation diversity, demonstrating that higher ideation diversity results in stronger performance. Finally, we strengthen our results by examining additional evaluation metrics beyond the standard medal-based scoring of MLE-bench, showing that our findings still hold across other agent performance metrics.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.894906",
        "filter_reason": "这篇论文完全符合你的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为一个工具去解决某个外部领域（如生物、金融）的问题，而是**直接研究AI研究智能体本身**。其核心贡献在于识别并验证了一个关键因素——“ideation diversity”（构思多样性），这个因素决定了AI智能体的性能好坏。这属于对LLM智能体进行“改进”和“理解”的范畴，完全符合你“构建、改进或演化LLM智能体”的核心目标。它不是简单的应用，而是对智能体内在机制的深入探究。 2.  **第二步：正面指标** - 论文高度匹配你的核心关注点。 - **核心范式**: 论文明确研究 `AI research agents`，属于 `Agentic AI` 和 `LLM-based Agents` 的核心范畴。 - **智能体能力**: 论文研究的“agent trajectories”（智能体轨迹）和“design, implementation, and training”（设计、实现、训练）过程，直接涉及智能体的 `Planning`（规划）和 `Tool Use`（工具使用，如编写和运行代码）。更重要的是，“ideation diversity”是智能体在复杂任务中进行有效探索和 `Self-Reflection`（自我反思）的关键，它决定了智能体能否跳出局部最优，找到更好的解决方案。 - **演化机制**: 论文通过控制实验验证了提高“ideation diversity”可以带来更强的性能，这本质上是在探索一种让智能体 `Iterative Improvement`（迭代改进）的机制，与“自我演化”的精神高度契合。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐、可解释性或多模态。它的焦点是智能体的性能和内在机制，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它研究的不是LLM本身的基础推理能力，而是**智能体在执行复杂任务（如机器学习研究）时的规划和探索策略**。它通过分析“agent trajectories”来理解智能体的行为，这完全属于Agentic框架下的推理研究。 - **自我演化的应用**: 虽然论文的应用场景是“AI research”，但这不是一个外部领域，而是智能体技术本身的前沿。其核心贡献——提出并验证“ideation diversity”这一改进机制——具有普适性，可以应用于其他需要复杂规划和创造的智能体。因此，它符合“保留”的例外情况。 **最终决策**: 这篇论文的核心贡献是**提出并验证了一个能够显著提升LLM智能体性能的关键原则**。它没有发明一个新的智能体架构，但它为我们如何**改进和优化现有智能体**提供了深刻的见解和实证依据。这项工作直接服务于“构建更好的智能体”这一终极目标，属于对智能体基础能力的深入探索，因此与你的研究课题“LLM智能体及其演化”高度相关。"
    },
    {
        "index": "#4",
        "title": "IPR-1: Interactive Physical Reasoner",
        "link": "/arxiv/2511.15407",
        "arxiv_id": "2511.15407",
        "authors": "Mingyu Zhang, Lifeng Zhuo, Tianxi Tan, Guocan Xie, Xian Nie, Yan Li, Renjie Zhao, Zizhu He, Ziyu Wang, Jiting Cai, Yong-Lu Li",
        "summary": "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.895849",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的三个研究方向均有紧密关联，尤其是“自我演化”和“单智能体”。 1.  **核心判断 (第一步):** *   **保留:** 论文的核心贡献是构建了一个名为IPR（Interactive Physical Reasoner）的新型LLM智能体框架。这直接命中了您筛选标准的第一步：核心贡献在于构建和改进LLM智能体。它不是将现有智能体作为工具去解决一个领域问题，而是提出了一种新的智能体架构和方法论。 2.  **与研究焦点的匹配度分析:** *   **单智能体:** 该智能体具备在复杂交互环境中进行规划和多步推理的能力（通过world-model rollouts实现前瞻），属于“单智能体”的研究范畴。它解决了现有VLM/VLA智能体在交互式环境中缺乏前瞻性的问题。 *   **自我演化:** 这是最关键的匹配点。论文明确强调了智能体的“自我演化”特性。摘要中提到智能体能够“keep improving with more experience”，并且实验证明“performance improves with more training games and interaction steps”。这表明IPR是一个通过经验和环境反馈进行自我完善和迭代的智能体，完全符合您“自我演化”的研究焦点。其核心机制——使用世界模型推演来评分和强化VLM策略——本身就是一种自我改进的框架。 *   **多智能体:** 虽然论文不涉及多智能体，但这不影响其符合您的研究范围，因为您的研究范围包含了三个方向，满足其一即可。 3.  **正面与排除指标分析:** *   **正面指标 (第二步):** 论文包含了大量正面指标，如`Agentic AI`、`Self-Evolving`、`Planning`、`Self-Improvement`、`Iterative Improvement`。 *   **排除标准 (第三步):** *   **安全与对齐:** 论文不涉及安全、对齐等问题。 *   **多模态与视觉:** 虽然论文使用了VLM（视觉语言模型），但这并非研究的核心。根据您的筛选标准，视觉能力在这里是作为智能体感知环境的工具，而论文的核心创新点在于结合世界模型和VLM策略，以实现物理推理能力的持续提升，而非视觉模型本身。因此，这不构成排除的理由。 4.  **特殊与模糊情况处理 (第四步):** *   **推理/规划:** 论文是关于智能体如何在交互式环境中进行规划和推理，符合保留条件。 *   **自我演化的应用:** 这篇论文本身就是提出一种新的“自我演化”机制，因此完全符合保留的例外情况。 **结论:** 该论文提出了一种新的智能体框架，并重点研究了其通过交互进行自我演化的能力，与您的研究目标高度契合。其核心贡献在于构建和演化LLM智能体，而非简单的应用或基础模型改进，因此应被保留。"
    },
    {
        "index": "#9",
        "title": "SOLID: a Framework of Synergizing Optimization and LLMs for Intelligent Decision-Making",
        "link": "/arxiv/2511.15202",
        "arxiv_id": "2511.15202",
        "authors": "Yinsheng Wang, Tario G You, Léonard Boussioux, Shan Liu",
        "summary": "This paper introduces SOLID (Synergizing Optimization and Large Language Models for Intelligent Decision-Making), a novel framework that integrates mathematical optimization with the contextual capabilities of large language models (LLMs). SOLID facilitates iterative collaboration between optimization and LLMs agents through dual prices and deviation penalties. This interaction improves the quality of the decisions while maintaining modularity and data privacy. The framework retains theoretical convergence guarantees under convexity assumptions, providing insight into the design of LLMs prompt. To evaluate SOLID, we applied it to a stock portfolio investment case with historical prices and financial news as inputs. Empirical results demonstrate convergence under various scenarios and indicate improved annualized returns compared to a baseline optimizer-only method, validating the synergy of the two agents. SOLID offers a promising framework for advancing automated and intelligent decision-making across diverse domains.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.897241",
        "filter_reason": "这篇论文符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为SOLID的**新框架**。这个框架的本质不是简单地将LLM应用于金融领域，而是设计了一种让**LLM智能体**与**数学优化智能体**进行**迭代协作**的机制。这完全符合“构建、改进LLM智能体”和“多智能体系统”的定义。虽然论文在股票投资案例中进行了验证，但其核心是方法论层面的创新，而非特定领域的应用。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了多个核心关注点： *   **核心范式**: 明确提到了“LLMs agents”和“collaboration”，直接命中`LLM-based Agents`和`Multi-Agent Systems (MAS)`。 *   **多智能体**: “iterative collaboration between optimization and LLMs agents” 这句话清晰地描述了智能体间的协作模式，符合`Collaboration`和`Communication`的子方向。 *   **智能体能力**: 整个框架旨在实现“Intelligent Decision-Making”，这涉及到智能体在复杂任务中的规划和推理过程，与`Planning`能力相关。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于智能体协作框架的设计和性能提升，没有涉及安全、对齐、可解释性或视觉等多模态内容。因此，它没有触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留条件** 论文提出的协作机制（通过dual prices和deviation penalties）是一种结构化的智能体交互和决策过程，可以被视为一种高级的**规划和推理**框架。它不是在提升LLM本身的基础推理能力，而是在构建一个让智能体（LLM和优化器）协同完成复杂决策任务的系统，这符合“保留”关于智能体规划/推理论文的规则。 **最终决策**: 该论文的核心贡献在于构建了一个新颖的多智能体协作框架（SOLID），定义了LLM智能体与优化智能体之间的交互协议。这直接对齐了你研究课题中的“多智能体”方向，特别是“智能体间的协作”子方向。尽管它以金融领域为例，但其本质是方法论创新，而非单纯的应用。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#3",
        "title": "Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining",
        "link": "/arxiv/2511.15456",
        "arxiv_id": "2511.15456",
        "authors": "Qian'ang Mao, Yuxuan Zhang, Jiaman Chen, Wenjun Zhou, Jiaqi Yan",
        "summary": "As Decentralized Finance (DeFi) develops, understanding user intent behind DeFi transactions is crucial yet challenging due to complex smart contract interactions, multifaceted on-/off-chain factors, and opaque hex logs. Existing methods lack deep semantic insight. To address this, we propose the Transaction Intent Mining (TIM) framework. TIM leverages a DeFi intent taxonomy built on grounded theory and a multi-agent Large Language Model (LLM) system to robustly infer user intents. A Meta-Level Planner dynamically coordinates domain experts to decompose multiple perspective-specific intent analyses into solvable subtasks. Question Solvers handle the tasks with multi-modal on/off-chain data. While a Cognitive Evaluator mitigates LLM hallucinations and ensures verifiability. Experiments show that TIM significantly outperforms machine learning models, single LLMs, and single Agent baselines. We also analyze core challenges in intent inference. This work helps provide a more reliable understanding of user motivations in DeFi, offering context-aware explanations for complex blockchain activity.",
        "subjects": "Artificial Intelligence, General Finance",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.895484",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建了一个新颖的多智能体LLM框架。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的本质是提出一个名为“Transaction Intent Mining (TIM)”的**框架**，该框架是一个**多智能体LLM系统**。它的核心贡献不是简单地将现有智能体应用于DeFi领域，而是**设计和构建了一个具有特定架构和协作机制的智能体系统**来解决复杂问题。这完全符合“构建、改进LLM智能体”的核心目标，因此应予以保留。 2.  **第二步：正面指标——高度匹配** 论文包含了大量您关注的核心指标： *   **核心范式**: 明确提出了 `Multi-Agent Systems (MAS)` 和 `LLM-based Agents`。 *   **智能体能力**: *   `Planning`: 论文的核心组件之一是“Meta-Level Planner”，负责动态协调和分解任务，这是典型的智能体规划能力。 *   `Tool Use`: “Question Solvers”使用“多模态链上/链下数据”来解决问题，这属于工具使用/环境感知。 *   `Self-Correction`: “Cognitive Evaluator”用于减轻幻觉并确保结果可验证，这是一种高级的自我纠错和反思机制。 *   **多智能体**: 整个框架就是多智能体系统，`Meta-Level Planner`协调多个`domain experts`（即Question Solvers），体现了明确的`Collaboration`（协作）和分工。 3.  **第三步：排除标准——未触发** *   论文虽然提到了“mitigates LLM hallucinations”，但这是作为其智能体框架中一个功能性组件（Cognitive Evaluator）来介绍的，其**主要贡献是框架本身，而非安全或对齐研究**。 *   论文提到了“multi-modal data”，但在DeFi场景下，这通常指文本、数字、图表等，而非核心的视觉（Vision）或视频理解。即使包含视觉信息，它也是作为智能体感知环境的工具，而非研究核心。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文中的“Meta-Level Planner”动态地将复杂意图分析分解为可解决的子任务，这完全符合“保留”标准，即研究智能体如何进行规划和多步推理，而不是改进LLM本身的基础推理能力。 **最终决策**: 这篇论文的核心贡献是构建了一个名为TIM的**自主多智能体LLM框架**。该框架包含规划器、解决器和评估器，分别对应了智能体的**规划、工具使用和自我反思/纠错**等核心能力，并展示了智能体间的**协作**。尽管其应用场景是DeFi，但其研究焦点和核心创新在于**智能体系统的架构设计与方法论**，这与您“构建、改进或演化LLM智能体”的核心目标高度一致，特别是与“单智能体”和“多智能体”两个方向紧密相关。因此，应判定为符合要求。"
    },
    {
        "index": "#6",
        "title": "Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration",
        "link": "/arxiv/2511.15351",
        "arxiv_id": "2511.15351",
        "authors": "Yifu Guo, Zishan Xu, Zhiyuan Yao, Yuquan Lu, Jiaye Lin, Sen Hu, Zhenheng Tang, Yingchao Li, Huacan Wang, Ronghao Chen",
        "summary": "Existing multimodal reasoning models and frameworks suffer from fundamental architectural limitations: most lack the human-like ability to autonomously explore diverse reasoning pathways-whether in direct inference, tool-driven visual exploration, programmatic visual manipulation, or intrinsic visual imagination. Consequently, they struggle to adapt to dynamically changing capability requirements in real-world tasks. Meanwhile, humans exhibit a complementary set of thinking abilities when addressing such tasks, whereas existing methods typically cover only a subset of these dimensions. Inspired by this, we propose Octopus: Agentic Multimodal Reasoning with Six-Capability Orchestration, a new paradigm for multimodal agentic reasoning. We define six core capabilities essential for multimodal reasoning and organize a comprehensive evaluation benchmark, Octopus-Bench, accordingly. Octopus is capable of autonomously exploring during reasoning and dynamically selecting the most appropriate capability based on the current state. Experimental results show that Octopus achieves the best performance on the vast majority of tasks in Octopus-Bench, highlighting the crucial role of capability coordination in agentic multimodal reasoning.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.896421",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为“Octopus”的**新范式/框架**，用于实现“Agentic Multimodal Reasoning”。其核心贡献在于构建和改进LLM智能体，而不是简单应用。摘要中明确指出，Octopus能够“autonomously explore during reasoning and dynamically select the most appropriate capability”，这直接指向了智能体的自主行为和决策机制，是典型的Agentic AI研究。它不属于非演化型应用、非Agentic的基础推理或基础设施研究。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **核心范式**: 明确使用了 `Agentic Multimodal Reasoning`，直接对应 `Agentic AI` 和 `LLM-based Agents`。 - **智能体能力**: 摘要中提到的“autonomously explore diverse reasoning pathways”和“dynamically selecting the most appropriate capability”是高级的**规划**能力。同时，“tool-driven visual exploration”和“programmatic visual manipulation”明确属于**工具使用**范畴。这种动态选择也体现了某种形式的**自我修正**或适应。 3.  **第三步：排除标准** - **安全与对齐**: 论文摘要未提及任何关于安全、对齐、可解释性或幻觉的内容，其焦点在于性能和能力，因此不在此排除范围内。 - **多模态与视觉**: 这是本论文最需要注意的一点。虽然标题和摘要大量提及“Multimodal”和“Visual”，但根据筛选规则的例外情况，它们是**作为智能体感知和操作环境的工具**出现的。论文的核心是“Six-Capability Orchestration”（六种能力的编排），即智能体如何管理和协调包括视觉在内的多种能力来完成推理任务。研究的核心是**智能体的架构和决策逻辑**，而不是视觉模型本身。因此，它符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外条款，不应被排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文完全符合“保留”条件。它研究的正是“智能体如何进行规划或在复杂任务中进行多步推理”，其提出的“自主探索”和“动态选择”机制是对ReAct、ToT等Agentic框架的进一步发展和创新，而非仅仅提升LLM的基础数学或逻辑能力。 5.  **第五步：最终决策** - 综合以上分析，该论文的核心贡献是构建了一个新的LLM智能体框架，该框架专注于提升智能体在多模态环境下的自主规划、工具使用和动态能力协调能力。这直接对准了您研究目标中的“单智能体”方向，特别是其规划、工具使用和自我反思/修正能力。因此，这篇论文与您的研究课题高度相关，应被**保留**。"
    },
    {
        "index": "#13",
        "title": "Knowledge-Informed Automatic Feature Extraction via Collaborative Large Language Model Agents",
        "link": "/arxiv/2511.15074",
        "arxiv_id": "2511.15074",
        "authors": "Henrik Bradland, Morten Goodwin, Vladimir I. Zadorozhny, Per-Arne Andersen",
        "summary": "The performance of machine learning models on tabular data is critically dependent on high-quality feature engineering. While Large Language Models (LLMs) have shown promise in automating feature extraction (AutoFE), existing methods are often limited by monolithic LLM architectures, simplistic quantitative feedback, and a failure to systematically integrate external domain knowledge. This paper introduces Rogue One, a novel, LLM-based multi-agent framework for knowledge-informed automatic feature extraction. Rogue One operationalizes a decentralized system of three specialized agents-Scientist, Extractor, and Tester-that collaborate iteratively to discover, generate, and validate predictive features. Crucially, the framework moves beyond primitive accuracy scores by introducing a rich, qualitative feedback mechanism and a \"flooding-pruning\" strategy, allowing it to dynamically balance feature exploration and exploitation. By actively incorporating external knowledge via an integrated retrieval-augmented (RAG) system, Rogue One generates features that are not only statistically powerful but also semantically meaningful and interpretable. We demonstrate that Rogue One significantly outperforms state-of-the-art methods on a comprehensive suite of 19 classification and 9 regression datasets. Furthermore, we show qualitatively that the system surfaces novel, testable hypotheses, such as identifying a new potential biomarker in the myocardial dataset, underscoring its utility as a tool for scientific discovery.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.898388",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出一个名为 \"Rogue One\" 的**新颖的、基于LLM的多智能体框架**。它不是简单地将现有智能体框架应用于特征工程，而是**构建了一个全新的多智能体协作方法论**。论文详细描述了该框架的架构（三个专业化智能体：科学家、提取器、测试员）、协作流程（迭代协作）和核心机制（定性反馈、泛洪-修剪策略）。这完全符合“构建、改进LLM智能体”的核心目标，属于“多智能体”方向的研究。虽然其应用场景是特征工程（一个特定领域），但论文的本质是提出一种新的智能体系统构建范式，而非仅仅解决该领域的问题。 2.  **第二步：正面指标 (高度相关)** 论文摘要中包含了大量与您研究焦点直接相关的正面指标： *   **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)` *   **多智能体**: `Collaboration` (明确提到 \"collaborate iteratively\") *   **智能体能力**: `Tool Use / Tool Augmentation` (通过集成的RAG系统使用外部知识) *   **演化机制**: `Iterative Improvement` (智能体间的迭代协作和反馈机制) 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文虽然提到了生成的特征具有 \"interpretable\"（可解释性），但这只是其方法带来的一个优点，并非论文的核心研究贡献。论文的核心是构建多智能体框架，而不是研究可解释性或对齐技术。 *   **多模态与视觉**: 论文专注于表格数据和文本知识（通过RAG），不涉及视觉或多模态内容。 4.  **第四步：特殊和模糊情况 (不适用)** 该论文的情况非常清晰，属于典型的多智能体系统构建研究，不涉及需要特殊处理的模糊情况。 **最终决策**: 该论文的核心贡献在于**构建了一个新颖的多智能体协作框架**，以解决自动化特征提取问题。它详细阐述了智能体的分工、通信、协作机制和工具使用方法，完全契合您研究课题中的“多智能体”方向。因此，这篇论文是高度相关且应被筛选出的前沿研究。"
    },
    {
        "index": "#22",
        "title": "Learning Interestingness in Automated Mathematical Theory Formation",
        "link": "/arxiv/2511.14778",
        "arxiv_id": "2511.14778",
        "authors": "George Tsoukalas, Rahul Saha, Amitayush Thakur, Sabrina Reguyal, Swarat Chaudhuri",
        "summary": "We take two key steps in automating the open-ended discovery of new mathematical theories, a grand challenge in artificial intelligence. First, we introduce $\\emph{FERMAT}$, a reinforcement learning (RL) environment that models concept discovery and theorem-proving using a set of symbolic actions, opening up a range of RL problems relevant to theory discovery. Second, we explore a specific problem through $\\emph{FERMAT}$: automatically scoring the $\\emph{interestingness}$ of mathematical objects. We investigate evolutionary algorithms for synthesizing nontrivial interestingness measures. In particular, we introduce an LLM-based evolutionary algorithm that features function abstraction, leading to notable improvements in discovering elementary number theory and finite fields over hard-coded baselines. We open-source the $\\emph{FERMAT}$ environment at this URL(https://github.com/trishullab/Fermat).",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-05",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.900895",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于数学领域，而是提出了一种**新的方法论**来驱动自动化科学发现。其核心贡献是“一个基于LLM的演化算法”，该算法用于“合成非平凡的趣味性度量”。这直接属于“构建、改进或演化LLM智能体”的范畴，特别是“自我演化”方向。论文中的智能体（或演化种群）在FERMAT环境中通过执行符号动作来探索和发现新理论，这是一个典型的智能体框架，而非简单的应用。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Self-Evolving`, `Evolutionary Algorithms`, `LLM-based Agents` (其提出的算法本身就是一种LLM智能体)。 - **演化机制**: `Self-Improvement`, `Iterative Improvement`, `Generational Evolution` (演化算法的本质就是代际迭代和自我完善)。 - 这些指标强烈表明该论文与您的研究高度相关。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态。它专注于智能体的能力构建，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是本案例的关键。虽然论文的应用领域是“数学理论形成”，但根据您设定的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 这篇论文正是如此。它的核心创新点是**“LLM-based evolutionary algorithm that features function abstraction”**，这是一种新颖的自我演化机制。数学领域只是验证该机制有效性的试验场。因此，它符合保留的例外情况。 - **推理/规划**: 论文涉及“theorem-proving”（定理证明），这是一种高级推理形式。但这种推理是在智能体框架（FERMAT环境）内，通过执行一系列动作来完成的，属于智能体的规划与执行能力，而非对LLM基础推理能力的孤立改进。 **最终决策**: 综合以上分析，该论文的核心贡献在于提出了一种新颖的、基于LLM的演化算法，用于驱动智能体进行开放式的理论发现。这精准地命中了您研究目标中的“自我演化”和“LLM智能体构建”两个核心方向。尽管其应用场景是数学，但其方法论层面的创新是普适的，完全符合您的筛选要求。因此，最终判断为 **True**。"
    },
    {
        "index": "#21",
        "title": "Ask WhAI:Probing Belief Formation in Role-Primed LLM Agents",
        "link": "/arxiv/2511.14780",
        "arxiv_id": "2511.14780",
        "authors": "Keith Moore, Jun W. Kim, David Lyu, Jeffrey Heo, Ehsan Adeli",
        "summary": "We present Ask WhAI, a systems-level framework for inspecting and perturbing belief states in multi-agent interactions. The framework records and replays agent interactions, supports out-of-band queries into each agent's beliefs and rationale, and enables counterfactual evidence injection to test how belief structures respond to new information. We apply the framework to a medical case simulator notable for its multi-agent shared memory (a time-stamped electronic medical record, or EMR) and an oracle agent (the LabAgent) that holds ground truth lab results revealed only when explicitly queried. We stress-test the system on a multi-specialty diagnostic journey for a child with an abrupt-onset neuropsychiatric presentation. Large language model agents, each primed with strong role-specific priors (\"act like a neurologist\", \"act like an infectious disease specialist\"), write to a shared medical record and interact with a moderator across sequential or parallel encounters. Breakpoints at key diagnostic moments enable pre- and post-event belief queries, allowing us to distinguish entrenched priors from reasoning or evidence-integration effects. The simulation reveals that agent beliefs often mirror real-world disciplinary stances, including overreliance on canonical studies and resistance to counterevidence, and that these beliefs can be traced and interrogated in ways not possible with human experts. By making such dynamics visible and testable, Ask WhAI offers a reproducible way to study belief formation and epistemic silos in multi-agent scientific reasoning.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-06",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.900619",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** - 论文的核心贡献并非将LLM智能体应用于医疗领域，而是提出了一个名为 **Ask WhAI 的系统级框架**。这个框架的目的是**检查和扰动多智能体交互中的信念状态**。这是一种全新的**方法论和研究框架**，用于理解和分析LLM智能体，完全符合“构建、改进或演化LLM智能体的方法论或新框架”这一核心要求。 - 它避开了“非演化型应用”的排除项，因为医疗案例模拟器只是用来**验证和展示该框架有效性**的实验平台，论文的真正价值在于框架本身，而非其在医疗领域的应用成果。 2.  **第二步：正面指标 (高度匹配)** - 论文与您的核心关注点高度契合，尤其是在**多智能体**方向： - **核心范式**: 明确涉及 `LLM-based Agents` 和 `Multi-Agent Systems (MAS)`。 - **多智能体**: 论文的核心就是研究智能体间的 `Collaboration`（协作，通过共享EMR）、`Communication`（通信，写入病历）以及由此产生的信念动态。 - **智能体能力**: 论文深入探讨了智能体的 `Memory`（共享记忆，即带时间戳的电子病历EMR）和 `Tool Use`（工具使用，即查询LabAgent获取实验室结果）。 - 虽然不直接涉及“自我演化”，但它为研究多智能体系统中的认知偏差和信念固化提供了工具，这是未来设计能够自我纠正和演化的智能体系统的重要基础。 3.  **第三步：排除标准 (未触犯)** - 论文虽然提到了“making such dynamics visible and testable”，具有一定的可解释性，但其**主要贡献是研究框架，而非安全或对齐技术本身**。它是一个用于科学发现的工具，而不是一个为了解决AI对齐问题而设计的系统。因此，它不属于被排除的“安全与对齐”类别。 - 论文不涉及多模态或视觉内容。 4.  **第四步：特殊与模糊情况 (符合保留规则)** - 论文研究的是智能体在复杂任务（多专科诊断）中的**多步推理和信念形成过程**，这属于智能体层面的推理，而非提升LLM基础Token预测能力，因此符合保留条件。 **最终决策**: 该论文提出了一种创新的、用于探测和理解多智能体系统中信念形成与交互动态的框架。它直接命中了您研究焦点中的“多智能体”方向，并为智能体的“记忆”和“工具使用”等核心能力提供了新的研究视角和方法论。这篇论文不是简单的应用，而是为Agentic AI领域贡献了一个有价值的研究工具，因此应被**保留**。"
    },
    {
        "index": "#14",
        "title": "ProRAC: A Neuro-symbolic Method for Reasoning about Actions with LLM-based Progression",
        "link": "/arxiv/2511.15069",
        "arxiv_id": "2511.15069",
        "authors": "Haoyong Wu, Yongmei Liu",
        "summary": "In this paper, we propose ProRAC (Progression-based Reasoning about Actions and Change), a neuro-symbolic framework that leverages LLMs to tackle RAC problems. ProRAC extracts fundamental RAC elements including actions and questions from the problem, progressively executes each action to derive the final state, and then evaluates the query against the progressed state to arrive at an answer. We evaluate ProRAC on several RAC benchmarks, and the results demonstrate that our approach achieves strong performance across different benchmarks, domains, LLM backbones, and types of RAC tasks.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.898647",
        "filter_reason": "这篇论文符合筛选要求，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 论文的核心贡献是提出一个名为 ProRAC 的**新框架**。这个框架并非简单地将LLM应用于某个领域，而是定义了一套结构化的方法论来解决“行动与变化推理”（RAC）问题。该方法论包括：1) 提取行动和问题；2) 逐步执行每个行动以推导状态；3) 基于最终状态评估答案。 - **判断**: 这个过程本质上是一个**规划与执行**的循环，是LLM智能体行为的核心特征。论文的核心是**构建一个让LLM进行规划和多步执行的框架**，而不是将LLM作为黑箱工具。因此，它符合“构建LLM智能体”的核心目标，应**保留**。 2.  **第二步：正面指标** - 论文与多个核心关注点高度匹配： - **核心范式**: 论文提出的 ProRAC 框架是一个典型的 `Agentic AI` 和 `LLM-based Agents` 的实现。 - **智能体能力**: 论文的精髓在于 `Planning`（规划，即提取和序列化行动）和一种结构化的多步推理。虽然未明确提及 `ReAct`，但其“推理+行动”的循环思想与 `ReAct` 范式高度一致。 3.  **第三步：排除标准** - 论文的研究焦点是提升智能体在特定逻辑推理任务上的性能框架，不涉及 `Safety`、`Alignment`、`Interpretability` 或 `Vision` 等排除领域。因此，未触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这正是本论文的典型情况。论文的贡献**不是**提升LLM本身的基础数学或逻辑能力，而是**提出一个智能体如何进行规划和多步推理的新框架**。它定义了智能体的行动流程（提取行动 -> 执行 -> 评估），这完全符合“保留”的条件。 5.  **第五步：最终决策** - 综合以上分析，ProRAC论文的核心贡献在于构建了一个新颖的、结构化的LLM智能体框架，用于解决需要复杂规划和逐步执行的推理任务。这直接命中了研究课题中“单智能体”方向下的“规划”子方向。因此，这篇论文与你的研究范围高度相关，应被筛选出来。"
    },
    {
        "index": "#39",
        "title": "DEPO: Dual-Efficiency Preference Optimization for LLM Agents",
        "link": "/arxiv/2511.15392",
        "arxiv_id": "2511.15392",
        "authors": "Sirui Chen, Mengshi Zhao, Lei Xu, Yuying Zhao, Beier Zhu, Hanwang Zhang, Shengjie Zhao, Chaochao Lu",
        "summary": "Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at https://opencausalab.github.io/DEPO.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.905922",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断——论文的本质是“改进LLM智能体”** - **保留**: 这篇论文的核心贡献并非将LLM智能体作为工具去解决某个特定领域（如生物、金融）的问题，而是聚焦于**改进LLM智能体本身**。它提出了一个全新的“dual-efficiency”（双重效率）概念来定义智能体的效率，并基于此设计了DEPO（双重效率偏好优化）方法来训练和优化智能体。这直接命中了你筛选标准中的“构建、改进或演化LLM智能体的方法论或新框架”。 2.  **第二步：正面指标——论文紧密围绕核心关注点** - **核心范式**: 论文明确研究 `LLM-based Agents`。 - **智能体能力**: 论文的核心是解决智能体在执行任务时的效率问题。它提出的“trajectory-level efficiency”（轨迹级效率，即最小化完成任务所需的步骤数）直接关联到智能体的**规划**能力。通过优化，智能体能用更少的步骤完成任务，这本身就是一种更优的规划表现。 - **演化机制**: 论文提出的“preference optimization”（偏好优化）方法，通过奖励简洁的响应和更少的行动步骤来训练模型。这是一种明确的**自我完善**和**迭代改进**机制，属于**自我演化**的范畴。智能体通过这种优化过程，演化出更高效的行为模式。 3.  **第三步：排除标准——论文不涉及排除领域** - 论文的研究焦点是智能体的效率和性能，完全没有涉及安全、对齐、可解释性或水印等内容。 - 论文实验基于文本任务（WebShop, BabyAI, 数学基准），不涉及视觉或多模态内容作为研究核心。 4.  **第四步：处理特殊和模糊情况——符合“保留”规则** - **推理/规划**: 这篇论文不是在提升LLM本身的基础数学或逻辑推理能力（例如，通过新的数据集或微调方法让模型更会解数学题）。相反，它是在**改进智能体的规划和执行框架**，让智能体在解决复杂任务时，其思维链和行动轨迹更短、更高效。这完全符合“保留”关于智能体规划和多步推理框架的规则。 **总结**: 该论文的核心贡献是提出了一种新的LLM智能体优化范式（DEPO），旨在提升智能体的规划和执行效率。它不仅为智能体效率提供了新的定义，还实现了一种让智能体自我完善、演化出更优行为模式的方法。这与你的研究目标——“构建、改进或演化LLM智能体”，特别是“单智能体”的规划和“自我演化”方向——高度契合。因此，应予以保留。"
    },
    {
        "index": "#49",
        "title": "PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback",
        "link": "/arxiv/2511.15253",
        "arxiv_id": "2511.15253",
        "authors": "Sirui Chen, Jinsong Zhou, Xinli Xu, Xiaoyu Yang, Litao Guo, Ying-Cong Chen",
        "summary": "Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided slides into model presentation videos by combining slide processing, visual-language analysis, narration script generation, personalized voice synthesis, and synchronized video assembly. The Coach Agent then evaluates user-recorded presentations against these exemplars, conducting multimodal speech analysis and delivering structured feedback in an Observation-Impact-Suggestion (OIS) format. To enhance the authenticity of the learning experience, the Coach Agent incorporates an Audience Agent, which simulates the perspective of a human listener and provides humanized feedback reflecting audience reactions and engagement. Together, these agents form a closed loop of observation, practice, and feedback. Implemented on a robust backend with multi-model integration, voice cloning, and error handling mechanisms, the system demonstrates how AI-driven agents can provide engaging, human-centered, and scalable support for presentation skill development in both educational and professional contexts.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.908662",
        "filter_reason": "这篇论文符合筛选要求，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个新颖的**多智能体系统**。其核心贡献并非“用AI解决演讲指导问题”，而是**构建了一个由“Ideal Presentation Agent”、“Coach Agent”和“Audience Agent”组成的协同工作框架**。这个框架定义了不同智能体的角色、能力以及它们之间的交互流程，这完全符合“构建、改进LLM智能体”的核心目标。它不是简单地将现有LLM作为工具应用，而是设计了智能体架构本身。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提出了 `Multi-Agent Systems (MAS)`，描述了一个双智能体（实际上是三智能体）系统。 - **智能体能力**: `Tool Use / Tool Augmentation` 是一个关键特征，Ideal Presentation Agent 集成了“视觉语言分析”、“语音合成”等多种工具来完成复杂任务。 - **多智能体**: 论文的核心就是 `Collaboration`（协作）和 `Communication`（通信）。多个智能体协同工作，形成一个“观察、练习、反馈”的闭环，这是多智能体研究的典型范例。 3.  **第三步：排除标准** - 论文不涉及安全、对齐或可解释性等排除领域。 - 虽然论文提到了 `visual-language analysis`，但它符合特殊情况的例外条款：**视觉能力是作为智能体感知和处理环境信息（幻灯片）的工具**，而不是论文研究的核心。论文的核心是智能体的架构和协作，而非提出新的视觉模型。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及非Agentic的基础推理改进。相反，它展示了智能体如何通过分工协作来完成一个复杂的多步骤任务，这本身就是一种高级的Agentic规划与执行。 - **自我演化的应用**: 论文不涉及自我演化机制，因此此条不适用。 **最终决策**: 综合以上分析，该论文的核心贡献在于**设计并实现了一个新颖的多智能体协作框架**来解决一个具体问题。它清晰地定义了智能体的角色、工具使用和交互模式，完全符合研究课题中“多智能体”这一核心方向。因此，尽管它是一个应用型研究，但其方法论贡献是Agentic层面的，应被保留。"
    },
    {
        "index": "#51",
        "title": "OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition",
        "link": "/arxiv/2511.15211",
        "arxiv_id": "2511.15211",
        "authors": "Xinli Tao, Xin Dong, Xuezhong Zhou",
        "summary": "Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.909223",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将一个已有的LLM或智能体框架应用到临床领域。它的核心贡献是**构建了一个新的多智能体协作框架（OEMA）**。该框架由三个具有不同职责的智能体（self-annotator, discriminator, predictor）组成，通过协作来解决零样本临床NER问题。这属于“构建LLM智能体”和“多智能体系统”的方法论贡献，因此符合保留标准。它避开了“非演化型应用”的排除规则，因为其创新点在于框架本身，而非应用本身。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提到了 `Multi-Agent Systems (MAS)`，其标题和摘要都强调了“多智能体协作”。 - **智能体能力**: 框架中的 `self-annotator` 和 `discriminator` 之间的交互，形成了一个数据筛选和优化的循环，这可以被视为一种 `Self-Refine` 或 `Self-Improvement` 的机制。 - **多智能体**: `Collaboration` 是该论文的核心机制，三个智能体分工合作以完成最终任务。 - **演化机制**: `self-annotator` 生成数据，`discriminator` 进行过滤，这个过程本身就是一种迭代和自我完善的体现，符合 `Iterative Improvement` 和 `Self-Refine` 的特征。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态等领域。它专注于提升特定NLP任务的性能，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这正是本论文的关键情况。虽然论文的应用领域是“临床命名实体识别”（一个特定领域），但其核心贡献是提出了一种**新的“自我演化”机制**。OEMA框架通过`self-annotator`和`discriminator`的协作，实现了对生成数据的自我筛选和优化，这是一种新颖的自我精炼（self-refine）框架。根据筛选规则中的例外条款：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。”，因此这篇论文应该被保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种新颖的、具有自我精炼能力的多智能体协作框架（OEMA）。它直接命中了我的研究焦点中的“多智能体”和“自我演化”两个方向。尽管它被应用于一个具体的领域（临床NER），但其方法论贡献是普适的，并且完全符合我寻找“构建、改进或演化LLM智能体”论文的核心目标。因此，最终判断为 **True**。"
    },
    {
        "index": "#109",
        "title": "irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution",
        "link": "/arxiv/2511.14794",
        "arxiv_id": "2511.14794",
        "authors": "Camilo Chacón Sartori, Christian Blum",
        "summary": "Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-15",
        "category": "cs.AI",
        "crawl_time": "2025-11-20T11:00:04.925946",
        "filter_reason": "这篇论文的核心贡献是提出 `irace-evo`，一个将LLM与自动算法配置工具相结合，以实现算法代码自我演化的框架。这完全符合你的研究范围，具体判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心不是简单地将LLM作为工具应用于某个领域（如解决VSBPP问题），而是**提出了一种新的方法论和框架**，该框架利用LLM来**演化算法本身的代码**。 - 这种“代码演化”机制，即让算法通过LLM的生成和迭代来不断完善自身，是典型的**自我演化**过程。它超越了简单的参数调整，进入了算法结构和逻辑的迭代优化，这与你的“自我演化”研究焦点高度契合。 - 因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** - 论文明确包含了你的核心关注点：`Self-Evolving`（代码演化）、`Evolutionary Algorithms`（背景是元启发式和演化算法）、`Self-Improvement`（发现优于现有算法的新变体）、`Iterative Improvement`（整个演化过程）。 - 虽然没有使用 `Agentic AI` 这个词，但LLM在其中扮演了一个主动的“代码生成器”和“改进者”的角色，这可以被视为一种特定形式的智能体行为。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不是关于安全、对齐或多模态，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况——完美匹配例外规则** - 这篇论文是**“自我演化的应用”**这一特殊情况的完美范例。根据你的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” - `irace-evo` 的核心贡献正是这个**新的自我演化机制**（LLM驱动的代码演化框架），而将其应用于“Variable-Sized Bin Packing Problem”只是为了验证该机制的有效性。因此，根据此规则，必须保留。 **最终决策**: 这篇论文的核心贡献在于构建了一个能够让算法通过LLM进行代码层面自我演化的框架。这直接命中了你研究目标中的“自我演化”方向，并且是关于构建和改进演化方法论的前沿研究，而非简单的应用。因此，这篇论文高度相关，应该被保留。"
    }
]