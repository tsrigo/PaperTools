[
    {
        "index": "#1",
        "title": "Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts",
        "link": "/arxiv/2510.24030",
        "arxiv_id": "2510.24030",
        "authors": "Ahmet Akkaya Melih, Yamuna Singh, Kunal L. Agarwal, Priya Mukherjee, Kiran Pattnaik, Hanuman Bhatia",
        "summary": "The rapid advancements in large foundation models and multi-agent systems offer unprecedented capabilities, yet current Human-in-the-Loop (HiTL) paradigms inadequately integrate human expertise, often leading to cognitive overload and decision-making bottlenecks in complex, high-stakes environments. We propose the \"Human-Machine Social Hybrid Intelligence\" (HMS-HI) framework, a novel architecture designed for deep, collaborative decision-making between groups of human experts and LLM-powered AI agents. HMS-HI is built upon three core pillars: (1) a \\textbf{Shared Cognitive Space (SCS)} for unified, multi-modal situational awareness and structured world modeling; (2) a \\textbf{Dynamic Role and Task Allocation (DRTA)} module that adaptively assigns tasks to the most suitable agent (human or AI) based on capabilities and workload; and (3) a \\textbf{Cross-Species Trust Calibration (CSTC)} protocol that fosters transparency, accountability, and mutual adaptation through explainable declarations and structured feedback. Validated in a high-fidelity urban emergency response simulation, HMS-HI significantly reduced civilian casualties by 72\\% and cognitive load by 70\\% compared to traditional HiTL approaches, demonstrating superior decision quality, efficiency, and human-AI trust. An ablation study confirms the critical contribution of each module, highlighting that engineered trust and shared context are foundational for scalable, synergistic human-AI collaboration.",
        "subjects": "Multiagent Systems",
        "date": "2025-10-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-29T11:00:04.875532",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一个名为“人机社会混合智能”（HMS-HI）的**新框架**。该框架旨在解决“大型模型智能体群体”与“人类专家”之间的深度协作决策问题。这完全符合我筛选标准中“构建、改进或演化LLM智能体”的核心目标，特别是属于“多智能体”这一研究方向。它不是简单地将现有智能体作为工具应用，而是设计了一套新的方法论和架构来管理智能体群体。 **第二步：正面指标分析** - 论文包含了多个我的核心关注点： - **核心范式**: 明确提到了 `Multi-Agent Systems`，并聚焦于 `LLM-powered AI agents`。 - **多智能体**: 论文的主题就是 `Collaboration`（协作）。其提出的三个核心模块都与多智能体能力直接相关： 1. `Shared Cognitive Space (SCS)`：可以看作是一种群体级的共享`Memory`（记忆）和情境感知机制。 2. `Dynamic Role and Task Allocation (DRTA)`：这是典型的多智能体`Collaboration`（协作）与任务规划机制。 3. `Cross-Species Trust Calibration (CSTC)`：涉及智能体与人类之间的`Communication`（通信）和建立信任，是社会性智能体系统的关键。 **第三步：排除标准分析** - **安全与对齐**: 论文虽然提到了`Explainable`（可解释的）声明，但其目的是为了“建立信任和促进相互适应”，从而实现更好的`Collaboration`（协作）。`Explainability`在这里是作为实现高效协作的**手段**，而不是论文的**主要研究贡献**。论文的核心是HMS-HI这个协作框架本身，而非提出一种新的可解释性方法。因此，它不属于被排除的“主要贡献是关于可解释性”的论文。 - **多模态与视觉**: 论文未提及视觉或多模态是其核心研究内容。 **第四步：特殊和模糊情况处理** - **推理/规划**: 论文中的`Dynamic Role and Task Allocation (DRTA)`模块本质上是一种在复杂任务中为群体（包括人类和AI智能体）进行规划和资源分配的机制，这属于智能体规划能力的范畴，因此应该保留。 - **自我演化的应用**: 此规则不适用，因为论文的核心是协作，而非自我演化。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的、用于人机混合群体协作决策的多智能体框架（HMS-HI）。它深入探讨了多智能体系统中的协作、通信、任务分配和共享情境等关键问题，完全符合我研究课题中“多智能体”这一核心方向。尽管它在一个具体的应用领域（城市应急响应）中进行验证，但其贡献是通用性的框架设计，而非特定领域的应用。因此，这篇论文与我的研究目标高度相关，应予以保留。"
    },
    {
        "index": "#6",
        "title": "Affordance Representation and Recognition for Autonomous Agents",
        "link": "/arxiv/2510.24459",
        "arxiv_id": "2510.24459",
        "authors": "Habtom Kahsay Gidey, Niklas Huber, Alexander Lenz, Alois Knoll",
        "summary": "The autonomy of software agents is fundamentally dependent on their ability to construct an actionable internal world model from the structured data that defines their digital environment, such as the Document Object Model (DOM) of web pages and the semantic descriptions of web services. However, constructing this world model from raw structured data presents two critical challenges: the verbosity of raw HTML makes it computationally intractable for direct use by foundation models, while the static nature of hardcoded API integrations prevents agents from adapting to evolving services. This paper introduces a pattern language for world modeling from structured data, presenting two complementary architectural patterns. The DOM Transduction Pattern addresses the challenge of web page complexity by distilling} a verbose, raw DOM into a compact, task-relevant representation or world model optimized for an agent's reasoning core. Concurrently, the Hypermedia Affordances Recognition Pattern enables the agent to dynamically enrich its world model by parsing standardized semantic descriptions to discover and integrate the capabilities of unknown web services at runtime. Together, these patterns provide a robust framework for engineering agents that can efficiently construct and maintain an accurate world model, enabling scalable, adaptive, and interoperable automation across the web and its extended resources.",
        "subjects": "Artificial Intelligence, Multiagent Systems, Software Engineering",
        "date": "2025-10-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-29T11:00:04.877613",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质是**构建和改进LLM智能体的核心方法论**。它没有将智能体作为工具去解决某个特定领域（如金融、医疗）的问题，而是聚焦于智能体本身的一个根本性挑战：**如何构建一个高效、自适应的内部世界模型**。论文提出的两种架构模式（DOM转导模式和超媒体可供性识别模式）是直接用于增强智能体自主性的新框架，这完全符合“构建、改进或演化LLM智能体”的核心目标。 **第二步：正面指标——高度相关** 论文包含了您关注的多个核心指标： 1.  **Agentic AI / LLM-based Agents**: 论文明确以“自主智能体”为核心研究对象，并讨论如何优化其“推理核心”，这直接指向了Agentic AI的研究。 2.  **Tool Use / Tool Augmentation**: 论文的第二个核心贡献“超媒体可供性识别模式”是典型的**动态工具使用**研究。它使智能体能够在运行时发现并集成未知的Web服务，这超越了使用预定义工具集的范畴，是智能体能力演化的关键一步。 3.  **Planning**: 虽然论文没有直接提出新的规划算法，但它所构建的“紧凑的、任务相关的世界模型”是智能体进行有效规划和多步推理的**基础和前提**。一个高质量的世界模型直接决定了规划的上限。 4.  **Self-Evolving**: 论文明确指出其目标是解决“防止智能体无法适应不断演化的服务”的问题，并实现“可扩展、自适应和可互操作的自动化”。这直接触及了“自我演化”中的**适应性**概念，即智能体如何适应变化的环境。 **第三步：排除标准——不涉及** 论文的核心贡献是关于智能体的架构和能力，而非安全、对齐或可解释性。同时，它处理的是结构化数据（DOM、语义描述），而非多模态或视觉数据，因此完全避开了您的排除标准。 **第四步：处理特殊和模糊情况** 这篇论文是“关于智能体如何进行规划或在复杂任务中进行多步推理”的典型范例，尽管它聚焦于规划前的世界模型构建阶段。它不是在提升LLM的基础推理能力（如数学计算），而是在为智能体的**自主规划和行动**提供基础设施，因此应被保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于提出了一种新的架构框架，用于增强LLM智能体的环境感知、世界建模和动态工具使用能力。这直接推动了智能体的自主性和适应性，与您研究的“单智能体”和“自我演化”方向高度契合。因此，这是一篇非常前沿且相关的论文，应被筛选出来。"
    },
    {
        "index": "#7",
        "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents",
        "link": "/arxiv/2510.24442",
        "arxiv_id": "2510.24442",
        "authors": "Yiding Wang, Yuxuan Chen, Fanxu Meng, Xifan Chen, Xiaolei Yang, Muhan Zhang",
        "summary": "Since real-world legal experiments are often costly or infeasible, simulating legal societies with Artificial Intelligence (AI) systems provides an effective alternative for verifying and developing legal theory, as well as supporting legal administration. Large Language Models (LLMs), with their world knowledge and role-playing capabilities, are strong candidates to serve as the foundation for legal society simulation. However, the application of LLMs to simulate legal systems remains underexplored. In this work, we introduce Law in Silico, an LLM-based agent framework for simulating legal scenarios with individual decision-making and institutional mechanisms of legislation, adjudication, and enforcement. Our experiments, which compare simulated crime rates with real-world data, demonstrate that LLM-based agents can largely reproduce macro-level crime trends and provide insights that align with real-world observations. At the same time, micro-level simulations reveal that a well-functioning, transparent, and adaptive legal system offers better protection of the rights of vulnerable individuals.",
        "subjects": "Artificial Intelligence, Computation and Language, Computers and Society, Multiagent Systems",
        "date": "2025-10-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-29T11:00:04.877966",
        "filter_reason": "这篇论文符合您的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于法律领域，而是**提出了一个名为“Law in Silico”的、基于LLM的智能体框架**。摘要明确指出，他们引入的是一个“LLM-based agent framework for simulating legal scenarios”。这完全符合您筛选标准中“构建、改进或演化LLM智能体的方法论或新框架”的要求。它不是在解决一个具体的法律问题，而是在构建一个能够模拟法律社会的通用工具，其本质是Agentic AI的研究。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)`。模拟一个“法律社会”必然涉及多个智能体（如公民、法官、立法者）的交互。 - **多智能体**: `Collaboration` (协作), `Communication` (通信), `Agent Society` (智能体社会)。论文中提到的“立法、裁决和执行等制度机制”以及“个体决策”都指向一个复杂的多智能体社会模拟。 - 这些正面指标强烈表明该论文与您的“多智能体”研究方向高度相关。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。它的焦点是智能体框架的构建和模拟，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文虽然应用在法律领域，但它完美地符合您设定的“例外”规则。其核心是提出一种新的**多智能体模拟框架**，而不是利用已有框架去解决法律问题。因此，它属于“保留”的范畴。 - **推理/规划**: 论文中的智能体进行“个体决策”，这内在地包含了规划和推理过程，并且是在一个多智能体交互的复杂环境中进行的，这属于智能体层面的推理，而非对LLM基础能力的改进。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建一个用于模拟法律社会的多智能体框架。它直接推动了LLM智能体在多智能体系统方向的发展，完全符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标。因此，最终判断为 **True**。"
    },
    {
        "index": "#4",
        "title": "Tongyi DeepResearch Technical Report",
        "link": "/arxiv/2510.24701",
        "arxiv_id": "2510.24701",
        "authors": "Tongyi DeepResearch Team, Baixuan Li, Bo Zhang, Dingchu Zhang, Fei Huang, Guangyu Li, Guoxin Chen, Huifeng Yin, Jialong Wu, Jingren Zhou, Kuan Li, Liangcai Su, Litu Ou, Liwen Zhang, Pengjun Xie, Rui Ye, Wenbiao Yin, Xinmiao Yu, Xinyu Wang, Xixi Wu, Xuanzhong Chen, Yida Zhao, Zhen Zhang, Zhengwei Tao, Zhongwang Zhang, Zile Qiao, Chenxi Wang, Donglei Yu, Gang Fu, Haiyang Shen, Jiayin Yang, Jun Lin, Junkai Zhang, Kui Zeng, Li Yang, Hailong Yin, Maojia Song, Ming Yan, Peng Xia, Qian Xiao, Rui Min, Ruixue Ding, Runnan Fang, Shaowei Chen, Shen Huang, Shihang Wang, Shihao Cai, Weizhou Shen, Xiaobin Wang, Xin Guan, Xinyu Geng, Yingcheng Shi, Yuning Wu, Zhuo Chen, Zijian Li, Yong Jiang",
        "summary": "We present Tongyi DeepResearch, an agentic large language model, which is specifically designed for long-horizon, deep information-seeking research tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is developed through an end-to-end training framework that combines agentic mid-training and agentic post-training, enabling scalable reasoning and information seeking across complex tasks. We design a highly scalable data synthesis pipeline that is fully automatic, without relying on costly human annotation, and empowers all training stages. By constructing customized environments for each stage, our system enables stable and consistent interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total parameters, with only 3.3 billion activated per token, achieves state-of-the-art performance across a range of agentic deep research benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We open-source the model, framework, and complete solutions to empower the community.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval, Machine Learning, Multiagent Systems",
        "date": "2025-10-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-29T11:00:04.876985",
        "filter_reason": "这篇论文完全符合你的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单应用LLM，而是提出了一种全新的、端到端的训练框架来**构建**一个专门的LLM智能体。其核心贡献是“agentic mid-training和agentic post-training”这一方法论，以及一个全自动的数据合成管道。这直接命中了你筛选标准中的“构建、改进或演化LLM智能体的方法论或新框架”。它不是将已有智能体用于特定领域，而是创造智能体本身。 2.  **第二步：正面指标** - 论文摘要中明确包含了你的多个核心关注点： - **核心范式**: `Agentic large language model`, `agentic mid-training`, `agentic post-training`。 - **智能体能力**: 论文旨在解决“长时程、深度信息检索”任务，这必然涉及复杂的**规划**、**工具使用**（如浏览器）和多步**推理**。 - **演化机制**: 其提出的训练框架，特别是分阶段的训练过程，可以被视为一种结构化的、通过训练数据和环境交互实现的智能体**改进**和**迭代**机制，这与“自我演化”的方向高度契合。 3.  **第三步：排除标准** - 论文的主要贡献不在于安全、对齐或可解释性。 - 论文也未将多模态或视觉作为研究核心，其焦点是基于文本的智能体构建。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文是关于智能体如何在复杂任务中进行规划和推理的，属于保留范畴。它不是在改进LLM的基础数学能力，而是在构建一个能够自主完成研究任务的智能体框架。 - **自我演化的应用**: 这篇论文是“自我演化”方向的一个绝佳范例。虽然它应用于“研究”这一特定领域，但其核心是提出了一种新的训练机制来**演化**出更强的智能体能力，完全符合“保留（例外）”的规则。 **最终决策**: 该论文的核心贡献在于提出了一套构建和训练LLM智能体的新框架，使其具备长时程规划和工具使用能力。这完全符合你“构建、改进或演化LLM智能体”的核心目标，并且属于“单智能体”和“自我演化”两个方向的交叉研究。因此，这篇论文应该被保留。"
    },
    {
        "index": "#10",
        "title": "TDFlow: Agentic Workflows for Test Driven Software Engineering",
        "link": "/arxiv/2510.23761",
        "arxiv_id": "2510.23761",
        "authors": "Kevin Han, Siddharth Maddikayala, Tim Knappe, Om Patel, Austen Liao, Amir Barati Farimani",
        "summary": "We introduce TDFlow, a novel test-driven agentic workflow that frames repository-scale software engineering as a test-resolution task, specifically designed to solve human-written tests. Given a set of tests, TDFlow repeatedly proposes, revises, and debugs repository-scale patches using precisely engineered sub-agents and tightly constrained tools. The workflow decomposes software engineering program repair into four components governed by respective sub-agents. This simple, forced decoupling of patch proposing, debugging, patch revision, and optional test generation (1) reduces long-context burden on any individual sub-agent, (2) focuses each sub-agent on specific, pre-defined sub-tasks, and (3) allows for specialized performance improvement on specific sub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on SWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and 94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within SWE-Bench Lite and Verified uncover only 7 instances of test hacking, which were subsequently counted as failures. Furthermore, we show that the primary obstacle to human-level software engineering performance lies within writing successful reproduction tests. We envision a human-LLM interactive system powered by TDFlow where human developers write tests solved by LLM systems. Together, these results indicate that modern LLMs, when embedded in a narrowly engineered, test-driven workflow, already achieve human-level test resolution -- with the final frontier for fully autonomous repository repair being the accurate generation of valid reproduction tests.",
        "subjects": "Software Engineering, Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-27",
        "category": "cs.MA",
        "crawl_time": "2025-10-29T11:00:04.878901",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于软件工程领域，而是提出了一种名为 **TDFlow** 的、全新的 **智能体工作流框架**。摘要明确指出，该框架通过“精心设计的子智能体”和“严格约束的工具”来解决问题。这表明论文的本质是关于**如何构建和设计一个高效的LLM智能体系统**，而不是将现有智能体作为工具去解决一个特定领域的问题。因此，它不属于“非演化型应用”的排除范畴。 **第二步：正面指标——高度匹配** 论文包含了多个您关注的核心关键词和概念： *   **核心范式**: `Agentic AI`, `LLM-based Agents`。标题和摘要中反复强调“Agentic Workflows”。 *   **多智能体**: 论文明确使用了“sub-agents”（子智能体）的概念，并将复杂的软件工程任务分解给不同的子智能体处理（补丁提出、调试、修订等）。这完全符合您对“多智能体”研究方向的关注，特别是智能体间的协作与任务分解。 *   **智能体能力**: `Planning`（整个工作流就是一个复杂的规划）、`Tool Use / Tool Augmentation`（明确提到使用工具）、`Self-Correction`（反复地提出、修订和调试的迭代过程）。 *   **演化机制**: 虽然不是严格意义上的“自我演化”，但其“反复地提出、修订和调试”的迭代改进机制，与`Iterative Improvement`和`Self-Refine`的理念高度一致。 **第三步：排除标准——未触发** 论文的主要贡献是关于智能体的架构设计和性能提升，不涉及安全、对齐、可解释性或视觉多模态等排除领域。 **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文提出的TDFlow工作流本身就是一个复杂的、多步骤的规划和执行框架。它不是在改进LLM的基础推理能力，而是在构建一个能让LLM进行复杂任务规划和执行的智能体系统。这完全符合“保留”的条件。 *   **自我演化的应用**: 这篇论文虽然应用在软件工程领域，但其核心是提出一种新的智能体工作流机制，这恰好是“保留”规则的例外情况。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于**构建了一个新颖的、由多个子智能体协作构成的工作流框架（TDFlow）**，以解决复杂的、多步骤的软件工程任务。它直接贡献于“LLM智能体及其演化”这一课题，特别是在**单智能体的规划/工具使用/自我修正**和**多智能体的协作/任务分解**这两个方向上提供了重要的方法论创新。因此，这篇论文与您的研究目标高度契合，应被筛选出来。"
    },
    {
        "index": "#6",
        "title": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking",
        "link": "/arxiv/2510.24698",
        "arxiv_id": "2510.24698",
        "authors": "Baixuan Li, Dingchu Zhang, Jialong Wu, Wenbiao Yin, Zhengwei Tao, Yida Zhao, Liwen Zhang, Haiyang Shen, Runnan Fang, Pengjun Xie, Jingren Zhou, Yong Jiang",
        "summary": "Parallel thinking expands exploration breadth, complementing the deep exploration of information-seeking (IS) agents to further enhance problem-solving capability. However, conventional parallel thinking faces two key challenges in this setting: inefficiency from repeatedly rolling out from scratch, and difficulty in integrating long-horizon reasoning trajectories during answer generation, as limited context capacity prevents full consideration of the reasoning process. To address these issues, we propose ParallelMuse, a two-stage paradigm designed for deep IS agents. The first stage, Functionality-Specified Partial Rollout, partitions generated sequences into functional regions and performs uncertainty-guided path reuse and branching to enhance exploration efficiency. The second stage, Compressed Reasoning Aggregation, exploits reasoning redundancy to losslessly compress information relevant to answer derivation and synthesize a coherent final answer. Experiments across multiple open-source agents and benchmarks demonstrate up to 62% performance improvement with a 10--30% reduction in exploratory token consumption.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.137707",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出了一种名为 **ParallelMuse** 的新范式，其目标是**改进LLM智能体**。摘要明确指出，这是一个“为深度信息搜寻智能体设计的两阶段范式”。它并非将现有智能体作为工具去解决某个特定领域的问题，而是直接针对智能体本身在“并行思维”和“信息搜寻”过程中的效率低下和轨迹整合困难等**根本性问题**进行优化。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标 (高度相关)** 论文包含了多个核心关注点： *   **核心范式**: 论文标题和摘要中多次出现 `Agentic`，明确其研究定位是智能体。 *   **智能体能力**: 论文的核心是关于智能体的**规划**与**推理**。它提出的“Functionality-Specified Partial Rollout”旨在提升智能体的探索效率和路径规划能力；“Compressed Reasoning Aggregation”则是对智能体长程推理轨迹的整合与提炼，这与智能体的**记忆**和**自我反思**机制密切相关。它解决的是智能体在复杂任务中如何更有效地进行多步推理的问题。 3.  **第三步：排除标准 (未触发)** 论文的研究焦点是智能体的算法框架和效率，与安全对齐、多模态视觉等排除标准无关。 4.  **第四步：处理特殊和模糊情况 (符合保留规则)** 论文完美地符合“推理/规划”的保留规则。它不是在提升LLM本身的基础数学或逻辑能力，而是在构建一个**新的Agentic框架**，让智能体能够更高效地进行并行探索和深度信息整合。这属于典型的智能体规划与推理研究，是您“单智能体”方向下的核心子方向。 **总结**: 该论文的本质是提出一种新的智能体框架来增强LLM智能体的规划和推理能力。其核心贡献在于方法论创新，直接服务于“构建、改进LLM智能体”这一目标，属于“单智能体”研究范畴下的“规划”与“推理”子方向。因此，这篇论文与您的研究课题高度相关，应该被保留。"
    },
    {
        "index": "#5",
        "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management",
        "link": "/arxiv/2510.24699",
        "arxiv_id": "2510.24699",
        "authors": "Rui Ye, Zhongwang Zhang, Kuan Li, Huifeng Yin, Zhengwei Tao, Yida Zhao, Liangcai Su, Liwen Zhang, Zile Qiao, Xinyu Wang, Pengjun Xie, Fei Huang, Siheng Chen, Jingren Zhou, Yong Jiang",
        "summary": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a `folding' operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.131824",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。我的判断依据如下： 1.  **核心判断（第一步）：保留。** 论文的核心贡献是提出了一种名为 **AgentFold** 的“新颖的智能体范式”。它不是简单地将现有智能体应用于某个领域，而是针对现有智能体（如ReAct）在长时程任务中存在的“上下文管理”这一根本性缺陷，提出了一套全新的解决方案。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **正面指标（第二步）：高度匹配。** 论文包含了多个你的核心关注点： *   **核心范式**: 论文明确提出了一个新的 `LLM-based Agent` 范式。 *   **智能体能力**: 论文的创新点 `proactive context management`（主动上下文管理）和 `folding` 操作，本质上是关于智能体的 **`Memory`**（记忆）和 **`Self-Reflection`**（自我反思）能力的重大改进。它将上下文视为一个“动态认知工作空间”，主动进行“回顾性整合”，这正是高级智能体能力的体现。 *   **推理/规划**: 论文聚焦于解决 `long-horizon tasks`（长时程任务）的挑战，这与智能体的 **`Planning`**（规划）能力紧密相关。有效的长时程规划离不开强大的记忆和上下文管理能力，因此该工作直接服务于提升智能体的规划水平。 3.  **排除标准（第三步）：未触发。** 论文的主要贡献是关于智能体的架构和能力提升，而非安全、对齐或多模态。它研究的“Web Agent”虽然涉及网页环境，但核心是智能体的内部工作机制，而不是视觉或多模态感知本身。 4.  **特殊和模糊情况（第四步）：符合保留规则。** 论文讨论的推理和规划是明确在 **智能体框架** 下进行的（与ReAct对比），旨在解决智能体在执行复杂任务时的上下文瓶颈问题，而非提升LLM本身的基础数学或逻辑推理能力。因此，它属于应保留的“智能体如何进行规划”的范畴。 **总结**: 论文《AgentFold》的核心创新在于提出了一种新的智能体架构，通过引入“折叠”机制来主动管理上下文，从而显著增强了LLM智能体的记忆和自我反思能力，以解决长时程任务中的关键挑战。这完全契合你关于“单智能体”方向中“记忆”和“自我反思”的研究焦点，是一篇高质量的前沿论文。"
    },
    {
        "index": "#9",
        "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision",
        "link": "/arxiv/2510.24694",
        "arxiv_id": "2510.24694",
        "authors": "Yida Zhao, Kuan Li, Xixi Wu, Liwen Zhang, Dingchu Zhang, Baixuan Li, Maojia Song, Zhuo Chen, Chenxi Wang, Xinyu Wang, Kewei Tu, Pengjun Xie, Jingren Zhou, Yong Jiang",
        "summary": "LLM-based search agents are increasingly trained on entity-centric synthetic data to solve complex, knowledge-intensive tasks. However, prevailing training methods like Group Relative Policy Optimization (GRPO) discard this rich entity information, relying instead on sparse, outcome-based rewards. This critical limitation renders them unable to distinguish informative \"near-miss\" samples-those with substantially correct reasoning but a flawed final answer-from complete failures, thus discarding valuable learning signals. We address this by leveraging the very entities discarded during training. Our empirical analysis reveals a strong positive correlation between the number of ground-truth entities identified during an agent's reasoning process and final answer accuracy. Building on this insight, we introduce Entity-aware Group Relative Policy Optimization (E-GRPO), a novel framework that formulates a dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect samples proportional to their entity match rate, enabling the model to effectively learn from these \"near-misses\". Experiments on diverse question-answering (QA) and deep research benchmarks show that E-GRPO consistently and significantly outperforms the GRPO baseline. Furthermore, our analysis reveals that E-GRPO not only achieves superior accuracy but also induces more efficient reasoning policies that require fewer tool calls, demonstrating a more effective and sample-efficient approach to aligning search agents.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.139463",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于**改进LLM智能体的训练和演化机制**。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断 (保留)** - 论文的本质是提出一种名为 **E-GRPO (Entity-aware Group Relative Policy Optimization)** 的新框架，用于更有效地训练和监督LLM搜索智能体。 - 它的核心贡献不是将智能体应用于某个新领域，而是**改进了智能体本身的学习和演化过程**。它解决了现有训练方法（如GRPO）无法从“near-miss”样本中学习的关键缺陷，这是一种对智能体学习机制的**根本性改进**。 - 因此，它完全符合“构建、改进或演化LLM智能体”的核心目标，应予以保留。 2.  **第二步：正面指标 (高度相关)** - **核心范式**: 论文明确研究 `LLM-based Agents`。 - **智能体能力**: 论文的核心贡献直接关联到智能体的多个核心能力： - `Tool Use`: 摘要明确指出，新方法能诱导出“更高效的推理策略，需要更少的工具调用”，这直接是对智能体工具使用能力的优化。 - `Self-Correction` / `Self-Improvement`: E-GRPO的核心机制——让智能体从“near-miss”样本中学习——本质上是一种更精细的**自我修正**和**自我完善**机制。它通过提供更密集的奖励信号，帮助智能体迭代其策略，这属于自我演化的范畴。 - **演化机制**: 论文的贡献 `E-GRPO` 是一种新的训练框架，其目标是实现更有效的 `Iterative Improvement`（迭代改进）和 `Self-Refine`（自我精炼）。 3.  **第三步：排除标准 (不适用)** - 论文的主要贡献不是关于安全、对齐、可解释性或多模态。虽然提到了 \"aligning search agents\"，但这里的 \"alignment\" 指的是任务层面的对齐（即让智能体的输出更符合正确答案），而非伦理或安全层面的对齐。因此，不触及任何排除标准。 4.  **第四步：处理特殊和模糊情况 (符合保留规则)** - **推理/规划**: 论文的研究对象是“搜索智能体”，其核心任务就是多步推理和规划。论文提出的E-GRPO框架通过改进奖励函数，优化了智能体的**推理策略**，使其更高效。这完全符合“保留”关于智能体如何进行规划和多步推理的论文的规则。 **总结**: 该论文的核心是提出一种新的训练框架（E-GRPO）来改进LLM搜索智能体的学习效率和能力。它直接触及了您研究焦点中的**单智能体**（优化工具使用和推理策略）和**自我演化**（通过改进的学习机制实现自我完善）两个方向。论文的贡献是方法论层面的，而非应用层面，因此与您的研究目标高度契合。"
    },
    {
        "index": "#7",
        "title": "WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking",
        "link": "/arxiv/2510.24697",
        "arxiv_id": "2510.24697",
        "authors": "Zhengwei Tao, Haiyang Shen, Baixuan Li, Wenbiao Yin, Jialong Wu, Kuan Li, Zhongwang Zhang, Huifeng Yin, Rui Ye, Liwen Zhang, Xinyu Wang, Pengjun Xie, Jingren Zhou, Yong Jiang",
        "summary": "Large Language Model (LLM)-based agents have emerged as a transformative approach for open-ended problem solving, with information seeking (IS) being a core capability that enables autonomous reasoning and decision-making. While prior research has largely focused on improving retrieval depth, we observe that current IS agents often suffer from low search efficiency, which in turn constrains overall performance. A key factor underlying this inefficiency is the sparsity of target entities in training tasks, which limits opportunities for agents to learn and generalize efficient search behaviors. To address these challenges, we propose WebLeaper, a framework for constructing high-coverage IS tasks and generating efficient solution trajectories. We formulate IS as a tree-structured reasoning problem, enabling a substantially larger set of target entities to be embedded within a constrained context. Leveraging curated Wikipedia tables, we propose three variants for synthesizing IS tasks, Basic, Union, and Reverse-Union, to systematically increase both IS efficiency and efficacy. Finally, we curate training trajectories by retaining only those that are simultaneously accurate and efficient, ensuring that the model is optimized for both correctness and search performance. Extensive experiments on both basic and comprehensive settings, conducted on five IS benchmarks, BrowserComp, GAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method consistently achieves improvements in both effectiveness and efficiency over strong baselines.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.138323",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断为“保留”。以下是详细的筛选过程和依据： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 `WebLeaper` 的新框架，其核心目标是**改进**LLM智能体在信息寻求任务上的效率和效果。它不是将现有智能体作为工具去解决一个外部领域问题，而是直接针对智能体本身的能力缺陷（搜索效率低）进行方法论上的创新。这完全符合“构建、改进或演化 LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文明确研究 `LLM-based Agents`。 - **智能体能力**: 论文的核心贡献在于提升智能体的 `Tool Use`（信息寻求/网络搜索）能力，并为此提出了一种新的 `Planning` 方法（将信息寻求构建为树状结构推理问题）。这直接命中了“单智能体”方向下的“规划”和“工具使用”子方向。 - **演化机制**: 虽然不是严格意义上的“自我演化”，但论文通过“筛选高效且准确的训练轨迹”来优化模型，这属于一种通过数据和反馈进行**迭代改进** 的机制，与演化思想有共通之处。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐、多模态与视觉等排除领域。它的焦点纯粹在于提升智能体的任务执行能力，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文将信息寻求构建为“树状结构推理问题”，这是一种典型的**智能体规划框架**。它不是在提升LLM底层的数学或逻辑推理能力，而是在为智能体设计一种更高效的多步任务执行和决策方法。因此，根据规则，这属于应保留的范畴。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种新的框架 `WebLeaper`，用于**改进**LLM智能体的规划和工具使用能力。它直接解决了现有智能体在执行复杂任务（信息寻求）时的效率瓶颈，属于对智能体核心能力的增强。因此，该论文精准地契合了您研究课题中的“单智能体”方向，特别是“规划”与“工具使用”子方向，应被**保留**。"
    },
    {
        "index": "#8",
        "title": "AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis",
        "link": "/arxiv/2510.24695",
        "arxiv_id": "2510.24695",
        "authors": "Xuanzhong Chen, Zile Qiao, Guoxin Chen, Liangcai Su, Zhen Zhang, Xinyu Wang, Pengjun Xie, Fei Huang, Jingren Zhou, Yong Jiang",
        "summary": "Training large language model agents on tasks at the frontier of their capabilities is key to unlocking advanced reasoning. We introduce a data synthesis approach inspired by the educational theory of the Zone of Proximal Development (ZPD), which defines this frontier as tasks an LLM cannot solve alone but can master with guidance. To operationalize this, we present the AgentFrontier Engine, an automated pipeline that synthesizes high-quality, multidisciplinary data situated precisely within the LLM's ZPD. This engine supports both continued pre-training with knowledge-intensive data and targeted post-training on complex reasoning tasks. From the same framework, we derive the ZPD Exam, a dynamic and automated benchmark designed to evaluate agent capabilities on these frontier tasks. We train AgentFrontier-30B-A3B model on our synthesized data, which achieves state-of-the-art results on demanding benchmarks like Humanity's Last Exam, even surpassing some leading proprietary agents. Our work demonstrates that a ZPD-guided approach to data synthesis offers a scalable and effective path toward building more capable LLM agents.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.138857",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个特定领域的问题，而是提出了一种**构建和改进LLM智能体的新方法论**。其核心贡献是`AgentFrontier Engine`，一个用于合成训练数据的自动化框架，其目标是系统性地提升LLM智能体的能力。这直接命中了“改进LLM智能体”这一核心目标。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: 论文标题和摘要中反复出现 `LLM Agents`。 - **演化机制**: 论文的核心思想——通过在“最近发展区”内合成数据来训练智能体——是一种**迭代改进**和**能力扩展**的机制。这与“自我演化”中“通过经验进行自我完善和迭代”的精神高度契合，尽管这里的“经验”是由外部框架精心合成的。它描述了智能体能力如何从一个层级向更高层级演化的路径。 - **智能体能力**: 论文旨在提升智能体的 `advanced reasoning` 和 `complex reasoning` 能力，这是智能体在执行复杂任务时的关键能力。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性，也未聚焦于多模态或视觉。因此，它完全避开了所有的排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文虽然涉及推理，但它并非提出一种新的CoT变体或微调方法来提升LLM的基础数学能力。相反，它关注的是**如何为智能体构建一个高效的训练课程**，使其能够掌握更复杂的推理任务。这是一种关于智能体“学习如何学习”的元层面方法，属于智能体框架的构建和改进范畴，因此应该保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种名为`AgentFrontier Engine`的新框架，通过一种受教育学理论启发的数据合成方法，来系统性地训练和提升LLM智能体的能力边界。这完全符合您“构建、改进或演化LLM智能体”的核心研究目标，特别是与“自我演化”方向中的“迭代改进”和“能力扩展”思想高度一致。因此，这篇论文应该被保留。"
    },
    {
        "index": "#3",
        "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents",
        "link": "/arxiv/2510.24702",
        "arxiv_id": "2510.24702",
        "authors": "Yueqi Song, Ketan Ramaneti, Zaid Sheikh, Ziru Chen, Boyu Gou, Tianbao Xie, Yiheng Xu, Danyang Zhang, Apurva Gandhi, Fan Yang, Joseph Liu, Tianyue Ou, Zhihao Yuan, Frank Xu, Shuyan Zhou, Xingyao Wang, Xiang Yue, Tao Yu, Huan Sun, Yu Su, Graham Neubig",
        "summary": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.129399",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心贡献是提出了“Agent Data Protocol (ADP)”，一个轻量级的表示语言，用于统一和标准化各种异构的LLM智能体训练数据集。 - **是否符合要求**: 这篇论文的本质是关于**改进LLM智能体**的**方法论**。它没有提出一个新的智能体架构或演化算法，但它解决了构建和改进LLM智能体过程中的一个关键瓶颈：训练数据的碎片化和标准化问题。通过提供一个统一的“中间语言”，ADP使得对智能体进行更有效、可扩展和可复现的监督微调（SFT）成为可能，从而直接促成了更强大的智能体的构建。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”这一核心目标。它不属于“非演化型应用”（因为它关注的是智能体本身的训练，而非应用），也不属于“非Agentic的推理”或“基础设施”（它关注的是数据层面的方法论，而非模型部署或硬件加速）。 2.  **第二步：正面指标** - 论文明确涉及了多个核心关注点。摘要中提到ADP能够捕获包括 `API/tool use`、`browsing`、`coding`、`software engineering` 和 `general agentic workflows` 在内的多种任务。这些都是**单智能体**研究中的核心能力，特别是`Tool Use`和`Planning`（隐含在agentic workflows中）。因此，这篇论文为我的第一个研究方向“单智能体”提供了重要的基础性支持。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题。 - 论文也未将 `Vision` 或多模态作为研究核心，其关注点是文本、代码和API交互的数据格式。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文不是提出一种新的推理或规划框架，而是为训练具备这些能力的智能体提供了标准化的“燃料”（数据）。它属于支持智能体推理/规划能力发展的基础方法论，因此应该保留。 - **自我演化**: 论文采用的是监督微调（SFT），这是一种静态的改进方式，而非动态的“自我演化”机制。但这并不影响其被保留，因为它属于“改进LLM智能体”的范畴。 **最终决策**: 综合以上分析，尽管这篇论文没有提出一个全新的智能体架构或自我演化算法，但它提出了一种**基础性的方法论（ADP协议）**，旨在解决LLM智能体训练中的核心数据挑战。这项工作直接赋能了更强大、更有效的LLM智能体的**构建与改进**，是推动整个Agentic AI领域发展的关键基础设施之一。因此，它高度契合我“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标。**保留**。"
    },
    {
        "index": "#10",
        "title": "SPICE: Self-Play In Corpus Environments Improves Reasoning",
        "link": "/arxiv/2510.24684",
        "arxiv_id": "2510.24684",
        "authors": "Bo Liu, Chuanyang Jin, Seungone Kim, Weizhe Yuan, Wenting Zhao, Ilia Kulikov, Xian Li, Sainbayar Sukhbaatar, Jack Lanchantin, Jason Weston",
        "summary": "Self-improving systems require environmental interaction for continuous adaptation. We introduce SPICE (Self-Play In Corpus Environments), a reinforcement learning framework where a single model acts in two roles: a Challenger that mines documents from a large corpus to generate diverse reasoning tasks, and a Reasoner that solves them. Through adversarial dynamics, the Challenger creates an automatic curriculum at the frontier of the Reasoner's capability, while corpus grounding provides the rich, near-inexhaustible external signal necessary for sustained improvement. Unlike existing ungrounded self-play methods that offer more limited benefits, SPICE achieves consistent gains across mathematical (+8.9%) and general reasoning (+9.8%) benchmarks on multiple model families. Our analysis reveals how document grounding is a key ingredient in SPICE to continuously generate its own increasingly challenging goals and achieve them, enabling sustained self-improvement.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.140072",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了“自我演化”和“Agentic AI”两个核心方向。 1.  **第一步：核心判断——保留** - 论文的核心是提出一个名为SPICE的新**框架**，该框架通过自我博弈的机制让LLM实现**持续的自我改进**。这完全符合“构建、改进或演化 LLM智能体”的核心目标。 - 它不是将现有智能体作为工具应用到特定领域，而是提出了一种**通用的自我演化方法论**。 - 它虽然提升了推理能力，但其方法是构建一个包含“挑战者”和“推理者”两个角色的智能体系统，通过环境交互和对抗性动态来实现，这属于Agentic层面的框架，而非单纯的LLM基础推理优化。 2.  **第二步：正面指标——高度匹配** - 论文摘要中明确包含了多个核心关键词：`Self-improving systems` (自我演化), `Self-Play` (自我演化/多智能体博弈), `Challenger` 和 `Reasoner` (Agentic角色), `automatic curriculum` (规划), `sustained self-improvement` (自我演化)。这些指标表明论文与您的研究焦点高度相关。 3.  **第三步：排除标准——未触发** - 论文的主要贡献是关于智能体的自我演化机制，而非安全、对齐或多模态。因此，它没有被排除标准所覆盖。 4.  **第四步：处理特殊和模糊情况——符合核心规则** - **自我演化的应用**: 这篇论文是“自我演化”方向的典型范例。它提出了一种新的自我演化机制（通过在语料库环境中的自我博弈来生成课程），即使其效果在数学和通用推理基准上测试，其核心贡献依然是这个**机制本身**，而非应用。根据您的规则，这种情况应该保留。 - **推理/规划**: 论文通过一个Agentic框架（挑战者生成任务，推理者解决任务）来提升推理能力。这完全符合“保留”的条件，即“关于智能体如何进行规划或在复杂任务中进行多步推理”，而不是仅仅改进LLM的底层推理能力。 **总结**: 论文《SPICE》的核心贡献是提出了一种新颖的、基于自我博弈的强化学习框架，使LLM智能体能够通过与语料库环境的交互，持续地自我完善和迭代。这精准地契合了您研究课题中的“自我演化”方向，并涉及了“单智能体”的规划和“多智能体”的博弈思想。因此，这篇论文是您应该保留的前沿研究。"
    },
    {
        "index": "#14",
        "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment",
        "link": "/arxiv/2510.24654",
        "arxiv_id": "2510.24654",
        "authors": "Pengcheng Qiu, Chaoyi Wu, Junwei Liu, Qiaoyu Zheng, Yusheng Liao, Haowen Wang, Yun Yue, Qianrui Fan, Shuai Zhen, Jian Wang, Jinjie Gu, Yanfeng Wang, Ya Zhang, Weidi Xie",
        "summary": "In this paper, we present a framework for training large language models (LLMs) as diagnostic agents with reinforcement learning, enabling them to manage multi-turn diagnostic processes, adaptively select examinations, and commit to final diagnoses. Unlike instruction-tuned models trained on static case summaries, our method acquires diagnostic strategies through interactive exploration and outcome-based feedback. Our contributions are fourfold: (i) We present DiagGym, a diagnostics world model trained with electronic health records that emits examination outcomes conditioned on patient history and recommended examination, serving as a virtual clinical environment for realistic diagnosis training and evaluation; (ii) We train DiagAgent via end-to-end, multi-turn reinforcement learning to learn diagnostic policies that optimize both information yield and diagnostic accuracy; (iii) We introduce DiagBench, a diagnostic benchmark comprising 750 cases with physician-validated examination recommendations and 99 cases annotated with 973 physician-written rubrics on diagnosis process; (iv) we demonstrate superior performance across diverse diagnostic settings. DiagAgent significantly outperforms 10 state-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two prompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34% higher diagnostic accuracy and 44.03% improvement in examination recommendation hit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic accuracy and 23.09% boost in examination recommendation F1 score. In rubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by 7.1% in weighted rubric score. These findings indicate that learning policies in interactive clinical environments confers dynamic and clinically meaningful diagnostic management abilities unattainable through passive training alone.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.147934",
        "filter_reason": "这篇论文完全符合你的研究范围，核心贡献在于提出了一种让LLM智能体进行“自我演化”的新方法。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的本质不是简单地将LLM应用于医疗领域，而是**构建了一个全新的框架**来训练和演化LLM智能体。其核心贡献包括： - **DiagGym**: 一个虚拟临床环境，作为智能体交互和学习的“世界模型”。 - **DiagAgent**: 通过**端到端、多轮强化学习**训练的诊断智能体。 - 这种通过“interactive exploration and outcome-based feedback”（交互式探索和基于结果的反馈）来学习诊断策略的方法，是典型的**自我演化**过程。它超越了静态的指令微调，让智能体在环境中动态地学习和完善自身能力。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** - 论文包含了多个你的核心关注点： - **自我演化**: 核心机制是强化学习，通过环境反馈进行迭代优化，完全符合`Self-Evolving`和`Iterative Improvement`的定义。 - **单智能体**: 论文聚焦于单个智能体的能力构建，包括`Planning`（学习诊断策略）、`Tool Use`（自适应地选择检查项目作为工具）。 - **核心范式**: 论文是关于`LLM-based Agents`的构建和演化。 3.  **第三步：排除标准——未触发** - 论文的主要贡献是提升智能体的诊断能力和效率，而非`Safety`、`Alignment`或`Interpretability`。 - 论文不涉及`Vision`或多模态内容。 4.  **第四步：处理特殊和模糊情况——完美契合例外规则** - 这篇论文是**“自我演化的应用”**这一例外情况的绝佳范例。虽然它应用在临床诊断这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**（即通过强化学习在虚拟环境中训练智能体策略）。根据你的规则，这种情况应该保留。论文的价值在于其方法论，而非应用领域本身。 **最终决策**: 这篇论文的核心是提出了一种通过强化学习让LLM智能体在模拟环境中进行交互式学习、从而实现自我演化的框架。它直接命中了你研究课题中的“自我演化”和“单智能体”方向，并且其贡献是方法论层面的，而非简单的应用。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#33",
        "title": "Iterative Critique-Refine Framework for Enhancing LLM Personalization",
        "link": "/arxiv/2510.24469",
        "arxiv_id": "2510.24469",
        "authors": "Durga Prasad Maram, Dhruvin Gandhi, Zonghai Yao, Gayathri Akkinapalli, Franck Dernoncourt, Yu Wang, Ryan A. Rossi, Nesreen K. Ahmed",
        "summary": "Personalized text generation requires models not only to produce coherent text but also to align with a target user's style, tone, and topical focus. Existing retrieval-augmented approaches such as LaMP and PGraphRAG enrich profiles with user and neighbor histories, but they stop at generation and often yield outputs that drift in tone, topic, or style. We present PerFine, a unified, training-free critique-refine framework that enhances personalization through iterative, profile-grounded feedback. In each iteration, an LLM generator produces a draft conditioned on the retrieved profile, and a critic LLM - also conditioned on the same profile - provides structured feedback on tone, vocabulary, sentence structure, and topicality. The generator then revises, while a novel knockout strategy retains the stronger draft across iterations. We further study additional inference-time strategies such as Best-of-N and Topic Extraction to balance quality and efficiency. Across Yelp, Goodreads, and Amazon datasets, PerFine consistently improves personalization over PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5 refinement iterations, and scalability with increasing critic size. These results highlight that post-hoc, profile-aware feedback offers a powerful paradigm for personalized LLM generation that is both training-free and model-agnostic.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.162334",
        "filter_reason": "这篇论文符合我的研究范围，应被保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个名为 \"PerFine\" 的**迭代批判-优化框架**。这并非简单地将LLM应用于个性化领域，而是构建了一个**新的方法论**，使LLM能够通过结构化的反馈循环来改进其输出。这个框架包含一个生成器和一个批判者，通过多轮的“生成-批判-优化”过程来提升结果。这本质上是一种**自我完善和迭代**的机制，完全符合“自我演化”的核心定义。因此，它不属于“非演化型应用”的排除范畴。 2.  **正面指标 (第二步):** 论文明确包含了多个核心关注点： *   **自我演化:** 论文的标题和摘要都强调了 \"Iterative\" 和 \"Refine\"，这正是自我演化的核心特征。 *   **自我反思/自我修正:** \"critique-refine\" 机制是典型的自我反思和自我修正过程。一个LLM（批判者）对另一个LLM（生成器）的输出进行评估和反馈，后者据此进行改进。 *   **迭代改进:** 论文明确研究了通过3-5轮的迭代来获得稳定提升，这是迭代改进的直接体现。 3.  **排除标准 (第三步):** 论文的研究焦点是提升个性化生成的质量和一致性，并未涉及安全、对齐、可解释性或视觉等多模态问题。因此，没有触发任何排除标准。 4.  **特殊和模糊情况 (第四步):** 这篇论文完美地契合了“自我演化的应用”这一例外规则。虽然它的应用场景是“个性化文本生成”（一个特定领域），但其**核心贡献是提出了一种新的“自我演化”机制**。根据筛选规则，即使应用在特定领域，只要核心是提出新的自我演化机制，就应该保留。 **总结:** 论文的核心是构建一个让LLM通过迭代反馈进行自我优化的框架，这与我研究目标中的“自我演化”方向高度一致。它不是简单的应用，而是对智能体能力（特别是自我反思和修正）的一种方法论创新。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#23",
        "title": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization",
        "link": "/arxiv/2510.24592",
        "arxiv_id": "2510.24592",
        "authors": "Guoxin Chen, Jing Wu, Xinjie Chen, Wayne Xin Zhao, Ruihua Song, Chengxi Li, Kai Fan, Dayiheng Liu, Minpeng Liao",
        "summary": "Autoformalization, which translates natural language mathematics into machine-verifiable formal statements, is critical for using formal mathematical reasoning to solve math problems stated in natural language. While Large Language Models can generate syntactically correct formal statements, they often fail to preserve the original problem's semantic intent. This limitation arises from the LLM approaches' treating autoformalization as a simplistic translation task which lacks mechanisms for self-reflection and iterative refinement that human experts naturally employ. To address these issues, we propose ReForm, a Reflective Autoformalization method that tightly integrates semantic consistency evaluation into the autoformalization process. This enables the model to iteratively generate formal statements, assess its semantic fidelity, and self-correct identified errors through progressive refinement. To effectively train this reflective model, we introduce Prospective Bounded Sequence Optimization (PBSO), which employs different rewards at different sequence positions to ensure that the model develops both accurate autoformalization and correct semantic validations, preventing superficial critiques that would undermine the purpose of reflection. Extensive experiments across four autoformalization benchmarks demonstrate that ReForm achieves an average improvement of 17.2 percentage points over the strongest baselines. To further ensure evaluation reliability, we introduce ConsistencyCheck, a benchmark of 859 expert-annotated items that not only validates LLMs as judges but also reveals that autoformalization is inherently difficult: even human experts produce semantic errors in up to 38.5% of cases.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.152259",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于“自动形式化”这一特定领域，而是提出了一种名为 **ReForm** 的**新方法论框架**。该框架的核心是让模型具备“自我反思”和“迭代完善”的能力，以解决现有方法在语义保真度上的缺陷。这本质上是在**构建和改进一个具备自我演化能力的LLM智能体**，而不是一个非演化型的应用。因此，它通过了第一步的核心判断。 2.  **第二步：正面指标——高度匹配** 论文摘要中明确包含了多个您关注的核心正面指标： *   **自我演化**: 论文的核心是 `Reflective`（反思性）方法，并明确提到了 `self-reflection`、`iterative refinement`（迭代完善）和 `self-correct`（自我修正）。这直接对应了您研究焦点中的“自我演化”方向。 *   **智能体能力**: ReForm框架包含“生成 -> 评估 -> 修正”的循环，这是一种典型的智能体工作流，涉及了 `Self-Correction` 和 `Self-Reflection` 能力。 3.  **第三步：排除标准——未触发** 论文的研究焦点是提升智能体在特定任务上的表现和语义一致性，其主要贡献不涉及安全、对齐、可解释性或多模态等领域。因此，第三步的排除标准不适用。 4.  **第四步：处理特殊和模糊情况——明确符合保留规则** *   **推理/规划**: 论文提出的ReForm框架是一个典型的智能体推理框架，它通过反思和修正来处理复杂任务（自动形式化），而不是仅仅提升LLM的基础数学或逻辑推理能力。这符合“保留”规则。 *   **自我演化的应用**: 这篇论文是“自我演化应用”规则下的一个完美范例。虽然它应用在“数学自动形式化”这个特定领域，但其**核心贡献是ReForm这个全新的“自我演化”机制本身**。根据您的规则，“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”。因此，这篇论文必须保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种名为ReForm的、具备自我反思和自我修正能力的LLM智能体框架。它直接贡献于“单智能体”和“自我演化”这两个核心研究方向，提供了关于如何构建和演化智能体能力的新见解。因此，这篇论文与您的研究课题高度相关，应被筛选保留。"
    },
    {
        "index": "#43",
        "title": "Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning",
        "link": "/arxiv/2510.24320",
        "arxiv_id": "2510.24320",
        "authors": "Zhiheng Xi, Jixuan Huang, Xin Guo, Boyang Hong, Dingwen Yang, Xiaoran Fan, Shuo Li, Zehui Chen, Junjie Ye, Siyu Yuan, Zhengyin Du, Xuesong Yao, Yufei Xu, Jiecao Chen, Rui Zheng, Tao Gui, Qi Zhang, Xuanjing Huang",
        "summary": "Training critiquing language models to assess and provide feedback on model outputs is a promising way to improve LLMs for complex reasoning tasks. However, existing approaches typically rely on stronger supervisors for annotating critique data. To address this, we propose Critique-RL, an online RL approach for developing critiquing language models without stronger supervision. Our approach operates on a two-player paradigm: the actor generates a response, the critic provides feedback, and the actor refines the response accordingly. We first reveal that relying solely on indirect reward signals from the actor's outputs for RL optimization often leads to unsatisfactory critics: while their helpfulness (i.e., providing constructive feedback) improves, the discriminability (i.e., determining whether a response is high-quality or not) remains poor, resulting in marginal performance gains. To overcome this, Critique-RL adopts a two-stage optimization strategy. In stage I, it reinforces the discriminability of the critic with direct rule-based reward signals; in stage II, it introduces indirect rewards based on actor refinement to improve the critic's helpfulness, while maintaining its discriminability via appropriate regularization. Extensive experiments across various tasks and models show that Critique-RL delivers substantial performance improvements. For example, it achieves a 9.02% gain on in-domain tasks and a 5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.172608",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接对应了您设定的“自我演化”方向。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM作为工具应用，也不是提升LLM的基础推理能力，而是提出了一种名为 **Critique-RL** 的新方法论/框架。该框架的核心是训练一个“评判者”模型，使其能够为“行动者”模型提供反馈，并驱动行动者进行自我完善。这个“行动者生成 -> 评判者反馈 -> 行动者完善”的闭环，正是构建和改进LLM智能体的典型范式，属于智能体自我演化的核心机制。 2.  **第二步：正面指标** - 论文内容高度匹配您的核心关注点： - **核心范式**: 论文虽然没有直接使用 `Agentic AI` 等词汇，但其“两玩家范式”是典型的智能体交互框架。 - **自我演化机制**: 这是最关键的匹配点。论文的核心贡献就是提出一种新的 **`Self-Improvement`** (自我完善) 和 **`Iterative Improvement`** (迭代改进) 机制。通过强化学习训练一个专门的评判者来驱动这一过程，这比简单的自我反思更进了一步，形成了一个结构化的演化循环。 - **智能体能力**: 论文中的 `critique` (评判) 和 `refine` (完善) 过程，是 **`Self-Correction`** (自我修正) 和 **`Self-Reflection`** (自我反思) 能力的具体实现和深化。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。其主要目标是提升模型在复杂任务上的性能，而非研究 `Safety`、`Alignment` 或 `Interpretability`。同时，它是一个纯文本模型的研究，不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化”研究的一个绝佳范例。它的核心贡献就是提出了一种新的“自我演化”机制（Critique-RL），而不是将某个已有的机制应用到特定领域。因此，它完全符合保留规则。 - **推理/规划**: 论文虽然提到了“复杂推理任务”，但其方法并非直接优化LLM的数学或逻辑推理能力，而是通过一个智能体框架（评判者驱动完善）来间接提升在复杂任务上的表现。这符合“保留”关于智能体推理/规划框架的规则。 **最终决策**: 这篇论文的核心贡献是 **Critique-RL**，一个通过两阶段强化学习来训练“评判者”模型，从而驱动LLM智能体进行“生成-评判-完善”的自我演化循环的新框架。这完全契合您研究目标中的 **“自我演化”** 方向，特别是关于智能体如何通过反馈进行自我完善和迭代的子方向。因此，这篇论文应被 **保留**。"
    },
    {
        "index": "#44",
        "title": "Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards",
        "link": "/arxiv/2510.24302",
        "arxiv_id": "2510.24302",
        "authors": "Shangyu Xing, Siyuan Wang, Chenyuan Yang, Xinyu Dai, Xiang Ren",
        "summary": "Reinforcement Learning with Verifiable Rewards (RLVR), particularly with algorithms like Group Relative Policy Optimization (GRPO), has proven highly effective in enhancing the reasoning capabilities of large language models. However, a critical bottleneck in current pipelines lies in the limited diversity of sampled trajectories during group rollouts. Homogeneous trajectories and their associated rewards would diminish the return signals for policy updates, thereby hindering effective policy learning. This lack of diversity stems primarily from token-level stochastic sampling, where local variations are likely to collapse into near-identical reasoning paths. To address this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a novel rollout strategy designed to explicitly promotes trajectory-level diversity by enforcing branching into different candidate tokens likely to yield distinct continuations. Specifically, LATR iteratively operates in three stages: (1) branching at high-uncertainty generation steps, (2) performing lookahead simulation for each new branch, and (3) pruning branches that exhibits prolonged similarity during simulation. Compared with stochastic Sampling, LATR accelerates policy learning by 131% on average and improves final pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy Optimization (DAPO) algorithms across different reasoning tasks. Our code and data are publicly available at https://github.com/starreeze/latr.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.178197",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于提出了一种新的方法来**演化和改进LLM智能体**。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM作为工具应用，也不是提升LLM的基础推理能力，而是提出了一种名为“Lookahead Tree-Based Rollouts (LATR)”的新颖rollout策略。这个策略旨在**改进强化学习训练过程中LLM智能体的学习效率**。它通过增强轨迹级别的探索多样性，直接加速了策略的学习和迭代，这本质上是对LLM智能体**自我演化**机制的一种改进。因此，它完全符合“构建、改进或演化 LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文的核心贡献与多个正面指标高度相关： - **自我演化**: 论文的核心是加速“policy learning”（策略学习），这正是智能体通过环境反馈进行自我完善和迭代的过程。论文明确指出其方法“accelerates policy learning by 131%”。 - **规划**: LATR方法本身是一种高级的规划与探索策略。它通过“branching”（分支）、“lookahead simulation”（前瞻模拟）和“pruning”（剪枝）来构建和搜索一个行为树，这与思维树等智能体规划范式在思想上是一致的，但应用在了训练阶段。 - **迭代改进**: 整个强化学习框架就是迭代改进的过程，而LATR是优化这一过程的关键技术。 3.  **第三步：排除标准** - 论文完全不涉及安全与对齐、多模态与视觉等排除领域。其研究焦点纯粹集中在提升智能体的学习效率和性能上。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它不是在研究如何让LLM在单次推理中表现更好（如新的CoT变体），而是在研究如何让LLM智能体在**与环境交互的学习过程中**更有效地探索和规划。LATR是一种用于**训练**智能体进行更好推理的元方法，属于智能体框架的改进，而非基础推理能力的提升。 **核心依据总结**: 该论文的核心贡献是LATR，一种用于强化学习训练的新型rollout策略。它通过引入树搜索机制来增加智能体在学习过程中探索的多样性，从而**加速了LLM智能体的自我演化（策略学习）过程**。这直接命中了你研究课题中的“自我演化”和“单智能体（规划/探索）”方向。它不是应用型研究，而是对智能体底层学习机制的深刻改进，因此是一篇高度相关的前沿论文。"
    },
    {
        "index": "#57",
        "title": "Reinforcement Learning for Long-Horizon Multi-Turn Search Agents",
        "link": "/arxiv/2510.24126",
        "arxiv_id": "2510.24126",
        "authors": "Vivek Kalyan, Martin Andrews",
        "summary": "Large Language Model (LLM) agents can leverage multiple turns and tools to solve complex tasks, with prompt-based approaches achieving strong performance. This work demonstrates that Reinforcement Learning (RL) can push capabilities significantly further by learning from experience. Through experiments on a legal document search benchmark, we show that our RL-trained 14 Billion parameter model outperforms frontier class models (85% vs 78% accuracy). In addition, we explore turn-restricted regimes, during training and at test-time, that show these agents achieve better results if allowed to operate over longer multi-turn horizons.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.190370",
        "filter_reason": "这篇论文符合研究范围，应被保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种使用强化学习（RL）来训练和改进LLM智能体的新方法。这完全符合“构建、改进或演化LLM智能体”的核心目标。它并非简单地将现有智能体作为工具应用于法律领域，而是提出了一种能让智能体“从经验中学习”并变得更强的新训练范式。因此，它不属于“非演化型应用”的排除范畴。 2.  **正面指标 (第二步):** 论文命中了多个核心正面指标： *   **核心范式:** 论文明确研究 `LLM-based Agents`。 *   **智能体能力:** 摘要中提到了 `Tool Use`（利用工具）和 `Multi-Turn`（多轮交互），这直接关联到智能体的规划和执行能力。 *   **演化机制:** 论文的核心是使用 `Reinforcement Learning` 让智能体通过经验进行 `Self-Improvement`（自我完善），这正是“自我演化”方向的典型体现。 3.  **排除标准 (第三步):** 论文的研究焦点是提升智能体的任务执行能力（准确率），不涉及安全、对齐、可解释性或视觉多模态等排除领域。 4.  **特殊和模糊情况 (第四步):** *   **自我演化的应用:** 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它在一个特定的法律搜索基准上进行测试，但其核心贡献是“一种用于自我演化的RL训练机制”，而不是“一个法律搜索智能体”。根据筛选规则，这种提出新演化机制的论文应该被保留。 *   **推理/规划:** 论文研究的 `Long-Horizon Multi-Turn Search` 属于智能体在复杂任务中的多步规划和推理，而非提升LLM本身的基础数学或逻辑能力，因此符合保留条件。 **总结:** 论文的核心贡献在于提出了一种通过强化学习来**改进和演化**LLM智能体能力的新方法论，使其在多轮、长周期的任务中表现更佳。这直接命中了研究课题中的“单智能体”（工具使用、规划）和“自我演化”两个核心方向，因此是一篇高度相关且应被保留的前沿论文。"
    },
    {
        "index": "#58",
        "title": "Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks",
        "link": "/arxiv/2510.24102",
        "arxiv_id": "2510.24102",
        "authors": "Yihan Wang, Peiyu Liu, Runyu Chen, Jiaxing Pu, Wei Xu",
        "summary": "Text-to-SQL technology has evolved rapidly, with diverse academic methods achieving impressive results. However, deploying these techniques in real-world systems remains challenging due to limited integration tools. Despite these advances, we introduce Squrve, a unified, modular, and extensive Text-to-SQL framework designed to bring together research advances and real-world applications. Squrve first establishes a universal execution paradigm that standardizes invocation interfaces, then proposes a multi-actor collaboration mechanism based on seven abstracted effective atomic actor components. Experiments on widely adopted benchmarks demonstrate that the collaborative workflows consistently outperform the original individual methods, thereby opening up a new effective avenue for tackling complex real-world queries. The codes are available at https://github.com/Satissss/Squrve.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.191144",
        "filter_reason": "这篇论文符合我的研究范围，应被保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于Text-to-SQL领域，而是提出了一个名为Squrve的**新框架**。该框架的核心创新点在于其**“multi-actor collaboration mechanism”（多智能体协作机制）**。这直接对应了我研究目标中的“多智能体”方向。论文的本质是构建一个由多个“actor”（可视为智能体）协同工作的系统来解决复杂任务，而不是单个智能体的简单应用。 2.  **第二步：正面指标** - 论文明确包含了我的核心关注点。摘要中提到的 `multi-actor collaboration mechanism`、`collaborative workflows` 和 `atomic actor components` 等术语，直接命中了正面指标中的 `Multi-Agent Systems (MAS)` 和 `Collaboration`。这表明论文的研究内容与我的“多智能体”方向高度相关。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等排除领域。其焦点是智能体的协作机制，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的多智能体协作机制本质上是一种更高级的规划和执行策略。它通过多个专门化的智能体协同工作来分解和解决复杂的Text-to-SQL查询，这属于智能体层面的规划和推理，而非提升LLM本身的基础推理能力，因此符合保留条件。 - **自我演化的应用**: 此处不适用。 **最终决策**: 综合分析，这篇论文的核心贡献是提出了一种新颖的**多智能体协作框架**，用于解决复杂的Text-to-SQL任务。尽管其应用场景是Text-to-SQL，但其方法论——即如何设计、构建和验证一个多智能体协作系统——完全符合我“LLM智能体及其演化”课题中关于“多智能体”的研究焦点。它不是对现有智能体的简单应用，而是对智能体系统架构的创新，因此是高度相关的前沿论文。"
    },
    {
        "index": "#66",
        "title": "TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents",
        "link": "/arxiv/2510.24014",
        "arxiv_id": "2510.24014",
        "authors": "Yizhu Jiao, Sha Li, Sizhe Zhou, Heng Ji, Jiawei Han",
        "summary": "The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE TEXT2DB that emphasizes the integration of IE output and the target database (or knowledge base). Given a user instruction, a document set, and a database, our task requires the model to update the database with values from the document set to satisfy the user instruction. This task requires understanding user instructions for what to extract and adapting to the given DB/KB schema for how to extract on the fly. To evaluate this new task, we introduce a new benchmark featuring common demands such as data infilling, row population, and column addition. In addition, we propose an LLM agent framework OPAL (Observe-PlanAnalyze LLM) which includes an Observer component that interacts with the database, the Planner component that generates a code-based plan with calls to IE models, and the Analyzer component that provides feedback regarding code quality before execution. Experiments show that OPAL can successfully adapt to diverse database schemas by generating different code plans and calling the required IE models. We also highlight difficult cases such as dealing with large databases with complex dependencies and extraction hallucination, which we believe deserve further investigation. Source code: https://github.com/yzjiao/Text2DB",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.210904",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建了一个新颖的LLM智能体框架。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断 (保留)** *   论文的本质是**构建一个LLM智能体框架**。摘要明确指出“we propose an LLM agent framework OPAL (Observe-Plan-Analyze LLM)”。这并非简单地将LLM作为工具应用于信息抽取（IE）领域，而是提出了一种新的、结构化的智能体方法论来解决该领域的挑战。因此，它不属于“非演化型应用”的排除范畴。 *   OPAL框架包含了智能体的核心组件：`Observer`（感知环境/数据库）、`Planner`（规划行动/生成代码）、`Analyzer`（反思/评估计划）。这表明其研究重点是智能体的工作机制，而非LLM本身的基础推理能力，因此不属于“非Agentic的推理”。 2.  **第二步：正面指标 (高度匹配)** *   **核心范式**: 论文明确提出了 `LLM-based Agents` 框架。 *   **智能体能力**: *   `Planning`: `Planner` 组件的核心功能就是生成基于代码的执行计划。 *   `Tool Use / Tool Augmentation`: `Planner` 生成的计划会调用IE模型作为工具，`Observer` 组件与数据库交互，这些都是典型的工具使用行为。 *   `Self-Correction / Self-Reflection`: `Analyzer` 组件在代码执行前提供反馈，这是一种明确的自我反思和修正机制，旨在提高执行质量。 3.  **第三步：排除标准 (未触发)** *   论文的主要贡献是OPAL框架，而不是安全、对齐或可解释性。虽然摘要中提到了“extraction hallucination”，但它是作为框架未来需要解决的挑战被提出，并非论文的核心研究内容。因此，不触发排除标准。 *   论文不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: OPAL框架的 `Observe-Plan-Analyze` 循环是一个典型的智能体在复杂任务中进行多步推理和规划的范例。它超越了简单的链式思考，构建了一个包含感知、规划、行动和反思的完整闭环，完全符合“保留”条件。 **最终决策**: 这篇论文的核心贡献是**OPAL，一个用于解决信息抽取与数据库集成问题的LLM智能体框架**。它系统地研究了智能体如何通过规划、工具使用和自我反思来适应动态环境（不同的数据库模式）。这完全契合您研究目标中的“单智能体”方向，特别是关于智能体的规划、工具使用和自我反思等子方向。因此，这篇论文应该被保留。"
    },
    {
        "index": "#63",
        "title": "Success and Cost Elicit Convention Formation for Efficient Communication",
        "link": "/arxiv/2510.24023",
        "arxiv_id": "2510.24023",
        "authors": "Saujas Vaduguru, Yilun Hua, Yoav Artzi, Daniel Fried",
        "summary": "Humans leverage shared conversational context to become increasingly successful and efficient at communicating over time. One manifestation of this is the formation of ad hoc linguistic conventions, which allow people to coordinate on short, less costly utterances that are understood using shared conversational context. We present a method to train large multimodal models to form conventions, enabling efficient communication. Our approach uses simulated reference games between models, and requires no additional human-produced data. In repeated reference games involving photographs and tangram images, our method enables models to communicate efficiently with people: reducing the message length by up to 41% while increasing success by 15% over the course of the interaction. Human listeners respond faster when interacting with our model that forms conventions. We also show that training based on success or cost alone is insufficient - both are necessary to elicit convention formation.",
        "subjects": "Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.209049",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献精准地落在“多智能体”和“自我演化”的交叉点上。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具去解决一个外部领域问题，而是提出了一种**新的训练方法**，旨在让智能体（模型）在交互过程中**演化出新的能力**——形成语言约定。这直接对应了您筛选标准中的“构建、改进或演化 LLM智能体的方法论或新框架”。论文的核心是关于智能体如何学习和改变其行为，而非应用本身。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标，证明其高度相关： - **多智能体**: 论文明确使用了“simulated reference games between models”（模型间的模拟参考游戏），这是多智能体系统研究的经典范式。 - **通信**: 整篇论文的主题就是“efficient communication”（高效通信）和“convention formation”（约定形成）。 - **协作/协调**: 摘要中提到“coordinate on short, less costly utterances”（协调简短、低成本的表述），这是智能体协作的体现。 - **自我演化/迭代改进**: 论文的核心是智能体“over time”（随时间推移）变得“increasingly successful and efficient”（日益成功和高效），这完全符合自我演化的定义。训练过程本身就是一种迭代改进机制。 3.  **第三步：排除标准** - 论文不涉及安全、对齐等排除主题。 - 值得注意的是，论文提到了“large multimodal models”和“photographs”。根据您的规则，这属于一个需要仔细判断的点。然而，这里的视觉信息（照片、七巧板图像）是作为智能体之间进行通信游戏的**环境和感知对象**，而不是研究的核心。论文的核心贡献并非改进视觉理解能力，而是研究智能体如何就它们所“看到”的内容**演化出高效的通信协议**。因此，这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外情况，不应被排除。 4.  **第四步：处理特殊和模糊情况** - 论文完美契合“自我演化的应用”这一例外规则。虽然它在一个特定的“参考游戏”场景中进行验证，但其核心贡献是提出了一种通用的、能让智能体自我演化的训练机制（基于成功和成本的联合优化来激发约定形成）。这种机制本身是您研究的焦点。 **最终决策**: 这篇论文的核心贡献在于提出了一种新颖的训练框架，使多智能体系统在重复交互中能够自发地演化出更高效的通信约定。它直接探讨了多智能体环境中的协作、通信与社会学习，并且其“随时间推移变得更高效”的特性明确地属于“自我演化”的范畴。因此，这篇论文是您研究课题“LLM智能体及其演化”中关于“多智能体”和“自我演化”方向的典型前沿研究，应予以保留。"
    },
    {
        "index": "#77",
        "title": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning",
        "link": "/arxiv/2510.23870",
        "arxiv_id": "2510.23870",
        "authors": "Marianne Menglin Liu, Sai Ashish Somayajula, Syed Fahad Allam Shah, Sujith Ravi, Dan Roth",
        "summary": "We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge 2025, a bilingual benchmark requiring complex reasoning such as arithmetic, commonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding the second-best system by more than 6% in execution accuracy (EX), with 55.0% in English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA). Our system follows an agentic framework with two components: Planner agent that generates stepwise natural language plans, and SQL agent that converts these plans into executable SQL. Since SQL agent reliably adheres to the plan, our refinements focus on the planner. Unlike prior methods that rely on multiple sub-agents for planning and suffer from orchestration overhead, we introduce a feedback-guided meta-prompting strategy to refine a single planner. Failure cases from a held-out set are clustered with human input, and an LLM distills them into corrective guidelines that are integrated into the planner's system prompt, improving generalization without added complexity. For the multilingual scenario, to address transliteration and entity mismatch issues, we incorporate entity-linking guidelines that generate alternative surface forms for entities and explicitly include them in the plan. Finally, we enhance reliability through plan diversification: multiple candidate plans are generated for each query, with the SQL agent producing a query for each plan, and final output selected via majority voting over their executions.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-27",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.222221",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进一个具有自我演化能力的LLM智能体框架。 以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于NL2SQL任务，而是提出了一种名为OraPlan-SQL的**智能体框架**。摘要明确指出“Our system follows an agentic framework with two components: Planner agent... and SQL agent...”。这表明论文的核心是关于如何构建和设计一个由多个智能体协作构成的系统来解决复杂问题，而非仅仅将LLM作为黑盒工具使用。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Agentic AI`, `LLM-based Agents`。论文通篇都在描述其智能体框架的设计和优化。 - **智能体能力**: `Planning` (论文标题和核心就是“Planning-Centric”)，`Tool Use` (SQL Agent将计划转换为可执行的SQL，可以视为使用SQL执行器这一工具)。 - **演化机制**: `Self-Improvement`, `Self-Refine`, `Iterative Improvement`。这是论文最关键的贡献之一。它提出的“**反馈引导的元提示策略**”是一种典型的自我演化机制：通过分析失败案例，提炼修正性指导方针，并更新到智能体的提示中，从而实现无需重新训练的迭代式自我完善。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态等领域，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文是关于智能体如何进行规划的。它提出了一个专门的“Planner agent”来生成多步计划，这完全符合“保留”的条件，因为它是在智能体框架内解决复杂推理问题，而不是提升LLM本身的基础推理能力。 - **自我演化的应用**: 这篇论文是“自我演化应用”的完美范例。虽然它的应用领域是NL2SQL，但其核心贡献是提出了一种**新的“自我演化”机制**（反馈引导的元提示策略）。根据您的规则“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”，这篇论文必须被保留。它的价值在于其方法论可以被泛化到其他需要智能体自我完善的任务中。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个新颖的LLM智能体框架，并重点提出了一种有效的自我演化/自我改进机制。它直接命中了您研究范围中的“单智能体”和“自我演化”两个核心方向。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#79",
        "title": "Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs. Human Time Perception",
        "link": "/arxiv/2510.23853",
        "arxiv_id": "2510.23853",
        "authors": "Yize Cheng, Arshia Soltani Moakhar, Chenrui Fan, Kazem Faghih, Parsa Hosseini, Wenxiao Wang, Soheil Feizi",
        "summary": "Large language model agents are increasingly used in multi-turn conversational settings to interact with and execute tasks in dynamic environments. However, a key limitation is their temporal blindness: they, by default, operate with a stationary context, failing to account for the real-world time elapsed between messages. This becomes a critical liability when an agent must decide whether to invoke a tool based on how much time has passed since the last observation. Without temporal awareness, agents often either over-rely on previous context (skipping necessary tool calls), or under-rely on it (unnecessarily repeating tool calls). To study this challenge, we introduce TicToc-v1, a test set of multi-turn user-agent trajectories across 34 scenarios with varying time sensitivity. Each trajectory ends with a user question, where the need for a tool call depends on the amount of time elapsed since the last message. To give LLMs temporal context, we augment dialogue messages with explicit timestamps, bridging the gap between static dialogue and evolving environments. We then collected human preferences for these samples, creating two subsets: one where humans preferred relying on the previous observation (prefer-noTool), and another where they preferred a new tool call (prefer-Tool). We evaluated how well LLM tool-calling decisions align with human preferences under varying time intervals on TicToc-v1. Our analysis show that without time information, most models perform only slightly better than random, with the top alignment rate being just over 60%. While adding timestamps leads to a slight improvement, particularly for larger models, the improvement is modest, peaking at around 65%. We also show that naive, prompt-based alignment have limited effectiveness. Our findings highlight the need for specific post-training alignment to align multi-turn LLM tool use with human temporal perception.",
        "subjects": "Computation and Language",
        "date": "2025-10-27",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.223212",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于**改进LLM智能体的能力**。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具应用到一个新领域，而是**识别并试图解决LLM智能体本身存在的一个核心缺陷**。论文的核心贡献包括： - **识别问题**：明确指出了多轮LLM智能体存在的“时间盲视”问题，这是一个影响其决策能力的关键局限。 - **提出改进方案**：通过为对话添加显式时间戳，提出了一种增强智能体时间感知能力的方法。 - **构建评估基准**：创建了TicToc-v1数据集，用于系统性地评估和衡量智能体在时间敏感任务中的工具使用决策能力。 这些贡献都直接指向了“构建、改进或演化LLM智能体”的核心目标，而非简单的应用。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (论文标题和摘要中明确提及)。 - **智能体能力**: `Tool Use` (论文的核心议题)，`Planning` (智能体决定是否调用工具是其规划能力的关键体现)。 这些指标强烈表明该论文与您的研究方向高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 论文中提到了“align multi-turn LLM tool use with human temporal perception”，但这**不属于排除标准**。这里的“对齐”是作为**评估智能体行为是否合理的一种度量标准**，而不是论文的主要研究贡献。论文的核心是解决智能体的能力缺陷（时间盲视），而不是研究通用的对齐技术、安全或可解释性。因此，不应被排除。 - **多模态与视觉**: 论文未涉及相关内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”条件。它研究的是智能体在动态、多轮对话中如何进行**基于时间的规划和决策**（即是否需要调用工具），这正是Agentic AI中规划能力的高级体现，而非提升LLM基础的数学或逻辑推理能力。 **总结**: 该论文精准地聚焦于**单智能体**方向下的**工具使用**和**规划**能力。它通过系统性地揭示一个现有缺陷（时间盲视），提出解决方案（时间戳），并构建评估基准（TicToc-v1），为如何改进LLM智能体的决策逻辑提供了深刻的见解和实用的工具。这完全符合您筛选“核心贡献在于构建、改进或演化LLM智能体”的论文的目标。因此，最终判断为保留。"
    },
    {
        "index": "#86",
        "title": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs",
        "link": "/arxiv/2510.24514",
        "arxiv_id": "2510.24514",
        "authors": "Huanyu Zhang, Wenshan Wu, Chengzu Li, Ning Shang, Yan Xia, Yangyu Huang, Yifan Zhang, Li Dong, Zhang Zhang, Liang Wang, Tieniu Tan, Furu Wei",
        "summary": "While Multimodal Large Language Models (MLLMs) excel at visual understanding, they often struggle in complex scenarios that require visual planning and imagination. Inspired by how humans use sketching as a form of visual thinking to develop and communicate ideas, we introduce Latent Sketchpad, a framework that equips MLLMs with an internal visual scratchpad. The internal visual representations of MLLMs have traditionally been confined to perceptual understanding. We repurpose them to support generative visual thought without compromising reasoning ability. Building on frontier MLLMs, our approach integrates visual generation directly into their native autoregressive reasoning process. It allows the model to interleave textual reasoning with the generation of visual latents. These latents guide the internal thought process and can be translated into sketch images for interpretability. To realize this, we introduce two components: a Context-Aware Vision Head autoregressively produces visual representations, and a pretrained Sketch Decoder renders these into human-interpretable images. We evaluate the framework on our new dataset MazePlanning. Experiments across various MLLMs show that Latent Sketchpad delivers comparable or even superior reasoning performance to their backbone. It further generalizes across distinct frontier MLLMs, including Gemma3 and Qwen2.5-VL. By extending model's textual reasoning to visual thinking, our framework opens new opportunities for richer human-computer interaction and broader applications. More details and resources are available on our project page: https://latent-sketchpad.github.io/.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.317405",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建了一个名为“Latent Sketchpad”的新框架，其本质是**改进LLM智能体的规划与推理能力**。它并非简单地将现有模型应用于特定领域，而是提出了一种全新的、结构化的推理方法论。该方法通过在模型的推理过程中引入一个内部的“视觉草稿板”，让模型能够生成并利用视觉潜在表示来辅助其思考和规划。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不属于“非演化型应用”或“非Agentic的推理”，因为它关注的是智能体如何进行多步规划和复杂推理，而不仅仅是提升模型的基础能力。 2.  **正面指标 (第二步):** 论文包含了多个核心关注点。 *   **智能体能力:** 论文的核心是关于**规划**，明确提到了“visual planning”并在“MazePlanning”数据集上进行评估。 *   **核心范式:** 其推理过程（文本推理 -> 生成视觉潜在表示 -> 继续文本推理）与**ReAct**（Reasoning + Acting）范式高度相似。这里的“生成视觉潜在表示”可以被视为一种特殊的内部**工具使用**，即智能体调用一个内部工具来辅助其思考过程。 3.  **排除标准 (第三步):** 论文虽然涉及多模态和视觉，但它并未被排除。根据规则，多模态技术“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在本论文中，视觉生成和利用**本身就是研究的核心**，是构成新型推理框架的关键部分，而不仅仅是用于感知。论文中提到的“可解释性”是该框架带来的一个附加好处，并非其主要研究贡献，因此不触发排除标准。 4.  **特殊和模糊情况 (第四步):** 论文完美符合“推理/规划”的保留规则。它不是关于提升LLM基础的数学或逻辑能力，而是关于**智能体如何进行规划或在复杂任务中进行多步推理**。它提出了一种新的Agentic框架，通过“视觉思考”来增强文本推理，这与ReAct、ToT等框架在精神上是一致的，都属于对智能体推理机制的探索和创新。 **最终决策 (第五步):** 综合分析，该论文的核心贡献在于提出了一种创新的框架，通过赋予LLM智能体“视觉思考”的能力，显著增强了其在复杂任务中的规划和多步推理能力。这直接命中了我的研究焦点“单智能体”方向下的“规划”和“工具使用”子方向。因此，这篇论文高度相关，应被筛选出来。"
    },
    {
        "index": "#90",
        "title": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model",
        "link": "/arxiv/2510.24285",
        "arxiv_id": "2510.24285",
        "authors": "Juntian Zhang, Song Jin, Chuanqi Cheng, Yuhan Liu, Yankai Lin, Xun Zhang, Yufei Zhang, Fei Jiang, Guojun Yin, Wei Lin, Rui Yan",
        "summary": "The limited capacity for fine-grained visual perception presents a critical bottleneck for Vision-Language Models (VLMs) in real-world applications. Addressing this is challenging due to the scarcity of high-quality data and the limitations of existing methods: supervised fine-tuning (SFT) often compromises general capabilities, while reinforcement fine-tuning (RFT) prioritizes textual reasoning over visual perception. To bridge this gap, we propose a novel two-stage task that structures visual perception learning as a coarse-to-fine progressive process. Based on this task formulation, we develop ViPER, a self-bootstrapping framework specifically designed to enable iterative evolution through self-critiquing and self-prediction. By synergistically integrating image-level and instance-level reconstruction with a two-stage reinforcement learning strategy, ViPER establishes a closed-loop training paradigm, where internally synthesized data directly fuel the enhancement of perceptual ability. Applied to the Qwen2.5-VL family, ViPER produces the Qwen-Viper series. With an average gain of 1.7% on seven comprehensive benchmarks spanning various tasks and up to 6.0% on fine-grained perception, Qwen-Viper consistently demonstrates superior performance across different vision-language scenarios while maintaining generalizability. Beyond enabling self-improvement in perceptual capabilities, ViPER provides concrete evidence for the reciprocal relationship between generation and understanding, a breakthrough to developing more autonomous and capable VLMs.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-10-28",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.320922",
        "filter_reason": "这篇论文符合您的研究范围，核心依据在于其贡献了一种新颖的“自我演化”机制，尽管其应用领域是视觉感知。 1.  **核心判断 (第一步):** 论文的核心贡献并非简单地将LLM或智能体框架应用于视觉领域，而是提出了一个名为 **ViPER** 的**自我演化框架**。摘要中明确指出，这是一个“self-bootstrapping framework specifically designed to enable iterative evolution through self-critiquing and self-prediction”（一个通过自我批判和自我预测来实现迭代演化的自举框架）。这完全符合您筛选标准中“核心贡献在于构建、改进或演化 LLM智能体”的要求，特别是“自我演化”这一方向。它不是非演化型应用，而是提出了一种新的演化方法论。 2.  **正面指标 (第二步):** 论文包含了多个您关注的核心正面指标： *   **核心范式:** `Self-Evolving` (自我演化) 是论文标题和摘要的核心主题。 *   **演化机制:** 论文明确提出了 `Self-Critiquing` (自我批判，属于 `Self-Correction`/`Self-Reflection` 范畴)、`Iterative Evolution` (迭代演化) 和 `Self-Improvement` (自我改进) 的机制。这些是您研究焦点中的关键概念。 3.  **排除标准与特殊情况处理 (第三步 & 第四步):** 这是最关键的一步。虽然论文涉及 `Vision-Language Models (VLMs)`，看似触发了“多模态与视觉”的排除标准，但根据您设定的**第四步特殊规则**，这种情况应被保留。 *   **规则应用:** 您的规则明确指出：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” *   **论文分析:** ViPER论文正是这种情况。它的核心是提出一种通用的、通过自我批判和闭环训练来迭代演化模型能力的**机制**。这个机制恰好被应用在了“视觉感知”这个特定领域。因此，研究的重点是**“如何演化”**，而不是**“视觉任务本身”**。论文的最终目标也是“developing more autonomous and capable VLMs”（开发更自主和更有能力的VLMs），这与构建更强大的智能体目标一致。 **结论:** 综合来看，尽管论文的标题和应用背景是视觉语言模型，但其本质和核心贡献是提出了一种创新的、可泛化的**自我演化方法论**。这完全契合您研究课题中的“自我演化”方向。根据您设定的筛选规则，特别是关于“自我演化的应用”的例外条款，这篇论文应该被**保留**。它为您的研究提供了一个关于如何实现智能体特定能力（此处为感知）自我演化的前沿案例。"
    },
    {
        "index": "#97",
        "title": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context",
        "link": "/arxiv/2510.23763",
        "arxiv_id": "2510.23763",
        "authors": "Siyin Wang, Jinlan Fu, Feihong Liu, Xinzhe He, Huangxuan Wu, Junhao Shi, Kexin Huang, Zhaoye Fei, Jingjing Gong, Zuxuan Wu, Yugang Jiang, See-Kiong Ng, Tat-Seng Chua, Xipeng Qiu",
        "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have driven rapid progress in Vision-Language-Action (VLA) models for robotic manipulation. Although effective in many scenarios, current approaches largely rely on explicit instructions, whereas in real-world interactions, humans rarely issue instructions directly. Effective collaboration requires robots to infer user intentions proactively. In this work, we introduce cross-modal contextual instructions, a new setting where intent is derived from spoken dialogue, environmental sounds, and visual cues rather than explicit commands. To address this new setting, we present RoboOmni, a Perceiver-Thinker-Talker-Executor framework based on end-to-end omni-modal LLMs that unifies intention recognition, interaction confirmation, and action execution. RoboOmni fuses auditory and visual signals spatiotemporally for robust intention recognition, while supporting direct speech interaction. To address the absence of training data for proactive intention recognition in robotic manipulation, we build OmniAction, comprising 140k episodes, 5k+ speakers, 2.4k event sounds, 640 backgrounds, and six contextual instruction types. Experiments in simulation and real-world settings show that RoboOmni surpasses text- and ASR-based baselines in success rate, inference speed, intention recognition, and proactive assistance.",
        "subjects": "Robotics, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-10-27",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.335269",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了 **RoboOmni**，一个全新的 **Perceiver-Thinker-Talker-Executor 框架**。这并非简单地将现有LLM或智能体框架应用于机器人领域，而是构建了一个新的、端到端的智能体架构来解决“主动意图识别与执行”这一特定问题。该框架统一了意图识别、交互确认和动作执行，这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是“非演化型应用”，因为其创新点在于智能体本身的架构设计，而非应用本身。 2.  **第二步：正面指标——高度相关** 论文明确包含了多个核心关注点： *   **核心范式**: 论文本质上是一个 **LLM-based Agent** 的研究，其提出的框架是典型的 **Agentic AI** 架构。 *   **智能体能力**: `Perceiver-Thinker-Talker-Executor` 结构清晰地体现了智能体的核心能力。`Perceiver` 负责感知（融合多模态信息），`Thinker` 负责推理和规划（推断用户意图），`Executor` 负责执行（机器人操作）。这直接对应了研究焦点中的“规划”和“工具使用”（机器人本身作为智能体在物理世界执行动作的工具）。 3.  **第三步：排除标准——未触犯** *   **安全与对齐**: 论文未涉及安全、对齐、可解释性等内容。 *   **多模态与视觉**: 这是本案例的关键点。虽然论文大量使用了 `MLLMs`、`Vision`、`Auditory` 等多模态技术，但它们是作为 **智能体感知环境的工具** 而存在的。论文的核心不是提出一个新的多模态模型，而是构建一个 **利用** 多模态感知能力的智能体框架。`Perceiver` 模块是这个智能体架构的一部分，而不是研究的全部。因此，这符合排除标准中的例外情况。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文的 `Thinker` 模块和“主动推断用户意图”的功能，完全属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个用于解决实际任务的智能体推理循环。 **总结**: 尽管论文的应用领域是机器人学，但其核心贡献在于提出了一种新颖的 **单智能体架构**，该架构通过整合多模态感知、意图推理和动作执行，实现了更高级的主动交互能力。这完全契合研究课题中“单智能体”方向，特别是关于智能体规划、感知与执行框架的探索。因此，这篇论文是高度相关的前沿研究，应该被保留。"
    },
    {
        "index": "#99",
        "title": "VisCoder2: Building Multi-Language Visualization Coding Agents",
        "link": "/arxiv/2510.23642",
        "arxiv_id": "2510.23642",
        "authors": "Yuansheng Ni, Songcheng Cai, Xiangchao Chen, Jiarong Liang, Zhiheng Lyu, Jiaqi Deng, Kai Zou, Ping Nie, Fei Yuan, Xiang Yue, Wenhu Chen",
        "summary": "Large language models (LLMs) have recently enabled coding agents capable of generating, executing, and revising visualization code. However, existing models often fail in practical workflows due to limited language coverage, unreliable execution, and lack of iterative correction mechanisms. Progress has been constrained by narrow datasets and benchmarks that emphasize single-round generation and single-language tasks. To address these challenges, we introduce three complementary resources for advancing visualization coding agents. VisCode-Multi-679K is a large-scale, supervised dataset containing 679K validated and executable visualization samples with multi-turn correction dialogues across 12 programming languages. VisPlotBench is a benchmark for systematic evaluation, featuring executable tasks, rendered outputs, and protocols for both initial generation and multi-round self-debug. Finally, we present VisCoder2, a family of multi-language visualization models trained on VisCode-Multi-679K. Experiments show that VisCoder2 significantly outperforms strong open-source baselines and approaches the performance of proprietary models like GPT-4.1, with further gains from iterative self-debug, reaching 82.4% overall execution pass rate at the 32B scale, particularly in symbolic or compiler-dependent languages.",
        "subjects": "Software Engineering, Artificial Intelligence, Computation and Language, Programming Languages",
        "date": "2025-10-24",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.336409",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接聚焦于构建和改进LLM智能体，特别是在“单智能体”和“自我演化”两个方向上。 1.  **第一步：核心判断——保留** - 论文的核心本质是**构建一个新型的LLM智能体**。标题明确指出“Building Multi-Language Visualization Coding Agents”，摘要中详细介绍了构建该智能体所需的数据集、基准和模型本身。 - 这不属于“非演化型应用”。论文的重点不是“如何用LLM解决可视化问题”，而是“如何构建一个更强大的、能够自我修正的可视化编码智能体”。其贡献在于智能体的方法论和架构，而非应用领域。 - 这不属于“非Agentic的推理”。论文的核心是“iterative correction mechanisms”和“multi-round self-debug”，这是一个典型的智能体循环（生成代码 -> 执行 -> 观察结果 -> 反思修正），而非单纯提升LLM的基础推理能力。 2.  **第二步：正面指标——高度匹配** - 论文包含了多个核心关注点： - **智能体能力**: 明确提到了 `Self-Correction`（自我修正）和 `Self-Debug`（自我调试），这正是“自我演化”方向的核心子方向。 - **核心范式**: 论文构建的是 `LLM-based Agents`。 - **演化机制**: “iterative self-debug”和“multi-turn correction dialogues”直接对应 `Self-Improvement` 和 `Iterative Improvement`。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不是关于安全、对齐或可解释性。 - 论文虽然涉及“Visualization”，但其核心是**编码智能体**，而非视觉智能体。智能体的任务是生成和调试代码（如Matplotlib, D3.js），而不是直接理解图像或视频。因此，这不属于被排除的多模态与视觉研究范畴。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **自我演化的应用**: 这篇论文是“自我演化”应用的一个完美范例。它的核心贡献是提出了一种新的“迭代自我调试”机制，并为此构建了配套的数据集和基准。即使它应用在“可视化编码”这个特定领域，根据您的规则，这种提出新演化机制的论文应该被**保留**。 - **推理/规划**: 论文中的“生成、执行、修正”循环，是一种在复杂任务（生成可执行且正确的可视化代码）中进行多步推理和规划的Agentic框架，符合保留条件。 **总结**: 该论文的核心贡献是构建了一个名为VisCoder2的编码智能体，其关键创新点在于引入了**迭代自我调试机制**，使智能体能够通过多轮交互和反思来修正自己的错误。这直接命中了您研究目标中的“单智能体”和“自我演化”方向。它不是简单的应用，而是对智能体能力本身的增强和演化，因此是一篇高度相关的前沿论文。"
    },
    {
        "index": "#103",
        "title": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media",
        "link": "/arxiv/2510.23626",
        "arxiv_id": "2510.23626",
        "authors": "Shuang Geng, Wenli Zhang, Jiaheng Xie, Rui Wang, Sudha Ram",
        "summary": "Social media user-generated content (UGC) provides real-time, self-reported indicators of mental health conditions such as depression, offering a valuable source for predictive analytics. While prior studies integrate medical knowledge to improve prediction accuracy, they overlook the opportunity to simultaneously expand such knowledge through predictive processes. We develop a Closed-Loop Large Language Model (LLM)-Knowledge Graph framework that integrates prediction and knowledge expansion in an iterative learning cycle. In the knowledge-aware depression detection phase, the LLM jointly performs depression detection and entity extraction, while the knowledge graph represents and weights these entities to refine prediction performance. In the knowledge refinement and expansion phase, new entities, relationships, and entity types extracted by the LLM are incorporated into the knowledge graph under expert supervision, enabling continual knowledge evolution. Using large-scale UGC, the framework enhances both predictive accuracy and medical understanding. Expert evaluations confirmed the discovery of clinically meaningful symptoms, comorbidities, and social triggers complementary to existing literature. We conceptualize and operationalize prediction-through-learning and learning-through-prediction as mutually reinforcing processes, advancing both methodological and theoretical understanding in predictive analytics. The framework demonstrates the co-evolution of computational models and domain knowledge, offering a foundation for adaptive, data-driven knowledge systems applicable to other dynamic risk monitoring contexts.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-29T11:00:06.354602",
        "filter_reason": "这篇论文的核心贡献完全符合您的研究范围，特别是“自我演化”方向。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于医疗领域，而是提出了一种新颖的“闭环LLM-知识图谱框架”。其核心创新在于构建了一个能够“持续知识演化”的迭代学习循环。论文明确指出，该框架通过“预测即学习”和“学习即预测”的相互强化过程，实现了计算模型与领域知识的“共同演化”。这完全符合您筛选标准中关于“自我演化”的定义，即“智能体通过经验、反思或环境反馈进行自我完善和迭代”。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **自我演化**: 摘要中明确出现了 `continual knowledge evolution` (持续的知识演化), `iterative learning cycle` (迭代学习循环), `co-evolution` (共同演化) 等关键词。 - **自我完善**: 论文提出的框架通过不断将新发现的知识（实体、关系）整合进知识图谱，实现了系统的自我完善和迭代。 - **记忆**: 知识图谱在这里扮演了结构化、可演化的长期记忆角色，存储和提炼从数据中学到的知识。 3.  **第三步：排除标准** - 论文的主要贡献不在于安全、对齐或多模态技术，因此没有触及任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”的完美范例。虽然它被应用在“抑郁症检测”这一特定医疗领域，但其核心贡献是提出了一种通用的“自我演化机制”（闭环框架）。根据您的规则，“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”。这篇论文恰好满足这一条件。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个能够通过与环境的交互（处理新的社交媒体数据）来迭代式地扩展和完善自身知识库（知识图谱）的LLM系统。这完全契合您对“自我演化”智能体的研究目标。它不是简单的应用，而是一种具有方法论意义的自我演化框架。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#85",
        "title": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust Multi-Objective AI Agents",
        "link": "/arxiv/2510.23682",
        "arxiv_id": "2510.23682",
        "authors": "Gokturk Aytug Akarlar",
        "summary": "Large language models show promise as autonomous decision-making agents, yet their deployment in high-stakes domains remains fraught with risk. Without architectural safeguards, LLM agents exhibit catastrophic brittleness: identical capabilities produce wildly different outcomes depending solely on prompt framing. We present Chimera, a neuro-symbolic-causal architecture that integrates three complementary components - an LLM strategist, a formally verified symbolic constraint engine, and a causal inference module for counterfactual reasoning. We benchmark Chimera against baseline architectures (LLM-only, LLM with symbolic constraints) across 52-week simulations in a realistic e-commerce environment featuring price elasticity, trust dynamics, and seasonal demand. Under organizational biases toward either volume or margin optimization, LLM-only agents fail catastrophically (total loss of \\$99K in volume scenarios) or destroy brand trust (-48.6% in margin scenarios). Adding symbolic constraints prevents disasters but achieves only 43-87% of Chimera's profit. Chimera consistently delivers the highest returns (\\$1.52M and \\$1.96M respectively, some cases +\\$2.2M) while improving brand trust (+1.8% and +10.8%, some cases +20.86%), demonstrating prompt-agnostic robustness. Our TLA+ formal verification proves zero constraint violations across all scenarios. These results establish that architectural design not prompt engineering determines the reliability of autonomous agents in production environments. We provide open-source implementations and interactive demonstrations for reproducibility.",
        "subjects": "Machine Learning, Artificial Intelligence, Logic in Computer Science, Software Engineering",
        "date": "2025-10-27",
        "category": "cs.LG",
        "crawl_time": "2025-10-29T11:00:06.656450",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **核心判断 (第一步):** - **保留**。这篇论文的本质是提出一个名为“Chimera”的**新架构**，用于构建更稳健、更可靠的AI智能体。其核心贡献并非将现有智能体应用于电商领域，而是**构建和改进LLM智能体的方法论**。论文明确指出“architectural design not prompt engineering determines the reliability of autonomous agents”，这直接命中了你“构建、改进或演化LLM智能体”的核心目标。 2.  **正面指标 (第二步):** - 论文包含了多个核心关注点。它明确讨论了`AI Agents`，其提出的架构中，LLM扮演`strategist`（规划者）的角色，并与符号约束引擎、因果推理模块协同工作，这本质上是`Tool Use / Tool Augmentation`和`Planning`能力的体现。整个系统旨在解决智能体在复杂任务中的自主决策问题，是典型的`Agentic AI`研究。 3.  **排除标准 (第三步):** - 论文虽然提到了“robustness”和“constraint violations”，但其主要贡献是**通过架构设计来提升智能体的决策能力和可靠性**，而不是专注于安全、对齐或可解释性本身。它的目标是让智能体在多目标优化（如利润与信任）中表现更好，这是对智能体**能力**的增强，而非纯粹的安全研究。因此，它不属于“安全与对齐”的排除范畴。 - 论文不涉及多模态或视觉内容。 4.  **特殊和模糊情况 (第四步):** - **推理/规划**: 论文的核心是关于智能体如何进行稳健的规划和决策。它提出的架构正是为了解决LLM作为智能体在规划时对提示词的脆弱性问题，这完全符合“保留”关于智能体规划和多步推理框架的论文的标准。 - **自我演化的应用**: 此条不适用，因为论文的核心是静态的架构设计，而非自我演化机制。 **总结:** 该论文的核心贡献是提出了一种创新的神经-符号-因果融合架构，用以构建更强大、更稳健的LLM智能体。它直接解决了智能体在自主规划和决策中的关键挑战，完全属于你研究范围中的“单智能体”方向，特别是关于智能体架构、规划和工具使用的子方向。尽管它在一个具体的应用场景（电商）中进行评估，但其贡献是通用性的方法论，因此应被保留。"
    },
    {
        "index": "#4",
        "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling",
        "link": "/arxiv/2510.24645",
        "arxiv_id": "2510.24645",
        "authors": "Zengzhuang Xu, Bingguang Hao, Zechuan Wang, Yuntao Wen, Maolin Wang, Yang Liu, Long Chen, Dong Wang, Yicheng Chen, Cunyin Peng, Chenyi Zhuang, Jinjie Gu, Leilei Gan, Xiangyu Zhao, Shi Gu",
        "summary": "Function calling (FC) empowers large language models (LLMs) and autonomous agents to interface with external tools, a critical capability for solving complex, real-world problems. As this ability becomes increasingly central to advanced AI systems, the need for high-quality, multi-turn training data to develop and refine it cannot be overstated. Existing data synthesis methods, such as random environment sampling or multi-agent role-playing, are not powerful enough to generate high-quality data in real-world environments. Practical challenges come in three folds: targeted model training, isolation of tool architecture, and multi-turn logical dependency. To address these structural deficiencies, we present FunReason-MT, a novel data synthesis framework for real-world multi-turn tool use. FunReason-MT resolves the complexity barrier in multi-turn FC data by employing 1) Environment-API Graph Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query Synthesis to simplify hard query construction, and 3) Guided Iterative Chain for sophisticated CoT generation. Evaluations on Berkeley Function-Calling Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built upon FunReason-MT generated data achieves state-of-the-art performance among comparable-sized models, outperforming most close-source models. Further performance improvements on BFCLv4 confirm that FunReason-MT provides a reliable and robust source for agentic learning.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.640728",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 该论文的核心贡献是提出了一个名为 **FunReason-MT** 的**数据合成框架**，其目的是为了生成高质量的**多轮函数调用**数据。 - **判断依据**: 函数调用是LLM智能体与外部工具交互、解决复杂问题的**核心能力**。这篇论文并非将智能体作为工具去解决某个特定领域（如生物、金融）的问题，而是聚焦于**如何构建和改进智能体本身的一项基础能力**。它提出了一种新的方法论（数据合成框架）来提升智能体的工具使用水平，这完全符合“构建、改进或演化 LLM智能体”的核心目标。因此，根据第一步的判断标准，应**保留**。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **核心范式**: 摘要中明确提到了 `autonomous agents` 和 `agentic learning`。 - **智能体能力**: 论文的主题是 `Function Calling (FC)`，这直接对应 `Tool Use / Tool Augmentation`。同时，多轮函数调用隐含了 `Planning`（规划一系列工具调用）的能力，摘要中提到的 `sophisticated CoT generation` 也与 `ReAct` 等推理范式密切相关。 3.  **第三步：排除标准** - 论文的研究焦点是提升智能体的能力，不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题。 - 论文也未涉及 `Vision`、`MLLMs` 等多模态内容。 - 因此，论文没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文研究的“多轮函数调用”本质上是智能体在复杂任务中进行多步推理和规划的一种具体实现。它不是在提升LLM的基础数学或逻辑能力，而是在提升智能体**使用工具进行规划和执行**的能力。这完全符合“保留”的条件。 **最终决策**: 该论文的核心贡献是提出了一种新的框架（FunReason-MT），用于生成高质量数据，以**训练和提升LLM智能体的多轮工具使用能力**。这直接对应了您研究课题中的“单智能体”方向，特别是“工具使用”和“规划”这两个子方向。论文的目标是“为智能体学习提供可靠的来源”，这与您“构建、改进或演化 LLM智能体”的核心目标高度一致。因此，这篇论文是您研究范围内的前沿和核心论文。"
    },
    {
        "index": "#2",
        "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs",
        "link": "/arxiv/2510.24663",
        "arxiv_id": "2510.24663",
        "authors": "Yifu Lu, Shengjie Liu, Li Dong",
        "summary": "Agentic tool use has gained traction with the rise of agentic tool calling, yet most existing work overlooks the complexity of multi-turn tool interactions. We introduce OrchDAG, a synthetic data generation pipeline that models tool execution as directed acyclic graphs (DAGs) with controllable complexity. Using this dataset, we benchmark model performance and propose a graph-based reward to enhance RLVR training. Experiments show that the dataset presents a challenging but solvable benchmark, and the proposed reward is effective when combined with GRPO-style algorithms, highlighting the importance of leveraging topological structure and data complexity in multi-turn tool use.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.638721",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建和改进LLM智能体的核心能力**。其核心贡献是`OrchDAG`，一个用于建模和训练智能体进行复杂工具编排的新框架。它不是将现有智能体作为工具去解决某个外部领域（如生物、金融）的问题，而是直接聚焦于智能体内部的“工具使用”这一核心机制，并提出了新的数据生成和训练方法来提升该能力。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文与您的核心关注点高度匹配。摘要中明确提到了多个关键范式和能力： - **核心范式**: `Agentic tool use` (智能体工具使用)。 - **智能体能力**: `Tool Orchestration` (工具编排，是`Tool Use`的高级形式)、`Planning` (规划，通过`Plan DAGs`体现)、`Multi-Turn Interactions` (多轮交互，涉及记忆和规划)。 - 这些关键词表明，论文的研究内容直接属于您关注的“单智能体”方向，特别是工具使用和规划这两个子方向。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。其主要贡献不是关于`Safety`、`Alignment`、`Interpretability`，也没有涉及`Vision`或`MLLMs`。研究焦点纯粹集中在智能体的行为和训练方法上。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的研究内容完美地符合“保留”条件。它不是在提升LLM的基础数学或逻辑推理能力，而是在研究**智能体如何进行规划**（`Plan DAGs`）和**在复杂任务中进行多步推理**（`Complex Tool Orchestration in Multi-Turn Interactions`）。这正是Agentic AI框架下的规划问题。 **综合结论**: 该论文的核心贡献在于提出了一种新的方法（`OrchDAG`数据管道和基于图的奖励机制）来**改进LLM智能体在复杂、多轮场景下的工具使用和规划能力**。这直接对应了您研究课题中的“单智能体”方向，特别是“工具使用”和“规划”子方向。它不是对现有智能体的简单应用，而是对智能体核心能力的**方法论层面的创新和改进**。因此，这篇论文是您研究范围内的前沿高质量文献，应被筛选出来。"
    },
    {
        "index": "#1",
        "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning",
        "link": "/arxiv/2510.24690",
        "arxiv_id": "2510.24690",
        "authors": "Shengjie Liu, Li Dong, Zhenyu Zhang",
        "summary": "We present a framework for uncovering and exploiting dependencies among tools and documents to enhance exemplar artifact generation. Our method begins by constructing a tool knowledge graph from tool schemas,including descriptions, arguments, and output payloads, using a DeepResearch-inspired analysis. In parallel, we derive a complementary knowledge graph from internal documents and SOPs, which is then fused with the tool graph. To generate exemplar plans, we adopt a deep-sparse integration strategy that aligns structural tool dependencies with procedural knowledge. Experiments demonstrate that this unified framework effectively models tool interactions and improves plan generation, underscoring the benefits of linking tool graphs with domain knowledge graphs for tool-augmented reasoning and planning.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.638120",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个**新的方法论框架**，用于提升LLM智能体的核心能力。其核心贡献在于构建一个“基于图的框架”，通过显式地建模工具之间的依赖关系以及领域知识，来增强智能体的“上下文内规划”能力。这直接属于“构建、改进LLM智能体”的范畴，而不是将现有智能体作为工具应用到某个特定领域。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **智能体能力**: 论文的核心是关于 `Planning`（规划）和 `Tool Use / Tool Augmentation`（工具使用/工具增强）。它提出的方法旨在让智能体更好地理解和使用工具，从而制定更优的计划。 - **核心范式**: 论文的研究内容与 `Agentic AI` 和 `LLM-based Agents` 紧密相关。其“tool-augmented reasoning and planning”的表述，与 `ReAct` 等智能体范式一脉相承，但提出了更精细化的改进方案。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题。 - 论文也未涉及 `Vision`、`MLLMs` 等多模态内容，其处理的对象是工具描述和文档（文本）。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于**智能体如何进行规划**的典型案例。它不是在提升LLM本身的基础数学或逻辑推理能力，而是在构建一个让智能体在复杂任务中（需要调用多个工具时）进行有效多步推理和规划的框架。这完全符合“保留”的条件。 **总结**: 该论文的核心贡献是提出了一种创新的图框架，用于解决LLM智能体在规划和工具使用中的关键挑战——如何理解和利用工具间的复杂依赖关系并结合领域知识。这直接命中了您研究焦点中的“单智能体”方向，特别是“规划”和“工具使用”这两个子方向。因此，这篇论文是您课题下的高质量前沿研究，应被筛选出来。"
    },
    {
        "index": "#15",
        "title": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine",
        "link": "/arxiv/2510.24359",
        "arxiv_id": "2510.24359",
        "authors": "Pedram Fard, Alaleh Azhir, Neguine Rezaii, Jiazi Tian, Hossein Estiri",
        "summary": "Artificial intelligence in medicine is built to serve the average patient. By minimizing error across large datasets, most systems deliver strong aggregate accuracy yet falter at the margins: patients with rare variants, multimorbidity, or underrepresented demographics. This average patient fallacy erodes both equity and trust. We propose a different design: a multi-agent ecosystem for N-of-1 decision support. In this environment, agents clustered by organ systems, patient populations, and analytic modalities draw on a shared library of models and evidence synthesis tools. Their results converge in a coordination layer that weighs reliability, uncertainty, and data density before presenting the clinician with a decision-support packet: risk estimates bounded by confidence ranges, outlier flags, and linked evidence. Validation shifts from population averages to individual reliability, measured by error in low-density regions, calibration in the small, and risk--coverage trade-offs. Anticipated challenges include computational demands, automation bias, and regulatory fit, addressed through caching strategies, consensus checks, and adaptive trial frameworks. By moving from monolithic models to orchestrated intelligence, this approach seeks to align medical AI with the first principle of medicine: care that is transparent, equitable, and centered on the individual.",
        "subjects": "Artificial Intelligence, Systems and Control, Quantitative Methods, Applications",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.652393",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将一个已有的智能体框架应用于医疗领域，而是**提出了一种全新的多智能体生态系统架构**。摘要中明确指出“We propose a different design: a multi-agent ecosystem for N-of-1 decision support”以及“By moving from monolithic models to orchestrated intelligence”。这表明其核心创新在于智能体的组织、协作和协调方式本身，属于构建和改进多智能体系统的方法论范畴。因此，它避开了“非演化型应用”的排除规则，因为其贡献是智能体框架，而非应用结果。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **多智能体**: 明确提出了 `multi-agent ecosystem`，并描述了智能体如何按功能聚类（`agents clustered by organ systems`）。 - **协作**: 描述了智能体结果的汇聚和协调（`results converge in a coordination layer`），这属于智能体间的协作机制。 - **工具使用**: 提到智能体使用共享的模型和证据合成工具（`draw on a shared library of models and evidence synthesis tools`），这是典型的工具使用能力。 3.  **第三步：排除标准** - 论文未被排除。虽然它提到了 `transparent` 和 `equitable`，这些词与可解释性和对齐相关，但它们是作为该医疗AI系统的**设计目标**出现的，而非论文的核心研究贡献。论文的核心是提出实现这些目标的**多智能体架构**，而不是研究安全或对齐技术本身。 4.  **第四步：处理特殊和模糊情况** - 本论文不涉及“推理/规划”或“自我演化”的特殊情况，因此无需特殊处理。 5.  **第五步：最终决策** - 综合来看，尽管论文的应用领域是精准医学，但其**本质贡献是构建一个新颖的多智能体系统框架**。它详细阐述了智能体的组织结构、协作方式和工具使用机制，完全符合“构建、改进或演化LLM智能体”这一核心研究目标，特别是其中的“多智能体”方向。因此，这篇论文是高度相关的，应该被保留。"
    },
    {
        "index": "#19",
        "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting",
        "link": "/arxiv/2510.24303",
        "arxiv_id": "2510.24303",
        "authors": "Deniz Gorur, Antoni Rago, Francesca Toni",
        "summary": "Judgmental forecasting is the task of making predictions about future events based on human judgment. This task can be seen as a form of claim verification, where the claim corresponds to a future event and the task is to assess the plausibility of that event. In this paper, we propose a novel multi-agent framework for claim verification, whereby different agents may disagree on claim veracity and bring specific evidence for and against the claims, represented as quantitative bipolar argumentation frameworks (QBAFs). We then instantiate the framework for supporting claim verification, with a variety of agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an existing approach for claim verification that generates and evaluates QBAFs; (2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM) from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents, extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of arguments from external sources. Finally, we conduct experiments with two standard judgmental forecasting datasets, with instances of our framework with two or three agents, empowered by six different base LLMs. We observe that combining evidence from agents can improve forecasting accuracy, especially in the case of three agents, while providing an explainable combination of evidence for claim verification.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.659522",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出一个“新颖的多智能体框架”，而不是简单地将现有框架应用于特定领域。摘要明确指出：“we propose a novel multi-agent framework for claim verification”。这直接命中了您筛选标准中的“保留”条件：论文的核心是关于构建LLM智能体或多智能体系统的方法论或新框架。它不是在解决一个生物或金融问题，而是在构建一个用于解决“论辩验证”这一通用任务的智能体架构。 2.  **第二步：正面指标——高度匹配** 论文包含了多个您关注的核心关键词和概念： *   **核心范式**: `Multi-Agent Systems (MAS)` 和 `LLM-based Agents` 在标题和摘要中被反复强调。 *   **多智能体**: 论文的核心就是研究智能体间的互动。摘要中提到“different agents may disagree on claim veracity and bring specific evidence for and against the claims”，这描述了智能体间的**通信** 和一种基于证据的**协作/博弈** 形式。 *   **智能体能力**: 论文中的 `RAG-ArgLLM agents` 和 `RbAM agents` 明确使用了检索增强生成（RAG）和关系论辩挖掘（RbAM）作为工具，这属于**工具使用/工具增强** 的范畴。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 论文虽然提到了“explainable combination of evidence”，但这只是其多智能体框架带来的一个有益特性，并非论文的主要研究贡献。论文的核心是框架设计和性能提升，而不是研究可解释性、安全或对齐本身。因此，不触发排除标准。 *   **多模态与视觉**: 论文完全基于文本的论辩和主张，不涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文提出的框架涉及多个智能体分别进行证据检索、论辩生成和评估，然后整合结果，这是一个复杂的多步推理过程，完全符合“智能体如何进行规划或在复杂任务中进行多步推理”的保留条件。 **最终决策**: 该论文的核心贡献在于**构建和改进一个多智能体LLM系统**。它研究了如何让不同类型的LLM智能体（使用不同工具和策略）进行协作和通信，以共同完成一项复杂的推理任务。这完全契合您研究课题中的“多智能体”方向，并且是关于智能体架构和方法的创新，而非简单的应用。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#17",
        "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation",
        "link": "/arxiv/2510.24339",
        "arxiv_id": "2510.24339",
        "authors": "Yunxuan Jiang, Silan Hu, Xiaoning Wang, Yuanyuan Zhang, Xiangyu Chang",
        "summary": "Large language models (LLMs) become increasingly integrated into data science workflows for automated system design. However, these LLM-driven data science systems rely solely on the internal reasoning of LLMs, lacking guidance from scientific and theoretical principles. This limits their trustworthiness and robustness, especially when dealing with noisy and complex real-world datasets. This paper provides VDSAgents, a multi-agent system grounded in the Predictability-Computability-Stability (PCS) principles proposed in the Veridical Data Science (VDS) framework. Guided by PCS principles, the system implements a modular workflow for data cleaning, feature engineering, modeling, and evaluation. Each phase is handled by an elegant agent, incorporating perturbation analysis, unit testing, and model validation to ensure both functionality and scientific auditability. We evaluate VDSAgents on nine datasets with diverse characteristics, comparing it with state-of-the-art end-to-end data science systems, such as AutoKaggle and DataInterpreter, using DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the results of AutoKaggle and DataInterpreter, which validates the feasibility of embedding PCS principles into LLM-driven data science automation.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.658599",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** - **论文的核心贡献是构建一个新的多智能体系统**。论文标题和摘要明确指出，其核心工作是提出并实现一个名为 \"VDSAgents\" 的多智能体系统。它不是简单地将一个已有的智能体框架（如AutoGPT）应用到数据科学领域，而是**设计了一个全新的、基于特定科学原则（PCS）的智能体架构和工作流**。这完全符合“构建、改进LLM智能体”的核心目标。 - **不属于“非演化型应用”**。虽然论文的应用领域是数据科学自动化，但其重点在于**如何通过多智能体协作来完成任务**，而不是将LLM作为一个黑盒工具来解决数据科学问题。论文的贡献在于智能体系统的设计本身，而非其在特定领域的应用结果。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文明确属于 `Multi-Agent Systems (MAS)` 范畴。 - **智能体能力**: 论文描述了一个模块化工作流，每个阶段由专门的智能体处理，这体现了智能体的 `Planning`（规划）能力。同时，智能体使用了“扰动分析、单元测试和模型验证”等方法，这可以被视为一种 `Tool Use`（工具使用）。 - **多智能体**: 论文的核心就是关于多个智能体如何在一个统一的框架下协同工作，以完成一个复杂任务，这直接命中了 `Collaboration`（协作）这一子方向。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不是关于安全、对齐、可解释性或多模态。它关注的是智能体的系统架构和任务执行能力，因此没有触及任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 论文描述的“模块化工作流”正是智能体进行复杂任务规划和执行的体现。它不是在改进LLM的基础推理能力，而是在构建一个让智能体能够进行多步、有结构推理的框架，因此符合保留条件。 **总结**: 这篇论文的核心是提出一个新颖的多智能体系统（VDSAgents），其贡献在于系统架构的设计和实现，旨在通过多智能体协作来完成复杂的数据科学任务。这完全契合您研究课题中的“多智能体”方向，并且涉及了智能体的规划和工具使用能力。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#22",
        "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools",
        "link": "/arxiv/2510.24284",
        "arxiv_id": "2510.24284",
        "authors": "Wenhao Wang, Peizhi Niu, Zhao Xu, Zhaoyu Chen, Jian Du, Yaxin Du, Xianghe Pang, Keduan Huang, Yanfeng Wang, Qiang Yan, Siheng Chen",
        "summary": "Large Language Models (LLMs) increasingly rely on external tools to perform complex, realistic tasks, yet their ability to utilize the rapidly expanding Model Contextual Protocol (MCP) ecosystem remains limited. Existing MCP research covers few servers, depends on costly manual curation, and lacks training support, hindering progress toward real-world deployment. To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training. MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing 68733 high-quality instruction-function call pairs and 6439 trajectories, far exceeding prior work in scale and diversity. Extensive experiments demonstrate MCP-Flow's effectiveness in driving superior MCP tool selection, function-call generation, and enhanced agentic task performance. MCP-Flow thus provides a scalable foundation for advancing LLM agents' proficiency in real-world MCP environments. MCP-Flow is publicly available at \\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.661103",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** - **论文本质**: 这篇论文的核心贡献是提出了一个名为 **MCP-Flow** 的自动化流程。这个流程的本质不是将LLM智能体应用到一个新领域，而是**构建一个方法论来系统性提升LLM智能体本身的核心能力**——即使用海量、多样化外部工具的能力。 - **符合目标**: 这直接命中了你“构建、改进或演化 LLM智能体”的核心目标。它不是一次性的应用，而是一个可扩展的、用于**改进**智能体的框架。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文明确围绕 `LLM-based Agents` 展开，并致力于提升其 `agentic task performance`。 - **智能体能力**: 论文的焦点是 `Tool Use / Tool Augmentation`，这是单智能体研究的核心子方向之一。它解决了智能体如何在大规模、真实世界的工具生态中进行有效选择和调用的关键问题。 - **演化机制**: 虽然论文标题未直接使用“Self-Evolving”，但其提出的“automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training”本质上是一个**自动化、迭代式的智能体能力提升机制**。它通过自动化地发现新工具、生成训练数据并微调模型，实现了智能体能力的持续增强，这与“自我演化”和“迭代改进”的精神高度一致。 3.  **第三步：排除标准——未触及** - 论文的主要贡献是提升智能体的工具使用效率和性能，而非安全、对齐或可解释性。 - 论文不涉及多模态或视觉内容，其焦点是基于API的MCP工具。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文研究的“工具使用”是智能体进行复杂任务规划和执行的关键环节，属于Agentic AI的范畴，而非单纯的LLM基础推理能力提升。 **结论**: 该论文的核心贡献是提出了一种新颖的、可扩展的自动化流程（MCP-Flow），用于**系统性提升LLM智能体在真实世界中的工具使用能力**。这完全符合你“构建、改进或演化 LLM智能体”的研究目标，并且精准地落在了“单智能体”方向下的“工具使用”子方向。其自动化、迭代式的方法论也与“自我演化”的理念相契合。因此，这篇论文是高度相关且应被保留的前沿研究。"
    },
    {
        "index": "#23",
        "title": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction",
        "link": "/arxiv/2510.24168",
        "arxiv_id": "2510.24168",
        "authors": "Weihua Cheng, Ersheng Ni, Wenlong Wang, Yifei Sun, Junming Liu, Wangyu Shen, Yirong Chen, Botian Shi, Ding Wang",
        "summary": "The rapid progress of Large Language Models (LLMs) and their multimodal extensions (MLLMs) has enabled agentic systems capable of perceiving and acting across diverse environments. A challenging yet impactful frontier is the development of GUI agents, which must navigate complex desktop and web interfaces while maintaining robustness and generalization. Existing paradigms typically model tasks as long-chain executions, concatenating historical trajectories into the context. While approaches such as Mirage and GTA1 refine planning or introduce multi-branch action selection, they remain constrained by two persistent issues: Dependence on historical trajectories, which amplifies error propagation. And Local exploration bias, where \"decision-first, observation-later\" mechanisms overlook critical interface cues. We introduce the Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the principle of observe first, then decide. MGA models each step as an independent, context-rich environment state represented by a triad: current screenshot, task-agnostic spatial information, and a dynamically updated structured memory. Experiments on OSworld benchmarks, real desktop applications (Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves substantial gains in robustness, generalization, and efficiency compared to state-of-the-art baselines. The code is publicly available at: {https://anonymous.4open.science/r/MGA-3571}.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.661654",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心是提出一个名为“Memory-Driven GUI Agent (MGA)”的**新框架**，用于构建和改进GUI智能体。它不是简单地将现有智能体应用于某个领域，而是针对现有智能体范式（如依赖历史轨迹导致的错误传播、局部探索偏差）提出了根本性的改进方法。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。 2.  **第二步：正面指标——高度匹配** - **核心范式**: 论文明确研究 `LLM-based Agents`，特别是 `GUI Agent`。 - **智能体能力**: 论文的核心贡献集中在两个关键能力上： - **`Memory`**: 标题和摘要都强调了“Memory-Driven”，并详细描述了其“dynamically updated structured memory”机制，这是对智能体记忆能力的直接改进。 - **`Planning`**: 论文提出的“observe first, then decide”原则，是对智能体决策和规划流程的重构，旨在解决现有方法的规划缺陷。这与`ReAct`等规划范式一脉相承，但提出了新的改进。 - **`Self-Correction`**: 虽然没有直接使用这个词，但其“observation-centric”的设计和结构化记忆，本质上是为了让智能体能更好地感知当前状态，从而纠正之前行动的偏差，这是一种隐式的自我纠错机制。 3.  **第三步：排除标准——未触及** - 论文的主要贡献不是关于安全、对齐或可解释性。 - 论文虽然使用了视觉信息（截图），但这完全符合排除标准中的例外情况：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉（截图）是智能体感知GUI环境的工具，而论文的**研究核心**是利用这些感知信息进行记忆和决策的**智能体框架**，而非视觉模型本身。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何在复杂任务中进行多步推理和规划的典型案例。它提出的“observe first, then decide”是一种新的Agentic规划框架，因此应被保留，而不是被排除为非Agentic的基础推理。 **最终决策**: 该论文的核心贡献是提出了一种名为MGA的新型LLM智能体框架，它通过引入结构化记忆和“观察优先”的决策机制，显著改进了GUI智能体的规划、记忆和鲁棒性。这完全契合您研究目标中的“单智能体”方向，特别是关于智能体的规划和记忆能力的改进。因此，这篇论文应该被保留。"
    },
    {
        "index": "#27",
        "title": "From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems",
        "link": "/arxiv/2510.24145",
        "arxiv_id": "2510.24145",
        "authors": "Yu Luo, Jiamin Jiang, Jingfei Feng, Lei Tao, Qingliang Zhang, Xidao Wen, Yongqian Sun, Shenglin Zhang, Jielong Huang, Nan Qi, Dan Pei",
        "summary": "Incident management (IM) is central to the reliability of large-scale cloud systems. Yet manual IM, where on-call engineers examine metrics, logs, and traces is labor-intensive and error-prone in the face of massive and heterogeneous observability data. Existing automated IM approaches often struggle to generalize across systems, provide limited interpretability, and incur high deployment costs, which hinders adoption in practice. In this paper, we present OpsAgent, a lightweight, self-evolving multi-agent system for IM that employs a training-free data processor to convert heterogeneous observability data into structured textual descriptions, along with a multi-agent collaboration framework that makes diagnostic inference transparent and auditable. To support continual capability growth, OpsAgent also introduces a dual self-evolution mechanism that integrates internal model updates with external experience accumulation, thereby closing the deployment loop. Comprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art performance and show that OpsAgent is generalizable, interpretable, cost-efficient, and self-evolving, making it a practically deployable and sustainable solution for long-term operation in real-world cloud systems.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.669209",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了“多智能体”和“自我演化”两个关键方向。 以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个已有的LLM智能体框架应用到云系统故障管理领域。它的核心贡献是**构建了一个全新的、名为OpsAgent的“self-evolving multi-agent system”（自我演化的多智能体系统）**。论文明确提出了一个“dual self-evolution mechanism”（双重自我演化机制），这属于方法论和新框架的创新，而非单纯的应用。因此，它避开了“非演化型应用”的排除规则。 2.  **第二步：正面指标** - 论文摘要中包含了大量核心关注点的关键词和概念： - **核心范式**: `Multi-Agent Systems (MAS)`, `Self-Evolving` - **多智能体**: `multi-agent collaboration framework` (协作框架) - **演化机制**: `self-evolving`, `dual self-evolution mechanism`, `continual capability growth`, `internal model updates with external experience accumulation` - 这些指标强烈表明该论文与您的研究焦点高度相关。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐或多模态。它关注的是智能体的协作与演化能力，因此没有触碰到任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美范例。虽然它的应用场景是特定的“云系统事件管理”，但其**核心创新点在于提出了一种新的“自我演化”机制**。根据您的规则，“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”。因此，这篇论文应该被保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建一个具有新颖双重自我演化机制的多智能体协作框架。它直接对“LLM智能体及其演化”这一课题做出了贡献，特别是在“多智能体协作”和“自我演化”两个前沿方向上。因此，这篇论文是您研究课题的理想候选，应予以保留。"
    },
    {
        "index": "#25",
        "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning",
        "link": "/arxiv/2510.24161",
        "arxiv_id": "2510.24161",
        "authors": "Wentao Tan, Bowen Wang, Heng Zhi, Chenyu Liu, Zhe Li, Jian Liu, Zengrong Lin, Yukun Dai, Yipeng Chen, Wenjie Yang, Enci Xie, Hao Xue, Baixu Ji, Chen Xu, Zhibin Wang, Tianshi Wang, Lei Zhu, Heng Tao Shen",
        "summary": "Multimodal large language models (MLLMs) have advanced vision-language reasoning and are increasingly deployed in embodied agents. However, significant limitations remain: MLLMs generalize poorly across digital-physical spaces and embodiments; vision-language-action models (VLAs) produce low-level actions yet lack robust high-level embodied reasoning; and most embodied large language models (ELLMs) are constrained to digital-space with poor generalization to the physical world. Thus, unified models that operate seamlessly across digital and physical spaces while generalizing across embodiments and tasks remain absent. We introduce the \\textbf{Boundless Large Model (BLM$_1$)}, a multimodal spatial foundation model that preserves instruction following and reasoning, incorporates embodied knowledge, and supports robust cross-embodiment control. BLM$_1$ integrates three key capabilities -- \\textit{cross-space transfer, cross-task learning, and cross-embodiment generalization} -- via a two-stage training paradigm. Stage I injects embodied knowledge into the MLLM through curated digital corpora while maintaining language competence. Stage II trains a policy module through an intent-bridging interface that extracts high-level semantics from the MLLM to guide control, without fine-tuning the MLLM backbone. This process is supported by a self-collected cross-embodiment demonstration suite spanning four robot embodiments and six progressively challenging tasks. Evaluations across digital and physical benchmarks show that a single BLM$_1$ instance outperforms four model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving $\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical tasks.",
        "subjects": "Artificial Intelligence, Multimedia, Robotics",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.668044",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建一个新的LLM智能体框架**。它没有将现有智能体作为工具去解决一个特定领域的问题，而是提出了一个名为BLM$_1$的“无界大模型”，旨在解决现有具身智能体在泛化能力上的根本性缺陷（跨空间、跨任务、跨具身形态）。其核心贡献是这个新的模型架构和训练范式，这完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **智能体能力**: 论文明确提到了“指令遵循和推理”，这直接关联到智能体的**规划**能力。其设计的“策略模块”和“跨具身控制”能力，本质上是让智能体能够使用不同的物理形态作为**工具**与环境交互。 - **核心范式**: 论文的研究对象是“具身智能体”，属于`LLM-based Agents`的范畴。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性，因此不在此排除范围内。 - **多模态与视觉**: 这是本论文最需要仔细辨析的一点。虽然论文标题和摘要都强调了“多模态”，但它完全符合筛选标准中的例外情况：“**除非它们被用作智能体感知环境的工具，而不是研究的核心**”。在这篇论文中，视觉和多模态能力是智能体实现“跨空间”和“跨具身”目标的必要感知手段，是服务于Agentic目标的**工具**。论文的核心创新点不在于提出新的视觉模型或多模态融合技术，而在于构建一个能够利用这些感知能力进行高级推理和控制的智能体框架。因此，不应因此排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“推理”是“具身推理”，是在智能体框架下进行的多步决策和规划，属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴，因此应该**保留**。 5.  **第五步：最终决策** - 综合以上分析，该论文的核心贡献在于提出了一种新的、具有更强泛化能力的LLM智能体架构（BLM$_1$），显著提升了智能体在复杂环境下的规划和工具使用能力。这完全符合我的研究焦点中的“单智能体”方向。因此，最终判断为 **True**。"
    },
    {
        "index": "#42",
        "title": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents",
        "link": "/arxiv/2510.23822",
        "arxiv_id": "2510.23822",
        "authors": "Zhenyu Zhang, Tianyi Chen, Weiran Xu, Alex Pentland, Jiaxin Pei",
        "summary": "Long-horizon tasks requiring multi-step reasoning and dynamic re-planning remain challenging for large language models (LLMs). Sequential prompting methods are prone to context drift, loss of goal information, and recurrent failure cycles, while hierarchical prompting methods often weaken cross-level continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive Context-Aware Reasoning and Planning), a hierarchical framework with shared context for reasoning and planning in LLMs. ReCAP combines three key mechanisms: (i) plan-ahead decomposition, in which the model generates a full subtask list, executes the first item, and refines the remainder; (ii) structured re-injection of parent plans, maintaining consistent multi-level context during recursive return; and (iii) memory-efficient execution, bounding the active prompt so costs scale linearly with task depth. Together these mechanisms align high-level goals with low-level actions, reduce redundant prompting, and preserve coherent context updates across recursion. Experiments demonstrate that ReCAP substantially improves subgoal alignment and success rates on various long-horizon reasoning benchmarks, achieving a 32% gain on synchronous Robotouille and a 29% improvement on asynchronous Robotouille under the strict pass@1 protocol.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-27",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.682280",
        "filter_reason": "这篇论文完全符合筛选要求，应被保留。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为ReCAP的、用于LLM智能体的分层推理与规划框架。这完全符合“保留”标准，即论文的核心是关于**构建、改进LLM智能体的方法论或新框架**。它不是将现有智能体作为工具去解决某个特定领域（如生物、金融）的问题，而是专注于改进智能体本身的能力。 2.  **第二步：正面指标** 论文高度匹配我的核心关注点： *   **核心范式**: 论文标题和摘要明确提到了 \"Large Language Model Agents\"，属于 `LLM-based Agents` 范畴。 *   **智能体能力**: 论文的核心是解决 \"multi-step reasoning and dynamic re-planning\" 问题，直接命中了 `Planning` 和 `Reasoning` 这两个关键能力。其提出的 \"memory-efficient execution\" 和 \"context-aware\" 机制也与 `Memory` 密切相关。其工作模式（生成子任务、执行、完善）与 `ReAct` 等经典智能体范式一脉相承。 3.  **第三步：排除标准** 论文的研究内容不涉及安全与对齐（Safety, Alignment）、多模态（Vision）等排除标准。它的焦点纯粹在于提升智能体的任务执行能力。 4.  **第四步：处理特殊和模糊情况** 论文的研究内容恰好是“推理/规划”这一特殊情况的典型“保留”案例。它不是在提升LLM的基础数学或逻辑推理能力，而是在构建一个**智能体框架**，让智能体能够更好地进行**多步规划和动态重规划**，这正是Agentic AI研究的核心。 **总结**: 该论文的本质是提出一种新的LLM智能体框架（ReCAP），旨在通过改进其规划、推理和上下文记忆机制，来提升其在长时程复杂任务中的表现。这直接命中了我的研究目标——“构建、改进或演化LLM智能体”，特别是“单智能体”方向下的“规划”与“记忆”子方向。因此，该论文是高度相关的前沿研究，应被保留。"
    },
    {
        "index": "#48",
        "title": "Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents",
        "link": "/arxiv/2510.23691",
        "arxiv_id": "2510.23691",
        "authors": "Zihao Wang, Xujing Li, Yining Ye, Junjie Fang, Haoming Wang, Longxiang Liu, Shihao Liang, Junting Lu, Zhiyong Wu, Jiazhan Feng, Wanjun Zhong, Zili Li, Yu Wang, Yu Miao, Bo Zhou, Yuanfan Li, Hao Wang, Zhongkai Zhao, Faming Wu, Zhengxuan Jiang, Weihao Tan, Heyuan Yao, Shi Yan, Xiangyang Li, Yitao Liang, Yujia Qin, Guang Shi",
        "summary": "We present Game-TARS, a generalist game agent trained with a unified, scalable action space anchored to human-aligned native keyboard-mouse inputs. Unlike API- or GUI-based approaches, this paradigm enables large-scale continual pre-training across heterogeneous domains, including OS, web, and simulation games. Game-TARS is pre-trained on over 500B tokens with diverse trajectories and multimodal data. Key techniques include a decaying continual loss to reduce causal confusion and an efficient Sparse-Thinking strategy that balances reasoning depth and inference cost. Experiments show that Game-TARS achieves about 2 times the success rate over the previous sota model on open-world Minecraft tasks, is close to the generality of fresh humans in unseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet in FPS benchmarks. Scaling results on training-time and test-time confirm that the unified action space sustains improvements when scaled to cross-game and multimodal data. Our results demonstrate that simple, scalable action representations combined with large-scale pre-training provide a promising path toward generalist agents with broad computer-use abilities.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-27",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.690860",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出了一种名为 **Game-TARS** 的新框架，用于构建**通才游戏智能体**。它不仅仅是应用一个已有的智能体，而是提出了一套全新的方法论，包括“统一的、可扩展的动作空间”、“衰减的持续损失”和“稀疏思考策略”等关键技术。这完全符合“核心贡献在于构建、改进LLM智能体”的要求。它不是非演化型应用，因为其贡献在于智能体本身的设计和训练，而非在特定领域的应用结果。 2.  **第二步：正面指标 (高度匹配)** 论文紧密围绕你的核心关注点： *   **核心范式**: 论文明确研究 `LLM-based Agents`，旨在构建一个“通才智能体”。 *   **智能体能力**: 论文的“统一的动作空间”是智能体与环境交互和**工具使用** 的核心创新。其“稀疏思考策略”直接关系到智能体的**规划** 和多步推理能力，旨在平衡推理深度与成本，这是智能体自主决策的关键。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题，其焦点是提升智能体的能力和泛化性。 *   **多模态与视觉**: 虽然论文标题和摘要都提到了“多模态”，但这完全符合筛选标准中的例外情况。在这里，视觉（以及其他模态）是作为智能体**感知游戏环境的工具**而存在的，是智能体实现其目标（玩游戏）的必要输入。论文的核心贡献并非提出新的视觉模型或视觉理解技术，而是构建一个能够有效利用多模态信息进行决策的智能体框架。因此，这不应成为排除的理由。 4.  **第四步：特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文提出的“稀疏思考策略”是典型的关于**智能体如何进行规划和推理**的技术。它不是在提升LLM本身的基础数学或逻辑能力，而是在优化智能体在复杂任务中的决策过程，因此应被保留。 **最终决策**: 该论文的核心是提出一种构建更强大、更通用的单智能体（Agentic）的新范式。它通过创新性的动作空间表示和推理策略，显著提升了LLM智能体在复杂、多模态环境中的表现。这完全契合你研究课题中的“单智能体”方向，特别是关于智能体规划和工具使用的子方向。因此，这篇论文应被**保留**。"
    },
    {
        "index": "#160",
        "title": "RefleXGen:The unexamined code is not worth using",
        "link": "/arxiv/2510.23674",
        "arxiv_id": "2510.23674",
        "authors": "Bin Wang, Hui Li, AoFan Liu, BoTao Yang, Ao Yang, YiLu Zhong, Weixiang Huang, Yanping Zhang, Runhuai Huang, Weimin Zeng",
        "summary": "Security in code generation remains a pivotal challenge when applying large language models (LLMs). This paper introduces RefleXGen, an innovative method that significantly enhances code security by integrating Retrieval-Augmented Generation (RAG) techniques with guided self-reflection mechanisms inherent in LLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing specialized secure code datasets - processes that can be resource-intensive - RefleXGen iteratively optimizes the code generation process through self-assessment and reflection without the need for extensive resources. Within this framework, the model continuously accumulates and refines its knowledge base, thereby progressively improving the security of the generated code. Experimental results demonstrate that RefleXGen substantially enhances code security across multiple models, achieving a 13.6% improvement with GPT-3.5 Turbo, a 6.7% improvement with GPT-4o, a 4.5% improvement with CodeQwen, and a 5.8% improvement with Gemini. Our findings highlight that improving the quality of model self-reflection constitutes an effective and practical strategy for strengthening the security of AI-generated code.",
        "subjects": "Software Engineering, Artificial Intelligence, Cryptography and Security",
        "date": "2025-10-27",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.787270",
        "filter_reason": "这篇论文符合筛选要求，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为 RefleXGen 的**新方法/框架**。该方法的核心机制是“引导式自我反思”和“迭代优化”，使模型能够通过“自我评估和反思”来“持续积累和优化其知识库”，从而“逐步提高”生成代码的安全性。这完全符合“构建、改进或演化 LLM智能体”的定义，特别是属于“自我演化”的范畴。它不是简单地将LLM应用于安全领域，而是构建了一个能让LLM自我演化的框架。因此，根据第一步，应**保留**。 2.  **第二步：正面指标** 论文摘要中包含了大量与我的研究焦点高度相关的正面指标： *   **核心范式**: `Self-Evolving` (自我演化) 是其核心思想。 *   **智能体能力**: 明确提到了 `Self-Reflection` (自我反思)、`Self-Correction` (自我评估) 和 `Iterative Improvement` (迭代优化)。 这些指标强烈表明该论文与我的研究目标高度相关。 3.  **第三步：排除标准** 论文的应用领域是“代码安全”，这触及了“安全”这一排除标准。然而，关键在于区分论文的**应用领域**和**核心贡献**。一篇论文如果主要贡献是提出一种新的漏洞分析算法或安全对齐技术，那么应该被排除。但本文的核心贡献是**一种通用的自我演化机制**，而代码安全只是该机制的应用场景和验证领域。论文的结论也强调“改进模型自我反思的质量”是核心策略，而非安全本身。因此，它不应被归为主要贡献为“安全”的论文而被排除。 4.  **第四步：处理特殊和模糊情况** 该情况完美符合“自我演化的应用”这一例外规则。规则明确指出：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” RefleXGen 正是这样一种应用于“代码安全”领域的“自我演化”智能体框架。因此，根据此核心规则，应**保留**。 5.  **第五步：最终决策** 综合以上分析，尽管论文的标题和摘要开头聚焦于“代码安全”这一应用领域，但其本质和核心贡献是构建了一个基于自我反思和迭代优化的LLM智能体框架。这完全符合我研究课题中“自我演化”的核心方向。因此，最终判断为 **True (保留)**。"
    },
    {
        "index": "#123",
        "title": "Lifecycle-Aware code generation: Leveraging Software Engineering Phases in LLMs",
        "link": "/arxiv/2510.24019",
        "arxiv_id": "2510.24019",
        "authors": "Xing Xing, Wei Wang, Lipeng Ma, Weidong Yang, Junjie Zheng",
        "summary": "Recent progress in large language models (LLMs) has advanced automatic code generation, yet most approaches rely on direct, single-step translation from problem descriptions to code, disregarding structured software engineering practices. We introduce a lifecycle-aware framework that systematically incorporates intermediate artifacts such as requirements analysis, state machine modeling, and pseudocode into both the training and inference stages. This design aligns code generation with standard software development phases and enables more structured reasoning. Experiments show that lifecycle-level fine-tuning improves code correctness by up to 75% over the same model before fine-tuning, with performance gains compounding across intermediate stages. Multi-step inference consistently surpasses single-step generation, demonstrating the effectiveness of intermediate scaffolding. Notably, open-source LLMs, once fine-tuned under our framework, match or slightly outperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our framework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and 22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B, respectively. Our pipeline also proves robust with up to 80\\% less training data, confirming its resilience. Ablation studies further reveal that each intermediate artifact contributes distinctly to final code quality, with state machine modeling yielding the most substantial impact. Our source code and detailed experimental data are available at https://anonymous.4open.science/r/Lifecycle-Aware-3CCB.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.772066",
        "filter_reason": "这篇论文符合我的研究范围，其核心贡献在于构建和改进LLM智能体的规划与执行框架。我的判断依据如下： 1.  **核心判断（第一步）**: 论文的核心是提出一个“生命周期感知框架”，而不是简单地将LLM应用于代码生成。这个框架将复杂的代码生成任务分解为一系列结构化的中间步骤（需求分析、状态机建模、伪代码），这本质上是一种**智能体的规划方法论**。它不是对LLM基础能力的简单应用，而是构建了一个让LLM能够进行更复杂、更结构化任务执行的**新框架**。因此，它符合“保留”标准，即“论文的核心是关于构建LLM智能体的方法论或新框架”。 2.  **正面指标（第二步）**: 论文明确涉及了我的核心关注点。 *   **规划**: 论文的整个框架就是一个多步骤的规划过程。智能体（LLM）不是直接生成最终代码，而是先规划出需求、设计状态机、编写伪代码，最后再生成代码。这与`Planning`和`ToT`（Tree of Thoughts）等Agentic范式高度一致。 *   **工具使用**: 论文中的“中间产物”（如状态机、伪代码）可以被看作是智能体在执行复杂任务时使用的**脚手架或内部工具**。智能体通过生成和利用这些中间产物来辅助最终决策，这符合`Tool Use / Tool Augmentation`的范畴。 *   **Agentic AI**: 该框架赋予了LLM一种类似软件工程师的结构化工作流，使其行为更像一个能够遵循复杂流程、分步解决问题的智能体，而非一个简单的“输入-输出”模型。 3.  **排除标准（第三步）**: 论文不涉及安全与对齐、多模态与视觉等排除领域，因此没有触发排除标准。 4.  **特殊情况处理（第四步）**: *   **推理/规划**: 这篇论文是“关于智能体如何进行规划或在复杂任务中进行多步推理”的典型例子。它提出的不是一个新的CoT提示技巧，而是一个完整的、在训练和推理中都起作用的**结构化Agentic框架**。这完全符合保留条件。 **结论**: 尽管论文的应用领域是代码生成，但其核心贡献是提出了一种新颖的、结构化的**LLM智能体规划框架**。它通过引入中间步骤和生命周期概念，显著增强了智能体解决复杂任务的能力。这完全符合我研究课题中“单智能体”方向下的“规划”和“工具使用”子方向。因此，这篇论文应该被保留。"
    },
    {
        "index": "#167",
        "title": "Agentsway -- Software Development Methodology for AI Agents-based Teams",
        "link": "/arxiv/2510.23664",
        "arxiv_id": "2510.23664",
        "authors": "Eranga Bandara, Ross Gore, Xueping Liang, Sachini Rajapakse, Isurunima Kularathne, Pramoda Karunarathna, Peter Foytik, Sachin Shetty, Ravi Mukkamala, Abdul Rahman, Amin Hass, Ng Wee Keong, Kasun De Zoysa, Aruna Withanage, Nilaan Loganathan",
        "summary": "The emergence of Agentic AI is fundamentally transforming how software is designed, developed, and maintained. Traditional software development methodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for human-centric teams and are increasingly inadequate in environments where autonomous AI agents contribute to planning, coding, testing, and continuous learning. To address this methodological gap, we present \"Agentsway\" a novel software development framework designed for ecosystems where AI agents operate as first-class collaborators. Agentsway introduces a structured lifecycle centered on human orchestration, and privacy-preserving collaboration among specialized AI agents. The framework defines distinct roles for planning, prompting, coding, testing, and fine-tuning agents, each contributing to iterative improvement and adaptive learning throughout the development process. By integrating fine-tuned LLMs that leverage outputs and feedback from different agents throughout the development cycle as part of a retrospective learning process, Agentsway enhances domain-specific reasoning, and explainable decision-making across the entire software development lifecycle. Responsible AI principles are further embedded across the agents through the coordinated use of multiple fine-tuned LLMs and advanced reasoning models, ensuring balanced, transparent, and accountable decision-making. This work advances software engineering by formalizing agent-centric collaboration, integrating privacy-by-design principles, and defining measurable metrics for productivity and trust. Agentsway represents a foundational step toward the next generation of AI-native, self-improving software development methodologies. To the best of our knowledge, this is the first research effort to introduce a dedicated methodology explicitly designed for AI agent-based software engineering teams.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-10-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-29T11:00:06.789902",
        "filter_reason": "这篇论文符合您的研究范围，核心判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非简单地将LLM智能体作为工具应用于软件开发领域，而是提出了一套全新的、专门为AI智能体团队设计的**方法论框架**。这个框架定义了智能体的角色、协作流程和演化机制，其本质是关于**如何构建、组织和演化一个多智能体系统**，因此属于“保留”范畴。它不是“非演化型应用”，因为其核心就是“自我改进”。 2.  **正面指标 (第二步):** 论文摘要中包含了大量您关注的核心关键词和概念： *   **多智能体:** 明确提出了 \"AI agents-based Teams\", \"collaboration among specialized AI agents\", \"agent-centric collaboration\"。 *   **自我演化:** 明确提到了 \"iterative improvement and adaptive learning\", \"self-improving software development methodologies\", 以及通过 \"retrospective learning process\" 利用反馈进行微调。这直接命中了您“自我演化”的研究焦点。 *   **智能体能力:** 定义了 \"planning\", \"coding\", \"testing\" 等不同角色的智能体，涉及了智能体的规划和任务分解能力。 3.  **排除标准 (第三步):** 论文虽然提到了 \"Responsible AI principles\" 和 \"explainable decision-making\"，但这并非其**主要贡献**。其主要贡献是“Agentsway”这个方法论本身，安全和可解释性是该方法论内嵌的特性，而非研究的核心问题。因此，不触发排除标准。 4.  **特殊和模糊情况处理 (第四步):** *   **自我演化的应用:** 这篇论文是“自我演化机制在特定领域应用”的完美范例。它的核心是提出一种新的“自我演化”方法论（Agentsway），并将其应用于软件开发领域。根据您的规则，这种情况应该**保留**。 *   **推理/规划:** 论文中的规划是**智能体系统层面**的规划，即如何组织不同角色的智能体完成复杂的软件开发任务，这属于Agentic AI的范畴，而非提升LLM本身的基础推理能力。 **最终决策 (第五步):** 综合来看，这篇论文的核心贡献是构建了一个**多智能体协作框架**，并为其设计了**自我演化和迭代改进的机制**。它直接对应了您研究目标中的“多智能体”和“自我演化”两个核心方向。论文探讨的不是智能体在某个领域的单次应用，而是智能体团队如何作为一个整体进行结构化协作和持续学习，这正是“LLM智能体及其演化”这一课题的前沿内容。因此，该论文高度相关，应予以保留。"
    }
]