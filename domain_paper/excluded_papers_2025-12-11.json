[
    {
        "index": "#7",
        "title": "Computing Evolutionarily Stable Strategies in Imperfect-Information Games",
        "link": "/arxiv/2512.10279",
        "arxiv_id": "2512.10279",
        "authors": "Sam Ganzfried",
        "subjects": "Computer Science and Game Theory, Artificial Intelligence, Multiagent Systems, Theoretical Economics, Populations and Evolution",
        "date": "2025-12-11",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.847803",
        "filter_reason": "这篇论文不符合您的研究范围，应予以排除。我的判断过程如下： 1.  **第一步：核心判断——论文本质是博弈论算法，而非LLM智能体研究。** 论文的核心贡献是提出一种用于计算“演化稳定策略”的算法。这里的“演化稳定策略”是博弈论中的一个经典概念，用于描述在种群演化中一种策略的稳定性。论文的研究对象是“不完美信息博弈”，这是一个数学和计算机科学理论领域。整篇论文没有提及任何关于大语言模型（LLM）、智能体架构或其能力构建的内容。因此，它不属于“构建、改进或演化LLM智能体”的范畴，直接在第一步的核心判断中就应被排除。 2.  **第二步：正面指标——缺乏核心关注点。** 尽管论文标题中出现了“Evolutionarily”和“Games”（可关联到Multi-Agent），但这些术语在本文中的含义与您的研究焦点完全不同。 *   **“演化”**: 在本文中指生物学和博弈论意义上的种群策略演化，而非AI智能体通过经验、反思进行“自我完善和迭代”。 *   **“博弈”**: 本文的“博弈”是抽象的数学模型，其中的“参与者”是理性的决策单元，而不是具备规划、记忆、工具使用等能力的LLM智能体。 *   论文完全不包含您关注的核心范式，如 `Agentic AI`, `LLM-based Agents`, `Self-Evolving`，也不涉及智能体能力如 `Planning`, `Tool Use`, `Memory` 等。 3.  **第三步：排除标准——不适用，但已超出范围。** 该论文不涉及安全、对齐或多模态等排除标准，但这仅仅是因为它属于一个完全不同的研究领域（计算博弈论），而不是您关注的Agentic AI领域。 4.  **第四步：处理特殊和模糊情况——术语混淆。** 这篇论文是一个典型的术语混淆案例。它使用了“演化”和“多参与者”等词汇，但这些词根植于博弈论的土壤，与您所研究的“自我演化智能体”和“多智能体协作”有着本质区别。您的研究焦点是智能体本身的设计和能力演化，而本文是关于博弈模型中均衡解的计算方法。 **最终决策**: 该论文是一篇纯粹的博弈论与算法研究论文，其核心贡献与“LLM智能体及其演化”这一课题毫无关联。它既没有使用LLM作为智能体基础，也没有研究智能体的规划、记忆、协作或自我演化机制。因此，应明确排除。"
    },
    {
        "index": "#3",
        "title": "Empirical Hardness in Multi-Agent Pathfinding: Research Challenges and Opportunities",
        "link": "/arxiv/2512.10078",
        "arxiv_id": "2512.10078",
        "authors": "Jingyao Ren, Eric Ewing, T. K. Satish Kumar, Sven Koenig, Nora Ayanian",
        "subjects": "Multiagent Systems",
        "date": "2025-12-10",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.846724",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质不符。** *   论文的核心贡献是研究“多智能体寻路（MAPF）”这一经典算法问题的**经验性难度**，包括算法选择、实例特征分析和基准数据集生成。这是一个属于运筹学、经典AI规划或机器人学领域的课题。 *   它的核心是**分析算法性能和问题难度**，而不是**构建、改进或演化LLM智能体**。论文中完全没有提及LLM，其研究的“智能体”是指地图上需要移动的简单实体（如机器人），而非具备复杂认知能力的LLM智能体。 *   因此，该论文完全符合第一步的排除标准：“非演化型应用”——它将“智能体”作为一个研究对象，但并未涉及LLM或智能体框架本身的构建与演化。 2.  **正面指标缺失（第二步）：缺乏核心关注点。** *   论文虽然包含“Multi-Agent”一词，但其语境是经典的MAPF问题，与我所关注的“LLM-based Agents”或具备协作、通信、社会学习能力的智能体社会无关。 *   论文完全缺失我关注的核心范式和能力指标，如 `Agentic AI`, `LLM-based Agents`, `Self-Evolving`, `Tool Use`, `Memory`, `Self-Reflection` 等。它提到的“Planning”是几何路径规划，而非智能体在复杂任务中的自主规划。 3.  **特殊情况的澄清（第四步）：** *   论文中的“Planning”不属于我关注的“智能体规划”。它不涉及ReAct、ToT等Agentic框架，而是关于为简单智能体计算无碰撞路径的算法。 *   论文不涉及任何“自我演化”机制，因此也不适用相关的例外规则。 **总结：** 该论文是一篇关于经典算法问题（MAPF）的分析与展望，其研究对象和研究目标与“LLM智能体及其演化”这一前沿课题存在根本性的区别。尽管标题中包含“Multi-Agent”，但这属于关键词陷阱，其内涵与我的研究焦点完全不同。因此，必须排除。"
    },
    {
        "index": "#9",
        "title": "A Simulation Framework for Studying Recommendation-Network Co-evolution in Social Platforms",
        "link": "/arxiv/2512.10106",
        "arxiv_id": "2512.10106",
        "authors": "Gaurav Koley, Sanika Digrajkar",
        "subjects": "Social and Information Networks, Multiagent Systems",
        "date": "2025-12-10",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.848309",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 论文的核心贡献是构建了一个**基于智能体的仿真框架**，用于研究社交平台中“推荐系统”与“社交网络”之间的**协同演化**关系。 - **是否构建/改进/演化LLM智能体**: **否**。论文虽然提到了“agent-based simulator”，但其目的是利用智能体作为仿真组件来模拟一个社会现象，而不是为了提升智能体本身的能力。摘要中明确指出推荐系统是一个“图注意力网络（GAT）”，而非LLM。论文的研究焦点是推荐算法对网络结构的影响，这是一个典型的计算社会科学或推荐系统研究课题，而非Agentic AI研究。 - **结论**: 该论文属于“非演化型应用”的排除范畴。它将智能体仿真作为一种工具，应用于研究推荐系统和社交网络这一特定领域问题，其核心贡献不在于智能体本身的构建或演化。 2.  **第二步：正面指标分析** - 论文确实包含 `Multi-Agent Systems (MAS)` 的概念，因为它是一个多智能体仿真。 - 它也提到了 `co-evolve`，但这里的演化是指“推荐系统”和“网络”两个系统层面的相互演化，**不是**指智能体通过经验、反思或环境反馈进行“自我完善和迭代”。 - 关键的正面指标如 `LLM-based Agents`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Self-Improvement` 等均未在摘要中出现。 3.  **第三步：排除标准分析** - 论文不涉及安全、对齐或多模态等排除项。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 此处不适用。论文的核心是提出一个仿真框架来观察现象，而不是提出一种新的“自我演化”机制。因此，关于“自我演化应用”的例外保留规则不适用。 **最终决策**: 综合以上分析，这篇论文的研究目标是利用多智能体仿真来理解推荐系统对社会网络结构的影响。尽管它使用了“智能体”和“演化”这两个词，但其内涵与您所关注的“LLM智能体及其演化”（即智能体自身的规划、工具使用、自我反思和自我完善能力）完全不同。论文的核心是**仿真方法论**和**社会现象发现**，而非**智能体能力的创新**。因此，该论文不符合您的研究范围，应予以排除。"
    },
    {
        "index": "#5",
        "title": "Better Prevent than Tackle: Valuing Defense in Soccer Based on Graph Neural Networks",
        "link": "/arxiv/2512.10355",
        "arxiv_id": "2512.10355",
        "authors": "Hyunsung Kim, Sangwoo Seo, Hoyoung Choi, Tom Boomstra, Jinsung Yoon, Chanyoung Park",
        "subjects": "Machine Learning, Multiagent Systems",
        "date": "2025-12-11",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.847254",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是提出了一个名为DEFCON的框架，用于量化足球运动员的防守贡献。它使用的技术是图注意力网络，输入是足球比赛的事件和追踪数据，输出是对球员防守表现的评估。 - **是否符合保留标准**: 不符合。该论文的核心是**构建一个特定领域的分析工具**（体育分析），而不是构建、改进或演化一个具有自主性的LLM智能体。 - **是否符合排除标准**: 完全符合。它属于典型的“**非演化型应用**”。论文将一个机器学习模型（GNN）作为工具，应用在足球这个特定领域，以解决该领域的评估问题。这与我的核心目标——研究Agentic AI的构建与演化——背道而驰。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现我关注的核心范式和能力关键词，如 `LLM-based Agents`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent Systems`, `Self-Evolving` 等。虽然足球比赛本身可以看作一个多智能体系统，但论文并未提出新的智能体协作、通信或演化机制，而是对已有的系统行为进行**事后分析**。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及智能体的推理/规划框架，也未提出任何自我演化机制，因此特殊情况的例外条款不适用。 **最终决策**: 综合以上分析，这篇论文的本质是**应用机器学习技术解决特定领域（体育分析）问题的研究**。它没有构建任何形式的LLM智能体，也没有提出关于智能体规划、协作或自我演化的新方法论。因此，它完全不符合我关于“LLM智能体及其演化”的研究课题要求，应予以排除。"
    },
    {
        "index": "#1",
        "title": "LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification",
        "link": "/arxiv/2512.10793",
        "arxiv_id": "2512.10793",
        "authors": "Michael Schlee, Christoph Weisser, Timo Kivimäki, Melchizedek Mashiku, Benjamin Saefken",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.247659",
        "filter_reason": "根据您提供的筛选标准，我对这篇论文进行了严格的分析，最终判断其不符合您的研究范围。以下是详细的判断过程： 1.  **第一步：核心判断** - **论文的核心贡献是什么？** 论文的核心贡献是提出了一种名为 `LabelFusion` 的**融合集成方法**，用于提升文本分类任务的准确性和成本效益。它通过一个多层感知机（FusionMLP）来学习如何结合传统Transformer分类器的嵌入向量和LLM生成的类别分数。 - **是否符合保留标准？** 不符合。这篇论文的本质是**模型融合**或**集成学习**在文本分类任务上的应用，而不是构建、改进或演化一个具有自主性的LLM智能体。 - **是否符合排除标准？** 符合。该论文明确属于**“非演化型应用”**。它将LLM作为一个黑箱工具，通过提示工程获取分类信号，然后与另一个模型融合，以解决“文本分类”这一特定领域的问题。论文的焦点在于如何更好地融合两种模型的输出，而不是研究LLM本身如何作为一个智能体去行动、规划或演化。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现您所关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 论文也未提及任何智能体能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。虽然它使用了LLM，但使用方式是“结构化提示工程”以获取分类分数，这与智能体自主使用工具解决复杂问题的范式有本质区别。 3.  **第三步：排除标准** - 该论文不涉及安全、对齐或多模态等排除项，但这并不改变其在第一步就被排除的根本性质。 4.  **第四步：处理特殊和模糊情况** - **推理/规划：** 论文不涉及智能体的规划或多步推理框架。它关注的是分类任务的最终预测，而非达成目标的过程。 - **自我演化的应用：** 论文的核心是“融合”，而非“自我演化”。它没有提出任何让智能体通过经验或反馈进行自我完善的机制。 **最终决策：** 这篇论文的核心是**一种用于提升文本分类性能的模型融合技术**。它将LLM视为一个功能组件（分类器/特征提取器），而不是研究的主体。您的研究焦点是“LLM智能体及其演化”，关注的是智能体的内在架构、能力和演化机制。因此，这篇关于模型集成的应用型论文与您的研究目标不符，应予以排除。"
    },
    {
        "index": "#6",
        "title": "Certifying Concavity and Monotonicity in Games via Sum-of-Squares Hierarchies",
        "link": "/arxiv/2512.10292",
        "arxiv_id": "2512.10292",
        "authors": "Vincent Leon, Iosif Sakos, Ryann Sim, Antonios Varvitsiotis",
        "subjects": "Computer Science and Game Theory, Multiagent Systems, Optimization and Control",
        "date": "2025-12-11",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.847528",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是提出了一种名为“平方和层次结构”的数学方法，用于**证明（certifying）**多人博弈中效用函数的凹性和单调性。它属于理论博弈论和优化领域的研究。 - **与筛选标准的匹配**: 论文的核心**不是**关于构建、改进或演化LLM智能体。它没有提出任何新的智能体框架、智能体能力（如规划、记忆）或演化机制。它研究的是博弈（智能体所处的环境）的数学属性，而不是智能体本身。 - **结论**: 根据第一步的排除规则，这篇论文应被**排除**。它不属于构建LLM智能体、多智能体系统或自我演化的方法论研究。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现您列出的任何核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。 - 虽然论文提到了 \"multiplayer games\"，但这只是其研究的数学对象，其研究焦点是博弈的数学性质（凹性、单调性），而非智能体之间的交互行为或智能体架构。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全、对齐或多模态等排除标准，但第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文讨论的是博弈的数学结构如何保证均衡的存在性和算法的收敛性，这属于博弈论的理论分析，**不是**关于智能体如何进行自主规划和多步推理的Agentic框架研究。因此，它不符合“保留”的条件。 **最终决策**: 这篇论文是一篇纯粹的理论博弈论与优化研究。它的核心是提供一种数学工具来分析和证明博弈模型的属性，而不是设计或改进智能体本身。您的研究焦点是“LLM智能体及其演化”，关注的是智能体的架构、能力和演化机制。尽管“多智能体”是您的研究方向之一，但该论文的研究内容（博弈的数学性质）与您的研究目标（智能体的构建与演化）存在本质区别。因此，这篇论文与您的研究课题不相关。"
    },
    {
        "index": "#9",
        "title": "From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages",
        "link": "/arxiv/2512.10630",
        "arxiv_id": "2512.10630",
        "authors": "Smiljana Antonijevic Ubois",
        "subjects": "Computation and Language, Computers and Society",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.259242",
        "filter_reason": "解析失败"
    },
    {
        "index": "#3",
        "title": "Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting",
        "link": "/arxiv/2512.10780",
        "arxiv_id": "2512.10780",
        "authors": "Manurag Khullar, Utkarsh Desai, Poorva Malviya, Aman Dalmia, Zheyuan Ryan Shi",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.250056",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是评估，而非构建或演化。** 论文的核心贡献是**评估**现有大型语言模型（LLMs）在处理罗马化印度语文本时的性能表现，特别是在医疗分诊这一特定应用场景中。它提出并量化了一个“Script Gap”问题，但并未提出任何新的LLM智能体架构、规划方法、工具使用机制或多智能体协作框架。因此，这篇论文属于“非演化型应用”，即将LLM作为工具应用于特定领域（医疗）并评估其表现，而不是研究如何构建或演化智能体本身。根据第一步的筛选标准，应予以排除。 2.  **第二步：正面指标——论文不包含我的核心关注点。** 论文摘要中完全没有出现 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等任何核心范式或智能体能力的关键词。其研究焦点是模型的鲁棒性和在不同输入形式下的性能差异，这与智能体的自主行为、规划或演化机制无关。 3.  **第三步：排除标准——论文的主要贡献触及了安全与对齐领域。** 论文的研究背景是“high-stakes clinical applications”，其结论明确指出了一个“critical safety blind spot”。论文的核心关切是LLM在真实世界高风险应用中的**可靠性**和**安全性**问题。根据筛选标准，只要论文的主要贡献是关于 `Safety` 或 `Reliability`，就应排除。这篇论文完全符合此排除标准。 **综合结论**: 该论文是一项关于LLM在特定任务（医疗分诊）和特定输入（罗马化文本）下的**性能评估与安全性分析**研究。它没有提出任何关于构建、改进或演化LLM智能体的新方法或框架。其核心贡献在于揭示了模型在安全性和鲁棒性方面的一个具体问题，这属于“安全与对齐”的研究范畴，而非“LLM智能体及其演化”。因此，这篇论文与我的研究目标不符，应被排除。"
    },
    {
        "index": "#2",
        "title": "The FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality",
        "link": "/arxiv/2512.10791",
        "arxiv_id": "2512.10791",
        "authors": "Aileen Cheng, Alon Jacovi, Amir Globerson, Ben Golan, Charles Kwong, Chris Alberti, Connie Tao, Eyal Ben-David, Gaurav Singh Tomar, Lukas Haas, Yonatan Bitton, Adam Bloniarz, Aijun Bai, Andrew Wang, Anfal Siddiqui, Arturo Bajuelos Castillo, Aviel Atias, Chang Liu, Corey Fry, Daniel Balle, Deepanway Ghosal, Doron Kukliansky, Dror Marcus, Elena Gribovskaya, Eran Ofek, Honglei Zhuang, Itay Laish, Jan Ackermann, Lily Wang, Meg Risdal, Megan Barnes, Michael Fink, Mohamed Amin, Moran Ambar, Natan Potikha, Nikita Gupta, Nitzan Katz, Noam Velan, Ofir Roval, Ori Ram, Polina Zablotskaia, Prathamesh Bang, Priyanka Agrawal, Rakesh Ghiya, Sanjay Ganapathy, Simon Baumgartner, Sofia Erell, Sushant Prakash, Thibault Sellam, Vikram Rao, Xuanhui Wang, Yaroslav Akulov, Yulong Yang, Zhen Yang, Zhixin Lai, Zhongru Wu, Anca Dragan, Avinatan Hassidim, Fernando Pereira, Slav Petrov, Srinivasan Venkatachary, Tulsee Doshi, Yossi Matias, Sasha Goldshtein, Dipanjan Das",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.249443",
        "filter_reason": "这篇论文不符合您的研究范围，核心原因在于其贡献是**评估基准**而非**智能体构建方法**。 1.  **第一步：核心判断** - **论文本质**: 该论文的核心贡献是提出了一个名为 \"The FACTS Leaderboard\" 的**基准测试和排行榜**，用于全面评估LLM在多种场景下的**事实准确性**。 - **是否符合保留标准**: 不符合。论文没有构建、改进或演化任何LLM智能体。它没有提出新的智能体框架、多智能体协作协议或自我演化机制。它的研究对象是“如何评估事实性”，而不是“如何构建一个更智能的智能体”。 - **是否符合排除标准**: 符合。这篇论文属于一种**评估方法论**，虽然它涉及到了工具使用（`FACTS Search`），但其焦点是**评判**使用工具后的结果，而不是改进智能体使用工具的能力本身。因此，它不属于构建或改进智能体的核心研究范畴。 2.  **第二步：正面指标** - 论文中虽然提到了 `Tool Use`（在 `FACTS Search` 子任务中），但这只是作为被评估模型的一项能力，而非论文提出的创新点。论文本身并未包含 `Agentic AI`, `Self-Evolving`, `Planning`, `Self-Reflection` 等核心范式或能力的创新性贡献。因此，缺乏关键的正面指标。 3.  **第三步：排除标准** - 论文包含 `Multimodal` (`FACTS Multimodal`)，但根据规则，这是作为评估的一个维度，而不是作为智能体感知环境的核心工具，因此这加强了排除的理由。 - 论文的核心主题 `Factuality`（事实性）与 `Hallucination`（幻觉）高度相关，后者是安全与对齐领域的关键议题。虽然论文未直接以安全为标题，但其研究内容与评估模型可靠性紧密相关，这偏离了您“构建智能体”的核心目标。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文没有提出任何新的智能体推理或规划框架。它只是评估模型在信息检索场景下的表现，这与“构建智能体如何进行规划”有本质区别。 - **自我演化的应用**: 论文完全不涉及自我演化机制。 **最终决策**: 综合以上分析，该论文是一个关于**LLM评估**的研究，而非关于**LLM智能体构建与演化**的研究。它提供了一个衡量智能体（或普通LLM）性能的尺子，但没有提供制造或改进智能体的新方法。因此，它严格地落在了您研究范围的之外，应予以排除。"
    },
    {
        "index": "#8",
        "title": "Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation",
        "link": "/arxiv/2512.10734",
        "arxiv_id": "2512.10734",
        "authors": "Rebekka Görge, Sujan Sai Gannamaneni, Tabea Naeven, Hammam Abdelwahab, Héctor Allende-Cid, Armin B. Cremers, Lennard Helmer, Michael Mock, Anna Schmitz, Songkai Xue, Elif Yildirir, Maximilian Poretschkin, Stefan Wrobel",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.258821",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个用于“文本数据偏见检测与缓解”的**流程**。它利用LLM作为工具（例如生成词表）来处理训练数据，最终目标是训练出更公平的LLM。这完全符合第一步排除标准中的 **“非演化型应用”**：将LLM作为工具应用到特定领域（数据安全与公平性）去解决该领域的问题。论文的本质是关于数据预处理和模型对齐，而非构建或演化智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `Planning`, `Tool Use` (指智能体自主使用工具), `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。虽然它提到了LLM生成词表，但这是作者在设计流程时使用的工具，而非智能体在执行任务时自主调用的工具。因此，该论文不包含任何正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这是最关键的排除依据。论文的核心议题是“偏见检测与缓解”、“防止不公平的模型输出”，并明确提到了“欧洲AI法案”。这直接命中了第三步排除标准中的 **“安全与对齐”** 类别，特别是 `Safety` 和 `Alignment`。根据规则，只要论文的主要贡献是关于这些方面，就应一律排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它讨论的是一个静态的、由人设计的数据处理流程，而非智能体的自主行为或演化机制。 **最终决策**：综合以上分析，这篇论文的核心贡献是关于LLM的安全与对齐（数据偏见缓解），属于明确排除的范畴。它没有提出任何关于构建、改进或演化LLM智能体的新方法或框架。因此，它与我的研究目标“LLM智能体及其演化”完全无关，应被排除。"
    },
    {
        "index": "#10",
        "title": "AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence",
        "link": "/arxiv/2512.10624",
        "arxiv_id": "2512.10624",
        "authors": "Bo Yang, Lanfei Feng, Yunkui Chen, Yu Zhang, Jianyu Zhang, Xiao Xu, Nueraili Aierken, Shijian Li",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.259755",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是构建了一个名为 **AgriGPT-Omni** 的多模态模型（统一语音-视觉-文本框架）和一个名为 **AgriBench-Omni-2K** 的农业领域基准。其目标是解决农业应用中的多语言和多模态问题。这完全符合筛选标准中的 **排除规则 1：非演化型应用**。该论文是将一个多模态大模型作为工具，应用到特定领域（农业）去解决该领域的问题，其核心是模型的多模态能力和领域适配，而不是构建或演化一个具有自主规划、工具使用或反思能力的智能体框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Memory`, `Self-Evolving`, `Multi-Agent` 等。它提到的 \"unified reasoning\" 指的是模型跨模态的推理能力，而非智能体在复杂任务中的多步规划和决策。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的。论文的核心是 **多模态与视觉**。标题和摘要反复强调 \"Speech-Vision-Text\", \"multimodal\", \"tri-modal\"。根据筛选标准，只要多模态是研究的核心（而不是作为智能体感知环境的工具），就应该排除。这篇论文的研究核心就是多模态模型的构建与评估。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的 \"reasoning\" 是指模型处理多模态输入的能力，不涉及智能体框架下的自主规划或行动序列生成，因此应排除。 - **自我演化的应用**: 论文没有提出任何自我演化机制，它是一个训练好的静态模型，因此不适用此例外规则。 **最终决策**: 综合以上分析，这篇论文的本质是**一个面向特定领域（农业）的多模态模型及其基准**，属于应用型研究。它并未在LLM智能体的构建、多智能体系统或自我演化机制方面做出核心贡献。因此，它严格不符合您关于 \"LLM智能体及其演化\" 的研究目标。"
    },
    {
        "index": "#5",
        "title": "OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification",
        "link": "/arxiv/2512.10756",
        "arxiv_id": "2512.10756",
        "authors": "Zijian Wu, Lingkai Kong, Wenwei Zhang, Songyang Gao, Yuzhe Gu, Zhongrui Cai, Tianyou Ma, Yuhong Liu, Zhi Wang, Runyuan Ma, Guangyu Wang, Wei Li, Conghui He, Dahua Lin, Kai Chen",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.251535",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为OPV（Outcome-based Process Verifier）的**验证器**，用于高效地验证长思维链的正确性。它通过一个迭代主动学习框架来训练这个验证器，使其能够更准确地检测推理过程中的错误。 根据您的筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** - 论文的核心是构建一个**验证器**，而不是一个完整的LLM智能体或其核心运行框架。虽然这个验证器可以与“策略模型”协作，提升其表现，但论文的创新点在于**如何评估和验证推理过程**，而非智能体本身如何进行**自主规划、工具使用或自我演化**。 - 这更符合排除标准中的 **“非Agentic的推理”**。论文关注的是提升LLM生成内容的逻辑正确性（通过外部验证），而不是研究智能体内部如何进行多步推理、决策或与环境交互的框架。它是一个用于提升推理质量的工具，而不是一个Agentic框架本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中提到了`Iterative Improvement`（迭代改进），但这指的是**验证器模型**通过主动学习和专家反馈进行迭代改进，而不是**任务执行智能体**通过经验、反思或环境反馈进行自我完善和迭代。您的核心关注点是智能体的自我演化，而非其辅助工具的模型训练优化。 - 其他核心范式如`Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`等均未在摘要中体现。 3.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这是最关键的判断点。根据规则，“如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）”则保留。但本文是关于**如何验证**一个已有的推理过程，而不是提出一种新的**智能体推理方法或框架**。因此，它更偏向于“提高LLM本身基础Token预测的数学或逻辑能力”的辅助工具，应被排除。 **结论**: 尽管该研究在提升LLM复杂推理任务的可靠性方面做出了重要贡献，但其本质是提出一个**外部验证组件**，而非构建、改进或演化LLM智能体的核心方法论。它的焦点在于“验证”这一环节，而不是智能体的“规划”、“记忆”、“工具使用”或“自我演化”等核心Agentic能力。因此，这篇论文不符合您关于“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#11",
        "title": "RoleRMBench & RoleRM: Towards Reward Modeling for Profile-Based Role Play in Dialogue Systems",
        "link": "/arxiv/2512.10575",
        "arxiv_id": "2512.10575",
        "authors": "Hang Ding, Qiming Feng, Dongqi Liu, Qi Zhao, Tao Yao, Shuo Wang, Dongsheng Chen, Jian Li, Zhenye Gan, Jiangning Zhang, Chengjie Wang, Yabiao Wang",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.260319",
        "filter_reason": "这篇论文的核心贡献是提出了一个用于角色扮演对话的奖励模型 `RoleRM` 和一个评估基准 `RoleRMBench`。其研究目标是解决现有奖励模型在主观、开放式的角色扮演场景中表现不佳的问题，从而更好地对齐LLM与人类在角色扮演上的偏好。 根据您的筛选标准，我的判断过程如下： 1.  **第一步：核心判断**：这篇论文的本质是**对齐**研究，而非智能体构建。它的核心是开发一个更优的**奖励模型**，这是一个用于评估和引导LLM行为的工具，而不是一个具有自主规划、工具使用或演化能力的智能体框架本身。因此，它不符合“构建、改进或演化LLM智能体”的核心目标，应被排除。 2.  **第二步：正面指标**：论文摘要中完全没有出现您关注的核心范式关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等。同样，它也未涉及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。因此，它缺乏任何符合您研究焦点的正面指标。 3.  **第三步：排除标准**：这是最关键的一步。论文摘要明确指出其研究动机是“aligning large language models (LLMs) with human preferences”（将大语言模型与人类偏好对齐），并在结尾强调其贡献是“establishing a foundation for subjective alignment”（为以人为中心的对话系统中的主观对齐奠定基础）。这完全符合您设定的排除标准：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Explainability (XAI)`, `Alignment` (对齐)...一律排除。” 4.  **第四步：处理特殊和模糊情况**：本文不涉及推理/规划或自我演化的特殊情况，因此该规则不适用。 **最终决策**：尽管该论文研究的是角色扮演，这可以看作是智能体的一种表现形式，但其核心贡献在于**如何评估和对齐**这种表现，而不是**如何构建或演化**一个能够进行角色扮演的智能体。论文的焦点是奖励模型和对齐技术，这属于您明确排除的研究范畴。因此，这篇论文不符合您关于“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#15",
        "title": "Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis",
        "link": "/arxiv/2512.10441",
        "arxiv_id": "2512.10441",
        "authors": "Nour El Houda Ben Chaabene, Hamza Hammami, Laid Kahloul",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.262084",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。 我的判断过程严格遵循了您设定的筛选标准： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的核心贡献是**构建一个应用于教育心理学领域的对话智能体系统**，用于分析和提升学生的学习表现与情绪健康。其本质是**非演化型应用**。 - 论文的目标是解决特定领域（教育）的问题，即“解码学生思想”和“进行心理与学习分析”。它将LLM、KG-BERT和LSTM等技术组合起来，作为一个工具来实现对学生状态的分类和干预。 - 这完全符合第一步排除标准中的第一条：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗、金融、法律、机器人控制等）。” 此处的特定领域就是教育心理学。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文虽然提到了“conversational agent”，但并未涉及我关注的核心Agentic能力。摘要中没有出现 `Planning`、`Tool Use`、`Memory`、`Self-Correction`、`Self-Reflection`、`Collaboration` 或 `Self-Evolving` 等关键词或概念。 - 该智能体的行为模式是响应和分析，而不是自主规划、使用工具或进行自我演化。它是一个被设计用来执行特定分析任务的系统，而非一个具备通用智能能力的框架。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不直接涉及安全与对齐或多模态视觉等排除项，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“semantic reasoning”（语义推理）是作为其分析学生状态的技术手段之一，而非智能体在复杂任务中进行自主规划和多步决策的框架。因此，它属于“非Agentic的推理”范畴，应被排除。 - **自我演化的应用**: 论文没有提出任何新的“自我演化”机制。该系统是静态设计的，其评估是基于一次性的试点研究，而不是智能体通过经验进行迭代和自我完善的过程。 **最终决策**: 综合以上分析，这篇论文的核心是**应用**一个包含LLM的系统来解决教育领域的问题，其贡献在于该应用本身的方法论和效果验证，而非在LLM智能体的构建、协作或演化机制上做出创新。我的研究焦点是Agentic AI的内在机制和演化，而这篇论文的焦点是智能体的外部应用价值。因此，该论文与我的研究目标不符，应予以排除。"
    },
    {
        "index": "#12",
        "title": "Causal Reasoning Favors Encoders: On The Limits of Decoder-Only Models",
        "link": "/arxiv/2512.10561",
        "arxiv_id": "2512.10561",
        "authors": "Amartya Roy, Elamparithy M, Kripabandhu Ghosh, Ponnurangam Kumaraguru, Adrian de Wynter",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.260777",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是**对不同LLM架构（Encoder-only vs. Decoder-only）在因果推理任务上的能力进行比较和分析**。它探讨了哪种底层模型结构更适合处理需要多步组合和严格逻辑控制的因果推理问题。这属于对LLM基础能力和模型架构的研究，而不是关于如何构建、改进或演化一个具有自主性的智能体。因此，它直接触发了**排除标准 #2：非Agentic的推理**。论文旨在提升对LLM本身推理能力的理解，而非提出一个新的智能体框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现您关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。虽然提到了 \"multihop composition\"，但这是在描述因果推理任务的特性，而不是在讨论智能体的规划或执行框架。因此，论文不包含任何正面指标。 3.  **第四步：处理特殊和模糊情况——推理/规划** 这是判断此论文的关键。根据规则： - **保留**: 如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）。这篇论文**不是**。它没有提出任何让智能体进行规划的新方法。 - **排除**: 如果只是关于提高LLM本身基础Token预测的数学或逻辑能力。这篇论文**正是如此**。它通过比较不同架构和微调方法，来探究哪种模型在因果推理上表现更好，这本质上是对模型基础能力的研究，与智能体框架无关。 **总结**: 该论文的核心是**模型架构分析**，研究的是“哪种模型更适合做因果推理”，这是一个关于LLM基础能力的问题。而您的研究焦点是“如何构建和演化智能体”，关注的是智能体的方法论和框架。因此，尽管论文主题是LLM，但其研究层面和贡献点与您的“LLM智能体及其演化”课题不匹配，应予以排除。"
    },
    {
        "index": "#4",
        "title": "Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation",
        "link": "/arxiv/2512.10772",
        "arxiv_id": "2512.10772",
        "authors": "Kevin Glocker, Kätriin Kukk, Romina Oji, Marcel Bollmann, Marco Kuhlmann, Jenny Kunz",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.250730",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于“构建、改进或演化LLM智能体”的论文，而这篇论文的核心贡献在于一种**模型缩放和语言适配的策略**，而非智能体框架。 以下是根据筛选标准的详细判断过程： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的本质是研究如何通过“放大”基础模型然后“合并”来高效地让语言模型适应新的语言。它关注的是**模型本身的语言能力和数据效率**，是一种模型训练和优化的方法论。 - **是否符合**: 它不符合“构建、改进或演化LLM智能体”的核心要求。论文中没有涉及任何智能体的概念，如自主规划、工具使用、目标导向行为或与环境交互。它属于**非演化型应用**的范畴，更准确地说，是关于基础模型能力提升的研究，而非智能体研究。因此，根据第一步的核心判断，应予以**排除**。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent`, `Collaboration`, `Self-Evolving` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** - 虽然论文不涉及安全、对齐或多模态等排除项，但第一步的排除理由已经足够充分。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划过程。它研究的是模型在语言任务上的性能，这是一个基础能力问题，而非智能体如何利用这种能力去完成复杂任务。 - **自我演化的应用**: 论文标题中的“Grow Up”具有迷惑性，但根据摘要内容，这里的“Grow Up”指的是研究者**主动放大模型规模**，而不是智能体**通过经验或反思进行自我成长和完善**。这是一种由外部驱动的模型构建策略，而非智能体内在的演化机制。因此，这不属于“自我演化”的例外情况。 **最终决策**: 该论文的核心贡献是提出了一种高效的模型缩放与合并策略，用于提升语言模型的多语言适配能力。这是一项有价值的基础模型研究，但它完全脱离了“智能体”的范畴，没有探讨任何关于智能体规划、工具使用、多智能体协作或自我演化的内容。因此，它不符合我为“LLM智能体及其演化”课题设定的筛选标准。"
    },
    {
        "index": "#6",
        "title": "TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage",
        "link": "/arxiv/2512.10741",
        "arxiv_id": "2512.10741",
        "authors": "Elroy Galbraith, Chadwick Sutherland, Donahue Morgan",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.257443",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文本质是“非演化型应用”** 论文的核心贡献是提出一个名为TRIDENT的**三层式架构**，用于解决特定领域（加勒比口音的紧急呼叫分诊）的问题。该系统结合了ASR、LLM（用于实体提取）和生物声学分析，其最终目标是**辅助人类调度员**，而不是构建一个自主的LLM智能体。这完全符合筛选标准中的第一条排除规则：“非演化型应用”，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。 2.  **第二步：正面指标——缺乏核心关注点** 论文中虽然提到了“large language models”，但其作用被限定在“local entity extraction”（局部实体提取）这一具体任务上。这只是一个NLP工具的应用，并未涉及您关注的核心Agentic能力，如`Planning`（规划）、`Tool Use`（由智能体自主发起的工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）等。论文也没有涉及`Multi-Agent`（多智能体）或`Self-Evolving`（自我演化）的任何概念。 3.  **第四步：处理特殊和模糊情况——不属于“推理/规划”的例外情况** 论文中LLM的“语义分析”是为了提取临床实体，这是一种信息抽取任务，而非智能体在复杂任务中的自主规划或多步推理框架（如ReAct或ToT）。它没有提出新的Agentic推理方法论，因此不符合保留条件。 **核心依据总结**: 该论文的本质是**人机交互系统**和**语音处理应用**，而非**Agentic AI**。它将LLM作为一个功能模块（实体提取器）嵌入到一个为特定场景（紧急呼叫）设计的固定流程架构中，以增强人类决策者的能力。论文的研究焦点在于如何通过多模态信号融合来提高特定场景下的系统鲁棒性，而不是探索LLM智能体本身的构建、协作或演化机制。因此，它与您“LLM智能体及其演化”的核心研究目标相去甚远。"
    },
    {
        "index": "#17",
        "title": "Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring \"Tortured Phrases\" in Scientific Literature",
        "link": "/arxiv/2512.10435",
        "arxiv_id": "2512.10435",
        "authors": "Agniva Maiti, Prajwal Panth, Suresh Chandra Satapathy",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.299198",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——本质是“非演化型应用”** 论文的核心贡献是提出一个名为SRAP的框架，用于检测和重构科学文献中被恶意篡改的“扭曲短语”以对抗抄袭。这是一个典型的将LLM（如SciBERT, SBERT）和检索技术（如FAISS）作为工具，应用于特定领域（学术诚信、文本取证）来解决该领域问题的案例。论文的重点在于**检测和恢复**这一具体任务，而不是构建一个具有自主性、规划能力或演化能力的LLM智能体。因此，它完全符合第一步排除标准中的“非演化型应用”。 2.  **第三步：排除标准——属于“安全与对齐”范畴** 论文的研究动机是维护“科学文献的完整性和可靠性”，其核心功能是检测恶意的文本生成（对抗性抄袭）。这本质上属于学术安全、内容安全和AI伦理的范畴，与您明确排除的“安全”、“安全”研究方向高度重合。其主要贡献是解决一个安全问题，而非推进Agentic AI本身。 3.  **第二步：正面指标——缺乏核心关注点** 通读标题和摘要，论文完全没有提及任何与您研究焦点相关的核心范式或能力。它不涉及`Agentic AI`、`Multi-Agent Systems`或`Self-Evolving`。虽然它使用了“工具”（FAISS），但这是一种静态的、算法层面的工具调用，而非智能体自主决策和使用的`Tool Use`。论文中也没有任何关于`Planning`、`Memory`、`Self-Reflection`、`Collaboration`或`Self-Improvement`的描述。 **总结**: 该论文的本质是一个应用于文本安全领域的、基于LLM的检测算法。它没有提出任何关于如何构建、改进或演化LLM智能体的新方法或框架。其核心贡献在于解决抄袭检测这一具体问题，而非推动Agentic AI的前沿发展。因此，根据您的筛选标准，这篇论文应被明确排除。"
    },
    {
        "index": "#18",
        "title": "T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground",
        "link": "/arxiv/2512.10430",
        "arxiv_id": "2512.10430",
        "authors": "Dmitrii Stoianov, Danil Taranets, Olga Tsymboi, Ramil Latypov, Almaz Dautov, Vladislav Kruglikov, Nikita Surkov, German Abramov, Pavel Gein, Dmitry Abulkhanov, Mikhail Gashkov, Viktor Zelenkovskiy, Artem Batalov, Aleksandr Medvedev, Anatolii Potapov",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.300042",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是构建了一个针对俄语的高效推理模型（T-pro 2.0）及其配套的推理加速流水线（EAGLE）。它主要关注的是模型本身的性能（混合推理能力）和效率（降低延迟），并提供了相应的数据集和基准。这完全符合**排除标准**中的 **“非Agentic的推理”** 和 **“基础设施”**。 - **非Agentic的推理**: 论文虽然提到了“reasoning-trace generation”，但其目标是提升LLM模型本身的基础推理能力，而不是构建一个能够自主规划、使用工具或进行自我反思的智能体框架。它没有涉及任何智能体架构或方法论。 - **基础设施**: 论文明确提到了“adapted EAGLE speculative-decoding pipeline to reduce latency”，这是一个典型的模型部署和推理优化工作，属于基础设施范畴。 2.  **第二步：正面指标** 论文摘要中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。唯一沾边的 `Reasoning` 也是在非Agentic的语境下使用的。 3.  **第三步：排除标准** 论文不涉及安全、对齐或多模态等排除领域，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文的“推理”属于被排除的情况。它旨在提升模型底层的、非框架性的数学或逻辑推理能力，而不是研究智能体如何在一个框架内进行多步规划和决策。它没有提出类似 ReAct 或 ToT 的智能体工作流。 **最终决策**: 综合以上分析，这篇论文的本质是构建一个特定语言（俄语）的高效LLM模型和优化其推理速度，属于模型工程和基础设施优化的范畴。其核心贡献与“构建、改进或演化LLM智能体”这一目标无关。因此，应将其排除。"
    },
    {
        "index": "#16",
        "title": "Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT",
        "link": "/arxiv/2512.10440",
        "arxiv_id": "2512.10440",
        "authors": "Nour El Houda Ben Chaabene, Hamza Hammami",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.298550",
        "filter_reason": "这篇论文不符合您的研究范围，核心原因在于其贡献点在于模型能力的增强，而非智能体的构建或演化。 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心是提出一种将知识图谱（KGs）通过KG-BERT集成到现有LLM（如Claude, GPT-4）中的方法，目的是增强模型的事实一致性和知识密集型任务的推理能力。 - **判断**: 这属于典型的**非Agentic的推理**。论文关注的是如何提升LLM模型本身的基础能力（事实准确性、知识推理），而不是构建一个具有自主性、规划能力或工具使用能力的智能体框架。它没有涉及智能体的核心要素，如目标导向的规划、与环境的交互、记忆机制或自我演化。因此，根据第一步的排除标准2，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现您所列出的任何核心范式或智能体能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent` 等。这进一步表明其研究焦点与您的目标不符。 3.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提到了“增强基础和推理能力”。根据您的规则，这属于“排除”情况，即“只是关于提高LLM本身基础Token预测的数学或逻辑能力”。这里的“推理”是指模型基于注入的知识进行更准确的判断，而不是智能体在复杂任务中进行多步、自主的规划和行动。它没有提出类似ReAct或ToT这样的Agentic推理框架。 **总结**: 尽管这篇论文的研究（解决LLM的事实幻觉问题）对于构建更可靠的智能体具有重要意义，但它本身的工作停留在模型增强层面，并未进入“智能体”的研究范畴。它的贡献是“如何让LLM更懂知识”，而不是“如何构建一个能自主使用知识的智能体”。因此，它不符合您“构建、改进或演化LLM智能体”的核心目标。"
    },
    {
        "index": "#13",
        "title": "XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs",
        "link": "/arxiv/2512.10545",
        "arxiv_id": "2512.10545",
        "authors": "Iñaki Lacunza, José Javier Saiz, Alexander Shvets, Aitor Gonzalez-Agirre, Marta Villegas",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.261269",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 `XDoGE` 的**多语言数据重加权算法**。其目标是优化训练数据中不同语言的分布，从而提升LLM在低资源语言上的表现。这本质上是一种**模型训练和数据优化**的方法，而不是关于构建、改进或演化LLM智能体的方法论。因此，根据筛选标准，该论文属于“非演化型应用”，应被**排除**。它将一种技术（数据重加权）应用到了一个特定领域（多语言性能提升），但其本身并未提出任何新的智能体框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现我关注的核心范式和能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Memory`, `Multi-Agent`, `Self-Evolving`, `Self-Reflection` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文没有触及安全、对齐或多模态等明确的排除领域，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 论文标题和摘要中提到的“演化”概念可能会引起混淆。然而，这里的“演化”指的是在**训练阶段**对数据分布进行优化和调整，是一种静态的、一次性的训练策略。这与我所关注的“自我演化”有着本质区别，后者是指智能体在**部署后**通过与环境的交互、经验积累和自我反思来动态地、自主地完善自身能力。因此，这不属于“自我演化的应用”的例外情况。 **最终决策**：综合以上分析，该论文的核心工作是关于LLM的训练数据优化，旨在提升模型的多语言能力，而非研究LLM智能体的构建、协作或自我演化机制。因此，它完全不符合我的研究目标。"
    },
    {
        "index": "#22",
        "title": "Multilingual VLM Training: Adapting an English-Trained VLM to French",
        "link": "/arxiv/2512.10336",
        "arxiv_id": "2512.10336",
        "authors": "Jules Lahmi, Alexis Roger",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.302778",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质不符** 论文的核心贡献是关于如何将一个英文训练的**视觉-语言模型（VLM）**适配到法语。它探讨的是模型微调策略（如LoRA）和数据集翻译问题，其本质是**改进一个基础多模态模型的语言能力**，而不是构建、改进或演化一个具有自主性的LLM智能体。根据筛选标准，这属于“非演化型应用”，即将模型技术应用于特定领域（多语言适配）以解决该领域的问题，而非研究智能体本身。 2.  **第三步：排除标准——命中“多模态与视觉”排除项** 这是最直接的排除理由。论文的标题和摘要明确指出其研究对象是**VLM（Vision-Language Model）**。我的筛选标准明确规定，应排除主要关注 `Vision`, `Vision-Language`, `MLLMs`, `VLMs` 的研究，除非它们被用作智能体感知环境的工具。在这篇论文中，VLM是研究的核心，而不是智能体的一个组件，因此完全符合排除条件。 3.  **第二步：正面指标——缺乏核心关注点** 论文的研究内容与我的核心关注点完全脱节。摘要中完全没有出现任何与智能体相关的关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Memory`, `Multi-Agent`, `Self-Evolving` 等。这进一步证实了该论文与我的研究课题无关。 综上所述，该论文虽然涉及模型改进，但其焦点是多模态模型的语言适配问题，而非LLM智能体的构建、协作或演化机制。因此，它不符合我的研究目标，应被排除。"
    },
    {
        "index": "#14",
        "title": "Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs",
        "link": "/arxiv/2512.10453",
        "arxiv_id": "2512.10453",
        "authors": "Lars G. B. Johnsen",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.261655",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献并非构建、改进或演化LLM智能体。它的本质是一项**语言学与认知科学的交叉研究**，旨在利用大型语言模型（LLMs）作为工具或研究对象，来验证和探讨一个经典的语言学理论——生成语法。论文通过测试LLM对特定语法结构的判断能力，来推断其是否学习到了底层的句法结构。这完全符合第一步排除标准中的 **“非演化型应用”**，即将LLM作为工具应用到特定领域（语言学）去解决该领域的问题（验证语法理论）。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式和能力。摘要和标题中未提及 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何与智能体构建和演化相关的关键词。论文的研究焦点是LLM的**句法敏感性**，这是一种基础的语言能力，而非智能体的自主行为能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不涉及安全对齐或多模态等排除项，但它本身的研究目标已经超出了“LLM智能体及其演化”的范畴。它的目标是理解LLM的内部表征，而不是赋予其更强的自主性、协作性或演化能力。 4.  **第四步：处理特殊和模糊情况** 这篇论文触及了“推理”的范畴，但它属于应被排除的类型。根据规则，应排除“只是关于提高LLM本身基础Token预测的数学或逻辑能力”的研究。本文探讨的句法结构识别能力，可以被视为LLM在语言层面的一种基础推理或模式识别能力，但它**不涉及智能体在复杂任务中进行多步自主规划或决策的框架**。论文没有提出任何新的Agentic框架（如ReAct, ToT），而是直接评估模型本身的能力。 **最终决策**: 综合以上分析，该论文的核心贡献在于**语言学理论验证**，而非**智能体工程**。它使用LLM作为研究工具，探究了LLM的句法能力，但没有提出任何关于如何构建、改进或演化LLM智能体的新方法或框架。因此，它与您“LLM智能体及其演化”的核心研究目标不符，应予以排除。"
    },
    {
        "index": "#20",
        "title": "Sliding Window Attention Adaptation",
        "link": "/arxiv/2512.10411",
        "arxiv_id": "2512.10411",
        "authors": "Yijiong Yu, Jiale Liu, Qingyun Wu, Huazheng Wang, Ji Pei",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.301316",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出了一套名为“Sliding Window Attention Adaptation (SWAA)”的方法，用于解决将滑动窗口注意力（SWA）应用到预训练模型时出现的性能下降问题。其本质是**对Transformer模型底层注意力机制的优化和适配**，目的是为了在保持长上下文性能的同时，降低推理的计算成本（从二次方到线性）。这完全属于您筛选标准中明确排除的“基础设施”和“部署优化”范畴。论文并未提出新的智能体框架、多智能体协作机制或自我演化范式。 2.  **第二步：正面指标——缺乏核心关注点。** 尽管论文摘要中提到了`chain-of-thought (CoT)`，但它只是作为五种辅助适配方法之一出现，用于帮助模型适应新的注意力机制。论文的核心并非研究CoT作为一种智能体推理框架，而是将其作为一种技术手段来缓解模型适配问题。论文完全没有涉及`Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`（作为智能体组件）等您关注的核心范式和能力。 3.  **第四步：特殊情况的排除——对CoT的提及不改变论文性质。** 根据您的规则，关于推理/规划的论文，只有当其核心是关于“智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）”时才应保留。在本论文中，CoT的角色是辅助性的，服务于“注意力机制适配”这一更底层的工程目标，而不是构建一个自主规划或行动的智能体。因此，它属于“提高LLM本身基础Token预测能力”的范畴，应被排除。 **总结：** 该论文的研究焦点是LLM模型内部的**计算效率和架构适配**问题，属于模型工程和优化的领域。它没有贡献任何关于LLM智能体的构建、交互或演化的新方法或新框架。因此，它严格地落在了您研究范围的“基础设施”排除项之外，应予以排除。"
    },
    {
        "index": "#25",
        "title": "PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset",
        "link": "/arxiv/2512.10148",
        "arxiv_id": "2512.10148",
        "authors": "Moonsoo Park, Jeongseok Yun, Bohyung Kim",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.309570",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断（第一步）：论文本质是“非演化型应用”** 论文的核心贡献是提出一个“两阶段提示框架”，用于在**特定领域（外卖评论回复）**生成个性化的回复。这完全符合筛选标准中的第一条排除规则：“非演化型应用”。论文并没有构建一个具有通用能力的LLM智能体，而是将LLM作为一种工具，通过巧妙的提示工程来解决一个具体的、领域性的文本生成问题。其目标是提升回复的个性化，而非赋予智能体规划、记忆或演化的能力。 2.  **缺乏智能体核心能力（第二步：正面指标缺失）** 论文的研究内容与您关注的核心指标几乎无关。 *   **单智能体能力**: 论文没有涉及智能体的自主`Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或`Self-Reflection`（自我反思）。其“两阶段”流程是一个固定的、预设的管道，而非智能体根据环境反馈自主决策的循环。 *   **多智能体**: 论文只涉及单个LLM生成回复，没有`Collaboration`（协作）、`Communication`（通信）等多智能体交互。 *   **自我演化**: 论文的方法是静态的，不涉及任何`Self-Improvement`（自我改进）或`Generational Evolution`（代际演化）机制。模型不会通过经验来迭代完善自身。 3.  **与“推理/规划”的区别（第四步：特殊情况处理）** 虽然论文的“两阶段”流程包含了一定的推理步骤（先推断角色，再生成回复），但这属于**非Agentic的推理**。它是一种为了提升特定任务输出质量而设计的静态提示策略，而不是一个智能体在复杂环境中进行多步、自主的规划和行动。这与ReAct或ToT等框架有本质区别，后者强调智能体在循环中“思考-行动”的自主性。 **总结**: 该论文的本质是**应用型研究**，聚焦于利用提示工程改进特定场景（外卖评论）下的文本生成效果。它虽然使用了LLM，但其核心贡献并非构建、改进或演化一个具有自主能力的“智能体”。因此，它严格地落在了您筛选标准的“排除”范围内，不符合您关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#24",
        "title": "Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning",
        "link": "/arxiv/2512.10150",
        "arxiv_id": "2512.10150",
        "authors": "Lama Alssum, Hani Itani, Hasan Abed Al Kader Hammoud, Philip Torr, Adel Bibi, Bernard Ghanem",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.309114",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）**: 论文的核心贡献并非构建、改进或演化LLM智能体。其本质是研究如何在使用持续学习方法对LLM进行微调时，**保持其原有的安全对齐能力**，防止“灾难性遗忘”导致的安全性能下降。论文的重点是“安全”和“对齐”，而不是智能体的能力或架构本身。 2.  **排除标准（第三步）**: 这篇论文完全符合“安全与对齐”的排除标准。摘要中反复出现的关键词，如 `Safety Alignment`、`Preserving Safety`、`mitigate safety degradation`、`lower attack success rates`、`safety-preserving baselines`，都明确表明其主要贡献集中在LLM的安全领域。根据您的筛选规则，只要论文的主要贡献是关于安全与对齐，就应一律排除。 3.  **对模糊情况的处理（第四步）**: 论文中提到了“Continual Learning (CL)”，这可能与“自我演化”的概念产生关联。然而，这里的“持续学习”是一种**训练技术**，其目的是防止模型在适应新任务时忘记旧的安全约束，而不是智能体在运行时通过经验、反思或环境反馈进行的**自主性自我完善和迭代**。它不是一种新的智能体演化机制，而是应用于模型训练阶段的一种安全加固方法。因此，这不属于“自我演化的应用”这一例外情况。 综上所述，尽管论文涉及了LLM的适应和迭代过程，但其核心目标和贡献是解决安全对齐问题，这与您研究的“LLM智能体及其演化”的核心目标（构建、改进、演化智能体本身的能力）存在本质区别。因此，该论文应被排除。"
    },
    {
        "index": "#19",
        "title": "Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers",
        "link": "/arxiv/2512.10422",
        "arxiv_id": "2512.10422",
        "authors": "Youmin Ko, Sungjong Seo, Hyunjoon Kim",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.300647",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 该论文的核心贡献是提出一个名为 **CoopRAG** 的新框架，用于改进问答任务中的检索增强生成（RAG）效果。其创新点在于“检索器”和“LLM”之间的协作，以及检索器模型内部不同层之间的协作，以提升检索和排序的准确性。 - **是否符合**: 论文的核心是**改进RAG这一特定技术**，而不是构建或演化一个具有通用能力的LLM智能体。虽然它涉及了类似智能体的工作流（如分解问题、迭代检索），但其最终目标和贡献是解决“问答”这一特定领域的问题，而非提出一个通用的智能体架构或演化机制。这更接近于“非演化型应用”的范畴，即为了解决特定领域问题而优化一个技术组件（RAG）。 2.  **第二步：正面指标分析** - 论文确实包含了一些与智能体相关的正面指标，如 `Planning` (将问题分解为子问题和推理链)、`Tool Use` (使用检索器作为工具) 和 `Self-Correction` (重建推理链)。这些元素使得论文看起来与Agentic AI相关。 - 然而，这些能力是**内嵌在一个为特定任务（QA）设计的RAG框架中**，而不是作为一个独立的、可泛化的智能体能力被提出。论文的重点是“如何通过协作让RAG在QA上表现更好”，而不是“如何构建一个具备规划、工具使用能力的通用智能体”。 3.  **第三步：排除标准分析** - 论文不涉及安全、对齐或多模态等排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文确实涉及了智能体式的规划和推理流程。根据规则，这倾向于保留。但是，关键在于这个流程是**服务于改进RAG性能**的，其本身不是研究的核心贡献。研究的核心是“协作机制”，而不是“智能体规划框架”。 - **自我演化的应用**: 论文不涉及自我演化机制。 5.  **第五步：最终决策** - **核心依据**: 尽管论文采用了类似智能体的工作流，但其**核心贡献是针对特定任务（QA）的RAG技术改进**，而不是对LLM智能体本身的构建、架构或演化机制的贡献。您的研究焦点是“LLM智能体及其演化”，关注的是智能体这个“主体”的能力和演化，而该论文关注的是一个“工具”（RAG）的优化。因此，这篇论文虽然技术上有价值，但偏离了您设定的核心研究目标。它属于“用更智能的方式优化一个工具”，而不是“构建或演化一个智能体”。故应排除。"
    },
    {
        "index": "#27",
        "title": "Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models",
        "link": "/arxiv/2512.10110",
        "arxiv_id": "2512.10110",
        "authors": "Yumou Wei, John Stamper, Paulo F. Carvalho",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.310553",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 该论文的核心是提出一个名为“生成-验证”的**流水线**，用于提升小型语言模型（SLM）在特定任务（问题生成）上的表现。它是一种方法论或流程优化，而不是构建一个具有自主性的智能体。 - **判断**: 这篇论文的本质属于**非演化型应用**。它将SLM作为核心组件，设计了一个固定的两步流程来解决“问题生成”这一特定领域的问题。它没有构建一个能够自主规划、使用工具或与环境动态交互的LLM智能体。因此，根据第一步的排除规则，应予以排除。 2.  **第二步：正面指标分析** - 论文中提到的“验证”步骤，虽然听起来像是一种自我修正，但它是在一个预设的、固定的流水线内部发生的，并非智能体自主的`Self-Correction`或`Self-Reflection`机制。它更像是一种后处理或质量控制步骤。 - 论文没有涉及`Planning`（自主规划）、`Tool Use`（使用外部工具）、`Memory`（长期记忆）、`Multi-Agent`（多智能体）或`Self-Evolving`（跨任务的自我演化）等任何核心Agentic AI范式。 3.  **第三步：排除标准** - 该论文不涉及安全、对齐或多模态等排除领域，因此不触发此处的排除规则。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提到了“概率推理”，但这种推理是用于流水线内部的“验证”环节，以评估生成问题的质量。这属于提升模型在特定任务上输出质量的**非Agentic的推理**，而不是智能体为解决复杂外部任务而进行的自主规划和多步推理框架（如ReAct）。因此，应排除。 - **自我演化的应用**: 该论文的“生成-验证”流水线是一个静态方法，不具备自我演化机制。它不会通过经验来迭代和改进自身。因此，关于“自我演化应用”的例外保留规则不适用。 **最终决策**: 综合以上分析，这篇论文的核心贡献是设计一个用于特定任务（问题生成）的静态流水线，而非构建、改进或演化一个具有自主性的LLM智能体。它属于将语言模型作为工具应用于特定领域的范畴，缺乏Agentic AI的核心要素（如自主规划、工具使用、记忆和自我演化）。因此，它不符合您的研究目标。"
    },
    {
        "index": "#28",
        "title": "What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models",
        "link": "/arxiv/2512.10080",
        "arxiv_id": "2512.10080",
        "authors": "Luciano Floridi, Jessica Morley, Claudio Novelli, David Watson",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.311011",
        "filter_reason": "这篇论文不符合研究范围，应被排除。 **核心判断依据 (第一步 & 第四步):** 1.  **论文本质不符 (第一步):** 论文的核心贡献并非“构建、改进或演化LLM智能体”，而是对现有LLM的“推理”能力进行哲学层面的分析和批判。它探讨的是LLM是否在进行真正的溯因推理，结论是它们只是在基于模式模仿推理的“表象”。这属于对LLM基础能力的理论探讨，而非提出新的智能体框架或方法论。 2.  **属于“非Agentic的推理” (第一步 & 第四步):** 根据筛选标准，应排除“只是关于提高LLM本身基础Token预测的数学或逻辑能力”或“分析其基础推理本质”的论文。本文正是如此。它没有提出一个让智能体进行规划或反思的新框架（如ReAct, ToT），而是在解构LLM推理的本质。它关注的是LLM“是什么”，而不是如何“构建一个能做什么的智能体”。 **辅助判断依据 (第二步 & 第三步):** *   **缺乏正面指标 (第二步):** 论文摘要中完全没有出现 `Agentic AI`, `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等核心关注点的关键词。虽然提到了 `Reasoning`，但如上所述，其语境是基础分析，而非智能体框架下的应用。 *   **不涉及排除标准 (第三步):** 论文虽然触及了可解释性和评估，但其主要贡献并非提出新的安全、对齐或可解释性方法，因此不属于第三步的硬性排除范围，但这并不能改变其核心与研究目标不符的事实。 **总结:** 我的研究目标是寻找那些**推动LLM智能体技术边界**的论文，即提出新架构、新能力、新演化机制的论文。而这篇论文是一篇**分析性和批判性**的论文，它试图回答“LLM的推理本质是什么？”这个根本问题，而不是“如何构建一个更会推理的智能体？”。因此，它虽然与LLM和推理相关，但与我的“LLM智能体及其演化”这一工程和构建导向的研究课题焦点不符。"
    },
    {
        "index": "#33",
        "title": "GPG: Generalized Policy Gradient Theorem for Transformer-based Policies",
        "link": "/arxiv/2512.10365",
        "arxiv_id": "2512.10365",
        "authors": "Hangyu Mao, Guangting Dong, Zhicheng Dou",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.324095",
        "filter_reason": "这篇论文的核心贡献是提出一个名为“广义策略梯度（GPG）”的数学定理，并将其应用于训练基于Transformer的策略（包括LLMs）。 我的研究焦点是“LLM智能体及其演化”，关注的是智能体的架构、能力（如规划、工具使用、记忆）和演化机制。而这篇论文的本质是关于强化学习中的**策略优化算法**，属于模型训练的底层方法论。 根据筛选标准第一步，这属于“基础设施”或“模型训练优化”的范畴，而非“构建、改进或演化LLM智能体”的方法论或框架。论文探讨的是如何更有效地更新模型权重（策略优化），而不是智能体如何进行自主规划、使用工具或自我演化。它没有涉及任何Agentic AI的核心范式或能力（如Planning, Tool Use, Self-Reflection等）。 因此，尽管该研究可能对训练更强大的LLM有贡献，但它并不直接属于我关于“LLM智能体及其演化”的研究范围。它关注的是“如何训练”，而不是“智能体是什么”或“智能体能做什么”。"
    },
    {
        "index": "#31",
        "title": "When Reject Turns into Accept: Quantifying the Vulnerability of LLM-Based Scientific Reviewers to Indirect Prompt Injection",
        "link": "/arxiv/2512.10449",
        "arxiv_id": "2512.10449",
        "authors": "Devanshu Sahoo, Manish Prasad, Vasudev Majhi, Jahnvi Singh, Vinay Chamola, Yash Sinha, Murari Mandal, Dhruv Kumar",
        "subjects": "Artificial Intelligence, Computation and Language, Cryptography and Security",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.312653",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心贡献不符 (第一步核心判断)**: 论文的核心贡献是**量化并展示“LLM评审员”系统在对抗性PDF攻击下的脆弱性**。它提出了一种新的评估指标（WAVS）和一套攻击策略，旨在操纵LLM的评审决策。这本质上是一项关于**LLM安全与脆弱性**的研究，而不是关于如何构建、改进或演化LLM智能体的研究。论文将LLM评审员视为一个被攻击的“黑箱”系统，而不是一个需要被增强其自主能力的智能体。这完全符合第一步排除标准中的“非演化型应用”——将LLM（或一个已有的Agentic框架）作为工具应用到特定领域（科学评审）去研究该领域的问题（评审系统的安全性）。 2.  **触及明确的排除标准 (第三步排除标准)**: 该论文的研究主题直接命中了“安全与对齐”这一排除类别。摘要中的关键词如“Vulnerability”（脆弱性）、“Adversarial”（对抗性）、“Attack Strategies”（攻击策略）都明确指向了安全研究的范畴。根据筛选标准，只要论文的主要贡献是关于 `Security`，就应一律排除。 3.  **缺乏核心关注点 (第二步正面指标)**: 尽管论文标题中提到了“LLM-Based Scientific Reviewers”，但这只是研究的对象，而非贡献。论文并未提出任何关于智能体核心能力的新方法，例如： *   它没有改进智能体的`Planning`（规划）能力。 *   它没有增强智能体的`Memory`（记忆）或`Tool Use`（工具使用）。 *   它没有涉及`Self-Reflection`（自我反思）或`Self-Evolving`（自我演化）机制。 *   它没有研究`Multi-Agent`（多智能体）的协作或通信。 论文的焦点是“如何攻击”，而不是“如何构建或演化”。 **总结**: 该论文是一项扎实的LLM安全研究，但它与我的核心目标——“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”——背道而驰。我的研究焦点是Agentic AI的内在能力提升和架构演进，而该论文的焦点是外部攻击和系统脆弱性分析。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#34",
        "title": "MotionEdit: Benchmarking and Learning Motion-Centric Image Editing",
        "link": "/arxiv/2512.10284",
        "arxiv_id": "2512.10284",
        "authors": "Yixin Wan, Lei Ke, Wenhao Yu, Kai-Wei Chang, Dong Yu",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.324764",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是构建了一个名为 `MotionEdit` 的新数据集和基准，以及一个名为 `MotionNFT` 的微调框架，用于解决“以运动为中心的图像编辑”这一特定计算机视觉任务。其本质是**改进扩散模型在特定视觉任务上的表现**，而不是构建、改进或演化LLM智能体。因此，根据筛选标准，这属于“非演化型应用”，应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式和能力关键词。例如，它没有涉及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection` 或 `Collaboration` 等任何与智能体相关的概念。其提出的 `MotionNFT` 是一个模型微调方法，而非智能体的自我演化机制。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，这篇论文完全属于“多模态与视觉”这一排除类别。论文的核心是 `Image Editing`、`Motion` 和 `Diffusion Models`。虽然它提到了 `Qwen-Image-Edit`，但只是将其作为被改进的基础模型之一，研究的焦点并非该模型的智能体能力，而是其图像编辑能力。视觉任务是论文的研究核心，而不是作为智能体感知环境的工具。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它是一个纯粹的计算机视觉研究，与智能体框架无关。 **最终决策**： 综合以上分析，该论文的核心是关于计算机视觉中的图像编辑技术和数据集构建，属于模型应用和改进的范畴，与我的研究目标“LLM智能体及其演化”在本质上是不同的。它没有提出任何关于智能体构建、多智能体交互或自我演化的方法论。因此，最终判断为**不符合**。"
    },
    {
        "index": "#40",
        "title": "Exploring LLMs for Scientific Information Extraction Using The SciEx Framework",
        "link": "/arxiv/2512.10004",
        "arxiv_id": "2512.10004",
        "authors": "Sha Li, Ayush Sadekar, Nathan Self, Yiqi Su, Lars Andersland, Mira Chaplin, Annabel Zhang, Hyoju Yang, James B Henderson, Krista Wigginton, Linsey Marr, T. M. Murali, Naren Ramakrishnan",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.328622",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用，而非智能体构建。** 论文的核心贡献是提出了一个名为 SciEx 的框架，用于解决“科学信息提取”这一特定领域的问题。摘要明确指出，该框架旨在应对科学文献中的挑战，如长文档、多模态内容等。这完全符合筛选标准中“非演化型应用”的排除条件：**将LLM（或一个已有的框架）作为工具应用到特定领域（这里是科学文献处理）去解决该领域的问题。** 论文的焦点在于如何构建一个高效、模块化的信息提取*管道*，而不是如何构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——缺乏核心关注点。** 尽管摘要中提到了“推理机制”，但它的上下文是“灵活集成新模型、提示策略和推理机制”，这表明 SciEx 是一个可以*容纳*不同推理方法的容器，其核心贡献在于框架的“模块化”和“可组合性”，而非提出一种新的智能体推理范式。论文并未提及 `Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent` 或 `Self-Evolving` 等您关注的核心智能体能力或机制。 3.  **第三步：排除标准——触及多模态，但非核心。** 论文提到了“多模态内容”和“多模态检索”，这触发了多模态的排除标准。虽然多模态可以作为智能体感知环境的工具，但在这篇论文中，它仅仅是信息提取管道中的一个处理环节，并非研究的核心贡献。研究的核心是整个框架的设计，而非多模态感知如何赋能智能体。 4.  **第四步：处理特殊情况——不适用。** 论文不涉及新的智能体规划或推理框架，也未提出任何自我演化机制，因此相关的特殊规则不适用。 **最终决策：** 该论文的本质是构建一个面向特定任务（科学信息提取）的应用框架，其核心贡献在于工程化和模块化设计，而非在LLM智能体的基础理论、架构或演化机制上做出创新。因此，它严格地属于“非演化型应用”，应被排除。"
    },
    {
        "index": "#39",
        "title": "Diffusion Is Your Friend in Show, Suggest and Tell",
        "link": "/arxiv/2512.10038",
        "arxiv_id": "2512.10038",
        "authors": "Jia Cheng Hu, Roberto Cavicchioli, Alessandro Capotondi",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.327805",
        "filter_reason": "这篇论文不符合研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 \"Show, Suggest and Tell (SST)\" 的新颖混合生成模型架构，用于提升图像描述生成任务的性能。它将扩散模型作为“建议模块”来辅助自回归模型，而不是构建一个具有自主性的LLM智能体。这完全符合**排除标准中的“非演化型应用”**，即它将一个新颖的模型架构（扩散+自回归）应用到了一个特定领域（计算机视觉的图像描述生成），其目标是提升该领域的任务指标（CIDEr-D分数），而非研究智能体本身的构建、改进或演化。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我的研究焦点相关的正面指标。它没有涉及 `Agentic AI`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent` 或 `Self-Evolving` 等任何核心概念。其“Suggest”机制是一种模型内部的、静态的、一次性的信息融合方式，而非智能体主动的、迭代的自我反思或工具使用行为。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，这篇论文明确触发了**“多模态与视觉”**的排除标准。摘要开篇就明确指出其研究背景是“generative Computer Vision tasks”，核心模型是“Diffusion Denoising models”，实验数据集是“COCO”。扩散模型在这里是研究的核心贡献之一，而不是作为智能体感知环境的工具。因此，这篇论文本质上是一篇计算机视觉与自然语言生成交叉领域的研究，而非Agentic AI研究。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何特殊或模糊情况。其“推理”是生成模型层面的文本生成优化，不涉及智能体的自主规划或决策。它也没有提出任何“自我演化”机制。 **最终决策**：综合以上分析，这篇论文的核心是改进图像描述生成这一特定任务的模型架构，属于计算机视觉和生成式模型的研究范畴。它与“LLM智能体及其演化”的研究目标——即构建具有自主规划、工具使用、协作或自我演化能力的智能体——存在本质区别。因此，应予以排除。"
    },
    {
        "index": "#38",
        "title": "Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning",
        "link": "/arxiv/2512.10054",
        "arxiv_id": "2512.10054",
        "authors": "Logan Robbins",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.327191",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是模型基础设施优化，而非智能体构建。** 论文的核心贡献是提出了一种名为“Parallel Decoder Transformer (PDT)”的**模型架构**和“Speculative Note Conditioning (SNC)”的**推理优化技术**。其根本目标是解决LLM自回归解码的延迟瓶颈，通过模型内部的并行化来加速生成过程。这完全属于筛选标准中第一步的排除类别：“基础设施: 排除主要关注模型基础设施、部署优化的研究”。论文并未提出新的智能体框架、智能体间的交互机制或智能体的自我演化方法。 2.  **对正面指标的误读 (第二步): “自我修正”并非智能体层面的能力。** 摘要中提到的“self-correction”是一个关键的混淆点。然而，这里的“自我修正”指的是**解码层面的修正**，即并行生成的多个文本流之间通过“notes”进行同步和验证，以确保最终输出的连贯性与原始顺序解码的语义保持一致。这是一种**技术性的纠错机制**，而非智能体在执行任务过程中的**行为反思与策略调整**。您所关注的“自我反思”或“自我修正”是智能体在环境交互中，基于任务失败或反馈来改进自身规划或决策的高阶认知能力，这与论文中的技术概念有本质区别。 3.  **排除标准 (第三步): 虽未直接触发，但本质已偏离。** 论文不涉及安全、对齐或多模态等排除领域，但其核心问题——推理加速——使其从根本上偏离了“Agentic AI”的研究焦点。 4.  **特殊情况的澄清 (第四步): 不属于智能体推理/规划。** 论文虽然提到了“Skeleton-of-Thought”，但其目的是为了引出自身在并行化上的优势，而非构建一个新的智能体推理框架。论文的工作是**模型内部的解码机制创新**，而不是**智能体外部的任务执行框架创新**。它属于“非Agentic的推理”范畴，因为它关注的是如何更快地生成Token序列，而不是智能体如何利用推理来完成复杂任务。 **总结**: 该论文是一项关于LLM推理加速和模型架构优化的扎实研究，但其贡献点在于**效率**和**基础设施**，而非**智能体能力**的构建、改进或演化。因此，它严格地不符合您为“LLM智能体及其演化”课题设定的筛选标准。"
    },
    {
        "index": "#35",
        "title": "Watermarks for Language Models via Probabilistic Automata",
        "link": "/arxiv/2512.10185",
        "arxiv_id": "2512.10185",
        "authors": "Yangkun Wang, Jingbo Shang",
        "subjects": "Cryptography and Security, Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.325329",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出一种新的语言模型水印方案，通过概率自动机实现。其研究目标是解决现有水印技术在生成多样性、检测开销和不可检测性方面的问题。这本质上是一项关于**模型安全与可追溯性**的研究，而非关于构建、改进或演化LLM智能体的方法论。因此，它不符合“保留”标准。 2.  **第二步：正面指标** 论文的标题和摘要中完全没有出现任何与我的核心关注点相关的关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步表明该论文与我的研究焦点无关。 3.  **第三步：排除标准** 这是最关键的一步。我的筛选标准明确规定：“只要论文的主要贡献是关于 `Safety`, `Security`, ... `Watermarking` (水印)... 一律排除。” 这篇论文的标题和摘要都明确指出其核心是“Watermarks”（水印），完全命中了排除标准。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及推理/规划或自我演化的特殊情况，因此无需进一步分析。 **最终决策**: 综合以上分析，该论文的核心贡献是LLM水印技术，属于“安全与对齐”的研究范畴，被我明确列为排除项。它与“LLM智能体及其演化”的核心目标——构建、改进或演化智能体本身——完全无关。因此，最终决策是**排除**。"
    },
    {
        "index": "#36",
        "title": "CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for Geometry-Aware and Domain-Aligned Data Augmentation",
        "link": "/arxiv/2512.10178",
        "arxiv_id": "2512.10178",
        "authors": "Keito Inoshita, Xiaokang Zhou, Akira Kawai, Katsutoshi Yada",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.325965",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合您的研究范围。我的判断过程如下： **第一步：核心判断——这篇论文的本质是什么？** 这篇论文的核心贡献是提出一个名为 **CIEGAD 的数据增强框架**。其目标是解决深度学习中的数据稀缺和标签不平衡问题，通过生成新的数据来补充现有数据分布中的“语义未覆盖区域”。 - **排除**: 该论文完全符合“非演化型应用”的排除标准。它将LLM（具体是作为“LLM-as-a-Judge”的质量控制模块）用作一个**工具**，来服务于其核心的数据增强任务。论文的研究焦点是**如何生成更高质量、更符合领域分布的数据**，而不是如何构建、改进或演化一个具有自主性的LLM智能体。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文中几乎没有包含您所关注的核心指标。 - **核心范式**: 论文没有讨论 `Agentic AI`, `Multi-Agent Systems`, 或 `Self-Evolving`。 - **智能体能力**: 论文没有涉及智能体的 `Planning`, `Memory`, `Tool Use`（作为智能体的核心能力）, `Self-Reflection` 等。虽然提到了 `LLM-as-a-Judge`，但这被用作一个外部的、静态的质量评估工具，而非智能体进行自我反思或自我修正的内部机制。 - **多智能体**: 完全不涉及。 - **演化机制**: 完全不涉及。 **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全与对齐、多模态与视觉等排除项，但第一步的判断已经足够将其排除。 **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划框架。 - **自我演化的应用**: 论文的核心是数据增强方法，而非自我演化机制。因此，不适用“自我演化应用”的例外保留规则。 **最终决策** 综合以上分析，这篇论文的本质是**一种利用LLM作为组件的机器学习数据增强方法**。它的研究目标是提升下游分类任务的性能，这与您“构建、改进或演化LLM智能体”的核心目标存在本质区别。论文中的LLM是一个被动的工具，而不是一个主动的、能够规划、记忆和演化的智能体。因此，这篇论文应被排除。"
    },
    {
        "index": "#4",
        "title": "Learning Controllable and Diverse Player Behaviors in Multi-Agent Environments",
        "link": "/arxiv/2512.10835",
        "arxiv_id": "2512.10835",
        "authors": "Atahan Cilan, Atay Özgövde",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.887800",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。 核心判断依据如下： 1.  **本质不符（第一步核心判断）**: 论文的核心贡献是提出一个**强化学习（RL）框架**，用于训练游戏中的智能体，使其行为可控且多样化。它明确使用了PPO（Proximal Policy Optimization）算法，这是一个经典的强化学习方法，与LLM智能体无关。我的研究焦点是“**LLM智能体**及其演化”，而本文研究的是“**RL智能体**”，这是两个不同的技术路径。论文完全没有提及LLM、语言模型或任何与自然语言处理相关的技术。 2.  **缺乏核心关注点（第二步正面指标）**: 尽管论文标题和摘要中提到了“Multi-Agent Environments”，但其研究范式是强化学习，而非我关注的Agentic AI。论文中缺少所有我关注的核心关键词，如 `LLM-based Agents`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Self-Evolving` 等。它研究的“行为控制”是通过强化学习的奖励函数和行为向量来实现的，而不是通过LLM的规划、反思或工具调用能力。 3.  **属于非演化型应用（第一步排除规则）**: 该论文将一个强化学习框架应用在特定的游戏领域（Unity游戏），以解决游戏测试、平衡等问题。这完全符合“非演化型应用”的排除标准——它没有提出新的智能体演化机制，而是将一个已有的技术范式（RL）应用于特定场景。 综上所述，虽然这篇论文在多智能体强化学习领域可能是一项有价值的工作，但它与我的核心研究课题“LLM智能体及其演化”在技术基础和研究范式上存在根本性的差异。因此，它不符合筛选要求。"
    },
    {
        "index": "#6",
        "title": "Interpretable and Steerable Concept Bottleneck Sparse Autoencoders",
        "link": "/arxiv/2512.10805",
        "arxiv_id": "2512.10805",
        "authors": "Akshay Kulkarni, Tsui-Wei Weng, Vivek Narayanaswamy, Shusen Liu, Wesam A. Sakla, Kowshik Thopalli",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.889106",
        "filter_reason": "这篇论文不符合研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文的本质是模型可解释性，而非智能体构建。** 论文的核心贡献是提出了一种名为“概念瓶颈稀疏自编码器（CB-SAE）”的新框架，其目标是提升模型（特别是LVLMs）的**可解释性**和**可操控性**。这属于模型分析和干预的范畴，而不是构建、改进或演化一个能够自主规划、使用工具或进行多智能体协作的LLM智能体。论文没有涉及智能体的核心能力，如规划、记忆、工具使用或自我反思。 2.  **第三步：排除标准——论文明确命中了两个关键的排除类别。** *   **安全与对齐:** 论文的摘要和标题反复强调其核心贡献是关于 **`Interpretability` (可解释性)** 和 **`Steerability` (可操控性)**。根据筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` (可解释性), `Explainability (XAI)`, `Alignment` (对齐)...一律排除。” 本文完全符合这一排除条件。 *   **多模态与视觉:** 论文明确指出其研究对象包括 **`LVLMs` (大语言视觉模型)** 和 **`image generation tasks`**。虽然规则中提到“除非它们被用作智能体感知环境的工具”，但在这篇论文中，视觉模型是**被研究和改进的主体**，而不是作为智能体框架中的一个组件。因此，它属于被排除的多模态研究。 3.  **第二步：正面指标——论文完全缺乏核心关注点。** 论文中没有出现任何与我的研究焦点相关的正面指标，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Collaboration`, `Self-Evolving` 等。这进一步确认了它与我的研究课题无关。 **总结:** 尽管该论文在模型可解释性领域可能是一项有价值的工作，但其研究焦点是“理解模型内部”和“操控模型行为”，这与我的核心目标“构建和演化能够自主行动的智能体”存在根本性差异。因此，根据筛选标准，该论文应被排除。"
    },
    {
        "index": "#5",
        "title": "Extrapolation of Periodic Functions Using Binary Encoding of Continuous Numerical Values",
        "link": "/arxiv/2512.10817",
        "arxiv_id": "2512.10817",
        "authors": "Brian P. Powell, Jordan A. Caraballo-Vega, Mark L. Carroll, Thomas Maxwell, Andrew Ptak, Greg Olmschenk, Jorge Martinez-Palomera",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.888477",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“归一化基-2编码（NB2E）”的输入编码方法，该方法能让普通的多层感知机（MLP）更好地外推周期函数。这个研究与“LLM智能体及其演化”的核心目标完全不符。 具体判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** 论文的核心是关于一种**神经网络输入表示方法**的发现，它提升了基础模型（MLP）在特定数学任务（周期函数外推）上的性能。它既没有涉及LLM，也没有涉及任何智能体框架。因此，根据第一步的排除规则，它属于对模型基础能力的研究，而非构建或演化智能体，应直接**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文完全不涉及任何与智能体相关的核心范式或能力。摘要和标题中没有出现 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何一个正面指标关键词。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全对齐或多模态等排除标准，但其核心内容已经超出了研究范围。 4.  **第四步：处理特殊和模糊情况** 根据“推理/规划”的特殊情况处理规则，虽然论文涉及“外推”这一推理形式，但它研究的是如何通过改进输入编码来提升基础模型（MLP）的能力，而不是在智能体框架下研究自主规划或多步推理。这完全符合“排除”的条件：“如果只是关于提高LLM本身基础Token预测的数学或逻辑能力（如新的数据集、非Agentic的微调方法）”。尽管这里用的是MLP而非LLM，但其本质是相同的，即非Agentic的基础能力提升。 **最终决策**：该论文是一项关于神经网络输入编码的基础性研究，旨在解决一个特定的数学问题。它没有构建任何形式的智能体，没有研究智能体的规划、记忆、工具使用或演化能力。因此，它与研究课题“LLM智能体及其演化”的核心目标无关，应予以排除。"
    },
    {
        "index": "#32",
        "title": "BRACE: A Benchmark for Robust Audio Caption Quality Evaluation",
        "link": "/arxiv/2512.10403",
        "arxiv_id": "2512.10403",
        "authors": "Tianyu Guo, Hongyu Chen, Hao Liang, Meiyi Qiang, Bohan Zeng, Linzhuang Sun, Bin Cui, Wentao Zhang",
        "subjects": "Sound, Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.313173",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是评估基准，而非智能体构建。** 该论文的核心贡献是提出了一个名为 **BRACE** 的**基准**，用于评估音频字幕的质量。我的研究目标是筛选那些核心贡献在于**构建、改进或演化LLM智能体**的论文。BRACE是一个评估工具，它本身不是智能体，也没有提出任何关于如何构建、改进或演化智能体的新框架或方法论。因此，从本质上讲，这篇论文属于评估方法学研究，而非Agentic AI的核心研究。 2.  **第一步：核心判断——属于“非演化型应用”。** 论文将LLM（用于数据损坏）和大型音频语言模型（LALM）作为工具，应用于“音频字幕质量评估”这一特定领域。这完全符合第一步排除标准中的“非演化型应用”：将已有的模型或框架作为工具应用到特定领域去解决该领域的问题。论文的重点是应用和评估，而不是智能体本身的演化。 3.  **第三步：排除标准——属于“多模态”研究。** 论文的研究对象是“音频字幕”和“大型音频语言模型（LALM）”，这明确属于**多模态** 范畴。根据我的筛选标准，除非多模态被用作智能体感知环境的工具，否则应被排除。在这篇论文中，多模态是研究的核心，而不是智能体的一个组件，因此符合排除条件。 4.  **关于“幻觉”的说明：** 尽管论文提到了“BRACE-Hallucination”用于检测幻觉内容，但这只是其评估基准的一个子功能。论文的**主要贡献**是基准本身，而不是一种新的检测或缓解幻觉的智能体机制。根据我的规则，只要论文的主要贡献不是关于安全、对齐或幻觉，就不因此排除。但即便如此，前述的“非演化型应用”和“多模态”这两点已足够将其排除。 **总结：** 该论文的核心是构建一个评估基准，属于评估方法学和多模态应用研究，与我的核心目标——“构建、改进或演化LLM智能体”——没有直接关联。因此，这篇论文应被排除。"
    },
    {
        "index": "#2",
        "title": "Generative Modeling from Black-box Corruptions via Self-Consistent Stochastic Interpolants",
        "link": "/arxiv/2512.10857",
        "arxiv_id": "2512.10857",
        "authors": "Chirag Modi, Jiequn Han, Eric Vanden-Eijnden, Joan Bruna",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.886695",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了一种名为“自洽随机插值”的新方法，用于解决一个特定的生成建模问题：从被噪声污染的数据中恢复出原始的干净数据。这本质上是一个**分布层面的逆问题**的解决方案。论文构建的是一个**生成模型**，而不是一个**LLM智能体**。因此，它属于“非演化型应用”，即将一种新的生成建模技术应用于科学和工程领域（如图像处理），而不是构建或演化智能体本身。根据第一步的排除规则，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式或能力相关的关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。虽然标题和摘要中出现了 \"Self-Consistent\"（自洽）和 \"iteratively update\"（迭代更新），但这些术语在本文的语境下描述的是一个**数学算法的收敛过程**，而非智能体的自我反思或自我完善机制。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文明确提到其应用领域包括 \"natural image processing\"（自然图像处理）和 \"scientific reconstruction\"（科学重建）。这直接触及了“多模态与视觉”的排除标准。虽然视觉可以作为智能体的工具，但在这篇论文中，视觉/图像数据本身就是要处理的核心问题，而不是智能体感知环境的一种手段。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。其“迭代更新”是算法层面的优化过程，而非智能体的决策过程。 - **自我演化的应用**: 这是最需要辨析的一点。尽管论文提出了一个迭代改进的机制，但它**不符合“自我演化智能体”的定义**。这里的“演化”是指一个数学模型（传输映射）通过迭代算法收敛到一个更优的、自洽的状态，以解决一个固定的逆问题。它不涉及智能体通过经验学习新技能、调整自身行为策略或进行代际演化。因此，第四步中关于“自我演化应用”的例外情况不适用。 **最终决策**: 综合以上分析，该论文的核心工作是提出一种用于解决数据恢复问题的生成建模算法，属于计算科学和机器学习方法论的范畴，与您研究的“LLM智能体及其演化”主题（关注智能体的构建、协作与自主演化）存在根本性的偏离。因此，应将其排除。"
    },
    {
        "index": "#37",
        "title": "Offscript: Automated Auditing of Instruction Adherence in LLMs",
        "link": "/arxiv/2512.10172",
        "arxiv_id": "2512.10172",
        "authors": "Nicholas Clark, Ryan Bai, Tanu Mitra",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.326588",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心贡献不符 (第一步)**: 论文的核心贡献是提出一个名为 \"Offscript\" 的**自动化审计工具**，用于**评估和检测**LLM是否遵循用户的自定义指令。我的研究目标是筛选那些**构建、改进或演化LLM智能体本身**的论文。这篇论文并没有提出新的智能体架构、规划方法、工具使用机制或自我演化框架，而是提供了一个**评估智能体行为合规性**的工具。它属于对现有模型行为的评估，而非智能体能力的构建。 2.  **触发了明确的排除标准 (第三步)**: 论文的核心主题是 \"instruction adherence\" (指令遵循) 和 \"auditing\" (审计)。这完全属于**安全与对齐** 的研究范畴。根据我的筛选标准，只要论文的主要贡献是关于对齐、安全或评估，就应一律排除。该论文的本质就是评估LLM的行为是否与用户的指令（一种对齐形式）保持一致。 3.  **缺乏正面指标 (第二步)**: 论文的摘要和标题中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。其焦点在于 \"auditing\" 和 \"compliance\"，这与我的研究焦点背道而驰。 综上所述，尽管该论文研究的是LLM相关的前沿问题，但其研究焦点是**对齐与评估**，而非**智能体的构建与演化**。因此，它严格地落在了我的排除范围之内。"
    },
    {
        "index": "#41",
        "title": "BAMBO: Construct Ability and Efficiency LLM Pareto Set via Bayesian Adaptive Multi-objective Block-wise Optimization",
        "link": "/arxiv/2512.09972",
        "arxiv_id": "2512.09972",
        "authors": "Kesheng Chen, Wenjian Luo, Zhenqian Zhu, Yamin Hu, Yiya Xi",
        "subjects": "Machine Learning, Computation and Language, Neural and Evolutionary Computing",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.334322",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种名为BAMBO的框架，用于通过贝叶斯优化和块划分策略来**构建LLM的帕累托集**。其本质是一种**模型合并与优化技术**，旨在解决LLM在“能力”与“效率”之间的权衡问题。它并不涉及构建一个具有自主规划、工具使用或记忆能力的LLM智能体，也没有提出多智能体系统或智能体的自我演化机制。因此，根据第一步的核心判断标准，该论文应被**排除**，因为它不属于构建、改进或演化LLM智能体的方法论。 2.  **正面指标 (第二步):** 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。同样，它也未提及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究焦点无关。 3.  **排除标准 (第三步):** 虽然论文不涉及安全、对齐或多模态等排除项，但这并不足以使其被保留，因为它首先未能通过核心判断。 4.  **特殊和模糊情况 (第四步):** *   **推理/规划:** 论文不涉及智能体的推理或规划框架。 *   **自我演化的应用:** 论文中提到的“演化循环”指的是其贝叶斯优化算法的迭代搜索过程，这是一种**算法层面的优化策略**，而非**智能体层面的自我完善机制**。智能体的自我演化是指智能体在与环境交互后，通过反思和学习来更新自身的行为策略或知识库。本文的“演化”是寻找最优模型配置的过程，与智能体的生命周期和学习机制无关。 **最终决策 (第五步):** 综合以上分析，这篇论文的核心贡献是LLM的**模型优化与合并技术**，属于模型工程和效率优化的范畴。它没有提出任何关于智能体架构、交互或演化的新方法。因此，尽管它是一篇关于LLM的前沿研究，但它与我的核心研究目标——“LLM智能体及其演化”——不匹配，应予以排除。"
    },
    {
        "index": "#1",
        "title": "Scaling Behavior of Discrete Diffusion Language Models",
        "link": "/arxiv/2512.10858",
        "arxiv_id": "2512.10858",
        "authors": "Dimitri von Rütte, Janis Fluri, Omead Pooladzandi, Bernhard Schölkopf, Thomas Hofmann, Antonio Orvieto",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.886064",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文的本质是什么？** - 论文的核心贡献是研究“离散扩散语言模型”的缩放定律。它探讨了不同噪声类型（如masked和uniform diffusion）对模型缩放行为的影响，以及在计算和数据限制下的最优参数-数据配比。 - 这是一项关于**基础模型架构和训练效率**的研究，而非关于构建、改进或演化LLM智能体的方法论。它属于“基础设施”或“基础模型研究”的范畴，根据筛选标准的第一步，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我的研究焦点相关的关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving`, `Self-Reflection` 等。这表明论文的研究内容与我的核心关注点（单智能体、多智能体、自我演化）无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全与对齐（Safety, Alignment）或多模态（Vision）等排除标准。然而，第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** - 论文虽然提到了“Diffusion Models”，但它是作为语言模型的一种架构（DLMs）来研究的，而不是作为智能体感知环境的工具。研究的核心是模型的缩放行为，而非智能体的能力或演化机制。 - 论文不涉及任何关于智能体规划或自我演化的特殊情况。 **最终决策**：该论文是一项关于基础语言模型架构（离散扩散模型）缩放行为的实证研究，其核心贡献在于理解模型本身的训练特性，而非构建或演化具有自主性、规划能力或协作能力的LLM智能体。因此，它完全不符合我关于“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#7",
        "title": "Template-Free Retrosynthesis with Graph-Prior Augmented Transformers",
        "link": "/arxiv/2512.10770",
        "arxiv_id": "2512.10770",
        "authors": "Youjun Zhao",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.889614",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是“非演化型应用”** 论文的核心目标是解决化学领域的特定问题——“逆合成反应预测”。它提出了一种改进的Transformer模型架构，通过注入分子图信息来提升预测的准确性。这完全符合筛选标准中的“排除规则1：非演化型应用”。论文的本质是将一个先进的模型（Transformer）作为工具，应用于特定领域（化学）去解决该领域的问题，其贡献在于模型架构的优化，而非构建或演化一个具有自主性的LLM智能体。 2.  **第二步：缺乏正面指标** 论文摘要中完全没有出现您关注的核心范式和智能体能力关键词。例如，它没有涉及`Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`或`Self-Reflection`。该模型是一个端到端的预测模型，输入产物，输出反应物，不具备智能体的自主规划、工具调用或自我迭代等核心特征。 3.  **第四步：特殊情况分析——属于“非Agentic的推理”** 虽然逆合成预测可以被视为一种复杂的推理任务，但它属于“排除规则”中的“非Agentic的推理”。论文的重点是改进模型本身对化学反应这一特定领域的“基础推理能力”（即预测反应物），而不是研究一个智能体如何通过规划、反思、使用工具等Agentic框架来解决通用或复杂任务。这与研究ReAct、ToT等Agentic推理框架有本质区别。 **总结**: 该论文的核心贡献是提出了一种针对化学逆合成任务的、性能更优的模型架构和训练方法。它是一项出色的领域应用研究，但其焦点是“模型”而非“智能体”，是“应用”而非“演化”。因此，它严格地落在了您研究范围之外。"
    },
    {
        "index": "#13",
        "title": "DCFO Additional Material",
        "link": "/arxiv/2512.10659",
        "arxiv_id": "2512.10659",
        "authors": "Tommaso Amico, Pernille Matthews, Lena Krieger, Arthur Zimek, Ira Assent",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.893105",
        "filter_reason": "解析失败"
    },
    {
        "index": "#9",
        "title": "Generalized Spherical Neural Operators: Green's Function Formulation",
        "link": "/arxiv/2512.10723",
        "arxiv_id": "2512.10723",
        "authors": "Hao Tang, Hao Chen, Chao Li",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.891001",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 论文的核心贡献是提出了一种名为“广义球面神经算子（GSNO）”的新框架，以及一个名为“GSHNet”的神经网络架构。其目标是解决球面域上的参数偏微分方程。 - **是否符合保留标准**: 不符合。该论文的核心是关于**神经算子**，这是一种用于科学计算和数值求解的深度学习模型，而非构建、改进或演化LLM智能体。 - **是否符合排除标准**: 符合。这篇论文是典型的**非演化型应用**。它将一种新设计的神经网络（GSNO）作为工具，应用于特定领域（如扩散MRI、天气预报）来解决该领域的偏微分方程问题。论文完全没有涉及LLM、智能体框架或其演化。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。这进一步确认了其与研究主题的无关性。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文没有直接触及“安全与对齐”或“多模态与视觉”等排除关键词，但第一步的判断已经足够将其排除。值得注意的是，论文中的“diffusion MRI”指的是一种医学成像技术，而不是生成式AI中的“扩散模型”。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文研究的是数值求解偏微分方程的数学推理，而非智能体在复杂任务中的自主规划和多步推理。因此，属于排除范畴。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制，因此例外情况不适用。 **最终决策**: 综合以上分析，该论文属于科学计算领域，其核心是提出一种新的神经网络架构来解决特定类型的数学问题。它与我的研究目标——“LLM智能体及其演化”——在研究对象、核心贡献和技术路线上完全不同。因此，应予以排除。"
    },
    {
        "index": "#14",
        "title": "Token Sample Complexity of Attention",
        "link": "/arxiv/2512.10656",
        "arxiv_id": "2512.10656",
        "authors": "Léa Bohbot, Cyril Letrouit, Gabriel Peyré, François-Xavier Vialard",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.893396",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是理论分析，具体来说是研究Transformer模型中注意力机制在序列长度趋于无穷时的数学收敛性质。它提出了“token样本复杂度”这一新概念，并推导了在不同分布假设下的收敛速率界限。 - **与筛选标准的匹配**: 这项研究属于对LLM基础组件（注意力机制）的**理论分析**，而不是关于**构建、改进或演化LLM智能体**的方法论或新框架。它没有提出任何新的智能体架构、规划策略、工具使用方法或多智能体协作协议。因此，根据第一步的排除标准，它属于“非Agentic的推理”范畴，应被排除。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving`, `Memory`, `Collaboration` 等。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准** - 虽然这篇论文不涉及安全、对齐或多模态等排除项，但第一步的判断已经足够明确，无需深入此步。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文虽然涉及“推理”的底层机制，但它研究的是注意力这一数学模块的收敛性，而非智能体层面的自主规划和多步决策框架。它完全符合“排除：如果只是关于提高LLM本身基础Token预测的数学或逻辑能力”的描述。 **最终决策**: 综合以上分析，该论文是一项关于LLM底层架构的纯粹理论研究，其贡献在于深化对注意力机制数学行为的理解，而非推动LLM智能体在规划、协作或自我演化等Agentic能力方面的发展。因此，它严格地落在了您研究范围之外。"
    },
    {
        "index": "#11",
        "title": "HybridVFL: Disentangled Feature Learning for Edge-Enabled Vertical Federated Multimodal Classification",
        "link": "/arxiv/2512.10701",
        "arxiv_id": "2512.10701",
        "authors": "Mostafa Anoosha, Zeinab Dehghani, Kuniko Paxton, Koorosh Aslansefat, Dhavalkumar Thakker",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.892254",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 `HybridVFL` 的新框架，用于改进**垂直联邦学习** 中的**多模态特征融合**。其本质是针对一种特定的分布式机器学习范式（VFL）的技术改进，旨在提升其在特定任务（多模态分类）上的性能。这完全符合第一步中的排除标准： *   **非演化型应用**: 论文将一种机器学习技术（VFL）应用到特定领域（移动健康诊断），以解决该领域的性能问题，其核心并非构建或演化智能体。 *   **基础设施**: 垂直联邦学习（VFL）本身就是一种用于隐私保护分布式计算的**基础设施或系统架构**。论文的工作是优化这种基础设施，而非研究智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等任何关键词。其技术焦点是 `Feature Disentanglement` (特征解缠) 和 `Cross-modal Transformer` (跨模态Transformer)，这些都是模型架构和特征工程领域的概念，与智能体无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文明确涉及了排除标准中的内容： *   **多模态与视觉**: 论文的核心任务是“多模态分类”，并在皮肤病变数据集（HAM10000）上进行评估，这表明其研究核心包含了视觉数据处理。这并非将视觉作为智能体感知环境的工具，而是研究的**核心对象**，因此属于排除范围。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何需要特殊处理的情况。它既不是关于智能体的推理/规划，也没有提出任何自我演化机制。 **最终决策**: 综合以上分析，该论文的研究方向是**联邦学习**和**多模态机器学习**，其核心贡献在于改进分布式系统中的特征融合效率。这与您关于“LLM智能体及其演化”的研究课题（聚焦于智能体的构建、协作与自我演化）在研究对象、核心贡献和技术路线上存在根本性差异。因此，该论文应被排除。"
    },
    {
        "index": "#12",
        "title": "Learning by Analogy: A Causal Framework for Composition Generalization",
        "link": "/arxiv/2512.10669",
        "arxiv_id": "2512.10669",
        "authors": "Lingjing Kong, Shaoan Xie, Yang Jiao, Yetian Chen, Yanhui Guo, Simone Shao, Yan Gao, Guangyi Chen, Kun Zhang",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.892826",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心贡献不符 (第一步核心判断)**: 论文的核心贡献是提出一个**因果框架**来解释和实现**组合泛化**能力。它关注的是模型如何学习和重组概念，这是一种对LLM基础认知能力的理论性探索。它并没有提出一个**LLM智能体**，即一个能够自主规划、使用工具、与环境交互或进行自我反思的实体。因此，这篇论文属于“非Agentic的推理”研究，其目标是提升模型本身的基础能力，而非构建或演化一个智能体框架。 2.  **缺乏核心关注点 (第二步正面指标)**: 论文摘要中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这表明其研究焦点与我的课题存在显著偏差。 3.  **符合排除规则 (第四步特殊情况处理)**: 根据第四步关于“推理/规划”的特殊规则，这篇论文应被排除。它研究的是组合泛化这一基础推理能力，但其方法是提出一个因果理论和数据生成过程，而不是一个智能体如何在复杂任务中进行多步规划和行动的框架（如 ReAct 或 ToT）。它属于“提高LLM本身基础Token预测的...能力”的范畴，而非“智能体如何进行规划或在复杂任务中进行多步推理”。 综上所述，尽管组合泛化是高级智能体可能需要的能力之一，但该论文的研究路径是基础理论和模型能力提升，而非智能体架构或演化机制的构建。因此，它不符合我筛选“LLM智能体及其演化”前沿论文的核心目标。"
    },
    {
        "index": "#8",
        "title": "LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation",
        "link": "/arxiv/2512.10735",
        "arxiv_id": "2512.10735",
        "authors": "Lin Du, Lu Bai, Jincheng Li, Lixin Cui, Hangyuan Du, Lichi Zhang, Yuting Chen, Zhao Li",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.890265",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **论文核心贡献**: 该论文提出了一种名为LGAN（线图聚合网络）的新型图神经网络（GNN）架构。其核心目标是解决现有GNN在图分类任务中表达能力受限和计算成本高的问题。 - **判断**: 这篇论文的本质是**基础模型架构的创新**，具体来说是针对图神经网络（GNN）的改进。它完全不涉及构建、改进或演化LLM智能体。因此，根据第一步的排除规则，它不属于“构建LLM智能体”或“自我演化”的范畴，应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要和标题中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文讨论的是 `Graph Neural Networks`, `Message Passing`, `Weisfeiler-Lehman test` 等GNN领域的术语。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文提到了 `Interpretability` (可解释性)，并指出其模型比其他高阶GNN更具可解释性。然而，这并非论文的**主要贡献**。其主要贡献是LGAN这个新架构本身，可解释性只是该架构带来的一个优点。因此，它不属于“主要贡献是关于安全与对齐”的排除情况，但这个点进一步证明了其研究焦点与您的“LLM智能体”目标相去甚远。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此此步不适用。 **最终决策**: 综合以上分析，这篇论文是一篇典型的图神经网络（GNN）架构研究，属于基础模型领域。它的核心贡献是提出一种更高效、表达能力更强的GNN模型，与您的研究课题“LLM智能体及其演化”在研究对象、核心贡献和研究范式上均无交集。因此，该论文应被明确排除。"
    },
    {
        "index": "#3",
        "title": "Bayesian Symbolic Regression via Posterior Sampling",
        "link": "/arxiv/2512.10849",
        "arxiv_id": "2512.10849",
        "authors": "Geoffrey F. Bomarito, Patrick E. Leser",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.887234",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了一种用于**符号回归**的新算法，即基于序贯蒙特卡洛的贝叶斯框架。其目标是改进从数据中发现数学方程的鲁棒性和不确定性量化能力。论文的本质是**一种针对特定机器学习任务（符号回归）的优化算法**，而不是构建、改进或演化一个具有自主性的LLM智能体。因此，根据第一步的排除标准，它属于“非演化型应用”，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。虽然它提到了与“遗传编程”的对比，但遗传编程在这里是作为被比较的基线方法，论文本身并未提出新的演化机制或智能体框架。智能体能力（如 `Planning`, `Tool Use`, `Memory`）和多智能体概念（如 `Collaboration`）也完全缺失。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文提到了其方法能产生“可解释的方程”，但这只是其算法带来的一个**结果或优点**，而非论文的核心贡献。论文的核心是算法本身，而不是一个关于可解释性的新框架。因此，这不构成一个硬性的排除理由，但进一步确认了其研究焦点与我的不同。 4.  **第四步：处理特殊和模糊情况** -   **推理/规划**: 论文中的“推理”是指SMC算法内部的概率计算和搜索过程，而非一个智能体在环境中进行自主规划和多步决策。这属于被排除的“非Agentic的推理”范畴。 -   **自我演化的应用**: 尽管论文与“演化算法”（遗传编程）相关，但它并未提出一种通用的“自我演化”机制。它的核心是一种针对符号回归任务的特定搜索算法，不符合“自我演化应用”的例外保留规则。 **最终决策**: 综合以上分析，该论文是一篇关于符号回归算法的机器学习论文，其核心贡献与LLM智能体的构建、多智能体系统或自我演化机制无关。它属于将一种新算法应用于特定领域（科学发现）的研究，完全偏离了我关于“LLM智能体及其演化”的核心研究目标。因此，最终判断为**排除**。"
    },
    {
        "index": "#10",
        "title": "Beyond the Black Box: Identifiable Interpretation and Control in Generative Models via Causal Minimality",
        "link": "/arxiv/2512.10720",
        "arxiv_id": "2512.10720",
        "authors": "Lingjing Kong, Shaoan Xie, Guangyi Chen, Yuewen Sun, Xiangchen Song, Eric P. Xing, Kun Zhang",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.891616",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一种基于“因果最小性”原则的理论框架，用于**解释和控制**生成模型（包括扩散模型和自回归语言模型）的内部表征。其目标是打开模型的“黑盒”，实现模型的可解释性、可控性和对齐。这并非关于构建、改进或演化一个具有自主规划、工具使用或协作能力的LLM智能体。因此，根据第一步的排除标准，该论文的核心是关于模型的可解释性与对齐，而非智能体框架的构建，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现您所列出的任何核心关注点，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent`, `Collaboration` 等。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这是最关键的排除依据。论文摘要明确指出了其研究目标与“安全与对齐”领域高度相关： *   **可解释性**: \"establish a principled foundation for **interpretable** generative models\" 和 \"endow the latent representations ... with clear causal **interpretation**\"。 *   **对齐**: \"hindering human understanding, control, and **alignment**\"。 *   **控制**: \"robust ... identifiable **control**\" 和 \"fine-grained model **steering**\"。 根据您的筛选标准，只要论文的主要贡献是关于 `Interpretability` (可解释性) 或 `Alignment` (对齐)，就应一律排除。这篇论文完全符合此排除条件。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它讨论的是对模型内部静态表征的解释，而非智能体的动态行为或演化机制。 **最终决策**: 综合以上分析，该论文的核心贡献在于生成模型的**可解释性与可控性**，属于模型安全与对齐的研究范畴。它没有提出任何关于LLM智能体的构建、规划、工具使用、多智能体协作或自我演化的新方法或框架。因此，它严格地落在了您指定的排除标准之外，不符合您关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#18",
        "title": "THeGAU: Type-Aware Heterogeneous Graph Autoencoder and Augmentation",
        "link": "/arxiv/2512.10589",
        "arxiv_id": "2512.10589",
        "authors": "Ming-Yi Hong, Miao-Chen Chiang, Youchen Teng, Yu-Hsiang Wang, Chih-Yu Wang, Che Lin",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.894509",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - 论文的核心贡献是提出一个名为 THeGAU 的**异质图神经网络（HGNN）框架**，用于解决图数据中的节点分类问题。其本质是改进一种特定的机器学习模型（GNN），而不是构建、改进或演化 LLM 智能体。 - 该论文完全属于 **“非演化型应用”** 的排除范畴。它没有涉及任何 LLM 或智能体框架，而是专注于图结构数据本身的建模方法。因此，在第一步就应该被排除。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction` 等。 - 文中提到的 `Augmentation`（增强）是指对图结构进行数据增强，是一种常见的机器学习技术，与智能体的“自我增强”或“自我演化”机制完全无关。 3.  **第三步：排除标准** - 虽然这篇论文不涉及安全、对齐或多模态等排除项，但它属于一个更根本的排除类别：**研究领域不匹配**。它属于图机器学习领域，而非 Agentic AI 领域。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此不适用特殊情况的例外规则。 **最终决策**: 这篇论文的核心是关于图神经网络（GNN）的算法创新，旨在提升节点分类任务的性能。它与“LLM智能体及其演化”这一研究课题在研究对象、核心贡献和技术路线上均无交集。因此，该论文应被明确排除。"
    },
    {
        "index": "#16",
        "title": "Uncertainty-Preserving QBNNs: Multi-Level Quantization of SVI-Based Bayesian Neural Networks for Image Classification",
        "link": "/arxiv/2512.10602",
        "arxiv_id": "2512.10602",
        "authors": "Hendrik Borras, Yong Wu, Bernhard Klein, Holger Fröning",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.893971",
        "filter_reason": "这篇论文不符合我的研究范围，其核心贡献与研究目标存在根本性偏差。我的判断依据如下： 1.  **第一步：核心判断——论文本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出了一种用于贝叶斯神经网络（BNNs）的多级量化框架，其目标是减少模型的计算和内存开销，以便在资源受限的边缘设备上部署。这完全属于筛选标准中明确排除的“基础设施”类别，即“主要关注模型基础设施、部署优化、硬件加速的研究”。论文的研究焦点是模型压缩和工程实现，而非构建或演化具有自主性的LLM智能体。 2.  **第二步：缺乏任何正面指标。** 论文的标题和摘要中完全没有出现任何与研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。其核心概念是 `Quantization` (量化), `Bayesian Neural Networks` (贝叶斯神经网络), 和 `Uncertainty` (不确定性)，这些都与我的研究目标无关。 3.  **第三步：符合明确的排除标准。** 论文的应用领域是“图像分类”，这直接命中了“多模态与视觉”的排除标准。虽然视觉可以作为智能体感知环境的工具，但在这篇论文中，视觉是研究的核心任务本身，而不是服务于一个更高层次的智能体框架。 **总结：** 该论文是一篇典型的模型工程优化研究，致力于解决贝叶斯神经网络在部署时的效率问题。它既不涉及LLM，也不涉及智能体的构建、协作或演化机制。因此，尽管它可能在其自身领域（高效能深度学习）内具有价值，但它与“LLM智能体及其演化”这一研究课题完全无关，应予以排除。"
    },
    {
        "index": "#15",
        "title": "Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach",
        "link": "/arxiv/2512.10633",
        "arxiv_id": "2512.10633",
        "authors": "C. Bosco, U. Minora, D. de Rigo, J. Pingsdorf, R. Cortinovis",
        "subjects": "Machine Learning, Social and Information Networks, Applications",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.893699",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种用于预测欧洲非法边境穿越的“混合方法论”，该方法结合了机器学习技术和人类专家的定性见解。这完全符合筛选标准中的“非演化型应用”排除项。论文的本质是将机器学习作为一种工具，应用于一个特定的领域（移民政策），以解决该领域的预测问题，其研究目标是提升预测准确性以支持政策制定，而非构建、改进或演化LLM智能体本身。 2.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现任何与您研究焦点相关的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction` 等。这进一步表明该论文的研究内容与您的目标无关。 3.  **研究焦点不符 (第三步):** 论文的研究焦点是“移民治理”和“政策预测”，这是一个典型的社会科学与数据科学交叉的应用领域。这与您所关注的“Agentic AI”基础研究（单智能体、多智能体、自我演化）存在本质区别。 4.  **特殊情况分析 (第四步):** 该论文不涉及任何特殊情况。它既没有提出新的智能体规划或推理框架，也没有提出任何“自我演化”机制。其“混合方法”指的是数据模型与专家知识的结合，而非智能体的自我完善或迭代。 **总结:** 该论文的核心贡献在于应用层面的预测方法论创新，而非智能体AI基础理论的突破。它将机器学习视为解决特定领域问题的工具，这与您筛选“核心贡献在于构建、改进或演化LLM智能体”论文的目标完全背离。因此，应果断排除。"
    },
    {
        "index": "#22",
        "title": "Disentangled and Distilled Encoder for Out-of-Distribution Reasoning with Rademacher Guarantees",
        "link": "/arxiv/2512.10522",
        "arxiv_id": "2512.10522",
        "authors": "Zahra Rahiminasab, Michael Yuhas, Arvind Easwaran",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.901019",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个“解耦蒸馏编码器”框架，其目标是压缩模型大小以便在资源受限的设备上部署，并保持模型在分布外（OOD）数据上的推理能力。这完全属于**基础设施**和**部署优化**的范畴，是明确的排除项。论文研究的模型是变分自编码器（VAE），而非LLM。 2.  **研究焦点不匹配:** 论文中的“推理”指的是模型对分布外样本的泛化分类能力，是一种非Agentic的、静态的模型能力评估。这与我关注的“智能体如何通过规划、工具使用、反思等方式进行多步自主决策”的Agentic推理完全不同。 3.  **缺乏正面指标 (第二步):** 论文标题和摘要中完全没有出现任何与我的核心关注点相关的关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。 4.  **结论:** 综上所述，该论文的本质是关于传统生成模型（VAE）的模型压缩与部署优化，旨在提升其在特定任务（OOD分类）上的鲁棒性。它既不涉及LLM，也不涉及智能体的构建、协作或演化。因此，它与研究课题“LLM智能体及其演化”的核心目标完全无关。"
    },
    {
        "index": "#17",
        "title": "Multi-Objective Reward and Preference Optimization: Theory and Algorithms",
        "link": "/arxiv/2512.10601",
        "arxiv_id": "2512.10601",
        "authors": "Akhil Agnihotri",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.894208",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非构建、改进或演化LLM智能体。摘要明确指出，该论文的核心是“推进约束强化学习（RL）”，并将其应用于“控制、偏好学习和大型语言模型对齐”。这属于典型的“非演化型应用”，即使用先进的算法（约束RL）作为工具，去解决一个特定领域的问题（模型对齐），而不是研究智能体本身的能力或架构。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文摘要中反复出现并明确强调了其研究焦点是“大型语言模型对齐”和“安全决策”。根据您的筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Alignment` (对齐)...一律排除”。这篇论文的最终贡献（MOPO算法）就是直接服务于对齐目标的，因此完全符合排除条件。 3.  **正面指标缺失 (第二步):** 论文中完全没有出现您所关注的核心范式和能力关键词。摘要中未提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等任何与智能体核心能力相关的概念。其讨论的是RLHF（从人类反馈中强化学习），这是一种对齐技术，而非智能体在环境中自主行动和演化的框架。 4.  **特殊情况处理 (第四步):** 论文虽然提到了“迭代算法”，但这指的是优化过程中的迭代更新，而非智能体通过经验、反思或环境反馈进行“自我演化”的机制。其目标是让模型输出符合人类偏好（对齐），而不是让智能体在执行任务的能力上自我完善。 综上所述，该论文是一篇关于约束强化学习理论及其在模型对齐领域应用的优秀研究，但其核心贡献与您“LLM智能体及其演化”的研究目标（聚焦于智能体的规划、工具使用、协作和自我演化能力）完全偏离，因此应被排除。"
    },
    {
        "index": "#20",
        "title": "Unlocking the Address Book: Dissecting the Sparse Semantic Structure of LLM Key-Value Caches via Sparse Autoencoders",
        "link": "/arxiv/2512.10547",
        "arxiv_id": "2512.10547",
        "authors": "Qingsen Ma, Dianyun Wang, Jiaming Lyu, Yaoye Wang, Lechen Ning, Sujie Zhu, Zhenbo Xu, Liuyu Xiang, Huining Li, Huijia Wu, Zhaofeng He",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.895129",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心贡献不符 (第一步)**: 论文的核心贡献是提出一个名为 `STA-Attention` 的框架，用于**解构和优化LLM内部的Key-Value (KV)缓存**。其目标是提高KV缓存的**可解释性**和**计算效率**，解决长上下文模型中的内存瓶颈问题。这属于**模型基础设施**和**部署优化**的范畴，而不是构建、改进或演化LLM智能体的方法论。根据筛选标准的第一步，这类关注基础设施的论文应被排除。 2.  **命中排除标准 (第三步)**: 论文摘要明确指出，其工作旨在“将KV缓存分解为可解释的‘语义原子’”，并“弥合机制可解释性与忠实注意力建模之间的鸿沟”。这表明论文的主要贡献是关于**可解释性**。根据您的筛选标准，只要论文的主要贡献是关于 `Interpretability` (可解释性)，就应一律排除。 3.  **缺乏正面指标 (第二步)**: 论文的研究内容与您关注的核心范式和能力无关。摘要中完全没有出现 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等任何正面指标关键词。虽然提到了“memory”，但这里指的是模型的**计算内存**，而非智能体用于存储经验、进行反思的**智能体记忆**。 综上所述，尽管这篇论文在LLM的底层机制和效率优化方面可能是一项有价值的研究，但它与您关于“LLM智能体及其演化”的核心目标——即构建和演化具备自主规划、工具使用、协作或自我演化能力的智能体——完全无关。因此，应将其排除。"
    },
    {
        "index": "#21",
        "title": "Mode-Seeking for Inverse Problems with Diffusion Models",
        "link": "/arxiv/2512.10524",
        "arxiv_id": "2512.10524",
        "authors": "Sai Bharath Chandra Gutha, Ricardo Vinuesa, Hossein Azizpour",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.895401",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为“变分模态搜索损失”的新方法，用于改进**扩散模型**在解决**逆问题**（如图像恢复）时的性能。其本质是针对一种特定的生成模型（Diffusion Model）进行算法层面的优化，使其在特定任务（图像处理）上表现更好。这完全属于“非演化型应用”的范畴，因为它将一个模型作为工具应用于特定领域，而没有涉及构建、改进或演化LLM智能体本身。因此，根据第一步的核心判断，应予以排除。 2.  **第二步：正面指标** 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use` 或 `Self-Reflection` 等。这进一步确认了该论文与我的研究目标无关。 3.  **第三步：排除标准** 该论文明确属于“多模态与视觉”的排除标准。其研究对象是**扩散模型**，应用任务是**图像恢复**。虽然我的筛选标准中提到“除非它们被用作智能体感知环境的工具”，但在这篇论文中，扩散模型是研究的**核心主体**，而不是一个智能体框架中的组件。论文的目标是改进扩散模型本身，而不是利用它来赋能一个LLM智能体。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与“推理/规划”或“自我演化”相关的特殊或模糊情况。它提出的是一种静态的、单次生成过程中的优化损失函数，而非智能体的迭代学习或自我完善机制。 **最终决策**：综合以上分析，这篇论文的核心工作是关于计算机视觉和生成模型（扩散模型）的算法创新，与“LLM智能体及其演化”这一研究课题在研究对象、核心贡献和技术路线上均无交集。因此，我判断该论文不符合要求，应予以排除。"
    },
    {
        "index": "#23",
        "title": "Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning",
        "link": "/arxiv/2512.10510",
        "arxiv_id": "2512.10510",
        "authors": "Chihyeon Song, Jaewoo Lee, Jinkyoo Park",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.901670",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质不匹配** 论文的核心贡献是提出了一种名为“自适应回放缓冲区”的方法，用于改进“离线到在线强化学习”算法。其本质是**对强化学习算法本身的数据管理策略进行优化**，旨在平衡离线数据和在线数据的使用。我的研究目标是“LLM智能体及其演化”，核心关注点必须是**构建、改进或演化基于LLM的智能体**。这篇论文完全没有提及LLM，其研究对象是通用的强化学习算法，而非LLM智能体。因此，它在最核心的层面上就不符合要求。 2.  **第二步：缺乏正面指标** 论文摘要中完全没有出现我关注的核心范式和能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。这进一步证实了该论文的研究方向与我的焦点领域无关。 3.  **第三步和第四步：不涉及特殊排除情况，但也不符合例外规则** 这篇论文不属于安全对齐或多模态等排除类别。同时，它也不符合“自我演化的应用”这一例外规则，因为它提出的“自适应回放缓冲区”是一种算法层面的数据采样机制，而不是一种让智能体进行自我完善、自我反思或迭代的“自我演化”框架。它改进的是学习算法，而不是智能体本身的演化能力。 **总结**: 尽管这篇论文在强化学习领域可能是一项有价值的工作，但它属于**通用强化学习算法研究**，与我的核心课题“LLM智能体及其演化”完全脱节。我的筛选标准明确要求论文的核心贡献必须围绕LLM智能体展开，而该论文完全不涉及LLM。因此，必须排除。"
    },
    {
        "index": "#19",
        "title": "Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning",
        "link": "/arxiv/2512.10573",
        "arxiv_id": "2512.10573",
        "authors": "Yi Huang, Qingyun Sun, Yisen Gao, Haonan Yuan, Xingcheng Fu, Jianxin Li",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.894798",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了一种名为 `LaT-IB` 的新方法，用于解决信息瓶颈原理在标签噪声下的脆弱性问题。其本质是**一种改进的表示学习理论和方法**，旨在提升模型在数据标签不干净的情况下的鲁棒性。它完全不涉及构建、改进或演化任何形式的智能体。因此，根据第一步的排除标准，它属于“非Agentic的推理”范畴，即提升模型的基础能力（此处为表示学习的鲁棒性），而非构建智能体框架，应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何我关注的核心范式或能力关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了该论文与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的研究主题是“标签噪声鲁棒性”，这属于机器学习模型鲁棒性的一个分支。虽然“鲁棒性”是一个相关概念，但论文的焦点是**数据层面的噪声**，而非智能体的安全、对齐或行为鲁棒性。因此，它不属于我明确排除的“安全与对齐”类别，但其研究内容本身已经偏离了“LLM智能体”这一核心。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何需要特殊处理的情况。它既不是关于智能体的推理/规划，也没有提出任何“自我演化”机制。 **最终决策**: 综合以上分析，这篇论文是一项扎实的基础机器学习研究，专注于改进信息瓶颈理论以应对标签噪声。然而，它的核心贡献与研究课题“LLM智能体及其演化”完全无关。它没有构建智能体，没有研究多智能体系统，也没有提出任何自我演化机制。因此，该论文应被明确排除。"
    },
    {
        "index": "#26",
        "title": "Hybrid Physics-ML Model for Forward Osmosis Flux with Complete Uncertainty Quantification",
        "link": "/arxiv/2512.10457",
        "arxiv_id": "2512.10457",
        "authors": "Shiv Ratn, Shivang Rampriyan, Bahni Ray",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.903473",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一种**混合物理-机器学习模型**，用于解决化学工程领域（正渗透技术）中的水通量预测问题。它使用高斯过程回归（GPR）来修正传统物理模型的误差，并进行不确定性量化。这完全符合筛选标准中的**排除项1：“非演化型应用”**。该研究是将机器学习（GPR，而非LLM）作为工具应用到一个特定领域（化学工程）去解决该领域的特定问题（通量预测），其核心目标并非构建、改进或演化LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与您研究焦点相关的正面指标。它不涉及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。其方法也不包含智能体的核心能力，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。该模型是一个静态的预测模型，不具备任何自主性或演化能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文的主要贡献不是关于安全与对齐或多模态，但第一步的判断已经足够将其排除。这篇论文的研究范式是“科学计算”或“工程应用”，与您关注的“Agentic AI”范式有根本区别。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何自我演化机制。因此，特殊情况的例外条款不适用。 **最终决策**：综合以上分析，该论文是一篇典型的将机器学习方法应用于特定科学工程问题的研究。其核心贡献在于解决正渗透领域的建模难题，而非在LLM智能体的构建、协作或演化方面做出任何方法论上的创新。因此，它严格地不符合您“LLM智能体及其演化”的研究课题要求，应予以排除。"
    },
    {
        "index": "#28",
        "title": "The Operator Origins of Neural Scaling Laws: A Generalized Spectral Transport Dynamics of Deep Learning",
        "link": "/arxiv/2512.10427",
        "arxiv_id": "2512.10427",
        "authors": "Yizhou Zhang",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.904578",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是**提出一个关于深度学习训练动力学的统一数学理论**。它通过算子理论和偏微分方程（PDE）来解释神经网络（特别是现代深度网络）的训练过程，并推导出神经缩放律的数学表达式。论文的本质是**对深度学习基础理论的数学建模与分析**，而不是构建、改进或演化一个LLM智能体。它没有提出任何新的智能体架构、规划方法、工具使用机制或多智能体协作框架。因此，根据第一步的核心判断标准，这篇论文应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现您列出的任何核心关注点。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何与智能体直接相关的概念。其关键词是 `operator-theoretic description`, `training dynamics`, `gradient descent`, `spectral transport`, `scaling-law exponents`, `NTK training` 等，这些都属于深度学习理论和优化动力学的范畴。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不属于安全对齐或多模态等明确的排除类别，但它属于更根本的排除类别：**非Agentic的基础理论研究**。您的研究焦点是“Agentic AI”，而这篇论文的焦点是“深度学习理论”。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何需要特殊处理的模糊情况。它既不是关于智能体的推理/规划，也不是关于自我演化的应用。 **最终决策**: 综合以上分析，这篇论文是一篇纯粹的深度学习理论文章，旨在从数学上解释神经缩放律和训练动力学的内在机理。它没有提出任何与LLM智能体构建、改进或演化相关的核心方法论。因此，它与您关于“LLM智能体及其演化”的研究课题不相关，应予以排除。"
    },
    {
        "index": "#27",
        "title": "Metacognitive Sensitivity for Test-Time Dynamic Model Selection",
        "link": "/arxiv/2512.10451",
        "arxiv_id": "2512.10451",
        "authors": "Le Tuan Minh Trinh, Le Minh Vu Pham, Thi Minh Anh Pham, An Duc Nguyen",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.904070",
        "filter_reason": "这篇论文不符合你的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个**测试时动态模型选择框架**。它引入了一个心理学指标 `meta-d'` 来衡量模型的“元认知敏感性”（即模型的置信度在多大程度上能反映其准确性），并利用这个指标训练一个基于bandit算法的仲裁器，来动态决定在特定任务中应该信任哪个专家模型。 这篇论文的本质是**模型集成与选择**的优化方法，而不是构建、改进或演化一个具有自主性的LLM智能体。它研究的是如何更好地“使用”已有的模型，而不是如何让模型本身变得更“智能”或更“自主”。因此，根据第一步的排除标准，它属于“非演化型应用”，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中几乎没有出现你关注的核心范式和能力指标。 -   **Agentic AI / LLM-based Agents**: 论文没有构建一个能自主规划、使用工具或拥有记忆的智能体。它构建的是一个仲裁器，这是一个外部的调度模块，而非一个智能体本身。 -   **Multi-Agent Systems**: 论文涉及多个模型，但它们之间没有协作、通信或博弈。它们是被动等待被选择的“专家”，而不是主动交互的“智能体”。这是一个“主-从”结构，而非多智能体社会。 -   **Self-Evolving**: 论文中的模型本身不会通过经验进行自我完善或迭代。只有仲裁器在学习一个选择策略，但这属于系统层面的优化，而非智能体自身的演化。 -   **Self-Correction / Self-Reflection**: 这是论文最具有迷惑性的地方。虽然论文标题和摘要中提到了“Metacognition”（元认知），但其实现方式并非智能体的自我反思。它是一个**外部仲裁器**利用一个**静态的、预先计算好的元认知敏感性分数**来做决策。智能体本身不具备反思和修正自身行为的能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的主要贡献不涉及安全、对齐或多模态等排除项。但这一点并不足以让它被保留，因为它首先就没有通过核心判断。 4.  **第四步：处理特殊和模糊情况** -   **推理/规划**: 该论文不涉及智能体如何进行多步推理或规划。它关注的是在推理开始前，选择哪个模型去执行推理。 -   **自我演化的应用**: 论文的核心贡献是一种新的“模型选择机制”，而不是一种新的“自我演化机制”。因此，关于“自我演化应用”的例外保留规则不适用。 **最终决策**: 综合以上分析，这篇论文的核心是**模型选择**，而非**智能体构建或演化**。它研究的是如何更有效地调度一组已有的专家模型，这属于系统优化或集成学习的范畴，与你的研究焦点——即智能体本身的内在能力（如规划、记忆、工具使用）和演化机制（如自我完善、多智能体协作）——存在本质区别。因此，这篇论文应被排除。"
    },
    {
        "index": "#25",
        "title": "T-SKM-Net: Trainable Neural Network Framework for Linear Constraint Satisfaction via Sampling Kaczmarz-Motzkin Method",
        "link": "/arxiv/2512.10461",
        "arxiv_id": "2512.10461",
        "authors": "Haoyu Zhu, Yao Zhang, Jiashen Ren, Qingchun Hou",
        "subjects": "Machine Learning, Artificial Intelligence, Optimization and Control",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.902899",
        "filter_reason": "这篇论文不符合研究范围，应予以排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出一个名为T-SKM-Net的可训练神经网络框架，用于高效解决线性约束满足问题。它将一个经典的数学算法（Sampling Kaczmarz-Motzkin）与神经网络相结合，以解决电力系统优化、机器人路径规划等领域的特定问题。 根据筛选标准，这完全符合**“非演化型应用”**的排除类别。论文的重点是应用一个新框架去解决特定领域的数学优化问题，而不是构建、改进或演化一个具有自主性的LLM智能体。论文中的“神经网络”是作为求解器的一部分，而不是作为智能体的大脑。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的摘要和标题中完全没有出现任何正面指标关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的应用场景是“安全关键应用”，这与排除标准中的“安全”领域相关。虽然论文的主要贡献不是安全研究本身，但这表明其研究动机和评估基准都集中在工程应用和算法效率上，而非智能体的内在机制。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“推理”是指数学算法的迭代求解过程，而非智能体在复杂任务中的自主规划和多步决策。它属于“提高LLM本身基础Token预测的数学或逻辑能力”的排除范畴（尽管这里甚至不是LLM），因此应排除。 - **自我演化的应用**: 论文没有提出任何自我演化机制。T-SKM-Net是一个固定的、可训练的框架，不具备通过经验或反馈进行自我完善的能力。 **最终决策**: 该论文的研究方向是优化理论与神经网络的交叉领域，其核心目标是解决一类数学问题。它完全不涉及LLM智能体的构建、多智能体交互或自我演化机制。因此，它与研究课题“LLM智能体及其演化”的核心目标严重偏离，应被排除。"
    },
    {
        "index": "#30",
        "title": "Fitting magnetization data using continued fraction of straight lines",
        "link": "/arxiv/2512.10390",
        "arxiv_id": "2512.10390",
        "authors": "Vijay Prakash S",
        "subjects": "Machine Learning, Materials Science, Classical Physics",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.905810",
        "filter_reason": "这篇论文完全不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出一种新的数学方法——“直线的连分数”，用于拟合物理学中的磁化数据。其本质是应用数学和凝聚态物理的研究，旨在解决一个特定的科学建模问题。 - **是否符合要求**: 完全不符合。该论文没有涉及任何关于LLM、智能体、多智能体系统或自我演化的内容。它属于典型的“非演化型应用”，甚至没有使用LLM作为工具，而是纯粹提出了一种数学拟合技术。因此，在第一步就应该被直接排除。 2.  **第二步：正面指标** - 论文的标题和摘要中，完全没有出现任何与您研究焦点相关的关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步证实了它与您的研究方向无关。 3.  **第三步：排除标准** - 虽然这篇论文不涉及安全对齐或多模态等排除项，但它在第一步的核心判断中已经被明确排除，因为它根本不属于人工智能研究的范畴。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理、规划或自我演化机制，因此这些特殊情况不适用。 **最终决策**: 综合以上分析，这篇论文是一篇纯粹的物理学和应用数学研究，其核心贡献与“LLM智能体及其演化”这一课题毫无关联。因此，最终判断为 **False**，应予以排除。"
    },
    {
        "index": "#29",
        "title": "The Eminence in Shadow: Exploiting Feature Boundary Ambiguity for Robust Backdoor Attacks",
        "link": "/arxiv/2512.10402",
        "arxiv_id": "2512.10402",
        "authors": "Zhou Feng, Jiahao Chen, Chunyi Zhou, Yuwen Pu, Tianyu Du, Jinbao Li, Jianhai Chen, Shouling Ji",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.905248",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种名为 \"Eminence\" 的、具有理论保证的、鲁棒的黑盒后门攻击框架。其研究焦点是深度神经网络（DNNs）的安全漏洞，特别是如何利用特征边界的模糊性来实施高效的后门攻击。这与我的核心目标——**构建、改进或演化LLM智能体**——完全无关。该论文属于AI安全领域，而非Agentic AI领域。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文的核心主题是 \"Backdoor Attacks\"（后门攻击），这直接命中了**安全与对齐**的排除标准。我的研究明确排除了主要贡献在于 `Security`（安全）的论文。此外，摘要中提到的 \"explainable\"（可解释的）也与 `Interpretability`（可解释性）这一排除项相关。 3.  **正面指标缺失 (第二步):** 论文的标题和摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。这进一步证实了该论文与我的研究焦点不匹配。 综上所述，尽管这篇论文可能在AI安全领域具有重要的学术价值，但其研究对象（DNNs的后门攻击）、核心贡献（新的攻击框架）和研究领域（AI安全）均与我的研究课题 \"LLM智能体及其演化\" 背道而驰。因此，根据筛选标准，必须将其排除。"
    },
    {
        "index": "#34",
        "title": "A Privacy-Preserving Cloud Architecture for Distributed Machine Learning at Scale",
        "link": "/arxiv/2512.10341",
        "arxiv_id": "2512.10341",
        "authors": "Vinoth Punniyamoorthy, Ashok Gadi Parthi, Mayilsamy Palanigounder, Ravi Kiran Kodali, Bikesh Kumar, Kabilan Kannan",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.913248",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是基础设施与安全，而非智能体构建。** 论文的核心贡献是提出一个“云原生的隐私保护架构”，用于大规模分布式机器学习。其关键词是“架构”、“隐私保护”、“联邦学习”、“差分隐私”、“零知识证明”和“合规性”。这完全符合筛选标准中的“基础设施”和“安全与对齐”排除项。论文的重点在于如何安全、合规地部署和管理分布式学习系统，而不是构建一个具有自主规划、工具使用或演化能力的LLM智能体。 2.  **第二步：正面指标——论文完全不包含核心关注点。** 通读摘要，论文没有提及任何与您研究焦点相关的核心范式或能力。例如，`Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等关键词均未出现。这表明论文的研究方向与您的目标相去甚远。 3.  **第三步：排除标准——论文的主要贡献是安全与对齐。** 论文的标题和摘要反复强调“Privacy-Preserving”（隐私保护）、“verifiable compliance”（可验证的合规性）、“differential privacy”（差分隐私）、“membership-inference risk”（成员推断风险）等。根据您的筛选标准，只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Alignment` 等，就应一律排除。这篇论文是典型的系统安全与隐私研究，因此被明确排除。 4.  **第四步：处理特殊和模糊情况——不适用。** 论文中提到的“adaptive governance powered by reinforcement learning”（由强化学习驱动的自适应治理）听起来可能与智能体有关，但在此上下文中，它显然是作为整个架构中用于优化“治理策略”的一个组件，而不是一个具有自主性、规划或演化能力的智能体。它没有改变论文作为基础设施和安全研究的本质。 **最终决策：** 综合以上分析，该论文的核心贡献是构建一个用于分布式机器学习的隐私保护云架构，属于基础设施和安全研究领域。它完全没有涉及LLM智能体的构建、多智能体交互或自我演化机制。因此，这篇论文与您关于“LLM智能体及其演化”的研究课题完全不相关，应予以排除。"
    },
    {
        "index": "#35",
        "title": "An Interpretable AI Tool for SAVR vs TAVR in Low to Intermediate Risk Patients with Severe Aortic Stenosis",
        "link": "/arxiv/2512.10308",
        "arxiv_id": "2512.10308",
        "authors": "Vasiliki Stoumpou, Maciej Tysarowski, Talhat Azemi, Jawad Haider, Howard L. Haronian, Robert C. Hagberg, Dimitris Bertsimas",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.913743",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 论文的核心贡献是构建一个**可解释的AI决策工具**，用于在特定医疗场景（严重主动脉瓣狭窄患者的治疗方案选择）中提供治疗建议。其方法论是“预后匹配、反事实结果建模和最优策略树（OPT）”。 - **判断**: 这完全符合**排除标准1：非演化型应用**。该研究是将一个AI模型（且不是LLM智能体）作为工具应用在医疗领域，以解决该领域的特定问题。它没有提出任何关于构建、改进或演化LLM智能体的新方法论或框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - **关键排除点**: 论文的标题和摘要反复强调其核心特点是 **\"Interpretable\" (可解释的)** 和 **\"transparent\" (透明的)**。这直接触发了**排除标准中的“安全与对齐”**条款，即“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` (可解释性), `Explainability (XAI)`...一律排除”。这篇论文的主要卖点就是其可解释性，因此应被明确排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与LLM智能体相关的推理/规划或自我演化机制，因此无需进入特殊情况的讨论。 **最终决策**: 综合以上分析，该论文是一个专注于医疗决策支持的可解释性AI研究，其本质是特定领域的应用，且核心贡献是可解释性。它既不涉及LLM智能体的构建，也不涉及多智能体系统或自我演化机制。因此，它完全不符合您关于“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#37",
        "title": "R^2-HGP: A Double-Regularized Gaussian Process for Heterogeneous Transfer Learning",
        "link": "/arxiv/2512.10258",
        "arxiv_id": "2512.10258",
        "authors": "Duo Wang, Xinming Wang, Chao Wang, Xiaowei Yue, Jianguo Wu",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.914673",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种名为 `R^2-HGP` 的**双正则化高斯过程模型**，用于解决**异构迁移学习**问题。其本质是一种统计机器学习方法，而非构建、改进或演化LLM智能体的方法论。该论文完全属于“非演化型应用”的排除范畴，因为它提出了一种新的机器学习模型，并将其应用于工程领域，而不是研究智能体本身。 2.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现任何与我研究焦点相关的核心范式或能力关键词。例如，它没有提及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 或 `Collaboration` 等任何与Agentic AI相关的概念。 3.  **概念混淆澄清:** *   论文中的 \"Multi-output Gaussian process (MGP)\" 指的是一个模型能同时预测多个输出变量，这与研究多个自主智能体交互的 \"Multi-Agent Systems (MAS)\" 是完全不同的概念。 *   论文研究的 \"Transfer Learning\"（迁移学习）是指将一个任务学到的知识用于另一个相关任务，这与智能体通过经验、反思进行自我迭代和完善的 \"Self-Evolving\"（自我演化）机制有本质区别。 综上所述，该论文的研究领域是统计机器学习（高斯过程）和迁移学习，与我的核心目标“LLM智能体及其演化”毫无关联。因此，应予以排除。"
    },
    {
        "index": "#40",
        "title": "Exact Recovery of Non-Random Missing Multidimensional Time Series via Temporal Isometric Delay-Embedding Transform",
        "link": "/arxiv/2512.10191",
        "arxiv_id": "2512.10191",
        "authors": "Hao Shu, Jicheng Li, Yu Jin, Ling Zhou",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.921439",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 该论文的核心贡献是提出了一种名为“时间等距延迟嵌入变换”的数学方法，以及一个基于此的“LRTC-TIDT”模型，用于解决**多维时间序列中非随机缺失数据的精确恢复问题**。 - **判断**: 这篇论文属于典型的**非演化型应用**。它提出了一种新的数据处理算法，并将其应用于网络流量、城市交通等特定领域。论文的核心是数据恢复技术，而不是构建、改进或演化LLM智能体。全文未提及LLM、智能体框架或任何与Agentic AI相关的概念。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。其关键词是 `Time Series`, `Missing Data`, `Tensor Completion`，这与您的研究焦点完全无关。 3.  **第三步：排除标准** - 虽然该论文不涉及安全、对齐或多模态等排除项，但它触发了最根本的第一步排除规则：它不是关于智能体的研究。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此无需进入特殊情况的讨论。 **最终决策**: 综合以上分析，这篇论文是一篇专注于时间序列数据挖掘和信号处理的论文，其核心贡献是一种数学变换和模型，用于数据补全。它与您的研究课题“LLM智能体及其演化”在研究对象、核心贡献和技术路线上均无交集。因此，应予以排除。"
    },
    {
        "index": "#39",
        "title": "Federated Domain Generalization with Latent Space Inversion",
        "link": "/arxiv/2512.10224",
        "arxiv_id": "2512.10224",
        "authors": "Ragja Palakkadavath, Hung Le, Thanh Nguyen-Tang, Svetha Venkatesh, Sunil Gupta",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.915777",
        "filter_reason": "这篇论文不符合您的研究范围，我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种新的**联邦学习**方法，用于解决**域泛化**问题。具体来说，它通过“latent space inversion”技术来增强本地训练的隐私性，并通过“important weight”策略来优化非独立同分布客户端的模型聚合。这本质上是一种**分布式机器学习的基础设施/算法优化**研究，其目标是提升模型在跨域数据上的泛化能力和保护数据隐私，而不是构建、改进或演化一个具有自主性的LLM智能体。因此，根据第一步的排除标准（基础设施），应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与您研究焦点相关的核心范式或能力关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文中的“客户端”是联邦学习框架中的计算节点，而非具有自主行为、协作或演化能力的智能体。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这篇论文虽然不直接涉及安全对齐或多模态等排除项，但其核心研究领域（联邦学习）已经超出了您设定的“LLM智能体及其演化”的范畴。 4.  **第四步：处理特殊和模糊情况** 论文不涉及智能体的规划推理，也没有提出任何自我演化机制。其模型性能的提升来自于一个外部设计的、更优化的聚合算法，而非智能体通过经验、反思或环境反馈进行的自我完善。 **最终决策**： 综合以上分析，该论文的研究问题是联邦学习中的模型聚合与域泛化，其贡献在于分布式训练算法的改进。这与您“构建、改进或演化LLM智能体”的核心目标存在根本性的偏离。因此，这篇论文应被**排除**。"
    },
    {
        "index": "#38",
        "title": "Adaptive Information Routing for Multimodal Time Series Forecasting",
        "link": "/arxiv/2512.10229",
        "arxiv_id": "2512.10229",
        "authors": "Jun Seo, Hyeokjun Choe, Seohui Bae, Soyeon Park, Wonbin Ahn, Taeyoon Lim, Junhyuk Kang, Sangjun Han, Jaehoon Lee, Dongwan Kang, Minjae Kim, Sungdong Yoo, Soonyoung Lee",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.915264",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。核心依据如下： 1.  **核心判断（第一步）：论文的本质是“非演化型应用”** 论文的核心贡献是提出了一个名为“自适应信息路由（AIR）”的框架，用于解决**多模态时间序列预测**这一特定领域的问题。其目标是提高预测的准确性。虽然论文中使用了大型语言模型（LLM），但LLM的角色是作为一个**数据预处理的工具**（“文本精炼管道”），将原始文本转换为更适合预测模型的格式。这完全符合筛选标准中“非演化型应用”的排除规则：**将LLM作为工具应用到特定领域（这里是金融/时间序列预测）去解决该领域的问题**。论文的核心是改进预测模型，而不是构建、改进或演化LLM智能体本身。 2.  **缺乏核心关注点（第二步）** 论文的研究内容与您关注的核心范式和能力完全无关。摘要中没有提及任何与 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`（智能体自主使用工具）、`Memory`、`Self-Reflection` 等相关的概念。LLM在这里是被动的、被调用的组件，而不是一个具有自主性的智能体。 3.  **不符合特殊情况的保留条件（第四步）** 论文虽然使用了LLM，但并未提出任何新的“自我演化”机制。LLM的使用是静态的、功能性的（数据转换），而不是一个能够通过经验、反思或环境反馈进行自我完善和迭代的智能体。因此，它不满足“自我演化的应用”这一例外保留条件。 **总结**：该论文的研究焦点是**时间序列预测模型**的创新，LLM仅作为辅助工具出现。您的研究焦点是**Agentic AI**本身，即智能体的架构、能力和演化机制。二者在核心贡献和研究目标上存在根本差异。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#42",
        "title": "Assessing Neuromorphic Computing for Fingertip Force Decoding from Electromyography",
        "link": "/arxiv/2512.10179",
        "arxiv_id": "2512.10179",
        "authors": "Abolfazl Shahrooei, Luke Arthur, Om Patel, Derek Kamper",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.922419",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是**评估一种特定的神经网络架构（脉冲神经网络 SNN）在特定生物医学任务（从肌电信号解码指尖力）中的性能**。这是一个典型的**非演化型应用**研究。它将一种计算模型（SNN）作为工具，应用于生物医学和康复工程领域，以解决该领域的信号解码问题。它完全没有涉及构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与您研究焦点相关的正面指标。它不涉及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。其研究内容也与 `Planning`、`Tool Use`、`Memory`、`Collaboration` 等智能体核心能力无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不直接触及安全与对齐或多模态等排除标准，但它在第一步的核心判断中已经被明确排除。它的研究主题是神经形态计算和生物信号处理，这与您的“LLM智能体及其演化”课题存在根本性的领域差异。 4.  **第四步：处理特殊和模糊情况** 此论文不涉及任何需要特殊处理的情况。它既不是关于智能体的推理/规划框架，也没有提出任何“自我演化”机制。 **最终决策**：综合以上分析，该论文是一篇关于神经形态计算在生物医学工程领域应用的评估研究。其核心贡献与“构建、改进或演化LLM智能体”这一目标完全无关。因此，它被严格排除在您的筛选范围之外。"
    },
    {
        "index": "#41",
        "title": "MiniF2F-Dafny: LLM-Guided Mathematical Theorem Proving via Auto-Active Verification",
        "link": "/arxiv/2512.10187",
        "arxiv_id": "2512.10187",
        "authors": "Mantas Baksys, Stefan Zetzsche, Olivier Bouissou",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.921952",
        "filter_reason": "这篇论文的核心贡献是创建了一个新的数学定理证明基准（miniF2F-Dafny），并评估了现有LLM在该基准上提供证明提示的能力。根据您的筛选标准，这篇论文应被排除。 1.  **第一步：核心判断——本质是“非演化型应用”** 论文的核心并非提出一个全新的、可泛化的LLM智能体构建或演化框架。它的主要工作是： *   **构建基准**: 将一个已有的数学数据集翻译到一个新的工具上，这是一个资源贡献，而非方法论贡献。 *   **评估现有模型**: 使用“现成的”LLM来解决特定领域（数学定理证明）的问题。 这完全符合您在第一步中定义的排除标准：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题...”。这里，LLM和Dafny定理证明器被组合起来，用于解决数学问题，而不是为了构建一个通用的智能体。 2.  **第二步与第四步：正面指标与特殊情况的分析** 尽管摘要中提到了“迭代错误纠正”和“LLM提供高层指导，自动化处理底层细节”，这些看似与`Self-Correction`和`Tool Use`相关。但是，这些元素在论文中扮演的是**被评估的技术**，而不是**被提出的核心创新**。论文的重点是“我们用这种方法在基准上取得了什么效果”，而不是“我们提出了一种新的智能体自我演化机制”。根据第四步的特殊规则，这并非提出一种新的“自我演化”机制，而是一种在特定任务中应用的、已有的提示技巧，因此不满足保留的例外条件。 3.  **结论** 综上所述，该论文的研究焦点是**应用**LLM解决特定领域的推理任务，并为此创建评估基准，而不是**构建、改进或演化LLM智能体本身**。其核心贡献在于基准构建和模型评估，这属于应用研究范畴，与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标不符。因此，应予以排除。"
    },
    {
        "index": "#24",
        "title": "UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning",
        "link": "/arxiv/2512.10492",
        "arxiv_id": "2512.10492",
        "authors": "Jiaxi Wu, Tiantian Zhang, Yuxing Wang, Yongzhe Chang, Xueqian Wang",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.902292",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是强化学习算法，而非LLM智能体。** *   论文的核心贡献是提出了一种名为“UACER”的**鲁棒对抗强化学习训练框架**。其核心创新点在于通过“多样化的评论家集成”和“时变衰减不确定性机制”来稳定训练过程、提升Q值估计的鲁棒性。 *   整篇论文的摘要和标题都聚焦于**强化学习**，特别是对抗性强化学习。它完全没有提及“LLM”、“Large Language Model”或任何与语言模型相关的内容。 *   根据筛选标准，我的核心目标是筛选关于“构建、改进或演化 **LLM智能体**”的论文。这篇论文研究的是如何训练一个传统的强化学习智能体，而非基于LLM的智能体。因此，它在第一步的核心判断中就被排除。 2.  **不符合核心关注点（第二步）：缺乏关键正面指标。** *   论文中没有出现任何我关注的核心范式，如 `Agentic AI`, `LLM-based Agents`, `Self-Evolving` 等。 *   它研究的智能体能力是强化学习中的策略学习和Q值估计，而非我关注的 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等LLM智能体的核心能力。 *   虽然提到了“protagonist and an adversary”（主角和对手），但这属于对抗性强化学习的设定，其研究重点是训练过程的稳定性，而非我关注的多智能体间的 `Collaboration`, `Communication`, `Social Learning` 等交互行为。 3.  **属于排除范畴（第一步和第四步）：非演化型应用。** *   论文明确指出其应用领域是“autonomous driving and robotic control”（自动驾驶和机器人控制），并在“MuJoCo control problems”上进行了验证。 *   这完全符合第一步排除标准中的“**非演化型应用**”：将一个已有的技术框架（对抗性强化学习）应用到特定领域（机器人控制）去解决该领域的问题。论文的核心是改进训练算法本身，而不是提出一种新的智能体架构或演化机制。 **总结：** 尽管论文标题中包含“Agent”一词，但它指的是传统强化学习中的智能体，而非我研究课题所聚焦的“LLM智能体”。论文的核心贡献是强化学习算法层面的创新，旨在提升训练的稳定性和鲁棒性，这与我寻找的关于LLM智能体的构建、协作和自我演化的研究目标存在根本性的偏差。因此，该论文应被排除。"
    },
    {
        "index": "#44",
        "title": "Rethinking Causal Discovery Through the Lens of Exchangeability",
        "link": "/arxiv/2512.10152",
        "arxiv_id": "2512.10152",
        "authors": "Tiago Brogueira, Mário Figueiredo",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.923302",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 论文的核心贡献是**重新审视因果发现**这一机器学习基础领域。它主张用“可交换性”这一更普适的统计学原理来替代传统的“独立同分布”假设，并基于此提出了一个新的合成数据集和一个用于因果发现的神经网络算法。 - 这篇论文的本质是**对一种机器学习方法论的改进**，而不是构建、改进或演化LLM智能体。它完全不属于“构建LLM智能体”、“多智能体系统”或“自我演化”的范畴。 - 根据筛选标准，这属于**排除**项中的“非Agentic的推理”：论文旨在提高模型在特定任务（因果发现）上的能力，但其方法不涉及智能体的自主规划、工具使用或自我演化框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。 - 缺乏这些正面指标，进一步确认了该论文与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全对齐或多模态等排除领域，但第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文确实涉及“推理”（因果推理），但它属于被排除的情况。它研究的是如何改进一个模型完成特定推理任务（因果发现）的方法，而不是研究一个智能体如何进行多步规划和决策。这与ReAct、ToT等Agentic框架有本质区别。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**因果发现理论和方法论的改进**，而非LLM智能体的构建或演化。它是一篇典型的机器学习理论/方法论文，与您关于“LLM智能体及其演化”的研究课题没有直接关联。因此，应予以排除。"
    },
    {
        "index": "#45",
        "title": "Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences",
        "link": "/arxiv/2512.10147",
        "arxiv_id": "2512.10147",
        "authors": "Sarwan Ali, Taslim Murad",
        "subjects": "Machine Learning, Genomics",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.923759",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 `Murmur2Vec` 的**新型哈希嵌入方法**，用于高效地生成COVID-19病毒刺突蛋白序列的低维表示。其本质是**生物信息学领域的一种算法创新**，旨在解决大规模病毒序列分析的效率和性能问题。 这完全不符合我筛选标准中的“保留”条件。论文的核心既不是构建LLM智能体，也不是关于多智能体系统或自我演化框架。它属于典型的**“非演化型应用”**，即将一种新的计算方法（嵌入生成）应用于特定领域（生物学）来解决该领域的问题（病毒谱系分类）。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文讨论的是 `Embedding`, `Hashing`, `Classification`，这些都与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文不涉及安全对齐或多模态等排除项，但第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** 此论文情况非常明确，不涉及任何需要特殊处理的模糊情况。它既不是关于智能体的推理/规划，也没有提出任何“自我演化”机制。 **最终决策**: 综合以上分析，这篇论文的核心贡献是生物序列处理领域的一种新嵌入技术，与“LLM智能体及其演化”这一课题毫无关联。它没有构建、改进或演化任何形式的智能体，而是将一种算法应用于特定科学问题。因此，必须排除。"
    },
    {
        "index": "#48",
        "title": "CHyLL: Learning Continuous Neural Representations of Hybrid Systems",
        "link": "/arxiv/2512.10117",
        "arxiv_id": "2512.10117",
        "authors": "Sangli Teng, Hang Liu, Jingyu Song, Koushil Sreenath",
        "subjects": "Machine Learning, Artificial Intelligence, Robotics, Signal Processing, Systems and Control",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.925347",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了一种名为CHyLL的新方法，用于学习**混合系统**的**连续神经表示**。混合系统是同时具有连续和离散动态的系统（例如一个弹跳的球）。论文的重点在于解决这类系统建模中的数学挑战（如模式切换和不连续性），通过微分拓扑的理论，将系统状态空间重构为一个流形，从而学习一个更平滑、更准确的动态模型。这本质上是一篇关于**动态系统建模**和**神经表示学习**的论文，而非关于构建或演化LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您关注的核心范式和能力。它不涉及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等任何核心概念。其能力焦点在于`flow prediction`（流预测）和`topological invariants identification`（拓扑不变量识别），这些都是系统建模领域的术语，与智能体的`Planning`, `Tool Use`, `Memory`, `Collaboration`等能力无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文不属于明确排除的“安全与对齐”或“多模态与视觉”类别，但它属于一个更根本的排除类别：**非Agentic的基础模型研究**。它研究的是如何用神经网络更好地表示一类数学系统，这与研究如何让一个基于LLM的智能体变得更自主、更智能是两个完全不同的研究方向。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的应用场景之一是“随机最优控制”。虽然“控制”与智能体的“行动”相关，但这里的“控制”是指基于一个精确的系统模型来计算最优输入，而不是一个智能体在不确定环境中进行自主规划和决策。因此，这不属于您关注的Agentic框架下的规划。 - **自我演化的应用**: 论文没有提出任何自我演化机制。它提出的是一个静态的建模方法，学习一个系统的表示。这不适用例外规则。 **最终决策**: 该论文的核心贡献是针对混合系统的一种新颖的神经表示学习方法，属于动态系统和控制理论领域。它与您的研究课题“LLM智能体及其演化”在研究对象、核心贡献和技术路线上均无交集。因此，应予以**排除**。"
    },
    {
        "index": "#36",
        "title": "A Kernel-based Resource-efficient Neural Surrogate for Multi-fidelity Prediction of Aerodynamic Field",
        "link": "/arxiv/2512.10287",
        "arxiv_id": "2512.10287",
        "authors": "Apurba Sarker, Reza T. Batley, Darshan Sarojini, Sourav Saha",
        "subjects": "Machine Learning, Fluid Dynamics",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.914199",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为KHRONOS的新型、基于核函数的神经网络代理模型，用于在资源受限条件下高效预测空气动力学场。这本质上是一种**新的模型架构**，旨在解决特定科学领域（计算流体力学/空气动力学）的仿真优化问题。它完全不属于构建、改进或演化LLM智能体的范畴。根据筛选标准，这应被归类为“非演化型应用”，因为它是一个应用于特定领域的工具，而非一个智能体框架。 2.  **第二步：正面指标** 论文的标题和摘要中，完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这表明论文的研究内容与您的核心关注点（单智能体、多智能体、自我演化）没有交集。 3.  **第三步：排除标准** 虽然论文没有直接触及安全与对齐或多模态等排除项，但其研究主题——空气动力学场的代理模型——本身就在您的研究焦点之外。 4.  **第四步：处理特殊和模糊情况** 论文不涉及任何智能体的规划或推理过程，它是一个用于预测的静态模型，而非一个能够自主决策和行动的智能体。同时，论文也未提出任何“自我演化”机制，KHRONOS模型本身不会通过经验或反馈进行自我完善和迭代，因此“自我演化的应用”这一例外情况也不适用。 **最终决策**：该论文的研究重点是计算科学和高效神经网络架构设计，与“LLM智能体及其演化”这一课题有本质区别。其核心贡献是模型本身，而非智能体的能力或框架。因此，应予以排除。"
    },
    {
        "index": "#53",
        "title": "Detailed balance in large language model-driven agents",
        "link": "/arxiv/2512.10047",
        "arxiv_id": "2512.10047",
        "authors": "Zhuo-Yang Song, Qing-Hong Cao, Ming-xing Luo, Hua Xing Zhu",
        "subjects": "Machine Learning, Statistical Mechanics, Artificial Intelligence, Adaptation and Self-Organizing Systems, Data Analysis, Statistics and Probability",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.933153",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是**理论分析**而非**构建或改进**。摘要明确指出，本文旨在“建立一个理论框架来理解和统一LLM智能体的宏观动力学”，并“将AI智能体的研究从一系列工程实践提升为一门建立在有效测量之上的科学”。这表明论文的重点是**理解和解释**现有LLM智能体的行为模式（发现“detailed balance”这一物理规律），而不是提出一种新的智能体架构、规划方法、工具使用机制或自我演化算法。我的核心目标是筛选关于**构建、改进或演化**智能体的方法论论文，而这篇论文属于对智能体系统的**科学分析**，而非工程构建。 2.  **正面指标（第二步）：** 尽管论文标题和摘要中提到了“LLM-driven agents”，但它并未包含我所关注的核心能力指标。文中没有讨论`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Collaboration`或`Self-Improvement`等具体智能体能力的实现或增强。它的焦点是底层的生成动力学，这是一个更基础、更理论化的层面。 3.  **排除标准（第三步）：** 该论文不涉及安全、对齐或多模态等明确的排除领域，但其本质与我的研究目标存在根本性差异。 4.  **最终决策（第五步）：** 综合来看，这篇论文的学术价值在于为LLM智能体系统提供了宏观动力学层面的理论解释，这是一个重要的基础研究方向。然而，我的研究课题聚焦于Agentic AI的**工程实践和方法论创新**，即如何让智能体变得更“智能”、更“自主”、更“会演化”。该论文并未提供任何新的智能体构建或演化框架，因此，它严格地落在了我的筛选范围之外。它回答的是“智能体内部是如何运作的？”这个问题，而我的研究关注的是“如何构建一个更好的智能体？”。"
    },
    {
        "index": "#50",
        "title": "\\textsc{Text2Graph}: Combining Lightweight LLMs and GNNs for Efficient Text Classification in Label-Scarce Scenarios",
        "link": "/arxiv/2512.10061",
        "arxiv_id": "2512.10061",
        "authors": "João Lucas Luz Lima Sarcinelli, Ricardo Marcondes Marcacini",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.926384",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文的核心贡献**: 论文提出了一个名为 `\\textsc{Text2Graph}` 的框架，其核心目标是解决**文本分类**任务，特别是在标签稀缺的场景下，通过结合轻量级LLM和图神经网络（GNN）来提高效率和降低能耗。 - **判断**: 这完全符合**排除标准 #1: 非演化型应用**。该论文将LLM作为一个组件（用于“部分标注”）与GNN（用于“标签传播”）结合，构建了一个解决特定领域问题（文本分类）的流程。它并没有提出新的LLM智能体架构、改进智能体的核心能力（如规划、记忆），也没有涉及智能体的自我演化机制。LLM在这里被用作一个高级的特征提取器或标注工具，而不是一个自主的、具有规划能力的智能体。 2.  **第二步：正面指标** - 论文中没有出现任何我关注的核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。虽然提到了LLM，但其使用方式是工具性的，而非智能体框架的核心。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐或多模态等排除领域，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。它关注的是分类任务的流程优化，而非智能体的决策过程。 - **自我演化的应用**: 论文没有提出任何自我演化机制。其流程是静态的：LLM标注 -> GNN传播，不存在迭代、自我完善或通过环境反馈进行学习的环节。 **最终决策**: 综合以上分析，该论文的本质是应用LLM和GNN技术解决一个具体的NLP任务（文本分类），其核心贡献在于提升该任务的效率和可持续性。这与我研究“LLM智能体及其演化”的核心目标——即构建、改进或演化智能体本身的方法论——完全不符。因此，应予以排除。"
    },
    {
        "index": "#46",
        "title": "Sequence-to-Image Transformation for Sequence Classification Using Rips Complex Construction and Chaos Game Representation",
        "link": "/arxiv/2512.10141",
        "arxiv_id": "2512.10141",
        "authors": "Sarwan Ali, Taslim Murad, Imdadullah Khan",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.924194",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是提出了一种**新的数据表示方法**。它将分子序列通过“混沌博弈表示”和“Rips复形构造”这两种数学/拓扑学技术，转换成图像，以便更好地利用视觉模型进行分类。 - **是否符合要求**: 这完全符合第一步中的**排除标准1：“非演化型应用”**。论文的本质是将一种新颖的数学工具（拓扑学）应用于特定领域（分子生物学/生物信息学）来解决该领域的特定问题（序列分类）。它没有构建、改进或演化任何形式的LLM智能体。论文中完全没有提及LLM、智能体框架或任何自主行为。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文提到了“vision-based deep learning architectures”（基于视觉的深度学习架构），这触及了**“多模态与视觉”**的排除标准。根据规则，除非视觉是智能体感知环境的工具，否则应排除。在此论文中，视觉模型是最终任务的执行者（分类器），而不是一个智能体框架的组成部分。研究的核心是数据转换，而非智能体的感知或行动。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它是一个纯粹的应用型方法论文。 **最终决策**: 综合以上分析，该论文的核心是提出一种用于生物序列分类的拓扑数据表示方法，属于典型的将技术应用于特定垂直领域的“非演化型应用”。它没有涉及LLM智能体的构建、规划、工具使用、多智能体协作或自我演化等任何核心研究目标。因此，必须排除。"
    },
    {
        "index": "#47",
        "title": "Partitioning the Sample Space for a More Precise Shannon Entropy Estimation",
        "link": "/arxiv/2512.10133",
        "arxiv_id": "2512.10133",
        "authors": "Gabriel F. A. Bastos, Jugurta Montalvão",
        "subjects": "Machine Learning, Statistics Theory",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.924628",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是提出了一种新的统计学方法，用于在数据样本量较小的情况下更精确地估计香农熵。其技术细节涉及“样本空间划分”、“缺失质量估计”和“未见结果数量估计”，这些都是信息论和统计学领域的经典问题。 - **与目标匹配度**: 该研究的本质是**基础统计方法的改进**，与“构建、改进或演化LLM智能体”这一核心目标完全无关。它没有涉及任何智能体框架、自主行为或演化机制。 - **结论**: 根据第一步的排除标准，该论文属于“非Agentic的推理”范畴，因为它旨在改进一个基础的数学/统计能力（熵估计），而不是在智能体框架内实现规划、工具使用或自我演化。因此，应直接**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文标题和摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全对齐或多模态等排除领域，但这并不改变其核心内容与您研究目标不符的事实。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何特殊情况。它既不是关于智能体的规划，也不是关于自我演化的应用。 **最终决策**: 综合以上分析，这篇论文是一篇纯粹的统计学/信息论研究，其目标是改进香农熵的估计方法。它完全没有触及LLM智能体的构建、多智能体系统或自我演化机制。因此，它完全不符合您为“LLM智能体及其演化”课题设定的筛选标准。"
    },
    {
        "index": "#49",
        "title": "MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis",
        "link": "/arxiv/2512.10098",
        "arxiv_id": "2512.10098",
        "authors": "Midhat Urooj, Ayan Banerjee, Farhat Shaikh, Kuntal Thakur, Sandeep Gupta",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.925945",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是非演化型应用。** 论文的核心贡献是提出一个名为 \"MedXAI\" 的框架，用于解决**医学图像分析**领域的特定问题。它通过结合深度视觉模型和专家知识，来提升医学图像诊断的准确性和可解释性。这完全符合“将一个已有的框架（或新构建的特定领域框架）作为工具应用到特定领域（医疗）去解决该领域的问题”的排除标准。其研究焦点是医学AI，而非通用的LLM智能体构建或演化方法论。 2.  **排除标准 (第三步): 论文命中了两个关键的排除类别。** *   **安全与对齐:** 论文的标题和摘要反复强调其核心贡献是提供一个“可解释的框架”和“人类可理解的解释”。这直接命中了 `Interpretability` (XAI) 这一排除标准。论文的主要目标之一就是解决模型在安全关键环境中的透明度问题，这正是对齐研究的范畴。 *   **多模态与视觉:** 论文的研究核心是“医学图像分析”，明确处理了fMRI和视网膜图像等视觉数据。其技术核心是“深度视觉模型”，视觉处理是研究的主体，而不是作为智能体感知环境的辅助工具。这完全符合多模态与视觉的排除标准。 3.  **正面指标 (第二步): 论文缺乏核心关注点。** 摘要中完全没有出现您关注的核心范式（如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`）或智能体核心能力（如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`）。虽然标题中有 \"Self-Verifying\"，但根据摘要描述，这更像是一个利用符号化知识进行验证的静态步骤，而非智能体自主的、迭代的自我反思或演化机制。 **总结:** 尽管 \"Retrieval-Augmented\" 和 \"Self-Verifying\" 等术语可能与智能体技术有表面关联，但该论文的本质是**一个专注于医学视觉领域的可解释性AI (XAI) 研究**。它的核心贡献在于提升特定任务（医学图像分类）的性能和可解释性，而不是构建、改进或演化一个具有自主规划、工具使用或自我演化能力的LLM智能体。因此，它与您关于 \"LLM智能体及其演化\" 的研究目标严重不符。"
    },
    {
        "index": "#52",
        "title": "DB2-TransF: All You Need Is Learnable Daubechies Wavelets for Time Series Forecasting",
        "link": "/arxiv/2512.10051",
        "arxiv_id": "2512.10051",
        "authors": "Moulik Gupta, Achyut Mani Tripathi",
        "subjects": "Machine Learning, Artificial Intelligence, Signal Processing",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.932478",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 论文的核心贡献是提出了一种名为 `DB2-TransF` 的新型神经网络架构，用于解决时间序列预测问题。其创新点在于用“可学习的Daubechies小波层”替换了Transformer中的自注意力机制，以降低计算复杂度并提高预测效率。 - **是否符合保留标准**: 不符合。这篇论文的本质是**模型架构的创新**，并将其应用于一个**特定领域**（时间序列预测）。它没有涉及构建、改进或演化LLM智能体。 - **是否符合排除标准**: 符合。这完全属于**“非演化型应用”**。论文将一个新颖的模型（DB2-TransF）作为工具应用到时间序列预测领域，以解决该领域的效率和精度问题，其研究焦点是预测模型本身，而非智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究课题无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文没有触及安全对齐或多模态等排除标准，但第一步的“非演化型应用”排除标准已经足够有力，无需进一步考虑此步。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文讨论的是时间序列预测，这是一种序列建模任务，而非智能体的自主规划或多步推理框架。它不属于“保留”范畴。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。它只是提出了一个静态的、经过改进的模型架构。因此，例外情况不适用。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心是针对时间序列预测任务的模型架构优化，属于典型的应用型研究。它完全没有涉及LLM智能体的构建、多智能体系统或自我演化机制。因此，它与我的研究目标“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#51",
        "title": "Mitigating Exposure Bias in Risk-Aware Time Series Forecasting with Soft Tokens",
        "link": "/arxiv/2512.10056",
        "arxiv_id": "2512.10056",
        "authors": "Alireza Namazi, Amirreza Dolatpour Fathkouhi, Heman Shakeri",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.932023",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 论文的核心贡献是提出了一种名为 \"SoTra\" 的新方法，用于解决时间序列预测中的 \"exposure bias\"（暴露偏差）问题。该方法通过传播 \"soft tokens\"（软令牌）来生成更稳定、更符合风险感知的预测轨迹。 - 这完全符合**排除标准 #1: 非演化型应用**。该论文将一个新颖的预测模型应用到了特定的领域（医疗领域的糖尿病和血流动力学管理），以解决该领域的技术问题（预测不稳定性）。它并没有构建、改进或演化一个具有自主规划、工具使用或反思能力的LLM智能体。其本质是预测模型方法的创新，而非智能体框架的创新。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何核心关注点的关键词或概念，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。该模型是一个预测器，不具备任何智能体的特征。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文提到了 \"risk-aware\"（风险感知）和 \"safety-critical\"（安全关键），但其主要贡献是预测技术，而非AI安全、对齐或可解释性理论。因此，它不直接属于“安全与对齐”的排除范畴，但这并不改变其作为“非演化型应用”的根本性质。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何特殊情况。它既不是关于智能体的推理/规划框架，也没有提出任何“自我演化”机制。 **最终决策**: 这篇论文的核心是改进时间序列预测模型，并将其应用于医疗领域。它不属于LLM智能体的构建、多智能体系统或自我演化的研究范畴。因此，它应被排除。"
    },
    {
        "index": "#55",
        "title": "SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation",
        "link": "/arxiv/2512.10042",
        "arxiv_id": "2512.10042",
        "authors": "Jongmin Lee, Meiqi Sun, Pieter Abbeel",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.934018",
        "filter_reason": "这篇论文不符合我的研究范围，核心原因在于其研究对象是**强化学习（RL）智能体**，而非**基于大语言模型的智能体（LLM-based Agents）**。 我的判断过程如下： 1.  **第一步：核心判断** - 论文的核心贡献是提出了一种名为 **SEMDICE** 的**强化学习算法**，用于在无监督预训练中最大化状态熵。其目标是学习一个通用的策略，以便在下游任务中快速适应。 - 这篇论文的本质是**强化学习算法的创新**，而不是构建、改进或演化LLM智能体的方法论或框架。论文中完全没有提及LLM、语言模型或任何与自然语言处理相关的技术。 - 因此，它没有通过第一步的“保留”标准。它不属于“构建LLM智能体”、“多智能体系统”或“自我演化”的范畴，而是属于经典的强化学习研究。 2.  **第二步：正面指标** - 论文中没有出现任何我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`。 - 虽然提到了“agent”和“policy”，但这是在RL的语境下，指的是一个学习策略以与环境交互的实体，不具备我所关注的 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等LLM智能体的核心认知能力。 - 因此，该论文不满足任何正面指标。 3.  **第三步：排除标准** - 论文不涉及安全、对齐或多模态等排除领域，但第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** - 论文讨论的“pre-training”和“adaptation”虽然听起来有点像“演化”，但其机制是基于状态熵最大化的RL算法，这与我所定义的“智能体通过经验、反思或环境反馈进行自我完善和迭代”的自我演化机制有本质区别。它不是智能体主动的自我迭代，而是一种被动的策略学习过程。 **最终决策**: 这篇论文是一篇关于强化学习算法的扎实研究，但它与我的研究课题“LLM智能体及其演化”完全脱节。我的研究焦点是**以LLM为核心大脑的智能体**，而该论文研究的是**传统的、非语言模型的RL智能体**。因此，尽管标题和摘要中出现了“agent”一词，但其内涵与我的研究目标不符，应予以排除。"
    },
    {
        "index": "#57",
        "title": "Robust Gradient Descent via Heavy-Ball Momentum with Predictive Extrapolation",
        "link": "/arxiv/2512.10033",
        "arxiv_id": "2512.10033",
        "authors": "Sarwan Ali",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.934887",
        "filter_reason": "这篇论文的核心贡献是提出了一种新的优化算法——HB-SGE（Heavy-Ball Synthetic Gradient Extrapolation），旨在改进梯度下降的鲁棒性和收敛速度。这属于机器学习的基础优化方法研究。 根据筛选标准的第一步“核心判断”，这篇论文的本质并非关于构建、改进或演化LLM智能体。它没有提出任何关于智能体规划、记忆、工具使用、多智能体协作或自我演化的方法论或框架。相反，它属于“非Agentic的推理”或更基础的“模型基础设施”（算法层面）的研究范畴。其焦点在于优化模型训练的数学过程，而非智能体在任务执行中的行为和能力。 在第二步“正面指标”中，论文摘要完全不包含 `Agentic AI`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use` 等任何核心关键词。第三步和第四步的特殊情况也不适用。 综上所述，尽管该研究可能在训练更强大的LLM方面有潜在价值，但其直接贡献是优化算法，而非智能体本身，因此严格不符合您关于“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#58",
        "title": "Cluster-Dags as Powerful Background Knowledge For Causal Discovery",
        "link": "/arxiv/2512.10032",
        "arxiv_id": "2512.10032",
        "authors": "Jan Marco Ruiz de Vargas, Kirtan Padh, Niki Kilbertus",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.935351",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出一种名为“Cluster-DAGs”的先验知识框架，并基于此改进了两种因果发现算法（Cluster-PC 和 Cluster-FCI）。其研究焦点是**因果推断**领域，旨在从数据中更有效地发现因果关系。 - **与核心目标的匹配度**: 您的核心目标是“构建、改进或演化 LLM智能体”。该论文完全没有涉及LLM或智能体的构建、规划、工具使用、记忆、自我演化等任何Agentic AI的核心概念。它属于典型的**非Agentic的推理**研究，专注于改进一个特定的机器学习算法（因果发现），而不是构建一个能够自主执行任务的智能体框架。因此，根据第一步的排除标准，应直接排除。 2.  **第二步：正面指标** - 论文的标题和摘要中，完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准** - 虽然该论文不涉及安全对齐或多模态等排除项，但这并不改变其核心内容与您研究目标不符的事实。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文确实涉及“推理”（因果推理），但它属于被排除的类别：“只是关于提高LLM本身基础Token预测的数学或逻辑能力”的范畴。尽管它不直接针对LLM，但其本质是改进一个底层的推理算法，而非构建一个在复杂任务中进行多步规划的智能体框架（如ReAct或ToT）。 **最终决策**: 该论文是一篇纯粹的因果推断领域的算法研究论文。其核心贡献是改进因果发现算法，而非构建、改进或演化LLM智能体。它与您的研究课题“LLM智能体及其演化”在研究对象、核心贡献和技术路线上均存在根本性差异。因此，最终判断为 **False**。"
    },
    {
        "index": "#54",
        "title": "Local LLM Ensembles for Zero-shot Portuguese Named Entity Recognition",
        "link": "/arxiv/2512.10043",
        "arxiv_id": "2512.10043",
        "authors": "João Lucas Luz Lima Sarcinelli, Diego Furtado Silva",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.933581",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种**用于零样本命名实体识别（NER）的本地LLM集成流水线**。它研究的是如何组合多个LLM的输出来提升在特定NLP任务（葡萄牙语NER）上的性能。这本质上是一种**模型集成方法**的应用，而不是构建、改进或演化一个具有自主性的LLM智能体。 根据筛选标准，这完全符合**排除项 1: 非演化型应用**。该论文将LLM（以及一种新的集成方法）作为工具，应用于特定领域（自然语言处理中的NER任务），其目标是解决该领域的问题，而非探索智能体本身的能力或演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现您关注的核心范式和能力关键词。例如： *   `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式均未提及。 *   `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等智能体能力也未涉及。 *   论文中的 \"Ensemble\" 指的是模型层面的集成，而非智能体之间的 `Collaboration` 或 `Communication`。 缺乏任何正面指标，进一步确认了该论文与您的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够有力，无需深入此步。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文研究的NER任务本身包含推理成分，但其方法并非关于智能体如何进行多步规划或自主决策，而是关于如何静态地组合多个模型的预测结果。因此，它属于被排除的“非Agentic的推理”范畴。 *   **自我演化的应用**: 论文没有提出任何自我演化机制。其集成方法是固定的，通过启发式规则选择，不具备自我完善或迭代的能力。 **最终决策**: 综合以上分析，这篇论文的核心是**一种针对特定NLP任务的模型集成技术**，它属于应用型研究。其研究目标是提升NER任务的性能，而非探索LLM智能体的构建、协作或演化。因此，它严格地被排除在您关于“LLM智能体及其演化”的研究课题之外。"
    },
    {
        "index": "#56",
        "title": "Intelligently Weighting Multiple Reference Models for Direct Preference Optimization of LLMs",
        "link": "/arxiv/2512.10040",
        "arxiv_id": "2512.10040",
        "authors": "Skyler Wu, Aymen Echarghaoui",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.934480",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心贡献不符 (第一步)**: 论文的核心贡献是提出了一种用于**直接偏好优化 (DPO)** 的加权策略，旨在通过智能地组合多个参考模型来更好地对齐LLM与人类偏好。这是一种**模型微调/对齐技术**，而不是关于构建、改进或演化LLM智能体的方法论。我的研究焦点是Agentic AI，即智能体本身的行为、能力和演化，而非底层的模型训练和对齐。 2.  **触发了明确的排除标准 (第三步)**: 论文摘要开篇即点明其研究目标是“aligning large language models (LLMs) with human preferences”（将LLM与人类偏好对齐）。这直接命中了第三步排除标准中的 `Alignment` (对齐)。此外，其实验数据集包含了 `SafeRLHF`，这进一步强化了其研究属于安全与对齐领域的属性。根据筛选规则，只要论文的主要贡献是关于对齐，就应一律排除。 3.  **缺乏核心关注点 (第二步)**: 论文中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。它讨论的是模型层面的优化，而非智能体层面的架构或行为。 4.  **不属于特殊情况的例外 (第四步)**: 这篇论文不涉及智能体的规划或推理框架，也不涉及自我演化机制。它提出的加权策略是一种外部的模型训练技巧，而非智能体在运行中进行自我完善的内部机制。 综上所述，尽管这篇论文在LLM对齐领域可能是一项有价值的工作，但它的本质是模型训练和优化，与我的研究课题“LLM智能体及其演化”的核心目标——构建和演化智能体本身——存在根本性的偏离。因此，应将其排除。"
    },
    {
        "index": "#61",
        "title": "HGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding",
        "link": "/arxiv/2512.09947",
        "arxiv_id": "2512.09947",
        "authors": "Fuyan Ou, Siqi Ai, Yulin Hu",
        "subjects": "Machine Learning, Information Retrieval",
        "date": "2025-12-08",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.942082",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出一种名为 **HGC-Herd** 的**异质图压缩**方法。它旨在解决异质图神经网络（HGNNs）在大规模图上的可扩展性问题，通过一种“放牧”机制生成更小但信息量不减的图，以提高下游任务的效率。 - **与目标匹配度**: 该研究的本质是**图表示学习**和**图数据结构优化**，与“构建、改进或演化LLM智能体”这一核心目标完全无关。论文中完全没有提及LLM、智能体或任何与Agentic AI相关的概念。因此，根据第一步的排除标准，这属于将一种算法应用到特定领域（图数据）的研究，而非关于智能体本身的研究，应直接**排除**。 2.  **第二步：正面指标** - 论文的标题和摘要中，完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准** - 虽然这篇论文不涉及安全对齐或多模态等排除项，但这并不改变它在第一步就已经被判定为不相关的事实。 4.  **第四步：特殊和模糊情况** - 该论文不涉及任何与智能体推理、规划或自我演化相关的特殊情况。 **最终决策**: 该论文的研究领域是图神经网络（GNN）和图数据压缩，其核心贡献是提升图学习任务的计算效率。这与您关于“LLM智能体及其演化”的研究课题在研究对象、核心贡献和技术路线上存在根本性的差异。因此，这篇论文与您的研究范围完全不匹配，应予以排除。"
    },
    {
        "index": "#62",
        "title": "An Elementary Proof of the Near Optimality of LogSumExp Smoothing",
        "link": "/arxiv/2512.10825",
        "arxiv_id": "2512.10825",
        "authors": "Thabo Samakhoana, Benjamin Grimmer",
        "subjects": "Statistics Theory, Machine Learning, Optimization and Control",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.942541",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 根据标题和摘要，这篇论文的核心是**数学理论分析**。它研究的是 `LogSumExp` 函数作为一种平滑 `max` 函数的方法，并从数学上证明了其（在常数因子范围内）的近最优性。其贡献在于提供了一个关于函数逼近的下界证明和构造。 - **是否符合要求**: 这篇论文的核心贡献**不是**关于构建、改进或演化LLM智能体。它没有涉及任何智能体框架、规划、记忆、工具使用或多智能体交互等概念。它属于基础数学或优化理论领域，而非Agentic AI研究。因此，根据第一步的核心判断标准，应予以**排除**。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现任何您所关注的核心范式、智能体能力、多智能体或演化机制相关的关键词（如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent` 等）。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准** - 虽然这篇论文不涉及安全对齐或多模态等排除标准，但它属于一个更根本的排除类别：**非Agentic的基础理论研究**。它研究的对象是数学函数，而非智能体系统。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文不涉及智能体的推理或规划框架。它讨论的是数学函数的性质，而不是智能体如何进行多步决策。因此，它不属于应保留的“Agentic框架”范畴。 - **自我演化的应用**: 论文没有提出任何自我演化机制，更不用说将其应用于特定领域了。 **最终决策**: 综合以上分析，该论文是一篇纯粹的数学理论文章，其研究对象和贡献与“LLM智能体及其演化”这一课题完全无关。它既不是关于构建智能体，也不是关于改进智能体的能力或使其演化。因此，最终判断为 **False**。"
    },
    {
        "index": "#59",
        "title": "Latent Action World Models for Control with Unlabeled Trajectories",
        "link": "/arxiv/2512.10016",
        "arxiv_id": "2512.10016",
        "authors": "Marvin Alles, Xingyuan Zhang, Patrick van der Smagt, Philip Becker-Ehmck",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.935816",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“潜在动作世界模型”的新方法，用于解决强化学习（RL）中的数据效率问题。它通过学习一个共享的潜在动作空间，将带动作标签的交互数据和不带动作标签的被动观察数据（如视频）结合起来，以训练一个更高效的动力学模型和策略。 这篇论文的本质是**强化学习算法和模型架构的创新**，其应用领域是**控制**。它完全符合筛选标准中的第一条排除规则：“**非演化型应用**”，即它将一个新颖的模型（世界模型）应用到特定领域（控制）去解决该领域的问题（数据标签稀缺）。它并没有构建、改进或演化一个具有规划、记忆、工具使用等能力的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式和能力指标。 -   **核心范式**: 论文未提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, 或 `Self-Evolving`。它研究的“世界模型”是RL领域的概念，与您关注的“智能体框架”有本质区别。 -   **智能体能力**: 论文没有讨论 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等高级智能体能力。它提到的“策略”是RL中用于选择动作的低层级控制策略，而非您所关注的、涉及复杂推理和规划的智能体规划。 -   **多智能体与演化机制**: 论文不涉及多智能体协作，也没有提出任何自我改进或自我演化的机制。模型是在一个固定的离线数据集上训练的，不会通过经验进行迭代完善。 3.  **第四步：处理特殊和模糊情况** -   **推理/规划**: 尽管论文涉及学习“策略”，这可以被视为一种规划形式，但它属于**排除**的情况。这里的规划是针对具体控制任务（如DMControl套件中的任务）的低层级、连续动作规划，而不是您所关注的、在复杂任务中进行多步推理的**Agentic框架**（如ReAct, ToT）。论文的核心是模型架构，而非智能体的推理机制。 **总结**: 该论文是一篇优秀的强化学习研究，但它聚焦于如何通过创新的模型架构来提升控制任务的数据效率。它的研究对象是“世界模型”和“控制策略”，而非“LLM智能体”。因此，尽管它使用了“智能体”在RL中的广义概念，但其核心贡献和研究焦点与您关于“LLM智能体及其演化”的课题目标不符。根据第一步的核心判断，应予以排除。"
    },
    {
        "index": "#63",
        "title": "Agile Deliberation: Concept Deliberation for Subjective Visual Classification",
        "link": "/arxiv/2512.10821",
        "arxiv_id": "2512.10821",
        "authors": "Leijie Wang, Otilia Stretcu, Wei Qiao, Thomas Denby, Krishnamurthy Viswanathan, Enming Luo, Chun-Ta Lu, Tushar Dogra, Ranjay Krishna, Ariel Fuxman",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition, Human-Computer Interaction, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.943116",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是“非演化型应用”** 论文的核心贡献是提出一个名为“Agile Deliberation”的**人机交互框架**，用于帮助人类用户在视觉分类任务中**迭代地明确和演化自己对某个概念的理解**。这里的“演化”主体是**人类用户**，而不是一个自主的LLM智能体。该框架是一个辅助人类进行“概念商议”的工具，其目标是优化一个**图像分类器**，而不是构建或演化一个具有自主规划、反思能力的LLM智能体。因此，它属于“将LLM（或框架）作为工具应用到特定领域（视觉分类）去解决该领域问题”的范畴，应被排除。 2.  **排除标准 (第三步): 论文核心属于“多模态与视觉”** 论文的标题和摘要明确指出，其研究问题是“主观视觉分类”，核心是“图像分类器”。整个方法论都是围绕视觉数据展开的。根据您的筛选标准，凡是核心关注点为 `Vision`, `Vision-Language` 等多模态领域的研究，除非它们是作为智能体感知环境的工具，否则一律排除。在这篇论文中，视觉是研究的**核心**，而不是智能体的一个工具，因此触发了排除标准。 3.  **特殊与模糊情况处理 (第四步): “自我演化”的例外情况不适用** 虽然论文中出现了“evolving intent”、“iteratively refine”等词汇，但这并不符合您所关注的“自我演化”机制。您关注的“自我演化”是指智能体通过经验、反思或环境反馈进行**自主**的自我完善和迭代。而本文中的演化是**人驱动的**：系统向用户展示边界案例，用户进行反思并提供反馈，系统再根据反馈调整模型。这是一个典型的人机交互循环，而非智能体的自主演化。因此，第四步中关于“自我演化的应用”的保留例外不适用于此。 **总结**: 该论文的本质是一个创新的**人机交互方法**，应用于**计算机视觉**领域，旨在解决主观概念定义的问题。它虽然涉及“迭代”和“演化”，但主体是人类而非智能体，且核心领域是视觉。这与您研究的“LLM智能体及其演化”的核心目标——构建、改进或演化**自主的**LLM智能体——存在根本性的偏离。因此，应予以排除。"
    },
    {
        "index": "#64",
        "title": "Deep sets and event-level maximum-likelihood estimation for fast pile-up jet rejection in ATLAS",
        "link": "/arxiv/2512.10819",
        "arxiv_id": "2512.10819",
        "authors": "Mohammed Aboelela",
        "subjects": "High Energy Physics - Experiment, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.943540",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出了一种名为DIPz的深度学习模型，用于解决高能物理领域（ATLAS实验）中的一个具体问题：在多重碰撞（pile-up）环境中快速、高效地识别和排除背景喷注。其技术核心是基于Deep Sets架构的回归模型和一种名为MLPL的事件级判别方法。 - **判断**: 这完全符合第一步中的**排除规则 #1: 非演化型应用**。论文将一个深度学习模型（而非LLM或智能体框架）作为工具，应用在特定的科学领域（粒子物理）来解决该领域的数据处理挑战，而不是研究如何构建、改进或演化LLM智能体本身。论文的本质是应用驱动的算法研究，而非Agentic AI的基础研究。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现第二步“正面指标”中的任何核心范式或关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其研究内容与这些关注点毫无关联。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文没有直接涉及“安全与对齐”或“多模态与视觉”等排除关键词，但它已经被第一步更根本的“非演化型应用”规则所排除。 4.  **第四步：处理特殊和模糊情况** - 论文的研究内容不涉及第四步中提到的“推理/规划”或“自我演化”的特殊情况。其“回归”任务是标准的机器学习任务，而非智能体在复杂任务中的自主规划和多步推理。论文也没有提出任何“自我演化”机制。 **最终决策**: 综合以上分析，该论文的研究焦点是高能物理实验的数据处理技术，与“LLM智能体及其演化”这一核心课题完全无关。它是一篇典型的领域应用论文，因此应被**排除**。"
    },
    {
        "index": "#71",
        "title": "Sharp Monocular View Synthesis in Less Than a Second",
        "link": "/arxiv/2512.10685",
        "arxiv_id": "2512.10685",
        "authors": "Lars Mescheder, Wei Dong, Shiwei Li, Xuyang Bai, Marcel Santos, Peiyun Hu, Bruno Lecouat, Mingmin Zhen, Amaël Delaunoy, Tian Fang, Yanghai Tsin, Stephan R. Richter, Vladlen Koltun",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.952517",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为SHARP的计算机视觉方法，用于从单张图像快速生成3D场景表示并进行视图合成。这是一个典型的计算机图形学和计算机视觉交叉领域的研究。它完全符合**排除标准1：非演化型应用**。该研究是将一个神经网络模型作为工具，应用于“视图合成”这一特定领域问题，其本身并未涉及构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 等任何核心范式或智能体能力。其关注点在于渲染速度（`less than a second`）和图像质量（`LPIPS`, `DISTS`），这些都是计算机视觉领域的评价指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文明确触发了**排除标准2：多模态与视觉**。其核心任务“Monocular View Synthesis”（单目视图合成）以及关键技术“3D Gaussian representation”（3D高斯表示）和“rendering”（渲染）都属于纯粹的视觉/图形学范畴。视觉是这篇论文的研究核心，而不是作为智能体感知环境的工具。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何自我演化机制，因此特殊情况的例外条款不适用。 **最终决策**：综合以上分析，这篇论文是一篇纯粹的计算机视觉/图形学研究，其目标是解决视图合成问题，与您关于“LLM智能体及其演化”的研究课题（聚焦于单智能体、多智能体和自我演化）完全无关。因此，应予以排除。"
    },
    {
        "index": "#70",
        "title": "PMB-NN: Physiology-Centred Hybrid AI for Personalized Hemodynamic Monitoring from Photoplethysmography",
        "link": "/arxiv/2512.10745",
        "arxiv_id": "2512.10745",
        "authors": "Yaowen Zhang, Libera Fresiello, Peter H. Veltink, Dirk W. Donker, Ying Wang",
        "subjects": "Medical Physics, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.951913",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 论文的核心贡献是提出了一种名为“PMB-NN”的混合AI模型，用于从光电容积描记（PPG）信号中个性化监测血压和血流动力学参数（如外周阻力R和动脉顺应性C）。该模型将深度学习与一个基于物理的生理模型（Windkessel模型）相结合，以提高预测结果的“生理合理性”和“可解释性”。 - **判断**: 这篇论文的本质是**非演化型应用**。它将一个特定的AI模型（PMB-NN）作为工具，应用在医疗健康领域（血流动力学监测）来解决该领域的具体问题。它没有构建、改进或演化任何形式的LLM智能体、多智能体系统或自我演化框架。因此，根据第一步的排除规则，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - **安全与对齐**: 论文明确将“可解释性”作为其核心贡献之一。摘要中提到：“...the embedded physiological constraints confer **interpretability** to the hybrid AI framework.” 根据您的筛选标准，“只要论文的主要贡献是关于...Interpretability...一律排除”。因此，该论文触发了明确的排除标准。 - **多模态与视觉**: 不适用。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及推理/规划或自我演化机制的特殊情况，因此此步骤不适用。 **最终决策**: 综合以上分析，这篇论文是一篇典型的医疗AI应用研究，其核心目标是构建一个更准确、更可解释的混合模型来解决血压估计问题。它既不涉及LLM智能体的构建，也不涉及多智能体协作或自我演化机制。其核心贡献之一“可解释性”更是您明确指定的排除项。因此，该论文与您关于“LLM智能体及其演化”的研究课题完全不符。"
    },
    {
        "index": "#73",
        "title": "Evaluating Gemini Robotics Policies in a Veo World Simulator",
        "link": "/arxiv/2512.10675",
        "arxiv_id": "2512.10675",
        "authors": "Gemini Robotics Team, Coline Devin, Yilun Du, Debidatta Dwibedi, Ruiqi Gao, Abhishek Jindal, Thomas Kipf, Sean Kirmani, Fangchen Liu, Anirudha Majumdar, Andrew Marmon, Carolina Parada, Yulia Rubanova, Dhruv Shah, Vikas Sindhwani, Jie Tan, Fei Xia, Ted Xiao, Sherry Yang, Wenhao Yu, Allan Zhou",
        "subjects": "Robotics, Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.953709",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心贡献不符 (第一步核心判断):** 论文的核心贡献是构建一个**用于评估机器人策略的生成式模拟系统**。它使用视频模型来创建逼真的环境，以测试已有的“Gemini Robotics policy checkpoints”的性能、泛化能力和安全性。这属于典型的**非演化型应用**。论文的重点是“评估”和“模拟”，而不是“构建、改进或演化”LLM智能体本身。智能体在这里是被测试的对象，而不是被研究或改进的核心。 2.  **命中明确的排除标准 (第三步排除标准):** *   **安全与对齐:** 论文摘要中明确指出，其系统的一个关键用途是“probing physical and semantic safety”（探测物理和语义安全）以及“performing red teaming of policies to expose behaviors that violate physical or semantic safety constraints”（对策略进行红队测试以暴露违反安全约束的行为）。这直接命中了“安全与对齐”的排除标准，因为论文的主要贡献之一就是关于策略的安全性评估。 *   **多模态与视觉:** 论文的核心技术基础是一个“frontier video foundation model (Veo)”。整个研究都是围绕如何利用视频生成模型来构建模拟器展开的。虽然这服务于机器人策略，但研究的核心是视频模型的应用，而非智能体的内在架构或演化机制。这属于“多模态与视觉”的排除范畴。 3.  **缺乏核心关注点 (第二步正面指标):** 论文中没有出现我关注的核心范式，如 `Agentic AI`, `Self-Evolving`, `Multi-Agent Systems` 等。虽然提到了“robotics policies”，但并未深入探讨智能体的 `Planning`, `Memory`, `Self-Reflection` 或 `Self-Improvement` 等内在能力。其焦点在于外部环境的模拟和策略表现的评估。 综上所述，该论文是一篇关于机器人学模拟和策略安全评估的研究，其本质是利用生成模型作为工具解决特定领域的应用问题，与“LLM智能体及其演化”的核心研究目标——即智能体本身的构建、改进和演化——存在根本性的偏离。因此，应果断排除。"
    },
    {
        "index": "#65",
        "title": "Quantum Approaches to Urban Logistics: From Core QAOA to Clustered Scalability",
        "link": "/arxiv/2512.10813",
        "arxiv_id": "2512.10813",
        "authors": "F. Picariello, G. Turati, R. Antonelli, I. Bailo, S. Bonura, G. Ciarfaglia, S. Cipolla, P. Cremonesi, M. Ferrari Dacrema, M. Gabusi, I. Gentile, V. Morreale, A. Noto",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.944148",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是提出一种名为“聚类QAOA（Cl-QAOA）”的**量子优化算法**，用于解决旅行商问题（TSP）这一经典的组合优化问题。其本质是**量子计算**与**运筹学**领域的研究，旨在通过改进量子算法来提升解决特定数学问题的效率和可扩展性。这完全符合**排除标准1：非演化型应用**。论文将一种算法（QAOA）应用到特定领域（城市物流），解决该领域的问题（TSP），其核心贡献是算法本身，而非构建或演化LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式、智能体能力、多智能体或演化机制相关的任何关键词或概念。例如，它没有提及 `LLM-based Agents`, `Planning` (在智能体自主规划的意义上), `Tool Use`, `Self-Reflection`, `Multi-Agent Systems` 或 `Self-Evolving`。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不直接涉及安全与对齐或多模态等排除项，但第一步的判断已经足够有力，可以将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“规划”是指量子算法的电路设计和问题分解策略，属于算法层面的规划，而非LLM智能体在复杂任务中进行自主决策和多步推理的Agentic框架。因此，应被排除。 - **自我演化的应用**: 论文提出的Cl-QAOA是一种算法改进，而不是一个智能体通过经验或反馈进行自我完善的机制。因此，关于“自我演化应用”的例外情况不适用。 **最终决策**: 该论文的核心贡献是量子计算领域的一种新算法，与“LLM智能体及其演化”这一研究课题完全无关。它既不涉及LLM，也不涉及智能体的构建、协作或演化。因此，应果断排除。"
    },
    {
        "index": "#72",
        "title": "Optimal transport unlocks end-to-end learning for single-molecule localization",
        "link": "/arxiv/2512.10683",
        "arxiv_id": "2512.10683",
        "authors": "Romain Seailles, Jean-Baptiste Masson, Jean Ponce, Julien Mairal",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.952991",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是针对**单分子定位显微镜（SMLM）**这一生物成像领域的技术难题，提出了一种新的**最优传输损失函数**和一个**迭代神经网络架构**，以提升超分辨率图像的重建效果。这完全属于将深度学习方法作为工具应用到特定领域（生物/显微镜学）来解决该领域问题的范畴。根据筛选标准，这属于“非演化型应用”，应直接**排除**。论文的核心是改进一个计算机视觉任务，而不是构建、改进或演化LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标。没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心范式或智能体能力。其讨论的是 `optimal transport loss`, `neural network`, `microscope's optical system`，这些都与我的研究目标无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的研究内容是关于图像重建（`reconstructing super-resolved images`），这明确属于**视觉** 领域。根据筛选标准，除非视觉是作为智能体感知环境的工具，否则应被排除。在这篇论文中，视觉处理本身就是研究的核心，而非服务于一个智能体框架，因此触发了排除标准。 4.  **第四步：处理特殊和模糊情况** 论文不涉及智能体的推理/规划框架，也没有提出任何“自我演化”机制。它提出的是一个更优的损失函数和模型架构，属于模型训练方法的改进，而非智能体的自我完善和迭代。因此，特殊规则不适用。 **最终决策：** 综合以上分析，该论文是一篇典型的计算机视觉与生物信息学交叉领域的应用研究。其核心贡献是解决特定领域的图像重建问题，与“LLM智能体及其演化”这一研究课题在研究对象、核心贡献和研究范式上均无交集。因此，最终判断为**不符合**，予以排除。"
    },
    {
        "index": "#76",
        "title": "Refinement Contrastive Learning of Cell-Gene Associations for Unsupervised Cell Type Identification",
        "link": "/arxiv/2512.10640",
        "arxiv_id": "2512.10640",
        "authors": "Liang Peng, Haopeng Liu, Yixuan Ye, Cheng Liu, Wenjun Shen, Si Wu, Hau-San Wong",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.955180",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“scRCL”的**精炼对比学习框架**，用于解决**生物信息学领域**的**无监督细胞类型识别**问题。这是一个典型的**非演化型应用**。论文的目标是改进特定领域（单细胞组学）的聚类效果，而不是构建、改进或演化一个具有自主性的LLM智能体。论文中完全没有提及LLM或智能体框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文完全不包含我的核心关注点。摘要和标题中没有任何与`Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`等相关的关键词或概念。其技术核心是`Contrastive Learning`（对比学习）和`Representation Learning`（表示学习），属于机器学习方法论的范畴，但并非Agentic AI的方法论。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，这篇论文完全在我的研究焦点之外。它属于将一种机器学习技术（对比学习）应用到特定科学领域（生物学）的应用型研究。这直接触发了第一步中的“非演化型应用”排除规则。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何特殊情况。它既不是关于智能体的推理/规划，也没有提出任何“自我演化”机制。 **最终决策**： 综合以上分析，这篇论文的核心是解决生物领域的特定问题，其技术贡献是一种新的对比学习框架，与LLM智能体的构建、多智能体系统或自我演化机制毫无关联。因此，它被明确排除。"
    },
    {
        "index": "#75",
        "title": "Virtual camera detection: Catching video injection attacks in remote biometric systems",
        "link": "/arxiv/2512.10653",
        "arxiv_id": "2512.10653",
        "authors": "Daniyar Kurmankhojayev, Andrei Shadrikov, Dmitrii Gordin, Mikhail Shkorin, Danijar Gabdullin, Aigerim Kambetbayeva, Kanat Kuatov",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.954677",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 论文的核心贡献是提出一种基于机器学习的“虚拟摄像头检测”方法，用于在远程生物识别系统中“捕获视频注入攻击”。这是一个针对特定安全威胁（视频注入）的解决方案，其本质是构建一个分类器或检测模型。 - **是否符合**: 这完全符合第一步中的排除标准 **1. 非演化型应用**。该研究是将机器学习技术作为工具，应用在“生物识别安全”这一特定领域去解决该领域的问题，其核心并非构建或演化一个具有自主规划、工具使用或反思能力的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文标题和摘要中完全没有出现任何与我的研究焦点相关的正面指标，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了其与研究主题的偏离。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - **安全与对齐**: 论文的研究动机和核心贡献是关于“安全”的，具体是检测攻击以提升系统安全性。这直接命中了排除标准中的“安全与对齐”类别。 - **多模态与视觉**: 论文处理的对象是“视频注入攻击”和“面部识别”，这属于视觉领域的研究范畴。虽然它不是多模态大模型，但其核心数据模态是视觉的，符合排除标准中的“多模态与视觉”类别。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况，因此无需进行特殊考量。 5.  **第五步：最终决策** - 综合以上分析，该论文的核心是解决一个计算机视觉和网络安全领域的具体问题，而非研究LLM智能体的构建、协作或演化机制。它既不符合“保留”标准，又明确符合多项“排除”标准。因此，这篇论文与我的研究课题“LLM智能体及其演化”完全不相关。"
    },
    {
        "index": "#74",
        "title": "AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search",
        "link": "/arxiv/2512.10671",
        "arxiv_id": "2512.10671",
        "authors": "Oscar Robben, Saeed Khalilian, Nirvana Meratnia",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.954160",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出一种名为“AEBNAS”的**硬件感知神经架构搜索（NAS）框架**，用于优化“early-exit networks”的设计。其本质是**模型基础设施和部署优化**的研究，旨在通过调整网络结构来降低能耗和延迟。这完全符合第一步排除标准中的“基础设施”类别，即“主要关注模型基础设施、部署优化、硬件加速的研究”。它并未涉及构建、改进或演化LLM智能体。 2.  **正面指标缺失（第二步）：** 论文摘要中完全没有出现任何与我核心关注点相关的关键词或概念。它没有讨论`Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`或`Self-Evolving`。同样，它也未涉及智能体的核心能力，如`Planning`、`Tool Use`、`Memory`、`Self-Reflection`等。 3.  **对“演化”概念的误读（第四步）：** 虽然论文标题和摘要中提到了“Neural Architecture Search”，这是一种基于演化思想的算法，但此处的“演化”指的是**在设计阶段搜索最优网络架构的过程**，而非智能体在运行时通过经验、反思或环境反馈进行的**自我完善和迭代**。我的研究焦点是后者，即智能体作为实体的动态演化能力，而非静态模型的设计优化。 综上所述，该论文的研究方向是高效的深度学习模型设计与硬件优化，与我的研究课题“LLM智能体及其演化”在核心问题和贡献上存在根本性差异。因此，应予以排除。"
    },
    {
        "index": "#79",
        "title": "Topology-Guided Quantum GANs for Constrained Graph Generation",
        "link": "/arxiv/2512.10582",
        "arxiv_id": "2512.10582",
        "authors": "Tobias Rohe, Markus Baumann, Michael Poppel, Gerhard Stenzel, Maximilian Zorn, Claudia Linnhoff-Popien",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.956665",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是关于**量子计算**领域的研究，具体是提出了一种改进**量子生成对抗网络**的方法，用于生成具有特定几何约束的图。其核心创新点在于将任务特定的几何先验知识（如拓扑结构）融入到量子电路的设计中，以提升生成效果。这完全属于**“非演化型应用”**的排除范畴。它并非构建一个通用的LLM智能体框架，而是将一个特定的模型应用于一个特定的领域（图生成）。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与您研究焦点相关的正面指标。它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，它也未涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。论文的焦点是量子电路的拓扑结构和损失函数设计，与智能体架构无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文没有直接触发“安全与对齐”或“多模态与视觉”的排除标准，但它所属的领域（量子计算、图生成）本身就与您的研究焦点“LLM智能体及其演化”相去甚远。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何与智能体相关的推理/规划框架，更没有提出任何“自我演化”机制。因此，特殊情况的例外条款不适用。 **最终决策**：综合以上分析，该论文是一篇纯粹的量子计算与图生成领域的应用研究。其核心贡献在于优化量子模型本身，而非构建、改进或演化LLM智能体。因此，它完全不符合您的研究目标，应予以排除。"
    },
    {
        "index": "#77",
        "title": "Adaptive Intrusion Detection System Leveraging Dynamic Neural Models with Adversarial Learning for 5G/6G Networks",
        "link": "/arxiv/2512.10637",
        "arxiv_id": "2512.10637",
        "authors": "Neha, Tarunpreet Bhatia",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.955624",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出一个用于5G/6G网络的**自适应入侵检测系统（IDS）**。它利用动态神经网络和对抗学习来提高网络安全威胁的检测能力。 - **判断**: 这完全符合**“非演化型应用”**的排除标准。论文将一个机器学习模型（动态神经网络）作为工具，应用在网络安全这一特定领域来解决该领域的问题。它并未构建、改进或演化一个具有自主规划、工具使用或反思能力的LLM智能体。因此，在第一步就应该被排除。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何与我的核心关注点相关的关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。它提到的“动态”和“增量学习”是机器学习模型层面的概念，而非智能体层面的能力或框架。 3.  **第三步：排除标准** - 这篇论文的主要贡献明确属于**“安全与对齐”**中的 `Security` 范畴。其研究目标就是构建一个更安全的网络入侵检测系统。根据筛选标准，只要论文的主要贡献是关于安全，就应该一律排除。 4.  **第四步：处理特殊和模糊情况** - 论文提到的“增量学习”虽然听起来像是一种演化，但它指的是模型参数的更新，以适应新的网络攻击模式，而不是智能体通过经验、反思或环境反馈进行自我完善和迭代的机制。因此，这不属于“自我演化”的例外情况。 **最终决策**: 综合以上分析，该论文是一篇典型的网络安全与机器学习交叉领域的应用研究。其核心是构建一个更鲁棒的分类模型，而非研究LLM智能体的构建、协作或演化机制。因此，它完全不符合我的研究目标“LLM智能体及其演化”。"
    },
    {
        "index": "#78",
        "title": "Authority Backdoor: A Certifiable Backdoor Mechanism for Authoring DNNs",
        "link": "/arxiv/2512.10600",
        "arxiv_id": "2512.10600",
        "authors": "Han Yang, Shaofeng Li, Tian Dong, Xiangyu Xu, Guangchi Liu, Zhen Ling",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.956159",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。 **核心判断依据如下：** 1.  **第一步：核心判断——论文本质不符** 论文的核心贡献是提出一种名为“Authority Backdoor”的**DNN模型安全保护机制**。其目标是防止深度神经网络（DNN）作为知识产权被盗用，通过植入后门来实现访问控制。这本质上属于**模型安全** 领域的研究，而非关于构建、改进或演化LLM智能体的方法论。论文的研究对象是通用的DNN，而非LLM或基于LLM的智能体。 2.  **第三步：排除标准——明确触及排除红线** 根据筛选标准，只要论文的主要贡献是关于 `Safety`、`Security`、`Watermarking` 等，就应一律排除。这篇论文的摘要明确指出其研究内容是“proactive protection scheme”（主动保护方案）、“secure authority mechanism”（安全授权机制）、“certifiable robustness against adversarial attacks”（针对对抗性攻击的可证明鲁棒性），并将“digital watermarking”（数字水印）作为对比技术。这些都直接命中了“安全与对齐”的排除标准。 3.  **第二步：正面指标——缺乏任何相关指标** 论文摘要中完全没有出现任何与我的研究焦点相关的正面指标。它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving` 等核心范式，也没有涉及 `Planning`、`Tool Use`、`Memory`、`Collaboration`、`Self-Improvement` 等智能体能力或演化机制。 **总结：** 该论文的研究焦点是DNN的知识产权保护和访问控制，属于模型安全领域。这与我的研究目标——“LLM智能体及其演化”——在研究方向和核心贡献上存在根本性差异。因此，尽管它可能是一篇优秀的AI安全论文，但它完全不符合本次筛选的要求。"
    },
    {
        "index": "#80",
        "title": "Flexible Deep Neural Networks for Partially Linear Survival Data",
        "link": "/arxiv/2512.10570",
        "arxiv_id": "2512.10570",
        "authors": "Asaf Ben Arie, Malka Gorfine",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.962282",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为FLEXI-Haz的深度神经网络（DNN）框架，用于生物统计学领域的生存数据分析。 根据您的筛选标准，这篇论文在第一步的核心判断中就应该被排除。具体原因如下： 1.  **核心判断——属于“非演化型应用”**: 论文将一个通用的深度神经网络（DNN）作为工具，应用在“生存数据”这一特定领域，以解决该领域的统计建模问题。其研究焦点是统计方法的创新（提出一种新的部分线性风险模型），而非构建、改进或演化LLM智能体。这完全符合第一步排除标准中的“非演化型应用”。 2.  **缺乏核心关注点**: 论文完全没有涉及您研究的核心范式。摘要中未提及任何与 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 相关的内容。其关键词是“深度神经网络”、“生存数据”、“风险模型”，与您的研究方向“Agentic AI”、“Multi-Agent Systems”、“Self-Evolving”完全不匹配。 3.  **不涉及LLM**: 论文的基础是通用的深度神经网络（DNN），而非大语言模型（LLM）。您的研究课题明确限定为“LLM智能体”，因此不使用LLM作为核心组件的论文自然不在范围内。 综上所述，尽管这是一篇在其领域内（生物统计/机器学习）可能很有价值的论文，但它完全不符合您关于“LLM智能体及其演化”的研究范围。它是一个应用型机器学习方法论文，而非Agentic AI的基础研究论文。"
    },
    {
        "index": "#66",
        "title": "What matters for Representation Alignment: Global Information or Spatial Structure?",
        "link": "/arxiv/2512.10794",
        "arxiv_id": "2512.10794",
        "authors": "Jaskirat Singh, Xingjian Leng, Zongze Wu, Liang Zheng, Richard Zhang, Eli Shechtman, Saining Xie",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Graphics, Machine Learning, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.944710",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是研究一种名为“表示对齐”的技术，用于改进**生成模型**的训练效果。具体来说，它探讨了如何从一个预训练的**视觉编码器**中蒸馏表示，以更好地指导**扩散模型**的生成过程。这完全属于计算机视觉和生成模型的研究范畴，其本质是优化模型训练方法，而非构建、改进或演化LLM智能体。因此，它不符合第一步的“保留”标准。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文的研究对象明确包括“vision encoder”和“diffusion features”，这直接命中了您设定的“多模态与视觉”排除标准。根据规则，除非视觉或扩散模型被用作智能体感知环境的工具，否则应予以排除。在这篇论文中，它们是研究的核心，而非工具。 3.  **正面指标 (第二步):** 论文中完全没有出现任何与您研究焦点相关的正面指标。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等任何核心概念。其讨论的“spatial structure”和“global information”是关于视觉特征的表示，而非智能体的能力或架构。 综上所述，该论文是一篇典型的计算机视觉/生成模型领域的论文，其研究目标、方法和核心贡献都与您关注的“LLM智能体及其演化”课题无关。因此，最终决策为排除。"
    },
    {
        "index": "#83",
        "title": "Hyperspectral Image Data Reduction for Endmember Extraction",
        "link": "/arxiv/2512.10506",
        "arxiv_id": "2512.10506",
        "authors": "Tomohiko Mizutani",
        "subjects": "Image and Video Processing, Machine Learning, Signal Processing",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.963775",
        "filter_reason": "这篇论文不符合研究范围。 我的判断过程如下： 1.  **第一步：核心判断** 该论文的核心贡献是提出一种用于高光谱图像端元提取的数据缩减算法，旨在降低现有“自字典”方法的计算成本。这本质上是一种针对特定领域（遥感/信号处理）的算法优化。根据筛选标准第一步，这属于典型的“非演化型应用”，即论文只是提出一种计算方法来解决特定领域的问题，其核心并非构建、改进或演化LLM智能体。论文中完全没有涉及LLM或任何智能体框架。 2.  **第二步：正面指标** 论文中完全没有出现任何与研究课题相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** 虽然论文处理的是图像数据，但其核心是信号处理算法，而非多模态模型或视觉智能体的研究，因此不直接触犯多模态与视觉的排除规则，但其本质已经超出了研究范围。 4.  **第四步：特殊和模糊情况** 论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何自我演化机制。 **最终决策**：综合以上分析，该论文是一篇纯粹的信号处理/遥感领域的算法研究论文。它的核心贡献是优化一个特定任务的计算效率，与“LLM智能体及其演化”这一研究课题的三个核心方向（单智能体、多智能体、自我演化）均无任何关联。因此，应予以排除。"
    },
    {
        "index": "#87",
        "title": "Supervised Learning of Random Neural Architectures Structured by Latent Random Fields on Compact Boundaryless Multiply-Connected Manifolds",
        "link": "/arxiv/2512.10407",
        "arxiv_id": "2512.10407",
        "authors": "Christian Soize",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.965682",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出一种全新的、基于概率和几何理论的**神经网络架构生成框架**。它通过在特定流形上定义的潜在随机场来随机生成神经网络的拓扑结构和权重。其本质是关于**如何从数学上构建一个神经网络**，而不是关于如何让一个已有的LLM或神经网络作为智能体去行动、协作或演化。 - **结论**: 这篇论文属于**基础设施**或**基础模型理论**研究的范畴，因为它关注的是神经网络结构本身的生成原理，而非智能体的行为、规划或演化机制。根据筛选标准，应予以**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。 - 论文讨论的是 \"supervised learning\"（监督学习）和 \"generative process\"（生成过程），这与智能体的自主规划和自我完善有本质区别。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文不直接涉及安全、对齐或多模态等排除项，但它触及了另一个更根本的排除项：**基础设施**。该研究旨在为神经网络架构的生成建立一个新的数学基础，这属于模型构建的底层理论，而非上层应用（智能体）的研究。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划。 - **自我演化的应用**: 这是最需要辨析的一点。论文提出了一个“生成”架构的机制，但这**不等于**“自我演化”机制。 - **自我演化** 指的是一个**已经存在的智能体**在与环境交互的过程中，通过经验、反思等方式**主动地、持续地改进自身**的能力、策略或知识结构（例如，一个智能体在完成多个任务后，学会了如何更好地规划）。 - 该论文的“生成”机制是一个**外部的、一次性的过程**，用于从零开始创建一个网络架构。它描述的是架构的“诞生”，而不是智能体在生命周期中的“成长”或“进化”。因此，它不符合“自我演化”的定义。 **最终决策**: 综合以上分析，这篇论文的核心是提出一种新颖的、数学上复杂的神经网络架构生成方法。它是一项关于神经网络基础理论的研究，与您关注的“LLM智能体及其演化”这一课题——即智能体的行为、交互和自我迭代能力——完全无关。因此，该论文应被**排除**。"
    },
    {
        "index": "#82",
        "title": "LLM-Auction: Generative Auction towards LLM-Native Advertising",
        "link": "/arxiv/2512.10551",
        "arxiv_id": "2512.10551",
        "authors": "Chujie Zhao, Qun Hu, Shiping Song, Dagui Chen, Han Zhu, Jian Xu, Bo Zheng",
        "subjects": "Computer Science and Game Theory, Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.963307",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文本质是应用，而非智能体构建。** 论文的核心贡献是提出了一种名为 `LLM-Auction` 的**生成式拍卖机制**，用于解决“LLM原生广告”这一特定商业场景下的货币化问题。其本质是**经济学和机制设计**的研究，而非人工智能智能体的研究。论文将LLM作为一个可优化的组件，使其输出能够满足拍卖机制的目标（如广告商价值和用户体验）。这完全符合第一步排除标准中的“**非演化型应用**”：将LLM作为工具应用到特定领域（广告/经济学）去解决该领域的问题。 2.  **缺乏核心关注点（第二步）：未涉及Agentic AI的核心能力。** 论文的研究焦点是**拍卖机制的效率和激励属性**，而不是智能体的自主能力。摘要中完全没有提及任何与我的研究焦点相关的关键词或概念，例如： *   **单智能体能力**: `Planning` (规划), `Tool Use` (工具使用), `Memory` (记忆), `Self-Reflection` (自我反思)。 *   **多智能体交互**: `Collaboration` (协作), `Communication` (通信), `Negotiation` (博弈)。 *   **自我演化**: `Self-Improvement` (自我完善), `Iterative Improvement` (迭代改进)。 论文中的LLM是一个被动执行生成任务的模型，其行为由预设的拍卖机制和优化算法（IRPO）决定，不具备任何自主性。 3.  **对特殊情况的澄清（第四步）：IRPO算法不等于自我演化。** 论文提出了 `Iterative Reward-Preference Optimization (IRPO)` 算法来优化LLM。这看起来像是一种“迭代改进”，但它是一种**离线的模型训练/微调方法**，旨在让模型学会生成符合经济目标的文本。它**不是**一个智能体在运行时通过与环境交互、进行经验学习或自我反思来动态完善自身能力的“**自我演化**”机制。因此，这不属于“自我演化的应用”这一例外情况。 **总结**: 该论文的学术贡献在于**设计了一个新颖的、基于LLM的经济拍卖机制**，属于交叉学科研究（AI + Economics）。虽然它使用了LLM，但其研究目标和核心方法论与我的“LLM智能体及其演化”课题（关注智能体的自主性、协作与演化）完全不同。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#84",
        "title": "From Lab to Reality: A Practical Evaluation of Deep Learning Models and LLMs for Vulnerability Detection",
        "link": "/arxiv/2512.10485",
        "arxiv_id": "2512.10485",
        "authors": "Chaomeng Lu, Bert Lagaisse",
        "subjects": "Cryptography and Security, Machine Learning, Software Engineering",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.964241",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步): 论文本质是应用评估，而非智能体构建。** 该论文的核心贡献是**评估**现有的深度学习模型和预训练LLM在“漏洞检测”这一特定任务上的表现。作者构建了一个新的数据集（VentiVul）和一个评估框架，旨在揭示当前模型在真实世界场景中的局限性。这完全符合筛选标准中的**排除规则1：非演化型应用**。论文并未提出任何新的LLM智能体构建、改进或演化的方法论，而是将LLM作为工具应用于安全领域。 2.  **排除标准 (第三步): 论文焦点属于安全与对齐范畴。** 论文的研究主题是“漏洞检测”，这是软件安全领域的核心问题。根据您的筛选标准，只要论文的主要贡献是关于`Security`（安全），就应一律排除。这篇论文的整个研究都围绕着一个安全应用展开，因此触发了明确的排除红线。 3.  **缺乏核心关注点 (第二步): 未涉及Agentic AI的核心能力。** 论文中完全没有提及您所关注的核心范式和能力，如`Agentic AI`、`Planning`、`Tool Use`、`Self-Reflection`、`Multi-Agent`或`Self-Evolving`。文中的LLM（如GPT-4o）被用作一个静态的、端到端的分类器来判断代码是否存在漏洞，而不是一个具备自主规划、工具使用或自我演化能力的智能体。 综上所述，该论文是一篇典型的应用领域评估论文，其核心贡献在于安全领域的评测方法和数据集，而非LLM智能体本身的架构、能力或演化机制。因此，它严格地落在了您研究范围的之外。"
    },
    {
        "index": "#85",
        "title": "Maximum Risk Minimization with Random Forests",
        "link": "/arxiv/2512.10445",
        "arxiv_id": "2512.10445",
        "authors": "Francesco Freni, Anya Fries, Linus Kühne, Markus Reichstein, Jonas Peters",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning, Methodology",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.964762",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出一种名为“最大风险最小化”的算法，并将其应用于随机森林模型，以提升模型在分布外数据上的泛化能力。这是一个典型的**机器学习算法**研究，专注于提升预测模型的鲁棒性。 - **与我的研究目标对比**: 我的核心目标是筛选关于**构建、改进或演化LLM智能体**的论文。这篇论文完全没有涉及“智能体”的概念。它研究的不是自主规划、工具使用、记忆或自我演化的实体，而是一个静态的、用于回归任务的统计模型（随机森林）。因此，根据第一步的排除标准，它属于“非Agentic的推理”范畴，应被排除。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其关键词是 `Random Forests`, `Regression`, `Out-of-distribution (OOD) generalization`, `Risk Minimization`，这些都属于传统机器学习和统计学习理论的领域。 3.  **第三步：排除标准** - 虽然这篇论文不涉及安全对齐或多模态，但第一步的核心判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“regret”（遗憾）一词虽然在强化学习中常见，但在此处的定义是“相对于最佳预测器的超额风险”，这是一个统计学习理论中的概念，与智能体在环境中通过交互学习和规划无关。论文没有提出任何关于智能体如何进行多步推理或规划的框架。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。它提出的是一种新的训练目标函数，模型在训练完成后是固定的，不会通过经验进行自我完善和迭代。 **最终决策**: 综合以上分析，这篇论文是一篇关于提升传统机器学习模型（随机森林）鲁棒性的研究，其本质是统计机器学习算法的改进，与“LLM智能体及其演化”这一研究课题的核心目标——构建和演化具有自主能力的智能体——完全无关。因此，应将其排除。"
    },
    {
        "index": "#93",
        "title": "Tracking large chemical reaction networks and rare events by neural networks",
        "link": "/arxiv/2512.10309",
        "arxiv_id": "2512.10309",
        "authors": "Jiayu Weng, Xinyi Zhu, Jing Liu, Linyuan Lü, Pan Zhang, Ying Tang",
        "subjects": "Molecular Networks, Machine Learning, Biological Physics",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.973883",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一种**更高效的神经网络方法**，用于解决化学动力学、系统生物学和流行病学领域中的一个特定数学难题——化学主方程。它通过改进优化算法（自然梯度下降）和采样策略来加速计算并提高精度。这完全符合**“非演化型应用”**的排除标准。该研究是将神经网络作为一种计算工具，应用于一个特定的科学领域，其目标是解决该领域的问题，而不是构建、改进或演化LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 或 `Self-Reflection` 等任何核心概念。论文中的“自回归神经网络”是一种模型架构，而非智能体框架。 3.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文不涉及LLM的推理或规划。 *   **自我演化的应用**: 这是唯一可能产生模糊的地方，但结论依然是排除。您规定，如果论文的核心是提出一种**新的“自我演化”机制**，即使应用在特定领域也应保留。然而，这篇论文提出的“演化”是指算法层面的优化（如使用自然梯度下降）和采样策略的改进，这些是提升计算效率的工程方法，**并非智能体通过经验、反思或环境反馈进行自我完善和迭代的机制**。该系统本身不具备学习、适应或自我改进的能力，它只是一个被更有效算法驱动的计算工具。因此，这个例外情况不适用。 **最终决策**: 该论文是一篇典型的计算化学/计算生物学交叉研究，其本质是应用神经网络技术解决特定科学领域的计算挑战。它与“LLM智能体及其演化”这一研究课题的核心目标——构建、改进或演化具有自主性、规划能力和演化能力的智能体——完全无关。因此，应果断排除。"
    },
    {
        "index": "#90",
        "title": "RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI",
        "link": "/arxiv/2512.10394",
        "arxiv_id": "2512.10394",
        "authors": "Weifan Guan, Huasen Xi, Chenxiao Zhang, Aosheng Li, Qinghao Hu, Jian Cheng",
        "subjects": "Robotics, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.972420",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 **RoboNeuron 的“通用部署框架”**。摘要中明确指出，该研究旨在解决当前具身AI系统面临的“严重工程障碍”，如“跨场景适应性差”、“模块间耦合僵化”和“推理加速碎片化”。其提出的解决方案是一个“高度模块化的架构”，通过“自动化工具”来简化开发，并建立一个“系统性的基准测试平台”。这些描述都清晰地指向了**基础设施和工程部署**的范畴，而非智能体核心能力的构建或演化。这直接命中了筛选标准中的“排除：基础设施”条款。 2.  **第二步：正面指标分析** 论文确实提到了一些正面指标，例如“enabling the LLM to dynamically orchestrate underlying robotic tools”，这涉及了“工具使用”。然而，论文的核心贡献**并非提出一种新的工具使用方法或智能体规划算法**，而是构建了一个**框架和工具**，让LLM能够更方便地调用已有的机器人工具。它的创新点在于工程实现和系统集成，而非智能体的认知或演化机制。 3.  **第三步：排除标准分析** 论文的主要贡献不涉及安全与对齐，因此没有触发该排除项。虽然论文提到了“Vision-Language-Action (VLA) models”，但它们是作为被框架集成的“组件”出现的，研究的核心是框架本身，而不是VLA模型或其视觉能力。这符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”的例外情况。 4.  **第四步：处理特殊和模糊情况** 论文不涉及自我演化的应用。在推理/规划方面，它没有提出新的智能体推理框架（如ReAct或ToT的变体），而是专注于如何将LLM的推理能力“接入”到机器人执行系统（ROS）中。 **最终决策：** 综合以上分析，尽管这篇论文对于推动具身AI的实际应用具有重要价值，但其本质是**一个连接基础模型与机器人操作系统的工程框架和基础设施**。它研究的是“如何更好地部署和集成”，而不是“如何让智能体本身变得更智能、更会协作或能够自我演化”。这与您“筛选出那些核心贡献在于构建、改进或演化 LLM智能体的论文”的核心目标不符。因此，应将其排除。"
    },
    {
        "index": "#86",
        "title": "Clustered Federated Learning with Hierarchical Knowledge Distillation",
        "link": "/arxiv/2512.10443",
        "arxiv_id": "2512.10443",
        "authors": "Sabtain Ahmad, Meerzhan Kanatbekova, Ivona Brandic, Atakan Aral",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.965255",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献识别**: 这篇论文的核心贡献是提出了一种名为 `CFLHKD` 的新颖方案，用于改进**聚类联邦学习**。它通过分层知识蒸馏的方法，在保护隐私和解决数据异构性的同时，提升了集群个性化模型和全局模型的性能。 - **与核心目标的匹配度**: 您的核心目标是筛选关于“构建、改进或演化 **LLM智能体**”的论文。而这篇论文的研究对象是**联邦学习**这一分布式机器学习范式，而非LLM智能体。它提出的是一种模型训练和聚合的算法优化，属于机器学习系统和基础设施的范畴。 - **应用排除规则**: 该论文完全符合第一步的排除标准 **1. 非演化型应用**。它提出了一种新的机器学习训练方法（`CFLHKD`），并将其应用于联邦学习领域，以解决该领域的数据异构性和效率问题。它没有构建或改进任何具有自主规划、工具使用或反思能力的智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现您列出的任何核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。 - 虽然论文提到了 \"inter-cluster knowledge sharing\"（集群间知识共享），但这指的是通过**知识蒸馏**这一模型压缩技术在不同模型之间传递信息，而不是智能体之间自主的通信、协作或社会学习。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全对齐或多模态等排除领域，但第一步的判断已经足够明确。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及推理/规划或自我演化的特殊情况。 **最终决策**: 综合以上分析，这篇论文的本质是**机器学习系统/算法**研究，专注于优化联邦学习框架。它虽然涉及多个“客户端”和“集群”，但这些是分布式计算中的概念，而非具有自主认知能力的“智能体”。论文的核心贡献与“LLM智能体及其演化”这一课题完全无关，因此应被排除。"
    },
    {
        "index": "#95",
        "title": "Neuronal Attention Circuit (NAC) for Representation Learning",
        "link": "/arxiv/2512.10282",
        "arxiv_id": "2512.10282",
        "authors": "Waleed Razzaq, Izis Kankaraway, Yun-Bo Zhao",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.974785",
        "filter_reason": "这篇论文的核心贡献是提出了一种新的、用于表征学习的连续时间注意力机制（NAC）。我的研究目标是筛选关于构建、改进或演化LLM智能体的论文。 根据筛选标准的第一步，这篇论文的本质属于“非演化型应用”，应予以排除。具体分析如下： 1.  **核心贡献不符**: 论文的核心是提出一种新颖的注意力机制（NAC），这是一种底层的神经网络架构创新，旨在改进表征学习，特别是在连续时间模型中。它没有涉及构建、改进或演化任何形式的LLM智能体。 2.  **属于应用型研究**: 论文将其提出的NAC机制应用到了不规则时间序列分类、自动驾驶车辆车道保持和工业预测等领域。这正是“将一个已有的框架（这里是新提出的注意力机制）作为工具应用到特定领域去解决该领域的问题”的典型例子，符合第一步的排除标准。 3.  **缺乏核心关注点**: 论文的摘要和标题中完全没有出现我的核心关注点，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` (智能体记忆), `Self-Reflection` 等任何相关关键词。文中提到的“memory”是指一种技术方案（Top-K pairwise concatenation）来提高计算效率，而非智能体的记忆模块。 综上所述，该论文的研究焦点是神经网络架构层面的注意力机制，而非智能体层面的构建、协作或演化。因此，它不符合我的研究范围。"
    },
    {
        "index": "#88",
        "title": "Diffusion differentiable resampling",
        "link": "/arxiv/2512.10401",
        "arxiv_id": "2512.10401",
        "authors": "Jennifer Rosina Andersson, Zheng Zhao",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.966150",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“扩散可微分重采样”的新方法，用于解决顺序蒙特卡洛（Sequential Monte Carlo, 如粒子滤波）中的重采样问题。这是一个典型的计算统计学和机器学习理论领域的研究，其目标是改进一种基础的统计算法。论文的核心是**统计推断方法**，而不是**构建、改进或演化LLM智能体**。因此，根据第一步的核心判断标准，这篇论文应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与我的研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。虽然它提到了“diffusion model”，但在这里，扩散模型是作为一种工具来辅助实现可微分重采样，而不是作为智能体的核心组件或研究对象。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这篇论文的研究内容（粒子滤波、参数估计）属于我的研究焦点之外。它不属于安全与对齐或多模态等特定排除类别，但其根本问题域与LLM智能体无关。 4.  **第四步：处理特殊和模糊情况** 此处不涉及特殊和模糊情况。论文既不是关于智能体的推理/规划框架，也不是关于自我演化机制的应用。 **最终决策**： 综合以上分析，这篇论文的本质是关于计算统计学中的一种新算法，与“LLM智能体及其演化”这一研究课题的核心目标——即构建、改进或演化智能体本身——完全无关。因此，最终判断为 **False (排除)**。"
    },
    {
        "index": "#94",
        "title": "FLARE: A Wireless Side-Channel Fingerprinting Attack on Federated Learning",
        "link": "/arxiv/2512.10296",
        "arxiv_id": "2512.10296",
        "authors": "Md Nahid Hasan Shuvo, Moinul Hossain, Anik Mallik, Jeffrey Twigg, Fikadu Dagefu",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.974349",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种名为FLARE的**侧信道攻击方法**，用于在联邦学习（FL）环境中，通过分析加密的无线流量来**推断客户端的深度学习模型架构（如CNN、RNN）**。这本质上是一篇关于**网络安全和隐私**的研究，其目标是揭示和利用系统漏洞，而不是构建、改进或演化LLM智能体。因此，它不符合我筛选的核心目标。 2.  **排除标准 (第三步):** 这是最直接的排除依据。论文的主要贡献明确属于 **`Security` (安全)** 领域。根据我的筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` ... 一律排除”。这篇论文完全命中了`Security`这一排除项。 3.  **正面指标缺失 (第二步):** 论文的摘要和标题中完全没有出现我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文讨论的是CNN和RNN，而非LLM，并且其研究范式是安全攻击，而非智能体框架。 4.  **研究焦点不符:** 我的研究焦点是Agentic AI的构建与演化，即如何让智能体变得更自主、更强大、更能协作和自我完善。而这篇论文的焦点是**如何破坏一个分布式学习系统的机密性**。两者在研究目标和方法论上存在根本性的不同。 综上所述，尽管这篇论文涉及了深度学习模型（CNN/RNN），但其核心贡献是安全攻击，与“LLM智能体及其演化”的研究课题完全无关。因此，最终决策为排除。"
    },
    {
        "index": "#97",
        "title": "Error Analysis of Generalized Langevin Equations with Approximated Memory Kernels",
        "link": "/arxiv/2512.10256",
        "arxiv_id": "2512.10256",
        "authors": "Quanjun Lang, Jianfeng Lu",
        "subjects": "Machine Learning, Machine Learning, Dynamical Systems, Numerical Analysis, Probability",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.975801",
        "filter_reason": "这篇论文完全不符合我的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文本质不符** - **核心贡献分析**: 这篇论文的核心贡献是对“广义朗之万方程”进行数学上的误差分析。它属于应用数学或理论物理学的范畴，研究的是随机动力系统的数学性质，如轨迹差异的衰减率、扰动界限等。 - **与LLM智能体的关系**: 论文中完全没有提及LLM（大语言模型）、智能体、规划、工具使用或任何与Agentic AI相关的概念。它研究的“记忆”是指数学模型中的“记忆核”，这是一个描述系统历史状态如何影响当前状态的函数，与人工智能智能体的认知记忆机制完全无关。 - **结论**: 根据第一步的筛选标准，这篇论文既不是关于构建LLM智能体，也不是关于改进或演化智能体。它属于一个完全不同的研究领域，因此应被**排除**。 2.  **第二步：正面指标——完全不匹配** - 论文中没有出现任何我关注的核心范式，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`。 - 论文中也没有涉及任何智能体能力，如 `Planning`, `Tool Use`, `Self-Reflection` 等。如前所述，文中的“memory”是数学术语，而非智能体能力。 3.  **第三步：排除标准——不属于特定排除项，但超出研究范围** - 虽然这篇论文不直接关于安全对齐或多模态，但它从根本上就不属于人工智能研究的范畴，因此更不可能符合我的研究目标。 4.  **第四步：特殊和模糊情况——不适用** - 这篇论文不涉及任何与智能体相关的推理或规划，更没有提出任何“自我演化”机制。 **最终决策**: 综合以上所有分析，这篇论文是一篇纯粹的数学/理论物理论文，其研究对象、方法和贡献都与“LLM智能体及其演化”这一课题毫无关联。因此，最终判断为 **False**，应予以排除。"
    },
    {
        "index": "#92",
        "title": "Residual subspace evolution strategies for nonlinear inverse problems",
        "link": "/arxiv/2512.10325",
        "arxiv_id": "2512.10325",
        "authors": "Francesco Alemanno",
        "subjects": "Optimization and Control, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.973364",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“残差子空间演化策略”的新型**优化算法**，用于解决“非线性逆问题”。这是一个典型的计算数学和优化领域的研究。它完全没有涉及构建、改进或演化任何形式的LLM智能体。因此，根据第一步的核心判断标准，这篇论文应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中不包含任何我关注的核心范式或智能体能力。虽然标题中出现了“evolution strategies”（演化策略），但这在优化领域是一个专有名词，指的是一种基于种群迭代的随机优化方法，与我所关注的“自我演化的智能体”概念完全不同。后者指智能体通过经验、反思来提升自身能力，而前者是一种数学搜索算法。论文中未提及 `LLM-based Agents`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Reflection` 等任何相关关键词。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文的研究焦点是数学优化，不属于安全对齐或多模态等排除领域，但它本身就在我的研究焦点（Agentic AI）之外。 4.  **第四步：处理特殊和模糊情况** 这篇论文恰好触及了一个关键的模糊点：**“演化”一词的含义**。在“LLM智能体及其演化”的语境下，“演化”指的是智能体层面的自我完善和能力迭代。而在这篇论文中，“演化策略”是一种算法层面的优化技术。因此，这篇论文属于“非Agentic的推理”，它研究的是如何改进一个数学求解过程，而不是一个智能体的自主推理或规划框架。 **最终决策**: 综合以上分析，该论文是一篇纯粹的优化算法研究，其目标是为非线性逆问题提供一种更高效的求解器。它与LLM智能体、多智能体系统或智能体的自我演化机制无任何关联。因此，它完全不符合我的研究目标，应被排除。"
    },
    {
        "index": "#96",
        "title": "Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters",
        "link": "/arxiv/2512.10271",
        "arxiv_id": "2512.10271",
        "authors": "Shruti Dongare, Redwan Ibne Seraj Khan, Hadeel Albahar, Nannan Zhao, Diego Melendez Maita, Ali R. Butt",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.975287",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是基础设施研究，而非智能体构建。** 论文的核心贡献是提出一个名为 `RLTune` 的**调度框架**，用于在异构GPU集群上动态分配深度学习（DL）任务。其目标是优化作业完成时间（JCT）、排队延迟和资源利用率等**系统级指标**。这完全属于**基础设施**和**部署优化**的研究范畴，是我在第一步筛选标准中明确要求排除的类型。论文的本质是解决资源管理问题，而不是构建或演化一个具有自主性的LLM智能体。 2.  **第二步：缺乏正面指标。** 论文虽然使用了强化学习（RL），但其应用场景是任务调度，而非智能体的决策。论文中完全没有提及任何与我的核心关注点相关的概念，例如 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Tool Use`、`Memory` 或 `Self-Reflection`。它所解决的“规划”问题是资源分配的优化问题，而不是智能体为完成复杂任务而进行的自主规划。 3.  **第四步：特殊情况分析。** - **推理/规划**: 论文中的“规划”是系统层面的作业调度规划，与智能体为实现目标而进行的多步推理和行动规划有本质区别。它属于优化算法的范畴，不符合我对智能体规划的定义。 - **自我演化**: 论文中的RL模型是基于历史数据“离线训练”的，部署后是一个固定的策略。它不具备在运行中通过经验、反思或环境反馈进行自我完善和迭代的“自我演化”能力。 综上所述，该论文是一项优秀的系统研究，但它聚焦于底层计算资源的管理和优化，与我的研究目标——“构建、改进或演化LLM智能体”——完全无关。因此，根据筛选标准，应予以排除。"
    },
    {
        "index": "#98",
        "title": "Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective",
        "link": "/arxiv/2512.10244",
        "arxiv_id": "2512.10244",
        "authors": "Tian Liu, Anwesha Basu, James Caverlee, Shu Kong",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.976270",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是模型微调方法，而非智能体构建。** 论文的核心贡献是提出了一种名为 \"Stage-Wise Finetuning with Temperature Tuning (SWIFT)\" 的微调方法。该方法旨在解决半监督少样本学习（SSFSL）问题，通过改进微调过程来提升视觉语言模型（VLM）在自动标注任务上的性能。这完全属于“非演化型应用”的排除范畴，因为它将一个已有的模型（VLM）作为工具，应用并优化于一个特定的机器学习任务（自动标注），而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **正面指标缺失 (第二步): 缺乏任何与智能体相关的核心概念。** 论文的摘要和标题中完全没有出现您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其研究焦点是模型训练层面的技术问题（如softmax分布过于平坦），而非智能体的行为或架构。 3.  **明确触及排除标准 (第三步): 论文核心是多模态与视觉研究。** 论文明确指出其研究对象是 \"Vision-Language Models (VLMs)\"，并在多个基准数据集上进行实验。根据您的筛选标准，“`Vision`, `Vision-Language`, `MLLMs`, `VLMs`...一律排除”，除非它们仅被用作智能体感知环境的工具。在这篇论文中，VLM是研究的核心对象，而不是智能体框架中的一个组件，因此完全符合排除条件。 4.  **特殊情况不适用 (第四步):** 论文不涉及智能体的规划或自我演化机制。其提出的“Stage-Wise”（分阶段）指的是模型训练的流程，而非智能体在执行任务中的多步规划或自我迭代完善。 **总结:** 该论文是一篇典型的机器学习领域的研究，其核心贡献是针对特定任务（半监督少样本学习）的模型微调技术。尽管它使用了强大的VLM模型，但其研究目标和方法论与“LLM智能体及其演化”这一课题的核心——即构建具有规划、工具使用、协作和自我演化能力的自主智能体——毫无关联。因此，应果断排除。"
    },
    {
        "index": "#100",
        "title": "Galaxy Phase-Space and Field-Level Cosmology: The Strength of Semi-Analytic Models",
        "link": "/arxiv/2512.10222",
        "arxiv_id": "2512.10222",
        "authors": "Natalí S. M. de Santi, Francisco Villaescusa-Navarro, Pablo Araya-Araya, Gabriella De Lucia, Fabio Fontanot, Lucia A. Perez, Manuel Arnés-Curto, Violeta Gonzalez-Perez, Ángel Chandro-Gómez, Rachel S. Somerville, Tiago Castro",
        "subjects": "Cosmology and Nongalactic Astrophysics, Astrophysics of Galaxies, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.977362",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 这篇论文的核心贡献是提出了一种结合图神经网络（GNN）和矩神经网络的机器学习模型，用于从星系相空间数据中精确估计宇宙学参数（$Ω_{\\rm m}$）。 - **判断**: 这完全符合**排除标准中的“非演化型应用”**。论文将一个机器学习模型（GNN，而非LLM）作为工具，应用到宇宙学这一特定领域，以解决该领域的参数推断问题。它研究的核心是宇宙学模型和预测方法，而不是构建、改进或演化LLM智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标。例如，没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等任何关键词或概念。这进一步确认了其与您研究方向的偏离。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文没有触及安全、对齐或多模态等排除领域，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - 论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何自我演化机制。因此，特殊情况的例外条款不适用。 5.  **第五步：最终决策** - **综合分析**: 该论文是一篇典型的交叉学科应用研究，其本质是利用机器学习技术（GNN）解决天体物理学问题。它的研究对象是宇宙和星系，而不是人工智能智能体。论文的核心目标是提升宇宙学参数的估计精度，而非探索智能体的构建、协作或演化机制。 - **最终结论**: 论文的研究领域（宇宙学）和核心技术（GNN）均与您关于“LLM智能体及其演化”的研究目标不符。因此，应予以排除。"
    },
    {
        "index": "#103",
        "title": "The Interplay of Statistics and Noisy Optimization: Learning Linear Predictors with Random Data Weights",
        "link": "/arxiv/2512.10188",
        "arxiv_id": "2512.10188",
        "authors": "Gabriel Clara, Yazan Mash'al",
        "subjects": "Machine Learning, Machine Learning, Computation",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.983949",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是对**线性回归模型**中带有随机数据权重的梯度下降算法进行理论分析。它研究了不同噪声分布对优化轨迹、隐式正则化和收敛性的影响。这本质上是一篇关于**优化理论**和**统计学习理论**的论文，其研究对象是基础的线性模型和优化算法，而非LLM智能体。因此，它直接排除了“保留”的可能性，因为它不涉及构建、改进或演化LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我研究焦点相关的正面指标。它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 等任何核心范式或智能体能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文没有直接触及“安全与对齐”或“多模态与视觉”等排除标准，但它本身的研究领域（优化理论）已经完全超出了“LLM智能体及其演化”的范畴。 4.  **第四步：处理特殊和模糊情况** 这篇论文的情况并不模糊。它不属于“推理/规划”的特殊情况，因为它分析的是优化算法的数学行为，而不是智能体在复杂任务中的自主规划或推理过程。它更不属于“自我演化的应用”，因为它没有提出任何让智能体自我完善的机制。 **最终决策**: 综合以上分析，该论文的核心贡献是**对传统机器学习模型（线性回归）的优化算法进行理论分析**，与我的研究目标“LLM智能体及其演化”完全无关。它既不涉及LLM，也不涉及智能体的任何核心能力（规划、工具使用、记忆、协作、自我演化等）。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#99",
        "title": "Design Space Exploration of DMA based Finer-Grain Compute Communication Overlap",
        "link": "/arxiv/2512.10236",
        "arxiv_id": "2512.10236",
        "authors": "Shagnik Pal, Shaizeen Aga, Suchita Pati, Mahzabeen Islam, Lizy K. John",
        "subjects": "Distributed, Parallel, and Cluster Computing, Hardware Architecture, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.976774",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是关于分布式机器学习系统的**基础设施优化**，而非构建或演化LLM智能体。摘要明确指出，该研究旨在解决分布式ML训练和推理中的“计算通信重叠”问题，提出了一种名为FiCCO的更细粒度的重叠技术，并利用GPU DMA引擎来最小化通信争用。这完全符合筛选标准中第一步的排除规则：“排除主要关注模型基础设施、部署优化、硬件加速的研究”。论文的目标是提升系统运行效率（1.6x speedup），而不是赋予LLM智能体新的能力或演化机制。 2.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现任何与我核心关注点相关的正面指标。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何关键词。其讨论的“schedules”（调度）是系统层面的任务调度，而非智能体的自主规划。 3.  **排除标准确认 (第三步):** 虽然论文不涉及安全对齐或多模态，但它精准地命中了“基础设施”这一排除类别。 4.  **特殊规则不适用 (第四步):** 论文中的“规划”概念是系统层面的计算与通信任务调度，而非智能体为达成目标而进行的自主规划。因此，它属于“排除”的情况。论文也未提出任何“自我演化”机制。 **总结:** 该论文的本质是系统层面的性能优化研究，旨在通过改进硬件（DMA）和软件调度策略来加速分布式ML工作负载。它不涉及任何关于智能体行为、架构、协作或演化的内容，因此与我的研究课题“LLM智能体及其演化”完全无关。"
    },
    {
        "index": "#106",
        "title": "Inference for Batched Adaptive Experiments",
        "link": "/arxiv/2512.10156",
        "arxiv_id": "2512.10156",
        "authors": "Jan Kemper, Davud Rostam-Afschar",
        "subjects": "Econometrics, Machine Learning, Methodology",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.985395",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为 BOLS (batched ordinary least squares) 的统计检验方法，用于在经济学等领域的“自适应实验”中进行因果推断。这本质上是一篇计量经济学或统计学领域的论文，其研究目标是解决特定领域（经济学实验）的因果推断问题，而非构建、改进或演化LLM智能体。因此，根据第一步的排除标准“非演化型应用”，该论文应被排除。 2.  **正面指标 (第二步):** 论文摘要中完全没有出现任何与我的研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。 3.  **排除标准 (第三步):** 虽然不直接涉及安全与对齐或多模态，但其研究领域（计量经济学、因果推断）本身就在我的核心关注点之外。 4.  **特殊与模糊情况 (第四步):** 论文标题中的 \"Adaptive\" (自适应) 是一个关键的混淆点。在此论文的上下文中，\"Adaptive Experiments\" 指的是一种实验设计方法，即根据实验过程中收集到的数据动态调整后续的实验分配策略。这与AI领域中智能体的“自我演化”或“自适应”能力是完全不同的概念。该论文并未提出任何与智能体自我演化相关的机制。 **结论:** 该论文是一篇纯粹的计量经济学方法论文，与“LLM智能体及其演化”这一研究课题无任何关联。其核心贡献是统计方法，而非智能体框架或演化机制。因此，最终判断为排除。"
    },
    {
        "index": "#105",
        "title": "The 2025 Foundation Model Transparency Index",
        "link": "/arxiv/2512.10169",
        "arxiv_id": "2512.10169",
        "authors": "Alexander Wan, Kevin Klyman, Sayash Kapoor, Nestor Maslej, Shayne Longpre, Betty Xiong, Percy Liang, Rishi Bommasani",
        "subjects": "Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.984940",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是构建并发布了一个“基础模型透明度指数”，用于评估和量化基础模型开发公司（如Alibaba, DeepSeek, xAI）的透明度实践。它本质上是一份关于AI产业治理、政策和公司实践的评估报告，而不是关于构建、改进或演化LLM智能体的方法论或新框架。因此，根据第一步的排除规则，这篇论文的核心不是关于Agentic AI、Multi-Agent Systems或Self-Evolving，应直接排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。其讨论的焦点是“透明度”、“数据获取”、“计算资源”和“政策干预”，与智能体的内在能力或演化机制无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这是排除该论文的最关键依据。论文的核心概念是“Transparency”（透明度）。透明度是“Interpretability”（可解释性）和“Explainability”（XAI）的核心组成部分，而这些都是您明确指定的排除标准。该研究旨在揭示模型开发过程中的信息缺失，属于AI安全、治理和对齐的宏观范畴，而非Agentic AI的技术实现。 **总结:** 该论文是一篇关于AI治理和产业政策的研究，其核心贡献是评估公司的透明度，这与您的研究目标“构建、改进或演化LLM智能体”完全不符。它属于您明确排除的“安全与对齐”领域（特别是可解释性/透明度方向），并且缺乏任何与智能体规划、工具使用、多智能体协作或自我演化相关的技术内容。因此，最终决策为 **False**。"
    },
    {
        "index": "#101",
        "title": "On Learning-Curve Monotonicity for Maximum Likelihood Estimators",
        "link": "/arxiv/2512.10220",
        "arxiv_id": "2512.10220",
        "authors": "Mark Sellke, Steven Yin",
        "subjects": "Statistics Theory, Machine Learning, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.983003",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是**理论统计学和机器学习理论**。论文的主题是“学习曲线单调性”和“最大似然估计器”，旨在为特定统计模型（如高斯分布、伽马分布）在增加数据量时性能单调提升提供理论保证。这是一个关于算法基础属性的数学证明。 论文中提到的LLM（GPT-5.2 Pro）的角色是**一个用于生成数学证明的工具**。作者利用LLM强大的推理能力来辅助发现和构建复杂的数学证明，但论文本身并没有提出任何关于如何构建、改进或演化这个LLM智能体的新方法或框架。 因此，这篇论文完全符合**排除标准1：非演化型应用**。它将一个强大的LLM作为工具，应用到了理论数学这个特定领域去解决该领域的问题（证明数学猜想）。论文的核心贡献在于数学证明的结果，而非使用LLM的方法论。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现您关注的核心范式、智能体能力或演化机制等关键词。虽然LLM进行了“推理”，但这并非在“Agentic”框架下的自主规划或工具使用，而是作为黑箱工具被人类研究者“提示”以完成特定任务。因此，所有正面指标均不满足。 **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不涉及安全与对齐或多模态等排除标准，但它已在第一步被明确排除。 **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文中的推理是LLM内部发生的、用于生成数学证明的过程。论文并未提出一种新的智能体推理框架（如ReAct或ToT），而是报告了使用现有模型完成一项复杂任务的结果。这属于“排除”情况，即它不是关于智能体如何进行规划，而是关于LLM基础能力的一种应用展示。 *   **自我演化的应用**: 论文不涉及任何自我演化机制。LLM本身没有被迭代、改进或演化。 **第五步：最终决策** 综合以上分析，这篇论文的本质是**利用LLM作为高级计算工具进行数学理论研究**。它的核心贡献在于统计学理论，而非LLM智能体的构建、多智能体系统或自我演化机制。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标背道而驰。因此，最终决策为**排除**。"
    },
    {
        "index": "#104",
        "title": "Semantic-Aware Confidence Calibration for Automated Audio Captioning",
        "link": "/arxiv/2512.10170",
        "arxiv_id": "2512.10170",
        "authors": "Lucas Dunker, Sai Akshay Menta, Snigdha Mohana Addepalli, Venkata Krishna Rayalu Garapati",
        "subjects": "Sound, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.984410",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种**用于自动音频字幕的置信度校准框架**。它通过在Whisper模型上增加一个置信度预测头，并使用语义相似性（而非传统的n-gram匹配）来重新定义预测的“正确性”，从而提高了模型预测的可靠性。 这完全符合**排除标准中的“非演化型应用”**。该研究将一个LLM（Whisper）作为基础工具，应用于“音频字幕”这一特定领域，旨在解决该领域模型输出“过度自信”的问题。其核心是改进一个特定应用的性能和可靠性，而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式和能力。它没有涉及`Agentic AI`、`Multi-Agent Systems`或`Self-Evolving`等概念。模型本身不具备`Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）等任何智能体能力。它是一个从音频输入到文本输出的直接映射模型，没有自主决策或与环境交互的循环。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的。论文的核心是“置信度校准”，这直接关系到模型的**可靠性**和**可预测性**。这些是**安全与对齐**研究范畴下的关键议题。根据您的筛选标准，只要论文的主要贡献是关于`Safety`、`Security`、`Interpretability`（可解释性）等，就应被排除。本文的置信度校准本质上就是一种提升模型可解释性和可靠性的技术。 4.  **第四步：处理特殊和模糊情况** 本文不涉及智能体的规划或推理，也不涉及任何自我演化机制，因此特殊情况不适用。 **最终决策**: 综合以上分析，这篇论文的本质是针对特定任务（音频字幕）的模型校准和可靠性提升，属于应用层研究和安全对齐的交叉领域。它并未提出任何关于LLM智能体构建、多智能体交互或自我演化的新方法或框架。因此，它严格地落在了您研究范围的排除区域之外。"
    },
    {
        "index": "#91",
        "title": "D2M: A Decentralized, Privacy-Preserving, Incentive-Compatible Data Marketplace for Collaborative Learning",
        "link": "/arxiv/2512.10372",
        "arxiv_id": "2512.10372",
        "authors": "Yash Srivastava, Shalin Jain, Sneha Awathare, Nitin Awathare",
        "subjects": "Cryptography and Security, Artificial Intelligence, Distributed, Parallel, and Cluster Computing, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.972930",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是构建了一个名为 D2M 的**去中心化数据市场**。它是一个用于协作式机器学习的**基础设施**，旨在解决数据共享中的隐私、信任和激励问题。论文详细描述了其市场机制、区块链仲裁、链下计算层以及对抗行为的防御策略。这完全符合筛选标准中第一步的排除项：“主要关注模型基础设施、部署优化、硬件加速的研究”。论文的本质是构建一个系统/框架，而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中几乎不包含任何我关注的核心正面指标。 *   **核心范式**: 论文没有提及 `Agentic AI`, `LLM-based Agents`, `Self-Evolving` 等。它讨论的是 `Collaborative Learning`，但这是指数据层面的联邦学习，而非智能体间的社会协作。 *   **智能体能力**: 完全没有涉及 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等智能体核心能力。 *   **多智能体**: 论文中的“参与者”是数据买家和卖家，他们是经济模型中的角色，而不是在环境中自主行动、通信和协作的智能体。 *   **演化机制**: 论文没有提出任何 `Self-Improvement` 或 `Self-Refine` 的机制。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文涉及 `Privacy` 和 `Security`（对抗行为），但这些是作为其数据市场框架的**属性和保障**来讨论的，并非论文的**核心研究贡献**。论文的核心是市场机制本身，而不是安全或对齐技术。因此，它不完全属于“安全与对齐”的排除范畴，但第一步的“基础设施”排除项已经足够有力。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及“推理/规划”或“自我演化的应用”等特殊情况，因此此步不适用。 5.  **第五步：最终决策** 综合以上分析，这篇论文的核心是关于**机器学习的数据基础设施和经济机制**，而非**LLM智能体的构建与演化**。它研究的“协作”是数据提供方和计算方之间的协作，而非智能体社会中的协作。因此，该论文与我的研究目标“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#107",
        "title": "STARS: Semantic Tokens with Augmented Representations for Recommendation at Scale",
        "link": "/arxiv/2512.10149",
        "arxiv_id": "2512.10149",
        "authors": "Han Chen, Steven Zhu, Yingrui Li",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.986059",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出一个名为STARS的、用于大规模电子商务推荐的**Transformer框架**。其本质是**一个特定领域的应用系统**，而非一个通用的LLM智能体构建或演化方法。 根据筛选标准，这属于典型的 **“非演化型应用”**，应予以排除。具体来说： 1.  **应用领域明确**：论文的目标是解决电子商务推荐系统中的问题（如冷启动、用户意图漂移、低延迟）。 2.  **LLM作为工具使用**：论文中提到使用“LLM-derived attribute tags”（LLM衍生的属性标签），这表明LLM在这里是作为一个特征提取工具，用来增强商品表示，而不是作为决策、规划或行动的智能体核心。 3.  **关注基础设施**：论文明确强调了“tens-of-milliseconds latency constraints”（毫秒级延迟约束）和“latency-conscious two-stage retrieval pipeline”（延迟感知的两阶段检索管道），这表明其核心贡献包含了大量的基础设施和部署优化，这也是第一步中明确的排除项。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文几乎不包含您关注的核心范式和能力指标。 - 它提到了“dual-memory user embeddings”（双记忆用户嵌入），但这是一种用于区分长期偏好和短期意图的**静态模型架构设计**，与智能体在交互过程中动态存储和检索信息的“记忆”机制有本质区别。 - 论文完全没有涉及`Planning`（规划）、`Tool Use`（工具使用）、`Self-Reflection`（自我反思）、`Collaboration`（协作）、`Self-Improvement`（自我完善）等任何与Agentic AI相关的核心概念。 **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全对齐或多模态等排除标准，但这并不改变其在第一步就被排除的命运。 **第四步：处理特殊和模糊情况** - **推理/规划**：该论文不涉及智能体的自主规划或多步推理框架。其“sequential recommendation”（序列推荐）是基于用户历史行为序列进行预测，是一种模式匹配任务，而非智能体的主动规划。 - **自我演化的应用**：该论文没有提出任何自我演化机制。 **第五步：最终决策** 综合以上分析，这篇论文的核心是构建一个高效的、特定于电商领域的推荐系统。它虽然巧妙地利用了LLM的输出来增强特征，但其本质是应用驱动和基础设施优化的研究，与您“构建、改进或演化LLM智能体”的核心目标完全不符。因此，应将其排除。"
    },
    {
        "index": "#108",
        "title": "A Model-Guided Neural Network Method for the Inverse Scattering Problem",
        "link": "/arxiv/2512.10123",
        "arxiv_id": "2512.10123",
        "authors": "Olivia Tsang, Owen Melia, Vasileios Charisopoulos, Jeremy Hoskins, Yuehaw Khoo, Rebecca Willett",
        "subjects": "Computational Physics, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.986544",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 论文的核心贡献是提出了一种**将物理模型（一个可微分的正向求解器）与神经网络相结合的新方法**，用于解决“逆散射问题”这一特定的物理成像难题。其创新点在于将物理知识显式地融入机器学习框架，以提高在高度非线性散射情况下的重建质量。 - **是否符合保留标准**: 不符合。这篇论文的本质是**将一种机器学习技术（神经网络）作为工具，应用于一个特定的科学计算领域（物理成像）**，以解决该领域的问题。它没有构建、改进或演化任何形式的LLM智能体。 - **是否符合排除标准**: 完全符合。它属于**“非演化型应用”**。论文的目标是解决逆散射问题，而不是研究智能体本身的架构或能力。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的核心范式或关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全与对齐，也不涉及多模态与视觉（虽然其应用领域是成像，但论文本身是关于底层物理模型和算法的，而非视觉理解）。因此，这一步的排除标准不直接适用，但也没有提供任何保留的理由。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 论文中提到方法 \"progressively refines reconstructions\"（逐步完善重建结果）。这可能会被误解为一种“自我完善”。然而，根据筛选规则，这不符合“自我演化”的例外情况。这里的“逐步完善”是**针对特定任务（图像重建）的算法策略**，通过使用不同频率的测量数据来稳定恢复过程。它并非一个通用的、能够使智能体自身能力（如规划、工具使用）得到提升的“自我演化机制”。论文的核心是物理-神经网络的结合方法，而不是这个迭代过程本身。 **最终决策**: 综合以上分析，该论文是一篇典型的**应用驱动的机器学习研究**，专注于解决物理领域的特定问题。其核心贡献与“LLM智能体及其演化”这一研究课题完全无关。因此，应将其排除。"
    },
    {
        "index": "#112",
        "title": "LxCIM: a new rank-based binary classifier performance metric invariant to local exchange of classes",
        "link": "/arxiv/2512.10053",
        "arxiv_id": "2512.10053",
        "authors": "Tiago Brogueira, Mário A. T. Figueiredo",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.988368",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 论文的核心贡献是提出了一种名为 LxCIM 的**新的二元分类器性能评估指标**。该指标旨在解决现有指标（如AUROC）在特定问题（如局部类别交换不变性问题）上的局限性。 - **判断**: 这篇论文的本质是**机器学习模型评估方法**的研究，而非关于构建、改进或演化LLM智能体。它没有提出任何新的智能体框架、智能体能力或演化机制。 - **结论**: 根据第一步的排除规则，该论文属于“非演化型应用”的范畴。它提出的是一个评估工具（指标），并将其应用于一个特定领域（因果发现），而不是研究智能体本身。因此，应直接**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。 - 这进一步证实了该论文与您的研究课题无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全与对齐、多模态与视觉等排除标准，但这并不改变其在第一步就被排除的事实。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及智能体规划或自我演化机制，因此特殊情况的例外条款不适用。 **最终决策**: 综合以上分析，这篇论文的核心是关于机器学习评估理论的创新，具体为一种新的分类性能指标。它完全偏离了您关于“LLM智能体及其演化”的核心研究目标，即构建、改进或演化智能体本身。因此，该论文应被明确排除。"
    },
    {
        "index": "#111",
        "title": "Independent Density Estimation",
        "link": "/arxiv/2512.10067",
        "arxiv_id": "2512.10067",
        "authors": "Jiahao Liu",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.987925",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“独立密度估计”（IDE）的新方法，旨在提升**大规模视觉-语言模型**的**组合泛化**能力。其研究重点是改进模型如何理解句子中单词与图像特征的对应关系，从而更好地处理未见过的组合。这本质上是一项关于**多模态模型基础能力**的研究，而非关于构建、改进或演化LLM智能体。根据筛选标准，这属于“非演化型应用”和“非Agentic的推理”，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现我关注的核心范式（如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`）、智能体能力（如 `Planning`, `Tool Use`, `Memory`）或多智能体相关（如 `Collaboration`, `Communication`）的任何关键词或概念。因此，它不满足任何正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的。论文摘要开篇即明确研究对象是“Large-scale Vision-Language models”，并讨论了“image captioning”（图像字幕）和“conditioned image generation”（条件图像生成）等任务。这完全符合“多模态与视觉”的排除标准。该研究的核心是视觉-语言模型本身，而不是将其作为智能体感知环境的工具。 4.  **第四步：处理特殊和模糊情况** 论文中提到了“compositional inference method”（组合推理方法）。但这属于“非Agentic的推理”范畴。这里的“推理”是指模型内部如何组合单词和图像特征以实现泛化，而不是一个智能体在复杂任务中进行的自主规划、工具调用或多步决策（如ReAct或ToT框架）。因此，这不满足保留的例外条件。 **最终决策**: 综合以上分析，该论文的核心是改进视觉-语言模型的基础表示学习和泛化能力，与我的研究目标——“LLM智能体及其演化”（关注智能体的规划、工具使用、协作和自我演化机制）——完全无关。因此，这篇论文应被排除。"
    },
    {
        "index": "#113",
        "title": "Fuzzy Hierarchical Multiplex",
        "link": "/arxiv/2512.09976",
        "arxiv_id": "2512.09976",
        "authors": "Alexis Kafantaris",
        "subjects": "Artificial Intelligence, Machine Learning, Systems and Control",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.988815",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个“模糊优化框架”，该框架扩展了FCM（模糊认知图）因果关系，并用于“服务流程设计中的信息传输服务优化”。这是一个典型的运筹学、系统工程或控制论领域的研究，其本质是构建一个数学模型来解决特定领域的优化问题。它完全不涉及构建、改进或演化LLM智能体。因此，根据第一步的排除标准，该论文属于“非演化型应用”，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词。例如，它没有提及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 或 `Self-Improvement`。这进一步确认了它与我的研究目标无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然该论文没有触发“安全与对齐”或“多模态与视觉”这两个排除项，但第一步的判断已经足够有力，无需深入此步。 4.  **第四步：处理特殊和模糊情况** 该论文的情况并不模糊。它讨论的“逻辑蕴含”和“概念层次”是在其模糊数学框架内的理论分析，而不是关于智能体如何进行自主规划和多步推理。它也没有提出任何“自我演化”机制。 5.  **第五步：最终决策** 综合以上分析，这篇论文的研究主题是“模糊优化”，与我的核心研究课题“LLM智能体及其演化”分属完全不同的领域。其贡献在于一个应用于特定领域的数学框架，而非Agentic AI的方法论或系统。因此，最终决策是排除。"
    },
    {
        "index": "#116",
        "title": "ZK-APEX: Zero-Knowledge Approximate Personalized Unlearning with Executable Proofs",
        "link": "/arxiv/2512.09953",
        "arxiv_id": "2512.09953",
        "authors": "Mohammad M Maheri, Sunil Cotterill, Alex Davidson, Hamed Haddadi",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning",
        "date": "2025-12-09",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.990222",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是模型安全与隐私，而非智能体构建。** 论文的核心贡献是提出了一种名为 ZK-APEX 的**机器遗忘**方法，并利用零知识证明来验证遗忘过程的有效性。其目标是解决模型在边缘设备个性化后的隐私、版权和安全问题。这完全属于**模型安全**和**隐私保护**的范畴，而不是关于如何构建、改进或演化一个具有自主性的LLM智能体。论文中的LLM（OPT-125M）和视觉模型（ViT）仅仅是其遗忘算法的应用对象，而不是研究的主体。 2.  **排除标准 (第三步): 明确命中安全与对齐的排除项。** 论文摘要开篇即点明其目标是 \"to satisfy privacy, copyright, and **safety** requirements\"。其核心技术亮点是 \"Paired with Halo2 **zero-knowledge proofs**, it enables the provider to verify...\"。这直接命中了筛选标准中明确排除的 `Safety`、`Security` 以及通过可验证证明间接涉及的 `Interpretability` 领域。根据规则，只要论文的主要贡献是关于这些方面，就应一律排除。 3.  **缺乏正面指标 (第二步): 未涉及任何Agentic AI的核心概念。** 论文摘要中完全没有提及任何与您研究焦点相关的关键词，例如 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving`、`Self-Reflection` 等。其工作流程是算法驱动的（稀疏掩码、补偿步骤、零知识证明），而非智能体自主驱动的。 4.  **特殊情况处理 (第四步): 不属于自我演化的范畴。** 虽然 \"unlearning\"（遗忘）改变了模型，但它不是您所定义的“自我演化”。自我演化是指智能体通过经验、反思或环境反馈进行**主动的自我完善和迭代**。而本文的“遗忘”是一个被动的、由外部删除请求触发的、以满足合规性为目的的过程，它不具备智能体自主学习和进化的特性。 综上所述，该论文是一篇专注于模型安全与隐私保护的优秀研究，但其核心贡献与您“LLM智能体及其演化”的研究目标完全偏离。因此，应将其排除。"
    },
    {
        "index": "#114",
        "title": "Enhancing Fake-News Detection with Node-Level Topological Features",
        "link": "/arxiv/2512.09974",
        "arxiv_id": "2512.09974",
        "authors": "Kaiyuan Xu",
        "subjects": "Social and Information Networks, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.989253",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出一种用于**虚假新闻检测**的模型增强方法。具体来说，它通过将图论中的拓扑特征（度中心性、局部聚类系数）与BERT生成的文本嵌入相结合，来提升图神经网络（GNN）在特定任务上的性能。 - **是否符合要求**: 这完全符合**排除标准1a：非演化型应用**。论文将LLM（BERT）作为一个静态的特征提取工具，应用于“虚假新闻检测”这一特定领域。其研究焦点是解决该领域的应用问题，而不是构建、改进或演化一个具有自主性的LLM智能体。论文没有提出任何关于智能体规划、工具使用、记忆或自我演化的新框架或方法论。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现我关注的核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。虽然提到了BERT，但它仅被用作生成嵌入的工具，而非一个智能体。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文的研究主题是虚假新闻检测，这属于信息安全和内容分析的范畴。虽然与安全相关，但其主要贡献并非关于AI安全、对齐或可解释性的理论，而是一个应用层面的技术改进。因此，它不直接命中“安全与对齐”的排除项，但其应用性质进一步确认了它不属于我的核心研究范围。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划框架，也未提出任何自我演化机制。因此，特殊规则不适用。 **最终决策**: 综合以上分析，这篇论文的本质是**一个应用驱动的模型改进**，而非一个关于LLM智能体基础架构或演化的研究。它将LLM作为解决特定领域问题（虚假新闻检测）的一个组件，其核心贡献在于该应用领域的方法论创新，而非Agentic AI的进步。因此，它严格地落在了我的筛选范围之外。"
    },
    {
        "index": "#109",
        "title": "Push Smarter, Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation",
        "link": "/arxiv/2512.10099",
        "arxiv_id": "2512.10099",
        "authors": "Steven Caro, Stephen L. Smith",
        "subjects": "Robotics, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.986988",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文本质是机器人控制，而非LLM智能体。** 论文的核心贡献是提出了一种名为HeRD的**分层强化学习-扩散策略**，用于解决机器人**非抓取操作**这一具体的控制问题。其架构包含一个高层级的强化学习（RL）智能体和一个低层级的扩散模型。尽管它提到了“智能体”，但这个智能体是传统的RL智能体，而不是基于大语言模型（LLM）的智能体。论文全文摘要中未提及LLM，因此它不属于构建、改进或演化LLM智能体的范畴。 2.  **符合排除标准：非演化型应用。** 该论文是典型的将一种新的算法框架（分层RL+扩散策略）应用到特定领域（机器人控制）去解决该领域问题的研究。它完全符合您在第一步中设定的排除规则：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如...机器人控制等）”。在这里，虽然不是LLM，但逻辑相同：它是一个应用于特定领域的控制方法，而非对智能体本身（特别是LLM智能体）的构建或演化研究。 3.  **第二步：正面指标缺失。** 论文缺少您关注的核心范式和能力指标。它没有涉及 `LLM-based Agents`, `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent` 或 `Self-Evolving` 等任何核心关键词。虽然它有 `Planning`（高层级目标选择），但这是机器人路径规划，而非LLM智能体在复杂任务中的自主规划。 4.  **第四步：特殊情况不适用。** 论文中的规划是机器人控制领域的规划，不属于“智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）”的范畴。同时，论文也未提出任何“自我演化”机制。 综上所述，尽管这篇论文在机器人学和强化学习领域可能是一项优秀的工作，但其研究焦点是**机器人控制策略**，与您关于“LLM智能体及其演化”的核心研究目标不符。因此，应予以排除。"
    },
    {
        "index": "#1",
        "title": "V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions",
        "link": "/arxiv/2512.10822",
        "arxiv_id": "2512.10822",
        "authors": "Mumuksh Tayal, Manan Tayal, Aditya Singh, Shishir Kolathaya, Ravi Prakash",
        "subjects": "Artificial Intelligence, Robotics",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.896125",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为 V-OCBF 的框架，用于从离线数据中学习**安全过滤器**。这属于**控制理论**和**安全强化学习** 的范畴，其目标是确保自主系统的物理安全（如机器人、车辆）。论文完全没有涉及构建、改进或演化基于LLM的智能体。它研究的“控制器”和“智能体”在本文语境下是物理系统的控制单元，而非具备自主规划、工具使用能力的LLM智能体。因此，根据第一步的核心判断，该论文应被排除。 2.  **排除标准 (第三步):** 这是最直接的排除依据。论文的标题、摘要和核心方法论都紧紧围绕 **Safety (安全)** 这一主题。它旨在解决“安全关键控制器”的合成问题，提供“严格的安全保证”。根据筛选标准，“只要论文的主要贡献是关于 Safety...一律排除”。这篇论文是典型的安全研究，因此被明确排除。 3.  **正面指标缺失 (第二步):** 论文中完全没有出现任何与研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning` (智能体规划), `Tool Use`, `Memory` 等。其方法论是基于离线强化学习和控制屏障函数，与LLM智能体的技术栈完全不同。 综上所述，该论文是一篇关于控制系统安全性的高质量研究，但其研究领域、核心贡献和技术路径均与“LLM智能体及其演化”这一课题无关。它属于被明确排除的“安全”类别，且不涉及LLM或Agentic AI的核心概念。因此，最终决策为排除。"
    },
    {
        "index": "#115",
        "title": "TDC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0",
        "link": "/arxiv/2512.09961",
        "arxiv_id": "2512.09961",
        "authors": "Jinyu Chen, Long Shi, Taotao Wang, Jiaheng Wang, Wei Zhang",
        "subjects": "Distributed, Parallel, and Cluster Computing, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.989735",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建一个用于Web3.0的**去中心化协作缓存框架**，旨在解决数据访问效率和一致性问题。其本质是**网络基础设施和分布式系统优化**的研究，而非构建或演化LLM智能体。论文中提到的“代理”是基于深度强化学习（DRL）的优化代理，用于动态调整缓存策略，这与我所关注的具备规划、记忆、工具使用等高级认知能力的LLM智能体有本质区别。因此，该论文属于“非演化型应用”，应被排除。 2.  **正面指标 (第二步):** 论文摘要中几乎没有出现我关注的核心范式和能力指标。虽然提到了“协作”，但这是在分布式系统节点间达成共识的语境下，而非多智能体社会中的协作、通信或社会学习。完全没有提及`LLM-based Agents`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`或`Self-Evolving`等任何核心关键词。 3.  **排除标准 (第三步):** 虽然论文涉及“安全”和“对抗性威胁”，但其主要贡献是缓存框架本身，而非一种新的安全或对齐技术，因此不直接触犯此条排除规则。但核心问题已在第一步解决。 4.  **特殊和模糊情况 (第四步):** 论文不涉及我所关注的推理/规划或自我演化的特殊情况。其使用的DRL是一种标准的优化算法，并非一种新颖的Agentic推理框架或自我演化机制。 **最终决策 (第五步):** 综合分析，这篇论文的研究焦点是**Web3.0网络架构和缓存策略优化**，它将DRL作为一种技术工具应用于该领域。其核心贡献与“LLM智能体及其演化”这一课题相去甚远。论文中的“代理”是功能单一的优化器，不具备我所研究的LLM智能体的核心特征。因此，该论文应被明确排除。"
    },
    {
        "index": "#3",
        "title": "HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition",
        "link": "/arxiv/2512.10807",
        "arxiv_id": "2512.10807",
        "authors": "Wang Lu, Yao Zhu, Jindong Wang",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.896794",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一个名为 **HAROOD** 的**基准**，用于评估在“基于传感器的人类活动识别”这一特定领域中，模型的分布外（OOD）泛化能力。这完全符合筛选标准中的**排除项 1: 非演化型应用**。论文的本质是将现有的机器学习模型（如CNN、Transformer）作为工具，应用于一个垂直领域（传感器数据分析、人类活动识别），并解决该领域的一个具体问题（OOD泛化）。它并未提出任何关于构建、改进或演化LLM智能体的新方法论或框架。 2.  **正面指标缺失 (第二步):** 论文的摘要和标题中完全没有出现您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其讨论的重点是 `Benchmark`, `Out-of-distribution (OOD)`, `Human Activity Recognition (HAR)`，这些都与您的核心研究目标相去甚远。 3.  **特殊情况不适用 (第四步):** *   论文不涉及**推理/规划**的智能体框架，它关注的是模型在特定数据分布下的泛化性能。 *   论文不涉及**自我演化机制**。它虽然研究“泛化”，但这并非智能体通过经验、反思或环境反馈进行的自我完善，而是模型在静态测试集上的表现评估。它没有提出任何新的自我改进或迭代演化的方法。 **总结:** 该论文的研究焦点是机器学习应用领域的一个具体技术问题（HAR中的OOD泛化），其贡献是提供一个评估基准。这与您“LLM智能体及其演化”的核心目标——即研究智能体本身的构建、协作与演化机制——存在根本性的差异。因此，该论文应被明确排除。"
    },
    {
        "index": "#119",
        "title": "QSTAformer: A Quantum-Enhanced Transformer for Robust Short-Term Voltage Stability Assessment against Adversarial Attacks",
        "link": "/arxiv/2512.09936",
        "arxiv_id": "2512.09936",
        "authors": "Yang Li, Chong Ma, Yuanzheng Li, Sen Li, Yanbo Chen, Zhaoyang Dong",
        "subjects": "Systems and Control, Machine Learning, Quantum Physics",
        "date": "2025-11-29",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.996446",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 这篇论文的核心贡献是提出一个名为 `QSTAformer` 的量子增强Transformer模型，用于解决电力系统领域的特定问题——短期电压稳定评估（STVSA）。这完全符合“非演化型应用”的排除标准。论文的本质是将一个新颖的模型架构（量子增强的Transformer）作为工具，应用于特定领域（电力系统）以解决该领域的鲁棒性问题，其核心并非构建、改进或演化LLM智能体。 2.  **排除标准 (第三步):** 论文的研究焦点是模型在“对抗攻击”下的“鲁棒性”，并为此开发了“对抗训练策略”。这明确属于 `Security` (安全) 的研究范畴。根据筛选标准，只要论文的主要贡献是关于安全、鲁棒性或对抗攻击的，就应被排除。 3.  **正面指标缺失 (第二步):** 论文的标题和摘要中完全没有出现任何与我核心关注点相关的正面指标，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。这进一步证实了它与我的研究课题无关。 综上所述，该论文是一篇典型的将机器学习模型应用于特定垂直领域（电力系统）并研究其安全性的工作，其核心目标、方法论和贡献均不涉及LLM智能体的构建、协作或演化，因此被明确排除。"
    },
    {
        "index": "#110",
        "title": "Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit",
        "link": "/arxiv/2512.10092",
        "arxiv_id": "2512.10092",
        "authors": "Nick Jiang, Xiaoqing Sun, Lisa Dunlap, Lewis Smith, Neel Nanda",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.987478",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种使用稀疏自编码器（SAEs）来创建“可解释嵌入”的方法，并将其定位为一个“数据分析工具包”。其本质是**模型可解释性**和**数据分析**，而不是构建、改进或演化LLM智能体。论文虽然分析了LLM的行为，但其自身并未提出任何新的智能体框架、多智能体系统或自我演化机制。因此，根据第一步的排除标准，这篇论文属于“非演化型应用”，即将一种新方法（SAE）作为工具应用于分析LLM和数据这一特定领域。 2.  **第二步：正面指标** 论文中完全没有出现您所关注的核心范式和能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。这进一步表明它与您的研究焦点无关。 3.  **第三步：排除标准** 这是最关键的一步。论文的标题和摘要反复强调其核心贡献在于“Interpretable Embeddings”（可解释嵌入）和“interpreting models”（解释模型）。摘要中提到的应用场景，如“identifying undesirable model behaviors or biases”（识别不良模型行为或偏见），都直接指向了**可解释性**和**安全性**研究领域。根据您的筛选标准，只要论文的主要贡献是关于 `Interpretability` (可解释性) 或 `Explainability (XAI)`，就应一律排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及推理/规划或自我演化的特殊情况。它提出的SAE是一种分析工具，而非智能体进行规划或自我演化的机制。 **最终决策**：综合以上分析，这篇论文的核心贡献是开发一种用于模型解释和数据分析的工具，属于可解释性（XAI）研究范畴，与您关于“LLM智能体及其演化”的核心目标（构建、改进、演化智能体本身）完全偏离。因此，应明确排除。"
    },
    {
        "index": "#8",
        "title": "Challenges of Evaluating LLM Safety for User Welfare",
        "link": "/arxiv/2512.10687",
        "arxiv_id": "2512.10687",
        "authors": "Manon Kempermann, Sai Suresh Macharla Vasu, Mahalakshmi Raveenthiran, Theo Farrell, Ingmar Weber",
        "subjects": "Artificial Intelligence, Computers and Society",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.900313",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是**提出一种新的、考虑用户背景的LLM安全性评估方法论**。它旨在解决如何更准确地评估LLM在提供个人建议时对特定用户（尤其是脆弱用户）的潜在风险。论文的本质是**评估科学**，而不是**智能体构建**。它没有提出新的LLM智能体架构、改进智能体的规划/工具使用能力，也没有设计让智能体自我演化的机制。因此，根据第一步的“排除”规则，这篇论文的核心不是关于构建、改进或演化LLM智能体。 2.  **第二步：正面指标** 论文摘要中完全没有出现我关注的核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent Systems` 等。其讨论的焦点是 `Safety Evaluation`, `User Welfare`, `User Context` 和 `Vulnerability`，这些都不是我的正面指标。 3.  **第三步：排除标准** 这是最关键的一步。论文的标题是“Challenges of Evaluating LLM **Safety** for User Welfare”，摘要中反复强调“**Safety** evaluations”。根据我的筛选标准：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` (可解释性), `Explainability (XAI)`, `Alignment` (对齐), `Watermarking` (水印), 或 `Hallucination` (幻觉)，一律排除。” 这篇论文完全符合这一排除标准，其主要贡献明确属于LLM安全与对齐的研究范畴。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及推理/规划框架的构建，也不涉及自我演化机制的应用，因此特殊情况的例外规则不适用。 **最终决策**：综合以上分析，这篇论文的核心贡献是关于LLM的安全性评估，这是一个与“LLM智能体及其演化”平行但不同的研究领域。它没有构建或演化任何智能体，其方法论旨在评估风险，而非增强智能体的自主能力。因此，这篇论文被明确排除在我的研究范围之外。"
    },
    {
        "index": "#5",
        "title": "COMPARE: Clinical Optimization with Modular Planning and Assessment via RAG-Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to ChatGPT-5 and Junior Operators",
        "link": "/arxiv/2512.10702",
        "arxiv_id": "2512.10702",
        "authors": "Wei Fang, Chiyao Wang, Wenshuai Ma, Hui Liu, Jianqiang Hu, Xiaona Niu, Yi Chu, Mingming Zhang, Jingxiao Yang, Dongwei Zhang, Zelin Li, Pengyun Liu, Jiawei Zheng, Pengke Zhang, Chaoshi Qin, Wangang Guo, Bin Wang, Yugang Xue, Wei Zhang, Zikuan Wang, Rui Zhu, Yihui Cao, Quanmao Lu, Rui Meng, Yan Li",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.898359",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合您的研究范围。我的判断过程如下： **第一步：核心判断——这篇论文的本质是什么？** 这篇论文的核心本质是**非演化型应用**。 *   **核心贡献分析**: 论文的核心贡献是**评估**一个名为CA-GPT的特定模型在医疗领域（经皮冠状动脉介入治疗，PCI）中的性能，并将其与通用模型（ChatGPT-5）和初级医生进行比较。其研究目标是证明CA-GPT在“OCT引导的PCI规划和评估”这一特定临床任务上更优越。 *   **与筛选标准的匹配**: 这完全符合第一步排除标准中的第一条：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗、金融、法律、机器人控制等）”。本文正是将一个基于RAG的LLM（CA-GPT）作为决策支持工具，应用于心脏病学这一特定领域，以解决OCT影像解读和手术规划的问题。它没有提出新的智能体构建、改进或演化的通用方法论或框架。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文中虽然出现了 `Planning` 和 `RAG-Enhanced` 等词汇，但它们并非您所关注的核心范式。 *   `Planning`: 这里的“Planning”指的是**临床手术规划**这一具体任务，而不是智能体在通用场景下的自主规划能力或新的规划框架。论文的重点是评估规划结果的好坏，而不是研究智能体“如何”进行规划。 *   `RAG-Enhanced`: RAG（检索增强生成）是一种成熟的技术，在这里被用作实现领域特定知识增强的手段。论文并未对RAG本身进行创新，也没有将其与智能体的记忆、工具使用或自我演化等核心能力相结合提出新框架。 因此，这些正面指标在此处是作为应用实现的细节出现，而非论文的核心研究贡献。 **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全与对齐、多模态与视觉等排除标准，但第一步的判断已经足够将其排除。 **第四步：处理特殊和模糊情况** *   **推理/规划**: 如上所述，本文的“规划”是特定领域的应用任务，而非关于智能体通用推理或规划框架的研究。因此，适用排除规则：“如果只是关于提高LLM本身基础Token预测的数学或逻辑能力（如新的数据集、非Agentic的微调方法）”，虽然本文不是数学逻辑，但同理，它是关于在特定任务上的表现，而非通用的Agentic框架。 **第五步：最终决策** 综合以上分析，这篇论文是一篇典型的**AI应用研究**，其重点在于验证一个定制化模型在特定垂直领域的有效性。它没有对LLM智能体的基础架构、多智能体交互机制或自我演化算法做出任何核心贡献。因此，它不符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标。"
    },
    {
        "index": "#7",
        "title": "Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning",
        "link": "/arxiv/2512.10691",
        "arxiv_id": "2512.10691",
        "authors": "Benjamin Gundersen, Nicolas Deperrois, Samuel Ruiperez-Campillo, Thomas M. Sutter, Julia E. Vogt, Michael Moor, Farhad Nooralahzadeh, Michael Krauthammer",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.899681",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——本质是“非演化型应用”** 论文的核心贡献是**将强化学习（RL）作为一种训练方法，应用于一个特定的视觉语言模型（VLM），以提升其在放射科报告生成这一垂直领域的性能**。它没有提出新的智能体架构、多智能体协作框架或自我演化机制。其本质是利用先进的模型训练技术解决特定领域（医疗影像）的问题，这完全符合筛选标准中“非演化型应用”的排除规则。 2.  **第三步：排除标准——核心是“多模态与视觉”** 论文的研究对象是视觉语言模型（VLMs），具体是基于Qwen3-VL构建的RadVLM。整个研究都围绕着如何处理和理解胸部X光图像（Vision）展开。根据您的筛选标准，凡是核心贡献在于`Vision`, `Vision-Language`, `MLLMs`的研究都应被排除，除非视觉仅作为智能体感知环境的工具。在此论文中，视觉理解本身就是研究的核心，而非一个智能体框架的附属组件。 3.  **第四步：特殊情况的澄清——“推理/规划”并非Agentic框架** 论文中提到了“thinking”（显式中间推理），但这并非您所关注的Agentic框架中的自主规划或反思循环。根据摘要描述，这是一种通过“冷启动SFT阶段”赋予模型的能力，更接近于一种模型训练技巧或思维链（CoT）的变体，目的是为了在RL阶段表现更好，而不是构建一个能够自主进行多步规划和工具使用的智能体。因此，它属于“非Agentic的推理”，应被排除。 **总结**: 尽管该论文在医疗AI领域可能是一项优秀的工作，但它与您“LLM智能体及其演化”的核心目标相去甚远。它的焦点是**特定领域应用的模型性能优化**，而非**智能体本身的构建、协作或演化机制**。因此，根据您的严格筛选标准，这篇论文应被排除。"
    },
    {
        "index": "#11",
        "title": "CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models",
        "link": "/arxiv/2512.10655",
        "arxiv_id": "2512.10655",
        "authors": "Tong Zhang, Carlos Hinojosa, Bernard Ghanem",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.906921",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质不符** 论文的核心贡献是提出一个名为CAPTAIN的框架，用于解决**文本到图像扩散模型**中的“记忆化”问题，即模型无意中复现训练数据，从而引发隐私和版权风险。这属于对特定模型（扩散模型）的特定问题（记忆化）的改进方法。根据筛选标准，这属于“非演化型应用”，因为它并非关于构建、改进或演化LLM智能体，而是将一个新方法应用于图像生成领域以解决该领域的问题。 2.  **排除标准 (第三步): 触及明确的排除红线** 该论文明确触及了两个关键的排除标准： *   **安全与对齐**: 论文摘要开篇即点明其研究动机是“隐私和版权问题”，其核心目标是“缓解记忆化”。这完全属于“安全与对齐”的研究范畴，根据筛选标准，只要主要贡献是关于`Safety`、`Security`、`Privacy`等，就应一律排除。 *   **多模态与视觉**: 论文的研究对象是“文本到图像扩散模型”，这明确属于“多模态与视觉”中的`Diffusion Models`类别。筛选标准指出，除非扩散模型被用作智能体感知环境的工具，否则应排除。在本论文中，扩散模型是研究的核心对象，而非工具。 3.  **正面指标 (第二步): 缺乏相关关键词** 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` (指智能体记忆), `Self-Reflection` 等。这进一步证实了其研究方向的偏离。 **总结**: 尽管CAPTAIN是一个在模型安全领域可能有价值的创新，但其研究对象是扩散模型而非LLM智能体，其核心目标是解决隐私安全问题而非构建或演化智能体。因此，它完全不符合“LLM智能体及其演化”这一研究课题的核心要求。"
    },
    {
        "index": "#19",
        "title": "Representation of the structure of graphs by sequences of instructions",
        "link": "/arxiv/2512.10429",
        "arxiv_id": "2512.10429",
        "authors": "Ezequiel Lopez-Rubio",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.910734",
        "filter_reason": "这篇论文的核心贡献是提出了一种新的图表示方法，即将图的邻接矩阵转换为一串可逆的指令序列，以便于深度学习语言模型（如LLM）进行处理。 我的研究目标是筛选关于“构建、改进或演化LLM智能体”的论文，聚焦于Agentic AI的三个核心方向：单智能体、多智能体和自我演化。 根据筛选标准进行判断： 1.  **第一步：核心判断**——这篇论文的本质是关于**数据表示**，而非**智能体框架**。它解决的是如何让LLM能够“理解”图结构数据的问题，这是一个基础的数据预处理或编码问题。它没有提出任何关于智能体如何规划、记忆、使用工具、协作或自我演化的方法论或框架。因此，它属于“非Agentic的推理”范畴，应被排除。论文的目的是提升LLM处理特定数据类型（图）的能力，而不是构建一个自主行动的智能体。 2.  **第二步：正面指标**——论文摘要中完全没有出现我的核心关注点，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Evolution`, `Multi-Agent Systems` 等任何关键词。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准**——虽然论文不涉及安全对齐或多模态等排除项，但这并不能改变其核心贡献与我的研究目标不符的事实。 4.  **第四步：特殊和模糊情况**——这篇论文不属于“自我演化的应用”这一例外情况，因为它根本没有提出任何自我演化机制。它也不属于“智能体的规划/推理”，因为它关注的是数据输入格式，而不是智能体在任务执行过程中的决策循环。 **结论**：该论文是一项关于数据表示的基础性研究，旨在让LLM能够处理图数据。它本身并未构建、改进或演化任何形式的LLM智能体。因此，它不符合我的研究范围，应被排除。"
    },
    {
        "index": "#13",
        "title": "Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via LLMs",
        "link": "/arxiv/2512.10611",
        "arxiv_id": "2512.10611",
        "authors": "Minghao LI, Ruihang Wang, Rui Tan, Yonggang Wen",
        "subjects": "Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.907926",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文本质是特定领域的应用，而非通用智能体框架的构建。** - 论文的核心贡献是提出了一个名为 \"Phythesis\" 的框架，用于解决一个非常具体的问题：**节能数据中心的设计**。 - 尽管该框架内部使用了LLM，并让LLM进行“自我批评”来优化场景拓扑，但这整个机制都是为了服务于“数据中心场景合成”这一特定应用目标。它没有提出一个通用的、可迁移到其他任务的LLM智能体构建或演化方法论。 - 这完全符合第一步的排除标准 **1. 非演化型应用**：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如……）”。在这里，数据中心设计就是那个特定领域。 2.  **对正面指标和特殊情况的辨析（第二步与第四步）：** - 论文中确实出现了 `Self-Correction`（自我批评）、`Iterative Improvement`（迭代优化）等正面指标，并且标题中包含 `Evolutionary`（演化）。这些是导致判断模糊的关键点。 - 然而，根据第四步的核心规则，我们需要区分“提出一种新的自我演化机制”和“在特定应用中使用了自我演化机制”。本文属于后者。它的“自我批评”是针对数据中心布局这一具体任务的，其演化过程也是与物理仿真器耦合的，并非一个通用的智能体自我演化框架。 - 因此，第四步中的“保留（例外）”条款不适用，因为论文的核心贡献不是“自我演化机制”本身，而是应用该机制解决特定问题的“Phythesis框架”。 3.  **最终决策（第五步）：** - 综合来看，这篇论文的研究焦点是**计算/建筑学领域的问题**，即如何利用AI优化数据中心设计。它巧妙地将LLM作为一个生成和优化的组件，但其科学贡献在于**应用层面的创新**，而非Agentic AI基础理论的突破。 - 您的核心目标是筛选那些核心贡献在于**构建、改进或演化LLM智能体本身**的论文。而Phythesis论文的核心贡献在于**构建一个用于特定领域设计的系统**，LLM智能体只是其中的一个模块。 - 因此，尽管论文质量可能很高，但它偏离了您“Agentic AI”的核心研究焦点，应予以排除。"
    },
    {
        "index": "#20",
        "title": "Boosting RL-Based Visual Reasoning with Selective Adversarial Entropy Intervention",
        "link": "/arxiv/2512.10414",
        "arxiv_id": "2512.10414",
        "authors": "Yang Yu, Zhuangzhuang Chen, Siqi Wang, Lanqing Li, Xiaomeng Li",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.916325",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 `SaEI` 的新方法，通过**对抗性熵干预**来微调**视觉语言模型（VLMs）**，以提升其在视觉推理任务上的表现。这是一种**模型微调技术**，旨在改进模型的基础推理能力，而不是构建一个具有自主规划、工具使用或记忆能力的智能体框架。因此，它属于“非Agentic的推理”这一排除类别。论文没有提出一个新的LLM智能体架构或演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。其核心是 `RL-based finetuning` 和 `entropy intervention`，这些是模型训练层面的技术，而非智能体架构层面的设计。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文明确命中了“多模态与视觉”这一排除标准。摘要中反复强调其研究对象是**视觉语言模型（VLMs）**，方法的核心是**扭曲视觉输入**。视觉是这项研究的核心，而不是作为智能体感知环境的一个工具。根据您的规则，这应被排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文确实提到了“推理能力”，但这属于“排除”的情况。它关注的是如何通过微调提升VLM在视觉问答等任务上的基础推理准确性，而不是研究一个智能体如何进行自主规划或在复杂环境中进行多步决策。这与ReAct、ToT等Agentic框架有本质区别。 - **自我演化的应用**: 此处不适用，因为论文的核心贡献并非一种自我演化机制。 **最终决策**: 综合以上分析，这篇论文的核心是改进VLMs的基础视觉推理能力的一种微调方法，属于模型训练优化的范畴。它既不涉及构建或演化LLM智能体，也属于您明确排除的“多模态与视觉”领域。因此，该论文与您关于“LLM智能体及其演化”的研究课题不符。"
    },
    {
        "index": "#22",
        "title": "LLM-Empowered Representation Learning for Emerging Item Recommendation",
        "link": "/arxiv/2512.10370",
        "arxiv_id": "2512.10370",
        "authors": "Ziying Zhang, Quanming Yao, Yaqing Wang",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.917296",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心判断（第一步）：** 这篇论文的本质是一个**非演化型应用**。其核心贡献是提出一个名为 `EmerFlow` 的表示学习框架，用于解决推荐系统中的“新兴物品推荐”问题。论文将LLM作为一个工具，通过“LLM推理”来丰富物品的文本特征，从而生成更好的物品嵌入向量。这完全符合筛选标准中“将LLM作为工具应用到特定领域（这里是推荐系统）去解决该领域的问题”的排除规则。论文的研究焦点是推荐算法的改进，而不是LLM智能体的构建、改进或演化。 2.  **正面指标缺失（第二步）：** 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等。它也没有涉及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`。虽然提到了“LLM推理”，但这里的推理是指利用LLM理解物品描述并生成特征，而非智能体在任务执行中的自主规划和决策过程。 3.  **特殊情况的澄清（第四步）：** *   **推理/规划：** 论文中的“LLM推理”是为了特征工程，而不是智能体的自主规划。它属于“提高LLM本身基础能力以服务于下游任务”的范畴，而非构建一个具备规划能力的智能体框架，因此应被排除。 *   **自我演化的应用：** 论文虽然提到了物品交互随时间“动态积累”，并使用元学习来“精炼嵌入”，但这描述的是推荐模型适应数据变化的过程，而不是智能体通过经验、反思或环境反馈进行自我完善和迭代的机制。因此，这不属于“自我演化”的例外情况。 综上所述，该论文的核心是应用LLM技术改进推荐系统，而非研究LLM智能体本身。因此，它不符合我关于“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#18",
        "title": "Targeted Data Protection for Diffusion Model by Matching Training Trajectory",
        "link": "/arxiv/2512.10433",
        "arxiv_id": "2512.10433",
        "authors": "Hojun Lee, Mijin Koo, Yeji Song, Nojun Kwak",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.910325",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为TAFAP的方法，用于在扩散模型微调过程中进行**定向数据保护**。其本质是**模型安全与隐私**领域的研究，旨在防止个性化模型泄露训练数据。这与您“构建、改进或演化LLM智能体”的核心目标完全不符。论文的研究对象是**扩散模型**，而非LLM智能体。 2.  **排除标准 (第三步):** 该论文明确命中了多个排除标准： *   **安全与对齐:** 论文的标题和摘要反复强调“Data Protection”（数据保护）、“Privacy Infringement”（隐私侵犯）、“safeguards”（保护措施），这完全属于`Security`和`Safety`的研究范畴。根据您的规则，只要主要贡献是关于安全与对齐的，就应一律排除。 *   **多模态与视觉:** 论文的研究对象是“Diffusion Model”（扩散模型）和“text-to-image models”（文本到图像模型），这属于`Vision`和`Diffusion Models`的范畴。虽然摘要中提到了“training trajectory”（训练轨迹），但这并非指智能体的自我演化，而是指模型在训练过程中的权重变化动态，是一种训练技术，与您关注的“自我演化”智能体机制有本质区别。 3.  **正面指标与特殊情况 (第二步 & 第四步):** *   论文中完全没有出现任何与您核心关注点相关的正面指标，如`Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving`等。 *   对于特殊情况，论文不涉及智能体的推理或规划。其“trajectory matching”技术是一种训练阶段的对抗性扰动方法，用于控制模型输出，而不是一个智能体在运行时通过经验进行自我完善和迭代。因此，它不符合“自我演化”的定义。 **总结:** 该论文是一篇关于**视觉生成模型（扩散模型）的数据隐私保护**的研究。尽管其技术细节（如控制训练轨迹）有一定创新性，但其研究领域、核心贡献和目标均与您的“LLM智能体及其演化”课题无关。因此，应果断排除。"
    },
    {
        "index": "#24",
        "title": "On the Collapse of Generative Paths: A Criterion and Correction for Diffusion Steering",
        "link": "/arxiv/2512.10339",
        "arxiv_id": "2512.10339",
        "authors": "Ziseok Lee, Minyeong Hwang, Sanghyun Jo, Wooyeol Lee, Jihyung Ko, Young Bin Park, Jae-Mun Choi, Eunho Yang, Kyungsu Kim",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.918326",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文本质不符** 论文的核心贡献是针对**扩散模型**的推理时引导技术提出了一种修正方法（ACE），以解决“生成路径坍塌”问题。其研究对象是**生成模型**，而非**LLM智能体**。论文将该方法应用于分子设计领域，这属于将一种模型技术应用于特定领域的“非演化型应用”，根据筛选标准应予以排除。我的核心目标是筛选关于构建、改进或演化**LLM智能体**的论文，而这篇论文与LLM或智能体架构无关。 2.  **第二步：正面指标——缺乏核心关注点** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步表明该论文与我的研究课题无关。 3.  **第三步：排除标准——属于排除范畴** 论文明确聚焦于**扩散模型**。根据排除标准，“`Diffusion Models`”属于“多模态与视觉”范畴，除非它们被用作智能体感知环境的工具。在这篇论文中，扩散模型本身就是研究的核心，而不是智能体的一个组件，因此完全符合排除条件。 4.  **第四步：处理特殊和模糊情况** 论文提出的“修正”是一种数学上的、固定的算法改进，用于保证生成过程的概率路径有效。它不属于智能体通过经验或反馈进行“自我演化”的机制。因此，关于“自我演化的应用”的例外规则不适用。 **最终决策**: 综合以上分析，该论文的研究领域是生成模型（特别是扩散模型）的算法改进，而我的研究焦点是LLM智能体的构建与演化。两者在研究对象、核心贡献和技术路线上存在根本性差异。因此，这篇论文被明确排除。"
    },
    {
        "index": "#23",
        "title": "REMISVFU: Vertical Federated Unlearning via Representation Misdirection for Intermediate Output Feature",
        "link": "/arxiv/2512.10348",
        "arxiv_id": "2512.10348",
        "authors": "Wenhan Wu, Zhili He, Huanghuang Liang, Yili Gong, Jiawei Jiang, Chuang Hu, Dazhao Cheng",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.917805",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为 `REMISVFU` 的框架，用于在**垂直联邦学习**中实现**“联邦遗忘”**。其目标是当某个参与者要求删除其数据贡献时，能够快速、有效地从联合训练的模型中移除该参与者的影响，同时保护数据隐私（符合GDPR的“被遗忘权”）。 这篇论文的本质是**机器学习中的数据隐私与安全技术**，而非构建、改进或演化LLM智能体。它没有涉及任何智能体的核心概念，如自主规划、工具使用或自我演化。因此，根据第一步的排除标准，它属于**“非演化型应用”**，因为它是一种应用于特定机器学习范式（联邦学习）的技术，旨在解决该领域的数据安全问题，而不是构建一个智能体。 2.  **第二步：正面指标** 论文中完全没有出现我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。因此，它不满足任何正面指标。 3.  **第三步：排除标准** 这篇论文是**安全与对齐**方向的典型研究。其核心动机是**数据保护法规**和**被遗忘权**，提出的技术是**“遗忘”**，并且评估指标之一是**抑制后门攻击**。这完全命中了“只要论文的主要贡献是关于 `Safety`, `Security`...一律排除”的规则。 4.  **第四步：处理特殊和模糊情况** 本文不涉及任何与智能体相关的推理/规划或自我演化机制，因此特殊规则不适用。 **最终决策**： 综合以上分析，这篇论文的核心贡献是关于**联邦学习中的数据隐私和安全**，具体是一种“遗忘”技术。它完全没有涉及LLM、智能体架构（无论是单智能体还是多智能体）或智能体的自我演化。尽管它提出了一种“框架”，但这个框架是用于隐私保护的，而不是用于构建或演化智能体。因此，它明确地被排除在我的研究范围之外。"
    },
    {
        "index": "#27",
        "title": "InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck",
        "link": "/arxiv/2512.10305",
        "arxiv_id": "2512.10305",
        "authors": "Quanmin Wei, Penglin Dai, Wei Li, Bingyi Liu, Xiao Wu",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.919917",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是特定领域的应用优化，而非LLM智能体的构建或演化。** - 论文的核心贡献是提出了一个名为 `InfoCom` 的框架，用于解决**自动驾驶**领域中多智能体（即车辆）协作感知时的**通信效率问题**。其本质是优化数据传输，将通信开销从MB级别降低到KB级别。 - 这完全符合第一步中的排除标准：“**非演化型应用**”。该论文将一个已有的多智能体概念（协作感知）作为工具，应用到自动驾驶这一特定领域，去解决该领域的通信瓶颈问题，其核心贡献在于通信协议和数据处理，而非智能体本身的认知架构或演化机制。 2.  **排除标准 (第三步): 论文属于多模态与视觉范畴。** - 论文的研究焦点是“**协作感知**”，这是一个典型的计算机视觉和传感器融合问题。论文摘要中明确指出其目标是“Precise environmental perception”，这直接落入了“**多模态与视觉**”的排除范围。 - 根据规则，除非视觉是作为智能体感知环境的工具，否则应排除。在这篇论文中，视觉感知本身就是要解决的核心问题，而不是一个服务于更高层次智能体任务的工具。 3.  **正面指标缺失 (第二步): 缺乏LLM智能体的核心关注点。** - 尽管论文标题和摘要中出现了 `Collaborative` 和 `Communication`，但这些词的上下文是关于数据包的传输效率，而不是智能体之间的认知协作、社会学习或基于语言的协商。 - 论文完全没有提及任何与LLM智能体相关的核心范式或能力，如 `Planning` (规划)、`Tool Use` (工具使用)、`Memory` (记忆)、`Self-Reflection` (自我反思) 或 `Self-Evolving` (自我演化)。 **总结**: 该论文是一篇优秀的计算机视觉和通信网络领域的交叉研究，但它关注的是物理世界智能体（自动驾驶车辆）的感知数据传输优化，与您研究的“基于LLM的智能体及其演化”这一核心目标相去甚远。因此，应予以排除。"
    },
    {
        "index": "#33",
        "title": "An exploration for higher efficiency in multi objective optimisation with reinforcement learning",
        "link": "/arxiv/2512.10208",
        "arxiv_id": "2512.10208",
        "authors": "Mehmet Emin Aydin",
        "subjects": "Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.928041",
        "filter_reason": "这篇论文不符合研究范围。 1.  **核心判断 (第一步)**: 论文的核心贡献是提出一种基于多目标强化学习（MORL）的方法，用于提升多目标优化算法的效率。其研究焦点是优化算法本身，即如何通过学习来选择最优的“算子序列”以提升搜索效率。根据筛选标准第一步，这属于典型的“非演化型应用”，它将强化学习作为一种工具应用于优化领域，而不是构建、改进或演化LLM智能体。论文中完全没有提及LLM或智能体框架。 2.  **正面指标缺失 (第二步)**: 论文摘要中完全没有出现任何与研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。其核心术语是“多目标优化”、“强化学习”和“算子”，这些都是优化和机器学习领域的术语，而非Agentic AI领域的术语。 3.  **特殊情况的排除 (第四步)**: 论文虽然涉及“规划”，但这里的“规划”是指为优化算法规划一个算子的应用序列，这属于算法层面的策略选择，而不是智能体为完成复杂任务（如“规划一次旅行”）而进行的自主规划和推理。它不涉及智能体的自主性、工具使用或与环境交互等核心能力。 综上所述，该论文的研究内容是关于优化算法的改进，与“LLM智能体及其演化”这一课题的核心目标——构建和演化具有自主能力的智能体——存在根本性差异，应予以排除。"
    },
    {
        "index": "#32",
        "title": "ID-PaS : Identity-Aware Predict-and-Search for General Mixed-Integer Linear Programs",
        "link": "/arxiv/2512.10211",
        "arxiv_id": "2512.10211",
        "authors": "Junyang Cai, El Mehdi Er Raqabi, Pascal Van Hentenryck, Bistra Dilkina",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.927561",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用研究，而非智能体构建。** 论文的核心贡献是提出一个名为“ID-PaS”的框架，用于解决“混合整数线性规划”这一特定领域的优化问题。它通过一个机器学习模型来预测变量赋值，以引导搜索过程，从而提升求解器（如Gurobi）的性能。这完全符合筛选标准中的**“非演化型应用”**排除项：将一个预测模型（论文未明确是LLM，但即使是，其用法也是）作为工具应用到特定领域（组合优化）去解决该领域的问题。论文的本质是改进一个优化算法，而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——论文完全不包含核心关注点。** 论文的标题和摘要中，完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其讨论的“Predict-and-Search”是一种针对数学规划问题的特定算法范式，而非智能体的通用规划或行动框架。 3.  **第三步：排除标准——论文不涉及安全或多模态等排除项，但第一步的排除已足够。** 该论文不涉及安全、对齐或多模态等排除标准，但这并不改变其作为应用研究的本质。 4.  **第四步：处理特殊和模糊情况——不适用。** 论文中的“Search”是数学优化领域的搜索算法，用于在解空间中寻找最优解，它不具备智能体在环境中进行自主规划和行动的含义。因此，这不属于“智能体如何进行规划”的保留范畴。同时，论文也未提出任何“自我演化”机制，因此相关的例外规则也不适用。 **最终决策**：综合以上分析，该论文的研究目标是提升特定数学问题的求解效率，属于运筹学和优化算法的范畴。其核心贡献与“LLM智能体及其演化”这一课题无关，因此应被排除。"
    },
    {
        "index": "#31",
        "title": "Reverse Thinking Enhances Missing Information Detection in Large Language Models",
        "link": "/arxiv/2512.10273",
        "arxiv_id": "2512.10273",
        "authors": "Yuxin Liu, Chaojie Gu, Yihang Zhang, Bin Qian, Shibo He",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.927078",
        "filter_reason": "这篇论文不符合您的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出一种名为“逆向思维”的推理方法，用于提升LLM在处理缺失信息问题上的表现。这本质上是对LLM基础推理能力的一种增强，类似于Chain-of-Thought (CoT)或Tree-of-Thought (ToT)的变体。它并未涉及构建一个具有自主规划、工具使用或记忆能力的智能体框架。因此，该论文属于“非Agentic的推理”这一排除类别。 2.  **正面指标缺失（第二步）：** 论文摘要中完全没有出现您关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`。同样，它也未提及智能体的关键能力，如 `Tool Use`, `Memory`, `Self-Reflection`, `ReAct` 等。虽然提到了与 `ToT` 的比较，但其比较对象是推理结构，而非智能体框架。 3.  **特殊情况的精准应用（第四步）：** 这是最关键的判断点。根据您对“推理/规划”的特殊情况处理规则： *   **排除规则适用：** 论文“只是关于提高LLM本身基础Token预测的数学或逻辑能力”。它提出了一种新的推理框架来增强模型的“逻辑完整性”，这正是该排除规则所针对的情况。 *   **保留规则不适用：** 论文并非“关于智能体如何进行规划或在复杂任务中进行多步推理”。它没有描述一个智能体如何与环境交互、使用工具、并根据反馈进行迭代行动。它仅仅是改进了LLM在回答问题时的内部思考过程。 **总结：** 尽管这篇论文可能对提升LLM的基础能力有重要价值，但其研究焦点是**模型推理机制的改进**，而非**智能体的构建、协作或演化**。您的核心目标是筛选那些贡献在于“Agentic”框架和机制的论文，而这篇论文的贡献在于“Reasoning”方法，因此它超出了您的研究范围。"
    },
    {
        "index": "#37",
        "title": "Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups",
        "link": "/arxiv/2512.10105",
        "arxiv_id": "2512.10105",
        "authors": "Soorya Ram Shimgekar, Abhay Goyal, Lam Yin Cheung, Roy Ka-Wei Lee, Koustuv Saha, Pi Zonooz, Navin Kumar",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.930193",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用研究，而非智能体构建。** 论文的核心贡献是提出一个“两阶段计算框架”，用于分析和建模特定领域（新加坡Telegram群组中的阴谋论叙事）的叙事原型。这个框架包含两个主要部分：1）一个微调的RoBERTa模型，用于文本分类；2）一个新颖的图神经网络（SiBeGNN），用于分析消息间的信念关系并进行聚类。 这完全符合筛选标准中的“非演化型应用”排除项。论文将现有的机器学习模型（RoBERTa, GNN）作为工具，应用到一个具体的社会科学问题（阴谋论传播分析）上。它没有构建、改进或演化任何具有自主性、规划能力或工具使用能力的LLM智能体。其目标是“分析”和“理解”数据，而不是“行动”或“演化”。 2.  **第二步：正面指标——论文完全不包含我的核心关注点。** 我仔细检查了论文标题和摘要，没有发现任何与我的研究焦点相关的正面指标。论文中完全没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式。同样，它也没有涉及智能体的关键能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 或多智能体间的 `Collaboration` 与 `Communication`。其方法论是静态的数据分析和建模，而非动态的智能体行为。 3.  **第三步与第四步：排除标准与特殊情况分析。** - **排除标准**：论文的主要贡献不是关于安全、对齐或多模态，因此不直接触达这些排除项。但这并不意味着它应该被保留。 - **特殊情况**：论文不涉及智能体的推理/规划框架，也没有提出任何“自我演化”机制。它是一个静态的分析流水线，因此不适用任何保留的例外情况。 **最终决策**：综合以上分析，这篇论文是一项典型的计算社会科学研究，其本质是利用机器学习模型作为分析工具来解决特定领域的问题。它没有提出任何关于LLM智能体构建、多智能体系统或自我演化的新方法或框架。因此，它与我的研究课题“LLM智能体及其演化”的核心目标完全不符，应予以排除。"
    },
    {
        "index": "#28",
        "title": "Trustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance",
        "link": "/arxiv/2512.10304",
        "arxiv_id": "2512.10304",
        "authors": "Byeong Ho Kang, Wenli Yang, Muhammad Bilal Amin",
        "subjects": "Artificial Intelligence, Emerging Technologies",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.920386",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非构建、改进或演化LLM智能体本身。摘要明确指出，其核心是提出一个“Ten Criteria for Trustworthy Orchestration AI”（可信编排AI的十项标准）和一个“Control-Panel architecture”（控制面板架构）。这是一个关于**治理、保证和问责**的框架，旨在将“governance”（治理）嵌入AI系统的执行结构中。它关注的是如何控制和监督AI系统，而不是如何增强智能体的自主能力（如规划、工具使用）或使其自我演化。因此，它不属于“构建、改进或演化LLM智能体”的核心范畴。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文的核心主题完全落在了您明确排除的“安全与对齐”领域。 *   **关键词匹配:** 论文标题和摘要中充满了与排除标准高度相关的词汇，如 `Trustworthy` (可信)、`Governance` (治理)、`Audit` (审计)、`Provenance` (来源)、`Transparent` (透明)、`Verifiable` (可验证)、`Human Control` (人类控制)。这些都直接指向 `Safety` (安全)、`Security` (保障)、`Interpretability` (可解释性) 和 `Alignment` (对齐)。 *   **贡献定位:** 论文自己定位为“assurance framework”（保证框架），其目标是确保系统“verifiable, transparent, reproducible and under meaningful human control”（可验证、透明、可复现并处于有意义的人类控制之下）。这清晰地表明其主要贡献是关于AI系统的可信度和治理，而非智能体的能力或演化。 3.  **正面指标缺失 (第二步):** 尽管论文提到了“agentic AI”，但它特意将其工作与“conventional agentic AI initiatives that primarily focus on AI-to-AI coordination”（主要关注AI到AI协调的常规智能体AI计划）区分开来。论文中并未出现您关注的核心能力关键词，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Self-Evolving` 或 `Collaboration` 等。 **总结:** 该论文的研究焦点是**AI治理和安全**，旨在为AI系统（可能包括智能体）提供一个外部的、可审计的、受人类监督的控制层。它研究的是“如何管住智能体”，而不是“如何让智能体变得更聪明或能自我进化”。这与您关于“LLM智能体及其演化”的核心研究目标——探索智能体内在的能力构建和演化机制——存在根本性的偏差。因此，根据筛选标准，应予以排除。"
    },
    {
        "index": "#38",
        "title": "Robust AI Security and Alignment: A Sisyphean Endeavor?",
        "link": "/arxiv/2512.10100",
        "arxiv_id": "2512.10100",
        "authors": "Apostol Vassilev",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.930627",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献并非构建、改进或演化LLM智能体。根据摘要，该论文的核心是“为AI安全与对齐的鲁棒性建立了信息论限制”，其方法论是“将哥德尔不完备性定理扩展到AI”。这属于对AI系统根本性问题的理论分析，而不是提出一个新的智能体框架、规划方法或演化机制。因此，根据第一步的核心判断标准，这篇论文应被排除。 2.  **第二步：正面指标** 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。虽然提到了“认知推理限制”，但其上下文是为了证明AI的局限性，而非提出一种新的智能体推理框架。因此，该论文不满足任何正面指标。 3.  **第三步：排除标准** 这是最关键的排除依据。论文的标题和摘要开篇就明确指出了其研究主题是 **“AI Security and Alignment”**。根据我的筛选标准，只要论文的主要贡献是关于 `Safety`, `Security`, 或 `Alignment`，就应一律排除。这篇论文完全符合这一排除条件。 4.  **第四步：处理特殊和模糊情况** 论文虽然提到了“认知推理限制”，但它并非在探讨如何构建一个具有更强推理能力的智能体，而是在论证AI系统在安全与对齐方面存在的理论天花板。这属于“非Agentic的推理”的排除范畴，即它关注的是AI的基础能力边界，而非智能体的自主行为框架。 **最终决策**: 综合以上分析，该论文的核心贡献是关于AI安全与对齐的理论局限性研究，属于明确排除的研究方向。它并未提出任何关于构建、改进或演化LLM智能体的新方法或框架。因此，这篇论文与我的研究课题“LLM智能体及其演化”不相关，应予以排除。"
    },
    {
        "index": "#29",
        "title": "Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for Reasoning Modules",
        "link": "/arxiv/2512.10300",
        "arxiv_id": "2512.10300",
        "authors": "Yanbei Jiang, Xueqi Ma, Shu Liu, Sarah Monazam Erfani, Tongliang Liu, James Bailey, Jey Han Lau, Krista A. Ehinger",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.920918",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个**可解释性框架**，用于分析视觉语言模型（VLMs）内部注意力头的功能，而不是构建、改进或演化LLM智能体。摘要中明确指出 \"we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs\"。这属于对现有模型的分析和解读，而非构建新的智能体方法论或框架。 2.  **排除标准 (第三步):** 该论文直接命中了两个明确的排除标准： *   **安全与对齐:** 论文的核心是关于**可解释性**。摘要中反复强调 \"interpretability framework\"、\"analyze the internal mechanisms\"、\"provide new insights into the cognitive organization\"，这些都是典型的可解释性研究，而非智能体构建。 *   **多模态与视觉:** 论文的研究对象是**视觉语言模型**，标题和摘要中多次提及 \"Vision Language Models\" 和 \"multimodal\"。虽然它提到了\"reasoning\"，但这是在分析VLMs内部的多模态推理机制，而不是将视觉作为智能体与环境交互的工具。 3.  **对模糊情况的处理 (第四步):** *   **推理/规划:** 论文虽然提到了 \"reasoning\" 和 \"chain-of-thought paradigm\"，但其目的并非构建一个能自主规划和推理的智能体框架（如ReAct）。相反，它利用CoT作为一种**分析工具**来创建数据集，以**探测**模型内部的推理模块。这属于“非Agentic的推理”范畴，即研究模型本身如何推理，而不是构建一个使用推理能力的智能体。 **总结:** 该论文的本质是**模型可解释性研究**，专注于**多模态（VLMs）**领域。它旨在“打开黑箱”，理解模型内部的工作原理，这与您“构建、改进或演化LLM智能体”的核心目标完全不同。因此，尽管论文标题中包含\"Reasoning\"，但其研究范式和核心贡献均不符合您的筛选要求。"
    },
    {
        "index": "#36",
        "title": "AgriRegion: Region-Aware Retrieval for High-Fidelity Agricultural Advice",
        "link": "/arxiv/2512.10114",
        "arxiv_id": "2512.10114",
        "authors": "Mesafint Fanuel, Mahmoud Nabil Mahmoud, Crystal Cook Marshal, Vishal Lakhotia, Biswanath Dari, Kaushik Roy, Shaohu Zhang",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.929670",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **核心判断 (第一步): 论文的本质是“非演化型应用”。** 论文的核心贡献是提出了一个名为 \"AgriRegion\" 的检索增强生成（RAG）框架，其目标是解决LLM在农业领域提供区域特异性建议时出现的“上下文幻觉”问题。这完全符合第一步排除标准中的第一条：“非演化型应用”。该研究是将一个已有的技术（RAG，可视为一种工具使用）进行特定领域的改造和应用，以解决农业领域的具体问题（提供高保真、区域感知的咨询）。论文的创新点在于“地理空间元数据注入”和“区域优先重排序”这些针对农业应用的检索优化，而不是构建或改进一个通用的LLM智能体框架。 2.  **缺乏核心关注点 (第二步): 论文未涉及您研究的核心范式。** 尽管RAG可以被视为智能体“工具使用”能力的一部分，但论文的焦点并非智能体本身。它没有探讨智能体的规划、记忆、自我反思等核心能力，也没有涉及多智能体协作或自我演化机制。其正面指标仅停留在“工具使用”的浅层应用上，且是高度领域化的。 3.  **不符合特殊情况的例外 (第四步): 论文不涉及“自我演化”机制。** 第四步的例外规则指出，如果论文的核心是提出一种新的“自我演化”机制，即使应用在特定领域也应保留。然而，AgriRegion的核心是“检索增强”，而非“自我演化”。智能体并没有通过经验、反思或环境反馈进行自我完善和迭代，它只是在一个被严格限制和优化的知识库中进行检索。因此，该例外情况不适用。 **结论:** 该论文的本质是利用LLM和RAG技术解决一个垂直领域（农业）的应用问题。它的贡献在于提升特定任务（农业咨询）的准确性和可靠性，而不是推动LLM智能体本身在规划、记忆、协作或演化等基础能力上的进步。因此，它与您“构建、改进或演化LLM智能体”的核心目标相悖，应被排除。"
    },
    {
        "index": "#41",
        "title": "Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research",
        "link": "/arxiv/2512.10058",
        "arxiv_id": "2512.10058",
        "authors": "Dani Roytburg, Beck Miller",
        "subjects": "Artificial Intelligence, Computers and Society, Human-Computer Interaction, Social and Information Networks",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.937297",
        "filter_reason": "这篇论文不符合研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非构建、改进或演化LLM智能体。根据摘要，该论文是一项“大规模的定量研究”，其核心是使用“文献计量和合著网络分析”来研究“AI安全”和“AI伦理”这两个学术社群之间的结构性分裂。这属于对学术研究本身的社会学分析，而非提出新的智能体技术或框架。因此，它在第一步的核心判断中就应被排除。 2.  **排除标准 (第三步):** 这是最直接和关键的排除依据。论文的标题和摘要明确指出，其研究主题是“统一AI安全与伦理研究”。摘要中反复出现的关键词，如 `harmless` (无害)、`aligned` (对齐)、`AI safety` (AI安全)、`ethics` (伦理)、`social bias` (社会偏见) 等，都直接命中了筛选标准中明确规定的排除项：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` (可解释性), `Explainability (XAI)`, `Alignment` (对齐)... 一律排除。” 3.  **缺乏正面指标 (第二步):** 论文摘要中完全没有出现任何与研究焦点相关的正面指标，如 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving` 等。这进一步证实了它与你的研究目标无关。 综上所述，该论文是一篇关于AI研究社群结构的社科/科学计量学研究，其核心贡献完全聚焦于AI安全与伦理领域，与“构建、改进或演化LLM智能体”这一核心目标相去甚远。因此，应果断排除。"
    },
    {
        "index": "#40",
        "title": "Linear socio-demographic representations emerge in Large Language Models from indirect cues",
        "link": "/arxiv/2512.10065",
        "arxiv_id": "2512.10065",
        "authors": "Paul Bouchaud, Pedro Ramaciotti",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.936761",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是**分析和解释**LLM内部如何表征社会人口统计信息（如性别、种族），并揭示这些表征如何导致隐式偏见。这是一项**诊断性/分析性**的研究，而非**建设性/生成性**的研究。它没有提出任何关于如何构建、改进或演化LLM智能体的新方法、框架或机制。因此，它不符合“核心贡献在于构建、改进或演化LLM智能体”这一根本要求，应被排除。 2.  **第二步：正面指标** 论文中完全没有出现您所关注的核心范式和能力指标。它没有涉及`Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`，也没有讨论智能体的`Planning`、`Tool Use`、`Memory`或`Self-Reflection`等能力。因此，它不满足任何正面指标。 3.  **第三步：排除标准** 这是最关键的排除依据。该论文的主要贡献明确属于**`Interpretability` (可解释性)** 和 **`Safety` (安全，特别是其中的公平性/Fairness)** 范畴。摘要中明确提到“解释人口统计推断”、“可解释的几何方向”、“隐式偏见”以及“公平性影响”。根据您的筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` ... 一律排除”。这篇论文是典型的模型可解释性与偏见分析研究，因此被明确排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及推理/规划或自我演化的特殊情况，因此此步不适用。 **最终决策**：综合以上分析，该论文是一项关于LLM内部表征和偏见的分析性研究，其核心贡献在于模型的可解释性与安全性，而非LLM智能体的构建、协作或演化。因此，它与您的研究课题“LLM智能体及其演化”不相关，应予以排除。"
    },
    {
        "index": "#56",
        "title": "Natural Language Interface for Firewall Configuration",
        "link": "/arxiv/2512.10789",
        "arxiv_id": "2512.10789",
        "authors": "F. Taghiyev, A. Aslanbayli",
        "subjects": "Networking and Internet Architecture, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.951355",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **第一步：核心判断——本质是“非演化型应用”** 论文的核心贡献是设计并实现了一个用于**配置企业防火墙**的自然语言接口。这是一个典型的将LLM作为工具应用到特定领域（网络安全/防火墙管理）的案例。论文明确指出：“Large language models are used only as assistive parsers that generate typed intermediate representation objects, while compilation and enforcement remain deterministic.” 这句话是关键，它表明LLM在此系统中仅扮演一个**辅助解析器**的角色，而不是一个具有自主性的智能体。整个系统的核心是确定性的编译和验证流程，而非LLM的智能体能力。因此，该论文完全符合“非演化型应用”的排除标准。 2.  **第二步：缺乏正面指标** 论文中没有出现任何我关注的核心范式或智能体能力。它不涉及`Agentic AI`框架的构建，没有讨论智能体的`Planning`、`Tool Use`（LLM本身是工具，但智能体没有使用工具的能力）、`Memory`或`Self-Reflection`。它也不是关于`Multi-Agent`系统或`Self-Evolving`机制的。 3.  **第三步：触及排除标准** 论文的研究领域是防火墙配置，这本质上是一个网络安全问题。文中提到的“safety gate that blocks overly permissive rules”进一步表明其贡献与安全策略紧密相关。虽然其主要贡献不是安全对齐理论，但其应用场景和核心问题都落在了“安全”这一排除焦点的外围，进一步确认了它与我的研究目标不符。 **总结**：该论文的本质是利用LLM的解析能力来构建一个特定领域的应用系统，而非研究LLM智能体本身的构建、改进或演化。LLM在其中只是一个功能组件，而不是研究的主体。因此，它被严格排除。"
    },
    {
        "index": "#43",
        "title": "SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration",
        "link": "/arxiv/2512.10046",
        "arxiv_id": "2512.10046",
        "authors": "Yan Zhuang, Jiawei Ren, Xiaokang Ye, Jianzhi Shen, Ruixuan Zhang, Tianai Yue, Muhammad Faayez, Xuhong He, Ziqiao Ma, Lianhui Qin, Zhiting Hu, Tianmin Shu",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.938389",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建了一个名为 **SimWorld-Robotics (SWR) 的模拟平台**，并基于该平台创建了两个用于评估机器人能力的**基准**。这完全符合第一步中的排除标准： *   **基础设施:** 论文的主要工作是开发一个基于Unreal Engine 5的模拟环境，这属于模型开发和测试的基础设施。 *   **非演化型应用:** 论文的目标是为机器人控制领域提供一个更逼真的测试环境，它将智能体（或VLMs）作为评估对象，而不是提出一种新的智能体构建、改进或演化的方法论。 2.  **正面指标分析 (第二步):** 尽管摘要中提到了 `multi-agent search task`、`collaboration`、`communication` 和 `planning abilities` 等正面指标，但这些词汇是用来描述**基准任务所需要评估的能力**，而不是论文本身提出的新方法。论文的核心是“如何构建一个能测试这些能力的平台”，而不是“如何让智能体更好地具备这些能力”。 3.  **排除标准确认 (第三步):** 论文的研究内容高度依赖**多模态与视觉**。摘要明确指出其平台是 `photorealistic` 的，任务涉及 `multimodal instruction-following` 和 `vision-language models (VLMs)`。视觉和多模态是论文所构建环境的基石，而不仅仅是智能体使用的工具，这触发了第三步的排除标准。 4.  **特殊与模糊情况处理 (第四步):** *   **推理/规划:** 论文提到现有模型缺乏 `reasoning, and planning abilities`，但其目的是通过基准来**揭示**这一不足，而不是提出一种新的智能体规划框架。因此，这属于排除情况。 *   **自我演化的应用:** 论文不涉及任何自我演化机制。 **最终决策 (第五步):** 综合以上分析，该论文的本质是**为具身智能和机器人领域提供一个先进的模拟环境和评估基准**。它是一个非常有价值的工具型研究，但其核心贡献并非关于LLM智能体的构建、协作或演化机制本身。因此，它不符合您“核心贡献在于构建、改进或演化LLM智能体”的研究目标，应予以排除。"
    },
    {
        "index": "#50",
        "title": "ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples",
        "link": "/arxiv/2512.09931",
        "arxiv_id": "2512.09931",
        "authors": "Akaash Chatterjee, Suman Kundu",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.947190",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用，而非方法论。** 论文的核心贡献是构建了一个名为 \"ExaCraft\" 的**个性化教育应用系统**。它使用LLM（Google Gemini）作为工具，来解决教育领域中“生成个性化学习案例”的具体问题。这完全符合筛选标准中的第一条排除规则：“非演化型应用: 如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗、金融、法律、机器人控制等）。” 在这里，特定领域就是**教育**。 2.  **第二步：正面指标分析——缺乏核心关注点。** 尽管论文提到了“动态上下文适应”和“演化”，但这些词汇是在应用层面描述的。它没有提出新的 `Agentic AI` 范式、`Multi-Agent Systems` 框架或 `Self-Evolving` 机制。系统虽然具备一定的记忆（如“主题进展历史”）和反应能力（如“响应挣扎指标”），但这些是作为其教育应用功能的实现细节，而非论文的核心创新点。论文的重点在于如何利用这些能力来提升教育效果，而不是如何构建一个通用的、具有这些能力的智能体框架。 3.  **第四步：处理特殊和模糊情况——不满足“自我演化”的例外条件。** 这是判断的关键点。论文中提到的“演化”是指**系统生成的学习案例**从基础到高级的演化，以及根据用户行为的变化而调整。这属于**输出内容的动态调整**，而不是**智能体系统本身的自我完善和迭代**。系统本身并没有通过经验、反思或环境反馈来改进其核心算法或架构。因此，它不符合“自我演化”的核心定义，也不满足“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域，也应该保留”的例外规则。 **结论:** 该论文的本质是一个将LLM应用于教育领域的应用型研究。其核心贡献在于解决个性化学习的问题，而非构建、改进或演化LLM智能体的方法论。因此，它不符合您关于“LLM智能体及其演化”的核心研究目标，应予以排除。"
    },
    {
        "index": "#59",
        "title": "Metaphor-based Jailbreaking Attacks on Text-to-Image Models",
        "link": "/arxiv/2512.10766",
        "arxiv_id": "2512.10766",
        "authors": "Chenyu Zhang, Yiwen Ma, Lanjun Wang, Wenhui Li, Yi Tu, An-An Liu",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-06",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.958168",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为MJA的**越狱攻击方法**，用于攻击文生图（T2I）模型。虽然该方法内部包含一个“基于LLM的多智能体生成模块（MLAG）”，但这个多智能体系统是作为实现攻击的**工具或手段**，而不是论文研究的核心目标。论文的本质是**安全与攻防研究**，而非构建或演化LLM智能体本身。根据第一步的排除规则，这属于“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”，这里的特定领域就是“AI安全与攻击”。 2.  **第二步：正面指标** 论文确实包含了一些正面指标，如 `LLM-based Agents`、`Multi-Agent Systems (MAS)` 和 `Collaboration`。MLAG模块协调多个智能体完成子任务，这在表面上看起来与“多智能体”方向相关。然而，这些指标的存在是为了服务于其核心的攻击目的，而不是为了探索智能体本身的新能力或演化机制。 3.  **第三步：排除标准** 这是最关键的一步。论文的核心贡献明确属于 `Security`（安全）和 `Safety`（安全）范畴。其标题、摘要和实验评估都围绕着“越狱攻击”、“绕过防御机制”和“攻击性能”展开。根据第三步的排除标准：“只要论文的主要贡献是关于 `Safety`, `Security`...一律排除。” 这条标准直接适用于本论文，因此必须排除。 4.  **第四步：处理特殊和模糊情况** 本论文的情况不属于“自我演化的应用”例外。虽然它使用了多智能体，但其目的不是提出一种新的智能体演化范式，而是利用智能体协作来生成更有效的攻击提示。它也不是关于提升智能体在通用任务上的规划或推理能力，而是将这种能力应用于一个非常具体的安全攻击场景。 **最终决策**: 综合以上分析，尽管该论文在技术上使用了多智能体框架，但其**核心贡献和研究焦点是AI安全攻防**，而不是LLM智能体的构建、改进或演化。根据您设定的筛选标准，特别是第三步关于安全与对齐的明确排除规则，这篇论文应被排除。它属于将智能体技术应用于安全领域的应用型研究，而非您所关注的Agentic AI基础研究。"
    },
    {
        "index": "#66",
        "title": "Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition",
        "link": "/arxiv/2512.10688",
        "arxiv_id": "2512.10688",
        "authors": "Lingfeng Liu, Yixin Song, Dazhong Shen, Bing Yin, Hao Li, Yanyong Zhang, Chao Wang",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.967318",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献分析**: 这篇论文的核心是提出一种名为“方向分解与校正”（DDC）的数学框架，用于解决协同过滤（CF）推荐系统中的“流行度偏差”问题。它通过分析贝叶斯个性化排序（BPR）优化过程中的嵌入几何结构，来校正模型偏差。 - **与我的研究目标对比**: 我的核心目标是筛选关于“构建、改进或演化LLM智能体”的论文。这篇论文的研究对象是传统的推荐系统模型（CF/BPR），而非LLM智能体。它提出的是一种针对特定领域（推荐系统）问题的算法改进，而不是一个通用的智能体框架或演化机制。 - **结论**: 该论文属于“非演化型应用”，即将一种数学方法应用于特定领域解决该领域的问题。因此，根据第一步的筛选标准，应予以**排除**。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 也没有提及任何智能体能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 这进一步确认了该论文与我的研究焦点无关。 3.  **第三步：排除标准** - 虽然论文不属于“安全与对齐”或“多模态与视觉”的排除类别，但第一步的排除理由已经足够充分。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“分析”和“校正”是针对模型嵌入向量的数学操作，而非智能体在任务执行中的自主规划或多步推理过程。因此不适用保留规则。 - **自我演化的应用**: 论文提出的DDC框架是一种静态的校正方法，而不是一个能让智能体通过经验或反馈进行自我完善和迭代的“自我演化”机制。因此不适用例外保留规则。 **最终决策**: 综合以上分析，这篇论文的本质是改进推荐系统算法，与“LLM智能体及其演化”这一核心课题完全无关。它没有构建智能体，没有研究多智能体交互，也没有提出自我演化机制。因此，最终判断为 **False**，应予以排除。"
    },
    {
        "index": "#49",
        "title": "Suzume-chan: Your Personal Navigator as an Embodied Information Hub",
        "link": "/arxiv/2512.09932",
        "arxiv_id": "2512.09932",
        "authors": "Maya Grace Torii, Takahito Murakami, Shuka Koseki, Yoichi Ochiai",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.941548",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 论文的核心贡献是提出一个名为“Embodied Information Hub”（具身信息中心）的**新型人机交互范式**。其理论基础是“社会临场理论”，目标是“减少心理距离”和“让知识共享更温暖、更以人为本”。论文的重点在于**用户体验（UX）和人机交互（HCI）**，而非智能体本身的架构或能力演化。 - **是否符合**: 这篇论文属于典型的**非演化型应用**。它将一个已有的技术组合（本地运行的LLM + RAG）封装在一个物理设备中，并将其应用于“知识共享与导航”这一特定领域，以解决该领域的人机交互问题。它没有提出新的构建、改进或演化LLM智能体的方法论或框架。因此，根据第一步的排除规则，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中提到了“AI agent”和“retrieval-augmented generation (RAG)”。RAG可以被视为一种工具使用和记忆机制。然而，这些只是论文用来实现其目标的**现有技术组件**，而不是论文的研究重点。论文并未深入探讨如何改进RAG，或如何设计更高级的规划、自我反思等智能体能力。因此，这些正面指标的出现并不足以改变其应用型论文的本质。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文的主要贡献不涉及安全、对齐或多模态等排除标准。但其核心焦点——人机交互、社会临场感、心理距离——同样在您的研究焦点之外。 4.  **第四步：处理特殊和模糊情况** - 论文不涉及新的推理/规划框架，也不涉及任何自我演化机制，因此不适用特殊情况的例外规则。 **最终决策**: 综合以上分析，该论文的本质是一项**人机交互（HCI）研究**，它利用LLM智能体作为实现其交互理念的载体。其核心贡献在于**应用层面**的创新，而非**智能体方法论**的突破。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标不符。因此，最终判断为 **False**。"
    },
    {
        "index": "#65",
        "title": "How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning",
        "link": "/arxiv/2512.10698",
        "arxiv_id": "2512.10698",
        "authors": "Jianbo Wang, Galina Sidorenko, Johan Thunberg",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.961633",
        "filter_reason": "这篇论文不符合我的研究范围，原因如下： 1.  **核心判断 (第一步): 论文本质是“非演化型应用”** 论文的核心贡献是提出一种结合深度强化学习（DRL）和解析方法的混合算法，用于解决网联自动驾驶车辆（CAVs）在紧急情况下的伦理制动问题。这是一个典型的将AI技术（此处是DRL，而非LLM）应用于特定领域（自动驾驶/机器人控制）以解决该领域安全问题的研究。它没有构建或改进一个通用的LLM智能体框架，而是将DRL作为解决车辆控制问题的工具。根据筛选标准，这属于“非演化型应用”，应被排除。 2.  **排除标准 (第三步): 论文核心贡献是“安全与对齐”** 论文的标题和摘要反复强调其研究焦点是“伦理紧急制动”、“安全要求”、“避免碰撞”和“减少伤害”。这表明论文的主要贡献在于解决一个具体的安全和伦理决策问题。根据筛选标准，只要论文的主要贡献是关于 `Safety` 或 `Ethics`（伦理，属于对齐范畴），就应一律排除。 3.  **正面指标缺失 (第二步): 缺乏LLM智能体的核心要素** 论文的研究方法基于深度强化学习（DRL），完全没有提及大语言模型（LLM）。因此，它不涉及任何与LLM智能体相关的核心范式或能力，如 `Agentic AI`、`LLM-based Agents`、`Tool Use`、`Memory`、`Self-Reflection` 等。虽然提到了“多车”场景和“车对车通信”，但其研究重点是优化单个车辆的制动策略以实现整体伤害最小化，而不是研究智能体间的协作、通信或社会学习机制。 综上所述，该论文既不是关于LLM智能体的构建，其核心贡献又属于明确排除的“安全与对齐”范畴，因此与研究课题“LLM智能体及其演化”完全不相关。"
    },
    {
        "index": "#68",
        "title": "Beyond Pixels: A Training-Free, Text-to-Text Framework for Remote Sensing Image Retrieval",
        "link": "/arxiv/2512.10596",
        "arxiv_id": "2512.10596",
        "authors": "J. Xiao, Y. Guo, X. Zi, K. Thiyagarajan, C. Moreira, M. Prasad",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.968649",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文本质是“非演化型应用”** 论文的核心贡献是提出了一种名为TRSLLaVA的“免训练、纯文本”的遥感图像检索框架。它利用VLM（视觉语言模型）为图像生成文本描述，然后将图像检索任务转化为文本匹配问题。这里，VLM是作为一个**工具**被用来解决特定领域（遥感）的特定问题（图像检索）。论文并未构建、改进或演化任何LLM智能体框架，其核心是应用层面的方法论创新，而非智能体本身的架构或能力演进。这完全符合第一步排除标准中的“非演化型应用”。 2.  **第三步：排除标准——论文属于“多模态与视觉”研究焦点之外** 论文的标题和摘要明确指出，其研究内容是关于“遥感图像检索”，并依赖于“视觉语言模型”。整个研究的核心是解决跨模态（图像-文本）检索中的“语义鸿沟”问题。虽然它使用了文本，但其本质是视觉领域的研究。根据您的筛选标准，只要论文的核心不是将多模态作为智能体感知环境的工具，而是研究多模态本身，就应被排除。本论文的研究焦点正是后者。 3.  **第二步：正面指标——缺乏核心关注点** 通览摘要，论文完全没有提及任何与您研究焦点相关的核心范式或能力，例如 `Agentic AI`, `Planning`, `Tool Use` (在智能体自主选择的意义上), `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。这进一步证实了该论文与您的研究课题无关。 **总结**：该论文是一项将VLM应用于遥感图像检索的应用研究，其核心贡献在于提出了一种新颖的、免训练的检索范式。它不涉及LLM智能体的构建、规划、记忆、自我演化或任何多智能体交互。因此，它严格地落在了您设定的排除范围之内。"
    },
    {
        "index": "#75",
        "title": "An M-Health Algorithmic Approach to Identify and Assess Physiotherapy Exercises in Real Time",
        "link": "/arxiv/2512.10437",
        "arxiv_id": "2512.10437",
        "authors": "Stylianos Kandylakis, Christos Orfanopoulos, Georgios Siolas, Panayiotis Tsanakas",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.977533",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是“非演化型应用”** 论文的核心贡献是提出一个用于实时识别和评估物理治疗练习的“算法框架”。其技术栈包括姿态估计神经网络、基于角度的特征提取、轻量级监督模型和动态规划序列匹配。这是一个典型的将机器学习/计算机视觉技术应用于特定领域（m-health，物理治疗）的案例。它没有构建、改进或演化任何形式的LLM智能体，而是将一个固定的算法流程应用于解决一个具体的垂直领域问题。这完全符合第一步排除标准中的“非演化型应用”。 2.  **第二步：正面指标——完全不匹配** 论文的标题和摘要中，完全没有出现任何与您核心关注点相关的正面指标。例如，没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何关键词。这表明论文的研究方向与您的课题相去甚远。 3.  **第三步：排除标准——属于“多模态与视觉”范畴** 论文的核心技术之一是使用“姿态估计神经网络”从“相机输入”中提取人体关键点。这明确属于计算机视觉的范畴。根据您的排除标准，除非视觉是作为智能体感知环境的工具，否则应被排除。在这篇论文中，视觉处理本身就是研究的核心，而不是服务于一个更高层次的LLM智能体。因此，它触发了“多模态与视觉”的排除规则。 4.  **第四步：特殊和模糊情况——不适用** 论文中提到的“动态规划方案”是一种用于序列匹配的算法，而非智能体在复杂任务中的自主规划过程。因此，它不属于“保留”的推理/规划范畴。同时，论文也未提出任何“自我演化”机制。 **总结**: 该论文的本质是一个应用于医疗健康领域的计算机视觉和序列建模算法，其目标是解决物理治疗动作识别与评估这一具体问题。它完全不涉及LLM智能体的构建、多智能体交互或自我演化机制。因此，它严格地落在了您研究范围之外，应予以排除。"
    },
    {
        "index": "#77",
        "title": "Beyond Endpoints: Path-Centric Reasoning for Vectorized Off-Road Network Extraction",
        "link": "/arxiv/2512.10416",
        "arxiv_id": "2512.10416",
        "authors": "Wenfei Guan, Jilin Mei, Tong Shen, Xumin Wu, Shuo Wang, Cheng Min, Yu Hu",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.978576",
        "filter_reason": "这篇论文不符合研究范围。 我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是两点：1）发布了一个名为WildRoad的越野路网数据集；2）提出了一个名为MaGRoad的计算机视觉框架，用于从图像中矢量化提取越野道路网络。这完全符合第一步的**排除标准1：非演化型应用**。该论文将一个深度学习模型（MaGRoad）作为工具，应用到了一个特定领域（地理信息系统/遥感图像分析），去解决该领域的具体问题（道路提取）。它并没有构建、改进或演化一个通用的LLM智能体框架。 2.  **第二步：正面指标** 论文中完全没有出现任何核心关注点的关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** 该研究本质上是一个**计算机视觉**任务。其核心是处理视觉信息（\"multi-scale visual evidence\"）来推断道路的连接性，这完全符合第三步的排除标准。虽然视觉可以作为智能体的感知工具，但在这篇论文中，视觉处理本身就是研究的核心，而不是服务于一个更高层次的智能体目标。 4.  **第四步：处理特殊和模糊情况** 论文标题和摘要中提到了 \"Reasoning\"（推理）。这是一个需要辨析的关键点。根据规则，我需要判断这是智能体的推理还是非Agentic的推理。这里的 \"path-centric reasoning\" 指的是一种在视觉和几何层面，沿着候选路径聚合证据以推断连接性的算法，是一种模型内部的、特定于任务的计算过程。它**不是**关于智能体如何进行自主规划、制定行动序列或使用工具的推理框架。因此，它属于“非Agentic的推理”，应被排除。 **最终决策**：综合以上分析，该论文是一篇典型的计算机视觉应用研究，其核心贡献在于解决特定领域的图像分割和网络提取问题。它不涉及LLM、智能体架构、多智能体交互或自我演化机制。因此，它完全不符合“LLM智能体及其演化”这一研究课题的要求。"
    },
    {
        "index": "#60",
        "title": "Designing AI-Resilient Assessments Using Interconnected Problems: A Theoretically Grounded and Empirically Validated Framework",
        "link": "/arxiv/2512.10758",
        "arxiv_id": "2512.10758",
        "authors": "Kaihua Ding",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.958618",
        "filter_reason": "这篇论文不符合研究范围。 我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个用于设计“AI韧性”教育评估的理论框架和实践方法。其目标是解决计算教育领域的学术诚信问题，防止学生滥用生成式AI完成作业。这完全符合**排除标准中的“非演化型应用”**。该论文将LLM（及其在多步推理上的局限性）作为一个分析对象和工具，来解决一个特定领域（教育）的问题，而不是提出一种构建、改进或演化LLM智能体的新方法。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中没有出现任何与我的研究焦点直接相关的正面指标。它没有讨论`Agentic AI`框架、`Multi-Agent`系统或`Self-Evolving`机制。虽然提到了“multi-step reasoning”，但这只是为了论证其评估方法有效性的一个前提（即LLM不擅长此道），而不是论文要解决的核心技术问题。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的研究焦点是教育技术和评估方法，这本身就在我的研究焦点之外。虽然它触及了AI的能力边界，但其主要贡献并非关于`Safety`或`Alignment`，而是教育领域的应用。 4.  **第四步：处理特殊和模糊情况** - **推理/规划:** 论文明确指出，其设计的“互联问题”评估之所以有效，是因为“当前语言模型在持续的多步推理和上下文处理方面存在困难”。这表明论文是在**利用**LLM的推理弱点，而不是在**改进**LLM的推理能力或构建一个能进行复杂规划的智能体。因此，它符合“排除”规则：只是关于LLM基础推理能力的观察，而非智能体框架内的规划方法。 - **自我演化的应用:** 论文完全不涉及任何自我演化机制。 **最终决策：** 综合以上分析，这篇论文的研究视角是教育技术，其核心产出是给教育工作者的评估设计框架。它虽然分析了LLM的能力，但目的在于“对抗”AI而非“构建”AI。因此，它与“构建、改进或演化LLM智能体”的核心目标完全不符，应予以排除。"
    },
    {
        "index": "#82",
        "title": "Cross-modal Retrieval Models for Stripped Binary Analysis",
        "link": "/arxiv/2512.10393",
        "arxiv_id": "2512.10393",
        "authors": "Guoqiang Chen, Lingyun Ying, Ziyang Song, Daguang Liu, Qiang Wang, Zhiqi Wang, Li Hu, Shaoyin Cheng, Weiming Zhang, Nenghai Yu",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.981474",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。判断依据如下： 1.  **核心判断（第一步）：论文的本质是“非演化型应用”。** 论文的核心贡献是提出了一个名为 `BinSeek` 的跨模态检索框架，用于解决“二进制代码分析”这一特定领域的问题。尽管摘要开头提到了“LLM-agent based binary code analysis”，但这仅仅是作为研究背景和应用场景，论文本身的核心工作是构建一个高效的检索模型，而不是构建、改进或演化LLM智能体本身。这完全符合第一步排除标准中的“非演化型应用”：将LLM（或相关技术）作为工具应用到特定领域（软件安全）去解决该领域的检索问题。 2.  **正面指标缺失（第二步）：论文不包含我的核心关注点。** 论文的关键词和贡献集中在“cross-modal retrieval”、“stripped binary analysis”、“embedding”和“reranker”上。它没有涉及我研究焦点的核心范式，如 `Agentic AI` 框架的设计、`Multi-Agent` 系统的协作机制，或 `Self-Evolving` 的演化算法。智能体的核心能力如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等也均未作为论文的贡献点被提出或研究。 3.  **符合排除标准（第三步）：论文属于特定领域的应用研究。** 论文的应用领域是“软件安全”，具体是“漏洞检测、恶意软件分析”等。虽然其主要贡献不是安全与对齐本身，但其研究动机和评估基准完全根植于这一特定领域。这进一步印证了它是一个应用型研究，而非关于智能体基础架构或演化的研究。 4.  **特殊和模糊情况处理（第四步）：不适用。** 论文不涉及新的推理/规划框架，也没有提出任何“自我演化”机制。它提到的“LLM-based data synthesis pipeline”是用于构建训练数据集的工具，而非论文研究的核心智能体机制。 **总结：** 该论文的本质是利用LLM相关技术（如嵌入）来解决二进制代码检索这一特定领域的工程问题。它虽然可能被用作某个LLM智能体的一个组件（检索工具），但其本身的研究贡献并非关于智能体的构建、协作或演化。因此，它严格地属于“非演化型应用”，与我的核心研究目标“构建、改进或演化LLM智能体”不符，应被排除。"
    },
    {
        "index": "#85",
        "title": "Neural personal sound zones with flexible bright zone control",
        "link": "/arxiv/2512.10375",
        "arxiv_id": "2512.10375",
        "authors": "Wenye Zhu, Jun Tang, Xiaofei Li",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.991234",
        "filter_reason": "这篇论文的核心贡献是提出了一种用于解决“个人声场”音频工程问题的3D卷积神经网络（CNN）方法。 根据筛选标准的第一步“核心判断”，这篇论文的本质属于“非演化型应用”。它将一个神经网络（CNN）作为工具，应用于音频信号处理这一特定领域，旨在解决声学场景再现的技术难题，而不是构建、改进或演化LLM智能体。 具体分析如下： 1.  **核心贡献不符**: 论文的核心是设计一个CNN模型来优化声场滤波器，这是一个典型的信号处理/音频工程领域的应用研究，与Agentic AI无关。 2.  **技术路线不符**: 论文使用的是3D CNN，而非LLM。我的研究焦点是“LLM智能体”，因此不使用LLM作为核心组件的论文首先就不符合基本要求。 3.  **缺乏关键指标**: 论文中完全没有涉及筛选标准第二步中的任何正面指标，如`Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving`等。它描述的是一个静态的、一次训练完成的模型，不具备智能体的自主性、规划能力或演化能力。 4.  **明确属于排除类别**: 该论文完美符合第一步排除标准中的“非演化型应用”——将一个已有的模型框架（CNN）应用到特定领域（音频/虚拟现实）去解决该领域的问题。 综上所述，该论文与“LLM智能体及其演化”的研究课题完全不相关，应被排除。"
    },
    {
        "index": "#78",
        "title": "How to Trick Your AI TA: A Systematic Study of Academic Jailbreaking in LLM Code Evaluation",
        "link": "/arxiv/2512.10415",
        "arxiv_id": "2512.10415",
        "authors": "Devanshu Sahoo, Vasudev Majhi, Arjun Neekhra, Yash Sinha, Murari Mandal, Dhruv Kumar",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.979125",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出并系统研究了一种针对LLM代码评估器的“学术越狱”攻击方法。它构建了一个攻击框架、一个用于攻击的数据集，并定义了评估攻击效果的指标。其本质是**对现有LLM应用的安全性进行攻击和评估**，而不是**构建、改进或演化LLM智能体本身**。因此，根据第一步的排除规则，这属于“非演化型应用”，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中没有出现任何与您核心关注点相关的正面指标。它没有讨论智能体的规划、记忆、工具使用、自我反思、多智能体协作或自我演化机制。虽然被攻击的对象是一个“LLM代码评估器”，但论文的研究焦点是外部如何攻击它，而不是该评估器内部如何作为一个智能体进行工作或进化。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这是最关键的一步。论文的核心主题是“Jailbreaking”（越狱），这直接命中了第三步中的排除标准：**安全与安全**。论文的全部贡献，包括攻击策略、数据集和评估指标，都围绕着LLM系统的安全漏洞展开。根据筛选规则，只要论文的主要贡献是关于 `Security`，就应一律排除。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及推理/规划或自我演化的特殊情况，因此此步不适用。 **最终决策**: 综合以上分析，尽管这篇论文研究的是LLM在特定场景下的应用，但其核心贡献是关于**安全攻击**，而非**智能体的构建或演化**。它完全符合第三步的排除标准，与您“LLM智能体及其演化”的研究目标（单智能体、多智能体、自我演化）背道而驰。因此，最终判断为 **False**，应排除此论文。"
    },
    {
        "index": "#84",
        "title": "Towards Fine-Grained Recognition with Large Visual Language Models: Benchmark and Optimization Strategies",
        "link": "/arxiv/2512.10384",
        "arxiv_id": "2512.10384",
        "authors": "Cong Pang, Hongtao Yu, Zixuan Chen, Lewei Lu, Xin Lou",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.990718",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质不符** 论文的核心贡献是针对**大型视觉语言模型**的**细粒度识别能力**进行优化。它提出了一个新的基准和一个数据/训练策略来提升模型在识别任务上的表现。这属于对基础模型（LVLM）特定能力的改进，而不是构建、改进或演化一个具有自主性的**LLM智能体**。根据筛选标准，这属于“非演化型应用”，即将模型作为工具来解决特定领域（视觉识别）的问题，因此应被排除。 2.  **第三步：排除标准——触及明确的排除项** 论文的标题和摘要都明确指出其研究对象是“Large **Visual** Language Models (LVLMs)”。这直接触发了您设定的“多模态与视觉”排除标准。研究的核心是视觉感知和识别，而不是Agentic AI的规划、工具使用或演化机制。即使视觉能力可以作为智能体的一部分，但在这篇论文中，它是研究的核心主题，而非智能体框架的附属工具。 3.  **第二步：正面指标——缺乏核心关注点** 通读摘要，论文完全没有提及任何与您研究焦点相关的关键词或概念。例如，它没有涉及 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）、`Multi-Agent`（多智能体）或 `Self-Evolving`（自我演化）等。其方法论是数据构建和训练过程优化，这与智能体的架构和行为机制有本质区别。 **总结**: 该论文的研究目标是提升LVLMs的视觉识别精度，属于计算机视觉和多模态模型领域的前沿研究。然而，它的核心贡献与“LLM智能体及其演化”这一课题无关。它既没有提出新的智能体框架，也没有探讨智能体的自主行为、协作或演化机制。因此，根据您的筛选标准，这篇论文应被明确排除。"
    },
    {
        "index": "#83",
        "title": "The Best of the Two Worlds: Harmonizing Semantic and Hash IDs for Sequential Recommendation",
        "link": "/arxiv/2512.10388",
        "arxiv_id": "2512.10388",
        "authors": "Ziwei Liu, Yejing Wang, Qidong Liu, Zijian Zhang, Chong Chen, Wei Huang, Xiangyu Zhao",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.982035",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为 `\\name` 的新框架，用于改进**序列推荐系统**。它通过调和语义ID（SID）和哈希ID（HID）来解决推荐系统中的长尾问题。这完全符合筛选标准中的第一条排除规则：**“非演化型应用”**。该论文将一个新颖的模型架构应用于“推荐系统”这一特定领域，旨在解决该领域内的技术问题，其本质是应用研究，而非关于智能体本身的构建或演化。 2.  **第二步：正面指标** 在论文的标题和摘要中，完全没有出现任何与研究焦点相关的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。这进一步确认了它与我的研究目标无关。 3.  **第三步：排除标准** 虽然论文不涉及安全与对齐或多模态等排除项，但第一步的排除理由已经足够充分。 4.  **第四步：处理特殊和模糊情况** 论文的研究焦点是物品嵌入和用户-物品交互建模，这与智能体的自主规划、工具使用、多智能体协作或自我演化机制完全无关。它不属于任何需要特殊处理的模糊情况。 **最终决策**：这篇论文是一篇典型的推荐系统领域的应用研究。它的核心目标是提升推荐算法的性能，而不是构建或演化LLM智能体。因此，它与研究课题“LLM智能体及其演化”的核心目标完全偏离，应予以排除。"
    },
    {
        "index": "#64",
        "title": "PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code",
        "link": "/arxiv/2512.10713",
        "arxiv_id": "2512.10713",
        "authors": "Itay Dreyfuss, Antonio Abu Nassar, Samuel Ackerman, Axel Ben David, Rami Katan, Orna Raz, Marcel Zalmanovici",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.961146",
        "filter_reason": "这篇论文的核心贡献是提出了一个名为PACIFIC的**基准测试生成框架**，用于评估LLM在代码任务中遵循指令和进行“代码空运行”的能力。根据您的筛选标准，这篇论文不符合您的研究范围，原因如下： 1.  **核心判断（第一步）：** 论文的本质是**评估**而非**构建或演化**。PACIFIC框架的核心功能是生成测试用例来衡量LLM的一项基础能力，而不是提出一种新的LLM智能体架构、改进智能体的规划/记忆/工具使用能力，或设计一种自我演化机制。论文摘要中明确指出：“In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM's intrinsic ability...” 这直接表明该研究刻意与“智能体行为”划清界限，专注于评估LLM的“内在能力”，这属于**非Agentic的推理**范畴，应被排除。 2.  **正面指标缺失（第二步）：** 论文的研究焦点是评估“instruction following”和“dry running”，并未涉及您关注的核心范式和能力。摘要中完全没有提及 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等任何正面指标关键词。相反，它强调了与这些概念的分离。 3.  **特殊情况的适用性（第四步）：** 这篇论文恰好是“推理/规划”排除标准的一个典型例子。它研究的是LLM在代码场景下的基础推理能力（遵循顺序指令、模拟代码执行），而不是一个智能体如何进行自主规划或在复杂任务中调用工具。因此，尽管涉及“推理”，但它属于应被排除的“非Agentic的推理”。 综上所述，PACIFIC是一个关于LLM能力评估的元研究（meta-research），其贡献在于评估方法论，而非智能体本身的构建或演化。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标不符。"
    },
    {
        "index": "#99",
        "title": "RobustSora: De-Watermarked Benchmark for Robust AI-Generated Video Detection",
        "link": "/arxiv/2512.10248",
        "arxiv_id": "2512.10248",
        "authors": "Zhuo Wang, Xiliang Liu, Ligang Sun",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.001216",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是构建了一个名为 **RobustSora** 的**基准数据集**，用于评估AI生成视频检测模型在面对水印操纵时的鲁棒性。其本质是**评估和测试现有模型**（包括MLLMs）的性能，而不是提出一种新的构建、改进或演化LLM智能体的方法论或框架。这完全符合第一步排除标准中的“非演化型应用”，即将AI模型作为工具应用于特定领域（AIGC视频检测）来解决该领域的问题。 2.  **第二步：正面指标** 论文中完全没有出现您所关注的核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。虽然提到了 `MLLM approaches`，但它们是作为被测试的对象，而不是研究的核心方法论。 3.  **第三步：排除标准** 这是决定性的排除依据。该论文直接命中了两个明确的排除标准： *   **安全与对齐**: 论文的标题和摘要都明确指出其核心是关于 **`Watermarking` (水印)**。它研究的是检测器如何依赖水印以及如何去除水印来评估检测器。根据筛选规则，“只要论文的主要贡献是关于 `Watermarking` (水印)，一律排除”。 *   **多模态与视觉**: 论文的研究对象是 **`AI-generated video`**，属于 `Vision` 和 `MLLMs` 的范畴。虽然它使用了MLLMs，但视觉视频是研究的核心主题，而不是作为智能体感知环境的工具。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何关于智能体推理/规划或自我演化的特殊情况。 **最终决策**: 综合以上分析，这篇论文的核心贡献是关于AIGC视频检测和水印鲁棒性的基准研究，与您“构建、改进或演化LLM智能体”的核心目标完全不符。同时，它直接触犯了“安全与对齐”（水印）和“多模态与视觉”两大排除标准。因此，应果断排除。"
    },
    {
        "index": "#107",
        "title": "Universal Hirschberg for Width Bounded Dynamic Programs",
        "link": "/arxiv/2512.10132",
        "arxiv_id": "2512.10132",
        "authors": "Logan Nye",
        "subjects": "Data Structures and Algorithms, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.005830",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种通用的、针对有界宽度动态规划（DP）的空间优化算法，这是对Hirschberg算法的泛化。论文的本质是**理论计算机科学和算法优化**，旨在解决动态规划过程中的空间复杂度问题。它完全没有涉及构建、改进或演化任何形式的LLM智能体。因此，根据第一步的核心判断标准，这篇论文应被**排除**。 2.  **第二步：正面指标** 论文摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。摘要中提到的 \"evolution\" 是指动态规划状态随时间的“演进”，是一个算法术语，而非AI智能体的“自我演化”。 3.  **第三步：排除标准** 虽然这篇论文不涉及安全对齐或多模态等排除项，但第一步的核心判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 论文讨论的动态规划（DP）有时可以作为智能体规划模块的底层技术之一。然而，这篇论文的焦点是**优化DP算法本身的空间效率**，而不是**构建一个使用DP进行规划的智能体框架**。它属于“非Agentic的推理”范畴，因为它关注的是计算原语的改进，而非智能体的自主行为框架。 **最终决策**: 这篇论文是一篇纯粹的算法理论论文，其贡献在于动态规划的空间优化。它与我的研究核心——“LLM智能体及其演化”——在领域、目标和贡献上完全无关。因此，最终判断为 **False**。"
    },
    {
        "index": "#100",
        "title": "InFerActive: Towards Scalable Human Evaluation of Large Language Models through Interactive Inference",
        "link": "/arxiv/2512.10234",
        "arxiv_id": "2512.10234",
        "authors": "Junhyeong Hwangbo, Soohyun Lee, Minsoo Cheong, Hyeon Jeon, Jinwook Seo",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.001749",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于“构建、改进或演化LLM智能体”的论文，而该论文的核心贡献是提出一个用于“评估”LLM输出的交互式系统。 具体判断过程如下： 1.  **第一步：核心判断——排除** - 论文的核心贡献是 `InFerActive`，一个“交互式推理系统”，其目标是实现“可扩展的人工评估”。它本质上是一个**评估工具或基础设施**，用于帮助人类更高效地理解和评判LLM的输出。 - 它没有提出新的LLM智能体架构，没有改进智能体的规划、记忆或工具使用能力，也没有涉及多智能体协作或自我演化机制。因此，根据第一步的排除标准（特别是“基础设施”和“非演化型应用”），应予以排除。 2.  **第二步：正面指标——不匹配** - 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 它也没有提及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文中的“推理”指的是LLM内部的token生成过程，而非智能体在环境中解决问题的自主规划。 3.  **第四步：处理特殊和模糊情况——确认排除** - **推理/规划**: 论文虽然提到了“Interactive Inference”，但这指的是让评估者交互式地探索LLM生成响应的概率树，以理解其行为。这属于对LLM基础生成过程的分析和可视化，而不是关于智能体如何进行多步规划和决策的框架。因此，它符合“排除：如果只是关于提高LLM本身基础Token预测的数学或逻辑能力”这一规则的精神，因为它关注的是评估和理解基础生成，而非构建智能体。 **结论**: 该论文的研究焦点是LLM的**评估方法论**和**人机交互工具**，而非LLM智能体的**构建、改进或演化**。尽管这项工作对LLM社区有价值，但它偏离了我设定的“Agentic AI”核心研究目标，因此应被排除。"
    },
    {
        "index": "#92",
        "title": "Translating Informal Proofs into Formal Proofs Using a Chain of States",
        "link": "/arxiv/2512.10317",
        "arxiv_id": "2512.10317",
        "authors": "Ziyu Wang, Bowen Yang, Shihao Zhou, Chenyi Li, Yuan Zhang, Bin Dong, Zaiwen Wen",
        "subjects": "Logic in Computer Science, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.994778",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“状态链”的两阶段框架，用于将自然语言描述的非形式化数学证明翻译成Lean4的形式化证明。其本质是**解决特定领域（形式化数学）的特定任务（证明翻译）**。虽然它使用了一个多步骤的流程，但这更像是一个为该任务定制的算法或工作流，而不是一个通用的、可迁移的LLM智能体框架。因此，它更符合**“非演化型应用”**的排除标准，即将LLM作为工具来解决一个领域问题，其核心贡献在于该领域的方法论，而非智能体本身的构建或演化。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中几乎没有出现您所列出的正面指标。它没有讨论`Agentic AI`、`Multi-Agent Systems`或`Self-Evolving`等核心范式。虽然其过程涉及多步推理，但它并未引入或改进如`Planning`、`Memory`、`Self-Reflection`或`Tool Use`等通用智能体能力。其“Chain of States”是一种针对证明翻译任务的特定表示方法，而非一个通用的智能体规划框架。 3.  **第四步：处理特殊和模糊情况——推理/规划** 这是判断此论文的关键点。根据筛选标准： - **排除**: 如果论文只是关于提高LLM本身基础Token预测的数学或逻辑能力（如新的数据集、非Agentic的微调方法）。 - **保留**: 如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）。 这篇论文提出的“Chain of States”方法，虽然是一个多步流程，但其核心创新点在于**通过引入中间表示来简化一个复杂的翻译任务**。它更接近于一种新颖的、针对特定领域的推理增强技术（类似于一个高度定制化的CoT变体），而不是一个关于智能体如何自主进行规划和决策的通用框架。它的目标是提升模型在“证明翻译”这一单一任务上的表现，而不是赋予智能体更广泛的自主规划和行动能力。因此，它更倾向于被归类为**“非Agentic的推理”**，应予以排除。 **最终决策**: 综合以上分析，该论文的核心贡献是针对形式化数学证明翻译的一种新颖算法，而非构建、改进或演化一个具有通用能力的LLM智能体。它属于一个高质量的应用型或特定任务推理型研究，但与您“LLM智能体及其演化”的核心研究目标——即关注智能体本身的架构、能力和演化机制——不符。因此，应将其排除。"
    },
    {
        "index": "#57",
        "title": "Developing and Evaluating a Large Language Model-Based Automated Feedback System Grounded in Evidence-Centered Design for Supporting Physics Problem Solving",
        "link": "/arxiv/2512.10785",
        "arxiv_id": "2512.10785",
        "authors": "Holger Maus, Paul Tschisgale, Fabian Kieser, Stefan Petersen, Peter Wulff",
        "subjects": "Physics Education, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.957061",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用，而非智能体构建。** 该论文的核心贡献是**开发并评估一个基于LLM的自动化反馈系统**，用于支持物理问题解决。这是一个典型的**非演化型应用**。论文的重点在于如何将LLM作为工具，应用在“物理教育”这一特定领域，并评估其效果（有用性、准确性、错误率）。它没有提出新的LLM智能体架构、改进智能体的核心能力（如规划、记忆），也没有涉及智能体的自我演化机制。因此，根据第一步的排除标准，应直接排除。 2.  **第二步：正面指标——缺乏核心关注点。** 论文中没有出现您所关注的核心范式和能力。它没有讨论`Agentic AI`框架、`Multi-Agent Systems`或`Self-Evolving`机制。该系统是一个被动的反馈生成器，不具备`Planning`（自主规划）、`Tool Use`（除了生成文本外没有使用外部工具）、`Memory`（长期记忆）、`Self-Reflection`或`Self-Correction`等智能体关键能力。它只是一个基于特定设计原则（ECD）的输入-输出系统。 3.  **第三步：排除标准——虽未直接命中，但焦点偏离。** 论文虽然讨论了LLM反馈的“风险”和“事实错误”，但其主要贡献并非关于`Safety`或`Alignment`的研究，而是对这些现象在特定应用场景下的观察和评估。这进一步印证了其“应用研究”的本质，而非对智能体本身的基础性研究。 4.  **第四步：处理特殊和模糊情况——不适用例外条款。** 论文讨论了未来生成“更自适应”反馈的可能性，但这只是一个展望。其**当前提出的系统本身并不具备自我演化能力**。因此，它不符合“核心是提出一种新的自我演化机制”的例外保留条件。它同样也不涉及智能体在复杂任务中的自主规划或多步推理框架。 **最终决策**: 综合以上分析，该论文的本质是LLM在垂直领域（教育）的应用评估，而非关于LLM智能体本身的构建、改进或演化。它的研究焦点是“如何用好LLM解决物理教学问题”，而不是“如何让LLM智能体变得更智能、更自主或能够演化”。这与您“构建、改进或演化LLM智能体”的核心目标完全不符，因此应被排除。"
    },
    {
        "index": "#96",
        "title": "Graph Neural Network Based Adaptive Threat Detection for Cloud Identity and Access Management Logs",
        "link": "/arxiv/2512.10280",
        "arxiv_id": "2512.10280",
        "authors": "Venkata Tanuja Madireddy",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.999592",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文本质不符** 论文的核心贡献是提出一个**基于图神经网络（GNN）的自适应威胁检测框架**，用于分析云身份和访问管理（IAM）日志。其本质是**将一种机器学习模型（GNN）应用于特定领域（云安全）**来解决该领域的威胁检测问题。这完全符合第一步排除标准中的第一条：“非演化型应用”，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。尽管本文用的是GNN而非LLM，但其逻辑完全一致：核心是应用，而非智能体本身的构建或演化。 2.  **第二步：正面指标——缺乏核心关注点** 论文摘要中完全没有出现任何与研究焦点相关的正面指标。它没有提及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式，也没有涉及 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等智能体能力。论文中提到的“适应性”是指GNN模型对数据模式的持续学习，而非智能体层面的自我完善和迭代。 3.  **第三步：排除标准——明确属于排除范畴** 论文的研究目标和贡献完全集中在**安全**领域。摘要中明确指出其目标是“威胁检测”、“缓解内部威胁、权限提升和横向移动攻击”，并致力于“AI驱动的零信任访问分析”。这直接命中了第三步的排除标准：“只要论文的主要贡献是关于 `Safety`, `Security`...一律排除”。 **总结**：该论文是一篇关于云安全的优秀研究，但它与“LLM智能体及其演化”这一课题毫无关联。它的核心是构建一个安全领域的专用模型，而不是研究通用或特定类型的智能体架构、多智能体交互或智能体的自我演化机制。因此，必须排除。"
    },
    {
        "index": "#88",
        "title": "Visual Funnel: Resolving Contextual Blindness in Multimodal Large Language Models",
        "link": "/arxiv/2512.10362",
        "arxiv_id": "2512.10362",
        "authors": "Woojun Jung, Jaehoon Go, Mingyu Jeon, Sunjae Yoon, Junyeong Kim",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.992813",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种名为 \"Visual Funnel\" 的方法，用于解决多模态大语言模型（MLLMs）在视觉感知上的“情境盲视”问题。其本质是一种**改进模型视觉输入处理和感知能力**的技术，而非构建、改进或演化LLM智能体的方法论或框架。它没有涉及智能体的规划、记忆、工具使用、自我反思等核心Agentic能力。 2.  **排除标准 (第三步):** 该论文明确属于“多模态与视觉”类别。其研究焦点是提升MLLMs对视觉细节和全局情境的理解能力。根据您的筛选标准，除非视觉是作为智能体感知环境的工具且不是研究核心，否则应排除。在这篇论文中，视觉感知的改进**本身就是研究的核心**，因此符合排除条件。 3.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现您关注的核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步表明其研究方向与您的课题“LLM智能体及其演化”不相关。 综上所述，尽管该论文在多模态领域可能是一项有价值的工作，但它聚焦于模型的基础感知能力提升，而非智能体的架构、行为或演化机制，因此与您的研究目标不符。"
    },
    {
        "index": "#112",
        "title": "Defining the Scope of Learning Analytics: An Axiomatic Approach for Analytic Practice and Measurable Learning Phenomena",
        "link": "/arxiv/2512.10081",
        "arxiv_id": "2512.10081",
        "authors": "Kensuke Takii, Changhao Liang, Hiroaki Ogata",
        "subjects": "Computers and Society, Artificial Intelligence, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.008508",
        "filter_reason": "这篇论文完全不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献不匹配**: 这篇论文的核心贡献是为“学习分析”这一领域提出一个公理化的理论框架，旨在定义其范围、结构和局限性。它关注的是如何从理论上理解和解释人类学习过程中的数据（如观察、经验构建、状态转换），而不是构建或改进任何形式的人工智能智能体。 - **研究领域不符**: 论文属于教育技术和学习科学领域，其研究对象是“学习者”和“学习现象”，而非“LLM智能体”。全文没有提及任何关于LLM、智能体框架或其演化的内容。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - **完全不包含**: 论文摘要和标题中完全没有出现任何我关注的核心范式（如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`）或智能体能力（如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`）。虽然提到了“state transition”（状态转换）和“inference”（推断），但这是在学习分析的理论语境下，指代学习者的认知状态变化，而非智能体的规划或推理过程。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - **领域完全偏离**: 虽然这篇论文不直接涉及安全、对齐或多模态等排除项，但它属于一个更根本的排除类别：**研究领域完全不相关**。我的研究焦点是“LLM智能体及其演化”，而该论文是关于“学习分析的理论基础”。 4.  **第四步：处理特殊和模糊情况** - **不适用**: 该论文不涉及任何与LLM智能体相关的推理、规划或自我演化机制的特殊情况。 **最终决策**: 综合以上分析，这篇论文是一篇关于“学习分析”领域理论基础的纯理论性研究。其核心目标、研究内容和贡献均与“LLM智能体及其演化”这一课题毫无关联。因此，根据筛选标准的第一步（核心判断），应明确**排除**。"
    },
    {
        "index": "#122",
        "title": "ELANA: A Simple Energy and Latency Analyzer for LLMs",
        "link": "/arxiv/2512.09946",
        "arxiv_id": "2512.09946",
        "authors": "Hung-Yueh Chiang, Bokun Wang, Diana Marculescu",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence",
        "date": "2025-12-07",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.012027",
        "filter_reason": "这篇论文不符合我的研究范围。 我的判断过程如下： 1.  **第一步：核心判断** - 论文的核心贡献是构建了一个名为 **ELANA** 的性能分析工具，用于测量LLM的延迟和功耗。 - 根据筛选标准，这完全属于被排除的 **“基础设施”** 范畴。论文关注的是模型部署的效率和硬件平台的性能表现，而不是智能体的构建、改进或演化机制。 - 因此，在第一步就应该被排除。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现任何与我的核心关注点相关的关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步确认了它与我的研究课题无关。 3.  **第三步 & 第四步：排除标准与特殊情况** - 该论文不涉及安全、对齐或多模态等排除项，但其本质（基础设施）已在第一步被明确排除。它也不涉及推理/规划或自我演化的特殊情况。 **最终决策**：该论文的核心是提供一个LLM的性能基准测试工具，属于模型部署和优化的基础设施研究。它没有提出任何关于LLM智能体的新框架、新能力或演化机制。因此，它完全不符合我关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#109",
        "title": "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio",
        "link": "/arxiv/2512.10120",
        "arxiv_id": "2512.10120",
        "authors": "Maris Basha, Anja Zai, Sabine Stoll, Richard Hahnloser",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.006867",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于构建、改进或演化LLM智能体的论文，而该论文的核心贡献与研究目标存在根本性偏差。 1.  **第一步：核心判断——论文本质不符** - **核心贡献**: 该论文的核心是提出一个名为 **VocSim** 的**训练-free基准**，用于评估**音频表征模型**的内在几何对齐能力。它关注的是如何衡量和比较不同音频嵌入在零样本设置下的“内容同一性”识别能力。 - **判断**: 这篇论文的本质是**评估方法学**和**基准构建**，属于**基础设施**的范畴。它没有构建、改进或演化任何形式的LLM智能体。它使用了一个现有的、冻结的模型作为评估对象，而不是创造一个新的智能体框架。因此，根据第一步的排除标准（基础设施、非演化型应用），应予以排除。 2.  **第二步：正面指标——完全缺失** - 论文摘要中完全没有出现任何与我核心关注点相关的正面指标。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等任何关键词或概念。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准——不直接相关但已排除** - 该论文不属于安全与对齐或多模态与视觉的排除范畴，但它在第一步的核心判断中已经被明确排除，因此无需深入此步。 4.  **第四步：特殊和模糊情况——不适用** - 论文不涉及智能体的推理或规划，更不涉及自我演化机制。它讨论的是音频表征的几何属性，而非智能体的行为或能力演化。 **总结**: 该论文是一项关于音频表征评估的扎实工作，但其研究对象是**音频嵌入**，贡献是**评估基准**。这与我的研究课题“LLM智能体及其演化”所关注的**智能体的构建、能力（规划、工具使用、记忆）、交互（协作、通信）和演化（自我完善）**完全不同。因此，这篇论文应被排除。"
    },
    {
        "index": "#120",
        "title": "ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects",
        "link": "/arxiv/2512.10031",
        "arxiv_id": "2512.10031",
        "authors": "Woojin Lee, Hyugjae Chang, Jaeho Moon, Jaehyup Lee, Munchurl Kim",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.011382",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了一种名为 ABBSPO 的新框架，用于解决计算机视觉领域中的“弱监督有向目标检测”问题。其具体创新点在于“自适应边界框缩放”和“基于对称先验的方向预测”这两种技术。这完全属于计算机视觉（CV）的技术范畴，其本质是改进一个视觉模型的性能，而不是构建、改进或演化一个LLM智能体。因此，根据第一步的排除标准，这篇论文应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我研究焦点相关的正面指标。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式。其能力描述也集中在目标检测的几何计算上，而非 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等智能体能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，这篇论文明确属于排除标准中的“多模态与视觉”类别。论文的研究对象是“航空图像”，核心任务是“目标检测”，这些都是典型的计算机视觉问题。虽然摘要中提到了“自监督学习”，但在此上下文中，它指的是利用数据自身特性（如对称性）来辅助模型训练的一种技术手段，而非我所关注的“智能体通过经验进行自我完善和迭代”的演化机制。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何需要特殊处理的情况。它既不是关于智能体的推理/规划，也没有提出新的“自我演化”机制。 **最终决策**: 综合以上分析，这篇论文是一篇纯粹的计算机视觉论文，其核心贡献在于改进目标检测算法。它与“LLM智能体及其演化”这一研究课题在研究对象、核心贡献和技术路线上完全不同。因此，我做出 **False** 的判断，该论文应被排除。"
    },
    {
        "index": "#117",
        "title": "MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata",
        "link": "/arxiv/2512.10041",
        "arxiv_id": "2512.10041",
        "authors": "Yihao Liu, Chenyu Gao, Lianrui Zuo, Michael E. Kim, Brian D. Boyd, Lisa L. Barnes, Walter A. Kukull, Lori L. Beason-Held, Susan M. Resnick, Timothy J. Hohman, Warren D. Taylor, Bennett A. Landman",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.010413",
        "filter_reason": "这篇论文不符合我的研究范围，判断依据如下： 1.  **核心判断 (第一步): 论文本质是“非演化型应用”** 论文的核心贡献是提出一个名为 \"MetaVoxel\" 的生成式联合扩散建模框架，用于处理医学影像和临床元数据。其本质是构建一个更高效的**多模态生成模型**，以统一医疗AI中的不同任务（如图像生成、年龄预测）。这完全符合“非演化型应用”的排除标准：它将一个先进的深度学习模型（扩散模型）作为工具，应用到特定领域（医疗）去解决该领域的问题，而没有涉及任何LLM智能体的构建、改进或演化。 2.  **缺乏正面指标 (第二步)** 论文摘要和标题中完全没有出现任何与我核心关注点相关的关键词。它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，它也未涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory` 或 `Self-Reflection`。 3.  **符合排除标准 (第三步): 核心是“多模态与视觉”** 论文的研究核心是处理 \"Imaging data\"（成像数据）和 \"T1-weighted MRI scans\"（T1加权MRI扫描）。这明确属于“多模态与视觉”的研究范畴。根据筛选规则，除非视觉是作为智能体感知环境的工具，否则应予以排除。在本论文中，视觉数据本身就是研究的核心对象，而不是智能体用于交互的工具。 **总结:** 该论文是一篇典型的医疗AI和多模态生成模型研究，其目标是构建一个统一的生成框架来处理医学影像和元数据。它与我的研究焦点——“LLM智能体及其演化”——在核心贡献、技术范式和研究目标上均无交集。因此，应予以排除。"
    },
    {
        "index": "#124",
        "title": "IoTEdu: Access Control, Detection, and Automatic Incident Response in Academic IoT Networks",
        "link": "/arxiv/2512.09934",
        "arxiv_id": "2512.09934",
        "authors": "Joner Assolin, Diego Kreutz, Leandro Bertholdo",
        "subjects": "Cryptography and Security, Artificial Intelligence, Networking and Internet Architecture, Software Engineering",
        "date": "2025-11-28",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.012668",
        "filter_reason": "这篇论文不符合研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文本质是“非演化型应用”** 论文的核心贡献是提出了一个名为 \"IoTEdu\" 的**集成平台**，用于解决学术物联网网络中的访问控制、入侵检测和自动事件响应等**安全问题**。这完全符合筛选标准中“非演化型应用”的排除类别。论文并未提出任何关于构建、改进或演化LLM智能体的新方法论或框架，而是将一个（可能存在的，但未提及的）技术方案应用到了一个特定的领域（网络安全和物联网管理）。 2.  **第三步：排除标准——论文焦点是“安全”** 论文的摘要明确指出其研究重点是解决“安全弱点”，并实现“事件检测”和“自动阻止”。根据筛选标准，只要论文的主要贡献是关于 `Security`（安全），就应一律排除。这篇论文是典型的网络安全研究，与Agentic AI的核心目标无关。 3.  **第二步：正面指标——完全缺失** 论文的标题和摘要中，完全没有出现任何与研究范围相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。这进一步证实了该论文与研究课题不相关。 **总结**: 该论文是一篇专注于物联网网络安全的系统应用研究，其核心贡献是构建一个安全平台，而非探索LLM智能体的架构、能力或演化机制。因此，它被明确排除在筛选范围之外。"
    },
    {
        "index": "#114",
        "title": "Classifying Metamorphic versus Single-Fold Proteins with Statistical Learning and AlphaFold2",
        "link": "/arxiv/2512.10066",
        "arxiv_id": "2512.10066",
        "authors": "Yongkai Chen, Samuel WK Wong, SC Kou",
        "subjects": "Applications, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.009335",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出一种**用于计算生物学领域的蛋白质分类方法**。它将AlphaFold2作为一个工具来生成蛋白质构象集合的特征，然后结合随机森林分类器来解决“区分变形蛋白和单折叠蛋白”这一具体的科学问题。这完全符合筛选标准中的**“非演化型应用”**排除项。论文的本质是应用AI技术解决特定领域（生物学）的问题，而不是构建、改进或演化LLM智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式或能力关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`（在智能体框架下）、`Self-Reflection` 等。虽然AlphaFold2可以被看作一个“工具”，但论文的重点是利用这个工具的输出结果，而不是研究智能体如何自主、动态地选择和使用工具。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不直接涉及安全对齐或多模态，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。其流程是固定的：采样 -> 生成结构 -> 提取特征 -> 分类，这是一个典型的机器学习流水线，而非智能体的决策过程。 - **自我演化的应用**: 论文虽然应用在特定领域（生物学），但其核心方法并不包含任何“自我演化”机制。该分类框架是静态的，不会通过经验或反馈进行自我完善和迭代。 **最终决策**: 综合以上分析，该论文的核心贡献在于**应用AI模型解决生物信息学问题**，而非**构建或演化LLM智能体**。它属于典型的“AI for Science”范畴，与我的研究焦点“LLM智能体及其演化”有本质区别。因此，应予以排除。"
    },
    {
        "index": "#104",
        "title": "Enhancing Large Language Models for End-to-End Circuit Analysis Problem Solving",
        "link": "/arxiv/2512.10159",
        "arxiv_id": "2512.10159",
        "authors": "Liangliang Chen, Weiyu Sun, Ying Zhang",
        "subjects": "Computers and Society, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.004358",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”** 论文的核心贡献是构建一个**端到端的电路分析问题求解器**。它将一个现有的LLM（Gemini 2.5 Pro）与一个视觉模型（YOLO）和一个电路仿真器组合起来，形成一个高度定制化的技术管道，专门用于解决“电路分析”这一特定工程领域的问题。论文的目标是提升在该特定任务上的准确率，并服务于“工程教育”这一应用场景。这完全符合筛选标准中第一条排除规则：“非演化型应用: 如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗、金融、法律、机器人控制等）”。这里的特定领域就是“电路分析”和“工程教育”。 2.  **第二步与第三步：正面指标与排除标准的分析** -   **正面指标**: 论文确实包含了一些看似相关的元素，如`Tool Use`（使用YOLO和ngspice）和一种`Self-Correction`机制（ngspice验证循环）。然而，这些能力是**内嵌在特定应用流程中**的，而不是作为一个通用的、可迁移的智能体能力或框架被提出。它们是解决电路识别和计算错误的“工程技巧”，而非对Agentic AI范式的根本性贡献。 -   **排除标准**: 论文涉及`Vision`（通过YOLO和OpenCV处理电路图），但这并非研究的核心，而是作为智能体感知特定环境（电路图）的工具。根据规则，这本身不构成排除理由，但它进一步印证了论文的应用导向。 3.  **第四步：处理特殊和模糊情况** -   **自我演化的应用**: 这是本论文最模糊、最需要辨析的一点。论文提出的“ngspice-based verification loop”确实是一个迭代改进的机制。但是，根据筛选规则的例外条款，只有当论文的核心是提出一种**新的、通用的“自我演化”机制**时，即使应用在特定领域也应保留。本文的验证循环是高度领域特定的（依赖.cir文件和ngspice仿真器），它是一个针对电路分析错误的**验证和修正流程**，而不是一个可以被泛化到其他任务的通用自我演化或自我反思框架。因此，这个例外条款不适用。该机制应被视为其特定应用解决方案的一部分，而非一个独立的、普适的演化方法论。 **结论**: 该论文的本质是一项出色的**AI应用工程研究**，它通过巧妙地组合现有工具，在电路分析这一垂直领域取得了显著成果。然而，它的核心贡献并非构建、改进或演化一个通用的LLM智能体框架。其提出的自我修正循环是领域特定的，不具备您所关注的Agentic AI的普适性。因此，它不符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”这一核心目标。"
    },
    {
        "index": "#125",
        "title": "Benchmarking Document Parsers on Mathematical Formula Extraction from PDFs",
        "link": "/arxiv/2512.09874",
        "arxiv_id": "2512.09874",
        "authors": "Pius Horn, Janis Keuper",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.012953",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是**构建了一个用于评估文档解析器性能的基准测试框架**。它关注的是如何从PDF中提取数学公式，并提出了一种使用LLM作为评估者的新方法。这完全符合筛选标准中的**排除项1：“非演化型应用”**。论文将LLM（作为judge）和已有的解析器（包括VLMs）作为工具，应用于“文档解析”这一特定领域，以解决该领域的评估问题。其研究目标不是构建、改进或演化LLM智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式和能力。虽然提到了`LLM-as-a-judge`，但这是一种评估技术，而非智能体的核心能力如`Planning`、`Tool Use`（指智能体自主决策使用工具）、`Self-Reflection`等。论文也未涉及`Multi-Agent`或`Self-Evolving`的任何概念。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的研究内容与`安全与对齐`无关。但是，它明确涉及了`多模态与视觉`，因为它评估的对象包括“vision-language models”和“specialized OCR models”。尽管这些模型被用作感知工具，但它们是**被评估的对象**，而不是论文所提出的**智能体框架的一部分**。因此，这篇论文的研究焦点更偏向于文档理解、OCR和评估方法论，与您的Agentic AI研究主题相去甚远。 4.  **第四步：处理特殊和模糊情况** 论文中的“LLM-as-a-judge”涉及推理，但它不属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。它是一个被动的、一次性的评估任务，不具备自主性、规划或目标导向性，因此应被排除。 **最终决策**: 综合以上分析，该论文的核心贡献是**一个评估基准**，而非一个**智能体框架或演化机制**。它将LLM作为评估工具来解决一个特定领域的应用问题，这完全不符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标。因此，应予以排除。"
    },
    {
        "index": "#93",
        "title": "High-Dimensional Data Processing: Benchmarking Machine Learning and Deep Learning Architectures in Local and Distributed Environments",
        "link": "/arxiv/2512.10312",
        "arxiv_id": "2512.10312",
        "authors": "Julian Rodriguez, Piotr Lopez, Emiliano Lerma, Rafael Medrano, Jacobo Hernandez",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.995288",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准的第一步“核心判断”，这篇论文的本质是关于大数据处理和分布式计算基础设施，而非构建或演化LLM智能体。摘要明确指出，论文内容是“大数据课程”的实践报告，详细描述了使用Apache Spark、Scala和Linux搭建分布式计算集群的技术细节，以及对Epsilon、RestMex和IMDb等数据集的处理流程。这完全符合第一步中的排除标准第3条：“主要关注模型基础设施、部署优化、硬件加速的研究”。 此外，论文中完全没有提及任何与“Agentic AI”、“LLM-based Agents”、“Multi-Agent Systems”或“Self-Evolving”相关的核心范式、智能体能力或演化机制（第二步、第三步的正面指标均不满足）。其核心贡献在于数据处理流程和分布式系统实现，与研究课题“LLM智能体及其演化”完全无关，应予以排除。"
    },
    {
        "index": "#126",
        "title": "UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting",
        "link": "/arxiv/2508.01426",
        "arxiv_id": "2508.01426",
        "authors": "Hang Ni, Weijia Zhang, Hao Liu",
        "subjects": "Machine Learning",
        "date": "2025-08-02",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:05.013257",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 `UniExtreme` 的**基础模型**，用于解决**极端天气预报**这一特定领域的问题。它通过设计新的神经网络模块（AFM 和 EPA）来提升模型在特定任务上的性能。这完全符合筛选标准中“非演化型应用”的排除项，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。尽管这里用的是“基础模型”而非LLM，但其本质是相同的：论文的创新点在于**应用领域（气象学）的模型架构**，而非智能体本身的构建或演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式或能力关键词。例如，它没有涉及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use` 或 `Self-Reflection` 等。虽然摘要中提到了“双级记忆融合网络”，但这里的“记忆”是神经网络架构中的一个技术组件，用于融合“事件先验”，这与智能体在交互过程中存储和检索经验、反思的“记忆”概念完全不同。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文的主要贡献是提升天气预报的准确性，属于科学计算和地球科学领域的应用研究。它不涉及安全、对齐或多模态等排除项，但其核心问题定位已经使其在第一步就被排除。 4.  **第四步：处理特殊和模糊情况** 论文不涉及推理/规划或自我演化的特殊情况。它是一个端到端的预测模型，而非一个具备规划、工具使用或自我改进能力的智能体。 **最终决策**： 综合以上分析，这篇论文的本质是**一个应用于特定科学领域（天气预报）的深度学习模型**，其核心贡献在于模型架构的创新，而非智能体的构建、协作或演化。因此，它严格地属于“非演化型应用”，与我的研究目标“LLM智能体及其演化”不符，应予以排除。"
    }
]