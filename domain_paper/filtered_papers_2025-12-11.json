[
    {
        "index": "#8",
        "title": "AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding",
        "link": "/arxiv/2512.10195",
        "arxiv_id": "2512.10195",
        "authors": "Gyutaek Oh, Sangjoon Park, Byung-Hoon Kim",
        "summary": "Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.",
        "subjects": "Computation and Language, Machine Learning, Multiagent Systems",
        "date": "2025-12-11",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.848065",
        "filter_reason": "这篇论文符合我的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是构建了一个名为 **AutoMedic 的多智能体模拟框架**。它不是简单地将LLM应用于医疗领域，而是提出了一种新的方法论和框架，用于自动化评估其他LLM智能体。这个框架本身就是一个多智能体系统（包含扮演“虚拟患者”的智能体和被测的“临床对话智能体”），其设计、构建和交互机制是论文的核心创新点。这完全符合“构建...多智能体系统的方法论或新框架”的保留标准。 2.  **第二步：正面指标——高度相关** 论文摘要中明确包含了多个核心关注点： *   **核心范式**: `Multi-Agent Systems (MAS)` (明确提到 \"multi-agent simulation framework\")。 *   **多智能体**: `Communication` (通过 \"multi-turn clinical dialogues\" 实现)。 该框架通过模拟多个智能体之间的动态交互来完成任务，这正是多智能体研究的核心。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 虽然论文提到了 \"safe and trustworthy application\"，但其主要贡献是**评估框架**，而不是提出一种新的安全、对齐或可解释性算法。该框架可以被用来评估安全性，但论文本身的研究焦点是构建这个评估工具，而非安全机制本身。因此，它不属于被排除的“主要贡献是关于安全与对齐”的论文。 *   **多模态与视觉**: 论文完全聚焦于文本对话，不涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文评估的是智能体在动态对话中的表现，这属于智能体在复杂任务中的多步推理和交互。虽然论文本身没有提出新的规划算法，但它构建了一个能够测试和评估这种能力的智能体框架，这属于Agentic AI研究的范畴。 **总结**: 尽管论文的应用领域是医疗，但其本质贡献是**方法论层面**的——它构建了一个新颖的**多智能体系统**来解决“如何有效评估对话智能体”这一通用问题。这完全符合我筛选“核心贡献在于构建、改进或演化LLM智能体”的目标，特别是与“多智能体”方向高度契合。因此，这篇论文应该被保留。"
    },
    {
        "index": "#10",
        "title": "Unsupervised Acquisition of Discrete Grammatical Categories",
        "link": "/arxiv/2503.18702",
        "arxiv_id": "2503.18702",
        "authors": "David Ph. Shakouri, Crit Cremers, Niels O. Schiller",
        "summary": "This article presents experiments performed using a computational laboratory environment for language acquisition experiments. It implements a multi-agent system consisting of two agents: an adult language model and a daughter language model that aims to learn the mother language. Crucially, the daughter agent does not have access to the internal knowledge of the mother language model but only to the language exemplars the mother agent generates. These experiments illustrate how this system can be used to acquire abstract grammatical knowledge. We demonstrate how statistical analyses of patterns in the input data corresponding to grammatical categories yield discrete grammatical rules. These rules are subsequently added to the grammatical knowledge of the daughter language model. To this end, hierarchical agglomerative cluster analysis was applied to the utterances consecutively generated by the mother language model. It is argued that this procedure can be used to acquire structures resembling grammatical categories proposed by linguists for natural languages. Thus, it is established that non-trivial grammatical knowledge has been acquired. Moreover, the parameter configuration of this computational laboratory environment determined using training data generated by the mother language model is validated in a second experiment with a test set similarly resulting in the acquisition of non-trivial categories.",
        "subjects": "Computation and Language",
        "date": "2025-03-24",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.848552",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建了一个多智能体系统来研究智能体的学习和演化过程。我的判断依据如下： 1.  **第一步：核心判断 (保留)** - 论文的核心是构建一个**多智能体系统**，该系统由一个“成人语言模型”和一个“女儿语言模型”组成。这直接对应了您研究焦点中的“多智能体”方向。 - 论文的核心贡献是这个**计算实验室环境**本身，以及其中智能体通过互动进行学习的方法论。它不是将现有智能体框架应用到一个新领域，而是**构建**了一个新的框架来研究智能体的能力。 - “女儿”智能体通过分析“母亲”智能体的输出来获取知识，并**将新学到的规则添加到自己的知识库中**。这个过程体现了智能体通过与环境（此处是另一个智能体）的交互进行迭代学习和自我完善，这与您“自我演化”的定义高度契合。 2.  **第二步：正面指标 (高度相关)** - **核心范式**: 论文明确提到了 `Multi-Agent System`。 - **多智能体**: 智能体之间存在明确的 `Communication`（母亲生成语言范例，女儿学习）和 `Social Learning`（女儿向母亲学习）。 - **演化机制**: 女儿智能体的知识是 `Iterative Improvement`（迭代改进）的，它通过分析输入数据来 `Self-Improve`（自我完善）其语法知识。 3.  **第三步：排除标准 (未触发)** - 论文不涉及安全、对齐、可解释性或视觉等多模态内容。其焦点纯粹在于智能体的学习和演化机制。 4.  **第四步：特殊和模糊情况 (不适用)** - 论文中的“推理”是智能体在特定框架（多智能体语言学习）内的认知过程，而非提升LLM基础数学或逻辑能力，因此不属于被排除的“非Agentic的推理”。 - 论文的核心就是提出一种新的学习和演化机制，因此即使其应用领域是“语言习得”这一特定领域，根据您的规则，也应该被保留。 **总结**: 该论文的本质是提出一个新颖的多智能体框架，用以研究一个智能体（女儿）如何通过与另一个智能体（母亲）的交互，自主地、迭代地学习和演化其内部知识（语法规则）。这完美地契合了您“LLM智能体及其演化”课题中的“多智能体”和“自我演化”两个核心方向。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#4",
        "title": "Norm-Governed Multi-Agent Decision-Making in Simulator-Coupled Environments:The Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP)",
        "link": "/arxiv/2512.09939",
        "arxiv_id": "2512.09939",
        "authors": "Stella C. Dong",
        "summary": "Reinsurance decision-making exhibits the core structural properties that motivate multi-agent models: distributed and asymmetric information, partial observability, heterogeneous epistemic responsibilities, simulator-driven environment dynamics, and binding prudential and regulatory constraints. Deterministic workflow automation cannot meet these requirements, as it lacks the epistemic flexibility, cooperative coordination mechanisms, and norm-sensitive behaviour required for institutional risk-transfer. We propose the Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP), a formal model that extends stochastic games and Dec-POMDPs by adding three missing elements: (i) simulator-coupled transition dynamics grounded in catastrophe, capital, and portfolio engines; (ii) role-specialized agents with structured observability, belief updates, and typed communication; and (iii) a normative feasibility layer encoding solvency, regulatory, and organizational rules as admissibility constraints on joint actions. Using LLM-based agents with tool access and typed message protocols, we show in a domain-calibrated synthetic environment that governed multi-agent coordination yields more stable, coherent, and norm-adherent behaviour than deterministic automation or monolithic LLM baselines--reducing pricing variance, improving capital efficiency, and increasing clause-interpretation accuracy. Embedding prudential norms as admissibility constraints and structuring communication into typed acts measurably enhances equilibrium stability. Overall, the results suggest that regulated, simulator-driven decision environments are most naturally modelled as norm-governed, simulator-coupled multi-agent systems.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.846976",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将LLM应用于再保险领域，而是**提出了一种新的多智能体系统框架**。其核心贡献是“Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP)”，这是一个扩展了随机博弈和Dec-POMDPs的**形式化模型**。论文的重点在于构建这个模型来解决一类复杂问题（以再保险为例），而不是解决再保险问题本身。这完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了大量您关注的核心指标： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。`LLM-based Agents` 被明确用作实现智能体的方式。 - **智能体能力**: 论文提到了 `Tool Use`（\"tool access\"）、`Memory`（隐含在\"belief updates\"中）。 - **多智能体**: 论文的核心就是关于 `Collaboration`（\"cooperative coordination mechanisms\"）、`Communication`（\"typed communication\"）以及在约束下的决策。它探讨了如何通过结构化通信和规范约束来改善多智能体协作的稳定性和效率。 - 这些指标强烈表明该论文与您的“多智能体”研究方向高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 论文提到了\"norms\"和\"regulatory constraints\"，但这里的“规范”是指业务和监管规则（如偿付能力规则），它们被用作智能体行为的**可行性约束**，而不是AI安全或伦理对齐意义上的`Safety`或`Alignment`。因此，这不属于排除范围。 - **多模态与视觉**: 论文未涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的研究内容属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。它不是在改进LLM的基础数学能力，而是在构建一个让多个智能体在复杂、动态、部分可观测的环境中进行协调决策的框架。这符合保留条件。 - **自我演化的应用**: 虽然论文不涉及“自我演化”，但它属于“自我演化的应用”规则中的例外情况：论文的核心是提出一种新的**多智能体协调机制**（R-CMASP框架），即使它被应用在特定的再保险领域，也应该被保留。 **最终决策**: 这篇论文的核心贡献在于构建了一个新颖的、受规范约束的多智能体系统框架（R-CMASP），用以解决在模拟器耦合的复杂环境中的决策问题。它深入探讨了多智能体间的协作、通信和约束机制，并使用了基于LLM的智能体进行实现。尽管其应用场景是再保险这一特定领域，但论文的学术价值在于其提出的**方法论和框架本身**，而非应用结果。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的目标，特别是“多智能体”方向，完全吻合。因此，应判定为 **True**。"
    },
    {
        "index": "#1",
        "title": "Thinking While Driving: A Concurrent Framework for Real-Time, LLM-Based Adaptive Routing",
        "link": "/arxiv/2512.10610",
        "arxiv_id": "2512.10610",
        "authors": "Xiaopei Tan, Muyang Fan",
        "summary": "We present Thinking While Driving, a concurrent routing framework that integrates LLMs into a graph-based traffic environment. Unlike approaches that require agents to stop and deliberate, our system enables LLM-based route planning while agents are moving, significantly reducing intersection wait times. Under high traffic, agents average just 0.75 seconds of decision latency. To coordinate many agents in real-time, we implement a non-blocking asynchronous architecture using Unity coroutines and a dedicated request manager. The environment is a weighted undirected graph with live congestion metrics, updated continuously by the agents to enable shared perception. Our results show LLM-driven agents can dynamically adapt to traffic, reroute around congestion, and exhibit behaviors beyond static pathfinding, all while maintaining real-time performance. This work provides a reproducible framework for future research in adaptive routing and multi-agent cooperation.",
        "subjects": "Multiagent Systems",
        "date": "2025-12-11",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.846188",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建和改进一个新颖的LLM智能体框架。我的判断过程如下： 1.  **第一步：核心判断 (保留)** 论文的核心是提出一个名为 \"Thinking While Driving\" 的**并发框架**。这并非简单地将现有LLM智能体应用于交通领域，而是**构建了一种新的方法论**，解决了LLM智能体在动态、实时环境中的一个关键瓶颈：决策延迟。论文的核心贡献是关于“如何构建一个更高效的、能够实时规划和行动的LLM智能体系统”，这直接命中了你“构建、改进LLM智能体”的核心目标。它不属于“非演化型应用”，因为其创新点在于智能体架构本身，而非应用场景的解决方案。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量与你研究焦点直接相关的核心范式和能力： *   **多智能体**: 论文明确提到 \"To coordinate many agents\", \"multi-agent cooperation\"，并设计了 \"shared perception\" 机制让智能体之间共享环境信息。这完全符合你“多智能体”方向中的“协作”和“通信”子方向。 *   **智能体能力**: 论文的核心是 \"LLM-based route planning\"，这属于智能体的“规划”能力。其“边移动边思考”的并发机制，是对传统规划模式（如ReAct中先思考后行动）的一种改进和演化。 *   **核心范式**: 整篇论文围绕一个 `LLM-based Agents` 的 `Multi-Agent System` 框架展开。 3.  **第三步：排除标准 (不涉及)** 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态。它专注于智能体的行为和系统架构，因此没有被排除。 4.  **第四步：处理特殊和模糊情况 (符合保留条件)** *   **推理/规划**: 论文的研究内容是关于智能体如何在动态环境中进行**实时规划和多步推理**（\"reroute around congestion\"）。它提出的并发框架是一种新的Agentic规划范式，而不是提升LLM本身的基础数学或逻辑能力。因此，根据规则，应该保留。 *   **自我演化的应用**: 虽然这篇论文不直接涉及“自我演化”，但它属于“多智能体”和“单智能体”的范畴，同样是你研究的核心。 **结论**: 该论文的核心贡献是提出了一种创新的、支持实时并发决策的LLM智能体框架，并成功应用于多智能体协作场景。它直接推动了LLM智能体在规划和协作能力上的边界，完美契合你“单智能体”和“多智能体”的研究方向。因此，应判定为符合要求。"
    },
    {
        "index": "#2",
        "title": "Emergent Collective Memory in Decentralized Multi-Agent AI Systems",
        "link": "/arxiv/2512.10166",
        "arxiv_id": "2512.10166",
        "authors": "Khushiyant",
        "summary": "We demonstrate how collective memory emerges in decentralized multi-agent systems through the interplay between individual agent memory and environmental trace communication. Our agents maintain internal memory states while depositing persistent environmental traces, creating a spatially distributed collective memory without centralized control. Comprehensive validation across five environmental conditions (20x20 to 50x50 grids, 5-20 agents, 50 runs per configuration) reveals a critical asymmetry: individual memory alone provides 68.7% performance improvement over no-memory baselines (1563.87 vs 927.23, p < 0.001), while environmental traces without memory fail completely. This demonstrates that memory functions independently but traces require cognitive infrastructure for interpretation. Systematic density-sweep experiments (rho in [0.049, 0.300], up to 625 agents) validate our theoretical phase transition prediction. On realistic large grids (30x30, 50x50), stigmergic coordination dominates above rho ~ 0.20, with traces outperforming memory by 36-41% on composite metrics despite lower food efficiency. The experimental crossover confirms the predicted critical density rho_c = 0.230 within 13% error.",
        "subjects": "Multiagent Systems",
        "date": "2025-12-10",
        "category": "cs.MA",
        "crawl_time": "2025-12-12T11:00:03.846451",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步核心判断 (保留)**: 论文的本质是**构建和改进多智能体系统**。其核心贡献在于提出并验证了一个关于“集体记忆”如何在去中心化多智能体系统中涌现的新框架和机制。这并非将已有智能体作为工具去解决某个特定领域的问题，而是对智能体系统本身的内在工作机制进行深入研究，完全符合“构建、改进或演化 LLM智能体”的核心目标。 2.  **第二步正面指标 (高度匹配)**: 论文包含了你研究焦点的多个核心关键词和概念： *   **多智能体**: 论文标题和摘要明确指出研究的是 `Decentralized Multi-Agent AI Systems`。 *   **智能体能力**: 论文的核心机制之一是 `individual agent memory` (个体记忆)。 *   **多智能体交互**: 论文深入探讨了智能体间的 `Communication`，具体形式为 `environmental trace communication` (环境痕迹通信) 和 `stigmergic coordination` (基于信息素的协调)，这属于协作和通信的子方向。 3.  **第三步排除标准 (未触发)**: 论文的研究内容与安全对齐、多模态视觉等排除方向完全无关。其焦点纯粹在于智能体系统的架构和涌现行为。 4.  **第四步特殊与模糊情况 (处理得当)**: *   **推理/规划**: 论文中的智能体需要在环境中寻找资源（由 \"food efficiency\" 可推断），这涉及到规划。但论文的贡献不在于提出一种新的规划算法，而在于揭示记忆和通信如何共同作用于智能体的集体行为，这属于智能体框架层面的研究，因此应保留。 *   **关于LLM的明确性**: 虽然摘要未明确提及 \"LLM\"，但其研究的 `Memory`、`Communication`、`Decentralized Coordination` 等是构建现代LLM智能体和多智能体系统的基石。这项工作为理解如何让多个LLM智能体在没有中心控制的情况下有效协作提供了理论基础和实证支持，其研究范式和发现对于你的课题具有直接且重要的价值。 **最终决策**: 综合来看，该论文的核心贡献在于提出并分析了一个新颖的去中心化多智能体系统框架，深入探讨了集体记忆的涌现机制。这精准地命中了你研究范围中的“多智能体”方向，并且其关于记忆和通信的发现对构建更高级的LLM智能体系统至关重要。因此，这篇论文应被**保留**。"
    },
    {
        "index": "#7",
        "title": "Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving",
        "link": "/arxiv/2512.10739",
        "arxiv_id": "2512.10739",
        "authors": "Songyang Gao, Yuzhe Gu, Zijian Wu, Lingkai Kong, Wenwei Zhang, Zhongrui Cai, Fan Zheng, Tianyou Ma, Junhao Shen, Haiteng Zhao, Duanyang Zhang, Huilun Zhang, Kuikun Liu, Chengqi Lyu, Yanhui Duan, Chiyu Chen, Ningsheng Ma, Jianfei Gao, Han Lyu, Dahua Lin, Kai Chen",
        "summary": "Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the \\textbf{O}utcome-based \\textbf{P}rocess \\textbf{V}erifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \\textsc{\\thisbench}, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2\\% to 73.3\\% on AIME2025 as the compute budget scales.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.258199",
        "filter_reason": "这篇论文符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于数学领域，而是提出了一个名为“Outcome-based Process Verifier (OPV)”的新组件，以及一个用于训练该组件的“迭代主动学习框架”。OPV的作用是验证智能体在长推理链中的中间步骤，这本质上是构建和改进智能体自我反思与自我纠正能力的关键部分。其迭代训练框架则是一种让该验证能力不断演化的机制。因此，论文的核心是关于**构建和改进LLM智能体的方法论**，而非单纯的应用。 2.  **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **核心范式**: 论文标题和内容明确指向 `Agentic AI` 和 `LLM-based Agents`。 *   **智能体能力**: 论文聚焦于 `Long-horizon Reasoning`，这是 `Planning` 的一种高级形式。OPV验证器本身就是一个 `Self-Correction` 或 `Self-Reflection` 机制的实现。 *   **演化机制**: 论文明确提出了一个 `Iterative Improvement` 框架，通过主动学习和迭代训练来“progressively improve the verification capability”，这完全符合 `Self-Evolving` 的定义。 3.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等内容，因此没有触及任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 这篇论文是典型的“保留”案例。它不是在研究如何提升LLM的基础数学推理能力（如通过新的数据集或微调），而是在研究**智能体如何进行长程规划并验证其推理过程**。OPV和其迭代框架是构成智能体高级推理能力的一部分，属于Agentic框架的范畴。 *   **自我演化的应用**: 这篇论文完美地符合了“例外”规则。虽然它应用在“数学问题求解”这一特定领域，但其核心贡献是提出了一种**新的“自我演化”机制（迭代主动学习框架）**。根据您的指示，这种情况应该保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种增强LLM智能体长程推理能力的新组件（OPV）和一种使其能力自我演化的迭代框架。这直接对应了您研究目标中的“单智能体”（规划、自我反思）和“自我演化”两个核心方向。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#26",
        "title": "Workflow is All You Need: Escaping the \"Statistical Smoothing Trap\" via High-Entropy Information Foraging and Adversarial Pacing",
        "link": "/arxiv/2512.10121",
        "arxiv_id": "2512.10121",
        "authors": "Zhongjie Jiang",
        "summary": "Central to long-form text generation in vertical domains is the \"impossible trinity\" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society, General Finance",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.310092",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进一个LLM智能体。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为“DeepNews Framework”的**智能体工作流**。摘要中明确指出这是一个“agentic workflow”，其目标是模拟专业记者的认知过程。这并非简单地将LLM作为工具应用于金融领域，而是**构建了一个具有特定架构和模块化能力的新颖智能体框架**。因此，它通过了第一步的核心判断，属于“构建LLM智能体的方法论或新框架”的保留范畴。 2.  **第二步：正面指标——高度相关** 论文包含了多个您关注的核心正面指标： *   **核心范式**: 论文明确提出了一个 `Agentic AI` / `LLM-based Agent` 框架。 *   **智能体能力**: *   `Tool Use`: 论文包含一个“dual-granularity retrieval mechanism”，这是典型的工具使用能力，用于信息获取。 *   `Planning`: 论文包含一个“schema-guided strategic planning”模块，用于构建逻辑骨架，这是智能体规划能力的直接体现。 *   `Self-Correction/Reflection`: “adversarial constraint prompting”模块通过引入对抗性约束来打破模型的概率平滑性，可以看作是一种高级的自我纠正或自我约束机制，属于智能体控制能力的范畴。 3.  **第三步：排除标准——未触发** 论文的主要目标是提升生成长文本的质量（低幻觉、逻辑连贯），并未涉及安全、对齐、可解释性或多模态等排除标准中的主题。因此，第三步的排除标准不适用。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文中的“规划”是智能体层面的规划。它不是在改进LLM的基础推理能力，而是在构建一个**智能体框架**，该框架利用外部知识库和模块化设计来完成复杂的写作任务规划。这完全符合“保留”的条件。 *   **自我演化的应用**: 虽然这篇论文不直接关于“自我演化”，但它触及了类似的原则。它提出了一个在特定领域（金融新闻）中应用的**新机制**。根据您的规则，如果论文的核心是提出一种新机制（这里是智能体工作流），即使应用在特定领域，也应该保留。这篇论文正是如此，其价值在于“DeepNews Framework”这个方法论本身，而非其在金融领域的应用结果。 **最终决策**: 综合以上分析，这篇论文的核心是构建一个集成了规划、工具使用和自我约束机制的LLM智能体框架。它直接回应了您研究课题中的“单智能体”方向，特别是智能体的规划和工具使用能力。尽管它在一个垂直领域进行验证，但其贡献是方法论层面的，具有普适性。因此，这篇论文与您的研究目标高度契合，应被保留。"
    },
    {
        "index": "#29",
        "title": "Replace, Don't Expand: Mitigating Context Dilution in Multi-Hop RAG via Fixed-Budget Evidence Assembly",
        "link": "/arxiv/2512.10787",
        "arxiv_id": "2512.10787",
        "authors": "Moshe Lahmy, Roi Yozevitch",
        "summary": "Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive-$k$, typically address this by \\textit{adding} more context or pruning existing lists. However, simply expanding the context window often leads to \\textbf{context dilution}, where distractors crowd out relevant information. We propose \\textbf{SEAL-RAG}, a training-free controller that adopts a \\textbf{``replace, don't expand''} strategy to fight context dilution under a fixed retrieval depth $k$. SEAL executes a (\\textbf{S}earch $\\rightarrow$ \\textbf{E}xtract $\\rightarrow$ \\textbf{A}ssess $\\rightarrow$ \\textbf{L}oop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \\textit{gap specification} (missing entities/relations), triggers targeted micro-queries, and uses \\textit{entity-first ranking} to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive-$k$ in a shared environment on \\textbf{HotpotQA} and \\textbf{2WikiMultiHopQA}. On HotpotQA ($k=3$), SEAL improves answer correctness by \\textbf{+3--13 pp} and evidence precision by \\textbf{+12--18 pp} over Self-RAG. On 2WikiMultiHopQA ($k=5$), it outperforms Adaptive-$k$ by \\textbf{+8.0 pp} in accuracy and maintains \\textbf{96\\%} evidence precision compared to 22\\% for CRAG. These gains are statistically significant ($p<0.001$). By enforcing fixed-$k$ replacement, SEAL yields a predictable cost profile while ensuring the top-$k$ slots are optimized for precision rather than mere breadth. We release our code and data at https://github.com/mosherino/SEAL-RAG.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.311465",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出了一种名为 **SEAL-RAG** 的**训练-free控制器**。它不是一个简单的RAG应用，而是一个具有动态决策能力的**方法论框架**。 - **是否符合**: 该框架通过一个循环（Search → Extract → Assess → Loop）来主动管理检索过程。它不是被动地使用检索到的信息，而是主动地评估当前上下文的不足，识别信息缺口，并规划下一步的检索行动（触发有针对性的微查询）。这种“评估-行动-再评估”的循环机制，本质上是一种**智能体的规划和自我修正过程**。因此，这篇论文的核心是关于**构建和改进LLM智能体**的，符合保留标准。 2.  **第二步：正面指标** - **核心范式**: 论文虽然没有直接使用 \"Agentic AI\" 这个词，但其提出的控制器和循环机制完全符合 `LLM-based Agents` 的范式。 - **智能体能力**: - **`Planning`**: SEAL-RAG的 `S -> E -> A -> L` 循环是一个典型的规划过程。它通过 `Assess` 和 `Extract` 步骤来理解当前状态（识别信息缺口），并规划下一步行动（`Search`）。 - **`Tool Use / Tool Augmentation`**: 检索器在这里被当作一个工具。SEAL-RAG控制器智能地决定何时以及如何使用这个工具（触发“微查询”），而不是简单地一次性使用。 - **`Memory`**: 论文中提到的 `gap specification`（缺口规范）是一种动态的、任务导向的短期记忆，它记录了智能体在解决问题过程中还需要什么信息。 - **`Self-Correction`**: 论文的核心策略“replace, don't expand”就是一种自我修正。智能体识别出当前上下文中的“distractors”（干扰信息），并主动用更相关的证据来替换它们，以优化其决策基础。 - **与ReAct的相似性**: 其循环机制与 `ReAct` (Reason+Act) 范式高度相似，都是通过一个循环来交替进行推理和行动，是Agentic AI研究的经典方向。 3.  **第三步：排除标准** - 论文的研究焦点是提升多跳问答任务的性能和效率，完全不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐议题。 - 论文处理的是纯文本数据，不涉及 `Vision`, `MLLMs` 等多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它不是在改进LLM本身的基础推理能力（如微调模型做数学题），而是在构建一个**外部的、框架性的规划与行动循环**，让LLM能够更好地解决复杂任务。这正是Agentic AI研究的核心。 **最终决策**: 这篇论文的核心贡献是提出了一种新颖的、具有动态规划和自我修正能力的智能体控制器（SEAL-RAG）。它通过一个循环机制，实现了对工具（检索器）的智能使用、对任务状态的动态记忆以及对自身行为的持续优化。这完全符合我研究课题中“单智能体”方向下的“规划”、“工具使用”和“自我反思”等核心关注点。因此，这篇论文与我的研究目标高度相关，应被**保留**。"
    },
    {
        "index": "#30",
        "title": "Remember Me, Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven Agent Evolution",
        "link": "/arxiv/2512.10696",
        "arxiv_id": "2512.10696",
        "authors": "Zouying Cao, Jiaji Deng, Li Yu, Weikang Zhou, Zhaoyang Liu, Bolin Ding, Hai Zhao",
        "summary": "Procedural memory enables large language model (LLM) agents to internalize \"how-to\" knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a \"passive accumulation\" paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose $\\textbf{ReMe}$ ($\\textit{Remember Me, Refine Me}$), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1) $\\textit{multi-faceted distillation}$, which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2) $\\textit{context-adaptive reuse}$, which tailors historical insights to new contexts via scenario-aware indexing; and 3) $\\textit{utility-based refinement}$, which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the $\\texttt{reme.library}$ dataset to facilitate further research.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.312110",
        "filter_reason": "这篇论文完全符合你的研究范围，是一个典型的、高质量的“自我演化”方向论文。以下是根据你的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个特定领域的问题，而是**提出了一种全新的、用于改进LLM智能体本身的框架（ReMe）**。其核心目标是解决现有智能体记忆系统的“被动积累”问题，实现智能体的“经验驱动演化”。这直接命中了你研究范围中的“构建、改进或演化LLM智能体”和“自我演化”两个核心点。 2.  **第二步：正面指标** - 论文摘要中包含了大量你的核心关注点关键词，匹配度极高： - **核心范式**: `LLM-based Agents`, `Self-Evolving` (标题和摘要中明确出现), `Agent Evolution`。 - **智能体能力**: `Memory` (论文的核心), `Self-Refine` (标题和机制3), `Self-Correction` (机制3的pruning可视为一种自我修正)。 - **演化机制**: `Self-Improvement`, `Iterative Improvement` (整个框架就是为此设计的), `Experience-Driven`。 - 论文提出的三个机制（多方面提炼、情境自适应重用、基于效用的精炼）都是围绕如何让智能体更好地利用经验、实现自我迭代和演化的具体方法论。 3.  **第三步：排除标准** - 论文完全没有涉及`Safety`、`Alignment`、`Hallucination`等安全与对齐主题。 - 论文也未涉及`Vision`、`MLLMs`等多模态内容，其焦点纯粹在智能体的认知和演化框架上。 - 因此，所有排除标准均未触发。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文虽然不直接提出新的规划算法，但它所研究的“记忆”是智能体进行有效规划和推理的基石。它通过改进记忆来提升智能体的整体能力，这属于对智能体核心能力的增强，而非对LLM基础推理能力的微调，因此符合保留条件。 - **自我演化的应用**: 这篇论文是“自我演化”方向的典范。它的核心贡献就是提出一种新的“自我演化”机制（ReMe框架），并在通用的智能体基准（BFCL-V3, AppWorld）上验证其有效性。这完全符合你设定的“即使应用在特定领域，只要核心是提出新演化机制就保留”的原则。 **最终决策**: 这篇论文的核心贡献是构建了一个名为ReMe的动态记忆框架，旨在通过提炼、重用和精炼经验，驱动LLM智能体实现自我演化和终身学习。它精准地聚焦于你的研究目标中的“自我演化”方向，并深入探讨了“单智能体”的核心能力“记忆”。论文内容前沿，方法论新颖，与你的研究范围高度契合，是应该被保留的典型论文。"
    },
    {
        "index": "#21",
        "title": "Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale",
        "link": "/arxiv/2512.10398",
        "arxiv_id": "2512.10398",
        "authors": "Zhaodong Wang, Zhenting Qi, Sherman Wong, Nathan Hu, Samuel Lin, Jun Ge, Erwin Gao, Yining Yang, Ben Maurer, Wenlin Chen, David Recordon, Yilun Du, Minlan Yu, Ying Zhang",
        "summary": "Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Software Engineering",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.302168",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建和演化LLM智能体。我的判断过程如下： 1.  **第一步：核心判断 (保留)** 论文的本质是提出一个新的LLM智能体框架。它不仅构建了一个具体的智能体，还提供了一个用于开发智能体的SDK平台。其核心贡献是关于智能体的架构设计、能力实现和自我完善机制，而不是将现有智能体作为工具应用到某个领域。因此，根据第一步的筛选标准，应予以**保留**。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量与你研究焦点直接相关的核心范式和能力关键词： *   **单智能体**: 论文明确提出了一个`AI Software Engineer`，并详细描述了其关键能力，包括用于长上下文推理的`hierarchical working memory`（规划/记忆）、用于跨会话持续学习的`persistent note-taking system`（记忆）以及用于鲁棒工具使用的`modular extension module`（工具使用）。这精准地命中了“单智能体”方向下的规划、记忆和工具使用等子方向。 *   **自我演化**: 论文最突出的亮点之一是提出了一个`meta-agent`，它通过一个`build-test-improve loop`（构建-测试-改进循环）来自动化智能体配置的`synthesis, evaluation, and refinement`（合成、评估和完善）。这完全符合“自我演化”方向下的`Self-Improvement`、`Self-Refine`和`Iterative Improvement`机制。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献并非关于安全、对齐、可解释性，也未涉及多模态或视觉。虽然提到了`transparency`（透明性），但这是作为其开源平台的一个特性，而非研究的核心议题。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文提出的`unified orchestrator with hierarchical working memory`是典型的智能体规划与推理框架，而非单纯提升LLM基础推理能力，因此符合保留条件。 *   **自我演化的应用**: 论文虽然应用在“软件工程”这一特定领域，但其核心贡献是提出了一种新颖的“自我演化”机制（meta-agent和build-test-improve loop）。根据你的特殊规则，这种提出新机制的应用论文应该被保留。 **最终决策**: 该论文的核心贡献是构建了一个具备工业级能力的LLM智能体（CCA）及其开发平台（SDK）。它系统性地解决了智能体在规划、记忆和工具使用方面的挑战，并创新性地引入了一个元智能体来实现智能体的自我完善和演化。这精准地覆盖了你研究课题中的“单智能体”和“自我演化”两大核心方向。因此，这篇论文是高度相关且应被筛选入的前沿研究。"
    },
    {
        "index": "#42",
        "title": "Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning",
        "link": "/arxiv/2412.20505",
        "arxiv_id": "2412.20505",
        "authors": "Hang Ni, Yuzhi Wang, Hao Liu",
        "summary": "Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2024-12-29",
        "category": "cs.CL",
        "crawl_time": "2025-12-12T11:00:04.334768",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献与你的研究目标高度契合。我的判断过程如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出一个名为“Cyclical Urban Planning (CUP)”的**新范式**和**多智能体LLM框架**。它不是简单地将现有智能体框架应用于城市规划，而是**构建**了一个由多个具有不同角色的LLM智能体（规划者、居民、评判者）组成的、能够闭环运行的系统。这完全符合“构建LLM智能体”和“多智能体系统”的核心要求。同时，其“循环生成、评估和完善”的闭环机制，本质上就是一种**自我演化**的设计。因此，这篇论文在第一步就应被保留。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量你的核心关注点： *   **核心范式**: `Multi-agent LLM-based framework` (直接命中)。 *   **智能体能力**: `Planning` (作为框架的核心组件之一)。 *   **多智能体**: 框架包含多个智能体，它们之间通过模拟居民行为进行`Interaction`，并通过评判环节进行`Communication`，这体现了多智能体的协作与交互。 *   **演化机制**: `Cyclical` (循环的), `continuously generates, evaluates, and refines` (持续生成、评估和完善), `closed-loop` (闭环), `iterative feedback` (迭代反馈)。这些关键词清晰地表明该框架具备`Self-Improvement`和`Iterative Improvement`的演化特性。 3.  **第三步：排除标准 (未触发)** 论文的研究焦点是框架设计和规划流程的有效性，没有涉及安全、对齐、可解释性或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况 (适用例外规则)** 这篇论文是一个典型的“自我演化的应用”案例。虽然它的应用领域是“城市规划”，但根据你的筛选规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 本文的核心正是这个**循环迭代的自我演化机制**（CUP框架），而非城市规划本身。因此，它完全符合保留的例外条件。 **最终决策**: 这篇论文的核心贡献在于构建了一个新颖的多智能体LLM框架，该框架通过规划、模拟和评判的闭环流程，实现了智能体系统的自我迭代与演化。它精准地命中了你研究范围中的“多智能体”和“自我演化”两个核心方向，并且其方法论贡献超越了具体的应用领域。因此，这是一篇高度相关且应被保留的前沿论文。"
    },
    {
        "index": "#33",
        "title": "Dynamics of Agentic Loops in Large Language Models: A Geometric Theory of Trajectories",
        "link": "/arxiv/2512.10350",
        "arxiv_id": "2512.10350",
        "authors": "Nicolas Tacheny",
        "summary": "Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.912752",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于为理解和改进LLM智能体提供了新的理论基础和分析工具。以下是根据你的筛选标准进行的详细判断： 1.  **第一步：核心判断——保留** - 论文的核心不是将LLM智能体作为工具应用于某个特定领域，而是深入研究LLM智能体本身的核心工作机制——即“递归反馈循环”。 - 它的本质是提出一种新的**分析框架**（几何理论）来理解和刻画智能体的行为动态（收敛、发散等）。这直接关系到如何**构建、改进或演化**LLM智能体，因为理解其动态是控制和优化其行为的前提。因此，它不属于“非演化型应用”或“非Agentic的推理”的排除范畴。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文标题和摘要中反复出现 `Agentic systems` 和 `agentic loops`，直击你的研究核心。 - **智能体能力**: 论文研究的“递归反馈循环”是 `Planning`、`Self-Correction` 和 `Self-Reflection` 等能力的底层实现机制。通过分析这些循环的动态，论文为如何设计更有效的规划和反思机制提供了洞见。 - **演化机制**: 论文的核心内容——分析智能体轨迹的 `convergence` (收敛) 和 `divergence` (发散)，与 `Self-Evolving`、`Iterative Improvement` 的概念紧密相连。它提供了一种量化评估智能体在迭代过程中是趋于稳定（自我完善）还是走向混乱（发散）的方法，这对于设计能够自我演化的智能体至关重要。 3.  **第三步：排除标准——未命中** - 论文的主要贡献是关于智能体的行为动态理论，而非 `Safety`、`Alignment` 或 `Interpretability`。虽然其研究成果可能有助于理解智能体行为（一种广义的解释），但其研究目标和贡献本身并非对齐或安全。 - 论文完全基于文本的语义嵌入空间，不涉及 `Vision` 或多模态内容。 4.  **第四步：处理特殊和模糊情况——符合保留条件** - **推理/规划**: 该论文完美符合“保留”条件。它不是在提升LLM的基础推理能力，而是在分析**智能体框架下的多步推理和迭代过程**的几何动态。它将智能体的迭代过程视为一个“离散动力系统”，这为设计和理解更复杂的规划框架（如ToT）提供了理论基础。 **最终决策**: 这篇论文的核心贡献是提出了一种几何理论来分析LLM智能体的核心行为模式。它不关注应用，而是深入智能体内部，研究其迭代循环的动态规律。这项工作为“如何设计一个能够稳定收敛、有效探索或自我完善的智能体”提供了全新的分析视角和理论工具，直接服务于“构建、改进或演化LLM智能体”这一核心目标。因此，这是一篇高度相关且具有前瞻性的前沿论文，应予以保留。"
    },
    {
        "index": "#117",
        "title": "Echo-CoPilot: A Multi-View, Multi-Task Agent for Echocardiography Interpretation and Reporting",
        "link": "/arxiv/2512.09944",
        "arxiv_id": "2512.09944",
        "authors": "Moein Heidari, Mohammad Amin Roohi, Armin Khosravi, Ilker Hacihaliloglu",
        "summary": "Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8\\%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning, Image and Video Processing",
        "date": "2025-12-06",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.995853",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是构建一个名为 Echo-CoPilot 的LLM智能体框架。其核心贡献并非简单地将LLM应用于心脏超声领域，而是提出了一种**方法论**：如何使用LLM作为“大脑”，在一个ReAct风格的循环中，去**编排和协调**一系列专门的工具（如图像识别、分割、测量等），以完成一个复杂的多步骤任务。这完全符合“构建LLM智能体的方法论或新框架”的保留标准。它不是在非演化型地使用一个已有的智能体框架，而是在**提出并实现一个新的智能体架构**。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (论文标题和摘要中明确提到 \"agent\")。 - **智能体能力**: `Tool Use / Tool Augmentation` (摘要中明确指出 \"orchestrate a suite of specialized echocardiography tools\" 和 \"invokes tools\")；`Planning` (摘要中提到 \"decomposes clinician queries\"，这是规划能力的体现)；`ReAct` (摘要中明确提到 \"ReAct-style loop\")。 - 这些正面指标强烈表明该论文与我的研究焦点高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐、可解释性等主题，因此不在此排除范围内。 - **多模态与视觉**: 这是本论文最需要辨析的一点。虽然论文处理的是心脏超声（一种视觉数据），并且与视觉语言模型进行比较，但**其研究的核心并非视觉模型本身**。视觉任务（如视图识别、分割）是作为智能体可以调用的**工具**而存在的。论文的核心贡献在于智能体如何**使用**这些工具，而不是如何**改进**这些视觉模型。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外条款。因此，不应因此排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确采用了ReAct框架，这是一种典型的智能体规划和推理范式。它研究的是智能体在复杂任务中如何进行多步推理和行动，而不是提升LLM本身的基础数学或逻辑能力。因此，符合保留条件。 5.  **第五步：最终决策** - 综合以上分析，尽管论文的应用领域是垂直的医疗领域，但其**核心贡献在于提出并验证了一个新颖的LLM智能体框架**，该框架展示了LLM如何通过规划、工具使用和多步推理来解决复杂现实世界问题。这直接命中了我研究目标中“构建、改进LLM智能体”的核心。因此，这篇论文是高度相关且有价值的前沿研究，应予以保留。"
    },
    {
        "index": "#120",
        "title": "Exploring Health Misinformation Detection with Multi-Agent Debate",
        "link": "/arxiv/2512.09935",
        "arxiv_id": "2512.09935",
        "authors": "Chih-Han Chen, Chen-Han Tsai, Yu-Shao Peng",
        "summary": "Fact-checking health-related claims has become increasingly critical as misinformation proliferates online. Effective verification requires both the retrieval of high-quality evidence and rigorous reasoning processes. In this paper, we propose a two-stage framework for health misinformation detection: Agreement Score Prediction followed by Multi-Agent Debate. In the first stage, we employ large language models (LLMs) to independently evaluate retrieved articles and compute an aggregated agreement score that reflects the overall evidence stance. When this score indicates insufficient consensus-falling below a predefined threshold-the system proceeds to a second stage. Multiple agents engage in structured debate to synthesize conflicting evidence and generate well-reasoned verdicts with explicit justifications. Experimental results demonstrate that our two-stage approach achieves superior performance compared to baseline methods, highlighting the value of combining automated scoring with collaborative reasoning for complex verification tasks.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-11-29",
        "category": "cs.LG",
        "crawl_time": "2025-12-12T11:00:04.996724",
        "filter_reason": "这篇论文符合筛选标准，应被保留。 **判断过程和核心依据如下：** 1.  **第一步：核心判断** 论文的核心贡献是提出了一种用于解决复杂验证任务的“多智能体辩论”框架。根据第一步的核心判断，这篇论文的本质是构建一个新的多智能体系统（Multi-Agent Systems）框架，而非简单地将已有框架作为工具应用到特定领域。其“多智能体辩论”机制是方法论上的创新，属于“构建、改进LLM智能体”的范畴。虽然其应用场景是健康领域，但论文的焦点在于**如何通过多智能体的协作来提升推理质量**，而不是健康领域的具体知识或问题本身。因此，它避开了“非演化型应用”的排除规则。 2.  **第二步：正面指标** 论文明确包含了第二步中的多个正面指标，特别是“多智能体”方向的核心关注点： *   `Multi-Agent Systems (MAS)`: 标题和摘要中明确提及。 *   `Collaboration`: 摘要中提到“collaborative reasoning”（协作推理）。 *   `Communication`: “Multi-Agent Debate”（多智能体辩论）本身就是一种结构化的通信形式。 *   `Negotiation`: 智能体通过辩论来“synthesize conflicting evidence”（综合冲突证据），这本质上是一种协商过程。 这些指标强烈表明论文与您的研究焦点高度相关。 3.  **第三步：排除标准** 论文的研究焦点是提升检测任务的性能，而非安全、对齐或多模态技术本身。虽然错误信息检测与安全相关，但论文的主要贡献是**方法论**（多智能体辩论框架），而不是一种新的安全技术或对齐方法。因此，它不触犯第三步的排除标准。 4.  **第四步：处理特殊和模糊情况** 根据第四步的特殊情况处理规则，论文的“多智能体辩论”属于智能体在复杂任务中进行多步推理和协作的新框架，这与“保留关于智能体如何进行规划或在复杂任务中进行多步推理的论文”的规则相符。它不是在改进LLM的基础推理能力，而是在构建一个让多个智能体共同推理的系统。 **最终决策：** 综上所述，尽管论文的应用场景是“健康错误信息检测”，但其核心创新在于提出了一种新的多智能体协作与推理范式，这直接贡献于“多智能体”这一研究方向，与您的研究课题“LLM智能体及其演化”高度相关。因此，应保留此论文。"
    },
    {
        "index": "#15",
        "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning",
        "link": "/arxiv/2512.10534",
        "arxiv_id": "2512.10534",
        "authors": "Haiteng Zhao, Junhao Shen, Yiming Zhang, Songyang Gao, Kuikun Liu, Tianyou Ma, Fan Zheng, Dahua Lin, Wenwei Zhang, Kai Chen",
        "summary": "Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.908872",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。其核心贡献在于构建了一个新颖的LLM智能体，并详细阐述了其工作机制，这与你的核心目标高度一致。 以下是详细的判断过程： 1.  **第一步：核心判断——保留** *   论文的本质是**构建一个新的LLM智能体**。它提出了一个名为 `InternGeometry` 的智能体框架，专门用于解决复杂的几何问题。这完全符合“核心贡献在于构建、改进或演化LLM智能体”的保留标准。 *   它不是将已有智能体作为工具应用到几何领域，而是**提出了一种新的智能体方法论**，即通过“提议-验证-反思”的循环来解决问题。 *   它不是关于提升LLM的基础推理能力，而是关于一个**完整的智能体框架**，该框架整合了规划、工具使用和反思。 2.  **第二步：正面指标——高度匹配** *   论文明确包含了多个核心关注点： *   **核心范式**: 论文标题和摘要中多次提到 `Large Language Model Agent`，完全命中。 *   **智能体能力**: *   `Planning`: 摘要中提到“iteratively proposing propositions and auxiliary constructions... to guide subsequent proposals”，这描述了智能体的规划和行动策略。 *   `Tool Use`: 智能体使用“symbolic engine”（符号引擎）来验证其提出的命题，这是典型的工具使用。 *   `Memory`: 论文明确提出了“A dynamic memory mechanism”，这是智能体的关键能力之一。 *   `Self-Reflection`: 智能体“reflecting on the engine's feedback to guide subsequent proposals”，这是明确的自我反思机制。 *   **演化机制**: 论文引入了 `Complexity-Boosting Reinforcement Learning (CBRL)`，这是一种通过逐步增加问题复杂度来加速智能体学习的训练方法，属于 `Iterative Improvement` 的范畴，是构建和改进智能体的关键部分。 3.  **第三步：排除标准——未触发** *   论文的主要贡献是关于智能体的能力和构建方法，而非安全、对齐、可解释性或幻觉。 *   论文处理的是几何问题，但通过符号语言而非视觉输入，因此不涉及多模态或视觉的核心研究，符号引擎仅作为工具被使用。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 该论文是关于智能体如何进行规划和多步推理的典型案例。它的“提议-验证-反思”循环是一个高级的Agentic推理框架，远超简单的Chain-of-Thought，因此应被保留。 *   **自我演化的应用**: 虽然论文应用在几何领域，但其核心是提出了一种新的智能体架构和训练方法（CBRL），这本身就属于“构建或改进LLM智能体”的范畴，因此符合保留规则。 **最终决策**: 这篇论文的核心贡献是构建了一个名为 `InternGeometry` 的LLM智能体，并详细描述了其基于**规划、工具使用、记忆和自我反思**的复杂工作机制。它完美地契合了你研究范围中的“单智能体”方向，特别是关于智能体能力构建的子方向。因此，这篇论文是高度相关且应被筛选出来的前沿研究。"
    },
    {
        "index": "#10",
        "title": "On the Dynamics of Multi-Agent LLM Communities Driven by Value Diversity",
        "link": "/arxiv/2512.10665",
        "arxiv_id": "2512.10665",
        "authors": "Muhua Huang, Qinlin Zhao, Xiaoyuan Yi, Xing Xie",
        "summary": "As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz's Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.906480",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非将LLM智能体作为工具应用于某个特定领域，而是**构建了一个多智能体模拟系统**，用以研究“价值多样性”这一因素如何影响LLM智能体社区的集体行为。这直接命中了筛选标准中的“构建...多智能体系统...的方法论或新框架”，因此应予以保留。 2.  **第二步：正面指标 (高度相关)** 论文摘要中包含了多个核心关注点： *   **核心范式**: 明确提到了 `Multi-Agent Systems (MAS)`，研究的是“LLM based multi-agent systems”。 *   **多智能体**: 研究内容涉及智能体间的“open-ended interactions”（开放性互动）、“constitution formation”（宪法形成），这直接对应了 `Collaboration`（协作）、`Communication`（通信）和 `Agent Society`（智能体社会）等子方向。 *   **演化机制**: 论文探讨了“emergent behaviors”（涌现行为）和“principles developed by the agents themselves”（由智能体自己发展的原则），这与群体层面的演化和社会学习紧密相关，符合“自我演化”的广义范畴。 3.  **第三步：排除标准 (未命中)** 论文的主要贡献是关于多智能体社区的动态行为，而非安全、对齐、可解释性或视觉多模态。因此，它没有触及任何排除标准。 4.  **第四步：特殊和模糊情况 (不适用)** 该论文不涉及非Agentic的基础推理，也不是一个简单的应用。它的核心是提出并验证一个关于多智能体系统设计和理解的新维度（价值多样性），这本身就是对Agentic AI研究的推进。 **最终决策**: 该论文的核心贡献在于**构建和分析一个LLM多智能体社区**，探索“价值多样性”这一关键变量如何塑造其集体行为和涌现能力。这完全符合您研究课题中的“多智能体”方向，并且其关于“涌现行为”和“社区自我发展”的发现也与“自我演化”的主题相契合。因此，这篇论文是高度相关且应被保留的前沿研究。"
    },
    {
        "index": "#14",
        "title": "NormCode: A Semi-Formal Language for Context-Isolated AI Planning",
        "link": "/arxiv/2512.10563",
        "arxiv_id": "2512.10563",
        "authors": "Xin Guan",
        "summary": "Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode's own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.908346",
        "filter_reason": "这篇论文符合筛选要求，应该被保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的本质是提出一种名为NormCode的半形式化语言和框架，用于构建和执行复杂的多步骤LLM工作流。其核心贡献在于解决LLM智能体在执行长链任务时的“上下文污染”问题，这是一种**构建和改进LLM智能体**的方法论。它不是将现有智能体简单应用于某个领域，而是提出了一种新的智能体工作流构建范式，因此符合核心保留标准。 **第二步：正面指标** - 论文与我的核心关注点高度匹配，尤其是在**单智能体**方向： - **核心范式**: 论文的核心是`Agentic AI`和`LLM-based Agents`。 - **智能体能力**: 论文的核心贡献是关于**规划**。它提出了一种新的规划语言来组织智能体的推理步骤，这与`ReAct`、`ToT`等Agentic规划框架属于同一类别。同时，它通过数据隔离机制直接解决了智能体的**记忆**（特别是短期工作记忆）管理难题，防止信息混淆。其将语义操作和语法操作分离的设计，也与**工具使用**的理念相通，将确定性的数据处理作为智能体工具箱的一部分。 **第三步：排除标准** - 论文没有触发明确的排除标准。 - **安全与对齐**: 虽然摘要中提到了“auditable by design”（可审计）和“transparency”（透明度），但这并非论文的**主要贡献**。论文的核心是提出一种新的**构建智能体的方法**，而可审计性和透明度是该设计带来的一个**有益属性**，而非研究目标本身。因此，它不属于主要关注安全、对齐或可解释性的论文。 - **多模态与视觉**: 论文未涉及视觉或多模态内容。 **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”情况的典型范例。它不是在提升LLM本身的基础数学或逻辑推理能力，而是在**构建一个让智能体能够进行更可靠、更结构化多步推理和规划的框架**。NormCode本身就是一个Agentic规划框架，完全符合保留条件。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种新颖的、用于构建LLM智能体工作流的规划框架NormCode。它直接解决了智能体在规划和记忆管理上的关键挑战，属于“单智能体”研究范畴下的“规划”和“记忆”子方向。尽管它提到了可审计性，但其本质是关于智能体的构建方法论，而非安全或对齐研究。因此，该论文与我的研究课题“LLM智能体及其演化”高度相关，应予以保留。"
    },
    {
        "index": "#16",
        "title": "Zero-shot 3D Map Generation with LLM Agents: A Dual-Agent Architecture for Procedural Content Generation",
        "link": "/arxiv/2512.10501",
        "arxiv_id": "2512.10501",
        "authors": "Lim Chien Her, Ming Yan, Yunshu Bai, Ruihao Li, Hao Zhang",
        "summary": "Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.909337",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是关于如何生成3D地图，而是提出了一种**新的LLM智能体架构**来实现这一目标。其核心贡献是“一个训练无关的、利用LLM智能体的架构”，具体来说是一个“双智能体架构”。这直接命中了“构建、改进或演化LLM智能体”的核心目标。它不是简单地将现有智能体作为工具应用，而是**设计了一种新的智能体协作与演化机制**。 2.  **第二步：正面指标** - 该论文包含了多个核心正面指标： - **核心范式**: 明确提出了 `LLM-based Agents` 和 `Multi-Agent Systems (MAS)`。 - **多智能体**: 核心机制是 `Actor` 智能体与 `Critic` 智能体的 `Collaboration`（协作）与 `Communication`（隐含的，通过Critic的反馈实现）。 - **自我演化**: 论文的核心是 `Iterative Workflow`（迭代工作流），其中Critic智能体提供反馈，Actor智能体 `Refines Configurations`（优化配置），这完全符合 `Self-Improvement`、`Self-Refine` 和 `Iterative Improvement` 的定义。智能体通过内部反馈循环进行自我完善。 - **智能体能力**: 智能体 `autonomously reasons`（自主推理）并使用 `PCG tools`（工具使用）。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐、可解释性等问题。 - **多模态与视觉**: 论文标题和摘要中提到了“3D Map Generation”，但这属于**应用领域**。论文的核心贡献并非提出新的视觉或多模态模型，而是将3D地图生成工具作为LLM智能体操作的**外部工具**。研究的焦点是智能体如何通过语言指令和内部协作来控制这个工具，而不是视觉理解本身。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的推理是典型的**Agentic推理**。智能体不是在解决一个孤立的数学或逻辑问题，而是在一个复杂任务（配置PCG参数）中进行多步规划和决策，这完全符合保留标准。 - **自我演化的应用**: 这篇论文是“自我演化应用”的完美范例。虽然它应用在“3D地图生成”这个特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**——即Actor-Critic的迭代优化循环。根据您的规则，这种情况下应该保留。 **最终决策**: 这篇论文的核心贡献在于提出了一种新颖的**双智能体协作架构**，通过**迭代反馈和自我优化**的机制，使LLM智能体能够掌握复杂工具。这精准地覆盖了您研究焦点的**“多智能体”**和**“自我演化”**两个方向。尽管其应用场景是3D内容生成，但论文的立足点和创新点在于智能体架构本身，而非应用领域。因此，这是一篇高度相关且应被保留的前沿论文。"
    },
    {
        "index": "#25",
        "title": "User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation",
        "link": "/arxiv/2512.10322",
        "arxiv_id": "2512.10322",
        "authors": "Yongqiang Yu, Xuhui Li, Hazza Mahmood, Jinxing Zhou, Haodong Hong, Longtao Jiang, Zhiqiang Xu, Qi Wu, Xiaojun Chang",
        "summary": "Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.918850",
        "filter_reason": "这篇论文符合筛选要求，应被保留。判断的核心依据是第四步的“自我演化的应用”特殊规则。 1.  **核心判断 (第一步)**: 从表面上看，这篇论文是关于“视觉与语言导航”（VLN）的，这是一个具体的应用领域，似乎符合“非演化型应用”的排除标准。然而，其核心贡献并非简单地应用一个已有框架，而是提出了一种新的适应机制。 2.  **正面指标 (第二步)**: 论文包含了多个核心关注点。 *   **自我演化**: 论文的核心是“持续适应”和“持续学习”，这直接对应了“自我演化”和“迭代改进”。 *   **记忆**: 论文明确提出了“记忆库热启动机制”，这是智能体记忆能力的关键体现，用于重用知识、稳定性能。 *   **自我完善**: 通过整合用户反馈进行适应，是一种明确的“自我完善”或“自我改进”机制。 3.  **排除标准 (第三步)**: 论文确实涉及“多模态与视觉”，这通常是一个排除项。但是，这里的视觉是智能体感知环境的工具，而非研究的核心。研究的核心是智能体如何利用反馈和记忆来**演化**其导航策略，而不是视觉模型本身的创新。 4.  **特殊和模糊情况 (第四步)**: 这是决定性的判断依据。 *   **自我演化的应用**: 论文的核心贡献是提出了一种**新的“自我演化”机制**——即“用户反馈驱动的适应框架”和“记忆库热启动机制”。尽管这个机制被应用在VLN这个特定领域，但它本身是一种通用的、关于智能体如何通过与环境和用户交互来持续自我完善的方法论。这完全符合“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”的例外规则。 **最终决策 (第五步)**: 综合分析，这篇论文的本质是提出了一种新颖的、结合了用户反馈和记忆机制的智能体自我演化框架。虽然其验证场景是视觉导航，但其方法论贡献具有普适性，直接命中了研究课题的“自我演化”核心方向。因此，根据筛选标准中的特殊规则，应将其保留。"
    },
    {
        "index": "#26",
        "title": "EpiPlanAgent: Agentic Automated Epidemic Response Planning",
        "link": "/arxiv/2512.10313",
        "arxiv_id": "2512.10313",
        "authors": "Kangkun Mao, Fang Xu, Jinru Ding, Yidong Jiang, Yujun Yao, Yirong Chen, Junming Liu, Xiaoqin Wu, Qian Wu, Xiaoyan Huang, Jie Xu",
        "summary": "Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.",
        "subjects": "Artificial Intelligence, Computers and Society",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.919417",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是**设计和评估一个名为EpiPlanAgent的多智能体框架**。摘要明确指出，该系统集成了“任务分解、知识 grounding 和模拟模块”，这表明其核心是构建一个具有特定能力的智能体架构，而不仅仅是将现有LLM或智能体框架作为黑盒工具应用于流行病领域。论文的重点在于**“如何构建”这个智能体系统**，并验证其有效性，这直接命中了您“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Agentic AI` (摘要中明确提及), `LLM-based Agents`, `Multi-Agent Systems` (摘要中明确提及)。 - **智能体能力**: `Planning` (标题和摘要的核心), `Tool Use / Tool Augmentation` (由“知识 grounding”和“模拟模块”所体现)。 - 这些指标强烈表明该论文与您的研究方向高度相关。 3.  **第三步：排除标准** - 论文的主要贡献并非关于安全、对齐或多模态技术。它专注于智能体的构建和应用，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文完美符合“保留”条件。它不是在提升LLM的基础数学或逻辑能力，而是在研究一个**智能体如何通过任务分解、知识 grounding 和模拟等模块化设计来进行复杂的规划**。这正是Agentic AI框架下的规划研究。 - **自我演化的应用**: 虽然这篇论文不涉及自我演化，但它属于一个类似的情况：一个新框架在特定领域的应用。根据您的规则，如果核心是提出新框架（这里是多智能体规划框架），即使应用在特定领域（公共卫生），也应该保留。这篇论文正是如此。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**提出并验证了一个用于自动化规划的多智能体框架（EpiPlanAgent）**。它详细描述了该框架的构成（任务分解、知识 grounding、模拟），这属于对LLM智能体（特别是多智能体方向）的构建和改进。尽管其应用场景是流行病应对，但论文的焦点是**Agentic AI方法论本身**，而非仅仅是解决一个领域问题。因此，这篇论文是您研究课题“LLM智能体及其演化”中“多智能体”和“规划”方向的优秀候选，应予以保留。"
    },
    {
        "index": "#21",
        "title": "AgentProg: Empowering Long-Horizon GUI Agents with Program-Guided Context Management",
        "link": "/arxiv/2512.10371",
        "arxiv_id": "2512.10371",
        "authors": "Shizuo Tian, Hao Wen, Yuxuan Chen, Jiacheng Liu, Shanhui Zhao, Guohong Liu, Ju Ren, Yunxin Liu, Yuanchun Li",
        "summary": "The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at https://github.com/MobileLLM/AgentProg.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.916853",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于对LLM智能体能力的改进，具体属于“单智能体”方向下的“记忆”和“规划”子方向。 1.  **第一步：核心判断 (保留)** - 论文的核心是提出一种名为 **AgentProg** 的新方法/框架，用于解决LLM智能体在执行长时程任务时面临的上下文管理瓶颈。这并非将现有智能体作为工具应用到某个领域，而是直接**构建和改进**智能体本身的核心机制（即记忆/上下文管理）。因此，它通过了第一步的核心判断，应予以保留。 2.  **第二步：正面指标 (高度匹配)** - 论文的研究内容与您的核心关注点高度契合： - **核心范式**: 论文明确研究 `LLM-based Agents` (GUI Agents)。 - **智能体能力**: 论文的核心贡献是解决 `Memory` 问题。它通过将交互历史重构为程序来管理上下文，这是一种结构化的记忆机制。同时，处理“long-horizon tasks”和引入“global belief state”直接关联到智能体的 `Planning` 能力，使其能够在多步、复杂的环境中保持性能。 3.  **第三步：排除标准 (未命中)** - 论文的主要贡献不是关于安全、对齐或可解释性，因此不涉及排除标准中的第一类。 - 论文虽然涉及GUI（图形用户界面），具有一定的视觉属性，但其研究核心**不是**视觉模型或多模态模型本身。GUI在这里是智能体感知和交互的**环境**，而论文的创新点在于智能体如何管理在这个环境中交互产生的信息（上下文）。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外情况。 4.  **第四步：特殊和模糊情况 (符合保留规则)** - **推理/规划**: 论文的研究内容是关于智能体如何通过有效的上下文管理来支持长时程规划和执行。这完全符合“保留”规则，即“关于智能体如何进行规划或在复杂任务中进行多步推理”。它不是在提升LLM的基础数学或逻辑推理能力，而是在构建一个更高级的Agentic框架。 **最终决策**: 该论文的核心贡献是提出了一种创新的、程序引导的上下文管理框架，以增强LLM智能体在长时程任务中的记忆和规划能力。这直接命中了您研究目标中的“单智能体”方向，特别是“记忆”和“规划”这两个关键子方向。它不是简单的应用，也不是基础设施或安全研究，因此是一篇非常相关且高质量的前沿论文，应被筛选保留。"
    },
    {
        "index": "#34",
        "title": "CP-Env: Evaluating Large Language Models on Clinical Pathways in a Controllable Hospital Environment",
        "link": "/arxiv/2512.10206",
        "arxiv_id": "2512.10206",
        "authors": "Yakun Zhu, Zhongzhen Huang, Qianhan Feng, Linjie Mu, Yannian Gu, Shaoting Zhang, Qi Dou, Xiaofan Zhang",
        "summary": "Medical care follows complex clinical pathways that extend beyond isolated physician-patient encounters, emphasizing decision-making and transitions between different stages. Current benchmarks focusing on static exams or isolated dialogues inadequately evaluate large language models (LLMs) in dynamic clinical scenarios. We introduce CP-Env, a controllable agentic hospital environment designed to evaluate LLMs across end-to-end clinical pathways. CP-Env simulates a hospital ecosystem with patient and physician agents, constructing scenarios ranging from triage and specialist consultation to diagnostic testing and multidisciplinary team meetings for agent interaction. Following real hospital adaptive flow of healthcare, it enables branching, long-horizon task execution. We propose a three-tiered evaluation framework encompassing Clinical Efficacy, Process Competency, and Professional Ethics. Results reveal that most models struggle with pathway complexity, exhibiting hallucinations and losing critical diagnostic details. Interestingly, excessive reasoning steps can sometimes prove counterproductive, while top models tend to exhibit reduced tool dependency through internalized knowledge. CP-Env advances medical AI agents development through comprehensive end-to-end clinical evaluation. We provide the benchmark and evaluation tools for further research and development at https://github.com/SPIRAL-MED/CP-Env.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.928578",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是构建了一个名为 **CP-Env** 的“可控智能体医院环境”。这本质上是一个**新的评估框架和基准**，专门用于衡量LLM智能体在复杂、动态场景下的表现。它不是简单地将一个已有的智能体框架应用到医疗领域，而是**创造了一个全新的、用于测试和推动智能体发展的方法论和环境**。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提到了 `Agentic hospital environment` 和 `agent interaction`。 - **多智能体**: 论文的核心是模拟一个包含 `patient and physician agents` 的生态系统，研究它们之间的交互，这直接命中了 `Multi-Agent Systems (MAS)` 和 `Collaboration`。 - **智能体能力**: 论文评估了智能体在 `long-horizon task execution`（长周期任务执行）中的表现，这与 `Planning`（规划）能力密切相关。同时，摘要中也提到了 `tool dependency`（工具依赖），触及了 `Tool Use`（工具使用）能力。 3.  **第三步：排除标准** - 论文没有被排除。虽然提到了 `Professional Ethics`（职业道德）和 `hallucinations`（幻觉），但论文的**主要贡献**是提出评估环境，而不是解决安全、对齐或幻觉问题本身。它是在评估这些现象，而不是以解决它们为核心创新点。论文也未涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文关注的是智能体在复杂的临床路径（一种长周期、多步骤任务）中的表现，这属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴，因此应该保留。 - **应用与框架的区分**: 这是本案例的关键。虽然论文的应用场景是医疗，但其本质**并非“非演化型应用”**。它不是在说“我们用一个智能体去诊断疾病”，而是在说“我们构建了一个医院环境来**评估和促进**智能体的发展”。这种构建评估基准的工作，是推动整个Agentic AI领域进步的基础性研究，与研究目标高度一致。 **最终决策**: 综合以上分析，该论文的核心贡献在于构建了一个多智能体评估环境（CP-Env），用于衡量和推动LLM智能体在复杂任务中的能力发展。这直接服务于“构建、改进或演化LLM智能体”的核心目标，并且重点落在多智能体系统上。因此，这篇论文与研究课题高度相关，应被保留。"
    },
    {
        "index": "#44",
        "title": "DynaMate: An Autonomous Agent for Protein-Ligand Molecular Dynamics Simulations",
        "link": "/arxiv/2512.10034",
        "arxiv_id": "2512.10034",
        "authors": "Salomé Guilbert, Cassandra Masschelein, Jeremy Goumaz, Bohdan Naida, Philippe Schwaller",
        "summary": "Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD setup, encompassing parameterization, input preparation, and software configuration, remains a major barrier for widespread and efficient usage. Agentic LLMs have demonstrated their capacity to autonomously execute multi-step scientific processes, and to date, they have not successfully been used to automate protein-ligand MD workflows. Here, we present DynaMate, a modular multi-agent framework that autonomously designs and executes complete MD workflows for both protein and protein-ligand systems, and offers free energy binding affinity calculations with the MM/PB(GB)SA method. The framework integrates dynamic tool use, web search, PaperQA, and a self-correcting behavior. DynaMate comprises three specialized modules, interacting to plan the experiment, perform the simulation, and analyze the results. We evaluated its performance across twelve benchmark systems of varying complexity, assessing success rate, efficiency, and adaptability. DynaMate reliably performed full MD simulations, corrected runtime errors through iterative reasoning, and produced meaningful analyses of protein-ligand interactions. This automated framework paves the way toward standardized, scalable, and time-efficient molecular modeling pipelines for future biomolecular and drug design applications.",
        "subjects": "Artificial Intelligence, Computational Engineering, Finance, and Science",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-12T11:00:04.938899",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非将LLM作为工具应用于生物化学领域，而是**提出了一个名为DynaMate的“模块化多智能体框架”**。摘要明确指出，这是一个用于自主设计和执行复杂工作流的框架。其研究重点在于**如何构建这个智能体系统**（包括模块划分、交互方式、能力集成），而不是该系统在药物发现领域的具体科学发现。因此，它不属于“非演化型应用”的排除范畴，而是关于“构建LLM智能体”的核心方法论研究。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量您关注的核心范式和能力指标： *   **核心范式**: 明确提到了 `Agentic LLMs` 和 `Multi-Agent Systems (MAS)`。 *   **多智能体**: 论文的核心是一个“多智能体框架”，由“三个专业化模块”组成，它们通过“交互”来完成任务，这直接对应了您研究焦点中的“多智能体”方向。 *   **智能体能力**: 摘要中明确列出了 `Planning` (“plan the experiment”)、`Tool Use` (“dynamic tool use, web search, PaperQA”) 和 `Self-Correction` (“self-correcting behavior”, “corrected runtime errors through iterative reasoning”)。这些都是您在“单智能体”方向下关注的核心能力。 *   **演化机制**: `Self-Correction` 和 `iterative reasoning` 体现了智能体在执行过程中根据反馈进行自我完善和迭代的能力，这与您“自我演化”方向中的“自我完善”和“迭代改进”高度相关。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献是关于智能体的架构和能力，没有涉及安全、对齐、可解释性或水印等排除标准。同时，它也未以多模态或视觉作为研究核心。 4.  **第四步：特殊和模糊情况 (清晰界定)** 这篇论文是“推理/规划”规则的完美范例。它研究的不是LLM本身的基础数学或逻辑推理能力，而是**智能体如何进行多步骤的规划和推理**（“plan the experiment”, “corrected runtime errors through iterative reasoning”）以完成一个复杂任务。这正是您希望保留的Agentic框架研究。 **总结:** 尽管论文的应用领域是分子动力学，但其本质和核心贡献是**提出并验证了一个新颖的多智能体框架**，该框架集成了规划、工具使用和自我纠正等关键Agentic能力。它为“如何构建能够自主解决复杂科学问题的LLM智能体”提供了具体的架构和方法论，这与您“构建、改进或演化 LLM智能体”的核心目标完全一致。因此，这是一篇高度相关且应被保留的前沿论文。"
    }
]