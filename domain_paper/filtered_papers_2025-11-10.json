[
    {
        "index": "#8",
        "title": "Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation",
        "link": "/arxiv/2511.07257",
        "arxiv_id": "2511.07257",
        "authors": "Hanya Elhashemy, Youssef Lotfy, Yongjian Tang",
        "summary": "The increasing adoption of Jupyter notebooks in data science and machine learning workflows has created a gap between exploratory code development and production-ready software systems. While notebooks excel at iterative development and visualization, they often lack proper software engineering principles, making their transition to production environments challenging. This paper presents Codelevate, a novel multi-agent system that automatically transforms Jupyter notebooks into well-structured, maintainable Python code repositories. Our system employs three specialized agents - Architect, Developer, and Structure - working in concert through a shared dependency tree to ensure architectural coherence and code quality. Our experimental results validate Codelevate's capability to bridge the prototype-to-production gap through autonomous code transformation, yielding quantifiable improvements in code quality metrics while preserving computational semantics.",
        "subjects": "Software Engineering, Multiagent Systems",
        "date": "2025-11-10",
        "category": "cs.MA",
        "crawl_time": "2025-11-12T11:00:03.706356",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为Codelevate的**新颖的多智能体系统**，用于自动将Jupyter notebooks转换为生产级代码。根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——保留。** 论文的本质是构建一个**多智能体系统**。它不是简单地将一个已有的LLM或智能体框架应用到软件工程领域，而是**提出并实现了一个新的多智能体协作框架**。该框架包含三个专门的智能体，并设计了它们之间的协作机制（通过共享依赖树）。这完全符合“构建、改进或演化LLM智能体”中的“构建多智能体系统”这一核心目标。因此，它不属于“非演化型应用”的排除范畴，因为其核心贡献是方法论和框架本身，而非应用结果。 2.  **第二步：正面指标——高度相关。** 论文明确包含了多个核心关注点： *   **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。 *   **多智能体**: 论文详细描述了智能体间的 `Collaboration`（协作，\"working in concert\"）和 `Communication`（通信，通过\"shared dependency tree\"）。 *   **智能体能力**: `Architect`智能体的角色暗示了`Planning`（规划）能力，而整个系统的代码转换过程则涉及`Tool Use`（工具使用，如解析和写入代码文件）。 3.  **第三步：排除标准——未触发。** 论文的研究焦点是代码转换的自动化框架，不涉及安全、对齐、可解释性或多模态等内容，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况——不适用。** 该论文不涉及自我演化，也不属于基础LLM推理能力的提升，因此相关特殊规则不适用。其多智能体协作的性质清晰地属于“保留”范畴。 **最终决策**：该论文的核心贡献在于**构建了一个新颖的多智能体协作框架**来解决一个复杂的自动化任务。这直接命中了研究课题中的“多智能体”方向。尽管其应用场景是软件工程，但研究的重点和价值在于智能体系统的设计、协作机制和能力实现，完全符合“构建、改进或演化LLM智能体”的核心目标。因此，应予以保留。"
    },
    {
        "index": "#9",
        "title": "Evaluating Online Moderation Via LLM-Powered Counterfactual Simulations",
        "link": "/arxiv/2511.07204",
        "arxiv_id": "2511.07204",
        "authors": "Giacomo Fidone, Lucia Passaro, Riccardo Guidotti",
        "summary": "Online Social Networks (OSNs) widely adopt content moderation to mitigate the spread of abusive and toxic discourse. Nonetheless, the real effectiveness of moderation interventions remains unclear due to the high cost of data collection and limited experimental control. The latest developments in Natural Language Processing pave the way for a new evaluation approach. Large Language Models (LLMs) can be successfully leveraged to enhance Agent-Based Modeling and simulate human-like social behavior with unprecedented degree of believability. Yet, existing tools do not support simulation-based evaluation of moderation strategies. We fill this gap by designing a LLM-powered simulator of OSN conversations enabling a parallel, counterfactual simulation where toxic behavior is influenced by moderation interventions, keeping all else equal. We conduct extensive experiments, unveiling the psychological realism of OSN agents, the emergence of social contagion phenomena and the superior effectiveness of personalized moderation strategies.",
        "subjects": "Artificial Intelligence, Computers and Society, Multiagent Systems",
        "date": "2025-11-10",
        "category": "cs.MA",
        "crawl_time": "2025-11-12T11:00:03.706617",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地应用LLM去解决内容审核问题，而是**构建了一个全新的、由LLM驱动的多智能体模拟器**。摘要明确指出：“We fill this gap by designing a LLM-powered simulator of OSN conversations...”。这个模拟器本身就是一个方法论上的创新，它通过多个LLM智能体来模拟在线社交网络中的用户行为，以评估审核策略。因此，其本质是关于**构建多智能体系统**，符合您的研究目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents` 和 `Multi-Agent Systems (MAS)` 是论文的核心。摘要中提到的“Agent-Based Modeling”和“OSN agents”直接印证了这一点。 - **多智能体**: 论文研究了智能体间的`Communication`（OSN conversations）和`Social Learning`（emergence of social contagion phenomena），这些都是多智能体系统中的关键动态。 3.  **第三步：排除标准** - **安全与对齐**: 虽然论文的应用领域是“Online Moderation”（在线审核），这与安全相关，但论文的**主要贡献不是一种新的安全算法或对齐技术**。它的贡献在于提供了一种**评估安全策略的新方法**，而这个方法的核心是构建多智能体模拟环境。因此，它没有触犯“主要贡献是关于Safety”的排除规则。研究的焦点是“如何构建智能体来模拟”，而不是“如何让智能体更安全”。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及自我演化或复杂的单智能体规划，因此无需处理这些特殊情况。 5.  **第五步：最终决策** - 综合来看，这篇论文的核心是提出了一种构建LLM多智能体系统的新框架，用于模拟复杂的社会交互现象。它完全符合您研究范围中的“多智能体”方向，特别是关于智能体通信、协作（或对抗）以及社会行为涌现的子方向。尽管其应用场景是内容审核，但其根本贡献在于Agentic AI的方法论创新，而非应用本身。因此，这篇论文是高度相关的前沿研究，应被筛选出来。"
    },
    {
        "index": "#2",
        "title": "S-DAG: A Subject-Based Directed Acyclic Graph for Multi-Agent Heterogeneous Reasoning",
        "link": "/arxiv/2511.06727",
        "arxiv_id": "2511.06727",
        "authors": "Jiangwen Dong, Zehui Lin, Wanyu Lin, Mingjin Zhang",
        "summary": "Large Language Models (LLMs) have achieved impressive performance in complex reasoning problems. Their effectiveness highly depends on the specific nature of the task, especially the required domain knowledge. Existing approaches, such as mixture-of-experts, typically operate at the task level; they are too coarse to effectively solve the heterogeneous problems involving multiple subjects. This work proposes a novel framework that performs fine-grained analysis at subject level equipped with a designated multi-agent collaboration strategy for addressing heterogeneous problem reasoning. Specifically, given an input query, we first employ a Graph Neural Network to identify the relevant subjects and infer their interdependencies to generate an \\textit{Subject-based Directed Acyclic Graph} (S-DAG), where nodes represent subjects and edges encode information flow. Then we profile the LLM models by assigning each model a subject-specific expertise score, and select the top-performing one for matching corresponding subject of the S-DAG. Such subject-model matching enables graph-structured multi-agent collaboration where information flows from the starting model to the ending model over S-DAG. We curate and release multi-subject subsets of standard benchmarks (MMLU-Pro, GPQA, MedMCQA) to better reflect complex, real-world reasoning tasks. Extensive experiments show that our approach significantly outperforms existing task-level model selection and multi-agent collaboration baselines in accuracy and efficiency. These results highlight the effectiveness of subject-aware reasoning and structured collaboration in addressing complex and multi-subject problems.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-11-10",
        "category": "cs.MA",
        "crawl_time": "2025-11-12T11:00:03.704752",
        "filter_reason": "这篇论文完全符合筛选标准，应被保留。 **判断过程和核心依据如下：** 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建和改进一个多智能体系统**。其核心贡献是提出了一个名为S-DAG（基于主题的有向无环图）的**新框架**，用于组织多个LLM智能体进行协作以解决复杂的、跨主题的推理问题。这完全符合“构建、改进LLM智能体”的核心目标，并且直接命中了“多智能体”这一研究方向。它不是将现有框架简单应用到某个领域，而是提出了一种新的协作方法论。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: 明确提到了 `Multi-Agent Systems (MAS)`。 - **多智能体**: 核心贡献就是关于 `Collaboration`（协作），通过S-DAG的结构化信息流实现了智能体间的 `Communication`（通信）。 - **智能体能力**: S-DAG本身可以看作是一种高级的 `Planning`（规划）机制，它规划了不同专业智能体的执行顺序和信息传递路径。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐，也没有涉及多模态或视觉。因此，它没有被任何排除标准命中。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它不是在研究如何提升单个LLM的基础数学或逻辑推理能力，而是在研究**一个智能体框架如何组织和执行多步、多主体的复杂推理任务**。S-DAG就是这个规划过程的具象化，它定义了推理的流程和智能体间的协作方式，这正是Agentic AI研究的核心。 **最终决策：** 该论文的核心贡献是提出了一种新颖的、基于图结构的多智能体协作框架（S-DAG），以解决异构推理问题。这直接对应了研究课题中的“多智能体”方向，特别是“智能体间的协作、通信”等子方向。论文的工作是方法论创新，而非应用或基础设施，因此完全符合筛选要求。"
    },
    {
        "index": "#17",
        "title": "Maestro: Learning to Collaborate via Conditional Listwise Policy Optimization for Multi-Agent LLMs",
        "link": "/arxiv/2511.06134",
        "arxiv_id": "2511.06134",
        "authors": "Wei Yang, Jiacheng Pang, Shixuan Li, Paul Bogdan, Stephen Tu, Jesse Thomason",
        "summary": "Multi-agent systems (MAS) built on Large Language Models (LLMs) are being used to approach complex problems and can surpass single model inference. However, their success hinges on navigating a fundamental cognitive tension: the need to balance broad, divergent exploration of the solution space with a principled, convergent synthesis to the optimal solution. Existing paradigms often struggle to manage this duality, leading to premature consensus, error propagation, and a critical credit assignment problem that fails to distinguish between genuine reasoning and superficially plausible arguments. To resolve this core challenge, we propose the Multi-Agent Exploration-Synthesis framework Through Role Orchestration (Maestro), a principled paradigm for collaboration that structurally decouples these cognitive modes. Maestro uses a collective of parallel Execution Agents for diverse exploration and a specialized Central Agent for convergent, evaluative synthesis. To operationalize this critical synthesis phase, we introduce Conditional Listwise Policy Optimization (CLPO), a reinforcement learning objective that disentangles signals for strategic decisions and tactical rationales. By combining decision-focused policy gradients with a list-wise ranking loss over justifications, CLPO achieves clean credit assignment and stronger comparative supervision. Experiments on mathematical reasoning and general problem-solving benchmarks demonstrate that Maestro, coupled with CLPO, consistently outperforms existing state-of-the-art multi-agent approaches, delivering absolute accuracy gains of 6% on average and up to 10% at best.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-08",
        "category": "cs.MA",
        "crawl_time": "2025-11-12T11:00:03.708734",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出了一个名为“Maestro”的**多智能体协作新框架**，以及一种名为“CLPO”的**强化学习训练方法**。这直接命中了筛选标准中的“构建、改进或演化 LLM智能体”以及“多智能体系统”。论文的本质不是将现有智能体作为工具去解决某个特定领域的问题，而是**提出了一种方法论来改进多智能体系统本身的协作效率和推理能力**。因此，它不属于“非演化型应用”或“非Agentic的推理”。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量您关注的核心关键词和概念： *   **核心范式**: `Multi-Agent Systems (MAS)`, `LLM-based Agents`。 *   **多智能体**: `Collaborate` (协作) 是论文标题和摘要的核心。论文通过“Execution Agents”和“Central Agent”的角色分工，探讨了智能体间的协作模式。 *   **智能体能力**: 论文旨在解决多智能体在复杂任务中的推理问题，这与`Planning`和`Reasoning`在智能体框架下的应用高度相关。它不是在提升LLM本身的基础推理能力，而是在构建一个能让多个LLM智能体更好地进行规划和推理的系统。 3.  **第三步：排除标准 (未触发)** 论文的研究焦点是提升多智能体系统的性能和协作机制，完全没有涉及`Safety`、`Alignment`、`Interpretability`等安全与对齐议题，也未涉及`Vision`、`MLLMs`等多模态内容。 4.  **第四步：特殊和模糊情况 (清晰符合)** 论文的研究内容属于“推理/规划”的特殊情况。它不是提出一种新的CoT变体来提升单个LLM的数学能力，而是设计了一个**多智能体框架**来处理复杂的推理任务。这完全符合“保留：如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）”这一规则。 **总结**: 该论文的核心贡献在于**构建和改进一个多智能体LLM协作框架**，以解决多智能体系统中的核心挑战（如探索与合成的平衡、信用分配问题）。这精准地契合了您研究课题中的“多智能体”方向，是关于Agentic AI方法论的前沿研究，而非简单的应用或基础模型优化。因此，应予以保留。"
    },
    {
        "index": "#2",
        "title": "ConvFill: Model Collaboration for Responsive Conversational Voice Agents",
        "link": "/arxiv/2511.07397",
        "arxiv_id": "2511.07397",
        "authors": "Vidya Srinivas, Zachary Englhardt, Maximus Powers, Shwetak Patel, Vikram Iyer",
        "summary": "Deploying conversational voice agents with large language models faces a critical challenge: cloud-based foundation models provide deep reasoning and domain knowledge but introduce latency that disrupts natural conversation, while on-device models respond immediately but lack sophistication. We propose conversational infill, a task where a lightweight on-device model generates contextually appropriate dialogue while seamlessly incorporating streaming knowledge from a powerful backend model. This approach decouples response latency from model capability, enabling systems that feel responsive while accessing the full power of large-scale models. We present ConvFill, a 360M parameter model trained on synthetic multi-domain conversations. Evaluation across multiple backend models shows that conversational infill can be successfully learned, with ConvFill achieving accuracy improvements of 36-42% over standalone small models of the same size while consistently retaining sub-200ms response latencies. Our results demonstrate the promise of this approach for building on-device conversational agents that are both immediately responsive and knowledgeable.",
        "subjects": "Computation and Language",
        "date": "2025-11-10",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.035505",
        "filter_reason": "这篇论文符合我的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将现有LLM或智能体框架应用于某个领域，而是提出了一种名为“conversational infill”（对话填充）的**新任务和新框架**。这个框架旨在解决构建响应式对话语音智能体时面临的核心挑战：延迟与能力的权衡。它通过设计一种轻量级模型与强大后端模型协同工作的**新架构**，来构建一种新型的LLM智能体。这完全符合“构建、改进LLM智能体”的核心目标。虽然它解决的是一个部署中的延迟问题（看似基础设施），但其解决方案是**在智能体架构层面的创新**，而非通用的部署优化或硬件加速。 2.  **第二步：正面指标——高度相关** -   **核心范式**: 论文明确是关于构建 `LLM-based Agents`（对话语音智能体）。 -   **多智能体**: 论文提出的“Model Collaboration”（模型协作）可以被看作是一种简化的多智能体系统，其中两个不同规模的模型（一个快速的设备端模型和一个强大的后端模型）进行协作以完成共同目标。这触及了多智能体研究中的协作方向。 3.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性或视觉等多模态问题，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** -   **基础设施 vs. 智能体设计**: 这是本案例的关键。论文的动机是解决延迟（一个基础设施问题），但其**贡献是提出了一种新的智能体设计范式**。我的研究焦点是“如何构建智能体”，而这篇论文恰好提供了一种构建特定类型（响应式）智能体的新方法。因此，它属于智能体构建的范畴，而非纯粹的基础设施研究。 **最终决策**: 综合来看，这篇论文的核心是提出一种创新的智能体架构（conversational infill），通过模型协作的方式，构建了性能和响应速度兼备的对话语音智能体。这直接贡献于“构建和改进LLM智能体”这一核心目标，特别是涉及到了多模型协作的类多智能体思想。因此，这篇论文与我的研究课题“LLM智能体及其演化”高度相关，应该被保留。"
    },
    {
        "index": "#3",
        "title": "Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction",
        "link": "/arxiv/2511.07392",
        "arxiv_id": "2511.07392",
        "authors": "Hyeryun Park, Byung Mo Gu, Jun Hee Lee, Byeong Hyeon Choi, Sekeun Kim, Hyun Koo Kim, Kyungsang Kim",
        "summary": "In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in the procedure, making it difficult to access and manipulate multimodal patient data without interruption. We propose a voice-directed Surgical Agent Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework, consisting of an orchestration agent and three task-specific agents driven by Large Language Models (LLMs). These LLM-based agents autonomously plan, refine, validate, and reason to map voice commands into specific tasks such as retrieving clinical information, manipulating CT scans, or navigating 3D anatomical models on the surgical video. We also introduce a Multi-level Orchestration Evaluation Metric (MOEM) to comprehensively assess the performance and robustness from command-level and category-level perspectives. The SAOP achieves high accuracy and success rates across 240 voice commands, while LLM-based agents improve robustness against speech recognition errors and diverse or ambiguous free-form commands, demonstrating strong potential to support minimally invasive da Vinci robotic surgery.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-10",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.035834",
        "filter_reason": "这篇论文符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文的本质**: 这篇论文的核心贡献是提出并构建了一个**分层多智能体编排平台（SAOP）**。它详细描述了该框架的架构（一个编排智能体+三个任务特定智能体）以及这些LLM智能体如何协同工作。这完全符合“构建、改进LLM智能体”或“多智能体系统”的核心目标。 - **排除项分析**: - **非演化型应用**: 虽然论文的应用领域是机器人手术，但其核心贡献并非“将LLM用于手术”，而是**“如何设计一个多智能体框架来解决手术中的交互问题”**。它提出了新的架构（SAOP）和新的评估指标（MOEM），这属于方法论创新，而非简单的应用。因此，它不属于“非演化型应用”的排除范畴。 - **非Agentic的推理**: 论文明确指出智能体能够“自主地规划、优化、验证和推理”，这是典型的Agentic行为，而非提升LLM本身的基础推理能力。 - **基础设施**: 论文不涉及模型基础设施或硬件加速。 2.  **第二步：正面指标** - 论文包含了大量你的核心关注点： - **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)` (明确提出了分层多智能体框架)。 - **智能体能力**: `Planning` (自主规划), `Self-Correction` / `Self-Refine` (优化和验证), `Tool Use` (将语音命令映射为检索信息、操作CT扫描等具体任务)。 - **多智能体**: `Collaboration` (编排智能体与任务智能体之间的协作)。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性。 - **多模态与视觉**: 论文提到了CT扫描、3D解剖模型和手术视频等多模态信息。但根据你的规则，这些是**智能体感知和操作的工具/对象**，而不是论文研究的核心。论文的核心是智能体的编排框架和决策逻辑，而非提出新的视觉或多模态模型。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“规划、优化、验证和推理”是在智能体框架内为了完成任务而进行的，属于Agentic的规划和推理，因此应该保留。 5.  **第五步：最终决策** - 综合来看，这篇论文的核心是**设计、实现和评估一个新颖的多智能体系统（SAOP）**，以解决复杂环境下的语音交互任务。它详细阐述了智能体的架构、协作方式、规划与工具使用能力，并提出了新的评估方法。这完全契合你研究课题中的“多智能体”方向，并与“单智能体”的规划、工具使用等能力紧密相关。尽管应用场景是特定的医疗领域，但其方法论贡献是普适的，属于Agentic AI的核心研究范畴。 因此，最终判断为 **True**。"
    },
    {
        "index": "#7",
        "title": "FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation",
        "link": "/arxiv/2511.07322",
        "arxiv_id": "2511.07322",
        "authors": "Song Jin, Shuqi Li, Shukun Zhang, Rui Yan",
        "summary": "While LLMs have shown great success in financial tasks like stock prediction and question answering, their application in fully automating Equity Research Report generation remains uncharted territory. In this paper, we formulate the Equity Research Report (ERR) Generation task for the first time. To address the data scarcity and the evaluation metrics absence, we present an open-source evaluation benchmark for ERR generation - FinRpt. We frame a Dataset Construction Pipeline that integrates 7 financial data types and produces a high-quality ERR dataset automatically, which could be used for model training and evaluation. We also introduce a comprehensive evaluation system including 11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent framework specifically tailored to address this task, named FinRpt-Gen, and train several LLM-based agents on the proposed datasets using Supervised Fine-Tuning and Reinforcement Learning. Experimental results indicate the data quality and metrics effectiveness of the benchmark FinRpt and the strong performance of FinRpt-Gen, showcasing their potential to drive innovation in the ERR generation field. All code and datasets are publicly available.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-10",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.036992",
        "filter_reason": "这篇论文符合筛选标准，应被保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个已有的智能体框架应用到金融领域。它的核心贡献之一是**“提出一个名为FinRpt-Gen的多智能体框架，该框架是专门为解决股票研究报告生成任务而量身定制的”**。这属于“构建、改进或演化LLM智能体”的范畴，特别是“多智能体系统”的方法论贡献。因此，它不属于“非演化型应用”的排除范围。 2.  **第二步：正面指标** - 论文摘要中明确包含了多个核心正面指标： - `LLM-based Multi-agent framework`: 直接命中“多智能体”研究方向。 - `train several LLM-based agents`: 进一步强化了其智能体研究的属性。 - 虽然摘要未详细展开，但一个用于生成复杂报告的“多智能体框架”必然涉及智能体间的**协作**、**通信**和**规划**，这些都是我的核心关注点。 3.  **第三步：排除标准** - 论文的主要贡献是关于框架设计、数据集构建和评估，没有涉及`Safety`、`Alignment`、`Interpretability`等安全与对齐主题。 - 论文处理的是金融数据，核心是文本报告生成，并未将`Vision`或`MLLMs`作为研究核心，因此不触发多模态排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的FinRpt-Gen框架，其目标是生成一份结构复杂的股票研究报告，这必然涉及到智能体内部的规划以及多智能体间的任务分解与协作规划。这完全符合“保留”关于智能体如何进行规划的论文的标准。 - **自我演化的应用**: 论文未明确提及“自我演化”机制，它采用的是监督微调和强化学习进行训练。但这并不影响其被保留，因为它已经通过“多智能体框架”这一核心贡献满足了筛选条件。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于**构建了一个新颖的多智能体框架**来解决一个复杂任务。尽管其应用场景是金融领域，但其科学价值在于智能体系统的设计本身，这与我的研究目标“LLM智能体及其演化”中的“多智能体”方向高度契合。因此，应将其保留。"
    },
    {
        "index": "#15",
        "title": "The Station: An Open-World Environment for AI-Driven Discovery",
        "link": "/arxiv/2511.06309",
        "arxiv_id": "2511.06309",
        "authors": "Stephen Chung, Wenyu Du",
        "summary": "We introduce the STATION, an open-world multi-agent environment that models a miniature scientific ecosystem. Leveraging their extended context windows, agents in the Station can engage in long scientific journeys that include reading papers from peers, formulating hypotheses, submitting code, performing analyses, and publishing results. Importantly, there is no centralized system coordinating their activities - agents are free to choose their own actions and develop their own narratives within the Station. Experiments demonstrate that AI agents in the Station achieve new state-of-the-art performance on a wide range of benchmarks, spanning from mathematics to computational biology to machine learning, notably surpassing AlphaEvolve in circle packing. A rich tapestry of narratives emerges as agents pursue independent research, interact with peers, and build upon a cumulative history. From these emergent narratives, novel methods arise organically, such as a new density-adaptive algorithm for scRNA-seq batch integration. The Station marks a first step towards autonomous scientific discovery driven by emergent behavior in an open-world environment, representing a new paradigm that moves beyond rigid optimization.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-09",
        "category": "cs.MA",
        "crawl_time": "2025-11-12T11:00:03.708184",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献与你的三个研究方向高度契合。判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献并非将LLM智能体作为工具去解决某个特定领域（如生物学）的问题，而是**构建了一个全新的、开放世界的多智能体环境**。这个环境本身就是一个方法论和框架，旨在研究AI智能体如何自主地进行科学发现。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。它不是“非演化型应用”，因为其重点在于智能体行为的涌现和演化机制，而非应用结果。 2.  **第二步：正面指标——高度匹配** - 论文摘要中充满了你的核心关注点： - **多智能体**: 明确提出 \"open-world **multi-agent environment**\"，并描述了智能体间的互动，如 \"reading papers from peers\"、\"interact with peers\"。 - **单智能体能力**: 智能体展现了高级的自主能力，包括 \"formulating hypotheses\" (规划)、\"submitting code, performing analyses\" (工具使用)、\"build upon a cumulative history\" (记忆)。 - **自我演化**: 这是最关键的一点。论文明确指出 \"novel methods arise **organically**\" 和 \"autonomous scientific discovery driven by **emergent behavior**\"。这表明智能体系统不是被预设好所有行为的，而是通过互动和经验，涌现出新的、更优的方法，这正是“自我演化”的核心体现。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不涉及安全、对齐、可解释性或水印等问题。 - 论文也未将视觉或多模态作为研究核心，而是聚焦于智能体的行为框架。 4.  **第四步：处理特殊和模糊情况——符合保留例外** - 论文虽然应用在“科学发现”领域，但它完美地符合“自我演化的应用”这一保留例外。其核心是提出了一种**新的“自我演化”机制**（即通过开放世界中的多智能体互动涌现出新方法），并应用该机制于科学领域。因此，它应该被保留。 **最终决策**: 这篇论文的核心是构建一个促进多智能体协作、自主规划和涌现式自我演化的新环境。它直接推动了“多智能体”和“自我演化”两个前沿方向的研究，并展示了智能体在复杂任务中的高级能力。因此，这篇论文是你研究课题“LLM智能体及其演化”的绝佳筛选对象。"
    },
    {
        "index": "#17",
        "title": "TCM-Eval: An Expert-Level Dynamic and Extensible Benchmark for Traditional Chinese Medicine",
        "link": "/arxiv/2511.07148",
        "arxiv_id": "2511.07148",
        "authors": "Zihao Cheng, Yuheng Lu, Huaiqian Ye, Zeming Liu, Minqi Wang, Jingjing Liu, Zihan Li, Wei Fan, Yuanfang Guo, Ruiji Fu, Shifeng She, Gang Wang, Yunhong Wang",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in modern medicine, yet their application in Traditional Chinese Medicine (TCM) remains severely limited by the absence of standardized benchmarks and the scarcity of high-quality training data. To address these challenges, we introduce TCM-Eval, the first dynamic and extensible benchmark for TCM, meticulously curated from national medical licensing examinations and validated by TCM experts. Furthermore, we construct a large-scale training corpus and propose Self-Iterative Chain-of-Thought Enhancement (SI-CoTE) to autonomously enrich question-answer pairs with validated reasoning chains through rejection sampling, establishing a virtuous cycle of data and model co-evolution. Using this enriched training data, we develop ZhiMingTang (ZMT), a state-of-the-art LLM specifically designed for TCM, which significantly exceeds the passing threshold for human practitioners. To encourage future research and development, we release a public leaderboard, fostering community engagement and continuous improvement.",
        "subjects": "Computation and Language",
        "date": "2025-11-10",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.039980",
        "filter_reason": "这篇论文符合筛选标准，应当保留。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献并非仅仅是构建一个应用于中医（TCM）领域的LLM，而是提出了一种名为 `Self-Iterative Chain-of-Thought Enhancement (SI-CoTE)` 的新方法。该方法的核心是“通过拒绝采样自主地丰富问答对，建立数据和模型共同演化的良性循环”。这本质上是一种**自我演化**的机制，它让模型（或其训练数据）能够通过迭代和自我完善来提升性能。因此，论文的核心是关于构建一种自我演化的方法论，符合“保留”标准。 2.  **第二步：正面指标** 论文明确包含了多个核心关注点： *   **演化机制**: `Self-Evolving`（共同演化）、`Self-Improvement`（自我完善）、`Self-Refine`（通过拒绝采样完善数据）、`Iterative Improvement`（自我迭代）。 这些正面指标强烈表明该论文与“自我演化”的研究方向高度相关。 3.  **第三步：排除标准** 论文的主要贡献不涉及安全、对齐、可解释性或多模态视觉，因此不触犯排除标准。 4.  **第四步：处理特殊和模糊情况** 这里的关键点是“自我演化的应用”。虽然论文的应用领域是特定的（传统中医），但其核心贡献是提出了一种**新的“自我演化”机制（SI-CoTE）**。根据筛选规则第四条的特殊情况说明：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 这篇论文完美地符合这一例外情况。它不是简单地将一个已有的智能体框架应用到中医领域，而是发明了一种能让数据和模型共同演化的新方法，并用中医领域作为验证其有效性的案例。 **最终决策**: 综合以上分析，尽管论文标题和摘要的大部分内容围绕着一个特定领域的基准和模型，但其最核心、最具创新性的贡献是 `SI-CoTE` 这一**自我演化机制**。该机制直接命中了研究课题的三大焦点之一“自我演化”。因此，这篇论文不仅符合，而且是高度符合你的研究范围，应当被保留。"
    },
    {
        "index": "#45",
        "title": "Steering LLMs toward Korean Local Speech: Iterative Refinement Framework for Faithful Dialect Translation",
        "link": "/arxiv/2511.06680",
        "arxiv_id": "2511.06680",
        "authors": "Keunhyeung Park, Seunguk Yu, Youngbin Kim",
        "summary": "Standard-to-dialect machine translation remains challenging due to a persistent dialect gap in large language models and evaluation distortions inherent in n-gram metrics, which favor source copying over authentic dialect translation. In this paper, we propose the dialect refinement (DIA-REFINE) framework, which guides LLMs toward faithful target dialect outputs through an iterative loop of translation, verification, and feedback using external dialect classifiers. To address the limitations of n-gram-based metrics, we introduce the dialect fidelity score (DFS) to quantify linguistic shift and the target dialect ratio (TDR) to measure the success of dialect translation. Experiments on Korean dialects across zero-shot and in-context learning baselines demonstrate that DIA-REFINE consistently enhances dialect fidelity. The proposed metrics distinguish between False Success cases, where high n-gram scores obscure failures in dialectal translation, and True Attempt cases, where genuine attempts at dialectal translation yield low n-gram scores. We also observed that models exhibit varying degrees of responsiveness to the framework, and that integrating in-context examples further improves the translation of dialectal expressions. Our work establishes a robust framework for goal-directed, inclusive dialect translation, providing both rigorous evaluation and critical insights into model performance.",
        "subjects": "Computation and Language",
        "date": "2025-11-10",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.048130",
        "filter_reason": "这篇论文符合我的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一个名为 `DIA-REFINE` 的**迭代优化框架**。这个框架通过一个“翻译、验证、反馈”的循环来引导LLM。这本质上是一个**自我演化**的机制，因为它让模型通过外部反馈（来自方言分类器）来迭代地改进其输出，而不是一次性完成任务。因此，这篇论文的本质是关于构建一个让LLM进行自我完善的方法论，符合“自我演化”的核心目标，应予以**保留**。 2.  **第二步：正面指标** 论文中包含了多个与我研究焦点高度相关的正面指标： *   **演化机制**: 论文明确提出了 `Iterative Refinement`（迭代优化）和 `Iterative Improvement`（迭代改进）的框架。 *   **自我演化**: 整个 `DIA-REFINE` 框架就是一个 `Self-Refine`（自我优化）过程的实例，它利用反馈来修正和提升自身表现。 这些指标强烈表明该论文与我的“自我演化”研究方向直接相关。 3.  **第三步：排除标准** 论文的研究内容不涉及安全与对齐、多模态与视觉等排除领域。它的焦点是方法论和评估指标，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** 这里的关键点是区分“非演化型应用”和“自我演化的应用”。 *   如果论文仅仅是使用一个现有的LLM（如GPT-4）去翻译韩语方言，并报告其效果，那它就属于“非演化型应用”，应被排除。 *   然而，这篇论文的核心贡献是**提出了一种新的“自我演化”机制**——即 `DIA-REFINE` 这个迭代反馈框架。虽然这个机制被应用在“韩语方言翻译”这个特定领域，但根据筛选规则中的例外条款：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 这篇论文完美地符合了这一例外情况。它的价值在于这个可迁移的迭代优化框架本身，而不仅仅是其在方言翻译上的应用。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个新颖的、基于反馈循环的**自我优化框架**。这完全符合我研究课题中“自我演化”的核心目标。尽管其应用场景（方言翻译）是具体的，但其方法论具有普适性，并且直接贡献于Agentic AI的自我完善能力。因此，这篇论文应被**保留**。"
    },
    {
        "index": "#44",
        "title": "Textual Self-attention Network: Test-Time Preference Optimization through Textual Gradient-based Attention",
        "link": "/arxiv/2511.06682",
        "arxiv_id": "2511.06682",
        "authors": "Shibing Mo, Haoyang Ruan, Kai Wu, Jing Liu",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable generalization capabilities, but aligning their outputs with human preferences typically requires expensive supervised fine-tuning. Recent test-time methods leverage textual feedback to overcome this, but they often critique and revise a single candidate response, lacking a principled mechanism to systematically analyze, weigh, and synthesize the strengths of multiple promising candidates. Such a mechanism is crucial because different responses may excel in distinct aspects (e.g., clarity, factual accuracy, or tone), and combining their best elements may produce a far superior outcome. This paper proposes the Textual Self-Attention Network (TSAN), a new paradigm for test-time preference optimization that requires no parameter updates. TSAN emulates self-attention entirely in natural language to overcome this gap: it analyzes multiple candidates by formatting them into textual keys and values, weighs their relevance using an LLM-based attention module, and synthesizes their strengths into a new, preference-aligned response under the guidance of the learned textual attention. This entire process operates in a textual gradient space, enabling iterative and interpretable optimization. Empirical evaluations demonstrate that with just three test-time iterations on a base SFT model, TSAN outperforms supervised models like Llama-3.1-70B-Instruct and surpasses the current state-of-the-art test-time alignment method by effectively leveraging multiple candidate solutions.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-10",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.047878",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了一种名为“文本自注意力网络（TSAN）”的新范式。其本质并非将LLM作为工具应用于某个特定领域，也不是提升LLM的基础推理能力，而是构建了一个**在测试时无需更新模型参数即可进行自我优化和迭代的框架**。这个框架通过生成多个候选答案，并利用一种新颖的“文本自注意力”机制来分析和综合这些答案，从而生成一个更优的最终答案。这种“迭代和可解释的优化”过程，本质上是一种**自我完善（Self-Improvement）和自我精炼（Self-Refine）**的机制，完全符合“自我演化”的核心定义。 **第二步：正面指标** - 论文包含了多个核心关注点： - **自我演化**: 论文的核心是“Test-Time Preference Optimization”，并明确提出了“iterative and interpretable optimization”（迭代和可解释的优化），这直接命中了“自我演化”方向。 - **自我完善/自我精炼**: TSAN的整个流程——生成多个候选、分析、综合、生成新答案——是一个典型的自我精炼循环。 - **迭代改进**: 论文明确指出该方法通过“just three test-time iterations”取得了显著效果，符合“迭代改进”的特征。 **第三步：排除标准** - **安全与对齐**: 虽然论文标题和摘要中提到了“Preference Optimization”（偏好优化），这与“对齐”相关，但需要仔细甄别。我的筛选标准是“只要论文的**主要贡献**是关于安全、对齐……一律排除”。在本论文中，**主要贡献是TSAN这个实现自我演化的方法论框架**，而不是提出一种新的对齐理论或安全机制。“偏好优化”是该框架所要解决的问题和应用场景，而非其核心创新点。因此，它不应被归为“对齐”研究而被排除。 - **多模态与视觉**: 论文内容完全不涉及视觉或多模态，因此不触发此项排除标准。 **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文不涉及智能体的规划或复杂任务推理，它关注的是对单个问题的答案进行优化。因此，此项规则不直接适用。 - **自我演化的应用**: 该论文提出的自我演化机制是通用的，并非局限于特定领域，因此此项规则不直接适用，但其精神（保留提出新演化机制的论文）支持了保留该论文的决定。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种新颖的、基于文本梯度和自注意力机制的**自我演化框架**。它使LLM能够在测试时通过迭代和自我精炼来提升输出质量，完全符合我研究课题中“自我演化”这一核心方向。尽管它触及了“对齐”的应用领域，但其本质是方法论创新，而非对齐理论本身。因此，最终判断为 **True**，应保留此论文。"
    },
    {
        "index": "#96",
        "title": "MCP4IFC: IFC-Based Building Design Using Large Language Models",
        "link": "/arxiv/2511.05533",
        "arxiv_id": "2511.05533",
        "authors": "Bharathi Kannan Nithyanantham, Tobias Sesterhenn, Ashwin Nedungadi, Sergio Peral Garijo, Janis Zenkner, Christian Bartelt, Stefan Lüdtke",
        "summary": "Bringing generative AI into the architecture, engineering and construction (AEC) field requires systems that can translate natural language instructions into actions on standardized data models. We present MCP4IFC, a comprehensive open-source framework that enables Large Language Models (LLMs) to directly manipulate Industry Foundation Classes (IFC) data through the Model Context Protocol (MCP). The framework provides a set of BIM tools, including scene querying tools for information retrieval, predefined functions for creating and modifying common building elements, and a dynamic code-generation system that combines in-context learning with retrieval-augmented generation (RAG) to handle tasks beyond the predefined toolset. Experiments demonstrate that an LLM using our framework can successfully perform complex tasks, from building a simple house to querying and editing existing IFC data. Our framework is released as open-source to encourage research in LLM-driven BIM design and provide a foundation for AI-assisted modeling workflows. Our code is available at https://show2instruct.github.io/mcp4ifc/.",
        "subjects": "Computation and Language",
        "date": "2025-10-29",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.062716",
        "filter_reason": "根据您提供的筛选标准，我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心贡献是提出了一个名为 **MCP4IFC 的开源框架**。这个框架的本质是赋予大型语言模型（LLM）操作外部标准化数据模型（IFC，建筑信息模型）的能力。 - **判断**: 这完全符合 **“构建、改进LLM智能体的方法论或新框架”** 的保留标准。该框架通过提供一系列工具（如场景查询、元素创建修改、动态代码生成），使LLM能够像一个智能体一样，在建筑设计的数字环境中执行复杂任务。虽然其应用领域是特定的（AEC建筑行业），但其核心贡献是**如何构建这样一个具备工具使用能力的智能体**，而不是简单地应用LLM解决一个领域问题。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (论文的核心就是构建基于LLM的智能体)。 - **智能体能力**: `Tool Use / Tool Augmentation` (这是MCP4IFC框架最核心的机制，提供了BIM工具集和动态代码生成系统)。虽然摘要未明确提及`Planning`，但执行“从建造简单房屋到查询和编辑现有数据”的复杂任务，必然隐含了规划和多步推理能力，这是Agentic框架的典型特征。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。它专注于构建一个功能性的智能体框架，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文属于“保留”情况。它不是在提升LLM的基础数学或逻辑推理能力，而是在构建一个让LLM能够通过工具使用进行多步规划和执行的Agentic框架。这与ReAct等范式的精神一致。 - **自我演化的应用**: 此规则不直接适用，因为论文未提出自我演化机制。关键在于第一步的判断，即其核心是构建智能体框架，而非单纯应用。 5.  **第五步：最终决策** - 综合以上分析，尽管论文的应用场景（建筑设计）非常具体，但其**核心贡献在于提出了一种构建LLM智能体的新框架，并重点解决了工具使用和动态代码生成这一关键Agentic能力**。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标高度一致。因此，这篇论文应该被保留。"
    },
    {
        "index": "#104",
        "title": "IterResearch: Rethinking Long-Horizon Agents via Markovian State Reconstruction",
        "link": "/arxiv/2511.07327",
        "arxiv_id": "2511.07327",
        "authors": "Guoxin Chen, Zile Qiao, Xuanzhong Chen, Donglei Yu, Haotian Xu, Wayne Xin Zhao, Ruihua Song, Wenbiao Yin, Huifeng Yin, Liwen Zhang, Kuan Li, Minpeng Liao, Yong Jiang, Pengjun Xie, Fei Huang, Jingren Zhou",
        "summary": "Recent advances in deep-research agents have shown promise for autonomous knowledge construction through dynamic reasoning over external sources. However, existing approaches rely on a mono-contextual paradigm that accumulates all information in a single, expanding context window, leading to context suffocation and noise contamination that limit their effectiveness on long-horizon tasks. We introduce IterResearch, a novel iterative deep-research paradigm that reformulates long-horizon research as a Markov Decision Process with strategic workspace reconstruction. By maintaining an evolving report as memory and periodically synthesizing insights, our approach preserves consistent reasoning capacity across arbitrary exploration depths. We further develop Efficiency-Aware Policy Optimization (EAPO), a reinforcement learning framework that incentivizes efficient exploration through geometric reward discounting and enables stable distributed training via adaptive downsampling. Extensive experiments demonstrate that IterResearch achieves substantial improvements over existing open-source agents with average +14.5pp across six benchmarks and narrows the gap with frontier proprietary systems. Remarkably, our paradigm exhibits unprecedented interaction scaling, extending to 2048 interactions with dramatic performance gains (from 3.5\\% to 42.5\\%), and serves as an effective prompting strategy, improving frontier models by up to 19.2pp over ReAct on long-horizon tasks. These findings position IterResearch as a versatile solution for long-horizon reasoning, effective both as a trained agent and as a prompting paradigm for frontier models.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-10",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.065519",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建和改进LLM智能体，具体分析如下： 1.  **第一步：核心判断 (保留)** 论文的核心是提出一个名为 **IterResearch** 的新颖框架，用于解决长期任务中的智能体问题。它不是简单地将现有智能体应用于某个领域，而是从根本上**重构了智能体的工作范式**（从单一上下文到迭代式马尔可夫决策过程）。这直接对应了你筛选标准中的“构建、改进或演化 LLM智能体的方法论或新框架”，因此应予以保留。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量与你研究焦点相关的核心关键词和概念： *   **核心范式**: 论文明确研究 `LLM-based Agents` (`deep-research agents`, `long-horizon agents`)。 *   **智能体能力**: *   `Planning`: 论文将长期研究构建为 `Markov Decision Process`，这本身就是一种高级的规划模型。 *   `Memory`: 明确提出 `maintaining an evolving report as memory`，这是智能体记忆机制的核心研究。 *   `Self-Reflection`: 通过 `periodically synthesizing insights` 来避免噪声污染，这是一种明确的自我反思机制。 *   `ReAct`: 论文将 `ReAct` 作为基线进行比较，表明其工作是在经典的Agentic框架上进行改进。 *   **演化机制**: *   `Self-Improvement` / `Iterative Improvement`: 论文的标题和核心思想就是“迭代研究”，其范式本身就是迭代改进的。此外，它提出的 `Efficiency-Aware Policy Optimization (EAPO)` 是一个强化学习框架，通过训练使智能体实现性能的迭代提升，这完全符合“自我演化”的范畴。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献是提升智能体在长期任务中的推理效率和性能，并未涉及安全、对齐、可解释性或水印等问题。同时，其研究对象是基于文本的知识构建，没有将视觉或多模态作为研究核心，因此未触发任何排除标准。 4.  **第四步：特殊和模糊情况 (完美契合)** 这篇论文是“推理/规划”这一特殊情况的典型范例。它研究的不是LLM本身的基础推理能力（如数学计算），而是**智能体如何进行复杂、长期的多步规划和推理**。它提出的IterResearch框架和MDP建模，正是为了解决智能体在长链任务中的规划和记忆难题，这与你的研究目标高度一致。 **总结**: 论文的核心贡献是提出了一种新的、迭代的、具备记忆和自我反思能力的LLM智能体框架（IterResearch），并配套了用于自我优化的强化学习方法（EAPO）。这直接命中了你研究范围中的“单智能体”和“自我演化”两个核心方向。因此，这篇论文是高度相关且应被筛选出的前沿研究。"
    },
    {
        "index": "#107",
        "title": "MENTOR: A Metacognition-Driven Self-Evolution Framework for Uncovering and Mitigating Implicit Risks in LLMs on Domain Tasks",
        "link": "/arxiv/2511.07107",
        "arxiv_id": "2511.07107",
        "authors": "Liang Shan, Kaicheng Shen, Wen Wu, Zhenyu Ying, Chaochao Lu, Guangze Ye, Liang He",
        "summary": "Ensuring the safety and value alignment of large language models (LLMs) is critical for their deployment. Current alignment efforts primarily target explicit risks such as bias, hate speech, and violence. However, they often fail to address deeper, domain-specific implicit risks and lack a flexible, generalizable framework applicable across diverse specialized fields. Hence, we proposed MENTOR: A MEtacognition-driveN self-evoluTion framework for uncOvering and mitigating implicit Risks in LLMs on Domain Tasks. To address the limitations of labor-intensive human evaluation, we introduce a novel metacognitive self-assessment tool. This enables LLMs to reflect on potential value misalignments in their responses using strategies like perspective-taking and consequential thinking. We also release a supporting dataset of 9,000 risk queries spanning education, finance, and management to enhance domain-specific risk identification. Subsequently, based on the outcomes of metacognitive reflection, the framework dynamically generates supplementary rule knowledge graphs that extend predefined static rule trees. This enables models to actively apply validated rules to future similar challenges, establishing a continuous self-evolution cycle that enhances generalization by reducing maintenance costs and inflexibility of static systems. Finally, we employ activation steering during inference to guide LLMs in following the rules, a cost-effective method to robustly enhance enforcement across diverse contexts. Experimental results show MENTOR's effectiveness: In defensive testing across three vertical domains, the framework substantially reduces semantic attack success rates, enabling a new level of implicit risk mitigation for LLMs. Furthermore, metacognitive assessment not only aligns closely with baseline human evaluators but also delivers more thorough and insightful analysis of LLMs value alignment.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-10",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.066434",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了您定义的第三个核心方向：“自我演化”。 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 MENTOR 的“自我演化框架”。它不是简单地将LLM应用于安全领域，而是构建了一个能让LLM通过自身经验进行迭代和完善的机制。论文的核心是方法论和框架本身，而非其在特定领域的应用结果。 2.  **第二步：正面指标** - 论文标题和摘要中明确包含了多个核心正面指标： - **核心范式**: `Self-Evolving` (自我演化) 是标题和摘要的核心。 - **智能体能力**: `Self-Reflection` (自我反思) 通过“元认知自我评估工具”实现，LLM被引导去“反思”其回应中的潜在风险。 - **演化机制**: `Self-Improvement` (自我完善) 和 `Iterative Improvement` (迭代改进) 通过“持续自我演化循环”实现，模型根据反思结果动态生成新规则，并应用于未来任务，从而不断提升自身能力。 3.  **第三步：排除标准** - **安全与对齐**: 这是本案例中最需要辨析的一点。虽然论文的**应用目标**是“安全”和“对齐”，但其**核心贡献**并非一种新的对齐理论或安全技术，而是一个实现自我演化的**框架**。论文的创新点在于“如何让智能体自我演化”，而“安全”是这个演化机制所解决的具体问题。根据筛选标准“只要论文的**主要贡献**是关于 Safety...一律排除”，本文的主要贡献是框架，因此不应被排除。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这条规则完美适用于本文。论文的核心是提出一种新的“自我演化”机制（元认知驱动的动态规则生成与迭代循环），并将其应用在“领域任务中的隐性风险”这一特定领域。根据您的指示，这种情况应该**保留**。 **核心依据总结**: 该论文的核心贡献是构建了一个具有元认知能力的自我演化框架。它通过让LLM进行自我反思，动态地生成和更新知识（规则），并形成一个持续改进的闭环。这完全符合您对“自我演化”智能体的定义，即“智能体通过经验、反思或环境反馈进行自我完善和迭代”。尽管其应用场景是安全对齐，但这并不改变其方法论上属于Agentic AI自我演化研究的本质。因此，这篇论文是您研究课题下的高度相关文献。"
    },
    {
        "index": "#132",
        "title": "The Imperfect Learner: Incorporating Developmental Trajectories in Memory-based Student Simulation",
        "link": "/arxiv/2511.05903",
        "arxiv_id": "2511.05903",
        "authors": "Zhengyuan Liu, Stella Xin Yin, Bryan Chen Zhengyu Tan, Roy Ka-Wei Lee, Guimei Liu, Dion Hoe-Lian Goh, Wenya Wang, Nancy F. Chen",
        "summary": "User simulation is important for developing and evaluating human-centered AI, yet current student simulation in educational applications has significant limitations. Existing approaches focus on single learning experiences and do not account for students' gradual knowledge construction and evolving skill sets. Moreover, large language models are optimized to produce direct and accurate responses, making it challenging to represent the incomplete understanding and developmental constraints that characterize real learners. In this paper, we introduce a novel framework for memory-based student simulation that incorporates developmental trajectories through a hierarchical memory mechanism with structured knowledge representation. The framework also integrates metacognitive processes and personality traits to enrich the individual learner profiling, through dynamical consolidation of both cognitive development and personal learning characteristics. In practice, we implement a curriculum-aligned simulator grounded on the Next Generation Science Standards. Experimental results show that our approach can effectively reflect the gradual nature of knowledge development and the characteristic difficulties students face, providing a more accurate representation of learning processes.",
        "subjects": "Computers and Society, Artificial Intelligence, Computation and Language, Human-Computer Interaction",
        "date": "2025-11-08",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.074225",
        "filter_reason": "这篇论文符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于教育领域，而是**构建一个全新的、具有特定能力的LLM智能体框架**。其核心贡献是“一种新颖的、基于记忆的学生模拟框架”，该框架通过“分层记忆机制”来模拟学生的“发展轨迹”。这完全符合你筛选标准中“构建、改进或演化LLM智能体的方法论或新框架”的要求。它不是在解决一个教育问题，而是在**创造一个能够模拟学习过程的智能体**，这是一个典型的Agentic AI研究。 2.  **第二步：正面指标** - 论文包含了多个你的核心关注点： - **自我演化**: 摘要中明确提到了“发展轨迹”、“渐进的知识构建”和“不断发展的技能组合”，这正是智能体随时间演化的体现。 - **记忆**: “基于记忆的学生模拟”和“分层记忆机制”是其核心创新点之一。 - **自我反思**: 论文明确指出“整合了元认知过程”，这是自我反思和自我认知的关键组成部分。 - **Agentic AI**: 整个框架就是一个LLM-based Agent，用于模拟一个复杂的个体（学生）。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。它的焦点是智能体的内部机制和行为模拟，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它被应用在“教育”这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**（即通过分层记忆模拟发展轨迹）。根据你的规则，这种情况应该保留。论文的价值在于这个机制本身，而不是它在教育领域的应用效果。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个能够模拟学习过程和知识演化的LLM智能体。它直接命中了你的“自我演化”和“单智能体（记忆、自我反思）”研究方向。尽管其应用场景是教育，但其方法论上的创新完全符合你筛选前沿Agentic AI论文的目标。因此，应判定为 **True**。"
    },
    {
        "index": "#128",
        "title": "Adapting Web Agents with Synthetic Supervision",
        "link": "/arxiv/2511.06101",
        "arxiv_id": "2511.06101",
        "authors": "Zhaoyang Wang, Yiming Liang, Xuchao Zhang, Qianhui Wu, Siwei Han, Anson Bastos, Rujia Wang, Chetan Bansal, Baolin Peng, Jianfeng Gao, Saravan Rajmohan, Huaxiu Yao",
        "summary": "Web agents struggle to adapt to new websites due to the scarcity of environment specific tasks and demonstrations. Recent works have explored synthetic data generation to address this challenge, however, they suffer from data quality issues where synthesized tasks contain hallucinations that cannot be executed, and collected trajectories are noisy with redundant or misaligned actions. In this paper, we propose SynthAgent, a fully synthetic supervision framework that aims at improving synthetic data quality via dual refinement of both tasks and trajectories. Our approach begins by synthesizing diverse tasks through categorized exploration of web elements, ensuring efficient coverage of the target environment. During trajectory collection, we refine tasks when conflicts with actual observations are detected, mitigating hallucinations while maintaining task consistency. After collection, we conduct trajectory refinement with a global context to mitigate potential noise or misalignments. Finally, we fine-tune open-source web agents on the refined synthetic data to adapt them to the target environment. Experimental results demonstrate that SynthAgent outperforms existing synthetic data methods, validating the importance of high-quality synthetic supervision. The code will be publicly available at https://github.com/aiming-lab/SynthAgent.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-11-08",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.073006",
        "filter_reason": "这篇论文符合研究范围，应被保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为一个工具去解决某个特定领域（如金融、医疗）的问题，而是聚焦于如何**改进LLM智能体本身**。其核心贡献是提出了一个名为 `SynthAgent` 的框架，用于解决Web智能体在适应新环境时面临的挑战。这完全符合“构建、改进或演化 LLM智能体”的核心目标。它不属于“非演化型应用”、“非Agentic的推理”或“基础设施”等排除类别。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文明确研究 `LLM-based Agents` (Web agents)。 - **智能体能力**: 论文的核心是提升智能体在真实环境（网站）中的执行能力，这直接关联到 `Tool Use` (使用浏览器) 和 `Planning` (执行任务轨迹)。 - **演化机制**: 这是最关键的匹配点。论文提出的 `dual refinement` (双重精炼) 机制，包括任务精炼和轨迹精炼，是一种典型的**迭代改进** 过程。它通过检测和修正错误（幻觉、噪声）来提升数据质量，进而提升智能体能力，这与 `Self-Refine` 和 `Self-Correction` 的概念高度契合。虽然这种演化发生在训练数据层面而非智能体运行时，但它是一种使智能体能力得以“演化”和“适应”新环境的机制，属于研究范畴。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐问题。 - 论文虽然处理Web页面（可能包含视觉元素），但其核心贡献并非视觉模型或多模态理解，而是智能体的行为规划和执行框架。因此，不触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文关注的是智能体在复杂环境中的多步执行（轨迹），并通过精炼来提升其规划的可靠性，这属于“保留”的范畴，而非提升LLM本身的基础推理能力。 - **自我演化的应用**: 论文的核心正是提出一种新的“精炼”机制来使智能体“适应”新环境，这可以被理解为一种广义上的演化。即使它被应用在“Web”这个特定领域，根据筛选规则，也应因其核心是提出演化机制而被保留。 **最终决策:** 综合以上分析，该论文的核心贡献是提出了一种通过高质量合成数据来**改进和适配LLM智能体**的新框架 `SynthAgent`。其“双重精炼”机制与“自我演化”和“迭代改进”的研究焦点高度相关。因此，这篇论文精准地符合“LLM智能体及其演化”的研究课题，应被筛选为 **True**。"
    },
    {
        "index": "#130",
        "title": "ScRPO: From Errors to Insights",
        "link": "/arxiv/2511.06065",
        "arxiv_id": "2511.06065",
        "authors": "Lianrui Li, Dakuan Lu, Jiawei Shao, Chi Zhang, Xuelong Li",
        "summary": "We propose Self-correction Relative Policy Optimization (ScRPO), a novel reinforcement learning framework designed to enhance large language models on challenging mathemati- cal problems by leveraging self-reflection and error correction. Our approach consists of two stages: (1) Trial-and-error learning stage: training the model with GRPO and collect- ing incorrect answers along with their cor- responding questions in an error pool; (2) Self-correction learning stage: guiding the model to reflect on why its previous an- swers were wrong. Extensive experiments across multiple math reasoning benchmarks, including AIME, AMC, Olympiad, MATH- 500, GSM8k, using Deepseek-Distill-Qwen- 1.5B and Deepseek-Distill-Qwen-7B. The ex- perimental results demonstrate that ScRPO consistently outperforms several post-training methods. These findings highlight ScRPO as a promising paradigm for enabling language models to self-improve on difficult tasks with limited external feedback, paving the way to- ward more reliable and capable AI systems.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-08",
        "category": "cs.CL",
        "crawl_time": "2025-11-12T11:00:04.073560",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非将LLM作为工具应用于数学领域，而是提出了一种名为ScRPO（Self-correction Relative Policy Optimization）的**全新强化学习框架**。这个框架的本质是赋予LLM一种**自我演化**的能力，即通过“自我反思”和“错误纠正”来迭代改进自身在复杂任务上的表现。这完全符合你筛选标准中“构建、改进或演化LLM智能体”的核心目标，特别是“自我演化”这一方向。它不是简单的应用，而是一种方法论上的创新。 2.  **第二步：正面指标——高度匹配** 论文摘要中明确包含了多个你的核心关注点： *   **演化机制**: `Self-correction` (自我纠正), `Self-reflection` (自我反思), `self-improve` (自我改进)。 *   **核心范式**: 论文提出的ScRPO框架本质上是一种实现`Self-Evolving`的`Agentic AI`范式。 这些正面指标强烈表明该论文与你的研究课题高度相关。 3.  **第三步：排除标准——未触发** 论文的主要贡献是提升模型的数学推理能力，而非研究`Safety`、`Alignment`或`Interpretability`。同时，论文也未涉及`Vision`或`Multimodality`。因此，它没有触及任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 这篇论文是“自我演化的应用”这一特殊情况的完美例证。虽然论文的实验是在数学领域进行的，但其**核心贡献是ScRPO这一“自我演化”机制本身**，而不是它在数学上的应用效果。根据你的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 因此，这篇论文应该被保留。此外，它也符合“推理/规划”的保留规则，因为它提出的是一个让智能体学会如何进行复杂多步推理的新框架，而非仅仅改进LLM的基础推理能力。 **最终决策**: 综合以上分析，该论文的核心贡献在于提出了一种新颖的、用于实现LLM自我反思和自我纠正的框架（ScRPO），这直接命中了你研究课题中的“自我演化”和“单智能体”能力方向。它不是简单的应用，也不是非智能体的基础能力提升，而是一种关于智能体如何学习和演化的方法论创新。因此，这篇论文完全符合你的筛选要求。"
    },
    {
        "index": "#4",
        "title": "Beyond Detection: Exploring Evidence-based Multi-Agent Debate for Misinformation Intervention and Persuasion",
        "link": "/arxiv/2511.07267",
        "arxiv_id": "2511.07267",
        "authors": "Chen Han, Yijia Ma, Jin Tan, Wenzhen Zheng, Xijin Tang",
        "summary": "Multi-agent debate (MAD) frameworks have emerged as promising approaches for misinformation detection by simulating adversarial reasoning. While prior work has focused on detection accuracy, it overlooks the importance of helping users understand the reasoning behind factual judgments and develop future resilience. The debate transcripts generated during MAD offer a rich but underutilized resource for transparent reasoning. In this study, we introduce ED2D, an evidence-based MAD framework that extends previous approach by incorporating factual evidence retrieval. More importantly, ED2D is designed not only as a detection framework but also as a persuasive multi-agent system aimed at correcting user beliefs and discouraging misinformation sharing. We compare the persuasive effects of ED2D-generated debunking transcripts with those authored by human experts. Results demonstrate that ED2D outperforms existing baselines across three misinformation detection benchmarks. When ED2D generates correct predictions, its debunking transcripts exhibit persuasive effects comparable to those of human experts; However, when ED2D misclassifies, its accompanying explanations may inadvertently reinforce users'misconceptions, even when presented alongside accurate human explanations. Our findings highlight both the promise and the potential risks of deploying MAD systems for misinformation intervention. We further develop a public community website to help users explore ED2D, fostering transparency, critical thinking, and collaborative fact-checking.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-10",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.172128",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。以下是我的详细判断过程： 1.  **第一步：核心判断——保留** - **核心贡献**: 论文的核心贡献是提出了一个名为 **ED2D 的新框架**，这是一个“基于证据的多智能体辩论框架”。这完全符合“构建、改进或演化 LLM 智能体”的核心目标。 - **非应用型论文**: 尽管论文的应用领域是“错误信息干预”，但其重点并非简单地将现有智能体用作工具，而是**提出并改进了一个新的多智能体系统（MAS）方法论**。论文详细阐述了如何通过“引入事实证据检索”来扩展和改进之前的多智能体辩论框架。这属于对智能体能力的构建和改进，而非单纯的应用。 - **非非Agentic推理**: 论文的研究对象是“多智能体辩论”，这是一个典型的Agentic AI范式，涉及智能体间的交互和推理，而非提升LLM本身的基础推理能力。 2.  **第二步：正面指标——高度匹配** - **核心范式**: 论文明确涉及 `Multi-Agent Systems (MAS)`。 - **智能体能力**: 论文通过“incorporating factual evidence retrieval”引入了 `Tool Use / Tool Augmentation` 能力，这是对智能体能力的关键改进。 - **多智能体**: 论文的核心是 `Multi-Agent Debate`，这直接对应了 `Collaboration`（协作）、`Communication`（通信）和 `Negotiation`（博弈/辩论）等多智能体交互模式。 3.  **第三步：排除标准——未触发** - **安全与对齐**: 论文虽然提到了系统误判时可能带来的风险（“inadvertently reinforce users' misconceptions”），但这只是对所构建系统行为的**分析和发现**，而非论文的主要贡献。论文的核心是构建和评估这个多智能体框架本身，而不是研究如何使其更安全、可解释或对齐。因此，它不属于安全与对齐的研究范畴。 - **多模态与视觉**: 论文未涉及相关内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文研究的“多智能体辩论”本身就是一种复杂的多步推理和规划过程。智能体通过辩论来形成最终判断，这完全符合“保留”关于智能体如何进行规划或在复杂任务中进行多步推理的论文的标准。 **总结**: 该论文的核心是提出并改进了一个**多智能体系统（ED2D框架）**，为其增加了**工具使用（证据检索）**的能力，并研究了其在特定任务中的表现。这精准地命中了您研究范围中的“多智能体”方向，并涉及了“单智能体”能力中的“工具使用”。因此，这篇论文是您研究课题下的高质量前沿文献，应被保留。"
    },
    {
        "index": "#5",
        "title": "AgenticSciML: Collaborative Multi-Agent Systems for Emergent Discovery in Scientific Machine Learning",
        "link": "/arxiv/2511.07262",
        "arxiv_id": "2511.07262",
        "authors": "Qile Jiang, George Karniadakis",
        "summary": "Scientific Machine Learning (SciML) integrates data-driven inference with physical modeling to solve complex problems in science and engineering. However, the design of SciML architectures, loss formulations, and training strategies remains an expert-driven research process, requiring extensive experimentation and problem-specific insights. Here we introduce AgenticSciML, a collaborative multi-agent system in which over 10 specialized AI agents collaborate to propose, critique, and refine SciML solutions through structured reasoning and iterative evolution. The framework integrates structured debate, retrieval-augmented method memory, and ensemble-guided evolutionary search, enabling the agents to generate and assess new hypotheses about architectures and optimization procedures. Across physics-informed learning and operator learning tasks, the framework discovers solution methods that outperform single-agent and human-designed baselines by up to four orders of magnitude in error reduction. The agents produce novel strategies -- including adaptive mixture-of-expert architectures, decomposition-based PINNs, and physics-informed operator learning models -- that do not appear explicitly in the curated knowledge base. These results show that collaborative reasoning among AI agents can yield emergent methodological innovation, suggesting a path toward scalable, transparent, and autonomous discovery in scientific computing.",
        "subjects": "Artificial Intelligence, Computational Engineering, Finance, and Science, Machine Learning",
        "date": "2025-11-10",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.172697",
        "filter_reason": "这篇论文完全符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具去解决科学机器学习（SciML）问题，而是**构建了一个全新的、名为 AgenticSciML 的协作多智能体系统框架**。其核心贡献在于这个多智能体系统的设计、协作机制和演化能力，而非其在SciML领域的应用结果。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `Collaborative Multi-Agent Systems` (协作多智能体系统)。 - **多智能体**: `Collaboration` (协作), `Communication` (通过结构化辩论体现)。 - **自我演化**: `Iterative Evolution` (迭代演化), `Self-Refine` (批判和完善), `Generational Evolution` (通过集成引导的演化搜索体现)。 - **智能体能力**: `Planning` (提出和评估新假设), `Memory` (检索增强的方法记忆)。 3.  **第三步：排除标准** - 论文不涉及安全、对齐、多模态等排除领域。其核心是方法论创新，而非基础设施或应用部署。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是本案例的关键。虽然论文的应用领域是SciML，但其核心贡献是提出了一种**新的“自我演化”和“多智能体协作”机制**。摘要明确指出，智能体通过协作推理产生了“涌现的方法论创新”，并发现了知识库中不存在的“新颖策略”。这完全符合筛选标准第四步的例外情况：**核心是提出新的自我演化机制，即使应用在特定领域，也应保留**。论文的重点是“智能体如何演化”，而不是“如何用智能体做SciML”。 **最终决策:** 该论文的核心贡献在于构建了一个能够通过**协作、辩论和迭代演化来自主发现新方法论**的多智能体系统。这直接命中了研究课题的“多智能体”和“自我演化”两个核心方向。尽管它以SciML为试验场，但其研究价值在于智能体框架本身，展示了智能体如何进行复杂的协作和自我完善，是关于Agentic AI及其演化的前沿研究。因此，这篇论文高度相关，必须保留。"
    },
    {
        "index": "#22",
        "title": "MathSE: Improving Multimodal Mathematical Reasoning via Self-Evolving Iterative Reflection and Reward-Guided Fine-Tuning",
        "link": "/arxiv/2511.06805",
        "arxiv_id": "2511.06805",
        "authors": "Jinhao Chen, Zhen Yang, Jianxin Shi, Tianyu Wo, Jie Tang",
        "summary": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in vision-language answering tasks. Despite their strengths, these models often encounter challenges in achieving complex reasoning tasks such as mathematical problem-solving. Previous works have focused on fine-tuning on specialized mathematical datasets. However, these datasets are typically distilled directly from teacher models, which capture only static reasoning patterns and leaving substantial gaps compared to student models. This reliance on fixed teacher-derived datasets not only restricts the model's ability to adapt to novel or more intricate questions that extend beyond the confines of the training data, but also lacks the iterative depth needed for robust generalization. To overcome these limitations, we propose \\textbf{\\method}, a \\textbf{Math}ematical \\textbf{S}elf-\\textbf{E}volving framework for MLLMs. In contrast to traditional one-shot fine-tuning paradigms, \\method iteratively refines the model through cycles of inference, reflection, and reward-based feedback. Specifically, we leverage iterative fine-tuning by incorporating correct reasoning paths derived from previous-stage inference and integrating reflections from a specialized Outcome Reward Model (ORM). To verify the effectiveness of \\method, we evaluate it on a suite of challenging benchmarks, demonstrating significant performance gains over backbone models. Notably, our experimental results on MathVL-test surpass the leading open-source multimodal mathematical reasoning model QVQ. Our code and models are available at \\texttt{https://zheny2751\\allowbreak-dotcom.github.io/\\allowbreak MathSE.github.io/}.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-11-10",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.191303",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出一个名为 **MathSE 的“自我演化框架”**。它不是简单地将现有模型应用于数学问题，而是构建了一个全新的方法论，该方法论包含“推理、反思和基于奖励的反馈”的迭代循环。这完全符合“构建、改进或演化 LLM 智能体”的核心目标，特别是“自我演化”方向。因此，它不属于“非演化型应用”或“非Agentic的推理”的排除范畴。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中明确包含了多个核心关注点： *   **核心范式**: `Self-Evolving` (标题和摘要中明确提及)。 *   **智能体能力**: `Self-Reflection` (摘要中提到 \"integrating reflections from a specialized Outcome Reward Model (ORM)\")。 *   **演化机制**: `Self-Improvement` / `Iterative Improvement` (摘要中描述 \"iteratively refines the model through cycles of inference, reflection, and reward-based feedback\")。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性。 *   **多模态与视觉**: 虽然论文涉及多模态大语言模型（MLLMs），但其核心并非提出新的视觉或多模态融合技术。在这里，视觉（数学问题中的图表）是智能体需要理解和处理的**环境/任务的一部分**，而研究的核心是**智能体如何通过自我演化来更好地解决这个任务**。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外情况。 4.  **第四步：处理特殊和模糊情况 (完美契合)** *   **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的典型范例。它的核心贡献是提出一种**新的“自我演化”机制**，并将其应用在“数学推理”这个特定领域。根据您的规则，这种情况应该**保留**。 **总结**: 该论文的本质是提出了一种新颖的、基于迭代反思和奖励反馈的**自我演化框架**，用于提升LLM智能体在复杂任务上的表现。其核心贡献直接对齐您的研究焦点中的“自我演化”方向，并且包含了“自我反思”等关键智能体能力。尽管它应用在数学领域并涉及多模态，但其方法论本身是关于Agentic AI的演化，而非特定领域的应用或视觉技术本身。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#53",
        "title": "Klear-AgentForge: Forging Agentic Intelligence through Posttraining Scaling",
        "link": "/arxiv/2511.05951",
        "arxiv_id": "2511.05951",
        "authors": "Qi Wang, Hongzhi Zhang, Jia Fu, Kai Fu, Yahui Liu, Tinghai Zhang, Chenxi Sun, Gangwei Jiang, Jingyi Tang, Xingguang Ji, Yang Yue, Jingyuan Zhang, Fuzheng Zhang, Kun Gai, Guorui Zhou",
        "summary": "Despite the proliferation of powerful agentic models, the lack of critical post-training details hinders the development of strong counterparts in the open-source community. In this study, we present a comprehensive and fully open-source pipeline for training a high-performance agentic model for interacting with external tools and environments, named Klear-Qwen3-AgentForge, starting from the Qwen3-8B base model. We design effective supervised fine-tuning (SFT) with synthetic data followed by multi-turn reinforcement learning (RL) to unlock the potential for multiple diverse agentic tasks. We perform exclusive experiments on various agentic benchmarks in both tool use and coding domains. Klear-Qwen3-AgentForge-8B achieves state-of-the-art performance among LLMs of similar size and remains competitive with significantly larger models.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-08",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.222578",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个**构建和改进LLM智能体的方法论**。其核心贡献是“一个全面的、完全开源的训练流程”，用于从基础模型出发，训练出一个高性能的智能体模型。这直接命中了您“构建、改进或演化LLM智能体”的核心目标。它不是将智能体作为工具去解决某个特定领域的问题，而是研究如何“锻造”智能体本身。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文标题和摘要明确提到了 `Agentic Intelligence` 和 `Agentic Model`。 - **智能体能力**: 论文的核心是训练智能体“与外部工具和环境交互”，这直接对应了 `Tool Use / Tool Augmentation`。其训练方法（SFT + RL）旨在解锁“多种多样的智能体任务”的潜力，这通常涉及复杂的规划和多步推理。 - **演化机制**: 论文提出的训练流程（SFT后接多轮RL）本身就是一种**改进和迭代**智能体能力的机制。虽然这更偏向于训练时的演化而非运行时的自我演化，但它完全符合“通过……进行自我完善和迭代”的广义精神，属于对智能体能力的“演化”和“增强”。 3.  **第三步：排除标准** - 论文完全没有涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐主题。 - 论文也未涉及 `Vision`, `MLLMs` 等多模态内容，其焦点纯粹在智能体的训练和能力上。 - 因此，论文未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文关注的是智能体如何通过训练获得与工具交互、完成复杂任务的能力，这属于**智能体框架下的推理与规划**，而非提升LLM本身的基础数学或逻辑能力。因此，符合保留条件。 - **自我演化的应用**: 此处不适用，因为论文的核心贡献就是演化机制本身，而非其在特定领域的应用。 **最终决策**: 这篇论文的核心贡献是提出一个用于**构建和改进**LLM智能体的开源训练流程，重点在于提升其**工具使用**能力。这精准地契合了您研究范围中的“单智能体”方向，特别是“构建、改进”这一核心目标。其训练方法也体现了“演化”的思想。因此，这篇论文是高度相关且有价值的前沿研究，应被筛选出来。"
    },
    {
        "index": "#39",
        "title": "Synthetic Data-Driven Prompt Tuning for Financial QA over Tables and Documents",
        "link": "/arxiv/2511.06292",
        "arxiv_id": "2511.06292",
        "authors": "Yaoning Yu, Kaimin Chang, Ye Yu, Kai Wei, Haojing Luo, Haohan Wang",
        "summary": "Financial documents like earning reports or balance sheets often involve long tables and multi-page reports. Large language models have become a new tool to help numerical reasoning and understanding these documents. However, prompt quality can have a major effect on how well LLMs perform these financial reasoning tasks. Most current methods tune prompts on fixed datasets of financial text or tabular data, which limits their ability to adapt to new question types or document structures, or they involve costly and manually labeled/curated dataset to help build the prompts. We introduce a self-improving prompt framework driven by data-augmented optimization. In this closed-loop process, we generate synthetic financial tables and document excerpts, verify their correctness and robustness, and then update the prompt based on the results. Specifically, our framework combines a synthetic data generator with verifiers and a prompt optimizer, where the generator produces new examples that exposes weaknesses in the current prompt, the verifiers check the validity and robustness of the produced examples, and the optimizer incrementally refines the prompt in response. By iterating these steps in a feedback cycle, our method steadily improves prompt accuracy on financial reasoning tasks without needing external labels. Evaluation on DocMath-Eval benchmark demonstrates that our system achieves higher performance in both accuracy and robustness than standard prompt methods, underscoring the value of incorporating synthetic data generation into prompt learning for financial applications.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-09",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.210396",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献并非解决金融领域的具体问题，而是提出了一种**“自我改进的提示框架”**。它构建了一个包含“合成数据生成器”、“验证器”和“提示优化器”的闭环系统，通过迭代来优化提示本身。 - **判断**: 这不属于“非演化型应用”。虽然论文的应用场景是金融QA，但其核心创新点在于那个能够自我完善、迭代的**方法论和框架**。这个框架的本质是让系统（在这里是提示）通过反馈循环进行自我演化，这与您研究目标中的“自我演化”高度契合。因此，应进入下一步。 2.  **第二步：正面指标** - 论文摘要中明确包含了多个核心关注点： - **自我演化**: `self-improving prompt framework`, `closed-loop process`, `steadily improves prompt accuracy`。 - **演化机制**: `Self-Improvement`, `Self-Refine` (incrementally refines the prompt), `Iterative Improvement` (iterating these steps)。 - 这些指标强烈表明，论文的研究焦点在于如何构建一个能够自我演化的系统，尽管这个系统目前作用于“提示”这一层面，而非一个完整的智能体。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。它的目标是提升性能和鲁棒性，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是判断此论文的关键。根据您设定的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 这篇论文正是如此。它的核心是那个**自我演化的机制**，金融QA只是这个机制得以验证和展示的试验场。因此，根据此条特殊规则，该论文应被保留。 - **推理/规划**: 论文提到了“financial reasoning tasks”，但其方法并非研究智能体如何进行多步规划，而是通过优化提示来提升LLM在特定任务上的推理表现。这更偏向于模型能力的微调，而非智能体的规划框架。但这并不影响其因“自我演化”机制而被保留。 5.  **第五步：最终决策** - 综合以上分析，尽管这篇论文没有描述一个具备规划、工具使用等能力的完整LLM智能体，但其核心贡献在于提出了一种新颖的、具有普适性的**自我演化框架**。这个框架通过生成-验证-优化的闭环，实现了系统（提示）的自主迭代和完善，完全符合您研究课题中“自我演化”的核心方向。因此，这篇论文与您的研究范围高度相关，应被筛选出来。"
    },
    {
        "index": "#44",
        "title": "Dataforge: A Data Agent Platform for Autonomous Data Engineering",
        "link": "/arxiv/2511.06185",
        "arxiv_id": "2511.06185",
        "authors": "Xinyuan Wang, Yanjie Fu",
        "summary": "The growing demand for AI applications in fields such as materials discovery, molecular modeling, and climate science has made data preparation an important but labor-intensive step. Raw data from diverse sources must be cleaned, normalized, and transformed to become AI-ready, while effective feature transformation and selection are essential for efficient training and inference. To address the challenges of scalability and expertise dependence, we present Data Agent, a fully autonomous system specialized for tabular data. Leveraging large language model (LLM) reasoning and grounded validation, Data Agent automatically performs data cleaning, hierarchical routing, and feature-level optimization through dual feedback loops. It embodies three core principles: automatic, safe, and non-expert friendly, which ensure end-to-end reliability without human supervision. This demo showcases the first practical realization of an autonomous Data Agent, illustrating how raw data can be transformed \"From Data to Better Data.\"",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-09",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.212961",
        "filter_reason": "这篇论文符合我的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是构建了一个名为 \"Data Agent\" 的**完全自主的系统**。这并非简单地将一个已有的LLM或智能体框架作为工具应用到数据工程领域，而是**提出并实现了一个专门用于数据工程任务的LLM智能体新框架**。其核心创新点在于智能体的自主性、工作流程（双重反馈循环）和验证机制，完全符合“构建、改进LLM智能体”的核心目标。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** 论文摘要中包含了多个核心关注点： *   **核心范式**: 明确提出了 `Data Agent`，这是一个 `LLM-based Agent`。 *   **智能体能力**: 描述了智能体通过 `LLM reasoning` 执行任务，并通过 `dual feedback loops`（双重反馈循环）进行优化。这直接对应了 `Self-Correction`、`Self-Reflection` 和 `Iterative Improvement` 的能力。数据清洗、转换等操作可以视为智能体的 `Tool Use`。 *   **演化机制**: “双重反馈循环”和“特征级优化”是典型的**自我演化**机制，智能体通过环境反馈（验证结果）来迭代和改进自身的行为策略。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 论文提到了 \"safe\" 原则。但在数据工程的上下文中，\"safe\" 指的是数据处理过程的可靠性、稳定性和不破坏数据完整性，而非AI安全领域的 `Safety`、`Security` 或 `Alignment`。因此，这不构成排除理由。 *   **多模态与视觉**: 论文专注于表格数据，不涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。尽管它应用在数据工程这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制（双重反馈循环）**，并构建了一个自主智能体来实现它。因此，根据规则，应当保留。 **最终决策**: 该论文的核心是构建一个具备自主规划、工具使用和通过反馈进行自我纠正/迭代能力的LLM智能体。它直接贡献于“单智能体”和“自我演化”两个研究方向。虽然其应用场景是数据工程，但论文的创新点在于智能体框架本身，而非应用领域的特定问题解决。因此，这篇论文与我的研究课题高度相关，应当保留。"
    },
    {
        "index": "#54",
        "title": "Self-Abstraction from Grounded Experience for Plan-Guided Policy Refinement",
        "link": "/arxiv/2511.05931",
        "arxiv_id": "2511.05931",
        "authors": "Hiroaki Hayashi, Bo Pang, Wenting Zhao, Ye Liu, Akash Gokul, Srijan Bansal, Caiming Xiong, Semih Yavuz, Yingbo Zhou",
        "summary": "Large language model (LLM) based agents are increasingly used to tackle software engineering tasks that require multi-step reasoning and code modification, demonstrating promising yet limited performance. However, most existing LLM agents typically operate within static execution frameworks, lacking a principled mechanism to learn and self-improve from their own experience and past rollouts. As a result, their performance remains bounded by the initial framework design and the underlying LLM's capabilities. We propose Self-Abstraction from Grounded Experience (SAGE), a framework that enables agents to learn from their own task executions and refine their behavior through self-abstraction. After an initial rollout, the agent induces a concise plan abstraction from its grounded experience, distilling key steps, dependencies, and constraints. This learned abstraction is then fed back as contextual guidance, refining the agent's policy and supporting more structured, informed subsequent executions. Empirically, SAGE delivers consistent performance gains across diverse LLM backbones and agent architectures. Notably, it yields a 7.2% relative performance improvement over the strong Mini-SWE-Agent baseline when paired with the GPT-5 (high) backbone. SAGE further achieves strong overall performance on SWE-Bench Verified benchmark, reaching 73.2% and 74% Pass@1 resolve rates with the Mini-SWE-Agent and OpenHands CodeAct agent framework, respectively.",
        "subjects": "Artificial Intelligence, Software Engineering",
        "date": "2025-11-08",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.223138",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出一个名为 SAGE (Self-Abstraction from Grounded Experience) 的新**框架**。这个框架的本质是让LLM智能体能够从自身的执行经验中学习，并通过“自我抽象”的机制来**精炼和改进其行为策略**。这完全符合“构建、改进或演化 LLM智能体”的核心目标，特别是属于“自我演化”这一方向。它不是一个简单的应用，而是一个关于智能体如何自我学习和迭代的**方法论**。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量与你研究焦点相关的核心关键词： *   **核心范式**: `LLM-based agents` (明确提及), `Self-Evolving` (核心思想是自我改进)。 *   **智能体能力**: `Planning` (标题和摘要中的 \"Plan-Guided\", \"induces a concise plan abstraction\"), `Memory` (从 \"grounded experience\" 中学习), `Self-Correction` / `Self-Reflection` (通过 \"self-abstraction\" 实现), `Self-Improvement` (明确提及 \"learn and self-improve\", \"refine their behavior\")。 *   **演化机制**: `Self-Improvement`, `Iterative Improvement` (整个框架就是一个迭代改进的循环)。 3.  **第四步：处理特殊和模糊情况 (关键判断点)** 这篇论文的应用领域是软件工程，这看起来像是“非演化型应用”。但是，根据你设定的**核心规则**：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域...也应该保留。” *   **核心贡献是机制，不是应用**: SAGE框架是这篇论文的核心创新点。软件工程任务只是用来验证该框架有效性的**实验场**。论文强调SAGE在“diverse LLM backbones and agent architectures”上都有效，证明了其通用性，而非局限于软件工程领域。 *   **符合自我演化定义**: 论文明确指出现有智能体“lacking a principled mechanism to learn and self-improve from their own experience”，而SAGE正是为了解决这一问题而提出的。它通过从经验中抽象出计划来指导后续行动，这是一个典型的自我完善和迭代过程，完全符合“自我演化”的定义。 4.  **第三步：排除标准 (未触发)** 论文的主要贡献不涉及安全、对齐、可解释性，也未涉及多模态或视觉，因此没有触发任何排除标准。 **总结**: 该论文的核心是提出一种名为SAGE的、能够让LLM智能体从自身经验中学习并自我演化的通用框架。它直接命中了你的“自我演化”研究焦点，并涉及“单智能体”的规划与记忆能力。尽管其验证场景在软件工程领域，但其贡献的普适性框架本质使其完全符合你的筛选要求。"
    },
    {
        "index": "#62",
        "title": "SMAGDi: Socratic Multi Agent Interaction Graph Distillation for Efficient High Accuracy Reasoning",
        "link": "/arxiv/2511.05528",
        "arxiv_id": "2511.05528",
        "authors": "Aayush Aluru, Myra Malik, Samarth Patankar, Spencer Kim, Kevin Zhu, Sean O'Brien, Vasu Sharma",
        "summary": "Multi-agent systems (MAS) often achieve higher reasoning accuracy than single models, but their reliance on repeated debates across agents makes them computationally expensive. We introduce SMAGDi, a distillation framework that transfers the debate dynamics of a five-agent Llama-based MAS into a compact Socratic decomposer-solver student. SMAGDi represents debate traces as directed interaction graphs, where nodes encode intermediate reasoning steps with correctness labels and edges capture continuity and cross-agent influence. The student is trained with a composite objective combining language modeling, graph-based supervision, contrastive reasoning, and embedding alignment to preserve both fluency and structured reasoning. On StrategyQA and MMLU, SMAGDi compresses a 40B multi-agent system into a 6B student while retaining 88% of its accuracy, substantially outperforming prior distillation methods such as MAGDi, standard KD, and fine-tuned baselines. These results highlight that explicitly modeling interaction graphs and Socratic decomposition enable small models to inherit the accuracy benefits of multi-agent debate while remaining efficient enough for real-world deployment.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.232469",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** - **论文本质**: 该论文的核心贡献是提出一个名为 **SMAGDi** 的**新框架**。这个框架的目的不是将LLM智能体作为工具去解决某个外部领域的问题，而是为了**改进和优化LLM智能体系统本身**。它具体解决的是多智能体系统（MAS）计算成本高昂的问题，通过一种蒸馏技术，将复杂的多智能体辩论过程提炼成一个更小、更高效的单智能体模型。这完全符合“构建、改进或演化LLM智能体”的核心目标。 - **排除项核对**: 论文不属于非演化型应用、非Agentic的基础推理，也非基础设施研究。 2.  **第二步：正面指标 (高度匹配)** - **核心范式**: 论文明确聚焦于 **`Multi-Agent Systems (MAS)`**。 - **多智能体**: 论文的核心是研究多智能体间的 **`Communication`**（通过“debates”和“interaction graphs”体现）和 **`Collaboration`**（通过“cross-agent influence”体现）。它试图捕捉并转移这种多智能体交互的动态过程。 - **智能体能力**: 论文涉及智能体的 **`Reasoning`** 能力，特别是通过多智能体辩论实现的复杂推理。 3.  **第三步：排除标准 (未触发)** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等问题，因此没有触发任何排除标准。 4.  **第四步：特殊和模糊情况 (符合保留规则)** - **推理/规划**: 该论文的研究对象是**智能体系统的推理过程**（“debate dynamics”），而不是LLM本身的基础Token预测能力。它提出了一种新的Agentic框架（SMAGDi）来处理和优化这种推理过程，因此完全符合保留条件。 **最终决策**: 该论文的核心贡献在于提出了一种创新的方法论（SMAGDi框架），用于**改进多智能体系统**，使其在保持高推理准确率的同时大幅提升效率。这直接命中了您研究焦点中的“**多智能体**”方向，并且是对智能体系统本身的“**改进**”，而非简单的应用。因此，这篇论文是您研究课题下的高度相关前沿文献，应予以保留。"
    },
    {
        "index": "#63",
        "title": "Evidence-Bound Autonomous Research (EviBound): A Governance Framework for Eliminating False Claims",
        "link": "/arxiv/2511.05524",
        "arxiv_id": "2511.05524",
        "authors": "Ruiying Chen",
        "summary": "LLM-based autonomous research agents report false claims: tasks marked \"complete\" despite missing artifacts, contradictory metrics, or failed executions. EviBound is an evidence-bound execution framework that eliminates false claims through dual governance gates requiring machine-checkable evidence. Two complementary gates enforce evidence requirements. The pre-execution Approval Gate validates acceptance criteria schemas before code runs, catching structural violations proactively. The post-execution Verification Gate validates artifacts via MLflow API queries (with recursive path checking) and optionally validates metrics when specified by acceptance criteria. Claims propagate only when backed by a queryable run ID, required artifacts, and FINISHED status. Bounded, confidence-gated retries (typically 1-2 attempts) recover from transient failures without unbounded loops. The framework was evaluated on 8 benchmark tasks spanning infrastructure validation, ML capabilities, and governance stress tests. Baseline A (Prompt-Level Only) yields 100% hallucination (8/8 claimed, 0/8 verified). Baseline B (Verification-Only) reduces hallucination to 25% (2/8 fail verification). EviBound (Dual Gates) achieves 0% hallucination: 7/8 tasks verified and 1 task correctly blocked at the approval gate, all with only approximately 8.3% execution overhead. This package includes execution trajectories, MLflow run IDs for all verified tasks, and a 4-step verification protocol. Research integrity is an architectural property, achieved through governance gates rather than emergent from model scale.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.232920",
        "filter_reason": "这篇论文符合我的研究范围，其核心贡献在于构建和改进LLM智能体。我的判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心是提出一个名为\"EviBound\"的**执行框架**和**治理框架**，用于规范和改进\"LLM-based autonomous research agents\"的行为。这并非将现有智能体作为工具去解决一个外部领域问题（如生物、金融），而是直接针对智能体本身的架构和工作流程进行创新。其目标是解决智能体在自主执行任务时产生虚假声明这一根本性问题，因此属于对LLM智能体的**构建与改进**范畴。 2.  **第二步：正面指标——高度相关** 论文包含了多个我关注的核心范式和能力： *   **核心范式**: 论文明确研究 `LLM-based Agents`，并提出了一种新的 `Agentic AI` 框架。 *   **智能体能力**: *   `Tool Use`: 智能体通过MLflow API查询来验证产物，这是典型的工具使用。 *   `Self-Correction`: 框架中的\"Bounded, confidence-gated retries\"机制是一种明确的自我纠错能力，允许智能体从失败中恢复。 *   `Planning`: \"pre-execution Approval Gate\"在代码执行前验证标准，这属于智能体规划阶段的一部分，确保计划的合理性。 3.  **第三步：排除标准——不适用** 尽管论文标题和摘要中提到了\"Eliminating False Claims\"和\"Hallucination\"，但这并非其**主要贡献**。论文的核心不是提出一种新的幻觉检测算法或对齐理论，而是提出一种**架构性的解决方案**。正如摘要最后一句强调的：“Research integrity is an architectural property, achieved through governance gates rather than emergent from model scale.” 这表明，论文的重点在于**如何通过设计智能体的架构（治理门）来确保其输出的可靠性**，而不是研究幻觉本身。因此，它不属于“安全与对齐”的排除范畴。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: EviBound框架通过\"Approval Gate\"和\"Verification Gate\"对智能体的整个执行流程（从规划到验证）进行了结构化的约束和增强。这完全符合“保留”关于智能体如何进行规划和多步推理的论文的标准，因为它定义了一个新的Agentic推理和执行范式。 **结论**: 该论文的核心贡献是提出了一种新颖的、带有双重治理门的LLM智能体框架，以增强其自主执行任务的可靠性和自我修正能力。这直接命中了我研究目标中的“构建、改进或演化LLM智能体”，特别是单智能体方向。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#67",
        "title": "Using Vision Language Models as Closed-Loop Symbolic Planners for Robotic Applications: A Control-Theoretic Perspective",
        "link": "/arxiv/2511.07410",
        "arxiv_id": "2511.07410",
        "authors": "Hao Wang, Sathwik Karnik, Bea Lim, Somil Bansal",
        "summary": "Large Language Models (LLMs) and Vision Language Models (VLMs) have been widely used for embodied symbolic planning. Yet, how to effectively use these models for closed-loop symbolic planning remains largely unexplored. Because they operate as black boxes, LLMs and VLMs can produce unpredictable or costly errors, making their use in high-level robotic planning especially challenging. In this work, we investigate how to use VLMs as closed-loop symbolic planners for robotic applications from a control-theoretic perspective. Concretely, we study how the control horizon and warm-starting impact the performance of VLM symbolic planners. We design and conduct controlled experiments to gain insights that are broadly applicable to utilizing VLMs as closed-loop symbolic planners, and we discuss recommendations that can help improve the performance of VLM symbolic planners.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-11-10",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.240428",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将VLM应用于机器人领域，而是提出了一种**改进VLM作为闭环符号规划器性能的方法论**。它从控制理论的视角，研究了“控制时域”和“热启动”等具体机制如何影响规划效果。这属于对智能体核心能力（规划）的**改进**，而不仅仅是将其作为工具应用。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点。标题和摘要中反复出现 `Symbolic Planners`（符号规划器），这与我的研究焦点中的 `Planning` 高度相关。整个研究围绕如何让VLM在机器人任务中更好地进行规划，这完全属于 `Agentic AI` 和 `LLM-based Agents` 的范畴。 3.  **第三步：排除标准** - **安全与对齐**：论文虽然提到了VLM可能产生“不可预测或代价高昂的错误”，但其研究目标是提升规划器的性能和可靠性，而非探讨安全、对齐或可解释性。因此，不触及此排除标准。 - **多模态与视觉**：论文标题和内容确实涉及 `Vision Language Models (VLMs)`。但根据筛选规则中的例外情况，这里的VLM并非研究的核心对象（比如改进其视觉理解能力），而是被用作**智能体进行规划和决策的核心组件**。论文的焦点是“规划”这一智能体行为，而不是VLM本身。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**：这篇论文是“推理/规划”保留规则的典型范例。它不是在提升LLM的基础数学或逻辑能力，而是在研究**智能体如何在一个复杂的、需要反馈的闭环环境中进行多步规划**。其提出的“控制时域”和“热启动”等概念，是对智能体规划过程的一种新框架或新机制的探索，与ReAct、ToT等在精神上是一致的。 **最终决策**： 综合以上分析，该论文的核心贡献在于**提出并验证了一种改进LLM智能体规划能力的新方法**。它虽然以机器人为应用场景，但其研究焦点是普适性的智能体规划机制，而非特定领域的解决方案。这完全符合我“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标，特别是与“单智能体”方向下的“规划”子方向高度契合。因此，最终判断为 **True**。"
    },
    {
        "index": "#79",
        "title": "Grounding Computer Use Agents on Human Demonstrations",
        "link": "/arxiv/2511.07332",
        "arxiv_id": "2511.07332",
        "authors": "Aarash Feizi, Shravan Nayak, Xiangru Jian, Kevin Qinghong Lin, Kaixin Li, Rabiul Awal, Xing Han Lù, Johan Obando-Ceron, Juan A. Rodriguez, Nicolas Chapados, David Vazquez, Adriana Romero-Soriano, Reihaneh Rabbany, Perouz Taslakian, Christopher Pal, Spandana Gella, Sai Rajeswar",
        "summary": "Building reliable computer-use agents requires grounding: accurately connecting natural language instructions to the correct on-screen elements. While large datasets exist for web and mobile interactions, high-quality resources for desktop environments are limited. To address this gap, we introduce GroundCUA, a large-scale desktop grounding dataset built from expert human demonstrations. It covers 87 applications across 12 categories and includes 56K screenshots, with every on-screen element carefully annotated for a total of over 3.56M human-verified annotations. From these demonstrations, we generate diverse instructions that capture a wide range of real-world tasks, providing high-quality data for model training. Using GroundCUA, we develop the GroundNext family of models that map instructions to their target UI elements. At both 3B and 7B scales, GroundNext achieves state-of-the-art results across five benchmarks using supervised fine-tuning, while requiring less than one-tenth the training data of prior work. Reinforcement learning post-training further improves performance, and when evaluated in an agentic setting on the OSWorld benchmark using o3 as planner, GroundNext attains comparable or superior results to models trained with substantially more data,. These results demonstrate the critical role of high-quality, expert-driven datasets in advancing general-purpose computer-use agents.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-10",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.252134",
        "filter_reason": "这篇论文符合我的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献并非将一个已有的智能体框架应用到特定领域，而是**提出了一种构建和改进LLM智能体的新方法论**。这个方法论包含两个部分：一个大规模、高质量的数据集（GroundCUA）和一个基于该数据集训练的模型（GroundNext）。 - 其核心目标是解决计算机使用智能体中的一个基础性挑战：**“接地”**，即将自然语言指令准确映射到屏幕上的UI元素。这直接关系到智能体感知和操作环境的能力，是构建可靠智能体的关键环节，属于“构建或改进LLM智能体”的范畴。 - 因此，它不属于“非演化型应用”的排除范畴，因为它是在为智能体提供核心能力，而不是简单地使用智能体。 2.  **第二步：正面指标——高度相关** - 论文明确提到了 `Agentic AI` 和 `Computer-use Agents`，并最终在 `agentic setting` 下进行评估。 - 论文的核心贡献——解决“接地”问题——是**智能体工具使用** 的一个关键前置步骤。一个无法准确识别和定位UI元素的智能体，无法有效地使用计算机作为工具。因此，这项工作直接服务于提升智能体的工具使用能力。 - 论文中提到使用 `o3 as planner`，这表明其贡献（GroundNext模型）是作为智能体“感知-规划-行动”循环中的一个核心组件，与智能体的规划能力紧密集成。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不是关于安全、对齐或可解释性。 - 虽然论文处理了截图（视觉数据），但这完全符合排除标准中的例外情况：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉是智能体感知桌面环境的工具，而研究的核心是**如何让智能体更好地“接地”**，即如何将语言指令与这个视觉环境中的元素对应起来。视觉是手段，不是目的。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文本身没有提出新的规划算法，但它提出的模型是规划器能够有效执行的前提。它解决了智能体在执行规划前的感知和定位问题，是整个Agentic框架中不可或缺的一环。因此，它属于“保留”范畴。 **最终决策**: 这篇论文的核心贡献在于通过构建一个高质量的数据集和一个专用模型，显著提升了计算机使用智能体的基础“接地”能力。这直接服务于“构建、改进LLM智能体”的核心目标，特别是单智能体方向中的“工具使用”能力。它不是简单的应用，而是对智能体核心组件的深度优化和方法论创新，因此完全符合我的研究范围。"
    },
    {
        "index": "#140",
        "title": "AgentSUMO: An Agentic Framework for Interactive Simulation Scenario Generation in SUMO via Large Language Models",
        "link": "/arxiv/2511.06804",
        "arxiv_id": "2511.06804",
        "authors": "Minwoo Jeong, Jeeyun Chang, Yoonjin Yoon",
        "summary": "The growing complexity of urban mobility systems has made traffic simulation indispensable for evidence-based transportation planning and policy evaluation. However, despite the analytical capabilities of platforms such as the Simulation of Urban MObility (SUMO), their application remains largely confined to domain experts. Developing realistic simulation scenarios requires expertise in network construction, origin-destination modeling, and parameter configuration for policy experimentation, creating substantial barriers for non-expert users such as policymakers, urban planners, and city officials. Moreover, the requests expressed by these users are often incomplete and abstract-typically articulated as high-level objectives, which are not well aligned with the imperative, sequential workflows employed in existing language-model-based simulation frameworks. To address these challenges, this study proposes AgentSUMO, an agentic framework for interactive simulation scenario generation via large language models. AgentSUMO departs from imperative, command-driven execution by introducing an adaptive reasoning layer that interprets user intents, assesses task complexity, infers missing parameters, and formulates executable simulation plans. The framework is structured around two complementary components, the Interactive Planning Protocol, which governs reasoning and user interaction, and the Model Context Protocol, which manages standardized communication and orchestration among simulation tools. Through this design, AgentSUMO converts abstract policy objectives into executable simulation scenarios. Experiments on urban networks in Seoul and Manhattan demonstrate that the agentic workflow achieves substantial improvements in traffic flow metrics while maintaining accessibility for non-expert users, successfully bridging the gap between policy goals and executable simulation workflows.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Computers and Society",
        "date": "2025-11-10",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.339134",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程和核心依据如下:** 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出了一个名为 \"AgentSUMO\" 的 **智能体框架**。它不是简单地将LLM作为工具应用于交通领域，而是构建了一个具备推理、规划和工具使用能力的LLM智能体，来解决特定问题（将抽象政策目标转化为可执行的模拟场景）。 - **结论**: 论文的核心是关于 **构建LLM智能体的方法论和新框架**，完全符合“保留”标准。它不属于“非演化型应用”，因为其创新点在于智能体框架本身，而非应用结果。 2.  **第二步：正面指标** - 论文摘要中包含了多个核心关注点的关键词，表明其高度相关： - **核心范式**: 明确提出了 `Agentic Framework`。 - **智能体能力**: 详细描述了智能体的 `Planning` 能力（\"formulates executable simulation plans\", \"Interactive Planning Protocol\"）和 `Tool Use / Tool Augmentation` 能力（\"orchestration among simulation tools\", \"Model Context Protocol\"）。其“自适应推理层”也体现了智能体的复杂推理过程。 - **结论**: 论文在“单智能体”方向上具有强烈的正面指标，特别是规划和工具使用这两个核心能力。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或幻觉等问题。 - 论文也未将多模态或视觉作为研究核心，SUMO模拟器是智能体交互的工具，而非研究对象本身。 - **结论**: 未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确聚焦于智能体如何进行规划。它描述了一个从理解高层意图到制定可执行计划的完整工作流，这正是智能体级别的规划和多步推理，符合“保留”条件。它不是在提升LLM本身的基础数学或逻辑能力。 5.  **第五步：最终决策** - **综合分析**: 该论文的核心贡献是构建了一个新颖的LLM智能体框架，该框架展示了高级的规划、推理和工具编排能力。虽然其应用场景是交通模拟，但其研究价值在于提出了一种通用的、能够处理复杂、抽象用户请求的智能体构建方法。这与研究课题“LLM智能体及其演化”中的“构建、改进LLM智能体”的核心目标高度契合，特别是“单智能体”方向。 因此，这篇论文是符合筛选要求的高质量前沿研究。"
    },
    {
        "index": "#142",
        "title": "Recursive Dynamics in Fast-Weights Homeostatic Reentry Networks: Toward Reflective Intelligence",
        "link": "/arxiv/2511.06798",
        "arxiv_id": "2511.06798",
        "authors": "B. G. Chae",
        "summary": "This study introduces the Fast-Weights Homeostatic Reentry Layer (FH-RL), a neural mechanism that integrates fast-weight associative memory, homeostatic regularization, and learned reentrant feedback to approximate self-referential computation in neural networks. Unlike standard transformer architectures that operate in a purely feedforward manner during inference, FH-RL enables internal recurrence without external looping, allowing prior latent states to be dynamically re-entered into the ongoing computation stream. We conduct controlled experiments sweeping the reentry gain $\\gamma$ and evaluate emergent internal dynamics using three novel metrics: the Information Reentry Ratio (IRR), Eigen-Spectrum Recursion Index (ESRI), and Representational Drift Periodicity (RDP). Results show that reentry quantity increases proportionally with~$\\gamma$, while the learned feedback matrix $W_r$ remains bounded and becomes more structured at moderate gains. Critically, a stable reflective band emerges around $\\gamma \\approx 0.10-0.20$, where internal feedback is maximally expressive yet spectrally stable: IRR rises smoothly, ESRI remains near zero, and RDP exhibits consistent low-frequency cycles. These findings provide quantitative evidence that reflective, thought-like internal processing can arise from a principled balance between feedback amplification and homeostatic regulation, linking modern fast-weight architectures to theories of cortical reentry and recursive cognition.",
        "subjects": "Machine Learning, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-11-10",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.340223",
        "filter_reason": "这篇论文符合您的研究范围，其核心贡献在于为LLM智能体的“自我演化”能力提供了基础性的神经机制架构。我的判断过程如下： **第一步：核心判断——保留** - 论文的核心是提出一种名为“快速权重稳态再入层（FH-RL）”的**新型神经机制**。这个机制的目标是让神经网络能够进行“自我指涉计算”和“反思性、类思维的内部处理”。 - 这完全符合“自我演化”方向的核心要求。它不是将现有智能体作为工具去应用，而是从最底层的架构层面，探索如何构建一个能够进行**自我反思**的系统。自我反思是自我完善和迭代（即自我演化）的关键前提。 - 因此，这篇论文的本质是关于构建和改进LLM智能体的基础能力（反思），应予以保留。 **第二步：正面指标——高度相关** - 论文明确包含了多个核心关注点： - **自我演化**: 标题和摘要中反复出现的“Reflective Intelligence”（反思性智能）、“self-referential computation”（自我指涉计算）直接指向了自我演化的核心。 - **记忆**: 论文的核心机制之一是“fast-weight associative memory”（快速权重联想记忆）和“prior latent states to be dynamically re-entered”（动态重新进入先前的潜在状态），这是一种高级的内部记忆形式。 - **自我反思**: “Reflective Intelligence”是论文的核心主题，其提出的机制旨在实现这一能力。 **第三步：排除标准——未触发** - 论文的主要贡献不是关于安全、对齐、可解释性，也未涉及多模态或视觉。因此，没有触发任何排除标准。 **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文的研究内容恰好处于“非Agentic的推理”和“Agentic的推理”之间的关键地带。它不是研究如何让LLM解决数学题（非Agentic推理），而是研究如何构建一个能够进行“反思性、类思维内部处理”的架构。这种反思能力是高级Agentic规划和决策的基础。根据筛选标准“保留: 如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理...”，虽然本文未直接研究规划任务，但它为智能体进行更复杂的、基于反思的推理提供了**底层硬件支持**，因此应保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种新的神经网络层（FH-RL），旨在从架构层面实现“反思性智能”。这直接对应了您研究焦点中的“自我演化”方向，特别是其子方向“自我反思”。它不是应用型研究，而是为构建更高级的、能够自我演化的LLM智能体提供了基础理论和构件，因此与您的研究课题高度相关，应被筛选出来。"
    },
    {
        "index": "#175",
        "title": "CoFineLLM: Conformal Finetuning of LLMs for Language-Instructed Robot Planning",
        "link": "/arxiv/2511.06575",
        "arxiv_id": "2511.06575",
        "authors": "Jun Wang, Yevgeniy Vorobeychik, Yiannis Kantaros",
        "summary": "Large Language Models (LLMs) have recently emerged as planners for language-instructed agents, generating sequences of actions to accomplish natural language tasks. However, their reliability remains a challenge, especially in long-horizon tasks, since they often produce overconfident yet wrong outputs. Conformal Prediction (CP) has been leveraged to address this issue by wrapping LLM outputs into prediction sets that contain the correct action with a user-defined confidence. When the prediction set is a singleton, the planner executes that action; otherwise, it requests help from a user. This has led to LLM-based planners that can ensure plan correctness with a user-defined probability. However, as LLMs are trained in an uncertainty-agnostic manner, without awareness of prediction sets, they tend to produce unnecessarily large sets, particularly at higher confidence levels, resulting in frequent human interventions limiting autonomous deployment. To address this, we introduce CoFineLLM (Conformal Finetuning for LLMs), the first CP-aware finetuning framework for LLM-based planners that explicitly reduces prediction-set size and, in turn, the need for user interventions. We evaluate our approach on multiple language-instructed robot planning problems and show consistent improvements over uncertainty-aware and uncertainty-agnostic finetuning baselines in terms of prediction-set size, and help rates. Finally, we demonstrate robustness of our method to out-of-distribution scenarios in hardware experiments.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2025-11-09",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.372526",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用在机器人领域，而是提出了一种名为 `CoFineLLM` 的新框架，其核心目标是**改进LLM作为智能体规划器的能力**。论文指出现有LLM规划器因过度自信而产生错误，导致需要频繁的人工干预，从而限制了其自主性。`CoFineLLM` 通过一种“符合预测感知”的微调方法，直接解决了这个智能体固有的问题，旨在减少预测集大小和人工求助率，从而提升智能体的自主规划能力。这完全符合“构建、改进或演化LLM智能体”的核心目标。它不是非演化型应用，因为它贡献的是一种改进智能体本身的方法论，而非应用成果。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (论文明确提到 \"LLM-based planners\")。 - **智能体能力**: `Planning` (论文的核心主题是 \"Robot Planning\" 和 \"planners\")。虽然论文没有直接提及 `Self-Reflection`，但其减少人工干预、增强自主性的目标，与提升智能体独立完成任务的能力高度相关，可以视为对智能体自主性的一种改进。 3.  **第三步：排除标准** - **安全与对齐**: 论文虽然提到了 \"reliability\" 和 \"correctness\"，但其主要贡献并非一个安全或对齐框架。它使用符合预测（CP）作为一种技术手段来提升规划的可靠性，最终目的是为了**减少人工干预、增强自主性**，而不是为了解决AI安全、伦理或对齐问题。因此，不触发此项排除标准。 - **多模态与视觉**: 论文的应用领域是机器人，但摘要中完全聚焦于语言指令和动作序列的规划，没有提及视觉、MLLMs等多模态技术。LLM在此扮演的是规划大脑的角色，而非感知工具。因此，不触发此项排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”的典型案例。它研究的不是LLM本身的基础推理能力（如数学计算），而是**智能体如何进行规划**。`CoFineLLM` 是一个专门为LLM智能体规划器设计的改进框架，旨在使其在长时程任务中表现更可靠、更自主，这完全符合您对“智能体规划”研究方向的定义。 5.  **第五步：最终决策** - 综合以上分析，该论文的核心贡献是提出了一种新颖的微调框架，用于**改进LLM智能体的核心规划能力**，以增强其自主性。它直接对齐了您研究范围中的“单智能体”方向，特别是“规划”这一子方向。尽管它在机器人领域进行评估，但其方法论贡献是通用且面向Agentic AI本身的，而非特定领域的应用。因此，这篇论文是高度相关的前沿研究，应被筛选入内。"
    },
    {
        "index": "#190",
        "title": "FLEX: Continuous Agent Evolution via Forward Learning from Experience",
        "link": "/arxiv/2511.06449",
        "arxiv_id": "2511.06449",
        "authors": "Zhicheng Cai, Xinyuan Guo, Yu Pei, JiangTao Feng, Jiangjie Chen, Ya-Qin Zhang, Wei-Ying Ma, Mingxuan Wang, Hao Zhou",
        "summary": "Autonomous agents driven by Large Language Models (LLMs) have revolutionized reasoning and problem-solving but remain static after training, unable to grow with experience as intelligent beings do during deployment. We introduce Forward Learning with EXperience (FLEX), a gradient-free learning paradigm that enables LLM agents to continuously evolve through accumulated experience. Specifically, FLEX cultivates scalable and inheritable evolution by constructing a structured experience library through continual reflection on successes and failures during interaction with the environment. FLEX delivers substantial improvements on mathematical reasoning, chemical retrosynthesis, and protein fitness prediction (up to 23% on AIME25, 10% on USPTO50k, and 14% on ProteinGym). We further identify a clear scaling law of experiential growth and the phenomenon of experience inheritance across agents, marking a step toward scalable and inheritable continuous agent evolution. Project Page: https://flex-gensi-thuair.github.io.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-09",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.407203",
        "filter_reason": "这篇论文完全符合我的研究范围，应予以保留。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种名为FLEX（Forward Learning with EXperience）的无梯度学习范式，旨在让LLM智能体在部署后能够通过积累的经验进行连续的自我演化。这直接命中了我的核心目标——“构建、改进或演化LLM智能体”。论文的本质是方法论创新，而非简单的应用，因此不属于“非演化型应用”的排除范畴。 2.  **研究焦点匹配:** 该研究明确属于我的第三个核心方向“自我演化”。它探讨了智能体如何通过“持续反思”成功与失败的经验来构建结构化的经验库，从而实现迭代式自我完善和代际间的经验继承。这正是“自我演化”方向的核心议题。 3.  **正面指标 (第二步):** 论文摘要中包含了大量正面指标，如 `Self-Evolving` (标题和摘要核心), `Self-Reflection` (“continual reflection”), `Self-Improvement` (“continuously evolve”), `Iterative Improvement` (“accumulated experience”) 等，进一步确认了其高度相关性。 4.  **特殊情况处理 (第四步):** 这篇论文是“自我演化的应用”这一特殊情况的完美例证。尽管论文在数学推理、化学逆合成和蛋白质适应度预测等特定领域进行了实验验证，但其核心是提出一种全新的“自我演化”机制。根据我的筛选规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 因此，这种应用场景不仅不应排除，反而证明了该演化机制的通用性和有效性，是加分项。 5.  **排除标准 (第三步):** 论文未涉及安全对齐、可解释性、多模态视觉等任何排除标准。 综上所述，FLEX这篇论文是关于LLM智能体自我演化机制的前沿研究，与我的研究课题“LLM智能体及其演化”高度契合，其核心贡献在于构建了一个让智能体持续演化的新框架，完全符合筛选要求。"
    },
    {
        "index": "#189",
        "title": "A Multi-Agent System for Semantic Mapping of Relational Data to Knowledge Graphs",
        "link": "/arxiv/2511.06455",
        "arxiv_id": "2511.06455",
        "authors": "Milena Trajanoska, Riste Stojanov, Dimitar Trajanov",
        "summary": "Enterprises often maintain multiple databases for storing critical business data in siloed systems, resulting in inefficiencies and challenges with data interoperability. A key to overcoming these challenges lies in integrating disparate data sources, enabling businesses to unlock the full potential of their data. Our work presents a novel approach for integrating multiple databases using knowledge graphs, focusing on the application of large language models as semantic agents for mapping and connecting structured data across systems by leveraging existing vocabularies. The proposed methodology introduces a semantic layer above tables in relational databases, utilizing a system comprising multiple LLM agents that map tables and columns to Schema.org terms. Our approach achieves a mapping accuracy of over 90% in multiple domains.",
        "subjects": "Databases, Artificial Intelligence",
        "date": "2025-11-09",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.401483",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出了一种**新颖的多智能体系统**，用于解决一个具体问题（将关系数据库映射到知识图谱）。它不是简单地使用一个已有的智能体框架，而是**构建了一个由多个LLM智能体组成的系统**，并设计了它们协同工作的方法论。 - **判断**: 这符合“保留”标准，因为其核心贡献在于**构建一个多智能体系统**。虽然它被应用在数据集成领域，但其研究焦点是智能体系统的架构和工作流程，而非仅仅是应用结果。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文标题和摘要中明确包含了多个核心关键词： - `Multi-Agent Systems (MAS)`: 标题直接点明。 - `LLM-based Agents`: 摘要中明确指出“utilizing a system comprising multiple LLM agents”。 - `Collaboration`: 多智能体系统本身就隐含了智能体间的协作与分工。 - 这些指标强烈表明该论文与您的“多智能体”研究方向高度相关。 3.  **第三步：排除标准** - 论文的主要贡献是关于智能体系统的设计和应用效果（准确率），没有涉及安全、对齐、可解释性或视觉等多模态内容。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及“自我演化”，但它在“多智能体”方向上非常契合。它描述了如何让多个智能体协同完成一个复杂的、需要多步推理和任务分解的语义映射任务。这属于构建和改进多智能体系统的范畴，是您研究目标的核心部分。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建和设计了一个多智能体系统**来解决语义映射问题。这完全符合您研究目标中的“构建、改进或演化 LLM智能体”以及“多智能体”方向。尽管它有一个明确的应用场景，但其研究价值在于智能体系统本身的设计和实现，而非应用领域的特定问题。因此，应判定为 **True (保留)**。"
    },
    {
        "index": "#205",
        "title": "PRAGMA: A Profiling-Reasoned Multi-Agent Framework for Automatic Kernel Optimization",
        "link": "/arxiv/2511.06345",
        "arxiv_id": "2511.06345",
        "authors": "Kelun Lei, Hailong Yang, Huaitao Zhang, Xin You, Kaige Zhang, Zhongzhi Luan, Yi Liu, Depei Qian",
        "summary": "Designing high-performance kernels requires expert-level tuning and a deep understanding of hardware characteristics. Recent advances in large language models (LLMs) have enabled automated kernel generation, yet most existing systems rely solely on correctness or execution time feedback, lacking the ability to reason about low-level performance bottlenecks. In this paper, we introduce PRAGMA, a profile-guided AI kernel generation framework that integrates execution feedback and fine-grained hardware profiling into the reasoning loop. PRAGMA enables LLMs to identify performance bottlenecks, preserve historical best versions, and iteratively refine code quality. We evaluate PRAGMA on KernelBench, covering GPU and CPU backends. Results show that PRAGMA consistently outperforms baseline AIKG without profiling enabled and achieves 2.81$\\times$ and 2.30$\\times$ averaged speedups against Torch on CPU and GPU platforms, respectively.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence",
        "date": "2025-11-09",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.419764",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了一个名为 **PRAGMA 的新框架**，而不是简单地将现有LLM或智能体作为工具应用。该框架是一个“多智能体框架”，其核心机制是“将执行反馈和细粒度硬件分析集成到推理循环中”，并能够“迭代优化代码质量”。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。 - 它不属于“非演化型应用”，因为其核心是提出了一种具备自我完善能力的框架，而不仅仅是用LLM去解决内核优化问题。 **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 在标题中明确指出。 - **自我演化机制**: `Self-Improvement` / `Iterative Improvement` 通过摘要中的 “iteratively refine code quality” 和 “preserve historical best versions” 体现。 - **智能体能力**: `Reasoning` 通过标题中的 “Profiling-Reasoned” 和摘要中的 “reasoning loop” 体现。`Memory` 通过 “preserve historical best versions” 体现。`Self-Correction` / `Self-Refine` 通过 “iteratively refine code quality” 体现。 **第三步：排除标准** - 论文不涉及安全与对齐（Safety, Alignment等），也不涉及多模态与视觉（Vision, MLLMs等）。因此，没有触发任何排除标准。 **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是本案例的关键。虽然论文的应用领域是“内核优化”，但根据筛选规则中的例外情况：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”。PRAGMA框架的核心创新点正是其“profile-guided”的推理循环和“iteratively refine”的自我演化机制。因此，尽管它应用于一个具体的工程领域，其方法论贡献本身完全符合我的研究焦点。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于构建了一个具备推理、记忆和自我迭代优化能力的多智能体框架。它完美地契合了我研究课题中的“多智能体”和“自我演化”两个核心方向。因此，最终判断为 **True (保留)**。"
    },
    {
        "index": "#215",
        "title": "LLM-Guided Reinforcement Learning with Representative Agents for Traffic Modeling",
        "link": "/arxiv/2511.06260",
        "arxiv_id": "2511.06260",
        "authors": "Hanlin Sun, Jiayang Li",
        "summary": "Large language models (LLMs) are increasingly used as behavioral proxies for self-interested travelers in agent-based traffic models. Although more flexible and generalizable than conventional models, the practical use of these approaches remains limited by scalability due to the cost of calling one LLM for every traveler. Moreover, it has been found that LLM agents often make opaque choices and produce unstable day-to-day dynamics. To address these challenges, we propose to model each homogeneous traveler group facing the same decision context with a single representative LLM agent who behaves like the population's average, maintaining and updating a mixed strategy over routes that coincides with the group's aggregate flow proportions. Each day, the LLM reviews the travel experience and flags routes with positive reinforcement that they hope to use more often, and an interpretable update rule then converts this judgment into strategy adjustments using a tunable (progressively decaying) step size. The representative-agent design improves scalability, while the separation of reasoning from updating clarifies the decision logic while stabilizing learning. In classic traffic assignment settings, we find that the proposed approach converges rapidly to the user equilibrium. In richer settings with income heterogeneity, multi-criteria costs, and multi-modal choices, the generated dynamics remain stable and interpretable, reproducing plausible behavioral patterns well-documented in psychology and economics, for example, the decoy effect in toll versus non-toll road selection, and higher willingness-to-pay for convenience among higher-income travelers when choosing between driving, transit, and park-and-ride options.",
        "subjects": "Computer Science and Game Theory, Artificial Intelligence, Systems and Control",
        "date": "2025-11-09",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.430198",
        "filter_reason": "这篇论文符合您的研究范围，其核心贡献在于提出了一种新颖的LLM智能体框架，该框架具备自我演化的能力。我的判断依据如下： 1.  **第一步：核心判断——保留** - 论文的核心并非简单地将LLM作为工具应用于交通领域，而是针对现有LLM智能体在交通建模中遇到的**可扩展性差、决策不透明、动态不稳定**等具体问题，提出了一种全新的智能体设计范式——**“代表性LLM智能体”**。这本质上是对LLM智能体本身的**构建和改进**，属于方法论层面的创新，因此应予以保留。 2.  **第二步：正面指标——高度匹配** - 论文的核心贡献与您的关注点高度重合： - **自我演化:** 这是论文最核心的亮点。论文明确提出了一个演化机制：智能体每天“审查旅行体验”，这是一种**自我反思**；然后通过一个“可解释的更新规则”来调整其路线选择策略，这是一种明确的**自我完善**和**迭代改进**。整个“LLM推理 + 更新规则”的闭环构成了一个完整的自我演化框架。 - **单智能体:** 论文详细描述了智能体的规划和决策过程，即如何在多条路线中维持和更新一个混合策略。 - **多智能体:** 论文的研究背景是基于智能体的交通模型，虽然通过“代表性智能体”进行了简化，但其根本目标是模拟大量旅行者（智能体）的群体行为，属于多智能体系统的范畴。 3.  **第三步：排除标准——未触及** - 论文的主要贡献是智能体框架的设计，而非安全、对齐或多模态技术。虽然提到了“可解释的更新规则”，但这是为了服务于智能体决策的清晰性和稳定性，是框架设计的一部分，而非以可解释性本身为研究目标。 4.  **第四步：处理特殊和模糊情况——适用例外规则** - **自我演化的应用:** 这篇论文是“自我演化应用”的完美范例。尽管其应用领域是交通建模，但论文的核心创新点是提出了一种**新的“自我演化”机制**（反思+更新规则）。根据您的筛选规则，这种情况应该**保留**。 - **推理/规划:** 论文中的推理是智能体在复杂环境（交通网络）中进行多步决策（路线选择）的过程，完全符合“保留”关于智能体规划和推理的论文的标准。 **总结:** 该论文的本质是**提出了一种具备自我反思和自我完善能力的LLM智能体新框架**，以解决其在特定应用场景下的瓶颈问题。其核心贡献完全聚焦于**智能体的构建与演化**，与您“LLM智能体及其演化”的研究课题，特别是“自我演化”方向，高度契合。因此，这篇论文应该被保留。"
    },
    {
        "index": "#218",
        "title": "WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation",
        "link": "/arxiv/2511.06251",
        "arxiv_id": "2511.06251",
        "authors": "Mingde Xu, Zhen Yang, Wenyi Hong, Lihang Pan, Xinyue Fan, Yan Wang, Xiaotao Gu, Bin Xu, Jie Tang",
        "summary": "User interface (UI) development requires translating design mockups into functional code, a process that remains repetitive and labor-intensive. While recent Vision-Language Models (VLMs) automate UI-to-Code generation, they generate only static HTML/CSS/JavaScript layouts lacking interactivity. To address this, we propose WebVIA, the first agentic framework for interactive UI-to-Code generation and validation. The framework comprises three components: 1) an exploration agent to capture multi-state UI screenshots; 2) a UI2Code model that generates executable interactive code; 3) a validation module that verifies the interactivity. Experiments demonstrate that WebVIA-Agent achieves more stable and accurate UI exploration than general-purpose agents (e.g., Gemini-2.5-Pro). In addition, our fine-tuned WebVIA-UI2Code models exhibit substantial improvements in generating executable and interactive HTML/CSS/JavaScript code, outperforming their base counterparts across both interactive and static UI2Code benchmarks. Our code and models are available at \\href{https://zheny2751-dotcom.github.io/webvia.github.io/}{\\texttt{https://webvia.github.io}}.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-09",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.431904",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建了一个新颖的LLM智能体框架。以下是详细的判断过程： 1.  **第一步：核心判断——保留** - 论文的本质是构建一个名为 **WebVIA** 的 **Agentic Framework**。它不是简单地将现有智能体应用于一个新领域，而是提出了一个包含 **exploration agent**（探索智能体）和 **validation module**（验证模块）的新框架来解决特定问题。这完全符合“构建、改进或演化LLM智能体”的核心目标。 - 它不属于“非演化型应用”，因为其核心贡献是框架本身，而非应用结果。它也不属于“非Agentic的推理”，因为它明确涉及智能体在环境中的行动（探索UI）和验证。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文标题和摘要多次强调 `Agentic Framework` 和 `exploration agent`，直接命中核心关注点。 - **智能体能力**: - `Planning`: `exploration agent` 捕获多状态UI截图，这本质上是一种在环境中进行探索和规划的策略性行为。 - `Tool Use`: 智能体通过截图等方式与环境（网页UI）进行交互，这属于工具使用和环境感知。 - `Self-Correction / Self-Reflection`: `validation module` 负责验证生成代码的交互性，这是一个典型的自我反思和验证机制，是智能体闭环的关键部分。 3.  **第三步：排除标准——未触发** - **安全与对齐**: 论文未涉及安全、对齐、可解释性等内容。 - **多模态与视觉**: 论文虽然涉及 `Vision-Language` 和 `VLMs`，但根据筛选规则，它们是作为智能体**感知环境的工具**而存在的。研究的核心是智能体如何利用视觉输入进行探索和验证，而不是VLM模型本身。因此，这不构成排除的理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的 `exploration agent` 明确属于智能体在复杂任务中进行多步推理和行动的范畴，符合保留标准。 5.  **第五步：最终决策** - 综合来看，这篇论文的核心贡献是提出一个新颖的、用于解决UI-to-Code问题的LLM智能体框架。该框架包含了智能体规划（探索）、工具使用（与环境交互）和自我反思（验证）等关键能力，完全属于您研究焦点中的 **“单智能体”** 方向。尽管它应用于特定领域，但其方法论贡献是普适的，属于Agentic AI的前沿研究。因此，应予以保留。"
    },
    {
        "index": "#361",
        "title": "IMDMR: An Intelligent Multi-Dimensional Memory Retrieval System for Enhanced Conversational AI",
        "link": "/arxiv/2511.05495",
        "arxiv_id": "2511.05495",
        "authors": "Tejas Pawar, Sarika Patil, Om Tilekar, Rushikesh Janwade, Vaibhav Helambe",
        "summary": "Conversational AI systems often struggle with maintaining coherent, contextual memory across extended interactions, limiting their ability to provide personalized and contextually relevant responses. This paper presents IMDMR (Intelligent Multi-Dimensional Memory Retrieval), a novel system that addresses these limitations through a multi-dimensional search architecture. Unlike existing memory systems that rely on single-dimensional approaches, IMDMR leverages six distinct memory dimensions-semantic, entity, category, intent, context, and temporal-to provide comprehensive memory retrieval capabilities. Our system incorporates intelligent query processing with dynamic strategy selection, cross-memory entity resolution, and advanced memory integration techniques. Through comprehensive evaluation against five baseline systems including LangChain RAG, LlamaIndex, MemGPT, and spaCy + RAG, IMDMR achieves a 3.8x improvement in overall performance (0.792 vs 0.207 for the best baseline). We present both simulated (0.314) and production (0.792) implementations, demonstrating the importance of real technology integration while maintaining superiority over all baseline systems. Ablation studies demonstrate the effectiveness of multi-dimensional search, with the full system outperforming individual dimension approaches by 23.3%. Query-type analysis reveals superior performance across all categories, particularly for preferences/interests (0.630) and goals/aspirations (0.630) queries. Comprehensive visualizations and statistical analysis confirm the significance of these improvements with p < 0.001 across all metrics. The results establish IMDMR as a significant advancement in conversational AI memory systems, providing a robust foundation for enhanced user interactions and personalized experiences.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-09-10",
        "category": "cs.AI",
        "crawl_time": "2025-11-12T11:00:06.629212",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** *   **论文本质**: 这篇论文的核心贡献是提出并构建了一个名为 IMDMR 的**新颖的记忆检索系统**。它不是将现有智能体框架简单应用到一个新领域，而是专注于**改进和构建LLM智能体的一个核心组件——记忆**。记忆是你明确列出的单智能体核心能力之一（“规划、**记忆**、工具使用、自我反思等”）。因此，这篇论文的本质是关于“构建、改进LLM智能体”，符合保留标准。 2.  **第二步：正面指标——高度相关** *   论文的核心内容直接命中了你的核心关注点。它虽然没有明确使用 \"Agentic AI\" 这个词，但其研究的“对话式AI系统”和“记忆系统”是LLM智能体的基础。 *   最关键的正面指标是 **`Memory`**。整篇论文都在围绕如何设计一个更强大的多维度记忆系统来展开，这直接对应了你研究焦点中的“单智能体”方向。 *   论文与 MemGPT 等知名的智能体记忆系统进行对比，进一步证明了它是在智能体研究的语境下进行的工作。 3.  **第三步：排除标准——未触发** *   论文的主要贡献是关于提升记忆检索的性能和效果，而不是关于安全、对齐、可解释性或水印。因此，它不属于“安全与对齐”的排除范畴。 *   论文处理的是文本对话，不涉及视觉或多模态内容，因此也避开了“多模态与视觉”的排除标准。 4.  **第四步：处理特殊和模糊情况——不适用** *   这篇论文不涉及推理/规划或自我演化的特殊情况，其焦点非常明确，就是记忆系统。 5.  **第五步：最终决策** *   综合来看，这篇论文的核心贡献是**构建一个创新的、多维度的记忆检索框架**，以增强LLM智能体在长期对话中的上下文感知和个性化能力。这完全契合你“筛选出那些核心贡献在于构建、改进LLM智能体的论文”的核心目标，并且精准地落在了“单智能体”研究方向的“记忆”子方向上。因此，这是一篇高度相关且应该保留的前沿论文。"
    }
]