[
    {
        "index": "#1",
        "title": "The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems",
        "link": "/arxiv/2511.15862",
        "arxiv_id": "2511.15862",
        "authors": "Devang Kulshreshtha, Wanyu Du, Raghav Jain, Srikanth Doss, Hang Su, Sandesh Swamy, Yanjun Qi",
        "summary": "This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.",
        "subjects": "Multiagent Systems, Computation and Language",
        "date": "2025-11-19",
        "category": "cs.MA",
        "crawl_time": "2025-11-21T11:00:05.163299",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断依据如下： 1.  **第一步：核心判断 (保留)** - 论文的核心贡献是提出一个**全新的框架**，用于**模拟和分析**LLM多智能体系统中的不合作行为。这并非将现有智能体框架简单应用于某个领域（如资源管理），而是**构建了一个新的方法论和工具**来研究智能体系统本身的内在动态。这直接命中了您“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标 (高度匹配)** - **核心范式**: 论文明确聚焦于 `LLM-based Multi-Agent Systems`，这是您研究的核心方向之一。 - **多智能体**: 论文研究的核心是智能体间的 `Uncooperative Behaviors`，这与 `Collaboration`、`Negotiation`、`Agent Society` 等多智能体交互主题紧密相关。它探讨了智能体行为如何影响集体结果，这是多智能体系统研究的关键问题。 - **演化机制**: 论文框架包含一个“动态生成和精炼不合作行为”的模拟管道，并且这些行为会“随着智能体状态的演化”而变化。这体现了 `Iterative Improvement` 和系统状态演化的思想，与您的“自我演化”关注点有交集，尽管它是在模拟环境中由框架驱动的演化。 3.  **第三步：排除标准 (未触发)** - **安全与对齐**: 虽然论文研究“不合作行为”，这与安全相关，但其**主要贡献并非提出一种新的安全技术或对齐方法**。相反，它提供了一个分析框架来**理解和量化**这种行为对系统稳定性的影响，其最终目的是“设计更有弹性的多智能体系统”，这属于构建和改进智能体的范畴，而非纯粹的安全研究。 - **多模态与视觉**: 论文未涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及此方面。 - **自我演化的应用**: 论文虽然应用在“协作资源管理”场景，但其核心是提出分析框架，而非解决资源管理问题本身，因此不属于“非演化型应用”的排除范围。 **总结**: 该论文的本质是**方法论创新**，它为LLM多智能体系统的研究提供了一个新的分析工具和理论视角（不合作行为的分类法）。它直接服务于您“多智能体”方向的研究目标，即理解智能体间的交互如何影响系统整体，并最终指导如何构建更稳健、更智能的系统。因此，这篇论文是您课题下的高质量前沿研究，应当保留。"
    },
    {
        "index": "#14",
        "title": "Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement",
        "link": "/arxiv/2511.16331",
        "arxiv_id": "2511.16331",
        "authors": "Jiashu Yao, Heyan Huang, Shuang Zeng, Chuwei Luo, WangJie You, Jie Tang, Qingsong Liu, Yuhang Guo, Yangyang Kang",
        "summary": "Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only \"simple\" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.",
        "subjects": "Computation and Language",
        "date": "2025-11-20",
        "category": "cs.CL",
        "crawl_time": "2025-11-21T11:00:05.875761",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献精准地命中了“自我演化”这一研究方向。 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM作为工具去解决某个特定领域的问题，也不是单纯提升LLM的基础推理能力。它的核心贡献是提出了一种名为“self-rewriting”（自我重写）的**新框架和方法论**。在这个框架中，模型通过重写自己的推理文本，并从重写后的版本中学习，从而实现自我完善。这完全符合“构建、改进或演化 LLM智能体”的核心目标，特别是“自我演化”的范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点，尤其是“自我演化”方向的关键词： - **核心范式**: `Self-Evolving` (自我演化) 是论文最核心的主题。 - **演化机制**: `Self-Improvement` (自我完善), `Self-Refine` (自我精炼), `Iterative Improvement` (迭代改进) 都是其“self-rewriting”框架的直接体现。 - **智能体能力**: `Self-Correction` (自我纠正) 和 `Self-Reflection` (自我反思) 是“重写”行为的本质，即模型审视并修正自己的思维过程。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐（Safety, Alignment）、可解释性（Interpretability）或多模态（Vision）等排除领域。其焦点纯粹在于提升智能体的内部推理质量和效率。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文虽然主题是“推理”，但它并非关于提升LLM在数学或逻辑等基础任务上的Token预测能力。相反，它关注的是**推理过程的质量**（如“over-thinking”, “disordered-thinking”），并提出一个结构化的框架（生成 -> 重写 -> 学习）来优化这个过程。这种对自身思维过程进行反思和优化的机制，是高级智能体（特别是自我演化智能体）的关键能力，而非简单的模型能力提升。因此，它符合“保留”的标准。 **核心依据总结**: 该论文的核心贡献是提出了一种让LLM能够**自我反思、自我修正并迭代优化其内部推理过程**的“self-rewriting”框架。这是一种典型的、新颖的**自我演化机制**。它不是应用，不是基础设施，也不是基础能力提升，而是直接作用于智能体自身完善的方法论创新，与你的研究课题“LLM智能体及其演化”中的“自我演化”方向高度契合。因此，应予以保留。"
    },
    {
        "index": "#28",
        "title": "SurvAgent: Hierarchical CoT-Enhanced Case Banking and Dichotomy-Based Multi-Agent System for Multimodal Survival Prediction",
        "link": "/arxiv/2511.16635",
        "arxiv_id": "2511.16635",
        "authors": "Guolin Huang, Wenting Chen, Jiaqi Yang, Xinheng Lyu, Xiaoling Luo, Sen Yang, Xiaohan Xing, Linlin Shen",
        "summary": "Survival analysis is critical for cancer prognosis and treatment planning, yet existing methods lack the transparency essential for clinical adoption. While recent pathology agents have demonstrated explainability in diagnostic tasks, they face three limitations for survival prediction: inability to integrate multimodal data, ineffective region-of-interest exploration, and failure to leverage experiential learning from historical cases. We introduce SurvAgent, the first hierarchical chain-of-thought (CoT)-enhanced multi-agent system for multimodal survival prediction. SurvAgent consists of two stages: (1) WSI-Gene CoT-Enhanced Case Bank Construction employs hierarchical analysis through Low-Magnification Screening, Cross-Modal Similarity-Aware Patch Mining, and Confidence-Aware Patch Mining for pathology images, while Gene-Stratified analysis processes six functional gene categories. Both generate structured reports with CoT reasoning, storing complete analytical processes for experiential learning. (2) Dichotomy-Based Multi-Expert Agent Inference retrieves similar cases via RAG and integrates multimodal reports with expert predictions through progressive interval refinement. Extensive experiments on five TCGA cohorts demonstrate SurvAgent's superority over conventional methods, proprietary MLLMs, and medical agents, establishing a new paradigm for explainable AI-driven survival prediction in precision oncology.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-11-20",
        "category": "cs.CL",
        "crawl_time": "2025-11-21T11:00:05.892576",
        "filter_reason": "这篇论文符合筛选要求，应被保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个现有LLM或智能体框架应用到医疗领域，而是**构建了一个全新的、名为SurvAgent的多智能体系统**。其核心贡献在于这个系统的架构设计，包括“分层CoT增强的案例库构建”和“基于二分法的多智能体推理”两个阶段。这完全符合“构建、改进或演化LLM智能体”的核心目标。它不是非演化型应用，因为它提出了一个包含“经验学习”机制的新框架。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 在标题和摘要中被明确提出。 - **智能体能力**: `Planning`（分层分析、渐进式区间优化）、`Memory`（案例库构建、通过RAG检索相似案例）、`Self-Reflection`（CoT推理过程）。 - **多智能体**: `Collaboration`（多智能体推理阶段整合多模态报告与专家预测）。 - **演化机制**: `Self-Improvement` / `Iterative Improvement`（通过案例库进行“experiential learning”，即经验学习，这是一种基于经验的自我完善机制）。 3.  **第三步：排除标准** - **安全与对齐**: 论文提到了“explainability”（可解释性），但这只是其智能体框架带来的一个**特性**，而非论文的**主要贡献**。论文的核心是构建智能体系统本身，而不是研究可解释性方法。因此，不排除。 - **多模态与视觉**: 论文处理了多模态数据（病理图像和基因数据）。但根据筛选规则，视觉/多模态在这里是作为**智能体感知环境的工具**，研究的核心是智能体如何利用这些信息进行推理和协作，而不是视觉模型本身。因此，不排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的CoT是嵌入在智能体的**分层分析和多智能体协作框架**中的，用于指导智能体的行为，属于Agentic框架的规划部分，而非单纯提升LLM基础推理能力。因此，保留。 - **自我演化的应用**: 这篇论文是“自我演化的应用”的一个完美**例外**。虽然它应用于癌症生存预测这一特定领域，但其核心贡献是提出了一种**新的“自我演化”机制**——通过构建案例库和进行经验学习来迭代改进。这完全符合“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域，也应该保留”的规则。 **最终决策**: 综合以上分析，该论文的核心贡献在于设计并实现了一个新颖的多智能体系统，该系统具备规划、记忆和基于经验的自我完善能力。它直接命中了研究课题中的“多智能体”和“自我演化”两个核心方向。尽管其应用场景是医疗领域，但其方法论和框架创新对于LLM智能体的研究具有普适性和前沿性。因此，这篇论文高度符合研究范围，应被**保留**。"
    },
    {
        "index": "#32",
        "title": "MiMo-Embodied: X-Embodied Foundation Model Technical Report",
        "link": "/arxiv/2511.16518",
        "arxiv_id": "2511.16518",
        "authors": "Xiaoshuai Hao, Lei Zhou, Zhijian Huang, Zhiwen Hou, Yingbo Tang, Lingfeng Zhang, Guang Li, Zheng Lu, Shuhuai Ren, Xianhui Meng, Yuchen Zhang, Jing Wu, Jinghui Lu, Chenxu Dang, Jiayi Guan, Jianhua Wu, Zhiyi Hou, Hanbing Li, Shumeng Xia, Mingliang Zhou, Yinan Zheng, Zihao Yue, Shuhao Gu, Hao Tian, Yuannan Shen, Jianwei Cui, Wen Zhang, Shaoqing Xu, Bing Wang, Haiyang Sun, Zeyu Zhu, Yuncheng Jiang, Zibin Guo, Chuhong Gong, Chaofan Zhang, Wenbo Ding, Kun Ma, Guang Chen, Rui Cai, Diyun Xiang, Heng Qu, Fuli Luo, Hangjun Ye, Long Chen",
        "summary": "We open-source MiMo-Embodied, the first cross-embodied foundation model to successfully integrate and achieve state-of-the-art performance in both Autonomous Driving and Embodied AI. MiMo-Embodied sets new records across 17 embodied AI benchmarks in Task Planning, Affordance Prediction and Spatial Understanding, while also excelling in 12 autonomous driving benchmarks across Environmental Perception, Status Prediction, and Driving Planning. Across these tasks, MiMo-Embodied significantly outperforms existing open-source, closed-source, and specialized baselines. Our results indicate that through multi-stage learning, curated data construction, and CoT/RL fine-tuning, these two domains exhibit strong positive transfer and mutually reinforce one another. We provide a detailed analysis of our model design and training methodologies to facilitate further research. Code and models are available at https://github.com/XiaomiMiMo/MiMo-Embodied.",
        "subjects": "Robotics, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-11-20",
        "category": "cs.CL",
        "crawl_time": "2025-11-21T11:00:05.894964",
        "filter_reason": "这篇论文符合我的研究范围，核心判断依据如下： 1.  **核心贡献是构建智能体框架 (符合第一步保留标准)**: 论文的核心贡献是提出了一个名为 \"MiMo-Embodied\" 的跨领域具身基础模型。这并非简单地将现有模型作为工具应用，而是构建了一个新的、统一的模型架构和训练方法论，使其能够在自动驾驶和具身AI两个领域都达到顶尖性能。这完全符合“构建、改进LLM智能体”的核心目标。 2.  **聚焦于智能体的核心能力 (符合第二步正面指标)**: 摘要中明确指出，该模型在 **\"Task Planning\" (任务规划)** 和 **\"Driving Planning\" (驾驶规划)** 等基准测试中取得了领先成绩。规划能力是单智能体研究的核心方向之一，是Agentic AI的关键组成部分。论文还提到了使用 **\"CoT/RL fine-tuning\"**，这些是训练智能体进行复杂决策和规划的常用技术，进一步印证了其Agentic属性。 3.  **未触及排除标准 (符合第三步)**: 论文的主要贡献是模型设计和性能提升，而非安全、对齐或可解释性。虽然它涉及 \"Embodied AI\" 和 \"Autonomous Driving\"，这些领域通常包含视觉感知，但根据筛选规则，只要视觉是作为智能体感知环境的工具，而非研究的核心，就不应排除。本论文的核心是**规划模型**，视觉感知是其输入的一部分，而非论文的创新点。 4.  **特殊情况处理 (符合第四步)**: 论文明确讨论了智能体的**规划**能力，这属于应保留的范畴。它不是关于提升LLM基础数学或逻辑能力，而是关于智能体在复杂环境中的多步决策和行动规划。 综上所述，该论文的核心是构建一个具备高级规划能力的具身智能体，其方法论和模型贡献直接服务于“LLM智能体及其演化”这一研究课题，特别是其中的“单智能体”方向。因此，应予以保留。"
    },
    {
        "index": "#36",
        "title": "Can MLLMs Read the Room? A Multimodal Benchmark for Assessing Deception in Multi-Party Social Interactions",
        "link": "/arxiv/2511.16221",
        "arxiv_id": "2511.16221",
        "authors": "Caixin Kang, Yifei Huang, Liangyang Ouyang, Mingfang Zhang, Ruicong Liu, Yoichi Sato",
        "summary": "Despite their advanced reasoning capabilities, state-of-the-art Multimodal Large Language Models (MLLMs) demonstrably lack a core component of human intelligence: the ability to `read the room' and assess deception in complex social interactions. To rigorously quantify this failure, we introduce a new task, Multimodal Interactive Deception Assessment (MIDA), and present a novel multimodal dataset providing synchronized video and text with verifiable ground-truth labels for every statement. We establish a comprehensive benchmark evaluating 12 state-of-the-art open- and closed-source MLLMs, revealing a significant performance gap: even powerful models like GPT-4o struggle to distinguish truth from falsehood reliably. Our analysis of failure modes indicates that these models fail to effectively ground language in multimodal social cues and lack the ability to model what others know, believe, or intend, highlighting the urgent need for novel approaches to building more perceptive and trustworthy AI systems. To take a step forward, we design a Social Chain-of-Thought (SoCoT) reasoning pipeline and a Dynamic Social Epistemic Memory (DSEM) module. Our framework yields performance improvement on this challenging task, demonstrating a promising new path toward building MLLMs capable of genuine human-like social reasoning.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-11-20",
        "category": "cs.CL",
        "crawl_time": "2025-11-21T11:00:05.896877",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地应用现有模型，而是**提出了一种新的方法论框架**来提升LLM智能体在特定复杂任务上的能力。其核心贡献是设计了“社交思维链推理管道”和“动态社会认知记忆模块”。这属于构建和改进LLM智能体的范畴，而非仅仅将其作为工具应用。论文的目标是让智能体具备“真正类人的社会推理”能力，这是Agentic AI的核心研究方向之一。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **多智能体**: 论文的研究背景是“多方社交互动”，评估欺骗行为本质上需要建模多个参与者的信念、意图和知识状态，这是多智能体系统研究的核心场景。 - **智能体能力**: 论文明确提出了一个**记忆**模块（`Dynamic Social Epistemic Memory`），并设计了一个用于复杂多步推理的管道（`Social Chain-of-Thought`），这与智能体的规划和推理能力直接相关。 3.  **第三步：排除标准** - **安全与对齐**: 尽管论文提到了“更值得信赖的AI系统”，但其主要贡献是提升智能体的**能力**（社会推理），而非研究安全机制、对齐方法或可解释性。因此，不触发排除标准。 - **多模态与视觉**: 论文确实聚焦于多模态大模型（MLLMs），但它的核心贡献**不是**一个新的视觉模型或多模态融合技术。相反，视觉和文本信息是作为智能体**感知环境的工具**，服务于其核心的社会推理任务。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外条款。研究的核心是SoCoT和DSEM这个推理和记忆框架，而非多模态处理本身。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的“社交思维链”是一个典型的智能体推理框架，用于在复杂任务（评估欺骗）中进行多步推理。这符合“保留”标准，因为它关注的是智能体如何推理，而非LLM底层的数学或逻辑能力。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于为LLM智能体构建了一个新的推理与记忆框架，以解决其在多智能体社会交互中的复杂推理问题。它直接触及了“多智能体”和“单智能体”（记忆、推理）两个核心研究方向，并且没有触犯任何排除标准。因此，这篇论文高度符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#41",
        "title": "JudgeBoard: Benchmarking and Enhancing Small Language Models for Reasoning Evaluation",
        "link": "/arxiv/2511.15958",
        "arxiv_id": "2511.15958",
        "authors": "Zhenyu Bi, Gaurav Srivastava, Yang Li, Meng Lu, Swastik Roy, Morteza Ziyadi, Xuan Wang",
        "summary": "While small language models (SLMs) have shown promise on various reasoning tasks, their ability to judge the correctness of answers remains unclear compared to large language models (LLMs). Prior work on LLM-as-a-judge frameworks typically relies on comparing candidate answers against ground-truth labels or other candidate answers using predefined metrics like entailment. However, this approach is inherently indirect and difficult to fully automate, offering limited support for fine-grained and scalable evaluation of reasoning outputs. In this work, we propose JudgeBoard, a novel evaluation pipeline that directly queries models to assess the correctness of candidate answers without requiring extra answer comparisons. We focus on two core reasoning domains: mathematical reasoning and science/commonsense reasoning, and construct task-specific evaluation leaderboards using both accuracy-based ranking and an Elo-based rating system across five benchmark datasets, enabling consistent model comparison as judges rather than comparators. To improve judgment performance in lightweight models, we propose MAJ (Multi-Agent Judging), a novel multi-agent evaluation framework that leverages multiple interacting SLMs with distinct reasoning profiles to approximate LLM-level judgment accuracy through collaborative deliberation. Experimental results reveal a significant performance gap between SLMs and LLMs in isolated judging tasks. However, our MAJ framework substantially improves the reliability and consistency of SLMs. On the MATH dataset, MAJ using smaller-sized models as backbones performs comparatively well or even better than their larger-sized counterparts. Our findings highlight that multi-agent SLM systems can potentially match or exceed LLM performance in judgment tasks, with implications for scalable and efficient assessment.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-20",
        "category": "cs.CL",
        "crawl_time": "2025-11-21T11:00:05.904357",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。 我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一个名为 `MAJ (Multi-Agent Judging)` 的新颖多智能体评估框架。这个框架利用多个具有不同推理特征的小语言模型（SLM）进行交互和协作，通过“协作审议”来提升评判任务的准确性。这完全符合“构建、改进或演化 LLM智能体”中的“构建多智能体系统”这一核心要求。它不是简单地将现有智能体作为工具应用，而是提出了一个新的多智能体协作框架。因此，根据第一步的判断标准，应该**保留**。 2.  **第二步：正面指标** 论文明确包含了我的核心关注点： *   **核心范式**: 论文的核心 `MAJ` 框架属于 `Multi-Agent Systems (MAS)`。 *   **多智能体**: 摘要中明确提到了 `Multi-Agent Judging`、`multiple interacting SLMs` 和 `collaborative deliberation`，这直接对应了多智能体研究中的 `Collaboration`（协作）和 `Communication`（通信）等子方向。 3.  **第三步：排除标准** 论文的主要贡献不涉及安全与对齐（Safety, Alignment）、可解释性（Interpretability）或多模态（Vision, MLLMs）等排除领域。它的焦点是智能体的协作机制和性能提升，因此没有触发排除标准。 4.  **第四步：处理特殊和模糊情况** 论文虽然涉及“推理”，但其切入点并非提升LLM本身的基础推理能力（如新的CoT变体），而是研究如何让多个智能体**协作**来完成一个复杂的推理评估任务。这属于智能体框架的设计范畴，符合“保留”关于智能体如何进行规划和多步推理的研究。`MAJ` 框架本身就是一个Agentic框架，而非非Agentic的推理方法。 5.  **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于提出了一种新的多智能体框架（`MAJ`），通过智能体间的协作来提升系统在特定任务（评判）上的整体性能。这直接命中了我的研究焦点之一“多智能体”，特别是其中的“协作”与“通信”子方向。因此，这篇论文与我的研究课题高度相关，最终判断为**保留**。"
    },
    {
        "index": "#42",
        "title": "AccelOpt: A Self-Improving LLM Agentic System for AI Accelerator Kernel Optimization",
        "link": "/arxiv/2511.15915",
        "arxiv_id": "2511.15915",
        "authors": "Genghan Zhang, Shaowei Zhu, Anjiang Wei, Zhenyu Song, Allen Nie, Zhen Jia, Nandita Vijaykumar, Yida Wang, Kunle Olukotun",
        "summary": "We present AccelOpt, a self-improving large language model (LLM) agentic system that autonomously optimizes kernels for emerging AI acclerators, eliminating the need for expert-provided hardware-specific optimization knowledge. AccelOpt explores the kernel optimization space through iterative generation, informed by an optimization memory that curates experiences and insights from previously encountered slow-fast kernel pairs. We build NKIBench, a new benchmark suite of AWS Trainium accelerator kernels with varying complexity extracted from real-world LLM workloads to evaluate the effectiveness of AccelOpt. Our evaluation confirms that AccelOpt's capability improves over time, boosting the average percentage of peak throughput from $49\\%$ to $61\\%$ on Trainium 1 and from $45\\%$ to $59\\%$ on Trainium 2 for NKIBench kernels. Moreover, AccelOpt is highly cost-effective: using open-source models, it matches the kernel improvements of Claude Sonnet 4 while being $26\\times$ cheaper.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-11-19",
        "category": "cs.CL",
        "crawl_time": "2025-11-21T11:00:05.904848",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建了一个名为AccelOpt的**自我改进的LLM智能体系统**。这直接命中了您研究范围中的核心方向：**自我演化**。它并非简单地将LLM作为工具应用于AI加速器领域，而是提出了一种让智能体通过经验**自主迭代和提升**的新方法论。其核心机制——“通过迭代生成探索优化空间”和“利用优化记忆整理过往经验”——是典型的智能体自我演化框架。因此，它不属于“非演化型应用”的排除范畴。 2.  **正面指标 (第二步):** 论文包含了多个您关注的核心关键词和概念： *   **核心范式:** `LLM-based Agents`, `Self-Evolving` (标题和摘要中的 \"Self-Improving\" 和 \"improves over time\")。 *   **智能体能力:** `Memory` (摘要明确提到 \"optimization memory\")。 *   **演化机制:** `Self-Improvement`, `Iterative Improvement` (摘要中的 \"self-improving\", \"iterative generation\", \"improves over time\")。 3.  **排除标准 (第三步):** 论文的主要贡献不涉及安全、对齐、可解释性或多模态视觉，因此没有触发任何排除标准。 4.  **特殊和模糊情况处理 (第四步):** 这是最关键的一点。该论文是“自我演化的应用”的完美范例。根据您的筛选标准第四条：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” AccelOpt正是这样一个案例：它的应用场景是“AI加速器内核优化”，但其核心价值在于那个能够**从“慢-快内核对”中学习并不断自我完善**的智能体系统本身。这个“优化记忆”和迭代改进的框架是具有普适性的智能体演化机制，远超出了特定领域的应用价值。 **最终决策 (第五步):** 综合以上分析，该论文的本质是提出并验证了一个具有**自我演化**能力的LLM智能体框架，其核心贡献在于智能体的构建和演化机制，而非其在特定领域的应用结果。这完全契合您关于“LLM智能体及其演化”的研究课题，特别是“自我演化”这一核心方向。因此，应判定为符合要求。"
    },
    {
        "index": "#52",
        "title": "Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning",
        "link": "/arxiv/2511.16043",
        "arxiv_id": "2511.16043",
        "authors": "Peng Xia, Kaide Zeng, Jiaqi Liu, Can Qin, Fang Wu, Yiyang Zhou, Caiming Xiong, Huaxiu Yao",
        "summary": "Large Language Model (LLM) Agents, often trained with Reinforcement Learning (RL), are constrained by a dependency on human-curated data, limiting scalability and tethering AI to human knowledge. Existing self-evolution frameworks offer an alternative but are typically restricted by the model's inherent capabilities and single-round interactions, hindering the development of complex curricula involving tool use or dynamic reasoning. We introduce Agent0, a fully autonomous framework that evolves high-performing agents without external data through multi-step co-evolution and seamless tool integration. Agent0 establishes a symbiotic competition between two agents initialized from the same base LLM: a curriculum agent that proposes increasingly challenging frontier tasks, and an executor agent that learns to solve them. We integrate external tools to enhance the executor's problem-solving capacity; this improvement, in turn, pressures the curriculum agent to construct more complex, tool-aware tasks. Through this iterative process, Agent0 establishes a self-reinforcing cycle that continuously produces high-quality curricula. Empirically, Agent0 substantially boosts reasoning capabilities, improving the Qwen3-8B-Base model by 18% on mathematical reasoning and 24% on general reasoning benchmarks. Code is available at https://github.com/aiming-lab/Agent0.",
        "subjects": "Machine Learning",
        "date": "2025-11-20",
        "category": "cs.LG",
        "crawl_time": "2025-11-21T11:00:06.211715",
        "filter_reason": "这篇论文完全符合你的研究范围，是一个高度相关的理想筛选对象。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具去解决某个特定领域的问题，而是提出了一种全新的、名为 **Agent0 的框架**。其核心贡献在于构建和演化LLM智能体的**方法论**本身。论文明确指出，这是一个“fully autonomous framework that evolves high-performing agents”，这直接命中了你“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文摘要中包含了大量你的核心关注点，这进一步确认了其高度相关性： - **核心范式**: `Self-Evolving` (标题和摘要多次强调), `LLM-based Agents`, `Multi-Agent Systems` (通过co-evolution体现)。 - **智能体能力**: `Tool Use / Tool Augmentation` (明确提及 \"seamless tool integration\")。 - **多智能体**: `Collaboration` (通过 \"symbiotic competition\" 和 \"co-evolution\" 体现)。 - **演化机制**: `Self-Improvement`, `Iterative Improvement` (通过 \"self-reinforcing cycle\" 和 \"iterative process\" 体现)。 3.  **第三步：排除标准** - 论文的主要贡献是关于提升智能体的能力和演化机制，完全不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐主题。 - 论文也未将 `Vision` 或多模态作为研究核心，`Tool Use` 是作为增强智能体推理能力的手段，符合你的要求。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化”机制本身的绝佳范例。它不是简单应用一个已有的演化框架，而是**提出了一种新的自我演化机制**（通过课程智能体和执行者智能体的协同演化）。即使它在数学和通用推理基准上进行了测试，其核心价值在于这个机制本身，因此完全符合保留条件。 - **推理/规划**: 论文涉及的是智能体层面的推理（`Tool-Integrated Reasoning`），通过工具和迭代循环解决复杂任务，而不是改进LLM底层的数学或逻辑推理能力。这符合你关于智能体规划的保留标准。 **最终决策**: 这篇论文的核心贡献是 **Agent0**，一个通过**多智能体协同演化**和**工具集成**来实现LLM智能体**自我演化**的框架。它完美地覆盖了你研究的三个核心方向： 1.  **单智能体**: 执行者智能体通过使用工具来增强能力。 2.  **多智能体**: 课程智能体和执行者智能体之间形成共生竞争关系。 3.  **自我演化**: 整个框架在没有外部数据的情况下，通过一个自我强化的循环不断迭代，实现智能体的自我完善。 因此，这篇论文不仅符合，而且是“LLM智能体及其演化”这一课题下的典型前沿研究，应予以保留。"
    },
    {
        "index": "#73",
        "title": "Extending Test-Time Scaling: A 3D Perspective with Context, Batch, and Turn",
        "link": "/arxiv/2511.15738",
        "arxiv_id": "2511.15738",
        "authors": "Chao Yu, Qixin Tan, Jiaxuan Gao, Shi Yu, Hong Lu, Xinting Yang, Zelai Xu, Yu Wang, Yi Wu, Eugene Vinitsky",
        "summary": "Reasoning reinforcement learning (RL) has recently revealed a new scaling effect: test-time scaling. Thinking models such as R1 and o1 improve their reasoning accuracy at test time as the length of the reasoning context increases. However, compared with training-time scaling, test-time scaling is fundamentally limited by the limited context length of base models, which remains orders of magnitude smaller than the amount of tokens consumed during training. We revisit test-time enhancement techniques through the lens of scaling effect and introduce a unified framework of multi-dimensional test-time scaling to extend the capacity of test-time reasoning. Beyond conventional context-length scaling, we consider two additional dimensions: batch scaling, where accuracy improves with parallel sampling, and turn scaling, where iterative self-refinement enhances reasoning quality. Building on this perspective, we propose 3D test-time scaling, which integrates context, batch, and turn scaling. We show that: (1) each dimension demonstrates a test-time scaling effect, but with a bounded capacity; (2) combining all three dimensions substantially improves the reasoning performance of challenging testbeds, including IOI, IMO, and CPHO, and further benefits from human preference feedback; and (3) the human-in-the-loop framework naturally extends to a more open-ended domain, i.e., embodied learning, which enables the design of humanoid control behaviors.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.LG",
        "crawl_time": "2025-11-21T11:00:06.231972",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于提出了一种促进LLM智能体自我演化的新框架。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单应用LLM，也不是提升LLM的基础推理能力，而是提出一个名为“3D test-time scaling”的**新框架**。这个框架旨在通过多个维度来扩展和增强LLM在测试时的推理能力，其核心机制之一就是“自我演化”。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点。最关键的是，它提出了“turn scaling”这一维度，其核心机制是“**iterative self-refinement**”（迭代式自我完善）。这直接命中了您研究焦点中的“**自我演化**”方向，以及其子方向“**自我反思**”、“**自我完善**”和“**迭代改进**”。虽然论文也涉及“规划”，但其核心创新点在于演化机制，而非规划本身。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐或多模态视觉。虽然提到了“embodied learning”（具身学习），但这只是作为其框架的一个应用示例，并非研究的核心。研究的核心是那个普适性的“3D缩放框架”。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文不是在提出一种新的非Agentic的推理技巧（如一种新的CoT变体），而是在构建一个**框架**来管理和增强推理过程。这个框架通过“turn scaling”实现了自我反思和迭代优化，这属于智能体的范畴，而非单纯的模型能力提升。 - **自我演化的应用**: 论文的核心贡献正是提出了一种新的“自我演化”机制（即通过turn scaling实现的iterative self-refinement）。即使它被应用在数学竞赛（IMO）或具身学习等特定领域，根据您的规则，这种提出新机制的论文也应该被保留。 **核心依据总结**: 该论文的核心贡献是“3D test-time scaling”框架，而其最具创新性和相关性的部分是“turn scaling”维度，它通过“iterative self-refinement”实现了智能体的**自我完善和迭代演化**。这完全契合您“自我演化”的研究方向。因此，这篇论文是关于**构建和演化LLM智能体方法论**的前沿研究，应当被保留。"
    },
    {
        "index": "#116",
        "title": "Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems",
        "link": "/arxiv/2511.15715",
        "arxiv_id": "2511.15715",
        "authors": "Yash Raj Singh",
        "summary": "Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces. We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks. We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective. This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-11-11",
        "category": "cs.LG",
        "crawl_time": "2025-11-21T11:00:06.289409",
        "filter_reason": "这篇论文完全符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一个名为“Graph-Memoized Reasoning”的**新框架**。这个框架旨在解决LLM智能体在推理过程中的效率问题，通过引入图结构化记忆来存储和重用过去的推理工作流。这直接属于“构建、改进或演化LLM智能体”的范畴，而不是将现有智能体作为工具应用到某个特定领域。它关注的是智能体内部机制的改进，因此通过了第一步的核心判断。 2.  **第二步：正面指标** - 论文摘要中包含了多个与你研究焦点高度相关的核心关键词和概念： - **智能体能力**: `Memory` (graph-structured memory), `Planning` (reasoning workflows, decision graphs)。 - **演化机制**: `Self-Improvement` (摘要明确指出该框架为“self-improving reasoning architectures”奠定了基础)。 - **核心范式**: 摘要结尾明确提到这是“a step toward persistent memory in large-scale **agentic systems**”，直接点明了其研究目标是智能体系统。 - 这些正面指标强烈表明该论文与你的研究课题高度相关。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐或多模态。虽然摘要中提到了“interpretable”（可解释性），但这只是该框架带来的一个**附带好处**，而非论文的核心研究目标。论文的核心是记忆化和工作流重用机制，因此不触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何进行规划和推理的典型范例。它不是在提升LLM本身的基础数学或逻辑能力，而是在构建一个更高层次的框架（类似于ReAct或ToT），让智能体能够更高效、更持久地进行多步推理。这完全符合“保留”的条件。 - **自我演化**: 论文提出的框架通过记忆和重用过去的成功经验，使得智能体系统能够“自我改进”，这直接命中了你“自我演化”的研究方向。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种创新的、旨在增强LLM智能体记忆和规划能力的新框架。它不仅直接关联到“单智能体”方向（记忆、规划），还触及了“自我演化”方向（自我改进）。论文的本质是方法论创新，而非应用或基础设施研究，且完全避开了所有排除标准。因此，这篇论文是与你研究课题“LLM智能体及其演化”高度相关的前沿文献，应予以保留。"
    },
    {
        "index": "#4",
        "title": "Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization",
        "link": "/arxiv/2511.16602",
        "arxiv_id": "2511.16602",
        "authors": "Yi Zhang, Che Liu, Xiancong Ren, Hanchu Ni, Yingji Zhang, Shuai Zhang, Zeyuan Ding, Jiayu Hu, Haozhe Shan, Junbo Qi, Yan Bai, Dengjie Li, Jiachen Luo, Yidong Wang, Yong Dai, Zenglin Xu, Bin Shen, Qifan Wang, Jian Tang, Xiaozhu Ju",
        "summary": "Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.306115",
        "filter_reason": "这篇论文符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将现有智能体应用于某个领域，而是提出了一种名为“Deliberate Practice Policy Optimization (DPPO)”的**全新训练框架**。这个框架被描述为一个“元认知的元循环”，其核心机制是动态地在监督微调和强化学习之间切换，以实现“自动弱点识别和有针对性的资源分配”。这完全符合您筛选标准中“构建、改进或演化 LLM智能体的方法论或新框架”的要求，特别是属于“自我演化”的范畴。 2.  **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **自我演化:** 这是论文最核心的亮点。DPPO框架本身就是一个自我演化的实现，通过“技能完善”和“能力扩展”的循环，让智能体（或其策略）不断迭代优化。 *   **自我反思/自我修正:** “自动弱点识别”是自我反思和自我修正的直接体现。 *   **Agentic AI:** 论文的目标是构建“通用且多功能的具身智能系统”，这正是Agentic AI的研究对象。 3.  **第三步：排除标准——不适用** *   **安全与对齐:** 论文未涉及安全、对齐、可解释性等内容。 *   **多模态与视觉:** 这是本案例最关键的一点。虽然论文标题和摘要中明确提到了`VLMs`（视觉语言模型），但根据您的核心规则，需要判断它是“研究的核心”还是“智能体感知环境的工具”。摘要明确指出，DPPO是一个“训练框架”，而VLM是这个框架作用的对象，即具身智能体的“感知模块”。论文的核心贡献是**DPPO这个训练方法**，而不是VLM本身。因此，视觉部分是作为智能体能力的一部分被包含的，而不是研究的焦点，不应因此排除。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 本案例完美契合了您设定的“自我演化的应用”这一特殊规则： > **保留 (例外):** 按照你的要求，如果论文的核心是提出一种新的“自我演化”机制，即使它被应用在特定领域（如“用于化学实验的自我演化智能体”），也应该保留。 这篇论文的核心正是提出了一种新的“自我演化”机制（DPPO），并将其应用在“具身智能”这个特定领域。因此，根据此规则，必须保留。 **最终决策:** 综合以上分析，尽管论文涉及视觉（VLM），但这只是作为具身智能体感知世界的工具。其**核心贡献是DPPO这一创新的、旨在实现智能体自我演化的训练框架**。这完全符合您“LLM智能体及其演化”的研究课题，特别是“自我演化”这一核心方向。因此，最终判断为 **True**。"
    },
    {
        "index": "#15",
        "title": "CorrectHDL: Agentic HDL Design with LLMs Leveraging High-Level Synthesis as Reference",
        "link": "/arxiv/2511.16395",
        "arxiv_id": "2511.16395",
        "authors": "Kangwei Xu, Grace Li Zhang, Ulf Schlichtmann, Bing Li",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable potential in hardware front-end design using hardware description languages (HDLs). However, their inherent tendency toward hallucination often introduces functional errors into the generated HDL designs. To address this issue, we propose the framework CorrectHDL that leverages high-level synthesis (HLS) results as functional references to correct potential errors in LLM-generated HDL designs.The input to the proposed framework is a C/C++ program that specifies the target circuit's functionality. The program is provided to an LLM to directly generate an HDL design, whose syntax errors are repaired using a Retrieval-Augmented Generation (RAG) mechanism. The functional correctness of the LLM-generated circuit is iteratively improved by comparing its simulated behavior with an HLS reference design produced by conventional HLS tools, which ensures the functional correctness of the result but can lead to suboptimal area and power efficiency. Experimental results demonstrate that circuits generated by the proposed framework achieve significantly better area and power efficiency than conventional HLS designs and approach the quality of human-engineered circuits. Meanwhile, the correctness of the resulting HDL implementation is maintained, highlighting the effectiveness and potential of agentic HDL design leveraging the generative capabilities of LLMs and the rigor of traditional correctness-driven IC design flows.",
        "subjects": "Artificial Intelligence, Programming Languages, Software Engineering, Systems and Control",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.309254",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于硬件设计领域，而是提出了一个名为 **CorrectHDL 的框架**。这个框架的核心是一个包含LLM、工具（HLS工具、RAG机制）和迭代反馈循环的**智能体工作流**。它通过“生成-验证-比较-修正”的闭环流程，实现了对LLM生成结果的迭代式优化。这本质上是在**构建一个具有自我纠正能力的LLM智能体**，而非仅仅将其作为一次性工具使用。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** 论文明确包含了多个核心关注点： *   **核心范式**: 标题和摘要中直接使用了 `Agentic HDL Design`，明确其智能体属性。 *   **智能体能力**: 论文框架体现了 `Tool Use`（使用HLS工具作为参考、使用RAG修复语法错误）和 `Self-Correction`（通过与HLS结果比较来迭代修正功能错误）。 *   **演化机制**: 摘要中明确提到 `iteratively improved`，这直接对应了 `Iterative Improvement` 和 `Self-Refine` 的演化机制。 3.  **第三步：排除标准——不适用** *   **安全与对齐**: 论文虽然解决了LLM在特定任务中的“幻觉”问题，但其目标是保证生成HDL的**功能正确性**，而非研究通用的LLM安全、对齐或可解释性。其贡献在于智能体框架，而非安全技术。 *   **多模态与视觉**: 论文处理的是文本输入（C/C++）和文本输出（HDL），不涉及多模态内容。 4.  **第四步：处理特殊和模糊情况——符合保留条件** *   **自我演化的应用**: 这篇论文是“自我演化应用”的一个绝佳范例。尽管它应用于硬件设计这一特定领域，但其核心贡献是提出了一种**新的自我演化/自我纠正机制**（即通过与HLS参考对比进行迭代优化）。根据筛选规则，这种提出新机制的论文应该被保留。 **最终决策**: 该论文的核心贡献是构建了一个名为CorrectHDL的智能体框架，该框架集成了工具使用（HLS、RAG）和迭代式自我纠正机制，以完成复杂的硬件设计任务。这完全符合我研究课题中“单智能体”和“自我演化”两个核心方向。因此，这篇论文应被**保留**。"
    },
    {
        "index": "#16",
        "title": "An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models",
        "link": "/arxiv/2511.16383",
        "arxiv_id": "2511.16383",
        "authors": "Alexander Zadorojniy, Segev Wasserkrug, Eitan Farchi",
        "summary": "Recently, using Large Language Models (LLMs) to generate optimization models from natural language descriptions has became increasingly popular. However, a major open question is how to validate that the generated models are correct and satisfy the requirements defined in the natural language description. In this work, we propose a novel agent-based method for automatic validation of optimization models that builds upon and extends methods from software testing to address optimization modeling . This method consists of several agents that initially generate a problem-level testing API, then generate tests utilizing this API, and, lastly, generate mutations specific to the optimization model (a well-known software testing technique assessing the fault detection power of the test suite). In this work, we detail this validation framework and show, through experiments, the high quality of validation provided by this agent ensemble in terms of the well-known software testing measure called mutation coverage.",
        "subjects": "Artificial Intelligence, Software Engineering",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.309526",
        "filter_reason": "这篇论文符合我的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于数学优化领域，而是**提出了一种新颖的、由多个智能体协作组成的框架**来解决“验证”这一特定挑战。论文详细描述了该框架的构成：包含多个专门的智能体，它们分别负责生成测试API、生成测试用例、以及生成模型变异。这本质上是在**构建和设计一个多智能体系统**，其方法论是论文的核心创新点，而非仅仅是应用。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **`Multi-Agent Systems (MAS)`**: 摘要中直接提到 \"several agents\" 和 \"agent ensemble\"，清晰地表明这是一个多智能体系统。 - **`Collaboration`**: 多个智能体（生成API的、生成测试的、生成变异的）协同工作，共同完成验证任务，这体现了智能体间的协作。 - **`Tool Use / Tool Augmentation`**: 智能体首先生成一个 \"problem-level testing API\"，然后其他智能体利用这个API来执行任务。这完全符合智能体创造并使用工具来解决复杂问题的范式。 - **`Planning`**: 整个流程（先生成API，再生成测试，最后生成变异）是一个结构化的多步骤规划过程，展示了智能体如何分解和执行复杂任务。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等领域。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文是关于智能体如何进行规划和执行多步骤任务的典型案例。它不是在提升LLM的基础数学推理能力，而是在构建一个智能体框架来验证数学模型，这完全符合“保留”的条件。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建了一个新颖的多智能体协作框架**，该框架通过规划、工具使用和智能体间的协作来完成复杂的模型验证任务。这完全契合我研究课题中的“多智能体”方向，并触及了单智能体的“规划”和“工具使用”能力。因此，尽管其应用领域是数学优化，但其方法论上的创新使其成为一篇高度相关的前沿论文，应被保留。"
    },
    {
        "index": "#23",
        "title": "ChemLabs on ChemO: A Multi-Agent System for Multimodal Reasoning on IChO 2025",
        "link": "/arxiv/2511.16205",
        "arxiv_id": "2511.16205",
        "authors": "Xu Qiang, Shengyuan Bai, Leqing Chen, Zijing Liu, Yu Li",
        "summary": "Olympiad-level benchmarks in mathematics and physics are crucial testbeds for advanced AI reasoning, but chemistry, with its unique multimodal symbolic language, has remained an open challenge. We introduce ChemO, a new benchmark built from the International Chemistry Olympiad (IChO) 2025. ChemO features two key innovations for automated assessment: Assessment-Equivalent Reformulation (AER), which converts problems requiring visual outputs (e.g., drawing molecules) into computationally tractable formats, and Structured Visual Enhancement (SVE), a diagnostic mechanism to disentangle a model's visual perception capabilities from its core chemical reasoning. To tackle this benchmark, we propose ChemLabs, a hierarchical multi-agent framework that mimics human expert collaboration through specialized agents for problem decomposition, perception, reasoning, and auditing. Experiments on state-of-the-art multimodal models demonstrate that combining SVE with our multi-agent system yields dramatic performance gains. Our top configuration achieves a score of 93.6 out of 100, surpassing an estimated human gold medal threshold and establishing a new state-of-the-art in automated chemical problem-solving. ChemO Dataset: https://huggingface.co/datasets/IDEA-AI4SCI/ChemO",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.311472",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **论文的本质是什么？** 论文的核心贡献是提出了一个名为 **ChemLabs** 的**分层多智能体框架**。虽然论文也包含一个化学领域的基准，但其核心方法论创新在于构建了一个新的多智能体系统来解决复杂问题。 - **是否符合保留标准？** 符合。论文的核心是关于**构建多智能体系统（Multi-Agent Systems）**的方法论，这直接命中了研究范围的第二个核心方向。它不是简单地将一个已有的智能体框架（如ReAct）应用到化学领域，而是设计了一个具有专门角色（问题分解、感知、推理、审计）的新颖多智能体架构。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` (标题和摘要中明确指出 \"a hierarchical multi-agent framework\")。 - **多智能体**: `Collaboration` (摘要中提到 \"mimics human expert collaboration\")，以及通过不同智能体角色（分解、感知、推理、审计）所隐含的 `Communication` 和协作机制。 - **智能体能力**: `Planning` (通过 \"problem decomposition\" 体现) 和 `Reasoning` (通过 \"reasoning\" agent 体现)。 3.  **第三步：排除标准** - **安全与对齐**: 论文不涉及安全、对齐、可解释性等内容。 - **多模态与视觉**: 论文涉及 \"multimodal reasoning\" 和 \"visual perception\"，这是一个潜在的排除点。但是，根据核心规则，**视觉在这里是作为智能体感知环境的工具**（论文中有一个专门的 \"perception\" agent），而不是研究的核心。研究的核心是**如何组织多个智能体（包括感知智能体）进行协作**来解决化学问题。因此，这完全符合“除非它们被用作智能体感知环境的工具”的例外情况，不应被排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的推理部分是由多智能体框架驱动的，属于智能体在复杂任务中的多步推理，符合保留条件。 5.  **第五步：最终决策** - 综合以上分析，尽管论文的应用领域是化学，并且涉及多模态，但其**最核心的贡献是提出了一种新颖的多智能体协作框架**。这个框架的设计、实现和验证是论文的精髓，完全符合“构建、改进LLM智能体”以及“多智能体”的研究目标。因此，这篇论文是高度相关的前沿研究，应被保留。"
    },
    {
        "index": "#28",
        "title": "SkyRL-Agent: Efficient RL Training for Multi-turn LLM Agent",
        "link": "/arxiv/2511.16108",
        "arxiv_id": "2511.16108",
        "authors": "Shiyi Cao, Dacheng Li, Fangzhou Zhao, Shuo Yuan, Sumanth R. Hegde, Connor Chen, Charlie Ruan, Tyler Griggs, Shu Liu, Eric Tang, Richard Liaw, Philipp Moritz, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica",
        "summary": "We introduce SkyRL-Agent, a framework for efficient, multi-turn, long-horizon agent training and evaluation. It provides efficient asynchronous dispatching, lightweight tool integration, and flexible backend interoperability, enabling seamless use with existing RL frameworks such as SkyRL-train, VeRL, and Tinker. Using SkyRL-Agent, we train SA-SWE-32B, a software engineering agent trained from Qwen3-32B (24.4% Pass@1) purely with reinforcement learning. We introduce two key components: an optimized asynchronous pipeline dispatcher that achieves a 1.55x speedup over naive asynchronous batching, and a tool-enhanced training recipe leveraging an AST-based search tool to facilitate code navigation, boost rollout Pass@K, and improve training efficiency. Together, these optimizations enable SA-SWE-32B to reach 39.4% Pass@1 on SWE-Bench Verified with more than 2x cost reduction compared to prior models reaching similar performance. Despite being trained solely on SWE tasks, SA-SWE-32B generalizes effectively to other agentic tasks, including Terminal-Bench, BrowseComp-Plus, and WebArena. We further demonstrate SkyRL-Agent's extensibility through case studies on deep research, computer use, and memory agents, each trained using a different training backend.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.313020",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为 **SkyRL-Agent 的框架**，用于高效地训练和演化 LLM 智能体。这直接命中了您“构建、改进或演化 LLM 智能体”的核心目标。它不是简单地将一个已有的智能体应用到软件工程领域，而是提出了一种新的**训练方法论**和**系统框架**，使智能体本身的能力得到提升和演化。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** 论文包含了您多个核心关注点： *   **单智能体**: 论文的核心是训练一个能够进行多轮、长视野任务的软件工程智能体。其关键贡献之一是“**工具增强的训练配方**”，这直接对应了“工具使用”这一核心能力。 *   **自我演化**: 整个框架的核心是使用**强化学习**来训练智能体。RL 是一种典型的通过环境反馈进行自我完善和迭代的机制，完全符合“自我演化”的定义。论文中提到的“从 Qwen3-32B 训练而来”以及性能的提升，都体现了智能体的演化过程。 3.  **第三步：排除标准——未命中** 论文的主要贡献不涉及安全、对齐、可解释性或多模态视觉。虽然智能体使用了一个基于AST的搜索工具，但这是一个文本/代码工具，而非视觉感知工具，且它服务于智能体的核心能力（工具使用），而非研究本身。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **自我演化的应用**: 论文将 SkyRL-Agent 框架应用于软件工程领域。根据您的规则，这属于“自我演化的应用”的例外情况。其核心贡献是**提出了一种新的自我演化机制**，而非应用本身。SWE-Bench 只是用来验证该机制有效性的实验场。 *   **基础设施**: 论文提到的“异步调度”和“后端互操作性”等优化，虽然听起来像基础设施，但其上下文是**专门为智能体训练过程服务的**。这些优化的目的是提升智能体训练的效率和效果，是构建和演化智能体方法论的一部分，而非通用的模型部署或硬件加速基础设施。 **最终决策**: 该论文的核心贡献在于提出了一种用于训练和演化 LLM 智能体的新框架和高效训练方法，重点提升了智能体的工具使用能力和通过强化学习进行自我演化的效率。这完全契合您在“单智能体”和“自我演化”方向的研究目标。因此，应予以保留。"
    },
    {
        "index": "#24",
        "title": "Multi-Agent Collaborative Reward Design for Enhancing Reasoning in Reinforcement Learning",
        "link": "/arxiv/2511.16202",
        "arxiv_id": "2511.16202",
        "authors": "Pei Yang, Ke Zhang, Ji Wang, Xiao Chen, Yuxin Tang, Eric Yang, Lynn Ai, Bill Shi",
        "summary": "We present CRM (Multi-Agent Collaborative Reward Model), a framework that replaces a single black-box reward model with a coordinated team of specialist evaluators to improve robustness and interpretability in RLHF. Conventional reward models struggle to jointly optimize multiple, sometimes conflicting, preference dimensions (e.g., factuality, helpfulness, safety) and offer limited transparency into why a score is assigned. CRM addresses these issues by decomposing preference evaluation into domain-specific agents that each produce partial signals, alongside global evaluators such as ranker-based and embedding-similarity rewards. A centralized aggregator fuses these signals at each timestep, balancing factors like step-wise correctness, multi-agent agreement, and repetition penalties, yielding a single training reward compatible with standard RL pipelines. The policy is optimized with advantage-based updates (e.g., GAE), while a value model regresses to the aggregated reward, enabling multi-perspective reward shaping without requiring additional human annotations beyond those used to train the evaluators. To support training and assessment, we introduce rewardBench, a benchmark and training suite aligned with the collaborative structure of CRM. Together, CRM and rewardBench provide a practical, modular path to more transparent reward modeling and more stable optimization.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.311854",
        "filter_reason": "这篇论文符合我的研究范围，应被保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一个名为CRM（Multi-Agent Collaborative Reward Model）的**新框架**。这个框架的本质不是将现有技术应用于某个领域，而是**构建了一个多智能体系统**来改进强化学习中的奖励模型设计。奖励模型是训练LLM智能体（尤其是在RLHF范式中）的关键组件，因此，改进奖励模型的设计方法，等同于在**改进LLM智能体的构建和训练方法**。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文高度符合我的核心关注点。标题和摘要中明确包含了多个正面指标： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。CRM框架由一个“coordinated team of specialist evaluators”（协调的专家评估团队）构成，这正是多智能体系统的体现。 - **多智能体**: 论文的核心机制是 `Collaboration`（协作）。这些“specialist agents”协同工作，分解复杂的偏好评估任务，并由一个聚合器融合它们的信号。这直接命中了“智能体间的协作”这一子方向。 3.  **第三步：排除标准** - 论文虽然提到了“improve robustness and interpretability”，但这并非其主要贡献。论文的**核心是提出“多智能体协作”这一方法论**，而“提升可解释性”是该框架带来的一个**结果或优势**，而非研究本身的主题。如果一篇论文的主要工作是提出一种新的可解释性理论或方法，那么它会被排除。但在这里，可解释性是作为多智能体设计的一个附带好处来讨论的，因此不触发排除标准。 - 论文不涉及安全、对齐或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的目标是“Enhancing Reasoning”，但其实现方式并非直接提出一个新的推理链（如CoT变体），而是通过改进训练智能体的**奖励信号**来间接提升其推理能力。这属于“改进LLM智能体”的范畴，因为奖励模型是塑造智能体行为（包括其规划和推理能力）的根本。因此，它符合保留条件。 **总结**: 该论文的核心贡献在于提出了一种新颖的**多智能体协作框架（CRM）**，用于改进LLM智能体训练中的关键环节——奖励模型设计。它直接命中了我的研究焦点中的“多智能体”方向，特别是“协作”子方向。虽然它触及了可解释性，但这并非其核心贡献。因此，这篇论文是关于如何通过多智能体系统来**构建和改进LLM智能体**的前沿研究，完全符合筛选要求。"
    },
    {
        "index": "#37",
        "title": "KRAL: Knowledge and Reasoning Augmented Learning for LLM-assisted Clinical Antimicrobial Therapy",
        "link": "/arxiv/2511.15974",
        "arxiv_id": "2511.15974",
        "authors": "Zhe Li, Yehan Qiu, Yujie Chen, Xiang Zhou",
        "summary": "Clinical antimicrobial therapy requires the dynamic integration of pathogen profiles, host factors, pharmacological properties of antimicrobials, and the severity of infection.This complexity imposes fundamental limitations on the applicability of Large Language Models (LLMs) in high-stakes clinical decision-making including knowledge gaps, data privacy concerns, high deployment costs, and limited reasoning capabilities. To address these challenges, we propose KRAL (Knowledge and Reasoning Augmented Learning), a low-cost, scalable, privacy-preserving paradigm that leverages teacher-model reasoning to automatically distill knowledge and reasoning trajectories via answer-to-question reverse generation, employs heuristic learning for semi-supervised data augmentation (reducing manual annotation requirements by approximately 80%), and utilizes agentic reinforcement learning to jointly enhance medical knowledge and reasoning while optimizing computational and memory efficiency. A hierarchical evaluation employing diverse teacher-model proxies reduces assessment costs, while modular interface design facilitates seamless system updates. Experimental results demonstrate that KRAL significantly outperforms traditional Retrieval-Augmented Generation (RAG) and Supervised Fine-Tuning (SFT) methods. It improves knowledge question-answering capability (Accuracy@1 on the external open-source benchmark MEDQA increased by 1.8% vs. SFT and 3.6% vs. RAG) and reasoning capability (Pass@1 on the external benchmark PUMCH Antimicrobial increased by 27% vs. SFT and 27.2% vs. RAG), achieved at ~20% of SFT's long-term training costs. This establishes KRAL as an effective solution for enhancing local LLMs' clinical diagnostic capabilities, enabling low-cost, high-safety deployment in complex medical decision support.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.315475",
        "filter_reason": "这篇论文符合您的研究范围，核心判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非简单地将LLM应用于医疗领域，而是提出了一种名为KRAL的**新范式/方法论**。这个方法论的核心是利用“智能体强化学习”来联合增强模型的知识和推理能力。这超越了“非演化型应用”的范畴，进入了“构建、改进或演化LLM智能体”的领域。因此，根据第一步的“保留”标准，应予以保留。 2.  **正面指标 (第二步):** 论文明确包含了多个核心关注点。 *   **核心范式:** 论文的核心机制是 `agentic reinforcement learning`，直接命中 `Agentic AI` 和 `Self-Evolving`。 *   **演化机制:** 通过强化学习进行“联合增强医学知识和推理”，这是一种明确的 `Self-Improvement` 和 `Iterative Improvement` 机制。 3.  **排除标准 (第三步):** 论文虽然提到了“高安全性部署”，但这只是其方法带来的一个优点，并非论文的核心研究贡献。论文的核心是KRAL框架本身，而不是安全、对齐或可解释性研究。因此，不触发排除标准。 4.  **特殊和模糊情况处理 (第四步):** *   **自我演化的应用:** 这篇论文是“自我演化的应用”这一例外情况的完美范例。尽管其应用领域是特定的（临床抗菌治疗），但其**核心贡献是提出了一种新的“自我演化”机制**——即通过智能体强化学习来迭代式地提升模型能力。根据您的规则，这种情况应该保留。 *   **推理/规划:** 论文旨在提升LLM在复杂医疗决策中的“推理能力”，并且是通过“智能体强化学习”这一Agentic框架来实现的，而非仅仅改进LLM的基础Token预测。这符合“保留”关于智能体推理的论文的标准。 **最终决策 (第五步):** 综合来看，这篇论文的本质是提出了一种包含“智能体强化学习”组件的新颖学习范式（KRAL），用于实现LLM在特定任务上的自我演化和能力增强。它虽然以医疗领域为应用背景，但其核心贡献在于方法论本身，完全符合您关于“LLM智能体及其演化”中“自我演化”方向的研究目标。因此，最终判断为符合要求。"
    },
    {
        "index": "#46",
        "title": "Multi-Agent LLM Orchestration Achieves Deterministic, High-Quality Decision Support for Incident Response",
        "link": "/arxiv/2511.15755",
        "arxiv_id": "2511.15755",
        "authors": "Philip Drammeh",
        "summary": "Large language models (LLMs) promise to accelerate incident response in production systems, yet single-agent approaches generate vague, unusable recommendations. We present MyAntFarm.ai, a reproducible containerized framework demonstrating that multi-agent orchestration fundamentally transforms LLM-based incident response quality. Through 348 controlled trials comparing single-agent copilot versus multi-agent systems on identical incident scenarios, we find that multi-agent orchestration achieves 100% actionable recommendation rate versus 1.7% for single-agent approaches, an 80 times improvement in action specificity and 140 times improvement in solution correctness. Critically, multi-agent systems exhibit zero quality variance across all trials, enabling production SLA commitments impossible with inconsistent single-agent outputs. Both architectures achieve similar comprehension latency (approx.40s), establishing that the architectural value lies in deterministic quality, not speed. We introduce Decision Quality (DQ), a novel metric capturing validity, specificity, and correctness properties essential for operational deployment that existing LLM metrics do not address. These findings reframe multi-agent orchestration from a performance optimization to a production-readiness requirement for LLM-based incident response. All code, Docker configurations, and trial data are publicly available for reproduction.",
        "subjects": "Artificial Intelligence, Software Engineering",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.318069",
        "filter_reason": "这篇论文完全符合我的研究范围，是一篇高质量的相关论文。以下是我的详细判断过程： 1.  **第一步：核心判断——保留** *   **论文本质**: 这篇论文的核心贡献不是简单地将LLM应用于“事件响应”这个特定领域，而是提出并验证了一种**新的方法论和框架**——即“多智能体编排”。它通过严谨的对照实验，证明了这种多智能体架构相比于单智能体架构，在决策质量上具有根本性的优势。 *   **排除项检查**: *   它不是“非演化型应用”，因为其重点在于**如何构建和编排智能体**，而不是用智能体去解决事件响应问题本身。其结论（多智能体编排能提升质量）是具有普适性的方法论贡献。 *   它不是“非Agentic的推理”，因为它研究的正是智能体如何作为一个系统来生成决策和行动建议，这属于智能体能力范畴。 *   它不是“基础设施”，虽然使用了容器化技术，但这只是为了实现可复现性，论文的核心是智能体架构，而非部署优化。 2.  **第二步：正面指标——高度匹配** *   **核心范式**: 论文标题和摘要中明确包含了 `Multi-Agent LLM Orchestration` 和 `Multi-Agent Systems`，这正是我研究焦点中的“多智能体”方向。 *   **多智能体**: 论文的核心是探讨多个智能体如何通过“编排”来协同工作，这本质上是一种高级的**协作**与**通信**机制。它证明了这种协作能带来“确定性”和“高质量”的输出，这是多智能体研究中的关键议题。 3.  **第三步：排除标准——不适用** *   论文的研究焦点是决策质量、行动特异性和解决方案正确性，没有涉及安全、对齐、可解释性或视觉等多模态内容。因此，所有排除标准均不适用。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文研究的正是智能体在复杂任务（事件响应）中进行多步推理并生成最终决策建议的过程。它比较了单智能体与多智能体两种不同的推理架构，这完全符合“保留”关于智能体如何进行规划或多步推理的论文的规则。 5.  **第五步：最终决策** *   综合以上分析，这篇论文的核心贡献在于**构建和改进了一个多智能体LLM系统**，并通过实证研究揭示了多智能体编排架构在提升决策质量和确定性方面的巨大价值。它直接命中了我的研究焦点“多智能体”，提供了新的框架、评估指标和深刻的见解，是一篇必须保留的前沿论文。"
    },
    {
        "index": "#43",
        "title": "IMACT-CXR - An Interactive Multi-Agent Conversational Tutoring System for Chest X-Ray Interpretation",
        "link": "/arxiv/2511.15825",
        "arxiv_id": "2511.15825",
        "authors": "Tuan-Anh Le, Anh Mai Vu, David Yang, Akash Awasthi, Hien Van Nguyen",
        "summary": "IMACT-CXR is an interactive multi-agent conversational tutor that helps trainees interpret chest X-rays by unifying spatial annotation, gaze analysis, knowledge retrieval, and image-grounded reasoning in a single AutoGen-based workflow. The tutor simultaneously ingests learner bounding boxes, gaze samples, and free-text observations. Specialized agents evaluate localization quality, generate Socratic coaching, retrieve PubMed evidence, suggest similar cases from REFLACX, and trigger NV-Reason-CXR-3B for vision-language reasoning when mastery remains low or the learner explicitly asks. Bayesian Knowledge Tracing (BKT) maintains skill-specific mastery estimates that drive both knowledge reinforcement and case similarity retrieval. A lung-lobe segmentation module derived from a TensorFlow U-Net enables anatomically aware gaze feedback, and safety prompts prevent premature disclosure of ground-truth labels. We describe the system architecture, implementation highlights, and integration with the REFLACX dataset for real DICOM cases. IMACT-CXR demonstrates responsive tutoring flows with bounded latency, precise control over answer leakage, and extensibility toward live residency deployment. Preliminary evaluation shows improved localization and diagnostic reasoning compared to baselines.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-19",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.317249",
        "filter_reason": "这篇论文符合筛选标准，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建一个新颖的多智能体系统**。其核心贡献并非简单地将现有框架（如AutoGen）应用于医学领域，而是设计了一个专门的、由多个专业化智能体（评估、辅导、检索、推理）协同工作的交互式辅导架构。论文详细描述了智能体之间的分工、协作流程、以及它们如何与外部工具（如PubMed、视觉语言模型）和内部状态（贝叶斯知识追踪BKT）进行交互。这完全符合“构建、改进LLM智能体”的核心目标，特别是“多智能体系统”这一方向。它不是“非演化型应用”，因为其创新点在于智能体系统的设计本身，而非其在特定领域的应用效果。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。 - **智能体能力**: 明确提到了 `Tool Use / Tool Augmentation` (使用PubMed, NV-Reason-CXR-3B等) 和 `Memory` (通过BKT模型追踪学习者状态)。 - **多智能体**: 论文的核心就是关于智能体间的 `Collaboration` (协同工作) 和 `Communication` (会话式辅导)。 3.  **第三步：排除标准** - **安全与对齐**: 论文中提到了“安全提示”，但这只是一个实现细节，用于防止在辅导场景中泄露答案，并非论文的主要研究贡献。因此，这不触排除规则。 - **多模态与视觉**: 论文使用了视觉语言模型 `NV-Reason-CXR-3B` 和一个 `U-Net` 分割模块。根据筛选标准，这些是作为**智能体感知环境的工具**而存在的，研究的核心是调用这些工具的智能体架构和决策逻辑，而不是视觉模型本身。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文描述了一个完整的多智能体工作流，智能体根据学习者状态（BKT）和输入来决定下一步行动（评估、辅导、检索或触发推理）。这属于智能体在复杂任务中进行多步规划和决策的范畴，符合保留条件。 - **自我演化的应用**: 此论文不涉及自我演化机制，因此此条不适用。 5.  **第五步：最终决策** - 综合分析，该论文的核心贡献在于提出并实现了一个创新的**多智能体协作框架**，用于解决复杂的交互式辅导任务。它详细阐述了智能体的设计、分工、通信和工具使用机制，这与研究课题中的“多智能体”方向高度契合。尽管其应用场景是特定的医学领域，但其方法论和系统架构对于LLM智能体的构建具有普遍的参考价值。因此，最终判断为 **True**。"
    },
    {
        "index": "#52",
        "title": "ToolMind Technical Report: A Large-Scale, Reasoning-Enhanced Tool-Use Dataset",
        "link": "/arxiv/2511.15718",
        "arxiv_id": "2511.15718",
        "authors": "Chen Yang, Ran Le, Yun Xing, Zhenwei An, Zongchao Chen, Wayne Xin Zhao, Yang Song, Tao Zhang",
        "summary": "Large Language Model (LLM) agents have developed rapidly in recent years to solve complex real-world problems using external tools. However, the scarcity of high-quality trajectories still hinders the development of stronger LLM agents. Most existing works on multi-turn dialogue synthesis validate correctness only at the trajectory level, which may overlook turn-level errors that can propagate during training and degrade model performance. To address these limitations, we introduce ToolMind, a large-scale, high-quality tool-agentic dataset with 160k synthetic data instances generated using over 20k tools and 200k augmented open-source data instances. Our data synthesis pipeline first constructs a function graph based on parameter correlations and then uses a multi-agent framework to simulate realistic user-assistant-tool interactions. Beyond trajectory-level validation, we employ fine-grained turn-level filtering to remove erroneous or suboptimal steps, ensuring that only high-quality reasoning traces are retained. This approach mitigates error amplification during training while preserving self-corrective reasoning signals essential for robust tool-use learning. Models fine-tuned on ToolMind show significant improvements over baselines on several benchmarks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.319685",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的核心贡献并非将LLM智能体作为工具去解决某个外部领域（如生物、金融）的问题，而是提出了一种**构建和改进LLM智能体**的基础性方法论和资源。具体来说，它贡献了一个高质量的工具使用数据集（ToolMind）和一个用于生成该数据集的**多智能体合成框架**。这直接服务于“构建、改进或演化LLM智能体”的核心目标，因为它解决了当前LLM智能体发展中“高质量轨迹稀缺”的关键瓶颈。因此，它不属于“非演化型应用”或“基础设施”的排除范畴。 **第二步：正面指标** - 该论文命中了多个核心正面指标，与您的研究焦点高度契合： - **核心范式**: 论文明确围绕 `LLM-based Agents` 展开，并提出了一个 `Multi-Agent Systems (MAS)` 框架来生成数据。 - **智能体能力**: 论文的核心是 `Tool Use / Tool Augmentation`。同时，其数据过滤机制旨在保留 `Self-Correction`（自我纠正）的推理信号，这与单智能体的自我反思能力直接相关。 - **多智能体**: 论文明确提到“uses a multi-agent framework to simulate realistic user-assistant-tool interactions”，这直接命中了您对多智能体协作与交互的研究方向。 - **演化机制**: 虽然论文本身不是关于智能体在任务中的自我演化，但其提供的“self-corrective reasoning signals”是训练智能体具备自我完善能力的关键数据基础，属于演化机制的前置研究。 **第三步：排除标准** - 论文未涉及任何排除标准。其核心贡献是关于数据质量和智能体能力提升，而非 `Safety`、`Alignment` 或 `Vision` 等方向。 **第四步：处理特殊和模糊情况** - **推理/规划**: 论文关注的是智能体在多轮工具使用中的“reasoning traces”（推理轨迹），这属于智能体在复杂任务中的多步推理范畴，符合保留条件。它并非研究LLM本身的基础数学或逻辑能力。 **最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种**利用多智能体框架来构建高质量工具使用数据集的新方法**。这个方法直接服务于提升LLM智能体的工具使用和自我纠正能力，是构建更强智能体的关键一步。它不仅触及了“单智能体”的工具使用和自我反思，还创新性地运用了“多智能体”框架来生成训练数据，与您的研究目标高度一致。因此，应判定为 **True (保留)**。"
    },
    {
        "index": "#88",
        "title": "Robot Metacognition: Decision Making with Confidence for Tool Invention",
        "link": "/arxiv/2511.16390",
        "arxiv_id": "2511.16390",
        "authors": "Ajith Anil Meera, Poppy Collis, Polina Arbuzova, Abián Torres, Paul F Kinghorn, Ricardo Sanz, Pablo Lanillos",
        "summary": "Robots today often miss a key ingredient of truly intelligent behavior: the ability to reflect on their own cognitive processes and decisions. In humans, this self-monitoring or metacognition is crucial for learning, decision making and problem solving. For instance, they can evaluate how confident they are in performing a task, thus regulating their own behavior and allocating proper resources. Taking inspiration from neuroscience, we propose a robot metacognition architecture centered on confidence (a second-order judgment on decisions) and we demonstrate it on the use case of autonomous tool invention. We propose the use of confidence as a metacognitive measure within the robot decision making scheme. Confidence-informed robots can evaluate the reliability of their decisions, improving their robustness during real-world physical deployment. This form of robotic metacognition emphasizes embodied action monitoring as a means to achieve better informed decisions. We also highlight potential applications and research directions for robot metacognition.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.330167",
        "filter_reason": "这篇论文符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一种“机器人元认知架构”。这并非简单地将现有智能体框架应用于机器人领域，而是构建了一个**新的方法论和框架**，旨在赋予智能体（机器人）一种新的核心能力：元认知。这直接命中了你筛选标准中“构建、改进或演化 LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文高度符合你的核心关注点。摘要中明确提到了 `Metacognition`（元认知），这正是 `Self-Reflection`（自我反思）和 `Self-Correction`（自我修正）的高级形式。 - 论文的核心机制是“confidence”（置信度），用于“evaluate the reliability of their decisions”（评估其决策的可靠性），这是一种明确的 `Self-Correction` 和 `Self-Improvement` 机制。 - 论文的用例是“autonomous tool invention”（自主工具发明），这属于高级的 `Tool Use / Tool Augmentation` 范畴，是智能体能力的重要体现。 - 整体来看，该论文聚焦于提升单智能体的内在决策和反思能力，完全属于你的“单智能体”和“自我演化”研究方向。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐或可解释性，因此不触发排除标准。 - 虽然论文涉及机器人，但其核心是认知架构，而非视觉或多模态技术本身。视觉（如果机器人使用摄像头）在这里被看作是智能体感知环境的工具，而非研究的核心贡献，因此符合你的筛选规则。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的“confidence-informed decision making”（基于置信度的决策）是一种新的智能体推理和决策框架，它超越了基础的Token预测，属于智能体在复杂任务中进行多步决策和自我评估的范畴，因此应该保留。 - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它应用在机器人这一特定领域，但其**核心贡献是提出了一种新的“自我演化”的基础机制——元认知**。这种机制使智能体能够反思和评估自身决策，是实现自我完善和迭代的关键一步。因此，根据你的规则，必须保留。 **最终决策**: 这篇论文的核心是构建一个具有元认知能力的智能体架构，使其能够通过自我反思（评估决策置信度）来指导行为，甚至进行工具发明。这完全符合你关于“LLM智能体及其演化”的研究课题，特别是在“单智能体”的“自我反思”和“自我演化”方向上。因此，最终判断为 **True**。"
    },
    {
        "index": "#101",
        "title": "AskDB: An LLM Agent for Natural Language Interaction with Relational Databases",
        "link": "/arxiv/2511.16131",
        "arxiv_id": "2511.16131",
        "authors": "Xuan-Quang Phan, Tan-Ha Mai, Thai-Duy Dinh, Minh-Thuan Nguyen, Lam-Son Lê",
        "summary": "Interacting with relational databases remains challenging for users across different expertise levels, particularly when composing complex analytical queries or performing administrative tasks. Existing systems typically address either natural language querying or narrow aspects of database administration, lacking a unified and intelligent interface for general-purpose database interaction. We introduce AskDB, a large language model powered agent designed to bridge this gap by supporting both data analysis and administrative operations over SQL databases through natural language. Built on Gemini 2, AskDB integrates two key innovations: a dynamic schema-aware prompting mechanism that effectively incorporates database metadata, and a task decomposition framework that enables the agent to plan and execute multi-step actions. These capabilities allow AskDB to autonomously debug derived SQL, retrieve contextual information via real-time web search, and adaptively refine its responses. We evaluate AskDB on a widely used Text-to-SQL benchmark and a curated set of DBA tasks, demonstrating strong performance in both analytical and administrative scenarios. Our results highlight the potential of AskDB as a unified and intelligent agent for relational database systems, offering an intuitive and accessible experience for end users.",
        "subjects": "Databases, Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.333924",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建一个新颖的LLM智能体**。其核心贡献并非简单地将现有框架应用于数据库领域，而是提出了一个名为AskDB的智能体，并为其设计了两个关键创新机制：`动态模式感知提示机制`和`任务分解框架`。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是非演化型应用，因为其重点在于智能体本身的设计和能力，而非仅仅解决数据库问题。 2.  **第二步：正面指标** - 论文高度符合你的核心关注点，具体体现在： - **核心范式**: 论文标题和摘要中明确使用了 `LLM Agent`。 - **智能体能力**: - **规划**: 论文的核心创新之一是 `任务分解框架`，它使智能体能够 `plan and execute multi-step actions`（规划和执行多步操作），这是典型的智能体规划能力。 - **工具使用**: 智能体能够 `retrieve contextual information via real-time web search`（通过实时网络搜索检索上下文信息），这明确展示了其工具使用能力。 - **自我反思/自我修正**: 论文提到智能体可以 `autonomously debug derived SQL`（自主调试派生出的SQL）和 `adaptively refine its responses`（自适应地优化其响应），这直接对应了自我反思和自我修正的能力。 3.  **第三步：排除标准** - 论文的主要贡献是关于智能体的能力构建和框架设计，没有涉及安全、对齐、可解释性或视觉等多模态内容。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文属于“保留”情况。它讨论的是智能体如何通过任务分解来规划和执行复杂任务，而不是提升LLM本身的基础推理能力。这完全符合Agentic AI的研究范畴。 - **自我演化的应用**: 虽然这篇论文的核心不是“自我演化”，但它提出的“自主调试”和“自适应优化”机制，可以看作是轻量级的自我完善。更重要的是，它完美诠释了“例外”规则：即使应用在数据库这一特定领域，但由于其核心贡献是提出了一种新的智能体构建方法（包含规划、工具使用、自我修正），因此必须保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建了一个具备规划、工具使用和自我修正能力的单智能体系统**。它提出了具体的创新框架来实现这些能力，完全契合你研究课题中的“单智能体”方向。尽管其应用场景是数据库交互，但其研究焦点在于智能体本身的设计与实现，而非简单的领域应用。因此，这篇论文是高度相关且有价值的前沿研究，应被筛选入内。"
    },
    {
        "index": "#111",
        "title": "Semantic Glitch: Agency and Artistry in an Autonomous Pixel Cloud",
        "link": "/arxiv/2511.16048",
        "arxiv_id": "2511.16048",
        "authors": "Qing Zhang, Jing Huang, Mingyang Xu, Jun Rekimoto",
        "summary": "While mainstream robotics pursues metric precision and flawless performance, this paper explores the creative potential of a deliberately \"lo-fi\" approach. We present the \"Semantic Glitch,\" a soft flying robotic art installation whose physical form, a 3D pixel style cloud, is a \"physical glitch\" derived from digital archaeology. We detail a novel autonomous pipeline that rejects conventional sensors like LiDAR and SLAM, relying solely on the qualitative, semantic understanding of a Multimodal Large Language Model to navigate. By authoring a bio-inspired personality for the robot through a natural language prompt, we create a \"narrative mind\" that complements the \"weak,\" historically, loaded body. Our analysis begins with a 13-minute autonomous flight log, and a follow-up study statistically validates the framework's robustness for authoring quantifiably distinct personas. The combined analysis reveals emergent behaviors, from landmark-based navigation to a compelling \"plan to execution\" gap, and a character whose unpredictable, plausible behavior stems from a lack of precise proprioception. This demonstrates a lo-fi framework for creating imperfect companions whose success is measured in character over efficiency.",
        "subjects": "Robotics, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.336882",
        "filter_reason": "这篇论文符合你的研究范围，应当保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非仅仅是“用LLM做一个机器人艺术装置”，而是提出了一种**构建LLM智能体的新颖框架和方法论**。摘要中明确指出，他们提出了一个“novel autonomous pipeline”（新颖的自主流程）和一个“lo-fi framework for creating imperfect companions”（用于创建不完美同伴的低技术框架）。这个框架的核心是**完全依赖多模态大语言模型（MLLM）的语义理解来进行导航和决策**，并**通过自然语言提示来为智能体塑造“人格”**。这完全符合“构建、改进LLM智能体”的核心目标，因此不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **核心范式**: `Agentic AI`, `LLM-based Agents`。论文的核心就是研究一个自主的、基于LLM的智能体。 *   **智能体能力**: `Planning`（论文分析了“plan to execution” gap，即规划与执行的差距，这是对智能体规划能力的深入探讨）和 `Tool Use`（将MLLM的语义理解能力作为替代LiDAR/SLAM的“导航工具”，这是一种非常规且创新的工具使用方式）。 *   **智能体设计**: 论文通过“authoring a bio-inspired personality”（通过提示创作人格）来构建智能体的“叙事心智”，这直接触及了智能体的行为塑造和个性化设计，是Agentic AI研究的前沿方向。 3.  **第三步：排除标准——未触发** *   论文的主要贡献不是关于安全、对齐或可解释性。 *   论文虽然使用了多模态LLM（MLLMs），但其目的不是研究视觉模型本身，而是将其作为智能体感知环境的**核心工具**。这完全符合筛选标准中“除非它们被用作智能体感知环境的工具，而不是研究的核心”的例外情况。研究的核心是这个**Agentic框架**，而不是视觉模型。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文明确涉及智能体的规划过程，并分析了其“规划到执行的差距”，这属于对智能体在复杂任务中多步推理和规划能力的探讨，符合保留条件。 *   **自我演化的应用**: 虽然这篇论文不涉及自我演化，但它也没有违反任何排除规则。 **最终决策**: 这篇论文的核心贡献在于提出了一种**以LLM的语义理解为中心、通过提示工程来塑造人格的全新智能体构建框架**。它探索了智能体在“不完美”和“弱感知”条件下的自主行为和涌现特性。这完全符合你“构建、改进或演化LLM智能体”的核心目标，特别是在**单智能体**的规划和工具使用方向上提供了非常新颖和前沿的视角。因此，应判定为 **True (保留)**。"
    },
    {
        "index": "#120",
        "title": "InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution",
        "link": "/arxiv/2511.16004",
        "arxiv_id": "2511.16004",
        "authors": "KeFan Li, Mengfei Wang, Hengzhi Zhang, Zhichao Li, Yuan Yuan, Mu Li, Xiang Gao, Hailong Sun, Chunming Hu, Weifeng Lv",
        "summary": "Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.339510",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接命中了“多智能体”和“自我演化”两个核心方向。 1.  **第一步：核心判断——保留** - 论文的核心贡献是提出一个名为 **InfCode** 的 **“对抗性多智能体框架”**。这并非简单地将现有LLM或智能体框架应用于软件工程领域，而是**构建了一个全新的、具有特定交互模式的多智能体方法论**。 - 该框架通过智能体间的对抗和协作来迭代式地改进输出，这属于对智能体系统的**改进和演化**，而非简单的应用。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** - **核心范式**: 论文明确提出了 `Multi-Agent Systems (MAS)`，并描述了其 `Adversarial`（对抗性）的交互模式。 - **多智能体**: 摘要中清晰地定义了三个不同的智能体角色：`Test Patch Generator`（测试补丁生成器）、`Code Patch Generator`（代码补丁生成器）和 `Selector agent`（选择器智能体）。它们之间通过 `Adversarial interaction`（对抗性交互）进行 `Collaboration`（协作）和 `Communication`（通信）。 - **演化机制**: 论文的核心机制是 **“iteratively refines both tests and patches”**（迭代式地改进测试和补丁）。这直接对应了 `Self-Refine`、`Iterative Improvement` 和 `Self-Evolving` 的概念。智能体系统通过一个循环过程，利用内部反馈（测试结果）来不断完善其产物（代码补丁），这是一种典型的自我演化机制。 3.  **第三步：排除标准——未命中** - 论文的主要贡献是关于提升智能体解决复杂任务的性能和可靠性，而非聚焦于 `Safety`、`Alignment` 或 `Hallucination` 等安全与对齐问题。 - 论文处理的是代码和文本，不涉及 `Vision` 或多模态内容。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它的应用领域是软件工程（一个特定领域），但其**核心创新点是提出了一种新的“自我演化”机制**——即通过多智能体对抗来迭代改进。因此，根据你的规则，必须保留。 - **推理/规划**: 论文中的智能体需要进行复杂的仓库级推理和规划来生成和验证代码补丁，这完全属于Agentic AI的范畴，而非提升LLM本身的基础推理能力。 **结论**: 论文的核心贡献在于构建了一个新颖的、具有对抗性和迭代式自我改进能力的多智能体框架。它直接推动了LLM智能体在“多智能体协作”和“自我演化”方向上的发展，与你的研究目标高度契合，因此应该被保留。"
    },
    {
        "index": "#119",
        "title": "InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution",
        "link": "/arxiv/2511.16005",
        "arxiv_id": "2511.16005",
        "authors": "Qingao Dong, Mengfei Wang, Hengzhi Zhang, Zhichao Li, Yuan Yuan, Mu Li, Xiang Gao, Hailong Sun, Chunming Hu, Weifeng Lv",
        "summary": "Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \\texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.339197",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的核心贡献是构建了一个名为 `INFCODE-C++` 的**新的自主系统（即LLM智能体）**，用于解决C++代码库中的问题。它并非简单地将一个已有的智能体框架应用到C++领域，而是针对C++的复杂性（如重载标识符、模板等）设计了**全新的核心组件**：`语义代码意图检索` 和 `确定性AST结构化查询`。这些组件是智能体感知和理解其环境（代码库）的工具，其本质是**对LLM智能体能力的构建和改进**。因此，它不属于“非演化型应用”的排除范畴。 **第二步：正面指标——高度相关** 论文包含了多个核心关注点： - **核心范式**: 论文明确提出了一个 `LLM-based Agent` (`INFCODE-C++`)。 - **智能体能力**: 论文的核心创新点在于极大地增强了智能体的**工具使用**能力。`语义检索`和`AST查询`是智能体用来精准定位问题、构建上下文的高级工具，这远超简单的关键词搜索。同时，`end-to-end issue resolution`（端到端问题解决）过程本身就隐含了智能体的**规划**能力，即智能体需要规划出从理解问题到定位代码再到生成修复补丁的完整流程。 **第三步：排除标准——不适用** 论文的研究焦点是提升智能体在软件工程任务中的性能，不涉及安全、对齐、可解释性或水印等问题。同时，它处理的是纯文本代码，不涉及视觉或多模态内容。因此，不触发任何排除标准。 **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 论文描述的智能体执行的是一个复杂的多步任务（问题理解 -> 代码定位 -> 补丁生成），这完全属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。其贡献在于通过新的工具（检索机制）来赋能这个推理过程，而不是改进LLM本身的数学或逻辑能力。 - **自我演化的应用**: 虽然这篇论文没有提出“自我演化”机制，但它属于“构建、改进LLM智能体”的核心范畴，因此符合保留条件。 **最终决策** 综合来看，`InfCode-C++` 的核心贡献是**提出了一种新的LLM智能体架构，通过创新的工具使用机制（语义检索和AST查询）来增强智能体在复杂静态语言环境下的感知和行动能力**。这完全符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标，特别是在“单智能体”方向下的“工具使用”和“规划”子方向上做出了明确的贡献。因此，应判定为 **True**。"
    },
    {
        "index": "#121",
        "title": "Hiding in the AI Traffic: Abusing MCP for LLM-Powered Agentic Red Teaming",
        "link": "/arxiv/2511.15998",
        "arxiv_id": "2511.15998",
        "authors": "Strahinja Janjuesvic, Anna Baron Garcia, Sohrob Kazerounian",
        "summary": "Generative AI is reshaping offensive cybersecurity by enabling autonomous red team agents that can plan, execute, and adapt during penetration tests. However, existing approaches face trade-offs between generality and specialization, and practical deployments reveal challenges such as hallucinations, context limitations, and ethical concerns. In this work, we introduce a novel command & control (C2) architecture leveraging the Model Context Protocol (MCP) to coordinate distributed, adaptive reconnaissance agents covertly across networks. Notably, we find that our architecture not only improves goal-directed behavior of the system as whole, but also eliminates key host and network artifacts that can be used to detect and prevent command & control behavior altogether. We begin with a comprehensive review of state-of-the-art generative red teaming methods, from fine-tuned specialist models to modular or agentic frameworks, analyzing their automation capabilities against task-specific accuracy. We then detail how our MCP-based C2 can overcome current limitations by enabling asynchronous, parallel operations and real-time intelligence sharing without periodic beaconing. We furthermore explore advanced adversarial capabilities of this architecture, its detection-evasion techniques, and address dual-use ethical implications, proposing defensive measures and controlled evaluation in lab settings. Experimental comparisons with traditional C2 show drastic reductions in manual effort and detection footprint. We conclude with future directions for integrating autonomous exploitation, defensive LLM agents, predictive evasive maneuvers, and multi-agent swarms. The proposed MCP-enabled C2 framework demonstrates a significant step toward realistic, AI-driven red team operations that can simulate advanced persistent threats while informing the development of next-generation defensive systems.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-21T11:00:06.339806",
        "filter_reason": "这篇论文符合研究范围，应被保留。判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出一种“新颖的命令与控制（C2）架构”，用于“协调分布式、自适应的侦察智能体”。这完全符合“构建、改进或演化LLM智能体”的核心目标。它不是简单地将一个已有的智能体框架应用到网络安全领域，而是**创造了一个新的架构来增强智能体系统的能力**，特别是它们的协作、通信和适应性。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了大量与研究焦点高度相关的正面指标： *   **核心范式**: `LLM-Powered Agentic Red Teaming`, `agentic frameworks`, `multi-agent swarms`。 *   **智能体能力**: `plan, execute, and adapt` (规划与适应), `goal-directed behavior` (目标导向行为)。 *   **多智能体**: `coordinate distributed, adaptive reconnaissance agents` (协调分布式智能体), `asynchronous, parallel operations`, `real-time intelligence sharing` (通信与协作)。 这些关键词清晰地表明，论文的研究内容集中在多智能体系统的构建和改进上。 3.  **第三步：排除标准——不适用** 论文虽然涉及“安全”和“检测规避”，但其**主要贡献是提出一个智能体架构**，而不是研究安全或对齐技术本身。安全和规避是该架构在“红队”这一特定应用场景下所展现出的特性和优势，是研究的副产品，而非核心研究问题。因此，它不符合“主要贡献是关于安全”的排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 论文讨论了智能体的“规划、执行和适应”，这属于智能体在复杂任务中的多步推理和规划，符合“保留”的条件。同时，它也遵循了“自我演化的应用”例外规则的核心精神：即使应用在“网络安全”这一特定领域，但由于其核心是提出一种新的智能体协调与演化（适应）机制，因此应该保留。 **最终决策**: 综合分析，这篇论文的核心是构建一个用于协调分布式LLM智能体的新架构，以提升它们在复杂任务中的规划、协作和自适应能力。这直接命中了研究课题中的“多智能体”方向，并与“单智能体”的规划、适应能力以及“自我演化”的迭代思想紧密相关。因此，这篇论文是高度相关的前沿研究，应被筛选入内。"
    }
]