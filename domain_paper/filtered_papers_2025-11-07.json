[
    {
        "index": "#14",
        "title": "A Toolbox for Improving Evolutionary Prompt Search",
        "link": "/arxiv/2511.05120",
        "arxiv_id": "2511.05120",
        "authors": "Daniel Grießhaber, Maximilian Kimmich, Johannes Maucher, Ngoc Thang Vu",
        "summary": "Evolutionary prompt optimization has demonstrated effectiveness in refining prompts for LLMs. However, existing approaches lack robust operators and efficient evaluation mechanisms. In this work, we propose several key improvements to evolutionary prompt optimization that can partially generalize to prompt optimization in general: 1) decomposing evolution into distinct steps to enhance the evolution and its control, 2) introducing an LLM-based judge to verify the evolutions, 3) integrating human feedback to refine the evolutionary operator, and 4) developing more efficient evaluation strategies that maintain performance while reducing computational overhead. Our approach improves both optimization quality and efficiency. We release our code, enabling prompt optimization on new tasks and facilitating further research in this area.",
        "subjects": "Computation and Language",
        "date": "2025-11-07",
        "category": "cs.CL",
        "crawl_time": "2025-11-10T11:00:04.160224",
        "filter_reason": "这篇论文符合你的研究范围，应予以保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种改进的“演化提示优化”方法。虽然它没有直接构建一个完整的智能体架构（如包含规划、记忆模块的智能体），但它聚焦于智能体核心能力之一——**自我完善与演化**。论文的本质是提出一种新的、更高效的**演化机制**，这直接关联到你的研究目标中的“自我演化”方向。它不是将现有智能体作为工具去解决某个领域问题，而是在改进智能体能力演化的底层方法论。 2.  **正面指标 (第二步):** 论文与你的核心关注点高度匹配。 *   **核心范式:** 论文明确围绕 `Evolutionary Algorithms` (演化算法) 展开，这是 `Self-Evolving` (自我演化) 的关键技术。 *   **演化机制:** 论文的贡献点，如“将演化分解为不同步骤”、“引入LLM裁判验证演化”、“整合人类反馈优化演化操作符”，都属于 `Self-Improvement` (自我改进) 和 `Iterative Improvement` (迭代改进) 的具体实现。 3.  **排除标准 (第三步):** 论文不涉及安全、对齐或多模态等排除领域，其焦点是优化算法的质量和效率，完全符合你的筛选要求。 4.  **特殊情况处理 (第四步):** 这篇论文是“自我演化的应用”这一特殊情况的完美例证。 *   **核心规则:** “如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” *   **应用:** 这篇论文提出的演化机制被应用于“提示优化”这个特定任务。提示是LLM智能体行为和能力的核心，一个能够高效演化自身提示的机制，是构建自我演化智能体的关键一环。因此，这篇论文提出的“工具箱”直接服务于“构建、改进或演化LLM智能体”的最终目标。 **结论:** 该论文的核心贡献在于提出了一种新的、更鲁棒的演化算法框架，用于优化LLM智能体的核心组件——提示。这完全符合你研究课题中“自我演化”的方向，为智能体如何通过迭代和反馈进行自我完善提供了具体的方法论支持。因此，应判定为符合要求。"
    },
    {
        "index": "#9",
        "title": "Reflective Personalization Optimization: A Post-hoc Rewriting Framework for Black-Box Large Language Models",
        "link": "/arxiv/2511.05286",
        "arxiv_id": "2511.05286",
        "authors": "Teqi Hao, Xioayu Tan, Shaojie Shi, Yinghui Xu, Xihe Qiu",
        "summary": "The personalization of black-box large language models (LLMs) is a critical yet challenging task. Existing approaches predominantly rely on context injection, where user history is embedded into the prompt to directly guide the generation process. However, this single-step paradigm imposes a dual burden on the model: generating accurate content while simultaneously aligning with user-specific styles. This often results in a trade-off that compromises output quality and limits precise control. To address this fundamental tension, we propose Reflective Personalization Optimization (RPO), a novel framework that redefines the personalization paradigm by decoupling content generation from alignment. RPO operates in two distinct stages: first, a base model generates a high-quality, generic response; then, an external reflection module explicitly rewrites this output to align with the user's preferences. This reflection module is trained using a two-stage process. Initially, supervised fine-tuning is employed on structured rewriting trajectories to establish a core personalized reasoning policy that models the transformation from generic to user-aligned responses. Subsequently, reinforcement learning is applied to further refine and enhance the quality of the personalized outputs. Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by decoupling content generation from personalization, significantly outperforms state-of-the-art baselines. These findings underscore the superiority of explicit response shaping over implicit context injection. Moreover, RPO introduces an efficient, model-agnostic personalization layer that can be seamlessly integrated with any underlying base model, paving the way for a new and effective direction in user-centric generation scenarios.",
        "subjects": "Computation and Language",
        "date": "2025-11-07",
        "category": "cs.CL",
        "crawl_time": "2025-11-10T11:00:04.152829",
        "filter_reason": "这篇论文符合我的研究范围，核心依据在于其提出了一种新颖的、具有自我反思和修正能力的智能体框架，属于“自我演化”和“单智能体”研究方向的交叉点。 **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于个性化领域，而是提出了一种名为“反思性个性化优化（RPO）”的**新框架**。该框架的核心贡献在于其**方法论**：通过一个外部的“反思模块”对基础模型的输出进行事后重写。这种“生成-反思-重写”的两阶段解耦范式，本质上是一种**自我修正**和**自我反思**的机制。这完全符合“构建、改进或演化LLM智能体”的核心目标，特别是“自我演化”中的自我完善和迭代。它不是非演化型应用，因为它关注的是智能体如何通过一个反思过程来改进其输出，而不是直接用LLM解决个性化问题。 **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文提出了一个 `Agentic AI` 框架。 - **智能体能力**: 论文的标题和摘要都明确强调了 `Reflective`（反思），其机制是 `Self-Correction`（自我修正）和 `Self-Reflection`（自我反思）的典型体现。反思模块通过学习“从通用到用户对齐的转换”，形成了一种个性化的推理策略。 - **演化机制**: RPO框架通过显式的重写步骤实现了 `Iterative Improvement`（迭代改进），其训练过程（SFT -> RL）本身也是一种 `Self-Refine`（自我精炼）的体现。 **第三步：排除标准** - 论文不涉及任何排除标准。虽然研究主题是“个性化”，这与“对齐”有概念上的重叠，但论文的**主要贡献**是技术性的——即一种实现个性化的新**机制**（反思性重写），而不是研究对齐的安全性、伦理或可解释性。因此，它不属于安全与对齐的研究焦点。 **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。尽管其应用场景是“个性化”，但其核心是提出了一种新的“自我演化”机制（即反思性重写）。根据筛选规则，这种论文应该被保留。 - **推理/规划**: 论文不涉及复杂任务的规划，但其“反思-重写”过程是一种高级的、结构化的推理行为，超越了简单的Token预测，属于智能体能力的范畴。 **第五步：最终决策** 综合以上分析，该论文的核心贡献是构建了一个具有自我反思和修正能力的LLM智能体框架（RPO）。它通过解耦内容生成与个性化对齐，引入了一个显式的反思模块来优化输出，这直接推动了LLM智能体在自我完善和演化方向上的研究进展。因此，这篇论文与我的研究课题高度相关，应当保留。"
    },
    {
        "index": "#32",
        "title": "Learning to reason about rare diseases through retrieval-augmented agents",
        "link": "/arxiv/2511.04720",
        "arxiv_id": "2511.04720",
        "authors": "Ha Young Kim, Jun Li, Ana Beatriz Solana, Carolin M. Pirkl, Benedikt Wiestler, Julia A. Schnabel, Cosmin I. Bercea",
        "summary": "Rare diseases represent the long tail of medical imaging, where AI models often fail due to the scarcity of representative training data. In clinical workflows, radiologists frequently consult case reports and literature when confronted with unfamiliar findings. Following this line of reasoning, we introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic system for rare disease detection in brain MRI. Our approach uses AI agents with access to external medical knowledge by embedding both case reports and literature using sentence transformers and indexing them with FAISS to enable efficient similarity search. The agent retrieves clinically relevant evidence to guide diagnostic decision making on unseen diseases, without the need of additional training. Designed as a model-agnostic reasoning module, RADAR can be seamlessly integrated with diverse large language models, consistently improving their rare pathology recognition and interpretability. On the NOVA dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2% performance gain, with the strongest improvements observed for open source models such as DeepSeek. Beyond accuracy, the retrieved examples provide interpretable, literature grounded explanations, highlighting retrieval-augmented reasoning as a powerful paradigm for low-prevalence conditions in medical imaging.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-06",
        "category": "cs.CL",
        "crawl_time": "2025-11-10T11:00:04.173995",
        "filter_reason": "这篇论文符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献是构建了一个名为 **RADAR (Retrieval Augmented Diagnostic Reasoning Agents)** 的**智能体系统**。它不是简单地将一个已有的LLM或智能体框架应用到医疗领域，而是**提出并实现了一个新的智能体架构和方法论**。这个智能体通过检索外部知识库来增强其诊断推理能力。这完全符合“构建、改进LLM智能体”的核心目标。 - 它不属于“非演化型应用”的排除范畴，因为其创新点在于智能体本身的设计（如何通过检索增强进行推理），而不是应用本身。医疗领域是验证其智能体有效性的试验场。 2.  **第二步：正面指标——高度相关** - 论文明确包含了多个核心关注点： - **核心范式**: `Agentic AI`, `LLM-based Agents`。标题和摘要中反复强调 \"agents\" 和 \"agentic system\"。 - **智能体能力**: `Tool Use / Tool Augmentation` (使用FAISS检索系统作为工具), `Reasoning` (核心是 \"Diagnostic Reasoning Agents\")。其工作流程（检索证据以指导决策）与 `ReAct` (Reason+Act) 范式高度相似。 3.  **第三步：排除标准——未触发** - **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性。虽然提到了 \"interpretability\"，但这是其智能体设计带来的一个**有益的副作用**（检索到的文献提供了解释），而不是论文研究的核心。核心是智能体本身。 - **多模态与视觉**: 论文处理的是 \"brain MRI\"，属于视觉领域。但是，视觉数据（MRI）是智能体需要**理解和处理的任务环境**，而智能体的核心机制是基于文本的检索和推理。智能体本身不是一个视觉模型，而是利用工具（检索）来处理视觉任务带来的挑战。这符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”的例外情况。研究的核心是智能体的推理框架，而非视觉模型本身。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它研究的是**智能体如何进行推理**（通过检索增强），而不是如何提升LLM底层的数学或逻辑能力。它提出的是一个具体的Agentic推理框架。 **总结**: 这篇论文的核心是提出了一种新的LLM智能体架构（RADAR），该智能体通过使用检索工具来增强其在复杂、数据稀缺任务（罕见病诊断）中的推理能力。这直接命中了你研究目标中的“构建、改进LLM智能体”以及“单智能体”方向下的“工具使用”和“推理”子方向。尽管它应用在医疗领域，但其贡献是方法论层面的，属于Agentic AI的前沿研究。因此，应判定为 **True**。"
    },
    {
        "index": "#37",
        "title": "Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation",
        "link": "/arxiv/2511.04700",
        "arxiv_id": "2511.04700",
        "authors": "Song Wang, Zihan Chen, Peng Wang, Zhepei Wei, Zhen Tan, Yu Meng, Cong Shen, Jundong Li",
        "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by integrating external knowledge sources to address their limitations in accessing up-to-date or specialized information. A natural strategy to increase the likelihood of retrieving relevant information is to expand the number of retrieved documents. However, involving more documents could introduce significant noise, as many documents may be irrelevant or misleading, thereby reducing the overall accuracy of the generated responses. To overcome the challenge associated with handling a larger number of documents, we propose WinnowRAG, a novel RAG framework designed to systematically filter out noisy documents while preserving valuable content -- a process we refer to as winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware clustering to group similar documents and form distinct topic clusters. Each cluster is assigned to an LLM agent for generating a unique answer. In Stage II, we perform winnowing, wherein a critic LLM evaluates the outputs of multiple agents and iteratively separates useful documents from noisy ones. To retain useful documents when discarding agents, we propose two strategic merging techniques to ensure that only relevant knowledge is used for generating the final response. Crucially, WinnowRAG is model-agnostic and does not require any model fine-tuning, making it easily adaptable to various tasks. Extensive experiments on various realistic datasets demonstrate the effectiveness of WinnowRAG over state-of-the-art baselines.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-01",
        "category": "cs.CL",
        "crawl_time": "2025-11-10T11:00:04.181928",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一个名为 `WinnowRAG` 的新框架。虽然其应用场景是检索增强生成（RAG），但其方法论本质上是关于**如何构建和组织一个多智能体系统**来解决问题。论文并非简单地将一个已有的智能体框架应用于RAG，而是**设计了一个新的、包含多个角色（生成智能体和评判智能体）的协作框架**。这完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心关注点： - **多智能体**: 论文明确提到将文档簇分配给“LLM agent”，并使用“critic LLM”来评估“multiple agents”的输出。这是一个典型的多智能体协作与评估场景。 - **自我演化/自我修正**: 第二阶段的“winnowing”过程，由评判LLM“迭代地”将有用文档与噪声文档分离，这是一种明确的**迭代式自我修正和精炼机制**，属于自我演化的范畴。 - **智能体能力**: 整个框架体现了智能体的规划（两阶段流程）、协作（多智能体分工）和评估能力。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等排除领域。其焦点在于提升RAG效果的方法论，而非安全或伦理问题。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文提出的框架是一个复杂的多步推理和规划过程。它不是在提升LLM本身的基础推理能力，而是在构建一个让多个智能体协同进行推理、评估和优化的**Agentic框架**。这符合保留条件。 - **自我演化的应用**: 这篇论文是提出一种新的“自我演化”（迭代精炼）机制的绝佳范例，即使它被应用在RAG这个特定领域，根据您的规则也应保留。 **最终决策**: 这篇论文的核心贡献在于提出了一种新颖的多智能体协作框架 `WinnowRAG`，该框架通过引入“生成智能体”和“评判智能体”的角色分工，并利用迭代式的评估和筛选机制，实现了对噪声信息的过滤和系统输出的自我优化。这直接对应了您研究课题中的**“多智能体”**和**“自我演化”**两个核心方向。因此，该论文与您的研究目标高度相关，应被筛选出来。"
    },
    {
        "index": "#52",
        "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property",
        "link": "/arxiv/2511.04956",
        "arxiv_id": "2511.04956",
        "authors": "Maria Mahbub, Vanessa Lama, Sanjay Das, Brian Starks, Christopher Polchek, Saffell Silvers, Lauren Deck, Prasanna Balaprakash, Tirthankar Ghosal",
        "summary": "High-Risk Property (HRP) classification is critical at U.S. Department of Energy (DOE) sites, where inventories include sensitive and often dual-use equipment. Compliance must track evolving rules designated by various export control policies to make transparent and auditable decisions. Traditional expert-only workflows are time-consuming, backlog-prone, and struggle to keep pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic system for HRP classification that pairs retrieval-augmented generation (RAG) with human oversight to produce policy-based outputs that can be audited. Small cooperating agents, retrieval, description refiner, classifier, validator, and feedback logger, coordinate via agent-to-agent messaging and invoke tools through the Model Context Protocol (MCP) for model-agnostic on-premise operation. The interface follows an Item to Evidence to Decision loop with step-by-step reasoning, on-policy citations, and append-only audit bundles (run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID improves accuracy and traceability over a non-agentic baseline while deferring uncertain items to Subject Matter Experts (SMEs). The demonstration shows single item submission, grounded citations, SME feedback capture, and exportable audit artifacts, illustrating a practical path to trustworthy LLM assistance in sensitive DOE compliance workflows.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-07",
        "category": "cs.CL",
        "crawl_time": "2025-11-10T11:00:04.199678",
        "filter_reason": "这篇论文符合筛选要求，应该被保留。我的判断过程如下： **第一步：核心判断** - **保留**。尽管论文的应用领域是特定的“高风险财产分类”，但其核心贡献并非简单地将LLM作为工具应用，而是**构建了一个新颖的“模块化agentic系统”（modular agentic system）**。论文的核心是关于这个系统（ORCHID）的设计、架构和工作流程，而不是HRP分类问题本身。这符合“构建LLM智能体”的核心要求。 **第二步：正面指标** - 论文包含了多个核心关注点，相关性非常高： - **核心范式**: 明确提到了 `agentic system`。 - **多智能体**: 摘要中清晰地描述了“小型协作智能体”，包括 `retrieval`, `description refiner`, `classifier`, `validator`, `feedback logger`，并且它们通过 `agent-to-agent messaging` 进行协调。这完全符合“多智能体”研究方向中的“协作”与“通信”。 - **智能体能力**: 提到了智能体通过 `Model Context Protocol (MCP)` 调用 `tools`，这直接对应了“工具使用”能力。同时，其“Item to Evidence to Decision loop with step-by-step reasoning”描述了一个复杂的、多步的决策和推理过程，这与智能体的“规划”能力密切相关。 **第三步：排除标准** - **安全与对齐**: 论文虽然提到了“transparent and auditable decisions”（透明和可审计的决策）和“trustworthy LLM assistance”（可信的LLM辅助），但这些是其所构建系统的**特性和目标**，而非论文的**核心研究贡献**。论文的核心是提出实现这些特性的agentic架构，而不是研究一种新的安全或对齐算法本身。因此，不应因此排除。 - **多模态与视觉**: 论文未涉及视觉或多模态内容，不触及此排除标准。 **第四步：处理特殊和模糊情况** - **推理/规划**: 论文描述的“Item to Evidence to Decision loop with step-by-step reasoning”是典型的智能体在复杂任务中进行多步规划和推理的框架，而非仅仅提升LLM本身的基础推理能力。因此，符合保留条件。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于提出了一种由多个协作智能体构成、具备工具调用和复杂决策循环能力的agentic框架（ORCHID）。虽然它在一个特定领域（DOE合规）进行演示，但其方法论和架构设计本身具有普适性，直接命中了“构建LLM智能体”和“多智能体系统”这两个核心研究方向。因此，这篇论文高度相关，应被保留。"
    },
    {
        "index": "#5",
        "title": "Real-Time Reasoning Agents in Evolving Environments",
        "link": "/arxiv/2511.04898",
        "arxiv_id": "2511.04898",
        "authors": "Yule Wen, Yixin Ye, Yanzhe Zhang, Diyi Yang, Hao Zhu",
        "summary": "Agents in the real world must make not only logical but also timely judgments. This requires continuous awareness of the dynamic environment: hazards emerge, opportunities arise, and other agents act, while the agent's reasoning is still unfolding. Despite advances in language model reasoning, existing approaches fail to account for this dynamic nature. We introduce real-time reasoning as a new problem formulation for agents in evolving environments and build Real-Time Reasoning Gym to demonstrate it. We study two paradigms for deploying language models in agents: (1) reactive agents, which employ language models with bounded reasoning computation for rapid responses, and (2) planning agents, which allow extended reasoning computation for complex problems. Our experiments show that even state-of-the-art models struggle with making logical and timely judgments in either paradigm. To address this limitation, we propose AgileThinker, which simultaneously engages both reasoning paradigms. AgileThinker consistently outperforms agents engaging only one reasoning paradigm as the task difficulty and time pressure rise, effectively balancing reasoning depth and response latency. Our work establishes real-time reasoning as a critical testbed for developing practical agents and provides a foundation for research in temporally constrained AI systems, highlighting a path toward real-time capable agents.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-07",
        "category": "cs.AI",
        "crawl_time": "2025-11-10T11:00:04.441534",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心不是将现有智能体框架应用于某个特定领域，而是针对“动态环境中的实时推理”这一新问题，提出了一种全新的智能体框架 `AgileThinker`。这直接属于“构建、改进LLM智能体的方法论或新框架”的范畴。它不是非演化型应用，也不是非Agentic的基础推理研究，因此应予以保留。 2.  **第二步：正面指标——高度匹配** 论文摘要中充满了您关注的核心关键词和概念： *   **核心范式**: `LLM-based Agents` (论文标题和摘要的核心)。 *   **智能体能力**: `Planning` (论文明确对比了 `reactive agents` 和 `planning agents` 两种范式，并提出了融合方案)。`AgileThinker` 本质上就是一种新的、能在时间压力下进行多步推理的智能体架构，这与 `ReAct`、`ToT` 等思想一脉相承，但针对动态环境进行了创新。 这些正面指标表明，论文的研究焦点与您的“单智能体”方向高度一致。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于智能体的推理效率和架构设计，完全没有涉及 `Safety`、`Alignment`、`Hallucination` 等安全与对齐问题，也未涉及 `Vision`、`MLLMs` 等多模态内容。因此，所有排除标准均不适用。 4.  **第四步：处理特殊和模糊情况——符合保留条件** 这篇论文是“推理/规划”特殊情况的完美范例。它研究的不是如何提升LLM模型本身的基础数学或逻辑能力，而是**研究智能体作为一个整体，如何在动态和有时间限制的环境中进行规划和推理**。论文提出的 `AgileThinker` 框架，通过结合反应式和规划式两种推理范式，直接解决了智能体在复杂任务中的自主规划问题，这正是您所关注的Agentic AI的核心。 **最终决策**: 该论文的核心贡献是定义了一个新的智能体研究问题（实时推理），并为此提出了一个创新的智能体框架 `AgileThinker`，旨在提升智能体在动态环境中的规划和推理能力。这完全契合您“构建、改进或演化LLM智能体”的核心目标，特别是“单智能体”方向下的“规划”与“推理”子方向。因此，最终判断为 **True**。"
    },
    {
        "index": "#9",
        "title": "TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning",
        "link": "/arxiv/2511.05489",
        "arxiv_id": "2511.05489",
        "authors": "Junwen Pan, Qizhe Zhang, Rui Zhang, Ming Lu, Xin Wan, Yuan Zhang, Chang Liu, Qi She",
        "summary": "Temporal search aims to identify a minimal set of relevant frames from tens of thousands based on a given query, serving as a foundation for accurate long-form video understanding. Existing works attempt to progressively narrow the search space. However, these approaches typically rely on a hand-crafted search process, lacking end-to-end optimization for learning optimal search strategies. In this paper, we propose TimeSearch-R, which reformulates temporal search as interleaved text-video thinking, seamlessly integrating searching video clips into the reasoning process through reinforcement learning (RL). However, applying RL training methods, such as Group Relative Policy Optimization (GRPO), to video reasoning can result in unsupervised intermediate search decisions. This leads to insufficient exploration of the video content and inconsistent logical reasoning. To address these issues, we introduce GRPO with Completeness Self-Verification (GRPO-CSV), which gathers searched video frames from the interleaved reasoning process and utilizes the same policy model to verify the adequacy of searched frames, thereby improving the completeness of video reasoning. Additionally, we construct datasets specifically designed for the SFT cold-start and RL training of GRPO-CSV, filtering out samples with weak temporal dependencies to enhance task difficulty and improve temporal search capabilities. Extensive experiments demonstrate that TimeSearch-R achieves significant improvements on temporal search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as long-form video understanding benchmarks like VideoMME and MLVU. Notably, TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1% improvement over the base model Qwen2.5-VL and 2.0% over the advanced video reasoning model Video-R1. Our code is available at https://github.com/Time-Search/TimeSearch-R.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-11-07",
        "category": "cs.AI",
        "crawl_time": "2025-11-10T11:00:04.449197",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将LLM应用于视频领域，而是提出了一种新的**方法论框架**。其核心贡献是 `TimeSearch-R`，一个通过强化学习来学习最优搜索策略的框架。该框架将时序搜索过程重新定义为一种“交错的文本-视频思考”，并引入了“完整性自验证”机制。这本质上是在构建一个具有特定能力（搜索、推理、自验证）的智能体，而非一个简单的应用工具。 2.  **第二步：正面指标分析** - 论文包含了多个核心关注点： - **智能体能力**: - `Planning`: 论文的核心是“时序搜索”，这本身就是一种规划能力——智能体需要决定在庞大的视频中“看”哪里，以最高效的方式找到相关信息。 - `Tool Use`: 智能体将“搜索视频片段”作为一种工具来辅助其完成最终的问答任务。 - `Self-Correction` / `Self-Reflection`: 论文明确提出了 `Completeness Self-Verification (CSV)` 机制，即智能体利用自身模型来验证其搜索结果的充分性。这是一种典型的自我反思和自我纠正机制，是智能体高级能力的关键体现。 - **核心范式**: 论文的“interleaved text-video thinking”与 `ReAct` (Reasoning and Acting) 范式高度相似，都是将推理和行动（这里是搜索）交织进行，是典型的 Agentic AI 研究范式。 3.  **第三步：排除标准分析** - **安全与对齐**: 论文的主要贡献不涉及安全、对齐或可解释性，因此不在此排除范围内。 - **多模态与视觉**: 这是本案例的关键点。虽然论文完全围绕视频展开，但它符合排除标准中的**例外情况**：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，**视频是智能体操作的环境和感知对象**，而研究的**核心是智能体如何在这个环境中进行高效搜索、推理和自我验证的框架**。论文的贡献点不在于提出新的视觉模型或视频理解技术，而在于提出了一种新的智能体工作流和学习方法。因此，它不应被排除。 4.  **第四步：特殊和模糊情况处理** - **推理/规划**: 这篇论文完美符合“保留”条件。它不是在提升LLM的基础数学或逻辑能力，而是在研究**智能体如何在复杂任务（长视频理解）中进行多步规划和推理**。其提出的搜索和自验证循环，正是一种新颖的Agentic推理框架。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个名为 `TimeSearch-R` 的智能体框架。该框架通过强化学习，让智能体学会了如何在复杂的长视频环境中进行**规划（时序搜索）**、**工具使用（调用搜索功能）**和**自我反思（自验证）**。尽管其应用领域是视频理解，但其研究焦点完全在于智能体的方法论创新，而非视觉技术本身。因此，该论文高度契合“LLM智能体及其演化”中关于“单智能体”的研究方向，特别是规划、工具使用和自我反思等子方向。**应予以保留。**"
    },
    {
        "index": "#1",
        "title": "Reasoning Is All You Need for Urban Planning AI",
        "link": "/arxiv/2511.05375",
        "arxiv_id": "2511.05375",
        "authors": "Sijie Yang, Jiatong Li, Filip Biljecki",
        "summary": "AI has proven highly successful at urban planning analysis -- learning patterns from data to predict future conditions. The next frontier is AI-assisted decision-making: agents that recommend sites, allocate resources, and evaluate trade-offs while reasoning transparently about constraints and stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting, ReAct, and multi-agent collaboration frameworks -- now make this vision achievable. This position paper presents the Agentic Urban Planning AI Framework for reasoning-capable planning agents that integrates three cognitive layers (Perception, Foundation, Reasoning) with six logic components (Analysis, Generation, Verification, Evaluation, Collaboration, Decision) through a multi-agents collaboration framework. We demonstrate why planning decisions require explicit reasoning capabilities that are value-based (applying normative principles), rule-grounded (guaranteeing constraint satisfaction), and explainable (generating transparent justifications) -- requirements that statistical learning alone cannot fulfill. We compare reasoning agents with statistical learning, present a comprehensive architecture with benchmark evaluation metrics, and outline critical research challenges. This framework shows how AI agents can augment human planners by systematically exploring solution spaces, verifying regulatory compliance, and deliberating over trade-offs transparently -- not replacing human judgment but amplifying it with computational reasoning capabilities.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-07",
        "category": "cs.AI",
        "crawl_time": "2025-11-10T11:00:04.438928",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非简单地将现有LLM智能体应用于城市规划领域，而是**提出一个全新的“Agentic Urban Planning AI Framework”**。这是一个方法论和框架层面的贡献，其本质是关于如何构建一个具备推理能力的多智能体系统。因此，它不属于“非演化型应用”的排除范畴，而是直接命中了“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量与你研究焦点直接相关的核心关键词和概念： *   **核心范式**: 明确提出了 `Agentic Urban Planning AI Framework` 和 `multi-agents collaboration framework`，直接对应 `Agentic AI` 和 `Multi-Agent Systems (MAS)`。 *   **智能体能力**: 论文的核心是构建具备推理能力的智能体，并明确引用了 `ReAct` 作为其技术基础之一，这与你的 `Planning` 和 `Reasoning` 焦点高度一致。 *   **多智能体**: `multi-agents collaboration framework` 和 `Collaboration` 组件直接对应你的“多智能体”研究方向。 3.  **第三步：排除标准 (未触发)** 摘要中提到了 `explainable` (可解释性)，但这并非论文的主要贡献。论文的主要贡献是**框架本身**，而“可解释性”只是该框架在解决城市规划问题时所需满足的一个**特性或要求**（“generating transparent justifications”），而不是论文研究的核心议题（如新的可解释性方法或理论）。因此，这不触发排除标准。 4.  **第四步：特殊和模糊情况 (符合保留规则)** 论文完美符合“推理/规划”的保留规则。它不是在研究如何提升LLM本身的基础数学或逻辑推理能力，而是在研究**智能体如何在一个复杂任务（城市规划）中进行多步推理、协作和决策**。它提出的框架包含了 `Analysis, Generation, Verification, Evaluation, Collaboration, Decision` 等逻辑组件，这正是对智能体规划和推理过程的系统性构建。 **总结**: 这篇论文的核心贡献是构建一个用于城市规划的多智能体协作框架，该框架强调了智能体的推理、规划和协作能力。这完全符合你研究范围中的“单智能体”和“多智能体”方向。尽管它以“城市规划”为应用背景，但其贡献在于**提出了一种新的Agentic AI构建方法论**，而非简单的应用。因此，这篇论文是高度相关且应该保留的前沿研究。"
    },
    {
        "index": "#22",
        "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation Framework",
        "link": "/arxiv/2511.05385",
        "arxiv_id": "2511.05385",
        "authors": "Chao Zhang, Yuhao Wang, Derong Xu, Haoxin Zhang, Yuanjie Lyu, Yuhao Chen, Shuochen Liu, Tong Xu, Xiangyu Zhao, Yan Gao, Yao Hu, Enhong Chen",
        "summary": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs autonomous, multi-round retrieval and reasoning to resolve queries. Although recent agentic RAG has improved via reinforcement learning, they often incur substantial token overhead from search and reasoning processes. This trade-off prioritizes accuracy over efficiency. To address this issue, this work proposes TeaRAG, a token-efficient agentic RAG framework capable of compressing both retrieval content and reasoning steps. 1) First, the retrieved content is compressed by augmenting chunk-based semantic retrieval with a graph retrieval using concise triplets. A knowledge association graph is then built from semantic similarity and co-occurrence. Finally, Personalized PageRank is leveraged to highlight key knowledge within this graph, reducing the number of tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative Process-aware Direct Preference Optimization (IP-DPO) is proposed. Specifically, our reward function evaluates the knowledge sufficiency by a knowledge matching mechanism, while penalizing excessive reasoning steps. This design can produce high-quality preference-pair datasets, supporting iterative DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at https://github.com/Applied-Machine-Learning-Lab/TeaRAG.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-11-07",
        "category": "cs.AI",
        "crawl_time": "2025-11-10T11:00:04.461122",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。以下是我的详细判断过程： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出了一种名为TeaRAG的、旨在提升Token效率的**Agentic RAG框架**。它不是简单地将RAG应用到一个新领域，而是针对现有Agentic RAG框架的缺陷（Token开销大）进行改进，提出了一套新的方法论。 - **判断**: 这完全符合您“构建、改进或演化LLM智能体”的核心目标。它属于对现有智能体框架的**改进**，因此应**保留**。 2.  **第二步：正面指标** - **核心范式**: 论文标题和摘要中多次明确提到 `Agentic`，直接命中了您的核心关注点。 - **智能体能力**: - **工具使用**: 论文的核心改进之一是“压缩检索内容”，这直接优化了智能体使用“检索”这一关键工具的效率。 - **规划/推理**: 论文的另一个核心是“减少推理步骤”，并为此提出了IP-DPO方法。这直接针对智能体的多步推理和规划过程进行优化，使其更简洁高效。 - **演化机制**: 论文提出的IP-DPO（迭代过程感知直接偏好优化）通过奖励函数引导模型进行自我完善，学习更简洁的推理路径。这可以被视为一种**自我完善**或**自我精炼**的机制，符合“自我演化”的广义范畴。 3.  **第三步：排除标准** - 论文的研究焦点是智能体的效率和性能，完全没有涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐议题。 - 论文是纯文本的RAG框架，不涉及 `Vision`, `MLLMs` 等多模态内容。 - 因此，论文未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”情况的完美范例。它研究的不是LLM本身的基础数学或逻辑能力，而是**智能体在执行任务时的推理过程**（如何用更少的步骤完成任务）。这正是您所关注的Agentic框架中的规划与推理环节。 **总结**: 该论文的核心是提出一个**新的Agentic框架**，通过优化智能体的**工具使用**（检索压缩）和**推理规划**（步骤精简）能力，使其更加高效。这直接对齐了您研究课题中的“单智能体”方向，特别是关于智能体规划和工具使用的子方向。因此，这篇论文是高度相关的前沿研究，应被筛选入内。"
    },
    {
        "index": "#29",
        "title": "DeepEyesV2: Toward Agentic Multimodal Model",
        "link": "/arxiv/2511.05271",
        "arxiv_id": "2511.05271",
        "authors": "Jack Hong, Chenxiao Zhao, ChengLin Zhu, Weiheng Lu, Guohai Xu, Xing Yu",
        "summary": "Agentic multimodal models should not only comprehend text and images, but also actively invoke external tools, such as code execution environments and web search, and integrate these operations into reasoning. In this work, we introduce DeepEyesV2 and explore how to build an agentic multimodal model from the perspectives of data construction, training methods, and model evaluation. We observe that direct reinforcement learning alone fails to induce robust tool-use behavior. This phenomenon motivates a two-stage training pipeline: a cold-start stage to establish tool-use patterns, and reinforcement learning stage to further refine tool invocation. We curate a diverse, moderately challenging training dataset, specifically including examples where tool use is beneficial. We further introduce RealX-Bench, a comprehensive benchmark designed to evaluate real-world multimodal reasoning, which inherently requires the integration of multiple capabilities, including perception, search, and reasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative benchmarks, demonstrating its effectiveness across real-world understanding, mathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2 exhibits task-adaptive tool invocation, tending to use image operations for perception tasks and numerical computations for reasoning tasks. Reinforcement learning further enables complex tool combinations and allows model to selectively invoke tools based on context. We hope our study can provide guidance for community in developing agentic multimodal models.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-11-07",
        "category": "cs.AI",
        "crawl_time": "2025-11-10T11:00:04.469635",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **核心判断 (第一步):** - **保留**: 论文的核心贡献是**构建和改进一个LLM智能体**。标题明确指出目标是“Toward Agentic Multimodal Model”，摘要详细阐述了从数据构建、训练方法到模型评估的完整流程，旨在解决“如何构建一个智能体多模态模型”的问题。这直接命中了你筛选标准中的“构建、改进LLM智能体的方法论或新框架”。 - **非排除**: 论文并非将已有智能体作为工具应用于特定领域，其贡献在于智能体本身的设计和训练。同时，它研究的推理是与工具使用紧密结合的Agentic推理，而非单纯的LLM基础能力提升。 2.  **正面指标 (第二步):** - 论文包含了大量你的核心关注点。标题和摘要中反复出现 `Agentic`、`Tool Use`、`Reasoning`。 - 具体而言，论文的核心创新点——一个包含冷启动和强化学习的两阶段训练流程——是为了**改进智能体的工具使用能力**。这属于“单智能体”方向下的“工具使用”子方向。 - 强化学习阶段用于“refine tool invocation”，这体现了智能体通过反馈进行**自我完善**的机制，与“自我演化”方向中的“自我完善”和“迭代改进”高度相关。 3.  **排除标准 (第三步):** - 论文的主要贡献不在于安全、对齐或可解释性，因此不触发排除标准。 - **关于多模态**: 虽然论文涉及视觉，但它完全符合你的特殊规则。视觉在这里是智能体**感知环境的工具**（“use image operations for perception tasks”），而不是研究的核心。论文的核心是“Agentic”，即如何让一个多模态模型具备主动调用工具和推理的能力，而非提出新的视觉模型或算法。因此，这不应成为排除的理由。 4.  **特殊和模糊情况 (第四步):** - **推理/规划**: 论文研究的推理是智能体框架下的推理，需要“integrate these operations into reasoning”，这符合保留条件。 - **自我演化的应用**: 论文提出的两阶段训练方法，特别是通过强化学习来“refine tool invocation”和实现“complex tool combinations”，本质上是一种让智能体能力迭代增强的机制，可以视为一种**自我完善**的方法论，符合你的研究目标。 **最终决策 (第五步):** 综合分析，这篇论文的核心贡献在于提出了一套构建和改进LLM智能体（特别是其工具使用能力）的新方法。它精准地聚焦于“单智能体”方向，并触及了“自我演化”中的自我完善机制。尽管涉及多模态，但其服务于Agentic AI的核心目标。因此，这篇论文与你的研究课题高度相关，应该被保留。"
    },
    {
        "index": "#101",
        "title": "AI-Powered Citation Auditing: A Zero-Assumption Protocol for Systematic Reference Verification in Academic Research",
        "link": "/arxiv/2511.04683",
        "arxiv_id": "2511.04683",
        "authors": "L. J. Janse van Rensburg",
        "summary": "Academic citation integrity faces persistent challenges, with research indicating 20% of citations contain errors and manual verification requiring months of expert time. This paper presents a novel AI-powered methodology for systematic, comprehensive reference auditing using agentic AI with tool-use capabilities. We develop a zero-assumption verification protocol that independently validates every reference against multiple academic databases (Semantic Scholar, Google Scholar, CrossRef) without assuming any citation is correct. The methodology was validated across 30 academic documents (2,581 references) spanning undergraduate projects to doctoral theses and peer-reviewed publications. Results demonstrate 91.7% average verification rate on published PLOS papers, with successful detection of fabricated references, retracted articles, orphan citations, and predatory journals. Time efficiency improved dramatically: 90-minute audits for 916-reference doctoral theses versus months of manual review. The system achieved <0.5% false positive rate while identifying critical issues manual review might miss. This work establishes the first validated AI-agent methodology for academic citation integrity, demonstrating practical applicability for supervisors, students, and institutional quality assurance.",
        "subjects": "Digital Libraries, Artificial Intelligence, Computers and Society",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-11-10T11:00:04.526460",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将一个已有的LLM智能体作为工具应用到“引文审计”这个领域。其核心贡献在于提出了一套**全新的、系统化的方法论**——“zero-assumption verification protocol”（零假设验证协议），并构建了一个具备**工具使用能力的AI智能体**来实现这一协议。论文明确指出其工作是“establishes the first validated AI-agent methodology for academic citation integrity”（建立了首个经过验证的用于学术引文完整性的AI智能体方法论）。这表明，研究的焦点是**如何构建和设计一个能够自主、系统地完成复杂任务的智能体系统**，而不仅仅是展示应用结果。这完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文摘要中明确包含了多个核心关注点： - **核心范式**: `Agentic AI` (明确提及) - **智能体能力**: `Tool Use / Tool Augmentation` (明确提及，智能体使用多个学术数据库进行验证) - **规划**: 虽然没有直接使用\"Planning\"一词，但描述的“独立验证每一条参考文献”、“对照多个学术数据库”等行为，本质上是一个需要智能体自主规划和执行的多步骤复杂任务流程。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐，也未涉及多模态与视觉。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何进行规划和执行复杂任务的典型案例。它不是在提升LLM的基础推理能力，而是在构建一个应用层级的智能体框架来解决实际问题。这符合“保留”的条件。 - **应用与方法的界限**: 这是最关键的一点。虽然论文的应用领域是“引文审计”，但其核心贡献是**提出并验证了一种构建智能体的新方法**。这与“非演化型应用”有本质区别。后者通常是“我们用Auto-GPT解决了X问题”，而本文是“我们设计了一个新的智能体协议来解决X问题，并验证了该协议的有效性”。因此，它属于研究范围内的“构建LLM智能体”的论文。 **最终决策**：综合以上分析，该论文的核心贡献在于提出并实现了一个具备工具使用能力的AI智能体方法论，用于解决一个复杂的、需要多步规划和自主执行的任务。这完全符合“构建、改进LLM智能体”的研究目标，因此应被保留。"
    },
    {
        "index": "#52",
        "title": "Grounded Test-Time Adaptation for LLM Agents",
        "link": "/arxiv/2511.04847",
        "arxiv_id": "2511.04847",
        "authors": "Arthur Chen, Zuxin Liu, Jianguo Zhang, Akshara Prabhakar, Zhiwei Liu, Shelby Heinecke, Silvio Savarese, Victor Zhong, Caiming Xiong",
        "summary": "Large language model (LLM)-based agents struggle to generalize to novel and complex environments, such as unseen websites or new sets of functions, due to a fundamental mismatch between their pre-training and test-time conditions. This challenge stems from two distinct failure modes: a syntactic misunderstanding of environment-specific components like observation formats, and a semantic misunderstanding of state-transition dynamics, which are only revealed at test time. To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment. First, an online distributional adaptation method parameterizes environmental nuances by learning a lightweight adaptation vector that biases the model's output distribution, enabling rapid alignment with an environment response format. Second, a deployment-time dynamics grounding method employs a persona-driven exploration phase to systematically probe and learn the environment's causal dynamics before task execution, equipping the agent with a nonparametric world model. We evaluate these strategies across diverse agentic benchmarks, including function calling and web navigation. Our empirical results show the effectiveness of both strategies across all benchmarks with minimal computational cost. We find that dynamics grounding is particularly effective in complex environments where unpredictable dynamics pose a major obstacle, demonstrating a robust path toward more generalizable and capable LLM-based agents. For example, on the WebArena multi-site split, this method increases the agent's success rate from 2% to 23%.",
        "subjects": "Machine Learning",
        "date": "2025-11-06",
        "category": "cs.LG",
        "crawl_time": "2025-11-10T11:00:04.548494",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于提出了一种改进LLM智能体泛化能力的新方法，属于“自我演化”和“单智能体能力提升”的交叉领域。 1.  **第一步：核心判断——保留** - 论文的核心不是将LLM智能体作为工具去解决某个特定领域（如金融、医疗）的问题，而是直接针对LLM智能体本身的根本缺陷——在测试时难以泛化到新环境——提出了两种改进策略。 - 这两种策略（在线分布适应和动态环境基础）是关于如何让智能体在部署时进行**自我调整和学习**的方法论，完全符合“构建、改进或演化LLM智能体”的核心目标。因此，它不是“非演化型应用”。 2.  **第二步：正面指标——高度匹配** - **核心范式**: 论文明确研究 `LLM-based Agents`。 - **自我演化机制**: 论文的标题和核心贡献是 `Test-Time Adaptation`（测试时适应），这本身就是一种**自我演化**或**自我改进**的形式。摘要中提到的“learning a lightweight adaptation vector”（学习轻量级适应向量）和“learn the environment's causal dynamics”（学习环境的因果动力学）都是智能体在部署后根据环境反馈进行自我完善的明确体现。 - **智能体能力**: 论文通过“persona-driven exploration phase”（角色驱动的探索阶段）来学习环境，这涉及到智能体的自主探索和对环境的理解，是高级规划和工具使用能力的基础。 3.  **第三步：排除标准——不涉及** - 论文的主要贡献不涉及安全、对齐、可解释性或水印。 - 论文不涉及多模态或视觉模型，其评估基准是函数调用和网页导航，属于典型的LLM智能体任务。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 论文提出的“动态环境基础”方法，通过探索阶段学习环境的因果动力学，构建了一个非参数化的世界模型。这直接赋能智能体在复杂环境中进行更有效的规划和决策，属于智能体框架的范畴，而非单纯提升LLM的基础推理能力。 - **自我演化的应用**: 这篇论文是提出一种新的“自我演化”机制的典型范例，即使它在网页导航等具体任务上进行验证，其核心贡献是普适性的智能体适应机制，因此必须保留。 **总结**: 该论文的核心是提出两种让LLM智能体在部署到新环境时，能够通过在线学习和适应来提升自身性能的方法。这直接命中了您研究目标中的“自我演化”方向，同时也极大地增强了“单智能体”的泛化和规划能力。因此，这是一篇高度相关且前沿的论文，应被保留。"
    }
]