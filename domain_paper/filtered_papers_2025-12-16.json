[
    {
        "index": "#21",
        "title": "CogMem: A Cognitive Memory Architecture for Sustained Multi-Turn Reasoning in Large Language Models",
        "link": "/arxiv/2512.14118",
        "arxiv_id": "2512.14118",
        "authors": "Yiran Zhang, Jincheng Hu, Mark Dras, Usman Naseem",
        "summary": "Large language models (LLMs) excel at single-turn reasoning but often lose accuracy and coherence over extended, multi-turn interactions. Recent evaluations such as TurnBench highlight recurring failure modes-reasoning bias, task drift, hallucination, overconfidence, and memory decay. Current approaches typically append full conversational histories, causing unbounded context growth, higher computational costs, and degraded reasoning efficiency. We introduce CogMem, a cognitively inspired, memory-augmented LLM architecture that supports sustained iterative reasoning through structured, persistent memory. CogMem incorporates three layers: a Long-Term Memory (LTM) that consolidates cross-session reasoning strategies; a Direct Access (DA) memory that maintains session-level notes and retrieves relevant long-term memories; and a Focus of Attention (FoA) mechanism that dynamically reconstructs concise, task-relevant context at each turn. Experiments on TurnBench show that this layered design mitigates reasoning failures, controls context growth, and improves consistency across extended reasoning chains, moving toward more reliable, human-like reasoning in LLMs.",
        "subjects": "Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.410499",
        "filter_reason": "这篇论文符合研究范围。其核心贡献是提出了一种名为CogMem的新型认知记忆架构，用于增强LLM在多轮交互中的持续推理能力，这直接属于“构建、改进LLM智能体”的范畴。 具体判断过程如下： 1.  **第一步：核心判断** - **保留**。论文的本质不是将LLM应用于某个特定领域，而是提出了一种新的**架构**来解决LLM在多轮交互中的根本性问题（如记忆衰减、推理偏差）。这种架构层面的创新，旨在构建一个更强大的、能够进行持续推理的智能体，完全符合“构建或改进LLM智能体”的核心目标。它不是简单的应用，也不是非Agentic的基础能力提升。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **智能体能力**: 论文的核心是 `Memory`（记忆），具体提出了长期记忆（LTM）、直接访问记忆（DA）等分层结构。这是智能体能力的关键组成部分。 - **智能体能力**: 论文的目标是支持 `Sustained Multi-Turn Reasoning`（持续的多轮推理），这与 `Planning`（规划）和 `ReAct` 等Agentic推理范式紧密相关。它关注的是智能体如何在复杂任务中维持推理链。 - 这些指标明确指向了研究焦点中的**“单智能体”**方向，特别是其子方向“记忆”和“规划”。 3.  **第三步：排除标准** - 论文没有触发任何排除标准。虽然摘要中提到该架构可以缓解“幻觉”，但其**主要贡献**是记忆架构本身，而不是一种新的安全或对齐技术。幻觉的减少是其架构改进带来的**效果**，而非研究目的。论文也未涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于“智能体如何进行规划或在复杂任务中进行多步推理”的典型范例。CogMem架构就是为了支持这种持续的、迭代的推理过程而设计的，因此完全符合“保留”的条件。它超越了单纯的LLM能力提升，进入了构建智能体系统的层面。 **最终决策**：综合以上分析，CogMem论文通过构建一个增强智能体记忆和推理能力的新架构，完全契合您关于“LLM智能体及其演化”中“单智能体”方向的研究目标。因此，应予以保留。"
    },
    {
        "index": "#30",
        "title": "RecGPT-V2 Technical Report",
        "link": "/arxiv/2512.14503",
        "arxiv_id": "2512.14503",
        "authors": "Chao Yi, Dian Chen, Gaoyang Guo, Jiakai Tang, Jian Wu, Jing Yu, Mao Zhang, Wen Chen, Wenjun Yang, Yujie Luo, Yuning Jiang, Zhujin Gao, Bo Zheng, Binbin Cao, Changfa Wu, Dixuan Wang, Han Wu, Haoyi Hu, Kewei Zhu, Lang Tian, Lin Yang, Qiqi Huang, Siqi Yang, Wenbo Su, Xiaoxiao He, Xin Tong, Xu Chen, Xunke Xi, Xiaowei Huang, Yaxuan Wu, Yeqiu Yang, Yi Hu, Yujin Yuan, Yuliang Yan, Zile Zhou",
        "summary": "Large language models (LLMs) have demonstrated remarkable potential in transforming recommender systems from implicit behavioral pattern matching to explicit intent reasoning. While RecGPT-V1 successfully pioneered this paradigm by integrating LLM-based reasoning into user interest mining and item tag prediction, it suffers from four fundamental limitations: (1) computational inefficiency and cognitive redundancy across multiple reasoning routes; (2) insufficient explanation diversity in fixed-template generation; (3) limited generalization under supervised learning paradigms; and (4) simplistic outcome-focused evaluation that fails to match human standards. To address these challenges, we present RecGPT-V2 with four key innovations. First, a Hierarchical Multi-Agent System restructures intent reasoning through coordinated collaboration, eliminating cognitive duplication while enabling diverse intent coverage. Combined with Hybrid Representation Inference that compresses user-behavior contexts, our framework reduces GPU consumption by 60% and improves exclusive recall from 9.39% to 10.99%. Second, a Meta-Prompting framework dynamically generates contextually adaptive prompts, improving explanation diversity by +7.3%. Third, constrained reinforcement learning mitigates multi-reward conflicts, achieving +24.1% improvement in tag prediction and +13.0% in explanation acceptance. Fourth, an Agent-as-a-Judge framework decomposes assessment into multi-step reasoning, improving human preference alignment. Online A/B tests on Taobao demonstrate significant improvements: +2.98% CTR, +3.71% IPV, +2.19% TV, and +11.46% NER. RecGPT-V2 establishes both the technical feasibility and commercial viability of deploying LLM-powered intent reasoning at scale, bridging the gap between cognitive exploration and industrial utility.",
        "subjects": "Information Retrieval, Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.421626",
        "filter_reason": "这篇论文符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。尽管论文的应用领域是推荐系统，但其核心贡献并非简单地将LLM或现有智能体框架作为工具应用。相反，论文的核心是**构建和改进LLM智能体系统本身**。摘要明确提出了两个关键创新：`Hierarchical Multi-Agent System`（分层多智能体系统）和`Agent-as-a-Judge`（智能体即评判者）框架。这些都是关于如何设计、组织和优化智能体以完成复杂任务的新方法论，完全符合“构建、改进或演化LLM智能体”的核心目标。它不是一篇“非演化型应用”论文，而是一篇以应用为背景，探讨智能体架构创新的论文。 2.  **第二步：正面指标** - 论文包含了多个核心关注点，相关性极强： - **核心范式**: `Multi-Agent Systems (MAS)` 被明确作为核心创新提出。 - **多智能体**: `Collaboration`（协作）被提及，用于描述多智能体系统如何工作。 - **智能体能力**: 论文的核心是关于`Reasoning`（推理），特别是通过多智能体协作和`Agent-as-a-Judge`框架实现的`multi-step reasoning`（多步推理）。 - 这些正面指标直接命中了你研究范围中的“多智能体”方向。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态。虽然提到了`human preference alignment`（人类偏好对齐），但这是通过`Agent-as-a-Judge`框架实现的评估改进，属于智能体能力的一部分，而非论文的核心贡献是关于对齐技术本身。因此，不触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”条件。它不是在提升LLM的基础推理能力，而是在构建一个**智能体框架**来执行复杂的意图推理和评估推理。`Hierarchical Multi-Agent System`和`Agent-as-a-Judge`都是典型的Agentic框架，用于结构化和分解复杂的推理任务。 5.  **第五步：最终决策** - 综合分析，这篇论文的核心是提出了一种新颖的**分层多智能体系统**来优化推荐系统中的推理过程。虽然其应用场景是推荐系统，但其研究本质是关于多智能体如何协作、如何进行结构化推理的Agentic AI方法论。这完全符合你研究课题中的“多智能体”方向，并且是关于“构建和改进LLM智能体”的前沿探索。因此，应判定为符合要求。"
    },
    {
        "index": "#34",
        "title": "Grammar Search for Multi-Agent Systems",
        "link": "/arxiv/2512.14079",
        "arxiv_id": "2512.14079",
        "authors": "Mayank Singh, Vikas Yadav, Shiva Krishna Reddy Malay, Shravan Nayak, Sai Rajeswar, Sathwik Tejaswi Madhusudhan, Eduardo Blanco",
        "summary": "Automatic search for Multi-Agent Systems has recently emerged as a key focus in agentic AI research. Several prior approaches have relied on LLM-based free-form search over the code space. In this work, we propose a more structured framework that explores the same space through a fixed set of simple, composable components. We show that, despite lacking the generative flexibility of LLMs during the candidate generation stage, our method outperforms prior approaches on four out of five benchmarks across two domains: mathematics and question answering. Furthermore, our method offers additional advantages, including a more cost-efficient search process and the generation of modular, interpretable multi-agent systems with simpler logic.",
        "subjects": "Artificial Intelligence, Computation and Language, Multiagent Systems",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.428835",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接命中了你的研究焦点。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一种**新的方法论/框架**，用于**自动搜索和构建多智能体系统**。摘要中明确指出，它探索的是“Multi-Agent Systems”的“code space”，并提出了一种“structured framework”。这完全符合你筛选标准中“核心贡献在于构建、改进或演化LLM智能体”的要求，特别是“多智能体系统”这一方向。它不是将已有智能体作为工具去解决特定领域问题，而是研究如何**创造**出更优的智能体系统本身。 2.  **第二步：正面指标** - 论文摘要中包含了多个核心正面指标：`Multi-Agent Systems (MAS)`、`Agentic AI`。虽然未直接使用“Self-Evolving”，但其核心的“Automatic search”机制，即通过搜索来发现和生成更优的多智能体系统，本质上是一种**系统层面的演化或迭代优化过程**，与“自我演化”的理念高度契合。 3.  **第三步：排除标准** - 论文的主要贡献**不是**关于安全、对齐或多模态。摘要中提到的“interpretable”（可解释）是其方法带来的一个**优点**，而不是论文研究的核心问题。论文的核心是“搜索方法”，而不是“如何让智能体可解释”，因此不触发排除规则。 4.  **第四步：处理特殊和模糊情况** - 这篇论文的研究内容超越了单纯的推理/规划，它关注的是**如何发现和组合智能体以形成一个高效的多智能体系统**。这是一种更高层次的、关于智能体系统架构的构建与演化，完全符合你的研究目标。 **最终决策**: 该论文的核心贡献是提出了一种用于自动构建和优化多智能体系统的新搜索框架。这直接对应了你研究课题中的“多智能体”方向，并且其“自动搜索”的机制与“自我演化”的理念紧密相关。因此，这篇论文是关于Agentic AI基础方法论的典型研究，与你的筛选标准高度匹配，应当保留。"
    },
    {
        "index": "#36",
        "title": "Hierarchical Multi-agent Large Language Model Reasoning for Autonomous Functional Materials Discovery",
        "link": "/arxiv/2512.13930",
        "arxiv_id": "2512.13930",
        "authors": "Samuel Rothfarb, Megan C. Davis, Ivana Matanovic, Baikun Li, Edward F. Holby, Wilton J. M. Kort-Kamp",
        "summary": "Artificial intelligence is reshaping scientific exploration, but most methods automate procedural tasks without engaging in scientific reasoning, limiting autonomy in discovery. We introduce Materials Agents for Simulation and Theory in Electronic-structure Reasoning (MASTER), an active learning framework where large language models autonomously design, execute, and interpret atomistic simulations. In MASTER, a multimodal system translates natural language into density functional theory workflows, while higher-level reasoning agents guide discovery through a hierarchy of strategies, including a single agent baseline and three multi-agent approaches: peer review, triage-ranking, and triage-forms. Across two chemical applications, CO adsorption on Cu-surface transition metal (M) adatoms and on M-N-C catalysts, reasoning-driven exploration reduces required atomistic simulations by up to 90% relative to trial-and-error selection. Reasoning trajectories reveal chemically grounded decisions that cannot be explained by stochastic sampling or semantic bias. Altogether, multi-agent collaboration accelerates materials discovery and marks a new paradigm for autonomous scientific exploration.",
        "subjects": "Materials Science, Artificial Intelligence, Computation and Language, Machine Learning, Multiagent Systems",
        "date": "2025-12-15",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.430290",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的筛选标准高度契合。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将LLM作为工具应用于材料科学领域。它的核心贡献是**构建了一个名为MASTER的全新多智能体框架**。该框架旨在实现“自主科学探索”，其创新点在于智能体之间的协作与推理机制，而非材料发现的具体结果。论文明确提出了“单智能体基线”和“三种多智能体方法”，这表明其研究焦点是智能体架构本身的设计与比较，完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了大量您关注的核心指标： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文标题和摘要的核心。`Agentic AI` 和 `LLM-based Agents` 是其基础。 - **智能体能力**: 摘要中提到智能体“自主地设计、执行和解释”，这直接对应了 `Planning` 和 `Tool Use`（执行原子模拟）。 - **多智能体**: 论文的核心贡献在于多智能体协作，明确提到了 `Collaboration`（“多智能体协作加速了材料发现”），并描述了具体的协作策略，如 `peer review`（同行评议），这可以看作是一种特殊的 `Communication` 和 `Negotiation` 机制。 3.  **第三步：排除标准** - 论文未触发任何排除标准。 - **安全与对齐**: 摘要中未提及任何关于安全、对齐、可解释性或幻觉的研究。 - **多模态与视觉**: 虽然提到了“多模态系统”，但其作用是“将自然语言翻译成密度泛函理论工作流”，这是作为智能体与环境（科学计算工具）交互的**工具**，而不是研究的核心。研究的核心是这个多智能体框架，而非多模态技术本身。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确是关于智能体如何进行推理的（“reasoning agents guide discovery”），属于“保留”范畴。它不是在改进LLM的基础推理能力，而是在构建一个让智能体能够进行复杂科学推理的框架。 - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美体现。虽然它应用在“功能材料发现”这一特定领域，但其**核心贡献是提出了一种新的多智能体协作与推理机制**。这种机制本身具有通用性，是您研究“多智能体”方向的宝贵素材。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**提出了一种新颖的分层多智能体协作框架（MASTER），用于实现自主的科学推理与探索**。它直接命中了您研究焦点中的“多智能体”方向，深入探讨了智能体间的协作策略（如同行评议、分诊排序），并展示了智能体在规划、工具使用方面的能力。尽管其应用领域是材料科学，但这恰恰是验证其智能体框架有效性的实验场，论文的价值在于框架本身，而非应用结果。因此，这篇论文是您课题“LLM智能体及其演化”的典型前沿研究，应予以保留。"
    },
    {
        "index": "#2",
        "title": "Multi-Agent Collaborative Framework for Intelligent IT Operations: An AOI System with Context-Aware Compression and Dynamic Task Scheduling",
        "link": "/arxiv/2512.13956",
        "arxiv_id": "2512.13956",
        "authors": "Zishan Bai, Enze Ge, Junfeng Hao",
        "summary": "The proliferation of cloud-native architectures, characterized by microservices and dynamic orchestration, has rendered modern IT infrastructures exceedingly complex and volatile. This complexity generates overwhelming volumes of operational data, leading to critical bottlenecks in conventional systems: inefficient information processing, poor task coordination, and loss of contextual continuity during fault diagnosis and remediation. To address these challenges, we propose AOI (AI-Oriented Operations), a novel multi-agent collaborative framework that integrates three specialized agents with an LLM-based Context Compressor. Its core innovations include: (1) a dynamic task scheduling strategy that adaptively prioritizes operations based on real-time system states, and (2) a three-layer memory architecture comprising Working, Episodic, and Semantic layers that optimizes context retention and retrieval. Extensive experiments on both synthetic and real-world benchmarks demonstrate that AOI effectively mitigates information overload, achieving a 72.4% context compression ratio while preserving 92.8% of critical information and significantly enhances operational efficiency, attaining a 94.2% task success rate and reducing the Mean Time to Repair (MTTR) by 34.4% compared to the best baseline. This work presents a paradigm shift towards scalable, adaptive, and context-aware autonomous operations, enabling robust management of next-generation IT infrastructures with minimal human intervention.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-12-15",
        "category": "cs.MA",
        "crawl_time": "2025-12-17T11:00:04.463102",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **核心判断 (第一步): 论文的核心贡献是构建一个新的多智能体框架，而非简单的应用。** 摘要明确指出，论文的核心是提出一个 \"novel multi-agent collaborative framework\" (新颖的多智能体协作框架) AOI。它不是简单地将一个已有的智能体框架（如LangChain或AutoGPT）应用到IT运维领域，而是设计了一个包含三个专门化智能体、动态任务调度策略和三层记忆架构的全新系统。这直接命中了你筛选标准中的“保留”条件：**核心贡献在于构建、改进LLM智能体或多智能体系统的方法论或新框架**。 2.  **正面指标 (第二步): 论文包含了多个核心关注点。** *   **多智能体**: 论文标题和摘要反复强调 \"Multi-Agent Collaborative Framework\"，直接对应你的研究焦点。 *   **协作与规划**: 论文的核心创新之一是 \"dynamic task scheduling strategy\" (动态任务调度策略)，这属于多智能体间的协作与规划范畴。 *   **记忆**: 另一个核心创新是 \"three-layer memory architecture\" (三层记忆架构)，这直接对应了单智能体能力中的 `Memory`，是构建高级智能体的关键技术。 3.  **排除标准 (第三步): 论文不涉及安全、对齐或多模态等排除领域。** 论文的研究内容集中在智能体的协作、规划和记忆机制上，没有涉及安全、对齐、幻觉或多模态视觉等问题，因此不触及相关排除标准。 4.  **特殊与模糊情况处理 (第四步): 论文属于“提出新框架”而非“非演化型应用”。** 尽管论文的应用领域是“Intelligent IT Operations”（智能IT运维），这看起来像一个特定领域的应用。但根据你的核心规则，判断的关键在于**贡献的本质**。这篇论文的贡献本质是**提出了一种新的多智能体协作范式**，并用IT运维场景来验证其有效性。这与“将LLM作为工具应用到特定领域”有本质区别。因此，它不应被归为“非演化型应用”而被排除。 **总结**: 该论文的核心贡献是设计并实现了一个具有新颖任务调度和记忆机制的多智能体协作框架（AOI）。这完全契合你研究课题中的“多智能体”方向，并深入探讨了智能体的“规划”和“记忆”能力。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#1",
        "title": "Multi-Agent Medical Decision Consensus Matrix System: An Intelligent Collaborative Framework for Oncology MDT Consultations",
        "link": "/arxiv/2512.14321",
        "arxiv_id": "2512.14321",
        "authors": "Xudong Han, Xianglun Gao, Xiaoyi Qu, Zhenyu Yu",
        "summary": "Multidisciplinary team (MDT) consultations are the gold standard for cancer care decision-making, yet current practice lacks structured mechanisms for quantifying consensus and ensuring decision traceability. We introduce a Multi-Agent Medical Decision Consensus Matrix System that deploys seven specialized large language model agents, including an oncologist, a radiologist, a nurse, a psychologist, a patient advocate, a nutritionist and a rehabilitation therapist, to simulate realistic MDT workflows. The framework incorporates a mathematically grounded consensus matrix that uses Kendall's coefficient of concordance to objectively assess agreement. To further enhance treatment recommendation quality and consensus efficiency, the system integrates reinforcement learning methods, including Q-Learning, PPO and DQN. Evaluation across five medical benchmarks (MedQA, PubMedQA, DDXPlus, MedBullets and SymCat) shows substantial gains over existing approaches, achieving an average accuracy of 87.5% compared with 83.8% for the strongest baseline, a consensus achievement rate of 89.3% and a mean Kendall's W of 0.823. Expert reviewers rated the clinical appropriateness of system outputs at 8.9/10. The system guarantees full evidence traceability through mandatory citations of clinical guidelines and peer-reviewed literature, following GRADE principles. This work advances medical AI by providing structured consensus measurement, role-specialized multi-agent collaboration and evidence-based explainability to improve the quality and efficiency of clinical decision-making.",
        "subjects": "Multiagent Systems",
        "date": "2025-12-16",
        "category": "cs.MA",
        "crawl_time": "2025-12-17T11:00:04.462629",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质是**构建并改进一个多智能体系统**。其核心贡献并非简单地将现有智能体框架应用于医疗领域，而是提出了一个全新的“Multi-Agent Medical Decision Consensus Matrix System”。这个系统包含了三个关键的创新点： 1.  **角色专业化**：部署了七个具有不同专业背景的LLM智能体（肿瘤科医生、放射科医生等）。 2.  **新颖的协作机制**：引入了一个基于数学（Kendall's W）的共识矩阵来量化智能体间的共识。 3.  **系统性能的迭代优化**：集成了强化学习方法（Q-Learning, PPO, DQN）来提升推荐质量和共识效率。 这完全符合“核心贡献在于构建、改进或演化LLM智能体”的保留标准，而不是一个“非演化型应用”。 **第二步：正面指标——高度匹配** 论文包含了大量您关注的核心指标： *   **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 *   **多智能体**: 论文详细描述了智能体间的 `Collaboration`（协作）、`Communication`（通信，通过达成共识体现），并构建了一个 `Agent Society`（智能体社会）来模拟MDT工作流。 *   **演化机制**: 集成强化学习（RL）来优化系统性能，这是一种明确的 `Iterative Improvement`（迭代改进）机制，与“自我演化”方向高度相关。 **第三步：排除标准——未触发** *   **安全与对齐**: 论文提到了“evidence-based explainability”（基于证据的可解释性）和“traceability”（可追溯性）。然而，这些是作为其多智能体框架的**一个特性和优势**被提出的，用于增强临床决策的可靠性，**并非论文的核心研究贡献**。论文的核心是那个多智能体协作框架本身，而不是研究如何实现可解释性或对齐。因此，这不触发排除标准。 *   **多模态与视觉**: 论文未涉及视觉或多模态内容。 **第四步：处理特殊和模糊情况** 这篇论文是“自我演化的应用”的一个绝佳范例。虽然它被应用在“肿瘤学MDT会诊”这一特定领域，但其核心贡献是提出了一种**新的多智能体协作框架和一种用RL进行系统优化的新机制**。这完全符合您设定的“例外”规则：**如果论文的核心是提出一种新的‘自我演化’（或广义上的‘改进’）机制，即使它被应用在特定领域，也应该保留。** **第五步：最终决策** 综合以上分析，该论文的核心贡献在于构建了一个新颖的多智能体协作框架，并引入了强化学习作为迭代改进机制。它直接命中了您的研究焦点“多智能体”，并与“自我演化”紧密相关。尽管其应用场景是医疗领域，但其方法论上的创新是普适的，完全符合您筛选“LLM智能体及其演化”前沿论文的目标。因此，最终判断为 **True**。"
    },
    {
        "index": "#39",
        "title": "EvoLattice: Persistent Internal-Population Evolution through Multi-Alternative Quality-Diversity Graph Representations for LLM-Guided Program Discovery",
        "link": "/arxiv/2512.13857",
        "arxiv_id": "2512.13857",
        "authors": "Kamer Ali Yuksel",
        "summary": "Large language models (LLMs) are increasingly used to evolve programs and multi-agent systems, yet most existing approaches rely on overwrite-based mutations that maintain only a single candidate at a time. Such methods discard useful variants, suffer from destructive edits, and explore a brittle search space prone to structural failure. We introduce EvoLattice, a framework that represents an entire population of candidate programs or agent behaviors within a single directed acyclic graph. Each node stores multiple persistent alternatives, and every valid path through the graph defines a distinct executable candidate, yielding a large combinatorial search space without duplicating structure. EvoLattice enables fine-grained alternative-level evaluation by scoring each alternative across all paths in which it appears, producing statistics that reveal how local design choices affect global performance. These statistics provide a dense, data-driven feedback signal for LLM-guided mutation, recombination, and pruning, while preserving successful components. Structural correctness is guaranteed by a deterministic self-repair mechanism that enforces acyclicity and dependency consistency independently of the LLM. EvoLattice naturally extends to agent evolution by interpreting alternatives as prompt fragments or sub-agent behaviors. Across program synthesis (proxy and optimizer meta-learning), EvoLattice yields more stable evolution, greater expressivity, and stronger improvement trajectories than prior LLM-guided methods. The resulting dynamics resemble quality-diversity optimization, emerging implicitly from EvoLattice's internal multi-alternative representation rather than an explicit external archive.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning, Multiagent Systems, Neural and Evolutionary Computing",
        "date": "2025-12-15",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.431954",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的“自我演化”和“多智能体”研究方向高度契合。以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM作为工具应用，而是提出了一种名为 `EvoLattice` 的**新框架**。该框架的核心是一种**演化方法论**，用于引导LLM来演化程序或智能体行为。摘要明确指出，它解决了现有演化方法的缺陷，并提出了一种全新的“内部种群演化”机制。这完全符合您“核心贡献在于构建、改进或演化LLM智能体”的目标。 2.  **第二步：正面指标** - 论文包含了大量您的核心关注点： - **核心范式**: `Self-Evolving` (论文标题和核心主题), `Multi-Agent Systems` (摘要中明确提到 \"evolve ... multi-agent systems\" 和 \"agent evolution\"), `Evolutionary Algorithms` (其机制是一种演化算法)。 - **演化机制**: `Self-Improvement`, `Generational Evolution`, `Iterative Improvement` (EvoLattice框架通过LLM引导的突变、重组和修剪来实现这些)。 - **多智能体**: 论文明确指出其框架“自然扩展到智能体演化”，并将图中的节点解释为“子智能体行为”。这直接触及了多智能体系统的构建与演化。 3.  **第三步：排除标准** - 论文的主要贡献是关于演化算法和框架设计，而非安全、对齐或多模态。因此，它没有被任何排除标准命中。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它在“程序合成”领域进行评估，但其**核心贡献是提出了一种新的“自我演化”机制 (`EvoLattice`框架)**。摘要中强调，该机制可以泛化到“智能体演化”，这使其价值超越了具体的应用领域，完全符合您筛选此类论文的要求。 **总结**: 该论文的核心贡献是 `EvoLattice`，一个创新的、用于LLM引导的程序和智能体行为演化的框架。它直接解决了“自我演化”这一核心研究方向，并明确扩展到“多智能体”领域。它不是简单的应用，而是提供了一种新的、更强大的演化方法论。因此，这篇论文是您研究课题“LLM智能体及其演化”的前沿和高相关度文献，应予以保留。"
    },
    {
        "index": "#6",
        "title": "LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms",
        "link": "/arxiv/2512.13713",
        "arxiv_id": "2512.13713",
        "authors": "Ali Parsaee, Yashar Talebirad, Csongor Szepesvári, Vishwajeet Ohal, Eden Redman",
        "summary": "Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \\textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infinite loops. A strategy passing mechanism is implemented as a form of consistent memory. We show that while standard LLMs and classical heuristics struggle, advanced reasoning models (e.g., O3) devise strategies to escape deadlocks. LoopBench allows the study of emergent distributed algorithms based on language-based reasoning, offering a testbed for collective intelligence.",
        "subjects": "Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-12-07",
        "category": "cs.MA",
        "crawl_time": "2025-12-17T11:00:04.465216",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的筛选标准高度契合。以下是我的详细判断过程： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出了一个名为 **LoopBench** 的**新基准**。这个基准并非简单应用现有智能体，而是专门设计用来**研究和发现**LLM群体在分布式系统中如何**涌现出新的协作策略**。它通过构建一个特定的挑战性环境（对称破缺图着色问题），来探索和评估LLM智能体的集体智能和演化能力。这完全符合“构建、改进或演化LLM智能体”的核心目标，因为它提供了一种方法论来**促进和理解**智能体的演化。 - **排除项检查**: 论文不是将智能体应用于生物、金融等特定领域（非演化型应用），也不是研究LLM本身的基础推理能力（非Agentic的推理），更不是关于基础设施。因此，它通过了第一步的核心判断。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标，证明其高度相关性： - **核心范式**: 明确涉及 `LLM-based Agents` 和 `Multi-Agent Systems (MAS)`（通过 \"LLM Swarms\", \"distributed systems\" 体现）。 - **多智能体**: 核心关注点就是 `Collaboration`（协作）、`Communication`（通过 \"strategy passing mechanism\" 体现）和 `Agent Society`（智能体社会）。 - **智能体能力**: 涉及 `Planning`（规划，智能体需要 \"devise strategies\"）和 `Memory`（记忆，\"strategy passing mechanism as a form of consistent memory\"）。 - **演化机制**: 论文的核心是研究**涌现**策略，这可以看作是一种群体层面的 `Self-Evolving` 或 `Iterative Improvement`。智能体通过策略传递机制，集体地“演化”出打破僵局的方法。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐问题。 - 论文也未涉及 `Vision`, `MLLMs` 等多模态内容。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文研究的正是智能体在复杂、分布式环境下的**多步推理和规划能力**（如何设计策略避免死锁），而不是提升LLM本身的数学或逻辑能力。这完全符合“保留”的条件。 - **自我演化的应用**: 虽然论文提出了一个基准（可以看作是一种应用框架），但其核心是提出一种研究**“自我演化”机制**的新方法，因此符合“保留”的例外规则。 **最终决策**: 这篇论文的核心贡献在于构建了一个创新的测试平台，用于探索LLM多智能体系统中的**集体智能、协作策略和涌现行为**。它直接对准了您研究焦点中的**“多智能体”**和**“自我演化”**两个方向。论文中提到的“策略传递机制”作为一种一致性记忆，以及研究智能体如何“摆脱死锁”，都深刻地触及了智能体协作与演化的本质。因此，这篇论文是您课题下非常前沿且高度相关的研究，应予以保留。"
    },
    {
        "index": "#94",
        "title": "Gödel's Poetry",
        "link": "/arxiv/2512.14252",
        "arxiv_id": "2512.14252",
        "authors": "Kelly J. Davis",
        "summary": "Formal, automated theorem proving has long been viewed as a challenge to artificial intelligence. We introduce here a new approach to computer theorem proving, one that employs specialized language models for Lean4 proof generation combined with recursive decomposition of difficult theorems into simpler entailing propositions. These models are coordinated through a multi-agent architecture that orchestrates autoformalization (if required), proof generation, decomposition of difficult theorems into simpler entailing propositions, and recursive proof (and/or decomposition) of these propositions. Without decomposition, we achieve a 90.4% pass rate on miniF2F. With decomposition, this is significantly improved. A key technical contribution lies in our extension of the Kimina Lean Server with abstract syntax tree (AST) parsing capabilities to facilitate automated, recursive proof decomposition. The system is made available on PyPI as goedels-poetry (at https://pypi.org/project/goedels-poetry ), and the open-source implementation KellyJDavis/goedels-poetry (at https://github.com/KellyJDavis/goedels-poetry ) facilitates both adaptation to alternative language models and extension with custom functionality.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.626095",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种用于自动化定理证明的**多智能体架构**。这完全符合筛选标准第一步中的“保留”条件，即论文的核心是关于构建LLM智能体或多智能体系统的方法论或新框架。它并非简单地将LLM作为工具应用于数学领域，而是构建了一个新颖的Agentic框架来解决该领域的问题，其贡献在于框架本身，而非应用结果。 2.  **正面指标 (第二步):** 论文包含了多个核心关注点。 *   **核心范式:** 明确提到了 `Multi-Agent Systems (MAS)`。 *   **智能体能力:** 论文中的“递归分解”是一种复杂的 `Planning` 策略，它将困难的定理分解为更简单的子命题进行证明。整个系统通过协调不同模型来使用工具（Lean4证明环境），体现了 `Tool Use`。 *   **多智能体:** 论文的核心就是描述一个多智能体系统，其中不同的智能体（或模型）负责不同的任务（自动形式化、证明生成、分解），这体现了智能体间的 `Collaboration`（协作）和 `Communication`（通信）。 3.  **排除标准 (第三步):** 论文的主要贡献不涉及安全、对齐、可解释性或多模态视觉，因此不触发任何排除标准。 4.  **特殊情况处理 (第四步):** *   **推理/规划:** 这篇论文是“推理/规划”保留规则的典型范例。它不是在研究如何让LLM的数学能力变得更强，而是在研究如何构建一个智能体系统（多智能体架构），通过**规划**（递归分解）和**协作**来完成复杂的推理任务（定理证明）。这正是Agentic AI研究的核心。 **最终决策 (第五步):** 综合以上分析，该论文的核心贡献在于构建了一个用于复杂任务（定理证明）的多智能体协作与规划框架。它直接命中了研究焦点中的“多智能体”方向，并深刻体现了“规划”和“协作”等关键能力。因此，这篇论文与“LLM智能体及其演化”的研究课题高度相关，应该被保留。"
    },
    {
        "index": "#101",
        "title": "ChartAgent: A Chart Understanding Framework with Tool Integrated Reasoning",
        "link": "/arxiv/2512.14040",
        "arxiv_id": "2512.14040",
        "authors": "Boran Wang, Xinming Wang, Yi Chen, Xiang Li, Jian Xu, Jing Yuan, Chenglin Liu",
        "summary": "With their high information density and intuitive readability, charts have become the de facto medium for data analysis and communication across disciplines. Recent multimodal large language models (MLLMs) have made notable progress in automated chart understanding, yet they remain heavily dependent on explicit textual annotations and the performance degrades markedly when key numerals are absent. To address this limitation, we introduce ChartAgent, a chart understanding framework grounded in Tool-Integrated Reasoning (TIR). Inspired by human cognition, ChartAgent decomposes complex chart analysis into a sequence of observable, replayable steps. Supporting this architecture is an extensible, modular tool library comprising more than a dozen core tools, such as keyelement detection, instance segmentation, and optical character recognition (OCR), which the agent dynamically orchestrates to achieve systematic visual parsing across diverse chart types. Leveraging TIRs transparency and verifiability, ChartAgent moves beyond the black box paradigm by standardizing and consolidating intermediate outputs into a structured Evidence Package, providing traceable and reproducible support for final conclusions. Experiments show that ChartAgent substantially improves robustness under sparse annotation settings, offering a practical path toward trustworthy and extensible systems for chart understanding.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.628069",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一个名为 **ChartAgent** 的图表理解框架，其本质是一个基于**工具集成推理（TIR）**的 LLM 智能体。论文详细描述了该智能体的架构：它如何将复杂任务分解为步骤，以及如何动态编排一个包含OCR、分割等工具的工具库。这完全符合“构建LLM智能体的方法论或新框架”的保留标准。它不是简单地将一个已有智能体作为工具应用，而是**构建了一个新的智能体本身**。 2.  **第二步：正面指标** 论文命中了多个核心正面指标，与您的研究焦点高度契合： *   **核心范式**: 论文标题和摘要反复强调 `Agent`，其核心是 `LLM-based Agent`。 *   **智能体能力**: 论文的亮点是 `Tool Use / Tool Augmentation`（工具集成推理、动态编排工具库）。同时，它也涉及 `Planning`（将复杂图表分析分解为一系列步骤），这与 `ReAct` 等范式思想一致。 *   **研究焦点**: 该论文明确属于您关注的 **“单智能体”** 方向，特别是其中的“工具使用”和“规划”子方向。 3.  **第三步：排除标准** *   **安全与对齐**: 论文未涉及安全、对齐、可解释性等主题，其目标是提升鲁棒性和可追溯性，属于性能优化，因此不在此排除范围内。 *   **多模态与视觉**: 这是本论文最需要辨析的一点。虽然论文处理的是图表（视觉数据），但它完全符合筛选标准中的例外情况：“**除非它们被用作智能体感知环境的工具，而不是研究的核心**”。在这篇论文中，视觉理解（通过OCR、分割等工具）是智能体**用来完成任务的手段**，而论文的**核心贡献是智能体本身的架构和推理框架**，而非提出一种新的视觉模型或多模态融合方法。因此，不应被排除。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文符合“保留”标准。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个**智能体框架**，让智能体能够进行多步规划和推理（“decomposes complex chart analysis into a sequence of observable, replayable steps”）。 **最终决策**: 综合以上分析，ChartAgent 论文的核心贡献在于构建了一个具备工具使用和规划能力的 LLM 智能体框架。它完美地契合了您研究课题中的“单智能体”方向，特别是“工具使用”和“规划”这两个子方向。尽管其应用领域是多模态的图表理解，但其方法论贡献是关于智能体本身的，因此完全符合您的筛选要求。"
    },
    {
        "index": "#117",
        "title": "Mathematics and Coding are Universal AI Benchmarks",
        "link": "/arxiv/2512.13764",
        "arxiv_id": "2512.13764",
        "authors": "Przemyslaw Chojecki",
        "summary": "We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uniform tightness of agent outputs and a Lipschitz AAI functional, the subspace of batteries generated by mathematical theorem-proving and coding tasks is dense in the moduli space of batteries with respect to the evaluation metric. Coding alone is universal in this sense, while pure mathematics is not; its privilege is spectral rather than expressive. We interpret this as evidence that mathematics and coding provide ``universal coordinates'' for evaluation, and that formal mathematics is a natural ignition domain for recursive self-improvement in advanced AI agents.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.632874",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断的核心依据在于，尽管论文标题和部分内容涉及“基准”，但其核心贡献并非提出一个新的评测数据集，而是从理论层面揭示了数学和编码作为特定环境，如何为LLM智能体的“自我演化”提供一种稳定且强大的机制。 具体分析如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地应用LLM或智能体去解决数学问题，也不是非Agentic的推理能力提升。它的核心贡献在于提出并论证了一个关于智能体“自我演化”的理论框架。论文明确指出，当智能体在“数学纤维”上运行时，由于存在形式化证明内核（如Lean, Coq）提供的“神谕般验证”，其演化过程（GVU flows）会进入“谱稳定的自我改进机制”。这直接命中了研究目标中的“自我演化”方向，探讨的是智能体如何通过环境反馈进行迭代和完善的内在机制。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **自我演化**: 明确提到了 `self-improvement regimes` 和 `recursive self-improvement`，这是论文最核心的亮点。 - **工具使用**: 论文将形式化证明内核视为一种工具，智能体通过与这个工具交互获得即时、无歧义的反馈，这是其自我改进机制得以成立的关键。 - **自我反思/修正**: “神谕般验证”本质上是一种强大的外部自我修正信号，驱动智能体的演化。 3.  **第三步：排除标准** - 论文不涉及安全、对齐、可解释性或视觉等多模态内容，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文完美符合第四步中的“例外”规则。虽然它以“数学”和“编码”为具体领域，但其核心贡献是提出了一种新的“自我演化”机制（即基于形式化验证的递归自我改进），而不是仅仅将智能体应用于数学领域。论文的结论——“形式化数学是高级AI智能体递归自我改进的自然启动域”——直接将数学定位为实现自我演化的催化剂和试验场，这正是研究课题所关注的前沿问题。 **最终决策**: 综合来看，这篇论文虽然使用了“基准”等词汇，但其内核是关于Agentic AI如何实现“自我演化”的深刻理论探讨。它识别并形式化了一个强大的自我演化范式（形式化数学+验证器），为构建能够持续自我完善的智能体提供了理论基础和实现路径。因此，它完全符合“LLM智能体及其演化”这一研究课题，特别是“自我演化”的核心方向，应被**保留**。"
    },
    {
        "index": "#127",
        "title": "IPR-1: Interactive Physical Reasoner",
        "link": "/arxiv/2511.15407",
        "arxiv_id": "2511.15407",
        "authors": "Mingyu Zhang, Lifeng Zhuo, Tianxi Tan, Guocan Xie, Xian Nie, Yan Li, Renjie Zhao, Zizhu He, Ziyu Wang, Jiting Cai, Yong-Lu Li",
        "summary": "Humans learn by observing, interacting with environments, and internalizing physics and causality. Here, we aim to ask whether an agent can similarly acquire human-like reasoning from interaction and keep improving with more experience. We study this in a Game-to-Unseen (G2U) setting, curating 1,000+ heterogeneous games with diverse physical and causal mechanisms, and evaluate at three human-like levels: Survival, Curiosity, Utility, from primitive intuition to goal-driven reasoning. Our analysis reveals complementary failures: VLM/VLA agents reason but lack look-ahead in interactive settings, while world models imagine but imitate visual patterns rather than analyze physics and causality. We therefore propose IPR (Interactive Physical Reasoner), using world-model rollouts to score and reinforce a VLM's policy, and introduce PhysCode, a physics-centric action code aligning semantic intent with dynamics to provide a shared action space for prediction and reasoning. Pretrained on 1,000+ games, our IPR performs robustly on three levels, matches GPT-5 overall, and surpasses it on Curiosity. We find that performance improves with more training games and interaction steps, and that the model also zero-shot transfers to unseen games. These results support physics-centric interaction as a path to steadily improving physical reasoning.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-11-19",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.635682",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建一个能够通过交互进行自我演化的智能体。 1.  **核心判断 (第一步):** - **保留**。这篇论文的本质不是简单应用现有技术，而是提出了一种全新的智能体框架 **IPR (Interactive Physical Reasoner)**。它的核心目标是让智能体通过与环境的交互来“acquire human-like reasoning from interaction and keep improving with more experience”（通过交互获得类似人类的推理能力并随着经验增加而持续改进）。这直接命中了您研究目标中的“构建、改进或演化 LLM智能体”，特别是“自我演化”方向。 2.  **正面指标 (第二步):** - 论文包含了多个核心关注点： - **自我演化:** 摘要中明确提到“keep improving with more experience”和“performance improves with more training games and interaction steps”，这表明智能体的性能是随着经验和交互而迭代提升的，是典型的自我演化机制。 - **智能体能力:** 论文提出了一个完整的智能体框架，涉及与环境的交互、策略、以及利用世界模型进行前瞻性推理，这属于智能体的规划和推理能力范畴。 - **核心范式:** 论文的核心是构建一个基于LLM（此处是VLM）的智能体，研究其演化路径。 3.  **排除标准 (第三步):** - 论文的主要贡献并非安全、对齐或可解释性，因此不触发排除标准。 - 虽然论文使用了VLM/VLA（视觉-语言模型），但根据筛选规则，它们是作为智能体“感知环境的工具”，而不是研究的核心。研究的核心是**IPR这个框架本身以及其自我演化的能力**，而不是视觉模型的技术细节。因此，这不构成排除理由。 4.  **特殊和模糊情况 (第四步):** - **自我演化的应用:** 这篇论文可以被看作是“自我演化”机制在“物理推理游戏”这一特定领域的应用。但根据您的核心规则，如果论文的核心是提出一种新的“自我演化”机制，即使应用在特定领域，也应该保留。本文的核心贡献正是IPR这一通过交互进行自我演化的新框架，因此完全符合保留条件。 - **推理/规划:** 论文研究的不是LLM本身的基础推理能力，而是智能体在交互环境中的物理推理和规划能力，这属于Agentic AI的范畴，应予以保留。 **总结:** 该论文的核心贡献是提出了一种名为IPR的交互式物理推理智能体框架。其最突出的特点是该智能体能够通过与环境的持续交互和经验积累来不断自我完善和提升性能，这精准地契合了您研究课题中的“自我演化”方向。因此，这篇论文是高度相关且应被保留的前沿研究。"
    }
]