[
    {
        "index": "#8",
        "title": "Dual Language Models: Balancing Training Efficiency and Overfitting Resilience",
        "link": "/arxiv/2512.14549",
        "arxiv_id": "2512.14549",
        "authors": "David Samuel, Lucas Georges Gabriel Charpentier",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.398801",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了一种新的语言模型训练方法，即“双目标训练”，它结合了自回归和掩码扩散两种训练目标，旨在平衡训练效率和抗过拟合能力。论文的本质是**改进基础语言模型的训练范式和性能**，而不是构建或演化一个智能体。它属于“非Agentic的推理”范畴，因为它关注的是模型本身的基础能力（效率和鲁棒性），而非智能体的自主行为框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要和标题中完全没有出现我的核心关注点。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式，也没有涉及 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等智能体关键能力。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 根据“推理/规划”的特殊规则，这篇论文应被排除。它研究的是如何通过改进训练目标来提升模型的基础性能，这属于“提高LLM本身基础Token预测”的范畴，而不是“关于智能体如何进行规划或在复杂任务中进行多步推理”。它没有提出任何新的Agentic框架（如ReAct或ToT）。 **最终决策**: 这篇论文的核心贡献在于语言模型训练方法的创新，旨在提升模型本身的效率和鲁棒性。它没有构建、改进或演化任何形式的LLM智能体，也未涉及智能体的规划、工具使用、多智能体协作或自我演化机制。因此，它严格地属于“非Agentic的推理”类别，不符合我关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#1",
        "title": "TiME: Tiny Monolingual Encoders for Efficient NLP Pipelines",
        "link": "/arxiv/2512.14645",
        "arxiv_id": "2512.14645",
        "authors": "David Schulmeister, Valentin Hartmann, Lars Klein, Robert West",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.389125",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一种名为TiME（Tiny Monolingual Encoders）的**小型、高效的单语编码器模型**。其研究目标是解决大型语言模型在效率、延迟和能耗方面的问题，以适用于对效率要求高的NLP流水线。这完全属于**基础设施**和**部署优化**的范畴，而非构建或演化智能体。根据筛选标准，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 等任何核心概念。其关注点是模型蒸馏、效率和性能权衡，与智能体的自主行为无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文的研究内容直接命中了“基础设施”这一排除标准。它专注于如何通过蒸馏等技术训练出更小、更快、更节能的模型，这属于模型工程和优化的领域，而不是Agentic AI的算法或框架研究。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何与智能体相关的推理、规划或自我演化机制，因此特殊情况的例外条款不适用。 **最终决策**: 综合以上分析，这篇论文的核心是关于**模型效率和基础设施优化**，旨在创建更小、更快的编码器模型，而非构建、改进或演化具有自主规划、工具使用或协作能力的LLM智能体。因此，它完全不符合您关于“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#10",
        "title": "Linguists should learn to love speech-based deep learning models",
        "link": "/arxiv/2512.14506",
        "arxiv_id": "2512.14506",
        "authors": "Marianne de Heer Kloots, Paul Boersma, Willem Zuidema",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing, Neurons and Cognition",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.399869",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - 论文的核心贡献是什么？根据摘要，这篇论文是一篇观点性/评论性文章。它并非提出一个新的技术框架或方法论，而是在探讨语言学理论与深度学习模型之间的关系。其核心论点是：相比于基于文本的LLM，基于语音的深度学习模型能更好地与语言学理论结合，从而推动该领域的发展。 - 这篇论文的本质是关于**语言学领域的研究范式**，而不是关于**构建或演化LLM智能体**。它没有提出任何关于智能体规划、工具使用、记忆、多智能体协作或自我演化的新方法。因此，它完全不符合“保留”标准，应被排除。 2.  **第二步：正面指标** - 论文中完全没有出现您所关注的核心范式（如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`）或智能体能力（如 `Planning`, `Tool Use`, `Self-Reflection`）等关键词。这进一步表明该论文与您的研究焦点无关。 3.  **第三步：排除标准** - 虽然这篇论文没有直接触及安全、对齐或多模态等排除项，但其核心议题——语言学理论与模型模态（文本 vs. 语音）的选择——本身就处在您的研究焦点“LLM智能体及其演化”之外。它属于交叉学科的理论探讨，而非Agentic AI的技术创新。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及推理/规划框架或自我演化机制，因此特殊规则不适用。 **最终决策**: 这篇论文的核心贡献是推动语言学领域采用语音模型，而非在技术上构建、改进或演化LLM智能体。它是一篇关于学科交叉应用的评论文章，完全偏离了您关于“Agentic AI”的三个核心研究方向（单智能体、多智能体、自我演化）。因此，应予以排除。"
    },
    {
        "index": "#4",
        "title": "Low-Resource, High-Impact: Building Corpora for Inclusive Language Technologies",
        "link": "/arxiv/2512.14576",
        "arxiv_id": "2512.14576",
        "authors": "Ekaterina Artemova, Laurie Burchell, Daryna Dementieva, Shu Okabe, Mariya Shmatova, Pedro Ortiz Suarez",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.391130",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的本质是一个**教程**，而非一篇提出新方法或新框架的研究论文。其核心内容是教授如何为低资源语言构建语料库和NLP流水线，包括数据收集、网络爬虫、平行句挖掘、机器翻译和下游应用（如文本分类）。 - 这完全符合**排除标准**中的第一条：**非演化型应用**。论文的核心是将NLP技术作为工具，应用到“低资源语言”这一特定领域去解决该领域的数据稀缺问题，而不是构建、改进或演化LLM智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。这表明论文的研究内容与您的核心关注点（单智能体、多智能体、自我演化）没有交集。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文提到了“equitable”（公平）和“socially impactful”（社会影响），这与安全与对齐的范畴有一定关联，但其主要贡献并非关于安全机制或对齐方法，因此不直接触此排除项。 - 论文提到了“multimodal reasoning”（多模态推理），但这是作为众多下游应用中的一个例子，并非研究的核心。根据规则，这不被视为保留的理由。 4.  **第四步：处理特殊和模糊情况** - 论文中的“multimodal reasoning”属于**排除**情况，它是一个标准的下游任务，不涉及智能体如何在复杂任务中进行多步推理的框架。 - 论文不涉及任何自我演化机制，因此“自我演化的应用”这一例外情况不适用。 **最终决策**: 综合以上分析，该论文的核心贡献是关于**数据工程和NLP应用方法的教学**，旨在解决低资源语言的处理问题。它完全没有涉及LLM智能体的构建、规划、工具使用、多智能体协作或自我演化等核心机制。因此，这篇论文与您关于“LLM智能体及其演化”的研究课题完全不符，应予以排除。"
    },
    {
        "index": "#7",
        "title": "VLegal-Bench: Cognitively Grounded Benchmark for Vietnamese Legal Reasoning of Large Language Models",
        "link": "/arxiv/2512.14554",
        "arxiv_id": "2512.14554",
        "authors": "Nguyen Tien Dong, Minh-Anh Nguyen, Thanh Dat Hoang, Nguyen Tuan Ngoc, Dao Xuan Quang Minh, Phan Phi Hai, Nguyen Thi Ngoc Anh, Dang Van Tu, Binh Vu",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.398338",
        "filter_reason": "这篇论文的核心贡献是构建了一个名为“VLegal-Bench”的基准数据集，用于评估大型语言模型在越南法律领域的推理能力。根据您的筛选标准，这篇论文不符合您的研究范围，原因如下： 1.  **核心判断（第一步）：** 论文的本质是**评估**而非**构建**。其核心工作是创建一个标准化的测试集来衡量现有LLM在特定领域（越南法律）的表现。这完全符合第一步的排除标准“非演化型应用”，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。在这里，LLM被用作评估对象，而论文本身并未提出任何新的智能体构建、改进或演化的方法论或框架。 2.  **正面指标缺失（第二步）：** 尽管摘要中提到了“multi-step reasoning”（多步推理）和“retrieval-augmented generation”（检索增强生成），但这些是基准数据集中用来**测试**LLM能力的任务类型，而不是论文提出的**新方法**。论文的贡献在于设计了这些测试问题，而不是发明了一种新的规划或工具使用机制。因此，它不包含您所关注的核心范式或智能体能力作为其核心贡献。 3.  **排除标准（第三步）：** 论文的最终目标之一是“supports the development of more reliable, interpretable, and ethically aligned AI-assisted legal systems”。其中，“interpretable”（可解释性）和“ethically aligned”（伦理对齐）是明确的排除标准。虽然这些是作为基准的长期影响被提及，但这进一步证明了论文的焦点在于评估和负责任的AI应用，而非Agentic AI的核心机制创新。 综上所述，该论文是一项重要的评估工作，为特定领域的LLM应用提供了宝贵的基准。然而，它的核心贡献是“评测”而非“构建”，与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”这一核心目标不符。因此，应予以排除。"
    },
    {
        "index": "#6",
        "title": "Agreement Between Large Language Models and Human Raters in Essay Scoring: A Research Synthesis",
        "link": "/arxiv/2512.14561",
        "arxiv_id": "2512.14561",
        "authors": "Hongli Li, Che Han Chen, Kevin Fan, Chiho Young-Johnson, Soyoung Lim, Yali Feng",
        "subjects": "Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.392629",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - 论文的核心贡献是**一项研究综合**，即对65项关于LLM在作文评分任务中与人类评分者一致性的研究进行了元分析。 - 论文的本质是**评估和总结**LLM在特定应用领域的表现，而不是**构建、改进或演化**LLM智能体。 - 这完全符合排除标准中的第一条：**非演化型应用**。该论文将LLM视为一个用于解决特定领域问题（教育评估）的工具或评估对象，其研究焦点在于评估效果的一致性，而非智能体本身的机制创新。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现您关注的核心范式关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 也没有提及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 因此，该论文不包含任何您所关注的核心正面指标。 3.  **第三步：排除标准** - 虽然该论文不直接涉及安全与对齐或多模态，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及推理/规划框架的创新，也不涉及自我演化机制。它是一项纯粹的评估性研究，因此不适用任何例外保留规则。 **最终决策**：该论文是一项关于LLM应用效果的评估研究，而非关于LLM智能体构建或演化的方法论研究。它的核心贡献在于总结和评估现有技术在特定任务上的表现，这与您“构建、改进或演化LLM智能体”的核心目标完全不符。因此，应予以排除。"
    },
    {
        "index": "#13",
        "title": "Effect of Document Packing on the Latent Multi-Hop Reasoning Capabilities of Large Language Models",
        "link": "/arxiv/2512.14427",
        "arxiv_id": "2512.14427",
        "authors": "Gabriele Prato, Shagun Sodhani, Alessandro Sordoni, Sarath Chandar",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.401344",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是研究一种**训练方法（文档打包）**对**大型语言模型（LLM）本身**的**基础能力（多跳推理）**的影响。它探讨的是模型训练动态和优化策略，旨在提升模型固有的推理能力。根据筛选标准，这属于“非Agentic的推理”范畴，即“只是关于提高LLM本身基础Token预测的数学或逻辑能力”。论文没有提出任何关于智能体（Agent）的框架、方法论或系统。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现我关注的核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。虽然提到了“multi-hop reasoning”（多跳推理），但这是作为被训练模型的一种基础能力来评估的，而不是在一个智能体框架下实现的自主规划或推理过程。 3.  **第四步：处理特殊和模糊情况——推理/规划** 这是判断此论文的关键。筛选标准明确指出： - **保留**: 如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）。 - **排除**: 如果只是关于提高LLM本身基础Token预测的数学或逻辑能力。 本论文显然属于后者。它研究的是如何通过改变训练数据组织方式来“注入”或“增强”模型的推理能力，而不是设计一个能够自主进行多步规划和推理的智能体架构。因此，它应被排除。 **总结**: 该论文的研究焦点是**LLM的训练技术**和**基础能力提升**，而非**LLM智能体的构建、改进或演化**。它没有涉及智能体的核心要素（如规划、工具使用、记忆、自我反思）或多智能体交互、自我演化机制。因此，尽管它对理解LLM的能力有贡献，但与“LLM智能体及其演化”这一研究课题的核心目标不符。"
    },
    {
        "index": "#5",
        "title": "Polypersona: Persona-Grounded LLM for Synthetic Survey Responses",
        "link": "/arxiv/2512.14562",
        "arxiv_id": "2512.14562",
        "authors": "Tejaswani Dash, Dinesh Karri, Anudeep Vurity, Gautam Datla, Tazeem Ahmad, Saima Rafi, Rohith Tangudu",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.391981",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一个名为 \"PolyPersona\" 的框架，用于生成**合成调查回复**。其本质是将LLM（通过LoRA微调）作为一个工具，应用于特定的领域——社会科学调查，以解决数据生成的问题。这完全符合**排除标准1：非演化型应用**。论文的重点在于“应用”，即如何让模型更好地扮演特定角色来生成特定格式的文本，而不是构建一个具有自主规划、工具使用或演化能力的智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式和能力指标。例如，它没有涉及 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）、`Multi-Agent`（多智能体）或 `Self-Evolving`（自我演化）等任何与Agentic AI相关的概念。论文中的 \"behavioral alignment\" 指的是生成回复与预设“角色”的一致性，而非智能体行为的对齐或演化。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文没有直接涉及安全、对齐或多模态等排除项，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** -   **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。它只是单次生成调查回复，属于基础的文本生成任务。 -   **自我演化的应用**: 论文没有提出任何新的“自我演化”机制。它是一个静态的、一次训练完成的应用框架，不涉及智能体通过经验或反馈进行自我完善和迭代。 **最终决策**: 综合以上分析，这篇论文的核心是**应用型研究**，旨在解决特定领域（调查数据生成）的问题，而非**构建或演化LLM智能体**。它缺乏任何关于智能体自主性、规划、工具使用、多智能体交互或自我演化的核心要素。因此，该论文与我的研究目标“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#12",
        "title": "SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models",
        "link": "/arxiv/2512.14481",
        "arxiv_id": "2512.14481",
        "authors": "Shizhuo Mao, Song Chen, Yi Kang",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.400836",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 `SASQ` 的量化感知训练（QAT）框架。其目标是解决大型语言模型（LLM）在部署时面临的内存和计算效率问题。具体来说，它通过优化激活值的量化因子，在不改变预训练权重的情况下，实现了高精度的静态量化，从而提升了模型的部署效率。 根据您的筛选标准，这完全属于 **“基础设施”** 的研究范畴。它关注的是如何让已有的LLM模型在硬件上运行得更高效、占用更少资源，而不是关于如何构建一个具有自主规划、工具使用或协作能力的智能体。因此，在第一步就应该被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现您所列出的任何核心范式或能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 如第一步所述，该论文的研究内容是模型量化和部署优化，这直接命中了您设定的 **“基础设施”** 排除标准。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何关于智能体推理、规划或自我演化的特殊情况。它纯粹是一项工程优化工作。 **最终决策**: 综合以上分析，这篇论文的核心贡献是LLM的部署优化技术，属于基础设施研究。它并未提出任何关于构建、改进或演化LLM智能体的新方法或框架。因此，它严格地超出了您关于“LLM智能体及其演化”的研究课题范围，应予以排除。"
    },
    {
        "index": "#2",
        "title": "JMMMU-Pro: Image-based Japanese Multi-discipline Multimodal Understanding Benchmark via Vibe Benchmark Construction",
        "link": "/arxiv/2512.14620",
        "arxiv_id": "2512.14620",
        "authors": "Atsuyuki Miyai, Shota Onohara, Jeonghun Baek, Kiyoharu Aizawa",
        "subjects": "Computation and Language, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.389845",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一个新的**评估基准**和一个**构建基准的方法**。具体来说，它创建了JMMMU-Pro这个日语多模态理解基准，并介绍了Vibe Benchmark Construction这种利用图像生成模型来低成本构建该基准的方法。论文的本质是**模型评估**，而不是**构建、改进或演化LLM智能体**。它没有提出任何新的智能体框架、规划方法、协作机制或自我演化算法。因此，根据第一步的核心判断标准，这篇论文应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所列出的任何核心关注点。它不涉及`Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving`等任何与智能体核心能力或演化机制相关的关键词或概念。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这篇论文完全命中了“多模态与视觉”这一排除标准。论文标题和摘要反复强调`Image-based`、`Multimodal Understanding`、`image generative model`、`visual perception`、`image-based VQA`等。其研究的核心是视觉-语言模型（LMMs）的视觉理解能力，而不是将视觉作为智能体感知环境的一种工具。根据您的规则，当多模态是研究的核心而非工具时，应予以排除。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及“推理/规划”或“自我演化的应用”等特殊情况，因此无需特殊考量。 **最终决策**： 综合以上分析，这篇论文的核心贡献是构建一个多模态评估基准，属于模型评估和基准研究领域，而非LLM智能体的构建、改进或演化。它直接触犯了“非演化型应用”（更准确地说是评估工具）和“多模态与视觉”两大排除标准。因此，它完全不符合您关于“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#17",
        "title": "Two CFG Nahuatl for automatic corpora expansion",
        "link": "/arxiv/2512.14239",
        "arxiv_id": "2512.14239",
        "authors": "Juan-José Guzmán-Landa, Juan-Manuel Torres-Moreno, Miguel Figueroa-Saavedra, Ligia Quintana-Torres, Graham Ranger Martha-Lorena Avendaño-Garrido",
        "subjects": "Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.408525",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出两种上下文无关文法（CFG），用于为资源稀缺的Nawatl语言生成人工句子，以扩充语料库。这本质上是一种**数据增强或语料库构建的技术**，而不是关于构建、改进或演化LLM智能体的方法论或框架。因此，该论文属于“非演化型应用”的排除范畴，它将一种技术（CFG）应用于特定领域（语言学、低资源语言处理）来解决数据稀缺问题，而非研究智能体本身。 2.  **第二步：正面指标** 论文中完全没有出现我关注的核心范式和关键词。它没有讨论`Agentic AI`、`Multi-Agent Systems`或`Self-Evolving`。同样，它也未涉及智能体的核心能力，如`Planning`、`Tool Use`、`Memory`或`Self-Reflection`。论文的目标是生成静态的文本数据，而非构建一个能够自主行动、规划或演化的智能体。 3.  **第三步：排除标准** 虽然论文没有触及安全对齐或多模态等排除标准，但第一步的判断已经足够明确，无需进一步依赖此标准。 4.  **第四步：处理特殊和模糊情况** 论文不涉及推理/规划框架，也未提出任何“自我演化”机制。它使用的CFG是静态的规则集，不具备自我完善或迭代的能力。因此，关于“自我演化的应用”的例外情况不适用。 **最终决策**：该论文的研究焦点是利用形式文法进行低资源语言的语料库扩充，属于自然语言处理（NLP）中的数据工程范畴。它与我的核心目标——“LLM智能体及其演化”——在研究对象、核心贡献和技术路线上完全不同。因此，这篇论文应被排除。"
    },
    {
        "index": "#14",
        "title": "Step-Tagging: Toward controlling the generation of Language Reasoning Models through step monitoring",
        "link": "/arxiv/2512.14332",
        "arxiv_id": "2512.14332",
        "authors": "Yannis Belkhiter, Seshu Tirupathi, Giulio Zizzo, John D. Kelleher",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.401839",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一个名为“Step-Tagging”的轻量级框架，用于实时监控和分类语言推理模型（LRM）生成的推理步骤，并基于此实现高效的提前停止。其本质是**对LLM推理过程的监控和优化**，旨在减少冗余的token生成，提高推理效率。 这不符合您“构建、改进或演化LLM智能体”的核心目标。该论文没有提出新的智能体架构、能力或演化机制。它更像是一个**推理过程的“插件”或“监控器”**，而不是一个智能体本身。因此，它触发了**排除规则2：非Agentic的推理**。论文关注的是如何让LLM的推理链更高效，而不是如何构建一个能自主规划、使用工具或自我演化的智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中提到了“verification and reflection steps”（验证和反思步骤），这看似与智能体的“自我反思”能力相关。然而，论文的重点并非**实现**或**改进**反思能力，而是**识别**和**计数**这些步骤，以便提前终止生成。它没有引入新的`Planning`、`Tool Use`、`Memory`或`Self-Evolving`机制。因此，正面指标非常弱。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文提到了“interpretable early stopping criteria”（可解释的提前停止标准），这触及了`Interpretability` (可解释性)。虽然这不是论文的主要贡献（主要贡献是效率提升），但它进一步表明该论文的焦点与您的核心目标（Agentic AI的构建与演化）有所偏离。 4.  **第四步：处理特殊和模糊情况** - **推理/规划:** 这是关键的判断点。根据规则，应排除“只是关于提高LLM本身基础Token预测的数学或逻辑能力”的论文。这篇论文虽然处理的是多步推理，但其方法（一个分类器监控步骤）并非一个新的智能体规划框架（如ReAct或ToT），而是对现有推理过程的一种外部优化。它没有赋予智能体新的自主性，只是让它的“思考过程”更精简。因此，它更偏向于“非Agentic的推理”，应被排除。 **最终决策：** 该论文的核心贡献在于**优化LLM的推理生成效率**，通过一个监控框架来控制输出长度。它没有提出新的智能体架构、能力（如规划、工具使用）或演化机制。其工作本质属于对LLM基础推理过程的工程优化，而非对“LLM智能体”这一实体的构建或演化。因此，这篇论文与您“LLM智能体及其演化”的研究课题不符，应予以排除。"
    },
    {
        "index": "#9",
        "title": "VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse",
        "link": "/arxiv/2512.14531",
        "arxiv_id": "2512.14531",
        "authors": "Ying Nie, Kai Han, Hongguang Li, Hang Zhou, Tianyu Guo, Enhua Wu, Xinghao Chen, Yunhe Wang",
        "subjects": "Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.399319",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 `VersatileFFN` 的新型前馈网络（FFN）架构，旨在通过参数复用和自适应计算来提升大语言模型（LLM）的参数效率和表示能力。 根据您的筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** - 论文的本质是**模型架构创新**，而非智能体框架构建。它专注于优化LLM内部的一个基础组件（FFN），通过设计一种“宽深复用”的机制，在不增加参数量的前提下，提升模型处理不同难度token的计算能力。这属于对LLM基础能力的改进，而不是构建一个具有自主性、规划能力或工具使用能力的智能体。 - 因此，该论文符合**排除标准**中的“非Agentic的推理”：它旨在提高LLM本身的基础Token预测和处理能力，其方法不涉及任何智能体自主规划、工具使用或自我演化框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现您所列出的任何核心范式或智能体能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。其核心概念是 `Parameter Efficiency`, `FFN`, `Adaptive Computation`，这些都属于模型优化和工程领域，而非Agentic AI研究。 3.  **第四步：处理特殊和模糊情况** - 论文中提到的“对困难token进行更深迭代精炼”听起来有些像“自我完善”，但这是一种**计算层面的自适应机制**，而非**认知层面的智能体行为**。它是在模型前向传播过程中，根据token的难度动态分配计算资源，这与智能体基于经验、反思或环境反馈进行自我迭代和改进的“自我演化”机制有本质区别。因此，它应被归类为“提高LLM本身基础Token预测能力”的范畴，应予以排除。 **最终决策**：该论文的核心贡献在于LLM的模型架构优化和参数效率提升，属于模型工程和基础能力增强的范畴。它并未涉及任何关于LLM智能体的构建、规划、工具使用、多智能体交互或自我演化的方法论。因此，这篇论文**不符合**您关于“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#15",
        "title": "Inflation Attitudes of Large Language Models",
        "link": "/arxiv/2512.14306",
        "arxiv_id": "2512.14306",
        "authors": "Nikoleta Anesti, Edward Hill, Andreas Joseph",
        "subjects": "Computation and Language, Econometrics",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.402310",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心判断（第一步）：该论文的本质是“非演化型应用”。** 论文的核心贡献并非构建、改进或演化LLM智能体，而是**将一个已有的LLM（GPT-3.5-turbo）作为研究工具，应用于经济学领域**，以探究其模拟人类通胀预期的能力。论文的研究重点是评估模型在特定社会经济任务上的行为表现，并将其与人类调查数据进行对比。这完全符合第一步排除标准中的“非演化型应用”：将LLM作为工具应用到特定领域（此处为经济学/社会科学）去解决该领域的问题。 2.  **缺乏核心关注点（第二步）：论文未涉及任何Agentic AI的核心范式或能力。** 通读摘要，全文没有提及任何与我的研究焦点相关的关键词，如 `Agentic AI`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent` 或 `Self-Evolving`。论文的研究方法是静态的评估，而不是动态的、自主的智能体行为。它没有提出任何新的智能体框架、规划算法、记忆机制或自我演化方法。 3.  **不符合特殊情况的例外（第四步）：** 该论文不属于“自我演化的应用”这一例外情况。它并未提出任何新的“自我演化”机制，仅仅是评估了一个固定模型的输出。因此，不能被保留。 **总结：** 该论文是一项关于LLM在社会科学领域应用的实证研究，其本质是**评估和应用**，而非**构建和创新**。我的研究目标是筛选那些在LLM智能体本身的架构、能力和演化机制上做出核心贡献的论文，而这篇论文显然不属于此范畴。因此，应予以排除。"
    },
    {
        "index": "#16",
        "title": "From Context to EDUs: Faithful and Structured Context Compression via Elementary Discourse Unit Decomposition",
        "link": "/arxiv/2512.14244",
        "arxiv_id": "2512.14244",
        "authors": "Yiqing Zhou, Yu Lei, Shuzheng Si, Qingyan Sun, Wei Wang, Yifei Wu, Hao Wen, Gang Chen, Fanchao Qi, Maosong Sun",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.402879",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是基础设施优化，而非智能体构建。** - 论文的核心贡献是提出了一种名为“EDU-based Context Compressor”的**上下文压缩框架**。其目标是解决LLM处理长文本时的计算成本和噪声问题，这是一种对LLM输入端的优化技术。 - 根据您的筛选标准，这属于**“基础设施”**或**“非演化型应用”**的范畴。论文虽然提到了“autonomous agents”是其应用场景之一，但它本身并没有构建、改进或演化任何智能体。它只是为智能体（或其他LLM应用）提供了一个更高效的“输入预处理工具”。研究的焦点是**压缩方法**，而不是**智能体本身**。 2.  **正面指标缺失 (第二步): 论文不包含您关注的核心智能体能力。** - 论文摘要中完全没有提及 `Planning` (规划), `Tool Use` (工具使用), `Memory` (记忆), `Self-Reflection` (自我反思), `Multi-Agent` (多智能体), `Self-Evolving` (自我演化) 等任何与智能体核心能力或架构相关的关键词。其核心范式是“Context Compression”，而非“Agentic AI”。 3.  **排除标准与特殊情况分析 (第三、四步):** - 该论文不属于安全、对齐或多模态等排除领域。 - 在“推理/规划”的特殊情况中，该论文并非关于智能体如何进行多步推理或规划，而是关于如何压缩输入文本，因此应被排除。 - 它也不涉及“自我演化”机制。 **结论:** 该论文的核心是提出一种改进LLM上下文处理效率的**基础技术**，而不是一个关于LLM智能体的**方法论或新框架**。它为智能体提供了更好的“燃料”（压缩后的上下文），但没有研究智能体这个“引擎”本身如何工作、协作或演化。因此，它严格地落在了您研究范围的“排除”区域。"
    },
    {
        "index": "#3",
        "title": "Towards Nepali-language LLMs: Efficient GPT training with a Nepali BPE tokenizer",
        "link": "/arxiv/2512.14585",
        "arxiv_id": "2512.14585",
        "authors": "Adarsha Shrestha, Basanta Pokharel, Binit Shrestha, Smriti Adhikari, Dinesh Gothe",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.390484",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是**为尼泊尔语这种低资源语言训练一个基础语言模型（GPT-2）**。其创新点在于创建了一个专门的尼泊尔语BPE分词器，并采用了一些训练策略（如FlashAttention）来提高训练效率和模型性能。这属于**基础模型构建和优化**的范畴，而非构建、改进或演化LLM智能体。论文完全没有涉及智能体的自主性、规划、工具使用或与环境交互等核心概念。因此，根据第一步的排除标准，它应被归类为“非Agentic的推理”或更基础的模型构建工作，予以排除。 2.  **第二步：正面指标** 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了该论文与您的研究方向无关。 3.  **第三步：排除标准** 虽然该论文不涉及安全、对齐或多模态等排除项，但这并不改变其核心内容与您研究目标不符的事实。排除标准的主要作用是剔除那些看似相关但焦点错误的论文，而本论文在第一步的核心判断中就已经被明确排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理或规划框架（如ReAct, ToT）。它的工作是提升模型本身对尼泊尔语的生成能力，属于底层的语言建模问题，而非智能体如何利用语言进行规划和行动的问题。因此，不适用保留规则。 **最终决策**: 该论文的本质是针对特定语言（尼泊尔语）的基础模型开发，其贡献在于语言模型训练技术和分词方法，而非智能体架构或能力的创新。这与您“LLM智能体及其演化”的核心目标——研究智能体的规划、记忆、协作和自我演化机制——完全偏离。因此，应予以排除。"
    },
    {
        "index": "#11",
        "title": "C-ing Clearly: Enhanced Binary Code Explanations using C code",
        "link": "/arxiv/2512.14500",
        "arxiv_id": "2512.14500",
        "authors": "Teodor Poncu, Ioana Pintilie, Marius Dragoi, Dragos Tantaru, Florin Brad",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.400369",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出了一种名为 \"C-ing Clearly\" 的**合成数据生成方法**。该方法通过利用C代码来生成数据，以微调LLM，从而提升LLM在**二进制代码摘要和漏洞检测**这两个特定任务上的表现。 - **判断**: 这完全符合**排除标准 1: 非演化型应用**。论文的本质是将LLM作为一种工具，通过一种新的数据增强技术，应用到**二进制代码分析**这一特定领域去解决该领域的问题。它没有构建、改进或演化任何形式的LLM智能体框架，没有涉及智能体的自主性、规划或交互。 2.  **第二步：正面指标** - 论文摘要中完全没有出现您关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 同样，它也没有提及任何智能体能力（如 `Planning`, `Tool Use`, `Memory`）或多智能体交互（如 `Collaboration`, `Communication`）。 - 缺乏这些正面指标，进一步确认了该论文与您的研究焦点无关。 3.  **第三步：排除标准** - 论文的应用领域是“漏洞检测”，这与安全相关。虽然其主要贡献不是安全理论本身，但其落脚点是解决一个特定领域的应用问题，这再次印证了它属于“非演化型应用”的排除范畴。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文旨在提升LLM对低级语言（汇编）的理解能力，这是一种基础能力的增强，而非关于智能体如何进行多步规划或推理的框架研究。因此，它属于“排除”的情况。 - **自我演化的应用**: 论文提出的是一种一次性的数据生成和微调方法，而不是一个能够让智能体通过经验或反馈进行持续自我完善和迭代的“自我演化”机制。 **最终决策**: 该论文的核心贡献是针对特定领域（二进制代码分析）的数据增强方法，旨在提升LLM在该领域的任务性能，而非研究LLM智能体的构建、协作或演化机制。因此，它严格地被排除在您的研究范围之外。"
    },
    {
        "index": "#18",
        "title": "Ladder Up, Memory Down: Low-Cost Fine-Tuning With Side Nets",
        "link": "/arxiv/2512.14237",
        "arxiv_id": "2512.14237",
        "authors": "Estelle Zheng, Nathan Cerisara, Sébastien Warichet, Emmanuel Helbert, Christophe Cerisara",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.409033",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“Ladder Side Tuning (LST)”及其变体“xLadder”的**参数高效微调（PEFT）方法**。其核心目标是解决在微调大型语言模型时遇到的**内存瓶颈问题**，通过引入轻量级旁路网络来降低峰值内存使用，从而在消费级GPU上实现更高效的模型微调。 根据筛选标准，这完全符合**排除规则中的第3条：“主要关注模型基础设施、部署优化、硬件加速的研究”**。这篇论文的本质是关于如何更高效地训练/微调模型，属于模型工程和优化的范畴，而不是构建或改进智能体的行为框架。 2.  **第二步：正面指标分析** 论文中几乎没有出现您关注的核心范式关键词。虽然提到了“reasoning”和“chain-of-thought (CoT)”，但其上下文是xLadder变体如何通过增加模型深度来“缩短CoT”，这指的是优化模型内部的推理计算效率，而非构建一个使用CoT进行规划和行动的智能体框架。论文的核心是**内存效率**，而不是智能体的**规划、记忆、工具使用或自我反思**等能力。 3.  **第三步：排除标准分析** 论文不涉及安全、对齐或多模态等排除领域，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 关键的模糊点在于论文提到了“reasoning”和“CoT”。根据规则： - **排除**: 这篇论文属于“只是关于提高LLM本身基础Token预测的数学或逻辑能力”的情况。它通过一种新的微调架构（xLadder）来让模型在执行CoT等推理任务时更节省内存、计算更高效。这并未引入任何新的智能体自主规划、与环境交互或工具使用的框架。它优化的是“思考”的内部过程，而不是“行动”的外部循环。 **最终决策**: 该论文的核心贡献是一种创新的模型微调技术，旨在解决硬件资源限制问题。它属于模型基础设施和部署优化的研究，与您关于“构建、改进或演化LLM智能体”的核心目标（Agentic AI）存在本质区别。因此，这篇论文应被排除。"
    },
    {
        "index": "#24",
        "title": "Efficient-DLM: From Autoregressive to Diffusion Language Models, and Beyond in Speed",
        "link": "/arxiv/2512.14067",
        "arxiv_id": "2512.14067",
        "authors": "Yonggan Fu, Lexington Whalen, Zhifan Ye, Xin Dong, Shizhe Diao, Jingyu Liu, Chengyue Wu, Hao Zhang, Enze Xie, Song Han, Maksim Khadkevich, Jan Kautz, Yingyan Celine Lin, Pavlo Molchanov",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.412187",
        "filter_reason": "解析失败"
    },
    {
        "index": "#20",
        "title": "Astraea: A State-Aware Scheduling Engine for LLM-Powered Agents",
        "link": "/arxiv/2512.14142",
        "arxiv_id": "2512.14142",
        "authors": "Hongqiu Ni, Jiabao Zhang, Guopeng Li, Zilong Wang, Ruiqi Wu, Chi Zhang, Haisheng Tan",
        "subjects": "Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.410039",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出了一个名为 \"Astraea\" 的“调度引擎”和“服务引擎”。其目标是解决LLM智能体在执行多阶段工作流时，现有推理系统（如vLLM）的调度粒度不匹配问题。论文的核心创新点在于“状态感知的分层调度算法”和“自适应KV缓存管理器”，旨在最小化端到端的“作业完成时间（JCT）”。这完全符合筛选标准中第一步的**排除规则 #3：基础设施**。论文关注的是如何更高效地**运行**已有的智能体，而不是如何**构建、改进或演化**智能体本身。 2.  **与核心目标的偏差：** 您的核心目标是筛选关于“构建、改进或演化 LLM智能体”的论文，关注点是智能体的内在能力，如规划、记忆、工具使用、自我反思、协作和自我演化。而Astraea论文的研究焦点是**系统性能**（延迟、吞吐量、公平性），它假设智能体已经存在，并致力于优化其执行环境。它没有提出任何新的智能体架构、规划方法、记忆机制或自我演化范式。 3.  **正面指标与排除标准的权衡：** 虽然论文摘要中提到了 \"LLM-Powered Agents\" 和 \"agentic workflow\" 等正面指标，但这些词汇是用来**定义问题背景**的，即“我们要为谁优化性能”。论文的真正贡献——调度引擎、KV缓存管理器、JCT优化——都属于系统和基础设施的范畴，并未触及您所关注的Agentic AI的核心方法论。 综上所述，尽管这篇论文的研究对象是LLM智能体，但其核心贡献属于计算机系统领域，专注于性能优化和基础设施，而非您所聚焦的智能体能力构建与演化。因此，它不符合您的筛选要求。"
    },
    {
        "index": "#23",
        "title": "A Unified Sparse Attention via Multi-Granularity Compression",
        "link": "/arxiv/2512.14082",
        "arxiv_id": "2512.14082",
        "authors": "Siran Liu, Zane Cao, Yongchao He",
        "subjects": "Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.411499",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为 `UniSparse` 的统一稀疏注意力机制，通过“复合令牌”和多粒度压缩来加速长上下文处理。其目标是解决LLM中自注意力机制的计算瓶颈，实现硬件友好的高效执行。这完全属于筛选标准中第一步的排除类别：**基础设施**。该论文关注的是模型底层的计算效率和架构优化，而不是构建、改进或演化LLM智能体的方法论或框架。 2.  **第二步：正面指标** 论文的标题和摘要中完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这表明其研究焦点与您的方向相去甚远。 3.  **第三步：排除标准** 该论文不涉及安全、对齐或多模态等排除标准，但其核心内容已被第一步的“基础设施”排除标准所覆盖。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及推理/规划或自我演化的特殊情况。它虽然提到了“reasoning”（推理），但其上下文是指长上下文理解能力，而论文的解决方案是优化底层的注意力计算，而非提出新的智能体推理框架（如ReAct或ToT）。 **最终决策**：该论文是一项关于LLM底层计算效率优化的研究，属于模型基础设施范畴。它没有提出任何与智能体规划、工具使用、多智能体协作或自我演化相关的框架或机制。因此，它严格地不符合您关于“LLM智能体及其演化”的核心研究目标。"
    },
    {
        "index": "#25",
        "title": "What Affects the Effective Depth of Large Language Models?",
        "link": "/arxiv/2512.14064",
        "arxiv_id": "2512.14064",
        "authors": "Yi Hu, Cai Zhou, Muhan Zhang",
        "subjects": "Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.412632",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是**分析大型语言模型（LLM）的内部架构属性**，具体来说是“有效深度”的概念。它研究了模型规模、训练方式和任务难度如何影响模型对其计算层（深度）的利用效率。论文的本质是对LLM基础能力和行为的**分析性研究**，而不是关于**构建、改进或演化LLM智能体**的方法论或新框架。因此，根据第一步的排除标准，它不属于“构建LLM智能体”或“自我演化”的范畴。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中没有出现任何我核心关注点的正面指标。它没有讨论 `Agentic AI`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent` 或 `Self-Evolving` 等任何与智能体相关的核心范式或能力。 3.  **第四步：处理特殊和模糊情况——推理/规划** 这是最关键的一点。虽然论文摘要中提到了“reasoning”（推理），但它完全符合“**非Agentic的推理**”这一排除规则。 - **排除**: 论文探讨的是“改进的推理源于更长的上下文而非更深的逐token计算”。这是在分析LLM模型本身实现推理的内部机制，而不是提出一个让智能体进行自主规划和多步推理的**新框架**（如ReAct, ToT）。我的研究焦点是后者，即如何设计智能体架构来赋能LLM完成复杂任务，而不是分析LLM内部的神经元或层是如何工作的。 **总结:** 该论文是一项关于LLM模型架构和计算效率的扎实研究，它试图理解模型性能的内在原因。然而，我的研究目标是“LLM智能体及其演化”，关注的是**如何将LLM作为核心大脑，构建能够自主规划、使用工具、自我反思和演化的智能体系统**。这篇论文的研究内容属于LLM基础模型分析的范畴，与我的Agentic AI研究焦点有本质区别。因此，应予以排除。"
    },
    {
        "index": "#26",
        "title": "Structure-Aware Decoding Mechanisms for Complex Entity Extraction with Large-Scale Language Models",
        "link": "/arxiv/2512.13980",
        "arxiv_id": "2512.13980",
        "authors": "Zhimin Qiu, Di Wu, Feng Liu, Chenrui Hu, Yuxiao Wang",
        "subjects": "Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.413104",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种“结构感知解码方法”，用于解决**复杂实体提取**这一特定自然语言处理（NLP）任务中的问题。其本质是改进模型在特定任务上的输出解码机制，以确保实体识别的结构一致性。这完全符合**排除规则1：“非演化型应用”**。该论文将大型语言模型（LLM）作为一种基础能力，应用于信息提取领域，解决该领域的具体技术挑战，而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与您研究焦点相关的核心范式或能力关键词。例如，它没有提及 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。这表明论文的研究方向与您的目标存在根本性偏差。 3.  **第四步：处理特殊和模糊情况** - **推理/规划 (Reasoning/Planning):** 论文虽然涉及“解码”，但这并非智能体意义上的“规划”或“多步推理”。它指的是在模型生成实体标签时的技术性解码过程，而非智能体为达成目标而进行的自主规划（如ReAct, ToT）。因此，它属于被排除的“非Agentic的推理”范畴，更侧重于模型在特定任务上的技术优化。 - **自我演化的应用:** 论文提出的是一种固定的解码方法，通过联合优化损失函数来提升性能，模型本身不具备通过经验或反馈进行自我完善和迭代的能力。因此，这不属于“自我演化”机制的范畴。 **结论:** 该论文的核心贡献是针对**实体提取**这一下游任务的技术创新，属于典型的NLP应用研究。它并未涉及LLM智能体的构建、多智能体交互或自我演化机制。因此，根据您的筛选标准，这篇论文应被排除。"
    },
    {
        "index": "#28",
        "title": "FiNERweb: Datasets and Artifacts for Scalable Multilingual Named Entity Recognition",
        "link": "/arxiv/2512.13884",
        "arxiv_id": "2512.13884",
        "authors": "Jonas Golde, Patrick Haller, Alan Akbik",
        "subjects": "Computation and Language",
        "date": "2025-12-15",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.420166",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 **FiNERweb 的数据集创建流水线**，用于大规模生成多语言命名实体识别（NER）的训练数据。论文的本质是 **数据工程和方法论在特定NLP任务（NER）上的应用**，而非构建或研究LLM智能体本身。 这完全符合排除标准中的 **“非演化型应用”**。论文将LLM作为“教师模型”或“评判者”工具，来解决特定领域（多语言NER）的数据稀缺问题。它的研究焦点是提升NER任务的性能，而不是LLM智能体的能力、架构或演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式和能力关键词。例如，它没有涉及 `Agentic AI`、`Planning`、`Tool Use`（这里的LLM作为标注工具，是研究者的工具，而非智能体自主使用的工具）、`Self-Reflection`、`Multi-Agent` 或 `Self-Evolving`。论文中的“teacher-student paradigm”是一种模型训练和蒸馏的框架，与您关注的“自我演化”机制有本质区别。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除领域，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它的工作是纯粹的数据集构建和模型评估，与智能体的自主行为无关。 5.  **第五步：最终决策** 综合以上分析，这篇论文的核心是利用LLM作为工具来创建一个高质量的NER数据集，其研究目标是解决特定NLP任务的数据瓶颈问题。它没有提出任何关于LLM智能体构建、改进或演化的新方法或框架。因此，它与您关于“LLM智能体及其演化”的核心研究目标不符，应予以排除。"
    },
    {
        "index": "#27",
        "title": "Olmo 3",
        "link": "/arxiv/2512.13961",
        "arxiv_id": "2512.13961",
        "authors": "Team Olmo, Allyson Ettinger, Amanda Bertsch, Bailey Kuehl, David Graham, David Heineman, Dirk Groeneveld, Faeze Brahman, Finbarr Timbers, Hamish Ivison, Jacob Morrison, Jake Poznanski, Kyle Lo, Luca Soldaini, Matt Jordan, Mayee Chen, Michael Noukhovitch, Nathan Lambert, Pete Walsh, Pradeep Dasigi, Robert Berry, Saumya Malik, Saurabh Shah, Scott Geng, Shane Arora, Shashank Gupta, Taira Anderson, Teng Xiao, Tyler Murray, Tyler Romero, Victoria Graf, Akari Asai, Akshita Bhagia, Alexander Wettig, Alisa Liu, Aman Rangapur, Chloe Anastasiades, Costa Huang, Dustin Schwenk, Harsh Trivedi, Ian Magnusson, Jaron Lochner, Jiacheng Liu, Lester James V. Miranda, Maarten Sap, Malia Morgan, Michael Schmitz, Michal Guerquin, Michael Wilson, Regan Huff, Ronan Le Bras, Rui Xin, Rulin Shao, Sam Skjonsberg, Shannon Zejiang Shen, Shuyue Stella Li, Tucker Wilde, Valentina Pyatkin, Will Merrill, Yapei Chang, Yuling Gu, Zhiyuan Zeng, Ashish Sabharwal, Luke Zettlemoyer, Pang Wei Koh, Ali Farhadi, Noah A. Smith, Hannaneh Hajishirzi",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.419657",
        "filter_reason": "这篇论文的核心贡献是发布了一个新的开源语言模型家族 Olmo 3 及其完整的训练流程。根据筛选标准的第一步，我的研究焦点是“构建、改进或演化 LLM智能体”的方法论或新框架。而 Olmo 3 论文本质上是关于一个基础模型的发布，它描述了模型具备的能力（如函数调用、长上下文推理），但并未提出一种新的智能体架构、规划框架或演化机制。 具体分析如下： 1.  **核心判断（第一步）**: 论文的核心是“介绍一个模型家族”，而不是“提出一种智能体方法”。它属于基础模型发布的范畴，而非 Agentic AI 的方法论研究。因此，它不符合“保留”标准，应被排除。它更接近于“非Agentic的推理”的边缘，因为它强调模型自身的推理能力，而不是一个让智能体进行推理的框架。 2.  **正面指标（第二步）**: 论文提到了“函数调用”和“推理”，这些与智能体能力相关。但是，这些是作为模型的特性被呈现的，而不是论文研究的核心范式或方法论。论文并未深入探讨如何构建一个能自主使用工具或进行复杂规划的智能体框架。 3.  **排除标准（第三步）**: 论文不涉及安全、对齐或多模态等排除领域。 4.  **特殊情况（第四步）**: 论文中提到的“thinking model”和“long-context reasoning”是关键点。根据规则，如果论文是关于“智能体如何进行规划或在复杂任务中进行多步推理”，则应保留。然而，从摘要来看，这篇论文更侧重于宣布一个“具备”这种思考能力的模型，而不是提出一种新的、通用的“让智能体思考”的框架。它描述的是模型的能力，而非智能体的方法论。这更符合“提高LLM本身基础Token预测的...能力”的排除情况。 **结论**: 尽管一个强大的基础模型（如 Olmo 3）是构建先进 LLM 智能体的重要基石，但这篇论文本身的研究贡献在于模型的构建和发布，而非智能体的构建、改进或演化方法。我的研究目标是探索“如何使用LLM构建智能体”，而该论文回答的是“我们构建了一个新的LLM”。因此，这篇论文与我的核心研究目标不符。"
    },
    {
        "index": "#32",
        "title": "SPARQL-LLM: Real-Time SPARQL Query Generation from Natural Language Questions",
        "link": "/arxiv/2512.14277",
        "arxiv_id": "2512.14277",
        "authors": "Panayiotis Smeros, Vincent Emonet, Ruijie Wang, Ana-Claudia Sima, Tarcisio Mendes de Farias",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.422644",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 该论文的核心贡献是提出了一个名为 \"SPARQL-LLM\" 的系统，用于将自然语言问题实时、低成本地转换为SPARQL查询。其重点在于解决特定领域（知识图谱查询，特别是生物信息学）的应用问题，强调的是准确性、速度和成本效益。 - **判断**: 这完全符合**排除标准**中的第一条：**非演化型应用**。论文将LLM作为一个核心组件（用于查询生成），但整个研究的焦点是构建一个解决“文本到SPARQL”这一特定任务的工具，而不是构建、改进或演化一个具有通用能力的LLM智能体。它没有提出新的智能体框架或演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现您列出的核心范式或能力关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Memory`, `Self-Reflection` 等。 - 虽然系统包含“查询生成和执行”的组件，这可以被宽泛地看作一种工具使用，但论文的论述框架是围绕一个特定任务的流水线，而不是一个自主规划、使用工具并进行反思的智能体。因此，它不满足正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全、对齐或多模态等排除标准，但这一步的优先级低于第一步的核心判断。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。它关注的是单步的翻译任务。 - **自我演化的应用**: 论文没有提出任何自我演化机制，因此例外情况不适用。 **最终决策**: 综合以上分析，这篇论文的本质是一个**应用型研究**，它利用LLM技术解决了一个具体的、有价值的领域问题（自然语言到SPARQL的转换）。然而，您的研究目标是“LLM智能体及其演化”，关注的是智能体本身的**构建、架构和演化机制**。该论文并未对Agentic AI的核心范式（如规划、记忆、自我反思、多智能体协作或自我演化）做出方法论上的贡献。因此，它虽然是一篇有价值的工程应用论文，但与您的研究课题不符，应予以排除。"
    },
    {
        "index": "#31",
        "title": "RePo: Language Models with Context Re-Positioning",
        "link": "/arxiv/2512.14391",
        "arxiv_id": "2512.14391",
        "authors": "Huayang Li, Tianyu Zhao, Richard Sproat",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.422122",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于构建、改进或演化LLM智能体的论文，而这篇论文的核心贡献在于改进LLM模型本身的基础架构，而非智能体框架。 以下是我的详细判断过程： 1.  **第一步：核心判断——论文的本质是什么？** - 论文的核心贡献是提出了一种名为RePo的新机制，用于重新定位上下文中的token位置。这是一种对LLM底层架构（特别是位置编码）的改进，旨在通过减少“外在认知负荷”来提升模型在处理长上下文、噪声和结构化数据时的“深度推理”能力。 - 这完全符合**排除标准**中的第二条：**非Agentic的推理**。论文关注的是如何提升LLM本身的基础推理能力（通过改进其处理上下文的方式），而不是构建一个具备自主规划、工具使用或自我反思能力的智能体框架。它没有涉及任何智能体的循环、目标导向行为或与环境的交互。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 同样，它也没有提及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `ReAct` 等。虽然提到了“深度推理”和“工作记忆”，但这些是在认知科学理论下对模型内部机制的描述，而非智能体的外部化能力。 3.  **第四步：处理特殊和模糊情况——推理/规划** - 这是判断的关键。根据规则，我需要区分“智能体的推理”和“LLM本身的基础推理”。 - **排除**: 这篇论文属于后者。它通过改进位置编码来增强模型捕捉长距离依赖关系的能力，从而提升其在特定任务上的推理表现。这是一种模型层面的优化，与智能体如何进行多步规划、如何调用工具来解决复杂问题的框架性研究有本质区别。例如，ReAct或ToT是关于智能体如何组织其思考过程和行动的框架，而RePo是关于模型如何更好地“阅读”和“理解”一段长文本。 **结论**: 尽管RePo这项技术未来可能会被集成到某个LLM智能体中，以提升其处理长上下文任务的能力，但该论文本身的研究焦点是**基础模型架构的创新**，而非**智能体的构建、改进或演化**。因此，它严格地落在了我的研究范围之外，应予以排除。"
    },
    {
        "index": "#33",
        "title": "Scalable Frameworks for Real-World Audio-Visual Speech Recognition",
        "link": "/arxiv/2512.14083",
        "arxiv_id": "2512.14083",
        "authors": "Sungnyun Kim",
        "subjects": "Audio and Speech Processing, Computation and Language, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.423110",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建一个鲁棒、可扩展的**音视频语音识别（AVSR）系统**。这是一个非常具体的应用领域。论文旨在解决该领域在真实环境下的性能退化问题，而不是提出一种通用的、用于构建或演化LLM智能体的新方法论或框架。根据筛选标准，这属于典型的“非演化型应用”，即将模型（即使是基础模型）作为工具来解决特定领域（此处为语音识别）的问题，因此应被排除。 2.  **排除标准 (第三步):** 论文的研究对象是“Audio-Visual Speech Recognition”，明确涉及**视觉和音频多模态**。摘要中反复提及“audio-visual features”、“multimodal inputs”。这直接命中了“多模态与视觉”的排除标准。研究的核心是处理多模态信息以完成识别任务，而非Agentic AI。 3.  **正面指标缺失 (第二步):** 通读摘要，论文完全没有提及任何与我的研究焦点相关的核心范式或能力。例如，`Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等关键词均未出现。论文中提到的与“large-scale foundation models”的集成，其目的是“最大化最终的识别准确率”，这表明基础模型是被用作提升特定任务性能的工具，而非研究的核心——智能体本身。 综上所述，该论文是一篇关于多模态模型在特定应用（语音识别）上的性能优化研究，其本质是应用驱动的，而非以构建、改进或演化LLM智能体为核心目标。因此，它完全不符合我的筛选要求。"
    },
    {
        "index": "#22",
        "title": "Multilingual and Continuous Backchannel Prediction: A Cross-lingual Study",
        "link": "/arxiv/2512.14085",
        "arxiv_id": "2512.14085",
        "authors": "Koji Inoue, Mikey Elmers, Yahui Fu, Zi Haur Pang, Taiga Mori, Divesh Lala, Keiko Ochi, Tatsuya Kawahara",
        "subjects": "Computation and Language, Human-Computer Interaction, Sound",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.411059",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建一个用于**多语言、连续反馈信号预测**的模型，并研究不同语言下的对话行为。这本质上是一个将Transformer模型应用于特定领域（对话语言学/口语对话系统）来解决该领域具体问题的研究。它完全符合**排除规则 #1: 非演化型应用**。论文的目标是改进对话系统的一个特定组件（使其更自然、更具文化感知），而不是构建、改进或演化一个具有自主规划、工具使用或自我反思能力的LLM智能体。 2.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现我关注的核心范式和能力关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。该模型的功能是单一的预测任务，不具备智能体的核心能力。 3.  **不属于特殊模糊情况 (第四步):** 该论文不涉及智能体的规划或推理框架，也不涉及任何自我演化机制。它是一个静态训练的预测模型，因此第四步的特殊情况均不适用。 综上所述，尽管该论文在对话系统领域可能是一项有价值的工作，但其研究焦点是应用层面的特定任务建模，而非Agentic AI的核心方法论或框架创新。因此，它与我关于“LLM智能体及其演化”的研究课题不相关。"
    },
    {
        "index": "#35",
        "title": "HyperVL: An Efficient and Dynamic Multimodal Large Language Model for Edge Devices",
        "link": "/arxiv/2512.14052",
        "arxiv_id": "2512.14052",
        "authors": "HyperAI Team, Yuchen Liu, Kaiyang Han, Zhiqiang Xia, Yuhang Dong, Chen Song, Kangyu Tang, Jiaming Xu, Xiushi Feng, WenXuan Yu, Li Peng, Mingyang Wang, Kai Wang, Changpeng Yang, Yang Li, Haoyu Lu, Hao Wang, Bingna Xu, Guangyao Liu, Long Huang, Kaibin Guo, Jinyang Wu, Dan Wu, Hongzhen Wang, Peng Zhou, Shuai Nie, Shande Wang, Runyu Shi, Ying Huang",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.429691",
        "filter_reason": "这篇论文不符合我的研究范围，其核心贡献与研究目标存在根本性偏离。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出一个名为 HyperVL 的高效多模态大语言模型，其目标是解决现有模型在边缘设备上部署时面临的**计算和内存瓶颈**。论文摘要明确指出，其创新点在于“为设备端推理量身定制”、“显著降低延迟和功耗”，并提出了“视觉分辨率压缩器（VRC）”和“双一致性学习（DCL）”等技术来优化模型架构和推理效率。这完全符合筛选标准中第一步的排除规则：“主要关注模型基础设施、部署优化、硬件加速的研究”。论文的本质是**模型工程和部署优化**，而不是构建或演化智能体的方法论。 2.  **第二步：正面指标——论文完全不包含我的核心关注点。** 论文摘要中完全没有出现任何与我的研究焦点相关的关键词。它没有讨论 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，它也未涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory`（指智能体的记忆机制，而非计算内存）、`Self-Reflection` 等。因此，该论文在正面指标上得分为零。 3.  **第三步：排除标准——论文属于“多模态与视觉”的排除范畴。** 论文标题和摘要都清晰地表明这是一个**多模态大语言模型**的研究。其核心是处理视觉信息，并优化视觉编码器。根据筛选标准，只要论文的核心是关于 `Vision`、`Vision-Language` 或 `MLLMs`，就应该被排除，除非视觉仅作为智能体感知环境的工具。在本论文中，视觉组件及其效率优化是研究的**核心本身**，而非服务于某个智能体框架的工具，因此完全符合排除条件。 **综合结论：** 该论文的核心贡献在于**提升多模态模型在边缘设备上的部署效率**，属于模型基础设施和工程优化的范畴。它既不涉及构建、改进或演化LLM智能体的方法论，也不包含任何与单智能体、多智能体或自我演化相关的核心概念。因此，这篇论文与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#29",
        "title": "Segmental Attention Decoding With Long Form Acoustic Encodings",
        "link": "/arxiv/2512.14652",
        "arxiv_id": "2512.14652",
        "authors": "Pawel Swietojanski, Xinwei Li, Mingbin Xu, Takaaki Hori, Dogan Can, Xiaodan Zhuang",
        "subjects": "Audio and Speech Processing, Computation and Language",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.420681",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是解决基于注意力的编码器-解码器（AED）模型在处理长格式音频时遇到的技术难题。它提出了四种模型架构上的修改（如注入显式位置编码、长格式训练等），以提升模型在长音频序列上的解码准确性和泛化能力。 - **是否符合要求**: 不符合。这篇论文的本质是**改进一个用于音频处理的特定神经网络模型架构**，它并不涉及构建、改进或演化LLM智能体。它属于“非Agentic的推理/模型架构改进”范畴，其目标是解决模型在特定任务（长音频解码）上的技术瓶颈，而非赋予智能体自主规划、工具使用或自我演化的能力。 2.  **第二步：正面指标** - 论文摘要和标题中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。这进一步确认了其与研究主题的无关性。 3.  **第三步：排除标准** - 虽然论文没有直接触及“安全与对齐”或“多模态与视觉”等明确的排除项，但其研究领域——**长格式声学编码与解码**——本身就在您的研究焦点“LLM智能体及其演化”之外。它属于语音处理或音频信号处理领域，而非Agentic AI领域。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中提到的“解码”和“注意力”机制是模型内部的计算过程，而非智能体层面的自主规划或多步推理框架。它不涉及ReAct、ToT等Agentic规划范式，而是对底层模型组件的优化，因此应被排除。 **最终决策**: 综合以上分析，该论文是一项针对音频处理模型架构的技术改进研究，其核心贡献与“LLM智能体及其演化”这一课题完全无关。它没有构建智能体，没有研究多智能体系统，也没有提出任何自我演化机制。因此，应予以排除。"
    },
    {
        "index": "#38",
        "title": "Let's (not) just put things in Context: Test-Time Training for Long-Context LLMs",
        "link": "/arxiv/2512.13898",
        "arxiv_id": "2512.13898",
        "authors": "Rachit Bansal, Aston Zhang, Rishabh Tiwari, Lovish Madaan, Sai Surya Duvvuri, Devvrit Khatri, David Brandfonbrener, David Alvarez-Melis, Prajjwal Bhargava, Mihir Sanjay Kale, Samy Jelassi",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-12-15",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.431426",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“测试时训练”的新方法，用于解决长上下文大语言模型（LLM）在处理长文本时性能不佳的问题。该方法通过在推理时对模型进行微小的、针对特定上下文的梯度更新，来克服静态自注意力机制的“分数稀释”问题，从而显著提升了模型在长上下文任务上的表现。 根据我的筛选标准，这篇论文不符合我的研究目标，原因如下： 1.  **核心判断不符（第一步）**: 我的核心目标是筛选关于“构建、改进或演化LLM智能体”的论文。这篇论文的本质是**改进LLM的基础能力**（即长上下文信息检索和利用能力），而不是构建或改进一个智能体框架。它关注的是模型内部的注意力机制，而不是智能体的外部行为、规划或交互逻辑。因此，它属于“非Agentic的推理”范畴，应被排除。 2.  **缺乏核心关注点（第二步）**: 论文中没有出现我关注的核心范式和智能体能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent` 或 `Self-Evolving`。虽然提到了“推理时计算”和“多步推理”，但其目的是为了引出并对比其新方法，而非提出一种新的智能体推理框架。 3.  **不属于自我演化（第四步）**: 尽管论文标题中的“Test-Time Training”听起来像是一种演化或适应，但它并非我定义的“自我演化”。我关注的自我演化是指智能体通过经验、反思或环境反馈进行**长期的、跨任务的自我完善和迭代**。而本文的方法是一种**针对单次输入的、即时的适应性微调**，它不会让智能体在未来的任务中变得更好，不具备演化的持续性。 综上所述，该论文是一项关于提升LLM基础模型能力（长上下文处理）的优秀研究，但其焦点并非智能体的构建、协作或演化，因此与我的研究课题“LLM智能体及其演化”不相关。"
    },
    {
        "index": "#41",
        "title": "Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records",
        "link": "/arxiv/2512.13700",
        "arxiv_id": "2512.13700",
        "authors": "Mitchell A. Klusty, Elizabeth C. Solie, Caroline N. Leach, W. Vaiden Logan, Lynnet E. Richey, John C. Gensel, David P. Szczykutowicz, Bryan C. McLellan, Emily B. Collier, Samuel E. Armstrong, V. K. Cody Bumgardner",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.432980",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用，而非智能体构建。** 论文的核心贡献是提出一个“安全、模块化的框架”，用于“从临床笔记中自动提取结构化特征”。其目标是解决医疗领域的特定问题——“减少人工病历审查的负担”。这完全符合筛选标准中的**排除规则1：非演化型应用**。该论文将LLM（以及RAG技术）作为工具，应用于医疗数据提取这一垂直领域，而不是提出一种新的LLM智能体构建、改进或演化的通用方法论。 2.  **第二步：正面指标——缺乏核心关注点。** 论文摘要中提到了RAG（Retrieval Augmented Generation），这可以被看作是一种工具使用的形式。然而，在本文的语境下，RAG是作为信息提取流水线中的一个组件，用于增强从非结构化文本中提取特定信息的能力，而不是作为一个自主智能体在复杂任务中主动选择和使用工具的框架。摘要中完全没有提及我的核心关注点，如`Planning`（规划）、`Memory`（记忆）、`Self-Reflection`（自我反思）、`Multi-Agent`（多智能体）或`Self-Evolving`（自我演化）等关键范式和能力。 3.  **第三步：排除标准——不适用，但已由第一步排除。** 论文不涉及安全、对齐或多模态等排除标准，但其核心性质已在第一步被明确排除。 4.  **第四步：处理特殊和模糊情况——不适用。** 论文不涉及新的推理/规划框架，也没有提出任何自我演化机制。它是一个为特定任务设计的静态应用系统。 **最终决策**：综合以上分析，这篇论文的本质是利用LLM解决医疗信息学领域的应用问题。尽管它构建了一个“框架”，但这个框架是面向特定应用（数据提取）的，而不是面向智能体核心能力（如自主规划、工具使用、自我演化）的构建或演化。因此，它与我的研究目标“构建、改进或演化LLM智能体”背道而驰，应予以排除。"
    },
    {
        "index": "#19",
        "title": "A Comparative Analysis of Retrieval-Augmented Generation Techniques for Bengali Standard-to-Dialect Machine Translation Using LLMs",
        "link": "/arxiv/2512.14179",
        "arxiv_id": "2512.14179",
        "authors": "K. M. Jubair Sami, Dipto Sumit, Ariyan Hossain, Farig Sadeque",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-12-16",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.409543",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出并比较了两种用于“标准孟加拉语到方言翻译”这一特定NLP任务的**检索增强生成（RAG）流水线**。它旨在解决一个低资源翻译问题，通过优化检索策略来提升翻译效果。 - **判断**: 这完全符合**排除标准中的“非演化型应用”**。论文将LLM和RAG技术作为工具，应用在“语言学翻译”这个特定领域，以解决该领域的数据稀缺问题。它并没有构建、改进或演化一个具有自主性的LLM智能体。LLM在其中扮演的是一个被动的、被调用的翻译引擎，而不是一个主动的、会规划、会反思的智能体。 2.  **第二步：正面指标** - 论文中没有出现您关注的核心范式关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 虽然RAG可以被视为一种`Tool Augmentation`，但论文的重点在于**“如何设计一个更好的检索工具”**，而不是**“智能体如何自主地、动态地使用工具”**。文中没有涉及智能体的规划、记忆管理、自我反思等关键能力。 3.  **第三步：排除标准** - 论文不涉及安全、对齐或多模态等排除项，但这并不改变其作为“非演化型应用”的本质。 4.  **第四步：特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。它关注的是单步翻译任务的输入（检索到的上下文）优化。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。它比较的是两种静态的、预先设计好的流水线，因此不适用此例外规则。 **最终决策**: 该论文的核心是一项针对特定领域（低资源翻译）的应用研究，其贡献在于改进了RAG的检索策略，而非LLM智能体的架构、能力或演化机制。因此，它不符合您关于“LLM智能体及其演化”的核心研究目标，应予以排除。"
    },
    {
        "index": "#42",
        "title": "Writing in Symbiosis: Mapping Human Creative Agency in the AI Era",
        "link": "/arxiv/2512.13697",
        "arxiv_id": "2512.13697",
        "authors": "Vivan Doshi, Mengyuan Li",
        "subjects": "Computers and Society, Artificial Intelligence, Computation and Language",
        "date": "2025-11-28",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.433623",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于**构建、改进或演化LLM智能体本身**的论文，而这篇论文的核心贡献是**研究人类在AI时代下的行为演化**。 具体判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的本质是一项**社会学或人机交互（HCI）研究**。它使用大规模语料库作为分析工具，来观察和建模**人类作者**在LLM出现后其写作风格和主题的适应性变化。论文的核心是“Mapping Human Creative Agency”（描绘人类创造力主体性），即研究人的变化，而不是构建或改进一个AI智能体。 - 这完全符合**排除标准1：非演化型应用**。该论文将LLM（作为一种现象或工具）应用到了“创意写作社会学”这个特定领域，去研究该领域的问题（人类如何适应AI），而不是研究LLM智能体本身如何演化。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中提到了“coevolution”（共同演化）和“agency”（主体性），但这些词的语境是**人类与AI的协同演化**以及**人类的创造力主体性**，而不是我关注的**AI智能体的自我演化**或**智能体的自主性**。 - 论文完全没有涉及我关注的核心范式，如`Agentic AI`、`LLM-based Agents`、`Self-Evolving`（指AI自我完善），也没有涉及智能体能力如`Planning`、`Tool Use`、`Self-Reflection`等。 3.  **第四步：处理特殊和模糊情况** - 论文中的“Dual-Track Evolution”和“Creative Archetype Map”是其核心发现，但这是对**人类行为模式**的观察和归纳，是一个描述性的社会学模型，而不是一个可供AI智能体进行**自我改进或迭代**的计算机制或算法框架。 - 因此，这不符合“自我演化的应用”的例外情况，因为它没有提出任何新的“自我演化”机制。 **结论**：该论文的研究对象是“人”，而非“智能体”。它探讨的是人机关系的社会学层面，而非Agentic AI的技术构建。虽然其研究主题与AI相关，但其核心贡献与我的研究目标——构建和演化LLM智能体——完全偏离。因此，应予以排除。"
    },
    {
        "index": "#37",
        "title": "Generative AI for Video Translation: A Scalable Architecture for Multilingual Video Conferencing",
        "link": "/arxiv/2512.13904",
        "arxiv_id": "2512.13904",
        "authors": "Amirkia Rafiei Oskooei, Eren Caglar, Ibrahim Sahin, Ayse Kayabay, Mehmet S. Aktas",
        "subjects": "Multimedia, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-12-15",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.430839",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。 我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出一个“可扩展的系统级架构”，用于解决实时视频翻译应用中的**系统级挑战**，如推理延迟和计算复杂度。摘要中反复出现的关键词，如“system-level challenges”、“scalable architecture”、“system-level framework”、“performance analysis”和“end-to-end system design”，都明确指向其研究焦点是**基础设施和系统优化**。 根据筛选标准，这直接命中了第一步的排除规则：“排除主要关注模型基础设施、部署优化、硬件加速的研究。” 论文并未提出新的LLM智能体构建方法、多智能体协作协议或自我演化机制，而是研究如何让一个已有的生成式AI流水线（可能包含LLM）在多用户视频会议场景下高效运行。因此，在第一步就应被排除。 2.  **第二步：正面指标** 论文中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。虽然提到了“turn-taking mechanism”，但在上下文中，它是一个用于降低计算复杂度的系统调度策略，而非智能体间的协作或通信机制。因此，论文不包含任何正面指标。 3.  **第三步：排除标准** 论文的研究对象是“Video Translation”，涉及视觉信息处理。虽然视觉本身不是绝对的排除项，但当它成为研究的核心应用场景而非智能体的感知工具时，它强化了该论文属于“应用”和“基础设施”而非“Agentic AI”的判断。 4.  **第四步：特殊和模糊情况** 该论文不涉及推理/规划或自我演化的特殊情况。它没有提出新的智能体推理框架，也没有提出任何自我演化机制。 **最终决策**： 这篇论文的本质是一篇**系统工程**论文。它研究的是如何优化一个生成式AI应用的部署效率和可扩展性，而不是如何构建、改进或演化LLM智能体本身。我的研究目标是“LLM智能体及其演化”，关注的是智能体的内在能力、交互方式和演化机制。这篇论文解决的是“如何高效部署”的问题，而非“如何构建更智能的智能体”的问题，因此与我的研究目标完全不符。"
    },
    {
        "index": "#40",
        "title": "Mitigating Catastrophic Forgetting in Mathematical Reasoning Finetuning through Mixed Training",
        "link": "/arxiv/2512.13706",
        "arxiv_id": "2512.13706",
        "authors": "John Graham Reynolds",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-12-05",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.432399",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于“构建、改进或演化LLM智能体”的论文，而这篇论文的核心贡献在于一种模型微调技术，而非智能体框架。 具体判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是提出一种“混合训练”策略，用于在数学推理任务上微调LLM时，缓解“灾难性遗忘”问题。这是一种针对模型训练过程的优化方法，旨在提升模型在特定任务上的基础能力，同时保留其通用能力。它并没有提出任何新的智能体框架、多智能体系统或自我演化机制。因此，根据第一步的排除规则 **2. 非Agentic的推理**，这篇论文应被排除。它的研究焦点是提升LLM本身的基础推理能力（数学），而不是构建一个能够自主规划、使用工具或自我反思的智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式（如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`）或智能体能力（如 `Planning`, `Tool Use`, `Self-Reflection`）。这进一步确认了它与我的研究焦点无关。 3.  **第四步：处理特殊和模糊情况——推理/规划** 这是最关键的一点。我的筛选标准明确区分了两种关于“推理”的研究： *   **保留**：关于智能体如何进行规划和多步推理的框架（如 ReAct, ToT）。 *   **排除**：关于提升LLM本身基础Token预测的数学或逻辑能力的研究。 这篇论文恰恰属于后者。它研究的是如何通过改进训练数据配比来提升模型在数学问题上的表现，这属于模型训练和优化的范畴，而不是Agentic AI的范畴。 **结论**：该论文的核心贡献是一种防止模型微调时能力退化的训练策略，属于模型训练优化的研究。它没有涉及任何智能体的构建、协作或自我演化机制，因此与我的研究课题“LLM智能体及其演化”不相关，应予以排除。"
    },
    {
        "index": "#43",
        "title": "Shakespeare, Entropy and Educated Monkeys",
        "link": "/arxiv/2512.11880",
        "arxiv_id": "2512.11880",
        "authors": "Ioannis Kontoyiannis",
        "subjects": "History and Overview",
        "date": "2025-12-08",
        "category": "cs.CL",
        "crawl_time": "2025-12-17T11:00:04.439197",
        "filter_reason": "这篇论文完全不符合我的研究范围。我的判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献并非关于构建、改进或演化LLM智能体。该论文本质上是一篇信息论和语言统计学领域的理论分析文章。它使用“受过教育的猴子”这一思想实验来量化在特定统计约束下，随机过程产生特定文本所需的时间。这属于理论计算和概率论的范畴，与Agentic AI、Multi-Agent Systems或Self-Evolving智能体的方法论或框架构建毫无关系。 2.  **正面指标缺失（第二步）：** 论文中完全没有出现我所关注的核心范式或能力关键词。例如，它没有讨论 `Agentic AI`、`LLM-based Agents`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Collaboration` 或 `Self-Improvement`。文中的“educated monkey”是一个用于理论计算的比喻，并非一个具有自主规划、工具使用或反思能力的智能体架构。 3.  **不属于特殊情况（第四步）：** 这篇论文不涉及任何关于智能体推理或规划的实际框架。它探讨的是一个受约束的随机生成过程的统计特性，而不是一个智能体如何进行多步决策。同时，它也没有提出任何“自我演化”的机制，所谓的“educated”只是一个静态的统计约束，而非动态的学习或迭代过程。 综上所述，该论文是一篇纯粹的理论信息论研究，与我的核心目标——筛选关于LLM智能体构建、多智能体系统或自我演化机制的前沿论文——完全无关。因此，应予以排除。"
    },
    {
        "index": "#1",
        "title": "gridfm-datakit-v1: A Python Library for Scalable and Realistic Power Flow and Optimal Power Flow Data Generation",
        "link": "/arxiv/2512.14658",
        "arxiv_id": "2512.14658",
        "authors": "Alban Puech, Matteo Mazzonelli, Celia Cintas, Tamara R. Govindasamy, Mangaliso Mngomezulu, Jonas Weiss, Matteo Baù, Anna Varbella, François Mirallès, Kibaek Kim, Le Xie, Hendrik F. Hamann, Etienne Vos, Thomas Brunschwiler",
        "subjects": "Machine Learning, Artificial Intelligence, Systems and Control, Optimization and Control",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.600888",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断（第一步）**: 这篇论文的本质是构建一个**数据生成库**，而非构建、改进或演化LLM智能体。其核心贡献 `gridfm-datakit-v1` 是一个应用于特定领域（电力系统工程）的Python库，用于生成训练机器学习（ML）求解器的数据集。这完全符合筛选标准中“非演化型应用”和“基础设施”的排除类别。它的目标是解决电力系统领域的数据问题，而不是研究智能体本身。 2.  **正面指标缺失（第二步）**: 论文的标题和摘要中，完全没有出现任何与我研究焦点相关的核心范式或能力关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 等。这表明该研究与Agentic AI的核心议题无关。 3.  **与研究目标不匹配**: 我的核心目标是筛选出那些核心贡献在于**智能体方法论或新框架**的论文。而这篇论文的核心贡献是**数据生成工具**。它研究的不是智能体如何规划、如何协作或如何自我演化，而是如何为传统的ML模型（而非智能体）创造更好的训练数据。 综上所述，该论文是一个典型的领域应用工具型研究，属于基础设施范畴，与“LLM智能体及其演化”的核心研究方向相去甚远，因此必须排除。"
    },
    {
        "index": "#2",
        "title": "ParaFormer: A Generalized PageRank Graph Transformer for Graph Representation Learning",
        "link": "/arxiv/2512.14619",
        "arxiv_id": "2512.14619",
        "authors": "Chaohao Yuan, Zhenjie Song, Ercan Engin Kuruoglu, Kangfei Zhao, Yang Liu, Deli Zhao, Hong Cheng, Yu Rong",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.601198",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出了一种名为 ParaFormer 的新模型，它是一种用于图表示学习的 Graph Transformer。其主要目标是解决 Graph Transformers 中存在的“过平滑”问题，通过引入 PageRank 机制来改进节点和图的表示学习效果。 - **与目标匹配度**: 该研究的本质是**图神经网络（GNN）**领域的基础模型创新，而非关于 LLM 智能体的构建、改进或演化。论文完全没有提及 LLM、智能体、规划、工具使用或自我演化等概念。因此，它属于“非Agentic的推理”范畴，因为它关注的是提升模型（图Transformer）本身的基础表示能力，而不是一个具备自主性的智能体框架。根据第一步的排除标准，应直接排除。 2.  **第二步：正面指标** - 论文的标题和摘要中，完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准** - 虽然该论文不涉及安全对齐或多模态等排除项，但第一步的核心判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此不适用特殊情况的例外规则。 **最终决策**: 综合以上分析，这篇论文的研究领域是图表示学习，其核心贡献是改进图神经网络模型的技术细节，与“LLM智能体及其演化”这一课题完全无关。因此，最终判断为 **False**。"
    },
    {
        "index": "#9",
        "title": "Improving Slow Transfer Predictions: Generative Methods Compared",
        "link": "/arxiv/2512.14522",
        "arxiv_id": "2512.14522",
        "authors": "Jacob Taegon Kim, Alex Sim, Kesheng Wu, Jinoh Kim",
        "subjects": "Machine Learning, Distributed, Parallel, and Cluster Computing, Networking and Internet Architecture",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.603089",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 论文的核心贡献是**解决科学计算网络中数据传输性能预测的类别不平衡问题**。它通过比较不同的数据增强技术（包括CTGAN等生成方法）来提升预测模型的准确性。 - 这完全符合**排除标准中的“非演化型应用”**。该论文将机器学习/生成模型作为一种工具，应用于“科学计算网络”这一特定领域，以解决该领域的性能预测问题。它并未构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现任何与您研究焦点相关的正面指标。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式，也未涉及 `Planning`, `Tool Use`, `Memory`, `Collaboration` 等智能体能力。这进一步确认了其与研究课题的无关性。 3.  **第三步与第四步：排除标准与特殊情况** - 该论文不涉及安全对齐或多模态等排除领域，也不涉及推理/规划或自我演化的特殊情况。其核心问题在第一步就已经被明确排除。 **结论**: 该论文的研究焦点是**数据科学方法（处理类别不平衡）在网络工程领域的应用**，而非**LLM智能体的构建、协作或演化**。因此，它严格地落在了您设定的排除范围之外，与您关于“LLM智能体及其演化”的核心研究目标不符。"
    },
    {
        "index": "#6",
        "title": "Residual GRU+MHSA: A Lightweight Hybrid Recurrent Attention Model for Cardiovascular Disease Detection",
        "link": "/arxiv/2512.14563",
        "arxiv_id": "2512.14563",
        "authors": "Tejaswani Dash, Gautam Datla, Anudeep Vurity, Tazeem Ahmad, Mohd Adnan, Saima Rafi, Saisha Patro, Saina Patro",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.602263",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的核心贡献是提出了一种名为“Residual GRU+MHSA”的新型深度学习模型架构，用于解决心血管疾病（CVD）检测这一特定领域的医疗问题。 - 论文的核心是模型架构的创新（结合残差GRU和多头自注意力），并在一个特定的表格数据集（UCI Heart Disease dataset）上验证其分类性能。 - 这完全符合**排除标准中的“非演化型应用”**。它没有构建或研究LLM智能体，而是将一个新颖的（但非智能体的）深度学习模型应用到一个垂直领域（医疗）去解决该领域的问题。我的研究焦点是智能体本身的构建与演化，而不是将模型作为工具应用于其他领域。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 论文中提到的“Multi-Head Self-Attention”是一种模型内部的注意力机制，用于捕捉特征间的全局依赖关系，这与智能体在环境中进行规划、使用工具或与其他智能体通信的“Agentic”行为完全不同。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不直接涉及“安全与对齐”或“多模态与视觉”等排除关键词，但它触犯了更根本的第一步排除原则。它的研究问题是医疗诊断，而非Agentic AI。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它是一个纯粹的监督学习分类任务。 **最终决策**: 综合以上分析，这篇论文的研究目标是改进特定领域（心血管疾病检测）的预测模型，其核心贡献在于模型架构设计，而非LLM智能体的构建、多智能体系统的设计或智能体的自我演化机制。因此，它与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#5",
        "title": "Hybrid Iterative Solvers with Geometry-Aware Neural Preconditioners for Parametric PDEs",
        "link": "/arxiv/2512.14596",
        "arxiv_id": "2512.14596",
        "authors": "Youngkyu Lee, Francesc Levrero Florencio, Jay Pathak, George Em Karniadakis",
        "subjects": "Machine Learning, Numerical Analysis",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.601966",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 \"Geo-DeepONet\" 的几何感知神经算子，并将其与传统数值方法（如松弛法、Krylov子空间算法）结合，构建了一种用于求解参数化偏微分方程的混合迭代求解器。其本质是**将一种神经网络（神经算子，而非LLM）作为工具，应用于科学计算领域，以解决该领域（PDE求解）的特定问题**。这完全符合第一步排除标准中的“非演化型应用”。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。它讨论的是 `neural operators`（神经算子）、`preconditioners`（预处理器）、`iterative solvers`（迭代求解器）和 `finite element discretizations`（有限元离散化），这些均不属于我的研究焦点。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文没有直接涉及安全对齐或多模态等排除项，但它已经在前面的核心判断中被明确归类为“非演化型应用”，因此无需进一步考虑此步。 4.  **第四步：处理特殊和模糊情况** 论文不涉及任何与智能体相关的推理或规划，其“迭代”是指数值求解器的迭代过程，而非智能体的自我演化或迭代改进。因此，特殊情况的例外条款不适用。 **最终决策**: 该论文的核心是利用神经算子改进PDE求解器，属于典型的科学计算交叉研究。它没有构建、改进或演化任何形式的LLM智能体，也没有研究智能体的规划、协作或自我演化机制。因此，这篇论文与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#7",
        "title": "Counterfactual Explanations for Time Series Should be Human-Centered and Temporally Coherent in Interventions",
        "link": "/arxiv/2512.14559",
        "arxiv_id": "2512.14559",
        "authors": "Emmanuel C. Chukwu, Rianne M. Schouten, Monique Tabak, Mykola Pechenizkiy",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.602520",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是关于**反事实解释**，旨在提高时间序列分类模型在临床应用中的可解释性和可操作性。它并没有构建、改进或演化任何形式的LLM智能体。论文讨论的是如何解释一个已有模型的决策，而不是如何创建一个能够自主规划、使用工具或自我演化的智能体。这属于“非演化型应用”的范畴，即将一种技术（反事实解释）应用于特定领域（临床时间序列分析）。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文的核心议题是“Counterfactual Explanations”（反事实解释）和“Interpretable Mechanisms”（可解释机制），这完全属于**可解释性** 的研究范畴。根据我的筛选标准，只要论文的主要贡献是关于 `Interpretability` (可解释性) 或 `Explainability (XAI)`，就应一律排除。该论文通篇都在讨论如何让模型的解释更符合人类认知和实际应用，这正是XAI的核心目标。 3.  **正面指标缺失 (第二步):** 论文中完全没有出现任何与我核心关注点相关的正面指标。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等任何关键词或概念。 综上所述，尽管该论文在其自身领域（可解释AI、时间序列分析）可能具有重要价值，但其研究焦点与我设定的“LLM智能体及其演化”课题完全不同。它的核心是解释模型，而非构建智能体，因此被明确排除。"
    },
    {
        "index": "#4",
        "title": "Hierarchical Persistence Velocity for Network Anomaly Detection: Theory and Applications to Cryptocurrency Markets",
        "link": "/arxiv/2512.14615",
        "arxiv_id": "2512.14615",
        "authors": "Omid Khormali",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.601695",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为“重叠加权分层归一化持久速度（OW-HNPV）”的**拓扑数据分析（TDA）方法**，用于检测时变网络中的异常。这是一种数学和数据分析层面的创新，其本质是**一种新的网络异常检测算法**。 根据筛选标准，这完全不符合“保留”条件。它并非关于构建、改进或演化LLM智能体。相反，它属于“排除”类别中的**“非演化型应用”**，因为它将一种新颖的数学方法应用到了一个特定领域（加密货币市场）来解决该领域的问题（网络异常检测和价格预测）。论文中完全没有提及LLM或智能体框架。 2.  **第二步：正面指标** 论文摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** 虽然这篇论文不涉及安全与对齐或多模态等排除项，但它已经触发了第一步中更根本的排除规则。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何“自我演化”机制。因此，特殊情况的例外条款不适用。 **最终决策**: 这篇论文的核心是**网络科学和拓扑数据分析**，而非**人工智能智能体**。它提出了一种新的数学度量（OW-HNPV）并将其应用于金融领域。这与我关于“LLM智能体及其演化”的研究课题在研究对象、核心贡献和技术路线上完全不同。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#11",
        "title": "AnySleep: a channel-agnostic deep learning system for high-resolution sleep staging in multi-center cohorts",
        "link": "/arxiv/2512.14461",
        "arxiv_id": "2512.14461",
        "authors": "Niklas Grieger, Jannik Raskob, Siamak Mehrkanoon, Stephan Bialonski",
        "subjects": "Machine Learning, Signal Processing, Quantitative Methods",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.603634",
        "filter_reason": "根据您提供的筛选标准，我对这篇论文进行了严格的分析，判断其不符合您的研究范围。具体判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 这篇论文的核心贡献是提出了一个名为 \"AnySleep\" 的深度神经网络模型，用于解决睡眠分期这一特定生物医学领域的问题。它是一个针对多中心、多通道脑电图（EEG）和眼电图（EOG）数据的分类模型。 - **判断**: 该论文属于 **“非演化型应用”**。它将深度学习模型（甚至不是LLM）作为工具，应用于睡眠研究领域，以解决该领域的特定问题（自动化睡眠分期）。论文完全没有涉及构建、改进或演化任何形式的智能体框架。因此，在第一步就应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中，完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不直接涉及“安全与对齐”或“多模态与视觉”的排除标准，但它在第一步的核心判断中已经被明确排除。它的研究范畴是生物医学信号处理和深度学习应用，与您的 Agentic AI 研究焦点存在根本性的差异。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它是一个纯粹的、静态的、经过训练的分类模型，不具备任何智能体的自主性或演化能力。 **最终决策**: 这篇论文的研究目标是构建一个高效的睡眠分期工具，其本质是深度学习在生物医学领域的应用。它既没有使用LLM作为核心，也没有构建任何具有规划、工具使用或自我演化能力的智能体。因此，它完全不符合您关于“LLM智能体及其演化”的研究课题要求，应予以排除。"
    },
    {
        "index": "#10",
        "title": "Kinetic-Mamba: Mamba-Assisted Predictions of Stiff Chemical Kinetics",
        "link": "/arxiv/2512.14471",
        "arxiv_id": "2512.14471",
        "authors": "Additi Pandey, Liang Wei, Hessam Babaee, George Em Karniadakis",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.603353",
        "filter_reason": "根据您提供的筛选标准，我的判断过程如下： 1.  **第一步：核心判断** 这篇论文的核心贡献是提出一个名为 \"Kinetic-Mamba\" 的神经算子框架，用于解决**化学动力学预测**这一特定科学领域的问题。论文的本质是将 Mamba 架构作为一种高效的时序建模工具，应用于预测化学反应路径和热化学状态的演化。这完全符合筛选标准中“非演化型应用”的排除条款，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗、金融、法律、机器人控制等）”。这里的特定领域是化学和燃烧科学。 2.  **第二步：正面指标** 论文摘要中完全没有出现任何与您核心关注点相关的正面指标关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 或 `Self-Reflection`。论文中的 \"evolution\" 指的是物理化学过程的“演化”，而非智能体的“自我演化”。 3.  **第三步：排除标准** 该论文不涉及安全、对齐或多模态等排除标准，但第一步的排除判断已经足够明确。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的模型是在进行物理过程的预测，这是一种基于数据的函数拟合和时序预测，而不是智能体在复杂任务中的自主规划或多步推理。因此，它属于被排除的范畴。 - **自我演化的应用**: 论文的核心是提出一个预测模型，而不是一种新的“自我演化”机制。因此，关于“自我演化应用”的例外保留规则不适用。 **最终决策**: 该论文的核心贡献在于利用先进的神经网络架构（Mamba）解决化学动力学领域的预测问题，属于典型的**领域应用型研究**。它并未构建、改进或演化任何形式的LLM智能体，其研究目标与您的“LLM智能体及其演化”课题不符。因此，应予以排除。"
    },
    {
        "index": "#8",
        "title": "Synthetic Electrogram Generation with Variational Autoencoders for ECGI",
        "link": "/arxiv/2512.14537",
        "arxiv_id": "2512.14537",
        "authors": "Miriam Gutiérrez Fernández, Karen López-Linares, Carlos Fambuena Santos, María S. Guillem, Andreu M. Climent, Óscar Barquero Pérez",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.602810",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出了一种使用变分自编码器（VAE）来生成合成心电图（EGM）数据的方法，以解决心电图成像（ECGI）领域中训练数据稀缺的问题。其本质是**一种应用于特定医学领域（心脏病学）的深度学习数据生成技术**。 - **匹配筛选规则**: 这完全符合第一步排除标准中的 **“非演化型应用”**。论文将一个已有的深度学习模型（VAE）作为工具，应用于生物医学领域，解决该领域的数据问题，其研究焦点并非构建或演化智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心范式或智能体能力。这进一步确认了它与我的研究课题无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不涉及安全与对齐或多模态视觉等排除项，但第一步的“非演化型应用”排除规则已经足够明确且优先级更高。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及推理/规划或自我演化机制的特殊情况，因此无需进一步分析。 **最终决策**: 综合以上分析，这篇论文的研究目标是解决特定医学领域的数据增强问题，其方法论是生成模型（VAE）的应用，而非关于LLM智能体的构建、协作或演化。因此，它完全偏离了我的核心研究目标“LLM智能体及其演化”，应被排除。"
    },
    {
        "index": "#12",
        "title": "Bridging Artificial Intelligence and Data Assimilation: The Data-driven Ensemble Forecasting System ClimaX-LETKF",
        "link": "/arxiv/2512.14444",
        "arxiv_id": "2512.14444",
        "authors": "Akira Takeshima, Kenta Shiraishi, Atsushi Okazaki, Tadashi Tsuyuki, Shunji Kotsuki",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.603917",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一个名为 \"ClimaX-LETKF\" 的**数据驱动的集合天气预报系统**。这是一个应用于特定领域（气象学）的机器学习系统，旨在解决天气预报中的数据同化和集合预报问题。这完全符合**排除标准 #1：非演化型应用**。该论文将机器学习模型作为工具应用于气象领域，而不是构建一个通用的、可迁移的LLM智能体框架或研究智能体的演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标。没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，也没有涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。文中的 \"Ensemble Forecasting\"（集合预报）是一种气象学和统计学中的技术，指通过多个模型或模型的不同初始条件进行预测并整合结果，这与我所关注的 \"Multi-Agent Systems\"（多智能体系统）中智能体间的协作、通信等概念完全不同。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不涉及安全对齐或多模态等排除项，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 论文不涉及智能体的规划或推理，也不涉及任何自我演化机制。因此，特殊情况的规则不适用。 **最终决策**： 综合以上分析，这篇论文的本质是**机器学习在气象预报领域的应用研究**。其核心贡献是构建了一个特定领域的预测系统，而非提出关于LLM智能体构建、多智能体协作或自我演化的新方法或新框架。因此，它严格地属于“非演化型应用”，不符合我的研究目标。"
    },
    {
        "index": "#15",
        "title": "SuperWing: a comprehensive transonic wing dataset for data-driven aerodynamic design",
        "link": "/arxiv/2512.14397",
        "arxiv_id": "2512.14397",
        "authors": "Yunjia Yang, Weishao Tang, Mengxin Liu, Nils Thuerey, Yufei Zhang, Haixin Chen",
        "subjects": "Machine Learning, Fluid Dynamics",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.604737",
        "filter_reason": "这篇论文的核心贡献是构建了一个名为SuperWing的跨音速机翼空气动力学数据集，并使用Transformer模型作为代理模型来验证该数据集的有效性。这与您的研究目标“构建、改进或演化LLM智能体”不符。 具体判断过程如下： 1.  **第一步：核心判断**——论文的本质是提出一个**数据集**，而非一个智能体框架或演化机制。论文将Transformer模型用作一个预测工具（surrogate model），来解决特定领域（空气动力学设计）的问题。这完全符合筛选标准第一步中的排除规则：“非演化型应用: 如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗、金融、...机器人控制等）。” 在此案例中，应用领域是空气动力学设计。 2.  **第二步：正面指标**——论文摘要中完全没有出现您关注的核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。它提到的Transformer是作为预测模型，而非具备自主规划、工具使用或反思能力的智能体。 3.  **第三步：排除标准**——虽然论文不涉及安全与对齐或多模态等排除项，但第一步的判断已经足够明确。 4.  **第四步：特殊和模糊情况**——论文不涉及智能体的规划或推理框架，也没有提出任何自我演化机制。因此，特殊情况不适用。 **最终决策**：该论文的研究焦点是数据集构建和其在特定工程领域的应用，而非LLM智能体的架构、能力或演化。因此，它不符合您的研究范围，应被排除。"
    },
    {
        "index": "#13",
        "title": "Dual-Axis RCCL: Representation-Complete Convergent Learning for Organic Chemical Space",
        "link": "/arxiv/2512.14418",
        "arxiv_id": "2512.14418",
        "authors": "Dejun Hu, Zhiming Li, Jia-Rui Shen, Jia-Ning Tu, Zi-Hao Ye, Junliang Zhang",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.604188",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”** 论文的核心贡献是提出了一种名为“Dual-Axis RCCL”的分子表示学习策略，并基于此构建了一个名为FD25的分子数据集。其目标是让图神经网络（GNNs）在有机化学空间中实现“收敛学习”和更好的泛化能力。这完全符合筛选标准中的第一条排除规则：“非演化型应用”。该论文将机器学习模型（GNNs）作为工具，应用于特定的科学领域（化学/分子建模），以解决该领域的预测问题，其研究焦点在于分子表示和数据集构建，而非智能体的构建、改进或演化。 2.  **第二步：缺乏正面指标** 通读论文摘要，完全没有出现任何与您研究焦点相关的正面指标关键词。例如，论文没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 或 `Self-Improvement` 等任何概念。其方法论核心是图卷积网络（GCN）和图表示，这与智能体框架无关。 3.  **第四步：特殊情况不适用** 论文虽然提到了“convergent learning”和“generalization”，但这并非智能体意义上的“自我演化”。它指的是模型在特定数据分布上训练后，能够泛化到未见过的分子结构上，这是机器学习模型性能的衡量标准，而不是智能体通过经验、反思或环境反馈进行自我完善和迭代的机制。因此，关于“自我演化的应用”的例外规则不适用。 **总结**：该论文是一项扎实的计算化学研究，专注于改进分子表示和数据集以提升GNNs的性能。然而，它的本质是应用机器学习解决特定领域问题，与您关于“LLM智能体及其演化”的核心研究目标——即构建、改进或演化具备自主规划、工具使用、协作或自我演化能力的智能体——完全无关。因此，应予以排除。"
    },
    {
        "index": "#14",
        "title": "GRAFT: Grid-Aware Load Forecasting with Multi-Source Textual Alignment and Fusion",
        "link": "/arxiv/2512.14400",
        "arxiv_id": "2512.14400",
        "authors": "Fangzhou Lin, Guoshun He, Zhenyu Guo, Zhe Huang, Jinsong Tao",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.604452",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文本质是应用型研究，而非智能体构建。** 论文的核心贡献是提出一个名为 GRAFT 的模型，用于解决**电网负荷预测**这一特定领域的问题。它通过融合新闻、社交媒体等多源文本信息来提升预测精度。这完全符合筛选标准中“非演化型应用”的排除条款，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。论文的目标是解决电力领域的预测任务，而不是构建或演化一个通用的LLM智能体框架。 2.  **第二步：正面指标——缺乏核心关注点。** 论文中虽然提到了“external-memory interface”，但根据摘要描述，这更像是一个用于接入不同数据源（新闻、政策等）的即插即用模块，而非智能体用于存储经验、进行反思的认知记忆。论文完全没有涉及 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Self-Reflection` 等核心范式和能力。其核心是数据对齐和融合技术，服务于预测任务。 3.  **第三步：排除标准——不属于安全或多模态焦点。** 虽然论文提到了“source-level interpretation”，但这只是模型的一个附加特性，用于分析文本对负荷的影响，并非论文的核心研究贡献。论文的主要目标是提升预测准确率，因此不触发“主要贡献是关于可解释性”的排除规则。 4.  **第四步：特殊和模糊情况处理。** 论文不涉及多智能体或自我演化。在推理方面，论文的推理是模型内部的预测推理，而非智能体在复杂任务中如何进行自主规划和多步决策的 Agentic 框架。因此，不符合保留条件。 **最终决策**： 该论文的本质是**一个应用在能源领域的、融合了文本信息的时间序列预测模型**。它的核心贡献在于解决特定领域的工程问题，而非推动LLM智能体本身的能力、架构或演化机制的发展。因此，它与您“构建、改进或演化LLM智能体”的核心目标相悖，应予以排除。"
    },
    {
        "index": "#3",
        "title": "Model-Based Reinforcement Learning in Discrete-Action Non-Markovian Reward Decision Processes",
        "link": "/arxiv/2512.14617",
        "arxiv_id": "2512.14617",
        "authors": "Alessandro Trapasso, Luca Iocchi, Fabio Patrizi",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.601459",
        "filter_reason": "这篇论文不符合您的研究范围，核心原因在于其研究对象并非“LLM智能体”。 1.  **第一步：核心判断——论文本质不符** - **核心贡献**: 该论文的核心贡献是提出了一种名为 QR-MAX 的新型**基于模型的强化学习算法**，用于解决具有非马尔可夫奖励的决策过程问题。其重点在于通过奖励机来分解马尔可夫转移学习和非马尔可夫奖励处理，并提供理论上的收敛性和样本效率保证。 - **与目标的偏差**: 您的核心目标是筛选关于“**构建、改进或演化 LLM智能体**”的论文。这篇论文通篇未提及大型语言模型、Transformer或任何与LLM相关的技术。它研究的是经典的强化学习智能体，而非基于LLM的智能体。因此，它在第一步的核心判断中就应该被排除。 2.  **第二步：正面指标——缺乏关键关注点** - 论文中完全没有出现您所列出的任何核心范式或能力关键词，如 `LLM-based Agents`, `Tool Use`, `Self-Reflection`, `Multi-Agent Systems` 等。虽然它涉及智能体和规划，但这是在RL的语境下，与您关注的Agentic AI（以LLM为核心驱动力）有本质区别。 3.  **第三步与第四步：排除标准与特殊情况** - 该论文不属于安全对齐或多模态等排除类别。 - 在“推理/规划”的特殊情况处理中，这篇论文也不符合保留条件。它不是关于智能体如何利用LLM进行多步推理（如ReAct, ToT），而是关于一个RL算法如何学习最优策略。它属于提升RL算法本身的基础能力，而非构建一个LLM智能体的推理框架。 **总结**: 尽管这是一篇关于智能体决策的高质量强化学习论文，但它的技术路径和研究焦点（经典RL算法）与您的研究课题（LLM智能体及其演化）完全不相关。您的筛选标准非常明确地指向了以LLM为核心的智能体研究，而该论文属于更广泛的、不依赖LLM的强化学习领域。因此，应予以排除。"
    },
    {
        "index": "#17",
        "title": "Black-Box Auditing of Quantum Model: Lifted Differential Privacy with Quantum Canaries",
        "link": "/arxiv/2512.14388",
        "arxiv_id": "2512.14388",
        "authors": "Baobao Song, Shiva Raj Pokhrel, Athanasios V. Vasilakos, Tianqing Zhu, Gang Li",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.605273",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种针对**量子机器学习（QML）模型**的**黑盒隐私审计框架**。其目标是检测和量化QML模型在训练过程中对敏感数据的记忆泄露。这与您的研究目标“构建、改进或演化LLM智能体”完全不符。该论文属于**安全与隐私**领域的方法论研究，而非Agentic AI的构建或演化。因此，根据第一步的排除规则，它应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全不包含您关注的核心范式或能力。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等任何核心范式。虽然论文提到了“memorizing”（记忆），但这是指模型对训练数据的隐私泄露，而非智能体用于推理和决策的`Memory`机制。论文的研究对象是QML模型，而非LLM智能体。 3.  **第三步：排除标准——是否为我的研究焦点之外？** **这是最关键的排除依据。** 论文的整个研究都围绕着`Security`（安全）和`Privacy`（隐私）展开。其核心贡献是“隐私审计”、“量化隐私泄露”和“隐私预算”，这些都明确属于您筛选标准中的排除类别：“只要论文的主要贡献是关于 `Safety`, `Security`...一律排除”。 4.  **第四步：处理特殊和模糊情况** 本论文情况清晰，不涉及任何模糊地带。它既不是关于智能体的推理/规划，也不是关于自我演化的应用。它是一篇纯粹的、专注于QML模型隐私安全的论文。 **最终决策：** 综合以上分析，该论文的研究领域（量子机器学习）、核心贡献（隐私审计）和关键技术（安全与隐私）均与您的研究范围“LLM智能体及其演化”存在根本性偏差。它没有构建或演化任何形式的智能体，而是为一种完全不同的模型（QML）提供了一种安全验证工具。因此，该论文应被明确排除。"
    },
    {
        "index": "#21",
        "title": "FLAME: Flow Enhanced Legendre Memory Models for General Time Series Forecasting",
        "link": "/arxiv/2512.14253",
        "arxiv_id": "2512.14253",
        "authors": "Xingjian Wu, Hanyin Cheng, Xiangfei Qiu, Zhengyu Li, Jilin Hu, Chenjuan Guo, Bin Yang",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.606385",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 论文的核心贡献是提出了一种名为 **FLAME** 的新型**时间序列预测基础模型**。它通过结合勒让德记忆和归一化流来提升预测的效率和准确性。 - **判断**: 这篇论文的本质是**构建一个用于特定任务（时间序列预测）的模型**，而不是构建或演化一个具有自主性、规划能力或工具使用能力的LLM智能体。因此，它完全符合第一步排除标准中的 **“非演化型应用”**。论文将一个新颖的模型架构应用在时间序列领域，以解决该领域的预测问题，这与研究“LLM智能体及其演化”的目标有本质区别。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中没有出现任何您关注的核心范式，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 论文中提到了 `Memory`，但这里的 `Legendre Memory` 是一种特定的数学和计算结构（基于勒让德多项式），用于捕捉时间序列中的长期依赖关系，**并非**智能体研究中的情景记忆、程序记忆或工作记忆等概念。 - 论文完全没有涉及 `Planning`, `Tool Use`, `Self-Reflection`, `Collaboration` 等智能体核心能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全与对齐或多模态等排除标准，但这并不改变其核心不符的事实。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的“推理”是指模型对时间序列数据进行推断和预测，这是一种模型能力，而非智能体在复杂任务中通过规划、调用工具、与环境交互来完成目标的多步推理框架。因此，它属于被排除的“非Agentic的推理”范畴。 **最终决策**: 综合以上分析，这篇论文的研究焦点是**时间序列预测模型架构的创新**，而非**LLM智能体的构建、协作或演化**。它属于将一个新模型应用于特定领域的应用型研究，完全不符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”这一核心目标。因此，最终判断为 **False**。"
    },
    {
        "index": "#20",
        "title": "Explainable Preference Learning: a Decision Tree-based Surrogate Model for Preferential Bayesian Optimization",
        "link": "/arxiv/2512.14263",
        "arxiv_id": "2512.14263",
        "authors": "Nick Leenders, Thomas Quadt, Boris Cule, Roy Lindelauf, Herman Monsuur, Joost van Oijen, Mark Voskuijl",
        "subjects": "Machine Learning, Artificial Intelligence, Optimization and Control",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.606105",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质不符** 论文的核心贡献是提出一种“基于决策树的可解释代理模型”，用于解决“偏好贝叶斯优化”问题。这是一种机器学习算法的改进，属于优化理论和可解释AI（XAI）的范畴。它完全没有涉及构建、改进或演化任何形式的LLM智能体。因此，根据第一步的排除标准，它属于“非演化型应用”或更准确地说是“非Agentic的机器学习方法”，应被排除。 2.  **第三步：排除标准——命中明确的排除项** 这是最关键的排除依据。论文的标题和摘要反复强调其核心贡献是“Explainable”（可解释的）和“inherently interpretable”（内在可解释的）。根据我的筛选标准，只要论文的主要贡献是关于 `Interpretability` (可解释性) 或 `Explainability (XAI)`，就一律排除。这篇论文是典型的可解释性研究，与我的研究焦点“LLM智能体及其演化”完全不同。 3.  **第二步：正面指标——完全不匹配** 论文中没有出现任何与我核心关注点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。这进一步确认了它与我的研究课题无关。 **总结**: 该论文的研究方向是可解释的贝叶斯优化算法，其核心贡献在于提升模型的可解释性，而非构建或演化智能体。它明确命中了“安全与对齐”类别下的“可解释性”排除标准，且与所有正面指标均无关联。因此，这篇论文与“LLM智能体及其演化”的研究课题完全不相关，必须排除。"
    },
    {
        "index": "#18",
        "title": "Causal Structure Learning for Dynamical Systems with Theoretical Score Analysis",
        "link": "/arxiv/2512.14361",
        "arxiv_id": "2512.14361",
        "authors": "Nicholas Tagliapietra, Katharina Ensinger, Christoph Zimmer, Osman Mian",
        "subjects": "Machine Learning, Artificial Intelligence, Dynamical Systems",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.605549",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“CaDyT”的新方法，用于**动态系统的因果结构学习**。其目标是根据观测数据推断出系统随时间演化的因果关系。这完全属于**“非演化型应用”**的排除范畴。论文并未涉及构建、改进或演化任何形式的LLM智能体，而是提出了一种用于分析动态系统（一个特定领域）的工具。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不属于安全对齐或多模态视觉的排除类别，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 论文虽然提到了“dynamical systems evolve”，但这指的是物理或数学系统的自然演化，而非智能体的“自我演化”。论文的研究方法是因果发现和高斯过程，与智能体的自主规划、工具使用或自我反思机制无关。因此，特殊情况不适用。 **最终决策**：该论文的研究领域是**因果发现**，旨在从数据中推断系统的因果图，而非构建或研究具有自主性、规划能力或演化能力的LLM智能体。其核心贡献与我的研究课题“LLM智能体及其演化”存在本质区别，因此应予以排除。"
    },
    {
        "index": "#23",
        "title": "Physically consistent model learning for reaction-diffusion systems",
        "link": "/arxiv/2512.14240",
        "arxiv_id": "2512.14240",
        "authors": "Erion Morina, Martin Holler",
        "subjects": "Machine Learning, Analysis of PDEs, Optimization and Control",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.606913",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **论文核心贡献分析**: 这篇论文的核心是提出一种新的机器学习方法，用于从数据中学习物理系统（特别是反应扩散系统）的模型。其关键创新在于将物理定律（如质量守恒、准正性）作为约束条件，直接整合到学习过程中，以确保学到的模型是物理上自洽且良定的。 - **与筛选标准的匹配**: 这篇论文的本质是**科学机器学习** 或**物理信息神经网络** 的研究。它完全不涉及LLM、智能体框架、多智能体系统或自我演化机制。它属于典型的**“非演化型应用”**，但更准确地说，它甚至没有使用LLM或智能体作为工具，而是在一个特定的科学领域（物理/应用数学）内构建一个全新的、领域特定的模型。因此，根据第一步的排除规则，应直接排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然摘要中提到了 `interpretable` (可解释的)，但这是指学到的物理模型符合物理定律因而易于理解，并非论文的主要贡献。论文的核心是建模方法，而非AI安全、对齐或可解释性（XAI）研究。因此，虽然触及了排除标准中的词汇，但论文的实质内容并不属于该类别。不过，这并不改变其被排除的最终结论。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体推理/规划或自我演化相关的特殊情况。 **最终决策**: 综合以上分析，该论文的研究课题是“物理系统的数据驱动建模”，而您的研究课题是“LLM智能体及其演化”。两者在研究对象、核心贡献和技术路线上存在根本性的差异。该论文没有构建、改进或演化任何形式的LLM智能体，因此与您的研究目标完全不符，应予以排除。"
    },
    {
        "index": "#22",
        "title": "Beyond MMD: Evaluating Graph Generative Models with Geometric Deep Learning",
        "link": "/arxiv/2512.14241",
        "arxiv_id": "2512.14241",
        "authors": "Salvatore Romano, Marco Grassia, Giuseppe Mangioni",
        "subjects": "Machine Learning, Artificial Intelligence, Physics and Society",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.606652",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献分析**: 这篇论文的核心贡献是提出了一种名为RGM（Representation-aware Graph-generation Model evaluation）的新方法，用于**评估图生成模型**。它解决了现有评估指标（如MMD）的局限性，并使用一个几何深度学习模型来对生成的图进行分类和评估。 - **与我的研究目标对比**: 我的核心目标是筛选关于**构建、改进或演化LLM智能体**的论文。这篇论文既没有构建新的智能体，也没有改进智能体的能力（如规划、工具使用），更没有涉及智能体的自我演化。它的研究对象是“图生成模型”，而非“LLM智能体”。 - **结论**: 论文的核心是**模型评估方法论**，属于机器学习的一个子领域，与我的研究焦点“LLM智能体及其演化”完全无关。因此，根据第一步的核心判断，应直接**排除**。 2.  **第二步：正面指标** - 论文中完全没有出现我关注的核心范式和能力相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究范围不相关。 3.  **第三步：排除标准** - 虽然论文没有直接触及“安全与对齐”或“多模态与视觉”等排除项，但第一步的判断已经足够有力，无需依赖此步。 4.  **第四步：处理特殊和模糊情况** - 论文不涉及任何与智能体相关的推理、规划或自我演化机制，因此特殊情况不适用。 **最终决策**: 综合以上分析，该论文的本质是关于图生成模型的评估方法研究，其贡献点在于提出了一种新的评估指标。这与我寻找“构建、改进或演化LLM智能体”的核心目标完全偏离。因此，这篇论文应被排除。"
    },
    {
        "index": "#28",
        "title": "Optimizing the Adversarial Perturbation with a Momentum-based Adaptive Matrix",
        "link": "/arxiv/2512.14188",
        "arxiv_id": "2512.14188",
        "authors": "Wei Tao, Sheng Long, Xin Liu, Wei Li, Qing Tao",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.608327",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文的本质不符。** 该论文的核心贡献是提出了一种名为“AdaMI”的新型**对抗攻击方法**。其研究内容是关于如何优化对抗性扰动，以提高攻击的迁移性和稳定性。这完全属于**模型安全与对抗性机器学习**的范畴，而非构建、改进或演化LLM智能体。根据筛选标准，这属于“非演化型应用”的排除范畴，因为它没有提出新的智能体框架或演化机制。 2.  **第三步：排除标准——触及明确的排除领域。** 论文的研究主题是“对抗样本”和“对抗攻击”，这直接命中了“安全与对齐”中的“安全”排除标准。论文的主要目标是提升攻击模型的能力，这与我的研究焦点“LLM智能体的构建与演化”有本质区别。 3.  **第二步：正面指标——完全不包含核心关注点。** 论文摘要中完全没有出现任何我关注的核心范式、智能体能力或演化机制相关的关键词，如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent` 等。其讨论的是优化理论中的梯度、动量和自适应矩阵，与智能体的自主行为无关。 综上所述，该论文是一篇典型的模型安全/攻击领域的论文，其核心贡献与研究课题“LLM智能体及其演化”无关，因此应被排除。"
    },
    {
        "index": "#24",
        "title": "Understanding the Gain from Data Filtering in Multimodal Contrastive Learning",
        "link": "/arxiv/2512.14230",
        "arxiv_id": "2512.14230",
        "authors": "Divyansh Pareek, Sewoong Oh, Simon S. Du",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.607165",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**对多模态对比学习中数据过滤效果的理论分析**。它旨在解释为什么“基于教师的过滤”能够提升模型性能，并给出了数学上的误差界限证明。这属于**基础模型训练技术**的范畴，而非构建、改进或演化LLM智能体的方法论。根据筛选标准，这属于“非演化型应用”或更基础的模型研究，应被排除。 2.  **排除标准 (第三步):** 论文标题和摘要明确指出其研究焦点是**“多模态对比学习”**。这直接触发了“多模态与视觉”的排除标准。论文的核心是研究如何通过过滤数据来提升多模态模型的表征学习能力，而不是将多模态能力作为智能体感知环境的工具。因此，它属于被排除的类别。 3.  **正面指标缺失 (第二步):** 论文中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与我的研究课题无关。 综上所述，该论文的研究方向是表征学习和数据管理，与“LLM智能体及其演化”的核心目标——构建和演化具有自主规划、工具使用和协作能力的智能体——存在本质区别。因此，应予以排除。"
    },
    {
        "index": "#25",
        "title": "Estimating problem difficulty without ground truth using Large Language Model comparisons",
        "link": "/arxiv/2512.14220",
        "arxiv_id": "2512.14220",
        "authors": "Marthe Ballon, Andres Algaba, Brecht Verbeken, Vincent Ginis",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.607438",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心贡献是提出了一种名为“LLM compare”的新方法，用于在没有真实标签的情况下估算问题的难度。该方法利用LLM进行成对的难度比较，并基于此计算Bradley-Terry分数。 - **是否符合要求**: 不符合。这篇论文的本质是**一种评估方法论**，而不是构建、改进或演化LLM智能体。它将LLM作为一个“比较器”工具来解决“如何估算问题难度”这个元问题。这完全符合第一步排除标准中的第一条：“非演化型应用”，即论文只是将LLM作为工具应用到特定领域（这里是模型评估和课程设计）去解决该领域的问题，其核心贡献并非智能体本身。 2.  **第二步：正面指标** - 论文摘要中完全没有出现您关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 也没有提及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。虽然LLM被用作“工具”，但论文的研究焦点并非“智能体的工具使用能力”，而是利用LLM来完成一项评估任务。 - 缺乏所有正面指标，这进一步确认了该论文与您的研究焦点无关。 3.  **第三步：排除标准** - 论文虽然提到了对幻觉的鲁棒性，但这只是对其方法有效性的一个验证，并非论文的主要贡献。因此，它不属于“安全与对齐”的排除范畴。 - 论文不涉及多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文确实涉及LLM的推理能力，但它不是在研究“智能体如何进行规划或在复杂任务中进行多步推理”。它只是利用LLM的推理能力来对问题难度进行判断。这属于排除情况：“如果只是关于提高LLM本身基础Token预测的数学或逻辑能力...”，虽然这里不是“提高”，而是“利用”，但其本质都不是研究智能体的自主规划框架。 - **自我演化的应用**: 论文没有提出任何自我演化机制。 **最终决策**: 综合以上分析，这篇论文的核心是提出一种**模型评估的新方法**，属于LLM研究中的“评估与度量”分支。它虽然使用了LLM，但研究对象是“问题难度”，而不是“智能体”。您的核心目标是筛选关于**构建和演化智能体本身**的论文，而这篇论文与此目标相去甚远。因此，应予以排除。"
    },
    {
        "index": "#26",
        "title": "Understanding and Improving Hyperbolic Deep Reinforcement Learning",
        "link": "/arxiv/2512.14202",
        "arxiv_id": "2512.14202",
        "authors": "Timo Klein, Thomas Lang, Andrii Shkabrii, Alexander Sturm, Kevin Sidak, Lukas Miklautz, Claudia Plant, Yllka Velaj, Sebastian Tschiatschek",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.607787",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质不匹配** - 论文的核心贡献是提出了一种名为 `Hyper++` 的新方法，用于**改进深度强化学习（DRL）智能体的训练过程**。具体来说，它通过使用双曲几何空间和特定的训练技巧（如分类价值损失、特征正则化）来解决PPO智能体在训练中的优化不稳定性问题。 - 您的核心目标是筛选关于 **LLM智能体** 的论文。这篇论文研究的智能体是标准的DRL智能体，其决策核心是神经网络，而非大语言模型（LLM）。全文未提及LLM、语言模型或任何与语言生成、理解相关的组件。 - 因此，该论文属于“改进智能体”的范畴，但并非您所关注的“LLM智能体”范畴。这是一个根本性的不匹配，应直接排除。 2.  **正面指标 (第二步): 缺乏核心关注点** - 论文中完全没有出现您所列出的任何核心范式或能力关键词，如 `LLM-based Agents`, `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 论文中的“智能体”是RL领域的标准定义，即一个在环境中通过试错学习策略的实体，这与您关注的具备规划、工具使用、记忆等高级认知能力的Agentic AI有本质区别。 3.  **排除标准 (第三步): 不适用但进一步确认范围** - 虽然论文不涉及安全对齐或多模态等排除项，但这并不改变其核心内容与您研究目标不符的事实。论文使用的Atari等环境虽然是视觉输入，但研究的核心是特征表示的数学空间（双曲空间），而非视觉本身，因此不触犯多模态排除规则。 4.  **特殊和模糊情况 (第四步): 不适用** - 论文不涉及LLM的推理/规划，也不涉及自我演化机制。它提出的是一个静态的、改进的训练算法，而不是一个能让智能体自我演化的框架。 **最终决策 (第五步):** 综合以上分析，尽管这篇论文在DRL领域可能是一项扎实的工作，但它研究的对象是**深度强化学习智能体**，而非您课题所聚焦的**LLM智能体**。其贡献在于优化训练算法和特征表示，而非构建、改进或演化基于LLM的Agentic框架。因此，该论文与您的研究范围“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#32",
        "title": "Cornserve: Efficiently Serving Any-to-Any Multimodal Models",
        "link": "/arxiv/2512.14098",
        "arxiv_id": "2512.14098",
        "authors": "Jeff J. Ma, Jae-Won Chung, Jisang Ahn, Yizhuo Liang, Akshay Jajoo, Myungjin Lee, Mosharaf Chowdhury",
        "subjects": "Machine Learning, Distributed, Parallel, and Cluster Computing",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.609419",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准的第一步“核心判断”，这篇论文的本质是关于模型基础设施和部署优化，而非构建、改进或演化LLM智能体。 1.  **核心贡献分析**: 论文的核心贡献是提出一个名为Cornserve的“高效的在线服务系统”，用于服务Any-to-Any多模态模型。其研究重点在于如何优化模型的部署计划、分解模型组件以及通过分布式运行时提高服务吞吐量和降低延迟。这完全符合第一步中的排除标准第3条：“主要关注模型基础设施、部署优化、硬件加速的研究”。 2.  **与筛选标准的匹配度**: *   **第一步 (核心判断)**: 论文的核心是“服务系统”，属于基础设施范畴，应被**排除**。 *   **第二步 (正面指标)**: 论文中没有出现任何关于`Agentic AI`, `Planning`, `Tool Use`, `Collaboration`, `Self-Evolving`等核心关注点的关键词。它提到的`planner`是指用于优化部署的系统规划器，而非智能体的任务规划器。 *   **第三步 (排除标准)**: 论文的核心是“多模态与视觉”，触发了排除规则。虽然论文中提到了LLM，但它只是作为被服务系统中的一个组件，研究的焦点并非LLM的智能体能力。 综上所述，尽管论文涉及LLM，但其研究范畴属于系统/工程领域，与“LLM智能体及其演化”的核心目标——智能体的构建、协作与演化机制——完全无关。因此，应予以排除。"
    },
    {
        "index": "#30",
        "title": "PathFinder: Advancing Path Loss Prediction for Single-to-Multi-Transmitter Scenario",
        "link": "/arxiv/2512.14150",
        "arxiv_id": "2512.14150",
        "authors": "Zhijie Zhong, Zhiwen Yu, Pengyu Li, Jianming Lv, C. L. Philip Chen, Min Chen",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.608879",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”** 论文的核心贡献是提出一个名为 `PathFinder` 的新型深度学习架构，用于解决无线通信领域的特定问题：**无线电路径损耗预测**。这是一个典型的将深度学习模型作为工具应用到特定领域（电信/5G网络优化）的案例。论文的目标是提升在该特定任务上的预测精度和泛化能力，而不是构建一个具有通用能力的、自主的LLM智能体。因此，它完全符合“非演化型应用”的排除标准。 2.  **第二步：缺乏正面指标** 论文摘要中完全没有出现任何与您研究焦点相关的核心范式或能力关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent Systems`, `Collaboration`, `Self-Evolving` 等。其技术焦点在于 `disentangled feature encoding`（解耦特征编码）和 `Mask-Guided Low-rank Attention`（掩码引导的低秩注意力），这些都是标准的深度学习模型组件，与智能体框架无关。 3.  **对“多发射器”的澄清** 论文标题和摘要中提到的 `Single-to-Multi-Transmitter`（单到多发射器）场景，这里的“发射器”指的是物理世界中的无线电信号发射塔或设备，**而不是指多个自主决策的智能体**。这与您研究焦点中的“多智能体系统”有着本质区别，后者关注的是智能体间的协作、通信和博弈等社会性行为。 4.  **最终决策** 综合来看，这篇论文的研究对象是无线信号传播模型，其贡献在于改进一个特定领域的预测算法。它既不涉及LLM，也不涉及智能体的构建、规划、工具使用、协作或自我演化等核心机制。因此，它完全偏离了您关于“LLM智能体及其演化”的研究课题，应果断排除。"
    },
    {
        "index": "#27",
        "title": "Random-Bridges as Stochastic Transports for Generative Models",
        "link": "/arxiv/2512.14190",
        "arxiv_id": "2512.14190",
        "authors": "Stefano Goria, Levent A. Mengütürk, Murat C. Mengütürk, Berkan Sesen",
        "subjects": "Machine Learning, Probability",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.608061",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为“随机桥”的新方法，用于改进生成模型。它本质上是一种在概率分布之间进行随机转换的数学框架，旨在提高生成样本的质量和效率。这与我的核心目标——**构建、改进或演化LLM智能体**——完全无关。论文没有涉及任何智能体框架、多智能体系统或自我演化机制。因此，根据第一步的核心判断，这篇论文应被排除。 2.  **第二步：正面指标** 论文的标题和摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其讨论的重点是 `Generative Models`, `Stochastic Processes`, `Probability Distributions`，这些都不是我的研究焦点。 3.  **第三步：排除标准** 这篇论文明确属于“多模态与视觉”的排除范围。摘要中提到其评估指标是 `Frechet inception distance (FID)`，这是衡量图像生成质量的经典指标。这表明该研究的核心是一种生成模型（类似于扩散模型GANs），其应用场景很可能是图像生成。根据筛选标准，除非这类模型被用作智能体感知环境的工具，否则应被排除。而本文的研究核心就是模型本身，并非其在智能体中的应用。 4.  **第四步：处理特殊和模糊情况** 本文不涉及任何需要特殊处理的情况。它既不是关于智能体的推理/规划，也不是关于自我演化的应用。 **最终决策**：综合以上分析，该论文是一篇关于生成模型基础方法的研究，虽然可能在其领域内具有前沿性，但其研究内容与“LLM智能体及其演化”这一课题完全脱节。因此，最终判断为 **False**，予以排除。"
    },
    {
        "index": "#29",
        "title": "On Improving Deep Active Learning with Formal Verification",
        "link": "/arxiv/2512.14170",
        "arxiv_id": "2512.14170",
        "authors": "Jonathan Spiegelman, Guy Amir, Guy Katz",
        "subjects": "Machine Learning, Logic in Computer Science",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.608596",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）**: 论文的核心贡献是提出一种改进“深度主动学习”的方法。它通过使用形式化验证生成对抗性样本来增强训练数据，从而提高模型的泛化能力。这本质上是一种**模型训练优化技术**，属于机器学习方法的范畴，而非构建、改进或演化LLM智能体。根据筛选标准，这属于“非演化型应用”，即将一种技术（对抗性样本生成）应用于特定领域（模型训练）来解决该领域的问题（减少标注成本、提升泛化性），因此应被排除。 2.  **正面指标缺失（第二步）**: 论文的标题和摘要中完全没有出现我关注的核心范式和智能体能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。这进一步表明该研究与我的研究焦点无关。 3.  **排除标准（第三步）**: 虽然论文提到了“对抗性输入”，这与安全领域相关，但其主要贡献并非提出新的安全或对齐机制，而是利用对抗性样本作为一种工具来优化训练过程。因此，它不直接属于“安全与对齐”的排除类别，但其核心问题仍然偏离了Agentic AI。 综上所述，该论文的研究重点是优化神经网络的数据效率和训练过程，与“LLM智能体及其演化”这一核心课题相去甚远。它没有涉及智能体的构建、规划、工具使用、多智能体交互或自我演化等任何核心议题。因此，最终决策为排除。"
    },
    {
        "index": "#19",
        "title": "Implicit Bias and Invariance: How Hopfield Networks Efficiently Learn Graph Orbits",
        "link": "/arxiv/2512.14338",
        "arxiv_id": "2512.14338",
        "authors": "Michael Murray, Tenzin Chan, Kedar Karhadker, Christopher J. Hillar",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.605808",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是关于**经典霍普菲尔德网络**的理论分析，研究其在处理具有对称性的图数据时如何隐式地学习不变性。这属于**神经网络学习理论**的范畴，而非构建、改进或演化LLM智能体。论文完全没有提及LLM、智能体框架或任何与Agentic AI相关的核心概念。因此，它在第一步的核心判断中就被排除。 2.  **正面指标缺失 (第二步):** 论文的标题和摘要中，完全没有出现任何我关注的核心范式、智能体能力或演化机制的关键词。例如，`Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等均未提及。这进一步确认了它与我的研究焦点无关。 3.  **研究领域的根本差异:** 我的研究课题是前沿的 \"LLM智能体及其演化\"，关注的是基于大语言模型的、具备自主规划、工具使用和演化能力的智能体系统。而该论文研究的是一种**经典的、非基于LLM的神经网络模型（Hopfield Networks）**，其目标是揭示一种基础的学习机制（隐式偏置导致不变性）。两者在研究对象、研究目标和技术路线上存在根本性的差异。 综上所述，该论文是一篇关于经典神经网络学习理论的深度研究，虽然在其领域内可能很有价值，但它与我的核心目标——筛选关于构建、改进或演化LLM智能体的论文——完全无关。因此，最终决策为排除。"
    },
    {
        "index": "#31",
        "title": "A First-Order Logic-Based Alternative to Reward Models in RLHF",
        "link": "/arxiv/2512.14100",
        "arxiv_id": "2512.14100",
        "authors": "Chunjin Jian, Xinhua Zhu",
        "subjects": "Machine Learning, Logic in Computer Science",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.609129",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出一种新的奖励机制（基于一阶逻辑的相似性）来替代RLHF中的传统奖励模型，并引入了一个名为S-GRPO的训练框架。其根本目标是改进LLM的**对齐**效果，使其输出更符合人类偏好。这篇论文的本质是关于**模型训练和优化方法**，而不是关于构建一个具有自主规划、工具使用或记忆能力的**LLM智能体**。它没有提出任何新的智能体架构或框架，因此不符合“保留”标准。 2.  **第二步：正面指标** 论文中完全没有出现您所关注的核心范式和能力指标，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent Systems` 等。其讨论的焦点是奖励模型、逻辑一致性和训练框架（S-GRPO, DPO），这些都是模型对齐和训练优化的术语，而非智能体研究的关键词。 3.  **第三步：排除标准** 这是最关键的一步。论文摘要开篇即点明其研究核心：“...aligning large language models (LLMs) with human values and preferences.”（使大型语言模型与人类价值观和偏好对齐）。全文围绕“对齐”展开，提出了替代传统奖励模型的对齐方法。根据您的筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Explainability (XAI)`, `Alignment` (对齐)...一律排除。” 这篇论文完全符合此排除标准。 4.  **第四步：处理特殊和模糊情况** 论文虽然提到了“逻辑”，但这属于**非Agentic的推理**范畴。它利用形式逻辑来构建一个更好的奖励信号，用于指导模型的训练过程，而不是让智能体在执行任务时运用逻辑进行自主规划和推理。这与ReAct、ToT等智能体推理框架有本质区别。 **最终决策**：综合以上分析，该论文的核心贡献在于LLM的**对齐技术**，而非LLM智能体的构建、改进或演化。它属于您明确指定的排除领域（安全与对齐），因此应被排除。"
    },
    {
        "index": "#36",
        "title": "FusAD: Time-Frequency Fusion with Adaptive Denoising for General Time Series Analysis",
        "link": "/arxiv/2512.14078",
        "arxiv_id": "2512.14078",
        "authors": "Da Zhang, Bingyu Li, Zhiyuan Zhao, Feiping Nie, Junyu Gao, Xuelong Li",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.610492",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 `FusAD` 的**深度学习模型框架**，用于解决**时间序列分析**（分类、预测、异常检测）这一特定领域的问题。其技术创新点在于“时频融合机制”和“自适应去噪机制”。这完全符合筛选标准中的**排除项 1：非演化型应用**。该论文是将一个新模型作为工具应用到特定领域，而不是研究如何构建、改进或演化LLM智能体本身。论文中完全没有提及LLM、智能体或任何与Agentic相关的概念。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中，完全没有出现任何您所关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction` 等。这进一步确认了该论文与您的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然该论文不涉及安全对齐或多模态等排除项，但它已经触发了最根本的第一步排除规则。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体规划或自我演化相关的特殊情况。它是一个纯粹的、针对特定数据类型（时间序列）的模型架构创新。 **最终决策**: 综合以上分析，这篇论文的研究对象是**时间序列分析模型**，而非**LLM智能体**。其核心贡献在于改进模型处理时序数据的能力，这与您关于“LLM智能体及其演化”的研究目标（单智能体、多智能体、自我演化）存在根本性的偏差。因此，该论文应被明确排除。"
    },
    {
        "index": "#35",
        "title": "SonicMoE: Accelerating MoE with IO and Tile-aware Optimizations",
        "link": "/arxiv/2512.14080",
        "arxiv_id": "2512.14080",
        "authors": "Wentao Guo, Mayank Mishra, Xinle Cheng, Ion Stoica, Tri Dao",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.610224",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为 `SonicMoE` 的方法，用于**加速混合专家模型的训练和推理**。其具体贡献包括：一个内存高效的算法、优化的GPU内核设计以及一种减少计算浪费的“token rounding”方法。这些工作本质上属于**模型基础设施和部署优化**的范畴，旨在提升MoE模型在硬件上的运行效率（减少内存占用、提高计算吞吐量）。根据筛选标准，应排除“主要关注模型基础设施、部署优化、硬件加速的研究”。因此，在第一步即可判定为排除。 2.  **第二步：正面指标** 论文中完全没有出现您所关注的核心范式或能力关键词，如 `Agentic AI`, `Tool Use`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Self-Reflection` 等。文中提到的“activation memory”指的是硬件层面的激活值内存占用，而非智能体的认知记忆机制。因此，该论文不包含任何正面指标。 3.  **第三步：排除标准** 该论文不涉及安全、对齐或多模态等排除领域，但其核心内容已触犯了第一步中的“基础设施”排除项。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及推理/规划或自我演化的应用，因此此步不适用。 **最终决策**: 综合以上分析，这篇论文的本质是**系统层面的性能优化**，而非**智能体能力或框架的创新**。它研究的是如何让一种特定的模型架构跑得更快、更省资源，而不是如何让LLM变得更像一个能够自主规划、使用工具或自我演化的智能体。因此，它与您关于“LLM智能体及其演化”的核心研究目标完全不符。"
    },
    {
        "index": "#37",
        "title": "Multivariate Time Series Forecasting with Hybrid Euclidean-SPD Manifold Graph Neural Networks",
        "link": "/arxiv/2512.14023",
        "arxiv_id": "2512.14023",
        "authors": "Yong Fang, Na Li, Hangguan Shan, Eryun Liu, Xinyu Li, Wei Ni, Er-Ping Li",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.610766",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的核心贡献是提出了一种名为“HSMGNN”的新型图神经网络模型，用于解决**多元时间序列预测**这一特定领域的问题。其创新点在于结合了欧几里得空间和黎曼空间的几何表示来提升预测精度。 - 根据筛选标准，这完全属于**“非演化型应用”**的排除类别。论文将一个新构建的模型（HSMGNN）作为工具，应用于特定领域（时间序列预测、交通管理），其目标是解决该领域的预测精度问题，而不是构建或演化一个具有通用能力的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` (指智能体的记忆机制), `Self-Reflection` 等。 - 摘要中提到的“trainable memory mechanism”是指为了“alleviate the high computational cost of Riemannian distance”而设计的“Adaptive-Distance-Bank (ADB) layer”，这是一种模型内部的计算优化技巧，与智能体的情景记忆、语义记忆或经验学习完全无关。 3.  **第三步与第四步：排除标准与特殊情况** - 该论文不涉及安全、对齐或多模态等排除标准，但其本质已在第一步被明确排除。 - 它也不涉及任何特殊情况。论文没有讨论智能体的规划或推理，更没有提出任何“自我演化”机制。 **最终决策**: 综合以上分析，这篇论文是一篇典型的机器学习应用研究，其核心是针对特定任务（时间序列预测）设计一个更高效的神经网络模型。它与我的研究目标——“构建、改进或演化LLM智能体”——在本质上毫无关联。因此，这篇论文应被**排除**。"
    },
    {
        "index": "#33",
        "title": "Arithmetic-Intensity-Aware Quantization",
        "link": "/arxiv/2512.14090",
        "arxiv_id": "2512.14090",
        "authors": "Taig Singh, Shreshth Rajan, Nikhil Iyer",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.609676",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“Arithmetic-Intensity-Aware Quantization (AIQ)”的混合精度量化框架。该框架旨在通过优化神经网络的逐层比特宽度，来最大化算术强度并提升推理吞吐量。 根据您的筛选标准，这篇论文在第一步“核心判断”中就应该被排除。其研究本质属于“基础设施”范畴，主要关注模型部署优化和硬件加速，而非构建、改进或演化LLM智能体。论文的目标是解决神经网络推理中的内存带宽瓶颈问题，这是一个典型的系统和硬件层面的优化问题。 具体分析如下： 1.  **核心判断（第一步）**: 论文的核心是量化技术，一种模型部署优化方法，完全符合“基础设施”排除标准。它没有构建任何智能体框架，也没有涉及智能体的任何核心能力。 2.  **正面指标（第二步）**: 论文中完全没有出现任何您关注的核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。 3.  **排除标准（第三步）**: 虽然论文不直接涉及安全与对齐或多模态，但它已经被第一步的“基础设施”规则明确排除。 4.  **特殊情况（第四步）**: 论文不涉及智能体框架内的推理/规划，也未提出任何自我演化机制。它提到的“搜索算法”是在量化方案空间中进行搜索，与智能体的行为或演化无关。 综上所述，该论文的研究焦点是模型性能优化和硬件效率，与您关于“LLM智能体及其演化”的研究课题完全不相关。因此，应予以排除。"
    },
    {
        "index": "#39",
        "title": "Accelerating MHC-II Epitope Discovery via Multi-Scale Prediction in Antigen Presentation",
        "link": "/arxiv/2512.14011",
        "arxiv_id": "2512.14011",
        "authors": "Yue Wan, Jiayi Yuan, Zhiwei Feng, Xiaowei Jia",
        "subjects": "Machine Learning, Quantitative Methods",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.611322",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是**为计算免疫疗法领域构建了一个新的、经过精心策划的数据集**，并提出了一个用于评估MHC-II抗原呈递预测模型的**多尺度评估框架和模块化分析**。其本质是**将机器学习方法应用于一个特定的科学领域（生物/医疗）**，以解决该领域的具体问题（MHC-II表位发现）。这完全符合第一步排除标准中的 **“非演化型应用”**。论文并未提出任何关于如何构建、改进或演化LLM智能体的新方法论或框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我核心关注点相关的关键词或概念，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。论文中提到的“Multi-Scale”指的是生物学过程中的不同尺度（肽段、抗原），而非“多智能体系统”，这是一个典型的领域术语陷阱。 3.  **第三步 & 第四步：排除标准与特殊情况处理** 该论文不涉及安全、对齐或多模态等排除标准。同时，它也不属于任何需要特殊处理的情况。它没有提出任何智能体规划或推理框架，更没有涉及任何“自我演化”机制。它是一个纯粹的应用型研究，其价值在于为特定领域提供了资源和基准。 **最终决策**: 综合以上分析，该论文是一篇典型的**应用机器学习于生物信息学**的研究。其核心贡献是数据集和评估基准，而非智能体架构或演化机制。因此，它与我关于“LLM智能体及其演化”的研究目标完全不符，应予以排除。"
    },
    {
        "index": "#41",
        "title": "Pattern-Guided Diffusion Models",
        "link": "/arxiv/2512.13945",
        "arxiv_id": "2512.13945",
        "authors": "Vivian Lin, Kuk Jin Jang, Wenwen Si, Insup Lee",
        "subjects": "Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.611848",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出一种名为“Pattern-Guided Diffusion Models (PGDM)”的新方法，用于改进多元时间序列的预测。其本质是**对扩散模型这一特定生成模型的改进**，通过引入数据中的“模式”来引导预测过程。 - **是否符合要求**: 不符合。该论文的研究对象是**扩散模型**，而非**LLM智能体**。它没有涉及构建、改进或演化任何形式的智能体框架。因此，根据第一步的排除标准，它属于“非演化型应用”，即将一种模型（扩散模型）应用到特定领域（时间序列预测）去解决该领域的问题。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何与我核心关注点相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** - 论文的核心是关于 `Diffusion Models`。根据筛选标准，如果 `Diffusion Models` 是研究的核心，而不是被智能体用作感知环境的工具，那么就应该被排除。在这篇论文中，扩散模型本身就是研究的主体，因此符合排除条件。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及智能体的推理/规划，也没有提出任何“自我演化”机制。因此，特殊情况的例外条款不适用。 **最终决策**: 综合以上分析，这篇论文的研究重点是改进一种生成模型（扩散模型）在时间序列预测任务上的性能，其核心贡献与方法论均与“LLM智能体及其演化”这一课题无关。它属于典型的模型应用与改进研究，而非智能体框架研究。因此，应予以排除。"
    },
    {
        "index": "#40",
        "title": "A Single Architecture for Representing Invariance Under Any Space Group",
        "link": "/arxiv/2512.13989",
        "arxiv_id": "2512.13989",
        "authors": "Cindy Y. Zhang, Elif Ertekin, Peter Orbanz, Ryan P. Adams",
        "subjects": "Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.611575",
        "filter_reason": "这篇论文的核心贡献是提出了一种新的机器学习架构，该架构能够自动适应权重以实现对任何空间群对称性的不变性，主要用于材料科学领域的晶体性质预测。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** 论文的本质属于 **“非演化型应用”**。它的核心目标是解决材料科学和凝聚态物理中的一个特定问题（即如何为230种空间群设计一个统一的、具有不变性的神经网络架构），而不是构建、改进或演化LLM智能体。论文中完全没有提及LLM或任何智能体框架。它是一个纯粹的、应用于特定科学领域的机器学习模型架构创新。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文完全不包含任何正面指标。摘要和标题中均未出现 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等任何与研究焦点相关的关键词。其讨论的核心是 `symmetries` (对称性), `space groups` (空间群), `Fourier bases` (傅里叶基) 和 `neural network architecture` (神经网络架构)。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文不直接涉及“安全与对齐”或“多模态与视觉”等排除项，但它已经被第一步的核心判断所排除。 4.  **第四步：处理特殊和模糊情况** 论文不涉及任何与智能体相关的推理/规划或自我演化机制。其提到的“自动适应权重”是指模型架构设计上的一种数学特性，而非智能体通过经验学习和自我完善的过程。 **最终决策：** 该论文的研究内容是几何深度学习在材料科学中的应用，与“LLM智能体及其演化”这一课题毫无关联。它的核心贡献是模型架构设计，而非智能体的构建或演化。因此，这篇论文不符合筛选要求，应被排除。"
    },
    {
        "index": "#43",
        "title": "A Complete Guide to Spherical Equivariant Graph Transformers",
        "link": "/arxiv/2512.13927",
        "arxiv_id": "2512.13927",
        "authors": "Sophia Tang",
        "subjects": "Machine Learning, Quantitative Methods",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.612367",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **论文核心贡献**: 这篇论文的核心是提出和解释一种名为“球面等变图神经网络”的模型架构。它专注于处理三维分子和生物分子数据，确保模型在输入数据旋转时，其预测结果能遵循物理上的旋转对称性（SO(3)等变性）。 - **与目标对比**: 您的核心目标是筛选关于“构建、改进或演化LLM智能体”的论文。这篇论文完全没有涉及LLM（大语言模型），也没有讨论智能体的规划、工具使用、记忆或自我演化等核心能力。它本质上是一篇关于**几何深度学习**和**图神经网络**在特定科学领域（化学、生物学）应用的论文。 - **结论**: 该论文属于**排除标准 #1 (非演化型应用)**。它构建了一个新的模型（EGNN）并将其应用于特定领域，而不是构建或研究LLM智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文没有触及安全与对齐、多模态视觉等排除标准，但第一步的判断已经足够将其排除。这篇论文的研究范式是几何深度学习，而非Agentic AI。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此特殊规则不适用。 **最终决策**: 综合以上分析，这篇论文是一篇关于几何深度学习模型（球面等变图Transformer）的技术指南，其研究焦点是物理对称性和分子结构建模，与您关于“LLM智能体及其演化”的研究课题完全不相关。因此，应予以排除。"
    },
    {
        "index": "#34",
        "title": "Derivative-Informed Fourier Neural Operator: Universal Approximation and Applications to PDE-Constrained Optimization",
        "link": "/arxiv/2512.14086",
        "arxiv_id": "2512.14086",
        "authors": "Boyuan Yao, Dingcheng Luo, Lianghao Cao, Nikola Kovachki, Thomas O'Leary-Roseberry, Omar Ghattas",
        "subjects": "Machine Learning, Numerical Analysis",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.609956",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文本质分析** 论文的核心贡献是提出了一种名为“导数感知傅里叶神经算子”的新型神经网络架构（DIFNO），并为其建立了通用逼近理论。其应用场景是解决“偏微分方程约束优化”这一科学计算问题。论文的本质是**科学计算与数值方法**的研究，而非人工智能智能体的研究。 根据筛选标准，这完全符合**排除规则中的第一条：“非演化型应用”**。该论文将一种神经网络（FNO）作为工具或代理模型，应用于物理/工程领域（PDE求解与优化），其核心目标是解决该领域的特定问题，而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——核心关注点匹配** 论文中完全没有出现任何我关注的核心范式、智能体能力、多智能体或演化机制相关的关键词。例如，它没有提及 `LLM-based Agents`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步确认了该论文与我的研究焦点无关。 3.  **第三步：排除标准——研究焦点之外** 该论文不属于安全对齐或多模态视觉的排除类别，但这并不改变其在第一步就被排除的事实。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划或自我演化机制的特殊情况。 **最终决策**： 综合以上分析，这篇论文的研究对象是“神经算子”，应用领域是“偏微分方程”，与我的核心目标“LLM智能体及其演化”存在根本性的领域差异。它是一篇典型的将机器学习模型应用于特定科学领域的论文，而非关于Agentic AI本身的方法论研究。因此，必须排除。"
    },
    {
        "index": "#47",
        "title": "Exploring Machine Learning, Deep Learning, and Explainable AI Methods for Seasonal Precipitation Prediction in South America",
        "link": "/arxiv/2512.13910",
        "arxiv_id": "2512.13910",
        "authors": "Matheus Corrêa Domingos, Valdivino Alexandre de Santiago Júnior, Juliana Aparecida Anochi, Elcio Hideiti Shiguemori, Luísa Mirelle Costa dos Santos, Hércules Carlos dos Santos Pereira, André Estevam Costa Oliveira",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.613462",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**应用**而非**构建**。它将现有的机器学习（Random Forest, XGBoost）和深度学习（LSTM, GRU）模型作为工具，应用于一个特定领域——南美洲的季节性降水预测。这完全符合“非演化型应用”的排除标准。论文的本质是评估不同模型在气象学领域的预测性能，而不是提出一种新的LLM智能体框架、多智能体系统或自我演化机制。 2.  **正面指标缺失 (第二步):** 论文中完全没有出现您关注的核心范式或能力关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 或 `Self-Reflection` 等任何与智能体相关的概念。其研究的“推理”仅限于LSTM/GRU模型内部的时间序列预测，而非智能体的自主规划与行动。 3.  **触及排除标准 (第三步):** 论文明确提到了“可解释人工智能（XAI）”来解释模型行为。根据您的筛选标准，只要论文的主要贡献涉及 `Interpretability` (可解释性) 或 `Explainable (XAI)`，就应被排除。虽然XAI在这里是辅助作用，但它进一步确认了该论文的研究焦点与您的Agentic AI核心目标相悖。 综上所述，该论文是一篇典型的交叉学科应用研究，属于气象学与数据科学的范畴，其核心目标并非构建或演化LLM智能体。因此，它严格地落在了您研究范围的之外。"
    },
    {
        "index": "#42",
        "title": "Informing Acquisition Functions via Foundation Models for Molecular Discovery",
        "link": "/arxiv/2512.13935",
        "arxiv_id": "2512.13935",
        "authors": "Qi Chen, Fabio Ramos, Alán Aspuru-Guzik, Florian Shkurti",
        "subjects": "Machine Learning, Artificial Intelligence, Quantitative Methods",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.612126",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文的本质是“非演化型应用”。** *   该论文的核心贡献是提出了一种**改进的贝叶斯优化方法**，用于加速分子发现。 *   在这个方法中，大型语言模型（LLM）和化学基础模型被用作**提供先验知识的工具**，以“为获取函数提供信息”。LLM在这里扮演的是一个强大的特征提取器或知识源的角色，而不是一个具有自主规划、工具使用或反思能力的智能体。 *   论文的目标是解决特定领域（分子发现）的优化问题，而不是构建、改进或演化一个通用的LLM智能体框架。这完全符合筛选标准中“非演化型应用”的排除规则：**将LLM作为工具应用到特定领域去解决该领域的问题**。 2.  **正面指标缺失 (第二步): 论文不包含您关注的核心Agentic概念。** *   尽管论文提到了LLM，但其核心范式是**贝叶斯优化**，而非`Agentic AI`或`Multi-Agent Systems`。 *   论文中没有涉及智能体的`Planning`（自主规划）、`Memory`（记忆机制）、`Tool Use`（智能体主动调用工具）、`Self-Reflection`（自我反思）或`Self-Evolving`（自我演化）等关键能力。 *   虽然论文使用了蒙特卡洛树搜索（MCTS），但MCTS在这里是作为BO算法的一部分，用于在分子空间中进行高效的**候选选择**，而不是作为一个智能体在复杂任务中进行多步行动规划。这与ReAct、ToT等Agentic框架中的规划有本质区别。 3.  **排除标准确认 (第三步):** 该论文不涉及安全、对齐或多模态等排除领域，但其核心内容已在第一步被排除。 4.  **特殊和模糊情况处理 (第四步):** *   **推理/规划:** 如上所述，MCTS的使用属于算法层面的候选搜索，而非智能体层面的自主行动规划。因此，应予以排除。 *   **自我演化的应用:** 论文的核心贡献是一种新的BO算法，而非一种新的“自我演化”机制。因此，不适用例外保留规则。 **最终决策 (第五步):** 综合以上分析，这篇论文的本质是利用LLM作为增强组件来改进一个特定领域的优化算法（贝叶斯优化）。它没有提出任何关于LLM智能体本身的新架构、新能力或演化机制。因此，它严格地属于“非演化型应用”，与您关于“LLM智能体及其演化”的核心研究目标不符。"
    },
    {
        "index": "#46",
        "title": "Capturing reduced-order quantum many-body dynamics out of equilibrium via neural ordinary differential equations",
        "link": "/arxiv/2512.13913",
        "arxiv_id": "2512.13913",
        "authors": "Patrick Egenlauf, Iva Březinová, Sabine Andergassen, Miriam Klopotek",
        "subjects": "Machine Learning, Statistical Mechanics, Quantum Physics",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.613171",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种使用神经常微分方程来模拟量子多体系统动力学的方法。这是一个典型的**非演化型应用**。它将一个机器学习模型（Neural ODE，并非LLM）作为工具，应用于解决计算物理学领域的特定问题（模拟量子系统）。论文的本质是物理建模，而非构建或演化智能体。 2.  **正面指标 (第二步):** 论文中完全没有出现任何与您研究焦点相关的正面指标。它不涉及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式，也没有讨论 `Planning`, `Tool Use`, `Memory`, `Collaboration` 等智能体能力。 3.  **排除标准 (第三步):** 虽然这篇论文不直接涉及安全对齐或多模态，但它落入了更根本的排除类别——即“将模型作为工具应用到特定领域”。 4.  **特殊和模糊情况 (第四步):** 该论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何“自我演化”机制。其研究的“演化”是指量子系统随时间的物理演化，而非智能体能力的自我完善和迭代。 **总结:** 该论文的研究对象是量子物理系统，研究工具是神经ODE，研究目标是实现更高效的物理模拟。这与您关于“LLM智能体及其演化”的研究课题在研究对象、核心贡献和技术路线上完全不同。因此，应果断排除。"
    },
    {
        "index": "#49",
        "title": "OPTIMA: Optimal One-shot Pruning for LLMs via Quadratic Programming Reconstruction",
        "link": "/arxiv/2512.13886",
        "arxiv_id": "2512.13886",
        "authors": "Mohammad Mozaffari, Samuel Kushnir, Maryam Mehri Dehnavi, Amir Yazdanbakhsh",
        "subjects": "Machine Learning, Artificial Intelligence, Performance",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.614060",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** 论文的核心贡献是提出了一种名为OPTIMA的**大模型剪枝方法**。它通过二次规划来优化剪枝后的权重重建过程，旨在实现更优的精度-效率权衡。这属于**模型优化和压缩**的范畴，是典型的**模型基础设施**研究。它关注的是如何让已有的LLM模型变得更小、更快，而不是如何构建一个具备自主规划、工具使用或演化能力的智能体。因此，根据第一步的排除标准“主要关注模型基础设施的研究”，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等任何关键词。其核心是 `Pruning` (剪枝)、`Quadratic Programming` (二次规划) 和 `Optimization` (优化)，这些都与智能体的构建和演化无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文完全符合“基础设施”这一排除标准。模型剪枝是部署和推理优化中的关键技术，它处理的是模型的静态结构和权重，而非智能体的动态行为、决策过程或演化机制。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何特殊或模糊的情况。它既不是关于智能体的推理/规划框架，也不是关于自我演化的应用。它纯粹是一项关于模型效率优化的工程技术研究。 **最终决策**: 综合以上分析，这篇论文的核心贡献是LLM的**工程优化技术**，而非**智能体架构或演化机制**。我的研究目标是“LLM智能体及其演化”，关注的是智能体的自主性、交互能力和自我完善能力。OPTIMA论文研究的是如何“压缩”模型，而我的研究关注的是如何“赋能”模型使其成为智能体。两者属于完全不同的研究方向。因此，该论文被排除。"
    },
    {
        "index": "#44",
        "title": "Sliding Window Recurrences for Sequence Models",
        "link": "/arxiv/2512.13921",
        "arxiv_id": "2512.13921",
        "authors": "Dragos Secrieru, Garyk Brixi, Yoshua Bengio, Taiji Suzuki, Michael Poli, Stefano Massaroli",
        "subjects": "Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.612633",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为“Sliding Window Recurrences (SWR)”的新算法和“Phalanx”层，其目的是通过优化计算以适应GPU内存层次结构，从而加速序列模型（特别是长上下文语言模型）的推理过程。论文明确提到了“GPU memory hierarchies”、“inter-warp communication”和“speedup”，这表明其研究焦点是**模型基础设施和性能优化**。根据筛选标准，主要关注模型基础设施、部署优化、硬件加速的研究应被**排除**。这篇论文的本质是提升底层模型的运行效率，而不是构建、改进或演化LLM智能体的方法论或框架。 2.  **第二步：正面指标** 论文的标题和摘要中完全没有出现任何与我核心关注点相关的正面指标。它没有提及 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 或 `Self-Reflection` 等任何关键词。这进一步确认了它与我的研究目标无关。 3.  **第三步：排除标准** 虽然这篇论文不涉及安全对齐或多模态等排除项，但它精准地命中了第一步中的“基础设施”排除项。 4.  **第四步：处理特殊和模糊情况** 这篇论文不涉及推理/规划或自我演化的应用，因此特殊规则不适用。它的工作是纯粹的计算优化，与智能体的认知架构或演化机制无关。 **最终决策**: 综合以上分析，该论文的核心贡献在于提升语言模型的底层计算效率，属于基础设施和性能优化范畴。它没有探讨LLM智能体的构建、多智能体交互或自我演化机制。因此，它完全不符合我关于“LLM智能体及其演化”的研究课题要求，应予以排除。"
    },
    {
        "index": "#38",
        "title": "EXAONE Path 2.5: Pathology Foundation Model with Multi-Omics Alignment",
        "link": "/arxiv/2512.14019",
        "arxiv_id": "2512.14019",
        "authors": "Juseung Yun, Sunwoo Yu, Sumin Ha, Jonghyun Kim, Janghyeon Lee, Jongseong Jang, Soonyoung Lee",
        "subjects": "Machine Learning, Quantitative Methods",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.611055",
        "filter_reason": "这篇论文不符合研究范围。 我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是构建一个名为 **EXAONE Path 2.5 的病理学基础模型**。其目标是整合组织学、基因组学等多模态生物数据，以创建一个更全面的肿瘤生物学表示，用于精准肿瘤学。这完全符合筛选标准中的 **排除规则 1：非演化型应用**。该论文是将一个先进的多模态模型架构应用到特定的生物医学领域（病理学），而不是提出一个通用的、可迁移的LLM智能体构建或演化方法。它的本质是领域应用，而非智能体框架研究。 2.  **第二步：正面指标** 论文摘要中完全没有出现任何与我的核心关注点相关的正面指标。例如，它没有提及 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving`, `Self-Reflection` 等任何智能体核心能力或范式。这进一步确认了它与我的研究目标无关。 3.  **第三步：排除标准** 论文明确涉及 **多模态与视觉**。其核心是处理组织学图像（WSI）和分子数据（基因组、转录组等）。根据排除标准，如果多模态是研究的核心（而不是作为智能体感知环境的工具），则应排除。在这篇论文中，多模态建模本身就是核心贡献，因此符合排除条件。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及智能体框架下的推理/规划，也没有提出任何自我演化机制。因此，特殊情况的规则不适用。 **最终决策**：综合以上分析，这篇论文虽然是一个高质量的前沿AI模型研究，但其焦点是**特定领域（病理学）的多模态基础模型**，而非**LLM智能体的构建、协作或演化**。它的贡献在于模型架构和生物医学应用，与我的研究课题“LLM智能体及其演化”的核心目标完全偏离。因此，应予以排除。"
    },
    {
        "index": "#45",
        "title": "Adaptive digital twins for predictive decision-making: Online Bayesian learning of transition dynamics",
        "link": "/arxiv/2512.13919",
        "arxiv_id": "2512.13919",
        "authors": "Eugenio Varetti, Matteo Torzoni, Marco Tezzele, Andrea Manzoni",
        "subjects": "Machine Learning, Numerical Analysis",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.612897",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个**自适应数字孪生框架**，用于土木工程领域（如桥梁维护）。该框架使用**动态贝叶斯网络**和**在线贝叶斯学习**来更新状态转移模型，并利用**强化学习**来计算动态策略。这完全符合筛选标准中的**排除项 1：非演化型应用**。论文将一种学习/优化方法（贝叶斯学习+RL）应用到一个特定领域（土木工程）的特定工具（数字孪生）上，以解决该领域的问题（结构健康监测）。它并非关于构建一个通用的、具有自主性的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中几乎不包含任何我关注的核心范式或智能体能力。 *   **核心范式**: 论文完全没有提及 `LLM-based Agents`, `Agentic AI`, `Multi-Agent Systems`。虽然提到了`Adaptive`，但其机制是贝叶斯更新，而非智能体的自我演化。 *   **智能体能力**: 论文没有涉及 `Tool Use`, `Memory`, `Self-Reflection` 等LLM智能体的核心能力。虽然提到了`Planning`（通过RL解决MDP），但这属于经典的决策和控制问题，与LLM智能体基于语言和工具的自主规划有本质区别。 *   **多智能体**: 完全不涉及。 *   **演化机制**: 论文的“自适应”和“在线学习”是针对模型参数的，是一种技术性的优化，而非智能体层面的自我完善、自我反思或迭代改进。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文中的规划是解决参数化马尔可夫决策过程（PMDP），这是强化学习领域的经典问题，不属于我关注的“LLM智能体如何在复杂任务中进行多步推理”的范畴。因此，应排除。 *   **自我演化的应用**: 尽管论文标题和摘要中出现了“Adaptive”（自适应），但这并非我研究焦点中的“Self-Evolving”（自我演化）。我的研究焦点是LLM智能体通过经验、反思等方式进行自我迭代。而本文的“自适应”是数字孪生模型参数的贝叶斯更新，主体是模型，不是智能体。因此，关于“自我演化的应用”的例外规则不适用。 **最终决策**: 这篇论文的核心是关于**数字孪生**和**强化学习**在特定工程领域的应用，其研究范式属于控制论、运筹学或特定领域的AI应用，与我的核心目标“**构建、改进或演化 LLM智能体**”完全无关。论文中完全没有提及LLM或任何与Agentic AI相关的核心概念。因此，这篇论文被明确排除。"
    },
    {
        "index": "#52",
        "title": "Dropout Neural Network Training Viewed from a Percolation Perspective",
        "link": "/arxiv/2512.13853",
        "arxiv_id": "2512.13853",
        "authors": "Finley Devlin, Jaron Sanders",
        "subjects": "Machine Learning, Statistical Mechanics, Probability, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.614893",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**从统计物理学的渗流理论视角，分析和解释神经网络训练中的Dropout技术**。这是一个关于基础模型训练方法的理论研究，旨在理解Dropout的内在机制及其对网络拓扑结构的影响。它完全没有涉及构建、改进或演化任何形式的智能体，无论是单智能体、多智能体还是自我演化智能体。因此，根据第一步的核心判断标准，该论文应被排除。 2.  **正面指标缺失 (第二步):** 论文的研究内容与我的核心关注点完全无关。摘要和标题中均未出现任何正面指标关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究课题不相关。 3.  **排除标准 (第三步):** 虽然该论文不涉及安全对齐或多模态等明确的排除领域，但其研究主题——神经网络训练的理论分析——本身就属于更基础的机器学习理论范畴，与我的“LLM智能体及其演化”这一前沿应用课题存在本质区别。 4.  **特殊与模糊情况 (第四步):** 该论文不涉及任何与智能体相关的推理、规划或自我演化机制。它研究的是模型训练过程中的一个数学/物理现象，而非智能体的行为或能力框架。 **总结:** 该论文是一篇关于深度学习基础训练技术的理论分析文章，其研究对象是Dropout和神经网络，而非LLM智能体。它的核心贡献在于理论解释，而非智能体的构建、改进或演化。因此，它完全不符合我的研究目标和筛选标准。"
    },
    {
        "index": "#50",
        "title": "Privacy-Enhancing Infant Cry Classification with Federated Transformers and Denoising Regularization",
        "link": "/arxiv/2512.13880",
        "arxiv_id": "2512.13880",
        "authors": "Geofrey Owino, Bernard Shibwabo",
        "subjects": "Machine Learning, Artificial Intelligence, Sound",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.614321",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文的本质是应用型研究，而非智能体构建。** 论文的核心贡献是提出一个用于“婴儿哭声分类”的端到端系统。该系统集成了去噪自编码器、Transformer和联邦学习技术，以解决特定领域（医疗/音频分析）中的隐私、噪声和效率问题。这完全符合筛选标准中“非演化型应用”的排除项，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。论文中的Transformer是作为分类模型使用，而非一个具备自主规划、工具使用或反思能力的智能体。 2.  **第二步：正面指标——论文完全不包含我的核心关注点。** 我仔细阅读了摘要，没有发现任何与我的研究焦点相关的正面指标关键词。论文没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Collaboration` 等任何核心概念。其研究重点是模型架构（Transformer）、训练方法（联邦学习）和部署优化，而非智能体的能力或框架。 3.  **第三步：排除标准——论文焦点在应用和基础设施，而非智能体。** 虽然论文标题提到了“Privacy-Enhancing”，但其主要贡献并非提出新的安全或对齐理论，而是应用联邦学习这一现有技术来实现隐私保护。这属于应用层面的优化，而非核心的安全与对齐研究。同时，论文对在NVIDIA Jetson Nano上的实时推理进行了优化，这触及了“基础设施”和“部署优化”的排除范畴。 4.  **第四步：特殊和模糊情况——不适用。** 论文不涉及智能体的推理或规划框架，也没有提出任何自我演化机制。因此，关于推理/规划和自我演化应用的例外规则不适用于此。 **最终决策**：综合以上分析，该论文是一篇典型的将深度学习模型应用于特定垂直领域（音频信号处理）的应用型研究。其核心贡献在于解决婴儿哭声分类的实际工程问题，而非构建、改进或演化LLM智能体。因此，它与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#55",
        "title": "The Double Life of Code World Models: Provably Unmasking Malicious Behavior Through Execution Traces",
        "link": "/arxiv/2512.13821",
        "arxiv_id": "2512.13821",
        "authors": "Subramanyam Sahoo, Jared Junkin",
        "subjects": "Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.615640",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个名为“Cross-Trace Verification Protocol (CTVP)”的AI控制框架，其目的是**验证和检测**代码生成模型中的恶意行为（如后门）。这是一个关于**AI安全与控制**的研究，而不是关于**构建、改进或演化LLM智能体**的研究。论文的本质是“防御”和“验证”，而非“构建”或“演化”。 2.  **排除标准 (第三步):** 这篇论文完全符合“安全与对齐”的排除标准。摘要中明确指出了其研究焦点： *   `malicious behavior` (恶意行为) *   `backdoor injection` (后门注入) *   `verifies untrusted code-generating models` (验证不可信的代码生成模型) *   `detects behavioral anomalies` (检测行为异常) *   `Adversarial Robustness Quotient (ARQ)` (对抗鲁棒性商) *   `AI control` (AI控制) 这些关键词清晰地表明，论文的主要贡献在于安全性、鲁棒性和对模型行为的控制，这与您研究的“Agentic AI的构建与演化”焦点有本质区别。 3.  **正面指标 (第二步):** 论文中完全没有出现您所关注的核心范式和能力指标，例如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Evolution`, `Multi-Agent`, `Collaboration` 等。这进一步证实了它与您的研究方向不相关。 综上所述，尽管该论文可能涉及LLM生成的代码，但其核心目标是解决安全问题，而非发展智能体的能力或演化机制。因此，它严格地属于“安全与对齐”的排除范畴，不符合您的研究目标。"
    },
    {
        "index": "#57",
        "title": "Constrained Policy Optimization via Sampling-Based Weight-Space Projection",
        "link": "/arxiv/2512.13788",
        "arxiv_id": "2512.13788",
        "authors": "Shengfan Cao, Francesco Borrelli",
        "subjects": "Machine Learning, Robotics",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.616221",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心贡献不符 (第一步)**: 论文的核心贡献是提出了一种名为SCPO的**安全策略优化算法**。其本质是在强化学习训练过程中，通过在模型的权重空间进行投影，来确保策略更新不会违反预定义的安全约束。这是一种关于**模型训练和优化**的方法论，而不是关于**构建、改进或演化LLM智能体**的框架。它关注的是“如何安全地训练一个策略”，而不是“智能体应该具备什么样的能力或结构”。 2.  **触发了明确的排除标准 (第三步)**: 这是最关键的排除依据。根据您的筛选标准，只要论文的主要贡献是关于 `Safety` (安全)，就应一律排除。这篇论文的标题、摘要和核心方法都紧紧围绕“Safety-critical learning”（安全关键学习）、“safety constraints”（安全约束）和“safe-by-induction guarantee”（归纳安全保证）。其全部创新点都旨在解决安全问题，而非提升智能体的自主性、协作性或演化能力。 3.  **缺乏正面指标 (第二步)**: 论文摘要中完全没有出现您关注的核心范式和能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这表明该研究与您的研究焦点（单智能体、多智能体、自我演化）没有直接关联。 4.  **不属于特殊情况的例外 (第四步)**: 该论文不涉及推理/规划框架，也不涉及自我演化机制。它虽然被应用在控制任务上，但其核心是安全优化，而非自我演化的应用，因此不符合任何例外保留的条件。 **总结**: 该论文属于**强化学习中的安全与对齐**研究领域，其目标是保证策略在训练过程中的安全性。这与您关注的**LLM智能体的架构、能力与演化**是两个不同的研究方向。因此，该论文应被明确排除。"
    },
    {
        "index": "#56",
        "title": "EEG-D3: A Solution to the Hidden Overfitting Problem of Deep Learning Models",
        "link": "/arxiv/2512.13806",
        "arxiv_id": "2512.13806",
        "authors": "Siegfried Ludwig, Stylianos Bakas, Konstantinos Barmpas, Georgios Zoumpourlis, Dimitrios A. Adamos, Nikolaos Laskaris, Yannis Panagakis, Stefanos Zafeiriou",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Human-Computer Interaction",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.615974",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为EEG-D3的深度学习方法，用于解决在解码脑电图（EEG）信号时存在的“隐藏过拟合”问题。这是一个典型的**非演化型应用**。它将深度学习模型作为一种工具，应用于神经科学和生物医学工程这一特定领域，以解决该领域的数据分析问题。论文的本质是改进一个特定任务（EEG解码）的模型性能和泛化能力，而不是构建、改进或演化LLM智能体本身。 2.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现任何与您研究焦点相关的核心范式或能力关键词。例如，它没有提及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这表明其研究内容与Agentic AI方向无关。 3.  **符合排除标准 (第三步):** 论文的研究领域是生物信号处理（EEG），这属于应用科学范畴。虽然论文中提到了“interpretability”（可解释性），但这是其模型设计的一个特性（通过独立子网络实现），用以辅助神经科学研究，而不是论文的核心贡献。论文的主要目标是解决过拟合问题，而非研究AI安全或对齐。 4.  **不涉及特殊情况 (第四步):** 论文不涉及智能体的规划或推理框架，更没有提出任何“自我演化”机制。它提出的是一种新的模型训练范式（D3），与智能体通过经验进行自我完善和迭代的概念完全不同。 **总结:** 该论文是一篇优秀的神经科学/生物医学工程领域的应用研究，但其研究对象是EEG信号解码模型，而非LLM智能体。它的贡献在于解决特定领域的机器学习问题（过拟合），与您关于“LLM智能体及其演化”的核心研究目标（构建、改进、演化智能体框架）存在根本性的偏离。因此，应明确排除。"
    },
    {
        "index": "#53",
        "title": "Topologically-Stabilized Graph Neural Networks: Empirical Robustness Across Domains",
        "link": "/arxiv/2512.13852",
        "arxiv_id": "2512.13852",
        "authors": "Jelena Losic",
        "subjects": "Machine Learning, Social and Information Networks",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.615137",
        "filter_reason": "这篇论文的核心贡献是提出一种新的图神经网络（GNN）框架，通过整合持久同调特征和稳定性正则化，来提升GNN对结构扰动的鲁棒性。 根据我的筛选标准，判断过程如下： 1.  **第一步：核心判断**——这篇论文的本质是关于图表示学习模型的改进，而非构建、改进或演化LLM智能体。论文的研究对象是GNN，一种处理图数据的神经网络模型，其目标是提升模型的鲁棒性。论文中完全没有提及LLM、智能体规划、工具使用、多智能体协作或自我演化等概念。因此，它直接触发了“非演化型应用”和“非Agentic的推理”的排除标准，因为它既不是关于智能体，也不是关于LLM的。 2.  **第二步：正面指标**——在第二步的正面指标检查中，论文内容与`Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`等核心范式完全无关，也未涉及`Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration`等任何智能体能力或多智能体交互的关键词。 3.  **第三步：排除标准**——虽然论文没有直接涉及安全与对齐或多模态等排除项，但这并不改变其研究方向与您的课题完全不符的事实。 4.  **第四步：特殊和模糊情况**——该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此特殊情况不适用。 **最终决策**：这篇论文属于图机器学习领域，研究的是如何提升GNN模型的鲁棒性。它与您的研究课题“LLM智能体及其演化”在研究对象、核心贡献和研究范式上均无交集。因此，这篇论文不符合您的要求，应被排除。"
    },
    {
        "index": "#54",
        "title": "Explainable reinforcement learning from human feedback to improve alignment",
        "link": "/arxiv/2512.13837",
        "arxiv_id": "2512.13837",
        "authors": "Shicheng Liu, Siyuan Xu, Wenjie Qiu, Hangfan Zhang, Minghui Zhu",
        "subjects": "Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.615398",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非构建、改进或演化LLM智能体。其本质是提出一种用于改进**强化学习人类反馈（RLHF）**的方法。具体来说，它包含一个**事后解释方法**和一个**反学习方法**，旨在通过识别并“反学习”导致不良输出的训练数据来提升模型的对齐性。这是一种模型层面的修正技术，而非一个智能体在运行时进行自主规划、工具使用或自我演化的框架。因此，它不属于“构建LLM智能体、多智能体系统或自我演化的方法论或新框架”的范畴。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文的标题和摘要明确指出了其核心贡献属于两个被明确排除的研究焦点： *   **可解释性:** 标题中的 \"Explainable\" 和摘要中的 \"post-hoc explanation method\" 直接表明，论文的核心是提供一种解释模型行为的方法。 *   **对齐:** 标题中的 \"improve alignment\" 和摘要中反复提及的 \"RLHF for alignment\" 明确指出，论文的主要目标是解决模型对齐问题。 根据您的筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Explainability (XAI)`, `Alignment` ... 一律排除。” 该论文完全符合此排除条件。 3.  **正面指标 (第二步) 与 特殊情况 (第四步):** 论文中没有出现任何与您核心关注点（如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等）相关的正面指标。它提出的“改进”机制（反学习）与智能体在任务执行中的“自我修正”或“自我反思”有本质区别，前者是静态的、离线的模型修正，后者是动态的、在线的智能体行为。因此，它也不符合“自我演化的应用”这一例外情况。 **总结:** 尽管这篇论文研究的是如何改进LLM，但其研究路径和最终落脚点是**模型对齐**和**可解释性**，而非您所关注的**Agentic AI**的架构、能力或演化机制。因此，它严格地超出了您设定的研究范围。"
    },
    {
        "index": "#60",
        "title": "MIDUS: Memory-Infused Depth Up-Scaling",
        "link": "/arxiv/2512.13751",
        "arxiv_id": "2512.13751",
        "authors": "Taero Kim, Hoyoon Byun, Youngjun Choi, Sungrae Park, Kyungwoo Song",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.617023",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为MIDUS（Memory-Infused Depth Up-Scaling）的**模型扩展方法**。其本质是改进大型语言模型的**底层架构**，通过用“逐头记忆层”替换复制块中的前馈网络（FFN），来更高效地增加模型深度和容量。这属于**模型基础设施和架构优化**的范畴，而非构建、改进或演化LLM智能体的方法论。根据第一步的排除标准第3条（基础设施），应予以排除。 2.  **正面指标分析 (第二步):** 论文标题和摘要中出现了“Memory”一词，这看似与您的关注点相关。然而，此处的“Memory”是一种**架构层面的记忆机制**，用于在模型前向传播过程中存储和检索信息以增强模型表达能力，类似于一种可训练的、稀疏的键值存储。这与您研究焦点中的**智能体记忆**有本质区别，后者指的是智能体存储和利用过往经验、任务历史、反思结果来指导未来规划和行动的能力。论文并未涉及任何`Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`或`Self-Evolving`等核心范式或能力。 3.  **排除标准确认 (第三步):** 该论文的研究内容完全符合“基础设施”这一排除类别。它关注的是如何更高效地“Scale”模型，而不是如何让模型具备“Agentic”的能力。 4.  **特殊与模糊情况处理 (第四步):** 论文不涉及推理/规划框架，也未提出任何自我演化机制。它提出的MIDUS是一种静态的架构改进，而不是一个动态的、基于经验进行自我完善的迭代过程。 **最终决策 (第五步):** 综合以上分析，这篇论文的核心贡献在于**优化LLM的架构和扩展效率**，是一项扎实的基础模型研究。然而，它完全没有触及您研究课题的核心——即智能体的自主性、规划、工具使用、协作或自我演化。因此，尽管它使用了“Memory”这个词，但其研究目标与“LLM智能体及其演化”相去甚远，应被排除。"
    },
    {
        "index": "#58",
        "title": "Enhancing Semi-Supervised Multi-View Graph Convolutional Networks via Supervised Contrastive Learning and Self-Training",
        "link": "/arxiv/2512.13770",
        "arxiv_id": "2512.13770",
        "authors": "Huaiyuan Xiao, Fadi Dornaika, Jingjun Bi",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.616481",
        "filter_reason": "这篇论文不符合研究范围。 我的核心判断依据如下： 1.  **核心贡献不匹配 (第一步核心判断)**: 论文的核心贡献是提出了一种名为MV-SupGCN的新型半监督图卷积网络（GCN）模型。其研究目标是改进多视图图数据的特征表示学习，通过结合监督对比学习和自训练（伪标签）等技术来提升模型性能。我的研究焦点是“LLM智能体及其演化”，核心在于构建、改进或演化具有自主规划、工具使用、记忆或自我演化能力的智能体。而这篇论文的研究对象是图神经网络（GCN），一种用于处理图结构数据的模型，与LLM智能体完全无关。它属于图机器学习领域，而非Agentic AI领域。 2.  **缺乏核心关注点 (第二步正面指标)**: 论文中未出现任何与研究焦点相关的核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Planning`, `Tool Use`, `Self-Reflection`, `Self-Evolving` 等。其技术术语，如 `Graph Convolutional Network`, `Contrastive Learning`, `Pseudo-labeling`，均属于传统机器学习和图神经网络的范畴。 3.  **对关键术语的误解澄清 (第四步特殊情况)**: 论文中提到的“Self-Training”（自训练）是半监督学习中的一种标准技术，指利用模型自身预测的伪标签来扩充训练数据，这与智能体通过经验、反思进行自我完善和迭代的“自我演化”机制有本质区别。前者是一种模型训练策略，后者是智能体的核心能力框架。 综上所述，该论文研究的是如何改进一种特定的神经网络模型（GCN）来解决多视图学习问题，而不是如何构建或演化LLM智能体。它完全偏离了我的研究课题，因此根据筛选标准的第一步（核心判断），应予以排除。"
    },
    {
        "index": "#59",
        "title": "Network-Wide Traffic Volume Estimation from Speed Profiles using a Spatio-Temporal Graph Neural Network with Directed Spatial Attention",
        "link": "/arxiv/2512.13758",
        "arxiv_id": "2512.13758",
        "authors": "Léo Hein, Giovanni de Nunzio, Giovanni Chierchia, Aurélie Pirayre, Laurent Najman",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.616751",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 论文的核心贡献是提出了一种名为“混合定向注意力时空图神经网络（HDA-STGNN）”的深度学习框架，用于解决**交通工程领域**的特定问题：**全路网交通流量估算**。 - 该研究本质上是将一种先进的图神经网络（GNN）模型作为工具，应用于交通数据分析。这完全符合**排除标准中的“非演化型应用”**。论文的重点是解决交通问题，而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的关键词。例如：`Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。 - 论文讨论的是`Spatio-Temporal Graph Neural Network`（时空图神经网络）和`Directed Spatial Attention`（定向空间注意力），这些是模型架构的技术细节，与智能体的核心能力无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不涉及“安全与对齐”或“多模态与视觉”等排除项，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它是一个纯粹的领域应用研究。 **最终决策**： 该论文的核心是利用GNN解决交通流量预测问题，属于典型的**将深度学习模型应用于特定垂直领域的研究**。它没有涉及LLM，也没有构建任何形式的智能体框架，更没有探讨智能体的规划、协作或自我演化机制。因此，它与您关于“LLM智能体及其演化”的研究课题完全不相关，应予以排除。"
    },
    {
        "index": "#61",
        "title": "Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis",
        "link": "/arxiv/2512.13749",
        "arxiv_id": "2512.13749",
        "authors": "Joyjit Roy, Samaresh Kumar Singh",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.617276",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**对现有嵌入表示方法在特定任务（金融新闻情感分析）上的比较评估**。它没有提出任何新的LLM智能体构建方法、多智能体协作框架或自我演化机制。论文的本质是将已有的NLP技术作为工具，应用于金融领域解决一个具体问题。这完全符合**排除标准1a：非演化型应用**。 2.  **正面指标缺失 (第二步):** 论文中完全没有出现我关注的核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。这进一步确认了它与我的研究焦点无关。 3.  **研究焦点不符:** 我的研究目标是“构建、改进或演化LLM智能体”，关注的是智能体本身的能力和架构。而该论文的研究目标是“评估不同嵌入技术在数据稀缺场景下的情感分类效果”，关注的是特定NLP任务的技术选型和性能表现。论文中提到的“每周情感聚合和叙事摘要”只是其评估方法的一个应用示例，并非论文的核心方法论贡献。 综上所述，该论文是一篇典型的应用型研究，它评估了现有工具在特定领域的表现，但没有对LLM智能体本身的构建、改进或演化做出任何核心贡献。因此，它被严格排除在我的研究范围之外。"
    },
    {
        "index": "#65",
        "title": "Plug-and-Play Parameter-Efficient Tuning of Embeddings for Federated Recommendation",
        "link": "/arxiv/2512.13734",
        "arxiv_id": "2512.13734",
        "authors": "Haochen Yuan, Yang Zhang, Xiang He, Quan Z. Sheng, Zhongjie Wang",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-14",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.618365",
        "filter_reason": "这篇论文不符合研究范围，应予以排除。我的判断依据如下： 1.  **核心判断（第一步）**: 该论文的核心贡献是提出一种用于联邦推荐系统的参数高效微调（PEFT）框架，以减少通信开销。这完全符合第一步筛选标准中的“非演化型应用”排除规则。论文的研究目标是解决特定领域（推荐系统）中的技术瓶颈（通信效率），而不是构建、改进或演化LLM智能体。它没有提出任何关于智能体架构、能力或演化机制的新方法论。 2.  **正面指标缺失（第二步）**: 论文中完全没有提及任何与研究课题相关的核心范式或能力。例如，`Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等关键词和概念在摘要中均未出现。其核心是 `Federated Recommendation` 和 `Parameter-Efficient Fine-Tuning (PEFT)`，这与智能体研究无关。 3.  **排除标准（第三步）**: 虽然该论文不直接涉及安全对齐或多模态等排除项，但第一步的排除已经足够明确且具有最高优先级。 4.  **特殊情况（第四步）**: 该论文不涉及任何关于智能体推理/规划或自我演化的特殊情况。它所讨论的“通信”是联邦学习中模型参数的网络传输，而非智能体之间的语义通信。 综上所述，该论文是一篇典型的应用领域优化研究，其本质是改进推荐系统的训练效率，而非探索LLM智能体的内在机制或演化。因此，它与“LLM智能体及其演化”的核心研究目标完全不符。"
    },
    {
        "index": "#51",
        "title": "Measuring Uncertainty Calibration",
        "link": "/arxiv/2512.13872",
        "arxiv_id": "2512.13872",
        "authors": "Kamil Ciosek, Nicolò Felicioni, Sina Ghiassian, Juan Elenter Litwin, Francesco Tonolini, David Gustaffson, Eva Garcia Martin, Carmen Barcena Gonzales, Raphaëlle Bertrand-Lalo",
        "subjects": "Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.614623",
        "filter_reason": "根据筛选标准，这篇论文不符合研究范围。 1.  **核心判断 (第一步):** 这篇论文的核心贡献是关于**二元分类器的校准误差的测量和边界估计方法**。它研究的是模型评估中的一个基础问题——校准，即模型预测置信度与其实际准确度的一致性。这属于模型性能度量和优化的范畴，而非智能体的自主行为、规划、工具使用或多智能体交互等Agentic AI的核心议题。因此，根据第一步的排除规则，它属于“非Agentic的推理”或更基础的理论研究，应被排除。 2.  **正面指标 (第二步):** 论文的标题和摘要中完全没有出现第二步所列的任何正面指标，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步表明它与研究焦点无关。 3.  **排除标准 (第三步):** 虽然模型校准与智能体的可靠性有一定关联，但该论文的主要贡献并非关于 `Safety` 或 `Alignment`，而是关于一个更底层的统计度量方法。因此，它不直接命中第三步的排除标准，但第一步的判断已经足够。 4.  **特殊和模糊情况 (第四步):** 该论文不涉及智能体的规划或推理框架，也不涉及自我演化机制。它只是改进了对一个基础模型属性（校准）的测量方法，因此不适用任何例外保留规则。 **最终决策 (第五步):** 综合以上分析，该论文是一篇关于机器学习模型评估理论的论文，其核心贡献与研究课题 \"LLM智能体及其演化\" 的目标严重偏离。它没有构建、改进或演化任何形式的智能体，因此应被排除。"
    },
    {
        "index": "#64",
        "title": "DARTs: A Dual-Path Robust Framework for Anomaly Detection in High-Dimensional Multivariate Time Series",
        "link": "/arxiv/2512.13735",
        "arxiv_id": "2512.13735",
        "authors": "Xuechun Liu, Heli Sun, Xuecheng Wu, Ruichen Cao, Yunyun Shi, Dingkang Yang, Haoran Li",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-14",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.618093",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出一个名为 DARTs 的**双路径鲁棒框架**，用于解决**高维多变量时间序列异常检测**这一特定领域的问题。其本质是一个创新的机器学习模型，而非构建、改进或演化LLM智能体的方法论。根据筛选标准，这属于典型的“非演化型应用”，即为了解决特定领域问题（工业控制系统的异常检测）而设计的模型，因此应被**排除**。 2.  **第二步：正面指标** 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 或 `Self-Improvement`。这进一步确认了该论文与您的研究方向无关。 3.  **第三步：排除标准** 虽然论文没有直接触及“安全与对齐”或“多模态与视觉”等排除关键词，但这并不改变其本质。它的核心是时间序列分析，这是一个与Agentic AI平行的不同研究领域。 4.  **第四步：处理特殊和模糊情况** 论文不涉及任何与智能体相关的推理或规划。它所描述的“学习表示”和“捕捉模式”是指模型从数据中学习统计特征，而不是智能体为了达成目标而进行的自主规划和行动。同时，该框架不具备任何自我演化的能力，它是一个静态的、训练后不再改变的模型。 **最终决策**：综合以上分析，该论文的研究焦点是**时间序列异常检测算法**，而非**LLM智能体**。尽管它可能在其自身领域是一项优秀的工作，但其核心贡献与您“构建、改进或演化LLM智能体”的核心目标完全不符。因此，最终判断为 **False**，应予以排除。"
    },
    {
        "index": "#69",
        "title": "CurvaDion: Curvature-Adaptive Distributed Orthonormalization",
        "link": "/arxiv/2512.13728",
        "arxiv_id": "2512.13728",
        "authors": "Bhavesh Kumar, Roger Jin, Jeffrey Quesnelle",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-13",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.619446",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出了一种名为“CurvaDion”的新算法，用于解决大规模语言模型**分布式训练**过程中的**梯度同步通信瓶颈**问题。其核心目标是减少GPU之间的通信开销，提高训练效率。这完全属于筛选标准中明确排除的“基础设施”类别，即“主要关注模型基础设施、部署优化、硬件加速的研究”。论文并未涉及任何关于LLM智能体的设计、行为、能力或演化机制。 2.  **第二步：正面指标——完全缺失。** 论文的标题和摘要中，完全没有出现任何与我研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Self-Correction`、`Collaboration` 等。论文讨论的“communication”是GPU节点间的梯度通信，而非智能体间的协作通信。 3.  **第三步：排除标准——不适用，但进一步确认了其非智能体属性。** 该论文不涉及安全、对齐或多模态等排除领域，但这并不改变其属于基础设施优化的本质。 **总结：** 尽管这篇论文对于高效训练LLM本身可能是一项有价值的工作，但它的研究焦点是**训练过程的工程优化**，而不是**智能体的架构、能力或演化**。我的研究目标是筛选那些核心贡献在于“构建、改进或演化LLM智能体”的论文，而CurvaDion论文的核心是让训练过程更快、更省钱，这与智能体如何规划、如何使用工具、如何协作或如何自我完善毫无关系。因此，根据第一步的核心判断标准，该论文应被明确排除。"
    },
    {
        "index": "#62",
        "title": "The Laminar Flow Hypothesis: Detecting Jailbreaks via Semantic Turbulence in Large Language Models",
        "link": "/arxiv/2512.13741",
        "arxiv_id": "2512.13741",
        "authors": "Md. Hasib Ur Rahman",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-14",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.617515",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为“层流假说”的理论和一种名为“语义湍流”的零样本检测指标，用于**检测和防御针对LLM的越狱攻击**。其本质是模型安全与对齐领域的研究，而非构建、改进或演化LLM智能体的方法论。它没有提出任何新的智能体框架、能力或演化机制。 2.  **排除标准 (第三步):** 这是最关键的排除依据。该论文完全聚焦于 `Safety` (安全)、`Security` (安全) 和 `Alignment` (对齐)。摘要中明确指出其目标是“securing them against adversarial 'jailbreaking' attacks”（保护它们免受对抗性“越狱”攻击），其核心贡献是“a lightweight, real-time jailbreak detector”（一个轻量级的、实时的越狱检测器）和“a non-invasive diagnostic tool for categorizing the underlying safety architecture”（一个用于分类底层安全架构的非侵入式诊断工具）。根据我的筛选标准，凡是主要贡献关于安全、对齐的论文，一律排除。 3.  **正面指标缺失 (第二步):** 论文中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving` 等。虽然提到了“reasoning process”（推理过程），但其上下文是分析模型内部表示的动态以进行安全检测，而不是研究智能体如何进行自主规划和多步推理。 4.  **特殊情况处理 (第四步):** 论文不涉及任何特殊情况。它既不是关于智能体的规划，也不是关于自我演化的应用。它是一项纯粹的模型安全研究。 综上所述，尽管这篇论文在LLM安全领域可能具有重要的学术价值，但其研究焦点与我的“LLM智能体及其演化”课题完全不同。因此，根据严格的筛选标准，最终决策为排除。"
    },
    {
        "index": "#70",
        "title": "RAST-MoE-RL: A Regime-Aware Spatio-Temporal MoE Framework for Deep Reinforcement Learning in Ride-Hailing",
        "link": "/arxiv/2512.13727",
        "arxiv_id": "2512.13727",
        "authors": "Yuhan Tang, Kangxin Cui, Jung Ho Park, Yibo Zhao, Xuan Jiang, Haoze He, Dingyi Zhuang, Shenhao Wang, Jiangbo Yu, Haris Koutsopoulos, Jinhua Zhao",
        "subjects": "Machine Learning",
        "date": "2025-12-13",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.619771",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是提出一个名为 **RAST-MoE-RL** 的深度强化学习框架，用于解决网约车平台中的供需匹配问题。其本质是**将一个先进的强化学习模型（结合了MoE和时空编码）作为工具，应用到特定领域（交通/物流）去优化一个具体的业务指标（等待时间、系统效率）**。这完全符合筛选标准中的**排除规则1：非演化型应用**。论文的贡献在于强化学习模型架构的创新，而非构建或演化一个具有通用能力的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我的核心关注点。摘要中未提及 `LLM-based Agents`, `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式。虽然强化学习涉及决策，但这里的决策是MDP框架下的策略学习，而非智能体自主的 `Planning`, `Tool Use`, `Memory` 或 `Self-Reflection`。论文也未涉及多智能体间的 `Collaboration` 或 `Communication`。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不属于安全、对齐或多模态等排除类别，但它在第一步已经被明确排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“规划”是强化学习策略在特定环境下的决策过程，它不涉及智能体如何分解任务、制定步骤或使用工具的通用规划框架。因此，这属于被排除的范畴。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。模型的改进是通过标准的强化学习训练过程完成的，而不是智能体在部署后通过经验或反思进行自我完善。 **最终决策**: 综合以上分析，这篇论文是一篇典型的**强化学习应用研究**。它的核心贡献在于为网约车场景设计了一个更高效的模型架构（RAST-MoE），而不是研究如何构建、改进或演化一个LLM智能体。因此，它与我的研究课题“LLM智能体及其演化”无关，应予以排除。"
    },
    {
        "index": "#66",
        "title": "Low-Rank Compression of Language Models via Differentiable Rank Selection",
        "link": "/arxiv/2512.13733",
        "arxiv_id": "2512.13733",
        "authors": "Sidhant Sundrani, Francesco Tudisco, Pasquale Minervini",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-14",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.618630",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是模型基础设施，而非智能体构建。** 该论文的核心贡献是提出了一种名为“LLRC”的新方法，用于对大语言模型进行低秩压缩。其研究焦点在于如何更有效地选择每一层的秩，以在压缩率和模型性能之间取得更好的平衡。这完全属于**模型基础设施**和**部署优化**的范畴，即如何让一个已有的LLM变得更小、更快。它没有涉及任何关于构建、改进或演化LLM智能体的方法论或新框架。根据筛选标准，这类研究应被明确排除。 2.  **缺乏正面指标 (第二步): 未包含任何智能体核心关注点。** 通读标题和摘要，论文完全没有提及任何与您研究焦点相关的关键词或概念。例如，它没有讨论 `Agentic AI`、`Tool Use`、`Planning`、`Memory`、`Self-Reflection`、`Multi-Agent`、`Collaboration` 或 `Self-Evolving`。其技术核心是数学上的“低秩分解”和“可微分秩选择”，与智能体的行为、能力或演化机制无关。 3.  **对应用领域的误解澄清 (第四步):** 论文在常识推理和问答任务上评估了其压缩效果。但这并不意味着论文是关于“推理”的。根据筛选标准，这属于**将LLM作为工具应用到特定领域去解决该领域的问题**（在这里，领域是模型评估，任务是推理和QA）。论文的核心是压缩技术，而不是一种新的推理或智能体框架。它只是用这些任务来证明压缩后的模型“依然好用”，这与研究智能体如何进行规划和推理有本质区别。 **总结:** 该论文是一篇典型的模型优化/压缩研究，其目标是提升LLM的工程效率和部署可行性。它完全偏离了您关于“LLM智能体及其演化”的核心研究目标，即探索智能体的自主性、协作性和自我完善能力。因此，根据筛选标准，应果断排除。"
    },
    {
        "index": "#63",
        "title": "TF-MCL: Time-frequency Fusion and Multi-domain Cross-Loss for Self-supervised Depression Detection",
        "link": "/arxiv/2512.13736",
        "arxiv_id": "2512.13736",
        "authors": "Li-Xuan Zhao, Chen-Yang Xu, Wen-Qiang Li, Bo Wang, Rong-Xing Wei, Qing-Hao Menga",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-14",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.617803",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出了一种名为 TF-MCL 的新模型，用于通过脑电图（EEG）信号进行自监督的抑郁症检测。其技术重点是“时频融合”和“多域交叉损失”，旨在改进对EEG信号的特征提取和表示学习能力。 - **是否符合要求**: 这篇论文的本质是**将一种新的机器学习模型（自监督学习）应用于特定领域（医疗健康，抑郁症检测）**。它完全没有涉及构建、改进或演化LLM智能体。因此，根据筛选标准中的“排除规则1：非演化型应用”，这篇论文应被直接排除。它的目标是解决特定领域的分类问题，而不是研究智能体本身的架构或能力。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我研究焦点相关的关键词或概念，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了它与我的研究课题无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不涉及安全对齐或多模态等排除项，但它已经触发了第一步中更根本的排除标准——“非演化型应用”。 4.  **第四步：处理特殊和模糊情况** - 论文中提到的“自监督学习”是一种模型训练范式，与我所关注的“自我演化”有本质区别。自我演化指的是智能体在部署后通过与环境的交互、反思或经验积累来持续迭代和自我完善。而本文的自监督学习只是在训练阶段利用无标签数据来预训练模型，模型本身不具备在任务中自我演化的能力。因此，这不属于“自我演化的应用”的例外情况。 **最终决策**: 该论文的研究方向是生物医学信号处理与机器学习，其核心贡献是针对特定数据类型（EEG）和特定任务（抑郁症检测）的模型创新。这与我的研究目标——“LLM智能体及其演化”——在研究对象、核心贡献和技术路线上完全不同。因此，这篇论文被排除。"
    },
    {
        "index": "#67",
        "title": "PIS: A Generalized Physical Inversion Solver for Arbitrary Sparse Observations via Set-Conditioned Diffusion",
        "link": "/arxiv/2512.13732",
        "arxiv_id": "2512.13732",
        "authors": "Weijie Yang, Xun Zhang",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-14",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.618878",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个名为“物理反演求解器（PIS）”的深度学习框架，用于解决物理领域的特定问题——从稀疏观测中反演物理参数。这完全符合筛选标准中的“非演化型应用”排除项。论文的本质是将一个先进的AI模型（基于扩散模型）作为工具，应用于流体力学、地震反演等具体科学领域，而不是研究如何构建、改进或演化LLM智能体本身。 2.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现我核心关注点的任何关键词或范式。它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，它也未涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory` 或 `Self-Reflection`。PIS模型本身是一个端到端的求解器，不具备自主性、规划或工具使用等智能体特征。 3.  **触及排除标准 (第三步):** 论文的核心技术是“扩散框架”。根据筛选标准，主要关注 `Diffusion Models` 的研究应被排除，除非它们被用作智能体感知环境的工具。在这篇论文中，扩散模型是核心贡献本身，而不是一个智能体框架的组件，因此符合排除条件。 4.  **特殊情况不适用 (第四步):** 论文虽然解决的是复杂的推理问题（物理反演），但它不属于“智能体如何进行规划”的范畴，而是设计一个专门的模型来直接解决该问题。它也没有提出任何“自我演化”机制，因此相关的例外规则不适用。 **总结:** 该论文是一篇优秀的AI for Science应用研究，但其焦点在于解决物理逆问题，而非Agentic AI的研究。它的核心贡献是应用层面的方法论，而非智能体架构或演化机制的突破，因此与我的研究目标“LLM智能体及其演化”不相关。"
    },
    {
        "index": "#68",
        "title": "Composite Classifier-Free Guidance for Multi-Modal Conditioning in Wind Dynamics Super-Resolution",
        "link": "/arxiv/2512.13729",
        "arxiv_id": "2512.13729",
        "authors": "Jacob Schnell, Aditya Makkar, Gunadi Gani, Aniket Srinivasan Ashok, Darren Lo, Mike Optis, Alexander Wong, Yuhao Chen",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-13",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.619192",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一种名为 \"Composite Classifier-Free Guidance (CCFG)\" 的新技术，用于改进扩散模型在处理多模态条件输入时的性能，并将其应用于风力动力学超分辨率这一特定领域。这完全符合第一步中的排除标准 **“非演化型应用”**。该研究是将一种深度学习模型（扩散模型）作为工具来解决气象学领域的问题，而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **正面指标缺失 (第二步):** 论文的摘要和标题中完全没有出现任何与我研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 或 `Self-Reflection` 等。这表明其研究范式与我的目标完全不同。 3.  **符合排除标准 (第三步):** 论文的核心研究对象是 **扩散模型**。根据第三步的排除标准，`Diffusion Models` 属于“多模态与视觉”范畴，除非它们被用作智能体感知环境的工具。在这篇论文中，扩散模型本身就是研究的核心，而不是智能体框架中的一个组件。因此，它符合排除条件。 综上所述，该论文是一篇典型的将生成式AI技术应用于特定科学计算领域的研究，其本质是模型改进和领域应用，与“LLM智能体及其演化”这一核心课题无关。因此，最终决策为排除。"
    },
    {
        "index": "#75",
        "title": "Predictive Modeling of Flood-Prone Areas Using SAR and Environmental Variables",
        "link": "/arxiv/2512.13710",
        "arxiv_id": "2512.13710",
        "authors": "Edwin Oluoch Awino, Denis Machanda",
        "subjects": "Machine Learning",
        "date": "2025-12-06",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.621017",
        "filter_reason": "这篇论文完全不符合我的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”。** 论文的核心贡献是提出一种结合合成孔径雷达（SAR）数据与环境变量，利用传统机器学习模型（如随机森林、支持向量机）来预测洪水易发区的方法。这是一个典型的将机器学习技术应用于特定领域（地理学、灾害管理）来解决实际问题的案例。它完全属于筛选标准中应被排除的“非演化型应用”，因为它没有构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——完全不包含我的核心关注点。** 论文摘要中完全没有出现任何与我研究焦点相关的关键词或范式。它没有提及 `LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。其讨论的“模型”是指随机森林等传统监督分类器，而非具备规划、记忆、工具使用或自我反思能力的智能体。 3.  **第三步和第四步：不适用。** 由于论文在第一步就已经被明确排除，后续关于安全对齐、多模态或特殊情况的判断已无必要。论文既不涉及LLM，也不涉及智能体框架，因此这些标准不适用。 **总结：** 该论文的研究对象是洪水预测模型，而非LLM智能体。其方法论是应用传统机器学习进行地理空间分析，这与我关于“LLM智能体及其演化”的核心目标——即探索智能体本身的构建、协作与演化机制——毫无关联。因此，该论文应被坚决排除。"
    },
    {
        "index": "#73",
        "title": "Prediction of Respiratory Syncytial Virus-Associated Hospitalizations Using Machine Learning Models Based on Environmental Data",
        "link": "/arxiv/2512.13712",
        "arxiv_id": "2512.13712",
        "authors": "Eric Guo",
        "subjects": "Machine Learning, Applications, Methodology",
        "date": "2025-12-06",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.620541",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”** 论文的核心贡献是开发一个基于环境数据（废水、气象、空气质量）的机器学习框架，用于预测呼吸道合胞病毒（RSV）的住院率。这完全符合筛选标准中的“非演化型应用”排除项。论文将机器学习模型（CART, Random Forest, Boosting）作为工具，应用于一个特定的领域（公共卫生/流行病学）来解决该领域的预测问题。它没有构建、改进或演化任何形式的LLM智能体。 2.  **第二步：缺乏任何正面指标** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步证明了该论文与您的研究方向无关。 3.  **根本性脱节：未使用LLM** 最关键的一点是，该论文的研究基础是传统的机器学习模型（随机森林、Boosting等），而非大语言模型（LLM）。您的研究课题是“LLM智能体及其演化”，一篇完全不涉及LLM的论文，从根本上就不可能符合要求。 **总结**: 该论文是一篇典型的应用型研究，其目标是解决公共卫生领域的预测问题。它的核心贡献在于应用现有机器学习技术，而非提出新的智能体方法论或演化机制。因此，它完全不符合您关于“构建、改进或演化LLM智能体”的核心研究目标。"
    },
    {
        "index": "#71",
        "title": "Time-Constrained Recommendations: Reinforcement Learning Strategies for E-Commerce",
        "link": "/arxiv/2512.13726",
        "arxiv_id": "2512.13726",
        "authors": "Sayak Chakrabarty, Souradip Pal",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-13",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.620021",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断（第一步）：** 这篇论文的本质是**非演化型应用**。其核心贡献是提出一种强化学习策略，用于解决电子商务领域中的一个特定问题——在用户时间预算有限的情况下进行商品推荐。论文的目标是优化推荐系统的性能指标（如用户参与度），而不是构建、改进或演化一个具有自主性的LLM智能体。它将强化学习作为一种工具应用于特定领域，完全符合第一步排除标准中的第一条。 2.  **核心关注点缺失（第二步）：** 论文中完全没有提及我的核心关注点。 *   **技术基础：** 论文的核心技术是强化学习（RL）和马尔可夫决策过程（MDP），而非LLM。标题和摘要中均未出现 \"LLM\"、\"Agent\" 或相关词汇。 *   **智能体能力：** 论文不涉及智能体的规划、工具使用、记忆或自我反思等Agentic核心能力。它所描述的“智能体”（即推荐系统）是一个根据策略输出推荐列表的模型，不具备自主性和复杂交互能力。 *   **多智能体与自我演化：** 论文研究的是单一推荐系统，不涉及多智能体间的协作或通信。同时，其学习过程是标准的强化学习训练，而非智能体通过经验、反思进行自我完善和迭代的“自我演化”机制。 3.  **研究焦点不符（第三步）：** 虽然论文没有触及安全、对齐或多模态等排除领域，但其核心问题——推荐系统优化——与我的研究焦点“LLM智能体及其演化”相去甚远。 **总结：** 该论文是一篇典型的将机器学习算法（强化学习）应用于垂直领域（电子商务推荐）的应用型研究。它的贡献在于解决了一个具体的业务问题，而非提出关于Agentic AI的基础性、框架性或演化性的新方法。因此，它不符合我的筛选要求。"
    },
    {
        "index": "#72",
        "title": "Federated Few-Shot Learning for Epileptic Seizure Detection Under Privacy Constraints",
        "link": "/arxiv/2512.13717",
        "arxiv_id": "2512.13717",
        "authors": "Ekaterina Sysoykova, Bernhard Anzengruber-Tanase, Michael Haslgrubler, Philipp Seidl, Alois Ferscha",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.620292",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是“非演化型应用”** 论文的核心贡献是提出了一种“联邦少-shot学习（FFSL）框架”，用于解决在隐私约束下的癫痫检测问题。其本质是将一种机器学习训练范式（联邦学习 + 少样本学习）应用到一个特定的垂直领域（医疗健康）来解决该领域的数据孤岛和个性化问题。论文中使用的模型是“预训练的生物信号转换器（BIOT）”，并未涉及LLM。这完全符合您在第一步中定义的排除标准：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗...）”。本文虽然不是使用LLM，但其逻辑完全一致：将一个模型作为工具应用于医疗领域，而非构建或演化智能体本身。 2.  **缺乏正面指标 (第二步)** 论文摘要中完全没有出现您关注的核心范式和能力关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection`, `Collaboration` 等。其技术焦点在于 `Federated Learning` 和 `Few-Shot Learning`，这些是分布式机器学习和高效学习的技术，与您研究的智能体核心能力无关。 3.  **特殊情况的澄清 (第四步)** *   **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。 *   **自我演化的应用**: 论文中的“个性化”是通过“少样本学习”这一外部训练过程实现的，即用少量新数据微调模型。这并非智能体通过经验、反思或环境反馈进行的“自我完善和迭代”。它不具备自主性，因此不符合“自我演化”的定义，也不适用于该例外情况。 *   **多智能体**: 论文中的“联邦学习”涉及多个“站点”或“客户端”，但它们是数据持有方和计算节点，并非具有自主目标、进行协作、通信或博弈的智能体。这是一种分布式计算架构，而不是一个多智能体社会。 **总结**: 该论文的研究焦点是**分布式机器学习在医疗诊断中的应用**，其核心贡献在于解决数据隐私和个性化建模的工程问题。这与您关于“LLM智能体及其演化”的研究课题，即关注智能体的内在能力构建、交互机制和自主演化，存在根本性的偏差。因此，该论文应被明确排除。"
    },
    {
        "index": "#79",
        "title": "Physics-Guided Deep Learning for Heat Pump Stress Detection: A Comprehensive Analysis on When2Heat Dataset",
        "link": "/arxiv/2512.13696",
        "arxiv_id": "2512.13696",
        "authors": "Md Shahabub Alam, Md Asifuzzaman Jishan, Ayan Kumar Ghosh",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Neural and Evolutionary Computing",
        "date": "2025-11-23",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.622062",
        "filter_reason": "该论文不符合我的研究范围，应予以排除。判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出一种“物理引导的深度神经网络（PG-DNN）”方法，用于解决热泵应力检测这一特定工程领域的问题。这完全符合筛选标准第一步中的**排除规则1：非演化型应用**。论文将深度学习模型作为工具，应用于特定领域（能源工程），其目标是解决该领域的具体问题（应力分类），而不是构建、改进或演化一个通用的LLM智能体框架。 2.  **正面指标缺失（第二步）：** 论文中完全没有出现任何与我的核心关注点相关的关键词或概念，例如 `Agentic AI`、`LLM-based Agents`、`Multi-Agent`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Collaboration` 等。这进一步确认了它与我的研究焦点无关。 3.  **研究焦点不符：** 论文的研究对象是深度神经网络在物理系统建模中的应用，属于传统的应用型AI研究。我的研究焦点是“LLM智能体及其演化”，关注的是智能体的自主性、规划能力、工具使用、多智能体交互以及自我演化机制。该论文的研究内容与这些方向没有任何交集。 综上所述，该论文是一篇典型的将AI技术应用于特定垂直领域的论文，其本质是应用研究而非智能体框架或演化机制的创新。因此，它不符合我的筛选要求。"
    },
    {
        "index": "#74",
        "title": "Delete and Retain: Efficient Unlearning for Document Classification",
        "link": "/arxiv/2512.13711",
        "arxiv_id": "2512.13711",
        "authors": "Aadya Goel, Mayuri Sridhar",
        "subjects": "Machine Learning",
        "date": "2025-12-06",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.620780",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“Hessian Reassignment”的机器遗忘方法，用于高效地从文档分类模型中移除特定类别数据的影响。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** 论文的核心是“Machine unlearning”（机器遗忘），这是一种模型安全和隐私保护技术，旨在移除模型对特定数据的记忆。它研究的对象是“document classification models”（文档分类模型），而非具有自主规划、工具使用或反思能力的LLM智能体。因此，这篇论文的本质不属于构建、改进或演化LLM智能体，而应归入**非演化型应用**的范畴，因为它提出了一种技术（遗忘）并将其应用于特定任务（文档分类）。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与我的研究焦点相关的正面指标，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。其关键词是 `unlearning`, `document classification`, `Hessian`, `membership-inference`，这些都与智能体的核心能力无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** **这是最关键的排除依据。** 该论文的主要贡献完全属于“安全与对齐”的排除范畴。“机器遗忘”技术本身就是为了解决数据隐私（如GDPR的“被遗忘权”）、模型安全（如防止成员推理攻击）等问题而提出的。论文明确提到其目标是“lowering membership-inference advantage”，这直接证明了其研究核心是模型安全与隐私，而非智能体能力的构建或演化。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及推理/规划或自我演化的特殊情况。它研究的是“遗忘”，这与“自我演化”或“自我完善”在概念上是相反的。 **最终决策：** 综合以上分析，这篇论文的核心贡献是关于模型安全和隐私的“机器遗忘”技术，而非关于LLM智能体的构建、协作或演化。它完全符合“安全与对齐”这一明确的排除标准。因此，该论文与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#81",
        "title": "LLmFPCA-detect: LLM-powered Multivariate Functional PCA for Anomaly Detection in Sparse Longitudinal Texts",
        "link": "/arxiv/2512.14604",
        "arxiv_id": "2512.14604",
        "authors": "Prasanjit Dubey, Aritra Guha, Zhengyi Zhou, Qiong Wu, Xiaoming Huo, Paromita Dubey",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.622602",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是“非演化型应用”** 论文的核心贡献是提出一个名为 `LLmFPCA-detect` 的**数据分析框架**，用于在稀疏纵向文本数据中进行异常检测。它将LLM用作一个**工具**（具体来说是文本嵌入器和动态关键词分析器），并结合函数主成分分析（FPCA）这一统计方法来完成特定领域的任务。这完全符合筛选标准中的第一条排除规则：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题...则排除”。该论文的研究焦点是数据分析和模式识别，而非构建或演化智能体本身。 2.  **缺乏核心关注点（第二步）** 论文中完全没有涉及您研究的核心范式和能力。摘要和标题中均未出现 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何与智能体相关的关键词。虽然LLM被用作“工具”，但论文探讨的是研究人员如何利用这个工具，而不是智能体如何自主地规划和使用工具。 3.  **不符合特殊情况的例外（第四步）** 该论文是一个应用型研究，但它并未提出任何新的“自我演化”机制。`LLmFPCA-detect` 框架本身是静态的，它不会通过经验、反思或环境反馈进行自我完善和迭代。因此，它不适用于“自我演化的应用”这一例外保留规则。 **总结**: 该论文的本质是利用LLM的能力来增强传统的数据分析流程，属于交叉学科的应用研究。其核心贡献在于**方法论创新**（LLM + FPCA），而非**智能体创新**。它没有构建一个具有自主性、规划能力或演化能力的LLM智能体，因此与您关于“LLM智能体及其演化”的核心研究目标不符。"
    },
    {
        "index": "#76",
        "title": "Variational Physics-Informed Ansatz for Reconstructing Hidden Interaction Networks from Steady States",
        "link": "/arxiv/2512.13708",
        "arxiv_id": "2512.13708",
        "authors": "Kaiming Luo",
        "subjects": "Machine Learning",
        "date": "2025-12-06",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.621245",
        "filter_reason": "这篇论文不符合研究范围。 我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为“变分物理信息拟设”（VPIA）的新方法，用于从稳态数据中重建复杂动态系统的隐藏交互网络。这完全符合筛选标准第一步中的“非演化型应用”排除规则。该论文的研究焦点是物理系统或复杂系统的网络结构推断问题，属于物理学、应用数学或系统科学领域。它没有涉及任何关于LLM智能体的构建、改进或演化。 2.  **第二步：正面指标** 论文中完全没有出现任何与研究课题相关的正面指标关键词。例如，`Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等核心概念均未在摘要中提及。 3.  **第三步：排除标准** 虽然该论文没有触发“安全与对齐”或“多模态与视觉”等具体的排除关键词，但第一步的判断已经足够明确，它属于更根本的“非演化型应用”类别。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划，也没有提出任何“自我演化”机制。因此，特殊情况的例外规则不适用。 **最终决策**： 该论文的本质是开发一种用于物理系统建模的工具，其目标是推断系统内部的交互网络。这与“构建、改进或演化LLM智能体”的核心目标完全无关。因此，应予以排除。"
    },
    {
        "index": "#86",
        "title": "Pattern Recognition of Aluminium Arbitrage in Global Trade Data",
        "link": "/arxiv/2512.14410",
        "arxiv_id": "2512.14410",
        "authors": "Muhammad Sukri Bin Ramli",
        "subjects": "General Economics, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.623892",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 该论文的核心贡献是提出一个**无监督机器学习框架**，用于在全球贸易数据中识别和分类铝套利模式。其研究目标是解决金融/贸易领域的特定问题（贸易异常检测和反洗钱）。 - **判断**: 这完全符合**排除标准中的“非演化型应用”**。论文将机器学习（而非LLM智能体）作为工具，应用于特定领域（全球贸易、金融），其贡献在于该领域的发现（如“Hardware Masking”现象），而非构建或改进智能体本身。论文中完全没有提及LLM或智能体架构。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现任何您关注的核心范式、智能体能力、多智能体或演化机制相关的关键词。例如，`Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent` 等均未在摘要中出现。这进一步确认了其与研究主题的无关性。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文明确提到使用 **SHAP (Shapley Additive Explanations)** 来验证结果。SHAP是**可解释性AI (Explainability, XAI)** 的代表性技术。根据您的排除标准，只要论文的主要贡献涉及 `Interpretability` 或 `Explainability (XAI)`，就应排除。虽然本文的主要贡献不是XAI，但使用XAI作为核心验证方法，表明其研究范式与您的“LLM智能体及其演化”焦点存在显著偏差。 4.  **第四步：处理特殊和模糊情况** - 本文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它是一个纯粹的领域应用研究。 **最终决策**: 综合以上分析，这篇论文是一篇典型的**领域应用型研究**。它利用传统的机器学习模型（Isolation Forests, Deep Autoencoders）解决金融贸易领域的具体问题，其核心贡献在于经济学和贸易模式的发现，而非人工智能智能体技术的创新。因此，它完全不符合您关于“构建、改进或演化LLM智能体”的核心研究目标，应予以排除。"
    },
    {
        "index": "#85",
        "title": "Hybrid Ensemble Method for Detecting Cyber-Attacks in Water Distribution Systems Using the BATADAL Dataset",
        "link": "/arxiv/2512.14422",
        "arxiv_id": "2512.14422",
        "authors": "Waqas Ahmed",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.623638",
        "filter_reason": "这篇论文完全不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出一个**混合集成学习模型**，用于在**水分配系统**中检测网络攻击。它结合了随机森林、XGBoost和LSTM等传统机器学习和深度学习模型，通过集成学习来提升检测性能。 - **判断**: 这完全符合**排除标准1：非演化型应用**。论文将已有的机器学习模型作为工具，应用到一个特定领域（工业控制系统的网络安全）去解决该领域的问题。它没有构建、改进或演化任何形式的LLM智能体。事实上，论文中完全没有提及LLM。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - **关键词扫描**: 论文标题和摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。 - **结论**: 该论文不包含任何您所关注的核心研究点。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - **安全与对齐**: 论文的研究主题是“网络攻击检测”，这明确属于**`Security`（安全）**范畴。根据您的筛选标准，只要论文的主要贡献是关于安全的，就应一律排除。 - **结论**: 该论文触发了明确的排除标准。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及智能体的推理/规划，也没有提出任何自我演化机制，因此特殊情况规则不适用。 **最终决策**: 综合以上分析，这篇论文是一篇典型的**应用型机器学习研究**，其目标是解决特定领域的安全问题。它既不涉及LLM，也不涉及智能体的构建、协作或演化。因此，它与您关于“LLM智能体及其演化”的研究课题完全无关，应被排除。"
    },
    {
        "index": "#78",
        "title": "Scaling and Transferability of Annealing Strategies in Large Language Model Training",
        "link": "/arxiv/2512.13705",
        "arxiv_id": "2512.13705",
        "authors": "Siqi Wang, Zhengyu Chen, Teng Xiao, Zheqi Lv, Jinluan Yang, Xunliang Cai, Jingang Wang, Xiaomeng Li",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-05",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.621795",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种用于优化大型语言模型训练过程中“学习率退火策略”的通用预测框架。其研究焦点在于**模型训练的基础设施和优化**，具体是如何更高效地调整超参数（学习率）来训练出更好的基础模型。这完全符合筛选标准中的排除项：“排除主要关注模型基础设施、部署优化的研究”。论文并未涉及构建、改进或演化LLM智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。其关键词是 `Learning rate scheduling`, `annealing strategies`, `training dynamics`, `hyperparameter searches`，这些都指向模型训练工程，而非智能体研究。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不直接关于安全对齐或多模态，但它触及了另一个更根本的排除项：**基础设施**。优化学习率调度是训练高效能LLM的基础工程问题，与智能体的行为、能力或演化机制无关。 4.  **第四步：处理特殊和模糊情况** 这篇论文的情况并不模糊。它不属于“推理/规划”的范畴，因为它研究的是训练过程中的数学优化，而非智能体在任务执行中的决策过程。它也不属于“自我演化的应用”，因为它提出的框架是用于优化训练，而不是让智能体在运行时进行自我完善。 **最终决策**: 综合以上分析，该论文的本质是关于**LLM训练工程**的研究，旨在通过优化学习率调度来提升训练效率和模型性能。它完全没有触及您研究课题的核心——即LLM智能体的构建、协作与演化。因此，这篇论文与您的研究范围“LLM智能体及其演化”无关，应予以排除。"
    },
    {
        "index": "#87",
        "title": "From STLS to Projection-based Dictionary Selection in Sparse Regression for System Identification",
        "link": "/arxiv/2512.14404",
        "arxiv_id": "2512.14404",
        "authors": "Hangjun Cho, Fabio V. G. Amaral, Andrei A. Klishin, Cassio M. Oishi, Steven L. Brunton",
        "subjects": "Machine Learning, Machine Learning, Optimization and Control, Computational Physics",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.624187",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出一种改进的稀疏回归算法（score-guided library selection），并将其应用于系统识别领域，特别是用于从数据中发现动态系统的控制方程（如SINDy算法）。论文的本质是**应用数学/控制理论**的研究，专注于优化算法（STLS）和模型选择方法，以更准确地识别物理系统。它完全没有涉及构建、改进或演化任何形式的LLM智能体。因此，根据筛选标准，这属于典型的“非演化型应用”，应直接排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心概念。其关键词是 `Sparse Regression`, `STLS`, `Dictionary Selection`, `System Identification`，这些都属于信号处理、统计学习和控制理论的范畴。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不涉及安全对齐或多模态，但它已经在前两步被明确排除，因为它根本不属于Agentic AI的研究领域。 4.  **第四步：处理特殊和模糊情况** 此处没有模糊情况。论文中提到的“Sequential Threshold Least Squares (STLS)”虽然是一个迭代过程，但它是一个用于解决数学优化问题的确定性算法，而非智能体的自主规划或推理过程。它不属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。 **最终决策**: 该论文的核心是提出一种用于系统识别的数学优化方法，与“LLM智能体及其演化”这一课题完全无关。它属于应被排除的“非演化型应用”类别。因此，最终判断为 **False**。"
    },
    {
        "index": "#88",
        "title": "Towards Transferable Defense Against Malicious Image Edits",
        "link": "/arxiv/2512.14341",
        "arxiv_id": "2512.14341",
        "authors": "Jie Zhang, Shuai Dong, Shiguang Shan, Xilin Chen",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.624469",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为TDAE的**防御机制**，用于保护基于扩散模型的图像编辑系统免受恶意攻击。其本质是**计算机视觉与安全领域**的研究，而非构建、改进或演化LLM智能体。它属于“非演化型应用”，即将一个优化框架（虽然涉及文本）应用于特定领域（图像安全）解决该领域的问题。 2.  **排除标准 (第三步):** 该论文明确命中了两个核心的排除类别： *   **安全与对齐:** 论文的标题、摘要和核心贡献都围绕着“Defense”（防御）、“Malicious”（恶意）、“adversarial”（对抗性）等关键词，其研究目标完全属于`Security`和`Safety`范畴。根据筛选标准，只要主要贡献是关于安全，就应一律排除。 *   **多模态与视觉:** 论文的研究对象是“diffusion-based image editing systems”（基于扩散的图像编辑系统），核心是处理“Image Edits”（图像编辑）。这完全属于`Vision`和`Diffusion Models`的研究范畴。虽然它使用了文本，但视觉部分是研究的核心，而不是作为智能体感知环境的工具。 3.  **对模糊点的澄清 (第四步):** 论文中提到的“iterative adversarial updates”（迭代对抗更新）和“refines text embeddings”（优化文本嵌入）可能会让人联想到“自我演化”或“自我反思”。然而，这里的“迭代”和“优化”是**对抗性训练算法的一部分**，其目的是为了找到更具鲁棒性的图像扰动和文本嵌入，以抵御攻击。这并不涉及智能体基于经验、反思或环境反馈进行**自主的、目标导向的自我完善**。它缺乏智能体的自主性、规划和工具使用等核心特征。 综上所述，该论文是一篇关于图像安全的计算机视觉研究，与您关注的“LLM智能体及其演化”的核心目标——即智能体的构建、协作与自我演化机制——完全无关。因此，应予以排除。"
    },
    {
        "index": "#91",
        "title": "Continual Learning at the Edge: An Agnostic IIoT Architecture",
        "link": "/arxiv/2512.14311",
        "arxiv_id": "2512.14311",
        "authors": "Pablo García-Santaclara, Bruno Fernández-Castro, Rebeca P. Díaz-Redondo, Carlos Calvo-Moa, Henar Mariño-Bodelón",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.625314",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个应用于工业物联网（IIoT）边缘计算场景的**增量学习架构**，其目的是解决制造业中的实时质量控制问题。这完全符合**排除标准 1 (非演化型应用)**。论文并非构建或改进一个具有自主性的LLM智能体，而是将一个已有的机器学习范式（增量学习/持续学习）作为一个工具，应用到特定的工程领域（边缘计算、工业质量控制）来解决该领域的具体问题。此外，论文标题和摘要中明确提到的“Architecture”（架构）和“Edge Computing”（边缘计算）也使其触及了**排除标准 3 (基础设施)**的范畴。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您关注的核心范式或能力关键词。例如，它没有提及 `LLM-based Agents`, `Multi-Agent Systems`, `Planning`, `Tool Use`, `Self-Reflection` 等。虽然提到了 `Continual Learning`（持续学习），但这是在传统机器学习模型训练的语境下，指模型在新数据上持续更新以避免灾难性遗忘，**并非指一个智能体通过经验、反思或环境反馈进行自我完善和迭代的“自我演化”机制**。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文不涉及安全与对齐或多模态等排除项，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及此内容。 - **自我演化的应用**: 这是唯一可能引起混淆的点。根据筛选规则，如果论文的核心是提出一种**新的“自我演化”机制**，即使应用在特定领域也应保留。然而，本论文的核心是**应用一个已有的“持续学习”方法**到一个新的领域（边缘IIoT），它本身并未提出任何新的、与智能体相关的自我演化机制。因此，这个例外情况不适用。 **最终决策**: 该论文的研究焦点是边缘计算架构和工业物联网应用，属于典型的应用型研究。其核心贡献与“构建、改进或演化LLM智能体”这一目标完全无关。因此，应将其排除。"
    },
    {
        "index": "#89",
        "title": "Dual Attention Guided Defense Against Malicious Edits",
        "link": "/arxiv/2512.14333",
        "arxiv_id": "2512.14333",
        "authors": "Jie Zhang, Shuai Dong, Shiguang Shan, Xilin Chen",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.624750",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文的本质是安全防御，而非智能体构建。** 论文的核心贡献是提出一种名为“DANP”的免疫化方法，用于防御针对文本到图像扩散模型的恶意编辑。其本质是**模型安全与对抗性防御**研究，旨在通过添加扰动来保护图像内容。这完全不属于“构建、改进或演化LLM智能体”的范畴，而应归类于**非演化型应用**，即将一种技术（扰动）应用于特定领域（图像安全）以解决该领域的问题。 2.  **第三步：排除标准——论文明确命中两个核心排除类别。** *   **安全与对齐:** 论文的研究动机是“ethical challenges”（伦理挑战），目标是“mitigate this risk”（降低风险），提出的方法是“defense”（防御）和“immunization method”（免疫化方法）。这完全符合“安全与对齐”的排除标准。 *   **多模态与视觉:** 论文的研究对象是“text-to-image diffusion models”（文本到图像扩散模型），核心任务是“image editing”（图像编辑）。这属于“多模态与视觉”中的“Diffusion Models”和“Vision-Language”范畴。根据规则，除非扩散模型被用作智能体感知环境的工具，否则应排除。在此论文中，扩散模型本身就是研究的核心，而非工具。 3.  **第二步：正面指标——论文完全不包含任何与智能体相关的正面指标。** 论文的摘要和标题中，完全没有出现任何与您研究焦点相关的关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Collaboration`, `Self-Evolving` 等。这进一步证实了它与您的研究方向无关。 综上所述，该论文是一篇典型的模型安全与防御研究，聚焦于多模态扩散模型，与您关于“LLM智能体及其演化”的核心目标（单智能体、多智能体、自我演化）完全偏离。因此，应果断排除。"
    },
    {
        "index": "#96",
        "title": "Weighted Conformal Prediction Provides Adaptive and Valid Mask-Conditional Coverage for General Missing Data Mechanisms",
        "link": "/arxiv/2512.14221",
        "arxiv_id": "2512.14221",
        "authors": "Jiarong Fan, Juhyun Park. Thi Phuong Thuy Vo, Nicolas Brunel",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.626631",
        "filter_reason": "这篇论文不符合您的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步):** 该论文的本质是统计学和机器学习理论的研究，而非构建、改进或演化LLM智能体。其核心贡献是提出一种名为“加权保形预测”的统计学方法，用于在数据存在缺失值时，为预测提供更有效（更窄且保证覆盖率）的不确定性量化区间。这完全属于“非演化型应用”的排除范畴，因为它提出的是一个通用的数据处理和预测框架，而不是一个具有自主性、规划或工具使用能力的智能体框架。 2.  **正面指标 (第二步):** 在对论文标题和摘要的审查中，完全没有出现任何与您核心关注点相关的正面指标。例如，`Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等关键词均未出现。这表明论文的研究内容与您的焦点方向没有交集。 3.  **排除标准与特殊情况 (第三步 & 第四步):** *   该论文不涉及安全、对齐或多模态等排除标准，但其核心内容已经使其在第一步就被排除。 *   在特殊情况处理中，论文讨论的是统计预测区间的有效性，不涉及智能体的自主规划或在复杂任务中的多步推理框架，因此不符合“推理/规划”的保留条件。它也没有提出任何“自我演化”机制。 **结论:** 该论文的研究焦点是统计推断方法，旨在改进预测区间的质量，与您设定的LLM智能体、多智能体系统或自我演化机制的研究目标存在根本性的偏离。因此，它不符合您的筛选要求。"
    },
    {
        "index": "#103",
        "title": "On the Hardness of Conditional Independence Testing In Practice",
        "link": "/arxiv/2512.14000",
        "arxiv_id": "2512.14000",
        "authors": "Zheng He, Roman Pogodin, Yazhe Li, Namrata Deka, Arthur Gretton, Danica J. Sutherland",
        "subjects": "Machine Learning, Machine Learning, Methodology",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.628613",
        "filter_reason": "解析失败"
    },
    {
        "index": "#92",
        "title": "Improving the Accuracy of Amortized Model Comparison with Self-Consistency",
        "link": "/arxiv/2512.14308",
        "arxiv_id": "2512.14308",
        "authors": "Šimon Kucharský, Aayush Mishra, Daniel Habermann, Stefan T. Radev, Paul-Christian Bürkner",
        "subjects": "Machine Learning, Machine Learning, Computation",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.625590",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是关于**“摊销贝叶斯模型比较”**，这是一种统计学和机器学习理论领域的方法。它提出使用“自洽性”技术来提高神经代理模型在模型误设情况下的鲁棒性。这篇论文的本质是**改进一种统计推断方法**，而不是构建、改进或演化LLM智能体。它完全不属于“构建LLM智能体、多智能体系统或自我演化的方法论或新框架”的范畴。因此，根据第一步的核心判断，应直接**排除**。 2.  **第二步：正面指标** 论文中完全没有出现您所关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准** 虽然论文没有直接触及安全、对齐或多模态等排除标准，但第一步的判断已经足够有力，无需依赖此步。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“推理”是指统计模型中的贝叶斯推断，而非智能体在复杂任务中的自主规划和多步决策。它不涉及任何智能体框架。 - **自我演化**: 这是最容易混淆的一点。论文标题中的“Self-Consistency”（自洽性）是一个统计学概念，指模型预测的内部一致性，是一种用于**训练更鲁棒模型的技巧**。它与您研究焦点中的“Self-Evolving”（自我演化）——即智能体通过经验、反思或环境反馈进行**自我完善和迭代**——有本质区别。前者是一种静态的训练方法，后者是一种动态的、智能体层面的学习和成长机制。因此，该论文不符合“自我演化”的例外情况。 **最终决策**: 该论文是一篇纯粹的统计学/机器学习理论论文，研究的是如何改进贝叶斯模型比较的准确性和鲁棒性。其核心贡献、方法论和关键词均与“LLM智能体及其演化”这一研究课题无关。因此，应予以排除。"
    },
    {
        "index": "#82",
        "title": "Sound and Music Biases in Deep Music Transcription Models: A Systematic Analysis",
        "link": "/arxiv/2512.14602",
        "arxiv_id": "2512.14602",
        "authors": "Lukáš Samuel Marták, Patricia Hu, Gerhard Widmer",
        "subjects": "Sound, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.622856",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 该论文的本质属于 **“非演化型应用”**。论文的核心工作是分析和评估现有的深度音乐转录（AMT）模型在不同音乐数据分布下的性能偏差。它引入了一个新的数据集（MDS corpus）来系统性地测试这些模型的泛化能力。这属于对一个特定领域（音乐信息检索）的模型进行性能分析和评估，而不是构建、改进或演化LLM智能体。论文的研究对象是AMT模型，而非Agentic AI。 2.  **正面指标缺失 (第二步):** 论文的研究内容完全不涉及我的核心关注点。摘要和标题中没有任何与 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving` 相关的关键词。其研究焦点是模型的 `Bias`（偏见）和 `Generalization`（泛化能力），而非智能体的 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Reflection`（自我反思）等能力。 3.  **排除标准确认 (第三步):** 虽然论文不直接涉及安全与对齐或多模态视觉，但它已经触发了第一步中最根本的排除标准——非演化型应用。因此，无需进一步考虑其他排除项。 4.  **特殊情况不适用 (第四步):** 论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何形式的“自我演化”机制。它仅仅是对现有模型在特定任务上的表现进行了一次深入的实证分析。 **总结:** 该论文的核心贡献在于对深度音乐转录模型进行系统性的偏见分析，属于模型评估和应用研究的范畴。它没有提出任何关于LLM智能体的构建、交互或演化的新方法或框架，因此与我的研究课题“LLM智能体及其演化”完全不相关。"
    },
    {
        "index": "#90",
        "title": "Semantic Mismatch and Perceptual Degradation: A New Perspective on Image Editing Immunity",
        "link": "/arxiv/2512.14320",
        "arxiv_id": "2512.14320",
        "authors": "Shuai Dong, Jie Zhang, Guoying Zhao, Shiguang Shan, Xilin Chen",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.625042",
        "filter_reason": "这篇论文不符合研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 该论文的核心贡献是提出一种名为SIFM的方法，用于通过添加不可感知的扰动来保护图像，使其免受基于扩散模型的恶意编辑。同时，它还提出了一个新的评估指标ISR。这完全属于“非演化型应用”的排除范畴。论文并非构建或演化LLM智能体，而是将扩散模型（以及作为评估工具的MLLM）应用于图像安全这一特定领域，以解决该领域的问题。 2.  **排除标准 (第三步):** 这是最关键的排除依据。 *   **安全与对齐:** 论文的主要研究目标是“safeguarding visual content against malicious manipulation”（保障视觉内容免受恶意操作），这直接命中了“安全与对齐”的排除标准。其核心是关于图像的`Security`（安全）和`Immunization`（免疫）。 *   **多模态与视觉:** 论文的核心研究对象是“Image Editing”（图像编辑）和“diffusion models”（扩散模型），属于“多模态与视觉”的排除标准。尽管论文中提到了使用MLLMs进行评估，但MLLMs在此处仅作为评估工具，并非研究的核心。研究的核心是视觉内容的安全防护，而非智能体本身。 3.  **正面指标 (第二步):** 论文中未出现任何与研究焦点相关的正面指标，如`Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving`等。其方法论和框架与LLM智能体的构建、协作或演化无关。 综上所述，该论文的研究焦点是图像安全与防御，与“LLM智能体及其演化”的核心目标——构建、改进或演化智能体——完全偏离。因此，最终判断为排除。"
    },
    {
        "index": "#93",
        "title": "TUN: Detecting Significant Points in Persistence Diagrams with Deep Learning",
        "link": "/arxiv/2512.14274",
        "arxiv_id": "2512.14274",
        "authors": "Yu Chen, Hongwei Lin",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning, Algebraic Topology",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.625847",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 TUN 的深度学习网络，用于解决拓扑数据分析（TDA）领域的一个特定问题：自动识别持久性图中的显著点。这是一个典型的**非演化型应用**。它将深度学习模型作为一种工具，应用于一个特定的科学领域（拓扑学），以解决该领域的数据解释问题。论文的本质是构建一个分类器，而不是构建、改进或演化一个具有自主性的LLM智能体。因此，根据第一步的排除规则，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现我的核心关注点。它没有提及 `LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。虽然提到了 `self-attention`，但这只是Transformer架构中的一个标准技术模块，用于特征融合，与智能体的 `Self-Reflection`（自我反思）或 `Self-Correction`（自我修正）能力完全无关。论文也不涉及 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Collaboration`（协作）等任何智能体核心能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文没有直接命中安全、对齐或多模态等排除关键词，但第一步的判断已经足够明确。该论文的研究焦点是拓扑数据分析，这与我的“LLM智能体及其演化”课题相去甚远。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理、规划或自我演化机制。它是一个静态的、用于分类任务的深度学习模型，因此不适用任何例外保留规则。 **最终决策**：综合以上分析，该论文的核心工作是应用深度学习技术解决拓扑学领域的特定问题，其贡献在于一个新颖的模型架构（TUN），而非关于LLM智能体的构建、协作或演化机制。因此，它完全不符合我的研究目标和筛选标准。"
    },
    {
        "index": "#102",
        "title": "Physics-Informed Machine Learning for Two-Phase Moving-Interface and Stefan Problems",
        "link": "/arxiv/2512.14010",
        "arxiv_id": "2512.14010",
        "authors": "Che-Chia Chang, Te-Sheng Lin, Ming-Chih Lai",
        "subjects": "Computational Physics, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.628326",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是提出了一种“物理信息神经网络框架”，用于解决物理学中的“斯蒂芬问题”。这是一个典型的将机器学习技术（具体是神经网络）应用于特定科学计算领域（计算物理）的研究。 - **匹配筛选标准**: 该研究完全符合**排除标准1：非演化型应用**。它将神经网络作为一种新的数值求解工具，去解决一个经典的物理问题（相变过程中的移动边界问题）。论文的重点在于如何设计网络结构和损失函数来更好地拟合物理规律，而不是构建一个具有自主性、规划能力或演化能力的智能体。 2.  **第二步：正面指标——是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。其讨论的核心是“物理信息”、“移动界面”、“温度场”、“神经网络”，这些都是科学机器学习领域的术语，而非智能体研究的术语。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不直接涉及安全、对齐或多模态等排除项，但它触及了一个更根本的排除项：**它不是关于LLM或智能体的研究**。它研究的是通用的神经网络在物理模拟中的应用，这与我的“LLM智能体及其演化”课题存在本质区别。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的特殊情况。它既不是关于智能体的推理/规划框架，也没有提出任何“自我演化”机制。它只是应用神经网络去模拟一个物理演化过程（界面的移动），这与智能体通过经验进行“自我完善”是完全不同的概念。 **最终决策**: 综合以上分析，这篇论文属于科学计算和物理信息机器学习领域。其核心目标是解决一个特定的物理问题，而不是构建、改进或演化LLM智能体。因此，它严格地落在了我的筛选范围之外。尽管该研究在其自身领域可能非常有价值，但它对我的研究课题“LLM智能体及其演化”没有直接贡献。"
    },
    {
        "index": "#104",
        "title": "Maximum Mean Discrepancy with Unequal Sample Sizes via Generalized U-Statistics",
        "link": "/arxiv/2512.13997",
        "arxiv_id": "2512.13997",
        "authors": "Aaron Wei, Milad Jalali, Danica J. Sutherland",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory, Methodology",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.628884",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是针对统计学中的“双样本检验”问题，提出了一种处理不等样本量的新方法。它通过推广广义U-统计量的理论，改进了最大均值差异（MMD）估计器在样本量不等情况下的渐近分布特性，并提升了检验的准确性。 - **与筛选标准的匹配**: 这篇论文的本质是**机器学习理论/统计学**研究，而非人工智能智能体研究。它完全没有涉及构建、改进或演化LLM智能体。因此，它不满足“保留”的任何条件，应被直接排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文标题和摘要中完全没有出现任何与我的研究焦点相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。因此，不满足任何正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不属于安全、对齐或多模态等明确的排除类别，但它在第一步的核心判断中已经被排除，因为它属于更基础的机器学习理论领域，与我的Agentic AI研究课题相去甚远。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理、规划或自我演化机制，因此特殊情况的规则不适用。 **最终决策**: 综合以上分析，该论文是一篇纯粹的统计学理论论文，其研究对象是MMD这一统计工具，而非LLM智能体。它的贡献在于改进了一种统计检验方法，与“构建、改进或演化LLM智能体”的核心目标完全无关。因此，这篇论文应被**排除**。"
    },
    {
        "index": "#97",
        "title": "Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting",
        "link": "/arxiv/2512.14115",
        "arxiv_id": "2512.14115",
        "authors": "Ramesh Gundluru, Shubham Gupta, Sri Rama Murty K",
        "subjects": "Sound, Machine Learning",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.626884",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种**联合多模态对比学习框架**，用于改进声学词嵌入（AWEs），以提升语音检索任务（如口语词检测和关键词发现）的性能。其本质是**一种应用于特定领域（语音处理）的机器学习模型/方法**，而不是关于构建、改进或演化LLM智能体的方法论。根据筛选标准，这属于“非演化型应用”，应予以排除。论文中没有提及任何关于智能体自主规划、工具使用或与环境交互的框架。 2.  **第二步：正面指标** 论文的标题和摘要中完全没有出现任何与您核心关注点相关的正面指标。例如，它没有涉及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何概念。其核心是“对比学习”和“声学词嵌入”，这是语音和自然语言处理领域的技术，而非智能体研究。 3.  **第三步：排除标准** 论文明确涉及**多模态**。标题中的“Joint Multimodal Contrastive Learning”和摘要中的“audio-text contrastive learning”都表明其核心是处理音频和文本两种模态。根据您的筛选标准，多模态研究属于排除范围，除非它们被用作智能体感知环境的工具。在这篇论文中，多模态学习本身就是研究的核心，而非服务于一个智能体框架，因此符合排除条件。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它关注的是模型在特定任务上的表征学习能力，与智能体的自主行为和演化机制无关。 **最终决策**: 综合以上分析，该论文的核心贡献是语音处理领域的一种新方法，与您关于“LLM智能体及其演化”的研究课题（聚焦于单智能体、多智能体和自我演化）完全不相关。因此，应将其排除。"
    },
    {
        "index": "#111",
        "title": "Simultaneous and Proportional Finger Motion Decoding Using Spatial Features from High-Density Surface Electromyography",
        "link": "/arxiv/2512.13870",
        "arxiv_id": "2512.13870",
        "authors": "Ricardo Gonçalves Molinari, Leonardo Abdala Elias",
        "subjects": "Signal Processing, Machine Learning, Systems and Control",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.631268",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出了一种名为 `MLD-BFM` 的新方法，用于从高密度表面肌电图信号中提取空间特征，以更准确地解码手指的运动。其本质是一项生物医学工程或机器人控制领域的研究，旨在改进假肢控制的性能。 - **是否符合**: 该论文属于典型的 **“非演化型应用”**。它将一个机器学习模型（多层感知机MLP）和一种新的特征提取技术，应用到一个特定领域（生物信号处理、假肢控制）来解决该领域的问题（手指运动解码）。论文完全没有涉及构建、改进或演化任何形式的LLM智能体。因此，根据第一步的核心判断标准，应予以排除。 2.  **第二步：正面指标** - 论文中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准** - 虽然这篇论文不涉及安全与对齐或多模态等排除标准，但它已经触发了第一步中更根本的排除规则——“非演化型应用”。 4.  **第四步：处理特殊和模糊情况** - 论文中的模型（MLP）是一个用于回归的静态模型，不涉及任何智能体的自主规划、工具使用或自我演化机制。因此，关于“推理/规划”和“自我演化的应用”的特殊情况均不适用。 **最终决策**: 综合以上分析，该论文的研究焦点是生物信号处理与机器人控制，与“LLM智能体及其演化”这一课题的核心目标——构建和演化智能体本身——存在根本性的偏离。它是一项应用型研究，而非关于智能体方法论的研究。因此，最终判断为 **False**，应排除。"
    },
    {
        "index": "#100",
        "title": "A Deep Dive into Function Inlining and its Security Implications for ML-based Binary Analysis",
        "link": "/arxiv/2512.14045",
        "arxiv_id": "2512.14045",
        "authors": "Omar Abusabha, Jiyong Uhm, Tamer Abuhmed, Hyungjoon Koo",
        "subjects": "Cryptography and Security, Machine Learning, Programming Languages",
        "date": "2025-12-16",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.627784",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非构建、改进或演化LLM智能体。它的本质是研究编译器优化技术（函数内联）对用于**二进制分析**的机器学习模型所带来的**安全影响**。这完全属于“非演化型应用”的排除范畴，即使用机器学习作为工具去解决特定领域（这里是二进制安全和编译器）的问题，而不是研究智能体本身。 2.  **排除标准 (第三步):** 论文的核心焦点是**安全**。标题明确指出“Security Implications”，摘要中反复出现“ML-assisted binary analysis tasks for security”、“exploited by evading...ML models”、“craft evasive binary variants”等关键词。这直接触发了“安全与对齐”的排除规则，论文的主要贡献是关于模型的安全性和鲁棒性，而非智能体的能力或演化。 3.  **正面指标缺失 (第二步):** 论文中完全没有出现与我研究焦点相关的任何核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。它讨论的是通用的“ML models”，而非具有自主性、规划能力的LLM智能体。 综上所述，该论文是一篇典型的系统安全与编译器交叉领域的研究，其核心问题是分析一种编译器优化如何成为攻击向量，以规避基于机器学习的二进制分析工具。这与我关于“LLM智能体及其演化”的研究目标完全无关，因此必须排除。"
    },
    {
        "index": "#107",
        "title": "Intelligent matter consisting of active particles",
        "link": "/arxiv/2512.13912",
        "arxiv_id": "2512.13912",
        "authors": "Julian Jeggle, Raphael Wittkowski",
        "subjects": "Soft Condensed Matter, Disordered Systems and Neural Networks, Artificial Intelligence, Machine Learning, Applied Physics",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.630224",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是关于物理或机器人领域的“活性物质”和“智能物质”。摘要中明确指出，研究对象是“简单运动智能体”和“活性粒子”，探讨的是通过物理实体（如被超声波或光驱动的粒子）的集体行为来涌现出智能。这与我的核心目标——“构建、改进或演化 **LLM智能体**”——存在根本性的领域差异。论文完全没有提及大语言模型（LLM）、神经网络或任何与自然语言处理相关的内容。因此，这篇论文应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 尽管论文标题和摘要中出现了“智能体”和“集体行为”等词汇，这与“多智能体”有表面上的相似性。但其上下文是物理粒子的运动和相互作用，而非计算智能体之间的协作、通信或博弈。论文的核心范式是“活性物质”和“物理储层计算”，而不是我关注的 `Agentic AI` 或 `LLM-based Agents`。因此，它不包含我的核心关注点。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这篇论文的研究焦点是物理学和复杂系统，虽然不直接属于“安全与对齐”或“多模态与视觉”的排除范畴，但它属于一个更根本的排除项：**非LLM研究**。我的研究课题明确限定在“LLM智能体”，而该论文完全不涉及LLM。 4.  **第四步：处理特殊和模糊情况** 此处没有模糊情况。论文讨论的“涌现”是物理系统层面的，而非AI智能体通过经验或反思进行的“自我演化”。它不属于“自我演化的应用”这一例外情况。 **最终决策**: 这篇论文的核心贡献在于研究物理粒子系统如何通过集体行为产生类似智能的涌现现象，属于物理学和机器人学的交叉领域。它完全不涉及大语言模型（LLM），因此与我的研究目标“LLM智能体及其演化”在研究对象和技术路线上完全不同。根据第一步的核心判断标准，该论文应被排除。"
    },
    {
        "index": "#112",
        "title": "Safe Online Control-Informed Learning",
        "link": "/arxiv/2512.13868",
        "arxiv_id": "2512.13868",
        "authors": "Tianyu Zhou, Zihao Liang, Zehui Lu, Shaoshuai Mou",
        "subjects": "Systems and Control, Machine Learning, Optimization and Control",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.631546",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合您的研究范围。我的判断过程如下： **第一步：核心判断——这篇论文的本质是什么？** 这篇论文的核心贡献是提出一个“安全的在线控制信息学习框架”（Safe Online Control-Informed Learning framework）。其本质是**控制理论与在线学习的结合**，旨在为安全关键型自主系统（如机器人臂）提供在不确定性下的鲁棒自适应控制能力。论文的关键技术是扩展卡尔曼滤波器（用于参数估计）和软plus屏障函数（用于安全约束）。 这完全符合**第一步的排除标准**： 1.  **非演化型应用**: 论文将学习框架应用于特定的工程领域——机器人控制（cart-pole, robot-arm systems）。它解决的是控制领域的动态系统适应和安全问题，而不是构建或演化一个具有通用智能的LLM智能体。 2.  **基础设施/底层技术**: 论文关注的是自主系统的底层控制、参数估计和安全保障机制，这更接近于机器人学或控制理论的基础设施，而非Agentic AI的高层认知架构。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现您列出的任何核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文中的“学习”是指系统参数的在线估计和调整，这与智能体通过经验进行自我完善和迭代的“自我演化”概念有本质区别。 **第三步：排除标准——是否为我的研究焦点之外？** 论文的核心贡献之一是“安全”（Safety），它通过“软plus屏障函数”来“强制约束满足”（enforces constraint satisfaction）。这直接命中了**第三步的排除标准**：“只要论文的主要贡献是关于 `Safety`...一律排除”。虽然安全对智能体很重要，但如果一篇论文的*核心创新点*在于安全机制本身，而不是智能体的智能行为，那么它就超出了您的研究焦点。 **第四步：处理特殊和模糊情况** 本论文的情况并不模糊。它虽然涉及“在线学习”和“适应”，但这属于控制理论范畴，而非您所关注的Agentic AI中的“自我演化”。它没有使用LLM，也没有构建一个具备规划、工具使用或反思能力的智能体。它是一个典型的控制理论论文，应用了机器学习方法。 **第五步：最终决策** 综上所述，该论文的核心是**控制系统的安全在线学习**，属于机器人学和自动控制领域。它不涉及LLM，不构建智能体，不研究多智能体协作，其“学习”和“适应”的概念也区别于Agentic AI中的“自我演化”。其核心贡献之一“安全”更是明确在您的排除标准之内。 因此，这篇论文与您关于“LLM智能体及其演化”的研究课题完全不相关，应予以排除。"
    },
    {
        "index": "#114",
        "title": "BiCoRec: Bias-Mitigated Context-Aware Sequential Recommendation Model",
        "link": "/arxiv/2512.13848",
        "arxiv_id": "2512.13848",
        "authors": "Mufhumudzi Muthivhi, Terence L van Zyl, Hairong Wang",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.632096",
        "filter_reason": "这篇论文不符合研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 论文的核心贡献是提出了一种名为 `BiCoRec` 的**序列推荐模型**，旨在解决推荐系统中的“流行度偏差”问题，以提高对偏好小众物品的用户的推荐准确性。 - **判断**: 这篇论文属于典型的 **“非演化型应用”**。它将一个机器学习模型（可能是基于Transformer的，但摘要未明确提及LLM）应用于**推荐系统**这一特定领域，以解决该领域内的特定问题（偏差缓解）。它并没有构建、改进或演化一个具有自主规划、工具使用或反思能力的LLM智能体。因此，根据第一步的核心判断标准，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现任何与我的研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Self-Reflection` 等任何核心范式或智能体能力。这进一步确认了它与我的研究目标无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文没有直接触及安全、对齐或多模态等排除项，但第一步的“非演化型应用”排除规则已经足够明确且优先级更高。 4.  **第四步：处理特殊和模糊情况** - **关于“演化”**: 摘要中提到了 \"users evolving preferences\"（用户演化的偏好）。这里的“演化”指的是**用户行为和兴趣随时间的变化**，这是推荐系统领域的常用术语，与我所关注的“智能体通过经验进行自我完善和迭代”的“自我演化”机制完全不同。这是一个关键的混淆点，但根据定义，它不属于我的研究范围。 - **关于“推理/规划”**: 论文提出了一种新的训练方案和注意力机制，这属于模型架构和训练方法的优化，而非智能体在复杂任务中的自主规划和多步推理框架。 **最终决策**: 综合以上分析，该论文是一篇典型的推荐系统领域应用研究。其核心目标是改进推荐算法的性能，而非构建或演化LLM智能体。论文中的“演化”一词描述的是用户行为，而非智能体机制。因此，它完全不符合“LLM智能体及其演化”这一研究课题的核心要求。"
    },
    {
        "index": "#110",
        "title": "Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences",
        "link": "/arxiv/2512.13890",
        "arxiv_id": "2512.13890",
        "authors": "Charles Marrder, Shuo Sun, Murray J. Holland",
        "subjects": "Quantum Physics, Machine Learning, Systems and Control",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.631008",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是“非演化型应用”** 论文的核心贡献是提出一种基于强化学习（RL）的方法，用于解决量子计算领域的一个特定问题：为量子比特设计最优的动力学退耦脉冲序列。这里的RL智能体是作为一个优化工具，被应用在一个高度专业化的物理领域（量子计算）。论文的重点在于解决物理问题，而不是构建、改进或演化智能体本身。这完全符合您筛选标准中“非演化型应用”的排除规则。 2.  **缺乏LLM智能体核心要素 (第二步)** 您的研究焦点是“LLM智能体及其演化”。这篇论文通篇未提及LLM（Large Language Model）。它使用的是一个标准的强化学习智能体，其核心能力是在一个定义好的动作空间中通过试错学习最优策略。论文中完全没有涉及您关注的核心能力，如基于语言的规划、记忆、工具使用、自我反思，或多智能体间的协作与通信。 3.  **不属于“自我演化”的范畴 (第四步)** 虽然论文提到智能体可以“学习”和“适应”，但这指的是强化学习智能体在特定任务中学习最优策略的标准过程，而非您所定义的“自我演化”。您关注的“自我演化”是指智能体通过经验、反思或环境反馈来完善和迭代其自身的架构、能力或学习算法。而本文的智能体并没有演化其核心机制，它只是在固定的框架内学习一个脉冲序列。因此，它不满足“自我演化”的例外保留条件。 **总结**: 该论文是一项出色的交叉学科研究，将RL应用于量子物理。然而，从您“LLM智能体及其演化”的研究视角来看，它属于将一个通用智能体（非LLM）作为工具解决特定领域问题的应用型研究，其核心贡献在于应用方法和领域成果，而非智能体本身的构建或演化。因此，它不符合您的筛选要求。"
    },
    {
        "index": "#108",
        "title": "KLO-Net: A Dynamic K-NN Attention U-Net with CSP Encoder for Efficient Prostate Gland Segmentation from MRI",
        "link": "/arxiv/2512.13902",
        "arxiv_id": "2512.13902",
        "authors": "Anning Tian, Byunghyun Ko, Kaichen Qu, Mengyuan Liu, Jeongkyu Lee",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.630496",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文本质不符** - 论文的核心贡献是提出了一种名为“KLO-Net”的新型神经网络架构，用于解决医学影像（前列腺MRI）中的**图像分割**问题。这是一个典型的计算机视觉和医学图像分析领域的研究。 - 根据筛选标准，这属于**“非演化型应用”**。它将一个深度学习模型（KLO-Net）作为工具应用在特定领域（医疗）来解决该领域的问题，其核心是模型架构的创新，而非构建或演化LLM智能体。 2.  **第二步：正面指标——完全不匹配** - 论文的标题和摘要中，完全没有出现任何与我的核心关注点相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这表明论文的研究方向与我的课题相去甚远。 3.  **第三步：排除标准——命中排除项** - 论文的研究核心是**视觉**，具体来说是MRI图像分割。这直接命中了排除标准中的“多模态与视觉”一项。虽然视觉可以作为智能体感知环境的工具，但在这篇论文中，视觉模型本身就是研究的全部内容，而不是作为智能体框架的一个组成部分。 **综合结论**: 该论文是一篇专注于计算机视觉和医学图像处理的论文，其目标是设计一个高效的图像分割网络。它完全不涉及LLM、智能体框架、多智能体协作或自我演化机制。因此，它与研究课题“LLM智能体及其演化”没有任何关联，必须排除。"
    },
    {
        "index": "#115",
        "title": "Unreasonable effectiveness of unsupervised learning in identifying Majorana topology",
        "link": "/arxiv/2512.13825",
        "arxiv_id": "2512.13825",
        "authors": "Jacob Taylor, Haining Pan, Sankar Das Sarma",
        "subjects": "Disordered Systems and Neural Networks, Mesoscale and Nanoscale Physics, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.632359",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出一种结合无监督和监督学习（使用自编码器）的方法，用于解决凝聚态物理领域的一个具体问题：识别马约拉纳纳米线中的拓扑相。 - **判断**: 这完全符合**排除标准 #1: 非演化型应用**。论文将一个标准的深度学习模型（自编码器）作为工具，应用在物理学领域去解决该领域的特定问题。它没有构建、改进或演化任何形式的LLM智能体、多智能体系统或自我演化机制。因此，在第一步就应该被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了其与我的研究课题无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全与对齐或多模态等排除领域，但它触发了第一步中更根本的“非演化型应用”排除规则。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及智能体的推理/规划，也没有提出任何“自我演化”机制，因此特殊情况的例外条款不适用。 **最终决策**: 综合以上分析，这篇论文是一篇典型的将机器学习技术应用于特定科学领域（物理学）的应用型研究。它的核心是解决物理问题，而不是构建或演化智能体。因此，它完全不符合我关于“LLM智能体及其演化”的研究目标，应予以排除。"
    },
    {
        "index": "#118",
        "title": "Improving the Plausibility of Pressure Distributions Synthesized from Depth through Generative Modeling",
        "link": "/arxiv/2512.13757",
        "arxiv_id": "2512.13757",
        "authors": "Neevkumar Manavar, Hanno Gerd Meyer, Joachim Waßmuth, Barbara Hammer, Axel Schneider",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.633163",
        "filter_reason": "这篇论文的核心贡献是提出了一种基于生成式模型（特别是扩散模型）的框架，用于从深度数据中合成物理上合理的压力分布图，其应用场景是医疗健康领域的患者监测。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的本质是**非演化型应用**。它将一个先进的生成模型（布朗桥扩散模型）作为工具，应用到一个特定领域（医疗健康、计算机视觉）去解决该领域的问题（压力分布图的合成）。论文的核心是改进生成模型本身（通过ILS和WOL）以产生更逼真的输出，而不是构建、改进或演化一个具有自主规划、工具使用或反思能力的LLM智能体。因此，根据第一步的排除规则，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我的研究焦点相关的正面指标。没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等任何核心范式或能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的。这篇论文的研究内容明确属于**多模态与视觉**领域。摘要中提到了“从深度合成”、“基于视觉的”以及核心方法“扩散模型”。虽然筛选标准中提到“除非它们被用作智能体感知环境的工具”，但在这篇论文中，视觉和扩散模型是研究的**核心**，而不是一个更大智能体框架的组成部分。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及“推理/规划”或“自我演化的应用”等特殊情况，它是一个纯粹的计算机视觉应用研究。 **最终决策**：综合以上分析，该论文是一篇关于计算机视觉和生成式模型在医疗领域应用的论文，其核心贡献与LLM智能体的构建、多智能体系统或自我演化机制完全无关。它完全符合“非演化型应用”和“多模态与视觉”的排除标准。因此，这篇论文不符合我的研究范围。"
    },
    {
        "index": "#121",
        "title": "Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN",
        "link": "/arxiv/2512.13715",
        "arxiv_id": "2512.13715",
        "authors": "Fatemeh Lotfi, Fatemeh Afghah",
        "subjects": "Artificial Intelligence, Machine Learning, Systems and Control",
        "date": "2025-12-08",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.634032",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是领域应用，而非智能体构建。** 论文的核心贡献是提出一个“元分层强化学习框架”，用于解决“O-RAN（开放无线接入网）中的可扩展资源管理”问题。这是一个典型的**非演化型应用**。它将一个先进的强化学习（RL）方法作为工具，应用于一个特定的工程领域（电信网络），以优化该领域的性能指标（如网络效率、QoS等）。论文的研究焦点是网络资源管理算法，而不是构建一个通用的、具有自主能力的LLM智能体。 2.  **缺少核心要素：LLM智能体。** 您的研究课题是“**LLM**智能体及其演化”。然而，这篇论文的摘要和标题中完全没有提及LLM（Large Language Model）。它讨论的是强化学习（RL）智能体，这与基于LLM的智能体在技术范式、能力和研究目标上有本质区别。RL智能体通常通过与环境交互学习策略以最大化奖励，而LLM智能体则侧重于利用语言模型进行推理、规划和工具使用。因此，该论文从根本上偏离了您的核心研究对象。 3.  **对相关概念的误读。** 虽然论文中出现了“agents”（智能体）和“meta-learning”（元学习）等看似相关的词汇，但其内涵与您的研究焦点不符： *   **智能体**: 这里的“low-level agents”是指执行具体网络调度任务的RL策略单元，而不是具备规划、记忆、工具使用等通用能力的Agentic AI。 *   **元学习**: 这里的元学习（受MAML启发）是为了让RL模型能够更快地适应不同的网络场景（即“快速适应”），这是一种算法层面的优化技巧。它不等同于您所关注的“自我演化”，即智能体通过经验、反思或环境反馈进行自我完善和迭代的机制。 **总结**: 该论文是一篇优秀的网络工程与强化学习交叉领域的研究，但其核心目标是解决特定领域的资源管理问题，而非构建、改进或演化LLM智能体。它完全符合第一步筛选标准中的“非演化型应用”排除规则，并且缺少“LLM-based Agents”这一最核心的研究要素。因此，应予以排除。"
    },
    {
        "index": "#116",
        "title": "Towards Deep Learning Surrogate for the Forward Problem in Electrocardiology: A Scalable Alternative to Physics-Based Models",
        "link": "/arxiv/2512.13765",
        "arxiv_id": "2512.13765",
        "authors": "Shaheim Ogbomo-Harmitt, Cesare Magnetti, Chiara Spota, Jakub Grzelak, Oleg Aslanidi",
        "subjects": "Image and Video Processing, Artificial Intelligence, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.632637",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是提出一个深度学习框架，作为解决心电学中“正问题”的代理模型，以替代计算成本高昂的传统物理模型。其本质是**将深度学习技术应用于一个特定的科学计算领域（生物医学/电生理学）**，以提高计算效率。 - **是否符合保留标准**: 不符合。论文的核心是构建一个**领域应用模型**，而不是构建、改进或演化一个具有自主性的LLM智能体。 - **是否符合排除标准**: 完全符合。它属于典型的**“非演化型应用”**。论文将一个深度学习模型（甚至不是LLM）作为工具，应用于特定领域（医疗）去解决该领域的问题（ECG信号预测）。这与研究LLM智能体的内在机制、规划和演化能力的目标完全不同。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我研究焦点相关的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文提到的“attention-based sequence-to-sequence architecture”是一种通用的深度学习模型架构，并非智能体框架。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不涉及安全对齐或多模态等排除项，但它已经被第一步的“非演化型应用”规则明确排除。 4.  **第四步：处理特殊和模糊情况** - 本论文不涉及任何与智能体规划或自我演化相关的特殊情况。它是一个纯粹的预测模型，不具备任何自主性、规划能力或演化机制。 **最终决策**: 综合以上分析，这篇论文的研究目标是解决计算心脏病学中的一个具体工程问题，其方法是构建一个高效的深度学习代理模型。它完全不涉及LLM智能体的构建、多智能体交互或自我演化机制。因此，它严格地属于“非演化型应用”，与我的研究课题“LLM智能体及其演化”无关，应予以排除。"
    },
    {
        "index": "#119",
        "title": "Time-aware UNet and super-resolution deep residual networks for spatial downscaling",
        "link": "/arxiv/2512.13753",
        "arxiv_id": "2512.13753",
        "authors": "Mika Sipilä, Sabrina Maggio, Sandra De Iaco, Klaus Nordhausen, Monica Palma, Sara Taskinen",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning, Image and Video Processing, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.633461",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了一种改进的深度学习模型（带有时间感知模块的UNet和SRDRN），用于解决一个特定领域的问题：大气污染物数据的**空间降尺度**。它将已有的深度学习架构作为工具，应用于环境科学领域。这完全符合**“非演化型应用”**的排除标准。论文的本质是应用研究，而非构建或演化LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我研究焦点相关的正面指标。它不涉及`Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`或`Self-Evolving`等核心范式。其研究内容也与`Planning`、`Tool Use`、`Memory`、`Collaboration`或`Self-Improvement`等智能体能力无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的研究核心是处理空间数据，属于**计算机视觉**和信号处理的范畴。UNet和SRDRN是经典的视觉/图像处理模型。根据筛选标准，主要关注`Vision`的论文应被排除，除非视觉模型被用作智能体感知环境的工具。在这篇论文中，视觉模型本身就是研究的核心，而不是智能体系统的一部分。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划，也没有提出任何“自我演化”机制。它只是在现有模型上增加了一个时间模块，这是一种静态的模型改进，而非智能体的动态演化。 **最终决策**：综合以上分析，该论文是一篇典型的将深度学习技术应用于特定科学领域（环境科学）的应用型论文。其核心贡献是模型架构的微调和性能提升，与“LLM智能体及其演化”这一研究课题的核心目标——构建、改进或演化智能体——完全无关。因此，应明确排除。"
    },
    {
        "index": "#125",
        "title": "Sim2Real Reinforcement Learning for Soccer skills",
        "link": "/arxiv/2512.12437",
        "arxiv_id": "2512.12437",
        "authors": "Jonathan Spraggett",
        "subjects": "Robotics",
        "date": "2025-12-13",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.635099",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一种使用强化学习（RL）来训练人形机器人（踢球、行走、跳跃等技能）的新方法。这完全属于**“非演化型应用”**的排除范畴。它将RL作为一种工具，应用于机器人控制这一特定领域，旨在解决该领域的Sim2Real问题，而不是构建、改进或演化LLM智能体本身。论文中完全没有提及LLM或任何智能体框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其技术核心是 `Reinforcement Learning (RL)`, `Curriculum Training`, 和 `Adversarial Motion Priors (AMP)`，这些都与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不涉及安全与对齐或多模态等排除项，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何特殊情况。它既不是关于智能体的规划/推理框架，也没有提出任何“自我演化”机制。 5.  **第五步：最终决策** 综合以上分析，这篇论文的研究对象是**机器人控制策略**，而非**LLM智能体**。其核心贡献在于强化学习方法在机器人学领域的应用，这与我“LLM智能体及其演化”的研究课题有本质区别。因此，该论文应被排除。"
    },
    {
        "index": "#120",
        "title": "Probabilistic Predictions of Process-Induced Deformation in Carbon/Epoxy Composites Using a Deep Operator Network",
        "link": "/arxiv/2512.13746",
        "arxiv_id": "2512.13746",
        "authors": "Elham Kiyani, Amit Makarand Deshpande, Madhura Limaye, Zhiwei Gao, Sai Aditya Pradeep, Srikanth Pilla, Gang Li, Zhen Li, George Em Karniadakis",
        "subjects": "Computational Engineering, Finance, and Science, Materials Science, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.633774",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出一种基于深度算子网络的数据驱动代理模型，用于预测材料科学领域（碳/环氧复合材料）的“工艺诱导变形”这一特定物理现象。这完全符合**“非演化型应用”**的排除标准。作者将深度学习模型作为一种高级工具来解决一个具体的工程问题，其研究焦点在于材料科学的预测精度和不确定性量化，而非构建、改进或演化任何形式的智能体。 2.  **正面指标缺失（第二步）：** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标。没有提及 `LLM-based Agents`、`Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，也没有涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。论文中使用的技术是 `Deep Operator Networks`、`Transfer Learning` 和 `Ensemble Kalman Inversion`，这些都是用于函数逼近、模型训练和不确定性量化的机器学习/统计方法，与智能体框架无关。 3.  **排除标准确认（第三步）：** 虽然论文没有触发安全、对齐或多模态等排除标准，但第一步的“非演化型应用”排除规则已经足够明确且具有最高优先级。 4.  **特殊/模糊情况处理（第四步）：** 论文中的“推理”是指模型对物理过程进行数值预测，这不属于智能体在复杂任务中的自主规划和多步推理。论文也没有提出任何“自我演化”机制，其使用的迁移学习是一种模型训练策略，而非智能体通过经验进行自我完善和迭代的机制。 综上所述，该论文是一篇典型的将深度学习技术应用于特定工程领域的研究，其本质是应用驱动而非智能体方法论驱动。因此，它与“LLM智能体及其演化”的核心研究目标完全不符。"
    },
    {
        "index": "#124",
        "title": "Modular connectivity in neural networks emerges from Poisson noise-motivated regularisation, and promotes robustness and compositional generalisation",
        "link": "/arxiv/2512.13707",
        "arxiv_id": "2512.13707",
        "authors": "Daoyuan Qian, Qiyao Liang, Ila Fiete",
        "subjects": "Biological Physics, Machine Learning, Neural and Evolutionary Computing, Machine Learning",
        "date": "2025-12-05",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.634868",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种新的正则化方法，该方法受神经科学启发，旨在**人工神经网络（ANNs）中诱导模块化结构**的出现，从而提升网络的鲁棒性和组合泛化能力。这是一个关于**神经网络架构和训练方法**的基础性研究，而不是关于构建、改进或演化LLM智能体的方法论。它完全不属于“构建LLM智能体”、“多智能体系统”或“自我演化”这三个核心范畴。因此，根据第一步的核心判断标准，应予以排除。 2.  **正面指标缺失 (第二步):** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与您的研究方向无关。 3.  **特殊情况的澄清 (第四步):** *   **推理/规划:** 论文虽然提到了“compositional generalisation”（组合泛化），但这指的是网络结构层面的模块化带来的泛化能力，而非智能体在复杂任务中的自主规划和多步推理框架。 *   **自我演化:** 论文中的“emerges”（涌现）指的是在训练过程中，网络连接模式自发形成模块化结构，这是一种**训练时的静态优化结果**，而不是智能体在部署后通过与环境交互、反思或迭代来**动态地自我完善和演化**的机制。它不符合“自我演化智能体”的定义。 **总结:** 该论文是一项扎实的神经网络基础研究，探讨如何通过正则化技术引导网络形成更优的内部结构。然而，它的研究层面是网络架构和训练优化，而非智能体的行为、能力或演化机制。因此，它严格地落在了您为“LLM智能体及其演化”课题设定的筛选范围之外。"
    },
    {
        "index": "#123",
        "title": "Smart Surveillance: Identifying IoT Device Behaviours using ML-Powered Traffic Analysis",
        "link": "/arxiv/2512.13709",
        "arxiv_id": "2512.13709",
        "authors": "Reza Ryan, Napoleon Paciente, Cahil Youngs, Nickson Karie, Qian Li, Nasim Ferdosian",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-12-06",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.634592",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”** 论文的核心贡献是提出一种使用传统机器学习模型（随机森林、多层感知机、K近邻）来分析网络流量，以识别物联网设备类型和行为的方法。这是一个典型的将机器学习技术应用于特定领域（物联网安全监控）的应用研究。它没有构建、改进或演化任何形式的LLM智能体，甚至没有使用LLM。这完全符合筛选标准中的“非演化型应用”排除规则。 2.  **第二步：正面指标——完全不包含核心关注点** 论文摘要中完全没有出现任何与我的研究焦点相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其技术核心是经典的机器学习分类算法，而非智能体框架。 3.  **第三步：排除标准——论文焦点是“安全”** 论文的研究动机是“introducing significant security challenges”（引入了重大的安全挑战）和“mitigate potential threats”（减轻潜在威胁）。其核心贡献是解决一个安全问题。根据筛选标准，只要论文的主要贡献是关于 `Security`（安全），就应该被排除。 **总结**: 该论文是一篇关于物联网安全和网络流量分析的论文，其本质是应用传统机器学习方法解决特定领域的安全问题。它与研究课题“LLM智能体及其演化”在研究对象（传统ML vs. LLM智能体）、研究目标（安全应用 vs. 智能体构建与演化）和研究范式上完全不同。因此，应果断排除。"
    },
    {
        "index": "#109",
        "title": "One Permutation Is All You Need: Fast, Reliable Variable Importance and Model Stress-Testing",
        "link": "/arxiv/2512.13892",
        "arxiv_id": "2512.13892",
        "authors": "Albert Dorador",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.630743",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一种改进的、基于单一确定性排列的“变量重要性”计算方法，并将其扩展为“系统性变量重要性”用于模型压力测试。这本质上属于**机器学习模型可解释性**和**模型诊断**领域的研究。它并非关于构建、改进或演化LLM智能体的方法论或新框架。因此，根据第一步的排除规则，该论文属于“非演化型应用”，即将一种机器学习方法应用到特定领域（金融、信用风险）以解决该领域的模型透明度和公平性问题，应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心概念。论文的研究对象是通用的机器学习模型（作为黑盒），而非LLM智能体。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这篇论文明确地落在了排除标准之内。摘要中反复强调了其研究目标与以下概念高度相关： *   **可解释性**: “Reliable estimation of feature contributions... is essential for trust, **transparency**...”, “This framework provides a **transparent** way...” *   **安全与对齐**: “...audit models for hidden reliance on protected attributes... enabling regulators and practitioners to assess **fairness** and **systemic risk**...” 这些关键词直接命中了“安全与对齐”排除标准中的 `Interpretability` (可解释性) 和 `Fairness` (公平性)。论文的主要贡献就是为了实现模型的可解释和公平审计，这与您筛选Agentic AI核心贡献的目标完全相悖。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何与“推理/规划”或“自我演化”相关的特殊情况，它是一篇纯粹的模型可解释性研究。 **最终决策**: 综合以上分析，该论文的核心贡献是改进一种机器学习模型可解释性技术，并应用于金融领域的模型审计和公平性评估。其研究焦点是模型诊断，而非LLM智能体的构建、协作或演化。因此，该论文与您的研究课题“LLM智能体及其演化”完全不相关，应被排除。"
    },
    {
        "index": "#126",
        "title": "Automated Pollen Recognition in Optical and Holographic Microscopy Images",
        "link": "/arxiv/2512.08589",
        "arxiv_id": "2512.08589",
        "authors": "Swarn Singh Warshaneyan, Maksims Ivanovs, Blaž Cugmas, Inese Bērziņa, Laura Goldberga, Mindaugas Tamosiunas, Roberts Kadiķis",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-12-09",
        "category": "cs.LG",
        "crawl_time": "2025-12-17T11:00:04.635369",
        "filter_reason": "这篇论文不符合您的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**应用**深度学习模型（YOLOv8s 和 MobileNetV3）来解决一个特定领域的问题——在光学和全息显微镜图像中自动识别花粉。这完全符合筛选标准中的“非演化型应用”排除项。论文的重点是模型在特定任务上的性能评估和通过数据增强来提升性能，而不是构建、改进或演化LLM智能体本身。 2.  **正面指标缺失 (第二步):** 论文中完全没有出现您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这表明其研究内容与您的焦点方向无关。 3.  **符合排除标准 (第三步):** 论文的研究核心是计算机视觉任务，即对“光学和全息显微镜图像”进行“目标检测”和“图像分类”。这直接命中了“多模态与视觉”的排除标准。视觉模型是研究的主体，而不是作为智能体感知环境的工具。 4.  **特殊情况不适用 (第四步):** 论文中提到的性能提升方法（数据集扩充、边界框区域扩大）是标准的机器学习工程实践，而非智能体通过经验、反思或环境反馈进行的“自我演化”机制。因此，关于“自我演化的应用”的例外保留规则不适用。 综上所述，该论文是一篇典型的计算机视觉应用研究，与您关于“LLM智能体及其演化”的核心目标完全不符。"
    }
]