[
    {
        "index": "#7",
        "title": "Multi-Agent Code Verification with Compound Vulnerability Detection",
        "link": "/arxiv/2511.16708",
        "arxiv_id": "2511.16708",
        "authors": "Shreshth Rajan",
        "summary": "LLMs generate buggy code: 29.6% of SWE-bench \"solved\" patches fail, 62% of BaxBench solutions have vulnerabilities, and existing tools only catch 65% of bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent when the agents look for different problems, confirmed by measuring agent correlation of p = 0.05--0.25. We also show that multiple vulnerabilities in the same code create exponentially more risk than previously thought--SQL injection plus exposed credentials creates 15x more danger (risk 300 vs. 20) than traditional models predict. Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method while running faster and without test execution. We tested 15 different agent combinations and found that using multiple agents improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to single agents, with gains of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and 4. The best two-agent combination reaches 79.3% accuracy. Testing on 300 real patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this practical for production use.",
        "subjects": "Software Engineering, Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-20",
        "category": "cs.MA",
        "crawl_time": "2025-11-24T11:00:04.679047",
        "filter_reason": "这篇论文符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建并验证了一个新的多智能体系统**。其核心贡献是“CodeX-Verify”这个系统本身，以及其背后的设计理念——即通过组合多个具有不同检测模式的专业化智能体来提升整体性能。这完全符合你筛选标准中“构建、改进或演化 LLM智能体”的核心目标，特别是“多智能体系统”这一方向。 - 虽然论文的应用领域是代码验证（一个特定领域），但它并非简单地“将已有框架作为工具应用”。相反，它**提出了一种新的多智能体协作方法论**，并从数学和实验上证明了其有效性。研究的重点是“如何构建这个多智能体系统”以及“为什么这个系统更好”，而不是“代码验证这个领域问题本身”。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的标题和核心。 - **多智能体**: 论文明确研究了智能体间的 `Collaboration`（协作），通过组合不同智能体来提升准确率，并量化了这种协作带来的增益（+39.7pp）。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主题是代码漏洞检测，属于`Security`范畴。但根据筛选标准，只有当论文的**主要贡献**是关于安全理论本身时才排除。本文的主要贡献是**用于解决安全问题的多智能体架构**，而不是新的漏洞检测算法或安全理论。它的核心创新在于“智能体如何协作”，而不是“如何发现漏洞”。因此，它不应被排除。 - **多模态与视觉**: 不涉及。 4.  **第四步：处理特殊和模糊情况** - 此处不适用。 5.  **第五步：最终决策** - 综合来看，这篇论文的核心贡献在于**提出并验证了一个新颖的多智能体协作框架**，以解决代码验证问题。它深入探讨了多智能体如何通过专业化分工与协作来超越单智能体的性能极限，这完全契合你研究课题中的“多智能体”方向。因此，这篇论文是高度相关且有价值的前沿研究，应被保留。"
    },
    {
        "index": "#5",
        "title": "Agentifying Agentic AI",
        "link": "/arxiv/2511.17332",
        "arxiv_id": "2511.17332",
        "authors": "Virginia Dignum, Frank Dignum",
        "summary": "Agentic AI seeks to endow systems with sustained autonomy, reasoning, and interaction capabilities. To realize this vision, its assumptions about agency must be complemented by explicit models of cognition, cooperation, and governance. This paper argues that the conceptual tools developed within the Autonomous Agents and Multi-Agent Systems (AAMAS) community, such as BDI architectures, communication protocols, mechanism design, and institutional modelling, provide precisely such a foundation. By aligning adaptive, data-driven approaches with structured models of reasoning and coordination, we outline a path toward agentic systems that are not only capable and flexible, but also transparent, cooperative, and accountable. The result is a perspective on agency that bridges formal theory and practical autonomy.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-21",
        "category": "cs.MA",
        "crawl_time": "2025-11-24T11:00:04.678525",
        "filter_reason": "这篇论文完全符合你的研究范围，是一篇高质量的理论与框架性论文。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是应用，而是构建。它的核心贡献是提出一个**新的构建Agentic AI的框架和视角**。论文主张将经典的AAMAS（自主智能体与多智能体系统）理论（如BDI架构、通信协议、机制设计）与现代的、数据驱动的LLM智能体相结合，以构建更强大、更可靠的智能体系统。这直接命中了你“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文高度符合你的核心关注点。摘要中明确包含了大量正面指标： - **核心范式**: `Agentic AI`, `Autonomous Agents and Multi-Agent Systems (AAMAS)` - **多智能体**: `cooperation`, `communication protocols`, `mechanism design`, `institutional modelling` - **智能体能力**: `reasoning`, `cognition` (与记忆、反思相关), `interaction capabilities` - 这些关键词表明，论文深入探讨了如何从理论和架构层面改进单智能体和多智能体系统的设计与协作。 3.  **第三步：排除标准** - 论文没有被排除。虽然摘要中提到了 `transparent` 和 `accountable`，但这并非论文的主要贡献。论文的核心是**提出一种构建智能体的方法论**，而透明和可问责是这个方法论带来的**期望结果或优势**，而不是其研究本身。论文的重点不是“如何实现安全对齐”，而是“如何通过融合理论来构建更好的智能体”，因此不属于安全与对齐的排除范畴。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确讨论了将“structured models of reasoning”（结构化推理模型）和“BDI architectures”与LLM结合。这完全符合“保留”标准，因为它是在智能体框架下探讨规划和推理，而不是孤立地提升LLM的基础推理能力。 **总结**: 这篇论文的核心贡献在于为“LLM智能体及其演化”这一前沿领域提供了一个坚实的理论基础和构建蓝图。它没有停留在应用层面，而是深入到了智能体的“灵魂”——即认知模型、协作机制和治理结构。它完美地契合了你研究的三个方向：通过引入BDI架构改进**单智能体**的规划与认知；通过通信协议和机制设计深化**多智能体**的协作；通过融合经典理论与自适应模型，为智能体的**自我演化**和迭代改进指明了方向。因此，这是一篇必须保留的关键论文。"
    },
    {
        "index": "#2",
        "title": "Optimizing PyTorch Inference with LLM-Based Multi-Agent Systems",
        "link": "/arxiv/2511.16964",
        "arxiv_id": "2511.16964",
        "authors": "Kirill Nagaitsev, Luka Grbcic, Samuel Williams, Costin Iancu",
        "summary": "Maximizing performance on available GPU hardware is an ongoing challenge for modern AI inference systems. Traditional approaches include writing custom GPU kernels and using specialized model compilers to tune high-level code for specific GPU targets. Recent work shows that LLM-based multi-agent systems can effectively perform such tuning, often outperforming existing compilers and eliminating the need for manual kernel development. However, the dynamics of multi-agent systems for this task remain unexplored. In this work, we present a logical framework for comparing multi-agent PyTorch optimization systems. Our evaluation shows that exploit-heavy strategies perform best when paired with error-fixing agents, and that performance correlates with the granularity of optimization steps. The best implementation achieves an average 2.88x speedup on an H100 GPU across diverse tasks in KernelBench, a benchmark suite covering a range of machine learning architectures in PyTorch.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Distributed, Parallel, and Cluster Computing",
        "date": "2025-11-21",
        "category": "cs.MA",
        "crawl_time": "2025-11-24T11:00:04.677715",
        "filter_reason": "这篇论文符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - 论文的标题和摘要初看似乎偏向于“基础设施”，因为它关注的是“PyTorch推理优化”。这符合第一步排除标准中的“基础设施”方向，因此需要仔细甄别。 - 然而，摘要中的关键句是：“However, the dynamics of multi-agent systems for this task remain unexplored. In this work, we present a logical framework for comparing multi-agent PyTorch optimization systems.” - 这句话明确指出了论文的**核心贡献**并非优化本身，而是**提出一个用于理解和比较多智能体系统动态的逻辑框架**。论文研究的是“多智能体系统如何工作”，而不是“如何用智能体解决一个优化问题”。因此，它不属于“非演化型应用”或“基础设施”的排除范畴，其本质是关于多智能体系统的研究。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - `LLM-based Agents`: 标题和摘要中直接提及。 - `Multi-Agent Systems (MAS)`: 这是论文的核心研究对象。 - `Collaboration`: 摘要中提到的“exploit-heavy strategies perform best when paired with error-fixing agents”描述了不同角色智能体之间的协作模式。 - `Self-Correction`: “error-fixing agents”直接体现了智能体的自我修正能力，这是智能体的重要能力之一。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性等，因此不触发此排除标准。 - 论文不涉及多模态或视觉，因此也不触发此排除标准。 4.  **第四步：处理特殊和模糊情况** - 这篇论文是“推理/规划”模糊情况的一个绝佳例子。虽然智能体执行的任务是代码优化（一种规划），但论文的重点不是优化算法本身，而是**驱动这个过程的智能体框架和策略**。它研究了智能体间的策略组合（如“exploit-heavy”与“error-fixing”的组合）如何影响最终效果，这完全符合“多智能体”研究方向的范畴。 5.  **第五步：最终决策** - 综合来看，尽管论文的应用领域是基础设施优化，但其**科学贡献在于对多智能体系统内部动态、协作策略和组合模式的深入分析与框架构建**。这直接服务于“构建、改进或演化LLM智能体”的核心目标，特别是“多智能体”方向。它为我们理解如何设计更高效的多智能体协作系统提供了宝贵的见解。因此，这篇论文应该被保留。"
    },
    {
        "index": "#8",
        "title": "Humanlike Multi-user Agent (HUMA): Designing a Deceptively Human AI Facilitator for Group Chats",
        "link": "/arxiv/2511.17315",
        "arxiv_id": "2511.17315",
        "authors": "Mateusz Jacniacki, Martí Carmona Serrat",
        "summary": "Conversational agents built on large language models (LLMs) are becoming increasingly prevalent, yet most systems are designed for one-on-one, turn-based exchanges rather than natural, asynchronous group chats. As AI assistants become widespread throughout digital platforms, from virtual assistants to customer service, developing natural and humanlike interaction patterns seems crucial for maintaining user trust and engagement. We present the Humanlike Multi-user Agent (HUMA), an LLM-based facilitator that participates in multi-party conversations using human-like strategies and timing. HUMA extends prior multi-user chatbot work with an event-driven architecture that handles messages, replies, reactions and introduces realistic response-time simulation. HUMA comprises three components-Router, Action Agent, and Reflection-which together adapt LLMs to group conversation dynamics. We evaluate HUMA in a controlled study with 97 participants in four-person role-play chats, comparing AI and human community managers (CMs). Participants classified CMs as human at near-chance rates in both conditions, indicating they could not reliably distinguish HUMA agents from humans. Subjective experience was comparable across conditions: community-manager effectiveness, social presence, and engagement/satisfaction differed only modestly with small effect sizes. Our results suggest that, in natural group chat settings, an AI facilitator can match human quality while remaining difficult to identify as nonhuman.",
        "subjects": "Computation and Language",
        "date": "2025-11-21",
        "category": "cs.CL",
        "crawl_time": "2025-11-24T11:00:05.250058",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个已有的LLM或智能体框架应用到群聊领域，而是**构建了一个全新的、名为HUMA的LLM智能体**。其核心贡献在于提出了一个包含Router、Action Agent和Reflection三个组件的**事件驱动架构**，专门用于使LLM适应多用户对话的动态环境。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是非演化型应用，因为它贡献的是智能体本身的设计，而非其在特定领域的应用结果。 2.  **第二步：正面指标** - 论文包含了多个我的核心关注点： - **核心范式**: `LLM-based Agents` (明确提及), `Multi-Agent Systems` (应用于多用户群聊环境)。 - **智能体能力**: `Self-Reflection` (被明确列为三大核心组件之一), `Planning` (Action Agent的决策过程可以视为一种动态规划)。 - **多智能体**: `Communication` (整个研究都围绕智能体在群体中的通信展开), `Collaboration` (智能体扮演“facilitator”角色，促进群体协作)。 - 这些正面指标，特别是`Self-Reflection`组件和`Multi-Agent`的应用场景，与我的研究焦点高度契合。 3.  **第三步：排除标准** - 论文的主要贡献不在于安全、对齐、可解释性或多模态技术。虽然它研究了“欺骗性”，但其目的是为了评估交互的自然度，而非提出新的安全或水印技术。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“Action Agent”和“Reflection”组件共同构成了一个在复杂动态环境（群聊）中进行多步决策和适应的框架。这属于“智能体如何进行规划或在复杂任务中进行多步推理”的保留范畴，而不是对LLM基础推理能力的改进。 - **自我演化的应用**: 虽然这不完全是自我演化论文，但其“Reflection”组件体现了智能体根据对话动态进行自我调整和适应的能力，这与自我演化的精神内核（通过反馈进行自我完善）是相通的。 5.  **第五步：最终决策** - 综合来看，尽管论文的评估部分侧重于人机交互和图灵测试式的欺骗性，但其**核心贡献是构建了一个新颖的、具有反思能力的多智能体交互框架（HUMA）**。这个框架本身，包括其架构和组件设计，正是我“构建、改进或演化LLM智能体”这一核心目标所关注的内容。因此，这篇论文与我的研究课题“LLM智能体及其演化”高度相关，尤其是在“多智能体”和“单智能体（反思能力）”两个方向上。最终判断为保留。"
    },
    {
        "index": "#14",
        "title": "A Simple Yet Strong Baseline for Long-Term Conversational Memory of LLM Agents",
        "link": "/arxiv/2511.17208",
        "arxiv_id": "2511.17208",
        "authors": "Sizhe Zhou",
        "summary": "LLM-based conversational agents still struggle to maintain coherent, personalized interaction over many sessions: fixed context windows limit how much history can be kept in view, and most external memory approaches trade off between coarse retrieval over large chunks and fine-grained but fragmented views of the dialogue. Motivated by neo-Davidsonian event semantics, we propose an event-centric alternative that represents conversational history as short, event-like propositions which bundle together participants, temporal cues, and minimal local context, rather than as independent relation triples or opaque summaries. In contrast to work that aggressively compresses or forgets past content, our design aims to preserve information in a non-compressive form and make it more accessible, rather than more lossy. Concretely, we instruct an LLM to decompose each session into enriched elementary discourse units (EDUs) -- self-contained statements with normalized entities and source turn attributions -- and organize sessions, EDUs, and their arguments in a heterogeneous graph that supports associative recall. On top of this representation we build two simple retrieval-based variants that use dense similarity search and LLM filtering, with an optional graph-based propagation step to connect and aggregate evidence across related EDUs. Experiments on the LoCoMo and LongMemEval$_S$ benchmarks show that these event-centric memories match or surpass strong baselines, while operating with much shorter QA contexts. Our results suggest that structurally simple, event-level memory provides a principled and practical foundation for long-horizon conversational agents. Our code and data will be released at https://github.com/KevinSRR/EMem.",
        "subjects": "Computation and Language",
        "date": "2025-11-21",
        "category": "cs.CL",
        "crawl_time": "2025-11-24T11:00:05.252755",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **论文本质**: 该论文的核心贡献是提出了一种新的、以事件为中心的长期对话记忆机制（EMem），用于解决LLM智能体在多轮对话中记忆连贯性和个性化的难题。它构建了一个包含会话、话语单元（EDU）及其参数的异构图，并基于此设计了检索方法。 - **判断**: 这完全符合“构建、改进或演化LLM智能体”的核心目标。论文并非将LLM智能体作为工具去解决某个外部领域（如医疗、金融）的问题，而是直接针对智能体本身的一个核心能力——**记忆**——进行方法论上的创新和改进。因此，根据第一步标准，应**保留**。 2.  **第二步：正面指标** - 论文标题和摘要中明确包含了 `LLM Agents` 和 `Memory`。 - `Memory` 是“单智能体”方向下的一个核心子方向。论文提出的“event-centric memory”和“heterogeneous graph”是对智能体记忆能力的直接增强。 - 虽然没有直接提及 `Planning` 或 `Self-Reflection`，但一个强大的长期记忆系统是实现复杂规划和有效自我反思的基石。因此，该研究与核心关注点高度相关。 3.  **第三步：排除标准** - 论文的主要贡献是关于记忆机制的设计和评估，不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐问题。 - 论文专注于文本对话，不涉及 `Vision`, `MLLMs` 等多模态内容。 - 因此，论文未触及任何排除标准。 4.  **第四步：处理特殊和模糊情况** - 该论文的研究内容是关于智能体的**记忆**，而非**推理**或**规划**本身，因此不适用“推理/规划”的特殊判断规则。 - 论文提出的是一种静态的、但更高效的记忆结构，而非一个动态的“自我演化”机制，因此也不适用“自我演化的应用”规则。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于为LLM智能体构建了一个新颖且有效的长期记忆框架。它直接解决了“单智能体”研究中的一个关键挑战——如何维持连贯的长期记忆。该研究是典型的Agentic AI方法论创新，完全符合“构建、改进LLM智能体”的核心目标，应被纳入研究范围。"
    },
    {
        "index": "#16",
        "title": "AutoLink: Autonomous Schema Exploration and Expansion for Scalable Schema Linking in Text-to-SQL at Scale",
        "link": "/arxiv/2511.17190",
        "arxiv_id": "2511.17190",
        "authors": "Ziyang Wang, Yuanlei Zheng, Zhenbiao Cao, Xiaojin Zhang, Zhongyu Wei, Pei Fu, Zhenbo Luo, Wei Chen, Xiang Bai",
        "summary": "For industrial-scale text-to-SQL, supplying the entire database schema to Large Language Models (LLMs) is impractical due to context window limits and irrelevant noise. Schema linking, which filters the schema to a relevant subset, is therefore critical. However, existing methods incur prohibitive costs, struggle to trade off recall and noise, and scale poorly to large databases. We present \\textbf{AutoLink}, an autonomous agent framework that reformulates schema linking as an iterative, agent-driven process. Guided by an LLM, AutoLink dynamically explores and expands the linked schema subset, progressively identifying necessary schema components without inputting the full database schema. Our experiments demonstrate AutoLink's superior performance, achieving state-of-the-art strict schema linking recall of \\textbf{97.4\\%} on Bird-Dev and \\textbf{91.2\\%} on Spider-2.0-Lite, with competitive execution accuracy, i.e., \\textbf{68.7\\%} EX on Bird-Dev (better than CHESS) and \\textbf{34.9\\%} EX on Spider-2.0-Lite (ranking 2nd on the official leaderboard). Crucially, AutoLink exhibits \\textbf{exceptional scalability}, \\textbf{maintaining high recall}, \\textbf{efficient token consumption}, and \\textbf{robust execution accuracy} on large schemas (e.g., over 3,000 columns) where existing methods severely degrade-making it a highly scalable, high-recall schema-linking solution for industrial text-to-SQL systems.",
        "subjects": "Computation and Language, Databases",
        "date": "2025-11-21",
        "category": "cs.CL",
        "crawl_time": "2025-11-24T11:00:05.253779",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。我的判断依据如下： 1.  **第一步：核心判断——论文的本质是构建LLM智能体框架。** 论文的核心贡献是提出了 **AutoLink**，一个被明确定义为 **\"autonomous agent framework\"（自主智能体框架）** 的新方法。它并非简单地将现有LLM或智能体框架应用于Text-to-SQL领域，而是**提出了一种全新的、由智能体驱动的方法论**来解决Schema Linking这一具体挑战。这完全符合“核心贡献在于构建、改进LLM智能体”的保留标准。它不属于“非演化型应用”，因为其创新点在于智能体的工作流程本身，而非应用结果。 2.  **第二步：正面指标——论文高度契合你的核心关注点。** 论文摘要中充满了与你研究方向高度相关的关键词和概念： *   **核心范式**: `Autonomous agent framework`, `agent-driven process`。 *   **智能体能力**: 论文描述的“iterative, agent-driven process”（迭代的、智能体驱动的过程）和“dynamically explores and expands”（动态地探索和扩展）是典型的智能体**规划** 和与环境交互的行为。这种逐步识别、迭代优化的过程也体现了**自我反思** 和**迭代改进** 的思想。 *   **演化机制**: `Iterative Improvement`（迭代改进）是AutoLink框架的核心特征，它通过多轮迭代来完善其Schema Linking结果，这是一种在任务执行过程中的演化。 3.  **第三步：排除标准——论文未触及任何排除领域。** 论文的研究焦点是提升智能体框架的性能和可扩展性，完全没有涉及安全、对齐、可解释性或视觉等多模态内容。因此，它不会因为第三步的任何标准而被排除。 4.  **第四步：处理特殊和模糊情况——论文是关于智能体的规划与推理。** 这篇论文是“推理/规划”特殊情况的完美范例。它不是在研究如何提升LLM生成SQL语句的基础能力，而是在研究**一个智能体应该如何规划和执行一个复杂的多步骤任务**（即Schema Linking）。它提出的框架（探索、评估、再探索）是一种高级的推理和规划策略，完全符合保留条件。 **总结**: 这篇论文的核心是提出一个名为AutoLink的**自主智能体框架**，用于解决大规模Text-to-SQL中的Schema Linking问题。其贡献在于**方法论创新**，即设计了一个迭代的、由智能体驱动的规划与执行流程。这直接命中了你研究课题中的“单智能体”方向，特别是规划、工具使用（与环境交互）和自我反思等子方向。因此，这篇论文是与你研究高度相关的前沿文献，应被筛选出来。"
    },
    {
        "index": "#35",
        "title": "NALA_MAINZ at BLP-2025 Task 2: A Multi-agent Approach for Bangla Instruction to Python Code Generation",
        "link": "/arxiv/2511.16787",
        "arxiv_id": "2511.16787",
        "authors": "Hossain Shaikh Saadi, Faria Alam, Mario Sanz-Guerrero, Minh Duc Bui, Manuel Mager, Katharina von der Wense",
        "summary": "This paper presents JGU Mainz's winning system for the BLP-2025 Shared Task on Code Generation from Bangla Instructions. We propose a multi-agent-based pipeline. First, a code-generation agent produces an initial solution from the input instruction. The candidate program is then executed against the provided unit tests (pytest-style, assert-based). Only the failing cases are forwarded to a debugger agent, which reruns the tests, extracts error traces, and, conditioning on the error messages, the current program, and the relevant test cases, generates a revised solution. Using this approach, our submission achieved first place in the shared task with a $Pass@1$ score of 95.4. We also make our code public.",
        "subjects": "Computation and Language, Software Engineering",
        "date": "2025-11-20",
        "category": "cs.CL",
        "crawl_time": "2025-11-24T11:00:05.273772",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断** - 论文的本质是**构建一个多智能体系统**。虽然它被应用于“孟加拉语指令到Python代码生成”这一特定任务，但其核心贡献并非“应用LLM解决代码生成问题”，而是**提出了一种新颖的“多智能体流水线”方法论**。该论文详细描述了两个智能体（代码生成智能体和调试智能体）如何分工协作、交互信息、并利用工具（执行单元测试）来迭代优化结果。这完全符合“构建LLM智能体”和“多智能体系统”的定义，因此不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `Multi-agent-based pipeline` 直接命中 `Multi-Agent Systems (MAS)`。 - **智能体能力**: 调试智能体根据测试失败和错误信息生成修订版解决方案，这体现了 `Self-Correction` 和 `Self-Reflection` 的能力。执行单元测试是典型的 `Tool Use`。 - **多智能体**: 代码生成智能体和调试智能体之间形成了明确的 `Collaboration`（协作）关系，前者产出初稿，后者负责修正，共同完成最终任务。 3.  **第三步：排除标准** - 论文内容完全不涉及安全与对齐、多模态与视觉等排除领域。其焦点纯粹在于智能体的架构设计和协作机制。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文提出的多智能体流水线本身就是一种复杂的任务规划和执行框架。它将一个复杂的代码生成任务分解为“生成-测试-调试”的循环，这是一种高级的Agentic推理过程，应予以保留。 **总结**: 尽管这篇论文以参加特定竞赛的形式呈现，但其核心价值在于提出并验证了一个有效的多智能体协作框架。该框架展示了智能体如何通过分工、工具使用和基于反馈的自我修正来提升整体性能。这为我的研究课题“LLM智能体及其演化”中的“多智能体”和“自我反思/修正”方向提供了一个具体且有价值的案例，因此完全符合筛选要求。"
    },
    {
        "index": "#55",
        "title": "OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists",
        "link": "/arxiv/2511.16931",
        "arxiv_id": "2511.16931",
        "authors": "Chenyang Shao, Dehao Huang, Yu Li, Keyu Zhao, Weiquan Lin, Yining Zhang, Qingbin Zeng, Zhiyu Chen, Tianxing Li, Yifei Huang, Taozhong Wu, Xinyang Liu, Ruotong Zhao, Mengsheng Zhao, Xuhua Zhang, Yue Wang, Yuanyi Zhen, Fengli Xu, Yong Li, Tie-Yan Liu",
        "summary": "With the rapid development of Large Language Models (LLMs), AI agents have demonstrated increasing proficiency in scientific tasks, ranging from hypothesis generation and experimental design to manuscript writing. Such agent systems are commonly referred to as \"AI Scientists.\" However, existing AI Scientists predominantly formulate scientific discovery as a standalone search or optimization problem, overlooking the fact that scientific research is inherently a social and collaborative endeavor. Real-world science relies on a complex scientific infrastructure composed of collaborative mechanisms, contribution attribution, peer review, and structured scientific knowledge networks. Due to the lack of modeling for these critical dimensions, current systems struggle to establish a genuine research ecosystem or interact deeply with the human scientific community. To bridge this gap, we introduce OmniScientist, a framework that explicitly encodes the underlying mechanisms of human research into the AI scientific workflow. OmniScientist not only achieves end-to-end automation across data foundation, literature review, research ideation, experiment automation, scientific writing, and peer review, but also provides comprehensive infrastructural support by simulating the human scientific system, comprising: (1) a structured knowledge system built upon citation networks and conceptual correlations; (2) a collaborative research protocol (OSP), which enables seamless multi-agent collaboration and human researcher participation; and (3) an open evaluation platform (ScienceArena) based on blind pairwise user voting and Elo rankings. This infrastructure empowers agents to not only comprehend and leverage human knowledge systems but also to collaborate and co-evolve, fostering a sustainable and scalable innovation ecosystem.",
        "subjects": "Computers and Society, Computational Engineering, Finance, and Science, Computation and Language",
        "date": "2025-11-21",
        "category": "cs.CL",
        "crawl_time": "2025-11-24T11:00:05.304390",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。其核心贡献与你的研究目标高度契合，具体分析如下： 1.  **第一步：核心判断——论文本质是构建智能体框架。** 论文的核心并非简单地将LLM应用于科学领域，而是提出了一个名为 `OmniScientist` 的**新框架**。这个框架的本质是构建一个“共同演化的生态系统”，其核心贡献在于**构建和演化LLM智能体系统**，而非仅仅应用它们。它明确指出现有AI科学家的局限性（缺乏社会协作性），并提出了解决方案，这完全符合“构建、改进或演化 LLM智能体”的核心目标。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——精准命中核心关注点。** 论文摘要中包含了大量与你研究焦点直接相关的正面指标： *   **多智能体:** 明确提到了“多智能体协作”、“协作研究协议”，并构建了一个让智能体和人类共同参与的“生态系统”。这直接命中了你的第二个研究方向。 *   **自我演化:** 标题和摘要的核心词就是“Co-evolving”（共同演化）。论文旨在让智能体能够“协作和共同演化， fostering a sustainable and scalable innovation ecosystem”。这完美契合你的第三个研究方向。 *   **智能体能力:** 论文涉及“端到端自动化”，包括“研究构想”、“实验自动化”等，这些都隐含了对智能体**规划**和**工具使用**能力的要求。 3.  **第三步：排除标准——未触及排除领域。** 论文的主要贡献是关于智能体的架构和生态系统，没有涉及安全、对齐、可解释性或水印等问题。同时，它也未以多模态或视觉作为研究核心，因此完全避开了你的排除标准。 4.  **第四步：处理特殊情况——属于“自我演化的应用”的保留例外。** 即使我们将这篇论文看作是“自我演化”在“科学”这一特定领域的应用，它也完全符合你设定的“保留（例外）”规则。论文的核心是**提出一种新的“共同演化”机制**，并用科学领域作为其验证和展示的舞台。它的贡献在于机制本身，而非应用结果。 **最终决策：** 这篇论文的核心贡献是提出一个支持多智能体协作与共同演化的框架 `OmniScientist`。它直接解决了你的研究焦点中的“多智能体”和“自我演化”两个核心方向，提出的方法论和框架具有前沿性和基础性。因此，这篇论文是与你研究课题高度相关的优质文献，应被**保留**。"
    },
    {
        "index": "#2",
        "title": "PersonaAgent with GraphRAG: Community-Aware Knowledge Graphs for Personalized LLM",
        "link": "/arxiv/2511.17467",
        "arxiv_id": "2511.17467",
        "authors": "Siqi Liang, Yudi Zhang, Yue Guo",
        "summary": "We propose a novel framework for persona-based language model system, motivated by the need for personalized AI agents that adapt to individual user preferences. In our approach, the agent embodies the user's \"persona\" (e.g. user profile or taste) and is powered by a large language model (LLM). To enable the agent to leverage rich contextual information, we introduce a Knowledge-Graph-enhanced Retrieval-Augmented Generation (Graph RAG) mechanism that constructs an LLM-derived graph index of relevant documents and summarizes communities of related information. Our framework generates personalized prompts by combining: (1) a summary of the user's historical behaviors and preferences extracted from the knowledge graph, and (2) relevant global interaction patterns identified through graph-based community detection. This dynamic prompt engineering approach allows the agent to maintain consistent persona-aligned behaviors while benefiting from collective knowledge. On the LaMP benchmark, our method improves news categorization F1 by 11.1%, movie tagging F1 by 56.1%, and reduces product rating MAE by 10.4% over prior methods. Our code is available at https://anonymous.4open.science/r/PersonaAgentwGraphRAG-DE6F",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-21",
        "category": "cs.LG",
        "crawl_time": "2025-11-24T11:00:05.675471",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出了一个名为 \"PersonaAgent\" 的**新框架**。该框架旨在构建能够体现用户个性的个性化LLM智能体。其核心创新点在于使用 \"GraphRAG\" 机制来增强智能体的记忆和知识检索能力，从而实现更精准的个性化。 - **判断**: 这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是简单地将现有智能体应用到一个新领域，而是提出了构建智能体的一种新方法。因此，在第一步就应**保留**。 2.  **第二步：正面指标** - **核心范式**: 论文明确提出了 \"PersonaAgent\"，这是一个典型的 `LLM-based Agent` 框架。 - **智能体能力**: 论文的核心机制 \"GraphRAG\" 直接命中了多个关键能力： - `Memory`: 通过构建知识图谱来存储和总结用户的历史行为与偏好，这是一种长期记忆的实现方式。 - `Tool Use / Tool Augmentation`: GraphRAG 本质上是一种工具，智能体通过查询这个知识图谱工具来获取外部信息，以增强其生成能力。 - `Planning`: 论文中提到的 \"dynamic prompt engineering approach\" 描述了智能体如何结合内部记忆（用户画像）和外部知识（图谱信息）来规划其下一步的输出，以保持行为的一致性。这属于智能体的规划与决策过程。 3.  **第三步：排除标准** - 论文的主要贡献是关于智能体的个性化框架，不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐议题。 - 论文专注于文本处理，不涉及 `Vision`, `MLLMs` 等多模态内容。 - 因此，论文没有触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的推理是围绕智能体如何利用记忆和工具来生成个性化响应展开的，属于智能体框架内的规划与决策过程，而非提升LLM底层的数学或逻辑推理能力。因此，符合保留条件。 - **自我演化的应用**: 此处不适用，因为论文的核心是静态的个性化，而非动态的自我演化。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建了一个新颖的LLM智能体框架**，该框架通过结合知识图谱（作为记忆和工具）来增强智能体的个性化能力。这完全符合我研究课题中“单智能体”方向下的“记忆”和“工具使用”子方向。因此，这篇论文与我的研究目标高度相关，应被**保留**。"
    },
    {
        "index": "#57",
        "title": "Cognitive BASIC: An In-Model Interpreted Reasoning Language for LLMs",
        "link": "/arxiv/2511.16837",
        "arxiv_id": "2511.16837",
        "authors": "Oliver Kramer",
        "summary": "Cognitive BASIC is a minimal, BASIC-style prompting language and in-model interpreter that structures large language model (LLM) reasoning into explicit, stepwise execution traces. Inspired by the simplicity of retro BASIC, we repurpose numbered lines and simple commands as an interpretable cognitive control layer. Modern LLMs can reliably simulate such short programs, enabling transparent multi-step reasoning inside the model. A natural-language interpreter file specifies command semantics, memory updates, and logging behavior. Our mental-model interpreter extracts declarative and procedural knowledge, detects contradictions, and produces resolutions when necessary. A comparison across three LLMs on a benchmark of knowledge extraction, conflict detection, and reasoning tasks shows that all models can execute Cognitive BASIC programs, with overall strong but not uniform performance.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-20",
        "category": "cs.CL",
        "crawl_time": "2025-11-24T11:00:05.305313",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“Cognitive BASIC”的新型框架，它是一种在LLM内部运行的、结构化的推理语言和解释器。我的判断过程如下： 1.  **第一步：核心判断——保留。** 论文的本质并非简单地将LLM作为工具应用，也不是提升LLM的基础推理能力（如数学计算）。它的核心是**构建一个新的方法论和框架**，用于结构化、控制LLM的推理过程。这个框架包含“认知控制层”、“内存更新”和“分步执行轨迹”，这些都是构建一个自主智能体所必需的核心组件。因此，它符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标——高度相关。** 论文明确涉及了多个我的核心关注点： *   **智能体能力**: 论文的“分步执行轨迹”直接对应`Planning`（规划）；“内存更新”对应`Memory`（记忆）；“检测矛盾，并在必要时产生解决方案”对应`Self-Correction`（自我纠正）和`Self-Reflection`（自我反思）。 *   **核心范式**: 整个“Cognitive BASIC”框架可以被视为一种新颖的`Agentic AI`实现方式，它为LLM智能体提供了一个可解释、可控制的认知架构。 3.  **第三步：排除标准——未触发。** *   **安全与对齐**: 论文虽然提到了“可解释”，但这并非其研究主旨。它的主要贡献是提出一个**实现**可解释推理的框架，而不是研究可解释性本身的理论或方法。因此，它不属于以`Interpretability`为核心贡献的论文，不应被排除。 *   **多模态与视觉**: 论文完全基于文本，不涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况——符合保留条件。** *   **推理/规划**: 这篇论文是关于“智能体如何进行规划或在复杂任务中进行多步推理”的典型范例。它超越了简单的思维链提示，提出了一个带有解释器的、更形式化的`Agentic框架`来执行多步推理。这完全符合保留标准。 **最终决策**: 该论文的核心贡献在于提出了一种创新的、用于构建LLM智能体内部推理过程的框架。它直接解决了单智能体研究中的规划、记忆和自我反思等关键问题。因此，这篇论文与我的研究课题“LLM智能体及其演化”高度相关，应该被保留。"
    },
    {
        "index": "#31",
        "title": "ToC: Tree-of-Claims Search with Multi-Agent Language Models",
        "link": "/arxiv/2511.16972",
        "arxiv_id": "2511.16972",
        "authors": "Shuyang Yu, Jianan Liang, Hui Hu",
        "summary": "Optimizing patent claims is a critical yet challenging task, demanding careful balance between maximizing novelty and preserving legal scope. Manual claim drafting is labor-intensive, costly, and inherently inconsistent, while conventional Large Language Models (LLMs) often lack the structured, iterative reasoning essential for precise claim refinement. To address these challenges, we introduce Tree of Claims (ToC), an innovative framework that redefines claim editing as a guided search problem. ToC synergistically integrates Monte Carlo Tree Search (MCTS) with a collaborative multi-agent system, comprising an LLM-based EditorAgent that proposes contextually grounded edits, and an ExaminerAgent that mimics patent examiner critiques through structured, chain-of-thought analyses of novelty and prior art disclosure. Driven by a carefully designed multi-objective reward function, ToC jointly optimizes novelty, scope retention, and semantic coherence. Experimental evaluation on a benchmark of 1145 claims demonstrates that ToC significantly outperforms standard LLMs in zero-shot and few-shot scenarios, achieving an average composite score improvement of 8\\%, and up to 9\\% in certain cases. Extensive experiments, including detailed ablation studies, validate ToC's efficacy in generating superior, legally robust claim revisions. Overall, ToC establishes a transparent, controllable, and interpretable methodology that effectively bridges advanced LLM reasoning capabilities with strategic MCTS planning for structured patent claim optimization.The source code is available at https://github.com/ysy2003/ToC.",
        "subjects": "Machine Learning",
        "date": "2025-11-21",
        "category": "cs.LG",
        "crawl_time": "2025-11-24T11:00:05.698881",
        "filter_reason": "这篇论文的核心贡献是提出了一个名为ToC（Tree-of-Claims）的创新框架，该框架将专利权利要求优化问题构建为一个引导式搜索问题，并采用了一个协作式多智能体系统来解决它。这完全符合您的研究范围。 以下是详细的判断过程： 1.  **第一步：核心判断——保留** - 论文的核心不是简单地将LLM应用于专利领域，而是**构建了一个全新的方法论框架**。这个框架的核心是“一个协作式多智能体系统”，包含一个`EditorAgent`和一个`ExaminerAgent`。这直接命中了您研究目标中的“构建、改进LLM智能体”和“多智能体系统”。 - 它不属于“非演化型应用”，因为其创新点在于智能体如何协作和搜索，而不是应用本身的结果。它也不属于“非Agentic的推理”，因为它构建了一个完整的智能体框架来执行任务，而不是仅仅改进LLM的基础推理能力。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文明确提出了一个`Multi-Agent Systems (MAS)`。 - **多智能体**: 包含`Collaboration`（协作式多智能体系统）和`Communication`（通过提议和批评进行隐式通信）。 - **智能体能力**: 涉及`Planning`（使用Monte Carlo Tree Search进行规划和搜索）和`ReAct`/`Chain-of-Thought`（ExaminerAgent使用结构化的CoT进行分析）。 - 论文几乎完美地覆盖了您在“多智能体”和“单智能体（规划）”方向上的所有核心关注点。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不是关于安全、对齐或可解释性。虽然摘要中提到了“interpretable methodology”，但这只是其框架的一个特性或优点，而非研究的核心焦点。核心焦点是框架本身的设计和效能。 - 论文不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”的典型案例。它提出了一个新的Agentic框架（ToC），该框架结合了MCTS（一种规划算法）和多智能体协作，以在复杂任务中进行多步推理和决策。这完全符合您对智能体如何进行规划的研究兴趣。 - **自我演化的应用**: 虽然这篇论文不涉及自我演化，但它属于您另一个核心关注点“多智能体”，因此同样具有高度相关性。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的、基于LLM的多智能体协作与规划框架。尽管其应用场景是专利优化，但其方法论本身是对Agentic AI前沿的直接探索，与您的研究课题“LLM智能体及其演化”中的“多智能体”和“单智能体（规划）”方向高度契合。因此，这篇论文应该被保留。"
    },
    {
        "index": "#4",
        "title": "Designing Domain-Specific Agents via Hierarchical Task Abstraction Mechanism",
        "link": "/arxiv/2511.17198",
        "arxiv_id": "2511.17198",
        "authors": "Kaiyu Li, Jiayu Wang, Zhi Wang, Hui Qiao, Weizhan Zhang, Deyu Meng, Xiangyong Cao",
        "summary": "LLM-driven agents, particularly those using general frameworks like ReAct or human-inspired role-playing, often struggle in specialized domains that necessitate rigorously structured workflows. Fields such as remote sensing, requiring specialized tools (e.g., correction, spectral indices calculation), and multi-step procedures (e.g., numerous intermediate products and optional steps), significantly challenge generalized approaches. To address this gap, we introduce a novel agent design framework centered on a Hierarchical Task Abstraction Mechanism (HTAM). Specifically, HTAM moves beyond emulating social roles, instead structuring multi-agent systems into a logical hierarchy that mirrors the intrinsic task-dependency graph of a given domain. This task-centric architecture thus enforces procedural correctness and decomposes complex problems into sequential layers, where each layer's sub-agents operate on the outputs of the preceding layers. We instantiate this framework as EarthAgent, a multi-agent system tailored for complex geospatial analysis. To evaluate such complex planning capabilities, we build GeoPlan-bench, a comprehensive benchmark of realistic, multi-step geospatial planning tasks. It is accompanied by a suite of carefully designed metrics to evaluate tool selection, path similarity, and logical completeness. Experiments show that EarthAgent substantially outperforms a range of established single- and multi-agent systems. Our work demonstrates that aligning agent architecture with a domain's intrinsic task structure is a critical step toward building robust and reliable specialized autonomous systems.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-11-21",
        "category": "cs.AI",
        "crawl_time": "2025-11-24T11:00:05.601225",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一种名为“分层任务抽象机制”（HTAM）的新型多智能体设计框架。这并非简单地将现有智能体框架应用于一个新领域，而是**构建和改进LLM智能体方法论**本身。论文旨在解决通用智能体框架在专业领域中的不足，其核心创新点在于智能体的架构设计，而非其在特定领域的应用效果。因此，它通过了第一步的核心判断，不属于“非演化型应用”或“非Agentic的推理”。 2.  **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **核心范式**: 论文明确提出了一个`Multi-Agent Systems (MAS)`框架（HTAM），并实例化为`EarthAgent`。 *   **多智能体**: 论文的核心是关于智能体间的`Collaboration`（协作），通过构建逻辑层次，让“每一层的子智能体在上一层输出的基础上运作”，这清晰地描述了多智能体的协作与工作流。 *   **智能体能力**: 该框架本质上是一种复杂的`Planning`（规划）机制，它将复杂问题分解为顺序的层次。同时，它也涉及`Tool Use`（工具使用），因为其应用场景（遥感）需要使用专业工具。 3.  **第三步：排除标准——未触发** 论文的主要贡献不在于安全、对齐、可解释性或多模态模型本身。虽然其应用领域“remote sensing”（遥感）会处理视觉数据，但视觉数据是智能体操作的**对象和环境**，而非论文研究的**核心**。论文的核心是智能体的设计框架，这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外条款。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文是关于智能体如何进行复杂规划和多步推理的典型范例。它提出的HTAM框架就是一种新的Agentic规划框架，远超于提升LLM基础推理能力的范畴，因此应被**保留**。 *   **自我演化的应用**: 此条不直接适用，因为论文的核心是静态的架构设计，而非动态的自我演化机制。 **最终决策**: 该论文的核心贡献在于**构建和改进多智能体系统**，提出了一个新颖的、以任务为中心的层次化架构（HTAM）来解决复杂规划问题。这精准地契合了您研究目标中的“多智能体”方向，并涉及“规划”和“工具使用”等关键能力。尽管它在一个特定领域（地理空间分析）中进行实例化和评估，但其本质是关于智能体设计的通用方法论，而非领域应用。因此，这篇论文是您研究课题下的高质量前沿文献。"
    },
    {
        "index": "#6",
        "title": "The Belief-Desire-Intention Ontology for modelling mental reality and agency",
        "link": "/arxiv/2511.17162",
        "arxiv_id": "2511.17162",
        "authors": "Sara Zuppiroli, Carmelo Fabio Longo, Anna Sofia Lippolis, Rocco Paolillo, Lorenzo Giammei, Miguel Ceriani, Francesco Poggi, Antonio Zinilli, Andrea Giovanni Nuzzolese",
        "summary": "The Belief-Desire-Intention (BDI) model is a cornerstone for representing rational agency in artificial intelligence and cognitive sciences. Yet, its integration into structured, semantically interoperable knowledge representations remains limited. This paper presents a formal BDI Ontology, conceived as a modular Ontology Design Pattern (ODP) that captures the cognitive architecture of agents through beliefs, desires, intentions, and their dynamic interrelations. The ontology ensures semantic precision and reusability by aligning with foundational ontologies and best practices in modular design. Two complementary lines of experimentation demonstrate its applicability: (i) coupling the ontology with Large Language Models (LLMs) via Logic Augmented Generation (LAG) to assess the contribution of ontological grounding to inferential coherence and consistency; and (ii) integrating the ontology within the Semas reasoning platform, which implements the Triples-to-Beliefs-to-Triples (T2B2T) paradigm, enabling a bidirectional flow between RDF triples and agent mental states. Together, these experiments illustrate how the BDI Ontology acts as both a conceptual and operational bridge between declarative and procedural intelligence, paving the way for cognitively grounded, explainable, and semantically interoperable multi-agent and neuro-symbolic systems operating within the Web of Data.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-21",
        "category": "cs.AI",
        "crawl_time": "2025-11-24T11:00:05.602264",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于为构建和改进LLM智能体提供了一个基础性的、形式化的认知架构框架。我的判断过程如下： **第一步：核心判断——保留** 论文的本质是构建一个方法论框架，而非应用。其核心贡献是提出了一个**形式化的信念-愿望-意图（BDI）本体论**。BDI是智能体领域的经典理论，用于建模智能体的心智状态（信念、愿望、意图）和决策过程。这篇论文的工作是将这一理论转化为一个结构化、可互操作的本体论，这直接服务于“构建或改进LLM智能体”的目标。它不是将智能体作为工具去解决某个领域问题，而是在为智能体本身“铸造骨架”。 **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **核心范式**: 论文明确围绕 `Agentic AI` 和 `Multi-Agent Systems (MAS)` 展开，其BDI模型是智能体理论的基石。 *   **智能体能力**: BDI模型直接对应了智能体的核心能力。`Beliefs`（信念）是智能体的**记忆**和对世界的认知；`Desires`（愿望）和`Intentions`（意图）驱动了智能体的**规划**和决策过程。论文通过将本体论与LLM耦合，旨在提升LLM的“推理连贯性和一致性”，这正是对智能体高级推理能力的改进。 *   **多智能体**: 摘要结尾明确指出，该工作为“cognitively grounded... semantically interoperable **multi-agent**... systems”铺平了道路，表明其设计目标之一就是支持多智能体系统。 **第三步：排除标准——未触发** *   **安全与对齐**: 论文虽然提到了“explainable”（可解释性），但这是其认知架构设计带来的一个**特性**，而非研究的**主要贡献**。论文的核心是构建智能体的心智模型，而不是研究如何对齐或保障其安全。因此，这不属于排除范围。 *   **多模态与视觉**: 论文未涉及视觉或多模态内容。 **第四步：处理特殊和模糊情况** *   **推理/规划**: 这篇论文是“保留”的典型案例。它不是在研究如何提升LLM的基础数学或逻辑推理能力，而是在研究如何为智能体构建一个**进行规划和多步推理的认知框架（BDI）**。通过将这个形式化的本体论与LLM结合，它为LLM赋予了结构化的、类似人类的推理过程，这完全符合对智能体规划能力的研究。 **第五步：最终决策** 综合来看，这篇论文的核心贡献是提供了一个**形式化的、可计算的智能体心智模型（BDI Ontology）**，并展示了如何将其与LLM结合，以构建推理更连贯、认知更合理的智能体。这项工作属于构建LLM智能体的基础性、方法论研究，直接触及了智能体的规划、记忆和推理等核心能力，并展望了其在多智能体系统中的应用。因此，它精准地契合了你关于“LLM智能体及其演化”的研究课题。"
    },
    {
        "index": "#9",
        "title": "Budget-Aware Tool-Use Enables Effective Agent Scaling",
        "link": "/arxiv/2511.17006",
        "arxiv_id": "2511.17006",
        "authors": "Tengxiao Liu, Zifeng Wang, Jin Miao, I-Hung Hsu, Jun Yan, Jiefeng Chen, Rujun Han, Fangyuan Xu, Yanfei Chen, Ke Jiang, Samira Daruki, Yi Liang, William Yang Wang, Tomas Pfister, Chen-Yu Lee",
        "summary": "Scaling test-time computation improves performance across different tasks on large language models (LLMs), which has also been extended to tool-augmented agents. For these agents, scaling involves not only \"thinking\" in tokens but also \"acting\" via tool calls. The number of tool calls directly bounds the agent's interaction with the external environment. However, we find that simply granting agents a larger tool-call budget fails to improve performance, as they lack \"budget awareness\" and quickly hit a performance ceiling. To address this, we study how to scale such agents effectively under explicit tool-call budgets, focusing on web search agents. We first introduce the Budget Tracker, a lightweight plug-in that provides the agent with continuous budget awareness, enabling simple yet effective scaling. We further develop BATS (Budget Aware Test-time Scaling), an advanced framework that leverages this awareness to dynamically adapt its planning and verification strategy, deciding whether to \"dig deeper\" on a promising lead or \"pivot\" to new paths based on remaining resources. To analyze cost-performance scaling in a controlled manner, we formalize a unified cost metric that jointly accounts for token and tool consumption. We provide the first systematic study on budget-constrained agents, showing that budget-aware methods produce more favorable scaling curves and push the cost-performance Pareto frontier. Our work offers empirical insights toward a more transparent and principled understanding of scaling in tool-augmented agents.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-21",
        "category": "cs.AI",
        "crawl_time": "2025-11-24T11:00:05.603853",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献是构建了一个名为 **BATS (Budget Aware Test-time Scaling)** 的新框架，以及一个 **Budget Tracker** 插件。其目的不是将现有智能体应用于某个领域，而是**改进LLM智能体本身的核心能力**，使其在资源约束下更有效地进行规划和行动。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。 2.  **第二步：正面指标——高度匹配** - 论文的核心范式是 **`LLM-based Agents`** 和 **`Agentic AI`**。 - 它直接聚焦于智能体的关键能力：**`Tool Use / Tool Augmentation`** 和 **`Planning`**。BATS框架的核心就是“动态适应其规划和验证策略”，这直接命中了您对“智能体的规划”这一研究焦点。 - 智能体根据剩余预算决定是“深入挖掘”还是“转向新路”，这体现了一种基于环境反馈（预算消耗）的适应性决策，与**`Self-Correction`**或**`Self-Reflection`**的理念相通。 3.  **第三步：排除标准——未触发** - 论文的主要贡献是关于提升智能体的性能和成本效益，而非安全、对齐或可解释性。 - 研究的工具是网络搜索，不涉及视觉或多模态内容作为研究核心。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 这篇论文是典型的“关于智能体如何进行规划”的研究。它提出的BATS框架是一种新的Agentic规划框架，超越了简单的ReAct，引入了预算感知的动态规划能力。因此，它明确属于“保留”范畴，而不是被排除的“非Agentic的推理”。 **最终决策**: 该论文的核心贡献在于提出了一种**改进单智能体规划和工具使用效率的新框架（BATS）**。它通过赋予智能体“预算感知”能力，使其能够更智能地分配计算资源（包括思考和行动），从而实现更有效的扩展。这直接对您研究课题中的“单智能体”方向，特别是“规划”和“工具使用”子方向，做出了前沿且核心的贡献。因此，这篇论文与您的研究目标高度契合。"
    },
    {
        "index": "#10",
        "title": "MirrorMind: Empowering OmniScientist with the Expert Perspectives and Collective Knowledge of Human Scientists",
        "link": "/arxiv/2511.16997",
        "arxiv_id": "2511.16997",
        "authors": "Qingbin Zeng, Bingbing Fan, Zhiyu Chen, Sijian Ren, Zhilun Zhou, Xuhua Zhang, Yuanyi Zhen, Fengli Xu, Yong Li, Tie-Yan Liu",
        "summary": "The emergence of AI Scientists has demonstrated remarkable potential in automating scientific research. However, current approaches largely conceptualize scientific discovery as a solitary optimization or search process, overlooking that knowledge production is inherently a social and historical endeavor. Human scientific insight stems from two distinct yet interconnected sources. First is the individual cognitive trajectory, where a researcher's unique insight is shaped by their evolving research history and stylistic preferences; another is the collective disciplinary memory, where knowledge is sedimented into vast, interconnected networks of citations and concepts. Existing LLMs still struggle to represent these structured, high-fidelity cognitive and social contexts. To bridge this gap, we introduce MirrorMind, a hierarchical cognitive architecture that integrates dual-memory representations within a three-level framework. The Individual Level constructs high-fidelity cognitive models of individual researchers by capturing their episodic, semantic, and persona memories; the Domain Level maps collective knowledge into structured disciplinary concept graphs; and the Interdisciplinary Level that acts as an orthogonal orchestration engine. Crucially, our architecture separates memory storage from agentic execution, enabling AI scientist agents to flexibly access individual memories for unique perspectives or collective structures to reason. We evaluate MirrorMind across four comprehensive tasks, including author-level cognitive simulation, complementary reasoning, cross-disciplinary collaboration promotion, and multi-agent scientific problem solving. The results show that by integrating individual cognitive depth with collective disciplinary breadth, MirrorMind moves beyond simple fact retrieval toward structural, personalized, and insight-generating scientific reasoning.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-21",
        "category": "cs.AI",
        "crawl_time": "2025-11-24T11:00:05.609609",
        "filter_reason": "这篇论文完全符合研究范围，应被保留。以下是基于筛选标准的详细判断过程： **第一步：核心判断——保留** 这篇论文的本质是提出一个名为 **MirrorMind** 的全新**分层认知架构**，其核心目标是构建更强大的AI科学家智能体。论文的核心贡献并非将现有智能体作为工具应用于科学领域，而是**构建和改进LLM智能体本身的方法论**。它通过引入双记忆模型和三层框架，解决了现有AI智能体在模拟人类科学家认知过程（个体认知与集体知识）上的不足。这完全符合“构建、改进或演化LLM智能体”的核心目标，因此直接进入保留流程。 **第二步：正面指标——高度匹配** 论文包含了大量与研究焦点高度相关的正面指标： *   **核心范式**: 论文通篇围绕 `LLM-based Agents` 展开，并提出了一个新颖的 `Agentic AI` 架构。其评估任务包括 `Multi-Agent scientific problem solving`，直接命中 `Multi-Agent Systems (MAS)` 方向。 *   **智能体能力**: 论文的核心创新点在于**记忆**。它详细阐述了 `Individual Level` 的 `episodic, semantic, and persona memories`（情景、语义和人格记忆），以及 `Domain Level` 的集体知识图谱。这直接对应了研究焦点中的 `Memory` 能力。同时，其架构旨在实现“insight-generating scientific reasoning”，这与智能体的 `Planning` 和复杂推理能力紧密相关。 *   **多智能体**: 论文明确提到了 `cross-disciplinary collaboration promotion`（跨学科协作促进）和 `multi-agent scientific problem solving`（多智能体科学问题解决）作为评估任务，这直接命中了 `Collaboration` 和 `Agent Society` 等子方向。 **第三步：排除标准——未触发** 论文的主要贡献是关于智能体的认知架构和推理能力，并未涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐议题。同时，论文也未将 `Vision` 或其他多模态技术作为研究核心，其焦点在于文本和知识图谱驱动的认知过程。因此，未触发任何排除标准。 **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文提出的推理能力是建立在其独特的“记忆存储与智能体执行分离”的架构之上的。它不是在提升LLM的基础Token预测能力，而是在构建一个能让智能体利用结构化记忆进行“个性化、结构化、洞察生成式”推理的框架。这完全符合“保留”关于智能体如何进行规划和多步推理的论文的规则。 *   **自我演化的应用**: 虽然论文的应用领域是科学研究，但其核心是提出一种新的智能体架构，而非简单的应用。因此，它不属于“非演化型应用”的排除范畴。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种创新的、融合了个体记忆与集体知识的LLM智能体架构。它直接推动了**单智能体**（特别是记忆和推理能力）和**多智能体**（协作和知识共享）领域的发展。论文的研究内容与“LLM智能体及其演化”的课题高度契合，是典型的关于如何构建和改进智能体的前沿研究。因此，最终判断为 **True (保留)**。"
    },
    {
        "index": "#21",
        "title": "REMSA: An LLM Agent for Foundation Model Selection in Remote Sensing",
        "link": "/arxiv/2511.17442",
        "arxiv_id": "2511.17442",
        "authors": "Binger Chen, Tacettin Emre Bök, Behnood Rasti, Volker Markl, Begüm Demir",
        "summary": "Foundation Models (FMs) are increasingly used in remote sensing (RS) for tasks such as environmental monitoring, disaster assessment, and land-use mapping. These models include unimodal vision encoders trained on a single data modality and multimodal architectures trained on combinations of SAR, multispectral, hyperspectral, and image-text data. They support diverse RS tasks including semantic segmentation, image classification, change detection, and visual question answering. However, selecting an appropriate remote sensing foundation model (RSFM) remains difficult due to scattered documentation, heterogeneous formats, and varied deployment constraints. We introduce the RSFM Database (RS-FMD), a structured resource covering over 150 RSFMs spanning multiple data modalities, resolutions, and learning paradigms. Built on RS-FMD, we present REMSA, the first LLM-based agent for automated RSFM selection from natural language queries. REMSA interprets user requirements, resolves missing constraints, ranks candidate models using in-context learning, and provides transparent justifications. We also propose a benchmark of 75 expert-verified RS query scenarios, producing 900 configurations under an expert-centered evaluation protocol. REMSA outperforms several baselines, including naive agents, dense retrieval, and unstructured RAG-based LLMs. It operates entirely on publicly available metadata and does not access private or sensitive data.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-11-21",
        "category": "cs.AI",
        "crawl_time": "2025-11-24T11:00:05.620468",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是**构建一个名为REMSA的LLM智能体**，用于自动化遥感基础模型的选择。它不是简单地将一个现成的LLM或智能体框架应用到遥感领域，而是提出了一个具有特定工作流程（解释需求、解决约束、排名模型、提供理由）的新智能体框架。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。它不属于“非演化型应用”，因为其创新点在于智能体本身的设计，而非应用领域。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **核心范式**: 明确提出了一个 `LLM-based Agent` (REMSA)。 - **智能体能力**: 展现了典型的智能体能力。它使用了**工具**（`Tool Use`），即RS-FMD数据库。它执行了**规划**（`Planning`），通过多步推理（解释用户查询、解决缺失约束、对候选模型进行排名）来完成一个复杂的任务。 3.  **第三步：排除标准** - 论文没有触及主要的排除标准。 - **安全与对齐**: 论文焦点是模型选择，而非安全、对齐或可解释性。 - **多模态与视觉**: 虽然论文的应用领域是“遥感”，这通常与视觉和多模态相关，但论文的**核心贡献**并非开发新的视觉模型或多模态技术。REMSA智能体处理的是关于这些模型的**元数据**（“operates entirely on publicly available metadata”），而不是图像像素本身。因此，视觉/多模态是智能体操作的**环境背景**，而不是研究的核心主题，故不触发排除规则。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文详细描述了REMSA如何通过一系列步骤来完成模型选择任务。这完全符合“保留”关于“智能体如何进行规划或在复杂任务中进行多步推理”的论文的规则。它不是在改进LLM的基础数学或逻辑推理能力，而是在构建一个应用这些能力的智能体框架。 **最终决策**: 综合以上分析，该论文的核心贡献在于构建了一个具备工具使用和规划能力的单智能体（REMSA），以解决一个复杂的知识密集型任务。它精准地落在了我的研究焦点“单智能体”方向，特别是“规划”和“工具使用”子方向上。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#50",
        "title": "UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task Accuracy to Operational Reliability",
        "link": "/arxiv/2511.17131",
        "arxiv_id": "2511.17131",
        "authors": "Horia Cristescu, Charles Park, Trong Canh Nguyen, Sergiu Talmacel, Alexandru-Gabriel Ilie, Stefan Adam",
        "summary": "While current Computer Use Agent (CUA) benchmarks measure task completion effectively, they provide limited assessment of enterprise deployment readiness, emphasizing functional correctness over the operational reliability required for production systems. We present UI-CUBE (UiPath Computer Use BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty tiers designed to expose fundamental architectural limitations in current CUAs. Our evaluation covers simple UI interactions (136 tasks) and complex workflows including copy-paste tasks (50 tasks) and enterprise application scenarios (40 tasks), with systematic interface variation coverage, multi-resolution testing and automated validation of task success through the application state. Evaluation of five state-of-the-art models reveals a sharp capability cliff rather than gradual performance degradation. Simple UI interactions achieve 67-85% success rates (compared to 97.9% human performance), but complex workflows drop precipitously to 9-19%. Human evaluators with no prior application experience achieve only 61.2% on complex tasks despite near-perfect performance on simple tasks, establishing realistic performance ceilings. This discontinuous performance pattern -- where agents achieve 68-87% of human performance on simple tasks but only 15-32% on complex workflows -- indicates fundamental architectural limitations in memory management, hierarchical planning, and state coordination rather than incremental capability gaps addressable through better training or prompting. UI-CUBE functions as an enterprise-readiness diagnostic, revealing that while current CUAs can manipulate individual interface elements, they cannot yet function as reliable workflow automation tools. These findings provide architectural insights essential for developing production-ready CUAs capable of managing complex, multi-step enterprise processes.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-21",
        "category": "cs.AI",
        "crawl_time": "2025-11-24T11:00:05.650760",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - 论文的核心贡献是提出了一个名为UI-CUBE的基准测试，用于评估计算机使用智能体（CUA）的运营可靠性。 - 虽然论文本身没有构建一个新的LLM智能体，但其核心目标与“构建、改进或演化LLM智能体”高度一致。它不是将智能体作为工具去解决一个外部领域问题（如金融、医疗），而是**对智能体本身进行深度剖析和评估**，旨在揭示其架构上的根本性缺陷。 - 论文明确指出，其发现为“开发生产就绪的CUA”提供了“架构见解”，这直接指向了“改进LLM智能体”这一核心目标。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文的研究对象是“Computer Use Agent (CUA)”，完全属于`Agentic AI`和`LLM-based Agents`的范畴。 - 论文的核心发现指出了当前智能体在`Planning`（分层规划）、`Memory`（记忆管理）和状态协调方面的根本性局限。这些都是单智能体研究的核心能力。 - 智能体与UI交互本质上是一种`Tool Use`。 3.  **第三步：排除标准** - 论文的主要贡献不是关于`Safety`、`Alignment`或`Interpretability`，而是关于智能体的能力和可靠性，因此不触犯安全与对齐的排除标准。 - 论文研究的是计算机使用智能体，视觉（UI理解）是其感知环境的工具，但研究的核心是智能体的整体架构和可靠性，而非视觉模型本身。这符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”的例外情况。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文深入探讨了智能体在复杂工作流中的规划失败问题，并指出了“分层规划”是关键瓶颈。这完全符合“保留”关于智能体如何进行规划的研究的规则。它的贡献不是提出一种新的规划算法，而是通过严谨的基准测试揭示了现有规划能力的不足，为未来改进指明了方向。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献虽然是一个基准，但其本质是**推动LLM智能体演化和改进的关键性研究**。它通过系统性的评估，精准地指出了当前智能体架构在记忆、规划和状态管理上的核心短板。这些洞见对于任何希望构建更强大、更可靠的LLM智能体的研究者来说都是至关重要的。因此，这篇论文完全符合“改进LLM智能体”的研究目标，应该被保留。"
    },
    {
        "index": "#91",
        "title": "AutoBackdoor: Automating Backdoor Attacks via LLM Agents",
        "link": "/arxiv/2511.16709",
        "arxiv_id": "2511.16709",
        "authors": "Yige Li, Zhe Li, Wei Zhao, Nay Myat Min, Hanxun Huang, Xingjun Ma, Jun Sun",
        "summary": "Backdoor attacks pose a serious threat to the secure deployment of large language models (LLMs), enabling adversaries to implant hidden behaviors triggered by specific inputs. However, existing methods often rely on manually crafted triggers and static data pipelines, which are rigid, labor-intensive, and inadequate for systematically evaluating modern defense robustness. As AI agents become increasingly capable, there is a growing need for more rigorous, diverse, and scalable \\textit{red-teaming frameworks} that can realistically simulate backdoor threats and assess model resilience under adversarial conditions. In this work, we introduce \\textsc{AutoBackdoor}, a general framework for automating backdoor injection, encompassing trigger generation, poisoned data construction, and model fine-tuning via an autonomous agent-driven pipeline. Unlike prior approaches, AutoBackdoor uses a powerful language model agent to generate semantically coherent, context-aware trigger phrases, enabling scalable poisoning across arbitrary topics with minimal human effort. We evaluate AutoBackdoor under three realistic threat scenarios, including \\textit{Bias Recommendation}, \\textit{Hallucination Injection}, and \\textit{Peer Review Manipulation}, to simulate a broad range of attacks. Experiments on both open-source and commercial models, including LLaMA-3, Mistral, Qwen, and GPT-4o, demonstrate that our method achieves over 90\\% attack success with only a small number of poisoned samples. More importantly, we find that existing defenses often fail to mitigate these attacks, underscoring the need for more rigorous and adaptive evaluation techniques against agent-driven threats as explored in this work. All code, datasets, and experimental configurations will be merged into our primary repository at https://github.com/bboylyg/BackdoorLLM.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-11-20",
        "category": "cs.AI",
        "crawl_time": "2025-11-24T11:00:05.692487",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 `AutoBackdoor` 的**新框架**，其核心是一个**自主的LLM智能体**。该智能体被设计用来执行一个复杂的多步骤任务：自动化后门攻击（包括触发器生成、数据投毒、模型微调）。论文的核心贡献在于**构建了这个智能体驱动的自动化流水线**，而不是简单地将一个已有的智能体作为工具应用。因此，它符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (标题和摘要中多次提及), `Agentic AI` (其自主流水线是Agentic AI的体现)。 - **智能体能力**: `Planning` (智能体需要规划并执行“生成触发器 -> 构建数据 -> 微调模型”这一系列复杂步骤)。虽然摘要未明确提及`Tool Use`，但其自动化流水线暗示了智能体可能调用外部工具或API来完成数据构建和模型微调等子任务。 3.  **第三步：排除标准** - **安全与对齐**: 这是本案例中最关键的一点。虽然论文的主题是`Security`（后门攻击），但筛选标准的关键在于“**主要贡献**”是什么。这篇论文的主要贡献**不是**一种新的攻击理论、防御方法或安全漏洞分析，而是**一种利用LLM智能体来实现攻击自动化的新方法论和新框架**。它研究的重点是“如何构建一个能干这件事的智能体”，而不是“这件事本身的安全细节”。因此，它没有因为“安全与对齐”主题而被排除。它属于“使用智能体进行红队测试”的范畴，其贡献在于智能体的能力构建，而非安全分析本身。 - **多模态与视觉**: 论文不涉及此内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文完全符合“保留”条件。它描述了一个智能体如何进行多步骤的规划和执行（`autonomous agent-driven pipeline`），这正是Agentic AI中规划能力的体现，远超于提升LLM本身的基础推理能力。 **最终决策**: 综合以上分析，这篇论文的核心贡献是**构建了一个能够自主规划和执行复杂对抗性任务的LLM智能体框架**。尽管其应用场景是网络安全，但其研究焦点和方法论完全属于“LLM智能体及其演化”的范畴，特别是“单智能体”方向下的规划与自动化执行。因此，该论文**符合**你的研究范围。"
    }
]