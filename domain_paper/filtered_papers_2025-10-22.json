[
    {
        "index": "#10",
        "title": "Learning to Make Friends: Coaching LLM Agents toward Emergent Social Ties",
        "link": "/arxiv/2510.19299",
        "arxiv_id": "2510.19299",
        "authors": "Philipp J. Schneider, Lin Tian, Marian-Andrei Rizoiu",
        "summary": "Can large language model (LLM) agents reproduce the complex social dynamics that characterize human online behavior -- shaped by homophily, reciprocity, and social validation -- and what memory and learning mechanisms enable such dynamics to emerge? We present a multi-agent LLM simulation framework in which agents repeatedly interact, evaluate one another, and adapt their behavior through in-context learning accelerated by a coaching signal. To model human social behavior, we design behavioral reward functions that capture core drivers of online engagement, including social interaction, information seeking, self-presentation, coordination, and emotional support. These rewards align agent objectives with empirically observed user motivations, enabling the study of how network structures and group formations emerge from individual decision-making. Our experiments show that coached LLM agents develop stable interaction patterns and form emergent social ties, yielding network structures that mirror properties of real online communities. By combining behavioral rewards with in-context adaptation, our framework establishes a principled testbed for investigating collective dynamics in LLM populations and reveals how artificial agents may approximate or diverge from human-like social behavior.",
        "subjects": "Artificial Intelligence, Multiagent Systems, Social and Information Networks",
        "date": "2025-10-22",
        "category": "cs.MA",
        "crawl_time": "2025-10-23T11:00:03.501531",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献精准地命中了您设定的“多智能体”和“自我演化”两个方向。 以下是根据您的筛选标准进行的详细判断过程： 1.  **第一步：核心判断** *   **论文本质**: 论文的核心是提出一个**全新的多智能体LLM模拟框架**（\"We present a multi-agent LLM simulation framework\"）。这个框架旨在让智能体通过互动、评估和适应来产生复杂的社会动态。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。 *   **排除项检查**: 论文并非将已有框架简单应用于特定领域，而是构建框架本身来研究社会动态这一通用问题。它研究的不是LLM的基础Token预测能力，而是智能体在社会环境中的行为。因此，它不属于任何排除类别。 2.  **第二步：正面指标** *   论文摘要中包含了大量您关注的核心范式和能力： *   **多智能体**: `Multi-agent LLM simulation framework`, `interact`, `evaluate one another`, `collective dynamics`, `LLM populations`。 *   **自我演化**: `adapt their behavior`, `in-context learning`, `emergent social ties`, `network structures...emerge`。智能体通过“指导信号”加速的“上下文内学习”来适应，这是一种明确的自我演化机制。 *   **智能体能力**: `Memory`（论文明确探讨了记忆机制），`Self-Correction/Reflection`（通过评估彼此和适应行为来体现）。 *   **多智能体**: `Collaboration`, `Communication`, `Social Learning`（整个研究都是关于社会学习和互动的）。 3.  **第三步：排除标准** *   论文的主要贡献是关于智能体社会行为的建模和演化框架，而非安全、对齐、可解释性或多模态视觉。因此，它不触及任何排除标准。 4.  **第四步：处理特殊和模糊情况** *   **自我演化的应用**: 这篇论文是“自我演化”方向的一个绝佳例子。它提出了“行为奖励函数”和“指导信号”作为新的演化机制，即使其应用场景是“社会动态模拟”，根据您的规则（“如果论文的核心是提出一种新的‘自我演化’机制...也应该保留”），这恰恰是需要保留的高质量论文。 **最终决策**: 这篇论文的核心贡献在于构建了一个新颖的多智能体框架，并引入了“指导信号”和“行为奖励”等机制，来驱动LLM智能体在模拟社会环境中进行互动、学习和演化，最终涌现出复杂的社会关系。这完美契合您“LLM智能体及其演化”的研究课题，特别是“多智能体”和“自我演化”两大核心方向。因此，这篇论文应被**保留 (True)**。"
    },
    {
        "index": "#3",
        "title": "ColorAgent: Building A Robust, Personalized, and Interactive OS Agent",
        "link": "/arxiv/2510.19386",
        "arxiv_id": "2510.19386",
        "authors": "Ning Li, Qiqiang Lin, Zheng Wu, Xiaoyun Mo, Weiming Zhang, Yin Zhao, Xiangmou Qu, Jiamu Zhou, Jun Wang, Congmin Zheng, Yuanyi Song, Hongjiang Chen, Heyuan Huang, Jihong Wang, Jiaxin Yin, Jingwei Yu, Junwei Liao, Qiuying Peng, Xingyu Lou, Jun Wang, Weiwen Liu, Zhuosheng Zhang, Weinan Zhang",
        "summary": "With the advancements in hardware, software, and large language model technologies, the interaction between humans and operating systems has evolved from the command-line interface to the rapidly emerging AI agent interactions. Building an operating system (OS) agent capable of executing user instructions and faithfully following user desires is becoming a reality. In this technical report, we present ColorAgent, an OS agent designed to engage in long-horizon, robust interactions with the environment while also enabling personalized and proactive user interaction. To enable long-horizon interactions with the environment, we enhance the model's capabilities through step-wise reinforcement learning and self-evolving training, while also developing a tailored multi-agent framework that ensures generality, consistency, and robustness. In terms of user interaction, we explore personalized user intent recognition and proactive engagement, positioning the OS agent not merely as an automation tool but as a warm, collaborative partner. We evaluate ColorAgent on the AndroidWorld and AndroidLab benchmarks, achieving success rates of 77.2% and 50.7%, respectively, establishing a new state of the art. Nonetheless, we note that current benchmarks are insufficient for a comprehensive evaluation of OS agents and propose further exploring directions in future work, particularly in the areas of evaluation paradigms, agent collaboration, and security. Our code is available at https://github.com/MadeAgents/mobile-use.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computation and Language",
        "date": "2025-10-22",
        "category": "cs.MA",
        "crawl_time": "2025-10-23T11:00:03.499576",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献与你的三大研究方向高度契合。判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的本质是**构建、改进和演化LLM智能体**。标题和摘要明确指出，论文的核心贡献是“Building A... OS Agent”并提出了一种新的智能体框架“ColorAgent”。这并非将现有智能体作为工具应用到特定领域，而是关于智能体本身的设计、训练和架构创新，完全符合“保留”标准。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量你的核心关注点： *   **自我演化**: 论文明确提到通过“**self-evolving training**”（自我演化训练）来增强模型能力。这直接命中了你的“Self-Evolving”研究方向。 *   **多智能体**: 论文开发了“a tailored **multi-agent framework**”（定制化的多智能体框架）来保证通用性、一致性和鲁棒性。这直接命中了你的“Multi-Agent”研究方向。 *   **单智能体**: 论文致力于实现智能体与环境的“**long-horizon**”交互，这涉及到复杂的**规划**能力。同时，作为一个OS智能体，其核心能力必然包含**工具使用**（与应用程序交互）。 3.  **第三步：排除标准 (不构成排除)** *   **安全与对齐**: 摘要中确实提到了“security”，但明确将其归类为“**future work**”（未来工作），而非本文的核心贡献。本文的核心是构建智能体本身，因此不构成排除依据。 *   **多模态与视觉**: 论文未提及视觉是其核心研究内容。OS智能体可能会处理屏幕信息（视觉），但根据规则，只要这不是研究的核心，而是智能体感知环境的工具，就可以接受。 4.  **第四步：处理特殊情况 (进一步确认)** *   **自我演化的应用**: 这篇论文完美地符合了“例外”情况。它提出了一种新的“自我演化训练”机制，并将其应用在OS这个特定领域。根据你的规则，即使应用在特定领域，只要核心是提出新的自我演化机制，就应该保留。本文正是如此。 **综合结论**: 这篇论文的核心贡献是构建了一个名为ColorAgent的OS智能体，并在此过程中提出了**自我演化训练方法**和**多智能体框架**。这精准地覆盖了你研究的三个核心方向：**单智能体（规划与交互）、多智能体（框架设计）和自我演化（训练机制）**。因此，这篇论文是与你研究课题高度相关的前沿论文，应予以保留。"
    },
    {
        "index": "#4",
        "title": "ToolDreamer: Instilling LLM Reasoning Into Tool Retrievers",
        "link": "/arxiv/2510.19791",
        "arxiv_id": "2510.19791",
        "authors": "Saptarshi Sengupta, Zhengyu Zhou, Jun Araki, Xingbo Wang, Bingqing Wang, Suhang Wang, Zhe Feng",
        "summary": "Tool calling has become increasingly popular for Large Language Models (LLMs). However, for large tool sets, the resulting tokens would exceed the LLM's context window limit, making it impossible to include every tool. Hence, an external retriever is used to provide LLMs with the most relevant tools for a query. Existing retrieval models rank tools based on the similarity between a user query and a tool description (TD). This leads to suboptimal retrieval as user requests are often poorly aligned with the language of TD. To remedy the issue, we propose ToolDreamer, a framework to condition retriever models to fetch tools based on hypothetical (synthetic) TD generated using an LLM, i.e., description of tools that the LLM feels will be potentially useful for the query. The framework enables a more natural alignment between queries and tools within the language space of TD's. We apply ToolDreamer on the ToolRet dataset and show that our method improves the performance of sparse and dense retrievers with and without training, thus showcasing its flexibility. Through our proposed framework, our aim is to offload a portion of the reasoning burden to the retriever so that the LLM may effectively handle a large collection of tools without inundating its context window.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-23T11:00:04.094765",
        "filter_reason": "这篇论文符合我的研究范围。以下是详细的判断过程： 1.  **第一步：核心判断** *   论文的本质是什么？论文的核心是提出 **ToolDreamer**，一个**用于改进LLM智能体工具检索能力的新框架**。它解决的是当工具库过大时，LLM如何高效、准确地找到合适工具这一关键问题。 *   **判断**：**保留**。这篇论文不是简单地将LLM或智能体作为工具应用到一个新领域，而是**直接聚焦于改进LLM智能体的一个核心组件——工具使用机制**。它提出了一种新的方法论，通过生成假设的工具描述来对齐查询和工具，这属于“构建或改进LLM智能体”的范畴。 2.  **第二步：正面指标** *   论文摘要中包含了多个我的核心关注点： *   **智能体能力**: `Tool Use / Tool Augmentation` 是论文的绝对核心。标题、摘要多次提及 \"Tool calling\", \"Tool Retrievers\", \"large tool sets\"。 *   **推理能力**: 论文明确提到 \"Instilling LLM Reasoning Into Tool Retrievers\" 和 \"offload a portion of the reasoning burden to the retriever\"，表明其工作与智能体的推理过程紧密相关。 *   **判断**：论文高度匹配“单智能体”方向下的“工具使用”能力，并涉及推理，正面指标非常明确。 3.  **第三步：排除标准** *   论文的主要内容不涉及 `Safety`, `Security`, `Alignment` 等安全与对齐问题。 *   论文也未以 `Vision`, `MLLMs` 等多模态内容为研究核心，LLM生成的文本描述是研究的重点。 *   **判断**：该论文没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 这篇论文关于“推理”的部分，完全符合“**保留**”的条件。它不是在研究如何让LLM更好地解数学题（非Agentic的推理），而是在研究智能体如何通过推理来**选择和规划工具的使用**，这是智能体自主行为的关键一步。ToolDreamer框架本身就是一种辅助智能体进行工具选择推理的新方法。 5.  **第五步：最终决策** *   **综合分析**：该论文的核心贡献是提出了一种新颖的框架（ToolDreamer）来增强LLM智能体的工具检索能力。这直接属于我研究范围中“单智能体”的“工具使用”子方向。它构建和改进了智能体的一个核心功能模块，而非简单应用或研究底层基础设施。因此，该论文与我的研究目标高度契合。 **最终结论**：该论文通过提出一种新框架来增强LLM智能体的一个核心功能（工具使用），完全符合我筛选关于“构建、改进或演化LLM智能体”论文的核心目标。"
    },
    {
        "index": "#25",
        "title": "VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos",
        "link": "/arxiv/2510.19488",
        "arxiv_id": "2510.19488",
        "authors": "Dunjie Lu, Yiheng Xu, Junli Wang, Haoyuan Wu, Xinyuan Wang, Zekun Wang, Junlin Yang, Hongjin Su, Jixuan Chen, Junda Chen, Yuchen Mao, Jingren Zhou, Junyang Lin, Binyuan Hui, Tao Yu",
        "summary": "Training computer-use agents requires massive amounts of GUI interaction data, but manually annotating action trajectories at scale is prohibitively expensive. We present VideoAgentTrek, a scalable pipeline that automatically mines training data from publicly available screen-recorded videos at web scale, eliminating the need for manual annotation. Our approach addresses a key challenge: raw videos contain implicit demonstrations but lack explicit action labels. To solve this, we develop Video2Action, an inverse dynamics module (IDM) with two components: (1) a video grounding model that detects and localizes GUI actions with precise temporal boundaries and context, and (2) an action-content recognizer that extracts structured parameters like click coordinates and typed text with high fidelity. Applied to 39,000 YouTube tutorial videos, our pipeline generates 1.52 million interaction steps automatically. We leverage this data through continued pretraining followed by supervised fine-tuning. On OSWorld-Verified, our approach improves task success rates from 9.3% (SFT-only baseline) to 15.8%, a 70% relative improvement. On AgentNetBench, step accuracy increases from 64.1% to 69.3%. Our results demonstrate that passive internet videos can be transformed into high-quality supervision for computer-use agents, providing a scalable alternative to expensive manual annotation.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-23T11:00:04.120577",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——这篇论文的本质是什么？** 这篇论文的核心贡献是构建了一个名为 `VideoAgentTrek` 的**可扩展数据生成管道**，用于训练**计算机使用智能体（computer-use agents）**。它提出了一种新的方法论（`Video2Action`），通过从无标签视频中自动挖掘和标注GUI交互数据，来解决训练智能体时数据稀缺的瓶颈问题。论文的本质是**改进LLM智能体的构建方法**，具体来说是改进其训练数据的获取方式，这直接服务于“构建、改进或演化LLM智能体”这一核心目标。因此，它不属于“非演化型应用”或“非Agentic的推理”，应**保留**。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文包含了多个核心关注点： - **核心范式**: 论文明确以 `LLM-based Agents`（计算机使用智能体）为研究对象。 - **智能体能力**: 论文的研究目标是提升智能体在计算机环境中的**工具使用（Tool Use）**能力，即通过GUI（图形用户界面）与计算机进行交互。其评估指标（任务成功率、步骤准确率）直接衡量了智能体执行复杂任务的能力。 - **演化机制**: 虽然论文没有提出智能体在运行时的自我演化，但它提出了一种**通过大规模数据驱动来“演化”或“改进”智能体能力**的机制。通过持续预训练（continued pretraining），智能体从海量视频中学习，实现了能力的迭代提升。这可以被视为一种模型层面的演化路径。 **第三步：排除标准——是否为我的研究焦点之外？** 论文不涉及任何排除标准： - **安全与对齐**: 论文未提及安全、对齐、可解释性或幻觉等问题。 - **多模态与视觉**: 论文虽然处理视频数据，但其目的并非研究视觉本身。在这里，**视频是作为智能体感知和学习的环境数据源**，而不是研究的核心。核心是如何从这些数据中提取出用于训练智能体的结构化动作信息。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外条款。 **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的研究成果（训练出的智能体）在OSWorld等基准测试上表现更好，这些测试本身就包含复杂的规划和多步推理。因此，该工作直接促进了智能体规划和推理能力的提升，属于应保留的范畴。 - **自我演化的应用**: 这不属于“自我演化的应用”的特殊情况，但其核心贡献——提出一种新的、可扩展的智能体训练和改进方法——本身就完全符合您的研究目标。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种创新的方法论，通过自动化地从海量视频中挖掘训练数据，来**构建和改进**能够使用计算机的LLM智能体。它直接解决了Agentic AI发展中一个关键的基础设施问题（数据获取），并显著提升了智能体的工具使用和任务执行能力。因此，这篇论文与您关于“LLM智能体及其演化”的研究课题高度相关，应被**保留**。"
    },
    {
        "index": "#48",
        "title": "SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets",
        "link": "/arxiv/2510.19247",
        "arxiv_id": "2510.19247",
        "authors": "Ziwei Wang, Jiayuan Su, Mengyu Zhou, Huaxing Zeng, Mengni Jia, Xiao Lv, Haoyu Dong, Xiaojun Ma, Shi Han, Dongmei Zhang",
        "summary": "Understanding and reasoning over complex spreadsheets remain fundamental challenges for large language models (LLMs), which often struggle with accurately capturing the complex structure of tables and ensuring reasoning correctness. In this work, we propose SheetBrain, a neuro-symbolic dual workflow agent framework designed for accurate reasoning over tabular data, supporting both spreadsheet question answering and manipulation tasks. SheetBrain comprises three core modules: an understanding module, which produces a comprehensive overview of the spreadsheet - including sheet summary and query-based problem insight to guide reasoning; an execution module, which integrates a Python sandbox with preloaded table-processing libraries and an Excel helper toolkit for effective multi-turn reasoning; and a validation module, which verifies the correctness of reasoning and answers, triggering re-execution when necessary. We evaluate SheetBrain on multiple public tabular QA and manipulation benchmarks, and introduce SheetBench, a new benchmark targeting large, multi-table, and structurally complex spreadsheets. Experimental results show that SheetBrain significantly improves accuracy on both existing benchmarks and the more challenging scenarios presented in SheetBench. Our code is publicly available at https://github.com/microsoft/SheetBrain.",
        "subjects": "Computation and Language",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-23T11:00:04.163189",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了 **SheetBrain，一个神经符号双工作流智能体框架**。它不是简单地将现有LLM或智能体框架应用于电子表格领域，而是**构建了一个新的、结构化的智能体方法论**来解决特定类型的复杂推理问题。该框架包含理解、执行和验证三个模块，这本身就是对智能体架构的创新。因此，它不属于“非演化型应用”的排除范围。 2.  **第二步：正面指标——高度相关** 论文命中了多个核心关注点： *   **核心范式**: 论文明确使用了 `Agent framework` 这一术语，其本质是 `LLM-based Agents`。 *   **智能体能力**: *   **工具使用**: 论文的执行模块明确集成了 `Python sandbox` 和 `Excel helper toolkit`，这是典型的 `Tool Use` 能力。 *   **自我反思/自我修正**: 论文的验证模块会 `verifies the correctness of reasoning and answers, triggering re-execution when necessary`。这完全符合 `Self-Correction` 和 `Self-Reflection` 的定义，是智能体自主迭代和改进的关键机制。 *   **规划**: 虽然“规划”一词未在摘要中直接出现，但“理解模块”通过生成“comprehensive overview”和“problem insight to guide reasoning”，实际上是在执行一种高级的规划和任务分解，为后续的执行和验证提供指导。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于智能体的架构和推理框架，而不是安全、对齐、可解释性或多模态。因此，它没有触及任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留条件** *   **推理/规划**: 论文研究的推理是嵌入在智能体框架中的。它不是在提升LLM本身的基础推理能力，而是在构建一个**能让LLM在复杂任务中进行准确多步推理的系统**（通过理解、执行、验证的循环）。这符合“保留”关于智能体推理的规则。 *   **自我演化的应用**: 论文中的“验证-重新执行”机制是一种**即时性的自我完善**，属于自我演化的范畴。虽然它应用于电子表格领域，但其核心是提出这种带有自我修正能力的智能体框架，因此根据规则应予以保留。 **最终决策**: 这篇论文的核心贡献在于**构建了一个具备工具使用和自我修正能力的LLM智能体框架**。它直接对应你的研究焦点“单智能体”中的“工具使用”和“自我反思”子方向。尽管其应用场景是电子表格，但其方法论和框架设计具有通用性，是对Agentic AI领域的前沿探索。因此，这篇论文与你的研究目标高度契合，应被筛选出来。"
    },
    {
        "index": "#36",
        "title": "AgenticMath: Enhancing LLM Reasoning via Agentic-based Math Data Generation",
        "link": "/arxiv/2510.19361",
        "arxiv_id": "2510.19361",
        "authors": "Xianyang Liu, Yilin Liu, Shuai Wang, Hao Cheng, Andrew Estornell, Yuzhi Zhao, Jiaheng Wei",
        "summary": "The creation of high-quality datasets to improve Large Language Model (LLM) reasoning remains a significant challenge, as current methods often suffer from generating low-quality/incorrect answers and limited information richness from available data sources. To address this, we propose AgenticMath, a novel agentic pipeline for generating high-quality mathematical question-answer pairs to enhance the supervised fine-tuning of LLMs. Our method operates through four stages: (1) Seed Question Filter that selects questions with high information richness, complexity, and clarity; (2) an Agentic Question Rephrase step that employs a multi-agent system to generate diverse, logically consistent paraphrases; (3) an Answer Augment step where rewrite answers using chain-of-thought reasoning to enhance numerical and logical correctness, without reliance on human-provided labels; and (4) a final Question and Answer Evaluation that retains only the most superior pairs. Extensive experiments demonstrate that, fine-tuning 3B-8B parameter LLMs on AgenticMath generated datasets (comprising only 30-60K math samples) achieves competitive or superior performance on diverse in domain and out-of-domain mathematical reasoning benchmarks compared to baselines trained on much more data (e.g., 400K or 2.3M samples). Our work demonstrates that targeted, high-quality data generation is a more efficient path to improving mathematical reasoning in LLMs than large-scale, low-quality alternatives.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-23T11:00:04.130832",
        "filter_reason": "这篇论文符合我的研究范围，应当保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个已有的智能体框架应用到数学领域，而是**核心贡献在于构建了一个新颖的、名为 \"AgenticMath\" 的智能体流程**。这个流程本身就是一个多智能体系统，其目的是为了生成高质量数据。这与我的核心目标“构建、改进或演化 LLM智能体”完全契合。它不属于“非演化型应用”，因为它的创新点在于智能体流程本身，而非在数学领域的应用结果。它也不属于“非Agentic的推理”，因为它没有提出新的数学推理方法，而是用智能体来生成数据。 2.  **第二步：正面指标** - 论文标题和摘要中明确包含了多个核心范式和能力的关键词，如 `Agentic-based`、`agentic pipeline`、`multi-agent system`。特别是 `multi-agent system`，直接命中了我的第二个研究焦点“多智能体”。整个流程包含多个步骤的迭代和评估，体现了智能体处理复杂任务的结构化特征。 3.  **第三步：排除标准** - 论文内容不涉及 `Safety`、`Alignment` 或 `Interpretability` 等安全问题。同时，它也没有涉及多模态或视觉。因此，不触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**：这是一个关键的判断点。论文的目标是“enhance LLM reasoning”，这看起来像是关于提高LLM基础推理能力的。然而，论文的**方法**并非提出一种新的非Agentic推理技巧（如CoT变体），而是**构建了一个新的Agentic框架**来完成数据生成这一复杂任务。根据筛选规则“如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）”则应保留。AgenticMath流程正是一个用于解决“生成高质量数据”这一复杂多步任务的**新Agentic框架**，因此应该保留。 5.  **第五步：最终决策** - 综合来看，尽管论文的最终应用场景是数学数据生成，但其**核心贡献和方法论是一个创新的多智能体系统**。这篇论文研究的不是“如何让LLM更好地做数学题”，而是“**如何构建一个智能体系统来为LLM创造更好的学习材料**”。这完全属于我研究范围中的“多智能体”方向，即构建和改进智能体本身。因此，这篇论文是高度相关的前沿研究，应当保留。"
    },
    {
        "index": "#50",
        "title": "DiSRouter: Distributed Self-Routing for LLM Selections",
        "link": "/arxiv/2510.19208",
        "arxiv_id": "2510.19208",
        "authors": "Hang Zheng, Hongshen Xu, Yongkai Lin, Shuai Fan, Lu Chen, Kai Yu",
        "summary": "The proliferation of Large Language Models (LLMs) has created a diverse ecosystem of models with highly varying performance and costs, necessitating effective query routing to balance performance and expense. Current routing systems often rely on a centralized external router trained on a fixed set of LLMs, making them inflexible and prone to poor performance since the small router can not fully understand the knowledge boundaries of different LLMs. We introduce DiSRouter (Distributed Self-Router), a novel paradigm that shifts from centralized control to distributed routing. In DiSRouter, a query traverses a network of LLM agents, each independently deciding whether to answer or route to other agents based on its own self-awareness, its ability to judge its competence. This distributed design offers superior flexibility, scalability, and generalizability. To enable this, we propose a two-stage Self-Awareness Training pipeline that enhances each LLM's self-awareness. Extensive experiments demonstrate that DiSRouter significantly outperforms existing routing methods in utility across various scenarios, effectively distinguishes between easy and hard queries, and shows strong generalization to out-of-domain tasks. Our work validates that leveraging an LLM's intrinsic self-awareness is more effective than external assessment, paving the way for more modular and efficient multi-agent systems.",
        "subjects": "Computation and Language",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-23T11:00:04.164159",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** - 论文的核心贡献是提出了一种名为 DiSRouter 的新范式，这是一个**构建多智能体系统的方法论和框架**。它不是将已有框架应用到某个领域，而是从零开始设计了一个由LLM智能体构成的分布式网络来解决查询路由问题。这完全符合“核心贡献在于构建、改进或演化LLM智能体”的要求。它不属于非演化型应用、非Agentic推理或基础设施研究。 2.  **第二步：正面指标 (高度相关)** - 论文包含了多个你的核心关注点： *   **多智能体**: 论文明确提出了一个“LLM智能体网络”，并指出其工作“为构建更加模块化和高效的多智能体系统铺平了道路”。智能体之间通过传递查询进行**协作**和**通信**。 *   **单智能体能力**: 论文的核心机制是每个智能体的“自我意识”，这属于**自我反思** 和**自我修正** 的范畴。智能体基于这种元认知能力来“判断其能力”并做出决策，这是一种高级的智能体**规划** 和决策能力。 *   **演化机制**: 虽然不是代际演化，但论文提出的“自我意识训练”流程旨在**增强每个LLM的自我意识**，这是一种对智能体核心能力的**改进** 和**迭代优化**，与自我演化的思想紧密相关。 3.  **第三步：排除标准 (未触发)** - 论文的主要贡献是关于系统架构、性能和效率，不涉及安全、对齐、可解释性或多模态视觉等排除领域。 4.  **第四步：特殊/模糊情况处理 (符合保留条件)** - 论文中的推理是典型的**智能体推理**。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个让智能体自主决定“是回答还是路由”的决策框架。这完全符合“保留”关于智能体规划和多步推理研究的要求。 **总结**: DiSRouter论文的核心创新点在于构建了一个由具备自我反思能力的LLM智能体组成的分布式系统。它直接贡献于**多智能体**领域的协作与通信范式，并深入探讨了**单智能体**的自我意识与决策机制。这与你的研究课题“LLM智能体及其演化”高度契合，是一篇极具价值的前沿论文。"
    },
    {
        "index": "#66",
        "title": "Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search",
        "link": "/arxiv/2510.18939",
        "arxiv_id": "2510.18939",
        "authors": "Howard Yen, Ashwin Paranjape, Mengzhou Xia, Thejas Venkatesh, Jack Hessel, Danqi Chen, Yuhao Zhang",
        "summary": "Long-horizon agentic search requires iteratively exploring the web over long trajectories and synthesizing information across many sources, and is the foundation for enabling powerful applications like deep research systems. In this work, we show that popular agentic search frameworks struggle to scale to long trajectories primarily due to context limitations-they accumulate long, noisy content, hit context window and tool budgets, or stop early. Then, we introduce SLIM (Simple Lightweight Information Management), a simple framework that separates retrieval into distinct search and browse tools, and periodically summarizes the trajectory, keeping context concise while enabling longer, more focused searches. On long-horizon tasks, SLIM achieves comparable performance at substantially lower cost and with far fewer tool calls than strong open-source baselines across multiple base models. Specifically, with o3 as the base model, SLIM achieves 56% on BrowseComp and 31% on HLE, outperforming all open-source frameworks by 8 and 4 absolute points, respectively, while incurring 4-6x fewer tool calls. Finally, we release an automated fine-grained trajectory analysis pipeline and error taxonomy for characterizing long-horizon agentic search frameworks; SLIM exhibits fewer hallucinations than prior systems. We hope our analysis framework and simple tool design inform future long-horizon agents.",
        "subjects": "Computation and Language",
        "date": "2025-10-21",
        "category": "cs.CL",
        "crawl_time": "2025-10-23T11:00:04.219900",
        "filter_reason": "这篇论文完全符合您的筛选标准，其核心贡献在于**构建和改进LLM智能体**，属于您研究焦点中的“单智能体”方向。 1.  **第一步：核心判断 (保留)** - 论文的本质是提出一个名为 **SLIM (Simple Lightweight Information Management)** 的新**框架**，用于解决现有LLM智能体在执行长时程任务时遇到的上下文限制问题。这直接对应了“构建、改进LLM智能体的方法论或新框架”的保留标准。 - 它不是将智能体作为工具应用到某个特定领域（如生物、金融），而是专注于改进智能体本身的能力。因此，不属于“非演化型应用”的排除范围。 - 它的研究内容是智能体的行为框架（如何管理信息、如何使用工具），而非提升LLM底层的Token预测能力，因此不属于“非Agentic的推理”。 2.  **第二步：正面指标 (高度匹配)** - 论文明确涉及了您关注的核心范式和能力： - **Agentic AI / LLM-based Agents**: 标题和摘要中多次出现 \"agentic search\"。 - **Planning**: 论文研究的是 \"Long-horizon agentic search\"，这本质上是智能体在复杂任务中的多步规划与执行。 - **Tool Use / Tool Augmentation**: SLIM框架的核心改进之一就是将检索分离为不同的 \"search and browse tools\"，并优化了工具调用效率。 - **Memory**: SLIM通过 \"periodically summarizes the trajectory\" 来管理上下文，这是一种显式的记忆管理机制，旨在解决智能体在长序列任务中的遗忘和信息过载问题。 3.  **第三步：排除标准 (不适用)** - 论文虽然提到 \"SLIM exhibits fewer hallucinations\"，但这只是其新框架带来的一个**积极结果**，而非论文的**核心贡献**。论文的核心是SLIM这个框架本身，而不是提出一种新的抗幻觉技术。因此，它不属于以安全、对齐或幻觉为主要贡献的排除范围。 - 论文不涉及多模态、视觉或基础设施。 4.  **第四步：特殊和模糊情况 (清晰符合)** - 论文是关于“智能体如何进行规划或在复杂任务中进行多步推理”的典型范例。它提出的SLIM框架可以看作是一种新的、用于长时程任务的Agentic推理框架，与ReAct、ToT等一脉相承，但专注于解决信息管理这一瓶颈。 **总结**: 该论文的核心是提出一个改进单智能体在长时程任务中表现的新框架SLIM，其贡献点直接命中了您研究焦点中的“单智能体”方向，特别是规划、工具使用和记忆管理。它不是应用型研究，也不是基础模型或安全对齐研究，因此是您应该保留的高相关性前沿论文。"
    },
    {
        "index": "#84",
        "title": "Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1",
        "link": "/arxiv/2510.19600",
        "arxiv_id": "2510.19600",
        "authors": "Qianli Ma, Siyu Wang, Yilin Chen, Yinhao Tang, Yixiang Yang, Chang Guo, Bingjie Gao, Zhening Xing, Yanan Sun, Zhipeng Zhang",
        "summary": "In the quest for scientific progress, communicating research is as vital as the discovery itself. Yet, researchers are often sidetracked by the manual, repetitive chore of building project webpages to make their dense papers accessible. While automation has tackled static slides and posters, the dynamic, interactive nature of webpages has remained an unaddressed challenge. To bridge this gap, we reframe the problem, arguing that the solution lies not in a single command, but in a collaborative, hierarchical process. We introduce $\\textbf{AutoPage}$, a novel multi-agent system that embodies this philosophy. AutoPage deconstructs paper-to-page creation into a coarse-to-fine pipeline from narrative planning to multimodal content generation and interactive rendering. To combat AI hallucination, dedicated \"Checker\" agents verify each step against the source paper, while optional human checkpoints ensure the final product aligns perfectly with the author's vision, transforming the system from a mere tool into a powerful collaborative assistant. To rigorously validate our approach, we also construct $\\textbf{PageBench}$, the first benchmark for this new task. Experiments show AutoPage not only generates high-quality, visually appealing pages but does so with remarkable efficiency in under 15 minutes for less than \\$0.1. Code and dataset will be released at $\\href{https://mqleet.github.io/AutoPage_ProjectPage/}{Webpage}$.",
        "subjects": "Software Engineering, Artificial Intelligence, Computation and Language",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-23T11:00:04.238650",
        "filter_reason": "这篇论文完全符合我的研究范围，应予以保留。判断依据如下： 1.  **核心判断 (第一步):** *   论文的核心贡献是构建了一个名为 **AutoPage** 的新型**多智能体系统**，用于将学术论文转化为项目网页。它并非简单地使用一个已有的智能体框架去解决一个应用问题，而是**提出了一种新的、协作的、分层级的智能体框架方法论**。它将任务解构为“从粗到细的管道”，并设计了专门的“Checker”智能体。这完全符合“保留”标准中“构建LLM智能体、多智能体系统的方法论或新框架”的要求。虽然其应用场景是网页制作，但其本质是关于智能体系统架构的创新。 2.  **正面指标 (第二步):** *   论文明确包含了多个核心关注点： *   **多智能体系统 (Multi-Agent Systems):** 标题和摘要中直接点明。 *   **协作:** 标题中的 \"Human-Agent Collaborative\" 和摘要中的 \"collaborative, hierarchical process\" 都是其核心设计理念。 *   **规划:** 摘要中提到了 \"narrative planning\"，这是智能体规划能力的体现。 *   **自我修正:** 通过专门的 \"Checker\" 智能体来验证每一步输出，这是一种在多智能体系统框架内的纠错和验证机制。 3.  **排除标准 (第三步):** *   论文虽然提到了 \"combat AI hallucination\"（对抗AI幻觉），但这并非其主要研究贡献。其主要贡献是**提出一个系统架构**，而“Checker”智能体是这个架构中的一个**组件**，用来实现高质量输出。这与“主要贡献是关于幻觉检测或缓解的论文”有本质区别。 *   同样，论文提到了 \"multimodal content generation\"（多模态内容生成），但这只是智能体执行任务的一部分，是其**工具使用能力**的体现，而不是论文研究的核心。研究的核心是这个多智能体系统如何协同工作来完成整个流程。 4.  **特殊和模糊情况 (第四步):** *   这篇论文完美地诠释了“构建智能体”与“应用智能体”的区别。如果论文只是说“我们用GPT-4和ReAct方法生成了网页”，那它应该被排除。但本文设计了**新的智能体角色（Checker）**、**新的协作流程（coarse-to-fine pipeline）**和**新的人机协作模式**，这是对智能体系统本身的贡献，因此必须保留。 **总结:** 这篇论文的核心是提出了一种创新的**多智能体协作框架**，以解决一个复杂的多步骤任务。它直接命中了我的研究焦点“多智能体”，并涉及规划、工具使用、协作等关键能力。尽管它有一个明确的应用场景，但其贡献在于智能体系统的**构建方法论**，而非应用本身。因此，这篇论文高度相关，是理想的筛选对象。"
    },
    {
        "index": "#2",
        "title": "Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents",
        "link": "/arxiv/2510.19771",
        "arxiv_id": "2510.19771",
        "authors": "Gil Pasternak, Dheeraj Rajagopal, Julia White, Dhruv Atreja, Matthew Thomas, George Hurn-Maloney, Ash Lewis",
        "summary": "LLM-based agents are increasingly moving towards proactivity: rather than awaiting instruction, they exercise agency to anticipate user needs and solve them autonomously. However, evaluating proactivity is challenging; current benchmarks are constrained to localized context, limiting their ability to test reasoning across sources and longer time horizons. To address this gap, we present PROBE (Proactive Resolution Of BottlEnecks). PROBE decomposes proactivity as a pipeline of three core capabilities: (1) searching for unspecified issues, (2) identifying specific bottlenecks, and (3) executing appropriate resolutions. We apply PROBE to evaluate leading LLMs and popular agentic frameworks, showing that even state-of-the-art models struggle to solve this benchmark. Computing our consistent measurements across frontier LLMs and agents, we find that the best end-to-end performance of 40% is achieved by both GPT-5 and Claude Opus-4.1. Additionally, we demonstrate the relative capabilities of each model and analyze mutual failure modes. Our results highlight the current limitations of autonomous action in agentic systems, and expose promising future research directions.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.807484",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是**构建了一个新的评估框架（PROBE）来衡量LLM智能体的“主动性”（Proactivity）**。主动性是智能体自主性的一个高级体现，它要求智能体不等指令，而是主动预见并解决问题。论文将“主动性”分解为“搜索未指定问题”、“识别具体瓶颈”和“执行解决方案”三个核心能力，这本质上是在定义和衡量一个高级的**单智能体（Agentic）**能力。因此，这篇论文的核心是关于**构建和改进LLM智能体**的方法论（评估方法论），符合“保留”标准。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文高度契合您的核心关注点： *   **核心范式**: 论文明确聚焦于 `LLM-based Agents` 和 `Agentic AI`。 *   **智能体能力**: 论文研究的“主动性”（Proactivity）是 `Planning`（规划）和自主行动的延伸和高级形式。其分解的三个步骤（搜索、识别、执行）涉及了复杂的 `Tool Use`（执行解决方案可能需要调用工具）和高级的 `ReAct`（推理与行动循环）能力。它超越了简单的反应式（Reactive）智能体，进入了更高级的自主规划领域。 **第三步：排除标准——是否为我的研究焦点之外？** 论文不涉及任何排除标准： *   **安全与对齐**: 论文焦点是智能体的能力评估，而非安全、对齐或可解释性。 *   **多模态与视觉**: 论文内容不涉及视觉或多模态模型。 **第四步：处理特殊和模糊情况** *   **推理/规划 (Reasoning/Planning)**: 这篇论文是典型的“保留”案例。它不是在研究如何提升LLM的基础数学或逻辑推理能力，而是在研究**智能体如何在复杂、开放的任务中进行自主规划和多步推理**。PROBE框架本身就是一个衡量智能体高级规划与执行能力的工具，完全符合您对Agentic框架的研究兴趣。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种衡量LLM智能体高级自主能力（主动性）的新框架。这直接服务于您“构建、改进或演化LLM智能体”的核心目标，特别是深化了对**单智能体（Agentic）**规划与自主行动能力的理解和评估。它不是简单的应用，而是对智能体核心能力本身的探索和度量，因此是您研究课题下的高质量前沿论文。"
    },
    {
        "index": "#8",
        "title": "AgentSense: LLMs Empower Generalizable and Explainable Web-Based Participatory Urban Sensing",
        "link": "/arxiv/2510.19661",
        "arxiv_id": "2510.19661",
        "authors": "Xusen Guo, Mingxing Peng, Xixuan Hao, Xingchen Zou, Qiongyan Wang, Sijie Ruan, Yuxuan Liang",
        "summary": "Web-based participatory urban sensing has emerged as a vital approach for modern urban management by leveraging mobile individuals as distributed sensors. However, existing urban sensing systems struggle with limited generalization across diverse urban scenarios and poor interpretability in decision-making. In this work, we introduce AgentSense, a hybrid, training-free framework that integrates large language models (LLMs) into participatory urban sensing through a multi-agent evolution system. AgentSense initially employs classical planner to generate baseline solutions and then iteratively refines them to adapt sensing task assignments to dynamic urban conditions and heterogeneous worker preferences, while producing natural language explanations that enhance transparency and trust. Extensive experiments across two large-scale mobility datasets and seven types of dynamic disturbances demonstrate that AgentSense offers distinct advantages in adaptivity and explainability over traditional methods. Furthermore, compared to single-agent LLM baselines, our approach outperforms in both performance and robustness, while delivering more reasonable and transparent explanations. These results position AgentSense as a significant advancement towards deploying adaptive and explainable urban sensing systems on the web.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.816467",
        "filter_reason": "这篇论文完全符合你的研究范围。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为 **AgentSense** 的框架，其本质是一个 **\"multi-agent evolution system\" (多智能体演化系统)**。这并非简单地将现有LLM智能体作为工具应用于城市感知领域，而是**构建了一个新颖的、具有演化能力的多智能体方法论和框架**。这直接命中了你研究范围中的“多智能体”和“自我演化”两个核心方向，因此通过第一步的核心判断，应予以保留。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了大量你的核心关注点： *   **核心范式**: `Multi-Agent Systems (MAS)` 被明确指出。`Self-Evolving` 的思想通过 \"evolution system\" 和 \"iteratively refines\" 体现。 *   **多智能体**: 论文明确对比了其多智能体方法与 \"single-agent LLM baselines\"，强调了其在多智能体架构下的优越性。 *   **演化机制**: \"iteratively refines them to adapt sensing task assignments to dynamic urban conditions\" 描述了一个清晰的迭代优化、适应环境的演化过程，与 `Self-Improvement` 和 `Iterative Improvement` 完全契合。 *   **智能体能力**: \"employs classical planner to generate baseline solutions and then iteratively refines them\" 涉及了智能体的规划能力。 3.  **第三步：排除标准——未触达** 摘要中提到了 \"explainable\" (可解释性)，但需要判断其是否为主要贡献。从摘要结构来看，\"explainability\" 是作为框架带来的一个优势（\"while producing natural language explanations...\"）被提及，而不是论文的核心研究问题。论文的核心是解决 \"limited generalization\" (泛化能力有限) 的问题，其方法是构建一个演化的多智能体系统。因此，这不属于以安全与对齐为主要贡献的论文，不应被排除。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 这篇论文是“自我演化的应用”的完美例证。它虽然应用于特定领域（城市感知），但其核心贡献是提出了一种**新的“自我演化”机制**（即多智能体演化系统）。根据你设定的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 这篇论文完全符合该保留例外情况。 **最终决策**: 该论文的核心贡献在于构建了一个多智能体演化框架，通过迭代优化来提升系统在动态环境下的表现。这直接对应了你研究课题中的“多智能体”和“自我演化”两个核心方向。尽管它有一个具体的应用场景，但其方法论上的创新是普适的，并且完全是你所关注的Agentic AI的范畴。因此，这篇论文高度相关，应该被筛选出来。"
    },
    {
        "index": "#11",
        "title": "NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning",
        "link": "/arxiv/2510.19429",
        "arxiv_id": "2510.19429",
        "authors": "Wonje Choi, Jooyoung Kim, Honguk Woo",
        "summary": "We address the challenge of adopting language models (LMs) for embodied tasks in dynamic environments, where online access to large-scale inference engines or symbolic planners is constrained due to latency, connectivity, and resource limitations. To this end, we present NeSyPr, a novel embodied reasoning framework that compiles knowledge via neurosymbolic proceduralization, thereby equipping LM-based agents with structured, adaptive, and timely reasoning capabilities. In NeSyPr, task-specific plans are first explicitly generated by a symbolic tool leveraging its declarative knowledge. These plans are then transformed into composable procedural representations that encode the plans' implicit production rules, enabling the resulting composed procedures to be seamlessly integrated into the LM's inference process. This neurosymbolic proceduralization abstracts and generalizes multi-step symbolic structured path-finding and reasoning into single-step LM inference, akin to human knowledge compilation. It supports efficient test-time inference without relying on external symbolic guidance, making it well suited for deployment in latency-sensitive and resource-constrained physical systems. We evaluate NeSyPr on the embodied benchmarks PDDLGym, VirtualHome, and ALFWorld, demonstrating its efficient reasoning capabilities over large-scale reasoning models and a symbolic planner, while using more compact LMs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.817981",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 NeSyPr 的新型具身推理框架，其本质是关于如何构建和改进 LLM 智能体。以下是根据您的筛选标准进行的详细判断过程： **第一步：核心判断——这篇论文的本质是什么？** - **保留 (Keep)**。这篇论文的核心不是将现有智能体框架简单应用于某个领域，而是提出了一种全新的方法论（神经符号程序化）来**构建和改进**基于LM的智能体。它解决了智能体在资源受限的动态环境中进行高效推理的挑战，这直接关系到智能体的核心能力。因此，它完全符合“构建、改进或演化 LLM智能体”的核心目标。 **第二步：正面指标——论文是否包含我的核心关注点？** - **核心范式**: 论文明确提出了一个 `LLM-based Agents` 的新框架 `NeSyPr`。 - **智能体能力**: 论文的核心是关于智能体的 `Planning` 和 `Reasoning`。它通过将符号规划器生成的多步计划“编译”成可组合的程序化表示，使LM能够进行高效的单步推理。这与 `ReAct` 等范式类似，都是关于智能体如何规划和执行任务的新框架。 - **演化机制**: 论文中提到的“编译知识”（knowledge compilation）和“自适应推理”（adaptive reasoning）能力，可以被看作是一种智能体在部署前进行自我完善和能力提升的机制。它通过将外部符号知识内化为自身推理过程的一部分，实现了智能体能力的迭代和增强，这与 `Self-Improvement` 和 `Iterative Improvement` 的思想高度契合。 **第三步：排除标准——是否为我的研究焦点之外？** - **安全与对齐**: 论文完全不涉及 `Safety`, `Alignment` 等主题。 - **多模态与视觉**: 论文虽然提到了“具身任务”（Embodied Tasks），但其核心贡献并非视觉或多模态处理，而是推理框架本身。视觉信息（如果存在）只是作为智能体感知环境的一部分输入，而不是研究的核心。 **第四步：处理特殊和模糊情况** - **推理/规划 (Reasoning/Planning)**: 这篇论文是典型的“保留”情况。它不是在研究如何提升LM本身的基础数学或逻辑能力，而是在研究一个**智能体框架**如何进行规划和多步推理。它提出的 `NeSyPr` 框架是一种新的 Agentic 框架，旨在让智能体在复杂任务中更高效地规划和行动，完全符合您的要求。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种新颖的神经符号框架，用于**构建和改进** LLM 智能体的规划与推理能力。它直接解决了智能体在真实世界部署中面临的效率和资源限制问题，属于 Agentic AI 的核心研究范畴。因此，这篇论文完全符合您的研究范围，应予以保留。"
    },
    {
        "index": "#4",
        "title": "Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning",
        "link": "/arxiv/2510.19732",
        "arxiv_id": "2510.19732",
        "authors": "Gunshi Gupta, Karmesh Yadav, Zsolt Kira, Yarin Gal, Rahaf Aljundi",
        "summary": "To enable embodied agents to operate effectively over extended timeframes, it is crucial to develop models that form and access memories to stay contextualized in their environment. In the current paradigm of training transformer-based policies for embodied sequential decision-making tasks, visual inputs often overwhelm the context limits of transformers, while humans can maintain and utilize a lifetime of experience compressed as memories. Significant compression is possible in principle, as much of the input is irrelevant and can be abstracted. However, existing approaches predominantly focus on either recurrent models with fixed-size memory or transformers with full-context reliance. In this work, we propose Memo, a transformer-based architecture and training recipe for reinforcement learning (RL) on memory-intensive, long-horizon tasks. Memo incorporates the creation and retrieval of memory by interleaving periodic summarization tokens with the inputs of a model during training. We demonstrate Memo's effectiveness on a gridworld meta-RL benchmark and a multi-object navigation task in photo-realistic indoor settings. Memo outperforms naive long-context transformer baselines while being more compute and storage efficient. Additionally, Memo generalizes better to longer contexts at inference time and remains robust in streaming settings, where historical context must be truncated to fit inference constraints.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition, Robotics",
        "date": "2025-10-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.808760",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)**：论文的本质是**构建一种新的智能体架构**。标题和摘要都明确指出，其目标是构建\"具身智能体\"，并提出了一种名为\"Memo\"的新\"架构和训练方法\"。这直接命中了“构建LLM智能体”的核心要求，它不是简单的应用，而是对智能体本身（特别是其记忆模块）的改进和创新。 2.  **第二步：正面指标 (强力匹配)**：论文与您核心关注点的匹配度非常高。 *   **核心范式**：论文研究的是`Embodied Agents`，这是`Agentic AI`的一个重要分支，并且其基于`Transformer`架构，属于`LLM-based Agents`的范畴。 *   **智能体能力**：论文的核心贡献点是**`Memory`**。它专门解决智能体在长时程任务中如何高效地形成和访问记忆的问题，这与您关注的“记忆”能力完全一致。虽然未明确提及，但支持“长时程任务”和“序列决策”本身就与智能体的`Planning`能力密切相关。 3.  **第三步：排除标准 (未触及)**：论文的主要贡献集中在智能体的记忆架构上，不涉及安全、对齐或可解释性。虽然提到了“视觉输入”，但这属于智能体感知环境的工具，是输入信号的一种，而非研究的核心。研究的核心是**如何处理和压缩包括视觉在内的所有历史信息**，而不是如何理解视觉本身。因此，它符合“除非它们被用作智能体感知环境的工具”这一例外条款，不应被排除。 4.  **第四步：特殊情况 (符合保留条件)**：论文讨论的是智能体在复杂环境中的“长时程任务”和“序列决策”，这完全属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴，应予以保留。 **总结**： 该论文的核心贡献是提出了一种创新的、基于Transformer的记忆架构，用于**构建和改进**能够处理长时程任务的LLM智能体。这精准地契合了您研究目标中的“单智能体”方向，特别是“记忆”这一子方向。它不是应用型研究，也不是基础设施或安全对齐研究，因此是一篇高度相关且应保留的前沿论文。"
    },
    {
        "index": "#12",
        "title": "MSC-Bench: A Rigorous Benchmark for Multi-Server Tool Orchestration",
        "link": "/arxiv/2510.19423",
        "arxiv_id": "2510.19423",
        "authors": "Jia-Kai Dong, I-Wei Huang, Chun-Tin Wu, Yi-Tien Tsai",
        "summary": "We introduce MSC-Bench, a large-scale benchmark for evaluating multi-hop, end-to-end tool orchestration by LLM agents in a hierarchical Model-Context Protocol (MCP) ecosystem. Existing benchmarks often evaluate tools in isolation, ignoring challenges such as functional overlap and cross-server orchestration, leading to overly optimistic assessments. MSC-Bench addresses these gaps by constructing ground truth through 'equal function sets', allowing objective metrics such as F1 score and reducing the dependency on LLM-as-a-judge evaluation. Organized as a five-level curriculum, it systematically tests agent capabilities from single-tool orchestration to complex cross-server planning, and robustness to out-of-scope requests. Experiments reveal that rigid hierarchies can hinder performance without co-designed strategies, and even state-of-the-art agents exhibit systemic weaknesses in robustness. MSC-Bench provides a diagnostic framework to expose these limitations and guide the development of more capable and efficient tool-using agents. The benchmark and resources are publicly available at https://github.com/snooow1029/MSC_Bench.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.818430",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是构建了一个名为 **MSC-Bench** 的基准。虽然它本身不是一个智能体，但其本质是**一个用于评估和指导LLM智能体改进的方法论**。论文明确指出，该基准旨在“指导开发更有能力和更高效的工具使用智能体”。这直接服务于“构建、改进或演化LLM智能体”的核心目标。它不是将智能体作为工具去解决一个外部领域问题，而是聚焦于智能体本身的能力评估与提升。 2.  **第二步：正面指标** - 论文高度匹配您的核心关注点。它明确涉及： - **核心范式**: `LLM-based Agents` - **智能体能力**: `Tool Use / Tool Augmentation` (论文的核心是“Tool Orchestration”，即工具编排，这是工具使用的高级形式) 和 `Planning` (论文明确测试“complex cross-server planning”)。 - 这些指标表明，论文的研究内容与您关注的“单智能体”方向，特别是工具使用和规划能力，紧密相关。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐或多模态。它的焦点是智能体的能力评估，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文研究的正是智能体如何进行“跨服务器规划”，这属于智能体在复杂任务中的多步推理和规划，完全符合“保留”的条件。它不是在改进LLM的基础数学或逻辑能力，而是在评估智能体框架层面的规划能力。 **综合判断**: 该论文的核心贡献是提出了一套严谨的评估框架（MSC-Bench），用于衡量LLM智能体在复杂环境下的**工具编排和规划能力**。这个基准的目的是**诊断现有智能体的系统性弱点**，并**为未来构建更强大的智能体指明方向**。因此，它虽然是一篇基准论文，但其根本目的是推动LLM智能体这一核心研究方向的进步，完全符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的要求。它为您的“单智能体”研究方向提供了重要的评估工具和洞见。"
    },
    {
        "index": "#31",
        "title": "Learning Affordances at Inference-Time for Vision-Language-Action Models",
        "link": "/arxiv/2510.19752",
        "arxiv_id": "2510.19752",
        "authors": "Ameesh Shah, William Chen, Adwait Godbole, Federico Mora, Sanjit A. Seshia, Sergey Levine",
        "summary": "Solving complex real-world control tasks often takes multiple tries: if we fail at first, we reflect on what went wrong, and change our strategy accordingly to avoid making the same mistake. In robotics, Vision-Language-Action models (VLAs) offer a promising path towards solving complex control tasks, but lack the ability to contextually and dynamically readjust behavior when they fail to accomplish a task. In this work, we introduce Learning from Inference-Time Execution (LITEN), which connects a VLA low-level policy to a high-level VLM that conditions on past experiences by including them in-context, allowing it to learn the affordances and capabilities of the low-level VLA. Our approach iterates between a reasoning phase that generates and executes plans for the low-level VLA, and an assessment phase that reflects on the resulting execution and draws useful conclusions to be included in future reasoning contexts. Unlike similar approaches to self-refinement in non-robotics domains, LITEN must reflect on unstructured real-world robot trajectories (e.g., raw videos), which requires structured guiderails during assessment. Our experimental results demonstrate LITEN is able to effectively learn from past experience to generate plans that use high-affordance instructions to accomplish long-horizon tasks.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-10-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.838050",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献与“单智能体”和“自我演化”两个方向高度契合。我的判断过程如下： 1.  **第一步：核心判断——保留** -   **论文的本质是什么？** 这篇论文的核心贡献是提出了一种名为 LITEN 的新**方法论/框架**。该框架旨在让一个基于视觉-语言-动作模型（VLA）的智能体在执行任务时，能够从失败中学习并动态调整其行为。这并非简单地将现有模型应用于机器人领域，而是构建了一个具有**推理、行动、反思、再规划**能力的闭环智能体系统。因此，它属于“构建、改进或演化 LLM智能体”的范畴，应该**保留**。 -   它不是“非演化型应用”，因为其核心就是研究智能体如何“演化”其策略。 -   它不是“非Agentic的推理”，因为其推理过程完全内嵌于一个自主规划和行动的框架中。 2.  **第二步：正面指标——高度匹配** -   论文包含了大量你的核心关注点： -   **智能体能力**: 论文明确提到了一个迭代循环，包含 `reasoning phase` (规划阶段) 和 `assessment phase` (评估/反思阶段)，这与 `Planning`、`Self-Reflection` 和 `Self-Correction` 完全一致。 -   **演化机制**: 整个 LITEN 框架就是一个 `Self-Evolving` 或 `Self-Improvement` 的机制。它通过在推理时（Inference-Time）将过去的经验（`past experiences`）纳入上下文，实现了 `Iterative Improvement`。 -   **核心范式**: 这是一个典型的 `Agentic AI` 框架。高层级 VLM 负责“思考”，低层级 VLA 负责“行动”，这是一种工具使用（`Tool Use`）和记忆（`Memory`，通过上下文实现）的结合体。 3.  **第三步：排除标准——不适用** -   论文不涉及安全、对齐、幻觉等问题。 -   **关于多模态与视觉**: 这是本篇论文最需要辨析的地方。虽然论文使用了 `Vision-Language-Action Models (VLAs)` 和 `VLMs`，但根据筛选标准“除非它们被用作智能体感知环境的工具，而不是研究的核心”，本篇论文**符合保留条件**。在这里，视觉（原始视频）是智能体感知和反思的**环境输入**，而论文的**研究核心**是“如何从这些视觉经验中学习和反思”的**机制（LITEN框架）**，而不是视觉模型本身。 4.  **第四步：处理特殊和模糊情况——明确符合保留条件** -   **推理/规划**: 论文提出的 LITEN 框架正是关于智能体如何在复杂任务（长视野机器人任务）中进行多步推理和规划的，完全符合“保留”标准。 -   **自我演化的应用**: 这篇论文是“自我演化的应用”这一规则的完美例证。它将一个新颖的“自我演化”机制（LITEN）应用在了机器人学这一特定领域。根据你的要求，只要核心是提出新的自我演化机制，就应该**保留**。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种让智能体在执行过程中通过反思和迭代来自我完善的新框架（LITEN）。它直接命中了你的研究焦点中的“单智能体”（规划、自我反思）和“自我演化”两个核心方向。尽管它应用在机器人领域并涉及视觉，但这并不改变其作为Agentic AI方法论的实质。因此，这篇论文与你的研究目标高度相关，应该被筛选出来。"
    },
    {
        "index": "#88",
        "title": "See, Think, Act: Online Shopper Behavior Simulation with VLM Agents",
        "link": "/arxiv/2510.19245",
        "arxiv_id": "2510.19245",
        "authors": "Yimeng Zhang, Jiri Gesi, Ran Xue, Tian Wang, Ziyi Wang, Yuxuan Lu, Sinong Zhan, Huimin Zeng, Qingjun Cui, Yufan Guo, Jing Huang, Mubarak Shah, Dakuo Wang",
        "summary": "LLMs have recently demonstrated strong potential in simulating online shopper behavior. Prior work has improved action prediction by applying SFT on action traces with LLM-generated rationales, and by leveraging RL to further enhance reasoning capabilities. Despite these advances, current approaches rely on text-based inputs and overlook the essential role of visual perception in shaping human decision-making during web GUI interactions. In this paper, we investigate the integration of visual information, specifically webpage screenshots, into behavior simulation via VLMs, leveraging OPeRA dataset. By grounding agent decision-making in both textual and visual modalities, we aim to narrow the gap between synthetic agents and real-world users, thereby enabling more cognitively aligned simulations of online shopping behavior. Specifically, we employ SFT for joint action prediction and rationale generation, conditioning on the full interaction context, which comprises action history, past HTML observations, and the current webpage screenshot. To further enhance reasoning capabilities, we integrate RL with a hierarchical reward structure, scaled by a difficulty-aware factor that prioritizes challenging decision points. Empirically, our studies show that incorporating visual grounding yields substantial gains: the combination of text and image inputs improves exact match accuracy by more than 6% over text-only inputs. These results indicate that multi-modal grounding not only boosts predictive accuracy but also enhances simulation fidelity in visually complex environments, which captures nuances of human attention and decision-making that text-only agents often miss. Finally, we revisit the design space of behavior simulation frameworks, identify key methodological limitations, and propose future research directions toward building efficient and effective human behavior simulators.",
        "subjects": "Computers and Society, Artificial Intelligence, Human-Computer Interaction, Machine Learning, Multimedia",
        "date": "2025-10-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.892480",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** *   **论文的核心贡献**: 这篇论文的核心贡献并非简单地应用LLM解决电商问题，而是提出了一种**构建和改进LLM智能体的新方法论**。具体来说，它研究了如何将视觉信息（网页截图）整合到基于LLM的智能体中，以提升其在模拟人类行为（如在线购物）时的决策能力。论文的标题“See, Think, Act”本身就概括了一个智能体的核心循环：感知、推理、行动。 *   **判断**: 论文的核心是关于**构建/改进一个Agentic LLM（VLM Agent）**，使其具备多模态感知能力，从而更好地进行规划和决策。因此，它不属于“非演化型应用”，应**保留**。 **第二步：正面指标——论文是否包含我的核心关注点？** *   **核心范式**: 论文明确提到了“VLM Agents”，完全符合`Agentic AI`和`LLM-based Agents`的范畴。 *   **智能体能力**: 论文的核心是让智能体在复杂的GUI环境中进行决策。这直接关联到`Planning`（规划下一步行动）和`Reasoning`（推理）。摘要中提到的“rationale generation”（生成基本原理）和“enhance reasoning capabilities”（增强推理能力）都是智能体高级认知能力的体现。 *   **结论**: 论文命中了多个核心正面指标，特别是`Agentic AI`和`Planning`。 **第三步：排除标准——是否为我的研究焦点之外？** *   **安全与对齐**: 论文未涉及安全、对齐或可解释性等内容。 *   **多模态与视觉**: 这是最关键的一点。虽然论文大量涉及视觉和多模态，但它完全符合例外情况。论文的研究核心**不是**提出一个新的视觉语言模型（VLM），而是**将VLM作为智能体感知环境的工具**，来构建一个更强大的智能体框架。视觉输入是智能体“See”环节的一部分，是服务于整个智能体决策流程的，而不是研究的最终目的。因此，这不应成为排除的理由。 **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文的研究内容完全符合“保留”条件。它不是在提升LLM的基础数学或逻辑能力，而是在研究**智能体如何在一个真实、复杂的交互环境（网页）中进行多步推理和规划**。这正是Agentic AI研究的核心问题。 **第五步：最终决策** 综合以上分析，这篇论文虽然以“在线购物行为模拟”为应用场景，但其**本质贡献在于提出了一种增强LLM智能体感知和决策能力的新框架**。它通过引入视觉模态，解决了现有文本智能体在GUI环境中的局限性，这属于您研究焦点中“单智能体”方向的“规划”和“工具使用”（将视觉作为一种感知工具）的范畴。因此，这篇论文与您“构建、改进或演化LLM智能体”的核心目标高度一致，应被**保留**。"
    },
    {
        "index": "#135",
        "title": "AI for Distributed Systems Design: Scalable Cloud Optimization Through Repeated LLMs Sampling And Simulators",
        "link": "/arxiv/2510.18897",
        "arxiv_id": "2510.18897",
        "authors": "Jacopo Tagliabue",
        "summary": "We explore AI-driven distributed-systems policy design by combining stochastic code generation from large language models (LLMs) with deterministic verification in a domain-specific simulator. Using a Function-as-a-Service runtime (Bauplan) and its open-source simulator (Eudoxia) as a case study, we frame scheduler design as an iterative generate-and-verify loop: an LLM proposes a Python policy, the simulator evaluates it on standardized traces, and structured feedback steers subsequent generations. This setup preserves interpretability while enabling targeted search over a large design space. We detail the system architecture and report preliminary results on throughput improvements across multiple models. Beyond early gains, we discuss the limits of the current setup and outline next steps; in particular, we conjecture that AI will be crucial for scaling this methodology by helping to bootstrap new simulators.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Databases, Software Engineering",
        "date": "2025-10-20",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.939555",
        "filter_reason": "这篇论文符合你的研究范围。 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于分布式系统领域，而是提出了一套**迭代的、演化的方法论**（即 \"generate-and-verify loop\"）。在这个循环中，LLM生成的策略会通过模拟器进行验证，然后基于结构化的反馈进行下一轮的生成和改进。这本质上是一个**自我演化**的框架。它不是一次性的应用，而是一个持续学习和迭代的机制，完全符合你研究目标中“通过环境反馈进行自我完善和迭代”的定义。 2.  **第二步：正面指标** - 论文摘要明确提到了几个关键的核心范式和能力： - `Self-Evolving`: 整个 \"generate-and-verify loop\" 就是一个自我演化的实例。 - `Iterative Improvement`: 摘要中直接使用了 \"iterative\" 一词，并描述了“structured feedback steers subsequent generations”的迭代改进过程。 - `Self-Refine`: LLM基于反馈生成下一版本策略的过程，就是一种自我精炼（Self-Refine）的体现。 - 虽然没有明确出现 `Agentic AI` 或 `LLM-based Agents` 的字样，但其描述的“LLM提出策略 -> 环境评估 -> 反馈 -> LLM改进策略”的闭环，正是LLM智能体与环境交互并进行演化的典型模式。 3.  **第三步：排除标准** - 论文的研究焦点不涉及安全、对齐、多模态或视觉等领域。因此，不触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是判断本论文的关键。根据你的要求，**“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。”** - 这篇论文正是如此。它的核心贡献是那个**“迭代生成-验证”的演化框架**，而不仅仅是这个框架在分布式系统设计上的应用。它提出了一种利用LLM和模拟器进行自动化策略优化的通用范式。因此，尽管其应用领域是“分布式系统”，但因其核心贡献在于方法论本身，属于“自我演化”的范畴，应当被保留。 **最终决策**: 综合分析，这篇论文的核心贡献是构建了一个利用LLM和模拟器进行迭代优化的自我演化框架。它精准地命中了你研究课题中的“自我演化”方向，虽然应用在特定领域，但其方法论具有普适性，完全符合你的筛选标准。因此，最终判断为 **True**。"
    },
    {
        "index": "#136",
        "title": "CosmoCore Affective Dream-Replay Reinforcement Learning for Code Generation",
        "link": "/arxiv/2510.18895",
        "arxiv_id": "2510.18895",
        "authors": "Santhosh Kumar Ravindran",
        "summary": "We introduce CosmoCore, a neuroscience-inspired reinforcement learning (RL) architecture that integrates affective signals to enhance code generation in large language models (LLMs). Motivated by human and animal learning where embarrassment from mistakes drives rapid correction, as observed in training a puppy to avoid repeating errors after a single scolding CosmoCore tags code generation trajectories with valence and surprise using a lightweight multi-layer perceptron (MLP). High-negative valence (cringe) episodes, such as buggy code outputs, are prioritized in a Dream Queue for five-fold replay during off-policy updates, while low-surprise successes are pruned to prevent overconfidence and buffer bloat. Evaluated on code generation benchmarks like HumanEval and BigCodeBench, alongside simulations with a custom data pipeline environment, CosmoCore reduces hallucinated code (e.g., syntax errors or logical bugs) by 48\\% and accelerates self-correction by 45\\%. Local experiments using Hugging Face models in a PySpark environment validate these gains, with code snippets provided for replication. Ablations confirm valence tagging boosts curiosity in exploration, and pruning mitigates inefficiency. This framework extends RL from human feedback (RLHF) for more emotionally aware code assistants, with applications in IDEs and data pipelines. Code and the custom mini-world simulation are released.",
        "subjects": "Software Engineering, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-10-20",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.940008",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。 以下是根据你的筛选标准进行的详细判断： 1.  **第一步：核心判断 (保留)** - **核心贡献**: 论文的核心贡献是提出了一个名为 **CosmoCore** 的全新强化学习架构。这并非简单应用现有框架，而是构建了一个**新的方法论和框架**。 - **是否符合**: 该框架的核心机制——通过情感信号（效价和惊奇度）标记经验、优先重放“尴尬”失败、修剪低价值成功——旨在让智能体从经验中**自我完善和迭代**。这完全符合 **“自我演化”** 的定义。它不是一个静态的应用，而是一个动态的、通过反馈进行自我优化的系统。因此，它不是“非演化型应用”。 2.  **第二步：正面指标 (高度匹配)** - 论文摘要中明确包含了多个核心关注点： - **自我演化**: 整个框架就是一种自我演化机制。 - **自我纠错**: 摘要直接指出“accelerates self-correction by 45%”。 - **自我反思/改进**: “情感信号”和“重放失败轨迹”的机制是一种模拟生物反思和学习的自我改进过程。 3.  **第三步：排除标准 (不适用)** - **安全与对齐**: 论文的主要贡献是关于提升性能和自我演化能力，而非安全、对齐或可解释性。 - **幻觉问题**: 这是一个关键点。虽然论文的结果提到了“reduces hallucinated code”，但论文的**核心贡献不是研究幻觉本身**，而是提出了一种**减少幻觉的智能体演化机制**。它属于“如何让智能体做得更好”的范畴，而不是“如何理解或分析智能体的缺陷”。因此，这不触犯排除规则。 - **多模态**: 论文不涉及多模态或视觉内容。 4.  **第四步：特殊和模糊情况 (支持保留)** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外规则的完美例证。它的核心是提出一种新的**“自我演化”机制**（情感驱动的重放），并将其应用在“代码生成”这个特定领域。按照规则，这种情况应该保留。 **最终决策**: 该论文的核心贡献在于构建了一个新颖的、受神经科学启发的强化学习框架，使LLM智能体能够通过从失败中进行优先学习来实现**自我演化和自我纠错**。这直接命中了你研究课题中的“自我演化”方向，并涉及“单智能体”的“自我反思”能力。它不是简单的应用，而是对智能体能力本身的根本性改进。因此，这篇论文与你研究目标的匹配度非常高，应被**保留 (True)**。"
    },
    {
        "index": "#137",
        "title": "CodeCRDT: Observation-Driven Coordination for Multi-Agent LLM Code Generation",
        "link": "/arxiv/2510.18893",
        "arxiv_id": "2510.18893",
        "authors": "Sergey Pugachev",
        "summary": "Multi-agent LLM systems fail to realize parallel speedups due to costly coordination. We present CodeCRDT, an observation-driven coordination pattern where agents coordinate by monitoring a shared state with observable updates and deterministic convergence, rather than explicit message passing. Using Conflict-Free Replicated Data Types (CRDTs), CodeCRDT enables lock-free, conflict-free concurrent code generation with strong eventual consistency. Evaluation across 600 trials (6 tasks, 50 runs per mode) shows both benefits and trade-offs: up to 21.1% speedup on some tasks, up to 39.4% slowdown on others, and 100% convergence with zero merge failures. The study formalizes observation-driven coordination for stochastic LLM agents, revealing semantic conflict rates (5-10%) and quality-performance tradeoffs, and provides empirical characterization of when parallel coordination succeeds versus fails based on task structure.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Software Engineering",
        "date": "2025-10-18",
        "category": "cs.AI",
        "crawl_time": "2025-10-23T11:00:04.940442",
        "filter_reason": "根据您的筛选标准，这篇论文完全符合要求，应被保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM智能体作为工具应用于代码生成领域，而是**提出了一种全新的、用于改进多智能体LLM系统效率的协调模式**。其核心贡献是`CodeCRDT`，这是一种解决多智能体协作中“协调成本过高”这一关键瓶颈的新方法论。这完全符合“构建、改进或演化LLM智能体”的核心目标，特别是在**多智能体**这个子方向上。它不是非演化型应用，因为它研究的是智能体系统本身的工作机制，而非其在特定领域的应用效果。 **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 - **多智能体**: 论文的核心是解决智能体间的`Collaboration`（协作）和`Communication`（通信）问题，并提出了一种新的“观察驱动”通信范式，替代了传统的“显式消息传递”。 - **智能体能力**: 虽然不是直接关于规划或记忆，但高效的`Coordination`（协调）是智能体协同完成复杂任务的基础能力，这篇论文正是在这个基础能力上做出了创新。 **第三步：排除标准** - 论文完全不涉及安全与对齐、多模态与视觉等排除领域。其研究焦点纯粹集中在多智能体的协作机制上。 **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文不直接研究单智能体的推理或规划，而是研究多智能体在执行任务（代码生成）时的协调机制。这属于多智能体研究的范畴，是您关注的重点之一。 - **基础设施**: 虽然论文使用了`CRDT`（一种分布式数据结构），但其目的并非研究CRDT本身的基础设施优化，而是**创造性地将其用作实现多智能体协调的工具**。研究的落脚点是“如何让LLM智能体更好地协作”，而不是“如何改进CRDT”。因此，它属于智能体研究，而非基础设施研究。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种新颖的、用于改进多智能体LLM系统协作效率和鲁棒性的方法论（`CodeCRDT`）。它直接解决了多智能体系统中的一个核心挑战——协调成本，并提供了新的协调范式。这与您研究课题中的“多智能体”方向高度契合，属于对LLM智能体本身的“改进”和“构建”，因此应被判定为符合要求。"
    }
]