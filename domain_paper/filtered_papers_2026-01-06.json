[
    {
        "index": "#9",
        "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems",
        "link": "/arxiv/2601.02695",
        "arxiv_id": "2601.02695",
        "authors": "Guibin Zhang, Haiyang Yu, Kaiming Yang, Bingli Wu, Fei Huang, Yongbin Li, Shuicheng Yan",
        "summary": "Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks. However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off. We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion. To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments. Leveraging an ever-expanding knowledge base of prior experience, EvoRoute dynamically selects Pareto-optimal LLM backbones at each step, balancing accuracy, efficiency, and resource use, while continually refining its own selection policy through environment feedback. Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.",
        "subjects": "Computation and Language, Multiagent Systems",
        "date": "2026-01-06",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.902305",
        "filter_reason": "这篇论文完全符合筛选标准，属于核心研究范围内的“自我演化”方向。 1.  **核心贡献符合第一步判断**: 论文的核心贡献是提出了 **EvoRoute**，这是一种**自我演化**的模型路由范式。它不是将现有的智能体简单应用到某个垂直领域（非演化型应用），也不是单纯的基础设施优化，而是针对LLM智能体系统本身提出了一种新的架构和演化机制，旨在解决智能体系统中的性能、成本和延迟之间的权衡问题。 2.  **精准命中“自我演化”与“Agentic AI”焦点**: *   **自我演化**: 论文明确提到这是一个“self-evolving”范式，并且详细描述了其机制：利用不断扩大的先验经验知识库，通过环境反馈持续完善其自身的选择策略。这完全符合筛选标准中关于“智能体通过经验、反思或环境反馈进行自我完善和迭代”的定义。 *   **Agentic AI**: 论文的研究对象是“Complex agentic AI systems”，涉及LLM、工具和记忆模块的协调集成，这直接对应了研究课题中的LLM智能体构建。 3.  **符合正面指标**: 论文包含了大量核心关键词，如 `Self-Evolving`、`Agentic AI`、`LLM-based Agents`、`Iterative Improvement`（通过反馈持续完善）以及 `Tool and memory modules`。 4.  **排除标准检查**: 论文不涉及安全对齐、多模态视觉核心研究或图技术。虽然它关注了成本和延迟（通常属于基础设施范畴），但其解决手段是通过智能体的自我演化策略来实现的，因此属于智能体架构的改进，而非单纯的底层硬件或部署优化。 综上所述，该论文提出了一种新的智能体自我演化机制，属于构建和改进LLM智能体的前沿研究，应予以保留。"
    },
    {
        "index": "#3",
        "title": "InfiAgent: An Infinite-Horizon Framework for General-Purpose Autonomous Agents",
        "link": "/arxiv/2601.03204",
        "arxiv_id": "2601.03204",
        "authors": "Chenglin Yu, Yuchen Wang, Songmiao Wang, Hongxia Yang, Ming Li",
        "summary": "LLM agents can reason and use tools, but they often break down on long-horizon tasks due to unbounded context growth and accumulated errors. Common remedies such as context compression or retrieval-augmented prompting introduce trade-offs between information fidelity and reasoning stability. We present InfiAgent, a general-purpose framework that keeps the agent's reasoning context strictly bounded regardless of task duration by externalizing persistent state into a file-centric state abstraction. At each step, the agent reconstructs context from a workspace state snapshot plus a fixed window of recent actions. Experiments on DeepResearch and an 80-paper literature review task show that, without task-specific fine-tuning, InfiAgent with a 20B open-source model is competitive with larger proprietary systems and maintains substantially higher long-horizon coverage than context-centric baselines. These results support explicit state externalization as a practical foundation for stable long-horizon agents. Github Repo:https://github.com/ChenglinPoly/infiAgent",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2026-01-06",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.900452",
        "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（第一步）：** *   论文的核心贡献是提出了 **InfiAgent**，这是一个用于通用自主智能体的**新框架**。 *   它解决的是 LLM 智能体在长视界任务中面临的上下文增长和误差累积问题，属于**构建和改进 LLM 智能体**的方法论研究。 *   它不是将现有智能体简单应用到特定领域（如医疗、金融），而是提出了底层的架构改进（状态外部化），因此不属于“非演化型应用”。 *   它关注的是智能体的系统架构和状态管理，而非模型的基础设施或硬件加速。 2.  **正面指标匹配（第二步）：** *   **核心范式**：明确属于 `Agentic AI` 和 `LLM-based Agents`。 *   **智能体能力**：论文重点解决了智能体的 **`Memory`**（通过文件中心的状态抽象外部化持久状态）和 **`Planning`**（在长视界任务中保持推理稳定性）能力。这是单智能体研究中的关键子方向。 3.  **排除标准检查（第三步）：** *   论文不涉及安全、对齐、多模态或图技术，未触发任何排除标准。 4.  **特殊情况处理（第四步）：** *   论文关于长视界任务中的推理稳定性，属于智能体如何在复杂任务中进行规划和多步推理的范畴，符合保留条件。 **总结**：该论文通过引入显式的状态外部化机制，改进了 LLM 智能体处理长视界任务的能力，是对智能体架构和记忆机制的重要创新，直接契合“单智能体”方向中的规划与记忆研究焦点。"
    },
    {
        "index": "#25",
        "title": "From Memorization to Creativity: LLM as a Designer of Novel Neural-Architectures",
        "link": "/arxiv/2601.02997",
        "arxiv_id": "2601.02997",
        "authors": "Waleed Khalid, Dmitry Ignatov, Radu Timofte",
        "summary": "Large language models (LLMs) excel in program synthesis, yet their ability to autonomously navigate neural architecture design--balancing syntactic reliability, performance, and structural novelty--remains underexplored. We address this by placing a code-oriented LLM within a closed-loop synthesis framework, analyzing its evolution over 22 supervised fine-tuning cycles. The model synthesizes PyTorch convolutional networks which are validated, evaluated via low-fidelity performance signals (single-epoch accuracy), and filtered using a MinHash-Jaccard criterion to prevent structural redundancy. High-performing, novel architectures are converted into prompt-code pairs for iterative fine-tuning via parameter-efficient LoRA adaptation, initialized from the LEMUR dataset. Across cycles, the LLM internalizes empirical architectural priors, becoming a robust generator. The valid generation rate stabilizes at 50.6 percent (peaking at 74.5 percent), while mean first-epoch accuracy rises from 28.06 percent to 50.99 percent, and the fraction of candidates exceeding 40 percent accuracy grows from 2.04 percent to 96.81 percent. Analyses confirm the model moves beyond replicating existing motifs, synthesizing 455 high-performing architectures absent from the original corpus. By grounding code synthesis in execution feedback, this work provides a scalable blueprint for transforming stochastic generators into autonomous, performance-driven neural designers, establishing that LLMs can internalize empirical, non-textual rewards to transcend their training data.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.211267",
        "filter_reason": "这篇论文完全符合筛选标准，属于“自我演化”和“Agentic AI”的核心研究范畴。 1.  **核心判断（符合自我演化机制）**： 论文的核心贡献在于构建了一个“闭环合成框架”，让LLM能够通过环境反馈（执行结果和性能评估）进行自我完善。论文详细描述了LLM经过22个监督微调周期的演化过程，通过迭代微调，模型内化了经验性的架构先验，从而提升了生成质量和性能。这完全符合“自我演化”中定义的“智能体通过经验、反思或环境反馈进行自我完善和迭代”。 2.  **符合Agentic AI特征**： 论文将LLM定位为一个“自主的、性能驱动的神经设计者”。它不仅仅是生成代码，而是通过“验证-评估-过滤-更新”的循环，展示了智能体利用工具（代码执行）和反馈机制来优化自身输出的能力，这属于Agentic AI的高级形态。 3.  **特殊情况处理（自我演化的应用）**： 虽然论文的应用场景是“神经架构设计”（NAS），属于特定领域的应用，但根据第四步的规则，只要论文的核心是提出一种新的“自我演化”机制，即使应用在特定领域也应保留。本文的重点在于证明LLM如何通过反馈循环“从记忆走向创造”，其演化机制具有通用性和研究价值，而非单纯的应用落地。 综上所述，该论文在自我演化和智能体框架构建上具有显著贡献，符合研究课题要求。"
    },
    {
        "index": "#8",
        "title": "MemRL: Self-Evolving Agents via Runtime Reinforcement Learning on Episodic Memory",
        "link": "/arxiv/2601.03192",
        "arxiv_id": "2601.03192",
        "authors": "Shengtao Zhang, Jiaqian Wang, Ruiwen Zhou, Junwei Liao, Yuchen Feng, Weinan Zhang, Ying Wen, Zhiyu Li, Feiyu Xiong, Yutao Qi, Bo Tang, Muning Wen",
        "summary": "The hallmark of human intelligence is the ability to master new skills through Constructive Episodic Simulation-retrieving past experiences to synthesize solutions for novel tasks. While Large Language Models possess strong reasoning capabilities, they struggle to emulate this self-evolution: fine-tuning is computationally expensive and prone to catastrophic forgetting, while existing memory-based methods rely on passive semantic matching that often retrieves noise. To address these challenges, we propose MemRL, a framework that enables agents to self-evolve via non-parametric reinforcement learning on episodic memory. MemRL explicitly separates the stable reasoning of a frozen LLM from the plastic, evolving memory. Unlike traditional methods, MemRL employs a Two-Phase Retrieval mechanism that filters candidates by semantic relevance and then selects them based on learned Q-values (utility). These utilities are continuously refined via environmental feedback in an trial-and-error manner, allowing the agent to distinguish high-value strategies from similar noise. Extensive experiments on HLE, BigCodeBench, ALFWorld, and Lifelong Agent Bench demonstrate that MemRL significantly outperforms state-of-the-art baselines. Our analysis experiments confirm that MemRL effectively reconciles the stability-plasticity dilemma, enabling continuous runtime improvement without weight updates.",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.297263",
        "filter_reason": "这篇论文完全符合筛选标准，应予以保留。具体判断依据如下： 1.  **核心判断（符合）**： 论文的核心贡献是提出了 **MemRL**，这是一个旨在实现 **Self-Evolving Agents（自我演化智能体）** 的框架。它解决的是智能体如何通过经验进行自我完善和迭代的问题，而非仅仅是将LLM作为工具应用到特定领域。这直接对应了研究目标中的“自我演化”方向。 2.  **正面指标（高度匹配）**： *   **核心范式**：论文标题和摘要中明确提到了 `Self-Evolving Agents` 和 `Reinforcement Learning`，属于核心关注点。 *   **智能体能力**：论文重点研究了 `Memory`（情景记忆 Episodic Memory）和 `Self-Improvement`（通过环境反馈持续改进）。 *   **演化机制**：论文提出了一种非参数强化学习机制，通过环境反馈在运行时迭代改进 Q-values（效用），从而实现智能体的持续演化，符合 `Iterative Improvement` 和 `Self-Refine` 的定义。 3.  **排除标准（未触发）**： *   论文不涉及安全、对齐、多模态视觉或图技术等排除项。 *   虽然论文在 HLE、BigCodeBench 等基准上进行了实验，但这些是用于验证智能体能力的通用任务，不属于“非演化型应用”的排除范畴。 4.  **特殊与模糊情况处理**： *   论文属于典型的 **自我演化** 机制研究。它提出了一种新的“在情景记忆上进行运行时强化学习”的方法，使智能体能够在不更新模型权重的情况下解决稳定性-可塑性困境并实现持续改进。这完全符合“保留：如果论文的核心是提出一种新的‘自我演化’机制”的规则。 综上所述，该论文专注于构建新的框架以实现LLM智能体的自我演化和记忆优化，是“LLM智能体及其演化”课题下的高质量相关论文。"
    },
    {
        "index": "#55",
        "title": "TiMem: Temporal-Hierarchical Memory Consolidation for Long-Horizon Conversational Agents",
        "link": "/arxiv/2601.02845",
        "arxiv_id": "2601.02845",
        "authors": "Kai Li, Xuanqing Yu, Ziyi Ni, Yi Zeng, Yao Xu, Zheqing Zhang, Xin Li, Jitao Sang, Xiaogang Duan, Xuelei Wang, Chengbao Liu, Jie Tan",
        "summary": "Long-horizon conversational agents have to manage ever-growing interaction histories that quickly exceed the finite context windows of large language models (LLMs). Existing memory frameworks provide limited support for temporally structured information across hierarchical levels, often leading to fragmented memories and unstable long-horizon personalization. We present TiMem, a temporal--hierarchical memory framework that organizes conversations through a Temporal Memory Tree (TMT), enabling systematic memory consolidation from raw conversational observations to progressively abstracted persona representations. TiMem is characterized by three core properties: (1) temporal--hierarchical organization through TMT; (2) semantic-guided consolidation that enables memory integration across hierarchical levels without fine-tuning; and (3) complexity-aware memory recall that balances precision and efficiency across queries of varying complexity. Under a consistent evaluation setup, TiMem achieves state-of-the-art accuracy on both benchmarks, reaching 75.30% on LoCoMo and 76.88% on LongMemEval-S. It outperforms all evaluated baselines while reducing the recalled memory length by 52.20% on LoCoMo. Manifold analysis indicates clear persona separation on LoCoMo and reduced dispersion on LongMemEval-S. Overall, TiMem treats temporal continuity as a first-class organizing principle for long-horizon memory in conversational agents.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.380678",
        "filter_reason": "这篇论文完全符合我的研究范围，理由如下： 1.  **核心贡献符合第一步判断**：论文的核心是提出了一种名为 TiMem 的时间-分层记忆框架，旨在解决长视界对话智能体在管理不断增长的交互历史时面临的上下文窗口限制问题。这属于“构建、改进或演化 LLM智能体”的范畴，而非将智能体作为工具应用到特定领域（如医疗、金融等）的非演化型应用。 2.  **精准命中第二步正面指标**：我的研究焦点明确包含“单智能体”方向下的“记忆”能力。该论文专门针对智能体的“记忆”机制进行了创新，提出了时间记忆树（TMT）和语义引导的整合机制，这正是对智能体核心组件的改进。 3.  **不触犯第三步排除标准**：论文主要关注智能体的记忆架构，不涉及安全与对齐、多模态视觉技术或知识图谱等被明确排除的领域。 综上所述，该论文致力于改进LLM智能体的记忆能力，属于单智能体研究的关键子方向，符合筛选要求。"
    },
    {
        "index": "#61",
        "title": "SYNAPSE: Empowering LLM Agents with Episodic-Semantic Memory via Spreading Activation",
        "link": "/arxiv/2601.02744",
        "arxiv_id": "2601.02744",
        "authors": "Hanqi Jiang, Junhao Chen, Yi Pan, Ling Chen, Weihang You, Yifan Zhou, Ruidong Zhang, Yohannes Abate, Tianming Liu",
        "summary": "While Large Language Models (LLMs) excel at generalized reasoning, standard retrieval-augmented approaches fail to address the disconnected nature of long-term agentic memory. To bridge this gap, we introduce Synapse (Synergistic Associative Processing Semantic Encoding), a unified memory architecture that transcends static vector similarity. Drawing from cognitive science, Synapse models memory as a dynamic graph where relevance emerges from spreading activation rather than pre-computed links. By integrating lateral inhibition and temporal decay, the system dynamically highlights relevant sub-graphs while filtering interference. We implement a Triple Hybrid Retrieval strategy that fuses geometric embeddings with activation-based graph traversal. Comprehensive evaluations on the LoCoMo benchmark show that Synapse significantly outperforms state-of-the-art methods in complex temporal and multi-hop reasoning tasks, offering a robust solution to the \"Contextual Tunneling\" problem. Our code and data will be made publicly available upon acceptance.",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.406202",
        "filter_reason": "1.  **核心判断 (第一步)**: 该论文的核心贡献是提出了一种名为 Synapse 的统一记忆架构，旨在解决 LLM 智能体在长期记忆中的“不连贯”问题。这属于对 LLM 智能体核心组件（记忆）的构建与改进，而非将智能体作为工具应用到特定领域（如医疗、金融），也非基础设施或基础模型推理能力的提升。因此，符合“保留”标准。 2.  **正面指标匹配 (第二步)**: 论文直接涉及 `LLM-based Agents` 的核心能力——`Memory`（记忆）。它引入了基于认知科学的扩散激活机制来优化智能体的记忆检索，这直接提升了智能体处理复杂时序和多跳推理任务的能力，属于单智能体方向的关键技术突破。 3.  **排除标准检查 (第三步)**: *   **安全与对齐**: 论文不涉及安全、对齐或可解释性问题。 *   **多模态**: 论文专注于文本记忆架构，不涉及视觉或多模态内容。 *   **图技术**: 尽管论文中提到了“动态图”和“图遍历”，但其核心目的是构建智能体的记忆系统，而非研究图神经网络（GNN）或知识图谱算法本身。图在这里是作为智能体内部存储和检索信息的机制，服务于智能体的功能，因此不应被排除。 4.  **综合结论**: 该论文通过改进智能体的记忆机制，直接增强了 LLM 智能体的自主性和任务处理能力，完全符合“单智能体”方向中关于“记忆”的研究焦点。"
    },
    {
        "index": "#95",
        "title": "ReTreVal: Reasoning Tree with Validation - A Hybrid Framework for Enhanced LLM Multi-Step Reasoning",
        "link": "/arxiv/2601.02880",
        "arxiv_id": "2601.02880",
        "authors": "Abhishek HS, Pavan C Shekar, Arpit Jain, Ashwanth Krishnan",
        "summary": "Multi-step reasoning remains a key challenge for Large Language Models (LLMs), particularly in complex domains such as mathematics and creative writing. While recent approaches including ReAct, Reflexion, and Self-Refine improve reasoning through iterative refinement and reflection, they often lack structured exploration of alternative solution paths and persistent learning across problems. We propose ReTreVal (Reasoning Tree with Validation), a hybrid framework that integrates Tree-of-Thoughts exploration, self-refinement, LLM-based critique scoring, and reflexion memory to enable bounded and validated multi-step reasoning. ReTreVal constructs a structured reasoning tree with adaptive depth based on problem complexity, where each node undergoes iterative self-critique and refinement guided by explicit LLM-generated feedback. A dual validation mechanism evaluates reasoning quality, coherence, and correctness at each node while persistently storing insights from successful reasoning paths and failure patterns in a reflexion memory buffer, enabling cross-problem learning. Critique-based pruning retains only the top-k highest-scoring nodes at each level, controlling computational cost while preserving high-quality solution paths. We evaluate ReTreVal against ReAct, Reflexion, and Self-Refine across 500 mathematical problems and creative writing tasks using Qwen 2.5 7B as the underlying LLM, and demonstrate that ReTreVal consistently outperforms existing methods through its combination of structured exploration, critique-driven refinement, and cross-problem memory, making it particularly effective for tasks requiring exploratory reasoning, rigorous verification, and knowledge transfer.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.444912",
        "filter_reason": "这篇论文完全符合筛选标准，属于核心研究范围内的“单智能体”与“自我演化”交叉领域。 1.  **核心判断**: *   论文的核心贡献是提出了 **ReTreVal** 这一混合框架，旨在构建和改进 LLM 智能体的多步推理能力。 *   它不是简单的应用型论文，而是提出了一种新的方法论，结合了 Tree-of-Thoughts (ToT)、自我细化和 Reflexion 记忆机制。 *   它不属于非演化型应用，也不属于基础设施或基础模型推理能力的微调，而是专注于智能体的架构设计。 2.  **符合研究焦点**: *   **单智能体**: 论文深入探讨了智能体的核心能力，包括 **Planning** (通过构建推理树进行结构化探索)、**Memory** (Reflexion memory buffer 用于持久化存储见解) 和 **Self-Reflection** (self-critique and refinement)。 *   **自我演化**: 论文明确提到了 \"persistent learning across problems\"（跨问题的持久学习）和 \"cross-problem memory\"（跨问题记忆）。智能体通过存储成功路径和失败模式的见解，利用这些经验在后续问题中进行改进，这完全符合“通过经验、反思进行自我完善”的自我演化定义。 3.  **排除标准检查**: *   论文不涉及安全、对齐、多模态或图技术等排除项。 *   虽然在数学和创意写作任务上进行了评估，但这只是验证框架有效性的实验场景，论文的核心在于框架本身的机制（验证、剪枝、记忆），而非特定领域的应用。 4.  **特殊规则处理**: *   根据“推理/规划”规则，该论文属于保留范畴。它不仅仅是提出一种新的 CoT 变体，而是构建了一个包含验证、记忆和树搜索的完整 **Agentic 框架**，与 ReAct 和 Reflexion 等经典 Agentic 方法进行对比和改进。 综上所述，该论文通过引入记忆机制和结构化探索，增强了 LLM 智能体的规划和自我演化能力，高度契合“LLM智能体及其演化”的研究课题。"
    },
    {
        "index": "#1",
        "title": "MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents",
        "link": "/arxiv/2601.03236",
        "arxiv_id": "2601.03236",
        "authors": "Dongming Jiang, Yi Li, Guanpeng Li, Bingzhe Li",
        "summary": "Memory-Augmented Generation (MAG) extends Large Language Models with external memory to support long-context reasoning, but existing approaches largely rely on semantic similarity over monolithic memory stores, entangling temporal, causal, and entity information. This design limits interpretability and alignment between query intent and retrieved evidence, leading to suboptimal reasoning accuracy. In this paper, we propose MAGMA, a multi-graph agentic memory architecture that represents each memory item across orthogonal semantic, temporal, causal, and entity graphs. MAGMA formulates retrieval as policy-guided traversal over these relational views, enabling query-adaptive selection and structured context construction. By decoupling memory representation from retrieval logic, MAGMA provides transparent reasoning paths and fine-grained control over retrieval. Experiments on LoCoMo and LongMemEval demonstrate that MAGMA consistently outperforms state-of-the-art agentic memory systems in long-horizon reasoning tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.383657",
        "filter_reason": "1.  **核心判断符合 (第一步)**: 该论文的核心贡献是提出了一种名为 MAGMA 的“智能体记忆架构”。这属于构建和改进 LLM 智能体的方法论范畴，旨在解决智能体在长视界推理中的记忆检索和表示问题。它不是将现有智能体简单应用于特定领域，也不是单纯的基础设施优化，而是直接针对智能体核心组件（记忆）的架构创新。 2.  **包含核心关注点 (第二步)**: 论文明确涉及 `Agentic AI` 和 `LLM-based Agents` 的核心能力——`Memory`（记忆）。它探讨了如何通过多图结构（语义、时间、因果、实体）来优化智能体的记忆存储和检索，从而提升推理能力。这完全符合单智能体方向中关于“记忆”机制的子方向。 3.  **排除标准检查 (第三步)**: *   **安全与对齐**: 虽然摘要提到了“alignment between query intent and retrieved evidence”（查询意图与检索证据的对齐），但这指的是信息检索层面的语义匹配，而非 AI 安全领域的“对齐”。论文主要贡献不在于 Safety 或 Alignment。 *   **多模态与视觉**: 论文未涉及视觉或多模态内容。 *   **图**: 尽管论文使用了“Multi-Graph”（多图）技术，但这是作为实现智能体记忆架构的**手段**，而非研究图算法本身。论文的主题是“Agentic Memory Architecture”，属于智能体研究，因此不应被排除。 综上所述，这篇论文通过改进智能体的记忆机制来提升其性能，属于构建和演化 LLM 智能体的核心研究范围，符合筛选标准。"
    },
    {
        "index": "#7",
        "title": "Batch-of-Thought: Cross-Instance Learning for Enhanced LLM Reasoning",
        "link": "/arxiv/2601.02950",
        "arxiv_id": "2601.02950",
        "authors": "Xuan Yang, Furong Jia, Roy Xie, Xiong Xi, Hengwei Bian, Jian Li, Monica Agrawal",
        "summary": "Current Large Language Model reasoning systems process queries independently, discarding valuable cross-instance signals such as shared reasoning patterns and consistency constraints. We introduce Batch-of-Thought (BoT), a training-free method that processes related queries jointly to enable cross-instance learning. By performing comparative analysis across batches, BoT identifies high-quality reasoning templates, detects errors through consistency checks, and amortizes computational costs. We instantiate BoT within a multi-agent reflection architecture (BoT-R), where a Reflector performs joint evaluation to unlock mutual information gain unavailable in isolated processing. Experiments across three model families and six benchmarks demonstrate that BoT-R consistently improves accuracy and confidence calibration while reducing inference costs by up to 61%. Our theoretical and experimental analysis reveals when and why batch-aware reasoning benefits LLM systems.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.388304",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（符合 Agentic AI 范畴）**： 虽然论文标题侧重于“推理”，但其核心贡献不仅仅是提出一种新的思维链变体，而是构建了一个名为 **BoT-R (Batch-of-Thought with Reflection)** 的架构。摘要明确指出，该方法是在 **\"multi-agent reflection architecture\"（多智能体反思架构）** 中实例化的。这表明论文的本质是构建了一个包含特定角色（Reflector 智能体）的智能体系统，而非单纯的模型推理能力提升。 2.  **符合正面指标（多智能体与自我反思）**： *   **多智能体**：论文明确提到了 \"multi-agent reflection architecture\"，涉及智能体之间的协作与信息交互（Reflector 执行联合评估以解锁互信息增益）。 *   **自我反思/修正**：论文的核心机制涉及 \"reflection\"（反思）和 \"detects errors\"（检测错误），这属于智能体的自我反思和自我修正能力范畴。 *   **Agentic 框架**：BoT-R 是一种新的 Agentic 框架，用于处理复杂任务，符合“构建、改进 LLM 智能体”的目标。 3.  **排除标准检查**： *   该论文不属于特定领域的非演化型应用（如医疗、法律），而是一种通用的推理架构改进。 *   虽然涉及推理，但它通过多智能体架构来实现，不属于“非 Agentic 的推理”排除项。 *   不涉及安全、对齐、多模态或图等排除领域。 综上所述，该论文通过引入多智能体反思架构来增强 LLM 的推理能力，属于 Agentic AI 和 Multi-Agent Systems 的研究范畴，符合筛选要求。"
    },
    {
        "index": "#19",
        "title": "Learning User Preferences Through Interaction for Long-Term Collaboration",
        "link": "/arxiv/2601.02702",
        "arxiv_id": "2601.02702",
        "authors": "Shuhaib Mehri, Priyanka Kargupta, Tal August, Dilek Hakkani-Tür",
        "summary": "As conversational agents accumulate experience collaborating with users, adapting to user preferences is essential for fostering long-term relationships and improving collaboration quality over time. We introduce MultiSessionCollab, a benchmark that evaluates how well agents can learn user preferences and leverage them to improve collaboration quality throughout multiple sessions. To develop agents that succeed in this setting, we present long-term collaborative agents equipped with a memory that persists and refines user preference as interaction experience accumulates. Moreover, we demonstrate that learning signals can be derived from user simulator behavior in MultiSessionCollab to train agents to generate more comprehensive reflections and update their memory more effectively. Extensive experiments show that equipping agents with memory improves long-term collaboration, yielding higher task success rates, more efficient interactions, and reduced user effort. Finally, we conduct a human user study that demonstrates that memory helps improve user experience in real-world settings.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.394842",
        "filter_reason": "这篇论文完全符合我的研究范围，属于“单智能体”与“自我演化”的交叉领域。 1.  **核心贡献符合要求**：论文的核心在于构建了一种“长期协作智能体”，并提出了相应的基准测试。这不仅仅是应用现有模型，而是提出了一种新的智能体框架，旨在解决智能体如何适应环境（用户）的问题。 2.  **符合“单智能体”方向**：论文明确聚焦于智能体的关键能力——**记忆**和**自我反思**。它详细描述了如何通过持久化的记忆来存储用户偏好，以及如何通过反思机制来更新记忆，这直接对应筛选标准中的“Agentic: 记忆、自我反思”。 3.  **符合“自我演化”方向**：论文强调智能体随着交互经验的积累，能够不断细化用户偏好并改进协作质量。这种通过经验反馈进行迭代改进和自我完善的过程，正是“自我演化”的核心体现。 4.  **排除标准检查**：论文不属于特定领域的非演化型应用（其核心是智能体机制的通用改进），也不涉及安全对齐、多模态或图技术等排除领域。 综上所述，该论文在构建具备记忆和自我演化能力的LLM智能体方面做出了实质性贡献，应予保留。"
    },
    {
        "index": "#22",
        "title": "AWARE-US: Benchmark for Preference-Aware Resolution in Tool-Calling Agents",
        "link": "/arxiv/2601.02643",
        "arxiv_id": "2601.02643",
        "authors": "Mehmet Kurmaz",
        "summary": "Tool-calling conversational agents querying structured databases often face two linked failures: underspecification (missing constraints needed to run a precise query) and infeasibility (the fully specified query returns an empty set because no item satisfies all constraints). Existing work often responds with \"no results\" or relaxes constraints using ad hoc rules, which can violate user intent by discarding requirements the user cares about most. We frame infeasibility handling as a preference-aware query repair problem: when a query is unsatisfiable, the agent should relax the least important constraints to the user. We propose three LLM-based methods for inferring relative constraint importance from dialogue: (1) local weighting, (2) global one-shot weighting, and (3) pairwise ranking. Experiments show local weighting achieves the best preference alignment, while global weighting performs best on correct constraint relaxation. We also introduce AWARE-US, a benchmark of persona-grounded queries requiring agents to disambiguate requests via conversation and resolve infeasibility in a way consistent with persona-implied preferences.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.396220",
        "filter_reason": "这篇论文完全符合我的研究范围，属于“单智能体”方向中的“工具使用”和“规划”子方向。 1.  **核心判断 (第一步)**: *   论文的核心贡献在于提出了一种新的方法论（偏好感知查询修复）和一个基准（AWARE-US），旨在解决“工具调用智能体”在查询结构化数据库时遇到的“不可行性”问题。 *   这不是将智能体简单应用于特定领域（如医疗或金融）的应用型论文，而是针对智能体在工具使用过程中的通用能力缺陷（查询失败处理）进行改进和构建。 *   它不属于基础设施优化，也不是非Agentic的基础推理提升。 2.  **正面指标匹配 (第二步)**: *   论文明确涉及 `LLM-based Agents` 和 `Tool Use / Tool Augmentation`。 *   它关注智能体如何根据对话上下文推断用户意图，并动态调整查询策略（放松约束），这属于智能体的 `Planning` 和决策能力范畴。 3.  **排除标准检查 (第三步)**: *   虽然论文提到了“preference alignment”（偏好对齐），但这里的对齐是指智能体在执行任务时对用户具体约束条件的偏好（例如用户更看重价格还是速度），而非AI安全、伦理或价值观层面的“对齐”。因此，不应被排除。 *   论文不涉及多模态视觉、图技术或安全防御机制。 4.  **特殊处理 (第四步)**: *   论文关于智能体如何处理工具调用失败并进行自我修正（查询修复），属于Agentic的推理与规划范畴，符合保留条件。 综上所述，该论文致力于改进LLM智能体的工具使用鲁棒性和交互规划能力，符合“构建、改进LLM智能体”的核心目标。"
    },
    {
        "index": "#25",
        "title": "SimpleMem: Efficient Lifelong Memory for LLM Agents",
        "link": "/arxiv/2601.02553",
        "arxiv_id": "2601.02553",
        "authors": "Jiaqi Liu, Yaofeng Su, Peng Xia, Siwei Han, Zeyu Zheng, Cihang Xie, Mingyu Ding, Huaxiu Yao",
        "summary": "To support reliable long-term interaction in complex environments, LLM agents require memory systems that efficiently manage historical experiences. Existing approaches either retain full interaction histories via passive context extension, leading to substantial redundancy, or rely on iterative reasoning to filter noise, incurring high token costs. To address this challenge, we introduce SimpleMem, an efficient memory framework based on semantic lossless compression. We propose a three-stage pipeline designed to maximize information density and token utilization: (1) \\textit{Semantic Structured Compression}, which applies entropy-aware filtering to distill unstructured interactions into compact, multi-view indexed memory units; (2) \\textit{Recursive Memory Consolidation}, an asynchronous process that integrates related units into higher-level abstract representations to reduce redundancy; and (3) \\textit{Adaptive Query-Aware Retrieval}, which dynamically adjusts retrieval scope based on query complexity to construct precise context efficiently. Experiments on benchmark datasets show that our method consistently outperforms baseline approaches in accuracy, retrieval efficiency, and inference cost, achieving an average F1 improvement of 26.4% while reducing inference-time token consumption by up to 30-fold, demonstrating a superior balance between performance and efficiency. Code is available at https://github.com/aiming-lab/SimpleMem.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.397879",
        "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（第一步）**： *   论文的核心贡献是提出了 **SimpleMem**，这是一个专门为 **LLM智能体** 设计的高效记忆框架。 *   它属于 **构建/改进 LLM智能体** 的范畴，旨在解决智能体在长期交互中的记忆管理问题，而非将智能体作为工具应用到特定领域（如医疗、金融等），也不是关于基础设施或硬件加速的研究。 2.  **正面指标匹配（第二步）**： *   论文直接涉及 **Agentic AI** 和 **LLM-based Agents** 的核心范式。 *   论文重点解决了智能体的 **Memory（记忆）** 能力，这是单智能体方向的关键子方向之一。摘要中提到的“管理历史经验”、“语义结构化压缩”和“递归记忆整合”都是为了增强智能体的记忆机制，使其能更好地支持长期交互。 3.  **排除标准检查（第三步）**： *   论文不涉及安全、对齐、多模态视觉或图技术等排除项。 综上所述，该论文致力于改进LLM智能体的核心组件（记忆系统），属于单智能体研究范畴，符合“构建、改进或演化 LLM智能体”的核心目标。"
    },
    {
        "index": "#88",
        "title": "Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices",
        "link": "/arxiv/2601.02732",
        "arxiv_id": "2601.02732",
        "authors": "Lingzhe Zhang, Tong Jia, Yunpeng Zhai, Leyi Pan, Chiming Duan, Minghua He, Mengxi Jia, Ying Li",
        "summary": "As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.454481",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心贡献符合“构建LLM智能体”的目标**： 尽管论文的应用场景是微服务中的根因定位（特定领域），但其核心贡献并非简单地将现有LLM作为工具应用，而是提出了一个新的框架 **AMER-RCL**。该框架包含两个关键的智能体组件： *   **Recursive Reasoning RCL engine**：明确被定义为一个**多智能体框架**，用于执行递归推理。 *   **Agentic Memory**：一种智能体记忆机制，用于增量累积和重用推理过程。 2.  **高度匹配“正面指标”**： *   **多智能体**：论文明确提出了多智能体框架来处理告警和细化候选原因。 *   **智能体能力**：涉及 `Memory`（智能体记忆）、`Reasoning`（递归推理）以及 `Multi-Agent` 协作。 *   **核心范式**：论文标题和摘要中多次强调 \"Agentic Memory\" 和 \"Agentic\"，完全符合 Agentic AI 的研究焦点。 3.  **通过“排除标准”和“特殊情况”检查**： *   虽然涉及特定领域（微服务），但根据第四步的“自我演化的应用”逻辑（此处虽非演化，但同理），如果论文的核心是提出一种新的智能体机制（如这里的递归推理+记忆机制），即使应用在特定领域，也应保留。这区别于仅仅调用API解决领域问题的“非演化型应用”。 *   论文不涉及安全、对齐、多模态视觉或图神经网络等排除内容。 综上所述，该论文在构建多智能体框架和智能体记忆机制方面做出了实质性贡献，属于 Agentic AI 和 Multi-Agent Systems 的前沿研究。"
    },
    {
        "index": "#118",
        "title": "The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance",
        "link": "/arxiv/2601.02454",
        "arxiv_id": "2601.02454",
        "authors": "Saba Naqvi, Mohammad Baqar, Nawaz Ali Mohammad",
        "summary": "Software testing has progressed toward intelligent automation, yet current AI-based test generators still suffer from static, single-shot outputs that frequently produce invalid, redundant, or non-executable tests due to the lack of execution aware feedback. This paper introduces an agentic multi-model testing framework a closed-loop, self-correcting system in which a Test Generation Agent, an Execution and Analysis Agent, and a Review and Optimization Agent collaboratively generate, execute, analyze, and refine tests until convergence. By using sandboxed execution, detailed failure reporting, and iterative regeneration or patching of failing tests, the framework autonomously improves test quality and expands coverage. Integrated into a CI/CD-compatible pipeline, it leverages reinforcement signals from coverage metrics and execution outcomes to guide refinement. Empirical evaluations on microservice based applications show up to a 60% reduction in invalid tests, 30% coverage improvement, and significantly reduced human effort compared to single-model baselines demonstrating that multi-agent, feedback-driven loops can evolve software testing into an autonomous, continuously learning quality assurance ecosystem for self-healing, high-reliability codebases.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.468007",
        "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心贡献符合“多智能体”与“自我演化”方向**： 论文的核心贡献是提出了一种“智能体多模型测试框架”。这不仅仅是一个应用，而是一个新的**多智能体系统（MAS）**架构。该系统包含三个具有不同角色的智能体（测试生成、执行与分析、审查与优化），它们通过协作完成任务，这直接对应了筛选标准中的“多智能体”方向。 2.  **具备明确的“自我演化”机制**： 摘要中明确提到这是一个“闭环、自我修正系统”，利用“沙箱执行”和“强化信号”进行“迭代再生或修补”。这种通过环境反馈（执行结果、覆盖率指标）来引导智能体自主改进和迭代的过程，完全符合“自我演化”中关于自我完善、自我修正和迭代改进的定义。 3.  **属于Agentic AI的构建而非单纯应用**： 虽然论文的应用场景是软件测试（特定领域），但根据筛选标准第四步的“自我演化的应用”例外规则，只要论文的核心是提出一种新的“自我演化”机制或Agentic框架，即使应用在特定领域也应保留。本文重点在于构建了一个能够自主规划、协作和反思的智能体框架，而非简单地将现有LLM作为工具生成测试代码。 综上所述，该论文在多智能体协作、自我修正机制以及闭环演化方面具有明确的方法论贡献，符合“LLM智能体及其演化”的研究课题。"
    }
]