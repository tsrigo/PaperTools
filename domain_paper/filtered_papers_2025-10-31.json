[
    {
        "index": "#6",
        "title": "The Denario project: Deep knowledge AI agents for scientific discovery",
        "link": "/arxiv/2510.26887",
        "arxiv_id": "2510.26887",
        "authors": "Francisco Villaescusa-Navarro, Boris Bolliet, Pablo Villanueva-Domingo, Adrian E. Bayer, Aidan Acquah, Chetana Amancharla, Almog Barzilay-Siegal, Pablo Bermejo, Camille Bilodeau, Pablo Cárdenas Ramírez, Miles Cranmer, Urbano L. França, ChangHoon Hahn, Yan-Fei Jiang, Raul Jimenez, Jun-Young Lee, Antonio Lerario, Osman Mamun, Thomas Meier, Anupam A. Ojha, Pavlos Protopapas, Shimanto Roy, David N. Spergel, Pedro Tarancón-Álvarez, Ujjwal Tiwari, Matteo Viel, Digvijay Wadekar, Chi Wang, Bonny Y. Wang, Licong Xu, Yossi Yovel, Shuwen Yue, Wen-Han Zhou, Qiyao Zhu, Jiajun Zou, Íñigo Zubeldia",
        "summary": "We present Denario, an AI multi-agent system designed to serve as a scientific research assistant. Denario can perform many different tasks, such as generating ideas, checking the literature, developing research plans, writing and executing code, making plots, and drafting and reviewing a scientific paper. The system has a modular architecture, allowing it to handle specific tasks, such as generating an idea, or carrying out end-to-end scientific analysis using Cmbagent as a deep-research backend. In this work, we describe in detail Denario and its modules, and illustrate its capabilities by presenting multiple AI-generated papers generated by it in many different scientific disciplines such as astrophysics, biology, biophysics, biomedical informatics, chemistry, material science, mathematical physics, medicine, neuroscience and planetary science. Denario also excels at combining ideas from different disciplines, and we illustrate this by showing a paper that applies methods from quantum physics and machine learning to astrophysical data. We report the evaluations performed on these papers by domain experts, who provided both numerical scores and review-like feedback. We then highlight the strengths, weaknesses, and limitations of the current system. Finally, we discuss the ethical implications of AI-driven research and reflect on how such technology relates to the philosophy of science. We publicly release the code at https://github.com/AstroPilot-AI/Denario. A Denario demo can also be run directly on the web at https://huggingface.co/spaces/astropilot-ai/Denario, and the full app will be deployed on the cloud.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning, Multiagent Systems",
        "date": "2025-10-30",
        "category": "cs.MA",
        "crawl_time": "2025-11-03T11:00:04.010113",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **核心判断 (第一步):** - **保留:** 这篇论文的本质是**构建并详细描述了一个名为 Denario 的AI多智能体系统**。其核心贡献是这个系统本身，包括其模块化架构、设计理念以及实现各种复杂任务（如生成想法、规划、使用工具、撰写论文）的能力。这完全符合“构建、改进或演化 LLM智能体”的核心目标。 - **排除项分析:** 它不属于“非演化型应用”。虽然论文展示了该系统在多个科学领域的应用，但这只是为了评估和展示其能力，其核心贡献是智能体系统本身，而非应用成果。它也不是关于提升LLM基础推理能力或基础设施的研究。 2.  **正面指标 (第二步):** - 论文摘要中明确包含了多个核心正面指标，直接命中你的研究焦点： - **核心范式:** `Multi-Agent Systems (MAS)` (明确指出是 \"AI multi-agent system\")。 - **智能体能力:** `Planning` (\"developing research plans\"), `Tool Use / Tool Augmentation` (\"writing and executing code\"), `Memory` (\"checking the literature\")。 - **多智能体:** `Collaboration` (作为一个多智能体系统，其设计必然包含智能体间的协作)。 3.  **排除标准 (第三步):** - 论文的主要贡献不在于安全、对齐或多模态技术。虽然摘要末尾提到了“伦理 implications”，但这只是讨论部分，并非论文的核心技术贡献。因此，它没有触发任何排除标准。 4.  **特殊和模糊情况 (第四步):** - **推理/规划:** 论文涉及智能体如何进行“developing research plans”，这属于智能体在复杂任务中的规划和多步推理，符合保留条件。 **最终决策 (第五步):** 综合分析，这篇论文的核心是提出并实现了一个用于科学发现的LLM多智能体框架。它直接贡献于“多智能体”这一研究方向，并涵盖了“单智能体”的规划、工具使用等关键能力。它不是一篇应用论文，而是一篇关于智能体系统构建的方法论论文。因此，该论文是关于构建和改进LLM智能体的前沿研究，完全符合你的筛选要求。"
    },
    {
        "index": "#7",
        "title": "LAFA: Agentic LLM-Driven Federated Analytics over Decentralized Data Sources",
        "link": "/arxiv/2510.18477",
        "arxiv_id": "2510.18477",
        "authors": "Haichao Ji, Zibo Wang, Yifei Zhu, Meng han, Dan Wang, Zhu Han",
        "summary": "Large Language Models (LLMs) have shown great promise in automating data analytics tasks by interpreting natural language queries and generating multi-operation execution plans. However, existing LLM-agent-based analytics frameworks operate under the assumption of centralized data access, offering little to no privacy protection. In contrast, federated analytics (FA) enables privacy-preserving computation across distributed data sources, but lacks support for natural language input and requires structured, machine-readable queries. In this work, we present LAFA, the first system that integrates LLM-agent-based data analytics with FA. LAFA introduces a hierarchical multi-agent architecture that accepts natural language queries and transforms them into optimized, executable FA workflows. A coarse-grained planner first decomposes complex queries into sub-queries, while a fine-grained planner maps each subquery into a Directed Acyclic Graph of FA operations using prior structural knowledge. To improve execution efficiency, an optimizer agent rewrites and merges multiple DAGs, eliminating redundant operations and minimizing computational and communicational overhead. Our experiments demonstrate that LAFA consistently outperforms baseline prompting strategies by achieving higher execution plan success rates and reducing resource-intensive FA operations by a substantial margin. This work establishes a practical foundation for privacy-preserving, LLM-driven analytics that supports natural language input in the FA setting.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-21",
        "category": "cs.MA",
        "crawl_time": "2025-11-03T11:00:04.010380",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断——论文的本质是构建新的智能体框架。** 论文的核心贡献并非简单地将LLM智能体作为工具应用于“联邦分析”这一特定领域，而是**提出了一种全新的“分层多智能体架构”**来解决该领域的问题。摘要中明确指出，该系统包含“一个粗粒度规划器”、“一个细粒度规划器”和“一个优化器智能体”。这表明论文的重点在于**设计、构建和协调多个专业化智能体**，这直接命中了您研究目标中的“构建、改进或演化LLM智能体”以及“多智能体”方向。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——论文高度契合核心关注点。** 论文摘要中包含了大量您关注的核心范式和能力关键词： *   **核心范式**: `Agentic LLM` (标题中), `Multi-Agent Systems` (分层多智能体架构)。 *   **智能体能力**: `Planning` (粗粒度规划器、细粒度规划器)。 *   **多智能体**: `Collaboration` (多个智能体协同工作，规划器分解任务，优化器进行优化)。 这些正面指标强有力地证明了论文与您的研究焦点高度相关。 3.  **第三步：排除标准——论文未触及排除领域。** 论文的主要贡献是关于智能体架构和任务规划，而非安全、对齐、可解释性或多模态。它虽然涉及隐私（通过联邦分析实现），但这是其应用场景的特性，而非论文的核心方法论贡献。因此，它安全地避开了所有排除标准。 4.  **第四步：处理特殊和模糊情况——论文是“智能体规划”的典型范例。** 该论文完美地符合“保留”规则。它不是在提升LLM的基础推理能力，而是在研究**智能体如何进行复杂的规划和多步推理**。具体来说，它描述了智能体如何将一个高级自然语言查询分解为子查询，再将其映射为可执行的工作流（DAG），并进行优化。这正是您所关注的“智能体在复杂任务中进行多步推理”的范畴。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**提出了一种新颖的多智能体协作框架来解决复杂的规划问题**。它直接对齐了您研究课题中的“多智能体”和“单智能体（规划）”两个核心方向。因此，这篇论文是您应该保留的前沿研究。"
    },
    {
        "index": "#4",
        "title": "MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval",
        "link": "/arxiv/2510.27569",
        "arxiv_id": "2510.27569",
        "authors": "Qi Luo, Xiaonan Li, Yuxin Wang, Tingshuo Fan, Yuan Li, Xinchi Chen, Xipeng Qiu",
        "summary": "Large Language Models (LLMs) excel at reasoning and generation but are inherently limited by static pretraining data, resulting in factual inaccuracies and weak adaptability to new information. Retrieval-Augmented Generation (RAG) addresses this issue by grounding LLMs in external knowledge; However, the effectiveness of RAG critically depends on whether the model can adequately access relevant information. Existing RAG systems rely on a single retriever with fixed top-k selection, restricting access to a narrow and static subset of the corpus. As a result, this single-retriever paradigm has become the primary bottleneck for comprehensive external information acquisition, especially in tasks requiring corpus-level reasoning. To overcome this limitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG framework that enables LLMs to dynamically coordinate multiple retrieval mechanisms for broader and more precise information access. MARAG-R1 equips the model with four retrieval tools -- semantic search, keyword search, filtering, and aggregation -- and learns both how and when to use them through a two-stage training process: supervised fine-tuning followed by reinforcement learning. This design allows the model to interleave reasoning and retrieval, progressively gathering sufficient evidence for corpus-level synthesis. Experiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that MARAG-R1 substantially outperforms strong baselines and achieves new state-of-the-art results in corpus-level reasoning tasks.",
        "subjects": "Computation and Language",
        "date": "2025-10-31",
        "category": "cs.CL",
        "crawl_time": "2025-11-03T11:00:04.936186",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进一个LLM智能体框架。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将RAG技术应用于某个领域，而是提出了一种全新的、更高级的RAG框架——**MARAG-R1**。其核心创新点在于将LLM从一个被动接收检索结果的模型，转变为一个能够**主动决策、动态协调多种工具**的智能体。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不属于“非演化型应用”，因为其贡献是方法论层面的，而非应用层面的。 2.  **第二步：正面指标** - 论文与您的核心关注点高度契合： - **核心范式**: 论文标题和摘要中明确提到了 **`Agentic Retrieval`**，直接点明了其Agentic AI的属性。 - **智能体能力**: 论文的核心是 **`Tool Use / Tool Augmentation`**。它为LLM配备了四种检索工具（语义搜索、关键词搜索等），并让LLM学习如何以及何时使用它们。这直接对应了“工具使用”这一关键能力。 - **智能体能力**: 论文描述的“interleave reasoning and retrieval, progressively gathering sufficient evidence”是典型的 **`Planning`** 和多步推理过程，与 **`ReAct`** 范式思想一致。智能体需要规划一个行动序列（使用哪个工具、何时使用）来达成最终目标。 3.  **第三步：排除标准** - 论文的主要贡献是提升智能体的信息获取和推理能力，不涉及安全、对齐、可解释性或视觉多模态等排除领域。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”的典型案例。它研究的不是LLM本身的基础数学或逻辑能力，而是**智能体如何在一个复杂任务（语料库级推理）中进行规划和行动**。通过动态选择工具来逐步收集证据，这正是Agentic框架下的高级推理能力。 **总结**: 该论文的核心贡献是提出了一个名为MARAG-R1的**多工具智能体框架**，通过强化学习让LLM学会在复杂任务中自主规划和协调多种检索工具。这直接命中了您研究课题中的**“单智能体”**方向，特别是**“工具使用”**和**“规划”**这两个子方向。它不是对现有技术的简单应用，而是对LLM智能体能力本身的实质性增强，因此是一篇非常相关且高质量的前沿论文。"
    },
    {
        "index": "#15",
        "title": "Dynamic Affective Memory Management for Personalized LLM Agents",
        "link": "/arxiv/2510.27418",
        "arxiv_id": "2510.27418",
        "authors": "Junfeng Lu, Yueyan Li",
        "summary": "Advances in large language models are making personalized AI agents a new research focus. While current agent systems primarily rely on personalized external memory databases to deliver customized experiences, they face challenges such as memory redundancy, memory staleness, and poor memory-context integration, largely due to the lack of effective memory updates during interaction. To tackle these issues, we propose a new memory management system designed for affective scenarios. Our approach employs a Bayesian-inspired memory update algorithm with the concept of memory entropy, enabling the agent to autonomously maintain a dynamically updated memory vector database by minimizing global entropy to provide more personalized services. To better evaluate the system's effectiveness in this context, we propose DABench, a benchmark focusing on emotional expression and emotional change toward objects. Experimental results demonstrate that, our system achieves superior performance in personalization, logical coherence, and accuracy. Ablation studies further validate the effectiveness of the Bayesian-inspired update mechanism in alleviating memory bloat. Our work offers new insights into the design of long-term memory systems.",
        "subjects": "Computation and Language",
        "date": "2025-10-31",
        "category": "cs.CL",
        "crawl_time": "2025-11-03T11:00:04.947520",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建和改进LLM智能体的一个核心组件——记忆系统**。它没有将智能体作为工具去解决某个外部领域的问题，而是聚焦于智能体内部的机制。论文的核心贡献是提出了一种“新的记忆管理系统”和“受贝叶斯启发的记忆更新算法”，这直接属于构建和改进LLM智能体的方法论范畴。 2.  **第二步：正面指标** - 论文高度符合您的核心关注点： - **核心范式**: 论文明确研究 `LLM-based Agents`。 - **智能体能力**: 论文的核心是 `Memory`（记忆）管理。更进一步，它提出的“动态更新”和“自主维护”机制，触及了 `Self-Evolving`（自我演化）的范畴，因为智能体的内部状态（记忆）能够根据交互进行迭代和优化。 - **演化机制**: 论文的“动态更新”和“最小化全局熵”的算法，本质上是一种 `Iterative Improvement`（迭代改进）机制，使智能体的记忆能够自我完善。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。其主要贡献是关于记忆管理算法和系统设计，而非安全、对齐或多模态技术。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及需要特殊处理的模糊情况。它不是关于基础LLM推理能力的提升，而是关于一个完整的Agentic能力（记忆）的改进。它也不是一个特定领域的应用，而是一个通用的智能体组件设计。 **核心依据总结**: 该论文的核心贡献在于**提出了一种新颖的、动态的、能够自主更新的记忆管理系统**，用于提升个性化LLM智能体的能力。这直接命中了您研究目标中的“**构建、改进或演化 LLM智能体**”。具体来说，它属于“**单智能体**”方向下的“**记忆**”子方向，并且其“动态更新”和“自主维护”的特性也体现了“**自我演化**”的思想。因此，这篇论文是您研究课题下的高度相关前沿文献。"
    },
    {
        "index": "#25",
        "title": "Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs",
        "link": "/arxiv/2510.27246",
        "arxiv_id": "2510.27246",
        "authors": "Mohammad Tavakoli, Alireza Salemi, Carrie Ye, Mohamed Abdalla, Hamed Zamani, J Ross Mitchell",
        "summary": "Evaluating the abilities of large language models (LLMs) for tasks that require long-term memory and thus long-context reasoning, for example in conversational settings, is hampered by the existing benchmarks, which often lack narrative coherence, cover narrow domains, and only test simple recall-oriented tasks. This paper introduces a comprehensive solution to these challenges. First, we present a novel framework for automatically generating long (up to 10M tokens), coherent, and topically diverse conversations, accompanied by probing questions targeting a wide range of memory abilities. From this, we construct BEAM, a new benchmark comprising 100 conversations and 2,000 validated questions. Second, to enhance model performance, we propose LIGHT-a framework inspired by human cognition that equips LLMs with three complementary memory systems: a long-term episodic memory, a short-term working memory, and a scratchpad for accumulating salient facts. Our experiments on BEAM reveal that even LLMs with 1M token context windows (with and without retrieval-augmentation) struggle as dialogues lengthen. In contrast, LIGHT consistently improves performance across various models, achieving an average improvement of 3.5%-12.69% over the strongest baselines, depending on the backbone LLM. An ablation study further confirms the contribution of each memory component.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-10-31",
        "category": "cs.CL",
        "crawl_time": "2025-11-03T11:00:04.957756",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了 **LIGHT 框架**，这是一个旨在**增强LLM长期记忆能力**的新方法论。该框架通过为LLM配备三种互补的记忆系统（长期情景记忆、短期工作记忆、关键事实便笺本）来构建一个更强大的智能体。这直接对应了您筛选标准中的“构建、改进或演化 LLM智能体”，属于对智能体核心能力的**改进**。它并非将现有智能体作为工具应用到特定领域，也不是关于基础模型推理或基础设施的研究。 2.  **第二步：正面指标——高度匹配** 论文与您的核心关注点高度契合： *   **核心范式**: 论文的工作本质上是 `Agentic AI` 和 `LLM-based Agents` 的研究。 *   **智能体能力**: 论文的绝对核心是 `Memory`（记忆）。它不仅提出了记忆系统，还构建了专门的基准（BEAM）来评估这种能力。此外，`scratchpad for accumulating salient facts`（积累关键事实的便笺本）也与智能体的 `Self-Reflection`（自我反思）或信息处理过程密切相关。 3.  **第三步：排除标准——未触及** 论文的研究焦点是智能体的架构和能力提升，完全没有涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题，也未涉及 `Vision` 或多模态内容。 4.  **第四步：处理特殊和模糊情况** 论文的研究内容不涉及推理/规划的特殊情况，也不属于自我演化的应用。它清晰地聚焦于为智能体构建一个关键的内部组件——记忆系统。 **最终决策**: 这篇论文的核心贡献是提出了一种名为LIGHT的新框架，通过赋予LLM复杂的记忆系统来**构建和改进LLM智能体**。这完全符合您“单智能体”研究方向中的“记忆”子方向。论文不仅提出了改进方法，还配套创建了新的评测基准，是一项非常扎实和前沿的Agentic AI研究。因此，应判定为 **True**。"
    },
    {
        "index": "#47",
        "title": "SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning",
        "link": "/arxiv/2510.27568",
        "arxiv_id": "2510.27568",
        "authors": "Ali Asgarov, Umid Suleymanov, Aadyant Khatri",
        "summary": "Solving mathematical reasoning problems requires not only accurate access to relevant knowledge but also careful, multi-step thinking. However, current retrieval-augmented models often rely on a single perspective, follow inflexible search strategies, and struggle to effectively combine information from multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge Integration for AGentic Mathematical reAsoning), a unified framework that orchestrates specialized agents to independently reason, perform targeted searches, and synthesize findings through a moderator mechanism. Each agent generates hypothetical passages to optimize retrieval for its analytic perspective, ensuring knowledge integration is both context-sensitive and computation-efficient. When evaluated on challenging benchmarks such as MATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms both open- and closed-source systems, achieving an absolute performance improvement of 7.4%. Our results demonstrate that multi-agent, on-demand knowledge integration significantly enhances both reasoning accuracy and efficiency, offering a scalable approach for complex, knowledge-intensive problem-solving. We will release the code upon publication.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-31",
        "category": "cs.CL",
        "crawl_time": "2025-11-03T11:00:04.979182",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于数学领域，而是提出了一种名为SIGMA的**新框架**。其核心贡献在于**构建和改进一个多智能体系统**，以解决知识密集型推理问题。摘要明确指出，这是一个“orchestrates specialized agents”（编排专门智能体）的“unified framework”（统一框架），这完全符合您对“构建、改进LLM智能体”的核心目标要求。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 摘要中明确提到了 `Agentic Mathematical Reasoning` 和 `multi-agent`，直接命中了 `Agentic AI` 和 `Multi-Agent Systems (MAS)`。 - **智能体能力**: 论文描述了智能体能够 `independently reason`（独立推理，涉及规划）和 `perform targeted searches`（执行定向搜索，属于工具使用）。 - **多智能体**: 论文的核心就是关于多智能体的 `Collaboration`（协作），通过一个 `moderator mechanism`（协调者机制）来 `synthesize findings`（综合发现），这是一种典型的多智能体协作模式。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐或可解释性，也没有涉及多模态或视觉。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文属于“保留”情况。它不是在研究如何提升LLM本身的基础数学能力，而是在研究一个**智能体框架（SIGMA）如何通过多智能体协作和工具使用来完成复杂的数学推理任务**。这与ReAct、ToT等Agentic框架的研究思路一脉相承，是关于智能体“如何做”规划与推理，而非LLM“如何做”推理。 **核心依据总结**: 该论文的核心贡献是**SIGMA框架本身**，一个用于知识整合的多智能体系统。它通过编排多个专门的智能体进行独立推理、搜索和协作，从而提升整体推理能力。这直接对应了您研究焦点中的**“多智能体”**方向，并涉及了**“单智能体”**方向中的规划和工具使用能力。因此，这篇论文是关于Agentic AI方法论的前沿研究，完全符合您的筛选要求。"
    },
    {
        "index": "#54",
        "title": "DRAMA: Unifying Data Retrieval and Analysis for Open-Domain Analytic Queries",
        "link": "/arxiv/2510.27238",
        "arxiv_id": "2510.27238",
        "authors": "Chuxuan Hu, Maxwell Yang, James Weiland, Yeji Lim, Suhas Palawala, Daniel Kang",
        "summary": "Manually conducting real-world data analyses is labor-intensive and inefficient. Despite numerous attempts to automate data science workflows, none of the existing paradigms or systems fully demonstrate all three key capabilities required to support them effectively: (1) open-domain data collection, (2) structured data transformation, and (3) analytic reasoning. To overcome these limitations, we propose DRAMA, an end-to-end paradigm that answers users' analytic queries in natural language on large-scale open-domain data. DRAMA unifies data collection, transformation, and analysis as a single pipeline. To quantitatively evaluate system performance on tasks representative of DRAMA, we construct a benchmark, DRAMA-Bench, consisting of two categories of tasks: claim verification and question answering, each comprising 100 instances. These tasks are derived from real-world applications that have gained significant public attention and require the retrieval and analysis of open-domain data. We develop DRAMA-Bot, a multi-agent system designed following DRAMA. It comprises a data retriever that collects and transforms data by coordinating the execution of sub-agents, and a data analyzer that performs structured reasoning over the retrieved data. We evaluate DRAMA-Bot on DRAMA-Bench together with five state-of-the-art baseline agents. DRAMA-Bot achieves 86.5% task accuracy at a cost of $0.05, outperforming all baselines with up to 6.9 times the accuracy and less than 1/6 of the cost. DRAMA is publicly available at https://github.com/uiuc-kang-lab/drama.",
        "subjects": "Databases, Artificial Intelligence, Computation and Language, Information Retrieval",
        "date": "2025-10-31",
        "category": "cs.CL",
        "crawl_time": "2025-11-03T11:00:04.992942",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非将LLM智能体作为工具应用于某个特定领域，而是**提出并构建了一个新的多智能体系统（Multi-Agent System）——DRAMA-Bot**。论文的本质是关于如何设计、构建和协调多个智能体（数据检索器、数据分析器、子智能体）来完成一个复杂的端到端任务。这直接命中了你研究目标中的“多智能体”方向，属于构建和改进LLM智能体的方法论研究，因此应予以保留。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量你的核心关注点： *   **核心范式**: 明确提出了一个 `Multi-Agent System`。 *   **智能体能力**: 整个系统涉及 `Planning`（如何协调子智能体执行任务）、`Tool Use`（数据检索和转换必然涉及工具调用）和 `ReAct` 式的推理循环（接收查询 -> 检索 -> 分析 -> 得出答案）。 *   **多智能体**: 论文的核心就是关于 `Collaboration`（协作）和 `Communication`（通信）。摘要明确指出，数据检索器通过“协调子智能体的执行”来工作，这体现了智能体间的协作与通信机制。 3.  **第三步：排除标准 (不涉及)** 论文的主要贡献不在于安全、对齐、可解释性，也未涉及视觉或多模态内容。它完全聚焦于智能体的系统架构和任务执行能力，因此不触犯任何排除标准。 4.  **第四步：特殊和模糊情况 (不适用)** 论文不涉及自我演化，因此相关特殊规则不适用。对于推理/规划，论文讨论的是智能体框架如何进行多步规划和推理，而非提升LLM本身的基础能力，这符合保留条件。 **总结**: 这篇论文的核心是提出一个名为DRAMA的新范式，并实现了一个名为DRAMA-Bot的多智能体系统来解决开放域数据分析问题。其贡献在于**智能体系统的架构设计、角色分工（数据检索器、数据分析器）和协作机制**，这正是你“多智能体”研究方向的典型范例。虽然其应用场景是数据分析，但论文的焦点是“如何构建这个智能体系统”，而不是“用智能体解决某个数据分析问题”，因此它不是一篇简单的应用型论文，而是一篇关于Agentic AI系统构建的前沿研究。"
    },
    {
        "index": "#56",
        "title": "Glia: A Human-Inspired AI for Automated Systems Design and Optimization",
        "link": "/arxiv/2510.27176",
        "arxiv_id": "2510.27176",
        "authors": "Pouya Hamadanian, Pantea Karimi, Arash Nasr-Esfahany, Kimia Noorbakhsh, Joseph Chandler, Ali ParandehGheibi, Mohammad Alizadeh, Hari Balakrishnan",
        "summary": "Can an AI autonomously design mechanisms for computer systems on par with the creativity and reasoning of human experts? We present Glia, an AI architecture for networked systems design that uses large language models (LLMs) in a human-inspired, multi-agent workflow. Each agent specializes in reasoning, experimentation, and analysis, collaborating through an evaluation framework that grounds abstract reasoning in empirical feedback. Unlike prior ML-for-systems methods that optimize black-box policies, Glia generates interpretable designs and exposes its reasoning process. When applied to a distributed GPU cluster for LLM inference, it produces new algorithms for request routing, scheduling, and auto-scaling that perform at human-expert levels in significantly less time, while yielding novel insights into workload behavior. Our results suggest that by combining reasoning LLMs with structured experimentation, an AI can produce creative and understandable designs for complex systems problems.",
        "subjects": "Artificial Intelligence, Computation and Language, Distributed, Parallel, and Cluster Computing",
        "date": "2025-10-31",
        "category": "cs.CL",
        "crawl_time": "2025-11-03T11:00:04.993947",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接对应了“多智能体”和“自我演化”两个核心方向。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献是提出一个名为“Glia”的**AI架构**，该架构采用**多智能体工作流**来设计计算机系统。这并非简单地将现有LLM或智能体框架作为工具应用，而是**构建了一个新的多智能体系统方法论**。 - 摘要中明确指出，该系统通过“evaluation framework that grounds abstract reasoning in empirical feedback”（一个将抽象推理与经验反馈相结合的评估框架）来工作。这描述了一个**迭代、自我完善的过程**，属于“自我演化”的范畴。 - 因此，论文的本质是关于**构建和改进多智能体系统**，并使其具备**自我演化**的能力，完全符合保留标准。 2.  **第二步：正面指标——高度匹配** - 论文摘要中包含了大量你的核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` (明确提到 \"multi-agent workflow\"), `Self-Evolving` (通过实验和反馈迭代改进)。 - **智能体能力**: `Reasoning` (每个智能体专门负责推理)。 - **多智能体**: `Collaboration` (智能体之间通过评估框架协作)。 - **演化机制**: `Iterative Improvement` (整个工作流就是一个迭代改进的过程)。 3.  **第三步：排除标准——未触发** - 论文虽然提到了“interpretable designs”（可解释的设计），但这只是其架构带来的一个优点，并非论文的主要研究贡献。论文的核心是架构本身，而不是对可解释性（XAI）的深入研究。 - 论文不涉及安全、对齐或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况——适用例外规则** - 这篇论文是“自我演化的应用”的完美范例。虽然它被应用在“分布式GPU集群”这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**——即一个由多个专门智能体（推理、实验、分析）协作，并通过结构化实验和反馈来迭代优化设计的框架。根据你的规则，这种情况应该保留。 **最终决策**: 这篇论文的核心贡献在于**构建了一个新颖的多智能体协作框架（Glia），该框架通过结构化的实验和反馈循环实现了自我演化和迭代优化**。它直接研究了“多智能体”如何“协作”，以及智能体如何通过“环境反馈”进行“自我演化”，这与你的研究目标“LLM智能体及其演化”高度契合。因此，应予以保留。"
    },
    {
        "index": "#62",
        "title": "CATArena: Evaluation of LLM Agents through Iterative Tournament Competitions",
        "link": "/arxiv/2510.26852",
        "arxiv_id": "2510.26852",
        "authors": "Lingyue Fu, Xin Ding, Yaoming Zhu, Shao Zhang, Lin Qiu, Weiwen Liu, Weinan Zhang, Xuezhi Cao, Xunliang Cai, Jiaxin Ding, Yong Yu",
        "summary": "Large Language Model (LLM) agents have evolved from basic text generation to autonomously completing complex tasks through interaction with external tools. However, current benchmarks mainly assess end-to-end performance in fixed scenarios, restricting evaluation to specific skills and suffering from score saturation and growing dependence on expert annotation as agent capabilities improve. In this work, we emphasize the importance of learning ability, including both self-improvement and peer-learning, as a core driver for agent evolution toward human-level intelligence. We propose an iterative, competitive peer-learning framework, which allows agents to refine and optimize their strategies through repeated interactions and feedback, thereby systematically evaluating their learning capabilities. To address the score saturation issue in current benchmarks, we introduce CATArena, a tournament-style evaluation platform featuring four diverse board and card games with open-ended scoring. By providing tasks without explicit upper score limits, CATArena enables continuous and dynamic evaluation of rapidly advancing agent capabilities. Experimental results and analyses involving both minimal and commercial code agents demonstrate that CATArena provides reliable, stable, and scalable benchmarking for core agent abilities, particularly learning ability and strategy coding.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-30",
        "category": "cs.CL",
        "crawl_time": "2025-11-03T11:00:05.101184",
        "filter_reason": "这篇论文完全符合研究范围。其核心贡献在于提出了一种新颖的、用于驱动和评估LLM智能体演化的方法论，精准地命中了“自我演化”和“多智能体”两个核心研究方向。 具体判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个外部领域的问题，也不是单纯提升LLM的基础推理能力。它的核心贡献是构建了一个**“迭代的、竞争性的同伴学习框架”**。这个框架本身就是一个方法论，其目的是让智能体通过相互竞争和学习来**“优化和完善其策略”**，这直接对应了“改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)`, `Self-Evolving`。 - **多智能体**: `Collaboration` (隐含在同伴学习中), `Communication` (隐含在交互中), `Agent Society` (锦标赛形式)。 - **演化机制**: `Self-Improvement`, `Iterative Improvement`。摘要中明确指出，其框架关注“学习能力”，包括“自我改进”和“同伴学习”，并允许智能体通过“重复的交互和反馈”进行迭代优化。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性，也未聚焦于多模态或视觉。因此，所有排除标准均未触发。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文关注的是智能体在竞争环境中如何学习和优化策略，这是一个更高层次的、与环境和其他智能体交互的演化过程，而非提升LLM本身的基础数学或逻辑推理能力。因此符合保留条件。 - **自我演化的应用**: 这篇论文提出的框架是通用的，并非局限于特定领域，但其核心思想——提出一种新的“自我演化”机制（通过竞争性同伴学习）——与筛选标准中的“例外”条款精神完全一致，即核心贡献是演化机制本身。 **最终决策**: 综合以上分析，该论文的核心贡献是构建了一个促进LLM智能体通过多智能体交互进行自我演化的框架。它不仅提出了一个评估平台，更重要的是提出了一种驱动智能体演化的新范式。这完全符合“构建、改进或演化LLM智能体”的核心目标，特别是在“多智能体”和“自我演化”两个方向上。因此，应予以保留。"
    },
    {
        "index": "#48",
        "title": "Towards Understanding Self-play for LLM Reasoning",
        "link": "/arxiv/2510.27072",
        "arxiv_id": "2510.27072",
        "authors": "Justin Yang Chae, Md Tanvirul Alam, Nidhi Rastogi",
        "summary": "Recent advances in large language model (LLM) reasoning, led by reinforcement learning with verifiable rewards (RLVR), have inspired self-play post-training, where models improve by generating and solving their own problems. While self-play has shown strong in-domain and out-of-domain gains, the mechanisms behind these improvements remain poorly understood. In this work, we analyze the training dynamics of self-play through the lens of the Absolute Zero Reasoner, comparing it against RLVR and supervised fine-tuning (SFT). Our study examines parameter update sparsity, entropy dynamics of token distributions, and alternative proposer reward functions. We further connect these dynamics to reasoning performance using pass@k evaluations. Together, our findings clarify how self-play differs from other post-training strategies, highlight its inherent limitations, and point toward future directions for improving LLM math reasoning through self-play.",
        "subjects": "Machine Learning",
        "date": "2025-10-31",
        "category": "cs.LG",
        "crawl_time": "2025-11-03T11:00:05.294990",
        "filter_reason": "这篇论文符合您的研究范围，应被保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心是关于“self-play”（自我博弈）这种训练方法。自我博弈是一种模型通过生成和解决自己的问题来进行自我提升的机制。这本质上是一种**自我演化** 的过程，完全符合您在第一步中定义的“保留”标准：“如果论文的核心是关于构建LLM智能体、多智能体系统 或 自我演化 的方法论或新框架”。虽然论文侧重于“理解”而非“构建”，但对核心演化机制的深入分析是改进和演化智能体的关键前提，因此属于研究范畴。 2.  **正面指标 (第二步):** 论文内容与您的核心关注点高度匹配。 *   **核心范式:** 论文的核心主题 `Self-play` 是 `Self-Evolving` 的一种具体实现形式。 *   **演化机制:** 论文研究了模型如何通过 `Self-Improvement` 和 `Iterative Improvement` 来提升自身能力。 3.  **排除标准 (第三步):** 论文不涉及任何排除标准。它没有讨论安全、对齐、可解释性，也没有涉及多模态或视觉内容。 4.  **特殊和模糊情况处理 (第四步):** *   **推理/规划:** 这是最关键的一点。虽然论文标题和摘要提到了“LLM Reasoning”，但其研究重点并非提出一种新的、非Agentic的推理技巧（如新的CoT变体）来提升LLM的基础数学能力。相反，它研究的是**“self-play”这一演化过程如何影响推理能力**。它关注的是“模型如何通过自我演化来变得更强”，而不是“如何让模型在单次推理中表现更好”。这完全符合您对“保留”关于智能体如何进行规划和多步推理框架的要求，因为自我博弈本身就是一个复杂的、多步的、目标导向的迭代过程。 **总结:** 该论文的核心贡献在于深入剖析了一种名为“自我博弈”的LLM自我演化机制。它不是简单地将LLM作为工具应用，也不是研究非Agentic的基础推理，而是聚焦于智能体如何通过与环境（自己生成的问题）交互并进行迭代式自我完善。这直接命中了您“自我演化”的研究焦点，因此是一篇高度相关的前沿论文。"
    },
    {
        "index": "#85",
        "title": "Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action with Foundation Models via Scene Graphs",
        "link": "/arxiv/2510.27558",
        "arxiv_id": "2510.27558",
        "authors": "Sushil Samuel Dinesh, Shinkyu Park",
        "summary": "This paper presents a framework that leverages pre-trained foundation models for robotic manipulation without domain-specific training. The framework integrates off-the-shelf models, combining multimodal perception from foundation models with a general-purpose reasoning model capable of robust task sequencing. Scene graphs, dynamically maintained within the framework, provide spatial awareness and enable consistent reasoning about the environment. The framework is evaluated through a series of tabletop robotic manipulation experiments, and the results highlight its potential for building robotic manipulation systems directly on top of off-the-shelf foundation models.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2025-10-31",
        "category": "cs.LG",
        "crawl_time": "2025-11-03T11:00:05.333496",
        "filter_reason": "这篇论文符合筛选标准，应当保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个**新的框架**，该框架将基础模型（包括多模态感知模型和通用推理模型）结合起来，以实现复杂的机器人操作任务。其核心贡献在于这个**框架本身的设计**，即如何通过场景图来维护环境状态，并指导一个通用推理模型进行任务序列规划。这完全符合“构建、改进LLM智能体”的核心目标。它并非简单地将一个已有的智能体框架（如ReAct）直接应用到机器人领域，而是提出了一个包含感知、记忆（场景图）、规划和执行的新颖智能体架构。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: 论文构建了一个典型的 `LLM-based Agent` 框架。 - **智能体能力**: 论文的核心是 `Planning`（任务序列规划），并通过动态维护的 `Scene Graphs` 实现了一种结构化的 `Memory`，用于环境感知和状态推理。机器人手臂本身可以被视为智能体执行物理动作的 `Tool`。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐或幻觉等问题。 - **多模态与视觉**: 论文确实涉及了 `Multimodal Perception`，但根据筛选规则，视觉在这里是作为智能体**感知环境的工具**而存在的，是智能体框架的一个组成部分，而非研究的核心。研究的核心是如何利用这种感知进行规划和行动，因此这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确属于“保留”情况。它研究的是智能体如何进行**任务序列规划**，这是智能体在复杂环境中进行多步推理和行动的关键能力，完全属于Agentic AI的范畴，而非提升LLM本身的基础推理能力。 5.  **第五步：最终决策** - 综合以上分析，尽管论文的应用领域是机器人操作，但其**核心贡献在于提出了一种新颖的LLM智能体框架**，该框架重点解决了智能体的规划、记忆和感知集成问题。这完全契合研究课题中“单智能体”方向下的“规划”和“记忆”子方向。因此，这篇论文高度相关，应当被保留。"
    },
    {
        "index": "#107",
        "title": "AURA: A Reinforcement Learning Framework for AI-Driven Adaptive Conversational Surveys",
        "link": "/arxiv/2510.27126",
        "arxiv_id": "2510.27126",
        "authors": "Jinwen Tang, Yi Shang",
        "summary": "Conventional online surveys provide limited personalization, often resulting in low engagement and superficial responses. Although AI survey chatbots improve convenience, most are still reactive: they rely on fixed dialogue trees or static prompt templates and therefore cannot adapt within a session to fit individual users, which leads to generic follow-ups and weak response quality. We address these limitations with AURA (Adaptive Understanding through Reinforcement Learning for Assessment), a reinforcement learning framework for AI-driven adaptive conversational surveys. AURA quantifies response quality using a four-dimensional LSDE metric (Length, Self-disclosure, Emotion, and Specificity) and selects follow-up question types via an epsilon-greedy policy that updates the expected quality gain within each session. Initialized with priors extracted from 96 prior campus-climate conversations (467 total chatbot-user exchanges), the system balances exploration and exploitation across 10-15 dialogue exchanges, dynamically adapting to individual participants in real time. In controlled evaluations, AURA achieved a +0.12 mean gain in response quality and a statistically significant improvement over non-adaptive baselines (p=0.044, d=0.66), driven by a 63% reduction in specification prompts and a 10x increase in validation behavior. These results demonstrate that reinforcement learning can give survey chatbots improved adaptivity, transforming static questionnaires into interactive, self-improving assessment systems.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Machine Learning",
        "date": "2025-10-31",
        "category": "cs.LG",
        "crawl_time": "2025-11-03T11:00:05.366433",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于调查领域，而是提出了一个名为AURA的**强化学习框架**，其核心贡献在于使AI驱动的对话系统能够**在会话中实时自适应和自我改进**。论文明确指出其目标是“transforming static questionnaires into interactive, self-improving assessment systems”。这种基于环境反馈（用户回答的LSDE质量分数）来动态调整自身行为（选择后续问题）的机制，完全符合“自我演化”的定义，即“智能体通过经验、反思或环境反馈进行自我完善和迭代”。因此，它不是一个简单的非演化型应用，而是一个关于智能体演化方法论的论文。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Agentic AI` (AURA是一个自主决策的对话智能体), `Self-Evolving` (论文的核心主题)。 - **智能体能力**: `Planning` (智能体规划下一步要问什么问题)。 - **演化机制**: `Self-Improvement` (明确提及), `Iterative Improvement` (通过强化学习在会话中迭代更新策略)。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。其焦点是提升智能体的适应性和性能，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它被应用在“对话式调查”这一特定领域，但其**核心贡献是AURA这个自我演化的框架本身**，而不是调查结果。它提出了一种新的、通用的机制（基于RL的自适应策略），使智能体能够根据实时反馈进行演化。根据筛选规则，这种情况应该保留。 - **推理/规划**: 论文中的智能体通过epsilon-greedy策略选择后续问题，这是一种在多轮对话中进行规划和决策的Agentic行为，而非提升LLM本身的基础推理能力，因此符合保留条件。 **最终决策**: 综合以上分析，尽管论文的应用场景是调查，但其核心贡献在于构建了一个能够通过强化学习进行实时自我调整和改进的LLM智能体框架。这直接命中了研究课题中的“自我演化”方向。因此，这篇论文与我的研究目标高度相关，应被保留。"
    },
    {
        "index": "#110",
        "title": "Adaptive Data Flywheel: Applying MAPE Control Loops to AI Agent Improvement",
        "link": "/arxiv/2510.27051",
        "arxiv_id": "2510.27051",
        "authors": "Aaditya Shukla, Sidney Knowles, Meenakshi Madugula, Dave Farris, Ryan Angilly, Santiago Pombo, Anbang Xu, Lu An, Abhinav Balasubramanian, Tan Yu, Jiaxiang Ren, Rama Akkiraju",
        "summary": "Enterprise AI agents must continuously adapt to maintain accuracy, reduce latency, and remain aligned with user needs. We present a practical implementation of a data flywheel in NVInfo AI, NVIDIA's Mixture-of-Experts (MoE) Knowledge Assistant serving over 30,000 employees. By operationalizing a MAPE-driven data flywheel, we built a closed-loop system that systematically addresses failures in retrieval-augmented generation (RAG) pipelines and enables continuous learning. Over a 3-month post-deployment period, we monitored feedback and collected 495 negative samples. Analysis revealed two major failure modes: routing errors (5.25\\%) and query rephrasal errors (3.2\\%). Using NVIDIA NeMo microservices, we implemented targeted improvements through fine-tuning. For routing, we replaced a Llama 3.1 70B model with a fine-tuned 8B variant, achieving 96\\% accuracy, a 10x reduction in model size, and 70\\% latency improvement. For query rephrasal, fine-tuning yielded a 3.7\\% gain in accuracy and a 40\\% latency reduction. Our approach demonstrates how human-in-the-loop (HITL) feedback, when structured within a data flywheel, transforms enterprise AI agents into self-improving systems. Key learnings include approaches to ensure agent robustness despite limited user feedback, navigating privacy constraints, and executing staged rollouts in production. This work offers a repeatable blueprint for building robust, adaptive enterprise AI agents capable of learning from real-world usage at scale.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-30",
        "category": "cs.LG",
        "crawl_time": "2025-11-03T11:00:05.373594",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非简单地将LLM应用于企业知识问答，而是提出并实现了一个名为“MAPE驱动的数据飞轮”的**方法论和框架**。这个框架构建了一个闭环系统，通过监控、分析、规划和执行（MAPE）的循环，利用真实世界的反馈（包括人工反馈）来**持续改进和演化**AI智能体。这完全符合你筛选标准中“构建、改进或演化 LLM智能体”的核心要求，特别是“自我演化”方向。 2.  **第二步：正面指标 (高度匹配)** 论文中充满了与你研究焦点高度相关的关键词和概念： *   **核心范式**: 论文的核心是构建一个 `Self-Evolving` 的 `LLM-based Agent`。 *   **演化机制**: 论文明确提出了 `Self-Improvement` (自我完善) 和 `Iterative Improvement` (迭代改进) 的机制，即通过收集失败样本进行微调，实现智能体的性能提升。 *   **智能体能力**: 论文解决了智能体在执行任务时的具体问题，如 `Tool Use` (检索增强生成RAG) 中的路由和查询改写错误，这些都是智能体能力的关键组成部分。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献不是关于安全、对齐、可解释性或多模态。虽然提到了隐私约束，但这只是实现过程中的一个挑战，而非研究的核心贡献。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况 (完美契合)** 这篇论文是“自我演化的应用”这一特殊情况的绝佳范例。虽然它被应用在“企业AI智能体”这一特定领域，但其**核心贡献是提出了一种新的、可复制的“自我演化”机制（MAPE数据飞轮）**。根据你的规则，即使应用在特定领域，只要核心是提出新的演化机制，就应该保留。论文明确指出，其目标是提供一个“可重复的蓝图”，这证明了其方法论的普适性，而非单一领域的应用。 **总结**: 该论文的本质是提出一个让AI智能体通过环境反馈和人工干预进行**自我完善和持续演化**的系统性框架。这精准地命中了你研究课题中的“自我演化”方向，并且其贡献是方法论层面的，而非简单的应用。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#5",
        "title": "VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation",
        "link": "/arxiv/2510.27617",
        "arxiv_id": "2510.27617",
        "authors": "Heng Ping, Arijit Bhattacharjee, Peiyu Zhang, Shixuan Li, Wei Yang, Anzhe Cheng, Xiaole Zhang, Jesse Thomason, Ali Jannesari, Nesreen Ahmed, Paul Bogdan",
        "summary": "Automation of Register Transfer Level (RTL) design can help developers meet increasing computational demands. Large Language Models (LLMs) show promise for Hardware Description Language (HDL) generation, but face challenges due to limited parametric knowledge and domain-specific constraints. While prompt engineering and fine-tuning have limitations in knowledge coverage and training costs, multi-agent architectures offer a training-free paradigm to enhance reasoning through collaborative generation. However, current multi-agent approaches suffer from two critical deficiencies: susceptibility to noise propagation and constrained reasoning space exploration. We propose VeriMoA, a training-free mixture-of-agents (MoA) framework with two synergistic innovations. First, a quality-guided caching mechanism to maintain all intermediate HDL outputs and enables quality-based ranking and selection across the entire generation process, encouraging knowledge accumulation over layers of reasoning. Second, a multi-path generation strategy that leverages C++ and Python as intermediate representations, decomposing specification-to-HDL translation into two-stage processes that exploit LLM fluency in high-resource languages while promoting solution diversity. Comprehensive experiments on VerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves 15--30% improvements in Pass@1 across diverse LLM backbones, especially enabling smaller models to match larger models and fine-tuned alternatives without requiring costly training.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-31",
        "category": "cs.AI",
        "crawl_time": "2025-11-03T11:00:05.277565",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为VeriMoA的、新颖的多智能体框架，用于提升LLM在复杂任务（Spec-to-HDL生成）中的表现。这完全符合您研究范围中的“多智能体”方向，并且触及了“单智能体”的规划与工具使用能力。 以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断——保留** - 论文的本质是**构建和改进一个多智能体框架**。它没有将现有的智能体框架简单地应用到一个新领域，而是识别了当前多智能体方法（噪声传播、推理空间受限）的缺陷，并提出了具体的创新机制（质量引导缓存、多路径生成）来解决这些问题。因此，它不是“非演化型应用”，而是关于智能体架构本身的研究。 2.  **第二步：正面指标——高度匹配** - **核心范式**: 论文明确提出了 `Mixture-of-Agents (MoA)` 框架，直接命中 `Multi-Agent Systems (MAS)`。 - **智能体能力**: - `Planning`: 论文通过“将规范到HDL的翻译分解为两阶段过程”来体现智能体的规划能力。 - `Tool Use / Tool Augmentation`: 论文利用 `C++` 和 `Python` 作为中间表示，这可以被视为智能体使用不同“工具”或“语言”来分解和解决问题。 - **多智能体**: 论文的核心是 `Collaboration`（协作生成），旨在通过多个智能体的协作来增强推理能力。 3.  **第三步：排除标准——未命中** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态。它的焦点是智能体的架构和性能提升。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何进行规划和推理的典型案例。它不是在提升LLM的基础Token预测能力，而是在构建一个让LLM能够进行更复杂、多步推理的Agentic框架（通过协作和任务分解）。这完全符合“保留”标准。 **最终决策**: 尽管论文的实验验证是在硬件设计（HDL生成）这一特定领域进行的，但这仅仅是作为评估其智能体框架有效性的**测试平台**。论文的**核心贡献**在于提出了一种通用的、可训练的多智能体协作框架，并设计了创新的机制来提升其性能。这与您“构建、改进或演化LLM智能体”的核心目标高度一致，特别是聚焦于“多智能体”的协作与推理。因此，这篇论文应该被保留。"
    },
    {
        "index": "#2",
        "title": "Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout for Long-Horizon Task Training",
        "link": "/arxiv/2510.27630",
        "arxiv_id": "2510.27630",
        "authors": "Dayuan Fu, Yunze Wu, Xiaojie Cai, Lyumanshan Ye, Shijie Xia, Zhen Huang, Weiye Si, Tianze Xu, Jie Sun, Keyu Li, Mohan Jiang, Junfei Wang, Qishuo Hua, Pengrui Lu, Yang Xiao, Pengfei Liu",
        "summary": "Large Language Model (LLM) agents have recently shown strong potential in domains such as automated coding, deep research, and graphical user interface manipulation. However, training them to succeed on long-horizon, domain-specialized tasks remains challenging. Current methods primarily fall into two categories. The first relies on dense human annotations through behavior cloning, which is prohibitively expensive for long-horizon tasks that can take days or months. The second depends on outcome-driven sampling, which often collapses due to the rarity of valid positive trajectories on domain-specialized tasks. We introduce Apollo, a sampling framework that integrates asynchronous human guidance with action-level data filtering. Instead of requiring annotators to shadow every step, Apollo allows them to intervene only when the agent drifts from a promising trajectory, by providing prior knowledge, strategic advice, etc. This lightweight design makes it possible to sustain interactions for over 30 hours and produces valuable trajectories at a lower cost. Apollo then applies supervision control to filter out sub-optimal actions and prevent error propagation. Together, these components enable reliable and effective data collection in long-horizon environments. To demonstrate the effectiveness of Apollo, we evaluate it using InnovatorBench. Our experiments show that when applied to train the GLM-4.5 model on InnovatorBench, Apollo achieves more than a 50% improvement over the untrained baseline and a 28% improvement over a variant trained without human interaction. These results highlight the critical role of human-in-the-loop sampling and the robustness of Apollo's design in handling long-horizon, domain-specialized tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-31",
        "category": "cs.AI",
        "crawl_time": "2025-11-03T11:00:05.276077",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断——论文的本质是构建/改进LLM智能体的方法论。** 论文的核心贡献是提出了一个名为 **Apollo** 的全新**采样框架**。这个框架并非将现有智能体作为工具去解决某个特定领域的问题，而是专注于**如何训练LLM智能体**，使其能够更好地完成长时程、专业化的任务。这直接命中了您“构建、改进或演化 LLM智能体”的核心目标。它解决的是智能体训练过程中的根本性挑战（数据稀疏、成本高昂），因此属于方法论层面的创新，应予以保留。 2.  **第二步：正面指标——论文紧密围绕核心关注点。** 论文摘要中充满了您关注的核心范式和能力： *   **核心范式**: 论文明确研究 `LLM-based Agents`。 *   **智能体能力**: 论文的核心是解决 `long-horizon tasks`，这直接关联到智能体的**规划**能力。其提出的“监督控制以过滤次优动作”机制，可以看作是一种引导下的**自我纠错**和**迭代改进**过程。 *   **演化机制**: 整个Apollo框架的设计目标就是通过人机交互和数据过滤，让智能体在训练过程中不断**自我完善**，获得更强的任务执行能力。这是一种明确的**自我演化**机制。 3.  **第三步：排除标准——论文不涉及安全、对齐或多模态等焦点之外的内容。** 论文的研究焦点是提升智能体的任务执行性能和训练效率，完全没有涉及 `Safety`, `Alignment`, `Interpretability` 或 `Vision` 等排除标准中的关键词。 4.  **第四步：处理特殊和模糊情况——论文属于智能体框架内的规划与演化。** *   **推理/规划**: 论文研究的不是LLM基础的数学或逻辑推理，而是智能体在复杂、多步骤任务中的**规划和执行能力**。Apollo框架旨在生成高质量的“轨迹”，这正是智能体规划和行动的体现，符合保留条件。 *   **自我演化的应用**: 论文的核心贡献是**Apollo这个“自我演化”的训练机制本身**。虽然它在 `InnovatorBench` 这个基准上进行了评估，但评估是为了证明该机制的有效性，而非将机制作为某个领域应用的附属品。这完全符合您“即使应用在特定领域，只要核心是新的自我演化机制就保留”的规则。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种创新的、用于训练和改进LLM智能体的框架（Apollo），旨在提升其在长时程任务中的规划和执行能力。这完全契合您关于“LLM智能体及其演化”的研究课题，特别是在**单智能体**的**规划**能力和**自我演化**的训练机制方面。因此，应判定为符合要求。"
    },
    {
        "index": "#13",
        "title": "ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool Use",
        "link": "/arxiv/2510.27363",
        "arxiv_id": "2510.27363",
        "authors": "Mengjie Deng, Guanting Dong, Zhicheng Dou",
        "summary": "Recently, large language models (LLMs) have demonstrated remarkable problem-solving capabilities by autonomously integrating with external tools for collaborative reasoning. However, due to the inherently complex and diverse nature of multimodal information, enabling multimodal large language models (MLLMs) to flexibly and efficiently utilize external tools during reasoning remains an underexplored challenge. In this work, we introduce ToolScope, an agentic framework designed to unify global planning with local multimodal perception, adopting a specialized Perceive tool to mitigates visual context degradation in long-horizon VQA task. ToolScope comprises three primary components: the Global Navigator, the Agentic Executor, and the Response Synthesizer. The Global Navigator functions as a \"telescope\", offering high-level strategic guidance. The Agentic Executor operates iteratively to augment MLLM with local perception through the integration of external tools-Search, Code, and Perceive. Finally, the Response Synthesizer consolidates and organizes the reasoning process into a coherent, user-friendly output. We evaluate ToolScope on four VQA benchmarks across diverse domains, including VQA 2.0, ScienceQA, MAT-Search and MathVista. It demonstrates strong generalization capabilities, achieving an average performance improvement of up to +6.69% across all datasets.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-31",
        "category": "cs.AI",
        "crawl_time": "2025-11-03T11:00:05.286554",
        "filter_reason": "这篇论文符合研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出一个名为 **ToolScope 的智能体框架**。摘要明确指出，这是一个旨在“统一全局规划与局部多模态感知”的“agentic framework”。它不是简单地将现有智能体应用到一个新领域，而是构建了一个新的方法论和架构来解决“如何让MLLMs灵活高效地利用外部工具”这一根本性问题。这完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标 (高度相关)** 论文包含了多个核心关注点： *   **核心范式**: 标题和摘要中直接使用了 `Agentic Framework`。 *   **智能体能力**: 论文的核心是 `Tool Use`，并且明确提出了 `Planning` 能力（通过 `Global Navigator` 组件提供“高级战略指导”）。其迭代执行的 `Agentic Executor` 与 `ReAct` 等推理-行动循环范式高度相似。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题。 *   **多模态与视觉**: 这是一个关键点。虽然论文处理的是视觉任务（VQA）并使用了MLLMs，但它符合排除标准中的**例外情况**。论文的研究核心**不是**改进视觉模型本身，而是构建一个能够**将视觉感知作为工具来使用**的智能体框架。`Perceive` 工具是智能体能力的一部分，而不是研究的主体。因此，这属于“智能体感知环境的工具”，而非被排除的“多模态与视觉”核心研究。 4.  **第四步：特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文明确提出了一个用于高层规划的 `Global Navigator` 和一个用于迭代执行的 `Agentic Executor`。这完全符合“保留关于智能体如何进行规划或在复杂任务中进行多步推理”的论文的规则。它不是在提升LLM的基础Token预测能力，而是在构建一个智能体的规划与执行框架。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的智能体框架（ToolScope），以增强LLM智能体在长时程、多模态任务中的规划和工具使用能力。它直接对“单智能体”方向下的“规划”和“工具使用”子方向做出了方法论贡献，完全符合“构建、改进或演化LLM智能体”的核心研究目标。因此，应判定为 **True**。"
    },
    {
        "index": "#11",
        "title": "Dialogue as Discovery: Navigating Human Intent Through Principled Inquiry",
        "link": "/arxiv/2510.27410",
        "arxiv_id": "2510.27410",
        "authors": "Jianwen Sun, Yukang Feng, Yifan Chang, Chuanhao Li, Zizhen Li, Jiaxin Ai, Fanrui Zhang, Yu Dai, Kaipeng Zhang",
        "summary": "A fundamental bottleneck in human-AI collaboration is the \"intention expression gap,\" the difficulty for humans to effectively convey complex, high-dimensional thoughts to AI. This challenge often traps users in inefficient trial-and-error loops and is exacerbated by the diverse expertise levels of users. We reframe this problem from passive instruction following to a Socratic collaboration paradigm, proposing an agent that actively probes for information to resolve its uncertainty about user intent. we name the proposed agent Nous, trained to acquire proficiency in this inquiry policy. The core mechanism of Nous is a training framework grounded in the first principles of information theory. Within this framework, we define the information gain from dialogue as an intrinsic reward signal, which is fundamentally equivalent to the reduction of Shannon entropy over a structured task space. This reward design enables us to avoid reliance on costly human preference annotations or external reward models. To validate our framework, we develop an automated simulation pipeline to generate a large-scale, preference-based dataset for the challenging task of scientific diagram generation. Comprehensive experiments, including ablations, subjective and objective evaluations, and tests across user expertise levels, demonstrate the effectiveness of our proposed framework. Nous achieves leading efficiency and output quality, while remaining robust to varying user expertise. Moreover, its design is domain-agnostic, and we show evidence of generalization beyond diagram generation. Experimental results prove that our work offers a principled, scalable, and adaptive paradigm for resolving uncertainty about user intent in complex human-AI collaboration.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-31",
        "category": "cs.AI",
        "crawl_time": "2025-11-03T11:00:05.285688",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。以下是基于您筛选标准的详细判断过程： 1.  **第一步：核心判断——保留** - **论文本质**: 这篇论文的核心贡献是提出了一种名为Nous的新型LLM智能体，以及一个基于信息论第一原理的训练框架，用于训练该智能体掌握主动探究用户意图的策略。这并非将已有智能体作为工具应用到特定领域，而是**提出了一种构建和改进LLM智能体的新方法论和新框架**。 - **排除项分析**: - **非演化型应用**: 论文虽然以“科学图表生成”作为验证任务，但这仅仅是其训练框架和智能体能力的**验证平台**。论文的核心是那个“领域无关”的训练框架和主动探究的智能体范式，而非图表生成本身。因此，它不属于非演化型应用。 - **非Agentic的推理**: 论文的研究内容恰恰是Agentic推理的核心。它不是在提升LLM的基础数学或逻辑能力，而是在研究智能体如何通过**主动规划（规划对话策略）**来解决“意图表达差距”这一复杂任务。 - **基础设施**: 论文不涉及模型部署或硬件加速。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文明确提出了一个`LLM-based Agent`（Nous），其研究范式属于`Agentic AI`。 - **智能体能力**: 论文的核心机制——主动探查信息以解决不确定性——是高级`Planning`（规划对话步骤以获取信息）和`Self-Correction`/`Self-Reflection`（认识到自身对用户意图的理解存在不确定性，并主动采取行动修正）的完美体现。智能体通过多轮对话迭代地完善对任务的理解，这是一种`Iterative Improvement`。 3.  **第三步：排除标准——未命中** - **安全与对齐**: 论文的主要贡献是关于提升人机协作的效率和智能体的意图理解能力，而非安全、对齐或可解释性。 - **多模态与视觉**: 论文的应用场景涉及“科学图表生成”，这属于视觉范畴。但是，根据您的核心规则，视觉在这里是智能体与外部世界交互的**输出模态或工具**，而不是研究的核心。研究的核心是驱动智能体进行有效对话的**内在机制和训练框架**，因此不应被排除。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 这篇论文是“保留”情况的典型范例。它研究的正是智能体如何在复杂、不确定的任务（理解人类意图）中进行规划和多步推理（通过苏格拉底式的提问）。其提出的“探究策略”就是一种新颖的Agentic规划框架。 **最终决策**: 该论文的核心贡献在于构建了一个具备主动规划和自我修正能力的LLM智能体，并提出了一套新颖的、基于信息论的训练框架来塑造这种能力。它直接推动了“单智能体”方向中关于规划和自我反思的研究，完全符合您“构建、改进或演化LLM智能体”的核心目标。因此，应判定为符合要求。"
    },
    {
        "index": "#17",
        "title": "GUI-Rise: Structured Reasoning and History Summarization for GUI Navigation",
        "link": "/arxiv/2510.27210",
        "arxiv_id": "2510.27210",
        "authors": "Tao Liu, Chongyu Wang, Rongjie Li, Yingchen Yu, Xuming He, Bai Song",
        "summary": "While Multimodal Large Language Models (MLLMs) have advanced GUI navigation agents, current approaches face limitations in cross-domain generalization and effective history utilization. We present a reasoning-enhanced framework that systematically integrates structured reasoning, action prediction, and history summarization. The structured reasoning component generates coherent Chain-of-Thought analyses combining progress estimation and decision reasoning, which inform both immediate action predictions and compact history summaries for future steps. Based on this framework, we train a GUI agent, \\textbf{GUI-Rise}, through supervised fine-tuning on pseudo-labeled trajectories and reinforcement learning with Group Relative Policy Optimization (GRPO). This framework employs specialized rewards, including a history-aware objective, directly linking summary quality to subsequent action performance. Comprehensive evaluations on standard benchmarks demonstrate state-of-the-art results under identical training data conditions, with particularly strong performance in out-of-domain scenarios. These findings validate our framework's ability to maintain robust reasoning and generalization across diverse GUI navigation tasks. Code is available at https://leon022.github.io/GUI-Rise.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-31",
        "category": "cs.AI",
        "crawl_time": "2025-11-03T11:00:05.288481",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM智能体应用于GUI导航领域，而是提出了一种**全新的、用于构建和改进LLM智能体的框架**。其核心贡献是“reasoning-enhanced framework”，该框架系统性地集成了`structured reasoning`（结构化推理）、`action prediction`（行动预测）和`history summarization`（历史摘要）。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。它不是在解决一个GUI领域的特定问题，而是在解决智能体本身在执行此类任务时的通用能力短板（如跨域泛化和历史利用）。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **智能体能力**: 明确提到了`Planning`（通过`structured reasoning`和`Chain-of-Thought`实现）、`Memory`（通过`history summarization`实现）和`Self-Correction`/`Self-Reflection`（通过`progress estimation`和`decision reasoning`体现）。 - **核心范式**: 论文的核心是构建一个`LLM-based Agent`（GUI-Rise），其框架设计属于`Agentic AI`的范畴。 - **演化机制**: 论文使用强化学习（GRPO）来训练智能体，并设计了`history-aware objective`（历史感知目标），将摘要质量与后续行动性能直接关联，这是一种通过环境反馈进行自我完善和迭代的机制，符合`Self-Improvement`和`Iterative Improvement`的指标。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及Safety、Alignment、Interpretability等内容。 - **多模态与视觉**: 论文提到了`Multimodal Large Language Models (MLLMs)`，但根据核心规则，它们在这里是作为智能体**感知GUI环境的工具**，而不是研究的核心。研究的核心是围绕这个感知工具构建的推理、记忆和决策框架。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的`structured reasoning`组件是典型的智能体规划机制，它生成用于指导行动的`Chain-of-Thought`，这完全符合“保留”关于智能体如何进行规划的论文的规定。它不是在提升LLM本身的基础推理能力，而是在构建一个让智能体能够进行有效推理的框架。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于提出了一种增强LLM智能体在复杂任务中推理和记忆能力的新框架。它直接隶属于“单智能体”研究方向，重点解决了智能体的`Planning`和`Memory`问题，并通过强化学习引入了`Self-Improvement`机制。尽管其应用场景是GUI导航，但这仅仅是验证其框架有效性的实验平台，论文的真正价值在于其提出的Agentic方法论本身。因此，该论文与“LLM智能体及其演化”的研究课题高度相关。"
    },
    {
        "index": "#21",
        "title": "CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete Mathematical Reasoning",
        "link": "/arxiv/2510.27094",
        "arxiv_id": "2510.27094",
        "authors": "Hamed Mahdavi, Pouria Mahdavinia, Alireza Farhadi, Pegah Mohammadipour, Samira Malek, Majid Daliri, Pedram Mohammadipour, Alireza Hashemi, Amir Khasahmadi, Vasant Honavar",
        "summary": "State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based Olympiad problems to solving most of the IMO 2025 problems, with leading systems reportedly handling 5 of 6 problems. Given this progress, we assess how well these models can grade proofs: detecting errors, judging their severity, and assigning fair scores beyond binary correctness. We study proof-analysis capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we grade on a 1-4 scale with detailed error annotations, and on MathArena solution sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models can reliably flag incorrect (including subtly incorrect) solutions but exhibit calibration gaps in how partial credit is assigned. To address this, we introduce agentic workflows that extract and analyze reference solutions and automatically derive problem-specific rubrics for a multi-step grading process. We instantiate and compare different design choices for the grading workflows, and evaluate their trade-offs. Across our annotated corpus and MathArena, our proposed workflows achieve higher agreement with human grades and more consistent handling of partial credit across metrics. We release all code, data, and prompts/logs to facilitate future research.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-31",
        "category": "cs.AI",
        "crawl_time": "2025-11-03T11:00:05.295597",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地应用LLM去解决数学问题，而是**提出并构建了一种新的“agentic workflows”（智能体工作流）**来解决一个复杂的、多步骤的任务——为数学证明打分。论文的核心贡献在于这个工作流的设计、实例化和比较，这完全符合“构建、改进LLM智能体的方法论或新框架”的要求。它不是非演化型应用，因为它提出的是一种可复用的方法论，而非特定领域的解决方案。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `Agentic AI` / `LLM-based Agents`。摘要中直接使用了“agentic workflows”这一术语。 - **智能体能力**: `Planning`。论文描述的工作流是一个多步骤的规划过程：“extract and analyze reference solutions and automatically derive problem-specific rubrics for a multi-step grading process”。这体现了智能体为完成复杂任务而进行的自主规划和步骤分解。 3.  **第三步：排除标准** - 论文不涉及安全、对齐等排除性主题。 - **关于多模态**: 尽管标题中出现了“Multimodal”，但摘要的核心内容完全集中在**文本推理**（证明、评分标准）和**智能体工作流**的设计上。多模态似乎是其所构建的“Benchmark”（基准测试）的一个特性，而不是其核心贡献“agentic workflows”的组成部分。根据规则“除非它们被用作智能体感知环境的工具，而不是研究的核心”，此处多模态是背景数据，核心是智能体框架，因此不应排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“推理/规划”规则中典型的**保留案例**。它不是在提升LLM的基础数学能力，而是在研究如何构建一个智能体框架来执行复杂的多步推理和规划任务（即评分流程）。这与ReAct、ToT等研究的思路一脉相承，都属于Agentic AI的范畴。 **最终决策:** 综合以上分析，该论文的核心贡献是提出并验证了一种用于复杂任务（数学证明评分）的LLM智能体工作流。这直接命中了您研究目标中的“单智能体”方向，特别是关于智能体的“规划”和“多步推理”能力。虽然其应用场景是数学领域，但其方法论具有普适性，属于对LLM智能体本身的构建和改进，因此完全符合筛选要求。"
    },
    {
        "index": "#117",
        "title": "Heterogeneous Robot Collaboration in Unstructured Environments with Grounded Generative Intelligence",
        "link": "/arxiv/2510.26915",
        "arxiv_id": "2510.26915",
        "authors": "Zachary Ravichandran, Fernando Cladera, Ankit Prabhu, Jason Hughes, Varun Murali, Camillo Taylor, George J. Pappas, Vijay Kumar",
        "summary": "Heterogeneous robot teams operating in realistic settings often must accomplish complex missions requiring collaboration and adaptation to information acquired online. Because robot teams frequently operate in unstructured environments -- uncertain, open-world settings without prior maps -- subtasks must be grounded in robot capabilities and the physical world. While heterogeneous teams have typically been designed for fixed specifications, generative intelligence opens the possibility of teams that can accomplish a wide range of missions described in natural language. However, current large language model (LLM)-enabled teaming methods typically assume well-structured and known environments, limiting deployment in unstructured environments. We present SPINE-HT, a framework that addresses these limitations by grounding the reasoning abilities of LLMs in the context of a heterogeneous robot team through a three-stage process. Given language specifications describing mission goals and team capabilities, an LLM generates grounded subtasks which are validated for feasibility. Subtasks are then assigned to robots based on capabilities such as traversability or perception and refined given feedback collected during online operation. In simulation experiments with closed-loop perception and control, our framework achieves nearly twice the success rate compared to prior LLM-enabled heterogeneous teaming approaches. In real-world experiments with a Clearpath Jackal, a Clearpath Husky, a Boston Dynamics Spot, and a high-altitude UAV, our method achieves an 87\\% success rate in missions requiring reasoning about robot capabilities and refining subtasks with online feedback. More information is provided at https://zacravichandran.github.io/SPINE-HT.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-10-30",
        "category": "cs.AI",
        "crawl_time": "2025-11-03T11:00:05.370137",
        "filter_reason": "这篇论文符合您的研究范围，应当被保留。我的判断过程如下： **第一步：核心判断——保留** 论文的核心贡献是提出一个名为 **SPINE-HT 的新框架**。这个框架并非简单地将现有LLM或智能体框架应用于机器人领域，而是设计了一套完整的方法论来解决“异构机器人在非结构化环境中协作”这一特定挑战。该框架的核心是利用LLM进行**任务生成、分配和基于反馈的迭代优化**。这完全符合“构建、改进LLM智能体”或“构建多智能体系统”的核心要求。因此，它不属于“非演化型应用”的排除范畴。 **第二步：正面指标——高度匹配** 论文包含了您关注的多个核心指标： *   **多智能体:** 论文明确研究“异构机器人团队”的“协作”，这是多智能体系统的典型场景。 *   **智能体能力:** *   **Planning:** LLM的核心作用之一是“生成基于能力的子任务”，这是一种高级的规划能力。 *   **Self-Correction / Refinement:** 框架包含一个关键步骤，即“根据在线操作期间收集的反馈进行优化”，这是一种基于环境反馈的自我修正和迭代改进机制。 *   **演化机制:** “根据在线反馈进行优化”体现了**Iterative Improvement**（迭代改进）的思想，这与“自我演化”的研究方向紧密相关。 **第三步：排除标准——未触发** 论文的主要贡献不在于安全、对齐或可解释性。虽然提到了“闭环感知和控制”，暗示可能使用了视觉，但视觉是作为机器人感知环境的**工具**，而非论文研究的核心。论文的核心是智能体的协作与决策框架，而非视觉模型本身。 **第四步：处理特殊和模糊情况——符合保留条件** *   **推理/规划:** 论文中的规划是典型的**智能体规划**。它不是在提升LLM的基础数学或逻辑推理能力，而是在构建一个让LLM能够为多智能体团队进行复杂任务分解和规划的框架。这完全符合保留条件。 *   **自我演化的应用:** 这是一个典型的“例外”情况。虽然论文应用在机器人这一特定领域，但其核心贡献是提出了一种**新的、包含迭代优化（自我完善）机制的智能体框架**。根据您的规则，这种提出新“自我演化”机制的论文，即使应用在特定领域，也应该保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的多智能体协作框架（SPINE-HT），该框架深度融合了LLM的规划能力、多智能体任务分配以及基于在线反馈的自我修正/迭代优化机制。它直接对应了您研究焦点中的“多智能体”和“自我演化”方向，并且其贡献是方法论层面的，而非简单的应用。因此，这篇论文与您的研究课题高度相关，应予以保留。"
    },
    {
        "index": "#138",
        "title": "VeriStruct: AI-assisted Automated Verification of Data-Structure Modules in Verus",
        "link": "/arxiv/2510.25015",
        "arxiv_id": "2510.25015",
        "authors": "Chuyue Sun, Yican Sun, Daneshvar Amrollahi, Ethan Zhang, Shuvendu Lahiri, Shan Lu, David Dill, Clark Barrett",
        "summary": "We introduce VeriStruct, a novel framework that extends AI-assisted automated verification from single functions to more complex data structure modules in Verus. VeriStruct employs a planner module to orchestrate the systematic generation of abstractions, type invariants, specifications, and proof code. To address the challenge that LLMs often misunderstand Verus' annotation syntax and verification-specific semantics, VeriStruct embeds syntax guidance within prompts and includes a repair stage to automatically correct annotation errors. In an evaluation on eleven Rust data structure modules, VeriStruct succeeds on ten of the eleven, successfully verifying 128 out of 129 functions (99.2%) in total. These results represent an important step toward the goal of automatic AI-assisted formal verification.",
        "subjects": "Software Engineering",
        "date": "2025-10-28",
        "category": "cs.AI",
        "crawl_time": "2025-11-03T11:00:05.392684",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于形式化验证领域，而是提出了一个名为“VeriStruct”的**新框架**。该框架的设计本身具有显著的Agentic特征。它包含一个“planner module”（规划器模块）来“orchestrate”（编排）整个验证流程，以及一个“repair stage”（修复阶段）来自动修正错误。这表明论文的重点是**构建一个具备规划和自我修正能力的LLM智能体**，而不是仅仅将LLM作为一个黑盒工具使用。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **智能体能力**: `Planning`（论文明确提出了“planner module”来系统性地生成验证所需的各种组件）、`Self-Correction`（论文中的“repair stage”是典型的自我修正机制）。 - **核心范式**: 论文构建的`VeriStruct`框架本质上是一个`LLM-based Agent`，用于解决复杂的多步骤任务。 - 这些正面指标强烈表明该论文与我的研究目标高度相关。 3.  **第三步：排除标准** - 论文的主要贡献是关于自动化验证的**方法论和框架**，而不是关于`Safety`、`Security`、`Alignment`或`Interpretability`。虽然形式化验证与安全相关，但本文的焦点是**如何构建智能体来自动化验证过程**，而非验证本身的安全属性或对齐问题。 - 论文不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”条件。它不是在改进LLM的基础数学或逻辑推理能力，而是在构建一个**智能体框架**，该框架利用LLM作为核心引擎，并通过一个**规划器**来分解和执行复杂任务（形式化验证）。这正是Agentic AI中规划能力的体现。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建了一个具备规划和自我修正能力的LLM智能体框架**，以解决自动化形式化验证这一复杂任务。它完全符合我研究范围中的“单智能体”方向，特别是“规划”和“自我反思/修正”这两个子方向。因此，这篇论文应该被保留。"
    }
]