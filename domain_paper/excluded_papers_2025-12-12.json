[
    {
        "index": "#2",
        "title": "Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control",
        "link": "/arxiv/2512.11247",
        "arxiv_id": "2512.11247",
        "authors": "Iftekharul Islam, Weizi Li",
        "subjects": "Multiagent Systems, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.MA",
        "crawl_time": "2025-12-15T11:00:03.479391",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是特定领域的应用，而非LLM智能体的构建。** - 论文的核心贡献是提出一种**多目标强化学习**框架，用于解决**大规模混合交通控制**这一特定领域的问题。其创新点在于设计了“冲突威胁向量”和“队列均等性惩罚”来优化强化学习的奖励函数，以平衡交通的效率、公平性和安全。 - 这完全符合筛选标准中的**排除规则1：非演化型应用**。论文将一个已有的机器学习范式（强化学习）应用到交通控制领域，其目标是解决该领域的具体问题，而不是构建、改进或演化一个通用的LLM智能体框架。 2.  **缺乏核心关注点 (第二步): 未涉及LLM智能体的关键能力。** - 论文中提到的“agents”是强化学习语境下的智能体，即学习最优策略以控制交通信号的决策单元，**并非基于大语言模型（LLM）的智能体**。 - 论文完全没有涉及您关注的核心范式和能力，如 `LLM-based Agents`, `Planning` (在Agentic AI意义上), `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent Communication/Collaboration`, 或 `Self-Evolving`。其“规划”是强化学习策略的体现，而非智能体自主的多步推理规划。 3.  **研究焦点不符 (第三步): 属于机器人/控制领域，而非Agentic AI。** - 论文的研究背景是“机器人车辆”和“混合交通”，这属于机器人学、自动驾驶和智能交通系统（ITS）的范畴。虽然这些领域可能会使用智能体，但本文的核心方法论是强化学习，与您聚焦的“LLM智能体及其演化”这一Agentic AI方向有本质区别。 **总结:** 该论文的核心贡献是**一种应用于交通控制的多目标强化学习方法**，而非一个关于LLM智能体的新框架或演化机制。它使用的是传统的强化学习智能体，而非LLM智能体，其研究目标是解决特定领域的工程问题，这与您筛选“构建、改进或演化LLM智能体”的核心目标完全不符。因此，应予以排除。"
    },
    {
        "index": "#1",
        "title": "Evaluating Cooperative Resilience in Multiagent Systems: A Comparison Between Humans and LLMs",
        "link": "/arxiv/2512.11689",
        "arxiv_id": "2512.11689",
        "authors": "Manuela Chacon-Chamorro, Juan Sebastián Pinzón, Rubén Manrique, Luis Felipe Giraldo, Nicanor Quijano",
        "subjects": "Multiagent Systems",
        "date": "2025-12-12",
        "category": "cs.MA",
        "crawl_time": "2025-12-15T11:00:03.479113",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是评估而非构建。** 论文的核心贡献是提出一个用于**评估**和**比较**人类与LLM智能体在多智能体环境中“合作韧性”的**基准**和**实验框架**。摘要中明确指出：“This experimental design establishes a benchmark for cooperative resilience...”。论文的主体工作是使用这个基准进行对比实验，并报告发现（“we find that human groups...”）。 这完全符合第一步排除标准中的“**非演化型应用**”。该研究将LLM智能体作为研究对象，在一个特定的社会困境环境中测试其行为表现，而不是提出一种新的构建、改进或演化LLM智能体的方法论或框架。我的核心目标是筛选那些**贡献在于“如何构建/改进/演化”**的论文，而这篇论文的贡献在于**“如何评估/比较”**。 2.  **第二步：正面指标——主题相关但贡献不符。** 论文确实包含了我的核心关注点，如“Multi-Agent Systems (MAS)”和“Communication”。这些是论文的研究主题，但并非其核心贡献。一篇论文可以讨论智能体，但如果它的贡献是关于智能体的评估、分析或应用，而不是关于智能体本身的构建和演化，那么它就不符合我的筛选要求。 3.  **第三步与第四步：排除标准与特殊情况。** 该论文不涉及安全对齐或多模态等排除标准。在特殊情况处理中，它也不属于“自我演化的应用”例外，因为它没有提出任何新的自我演化机制。 **最终决策**：尽管这篇论文的研究主题（多智能体协作）与我的研究方向高度相关，但其核心贡献是**评估性**和**分析性**的，而非**构造性**或**演化性**的。它回答的是“现有LLM智能体表现如何？”的问题，而不是“如何构建一个更好的LLM智能体？”的问题。根据第一步的核心判断标准，这类论文属于“非演化型应用”，因此应被排除。"
    },
    {
        "index": "#3",
        "title": "Agile Flight Emerges from Multi-Agent Competitive Racing",
        "link": "/arxiv/2512.11781",
        "arxiv_id": "2512.11781",
        "authors": "Vineet Pasumarti, Lorenzo Bianchi, Antonio Loquercio",
        "subjects": "Robotics, Artificial Intelligence, Multiagent Systems",
        "date": "2025-12-12",
        "category": "cs.MA",
        "crawl_time": "2025-12-15T11:00:03.479662",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于“LLM智能体”的论文，而这篇论文的核心贡献与LLM无关。 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是提出一种通过**多智能体竞争**来训练**强化学习（RL）智能体**的新方法，以实现敏捷的无人机飞行控制。这里的“智能体”是基于强化学习训练的策略网络，用于执行低级物理控制任务（如飞行、超车），而不是基于大语言模型（LLM）进行高级认知任务的智能体。因此，论文的核心是关于**RL智能体**，而非**LLM智能体**。根据筛选标准，这直接偏离了我的核心目标，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文确实包含了 `Multi-Agent Systems (MAS)` 这一正面指标，研究了智能体间的竞争。然而，它完全缺失了最关键的核心范式：`LLM-based Agents`。同时，它也未涉及我所关注的智能体核心能力，如 `Planning`（高级规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）等。论文中的“策略”是行为层面的（如阻挡），而非认知层面的。 3.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的智能体执行的是低级控制，而非我所关注的高级、多步推理或任务规划。它不涉及ReAct、ToT等Agentic推理框架。 - **自我演化的应用**: 论文虽然展示了通过竞争环境“涌现”出更优策略，但这是一种外部训练动态，而非智能体内部的“自我演化”机制（如自我反思、自我修正）。因此，它不符合“自我演化”的核心定义。 **最终决策**: 尽管这篇论文在多智能体强化学习和机器人控制领域可能是一项优秀的工作，但它的研究对象是**RL智能体**，而非我课题核心的**LLM智能体**。它缺少了语言模型、推理、规划、工具使用等LLM智能体的关键要素。因此，这篇论文与我的研究范围“LLM智能体及其演化”存在根本性的偏差，应被排除。"
    },
    {
        "index": "#1",
        "title": "SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support",
        "link": "/arxiv/2512.11755",
        "arxiv_id": "2512.11755",
        "authors": "Yuming Feng, Xinrui Jiang",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.602038",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是构建了一个名为SUMFORU的**个性化评论摘要框架**。它的目标是解决特定领域（电子商务）的问题，即帮助用户根据个人偏好（用户画像）做出购买决策。论文提出的方法（SFT和RLAIF）是用来训练一个模型，使其生成的摘要能够与用户画像“对齐”。这完全符合**“非演化型应用”**的排除标准：它将LLM和先进的微调技术作为工具，应用到一个特定领域去解决该领域的问题，而不是构建一个具有自主能力的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中没有出现您关注的核心范式或智能体能力。它没有涉及`Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）等任何Agentic AI的核心能力。它也不是一个`Multi-Agent`系统，更不涉及`Self-Evolving`（自我演化）机制。因此，没有任何正面指标支持保留该论文。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这是最关键的排除依据。论文的核心方法论和贡献都围绕着**“对齐”**这一概念。摘要中明确提到其方法是“两阶段对齐程序”，目标是“将输出与明确的用户画像对齐”，并评估“偏好对齐”的效果。这直接命中了排除标准中的“只要论文的主要贡献是关于 `Alignment` (对齐)，一律排除”。尽管这里的对齐是“个性化对齐”而非“安全对齐”，但它仍然属于对齐研究的范畴，而非您关注的智能体构建与演化。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及推理/规划或自我演化的特殊情况。它使用的RLAIF是一种训练/对齐技术，而不是智能体在部署后进行自我改进或演化的机制。 **最终决策**: 综合以上分析，该论文的本质是一个**应用型研究**，其核心贡献是提出了一种**模型对齐方法**（个性化对齐）来解决特定领域（电商摘要）的问题。它没有构建、改进或演化一个具有自主规划、工具使用或反思能力的LLM智能体。因此，它严格不符合您关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#6",
        "title": "Bandwidth-constrained Variational Message Encoding for Cooperative Multi-agent Reinforcement Learning",
        "link": "/arxiv/2512.11179",
        "arxiv_id": "2512.11179",
        "authors": "Wei Duan, Jie Lu, En Yu, Junyu Xuan",
        "subjects": "Machine Learning, Multiagent Systems",
        "date": "2025-12-11",
        "category": "cs.MA",
        "crawl_time": "2025-12-15T11:00:03.480457",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“带宽约束变分消息编码（BVME）”的轻量级模块，用于解决**多智能体强化学习（MARL）**中，在通信带宽受限的情况下如何高效编码和传输信息的问题。其研究对象是基于强化学习的智能体，而非基于大语言模型（LLM）的智能体。因此，这篇论文的本质是**改进MARL中的通信效率**，而不是构建、改进或演化**LLM智能体**。根据筛选标准，这属于将智能体框架（此处是MARL框架）应用于解决特定问题（通信压缩），而非对LLM智能体本身进行创新，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文确实包含了我的部分关注点，如 `Multi-Agent Systems (MAS)` 和 `Communication`。然而，它完全缺失了最核心的关键词：`LLM-based Agents`。我的研究焦点是“LLM智能体”，而该论文的智能体是传统的强化学习智能体，两者在底层架构和能力上有本质区别。因此，尽管主题相关，但技术路线和研究对象不符。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除标准。但它在更根本的层面上被排除，因为它不属于“LLM智能体”的范畴。 4.  **第四步：处理特殊和模糊情况** 此处不涉及推理/规划或自我演化的特殊情况。论文提出的BVME是一种在训练期间学习到的静态压缩方法，不涉及智能体在运行时的自我反思、自我完善或迭代演化。 **最终决策**: 综合以上分析，这篇论文是一篇优秀的多智能体强化学习研究，专注于智能体间的通信优化。然而，我的研究课题是“**LLM智能体及其演化**”，核心是**以LLM为大脑的智能体**。该论文的研究对象是传统的强化学习智能体，其贡献（通信压缩算法）并未与LLM结合，也未探讨LLM智能体的规划、记忆、工具使用或自我演化等核心能力。因此，尽管它属于“多智能体”这一大类，但与我的核心研究目标“LLM智能体”存在根本性的偏离，应予以排除。"
    },
    {
        "index": "#8",
        "title": "Agent-Based Modular Learning for Multimodal Emotion Recognition in Human-Agent Systems",
        "link": "/arxiv/2512.10975",
        "arxiv_id": "2512.10975",
        "authors": "Matvey Nepomnyaschiy, Oleg Pereziabov, Anvar Tliamov, Stanislav Mikhailov, Ilya Afanasyev",
        "subjects": "Machine Learning, Artificial Intelligence, Human-Computer Interaction, Multiagent Systems",
        "date": "2025-12-02",
        "category": "cs.MA",
        "crawl_time": "2025-12-15T11:00:03.480985",
        "filter_reason": "这篇论文不符合您的研究范围，主要基于以下几点核心判断： 1.  **核心贡献不匹配（第一步核心判断）**: 论文的核心贡献是提出一个**用于多模态情感识别的模块化多智能体框架**。其本质是利用“智能体”这一概念来设计一个更灵活、可维护的**软件架构**，其中每个模态的编码器和分类器被视为一个独立的“智能体”。这与您研究目标中“构建、改进或演化LLM智能体”的核心关注点有本质区别。您关注的是具有自主规划、工具使用等能力的认知智能体，而本文关注的是工程架构上的模块化设计。 2.  **缺少LLM核心要素（第二步正面指标）**: 您的研究课题明确为“**LLM**智能体及其演化”。然而，通篇摘要并未提及LLM（Large Language Model）。论文中的“智能体”是模态编码器和分类器，它们不一定是基于LLM的。缺少LLM这一核心要素，使其从根本上偏离了您的研究范围。 3.  **触发明确的排除标准（第三步排除标准）**: 论文的核心是“**多模态情感识别**”，明确涉及视觉和音频。根据您的筛选标准，“多模态与视觉”属于排除范畴，除非它们仅被用作智能体感知环境的工具。在这篇论文中，多模态感知本身就是研究的核心和目标，而不是一个服务于更高层次智能体任务的工具。因此，它触发了排除规则。 4.  **不属于自我演化（第一步和第四步）**: 论文强调的是框架的“模块化集成”和“无缝替换”，这体现了架构的灵活性和可维护性，但并非智能体通过经验、反思或环境反馈进行“自我完善和迭代”的演化机制。 综上所述，尽管论文标题和摘要中包含了“Agent-Based”和“Multi-Agent”等关键词，但其研究实质是关于多模态系统的一种新颖的软件架构设计，而非您所关注的、以LLM为核心、具备自主能力和演化特性的Agentic AI。因此，该论文应被排除。"
    },
    {
        "index": "#2",
        "title": "Speculative Decoding Speed-of-Light: Optimal Lower Bounds via Branching Random Walks",
        "link": "/arxiv/2512.11718",
        "arxiv_id": "2512.11718",
        "authors": "Sergey Pankratov, Dan Alistarh",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.602481",
        "filter_reason": "这篇论文不符合研究范围。 其核心贡献是为一种名为“推测解码”的LLM推理加速技术建立了理论性能下界。论文通过将token生成过程类比为分支随机游走，分析了并行token生成的速度极限。 根据筛选标准的第一步“核心判断”，该论文明确属于“基础设施”类别。论文的研究焦点是优化LLM的推理速度和效率，属于模型部署和系统优化的范畴，而非构建、改进或演化LLM智能体的方法论或框架。 具体来说： 1.  **核心贡献错位**：论文的核心是“加速推理”和“运行时间下界”，这是典型的系统优化研究，与Agentic AI的行为、能力或演化机制无关。 2.  **缺乏Agentic元素**：论文内容完全不涉及智能体的规划、记忆、工具使用、自我反思、多智能体协作或自我演化等核心Agentic能力。它关注的是底层的token生成效率，而非高层次的智能体决策过程。 3.  **符合排除标准**：该论文完全符合第一步排除标准中的第3点：“主要关注模型基础设施、部署优化、硬件加速的研究”。 因此，尽管这是一篇关于LLM的前沿研究，但其研究目标与“LLM智能体及其演化”的课题方向存在根本性差异，应予以排除。"
    },
    {
        "index": "#5",
        "title": "Elevation Aware 2D/3D Co-simulation Framework for Large-scale Traffic Flow and High-fidelity Vehicle Dynamics",
        "link": "/arxiv/2512.11249",
        "arxiv_id": "2512.11249",
        "authors": "Chandra Raskoti, Weizi Li",
        "subjects": "Robotics, Multiagent Systems",
        "date": "2025-12-12",
        "category": "cs.MA",
        "crawl_time": "2025-12-15T11:00:03.480199",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是构建一个用于自动驾驶系统测试的、具有高程感知能力的2D/3D协同仿真框架。它整合了SUMO（交通仿真器）和CARLA（3D仿真器），并融合了地理数据，以创建更真实的物理测试环境。 这完全符合第一步中的**排除标准**： *   **非演化型应用**: 该论文是将一个技术框架（仿真环境）应用到特定领域（自动驾驶测试）去解决该领域的问题（缺乏真实地形）。它没有构建或演化LLM智能体，而是为智能体（或自动驾驶算法）提供一个“舞台”。 *   **基础设施**: 论文的核心是关于仿真环境的构建和集成，这属于研究的基础设施层面，而非智能体本身的认知或演化能力。 2.  **第二步：正面指标** 论文的标题和摘要中完全没有出现任何第二步所列的正面指标关键词，如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Self-Reflection`, `Collaboration`, `Self-Improvement` 等。虽然交通流可能涉及多个车辆智能体，但论文的贡献点在于它们所处的物理环境，而非智能体间的交互或智能体自身的决策框架。 3.  **第三步：排除标准** 论文提到了 \"realistic 3D perception\"，但这指的是仿真环境为被测试的自动驾驶系统提供的感知输入，是环境的一部分，而不是论文研究的核心。这符合第三步中关于多模态的排除规则：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉是仿真环境提供的特性，而非论文研究的智能体能力。 4.  **第四步：特殊和模糊情况** 该论文不涉及推理/规划或自我演化的机制，因此第四步的特殊情况不适用。 **最终决策**: 该论文的研究焦点是**仿真工程**和**自动驾驶测试基础设施**，旨在提高物理环境的真实感。它完全没有涉及LLM智能体的构建、规划、协作或自我演化等核心议题。因此，它与“LLM智能体及其演化”的研究目标完全无关，应被排除。"
    },
    {
        "index": "#3",
        "title": "Automating Historical Insight Extraction from Large-Scale Newspaper Archives via Neural Topic Modeling",
        "link": "/arxiv/2512.11635",
        "arxiv_id": "2512.11635",
        "authors": "Keerthana Murugaraj, Salima Lamsiyah, Marten During, Martin Theobald",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.602923",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是**应用**一个已有的神经主题模型（BERTopic）来解决特定领域（历史学研究）的问题。它旨在从报纸档案中提取和分析主题，并追踪这些主题随时间的**演化**。 - **排除依据**: 这完全符合**排除标准1：非演化型应用**。论文将一个基于Transformer的工具（BERTopic）作为“黑盒”或“组件”应用于历史文本分析，其核心目标是解决历史学领域的问题，而不是构建、改进或演化一个LLM智能体本身。论文中提到的“演化”是指**研究对象的演化**（即历史主题的演变），而非**智能体的自我演化**。 2.  **第二步：正面指标** - 论文中完全没有出现您关注的核心范式或能力相关的关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。BERTopic虽然使用了Transformer嵌入，但它本身是一个主题建模工具，而非一个具备自主规划、工具使用或反思能力的智能体框架。 3.  **第三步：排除标准** - 虽然论文不涉及安全对齐或多模态等排除项，但第一步的判断已经足够明确。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是本案例的关键混淆点。论文确实提到了“演化”，但它指的是**追踪数据中主题的演化**，而不是提出一种让智能体自我完善的**机制**。根据规则，只有当论文的核心贡献是提出一种**新的自我演化机制**时，即使应用在特定领域也应保留。本文显然没有提出任何新的智能体演化机制，因此该例外情况不适用。 **最终决策**: 该论文是一篇典型的将AI技术应用于人文社科领域的应用研究。其核心贡献在于验证了BERTopic在历史话语分析中的有效性，而非在LLM智能体的构建、协作或演化方面做出任何方法论上的创新。因此，它严格地落在了您研究范围之外，应予以排除。"
    },
    {
        "index": "#5",
        "title": "Visualizing token importance for black-box language models",
        "link": "/arxiv/2512.11573",
        "arxiv_id": "2512.11573",
        "authors": "Paulius Rauba, Qiyao Wei, Mihaela van der Schaar",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.603824",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为“Distribution-Based Sensitivity Analysis (DBSA)”的方法，用于可视化和理解黑盒LLM的输出对每个输入token的依赖性。这本质上是一种**模型可解释性**和**审计**工具。它并没有构建、改进或演化一个LLM智能体，而是对一个已有的、静态的LLM进行分析。因此，它不属于“构建、改进或演化LLM智能体”的核心范畴。 2.  **排除标准 (第三步):** 论文直接命中了明确的排除标准。摘要中明确提到其目标是“auditing black-box large language models”（审计黑盒大语言模型），并旨在“understand how the outputs... depend on each input token”（理解输出如何依赖于每个输入token）。这完全属于 `Interpretability` (可解释性) 和 `Explainability (XAI)` 的研究范畴。根据我的筛选规则，只要论文的主要贡献是关于可解释性，就应一律排除。 3.  **正面指标缺失 (第二步):** 论文的研究内容与我的核心关注点完全脱节。摘要中完全没有提及任何与 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving` 相关的关键词。它也没有涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory` 或 `Self-Reflection`。 综上所述，尽管这篇论文在LLM安全和可解释性领域可能具有重要价值，但其研究焦点是“理解模型行为”，而非“构建或演化智能体”。这与我关于“LLM智能体及其演化”的研究目标不符，因此应被排除。"
    },
    {
        "index": "#12",
        "title": "Improving Translation Quality by Selecting Better Data for LLM Fine-Tuning: A Comparative Analysis",
        "link": "/arxiv/2512.11388",
        "arxiv_id": "2512.11388",
        "authors": "Felipe Ribeiro Fujita de Mello, Hideyuki Takada",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.642999",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献分析**: 这篇论文的核心贡献是研究如何为机器翻译任务选择更优的微调数据，以提升LLM在特定领域的翻译性能。它对比了多种数据选择策略，并分析了它们对模型效果的影响。 - **是否符合保留标准**: 不符合。论文的核心是关于**数据选择方法**和**模型微调**，而不是构建、改进或演化LLM智能体。 - **是否符合排除标准**: 符合。这完全符合第一条排除标准：“非演化型应用”。论文将LLM微调作为一种技术手段，应用于解决机器翻译这一具体领域的问题，其研究焦点是数据选择策略对模型性能的影响，而非智能体本身。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现任何与我的核心关注点相关的关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步确认了它与我的研究目标无关。 3.  **第三步：排除标准** - 论文不涉及安全、对齐或多模态等排除领域，但这并不改变其因属于“非演化型应用”而被排除的根本原因。 4.  **第四步：特殊和模糊情况** - 论文不涉及推理/规划或自我演化的应用，因此无需启动特殊规则。 **最终决策**: 综合以上分析，这篇论文的研究重点是提升LLM在特定下游任务（机器翻译）上的性能，属于典型的应用型研究。它没有提出任何关于智能体架构、能力或演化机制的新方法。因此，它完全不符合“LLM智能体及其演化”这一研究课题的核心要求，应予以排除。"
    },
    {
        "index": "#8",
        "title": "Building Patient Journeys in Hebrew: A Language Model for Clinical Timeline Extraction",
        "link": "/arxiv/2512.11502",
        "arxiv_id": "2512.11502",
        "authors": "Kai Golan Hashiloni, Brenda Kasabe Nokai, Michal Shevach, Esthy Shemesh, Ronit Bartin, Anna Bergrin, Liran Harel, Nachum Dershowitz, Liat Nadai Arad, Kfir Bar",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.605234",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”。** 论文的核心贡献是构建一个**特定领域（医疗）和特定语言（希伯来语）的语言模型**，用于从电子健康记录中提取临床时间线。这是一个典型的将语言模型作为工具，应用于特定垂直领域（医疗信息学）解决特定问题（时间线提取）的研究。它完全符合筛选标准中的第一条排除规则：“非演化型应用 (Non-Evolving Applications)”。论文的重点在于模型的领域适应性和任务性能，而非构建一个具有自主性、规划或演化能力的智能体。 2.  **第二步：缺乏正面指标。** 论文的摘要和标题中完全没有出现您关注的核心范式关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等。同样，它也未涉及任何智能体能力，如 `Planning`, `Tool Use`, `Self-Reflection` 或多智能体间的 `Collaboration`。其核心是信息提取，而非智能体行为。 3.  **第三步与第四步：不涉及特殊排除情况或模糊地带。** 论文不涉及安全、对齐或多模态等排除标准。同时，它也不属于“推理/规划”或“自我演化的应用”等特殊情况。它没有提出任何关于智能体如何进行多步自主规划的框架，也没有提出任何新的自我演化机制。 **核心依据总结：** 该论文的本质是**领域应用型NLP研究**，而非**智能体架构或演化机制研究**。它构建的是一个更擅长特定任务的“工具”（一个领域微调的BERT模型），而不是一个能够自主规划、使用工具或自我演化的“智能体”。因此，它与您关于“LLM智能体及其演化”的核心研究目标完全不符。"
    },
    {
        "index": "#10",
        "title": "CLINIC: Evaluating Multilingual Trustworthiness in Language Models for Healthcare",
        "link": "/arxiv/2512.11437",
        "arxiv_id": "2512.11437",
        "authors": "Akash Ghosh, Srivarshinee Sridhar, Raghav Kaushik Ravi, Muhsin Muhsin, Sriparna Saha, Chirag Agarwal",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.606084",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出了一个名为 CLINIC 的**评估基准**，用于衡量语言模型在医疗保健领域的多语言可信度。它没有构建、改进或演化任何形式的LLM智能体。这完全符合第一步排除标准中的“**非演化型应用**”，即论文将LLM作为评估对象，应用于特定领域（医疗保健），以解决该领域的评估问题，而非提出新的智能体方法论。 2.  **排除标准 (第三步):** 论文的核心内容与您明确排除的“**安全与对齐**”方向高度重合。摘要明确指出，该基准从五个维度评估模型，其中包括 `truthfulness` (真实性)、`fairness` (公平性)、`safety` (安全性)、`robustness` (鲁棒性) 和 `privacy` (隐私性)。这些都是安全与对齐研究的核心议题。论文的主要目标是“enhancing the global reach and **safety** of LMs in healthcare”，这进一步确认了其研究焦点是模型安全，而非智能体的构建或演化。 3.  **正面指标 (第二步):** 论文中完全没有出现您所关注的核心范式或能力关键词，如 `Agentic AI`、`Planning`、`Tool Use`、`Self-Reflection`、`Multi-Agent Systems` 或 `Self-Evolving` 等。这表明其研究内容与您的核心关注点无关。 综上所述，该论文是一篇关于模型评估与安全性的研究，其核心贡献是基准构建，而非智能体技术的创新。因此，它严格地落在了您研究范围之外。"
    },
    {
        "index": "#7",
        "title": "Does Less Hallucination Mean Less Creativity? An Empirical Investigation in LLMs",
        "link": "/arxiv/2512.11509",
        "arxiv_id": "2512.11509",
        "authors": "Mohor Banerjee, Nadya Yuki Wangsajaya, Syed Ali Redha Alsagoff, Min Sen Tan, Zachary Choy Kit Chun, Alvin Chan Guo Wei",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.604751",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文的核心贡献是实证研究，而非智能体构建。** 该论文的本质是一项**实证调查**，旨在评估现有的三种减少幻觉的技术（CoVe, DoLa, RAG）对LLM创造力的影响。它并没有提出任何新的LLM智能体框架、多智能体协作机制或自我演化方法。论文的研究对象是“技术对模型输出属性的影响”，而不是“如何构建或改进一个智能体”。这属于对LLM基础行为和特性的研究，而非Agentic AI的方法论创新，因此符合第一步中的“排除”标准。 2.  **排除标准 (第三步): 论文的主要贡献与“幻觉”直接相关。** 这是最直接的排除依据。您的筛选标准明确规定：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Explainability (XAI)`, `Alignment` (对齐), `Watermarking` (水印), 或 `Hallucination` (幻觉)，一律排除。” 这篇论文的标题、摘要和研究问题都紧紧围绕着“Hallucination”（幻觉）展开，探讨减少幻觉的副作用。因此，它完全符合此项硬性排除标准。 3.  **正面指标 (第二步): 缺乏核心关注点。** 尽管论文提到了CoVe和RAG，这些技术有时会出现在智能体框架中，但该论文的研究视角并非智能体的规划、工具使用或自我反思。它没有涉及`Planning`, `Memory`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving`等您关注的核心范式和能力。论文的焦点是模型输出的“创造力”这一属性，而不是智能体的自主行为框架。 综上所述，该论文是一项关于LLM模型行为（幻觉与创造力的权衡）的优秀研究，但其核心贡献不属于构建、改进或演化LLM智能体的范畴，且直接触及了“幻觉”这一排除标准。因此，它不符合您的研究目标。"
    },
    {
        "index": "#11",
        "title": "Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction",
        "link": "/arxiv/2512.11399",
        "arxiv_id": "2512.11399",
        "authors": "Galann Pennec, Zhengyuan Liu, Nicholas Asher, Philippe Muller, Nancy F. Chen",
        "subjects": "Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.642406",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是“非演化型应用”** 论文的核心贡献是提出了一种**用于长视频摘要的片段选择方法**。它将LLM作为一个组件（选择器）嵌入到一个固定的流程中：先用轻量级模型生成视频片段描述，再用LLM根据这些描述选择关键片段。这本质上是将LLM作为工具应用于**视频摘要**这一特定领域，以解决该领域的信息丢失和成本问题。论文的目标是改进视频摘要的效果，而不是构建、改进或演化一个具有自主性的LLM智能体。因此，它符合“非演化型应用”的排除标准。 2.  **排除标准 (第三步): 论文核心属于“多模态与视觉”** 论文的标题、摘要和核心问题都围绕着“Long Video Summarization”和“Key Moment Extraction”。其研究焦点是视频理解、视觉信息处理和多模态摘要。虽然它使用了LLM，但LLM在这里是服务于视觉任务的工具，而不是研究的主体。根据您的筛选标准，主要关注 `Vision`, `Vision-Language`, `Video Understanding` 的论文应被排除，除非它们被用作智能体感知环境的工具。在本论文中，视觉处理是研究的核心，而非智能体的一个感知模块。 3.  **缺乏核心关注点 (第二步)** 论文中没有出现您关注的核心范式和能力。它没有涉及智能体的`Planning`（规划）、`Memory`（记忆）、`Self-Reflection`（自我反思），也没有涉及多智能体的`Collaboration`（协作）或`Self-Evolving`（自我演化）机制。LLM的角色是被动的、一次性的选择器，不具备任何智能体的自主性或迭代改进能力。 综上所述，该论文是一项专注于视频处理和多模态应用的研究，虽然利用了LLM，但其核心贡献与“LLM智能体及其演化”这一课题相去甚远。因此，应予以排除。"
    },
    {
        "index": "#13",
        "title": "Mining Legal Arguments to Study Judicial Formalism",
        "link": "/arxiv/2512.11374",
        "arxiv_id": "2512.11374",
        "authors": "Tomáš Koref, Lena Held, Mahammad Namazov, Harun Kumru, Yassine Thlija, Christoph Burchard, Ivan Habernal",
        "subjects": "Computation and Language, Computers and Society",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.643621",
        "filter_reason": "这篇论文不符合研究范围，应被排除。 核心判断依据如下： 1.  **第一步：核心判断——本质是“非演化型应用”** 论文的核心贡献是开发了一套自动化方法（包括数据集MADON和模型管道）来**检测和分类法律文书中的司法论证**，其最终目的是为了研究“司法形式主义”这一法学问题。论文的本质是将LLM作为先进的自然语言处理工具，应用于**法律领域**，解决该领域的特定分析问题。这完全符合筛选标准中的**排除规则 #1：非演化型应用**。论文的研究焦点是“法律论证挖掘”，而不是“LLM智能体”本身的构建或演化。 2.  **第二步：缺乏正面指标** 通读摘要，论文完全没有提及任何与我的核心关注点相关的关键词或概念。例如，它没有涉及智能体的`Planning`（规划）、`Tool Use`（工具使用，这里的LLM本身就是工具）、`Memory`（记忆）、`Self-Reflection`（自我反思），也没有涉及`Multi-Agent`（多智能体）的`Collaboration`（协作）或`Communication`（通信），更没有提出任何`Self-Evolving`（自我演化）的机制。 3.  **第三步：触及排除标准** 摘要中明确提到其模型管道在“...reducing computational costs and increasing **explainability**”（...提高可解释性）。`Explainability`（可解释性）是筛选标准中明确列出的排除项。虽然这可能不是论文的主要贡献，但它的出现进一步证明了该论文的研究方向与我的“Agentic AI”焦点不符。 **总结**: 该论文是一项典型的“LLM+X”应用研究，其中X是“法律”。它利用LLM的能力来解决一个特定领域的文本分类和分析问题，其方法论贡献在于法律NLP领域，而非智能体架构或演化机制。因此，它不符合我筛选“LLM智能体及其演化”前沿论文的核心目标。"
    },
    {
        "index": "#18",
        "title": "AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference",
        "link": "/arxiv/2512.11280",
        "arxiv_id": "2512.11280",
        "authors": "Kuan-Wei Lu, Ding-Yong Hong, Pangfeng Liu",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.646641",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出了一种名为“AdaSD”的自适应投机解码方法，其目标是**加速大型语言模型的推理过程**。它通过动态调整生成参数来减少延迟，属于典型的**模型推理优化**和**部署基础设施**研究。根据筛选标准，应排除“主要关注模型基础设施、部署优化、硬件加速的研究”。这篇论文的本质是让LLM跑得更快，而不是让LLM变得更像一个智能体。 2.  **第二步：正面指标——完全不涉及核心关注点。** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。其讨论的核心是“speculative decoding”（投机解码）、“speedup”（加速）、“inference”（推理）和“efficiency”（效率），这些都是系统工程和性能优化的术语。 3.  **第三步：排除标准——符合基础设施排除项。** 虽然论文不涉及安全对齐或多模态，但它精准地命中了第一步中明确的排除项：**基础设施**。它的全部价值在于提升LLM服务的吞吐量和响应速度，这是一个系统层面的问题，与智能体的认知架构、行为模式或演化机制无关。 4.  **第四步：处理特殊和模糊情况——不适用。** 该论文不涉及推理/规划框架（如ReAct），也不涉及任何自我演化机制。它讨论的“推理”是指底层的token生成过程，而非智能体层面的任务规划和决策。 **最终决策**：这篇论文的核心贡献是LLM推理加速技术，属于系统优化和基础设施范畴。我的研究目标是“LLM智能体及其演化”，关注的是智能体的行为、能力和演化机制。两者在研究层面和目标上存在根本差异。因此，该论文与我的研究课题完全不相关，应予以排除。"
    },
    {
        "index": "#6",
        "title": "Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet",
        "link": "/arxiv/2512.11567",
        "arxiv_id": "2512.11567",
        "authors": "Mevlüt Bagci, Ali Abusaleh, Daniel Baumartz, Giueseppe Abrami, Maxim Konca, Alexander Mehler",
        "subjects": "Computation and Language, Multimedia",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.604297",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是构建了一个名为 `MultiParTweet` 的多语言推文语料库和一个名为 `TTLABTweetCrawler` 的数据收集工具。其研究方法是利用现有的文本模型和视觉语言模型（VLM）对这个语料库进行自动标注（情感、主题等），并与人工标注进行评估对比。这完全符合筛选标准中的**“非演化型应用”**排除项。论文将LLM/VLM作为工具，应用于政治学和计算语言学领域（分析议员推文），其核心目标是创建和评估一个数据资源，而非构建、改进或演化LLM智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与您核心关注点相关的正面指标。摘要中没有提及 `Agentic AI`、`Planning`、`Tool Use`（在智能体自主决策的意义上）、`Self-Reflection`、`Multi-Agent`、`Collaboration` 或 `Self-Evolving` 等任何概念。论文中的“工具使用”指的是研究者使用模型来标注数据，而不是智能体自主调用工具来完成任务。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文明确提到了使用“一个视觉语言模型（VLM）”进行标注。根据您的排除标准，`Vision` 和 `VLM` 属于排除范围，除非它们被用作智能体感知环境的工具。在本论文中，VLM是作为研究方法的一部分，用于数据标注，而不是作为智能体框架中的一个感知模块。因此，这进一步确认了该论文在您的研究焦点之外。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及“推理/规划”或“自我演化”的特殊情况，因此无需进一步分析。 **最终决策**：该论文是一项关于数据集构建和模型评估的研究，属于计算语言学和政治科学的交叉领域。它虽然使用了先进的语言和视觉模型，但其本质是应用这些模型来解决特定领域（政治文本分析）的问题，而非对LLM智能体本身的架构、能力或演化机制进行创新。因此，它被严格排除。"
    },
    {
        "index": "#16",
        "title": "LegalRikai: Open Benchmark -- A Benchmark for Complex Japanese Corporate Legal Tasks",
        "link": "/arxiv/2512.11297",
        "arxiv_id": "2512.11297",
        "authors": "Shogo Fujita, Yuji Naraki, Yiqing Zhu, Shinsuke Mori",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.645505",
        "filter_reason": "这篇论文不符合您的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断（第一步）：** 该论文的核心贡献是**提出一个新的基准和评估框架**，而不是构建、改进或演化LLM智能体的方法论。论文标题和摘要明确指出，其工作是“introduces LegalRikai: Open Benchmark, a new benchmark”和“propose a dataset evaluation framework”。这完全符合筛选标准中的**“非演化型应用”**排除项——即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。在这里，论文将GPT-5等LLM作为评估工具，用于衡量它们在日本公司法领域的表现，其研究焦点是**评估**，而非智能体本身的构建或演化。 2.  **正面指标（第二步）：** 论文摘要中完全没有出现您所关注的核心范式或能力关键词，如 `Agentic AI`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。论文讨论的是 `benchmark`, `evaluation`, `human evaluation`, `automated evaluation`，这些都属于评估和度量范畴，而非智能体机制设计。 3.  **特殊和模糊情况（第四步）：** 尽管论文涉及“long-form, structured outputs”和“document-level editing”等复杂任务，但这并不等同于智能体的规划或推理框架。论文的重点在于**评估模型在这些任务上的表现和缺陷**，而不是提出一种新的智能体架构（如ReAct或ToT）来让模型更好地完成这些任务。因此，它不属于“关于智能体如何进行规划或在复杂任务中进行多步推理”的保留范畴。 综上所述，该论文的本质是**领域应用评估**，其核心贡献是基准测试和数据集，这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标完全不符。因此，应果断排除。"
    },
    {
        "index": "#20",
        "title": "Leveraging LLMs for Title and Abstract Screening for Systematic Review: A Cost-Effective Dynamic Few-Shot Learning Approach",
        "link": "/arxiv/2512.11261",
        "arxiv_id": "2512.11261",
        "authors": "Yun-Chung Liu, Rui Yang, Jonathan Chong Kai Liew, Ziran Yin, Henry Foote, Christopher J. Lindsell, Chuan Hong",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.652971",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”** - **核心贡献分析**: 该论文的核心贡献是提出了一种“两阶段动态少样本学习（DFSL）”方法，用于解决特定领域（循证医学）中的具体问题（系统综述的标题和摘要筛选）。其目标是提高效率和成本效益，而不是构建或改进一个具有自主性的LLM智能体。 - **是否符合排除规则**: 完全符合。这篇论文是将LLM作为一个工具（一个分类器）应用到特定任务中，属于典型的“非演化型应用”。论文的重点在于应用层面的方法论创新（如何组合不同成本的LLM以优化特定任务），而非智能体本身的架构或能力演化。 2.  **第二步：正面指标——缺乏核心关注点** - 论文摘要中完全没有提及任何与您研究焦点相关的核心范式或能力。例如，它没有涉及`Planning`（规划）、`Tool Use`（工具使用，这里的LLM本身就是工具）、`Memory`（记忆）、`Self-Reflection`（自我反思）、`Multi-Agent`（多智能体）或`Self-Evolving`（自我演化）等任何概念。其工作流程是预设的、静态的，不具备智能体的自主性。 3.  **第三步：排除标准——不涉及安全与对齐或多模态** - 该论文不涉及安全、对齐或多模态等排除标准，但这并不改变其被排除的命运，因为第一步的判断已经足够明确。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的LLM执行的是分类任务，而非复杂的多步推理或自主规划。它不属于“智能体如何进行规划”的范畴。 - **自我演化的应用**: 论文提出的是一个固定的两阶段流程，不包含任何“自我演化”机制。因此，不满足保留的例外情况。 **最终决策**: 综合以上分析，这篇论文的本质是利用LLM解决特定领域（医学文献筛选）的应用效率问题，其核心贡献是应用层面的方法，而非关于LLM智能体的构建、改进或演化。它与您研究的“Agentic AI”核心目标（单智能体、多智能体、自我演化）完全无关。因此，应将其排除。"
    },
    {
        "index": "#21",
        "title": "Multi-Intent Spoken Language Understanding: Methods, Trends, and Challenges",
        "link": "/arxiv/2512.11258",
        "arxiv_id": "2512.11258",
        "authors": "Di Wu, Ruiyu Fang, Liting Jiang, Shuangyong Song, Xiaomeng Huang, Shiquan Wang, Zhongqiu Li, Lingling Shi, Mengjiao Bao, Yongxiang Li, Hao Huang",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.653519",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是一篇关于“多意图口语语言理解”的**综述**。它回顾、总结和分析了该领域现有的方法、趋势和挑战。这完全不符合您筛选标准中“核心贡献在于构建、改进或演化LLM智能体”的要求。这篇论文没有提出任何新的智能体框架、多智能体系统或自我演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文完全不包含您关注的核心范式和能力。摘要中反复出现的关键词是“Multi-intent spoken language understanding (SLU)”、“intent detection”和“slot filling”。这些都是自然语言处理（NLP）领域的经典任务，属于对输入文本/语音的理解和解析，而非智能体的自主行为。论文没有提及任何关于`Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent Systems`或`Self-Evolving`的内容。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文属于典型的**非演化型应用**。它的研究焦点是解决一个特定领域（口语语言理解）的问题，而不是研究智能体本身的构建和演化。虽然LLM可能被用作SLU任务中的一个模型，但论文的核心是SLU这个任务本身，而不是如何让LLM变成一个更智能的“智能体”。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何特殊或模糊的情况。它既不是关于智能体的规划与推理，也不是关于自我演化的应用。它是一篇纯粹的、针对特定NLP任务的领域综述。 **最终决策**: 综合以上分析，这篇论文是一篇关于特定NLP任务（多意图口语语言理解）的综述，其研究内容与您“LLM智能体及其演化”的核心目标（构建、改进、演化智能体）完全无关。因此，根据第一步的核心判断标准，应予以排除。"
    },
    {
        "index": "#17",
        "title": "CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise",
        "link": "/arxiv/2512.11282",
        "arxiv_id": "2512.11282",
        "authors": "Qingsen Ma, Dianyun Wang, Ran Jing, Yujun Sun, Zhenbo Xu",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.646090",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心贡献与第一步判断（排除）**: 论文的核心贡献是提出一个“即插即用的因果提示框架”，其根本目标是“减轻幻觉”。这并非关于构建、改进或演化一个具有自主性的LLM智能体。CIP框架是一种优化LLM输入（Prompt）以获得更可靠输出的技术，它本身不构成一个智能体架构，也未涉及智能体的规划、记忆、工具使用或自我演化等核心能力。因此，它属于“非Agentic的推理”范畴，旨在提升LLM模型本身的基础能力（事实性和因果一致性），而非构建一个Agentic系统。 2.  **第三步排除标准（硬性排除）**: 这是最关键的排除依据。您的筛选标准明确指出，只要论文的主要贡献是关于 `Safety`、`Interpretability` (可解释性) 或 `Hallucination` (幻觉)，就应一律排除。本论文的标题和摘要都反复强调其核心目标是“Mitigating Hallucinations”（减轻幻觉），并提到了提升“interpretability”（可解释性）。这完全符合硬性排除标准。 3.  **第二步正面指标（缺失）**: 论文摘要中完全没有出现您所关注的核心范式和能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。这进一步表明该研究与您的焦点方向无关。 4.  **第四步特殊情况的澄清**: 论文虽然涉及“推理”，但它不属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。它关注的是通过因果提示来纠正模型在长文本下的基础推理错误，防止其产生虚假内容，而不是设计一个能够自主规划和行动的智能体框架。 综上所述，尽管该论文在解决LLM幻觉问题上可能具有价值，但其研究焦点是模型的安全性和可靠性，而非您所关注的“LLM智能体及其演化”的构建与演化。因此，根据您的严格筛选标准，该论文应被排除。"
    },
    {
        "index": "#4",
        "title": "Bounding Hallucinations: Information-Theoretic Guarantees for RAG Systems via Merlin-Arthur Protocols",
        "link": "/arxiv/2512.11614",
        "arxiv_id": "2512.11614",
        "authors": "Björn Deiseroth, Max Henning Höth, Kristian Kersting, Letitia Parcalabescu",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.603373",
        "filter_reason": "这篇论文的核心贡献是提出一种名为Merlin-Arthur (M/A)的训练框架，旨在通过信息论的方法来减少RAG（检索增强生成）系统的幻觉，并提供可验证的保证。尽管RAG系统本身可以被视为一种使用工具（检索器）的LLM智能体，但本论文的研究焦点和核心贡献并不在于构建或演化智能体的能力，而在于提升其输出的**可靠性、安全性和可解释性**。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断**：论文的本质是改进RAG系统的可靠性，而非提出新的智能体架构或演化机制。它将RAG流程视为一个“交互式证明系统”，其目标是让生成器（Arthur）学会依赖可验证的证据并拒绝回答证据不足的问题。这更接近于对现有智能体组件（RAG）进行安全加固，而不是构建一个具有新规划、记忆或演化能力的智能体。 2.  **第二步：正面指标**：论文确实涉及了`Tool Use`（检索器）和某种形式的`Self-Correction`（学会拒绝回答）。然而，这些是实现其核心目标（减少幻觉）的手段，而非论文本身的研究焦点。 3.  **第三步：排除标准**：这是决定性的排除依据。论文的标题和摘要反复强调其核心贡献： *   **`Bounding Hallucinations` (限制幻觉)**：这是标题的核心，直接命中排除标准中的`Hallucination`。 *   **`Information-Theoretic Guarantees` (信息论保证)** 和 **`verifiable evidence` (可验证证据)**：这些贡献旨在提升系统的**安全性**和**可靠性**。 *   **`linear-time XAI method` (线性时间的XAI方法)**：明确提到了可解释性，命中排除标准中的`Interpretability (XAI)`。 根据筛选规则，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` (可解释性), `Explainability (XAI)`, `Alignment` (对齐), `Watermarking` (水印), 或 `Hallucination` (幻觉)，一律排除。” 这篇论文完全符合这一排除条件。 4.  **第四步：处理特殊和模糊情况**：论文不涉及新的规划或推理框架，也不涉及自我演化机制。它提出的M/A训练框架是一种外部监督训练方法，而非智能体在部署期间的自主演化。 **最终决策**：尽管论文研究对象（RAG）与LLM智能体相关，但其核心贡献在于解决**幻觉问题**、提供**安全保证**和增强**可解释性**，这完全属于“安全与对齐”的研究范畴。根据您明确的排除标准，该论文不符合您关于“LLM智能体及其演化”的研究目标，因此应被排除。"
    },
    {
        "index": "#22",
        "title": "SciLaD: A Large-Scale, Transparent, Reproducible Dataset for Natural Scientific Language Processing",
        "link": "/arxiv/2512.11192",
        "arxiv_id": "2512.11192",
        "authors": "Luca Foppiano, Sotaro Takeshita, Pedro Ortiz Suarez, Ekaterina Borisova, Raia Abu Ahmad, Malte Ostendorff, Fabio Barth, Julian Moreno-Schneider, Georg Rehm",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.654013",
        "filter_reason": "这篇论文的核心贡献是构建并发布了一个大规模的科学语言数据集（SciLaD）及其生成流水线。根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是关于**数据集的构建和验证**。作者的主要工作是收集、处理和发布科学文献数据，并通过预训练一个RoBERTa模型来证明该数据集的质量。这完全符合第一步排除标准中的“基础设施”类别（此处为数据基础设施），而非关于构建、改进或演化LLM智能体的方法论或新框架。因此，应直接排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与我的研究焦点相关的正面指标关键词，例如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了该论文与我的研究范围无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然该论文没有触发“安全与对齐”或“多模态与视觉”的排除标准，但第一步的“基础设施”排除标准已经足够明确且优先级更高。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它的工作是基础性的数据准备，而非智能体层面的机制设计。 **最终决策**：综合以上分析，这篇论文的核心贡献是提供一个数据资源，而不是提出一种新的LLM智能体架构、多智能体协作机制或自我演化方法。它属于AI研究的基础设施层面，与我的核心目标“构建、改进或演化LLM智能体”不符。因此，最终判断为 **False**。"
    },
    {
        "index": "#14",
        "title": "qa-FLoRA: Data-free query-adaptive Fusion of LoRAs for LLMs",
        "link": "/arxiv/2512.11366",
        "arxiv_id": "2512.11366",
        "authors": "Shreya Shukla, Aditya Sriram, Milinda Kuppur Narayanaswamy, Hiteshi Jain",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.644215",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是基础设施优化，而非智能体构建。** 该论文的核心贡献是提出了一种名为 `qa-FLoRA` 的方法，用于在处理多领域复合查询时，动态地、免训练地融合多个LoRA适配器。这本质上是一种**模型部署优化**和**参数高效微调（PEFT）**的技术。它关注的是如何更有效地组合和利用已经训练好的模型组件（LoRA），而不是构建一个具有自主规划、记忆或工具使用能力的LLM智能体。根据筛选标准，这属于“主要关注模型基础设施、部署优化”的研究，应予以排除。 2.  **缺乏核心关注点（第二步）：论文不包含您研究焦点的关键范式和能力。** 论文的摘要和标题中完全没有出现您所列出的任何核心正面指标，例如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其解决的问题（LoRA融合）与智能体的核心能力构建是两个不同的研究方向。 3.  **不属于特殊情况的例外（第四步）：** 论文虽然处理“复合查询”，这可能涉及多步推理，但其方法本身并非关于智能体如何进行规划和推理。它是在模型层面，通过调整融合权重来更好地响应查询，而不是在智能体架构层面设计新的推理或规划框架（如ReAct或ToT）。因此，它不属于“关于智能体如何进行规划”的保留范畴。 **总结：** 尽管 `qa-FLoRA` 是一项在模型部署和适配领域有价值的工作，能够提升LLM在多领域任务上的表现，但它的技术核心是**模型工程和优化**，而非**智能体架构或演化机制的设计**。它没有提出任何关于智能体如何自主行动、协作或自我演化的新方法。因此，它严格地落在了您筛选标准中的“基础设施”排除类别，与您“LLM智能体及其演化”的核心研究目标不符。"
    },
    {
        "index": "#26",
        "title": "MultiScript30k: Leveraging Multilingual Embeddings to Extend Cross Script Parallel Data",
        "link": "/arxiv/2512.11074",
        "arxiv_id": "2512.11074",
        "authors": "Christopher Driggers-Ellis, Detravious Brinkley, Ray Chen, Aashish Dhawan, Daisy Zhe Wang, Christan Grant",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Multimedia",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.655909",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是创建了一个名为“MultiScript30k”的新数据集，用于扩展多模态机器翻译（MMT）的平行语料。这完全属于“非演化型应用”的范畴。它使用一个已有的模型（NLLB200-3.3B）作为工具，为特定领域（机器翻译）生成资源（数据集），而不是提出一种构建、改进或演化LLM智能体的新方法或框架。 2.  **正面指标 (第二步):** 论文摘要中完全没有出现任何与我核心关注点相关的关键词或概念，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent Systems`, `Self-Evolving` 等。其讨论焦点是数据集构建、翻译质量评估（余弦相似度、COMETKiwi分数），与智能体的能力或机制无关。 3.  **排除标准 (第三步):** 论文的研究背景是“多模态机器翻译（MMT）”，这直接命中了“多模态与视觉”这一排除标准。虽然论文本身可能主要处理文本，但其贡献是服务于一个被明确排除的研究领域。 综上所述，该论文的本质是数据集构建工作，服务于机器翻译领域，与我的核心目标“构建、改进或演化LLM智能体”以及三个研究方向（单智能体、多智能体、自我演化）均无关联。因此，应果断排除。"
    },
    {
        "index": "#29",
        "title": "MedBioRAG: Semantic Search and Retrieval-Augmented Generation with Large Language Models for Medical and Biological QA",
        "link": "/arxiv/2512.10996",
        "arxiv_id": "2512.10996",
        "authors": "Seonok Kim",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.657229",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一个名为 \"MedBioRAG\" 的模型，这是一个专门为生物医学领域问答（QA）任务优化的**检索增强生成（RAG）系统**。它通过结合语义和词汇搜索、文档检索以及监督微调来提升在特定领域的QA性能。这完全符合**排除规则1：“非演化型应用”**。该论文并未构建一个新的LLM智能体框架，也没有提出智能体如何演化或改进的新方法，而是将一个已有的技术（RAG）应用并优化于一个特定垂直领域（生物医学），以解决该领域的问题。其核心是**应用层面的优化**，而非智能体本体的构建或演化。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现您所列出的核心范式或能力关键词，例如 `Agentic AI`, `Planning`, `Memory`, `Self-Reflection`, `Collaboration`, `Self-Evolving` 等。虽然RAG可以被视为一种工具使用（Tool Use）的形式，但本文的重点在于**改进检索工具本身**（如何更精准地找到生物医学文献），而不是研究一个智能体如何自主地、策略性地使用工具来完成复杂任务。因此，它不满足任何关键的正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除标准，但这并不改变其作为“非演化型应用”的本质。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文描述的是一个“检索-生成”的流水线，而不是一个具有自主规划和多步推理能力的智能体框架（如ReAct或ToT）。它不涉及智能体的决策过程，因此应被排除。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。MedBioRAG是一个经过微调的静态模型，不具备通过经验或反馈进行自我完善的能力。 **最终决策**: 综合以上分析，这篇论文的本质是**一个针对特定领域（生物医学）的RAG应用优化研究**。它的核心贡献在于提升信息检索和生成的准确性，而不是构建、改进或演化LLM智能体。因此，它完全不符合您关于“LLM智能体及其演化”的核心研究目标，应予以排除。"
    },
    {
        "index": "#23",
        "title": "FIBER: A Multilingual Evaluation Resource for Factual Inference Bias",
        "link": "/arxiv/2512.11110",
        "arxiv_id": "2512.11110",
        "authors": "Evren Ayberk Munis, Deniz Yılmaz, Arianna Muti, Çağrı Toraman",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.654471",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是评估，而非构建。** 论文的核心贡献是提出了一个名为 FIBER 的多语言评估基准，用于衡量大型语言模型在事实推理中的偏见。论文的本质是**评估和分析**LLM的固有属性（事实可靠性、语言偏见），而不是**构建、改进或演化**一个LLM智能体。它没有提出任何新的智能体架构、规划方法、工具使用机制或多智能体协作协议。因此，根据“非演化型应用”的排除规则，这篇论文应被排除。 2.  **第二步：正面指标——论文缺乏核心关注点。** 论文摘要中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent Systems`, `Self-Evolving` 等。文中提到的 \"multi-entity settings\" 指的是问题中涉及多个实体（例如“法国和意大利的首都是哪里？”），而非多个自主智能体之间的交互，这与我的“多智能体”研究方向完全无关。 3.  **第三步：排除标准——研究焦点偏离。** 论文的研究主题是“事实推理偏见”，这与 `Safety` 和 `Bias` 研究高度相关。尽管论文的主要贡献是基准而非缓解偏见的方法，但其研究焦点仍然是评估模型的安全与可靠性属性，而不是提升智能体的自主能力。这进一步确认了它偏离了我的核心研究目标。 4.  **第四步：处理特殊情况——不适用。** 论文不涉及智能体的规划框架或自我演化机制，因此相关的特殊规则不适用。 **最终决策：** 该论文是一项关于LLM评估的重要工作，但它属于模型评测领域，而非Agentic AI领域。它的核心贡献是提供一个衡量工具，而不是一个构建智能体的方法论。因此，它完全不符合我“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”这一核心目标。"
    },
    {
        "index": "#30",
        "title": "Benchmarking Automatic Speech Recognition Models for African Languages",
        "link": "/arxiv/2512.10968",
        "arxiv_id": "2512.10968",
        "authors": "Alvin Nahabwe, Sulaiman Kagumire, Denis Musinguzi, Bruno Beijuka, Jonah Mubuuke Kyagaba, Peter Nabende, Andrew Katumba, Joyce Nakatumba-Nabende",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2025-11-30",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.662924",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的核心贡献是**对现有的自动语音识别（ASR）模型进行基准测试**。它比较了Whisper、XLS-R等四个模型在非洲语言上的表现，并分析了数据量、模型架构和解码策略对结果的影响。 - 这完全符合**排除标准中的“非演化型应用”**。论文将已有的ASR模型（即使其中包含像Whisper这样的大型模型）作为工具，应用在“非洲语言识别”这个特定领域，以解决该领域的模型选择和优化问题。它没有提出任何关于如何构建、改进或演化LLM智能体的新方法论或框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现我关注的核心范式或能力关键词。摘要中没有提及 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等任何与智能体相关的概念。其研究焦点是语音识别的工程实践和模型性能分析，而非智能体的内在机制。 3.  **第三步 & 第四步：排除标准与特殊情况** - 该论文不涉及安全对齐或多模态等排除领域。 - 它也不涉及“推理/规划”或“自我演化的应用”等特殊情况。论文中的“迭代”指的是研究人员在实验中逐步增加数据量，这是一种实验方法，而不是智能体自身的“自我演化”或“迭代改进”机制。 **最终决策**: 综合以上分析，该论文的本质是一项针对特定应用领域（非洲语言ASR）的模型基准研究，其核心贡献在于提供实践性的模型选择和优化指导，而非在LLM智能体的构建、协作或演化方面做出理论或方法学的创新。因此，它与我关于“LLM智能体及其演化”的研究课题完全不相关，应予以排除。"
    },
    {
        "index": "#31",
        "title": "ASR Under the Stethoscope: Evaluating Biases in Clinical Speech Recognition across Indian Languages",
        "link": "/arxiv/2512.10967",
        "arxiv_id": "2512.10967",
        "authors": "Subham Kumar, Prakrithi Shivaprakash, Abhishek Manoharan, Astut Kurariya, Diptadhi Mukherjee, Lekhansh Shukla, Animesh Mukherjee, Prabhat Chand, Pratima Murthy",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2025-11-30",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.663454",
        "filter_reason": "解析失败"
    },
    {
        "index": "#25",
        "title": "Applying NLP to iMessages: Understanding Topic Avoidance, Responsiveness, and Sentiment",
        "link": "/arxiv/2512.11079",
        "arxiv_id": "2512.11079",
        "authors": "Alan Gerber, Sam Cooperman",
        "subjects": "Computation and Language, Computers and Society, Applications, Other Statistics",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.655360",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的核心贡献是构建了一个“iMessage文本消息分析器”，并将其应用于分析用户的iMessage数据，以研究人类交流行为，如话题回避、响应性和情感。 - 这完全符合**排除标准1：非演化型应用**。论文的本质是将NLP技术（可能包含LLM，但LLM在此仅作为分析工具）应用到一个特定领域（社会计算/人机交互），去解决该领域的问题（理解人类行为）。它并没有提出任何关于如何构建、改进或演化LLM智能体本身的新方法论或框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标。没有提及`Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Self-Reflection`等任何核心概念。其研究重点是`topic modeling`、`sentiment analysis`等传统NLP分析任务，而非智能体的能力构建。 3.  **第三步与第四步：排除标准与特殊情况** - 该论文不涉及安全对齐或多模态等排除标准，但它已在第一步被明确排除。 - 它也不涉及推理/规划或自我演化的特殊情况，因为它根本不是在研究智能体，而是在用技术分析人类产生的数据。 **最终决策**: 该论文的核心是数据分析应用，而非智能体构建。它的研究目标是理解人类交流模式，而不是创造或演化一个能够自主行动、规划或学习的AI智能体。因此，它与您“LLM智能体及其演化”的核心目标完全不符，应予以排除。"
    },
    {
        "index": "#24",
        "title": "Explanation Bias is a Product: Revealing the Hidden Lexical and Position Preferences in Post-Hoc Feature Attribution",
        "link": "/arxiv/2512.11108",
        "arxiv_id": "2512.11108",
        "authors": "Jonathan Kamp, Roos Bakker, Dominique Blok",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.654909",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非构建、改进或演化LLM智能体。它的本质是**对现有模型解释方法（Post-Hoc Feature Attribution）的偏见进行分析和评估**。它研究的是“解释”本身的质量和特性，而不是创造一个能够自主行动、规划或演化的智能体。这属于对模型行为的分析，而非智能体框架的构建。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文的核心主题是“Explanation”（解释）和“Feature Attribution”（特征归因），这直接命中了排除标准中的 **`Interpretability` (可解释性)** 和 **`Explainability (XAI)`**。根据筛选规则，只要论文的主要贡献是关于可解释性，就应一律排除。 3.  **正面指标缺失 (第二步):** 论文中完全没有出现我研究焦点的任何核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent Systems` 等。这进一步确认了它与我的研究目标无关。 综上所述，尽管该研究在模型可解释性领域可能具有重要价值，但它并不涉及LLM智能体的构建、协作或自我演化机制，因此不符合我为“LLM智能体及其演化”课题设定的筛选标准。"
    },
    {
        "index": "#27",
        "title": "PIAST: Rapid Prompting with In-context Augmentation for Scarce Training data",
        "link": "/arxiv/2512.11013",
        "arxiv_id": "2512.11013",
        "authors": "Pawel Batorski, Paul Swoboda",
        "subjects": "Computation and Language",
        "date": "2025-12-11",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.656331",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为PIAST的**自动提示工程算法**，用于快速构建和优化LLM上下文学习中的少量示例。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的本质是**一种提升LLM提示效率的方法**，而非构建或演化一个LLM智能体。它关注的是如何为LLM的输入（Prompt）选择最佳的示例，以在特定任务（如GSM8K、文本分类）上获得更好的性能。 - 根据筛选标准，这属于**“非Agentic的推理”**。论文旨在提高LLM在特定任务上的基础推理能力，但其方法（优化示例）不涉及任何智能体框架，如自主规划、工具使用或自我反思循环。它没有定义一个能够自主行动和演化的智能体实体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中没有出现任何我核心关注点的正面指标。它没有提及`Agentic AI`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent`或`Self-Evolving`等关键概念。虽然提到了“iteratively replaces/drops/keeps”，但这描述的是其**外部算法的迭代过程**，而不是智能体内部的自我完善或演化机制。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全对齐或多模态等排除标准，因此这一步不适用。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文的情况完全符合“排除”条件。它通过优化提示示例来提升LLM在GSM8K（数学推理）等任务上的表现，这属于“提高LLM本身基础Token预测的数学或逻辑能力”，而不是“关于智能体如何进行规划或在复杂任务中进行多步推理”。它没有引入任何新的Agentic框架（如ReAct）。 **核心依据总结**: 我的研究焦点是**智能体本身**的构建、协作与演化。而这篇论文的焦点是**智能体的输入**。PIAST是一个外部的、用于优化Prompt的工具，它本身不具备智能体的任何特征（自主性、规划、记忆等），也没有提出让智能体自我演化的机制。因此，尽管它是一种前沿的LLM优化技术，但它不属于“LLM智能体及其演化”这一核心研究范畴。它属于更广泛的“高效LLM使用方法”领域，而非“Agentic AI”领域。故应排除。"
    },
    {
        "index": "#36",
        "title": "Task-Specific Sparse Feature Masks for Molecular Toxicity Prediction with Chemical Language Models",
        "link": "/arxiv/2512.11412",
        "arxiv_id": "2512.11412",
        "authors": "Kwun Sy Lee, Jiawei Chen, Fuk Sheng Ford Chung, Tianyu Zhao, Zhenyuan Chen, Debby D. Wang",
        "subjects": "Computational Engineering, Finance, and Science, Artificial Intelligence, Computation and Language, Machine Learning, Biomolecules",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.666337",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是应用而非智能体构建。** 论文的核心贡献是提出一种新的多任务学习（MTL）框架，用于解决特定领域（药物发现、化学）的问题（分子毒性预测）。它将化学语言模型作为其架构的一部分，但论文的焦点在于如何通过任务特定的稀疏注意力模块来提升模型的**准确性和可解释性**，而不是构建一个具有自主规划、工具使用或记忆能力的LLM智能体。这完全符合“非演化型应用”的排除标准，即“将LLM作为工具应用到特定领域去解决该领域的问题”。 2.  **第二步：正面指标——缺乏核心关注点。** 论文摘要中完全没有出现我关注的核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。其技术焦点是 `Multi-Task Learning` (多任务学习) 和 `Sparsity` (稀疏性)，这与智能体的构建和演化无关。 3.  **第三步：排除标准——核心贡献属于可解释性研究。** 论文明确指出其目标是解决模型的“黑箱”问题，并“增强洞察力”、“提供化学直观的可视化”、“揭示影响预测的特定片段”。这些描述清晰地表明，论文的主要贡献在于**模型的可解释性**。根据我的筛选标准，“只要论文的主要贡献是关于 `Interpretability` (可解释性)...一律排除”。因此，仅凭这一点就足以排除该论文。 **总结**：该论文是一篇典型的将语言模型应用于科学计算领域的可解释性研究（XAI），其核心是改进模型在特定任务上的表现和透明度，而非构建或演化具有自主性的LLM智能体。因此，它与我的研究课题“LLM智能体及其演化”完全不相关。"
    },
    {
        "index": "#32",
        "title": "From Signal to Turn: Interactional Friction in Modular Speech-to-Speech Pipelines",
        "link": "/arxiv/2512.11724",
        "arxiv_id": "2512.11724",
        "authors": "Titaya Mairittha, Tanakon Sawanglok, Panuwit Raden, Jirapast Buntub, Thanapat Warunee, Napat Asawachaisuvikrom, Thanaphum Saiwongin",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Computation and Language, Software Engineering",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.663994",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于构建、改进或演化LLM智能体本身的论文，而这篇论文的核心贡献在于分析一个现有语音交互系统的架构问题。 具体判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是**分析**一个模块化语音到语音（S2S-RAG）流水线中出现的“交互摩擦”。它通过系统级分析，指出了三个导致对话中断的模式：时间错位、表达扁平化和修复僵化。论文的最终结论是：“构建自然的语音AI是一个基础设施设计挑战”，需要从优化独立组件转向精心编排它们之间的“接缝”。 这完全符合**第一步的排除标准 #3：基础设施**。论文的本质是关于系统架构、组件集成和交互体验的优化，而不是关于智能体内部能力的构建或演化。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中提到了“Retrieval-Augmented Generation (RAG)”，这可以被视为一种工具使用。然而，论文的重点并非改进RAG本身或提出新的工具使用方法，而是将RAG作为现有系统中的一个模块，分析该模块在整个语音流水线中如何引发交互问题。论文没有涉及`Planning`、`Memory`、`Self-Reflection`、`Multi-Agent`或`Self-Evolving`等核心智能体范式或能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 论文不涉及推理/规划或自我演化的特殊情况。 **最终决策**: 该论文的核心贡献是**对现有语音AI系统架构的批判性分析**，并将其问题归结为**基础设施层面的设计挑战**。它没有提出任何新的LLM智能体框架、能力改进方法或自我演化机制。因此，尽管它讨论了包含LLM和工具（RAG）的系统，但其研究焦点是系统工程的“接缝”问题，而非智能体本身的“核心”问题，与我的研究课题“LLM智能体及其演化”不符。应予以排除。"
    },
    {
        "index": "#34",
        "title": "HFS: Holistic Query-Aware Frame Selection for Efficient Video Reasoning",
        "link": "/arxiv/2512.11534",
        "arxiv_id": "2512.11534",
        "authors": "Yiqing Yang, Kin-Man Lam",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language, Multimedia",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.665104",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **第一步：核心判断——论文本质是应用，而非智能体构建。** 论文的核心贡献是提出了一种名为HFS的**视频关键帧选择框架**，旨在提升视频推理任务的效率。虽然它使用了小型语言模型（SLM）和多模态大语言模型（MLLM）作为组件，但其根本目标是解决**视频理解**这一特定领域的问题，而不是构建、改进或演化一个具有自主性的LLM智能体。这完全符合第一步排除标准中的“非演化型应用”：将LLM作为工具应用到特定领域（这里是视觉/视频领域）去解决该领域的问题。 2.  **第三步：排除标准——论文核心属于多模态与视觉领域。** 论文的研究对象是视频，其方法围绕“多模态特征”、“Multimodal Large Language Models (MLLMs)”展开，并在多个视频问答基准上进行验证。这明确属于筛选标准中需要排除的“多模态与视觉”类别。尽管规则中提到“除非它们被用作智能体感知环境的工具”，但在这篇论文中，视觉处理是**研究的核心问题本身**，而不是一个服务于更高层次智能体目标的感知模块。 3.  **第四步：特殊情况处理——Chain-of-Thought的使用不构成Agentic推理。** 论文中提到了使用“Chain-of-Thought approach”，但这并不符合筛选标准中关于“推理/规划”的保留条件。这里的CoT被用作一种**技术手段**，来引导SLM生成“任务特定的隐式查询向量”，这是一个固定的、端到端训练流程中的内部步骤。它并非描述一个智能体如何自主地进行多步规划、决策或与环境交互以解决复杂任务。因此，它不属于Agentic框架的范畴，更接近于一种提升模型组件性能的技巧。 **总结：** 该论文的本质是利用LLM组件来优化一个视觉任务（视频帧选择），其核心贡献在于视频处理领域的方法论创新，而非Agentic AI的架构或演化机制。它既不属于单智能体、多智能体或自我演化的研究范畴，又明确触及了“多模态与视觉”这一排除标准。因此，应予以排除。"
    },
    {
        "index": "#33",
        "title": "DentalGPT: Incentivizing Multimodal Complex Reasoning in Dentistry",
        "link": "/arxiv/2512.11558",
        "arxiv_id": "2512.11558",
        "authors": "Zhenyang Cai, Jiaming Zhang, Junjie Zhao, Ziyi Zeng, Yanchao Li, Jingyi Liang, Junying Chen, Yunjin Yang, Jiajun You, Shuzhi Deng, Tongfei Wang, Wanting Chen, Chunxiu Hao, Ruiqi Xie, Zhenwei Wen, Xiangyi Feng, Zou Ting, Jin Zou Lin, Jianquan Li, Guangjun Yu, Liangyi Chen, Junwen Wang, Shan Jiang, Benyou Wang",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.664679",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断（第一步）：论文本质是“非演化型应用”** 论文的核心贡献是构建了一个名为DentalGPT的、专门用于牙科领域的多模态大语言模型（MLLM）。其工作重点是通过构建大规模的牙科图文数据集，并结合强化学习来微调模型，以提升其在特定领域（牙科）的视觉理解和诊断推理能力。这完全符合第一步排除标准中的 **“非演化型应用”**：它将一个已有的模型范式（MLLM）作为工具，应用到特定领域（牙科）去解决该领域的问题（疾病诊断、VQA）。论文的核心是领域适应和数据集构建，而非提出新的智能体构建或演化方法论。 2.  **缺乏核心关注点（第二步）** 论文摘要中完全没有提及任何与您研究焦点相关的核心范式或能力。例如，`Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等关键词均未出现。这表明论文的研究方向与您的目标存在根本性偏差。 3.  **触犯明确的排除标准（第三步）** 论文的研究核心是 **多模态与视觉**。标题和摘要反复强调 `Multimodal`、`MLLMs`、`dental images`、`visual details`。根据您的筛选标准，只要论文的核心是关于多模态模型本身，而不是将其作为智能体感知环境的工具，就应被排除。本文的研究对象DentalGPT本身就是一个MLLM，其创新点在于提升其多模态能力，因此触犯了此项排除标准。 4.  **对“推理”的误判（第四步）** 论文中提到的“复杂推理”是通过强化学习来增强模型的端到端推理能力，这属于 **“非Agentic的推理”**。它旨在提升模型本身在特定任务上的表现，而不是构建一个能够自主规划、行动和观察的智能体框架（如ReAct, ToT）。这与您关注的“智能体如何进行规划”有本质区别。 综上所述，该论文是一篇典型的领域应用型MLLM研究，其核心贡献在于提升模型在特定垂直领域的性能，而非探索LLM智能体的构建、协作或演化机制。因此，它不符合您的研究课题要求。"
    },
    {
        "index": "#37",
        "title": "Adaptive Soft Rolling KV Freeze with Entropy-Guided Recovery: Sublinear Memory Growth for Efficient LLM Inference",
        "link": "/arxiv/2512.11221",
        "arxiv_id": "2512.11221",
        "authors": "Adilet Metinov, Gulida M. Kudakeeva, Bolotbek uulu Nursultan, Gulnara D. Kabaeva",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.666857",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为ASR-KF-EGR的推理时优化框架，旨在通过管理KV缓存来降低LLM长上下文推理时的内存消耗。 根据筛选标准的第一步“核心判断”，该论文的本质属于“基础设施”和“部署优化”的研究。它关注的是如何让LLM运行得更高效、内存占用更小，而不是如何构建、改进或演化一个具有自主能力的智能体。论文中提到的“Memory”指的是计算内存（VRAM），而非智能体用于存储经验、对话历史的“记忆”能力。 具体分析如下： 1.  **核心判断（第一步）**: 论文的核心是优化LLM的推理过程，使其在内存受限的环境下更高效。这完全符合“排除”标准中的第3点：“主要关注模型基础设施、部署优化、硬件加速的研究”。它没有提出新的智能体框架或能力。 2.  **正面指标（第二步）**: 论文不包含任何“正面指标”中的核心范式或能力。它没有涉及`Planning`、`Tool Use`、`Self-Reflection`、`Multi-Agent`或`Self-Evolving`等任何与智能体行为相关的概念。 3.  **排除标准（第三步）**: 虽然不属于安全、对齐或多模态等排除类别，但它属于更基础的“基础设施”类别，优先级更高。 4.  **特殊情况（第四步）**: 该论文与“推理/规划”或“自我演化的应用”等特殊情况无关。它解决的是底层的计算效率问题，而非上层的智能体决策或学习机制。 综上所述，尽管这是一篇在LLM工程领域有价值的工作，但它完全偏离了您关于“LLM智能体及其演化”的核心研究目标，应予以排除。"
    },
    {
        "index": "#2",
        "title": "Causal Inference in Energy Demand Prediction",
        "link": "/arxiv/2512.11653",
        "arxiv_id": "2512.11653",
        "authors": "Chutian Ma, Grigorii Pomazkin, Giacinto Paolo Saggese, Paul Smith",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.227435",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 论文的核心是提出一个**结构因果模型**和一个**贝叶斯模型**，用于解决**能源需求预测**这一特定领域的问题。其本质是应用因果推断技术来提升预测模型的性能和鲁棒性。 - **是否符合要求**: 这完全符合筛选标准中的**排除规则 #1: 非演化型应用**。该论文将一个机器学习模型（贝叶斯模型，而非LLM智能体）作为工具，应用于能源领域，以解决该领域的预测问题。它没有构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准** - 虽然论文没有触及安全与对齐、多模态与视觉等排除标准，但第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划框架（如ReAct），也不涉及任何自我演化机制。因此，特殊情况的例外条款不适用。 **最终决策**: 这篇论文的研究重点是**应用因果推断于能源预测**，属于应用机器学习或数据科学的范畴。其核心贡献与您的研究目标——“LLM智能体及其演化”——在本质上完全不同。论文中未提及LLM、智能体框架、多智能体系统或任何形式的自我演化机制。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#3",
        "title": "AI Benchmark Democratization and Carpentry",
        "link": "/arxiv/2512.11588",
        "arxiv_id": "2512.11588",
        "authors": "Gregor von Laszewski, Wesley Brewer, Jeyan Thiyagalingam, Juri Papay, Armstrong Foundjem, Piotr Luszczek, Murali Emani, Shirley V. Moore, Vijay Janapa Reddi, Matthew D. Sinclair, Sebastian Lobentanzer, Sujata Goswami, Benjamin Hawks, Marco Colombo, Nhan Tran, Christine R. Kirkpatrick, Abdulkareem Alsudais, Gregg Barrett, Tianhao Li, Kirsten Morehouse, Shivaram Venkataraman, Rutwik Jain, Kartik Mathur, Victor Lu, Tejinder Singh, Khojasteh Z. Mirza, Kongtao Chen, Sasidhar Kunapuli, Gavin Farrell, Renato Umeton, Geoffrey C. Fox",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.228234",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于**构建、改进或演化LLM智能体本身**的论文，而这篇论文的核心贡献是关于**AI基准测试的构建、改进和民主化**。 以下是根据筛选标准的详细判断过程： 1.  **第一步：核心判断——这篇论文的本质是什么？** - **排除**。这篇论文的本质是关于AI评估基础设施的研究。它讨论了当前静态基准测试的局限性（如模型记忆化），并提出需要构建“动态、自适应的基准测试框架”和推广“AI基准测试木工”这一技能。这完全符合第一步排除标准中的第3点：“主要关注模型基础设施、部署优化、硬件加速的研究”。基准测试是机器学习研究和评估流程中的关键基础设施，但它本身不是智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - **不包含**。论文摘要中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。虽然提到了“AI evolution”，但这是指整个AI领域的快速发展，而不是智能体个体的自我演化机制。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - **符合**。虽然论文的主要焦点不是安全与对齐，但它提到了基准测试需要维持“可解释性”，这属于排除标准中的关键词。更重要的是，它的核心议题——基准测试——本身就在我的研究焦点之外。 4.  **第四步：处理特殊和模糊情况** - **不适用**。论文没有涉及智能体的推理/规划框架，也没有提出任何自我演化的机制。它讨论的是如何评估模型，而不是如何让模型自主行动或演化。 **最终决策**: 这篇论文的核心贡献是提出一种新的**评估方法论**（动态基准测试）和相关的教育倡议（基准测试木工），旨在解决AI模型评估中的挑战。它研究的对象是“基准”，而不是“智能体”。因此，尽管它讨论了AI的演化，但其视角是**评估者**的视角，而非**构建者**的视角。这与我研究“LLM智能体及其演化”的核心目标——即智能体本身的构建、能力与演化机制——完全不符。故应排除。"
    },
    {
        "index": "#35",
        "title": "Rethinking Expert Trajectory Utilization in LLM Post-training",
        "link": "/arxiv/2512.11470",
        "arxiv_id": "2512.11470",
        "authors": "Bowen Ding, Yuhan Chen, Jiayang Lv, Jiyao Yuan, Qi Zhu, Shuangshuang Tian, Dantong Zhu, Futing Wang, Heyuan Deng, Fei Mi, Lifeng Shang, Tao Lin",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.665721",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是关于**LLM的后训练方法论**，而非构建或演化LLM智能体。论文提出了一个名为“可塑性-天花板”的框架，旨在优化监督微调（SFT）和强化学习（RL）的结合方式，以最大化模型性能。这属于**提升基础模型能力**的范畴，而不是设计一个具有自主性、规划或工具使用能力的智能体框架。根据筛选标准，这属于“非Agentic的推理”，应被排除。 2.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现您关注的核心范式和能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Memory`, `Multi-Agent`, `Self-Evolving` 等。其讨论的“专家轨迹”是SFT和RL中的标准术语，指代训练数据，而非智能体在环境中的行动轨迹。 3.  **符合排除规则 (第四步):** 该论文是典型的关于如何提升LLM基础推理能力的研究。它探讨的是通过更好的训练流程和数据选择策略来增强模型本身，而不是研究智能体如何利用这些能力进行多步规划或任务执行。这完全符合“排除：如果只是关于提高LLM本身基础Token预测的数学或逻辑能力”的规则。 **总结:** 该论文的研究焦点是**模型训练工程**，旨在优化LLM的后训练过程，使其成为一个更强大的基础模型。而您的研究焦点是**Agentic AI**，即如何将LLM作为核心“大脑”来构建能够自主行动、协作和演化的智能体系统。两者属于不同的研究领域，因此该论文不符合您的要求。"
    },
    {
        "index": "#1",
        "title": "MedAI: Evaluating TxAgent's Therapeutic Agentic Reasoning in the NeurIPS CURE-Bench Competition",
        "link": "/arxiv/2512.11682",
        "arxiv_id": "2512.11682",
        "authors": "Tim Cofala, Christian Kalfar, Jingge Xiao, Johanna Schrader, Michelle Tang, Wolfgang Nejdl",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.226966",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是应用型评估，而非方法论创新。** 论文的核心贡献并非构建、改进或演化LLM智能体的通用方法论或新框架。根据摘要，其核心工作是“介绍了我们从参与CURE-Bench NeurIPS 2025挑战赛中获得的见解”，并“分析了用于函数（工具）调用的检索质量如何影响整体模型性能，以及通过改进工具检索策略所实现的性能提升”。这本质上是对一个已有的智能体（TxAgent）在特定领域（医疗治疗决策）的应用表现进行评估和组件级优化。这完全符合第一步中的排除标准 **“非演化型应用”**：将一个已有的Agentic框架（TxAgent）应用到特定领域（医疗）去解决该领域的问题，并评估其效果。 2.  **贡献焦点不在于“演化”或“构建”。** 尽管论文提到了“改进工具检索策略”，但这种改进是针对特定任务和特定数据集的增量优化，而非提出一种能够让智能体进行自我完善和迭代的通用“自我演化”机制。它没有涉及智能体通过经验、反思或环境反馈进行自我完善的核心研究目标。 3.  **正面指标与排除标准的权衡。** 虽然论文包含了 `Agentic AI`, `Tool Use`, `Reasoning` 等正面指标，但这些指标描述的是论文的研究对象，而非其核心贡献。筛选标准的核心在于判断论文的“核心贡献”是什么。这篇论文的贡献是“评估”和“在特定应用场景下的优化分析”，而不是“构建”或“演化”智能体本身。因此，第一步的排除判断优先级更高。 综上所述，该论文是一篇优秀的应用型研究，详细分析了LLM智能体在医疗领域的应用挑战和性能表现。但其核心贡献在于应用评估和特定场景的优化，而非您所关注的构建、改进或演化LLM智能体的前沿方法论。因此，它不符合您的筛选要求。"
    },
    {
        "index": "#39",
        "title": "SCOUT: A Defense Against Data Poisoning Attacks in Fine-Tuned Language Models",
        "link": "/arxiv/2512.10998",
        "arxiv_id": "2512.10998",
        "authors": "Mohamed Afane, Abhishek Satyam, Ke Chen, Tao Li, Junaid Farooq, Juntao Chen",
        "subjects": "Cryptography and Security, Computation and Language",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.673139",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于构建、改进或演化LLM智能体的论文，而这篇论文的核心贡献是模型安全与防御。 具体判断过程如下： 1.  **第一步：核心判断** - 论文的核心贡献是提出 **SCOUT**，一个用于检测微调语言模型中**数据投毒/后门攻击**的**防御框架**。 - 这篇论文的本质是**模型安全**研究，而不是关于构建或演化智能体的方法论。它没有涉及智能体的规划、工具使用、记忆、自我反思或多智能体协作等核心能力。因此，它不属于“保留”的范畴，而应归入“非演化型应用”或更具体地说是“安全与对齐”的排除类别。 2.  **第二步：正面指标** - 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 也没有提及智能体的关键能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 缺乏任何正面指标，进一步表明该论文与我的研究焦点无关。 3.  **第三步：排除标准** - 这是最关键的一步。论文的标题和摘要明确指出其研究重点是 **\"Defense Against Data Poisoning Attacks\"**（防御数据投毒攻击）和 **\"security threats\"**（安全威胁）。 - 根据我的筛选标准：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Alignment` ... 一律排除。” 这篇论文完全符合此排除标准。它的核心是解决安全问题，而不是构建或演化智能体。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及推理/规划或自我演化的特殊情况，因此无需特殊考量。 **最终决策**：综合以上分析，这篇论文的核心贡献是LLM的安全与防御，而非LLM智能体的构建、改进或演化。尽管模型安全对智能体系统很重要，但这篇论文的研究本身并不属于“Agentic AI”的范畴。因此，它被明确排除。"
    },
    {
        "index": "#7",
        "title": "General-purpose AI models can generate actionable knowledge on agroecological crop protection",
        "link": "/arxiv/2512.11474",
        "arxiv_id": "2512.11474",
        "authors": "Kris A. G. Wyckhuys",
        "subjects": "Artificial Intelligence, Computers and Society, Information Retrieval",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.230003",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** - **论文的核心贡献是什么？** 这篇论文的核心贡献是**评估和验证**两个现有的大型语言模型（DeepSeek和ChatGPT）在特定领域（农业生态作物保护）中生成知识的质量。它比较了这两个模型在事实准确性、数据一致性和知识广度等方面的表现。 - **是否符合“构建、改进或演化LLM智能体”的目标？** 不符合。该论文没有提出任何新的智能体框架、改进方法或演化机制。它只是将现有的LLM作为工具，去解决一个特定领域的知识生成与验证问题。 - **结论：** 这篇论文属于典型的**“非演化型应用”**，即使用LLM作为工具应用到农业科学领域。根据筛选标准，应直接排除。 2.  **第二步：正面指标** - 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** - 虽然论文提到了“hallucinated”（幻觉），但这只是作为评估模型性能的一个负面指标，并非论文的主要研究贡献。论文的核心不是解决幻觉问题，而是量化它在特定应用中的程度。因此，它不属于“安全与对齐”的排除范畴，但已在第一步被排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及智能体的规划或推理框架，也不涉及任何自我演化机制，因此特殊规则不适用。 **最终决策**：综合以上分析，该论文的本质是一项**应用评估研究**，而非**智能体方法学研究**。它关注的是“LLM在农业领域能做什么”，而不是“如何构建一个更好的LLM智能体”。因此，它完全不符合我关于“LLM智能体及其演化”的核心研究目标。"
    },
    {
        "index": "#8",
        "title": "Three methods, one problem: Classical and AI approaches to no-three-in-line",
        "link": "/arxiv/2512.11469",
        "arxiv_id": "2512.11469",
        "authors": "Pranav Ramanathan, Thomas Prellberg, Matthew Lewis, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.230492",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是**系统性地比较**了三种方法（经典整数线性规划、PatternBoost transformer学习、强化学习PPO）在解决一个特定数学问题“No-Three-In-Line”上的性能。这完全符合**排除标准1：非演化型应用**。该论文将AI模型（Transformer和PPO）作为解决特定领域（组合几何）问题的工具，其研究焦点在于比较不同算法在特定任务上的效果，而不是构建、改进或演化LLM智能体本身。论文没有提出任何新的智能体框架、能力或演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所列出的任何核心正面指标。它没有涉及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving` 等核心范式。虽然提到了强化学习（PPO），但它是被用作一个优化算法来寻找问题的解，而不是作为构建具有自主规划、工具使用或反思能力的智能体的框架。论文的研究对象是算法，而非智能体。 3.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不符合保留条件。它没有研究“智能体如何进行规划”，而是使用RL算法直接学习一个策略来输出问题的解。这与研究智能体在复杂任务中进行多步推理的框架（如ReAct）有本质区别。它更接近于“提高模型在特定任务上的基础能力”，而非构建一个通用的Agentic推理框架。 - **自我演化的应用**: 论文不涉及任何“自我演化”机制，因此例外情况不适用。 **结论**: 综合以上分析，该论文是一篇典型的AI应用研究，旨在解决一个具体的数学问题。它的核心贡献不在于LLM智能体的构建、改进或演化，因此与您“LLM智能体及其演化”的核心研究目标不符，应予以排除。"
    },
    {
        "index": "#40",
        "title": "TV2TV: A Unified Framework for Interleaved Language and Video Generation",
        "link": "/arxiv/2512.05103",
        "arxiv_id": "2512.05103",
        "authors": "Xiaochuang Han, Youssef Emad, Melissa Hall, John Nguyen, Karthik Padthe, Liam Robbins, Amir Bar, Delong Chen, Michal Drozdzal, Maha Elbayad, Yushi Hu, Shang-Wen Li, Sreya Dutta Roy, Jakob Verbeek, XuDong Wang, Marjan Ghazvininejad, Luke Zettlemoyer, Emily Dinan",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.673901",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是多模态生成，而非智能体构建。** 论文的核心贡献是提出了一个名为TV2TV的**视频生成框架**。其目标是解决视频生成任务中的复杂语义分支和高级推理问题。虽然它借鉴了语言模型的推理思想（“用文字思考”），但这整个机制是服务于“生成高质量视频”这一最终目的的。它本质上是一个**非演化型应用**，即将LLM的推理能力作为一种内部组件，用于改进特定领域（视频生成）的模型性能，而不是构建一个具有自主性、规划能力和工具使用能力的通用LLM智能体。 2.  **排除标准 (第三步): 论文核心属于多模态与视觉领域。** 这是最直接的排除依据。我的筛选标准明确指出，如果论文主要关注点是 `Vision`, `Vision-Language`, `MLLMs` 等，并且它们是研究的核心而非智能体的工具，就应排除。TV2TV论文的研究核心正是**视频生成**、**视觉质量**和**视频帧预测**。语言模型在这里是作为规划和提升视频生成质量的工具，这与我的研究焦点“Agentic AI”是本末倒置的。我的研究是“用智能体解决问题”，而这篇论文是“用LLM技术解决视频生成问题”。 3.  **特殊与模糊情况处理 (第四步): “规划”不等于“智能体”。** 论文中提到的“用文字思考”和“决定接下来应该发生什么”确实是一种**规划**。然而，根据筛选标准，我们需要区分智能体的规划和生成模型的内部推理。这里的规划是**生成管道内部的一个静态步骤**，用于决定下一帧视频的内容，它不涉及智能体在动态环境中的自主决策、与外部工具的交互、或基于反馈的自我修正。它更接近于“非Agentic的推理”，即提升模型（这里是视频生成模型）本身的基础能力，而不是构建一个Agentic框架。 **总结:** 尽管TV2TV框架巧妙地利用了语言模型的推理能力来增强视频生成，但其本质和核心贡献属于**多模态生成领域**，而非**LLM智能体领域**。它没有构建一个自主的、可演化的智能体，而是构建了一个更强大的视频生成器。因此，它不符合我关于“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#4",
        "title": "AI-MASLD Metabolic Dysfunction and Information Steatosis of Large Language Models in Unstructured Clinical Narratives",
        "link": "/arxiv/2512.11544",
        "arxiv_id": "2512.11544",
        "authors": "Yuan Shen, Xiaojun Wu, Linghua Yu",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.228656",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是评估而非构建** 论文的核心贡献并非构建、改进或演化LLM智能体。它的本质是一项**实证评估研究**，旨在测试现有LLM（GPT-4o, Gemini等）在特定领域（医疗临床叙述）处理信息时的能力，并发现其功能衰退现象。这完全符合第一步排除标准中的 **“非演化型应用”**——将LLM作为工具应用到医疗领域，去解决该领域的问题（评估信息提取的可靠性），而不是提出新的智能体方法论或框架。论文提出的“AI-MASLD”概念，是对一种观察到的失败模式的命名和描述，而不是一种新的智能体演化机制。 2.  **排除标准 (第三步): 核心贡献属于安全与对齐** 论文的最终落脚点和主要贡献是提供一个“至关重要的安全警告”，强调LLM在医疗应用中的风险和局限性。这明确地将其归入了 **“安全与对齐”** 的排除范畴。研究焦点是模型的可靠性、缺陷和潜在危害，而非其作为智能体的能力增强或演化。 3.  **正面指标缺失 (第二步): 缺乏Agentic核心要素** 通读摘要，论文完全没有提及任何与您研究焦点相关的核心概念。它不涉及智能体的`规划`、`工具使用`、`记忆`、`自我反思`，也没有`多智能体协作`或`自我演化`的任何机制。论文的研究对象是LLM的基础信息提取能力在噪声环境下的表现，而非其作为智能体的自主行为能力。 综上所述，该论文是一项关于LLM在特定高风险领域应用的可靠性与安全性研究，其核心是评估和发现问题，而非构建或演化智能体。因此，它严格地落在了您研究范围之外。"
    },
    {
        "index": "#9",
        "title": "Motif-2-12.7B-Reasoning: A Practitioner's Guide to RL Training Recipes",
        "link": "/arxiv/2512.11463",
        "arxiv_id": "2512.11463",
        "authors": "Junghwan Lim, Sungmin Lee, Dongseok Kim, Taehyun Kim, Eunhwan Park, Jeesoo Lee, Jeongdoo Lee, Junhyeok Lee, Wai Ting Cheung, Dahye Choi, Minsu Ha, Jaeheui Her, Jaeyeon Huh, Hanbin Jung, Changjin Kang, Beomgyu Kim, Minjae Kim, Taewhan Kim, Youngrok Kim, Hyukjin Kweon, Haesol Lee, Kungyu Lee, Dongpin Oh, Yeongjae Park, Bokki Ryu, Dongjoo Weon",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.231213",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一套用于训练语言模型（`Motif-2-12.7B-Reasoning`）的“训练方案”，旨在提升模型在复杂推理和长上下文理解方面的能力。这属于**模型训练和优化的范畴**，而非构建、改进或演化LLM智能体的方法论或新框架。根据筛选标准，这直接触发了**排除项2：非Agentic的推理**。论文关注的是如何通过SFT和RLFT等技术提升LLM本身的基础推理能力，而不是设计一个能够自主规划、使用工具或进行自我反思的智能体框架。 2.  **第二步：正面指标分析** 尽管摘要中提到了“agentic benchmarks”，但这只是评估模型性能的测试集，并非论文的核心贡献。论文本身并未包含我关注的核心范式或智能体能力的关键词，如 `Agentic AI`、`Planning`（作为框架）、`Tool Use`、`Self-Reflection`、`ReAct`、`Multi-Agent` 或 `Self-Evolving`。它提到的“memory-efficient infrastructure”指的是系统内存优化，而非智能体的记忆机制。 3.  **第四步：处理特殊情况** 这篇论文是“推理/规划”模糊情况的典型案例。 - **排除**: 论文的核心是提升LLM的基础Token预测能力在数学、编码等领域的表现，其方法是数据筛选和训练算法（SFT/RLFT），这不涉及智能体自主规划或多步推理的框架设计。 - **保留**: 如果论文提出了一种新的智能体框架（例如，一种超越ReAct或ToT的新规划方法），即使它也包含训练细节，也应该保留。但本文并非如此。 **核心依据**: 我的研究焦点是**Agentic AI的架构、机制和演化**，即“如何让LLM成为一个智能体”。而这篇论文的焦点是**如何训练一个更强大的基础模型**，即“如何让LLM这个大脑更聪明”。虽然一个更聪明的大脑对智能体很重要，但这篇论文的贡献在于“训练大脑”本身，而不是“设计智能体”。因此，它属于模型训练领域，而非我的核心研究范围“LLM智能体及其演化”。"
    },
    {
        "index": "#5",
        "title": "EmeraldMind: A Knowledge Graph-Augmented Framework for Greenwashing Detection",
        "link": "/arxiv/2512.11506",
        "arxiv_id": "2512.11506",
        "authors": "Georgios Kaoukis, Ioannis Aris Koufopoulos, Psaroudaki Eleni, Danae Pla Karidi, Evaggelia Pitoura, George Papastefanatos, Panayiotis Tsaparas",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.229122",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文本质是“非演化型应用”** 论文的核心贡献是构建了一个名为 `EmeraldMind` 的框架，用于解决特定领域的问题——检测“漂绿”行为。它将知识图谱和检索增强生成（RAG）技术相结合，以提升在特定任务（ESG报告分析）上的性能。这完全符合筛选标准中的排除项：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗、金融、法律……）”。这里的特定领域是环境、社会和治理（ESG）相关的虚假信息检测。 2.  **缺乏核心关注点（第二步）：未涉及智能体的关键能力** 尽管论文使用了检索增强生成（RAG），这可以被视为一种“工具使用”，但论文并未提出一个通用的、自主的智能体框架。摘要中没有提及任何关于智能体自主规划、长期记忆、自我反思、自我修正或与环境进行多步交互循环的机制。它描述的是一个更直接的“检索-评估-分类”流程，而不是一个具有能动性的智能体。 3.  **触及排除标准（第三步）：关注点偏向安全与可解释性** 论文明确强调了其框架的几个关键特性：“呈现透明、证据-backed的裁决”和“负责任地拒绝回答”。这些特性直接关联到 `Interpretability` (可解释性)、`Explainability (XAI)` 和 `Safety` (安全)。根据您的筛选标准，只要论文的主要贡献与这些方面紧密相关，就应被排除。虽然其主要贡献是应用框架，但这些被重点突出的特性使其进一步偏离了您对“构建和演化智能体”的核心关注。 4.  **不符合特殊情况（第四步）** 该论文不属于“自我演化的应用”例外情况，因为它没有提出任何能让智能体通过经验或反馈进行自我完善和迭代的机制。其框架是静态的，依赖于预先构建的知识图谱。 **总结**： `EmeraldMind` 论文的核心目标是构建一个更准确、更可解释、更安全的**应用系统**来解决“漂绿”这一具体问题。它虽然使用了与智能体相关的技术（如RAG），但其研究焦点并非智能体本身的架构、能力或演化机制，而是如何利用这些技术优化特定领域的应用效果。因此，它不符合您关于“LLM智能体及其演化”的前沿研究筛选目标。"
    },
    {
        "index": "#6",
        "title": "BAID: A Benchmark for Bias Assessment of AI Detectors",
        "link": "/arxiv/2512.11505",
        "arxiv_id": "2512.11505",
        "authors": "Priyam Basu, Yunfeng Zhang, Vipul Raheja",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.229572",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **核心判断 (第一步)**: 论文的核心贡献是构建了一个名为 BAID 的**基准**，用于**评估**AI文本检测器中的偏见。它并没有提出新的LLM智能体架构、改进智能体的能力（如规划、记忆），也没有设计智能体的自我演化机制。因此，这篇论文的本质是**评估和审计**一个AI系统，而非**构建或演化**一个LLM智能体。这直接触发了第一步的排除标准：“非演化型应用”，即将LLM或相关技术作为工具应用到特定领域（此处为AI安全与公平性评估）去解决该领域的问题。 2.  **排除标准 (第三步)**: 论文的核心主题是“偏见评估”。这明确属于“安全与对齐”的研究范畴。根据筛选标准，只要论文的主要贡献是关于 `Safety`、`Security`、`Interpretability`、`Alignment` 等，就应被排除。该论文旨在揭示和量化AI检测器在不同社会群体上的性能差异，这正是AI安全和公平性研究的核心议题。 3.  **正面指标 (第二步)**: 论文的摘要和标题中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving` 等。其关注点在于 `Bias Assessment`、`Benchmark`、`Auditing`，这与我的研究方向完全偏离。 **综上所述**，该论文的核心贡献是提出一个用于评估AI检测器偏见的基准，属于AI安全与对齐领域，而非LLM智能体的构建、改进或演化。因此，它不符合我的研究目标，应被排除。"
    },
    {
        "index": "#13",
        "title": "CAPTURE: A Benchmark and Evaluation for LVLMs in CAPTCHA Resolving",
        "link": "/arxiv/2512.11323",
        "arxiv_id": "2512.11323",
        "authors": "Jianyi Zhang, Ziyin Zhou, Xu Ji, Shizhao Liu, Zhangchi Zhao",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.232762",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**构建一个基准**，用于评估大视觉语言模型在解决CAPTCHA任务上的表现。它没有提出任何关于构建、改进或演化LLM智能体的新方法论或新框架。这完全符合第一步中的排除标准：“非演化型应用”，即只是将模型（LVLMs）作为工具应用到特定领域（安全/CAPTCHA）去解决该领域的评估问题。 2.  **排除标准 (第三步):** 论文明确聚焦于**大视觉语言模型**。标题和摘要中反复提及 \"LVLMs\" (Large Visual Language Models)，这直接触发了第三步中的排除标准：“多模态与视觉”。研究的核心是LVLMs的视觉理解和推理能力，而不是将视觉作为智能体感知环境的一个工具。 3.  **缺乏正面指标 (第二步):** 论文中完全没有出现您所关注的核心范式和能力。它不涉及 `Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving`。虽然摘要中提到了 \"reasoning capabilities\"，但这指的是LVLM模型本身的基础能力，而非在智能体框架下的自主规划或工具使用。 综上所述，该论文的本质是**模型评估**，而非**智能体构建**。它的研究焦点是LVLMs在特定视觉任务上的性能基准，这与您“构建、改进或演化LLM智能体”的核心目标相去甚远。因此，应予以排除。"
    },
    {
        "index": "#19",
        "title": "Unified Smart Factory Model: A model-based Approach for Integrating Industry 4.0 and Sustainability for Manufacturing Systems",
        "link": "/arxiv/2512.10631",
        "arxiv_id": "2512.10631",
        "authors": "Ishaan Kaushal, Amaresh Chakrabarti",
        "subjects": "Emerging Technologies",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.234487",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是提出了一个“统一智能工厂模型（USFM）”。根据摘要，这是一个基于“对象过程方法论（OPM）”和“基于模型的系统工程（MBSE）”的框架，旨在将高层级的可持续发展目标转化为工厂级别的可衡量指标，并对制造活动进行建模。 - **判断**: 论文的核心是**系统工程和制造业流程管理**，而非构建或演化LLM智能体。它完全没有提及LLM、智能体或任何相关的人工智能框架。因此，这篇论文明确属于**排除类别中的“非演化型应用”**。它将一个特定的工程模型（MBSE/OPM）应用在制造业领域，来解决可持续发展问题，这与我的研究目标“构建、改进或演化LLM智能体”完全无关。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何我关注的核心范式、智能体能力、多智能体或演化机制相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Multi-Agent Systems`, `Self-Evolving` 等。这进一步确认了该论文与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不属于“安全与对齐”或“多模态与视觉”的排除类别，但它在第一步的核心判断中已经被明确排除，因为它根本不属于人工智能研究的范畴。 4.  **第四步：处理特殊和模糊情况** - 本论文不涉及任何与“推理/规划”或“自我演化”相关的模糊情况。其讨论的“规划”是工厂级别的生产流程规划，而非智能体的自主任务规划。 5.  **第五步：最终决策** - 综合以上分析，该论文是一篇典型的工业工程/制造业领域的论文，其研究内容是关于如何使用MBSE方法来建模和优化工厂的可持续发展指标。它没有涉及LLM，没有涉及智能体，更没有涉及智能体的演化。因此，它完全不符合我为“LLM智能体及其演化”课题设定的筛选标准。"
    },
    {
        "index": "#10",
        "title": "Back to the Baseline: Examining Baseline Effects on Explainability Metrics",
        "link": "/arxiv/2512.11433",
        "arxiv_id": "2512.11433",
        "authors": "Agustin Martin Picard, Thibaut Boissin, Varshini Subhash, Rémi Cadène, Thomas Fel",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.231855",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是关于**可解释性人工智能（XAI）**。它研究的是评估归因方法时所使用的“基线”存在的问题，并提出了一种新的基线来改善评估指标。这与“构建、改进或演化LLM智能体”的核心目标完全无关。论文没有提出任何新的智能体框架、智能体能力或演化机制。因此，在第一步的核心判断中，就应被排除。 2.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文明确命中了两个关键的排除标准： *   **安全与对齐：** 论文的研究领域是“Explainable Artificial Intelligence (XAI)”，即“可解释性”。根据您的筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` (可解释性)...一律排除”。这篇论文是典型的可解释性研究，因此必须排除。 *   **多模态与视觉：** 论文的研究对象是图像，具体是“alter the pixels of the input image”。这属于视觉范畴。虽然视觉可以作为智能体感知环境的工具，但在这篇论文中，视觉是XAI研究的核心主题，而不是作为智能体框架的一部分被研究，因此符合排除条件。 3.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与您研究焦点相关的正面指标，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。 **总结：** 该论文是一篇纯粹的XAI方法学研究，旨在改进对模型归因方法的评估。它既不涉及LLM智能体的构建，也不涉及多智能体系统或自我演化机制。其核心贡献完全落在“可解释性”这一明确排除的研究方向上。因此，该论文与您的研究课题“LLM智能体及其演化”完全不相关。"
    },
    {
        "index": "#20",
        "title": "Particulate: Feed-Forward 3D Object Articulation",
        "link": "/arxiv/2512.11798",
        "arxiv_id": "2512.11798",
        "authors": "Ruining Li, Yuxin Yao, Chuanxia Zheng, Christian Rupprecht, Joan Lasenby, Shangzhe Wu, Andrea Vedaldi",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Graphics",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.234829",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **核心判断 (第一步)**: 论文的核心贡献是提出了一种名为 `Particulate` 的前馈神经网络，用于从单个静态3D网格中快速推断物体的铰接结构（如部件、运动学关系）。这本质上是一个 **3D视觉/计算机图形学** 领域的技术创新，而非关于构建、改进或演化LLM智能体的方法论。根据筛选标准，这属于 **“非演化型应用”**，即将一个深度学习模型应用于特定领域（3D视觉）解决该领域的问题，因此应被排除。 2.  **正面指标 (第二步)**: 论文中完全没有出现您关注的核心范式或智能体能力相关的关键词，如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent` 或 `Self-Evolving`。论文中的 `Transformer` 网络是作为一种处理点云数据的通用架构，并非一个智能体框架。 3.  **排除标准 (第三步)**: 该论文完全符合 **“多模态与视觉”** 的排除标准。其研究对象是 `3D mesh` (3D网格)、`point cloud` (点云)，目标是生成 `articulated 3D model` (铰接3D模型)。这属于典型的 `3D Vision` 研究范畴，且是该论文的绝对核心，而不是作为智能体感知环境的工具。 4.  **特殊和模糊情况 (第四步)**: 论文不涉及任何与智能体相关的推理或规划框架。它是一个端到端的预测模型，而非一个自主规划、使用工具或进行多步推理的智能体。同时，论文也未提出任何“自我演化”机制。 **最终决策 (第五步)**: 综合以上分析，这篇论文的核心是3D视觉模型，与您的研究焦点“LLM智能体及其演化”在本质上完全不同。它既不涉及智能体的构建，也不涉及多智能体系统或自我演化机制。因此，应明确排除。"
    },
    {
        "index": "#17",
        "title": "Deep Learning--Accelerated Multi-Start Large Neighborhood Search for Real-time Freight Bundling",
        "link": "/arxiv/2512.11187",
        "arxiv_id": "2512.11187",
        "authors": "Haohui Zhang, Wouter van Heeswijk, Xinyu Hu, Neil Yorke-Smith, Martijn Mes",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.233888",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **结论：排除**。 - **依据**：这篇论文的核心贡献是提出一种用于解决“实时货运捆绑”这一特定物流领域问题的混合算法。它将一个Transformer神经网络作为“构造性策略”，为“大规模邻域搜索”元启发式算法提供高质量的初始解。这完全符合筛选标准中的“非演化型应用”类别：它将一个深度学习模型（Transformer，但并非作为LLM智能体）作为工具，应用于特定领域（物流）去解决该领域的组合优化问题。论文的本质是算法工程和运筹学，而非构建或演化智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - **结论：不包含**。 - **依据**：论文摘要中完全没有出现任何您关注的核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。虽然提到了“routing”（路径规划），但这是在组合优化问题（旅行商问题）的语境下，指代寻找最优路径，而不是智能体自主规划行动序列的能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - **结论：不适用**。 - **依据**：虽然论文不涉及安全对齐或多模态等排除项，但第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** - **结论：不适用**。 - **依据**：论文不涉及智能体框架下的推理/规划，也没有提出任何自我演化机制。 **最终决策**： 综合以上分析，这篇论文的核心是**应用深度学习技术加速一个特定领域的组合优化求解器**。它所使用的Transformer模型是一个功能固定的“构造器”，用于生成初始解，不具备任何智能体的自主性、规划、记忆、工具使用或自我演化能力。因此，该论文的研究焦点是运筹学和算法优化，与您关于“LLM智能体及其演化”的研究目标完全不符。"
    },
    {
        "index": "#18",
        "title": "CORL: Reinforcement Learning of MILP Policies Solved via Branch and Bound",
        "link": "/arxiv/2512.11169",
        "arxiv_id": "2512.11169",
        "authors": "Akhil S Anand, Elias Aarekol, Martin Mziray Dalseg, Magnus Stalhane, Sebastien Gros",
        "subjects": "Artificial Intelligence, Machine Learning, Systems and Control, Optimization and Control",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.234232",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出一个名为CORL的框架，使用强化学习（RL）来端到端地微调混合整数线性规划（MILP）的求解策略，以提升其在特定任务上的性能。这属于**将机器学习方法（强化学习）应用于一个特定的传统领域（运筹学优化）**，而不是构建、改进或演化LLM智能体。因此，它符合第一步的排除标准：“非演化型应用”，即只是将一种机器学习方法应用到特定领域去解决该领域的问题。论文的研究对象是MILP求解器，而非具有自主规划、记忆、工具使用等能力的LLM智能体。 2.  **第二步：正面指标** 论文中完全不包含任何与研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Tool Use`, `Memory`, `Self-Reflection` 等。虽然提到了`Reinforcement Learning`，但它是作为一种优化MILP求解器的工具，而不是用于构建或演化智能体。 3.  **第三步：排除标准** 论文不涉及安全与对齐或多模态与视觉，因此不触犯此条排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文虽然涉及“sequential decision making”（序列决策），但这指的是运筹学中的优化问题，而非Agentic AI语境下智能体的自主规划能力。它没有提出任何新的智能体规划框架（如ReAct或ToT），而是改进一个底层的数学求解算法。因此，这属于“非Agentic的推理”，应被排除。 - **自我演化的应用**: 论文使用RL进行“end to end fine tunes”，这是一种迭代改进。但这并非一个通用的“自我演化”智能体机制，而是针对特定MILP模型的参数优化。其核心贡献是“如何让MILP求解器可微以适配RL”，而不是提出一种新的自我演化范式。 **最终决策**: 该论文的研究焦点是优化算法，与“LLM智能体及其演化”这一核心课题无关。它没有构建或改进任何形式的LLM智能体，而是将强化学习技术应用于一个完全不同的领域（运筹学）。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#21",
        "title": "Super Suffixes: Bypassing Text Generation Alignment and Guard Models Simultaneously",
        "link": "/arxiv/2512.11783",
        "arxiv_id": "2512.11783",
        "authors": "Andrew Adiletta, Kathryn Adiletta, Kemal Derya, Berk Sunar",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.235127",
        "filter_reason": "这篇论文不符合研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“Super Suffixes”的对抗性攻击方法，用于绕过LLM的对齐机制和防护模型，并相应地提出了一种名为“DeltaGuard”的防御检测方法。其本质是关于LLM的**安全、对抗性攻击与防御**，而不是关于构建、改进或演化LLM智能体本身。它没有提出新的智能体架构、规划策略、记忆机制或自我演化框架。因此，根据第一步的排除规则，这篇论文应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式或能力关键词，例如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其讨论的焦点是 `adversarial inputs`, `alignment objectives`, `bypassing protection`, `detect attacks`，这些均不属于我的研究焦点。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这篇论文是典型的“安全与对齐”研究。摘要中明确提到了 `enhanced security`, `protect text generation models from adversarial or malicious inputs`, `overriding multiple alignment objectives`, `compromised`, `detect malicious prompts`。根据筛选标准，只要论文的主要贡献是关于 `Safety`, `Security`, `Alignment`，就应一律排除。这篇论文完全符合此排除标准。 4.  **第四步：处理特殊和模糊情况** 本文不涉及推理/规划或自我演化的特殊情况，因此该步骤不适用。 **最终决策**： 综合以上分析，尽管这篇论文研究的是前沿的LLM技术，但其核心领域是**安全与对齐**，而非**LLM智能体的构建与演化**。它研究的是如何攻破和加固LLM的安全护栏，而不是如何让智能体变得更自主、更智能或能够自我进化。因此，它严格地落在了我的研究范围之外，应被排除。"
    },
    {
        "index": "#23",
        "title": "Conditional Coverage Diagnostics for Conformal Prediction",
        "link": "/arxiv/2512.11779",
        "arxiv_id": "2512.11779",
        "authors": "Sacha Braun, David Holzmüller, Michael I. Jordan, Francis Bach",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.235742",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心贡献不符 (第一步核心判断)**: 论文的核心贡献是提出了一种名为“ERT (excess risk of the target coverage)”的新统计指标，用于诊断和评估“共形预测”系统的“条件覆盖率”。这是一个关于**预测系统可靠性评估**的统计学方法，而非关于**构建、改进或演化LLM智能体**的方法论或新框架。论文的研究对象是“预测系统”，而不是“智能体”。 2.  **缺乏核心关注点 (第二步正面指标)**: 论文的摘要和标题中完全没有出现我关注的核心范式和智能体能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其讨论的重点是“覆盖率”、“分类器风险”、“共形预测”等机器学习理论和统计评估术语。 3.  **研究焦点偏离 (第三步排除标准)**: 论文的核心目标是“理解、诊断和改进预测系统的条件可靠性”。这种对系统“可靠性”和“诊断”的关注，使其研究范畴更接近于**安全与对齐**领域中的可解释性或可靠性评估，而不是我聚焦的Agentic AI的构建与演化。 综上所述，该论文属于机器学习理论/统计评估领域，旨在为预测模型提供一种新的不确定性量化评估工具。它并未涉及智能体的规划、工具使用、多智能体协作或自我演化等核心机制，因此与我的研究课题“LLM智能体及其演化”不相关。根据筛选标准，应予以排除。"
    },
    {
        "index": "#24",
        "title": "Smudged Fingerprints: A Systematic Evaluation of the Robustness of AI Image Fingerprints",
        "link": "/arxiv/2512.11771",
        "arxiv_id": "2512.11771",
        "authors": "Kai Yao, Marc Juarez",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.236020",
        "filter_reason": "这篇论文的核心贡献是对AI图像指纹技术进行系统性的安全评估，研究其在对抗性攻击下的鲁棒性。这与您的研究目标“构建、改进或演化LLM智能体”完全不符。 具体判断过程如下： 1.  **第一步：核心判断**：该论文的本质是关于AI生成内容（AIGC）的**安全与取证**研究，具体是评估和攻击图像模型的指纹（一种水印技术）。它既没有构建新的LLM智能体，也没有提出多智能体系统或自我演化框架。因此，根据第一步的核心判断，应被**排除**。 2.  **第二步：正面指标**：论文摘要中完全没有出现您关注的核心范式或智能体能力相关的正面指标，例如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent Systems` 等。 3.  **第三步：排除标准**：该论文明确命中了多个排除标准。 *   **安全与对齐**：论文的核心是 `Security` (安全评估)，研究的是 `Watermarking` (模型指纹) 技术的鲁棒性。这完全属于“只要论文的主要贡献是关于 Safety, Security, Watermarking，一律排除”的范畴。 *   **多模态与视觉**：论文的研究对象是 `AI Image Fingerprints` 和 `image generators`，属于 `Vision` 领域。虽然LLM智能体可能会使用视觉工具，但在这篇论文中，视觉模型本身是研究的核心，而不是智能体的一个组件。 4.  **第四步：特殊和模糊情况**：该论文不涉及任何与智能体规划或自我演化相关的特殊情况。 **最终决策**：综合以上分析，该论文是一篇典型的AI安全与取证领域的研究，其焦点是图像模型的指纹技术，与您的Agentic AI研究焦点（单智能体、多智能体、自我演化）无关。因此，应明确排除。"
    },
    {
        "index": "#32",
        "title": "Multi-temporal Calving Front Segmentation",
        "link": "/arxiv/2512.11560",
        "arxiv_id": "2512.11560",
        "authors": "Marcel Dreier, Nora Gourmelon, Dakota Pyles, Fei Wu, Matthias Braun, Thorsten Seehaus, Andreas Maier, Vincent Christlein",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.238620",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种用于**多时相冰川崩解前缘分割**的深度学习方法。它通过并行处理同一冰川的时间序列图像，并在特征图之间交换信息来提升分割精度。这完全属于**“非演化型应用”**。论文将一个深度学习模型（Tyrion架构）作为工具，应用于冰川学/遥感这一特定领域，以解决该领域的图像分割问题，其本质是计算机视觉研究，而非构建或演化LLM智能体。 2.  **正面指标缺失 (第二步):** 论文中完全没有出现您所关注的核心范式和能力。它不涉及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，它也没有讨论智能体的 `Planning`、`Tool Use`、`Memory`、`Collaboration` 或 `Self-Improvement` 等关键能力。 3.  **明确符合排除标准 (第三步):** 该论文的研究内容明确属于**“多模态与视觉”**类别。其核心任务是处理合成孔径雷达（SAR）图像进行分割，这是一个纯粹的计算机视觉问题。根据您的筛选标准，除非视觉是作为智能体感知环境的工具，否则应予以排除。在此论文中，视觉本身就是研究的核心，而非服务于一个更高层次的智能体框架。 综上所述，该论文是一篇典型的计算机视觉应用研究，与您关于“LLM智能体及其演化”的核心目标（单智能体、多智能体、自我演化）完全无关。因此，应予以排除。"
    },
    {
        "index": "#25",
        "title": "Generative Parametric Design (GPD): A framework for real-time geometry generation and on-the-fly multiparametric approximation",
        "link": "/arxiv/2512.11748",
        "arxiv_id": "2512.11748",
        "authors": "Mohammed El Fallaki Idrissi, Jad Mounayer, Sebastian Rodriguez, Fodil Meraghni, Francisco Chinesta",
        "subjects": "Computational Engineering, Finance, and Science, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.236314",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个名为“生成式参数化设计（GPD）”的框架，用于解决工程领域的几何生成和参数逼近问题。其核心技术是“降秩自编码器（RRAE）”和“稀疏 Proper Generalized Decomposition (sPGD)”，这些是传统的机器学习/深度学习模型，而非LLM。该论文完全属于 **“非演化型应用”** 的排除类别，因为它将一个机器学习框架作为工具应用到了特定的工程领域（仿真科学、数字孪生），其目标是解决该领域的设计和优化问题，而不是构建、改进或演化LLM智能体。 2.  **正面指标缺失 (第二步):** 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标。它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，它也未涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory` 或 `Self-Reflection`。这进一步确认了该论文与我的研究目标无关。 3.  **特殊规则不适用 (第四步):** *   **推理/规划:** 论文中的“设计探索和优化”是工程领域的概念，并非指智能体在复杂任务中的自主规划或多步推理框架（如ReAct）。因此，不适用保留规则。 *   **自我演化的应用:** 尽管论文应用于特定领域，但它并未提出任何“自我演化”机制。GPD框架本身是静态的，用于生成和逼近，而不是一个能从经验中学习和自我完善的智能体。因此，“自我演化的应用”这一例外保留规则不适用。 综上所述，该论文的本质是面向工程应用的机器学习方法论，与“LLM智能体及其演化”这一核心课题在研究对象、技术范式和研究目标上均存在根本性差异。因此，应予以排除。"
    },
    {
        "index": "#26",
        "title": "CogniSNN: Enabling Neuron-Expandability, Pathway-Reusability, and Dynamic-Configurability with Random Graph Architectures in Spiking Neural Networks",
        "link": "/arxiv/2512.11743",
        "arxiv_id": "2512.11743",
        "authors": "Yongsheng Huang, Peibo Duan, Yujie Wu, Kai Sun, Zhipeng Liu, Changsheng Zhang, Bin Zhang, Mingkun Xu",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.236676",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。判断依据如下： 1.  **核心判断（第一步）：论文的核心贡献与LLM智能体无关。** 论文的标题和摘要明确指出，其核心研究对象是**脉冲神经网络**，而非大语言模型（LLM）。论文提出的新范式“CogniSNN”是一种SNN架构，旨在通过随机图结构来模拟大脑的特性。我的研究目标是“LLM智能体及其演化”，核心是**基于LLM构建的智能体**。这篇论文从根本上就不属于LLM的研究范畴，因此直接在第一步的核心判断中就应该被排除。 2.  **对“自我演化”概念的误读（第四步）：** 虽然论文中提到了“Dynamic Growth Learning (DGL) algorithm”（动态增长学习算法）和“Pathway-Reusability”（通路可复用性），这些概念听起来与“自我演化”和“连续学习”相关。但是，根据筛选标准中的核心规则，这些机制是应用于**SNNs**的，而不是**LLM智能体**。我的研究焦点是LLM智能体的演化，而不是任何神经网络模型的演化。因此，即使该论文提出了新颖的演化机制，但由于其应用对象（SNN）不符合我的核心要求，所以不能保留。第四步的例外规则“如果论文的核心是提出一种新的‘自我演化’机制”有一个隐含前提，即该机制是作用于LLM智能体之上的。 3.  **缺乏正面指标（第二步）：** 论文摘要中完全没有出现任何与我的研究焦点相关的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Planning`, `Tool Use`, `Self-Reflection` 等。这进一步证实了该论文与我的研究课题无关。 **总结：** 尽管该论文在神经形态计算和SNN领域可能是一项有价值的工作，提出了具有动态增长和知识复用能力的网络结构，但它的技术基础（SNN）和研究目标（改进SNN架构）与我的核心课题“LLM智能体及其演化”存在根本性的偏差。因此，这篇论文被明确排除。"
    },
    {
        "index": "#34",
        "title": "Optimizing the Training Diet: Data Mixture Search for Robust Time Series Forecasting",
        "link": "/arxiv/2512.11546",
        "arxiv_id": "2512.11546",
        "authors": "Federico Pennino, Maurizio Gabbrielli",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.239415",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心判断 (第一步): 论文本质是数据优化，而非智能体构建或演化。** 该论文的核心贡献是提出一个**数据为中心**的框架，通过优化训练数据的混合比例来提升时间序列预测模型的性能。其本质是解决“如何为模型挑选更好的训练食谱”这一数据选择问题，而不是构建、改进或演化一个具有自主性的LLM智能体。论文中提到的模型是通用的深度学习模型（“large-scale encoder”和“smaller target model”），并未涉及LLM或任何智能体架构。因此，它完全符合第一步中的排除标准 **“1. 非演化型应用”**，即将一个优化框架应用于特定领域（时间序列预测）来解决该领域的问题。 2.  **缺乏核心关注点 (第二步): 无任何Agentic相关指标。** 通读摘要，论文完全没有提及我的核心关注点。它不包含 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving` 等核心范式，也未涉及 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等智能体能力。其方法论是基于聚类和优化库的搜索，与智能体的自主行为无关。 3.  **对“演化”的误解澄清 (第四步): 优化过程不等于智能体的自我演化。** 虽然论文使用了“Optuna optimization framework”进行搜索，但这是一种**外部的、元级别的优化**，旨在寻找最优的数据配比。它不是智能体通过经验、反思或环境反馈进行的**自我完善和迭代**。模型本身是被动的，它只是根据给定的数据集进行训练，并不参与演化过程。这与我所关注的“自我演化”机制有着本质区别。 综上所述，该论文的研究方向是数据工程和模型训练优化，与我的研究焦点“LLM智能体及其演化”在核心问题和方法论上均不匹配。因此，应予以排除。"
    },
    {
        "index": "#35",
        "title": "Graph Embedding with Mel-spectrograms for Underwater Acoustic Target Recognition",
        "link": "/arxiv/2512.11545",
        "arxiv_id": "2512.11545",
        "authors": "Sheng Feng, Shuqing Ma, Xiaoqian Zhu",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.239710",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 论文的核心贡献是提出一个名为 \"UATR-GTransformer\" 的深度学习模型，用于解决“水下声学目标识别”这一特定领域的问题。该模型结合了Transformer和图神经网络（GNN）来处理非欧几里得空间中的声学信号。 - **判断**: 这完全符合**排除标准中的“非演化型应用”**。论文的本质是将一个新颖的深度学习架构（Transformer + GNN）作为工具，应用到特定领域（海洋声学工程）去解决该领域的分类问题。它没有涉及构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 虽然论文提到了 `Transformer`，但这里的Transformer是作为模型的一个组件，用于处理Mel频谱图块，这与作为LLM智能体核心推理引擎的Transformer在应用范式上完全不同。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文的研究焦点是**特定领域的信号处理和模式识别**，而非Agentic AI。它不属于安全与对齐或多模态与视觉的排除范畴，但它最核心的问题在于它是一个**领域应用型研究**，而非智能体框架或机制的研究。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此特殊规则不适用。 **最终决策**: 综合以上分析，这篇论文的研究目标是解决水下声学识别问题，其核心贡献是一个新的深度学习模型架构。这与您“构建、改进或演化LLM智能体”的核心目标完全不符。它是一个典型的将深度学习技术应用于特定垂直领域的案例，因此应被明确排除。"
    },
    {
        "index": "#28",
        "title": "From Verification Burden to Trusted Collaboration: Design Goals for LLM-Assisted Literature Reviews",
        "link": "/arxiv/2512.11661",
        "arxiv_id": "2512.11661",
        "authors": "Brenda Nogueira, Werner Geyer, Andrew Anderson, Toby Jia-Jun Li, Dongwhi Kim, Nuno Moniz, Nitesh V. Chawla",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.237334",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选那些核心贡献在于**构建、改进或演化LLM智能体**的论文，而这篇论文的本质是**人机交互（HCI）研究**，而非Agentic AI研究。 以下是根据筛选标准的详细判断过程： 1.  **第一步：核心判断——这篇论文的本质是什么？** - **排除**。这篇论文的核心贡献是提出了一个用于“LLM辅助文献综述”的**设计目标和高层级框架**。其目的是解决研究人员在使用LLM进行文献综述时遇到的“信任缺失”、“验证负担”等问题。这完全符合**排除标准1：非演化型应用**。论文将LLM作为一个工具，应用于“学术写作”这一特定领域，并致力于优化该应用场景下的人机协作体验，而不是提出一种新的智能体构建或演化方法。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中几乎没有出现我的核心关注点。它没有涉及`Planning`（规划）、`Tool Use`（工具使用，这里的LLM本身就是工具，而非智能体主动使用工具）、`Memory`（记忆）、`Self-Evolving`（自我演化）等任何智能体核心能力。虽然提到了“collaboration”（协作），但指的是“研究人员与AI系统”之间的协作，而非智能体之间的协作。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - **是**。论文的核心贡献与**安全与对齐**排除标准高度重合。摘要明确指出，其框架通过“人类反馈对齐”和“生成引导的解释”来“推进信任”和“可验证的行动”。这本质上是在研究如何提升LLM应用的可解释性、可信度和人机对齐，这些都是HCI和XAI领域的核心议题，而非Agentic AI的核心议题。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何特殊情况。它既不是关于智能体的自主规划，也没有提出任何自我演化机制。 **最终决策**: 综合以上分析，这篇论文的核心贡献是**设计一个更好的人机交互界面和工作流**，以解决特定领域（文献综述）的应用问题。它的研究焦点是**如何让人类更信任、更高效地与LLM协作**，而不是**如何让LLM本身变得更智能、更自主或能够自我演化**。因此，尽管它是一篇有价值的研究，但它属于人机交互（HCI）范畴，与我的“LLM智能体及其演化”研究课题不符，应予以排除。"
    },
    {
        "index": "#36",
        "title": "Parallax: Runtime Parallelization for Operator Fallbacks in Heterogeneous Edge Systems",
        "link": "/arxiv/2512.11532",
        "arxiv_id": "2512.11532",
        "authors": "Chong Tang, Hao Dai, Jagmohan Chauhan",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.240046",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 \"Parallax\" 的**运行时框架**，用于在异构边缘设备上加速深度神经网络（DNN）的推理。它通过优化计算图的并行执行、内存管理和调度策略，来解决DNN在移动设备上因算子回退到CPU而导致的延迟和内存问题。这完全属于**基础设施、部署优化和硬件加速**的研究范畴。根据筛选标准，这类论文应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与我研究焦点相关的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。虽然提到了 \"memory management\"，但这里指的是计算机系统的内存管理，而非智能体的记忆机制。因此，该论文不包含任何正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文的研究焦点是系统层面的性能优化，不属于安全与对齐或多模态与视觉的排除范畴，但它已经被第一步的“基础设施”排除规则所覆盖。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理、规划或自我演化机制，因此特殊情况不适用。 **最终决策**: 综合以上分析，这篇论文的本质是关于**DNN推理的底层系统优化**，其核心贡献是提升计算效率，而非构建、改进或演化LLM智能体。它与我的研究目标“LLM智能体及其演化”在研究层面和核心贡献上存在根本性的偏离。因此，我判断这篇论文不符合要求，应予以排除。"
    },
    {
        "index": "#37",
        "title": "Contrastive Time Series Forecasting with Anomalies",
        "link": "/arxiv/2512.11526",
        "arxiv_id": "2512.11526",
        "authors": "Joel Ekstrand, Zahra Taghiyarrenani, Slawomir Nowaczyk",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.240350",
        "filter_reason": "这篇论文不符合我的研究范围，其核心贡献与LLM智能体的构建、改进或演化无关。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 论文标题和摘要明确指出，其核心是解决**时间序列预测**问题。它提出了一个名为Co-TSFA的**正则化框架**，用于在存在异常值的情况下提高预测的准确性。 - 这完全符合**排除标准中的“非演化型应用”**。该论文将一个机器学习模型（一个正则化框架）作为工具，应用于特定领域（时间序列分析）来解决该领域的问题（如何处理异常值）。它没有涉及构建、改进或演化任何形式的智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要和标题中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 缺乏这些正面指标，进一步确认了该论文与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不属于安全与对齐或多模态等排除类别，但这并不重要，因为它在第一步的核心判断中已经被明确排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划，也没有提出任何“自我演化”机制。因此，特殊情况的例外条款不适用。 **最终决策**：综合以上分析，这篇论文的核心贡献是提出了一种改进时间序列预测算法的方法，属于应用机器学习研究的范畴。它完全没有触及LLM智能体的构建、多智能体系统或自我演化机制。因此，它严格地超出了“LLM智能体及其演化”这一研究课题的范围，应予以排除。"
    },
    {
        "index": "#38",
        "title": "NeuralOGCM: Differentiable Ocean Modeling with Learnable Physics",
        "link": "/arxiv/2512.11525",
        "arxiv_id": "2512.11525",
        "authors": "Hao Wu, Yuan Gao, Fan Xu, Fan Zhang, Guangliang Liu, Yuxuan Liang, Xiaomeng Huang",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.240674",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 **NeuralOGCM** 的**可微分海洋建模框架**。其本质是**科学计算**领域的研究，旨在通过融合深度学习和物理知识来提升海洋模拟的效率和精度。它不属于构建、改进或演化LLM智能体的范畴。因此，根据第一步的排除标准，该论文应被归类为**“非演化型应用”**，即将深度学习技术作为工具应用于特定领域（海洋学）来解决该领域的模拟问题，而非研究智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中几乎不包含您关注的核心范式和能力。它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`。虽然提到了 `learnable physics`（可学习的物理），但这与您关注的 `Self-Evolving`（自我演化）机制有本质区别。前者是模型参数通过梯度下降进行优化，后者是指智能体在任务环境中通过经验、反思等方式进行行为策略的迭代。论文也完全没有涉及 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等智能体核心能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不属于安全对齐或多模态视觉的排除范畴，但其核心内容已经超出了您的研究焦点。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划。 - **自我演化的应用**: 这是唯一可能引起混淆的点。论文提出的“可学习的物理”允许模型“自主优化其物理核心”。然而，这**不符合您定义的“自我演化”例外情况**。这里的“优化”是模型在训练数据上通过端到端学习调整内部参数，是一种标准的模型训练范式，而不是智能体在执行任务过程中的自我完善和迭代。因此，不能将其视为提出了一种新的“自我演化”机制。它本质上仍然是一个应用型研究。 5.  **第五步：最终决策** 综合以上分析，这篇论文的核心是**科学计算中的物理建模**，而非**Agentic AI**。它研究的是如何构建更优的模拟器，而不是如何构建更智能的智能体。因此，它与您关于“LLM智能体及其演化”的研究课题完全不相关，应予以排除。"
    },
    {
        "index": "#47",
        "title": "MLLM Machine Unlearning via Visual Knowledge Distillation",
        "link": "/arxiv/2512.11325",
        "arxiv_id": "2512.11325",
        "authors": "Yuhang Wang, Zhenxing Niu, Haoxuan Ji, Guangyu He, Haichang Gao, Gang Hua",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.249010",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种“机器遗忘”方法，用于从多模态大语言模型（MLLM）中**选择性擦除视觉知识**。这本质上是一种模型编辑或安全技术，旨在移除模型已有的特定能力（识别敏感视觉信息），而不是构建、改进或演化一个具有自主能力的智能体。我的研究焦点是“构建、改进或演化LLM智能体”，而这篇论文是关于“修改和限制模型”，因此其本质与我的核心目标不符。 2.  **排除标准 (第三步):** 该论文明确命中了两条关键的排除标准： *   **安全与对齐:** 论文的核心主题是“机器遗忘”，其目的是“移除敏感信息”，这完全属于模型安全、隐私和对齐的研究范畴。根据筛选标准，只要主要贡献是关于`Safety`或`Security`，就应一律排除。 *   **多模态与视觉:** 论文的研究对象是“MLLM”（多模态大语言模型），其核心创新点在于处理“视觉知识”。这属于`Vision-Language`和`MLLMs`的范畴。根据标准，除非视觉是作为智能体感知环境的工具，否则应排除。在这篇论文中，视觉是研究的核心，而非工具。 3.  **正面指标缺失 (第二步):** 论文的摘要和标题中完全没有出现任何与我研究焦点相关的正面指标，如`Agentic AI`, `Planning`, `Tool Use`, `Self-Evolving`, `Multi-Agent`等。这进一步证实了它与我的研究课题无关。 综上所述，尽管该论文在AI安全领域可能是一项有价值的工作，但它的核心贡献是关于模型的安全编辑，而非智能体的构建、协作或演化。因此，它严格地落在了我的筛选范围之外。"
    },
    {
        "index": "#45",
        "title": "REMODEL-LLM: Transforming C code to Java using LLMs",
        "link": "/arxiv/2512.11402",
        "arxiv_id": "2512.11402",
        "authors": "Aryan Gupta, Y. Raghu Reddy",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.248064",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用研究，而非智能体构建。** 论文的核心贡献是提出并评估一个用于“将C代码翻译成Java代码”的混合流水线。这是一个非常具体的应用领域（软件工程/代码迁移）。论文的本质是利用LLM作为工具来解决一个特定领域的任务，并评估不同LLM在该任务上的表现。这完全符合第一步排除标准中的 **“非演化型应用”**：将LLM作为工具应用到特定领域去解决该领域的问题。论文没有提出任何关于如何构建、改进或演化LLM智能体的新方法论或框架。 2.  **第二步：正面指标——论文完全不包含核心关注点。** 通读摘要，论文没有提及任何一个您所关注的核心范式或能力。例如，`Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等关键词均未出现。论文的“hybrid pipeline”和“prompting strategy”是针对代码翻译这一特定任务的工程技巧，而非通用的智能体能力框架。 3.  **第四步：处理特殊和模糊情况——关于“推理”的辨析。** 摘要中提到了“reasoning capabilities”，但这属于排除的情况。论文是在**评估**LLM在代码翻译任务上表现出的基础推理能力（“revealing a hard ceiling for the reasoning capabilities”），而不是在**构建一个能够进行自主规划和多步推理的智能体框架**。这属于“关于提高LLM本身基础Token预测的数学或逻辑能力”的范畴，只不过这里的“逻辑”是代码逻辑。它没有涉及ReAct、ToT这类Agentic的推理框架。 **总结:** 该论文的研究焦点是**模型在特定任务（代码翻译）上的性能评估和应用方法优化**，属于软件工程和自然语言处理应用的交叉领域。它并未触及您研究课题的核心——即LLM智能体的构建、协作与演化机制。因此，这篇论文与您的研究目标不符，应予以排除。"
    },
    {
        "index": "#43",
        "title": "Flowception: Temporally Expansive Flow Matching for Video Generation",
        "link": "/arxiv/2512.11438",
        "arxiv_id": "2512.11438",
        "authors": "Tariq Berrada Ifriqi, John Nguyen, Karteek Alahari, Jakob Verbeek, Ricky T. Q. Chen",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.247412",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为Flowception的新型非自回归视频生成框架，旨在提高视频生成的效率和质量。这与您的研究目标“构建、改进或演化LLM智能体”存在根本性的偏离。 具体判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 该论文的本质是一种**生成模型**，具体应用于**视频生成**领域。它提出了一种新的概率路径学习方法来生成视频帧序列。这完全符合筛选标准中的“非演化型应用”排除项，即它将一种新的模型技术应用于特定领域（视频生成），而不是构建或研究LLM智能体本身。论文中没有涉及任何智能体框架、自主决策或与环境交互的概念。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您关注的核心范式或能力关键词。例如，它没有讨论`Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving`等。因此，它不具备任何正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，该论文明确属于“多模态与视觉”这一排除类别。其标题“Video Generation”和摘要中反复提及的“frames”（帧）、“image-to-video generation”（图像到视频生成）、“video interpolation”（视频插值）等，都清晰地表明其研究核心是计算机视觉和视频内容生成，而非Agentic AI。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与“推理/规划”或“自我演化”相关的特殊情况。它讨论的是模型生成过程的技术细节，而非智能体的认知或演化机制。 **最终决策**：综合以上分析，该论文的研究方向是计算机视觉和生成模型，与您聚焦的LLM智能体及其演化的研究课题完全无关。因此，应予以排除。"
    },
    {
        "index": "#42",
        "title": "Boosting Skeleton-based Zero-Shot Action Recognition with Training-Free Test-Time Adaptation",
        "link": "/arxiv/2512.11458",
        "arxiv_id": "2512.11458",
        "authors": "Jingmin Zhu, Anqi Zhu, Hossein Rahmani, Jun Liu, Mohammed Bennamoun, Qiuhong Ke",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.247102",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断依据如下： 1.  **核心判断（第一步）：论文本质是“非演化型应用”** 论文的核心贡献是提出一个名为 \"Skeleton-Cache\" 的框架，用于解决**骨架零样本动作识别**这一特定计算机视觉领域的问题。虽然它利用了LLM的语义推理能力，但LLM在这里是作为一个增强组件或工具，用于分配类别权重，而不是研究的主体。论文的核心是构建一个更好的动作识别系统，而不是构建、改进或演化一个具有自主性的LLM智能体。这完全符合“非演化型应用”的排除标准。 2.  **排除标准（第三步）：论文核心属于“多模态与视觉”** 论文的标题和摘要明确指出，其研究对象是“骨架”，这是一个典型的视觉/多模态领域。整个框架的设计、实验和评估都围绕着骨架数据展开。根据筛选标准，只要论文的核心是关于视觉或多模态的，就应该排除，除非它们被用作智能体感知环境的工具。在本论文中，视觉（骨架识别）是研究本身，而不是智能体框架的一个工具模块。 3.  **特殊和模糊情况（第四步）：“测试时自适应”不等于“自我演化”** 论文提出了“测试时自适应”机制，但这与我所关注的“自我演化”有本质区别。“自我演化”指的是智能体通过经验、反思或环境反馈进行**长期的、迭代的自我完善**，通常涉及学习新的策略或改进自身模型。而“测试时自适应”是一种**即时的、针对单个输入的动态调整**，它不涉及智能体模型本身的迭代更新或能力提升。因此，该论文不满足“自我演化”的核心要求。 综上所述，该论文虽然巧妙地结合了LLM，但其本质是一个针对特定视觉任务的算法改进，缺乏对LLM智能体核心能力（如自主规划、工具使用、记忆、自我反思）或演化机制的构建与研究。因此，它不符合我的研究目标。"
    },
    {
        "index": "#40",
        "title": "Towards Privacy-Preserving Code Generation: Differentially Private Code Language Models",
        "link": "/arxiv/2512.11482",
        "arxiv_id": "2512.11482",
        "authors": "Melih Catal, Pooja Rani, Harald C. Gall",
        "subjects": "Software Engineering, Artificial Intelligence, Cryptography and Security",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.241304",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是**将差分隐私技术应用于代码语言模型的训练过程**，以解决模型记忆训练数据所带来的隐私泄露风险。其本质是**模型安全与隐私保护**领域的研究，而非构建、改进或演化LLM智能体。它没有提出新的智能体框架、规划方法、工具使用机制或多智能体协作模式。因此，根据第一步的排除标准，这属于“非演化型应用”，即将一种技术（DP）应用于特定模型（CodeLLM）以解决特定领域问题（隐私），应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所列出的核心关注点。它不涉及 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等任何核心范式或能力。虽然论文提到了“memorization”（记忆），但这里指的是模型对训练数据的**数据记忆**，而不是智能体架构中的**情景记忆或程序性记忆**，后者是智能体实现连续任务和自我反思的关键能力。因此，该论文不满足任何正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，这篇论文完全符合排除标准。其核心贡献是关于 `Privacy`（隐私），这明确属于“安全与对齐”的范畴。根据您的筛选规则，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Alignment` ... 一律排除”。本文是隐私保护的典型研究，因此应被明确排除。 4.  **第四步：处理特殊和模糊情况** 本文不涉及推理/规划或自我演化的特殊情况，因此无需特殊处理。 **最终决策**： 综合以上分析，该论文的核心贡献在于提升CodeLLM的隐私安全性，而非研究LLM智能体的构建、协作或演化机制。它完全属于“安全与对齐”这一排除类别，与您关于“LLM智能体及其演化”的研究目标不符。因此，最终判断为 **False**。"
    },
    {
        "index": "#49",
        "title": "Few-Shot VLM-Based G-Code and HMI Verification in CNC Machining",
        "link": "/arxiv/2512.11296",
        "arxiv_id": "2512.11296",
        "authors": "Yasaman Hashem Pour, Nazanin Mahjourian, Vinh Nguyen",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.249929",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：该论文属于“非演化型应用”。** 论文的核心贡献是提出一个**用于CNC加工领域的G代码和HMI验证方法**。它使用视觉语言模型（VLM）作为工具，来解决一个特定工业领域（CNC机床操作）中的具体问题。论文的重点在于如何将VLM应用于这个特定任务，并验证其有效性，而不是在于构建、改进或演化一个通用的LLM智能体框架。这完全符合您筛选标准中“排除：非演化型应用”的描述。 2.  **缺乏核心关注点（第二步）：** 论文的研究内容与您关注的核心范式和能力无关。摘要中没有提及任何关于`Agentic AI`、`Planning`、`Tool Use`（在智能体自主使用工具的意义上）、`Self-Reflection`、`Multi-Agent`或`Self-Evolving`等概念。该VLM是一个被动的验证器，而不是一个主动规划、使用工具或自我演化的智能体。 3.  **符合排除标准（第三步）：** 论文的核心是`Vision-Language`（VLM）的应用。虽然您的筛选标准中提到“除非它们被用作智能体感知环境的工具”，但在这篇论文中，视觉能力本身就是研究的核心贡献，并且是服务于一个特定的应用场景（CNC验证），而不是作为一个通用智能体框架的感知模块。因此，它更偏向于一个多模态应用研究，而非Agentic AI研究。 **总结：** 该论文的本质是**应用研究**，它将一个先进的模型（VLM）应用到一个垂直领域（CNC加工）来解决一个具体问题（代码与界面验证）。它没有提出任何关于LLM智能体本身在规划、记忆、协作或自我演化方面的新方法论或框架。因此，它与您“构建、改进或演化LLM智能体”的核心目标不符。"
    },
    {
        "index": "#46",
        "title": "Surveillance Video-Based Traffic Accident Detection Using Transformer Architecture",
        "link": "/arxiv/2512.11350",
        "arxiv_id": "2512.11350",
        "authors": "Tanu Singh, Pranamesh Chakraborty, Long T. Truong",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.248503",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用研究，而非智能体构建。** 论文的核心贡献是两点：1) 创建了一个用于交通事故检测的新数据集；2) 提出了一个基于Transformer和光流的计算机视觉模型，用于在监控视频中检测交通事故。这完全符合**排除标准中的“非演化型应用”**。该论文将一个先进的模型架构应用到一个特定领域（交通监控）去解决该领域的问题，其研究焦点是提升该特定任务的检测准确率，而不是构建、改进或演化一个具有通用能力的LLM智能体。 2.  **第二步：正面指标——论文完全不包含我的核心关注点。** 通读摘要，论文的关键词集中在 `Transformer architecture`, `spatial-temporal dependencies`, `convolutional layers`, `motion cues`, `optical flow`, `vision language models` (作为对比基准)。这些都与计算机视觉和模型架构相关。摘要中完全没有出现任何与我的研究焦点相关的正面指标，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。 3.  **第三步：排除标准——论文属于多模态与视觉研究。** 论文的研究核心是视频理解，这直接命中了**排除标准中的“多模态与视觉”**。虽然论文提到了与GPT、Gemini等VLM进行比较，但这只是为了评估其提出的视觉模型的效果，VLM在这里是作为“陪跑”的基准模型，而不是研究的主体或智能体框架的一部分。论文的本质是视觉模型的研究，而非Agentic AI的研究。 4.  **第四步：特殊和模糊情况处理——不适用。** 该论文不涉及智能体的规划或推理，更没有提出任何自我演化机制。因此，关于推理/规划和自我演化应用的例外情况不适用。 **最终决策**：综合以上分析，这篇论文是一篇典型的计算机视觉应用研究。它的目标是解决特定领域的具体问题（交通事故检测），而不是探索LLM智能体的构建、协作或演化机制。因此，它与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#48",
        "title": "Condensation-Concatenation Framework for Dynamic Graph Continual Learning",
        "link": "/arxiv/2512.11317",
        "arxiv_id": "2512.11317",
        "authors": "Tingxu Yan, Ye Yuan",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.249455",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心贡献不匹配 (第一步核心判断)**: *   **论文核心**: 这篇论文的核心贡献是提出一个名为 \"Condensation-Concatenation-based Continual Learning (CCC)\" 的框架，用于解决**图神经网络 (GNN)** 在动态图上进行**持续学习** 时的灾难性遗忘问题。其研究对象是 GNN 模型，而非 LLM 智能体。 *   **研究目标**: 我的研究目标是 \"LLM智能体及其演化\"，核心关注点是构建、改进或演化**基于LLM的智能体**。这篇论文完全没有涉及 LLM，也没有涉及智能体的概念（如规划、工具使用、自我反思等）。 *   **结论**: 该论文属于典型的**非演化型应用**，它提出了一种机器学习方法（持续学习）并将其应用于特定领域（图数据），而不是构建或演化一个智能体框架。因此，根据第一步的核心判断标准，应予以排除。 2.  **缺乏正面指标 (第二步正面指标)**: *   论文的标题和摘要中完全没有出现任何与我研究焦点相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。这进一步确认了它与我的研究范围无关。 3.  **对“演化”概念的误读 (第四步特殊情况)**: *   虽然论文提到了 \"Continual Learning\"（持续学习），这与 \"Self-Evolving\"（自我演化）在字面上有相似之处，但其内涵完全不同。 *   论文中的“演化”指的是**模型如何适应不断变化的数据流（动态图）**，以防止遗忘旧知识。这是一个模型训练和适应的范式。 *   我所关注的“自我演化”是指**智能体作为自主实体，如何通过经验、反思或与环境交互来迭代和改进自身的决策逻辑、策略或能力**。这是一个关于智能体架构和行为的更高层次的概念。 *   因此，该论文的“持续学习”机制不属于我研究范围内的“自我演化”智能体机制。 综上所述，该论文的研究对象是 GNN 的持续学习方法，与 LLM 智能体的构建、协作或演化毫无关联。它属于一个不同的研究领域（图机器学习），因此不符合筛选要求。"
    },
    {
        "index": "#41",
        "title": "Exploring MLLM-Diffusion Information Transfer with MetaCanvas",
        "link": "/arxiv/2512.11464",
        "arxiv_id": "2512.11464",
        "authors": "Han Lin, Xichen Pan, Ziqi Huang, Ji Hou, Jialiang Wang, Weifeng Chen, Zecheng He, Felix Juefei-Xu, Junzhe Sun, Zhipeng Fan, Ali Thabet, Mohit Bansal, Chu Wang",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.241695",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 `MetaCanvas` 的**轻量级框架**，旨在解决多模态大语言模型（MLLMs）在视觉生成任务中能力未被充分利用的问题。其本质是**改进视觉生成技术**，让MLLMs能更好地作为扩散模型的“规划器”，在潜在空间中进行推理，以实现更精确的图像/视频生成。这属于典型的**非演化型应用**。论文将MLLM的推理能力作为一种工具，应用于视觉生成这一特定领域，其目标是提升生成效果，而非构建或演化一个具有通用能力的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中确实提到了 `reasoning and planning`，这是一个正面指标。然而，这里的“规划”是特指在“空间和时空潜在空间”中为扩散模型生成内容进行规划，其目的是服务于视觉生成任务，而不是一个智能体为了解决外部复杂问题而进行的自主规划和行动序列决策。因此，这个正面指标的权重较低，且其内涵与您关注的Agentic Planning有本质区别。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这是最关键的排除依据。该论文完全属于**多模态与视觉**的研究范畴。摘要中明确指出，其目标是“narrowing the gap between multimodal understanding and generation”（弥合多模态理解与生成之间的差距），并且核心组件是 `MLLMs` 和 `Diffusion Models`。根据您的筛选标准，只要论文的核心是关于 `MLLMs` 或 `Diffusion Models` 本身（而不是将它们作为智能体的工具），就应排除。这篇论文的研究核心正是如何让这两者更好地协同工作，属于多模态领域的前沿，而非Agentic AI。 4.  **第四步：处理特殊和模糊情况——推理/规划** 如前所述，虽然论文提到了“推理和规划”，但它不符合您对Agentic Reasoning/Plannning的定义。它不是关于一个智能体如何自主地、多步骤地与环境交互、使用工具来完成一个开放性任务（如ReAct框架）。相反，它是一种更高级的“条件生成”机制，MLLM的“规划”过程被内嵌在生成管道中，用于控制像素级的输出，而非驱动智能体的行为。 **最终决策**： 综合以上分析，这篇论文的核心贡献在于**多模态视觉生成方法的创新**，而非LLM智能体的构建、协作或演化。它虽然利用了LLM的推理能力，但目的是为了解决特定领域（视觉生成）的问题，完全符合“非演化型应用”和“多模态与视觉”这两项排除标准。因此，该论文与您关于“LLM智能体及其演化”的研究目标不符。"
    },
    {
        "index": "#50",
        "title": "AI Autonomy or Human Dependency? Defining the Boundary in Responsible AI with the $α$-Coefficient",
        "link": "/arxiv/2512.11295",
        "arxiv_id": "2512.11295",
        "authors": "Nattaya Mairittha, Gabriel Phorncharoenmusikul, Sorawit Worapradidth",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.250398",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于**构建、改进或演化LLM智能体**的论文，而这篇论文的核心贡献并非如此。 1.  **核心判断 (第一步):** 这篇论文的本质是关于**AI伦理、治理和系统评估**，而非智能体的构建。它提出了一个名为“AI Autonomy Coefficient (alpha)”的**度量指标**和一个“AI-First, Human-Empowered (AFHE)”的**部署范式**，旨在解决“Human-Instead-of-AI (HISOAI)”这一伦理和经济问题。论文的核心是**定义和衡量**AI系统的自主性，而不是**实现或增强**智能体的内部能力（如规划、记忆、工具使用等）。因此，它不属于“构建、改进或演化LLM智能体”的范畴。 2.  **排除标准 (第三步):** 该论文明确属于**安全与对齐**的研究领域。摘要中反复出现的关键词，如“Responsible AI”、“ethical failure”、“ethical oversight”、“transparency”和“verifiable autonomy”，都表明其主要贡献是关于AI系统的伦理、透明度和负责任部署。根据我的筛选标准，凡是主要贡献关于安全、对齐、可解释性的论文都应被排除。 3.  **正面指标缺失 (第二步):** 论文中没有提及任何我关注的核心技术点。它没有讨论智能体的`Planning`、`Tool Use`、`Memory`、`Self-Reflection`，也没有涉及`Multi-Agent`的`Collaboration`或`Communication`，更没有提出任何`Self-Evolving`或`Self-Improvement`的机制。 综上所述，尽管论文标题中包含“Autonomy”（自主性），但其研究焦点是**如何度量和规范自主性**，以确保AI系统的负责任部署，这是一个AI治理和伦理问题，与我所关注的**如何从技术上构建和演化具有自主能力的LLM智能体**的研究目标完全不同。因此，应予以排除。"
    },
    {
        "index": "#55",
        "title": "A Simple Generalisation of the Implicit Dynamics of In-Context Learning",
        "link": "/arxiv/2512.11255",
        "arxiv_id": "2512.11255",
        "authors": "Francesco Innocenti, El Mehdi Achour",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.258005",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是对“上下文学习”这一LLM基础能力的**理论解释和泛化**。它将Transformer块的内部机制抽象为一种“隐式的权重更新”，并从数学上推广了这一理论。这属于对LLM底层工作原理的理论研究，而不是关于如何构建、改进或演化一个LLM智能体。因此，根据第一步的排除标准，该论文属于“非Agentic的推理”，因为它关注的是模型本身的基础能力（ICL），而非一个具备自主规划、工具使用或反思能力的智能体框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的摘要和标题中完全没有出现您关注的核心范式或能力关键词，如 `Agentic AI`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步表明它与您的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不属于安全、对齐或多模态等明确的排除类别，但它在第一步的核心判断中已经被排除。 4.  **第四步：处理特殊和模糊情况** 这篇论文恰好触及了“推理/规划”这一模糊情况。根据规则，应排除“只是关于提高LLM本身基础Token预测的数学或逻辑能力”的研究。本文对ICL的理论分析，正是对LLM基础推理/学习能力的一种数学解释，它没有提出任何新的智能体规划或推理框架（如ReAct或ToT），因此应被排除。 **最终决策**: 综合以上分析，这篇论文的核心是**LLM基础理论**研究，旨在解释和泛化ICL的内在机制，而非**Agentic AI**研究。它没有提出任何关于构建智能体、多智能体系统或自我演化的方法论或框架。因此，它严格地落在了您研究范围之外。"
    },
    {
        "index": "#53",
        "title": "A Scalable Multi-GPU Framework for Encrypted Large-Model Inference",
        "link": "/arxiv/2512.11269",
        "arxiv_id": "2512.11269",
        "authors": "Siddharth Jayashankar, Joshua Kim, Michael B. Sullivan, Wenting Zheng, Dimitrios Skarlatos",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.251897",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为“Cerium”的**多GPU框架**，用于加速**大型模型的加密推理**。其研究重点在于**基础设施、部署优化和硬件加速**，通过优化编译器、运行时系统和并行化技术来解决全同态加密（FHE）在大型模型（如Llama3-8B）上的性能瓶颈。这完全符合第一步中的排除标准：“排除主要关注模型基础设施、部署优化、硬件加速的研究。” 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式或能力关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。它虽然提到了LLM，但只是将其作为验证其框架性能的**应用对象**，而不是研究的主体。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的研究焦点是AI系统的**隐私保护**和**性能优化**，这属于AI基础设施和系统安全的范畴，而非Agentic AI的构建与演化。虽然隐私与安全相关，但其主要贡献是工程实现和性能提升，而非安全与对齐理论本身，因此不直接触犯“安全与对齐”的排除红线，但其本质已被第一步的“基础设施”标准所排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何关于智能体推理/规划或自我演化的机制。它研究的是如何让一个已有的、静态的模型在特定硬件和加密环境下运行得更快，而不是如何让模型变得更智能、更自主或能够自我完善。 **最终决策**: 综合以上分析，这篇论文的本质是**AI系统工程**研究，专注于解决大型模型在特定隐私保护场景下的部署和性能问题。它没有提出任何关于LLM智能体的新架构、新能力或演化机制。因此，尽管它涉及LLM，但其研究焦点与我的“LLM智能体及其演化”课题完全不同，应予以排除。"
    },
    {
        "index": "#52",
        "title": "Words to Describe What I'm Feeling: Exploring the Potential of AI Agents for High Subjectivity Decisions in Advance Care Planning",
        "link": "/arxiv/2512.11276",
        "arxiv_id": "2512.11276",
        "authors": "Kellie Yu Hui Sim, Pin Sym Foong, Chenyu Zhao, Melanie Yi Ning Quek, Swarangi Subodh Mehta, Kenny Tsu Wei Choo",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.251394",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献**不是**构建、改进或演化LLM智能体的方法论或新框架。根据摘要，论文的本质是一项**人机交互（HCI）领域的应用探索研究**。作者构建了一个“体验原型”来探索AI智能体在“预先护理计划”这一高风险、高主观性决策领域的应用潜力。其研究方法是用户工作坊、分析用户的应对策略和功能请求，最终产出的是设计建议和对AI在该领域新角色的论证。这完全符合**排除标准1：非演化型应用**。论文将智能体作为工具或研究对象，应用于特定领域（医疗/社会关怀），以解决该领域的问题，而非贡献新的智能体技术本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 尽管论文标题和摘要中提到了 \"AI Agents\" 和 \"agent autonomy\"，但这些词汇是在应用和设计的语境下被讨论的。论文并未深入探讨智能体的核心技术能力，如`Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）或`Self-Improvement`（自我完善）的实现机制。因此，它缺乏您所关注的核心技术正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这篇论文的研究焦点是人机交互、用户体验和设计伦理，虽然与AI相关，但其核心贡献并非您所列出的排除项（如安全、对齐、多模态等），但其本质更偏向于应用层面的社会科学和设计学研究，而非您所聚焦的Agentic AI的技术内核。 4.  **第四步：处理特殊和模糊情况** 论文中提到参与者“train it to be their personal proxy”，这里的“训练”更接近于用户通过交互来配置或教化智能体自己的偏好，是一种用户驱动的个性化过程，而非智能体通过算法进行**自我演化**的技术机制。因此，这不属于“自我演化的应用”的例外情况。 **最终决策**: 综合以上分析，该论文是一篇典型的将AI智能体概念应用于特定社会问题（预先护理计划）的探索性研究。其核心贡献在于通过用户研究揭示了人机交互的挑战和设计启示，而非提出新的智能体架构、规划方法或演化算法。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标不符，因此应予以排除。"
    },
    {
        "index": "#60",
        "title": "Image Tiling for High-Resolution Reasoning: Balancing Local Detail with Global Context",
        "link": "/arxiv/2512.11167",
        "arxiv_id": "2512.11167",
        "authors": "Anatole Jacquin de Margerie, Alexis Roger, Irina Rish",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.260458",
        "filter_reason": "解析失败"
    },
    {
        "index": "#56",
        "title": "VFMF: World Modeling by Forecasting Vision Foundation Model Features",
        "link": "/arxiv/2512.11225",
        "arxiv_id": "2512.11225",
        "authors": "Gabrijel Boduljak, Yushi Lan, Christian Rupprecht, Andrea Vedaldi",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.258497",
        "filter_reason": "这篇论文的核心贡献是提出了一种新的世界建模方法VFMF，它通过在视觉基础模型（VFM）的特征空间中进行生成式预测，来预测未来的世界状态。我的研究目标是筛选关于“构建、改进或演化LLM智能体”的论文，关注点是智能体的规划、记忆、工具使用、多智能体协作和自我演化等Agentic能力。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断** 该论文的本质是构建一个**世界模型**，而不是一个**智能体**。它专注于如何更准确、更高效地预测视觉特征（如语义分割、深度等），这属于基础模型或环境感知组件的研究，而非智能体本身的设计或演化。论文没有提出任何关于智能体规划、记忆、工具使用或自我反思的框架。因此，根据第一步的核心判断标准，它应被排除，因为它不属于构建、改进或演化LLM智能体的范畴。 2.  **第二步：正面指标** 论文中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。同样，它也未涉及智能体能力（`Planning`, `Tool Use`, `Memory`）、多智能体（`Collaboration`）或演化机制（`Self-Improvement`）的讨论。因此，它不满足任何正面指标。 3.  **第三步：排除标准** 论文完全聚焦于视觉领域。其核心内容围绕“Vision Foundation Model Features”、“RGB”、“semantic segmentation”等视觉概念展开。根据第三步的排除标准，主要贡献属于“多模态与视觉”范畴的论文应被排除，除非视觉仅作为智能体的工具。在此论文中，视觉特征预测是研究的核心，而非工具，因此符合排除条件。 4.  **第四步：处理特殊和模糊情况** 虽然世界模型是高级智能体的重要组成部分，但这篇论文的贡献点在于模型本身（如何预测），而不是智能体如何利用这个模型进行规划、决策或自我演化。论文没有涉及任何智能体框架、多智能体交互或自我演化机制，因此不适用特殊情况中的保留规则。 **最终决策**：该论文的研究内容是关于视觉世界建模的预测技术，属于计算机视觉和基础模型的范畴，与“LLM智能体及其演化”的核心目标不符。它没有构建或演化智能体，而是构建了一个可能被智能体使用的环境模型组件。因此，应予以排除。"
    },
    {
        "index": "#58",
        "title": "amc: The Automated Mission Classifier for Telescope Bibliographies",
        "link": "/arxiv/2512.11202",
        "arxiv_id": "2512.11202",
        "authors": "John F. Wu, Joshua E. G. Peek, Sophie J. Miller, Jenny Novacescu, Achu J. Usha, Christopher A. Wilkinson",
        "subjects": "Instrumentation and Methods for Astrophysics, Artificial Intelligence, Digital Libraries, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.259516",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的核心贡献是提出了一个名为“amc”的**工具**，用于解决天文学文献分类的特定领域问题。它利用LLM作为文本处理引擎，来自动识别和归类与望远镜相关的论文。 - 这完全符合**排除标准1a：非演化型应用**。论文的重点是LLM在“图书馆科学”和“天文学”领域的应用，而不是构建、改进或演化LLM智能体的方法论本身。其核心是“应用”，而非“智能体架构”。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现您列出的任何核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。 - 该工具被描述为一个分类器，其工作模式是处理文本并输出标签，并未体现出智能体的自主规划、记忆、工具使用或自我反思等关键特征。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全、对齐或多模态等排除项，但第一步的排除已经足够有力。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的多步推理或任务规划，它是一个相对直接的分类任务。 - **自我演化的应用**: 论文虽然提到可以用来“发现潜在的标签错误”，但这指的是工具对**外部数据**的检查，而不是工具**自身**的演化或改进机制。因此，这不属于“自我演化”的例外情况。 **最终决策**: 该论文的本质是利用LLM解决特定领域（天文学文献管理）问题的应用型研究。它没有提出任何关于LLM智能体构建、多智能体协作或自我演化的新框架或方法论。因此，它不符合您“核心贡献在于构建、改进或演化LLM智能体”的研究目标，应予以排除。"
    },
    {
        "index": "#59",
        "title": "Fast EXP3 Algorithms",
        "link": "/arxiv/2512.11201",
        "arxiv_id": "2512.11201",
        "authors": "Ryoma Sato, Shinji Ito",
        "subjects": "Machine Learning, Artificial Intelligence, Data Structures and Algorithms",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.259997",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - 论文的核心贡献是针对 **EXP3算法** 提出了一种更快的实现方法，并分析了其时间复杂度和遗憾界限的权衡。 - EXP3是一种经典的**在线学习**或**多臂老虎机**算法，用于处理探索-利用权衡问题。 - 这篇论文的本质是**机器学习理论**研究，专注于优化一个特定算法的计算效率。它**没有**涉及构建、改进或演化任何形式的LLM智能体。因此，根据第一步的核心判断标准，这篇论文应被**排除**。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 也没有提及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 缺乏任何正面指标，进一步确认了其与研究范围的不相关性。 3.  **第三步：排除标准** - 虽然这篇论文不涉及安全与对齐或多模态等排除项，但它被排除的原因更为根本，即它不属于“LLM智能体及其演化”这一核心领域。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: EXP3算法可以被看作是一种非常底层的决策机制，但它与我所关注的“智能体在复杂任务中进行多步推理或规划”有本质区别。我的研究焦点是如ReAct、ToT这类将LLM作为推理核心，并结合工具、记忆等组件的**Agentic框架**。而该论文研究的是一个与LLM无关的、独立的数学算法，因此属于“非Agentic的推理”范畴，应被排除。 **最终决策**: 这篇论文的核心是关于一个经典的在线学习算法（EXP3）的计算优化，属于机器学习理论领域。它完全没有涉及LLM、智能体架构、多智能体交互或自我演化机制。因此，它与我“LLM智能体及其演化”的研究课题完全不相关，应予以排除。"
    },
    {
        "index": "#62",
        "title": "Autoencoder-based Semi-Supervised Dimensionality Reduction and Clustering for Scientific Ensembles",
        "link": "/arxiv/2512.11145",
        "arxiv_id": "2512.11145",
        "authors": "Lennard Manuel, Hamid Gadirov, Steffen Frey",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.261451",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了一种**增强的自编码器框架**，用于科学数据集的降维和聚类。其本质是一种**机器学习方法**，旨在解决特定领域（科学数据可视化）的数据分析问题。论文完全没有涉及构建、改进或演化任何形式的智能体。因此，它直接触发了**排除标准1：非演化型应用**。该论文是将一种算法（自编码器）作为工具应用到科学领域，而不是研究智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标。没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，也没有涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory` 或 `Self-Reflection`。这进一步确认了该论文与我的研究目标无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不属于“安全与对齐”或“多模态与视觉”的排除范畴，但它在第一步的核心判断中已经被明确排除。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及任何特殊或模糊情况。它不是关于智能体的推理/规划，也没有提出任何“自我演化”机制。 **最终决策**：综合以上分析，这篇论文的研究焦点是**数据降维与聚类算法**，属于传统的机器学习研究领域。它与我关于“LLM智能体及其演化”的研究课题（关注智能体的构建、协作与演化）在核心贡献和研究范式上完全不同。因此，最终判断为**排除**。"
    },
    {
        "index": "#61",
        "title": "MiniScope: A Least Privilege Framework for Authorizing Tool Calling Agents",
        "link": "/arxiv/2512.11147",
        "arxiv_id": "2512.11147",
        "authors": "Jinhao Zhu, Kevin Tseng, Gil Vernik, Xiao Huang, Shishir G. Patil, Vivian Fang, Raluca Ada Popa",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.260977",
        "filter_reason": "这篇论文不符合你的研究范围，应被排除。判断依据如下： 1.  **核心贡献分析 (第一步)**: 论文的核心贡献是提出了一个名为 MiniScope 的**安全框架**，其目的是为工具调用智能体实施“最小权限原则”，以限制不可靠的LLM可能造成的损害。论文的本质是**安全与授权**，而不是构建、改进或演化智能体本身的能力。它假设了工具调用智能体的存在，并为其提供一个安全外壳，而不是研究智能体如何更好地规划、记忆或演化。 2.  **触发排除标准 (第三步)**: 论文明确且主要地聚焦于 `Security` (安全)。摘要中反复出现的关键词，如 \"security risks\" (安全风险)、\"confining potential damage\" (限制潜在损害)、\"least privilege principles\" (最小权限原则)、\"balance security and ease of use\" (平衡安全与易用性) 以及 \"minimizing permissions\" (最小化权限)，都清晰地表明其主要贡献属于安全与对齐领域。根据你的筛选标准，只要论文的主要贡献是关于 `Security`，就应一律排除。 3.  **与研究焦点的偏差**: 你的研究焦点是提升智能体的内在能力（规划、记忆、工具使用、自我演化）或智能体间的交互模式（协作、通信）。而本文的研究焦点是**控制**和**限制**智能体的行为，以防止安全事件。它没有让智能体变得更“智能”或更“自主”，而是让它们在受控的环境中变得更“安全”。 综上所述，尽管论文涉及了“Tool Calling Agents”这一Agentic AI的概念，但其核心贡献完全落在“安全与对齐”这一明确的排除类别中，因此不符合你关于“构建、改进或演化LLM智能体”的核心研究目标。"
    },
    {
        "index": "#68",
        "title": "A probabilistic foundation model for crystal structure denoising, phase classification, and order parameters",
        "link": "/arxiv/2512.11077",
        "arxiv_id": "2512.11077",
        "authors": "Hyuna Kwon, Babak Sadigh, Sebastien Hamel, Vincenzo Lordi, John Klepeis, Fei Zhou",
        "subjects": "Materials Science, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.269526",
        "filter_reason": "这篇论文不符合研究范围。 我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** 论文的核心贡献是提出一个用于**晶体结构去噪、相分类和序参数提取的概率基础模型**。这完全属于“**非演化型应用**”的排除范畴。论文将一个深度学习模型（尽管被称为“基础模型”）作为工具，应用于**材料科学**这一特定领域，以解决该领域的数据分析问题。它没有构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我的研究焦点相关的正面指标。它不涉及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式，也没有讨论智能体的 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 或多智能体间的 `Collaboration` 等能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文的研究焦点是材料科学和计算物理，这与我的“LLM智能体及其演化”研究课题完全不同。虽然它不属于“安全与对齐”或“多模态与视觉”的排除类别，但它属于优先级更高的“非演化型应用”排除类别。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何智能体相关的推理/规划框架，更没有提出任何“自我演化”机制。它是一个静态的、用于特定科学任务的模型，因此不适用任何例外保留规则。 **最终决策**： 该论文的本质是应用一个深度学习模型解决材料科学领域的具体问题，其核心贡献在于模型本身的设计和在该领域的应用效果，而非构建或演化具有自主性的LLM智能体。因此，根据第一步的核心判断标准，该论文应被**排除**。"
    },
    {
        "index": "#67",
        "title": "Clip-and-Verify: Linear Constraint-Driven Domain Clipping for Accelerating Neural Network Verification",
        "link": "/arxiv/2512.11087",
        "arxiv_id": "2512.11087",
        "authors": "Duo Zhou, Jorge Chavez, Hesun Chen, Grani A. Hanasusanto, Huan Zhang",
        "subjects": "Machine Learning, Artificial Intelligence, Cryptography and Security, Optimization and Control",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.269022",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“Clip-and-Verify”的线性约束驱动裁剪框架，用于加速神经网络（NN）的形式化验证。根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** 这篇论文的本质是关于**神经网络的形式化验证**，而非构建或演化智能体。它提出了一种算法来加速验证器（如α,β-CROWN）在证明神经网络满足特定属性时的速度。这完全不符合“构建、改进或演化LLM智能体”的核心目标。它属于**基础设施**或更具体地说是**模型安全验证**的范畴，因此应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我的核心关注点相关的正面指标。它没有讨论`Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`或`Self-Evolving`。其核心能力是`Verification`（验证），而非`Planning`、`Tool Use`、`Memory`或`Self-Reflection`。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，这篇论文明确地属于“安全与对齐”这一排除标准。神经网络验证是确保模型安全性和鲁棒性的核心技术，其目标是证明模型在特定输入范围内不会产生错误行为。这直接对应了`Safety`和`Security`的研究范畴。根据筛选规则，只要论文的主要贡献是关于Safety，就应一律排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此特殊规则不适用。 **最终决策**： 综合以上分析，该论文的研究领域是神经网络的形式化验证，属于模型安全和基础设施的范畴。其核心贡献与“LLM智能体及其演化”的研究目标（单智能体、多智能体、自我演化）完全无关，并且直接触犯了“安全与对齐”的排除标准。因此，这篇论文不符合筛选要求。"
    },
    {
        "index": "#63",
        "title": "Fairness-Regularized Online Optimization with Switching Costs",
        "link": "/arxiv/2512.11131",
        "arxiv_id": "2512.11131",
        "authors": "Pengfei Li, Yuelin Han, Adam Wierman, Shaolei Ren",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.261914",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出一个名为 `FairOBD` 的**在线优化算法**，用于解决带有切换成本和公平性约束的在线凸优化问题。其理论贡献在于证明了该算法的渐近竞争比，并通过在“动态计算资源供给”这一具体场景下的实验来验证其有效性。 - **是否符合要求**: 不符合。这篇论文的本质是**运筹学/机器学习理论**研究，而非LLM智能体研究。它属于筛选标准中的“**非演化型应用**”排除项。论文将一个优化算法（FairOBD）作为工具，应用到“动态计算资源供给”这个特定领域去解决该领域的资源分配问题，其核心目标是优化成本和公平性，而不是构建或演化一个具有自主规划、工具使用或反思能力的智能体。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何与我核心关注点相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** - 虽然论文提到了“公平性”，但其主要贡献并非关于AI安全、对齐或可解释性。然而，这并不改变其作为“非演化型应用”的本质。它的核心是优化算法，而非智能体架构或演化机制。 4.  **第四步：处理特殊和模糊情况** - 论文不涉及“推理/规划”在智能体框架下的应用，也不涉及任何“自我演化”机制。它提出的 `FairOBD` 算法是一个固定的优化方法，不具备自我完善或迭代的能力。 **最终决策**: 综合以上分析，该论文是一篇关于在线优化算法的理论与应用研究，其核心贡献与“构建、改进或演化LLM智能体”这一目标完全无关。它属于典型的将算法应用于特定领域问题的论文，因此应被排除。"
    },
    {
        "index": "#69",
        "title": "Fast, accurate measurement of the worker populations of honey bee colonies using deep learning",
        "link": "/arxiv/2512.11075",
        "arxiv_id": "2512.11075",
        "authors": "Junmin Zhong, Jon F. Harrison, Jennie Si, Jun Chen",
        "subjects": "Quantitative Methods, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.270007",
        "filter_reason": "根据您提供的筛选标准，我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献分析**: 这篇论文的核心贡献是提出了一种基于深度学习（具体是CSRNet模型）的方法来自动化蜜蜂种群计数，并为此任务创建了一个新的数据集（ASUBEE）。其本质是将一个已有的计算机视觉模型（CSRNet）应用到一个特定的生态学领域（蜜蜂种群监测）。 - **判断**: 这完全符合 **排除标准 1: 非演化型应用**。论文的重点是解决特定领域（生态学、农业）的问题，而不是构建、改进或演化LLM智能体本身。它没有提出任何新的智能体框架、多智能体协作机制或自我演化方法。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何与您研究焦点相关的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准** - 该论文的研究内容属于 **多模态与视觉** 范畴。它的核心是处理图像（hive monitoring, per image），通过密度图估计来解决视觉任务（计数蜜蜂）。虽然视觉可以作为智能体的感知工具，但在这篇论文中，视觉模型本身就是研究的核心，而不是服务于一个更高层次的智能体框架。因此，它符合排除标准。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及智能体的推理/规划，也没有提出任何自我演化机制，因此特殊情况的例外条款不适用。 **最终决策**: 这篇论文的核心是应用深度学习技术解决一个具体的视觉计数问题，属于典型的AI for Science应用研究。它没有涉及LLM智能体的构建、多智能体交互或自我演化机制。因此，它完全不符合您关于 \"LLM智能体及其演化\" 的研究范围。"
    },
    {
        "index": "#73",
        "title": "SoccerMaster: A Vision Foundation Model for Soccer Understanding",
        "link": "/arxiv/2512.11016",
        "arxiv_id": "2512.11016",
        "authors": "Haolin Yang, Jiayuan Rao, Haoning Wu, Weidi Xie",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.272127",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是构建了一个名为 \"SoccerMaster\" 的**视觉基础模型**，用于处理足球视频理解任务（如运动员检测、事件分类）。这完全符合筛选标准中的**排除项 1：非演化型应用**。该论文将一个基础模型范式应用到了“足球”这个特定领域，旨在解决该领域的视觉感知问题，而不是构建、改进或演化一个具有自主规划、工具使用或反思能力的LLM智能体。论文的本质是计算机视觉研究，而非Agentic AI研究。 2.  **第二步：正面指标** 论文摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** 论文明确属于**排除项：多模态与视觉**。标题中的 \"Vision Foundation Model\" 和摘要中的 \"soccer visual understanding tasks\" 都清晰地表明，这篇论文的核心是视觉模型。根据规则，除非视觉模型被用作智能体感知环境的工具（而非研究核心），否则应排除。在此论文中，视觉模型本身就是研究的核心，因此必须排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理、规划或自我演化机制，因此特殊规则不适用。 **最终决策**：综合以上分析，该论文是一篇典型的领域应用型计算机视觉论文，其核心贡献在于构建一个视觉模型，而非LLM智能体。它与我的研究课题“LLM智能体及其演化”在核心目标和研究范式上完全不同，因此应被排除。"
    },
    {
        "index": "#64",
        "title": "In-Context Multi-Objective Optimization",
        "link": "/arxiv/2512.11114",
        "arxiv_id": "2512.11114",
        "authors": "Xinyu Zhang, Conor Hassan, Julien Martinelli, Daolang Huang, Samuel Kaski",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.267538",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为TAMO的、基于Transformer的通用优化策略，用于解决多目标黑盒优化问题。尽管它使用了Transformer架构和强化学习训练，这些技术与智能体研究相关，但其本质和研究焦点与我的研究目标不符。 具体判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 论文的核心是构建一个**优化器**，而不是一个**智能体**。TAMO被明确定义为一个“通用策略”和“即插即用优化器”，其目标是高效地提出下一个设计点以优化帕累托前沿。 - 这符合**排除标准中的“非演化型应用”**。虽然它没有使用一个已有的智能体框架，但它构建了一个**工具**来解决特定领域的问题（多目标优化，应用于药物设计、自主系统等）。研究的焦点是优化算法的效率和效果（减少提案时间、提升帕累托质量），而不是智能体的内在能力（如规划、反思、工具使用）。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文几乎不包含我关注的核心指标。 - 它没有涉及 `Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving` 的核心范式。 - 它没有讨论智能体的 `Planning`、`Tool Use`、`Self-Correction` 等能力。虽然它以“整个查询历史”为条件，这可以看作一种简单的记忆形式，但它是在优化算法的上下文中使用，而非智能体的自主记忆机制。 - 强化学习训练是为了优化一个特定的数学指标（累积超体积改进），而不是为了让智能体学会如何更好地行动或演化。 3.  **第四步：处理特殊和模糊情况** - **推理/规划**: TAMO在推理时只是一个单步的“前向传播”来提出下一个设计。它不涉及智能体在复杂任务中进行多步**规划**的过程。它的训练目标（累积奖励）虽然具有长期性，但这是一种算法设计，而非智能体在运行时展现的规划能力。因此，它更接近于“提高LLM本身基础Token预测的数学或逻辑能力”的范畴，只不过应用场景是优化问题，而非自然语言。根据此规则，应**排除**。 - **自我演化的应用**: 论文的核心贡献不是一种新的“自我演化”机制。TAMO是预训练好的，在测试时不会进行自我完善或迭代。因此，此规则不适用。 **结论**: 该论文是一项杰出的优化算法研究，它巧妙地利用了Transformer的上下文学习能力来替代传统贝叶斯优化中的代理模型和获取函数。然而，它的本质是构建一个更高效的**优化工具**，而不是研究或构建具有自主性、规划能力或演化能力的**LLM智能体**。因此，它不符合我关于“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#71",
        "title": "KathDB: Explainable Multimodal Database Management System with Human-AI Collaboration",
        "link": "/arxiv/2512.11067",
        "arxiv_id": "2512.11067",
        "authors": "Guorui Xiao, Enhao Zhang, Nicole Sullivan, Will Hansen, Magdalena Balazinska",
        "subjects": "Databases, Artificial Intelligence",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.271047",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是构建一个名为 **KathDB 的数据库管理系统（DBMS）**。它旨在解决传统数据库在处理多模态数据（文本、图像等）时的局限性，通过结合基础模型（如LLM）的推理能力来增强数据库的功能。这完全符合第一步排除标准中的 **“非演化型应用”**。论文的本质是将LLM作为一个强大的“黑箱”或组件，集成到一个特定的应用系统（数据库）中，以解决该领域（数据库管理）的问题，而不是研究LLM智能体本身的构建、改进或演化。 2.  **第二步：正面指标** 论文中几乎没有出现您关注的核心正面指标。虽然提到了“reasoning power”，但这指的是LLM在数据库查询解析和执行中的推理作用，而非智能体自主的规划或行动。它没有涉及 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等任何智能体核心能力。 3.  **第三步：排除标准** 这篇论文明确命中了两个关键的排除标准： *   **安全与对齐**: 论文标题和摘要都强调了 **“Explainable”**（可解释性）。其核心目标之一就是提供“explainable answers”，这属于 `Interpretability` (可解释性) 的研究范畴，是您明确要求排除的。 *   **多模态与视觉**: 论文标题和摘要明确指出这是一个 **“Multimodal Database Management System”**，处理的是多模态数据。这直接命中了排除标准。虽然LLM被用作处理多模态数据的工具，但多模态处理本身是该系统的核心功能，而不是一个智能体感知环境的工具。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文中的“reasoning”是数据库系统层面的，用于理解和执行用户查询，不属于智能体在复杂任务中进行多步自主规划的范畴。因此，应被排除。 *   **自我演化的应用**: 论文不涉及任何自我演化机制。用户与系统的“iteratively”（迭代）交互是指用户可以反复调整查询，而不是系统本身在进行自我完善和迭代。 **最终决策**: 综合以上分析，该论文的核心贡献是一个**数据库系统**，其研究焦点是**可解释性**和**多模态数据处理**。它将LLM作为增强系统功能的工具，而非研究对象。这与您“构建、改进或演化LLM智能体”的核心目标完全不符，因此应果断排除。"
    },
    {
        "index": "#75",
        "title": "Beyond Memristor: Neuromorphic Computing Using Meminductor",
        "link": "/arxiv/2512.11002",
        "arxiv_id": "2512.11002",
        "authors": "Frank Zhigang Wang",
        "subjects": "Emerging Technologies, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.278107",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** 论文的核心贡献是提出了一种名为“meminductor”（记忆电感器）的新型物理硬件元件，并探讨了它在神经形态计算中的应用。论文的本质是**硬件基础设施**和**新型计算范式**的研究，而非关于LLM智能体的构建、改进或演化。根据筛选标准，主要关注模型基础设施、硬件加速的研究应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式或能力。虽然提到了“memory”，但这指的是磁性核心对电流历史的物理记忆，是一种硬件层面的特性，与LLM智能体的结构化记忆、经验回放等软件层面的机制完全不同。论文也未涉及`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving`等任何核心关注点。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文的研究焦点是**硬件基础设施**，这直接命中了第一步中的排除标准。它不属于安全与对齐或多模态等排除类别，但其核心内容已经超出了“LLM智能体及其演化”的软件和算法层面。 4.  **第四步：处理特殊和模糊情况** 本论文情况清晰，不涉及推理/规划或自我演化的应用等模糊地带。它明确是一篇硬件领域的论文。 5.  **第五步：最终决策** 综合以上分析，这篇论文的核心是关于一种新型硬件元件及其在神经形态计算中的应用，属于硬件基础设施研究。我的研究目标是“LLM智能体及其演化”，聚焦于智能体的算法、框架和演化机制。两者在研究层面（硬件 vs. 软件/算法）和核心贡献上存在根本性差异。因此，该论文与我的研究课题无关，应被排除。"
    },
    {
        "index": "#72",
        "title": "WholeBodyVLA: Towards Unified Latent VLA for Whole-Body Loco-Manipulation Control",
        "link": "/arxiv/2512.11047",
        "arxiv_id": "2512.11047",
        "authors": "Haoran Jiang, Jin Chen, Qingwen Bu, Li Chen, Modi Shi, Yanjie Zhang, Delong Li, Chuanzhe Suo, Chuang Wang, Zhihui Peng, Hongyang Li",
        "subjects": "Robotics, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.271645",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文本质是“非演化型应用”** 论文的核心贡献是提出了一个名为 \"WholeBodyVLA\" 的框架，用于解决人形机器人的“全身移动操作”这一特定领域的控制问题。它构建了一个视觉-语言-动作（VLA）模型，并将其应用于机器人控制。这完全符合筛选标准中的“非演化型应用”排除项：**将一个已有的模型范式（VLA）应用到特定领域（机器人控制）去解决该领域的问题**。论文的目标是提升机器人的物理操作能力，而不是构建或演化一个具有通用智能的LLM智能体。 2.  **第三步：排除标准——论文核心属于“多模态与视觉”** 论文的标题和摘要都明确指出其核心是 \"VLA\" (Vision-Language-Action) 模型，并且从 \"egocentric videos\"（自身视角视频）中学习。这表明该论文的研究根基是多模态学习，特别是视觉-语言-动作的联合建模。根据筛选标准，**主要关注 `Vision-Language`、`MLLMs` 的研究应被排除**，除非视觉仅被用作智能体感知环境的工具。在本论文中，视觉-语言-动作的联合建模是核心贡献本身，而非一个外围工具，因此应被排除。 3.  **第二步：正面指标——缺乏核心关注点** 论文摘要中完全没有提及我的核心关注点。它没有讨论智能体的 `Planning`（规划）、`Memory`（记忆）、`Self-Reflection`（自我反思）等高级认知能力。它也不是关于 `Multi-Agent`（多智能体）协作或 `Self-Evolving`（自我演化）机制的。其重点在于通过模仿学习和强化学习来优化机器人的底层运动控制策略，这与我的研究焦点——Agentic AI的认知架构和演化机制——相去甚远。 **总结**: 尽管 \"WholeBodyVLA\" 是一个在机器人控制领域可能非常有价值的工作，但它的本质是**一个应用于特定领域的多模态控制模型**，而不是一个关于LLM智能体构建、协作或演化的研究。它被排除的主要原因是：1）它是一个非演化型的领域应用；2）其核心技术属于多模态与视觉范畴，而非Agentic AI的核心方法论。因此，它不符合我的研究目标。"
    },
    {
        "index": "#74",
        "title": "Leveraging Text Guidance for Enhancing Demographic Fairness in Gender Classification",
        "link": "/arxiv/2512.11015",
        "arxiv_id": "2512.11015",
        "authors": "Anoop Krishnan",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.277674",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种利用文本引导来提升**人脸图像性别分类**任务中**人口统计公平性**的方法。这本质上是一种针对特定计算机视觉任务的模型训练优化技术，而非构建、改进或演化LLM智能体的方法论。因此，它完全符合第一步排除标准中的“**非演化型应用**”——将一种多模态技术（文本+图像）应用于特定领域（计算机视觉、AI公平性）来解决该领域的问题。 2.  **排除标准 (第三步):** 论文的研究焦点明确落在我的排除范围内。 *   **多模态与视觉:** 论文的核心是“facial image based gender classification”和“computer vision systems”，属于典型的`Vision`研究。虽然它使用了文本，但文本是作为训练视觉模型的“引导”信号，研究的主体是视觉模型本身，而不是一个使用视觉作为感知工具的智能体。 *   **安全与对齐:** 论文的核心目标是“demographic fairness”（人口统计公平性），这与`Safety`和`Alignment`（对齐）领域高度相关。摘要中明确提到其贡献是“an interpretable and intuitive training paradigm”，也触及了`Interpretability`（可解释性）。根据筛选标准，只要主要贡献是关于这些方面的，就应排除。 3.  **正面指标 (第二步):** 论文中完全没有出现任何与我研究焦点相关的正面指标关键词。它没有讨论`Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`，也没有涉及智能体的核心能力如`Planning`、`Tool Use`、`Memory`或`Self-Reflection`。 **总结:** 该论文的研究领域是计算机视觉和AI公平性，其核心贡献是一种提升视觉模型公平性的训练范式。这与我关于“LLM智能体及其演化”的研究课题（聚焦于智能体的构建、协作与自我演化机制）完全无关。因此，根据筛选标准，这篇论文应被明确排除。"
    },
    {
        "index": "#80",
        "title": "Mathematics of natural intelligence",
        "link": "/arxiv/2512.10988",
        "arxiv_id": "2512.10988",
        "authors": "Evgenii Vityaev",
        "subjects": "Neurons and Cognition, Artificial Intelligence",
        "date": "2025-12-07",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.280553",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——排除** 论文的核心贡献是提出一套用于描述“自然智能”和大脑认知结构（如“cognitome”、“神经超网络”）的数学模型。它探讨的是生物大脑在演化过程中形成的认知机制和意识理论，属于神经科学和认知理论的范畴。这与您的研究目标——**构建、改进或演化基于LLM的人工智能体**——在本质上完全不同。论文没有涉及任何关于LLM、智能体架构或其演化的内容。 2.  **第二步：正面指标——完全不匹配** 论文摘要中完全没有出现您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准——不适用但方向不符** 虽然论文不涉及安全、对齐或多模态等具体的排除项，但其研究方向（生物智能的数学建模）本身就在您的研究焦点之外。 4.  **第四步：处理特殊和模糊情况——不适用** 论文中的“evolution”（演化）指的是生物学的演化，而非智能体通过经验或反馈进行的“自我演化”。因此，这不属于例外情况。 **最终决策**：该论文是一篇关于自然智能和大脑数学建模的理论研究，而非关于LLM智能体的工程或算法研究。其核心贡献与您“LLM智能体及其演化”的课题完全不相关，因此应被排除。"
    },
    {
        "index": "#79",
        "title": "Dora: QoE-Aware Hybrid Parallelism for Distributed Edge AI",
        "link": "/arxiv/2512.10990",
        "arxiv_id": "2512.10990",
        "authors": "Jianli Jin, Ziyang Lin, Qianli Dong, Yi Chen, Jayanth Srinivasa, Myungjin Lee, Zhaowei Tan, Fan Lai",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.280123",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出了一个名为 \"Dora\" 的框架，用于在分布式边缘AI环境中实现“QoE感知的混合并行”。其关键机制包括模型分区器、网络调度器和运行时适配器，所有这些都旨在优化计算资源、网络通信和能耗，以满足服务质量要求。这完全属于**基础设施** 的研究范畴，关注的是模型部署和执行效率，而不是智能体本身的架构、能力或演化机制。根据筛选标准，应予以排除。 2.  **第二步：正面指标——论文完全不包含核心关注点。** 通读摘要，论文没有提及任何与您研究焦点相关的关键词或概念。例如，它没有讨论 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。它也没有涉及智能体的核心能力，如 `Planning`（任务规划）、`Tool Use`、`Memory` 或 `Self-Reflection`。论文中提到的 \"planners\" 是指用于混合并行计算的规划器，而非智能体的任务规划器。 3.  **第四步：处理特殊和模糊情况——规划问题属于系统层面。** 论文虽然提到了 \"planners\"，但这属于系统层面的计算图规划和资源调度，目的是优化模型在多个设备上的执行效率。这与您关注的智能体层面的“规划”有本质区别。您关注的是智能体如何自主地规划一系列动作以完成复杂任务（如 ReAct, ToT），而这篇论文关注的是如何将一个AI模型（可能是任何模型，不一定是LLM或智能体）高效地拆分并运行在分布式硬件上。 **总结：** 该论文是一篇典型的系统/网络领域的论文，其研究目标是优化分布式AI的运行效率和能耗。它并未涉及LLM智能体的构建、多智能体交互或自我演化机制。因此，它完全偏离了您关于 \"LLM智能体及其演化\" 的研究课题，应被排除。"
    },
    {
        "index": "#78",
        "title": "MolSculpt: Sculpting 3D Molecular Geometries from Chemical Syntax",
        "link": "/arxiv/2512.10991",
        "arxiv_id": "2512.10991",
        "authors": "Zhanpeng Chen, Weihao Gao, Shunyu Wang, Yanan Zhu, Hong Meng, Yuexian Zou",
        "subjects": "Machine Learning, Artificial Intelligence, Chemical Physics, Quantitative Methods",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.279554",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献**: 论文的核心贡献是提出了一个名为 `MolSculpt` 的新框架，用于从1D化学语法生成3D分子几何结构。这是一个**跨模态生成模型**，其本质是解决药物发现和材料科学领域的一个特定问题。 - **是否为智能体**: 该框架不具备任何智能体的核心特征。它没有提及**规划**、**工具使用**、**记忆**、**自我反思**或与环境的交互。它是一个端到端的生成模型，接收输入并产生输出，缺乏自主性和决策能力。 - **结论**: 该论文属于**“非演化型应用”**。它将一个“冻结的1D分子基础模型”（可以视为一个LLM）作为静态的知识提取器，与一个3D扩散模型结合，共同解决一个特定领域的生成任务。其核心是模型架构的创新，而非智能体的构建、改进或演化。因此，在第一步就应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文的核心技术之一是“3D分子扩散模型”。这明确属于**“多模态与视觉”**的排除范畴。虽然3D几何结构可以被视为一种环境感知，但在这里，它是研究的**核心产出**，而不是智能体用于行动的工具。论文的重点是生成这种视觉/几何表示，而非智能体如何利用它。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的多步推理或规划框架。 - **自我演化的应用**: 论文没有提出任何自我演化或自我改进的机制。它是一个训练后固定的模型。 **最终决策**: 综合以上分析，这篇论文虽然使用了类似LLM的基础模型，但其研究目标是解决特定领域的3D分子生成问题，而非构建或研究LLM智能体本身。它缺乏智能体的自主性、规划、工具使用和演化等关键属性，属于典型的应用型研究，而非Agentic AI的基础研究。因此，它不符合您的筛选要求。"
    },
    {
        "index": "#81",
        "title": "Marti-5: A Mathematical Model of \"Self in the World\" as a First Step Toward Self-Awareness",
        "link": "/arxiv/2512.10985",
        "arxiv_id": "2512.10985",
        "authors": "Igor Pivovarov, Sergey Shumsky",
        "subjects": "Neurons and Cognition, Artificial Intelligence, Machine Learning",
        "date": "2025-12-05",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.281022",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质不是LLM智能体。** 论文的核心贡献是提出一个**受生物学启发的强化学习数学模型**，用于在虚拟环境中（如雅达利游戏）实现自我与环境的分离。摘要中明确指出这是一个“reinforcement learning agent”，其模型基于“neocortical columns”和“basal ganglia”。通篇摘要没有提及任何与大型语言模型（LLM）、Transformer或自然语言生成相关的内容。我的研究核心是“**LLM**智能体及其演化”，而该论文的研究范式是经典的强化学习，与LLM无关。因此，它在最根本的层面上就不符合要求。 2.  **正面指标（第二步）：缺乏关键范式。** 尽管论文涉及了“Agent”和“Self-Model”（可视为一种记忆或自我认知的雏形），但它完全缺失了我关注的核心范式，如 `LLM-based Agents`, `Tool Use`, `Self-Reflection`（在LLM框架下）等。论文中的“选择下一个动作”是强化学习的基础循环，而非LLM智能体中复杂的、基于语言和工具的规划与决策过程。 3.  **排除标准（第三步）与特殊情况（第四步）：** - 该论文不属于安全、对齐或多模态等排除类别。 - 在处理“推理/规划”的特殊情况时，该论文的规划是RL智能体的策略学习，而非LLM智能体的多步推理框架（如ReAct, ToT）。 - 在处理“自我演化”的特殊情况时，该论文描述的是一个智能体通过强化学习**学习**行为策略，而不是一个智能体**自我演化**其核心架构、学习算法或能力。它没有提出一种新的“自我演化”机制。 **最终决策（第五步）：** 综合以上分析，这篇论文的研究对象是**强化学习智能体**，而非**LLM智能体**。虽然其探讨的“自我模型”和“自我意识”主题在哲学和认知科学上与Agentic AI有遥远的关联，但其技术实现和研究范式与我的核心目标——“构建、改进或演化**LLM**智能体”——完全脱节。因此，这篇论文被排除。"
    },
    {
        "index": "#76",
        "title": "Unambiguous Representations in Neural Networks: An Information-Theoretic Approach to Intentionality",
        "link": "/arxiv/2512.11000",
        "arxiv_id": "2512.11000",
        "authors": "Francesco Lässig",
        "subjects": "Neurons and Cognition, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.278558",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种**信息论方法来量化神经网络内部表征的“歧义性”**，并将其与意识理论（意向性）联系起来。这是一项关于**神经网络可解释性**和**理论认知科学**的研究，而非关于构建、改进或演化LLM智能体。论文中使用的模型是在MNIST数据集上训练的普通神经网络，完全没有涉及智能体的规划、工具使用、记忆或自我演化等核心Agentic能力。因此，它不符合“保留”标准，而更偏向于对模型内部状态的理论分析。 2.  **正面指标缺失 (第二步):** 论文的标题和摘要中完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。这表明其研究焦点与您的目标相去甚远。 3.  **触及明确的排除标准 (第三步):** 这是最关键的排除依据。该论文的主要贡献在于提出一种“量化神经网络系统表征歧义的方法”，这完全属于**`Interpretability` (可解释性)** 的研究范畴。根据您的筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` (可解释性)...一律排除”。因此，即使该研究很有深度，也明确超出了您设定的研究范围。 4.  **不属于特殊情况 (第四步):** 该论文不涉及智能体的推理或规划框架，也未提出任何自我演化机制，因此不适用任何例外保留规则。 **总结:** 该论文是一项关于神经网络表征和可解释性的高质量理论研究，但其本质是分析“模型是什么”，而不是构建“模型做什么”的智能体。它与您“LLM智能体及其演化”的核心目标——即构建、改进和演化具有自主能力的智能体——完全不相关。因此，最终决策为排除。"
    },
    {
        "index": "#84",
        "title": "Cognitive Mirrors: Exploring the Diverse Functional Roles of Attention Heads in LLM Reasoning",
        "link": "/arxiv/2512.10978",
        "arxiv_id": "2512.10978",
        "authors": "Xueqi Ma, Jun Wang, Yanbei Jiang, Sarah Monazam Erfani, Tongliang Liu, James Bailey",
        "subjects": "Neurons and Cognition, Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.287655",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个**可解释性框架**，用于分析和理解LLM内部组件（注意力头）在推理任务中的功能角色。它没有构建、改进或演化任何形式的LLM智能体。其研究对象是LLM的内部机制，而非智能体的行为框架或演化路径。因此，根据第一步的排除标准，这篇论文的本质是模型分析，而非智能体构建，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您列出的核心范式或能力关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。虽然提到了 \"reasoning\"，但这是在分析模型内部组件功能的语境下，而非智能体自主行动的语境。 3.  **第三步：排除标准——是否为我的研究焦点之外？** **这是最关键的排除依据。** 论文的摘要明确指出其核心贡献是 \"a novel interpretability framework\"（一个新颖的可解释性框架），其目标是 \"understanding these mechanisms\"（理解这些机制）和 \"offer a deeper understanding of LLM reasoning\"（为LLM推理提供更深入的理解）。这完全符合您在第三步中设定的排除标准：**只要论文的主要贡献是关于 `Interpretability` (可解释性) 或 `Explainability (XAI)`，一律排除。** 4.  **第四步：处理特殊和模糊情况** - **推理/规划:** 论文虽然研究 \"reasoning\"，但它属于“非Agentic的推理”。它关注的是通过分析注意力头来提升LLM本身的基础推理能力，而不是构建一个能够自主规划和执行任务的智能体框架（如ReAct或ToT）。因此，它符合排除条件。 - **自我演化的应用:** 此处不适用。 **最终决策:** 综合以上分析，该论文的核心贡献是LLM的可解释性研究，旨在揭示模型内部的“认知头”如何工作。尽管这项研究对于理解LLM的推理能力有重要意义，但它并不涉及构建、改进或演化LLM智能体本身。它属于模型分析领域，而非您所聚焦的Agentic AI领域。因此，这篇论文不符合您的研究目标。"
    },
    {
        "index": "#83",
        "title": "Reducing Fragmentation and Starvation in GPU Clusters through Dynamic Multi-Objective Scheduling",
        "link": "/arxiv/2512.10980",
        "arxiv_id": "2512.10980",
        "authors": "Akhmadillo Mamirov",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence",
        "date": "2025-12-04",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.281935",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出了三种用于GPU集群的**动态调度器**（HPS, PBS, SBS），其目标是解决GPU集群中的资源碎片化、饥饿问题和低利用率问题。这完全属于您筛选标准中明确排除的**“基础设施”**类别，即“主要关注模型基础设施、部署优化、硬件加速的研究”。论文的研究对象是计算资源的管理和调度，而不是智能体本身的架构、能力或演化机制。 2.  **第二步：正面指标——论文完全不包含核心关注点。** 通读摘要，论文没有提及任何与您研究焦点相关的核心范式或能力。例如，`Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等关键词均未出现。论文中的“multi-tenant”指的是多租户共享集群资源，与“Multi-Agent Systems”（智能体间的协作与通信）是完全不同的概念。 3.  **第三步：排除标准——虽然不直接触发，但进一步确认了其领域偏离。** 论文不涉及安全、对齐或多模态等排除项，但这并不改变其本质。它的核心是系统层面的性能优化，与AI智能体的研究相去甚远。 4.  **第四步：处理特殊和模糊情况——不适用。** 论文中的“调度”是操作系统或云计算领域的概念，指为计算任务分配资源，这与智能体为完成目标而进行的“规划”有本质区别。论文也未提出任何“自我演化”机制。 **最终决策**：该论文是一篇典型的计算机系统/高性能计算领域的研究，其核心贡献在于优化GPU集群的资源调度效率。它并未构建、改进或演化任何形式的LLM智能体，因此与您关于“LLM智能体及其演化”的研究课题完全无关，应予以排除。"
    },
    {
        "index": "#86",
        "title": "Multimodal Fusion of Regional Brain Experts for Interpretable Alzheimer's Disease Diagnosis",
        "link": "/arxiv/2512.10966",
        "arxiv_id": "2512.10966",
        "authors": "Farica Zhuang, Dinara Aliyeva, Shu Yang, Zixuan Wen, Duy Duong-Tran, Christos Davatzikos, Tianlong Chen, Song Wang, Li Shen",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2025-11-30",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.288835",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个名为 MREF-AD 的模型，用于阿尔茨海默病的诊断。这是一个典型的**非演化型应用**。它将一个机器学习框架（混合专家模型）应用于特定领域（医疗影像分析），以解决该领域的问题（疾病诊断）。论文的本质是应用研究，而非关于构建通用LLM智能体或其演化机制的方法论研究。 2.  **排除标准 (第三步):** 该论文明确命中了两个关键的排除标准。 *   **安全与对齐:** 论文摘要中明确指出，其核心贡献之一是提供了 \"enhanced interpretability\"（增强的可解释性），即解释模型如何利用不同脑区的生物标志物进行诊断。根据筛选标准，只要论文的主要贡献是关于 `Interpretability` (可解释性)，就应被排除。 *   **多模态与视觉:** 论文处理的是多模态数据，具体是 \"amyloid PET and MRI\"（淀粉样蛋白PET和MRI），这属于医学影像范畴。这完全符合“多模态与视觉”的排除标准。论文的核心是融合这些视觉信息，而不是将它们作为智能体感知环境的工具。 3.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步证明了该论文与我的研究课题无关。 综上所述，该论文是一篇专注于医疗AI和可解释机器学习的应用型研究，其核心目标、技术方法和贡献均与“LLM智能体及其演化”这一课题不符，因此应被排除。"
    },
    {
        "index": "#82",
        "title": "Developmental Symmetry-Loss: A Free-Energy Perspective on Brain-Inspired Invariance Learning",
        "link": "/arxiv/2512.10984",
        "arxiv_id": "2512.10984",
        "authors": "Arif Dönmez",
        "subjects": "Neurons and Cognition, Artificial Intelligence, Machine Learning, Adaptation and Self-Organizing Systems",
        "date": "2025-12-04",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.281500",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“Symmetry-Loss”的新算法原则，这是一种用于**表征学习**的损失函数。其目标是让模型学习到具有不变性和等变性的表征，灵感来源于大脑的发育过程和自由能原理。这篇论文的本质是**基础机器学习理论**，特别是关于如何从环境对称性中学习更好的表征，它并不涉及构建、改进或演化任何形式的智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式和能力的关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。虽然提到了“迭代精炼”，但这是指对“有效对称群”的精炼，是表征学习的过程，而非智能体能力的演化。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文没有直接命中安全、对齐或多模态等排除关键词，但其研究的“不变性学习”通常与计算机视觉和基础感知模型紧密相关，属于更广泛的机器学习基础研究领域，而非您聚焦的Agentic AI。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划框架。它关注的是底层的、非智能体的表征学习机制。 - **自我演化的应用**: 论文虽然提到了“发育过程”和“自组织”，但这是一种比喻，用来形容其表征学习算法的数学过程。它没有提出一种能让智能体通过经验或反馈进行自我完善的机制。因此，这不属于您所定义的“自我演化”智能体的例外情况。 **最终决策**: 综合以上分析，该论文是一篇关于受大脑启发的**基础表征学习理论**的研究。它的核心是提出一种新的损失函数来优化模型对世界结构（对称性）的理解，而不是构建或演化一个具有自主性、规划能力或工具使用能力的LLM智能体。因此，它与您“LLM智能体及其演化”的核心研究目标完全不符，应予以排除。"
    },
    {
        "index": "#87",
        "title": "Emotion-Driven Personalized Recommendation for AI-Generated Content Using Multi-Modal Sentiment and Intent Analysis",
        "link": "/arxiv/2512.10963",
        "arxiv_id": "2512.10963",
        "authors": "Zheqi Hu, Xuanjing Chen, Jinlin Hu",
        "subjects": "Information Retrieval, Artificial Intelligence, Human-Computer Interaction, Machine Learning, Multimedia",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.289574",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为MMEI的**多模态情感和意图识别模型**，并将其集成到一个**个性化AIGC推荐框架**中。其本质是利用多模态数据（视觉、听觉、文本）来改进推荐系统的效果。这完全符合第一步排除标准中的第一条：“**非演化型应用**”。论文将BERT、ViT等模型作为工具，应用于特定领域（推荐系统）去解决该领域的问题（提升用户参与度），但其本身并未构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式或能力关键词，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。其研究焦点是多模态融合与推荐算法，而非智能体的内在机制或交互演化。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的核心研究内容涉及视觉和听觉模态，符合第三步排除标准中的“**多模态与视觉**”。虽然它使用了BERT（一种语言模型），但视觉和听觉是研究的核心组成部分，而不是作为智能体感知环境的工具。因此，这属于被排除的范畴。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及“推理/规划”或“自我演化的应用”等特殊情况。它是一个典型的应用型研究，没有提出新的智能体框架或演化机制。 **最终决策**：综合以上分析，这篇论文的核心是关于**推荐系统**和**多模态情感分析**，而非关于LLM智能体的构建、协作或演化。它将现有模型作为组件应用于一个特定任务，属于典型的应用研究，与研究课题“LLM智能体及其演化”的核心目标不符。因此，应予以排除。"
    },
    {
        "index": "#89",
        "title": "AI as Cognitive Amplifier: Rethinking Human Judgment in the Age of Generative AI",
        "link": "/arxiv/2512.10961",
        "arxiv_id": "2512.10961",
        "authors": "Tao An",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-10-30",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.290708",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献并非构建、改进或演化LLM智能体。根据摘要，它是一篇“立场论文”，旨在提出一个关于人与AI关系的概念框架，即“AI作为认知放大器”。论文的核心论点是，AI工具的效果取决于使用者的专业知识和判断力，而非AI本身。这完全符合**排除标准中的“非演化型应用”**，因为它将AI视为一个工具，来分析和解决“如何提升人类在AI时代的生产力与判断力”这一属于人机交互（HCI）和教育学领域的问题，而不是研究如何让AI智能体本身变得更自主、更强大。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所列出的任何核心正面指标。它没有讨论 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving` 等任何关于智能体内部机制或能力的技术细节。虽然提到了“iterative refinement”（迭代完善），但这是指**人类用户**与AI工具之间的交互过程，而非智能体的自我完善或自我演化机制。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 这篇论文虽然不直接涉及安全、对齐或多模态等排除项，但其本质属于更广泛的“非演化型应用”排除范畴。它的研究焦点是“人”，而不是“智能体”。 4.  **第四步：处理特殊和模糊情况** 论文不涉及任何需要特殊判断的模糊情况。它既不是关于智能体的自主规划，也不是关于提出新的自我演化机制。 **最终决策**: 综合以上分析，该论文是一篇关于人机交互和认知科学的社科类立场论文，其核心是探讨人类如何更好地使用AI工具，而不是如何构建或演化AI智能体。因此，它完全偏离了您关于“LLM智能体及其演化”的核心研究目标，应予以排除。"
    },
    {
        "index": "#90",
        "title": "Measuring skill-based uplift from AI in a real biological laboratory",
        "link": "/arxiv/2512.10960",
        "arxiv_id": "2512.10960",
        "authors": "Ethan Obie Romero-Severson, Tara Harvey, Nick Generous, Phillip M. Mach",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-10-29",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.291191",
        "filter_reason": "这篇论文不符合我的研究范围。 1.  **核心判断 (第一步):** 论文的核心贡献是一项**实证研究**，旨在测量一个“AI推理模型”对人类在真实生物实验室中完成任务的技能提升效果。这完全符合第一步中的**“非演化型应用”**排除标准。论文将AI模型作为一个工具，应用于特定领域（生物学），以研究人机交互及其影响，而不是构建、改进或演化LLM智能体本身。论文的研究方法是实验设计和效果评估，而非提出新的智能体框架或演化机制。 2.  **正面指标 (第二步):** 论文中提到的“AI reasoning model”虽然可能是一个LLM，但论文并未探讨其内部的`Planning`、`Tool Use`或`Self-Reflection`等智能体能力。研究的焦点是人类参与者如何与这个模型互动，而不是模型本身如何作为一个自主智能体运作。因此，论文缺乏我所关注的核心范式和能力指标。 3.  **排除标准 (第三步):** 论文的研究动机和讨论部分明确涉及“预测AI系统的风险和益处”以及“全球生物安保”，这直接触及了**“安全与对齐”**的范畴。根据筛选标准，只要论文的主要贡献与此相关，就应排除。 4.  **特殊与模糊情况 (第四步):** 论文不涉及提出新的智能体规划框架，也不涉及任何自我演化机制。因此，相关的例外情况均不适用。 **结论:** 综合来看，这篇论文是一篇典型的人机交互（HCI）或AI社会影响研究，它评估了现有AI技术在特定场景下的应用效果。我的研究焦点是Agentic AI的**构建与演化方法论**，而这篇论文的焦点是AI工具的**应用效果评估**，两者存在根本差异。因此，应予以排除。"
    },
    {
        "index": "#1",
        "title": "A General Algorithm for Detecting Higher-Order Interactions via Random Sequential Additions",
        "link": "/arxiv/2512.11793",
        "arxiv_id": "2512.11793",
        "authors": "Ahmad Shamail, Claire McWhite",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.242406",
        "filter_reason": "这篇论文的核心贡献是提出了一种通用的、基于几何的算法（L-score），用于检测任意系统中元素之间的高阶交互、冗余和协同效应。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** - 该论文的本质是一个**通用的数学/统计分析方法**，用于揭示系统中不同元素（或特征、行动）之间的相互作用关系。它是一个分析工具，而不是一个关于构建或改进智能体的框架。 - 论文完全没有提及LLM、智能体、规划、记忆、工具使用或自我演化等核心概念。因此，它不符合“构建、改进或演化LLM智能体”的核心目标。 - 它属于一种基础性的方法论研究，而非Agentic AI的应用或框架研究。根据第一步的排除规则，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中未出现任何我关注的核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems (MAS)`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。 - 虽然提到了 \"synergy\" (协同) 和 \"interactions\" (交互)，但这是在纯粹的数学和统计学意义上（例如，`Y=X1*X2`），而不是指智能体之间的协作或通信。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全、对齐或多模态等排除领域，但其核心内容与研究范围相去甚远。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何需要特殊处理的模糊情况。它既不是关于智能体的推理/规划，也不是关于自我演化的应用。 **最终决策**：综合以上分析，这篇论文提出的是一个通用的系统交互分析算法，与“LLM智能体及其演化”这一研究课题完全不相关。它不属于构建、改进或演化智能体的范畴，因此应被排除。"
    },
    {
        "index": "#2",
        "title": "Softmax as Linear Attention in the Large-Prompt Regime: a Measure-based Perspective",
        "link": "/arxiv/2512.11784",
        "arxiv_id": "2512.11784",
        "authors": "Etienne Boursier, Claire Boyer",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.243039",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是**提供了一个理论分析框架**，用于研究Transformer模型中的Softmax Attention机制。它从数学上证明了在长提示下，Softmax Attention的行为可以近似为线性Attention，并为此建立了非渐近集中界限。这属于对**基础模型组件的理论分析**，而不是构建或改进一个完整的LLM智能体系统。 根据筛选标准，这属于**排除**项中的“非Agentic的推理”。论文关注的是模型内部机制的数学原理，而不是如何让智能体利用这个机制进行自主规划、工具使用或演化。它研究的是“引擎”的物理特性，而不是如何设计一辆“自动驾驶汽车”。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够有力。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文虽然涉及“Attention”这一与推理相关的核心机制，但它并非从智能体的角度出发。它没有提出新的智能体规划框架（如ReAct或ToT），而是对底层Attention算子进行数学建模和分析。因此，它属于被排除的“提高LLM本身基础Token预测的数学或逻辑能力”的理论研究范畴。 - **自我演化的应用**: 此处不适用。 **最终决策**: 综合以上分析，这篇论文是一篇关于Transformer模型基础组件的理论研究，其目标是深化对Softmax Attention数学行为的理解。它没有提出任何关于LLM智能体的构建、协作或演化的新方法或框架。因此，它完全偏离了我关于“LLM智能体及其演化”的研究课题，应被排除。"
    },
    {
        "index": "#5",
        "title": "High-Dimensional Surrogate Modeling for Closed-Loop Learning of Neural-Network-Parameterized Model Predictive Control",
        "link": "/arxiv/2512.11705",
        "arxiv_id": "2512.11705",
        "authors": "Sebastian Hirt, Valentinus Suwanto, Hendrik Alsmeier, Maik Pfefferkorn, Rolf Findeisen",
        "subjects": "Machine Learning, Systems and Control",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.244908",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种新的**优化方法**，用于解决控制工程领域的一个具体问题：高维模型预测控制器（MPC）的参数调优。它使用贝叶斯神经网络作为代理模型，来替代传统的高斯过程，从而更高效地进行贝叶斯优化。这完全符合**排除标准中的“非演化型应用”**。该研究是将一种先进的机器学习技术（贝叶斯神经网络）作为工具，应用于特定领域（控制理论），以解决该领域的问题（控制器参数学习），其本质是优化算法的改进，而非构建或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我所关注的核心范式和能力。它不涉及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。虽然提到了 \"learning\"，但这是指参数的优化学习，而非智能体的自我完善或学习新技能。论文也没有讨论智能体的 `Planning`、`Tool Use`、`Memory` 或 `Self-Reflection` 等核心能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的主要焦点是控制理论和优化算法，不属于安全与对齐或多模态与视觉的排除范畴，但这并不改变其不符合我核心研究方向的事实。 4.  **第四步：处理特殊和模糊情况** -   **推理/规划**: 论文研究的对象是“模型预测控制”（MPC），MPC本身确实包含规划过程。但是，这篇论文的重点**不是**研究智能体如何进行规划，而是研究如何**优化MPC这个规划算法的参数**。这属于“排除”情况，即关注底层组件的性能，而非构建一个自主的Agentic框架。 -   **自我演化的应用**: 论文中的“closed-loop learning”是一个参数优化的迭代过程，而不是智能体通过经验或反思进行自我演化的机制。因此，它不符合“自我演化”的核心定义，也不适用该例外规则。 **最终决策**: 综合以上分析，该论文是一篇典型的将机器学习方法应用于控制工程的交叉学科研究。其核心贡献在于改进一种优化技术，而非构建、改进或演化LLM智能体。因此，它严格地落在了我的筛选范围之外。"
    },
    {
        "index": "#7",
        "title": "A Fast Interpretable Fuzzy Tree Learner",
        "link": "/arxiv/2512.11616",
        "arxiv_id": "2512.11616",
        "authors": "Javier Fumanal-Idocin, Raquel Fernandez-Peralta, Javier Andreu-Perez",
        "subjects": "Machine Learning, Symbolic Computation",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.245866",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“A Fast Interpretable Fuzzy Tree Learner”的新型机器学习算法。该算法旨在解决**表格数据分类**问题，通过结合模糊逻辑和树结构，实现比传统进化算法更快的训练速度和更好的可解释性。论文的本质是**一种新的机器学习模型/算法**，而非构建、改进或演化LLM智能体。它属于“非演化型应用”的范畴，因为它专注于解决一个特定的机器学习任务（表格分类），而不是提出一个通用的智能体框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文完全不包含我的核心关注点。摘要中没有提及任何与`Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`或`Self-Evolving`相关的概念。它也没有讨论智能体的核心能力，如`Planning`、`Tool Use`、`Memory`或`Self-Reflection`。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文没有触及安全与对齐或多模态等排除项，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** 论文中提到了“Evolutionary approaches”，但这并非我关注的“自我演化”。这里的“Evolutionary”指的是传统的进化计算方法（如遗传算法），论文将其作为比较的基准，以凸显自己提出的方法在计算效率上的优势。这并非关于智能体通过经验或反馈进行自我完善和迭代的机制。因此，这不属于“自我演化的应用”这一例外情况。 **最终决策**： 该论文的研究焦点是开发一种用于表格数据分类的、高效且可解释的模糊树学习算法。它属于传统机器学习模型研究的范畴，与我的核心目标——“LLM智能体及其演化”——没有直接关联。因此，这篇论文应被排除。"
    },
    {
        "index": "#3",
        "title": "The Adaptive Vekua Cascade: A Differentiable Spectral-Analytic Solver for Physics-Informed Representation",
        "link": "/arxiv/2512.11776",
        "arxiv_id": "2512.11776",
        "authors": "Vladimer Khasia",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.243581",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出了一种名为“自适应Vekua级联（AVC）”的新型神经网络架构。这个架构旨在解决物理信息表示中的两个经典问题：光谱偏差和维度灾难。它通过结合深度学习和经典逼近理论，将复杂的物理动态投影到潜在流形上，并用一个可微分的线性求解器来优化结果。 - **判断结论**: 这篇论文的本质是**科学计算**和**物理机器学习**领域的研究。它提出了一种新的神经网络**求解器**，用于高效、准确地表示物理场（如波动、湍流等）。这完全符合筛选标准中的**排除项1：非演化型应用**。论文将一个新颖的深度学习架构作为工具，应用于物理和医学等特定领域，其核心目标是解决该领域（物理场表示）的问题，而非构建、改进或演化LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与我的研究焦点相关的关键词。例如：`Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等均未提及。这进一步确认了它与我的研究目标无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文不涉及安全对齐或多模态视觉等排除项，但第一步的判断已经足够有力，可以将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中提到的“求解器”是针对物理方程的数学求解器，而非智能体在复杂任务中进行多步推理或规划的框架。因此，这不属于应保留的Agentic推理范畴。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。其核心是架构创新，而非一个能让智能体通过经验自我完善的迭代过程。 **最终决策**: 综合以上分析，该论文的研究焦点是物理机器学习和神经表示，其核心贡献是解决物理问题的计算方法。这与我“LLM智能体及其演化”的研究课题（关注智能体的构建、协作与演化）完全不符。因此，应将其排除。"
    },
    {
        "index": "#4",
        "title": "SpectralKrum: A Spectral-Geometric Defense Against Byzantine Attacks in Federated Learning",
        "link": "/arxiv/2512.11760",
        "arxiv_id": "2512.11760",
        "authors": "Aditya Tripathi, Karan Sharma, Rahul Mishra, Tapas Kumar Maiti",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.244319",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 SpectralKrum 的防御机制，用于在联邦学习（FL）中抵御拜占庭攻击。根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——论文本质不符。** 这篇论文的本质是关于**分布式机器学习系统的安全性与鲁棒性**，而非构建、改进或演化LLM智能体。它解决的是联邦学习框架下，恶意客户端破坏全局模型的安全问题。这完全符合第一步排除标准中的“基础设施”和“安全”相关的研究，而不是关于智能体本身的方法论或框架。 2.  **第二步：正面指标——缺乏核心关注点。** 论文中完全没有出现我核心关注点的任何正面指标。它没有讨论 `Agentic AI`、`LLM-based Agents`、`Self-Evolving` 等核心范式，也未涉及智能体的 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等能力，更没有关于多智能体 `Collaboration` 或 `Communication` 的内容。 3.  **第三步：排除标准——明确命中排除项。** 论文的研究焦点完全落在了“**安全与对齐**”这一排除标准上。其核心目标是解决 `Security` 问题，即防御恶意客户端的攻击，这与我的研究目标“LLM智能体及其演化”有本质区别。虽然论文没有直接使用 \"Safety\" 或 \"Security\" 作为标题关键词，但其摘要内容明确指出这是对 \"Byzantine Attacks\" 的 \"Defense\"，属于典型的机器学习安全研究。 4.  **第四步：处理特殊情况——不适用。** 该论文不涉及推理/规划或自我演化的特殊情况。虽然联邦学习涉及多个“客户端”，但这些客户端在本文中是作为数据持有者和模型更新者存在的，并不具备Agentic AI所研究的规划、记忆、工具使用或自我反思等核心能力。因此，这里的“多客户端”系统不等同于“多智能体系统”的研究范畴。 **最终决策：** 综合以上分析，该论文属于机器学习安全领域的研究，其核心贡献是提升联邦学习系统的鲁棒性，与我的研究课题“LLM智能体及其演化”完全不相关。因此，应予以排除。"
    },
    {
        "index": "#10",
        "title": "Brain-Semantoks: Learning Semantic Tokens of Brain Dynamics with a Self-Distilled Foundation Model",
        "link": "/arxiv/2512.11582",
        "arxiv_id": "2512.11582",
        "authors": "Sam Gijsen, Marc-Andre Schulz, Kerstin Ritter",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Neurons and Cognition",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.252500",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 论文的核心贡献是提出了一个名为 \"Brain-Semantoks\" 的**自监督框架**，用于学习功能性磁共振成像（fMRI）时间序列的抽象表示。其创新点在于一个“语义分词器”和一个“自蒸馏目标”，旨在为神经科学领域构建一个更强大的基础模型。 - **判断**: 这篇论文的本质是**将深度学习模型（特别是基础模型）应用于特定科学领域（神经科学）**，以解决该领域的数据表示和分析问题。它完全符合筛选标准中第一步的排除项 **“1. 非演化型应用”**。论文没有构建、改进或演化任何形式的LLM智能体，而是将模型作为工具应用于fMRI数据分析。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有出现任何与我研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心范式或智能体能力。这进一步确认了它与我的研究目标无关。 3.  **第四步：处理特殊和模糊情况** - 论文中提到了 \"self-distilled\"（自蒸馏），这可能会让人联想到“自我演化”。然而，根据筛选标准的核心规则，这里的“自蒸馏”是一种**模型训练技术**，用于在训练过程中强制模型学习到跨时间的稳定表示，以对抗噪声。它**不是**一个智能体在执行任务过程中通过经验、反思或环境反馈来**自我完善和迭代其行为策略或能力的机制**。因此，它不符合“自我演化”的定义，也不满足“自我演化的应用”这一例外情况的保留条件。 **最终决策**: 综合以上分析，该论文是一篇典型的交叉学科应用研究，其核心是针对特定数据（fMRI）提出新的表示学习方法，而非关于LLM智能体的构建、多智能体交互或智能体的自我演化机制。因此，这篇论文与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#15",
        "title": "Parametric Numerical Integration with (Differential) Machine Learning",
        "link": "/arxiv/2512.11530",
        "arxiv_id": "2512.11530",
        "authors": "Álvaro Leitao, Jonatan Ráfales",
        "subjects": "Machine Learning, Numerical Analysis",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.254746",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 根据标题和摘要，这篇论文的核心是提出一种新的机器/深度学习方法（特别是微分学习框架）来解决**参数数值积分**这一经典的数学计算问题。其目标是提高积分计算的精度、可扩展性和样本效率。 - **是否符合**: 这完全符合第一步中的排除标准 **“1. 非演化型应用”**。该论文将机器学习作为一种工具，应用于一个特定的、非AI的领域（数值计算），以解决该领域的问题。它没有构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准** - 虽然论文没有直接命中“安全与对齐”或“多模态与视觉”等排除关键词，但第一步的“非演化型应用”排除已经足够有力。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何自我演化机制。因此，特殊情况的例外条款不适用。 **最终决策**: 该论文的研究本质是**计算数学**与**机器学习**的交叉，旨在解决数值积分问题。它并非关于构建具有自主性、规划能力或演化能力的LLM智能体。因此，它与您关于“LLM智能体及其演化”的核心研究目标完全不符，应予以排除。"
    },
    {
        "index": "#11",
        "title": "Fully Inductive Node Representation Learning via Graph View Transformation",
        "link": "/arxiv/2512.11561",
        "arxiv_id": "2512.11561",
        "authors": "Dooho Lee, Myeong Kong, Minho Jeong, Jaemin Yoo",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.252958",
        "filter_reason": "这篇论文不符合您的研究范围。 根据您的筛选标准，我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为“Graph View Transformation”（GVT）的新方法，用于解决图结构数据中的节点表示学习问题，特别是实现跨数据集的全归纳推理。这本质上是一篇关于**图神经网络（GNN）和图表示学习**的方法论研究，而非关于构建、改进或演化LLM智能体。它属于“非Agentic的推理”范畴，其目标是提升模型在图数据这一特定模态上的基础表征和泛化能力，而不是研究智能体的自主规划、工具使用或自我演化框架。因此，在第一步就应被**排除**。 2.  **第二步：正面指标** 在检查论文摘要时，完全没有出现任何您所关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。这进一步确认了该论文与您的研究焦点无关。 3.  **第三步：排除标准** 该论文不涉及安全、对齐或多模态等排除领域，但这并不改变其核心研究方向与您的要求不符的事实。 4.  **第四步：处理特殊和模糊情况** 论文中提到的“inductive”（归纳）指的是模型泛化到未见过的数据集的能力，这是机器学习中的一个标准概念，与您所关注的“自我演化”（智能体通过经验、反思进行自我完善）机制完全不同。该论文的研究对象是图数据，而非LLM智能体，因此不适用任何例外保留规则。 **最终决策**：该论文是图机器学习领域的一项高质量研究，但其研究焦点是改进图模型的基础能力，与“LLM智能体及其演化”这一课题的核心目标——构建、改进或演化智能体框架——存在根本性差异。因此，应予以排除。"
    },
    {
        "index": "#6",
        "title": "Bridging Streaming Continual Learning via In-Context Large Tabular Models",
        "link": "/arxiv/2512.11668",
        "arxiv_id": "2512.11668",
        "authors": "Afonso Lourenço, João Gama, Eric P. Xing, Goreti Marreiros",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.245388",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“流式持续学习”的新学习范式，并论证了大型表格模型可以作为连接持续学习（CL）和流式学习（SL）的桥梁。其本质是**一种新的机器学习算法/框架**，用于处理数据流中的概念漂移和灾难性遗忘问题。它并非关于构建一个具有自主性、规划能力或工具使用能力的“智能体”。因此，根据第一步的筛选标准，这篇论文应被排除，因为它不属于构建、改进或演化LLM智能体的范畴，而更偏向于一种非演化型的算法应用。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中几乎没有出现我关注的核心范式和能力关键词。它没有提及`Agentic AI`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection`等。虽然提到了`Memory`和`Retrieval`，但这是在数据选择的背景下，指从历史数据流中检索信息以辅助模型训练，这与智能体为完成复杂任务而进行的情景记忆或工具检索有本质区别。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划框架。 - **自我演化的应用**: 这是最容易混淆的一点。论文中的“持续学习”和“适应”听起来像“演化”。然而，这里的“演化”指的是**模型在数据流上的训练过程**，即模型参数随新数据而调整，以适应分布变化。这不同于我研究焦点中的“自我演化”，即**智能体作为一个自主实体，通过反思、经验总结或与环境交互来主动改进自身的策略、代码或认知结构**。该论文没有提出一个智能体自我完善的机制，而是提出了一个让模型更好地从数据流中学习的算法。 **最终决策**: 综合以上分析，这篇论文的核心是解决流式数据场景下的机器学习问题，其贡献在于算法层面，而非智能体架构或机制。它虽然使用了大型模型（LTMs），但并未将其构建成一个具有自主规划、工具使用或自我反思能力的智能体。因此，该论文与我的研究目标“LLM智能体及其演化”不匹配，应予以排除。"
    },
    {
        "index": "#14",
        "title": "A Multi-Criteria Automated MLOps Pipeline for Cost-Effective Cloud-Based Classifier Retraining in Response to Data Distribution Shifts",
        "link": "/arxiv/2512.11541",
        "arxiv_id": "2512.11541",
        "authors": "Emmanuel K. Katalay, David O. Dimandja, Jordan F. Masakuna",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.254310",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是基础设施，而非智能体构建。** 论文的核心贡献是提出一个“自动化的MLOps流水线”，用于检测数据分布漂移并自动触发模型重新训练。这完全属于筛选标准中第一步的排除规则第3条：“主要关注模型基础设施、部署优化的研究”。论文的重点在于运维层面的自动化和资源优化，而不是构建一个具有自主性、规划或反思能力的LLM智能体。 2.  **第二步：缺乏任何正面指标。** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词。它没有提及`LLM-based Agents`、`Agentic AI`、`Multi-Agent Systems`或`Self-Evolving`。其讨论的能力是“数据分布漂移检测”和“模型更新触发”，这些是运维监控功能，而非智能体的`Planning`、`Tool Use`、`Memory`或`Self-Reflection`能力。 3.  **第三步：符合排除标准。** 如第一步所述，该论文的核心是MLOps基础设施，这本身就是一项明确的排除标准。 4.  **第四步：特殊情况不适用。** 有人可能会争辩说，一个能自动响应环境变化（数据漂移）并自我更新的系统，算是一种“演化”。然而，这与筛选标准中定义的“自我演化”有本质区别。标准中的“自我演化”指的是**智能体内部**通过经验、反思或反馈进行自我完善和迭代的机制。而本文描述的是一个**外部系统**（MLOps流水线）来监控和管理一个被动模型的生命周期。模型的“演化”（重新训练）是由外部流水线触发的，而非模型自身的智能体行为。因此，这不属于“自我演化的应用”这一例外情况。 **最终决策**：该论文是一篇关于机器学习运维（MLOps）的研究，其核心是构建一个自动化的模型维护流水线。它不涉及LLM智能体的构建、多智能体交互或智能体的自我演化机制。因此，它完全不符合“LLM智能体及其演化”这一研究课题的核心目标，应予以排除。"
    },
    {
        "index": "#21",
        "title": "Sliced ReLU attention: Quasi-linear contextual expressivity via sorting",
        "link": "/arxiv/2512.11411",
        "arxiv_id": "2512.11411",
        "authors": "Siwan Boufadène, François-Xavier Vialard",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.263042",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心贡献不符 (第一步)**: 论文的核心贡献是提出了一种名为 \"sliced ReLU attention\" 的新型注意力机制。其研究焦点在于改进模型的基础架构组件（注意力机制），旨在提升计算效率（准线性复杂度）和理论表达能力（上下文通用近似）。这属于对底层模型架构的优化，而非构建、改进或演化一个完整的LLM智能体。 2.  **属于“非Agentic的推理”范畴 (第一步排除规则)**: 该论文的研究内容完全符合“非Agentic的推理”这一排除标准。它致力于提升LLM处理长上下文的基础能力，但并未涉及任何智能体框架，如自主规划、工具使用、记忆或自我反思。论文提出的机制可以被未来的智能体系统所使用，但论文本身并未提出或研究任何智能体。 3.  **缺乏正面指标 (第二步)**: 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。其关键词是 `attention mechanism`, `complexity`, `expressivity`, `sorting`，这些都指向模型架构和计算理论，而非智能体行为。 综上所述，尽管这篇论文可能在提升LLM基础性能方面具有重要价值，但它属于模型架构层面的基础研究，与我的研究课题“LLM智能体及其演化”的直接关联性很低。我的目标是筛选那些以智能体本身为核心研究对象的论文，而这篇论文的核心是智能体的一个基础组件。因此，应予以排除。"
    },
    {
        "index": "#22",
        "title": "Bhargava Cube--Inspired Quadratic Regularization for Structured Neural Embeddings",
        "link": "/arxiv/2512.11392",
        "arxiv_id": "2512.11392",
        "authors": "S Sairam, Prateek P Kulkarni",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.263465",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出一种**新颖的神经表示学习方法**。具体来说，它引入了一种受数论启发的二次正则化技术，用于学习具有数学结构性的神经嵌入。论文的重点在于改进神经网络潜在空间的结构性和可解释性，而不是构建、改进或演化一个能够自主行动的智能体。 - **排除**: 该论文属于“非演化型应用”和“非Agentic的推理”的范畴。它提出了一种新的数学约束方法，并将其应用于表示学习任务（在MNIST数据集上），这本质上是一种改进模型内部表示的技术，而非构建一个具有规划、工具使用或反思能力的LLM智能体。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式和能力的关键词。 - **核心范式**: 未提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - **智能体能力**: 未提及 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `ReAct` 等。 - **多智能体**: 未提及任何相关概念。 - **演化机制**: 未提及 `Self-Improvement`, `Self-Refine` 等。 **第三步：排除标准——是否为我的研究焦点之外？** 论文明确提到了其方法的一个优点是产生“**可解释的3维嵌入**”。这直接触及了排除标准中的 `Interpretability` (可解释性)。虽然可解释性不是其唯一贡献，但它是论文成果的一个关键特性，这进一步表明其研究焦点与您的“LLM智能体及其演化”课题不同。 **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文不涉及智能体的推理或规划框架。它关注的是嵌入空间的数学结构，而非智能体如何进行多步决策。 - **自我演化的应用**: 该论文没有提出任何自我演化机制，因此相关的例外情况不适用。 **最终决策** 综合以上分析，这篇论文的本质是**表示学习**和**正则化技术**的研究，属于机器学习的基础方法领域。它的核心目标是让神经嵌入更具数学结构性，这与您研究的“LLM智能体及其演化”这一Agentic AI方向存在根本性的差异。因此，该论文应被排除。"
    },
    {
        "index": "#16",
        "title": "xGR: Efficient Generative Recommendation Serving at Scale",
        "link": "/arxiv/2512.11529",
        "arxiv_id": "2512.11529",
        "authors": "Qingxiao Sun, Tongxuan Liu, Shen Zhang, Siyu Wu, Peijun Yang, Haotian Liang, Menxin Li, Xiaolong Ma, Zhiwei Liang, Ziyi Ren, Minchao Zhang, Xinyu Liu, Ke Zhang, Depei Qian, Hailong Yang",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.255358",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是基础设施优化，而非智能体构建。** 论文的核心贡献是提出了一个名为 `xGR` 的“服务系统”，其目标是解决生成式推荐（GR）模型在大规模部署时的效率和延迟问题。摘要中明确指出，这是一个“GR-oriented serving system”，其创新点在于“staged computation”、“separated KV cache”、“early sorting termination”、“multi-stream parallelism”等系统层面的优化技术。这完全符合筛选标准中第一步的排除规则：“排除主要关注模型基础设施、部署优化、硬件加速的研究”。论文的本质是系统工程，而非智能体方法论。 2.  **第二步：正面指标——论文完全不包含我的核心关注点。** 我仔细阅读了摘要，没有发现任何与我的研究焦点相关的关键词。论文没有提及 `Agentic AI`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent`、`Collaboration` 或 `Self-Evolving` 等。它的核心是提升“throughput”（吞吐量）和降低“latency”（延迟），这些都是典型的系统性能指标，与智能体的能力构建无关。 3.  **第三步：排除标准——论文属于基础设施类别。** 虽然论文不涉及安全对齐或多模态，但它精准地命中了“基础设施”这一排除项。它研究的是如何更高效地运行一个已有的模型（生成式推荐模型），而不是如何创造或改进一个智能体。 4.  **第四步：处理特殊和模糊情况——不适用。** 该论文不涉及推理/规划框架的创新，也不涉及任何自我演化机制。它只是将一个LLM架构应用在推荐领域，并优化其服务过程，属于典型的“非演化型应用”。 **最终决策**：综合以上分析，这篇论文的核心贡献是关于LLM应用（推荐系统）的**服务基础设施优化**，旨在提升系统吞吐量和降低延迟。它完全没有涉及LLM智能体的构建、改进或演化。因此，它严格地被排除在我的研究范围之外。"
    },
    {
        "index": "#8",
        "title": "Gradient Descent as a Perceptron Algorithm: Understanding Dynamics and Implicit Acceleration",
        "link": "/arxiv/2512.11587",
        "arxiv_id": "2512.11587",
        "authors": "Alexander Tyurin",
        "subjects": "Machine Learning, Numerical Analysis, Optimization and Control",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.246315",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 论文的核心贡献在于对神经网络训练中的**梯度下降（GD）算法**进行理论分析。它将GD的步骤与经典的感知机算法联系起来，旨在解释神经网络的优化动态和“隐式加速”现象。 - **判断**: 这篇论文的本质是**优化理论**研究，而非构建或改进LLM智能体。它关注的是模型训练的底层算法动态，而不是训练后模型作为智能体的行为、能力或演化。因此，根据第一步的排除标准，它属于“非Agentic的推理”范畴，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全与对齐，也不涉及多模态与视觉，因此不触发第三步的明确排除项。但第一步的判断已经足够有力。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文虽然涉及“推理”（数学推导和理论分析），但它不是关于智能体如何进行自主规划和多步决策。它研究的是优化算法本身的数学行为，这完全符合“排除：如果只是关于提高LLM本身基础Token预测的数学或逻辑能力”的延伸逻辑——即研究训练模型的数学过程，而非模型作为智能体的推理过程。 - **自我演化的应用**: 论文没有提出任何自我演化机制。 5.  **第五步：最终决策** - 综合以上分析，该论文是一篇纯粹的关于神经网络优化算法的理论研究。它的目标是解释梯度下降的动态特性，而不是设计、构建或演化一个能够自主行动、使用工具或进行协作的LLM智能体。因此，它完全不符合您关于“LLM智能体及其演化”的研究课题。"
    },
    {
        "index": "#20",
        "title": "Hyperbolic Gaussian Blurring Mean Shift: A Statistical Mode-Seeking Framework for Clustering in Curved Spaces",
        "link": "/arxiv/2512.11448",
        "arxiv_id": "2512.11448",
        "authors": "Arghya Pratihar, Arnab Seal, Swagatam Das, Inesh Chattopadhyay",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.262613",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的核心贡献是提出了一种名为 `HypeGBMS` 的新算法，它是一种在双曲空间中进行聚类的统计方法。论文的本质是**改进一种无监督学习算法（聚类）**，使其能够更好地处理具有层次结构的数据。 - 根据筛选标准，这属于**排除**范畴。它既不是关于构建LLM智能体，也不是关于多智能体系统或自我演化框架。它是一种基础的机器学习方法，与“Agentic AI”的核心概念无关。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标。 - 缺失的关键词包括：`Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration`, `Self-Improvement` 等。 - 这进一步确认了该论文与我的研究目标不相关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文不涉及安全与对齐，也不涉及多模态与视觉。因此，它不属于这些特定的排除类别。但是，它在第一步的核心判断中已经被排除，因为其研究主题（聚类算法）本身就在我的研究焦点之外。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何需要特殊处理的情况。它既不是关于智能体的推理/规划，也不是关于自我演化的应用。 **最终决策**： 综合以上分析，这篇论文的核心是提出一种新的**聚类算法**，属于统计机器学习和几何表示学习的范畴。它完全没有涉及LLM智能体的构建、规划、工具使用、多智能体协作或自我演化等核心议题。因此，尽管它可能在其自身领域是一项有价值的工作，但它与我的研究课题“LLM智能体及其演化”完全无关，应予以排除。"
    },
    {
        "index": "#23",
        "title": "Mitigating the Safety Alignment Tax with Null-Space Constrained Policy Optimization",
        "link": "/arxiv/2512.11391",
        "arxiv_id": "2512.11391",
        "authors": "Yifan Niu, Han Xiao, Dongyi Liu, Nuo Chen, Jia Li",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.263986",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为“NSPO”的新颖强化学习框架，其目标是解决LLM在**安全对齐**过程中出现的“对齐税”问题，即在追求安全性的同时损害模型通用能力的问题。论文的本质是关于**模型的安全与对齐**，而不是关于构建、改进或演化LLM智能体的方法论。它没有提出新的智能体架构、规划策略、工具使用范式或多智能体协作机制。因此，根据第一步的排除标准，这篇论文应被排除。 2.  **第二步：正面指标** 论文的标题和摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。其讨论的焦点是 `Safety Alignment` 和 `Policy Optimization`，这与我的研究焦点无关。 3.  **第三步：排除标准** 这是最关键的一步。论文的标题《Mitigating the **Safety Alignment** Tax...》和摘要中反复出现的“**safety alignment**”、“align with human values”、“**safety** performance”等词汇，明确表明其主要贡献属于**安全与对齐**的研究范畴。根据我的筛选标准，只要论文的主要贡献是关于 `Safety` 或 `Alignment`，就应一律排除。这篇论文是典型的对齐研究，因此被明确排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何特殊或模糊的情况。它既不是关于智能体的推理/规划框架，也不是关于自我演化的应用。 **最终决策**：综合以上分析，这篇论文的核心是LLM的安全对齐技术，旨在解决模型训练中的权衡问题，而非研究智能体的行为、能力或演化机制。它与我的研究课题“LLM智能体及其演化”在核心目标上存在根本差异，因此最终判断为 **False**，予以排除。"
    },
    {
        "index": "#26",
        "title": "Symmetry-Aware Steering of Equivariant Diffusion Policies: Benefits and Limits",
        "link": "/arxiv/2512.11345",
        "arxiv_id": "2512.11345",
        "authors": "Minwoo Park, Junwoo Chang, Jongeun Choi, Roberto Horowitz",
        "subjects": "Machine Learning, Robotics",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.265425",
        "filter_reason": "这篇论文不符合我的研究范围，核心原因在于其研究对象和贡献点与“LLM智能体及其演化”这一主题存在根本性偏差。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是关于**“等变扩散策略”**的优化方法。它提出了一种利用对称性来指导强化学习（RL）微调这些策略的框架。其本质是**一种针对特定生成模型（扩散模型）在强化学习任务中的优化技术**，而非构建或演化一个具有自主规划、记忆或工具使用能力的LLM智能体。因此，它不属于“构建、改进或演化LLM智能体”的范畴，应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中几乎不包含我关注的核心范式和能力。它没有提及`LLM-based Agents`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent`或`Self-Evolving`等任何核心关键词。虽然“Steering”和“Fine-tuning”听起来像是一种改进，但其机制是强化学习，且目标是优化一个策略函数，而不是一个完整的智能体架构。 3.  **第三步：排除标准——是否为我的研究焦点之外？** **这是最关键的排除依据。** 论文的核心研究对象是**`Diffusion Models`**。根据我的筛选标准，主要关注`Diffusion Models`的论文应被排除，除非它们被用作智能体感知环境的工具。在这篇论文中，扩散模型本身就是研究的核心（即策略本身），而不是智能体的一个组件。因此，它明确触发了排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。它关注的是策略的生成和优化，属于更底层的模型训练和优化问题。 - **自我演化的应用**: 论文虽然涉及通过RL进行策略改进，但这并非我定义的“自我演化”机制。我关注的自我演化是指智能体通过经验、反思或环境反馈进行**自主的、框架性的**自我完善和迭代。而本文的“Steering”是一种外部的、人为设计的RL微调过程，并非智能体内在的演化能力。因此，它不符合“自我演化”的例外保留条件。 **最终决策**: 该论文属于机器人学和强化学习领域，研究的是如何利用几何对称性来优化一种特定的策略表示方法（等变扩散策略）。它的贡献在于模型优化技术，而非智能体架构或演化机制。由于论文完全不涉及LLM，且核心是作为排除项的`Diffusion Models`，它与我的研究课题“LLM智能体及其演化”完全不相关。因此，最终判断为排除。"
    },
    {
        "index": "#25",
        "title": "CAT: Can Trust be Predicted with Context-Awareness in Dynamic Heterogeneous Networks?",
        "link": "/arxiv/2512.11352",
        "arxiv_id": "2512.11352",
        "authors": "Jie Wang, Zheng Yan, Jiahe Lan, Xuyan Li, Elisa Bertino",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.264950",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于构建、改进或演化LLM智能体的论文，而这篇论文的核心贡献并非如此。 1.  **核心判断 (第一步):** *   **论文本质:** 这篇论文的核心是提出一个名为CAT的**图神经网络（GNN）模型**，用于在动态异构网络中进行**信任预测**。它属于图机器学习和网络分析的范畴。 *   **排除依据:** 该论文属于“**非演化型应用**”。它将GNN作为一种工具，应用于“信任预测”这一特定领域问题，旨在提升预测的准确性。论文完全没有涉及构建LLM智能体、多智能体系统或自我演化机制。它没有提及LLM，也没有讨论智能体的规划、记忆、工具使用或自我反思等核心能力。 2.  **正面指标 (第二步):** *   论文中没有出现任何我关注的核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。虽然提到了“trust”，但研究的是如何“预测”信任，而不是智能体之间如何建立或演化信任关系。 3.  **排除标准 (第三步):** *   该论文的研究焦点是**图神经网络（GNN）**和**网络分析**，这与我的研究焦点“Agentic AI”有本质区别。它关注的是节点和边的表示学习与预测，而不是智能体的行为、交互或演化。 4.  **特殊和模糊情况 (第四步):** *   该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此不适用特殊情况的例外规则。 **结论:** 尽管这篇论文在信任预测和图神经网络领域可能是一项有价值的研究，但其核心贡献是改进一种机器学习模型（GNN）来解决特定领域的预测任务，而不是构建或演化LLM智能体。因此，它严格地被排除在我的研究范围之外。"
    },
    {
        "index": "#12",
        "title": "Elastic-Net Multiple Kernel Learning: Combining Multiple Data Sources for Prediction",
        "link": "/arxiv/2512.11547",
        "arxiv_id": "2512.11547",
        "authors": "Janaina Mourão-Miranda, Zakria Hussain, Konstantinos Tsirlis, Christophe Phillips, John Shawe-Taylor",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.253421",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文本质不符** - 论文的核心贡献是提出了一种新的**多核学习（MKL）算法**，具体来说是“弹性网络正则化MKL (ENMKL)”。这是一种经典的机器学习方法，用于融合来自不同数据源（或不同特征表示）的信息，以提升预测模型的性能。 - 该研究完全**不涉及**构建、改进或演化任何形式的智能体。它没有提及LLM、智能体框架、规划、工具使用或自我演化等概念。因此，它直接属于“非Agentic的推理”和“非演化型应用”的排除范畴。其本质是改进一种机器学习模型（SVM/KRR）的训练方法，而非构建一个自主的智能体。 2.  **第二步：正面指标——完全缺失** - 论文摘要中完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步表明它与您的研究焦点无关。 3.  **第三步：排除标准——触及关键排除项** - 论文摘要中明确指出，其方法的一个关键优势是“产生更稀疏、更可解释的模型”，并且“当模型可解释性至关重要时……尤其有价值”。`Interpretability` (可解释性) 是您明确列出的排除标准。由于论文的主要贡献之一就是提升模型的可解释性，这构成了一个强有力的排除理由。 4.  **第四步：特殊和模糊情况——不适用** - 该论文不涉及智能体的规划或推理，也不涉及任何自我演化机制，因此特殊情况的规则不适用。 **最终决策**: 综合以上分析，这篇论文是一篇关于机器学习算法（多核学习）的研究，其核心贡献在于优化模型训练过程和提升模型的可解释性，并将其应用于神经影像学领域。这与您关于“LLM智能体及其演化”的研究课题在研究对象、核心贡献和技术路线上完全不同。因此，应予以排除。"
    },
    {
        "index": "#24",
        "title": "Attacking and Securing Community Detection: A Game-Theoretic Framework",
        "link": "/arxiv/2512.11359",
        "arxiv_id": "2512.11359",
        "authors": "Yifan Niu, Aochuan Chen, Tingyang Xu, Jia Li",
        "subjects": "Machine Learning, Computer Science and Game Theory",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.264474",
        "filter_reason": "这篇论文不符合我的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是安全研究，而非LLM智能体构建。** 论文的核心贡献是提出一个名为 `CD-GAME` 的博弈论框架，用于社区检测任务中的攻击与防御。其研究焦点是图模型的安全性和鲁棒性，而非构建、改进或演化LLM智能体。论文中提到的“攻击者”和“防御者”是博弈论中的算法实体，它们不具备LLM智能体的核心特征，如基于自然语言的规划、记忆、工具使用或自我反思。因此，这篇论文属于“非演化型应用”，即将博弈论方法应用于社区检测这一特定领域解决安全问题。 2.  **排除标准 (第三步): 论文的主要贡献属于“安全与对齐”范畴。** 论文的标题和摘要明确指出了其研究内容是“攻击”和“保障安全”。关键词包括 `Attacking`、`Securing`、`adversarial graphs`、`robustness`。这完全符合筛选标准中“只要论文的主要贡献是关于 Safety, Security...一律排除”的规定。这是最直接、最关键的排除依据。 3.  **正面指标分析 (第二步): 相关术语的语境不符。** 虽然论文提到了 `Game-Theoretic Framework` (博弈论框架) 和 `dynamic evolutionary process` (动态演化过程)，但这些术语的语境与我的研究目标有本质区别。 *   **多智能体**: 这里的“多智能体”指的是博弈论中相互对抗的“玩家”，而不是我所关注的、能够进行协作、通信和社会学习的LLM智能体。 *   **演化**: 这里的“演化”指的是博弈策略在对抗中动态调整直至达到纳什均衡的过程，而不是智能体通过经验、反思或环境反馈进行自我完善和迭代的“自我演化”机制。 4.  **特殊情况处理 (第四步): 不适用例外情况。** 论文虽然提到了“演化”，但它并非提出一种通用的“自我演化”机制。其演化机制是内嵌在特定安全博弈中的，不符合“核心是提出一种新的‘自我演化’机制”的保留例外条件。 综上所述，该论文是一篇关于图数据安全和博弈论的扎实研究，但其核心贡献与研究课题“LLM智能体及其演化”完全无关。它的研究对象、方法和目标均不属于Agentic AI的范畴，且明确属于应排除的“安全”研究方向。因此，最终判断为排除。"
    },
    {
        "index": "#29",
        "title": "Pace: Physics-Aware Attentive Temporal Convolutional Network for Battery Health Estimation",
        "link": "/arxiv/2512.11332",
        "arxiv_id": "2512.11332",
        "authors": "Sara Sameer, Wei Zhang, Kannan Dhivya Dharshini, Xin Lou, Yulin Gao, Terence Goh, Qingyu Yan",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.266913",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出了一种名为 \"Pace\" 的**物理感知注意力时序卷积网络**，用于解决**电池健康估算**这一特定领域的问题。 - **判断**: 该论文属于典型的 **\"非演化型应用\" (Non-Evolving Applications)**。它构建了一个新颖的深度学习模型，并将其应用于一个垂直领域（电池管理）。论文中完全没有提及LLM、智能体框架、多智能体系统或任何形式的自我演化机制。它的目标是提高特定任务的预测精度，而不是构建或演化一个具有自主性的智能体。因此，根据第一步的核心判断规则，应予以**排除**。 2.  **第二步：正面指标** - 论文的标题和摘要中，完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文讨论的是 `Temporal Convolutional Network` (时序卷积网络) 和 `Attention` (注意力机制)，这些是模型架构的组件，而非智能体的能力。因此，该论文不满足任何正面指标。 3.  **第三步：排除标准** - 虽然论文没有触及安全与对齐、多模态与视觉等排除领域，但第一步的判断已经足够明确，无需深入此步。 4.  **第四步：处理特殊和模糊情况** - 论文中的推理是模型对电池健康状态的预测，属于标准的机器学习推理，不涉及智能体的自主规划或多步决策框架。因此，它属于被排除的“非Agentic的推理”。 **最终决策**: 这篇论文的核心贡献是**一个应用于特定工程领域的深度学习模型架构**，而非关于LLM智能体的构建、改进或演化。它完全符合第一步中的“非演化型应用”排除标准。因此，这篇论文与您关于 \"LLM智能体及其演化\" 的研究课题不相关。"
    },
    {
        "index": "#27",
        "title": "DAPO: Design Structure-Aware Pass Ordering in High-Level Synthesis with Graph Contrastive and Reinforcement Learning",
        "link": "/arxiv/2512.11342",
        "arxiv_id": "2512.11342",
        "authors": "Jinming Ge, Linfeng Du, Likith Anaparty, Shangkun Li, Tingyuan Liang, Afzal Ahmad, Vivek Chaturvedi, Sharad Sinha, Zhiyao Xie, Jiang Xu, Wei Zhang",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.265993",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是“非演化型应用”。** 论文的核心贡献是提出一个名为DAPO的框架，用于解决**高层次综合（HLS）**这一特定硬件设计领域的问题。其目标是优化FPGA加速器的性能。虽然论文中提到了“强化学习智能体”，但这个智能体是作为实现该领域特定优化目标的**工具**，而不是研究的核心。研究的焦点在于如何通过图对比学习和硬件模型来**引导**这个智能体，从而发现更好的“pass ordering”（优化顺序）。这完全符合“将智能体框架作为工具应用到特定领域去解决该领域的问题”的排除标准。 2.  **缺乏核心关注点（第二步）：论文不涉及LLM智能体。** 您的研究课题明确是关于“**LLM**智能体及其演化”。这篇论文使用的是传统的**强化学习（RL）**智能体，全文未提及任何大型语言模型（LLM）。因此，它缺少了您研究范围中最基本、最核心的要素。论文中的智能体不具备LLM特有的能力，如基于自然语言的规划、复杂的工具使用链或基于文本的自我反思。 3.  **不符合特殊情况的例外（第四步）。** 论文虽然使用了一个智能体，但它既不是“自我演化”的（RL智能体是通过训练学习策略，而非通过经验自我完善和迭代），也不是关于“LLM智能体的规划/推理”。因此，它不适用于任何保留的例外情况。 **总结：** 该论文的本质是**将一个强化学习智能体应用于硬件设计自动化（EDA）领域**，其核心贡献是针对该领域的优化方法，而非构建、改进或演化LLM智能体本身。因此，它与您关于“LLM智能体及其演化”的研究目标完全不符。"
    },
    {
        "index": "#33",
        "title": "SRLR: Symbolic Regression based Logic Recovery to Counter Programmable Logic Controller Attacks",
        "link": "/arxiv/2512.11298",
        "arxiv_id": "2512.11298",
        "authors": "Hao Zhou, Suman Sourav, Binbin Chen, Ke Yu",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.273931",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文本质是应用研究，而非智能体构建。** 论文的核心贡献是提出一种名为SRLR的**符号回归**方法，用于从工业控制系统（ICS）的输入输出数据中恢复可编程逻辑控制器（PLC）的控制逻辑，目的是检测网络攻击。这是一个典型的**非演化型应用**。它将一种机器学习技术（符号回归）作为工具，应用在“工业控制系统安全”这一特定领域，去解决该领域的“攻击检测”问题。论文完全没有涉及构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——完全不包含我的核心关注点。** 论文摘要和标题中，完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。其核心技术是“Symbolic Regression”，虽然这与演化计算有关，但在此论文中它被用作一种数据拟合和公式发现的工具，而非智能体进行自我演化的机制。 3.  **第三步：排除标准——论文主要贡献属于排除范畴。** 这篇论文的主要贡献明确地落在了排除标准之内。摘要中明确指出，现有机器学习方法“fall short of providing explanation for their decisions”（缺乏决策解释能力），而SRLR的目标是生成“explainable rules”（可解释规则）。同时，整篇论文的主题是“Counter ... Attacks”（反击攻击），这直接对应了排除标准中的 `Security`（安全）。根据筛选规则，只要论文的主要贡献是关于安全或可解释性，就应予以排除。 4.  **第四步：特殊和模糊情况——不适用。** 该论文不涉及推理/规划的Agentic框架，也未提出任何自我演化机制，因此特殊情况的规则不适用。 **最终决策**：综合以上分析，该论文是一篇专注于工业控制系统安全与可解释性的应用研究。它虽然使用了符号回归技术，但其本质是解决特定领域的工程问题，与“LLM智能体及其演化”这一核心研究课题完全无关。因此，应将其排除。"
    },
    {
        "index": "#28",
        "title": "Spectral entropy prior-guided deep feature fusion architecture for magnetic core loss",
        "link": "/arxiv/2512.11334",
        "arxiv_id": "2512.11334",
        "authors": "Cong Yao, Chunye Gong, Jin Zhang",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.266427",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出了一种名为 `SEPI-TFPNet` 的混合深度学习模型，用于更准确地预测电力电子系统中的磁芯损耗。它结合了物理经验模型和数据驱动模型（CNN、注意力机制、LSTM），旨在解决一个特定工程领域（电力电子）的预测问题。 - **是否符合保留标准**: 不符合。这篇论文的核心是**构建一个用于特定任务（磁芯损耗预测）的深度学习模型**，而不是构建、改进或演化LLM智能体。 - **是否符合排除标准**: 完全符合。它属于典型的**“非演化型应用”**。论文将深度学习作为一种工具，应用在“电力电子”和“磁性材料”这一特定领域，以解决该领域的建模精度问题。其研究目标是提升预测准确性和鲁棒性，而非探索智能体的内在机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的关键词。例如：`Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文讨论的是 `deep learning`, `CNN`, `attention mechanism`, `LSTM`, `feature fusion` 等通用的深度学习技术，这些技术被用作解决工程问题的手段，而非构建智能体的核心范式。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文提到了“interpretability”（可解释性），但这只是作为其混合模型相比于纯黑盒模型的一个附带优点，并非论文的主要研究贡献。论文的核心是模型架构和预测性能，因此不触发“安全与对齐”的排除规则。同样，它也不涉及多模态与视觉。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划，更不涉及自我演化机制。因此，特殊情况的规则不适用。 **最终决策**: 综合以上分析，这篇论文的研究方向是“应用于电力电子领域的深度学习预测模型”，与您的研究课题“LLM智能体及其演化”在研究对象、核心贡献和研究目标上存在根本性的差异。它既不涉及LLM，也不涉及智能体的任何核心能力（规划、工具使用、记忆、演化等）。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#36",
        "title": "Insight Miner: A Time Series Analysis Dataset for Cross-Domain Alignment with Natural Language",
        "link": "/arxiv/2512.11251",
        "arxiv_id": "2512.11251",
        "authors": "Yunkai Zhang, Yawen Zhang, Ming Zheng, Kezhen Chen, Chongyang Gao, Ruian Ge, Siyuan Teng, Amine Jelloul, Jinmeng Rao, Xiaoyuan Guo, Chiang-Wei Fang, Zeyu Zheng, Jie Yang",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.275404",
        "filter_reason": "这篇论文不符合你的研究范围。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是应用，而非智能体构建。** 论文的核心贡献是提出了一个名为 `TS-Insights` 的时间序列-语言对齐数据集，以及一个在该数据集上训练的、用于生成时间序列描述的多模态模型 `Insight Miner`。这明确指向了**特定领域（时间序列分析）的应用**。虽然论文中提到了使用了一个 \"agentic workflow\"，但这个工作流是作为**构建数据集的工具**出现的，其本身并不是论文的研究对象或核心贡献。论文的重点在于展示这个数据集和模型的有效性，而不是提出或改进一种新的智能体框架。这完全符合第一步的排除标准：“非演化型应用: 如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。 2.  **正面指标与排除标准的权衡（第二、三步）：关键词具有误导性。** 论文中确实出现了 `agentic workflow` 和 `tools` 等正面指标词汇。然而，仔细分析其上下文，这些词汇是用来描述其数据集构建过程的，即“使用统计工具提取特征，然后用GPT-4合成描述”。这更像是一个自动化脚本或流程，而非一个具有自主规划、记忆或反思能力的智能体框架。论文的核心是**数据集**和**模型**，而不是**智能体**。此外，论文的核心是 `large-scale multimodal model (LMM)`，这属于多模态范畴，虽然不直接排除，但它进一步证实了论文的焦点在于模型处理特定模态（时间序列）的能力，而不是智能体的内在机制。 3.  **特殊情况的澄清（第四步）：不属于智能体推理/规划的范畴。** 论文中提到的 \"agentic workflow\" 并非一种新的智能体规划或推理框架。它是一个固定的、用于数据生成的流程（先提取特征，再生成文本），不涉及智能体在未知环境下的自主决策、多步规划或自我反思。因此，它不符合“保留: 如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理”的条件。 **总结：** 你的核心目标是筛选那些**核心贡献在于构建、改进或演化LLM智能体**的论文。而这篇论文的核心贡献是一个**应用数据集**和一个**应用模型**，其使用的“agentic workflow”仅仅是实现该贡献的辅助手段，而非研究主体。因此，该论文应被排除。"
    },
    {
        "index": "#31",
        "title": "Benchmarking the Generality of Vision-Language-Action Models",
        "link": "/arxiv/2512.11315",
        "arxiv_id": "2512.11315",
        "authors": "Pranav Guruprasad, Sudipta Chowdhury, Harsh Sikka, Mridul Sharma, Helen Lu, Sean Rivera, Aryan Khurana, Hangliang Ren, Yangyue Wang",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.273034",
        "filter_reason": "这篇论文不符合你的研究范围，应被排除。核心判断依据如下： 1.  **核心贡献不符 (第一步)**: 论文的核心贡献是提出了一个名为 \"MultiNet v1.0\" 的**统一基准**，用于评估现有视觉-语言-动作模型的跨领域能力。你的研究目标是筛选那些核心贡献在于**构建、改进或演化**LLM智能体的论文。一个评估基准，无论设计得多好，其本质是**测量和诊断**，而不是**创造或改进**。因此，这篇论文属于评估研究，而非方法论或框架构建研究，直接与你的核心目标相悖。 2.  **命中明确的排除标准 (第三步)**: 论文的研究对象是 \"Vision-Language-Action Models (VLAs)\" 和 \"vision language models (VLMs)\"。这完全命中了你设定的排除标准中的“多模态与视觉”类别。虽然论文评估了智能体能力（如工具使用、多智能体协调），但其研究的核心是**多模态模型**的泛化能力，而不是一个以LLM为核心的、可演化的智能体框架。视觉和多模态在这里是研究的主体，而不是智能体感知环境的工具。 3.  **正面指标的误用 (第二步)**: 尽管摘要中提到了 `Tool Use` 和 `Multi-Agent Coordination` 等正面指标，但需要明确这些词出现的语境。论文是在**定义评估维度**，即用这些能力来衡量现有模型，而不是提出一种新的、更强大的工具使用方法或多智能体协作机制。你的研究焦点是后者（提出新方法），而非前者（用旧标准做评估）。 综上所述，该论文是一篇关于多模态智能体评估的基准测试论文，其核心贡献是“评测工具”而非“智能体本身”或“演化机制”。它虽然与Agentic AI相关，但其研究性质和核心贡献均不在你的筛选范围内。"
    },
    {
        "index": "#39",
        "title": "Latent Variable Causal Discovery under Selection Bias",
        "link": "/arxiv/2512.11219",
        "arxiv_id": "2512.11219",
        "authors": "Haoyue Dai, Yiwen Qiu, Ignavier Ng, Xinshuai Dong, Peter Spirtes, Kun Zhang",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.276891",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出一种名为“秩约束”的**统计方法**，用于在存在“选择偏差”的情况下进行“潜变量因果发现”。它属于统计学和因果推断领域，旨在解决一个理论性的统计问题。 - **与目标对比**: 您的核心目标是筛选关于“构建、改进或演化LLM智能体”的论文。该论文完全没有涉及LLM、智能体框架、多智能体系统或自我演化机制。它不是关于构建一个能自主行动的智能体，而是关于一种分析数据背后因果结构的数学工具。 - **结论**: 根据第一步的排除规则，这篇论文属于“非演化型应用”和“非Agentic的推理”的范畴之外，它根本不属于Agentic AI的研究领域，因此应被**排除**。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何您关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。这进一步确认了它与您的研究焦点无关。 3.  **第三步：排除标准** - 虽然论文不涉及“安全与对齐”或“多模态与视觉”等排除项，但它触犯了最根本的排除原则：**研究主题不符**。 4.  **第四步：处理特殊和模糊情况** - 论文讨论的“推理”是统计层面的因果推理，而非智能体在任务执行中的自主规划和多步推理。因此，不适用保留规则。 **最终决策**: 综合以上分析，该论文是一篇纯粹的统计学与因果推断理论文章，其核心贡献与“LLM智能体及其演化”这一研究课题完全无关。因此，最终判断为 **False**，应予以排除。"
    },
    {
        "index": "#43",
        "title": "Progress over Points: Reframing LM Benchmarks Around Scientific Objectives",
        "link": "/arxiv/2512.11183",
        "arxiv_id": "2512.11183",
        "authors": "Alwin Jin, Sean M. Hendryx, Vaskar Nath",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.283952",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选关于构建、改进或演化LLM智能体的论文，而这篇论文的核心贡献是提出一种新的**基准测试方法论**，而非智能体本身。 以下是根据筛选标准的详细判断过程： 1.  **第一步：核心判断** - 论文的核心是构建、改进或演化LLM智能体吗？**不是**。 - 论文摘要明确指出，其核心贡献是“主张采用以进步为导向的基准测试”，并“实例化了一个基于NanoGPT speedrun的环境”。其目标是“催化对语言建模栈的可复用改进”，并将“基准测试”重新定义为科学进步的载体。 - 这完全符合第一步的排除标准 **3. 基础设施**：该论文主要关注的是如何评估和衡量模型训练的进展，这属于研究基础设施和评估方法论的范畴，而不是智能体架构或能力的创新。 2.  **第二步：正面指标** - 论文中没有出现我关注的核心范式，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 论文也未涉及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 虽然摘要中提到了“新颖算法思想的出现”，但这被描述为使用该基准测试环境所观察到的结果，而不是论文所提出的方法论本身。论文本身并未提出一个能让智能体自我演化或涌现出新能力的框架。 3.  **第三步：排除标准** - 论文不涉及安全、对齐或多模态等排除领域，但这并不改变其核心贡献与我的研究目标不符的事实。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划过程。它关注的是模型训练的效率，这是一个更底层的工程问题。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。它提出的基准测试环境可以被用来评估任何方法（包括未来的自我演化方法）的训练效率，但这篇论文本身并未构建这样的智能体。 **最终决策**: 该论文的本质是关于**评估科学**和**研究基础设施**的，它提出了一种新的基准测试范式来衡量和激励语言模型训练效率的进步。我的研究焦点是**Agentic AI**，即智能体本身的构建、行为和演化。因此，尽管这篇论文可能对整个AI领域有启发，但它并不直接贡献于“LLM智能体及其演化”这一核心课题，应予以排除。"
    },
    {
        "index": "#37",
        "title": "Task-Aware Multi-Expert Architecture For Lifelong Deep Learning",
        "link": "/arxiv/2512.11243",
        "arxiv_id": "2512.11243",
        "authors": "Jianyu Wang, Jacob Nean-Hua Sheikh, Cat P. Le, Hoda Bidkhori",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.275904",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文本质不符** - **论文核心贡献**: 这篇论文的核心是提出了一种名为“Task-Aware Multi-Expert (TAME)”的**持续学习算法**。其目标是解决神经网络在按顺序学习多个任务时的“灾难性遗忘”问题。 - **与我的研究目标对比**: 我的核心目标是筛选关于**构建、改进或演化LLM智能体**的论文。TAME算法虽然涉及“终身学习”，但其本质是一种**模型架构和训练策略**，用于提升基础模型在任务序列上的知识保留能力，而不是构建一个具有自主性、规划能力或工具使用能力的智能体。它属于机器学习中的“持续学习”子领域，而非“Agentic AI”领域。因此，根据第一步的排除标准，它应被排除。 2.  **第二步：正面指标——缺乏关键关注点** - 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 虽然提到了“replay buffer”（重放缓冲区），这是一种记忆形式，但它是持续学习中用于存储历史数据样本的**技术性记忆**，与智能体在复杂环境中进行规划和决策所需的**语义记忆或情景记忆**有本质区别。 - 论文未涉及 `Planning`, `Tool Use`, `Self-Reflection`, `Collaboration` 等任何智能体核心能力。 3.  **第三步：排除标准——不适用** - 论文的主要贡献不是关于安全、对齐或多模态，因此不触发此处的排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化 vs. 持续学习**: 这是最关键的区分点。我的研究焦点“自我演化”指的是智能体通过**主动的反思、与环境交互、获得反馈**来迭代和完善自身的行为策略或能力。而本文的“终身学习”或“持续学习”是指模型被动地学习一系列**预先定义好的任务**，并努力不忘记旧知识。TAME算法本身不具备主动反思或演化的机制，它只是一个更高效的知识管理和迁移框架。因此，它不符合我对“自我演化”的定义，第四步的例外规则不适用。 **最终决策**: 综合以上分析，该论文是一篇关于持续学习算法的研究，其核心贡献在于改进模型架构以应对灾难性遗忘。它并未涉及LLM智能体的构建、多智能体交互或基于反思的自我演化机制。因此，这篇论文与我的研究课题“LLM智能体及其演化”不相关，应予以排除。"
    },
    {
        "index": "#41",
        "title": "Beyond Memorization: Gradient Projection Enables Selective Learning in Diffusion Models",
        "link": "/arxiv/2512.11194",
        "arxiv_id": "2512.11194",
        "authors": "Divya Kothandaraman, Jaclyn Pytlarz",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.283061",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心贡献不符 (第一步核心判断):** 论文的核心贡献是提出了一种名为“梯度投影框架”的新方法，用于在**扩散模型**的训练过程中实现“选择性遗忘”，以防止模型记忆化敏感或专有概念。其本质是针对**生成模型的安全性和隐私保护**问题，提出的一种训练阶段的防御机制。这与您研究目标“构建、改进或演化LLM智能体”有本质区别。论文不涉及任何智能体的构建、规划、工具使用或演化框架。 2.  **命中明确的排除标准 (第三步排除标准):** *   **安全与对齐:** 这是最直接的排除理由。论文摘要明确指出其研究动机是解决“重大安全和知识产权风险”，目标是建立“IP安全和隐私保护的生成AI”。这完全属于您定义的“安全与对齐”排除范畴。 *   **多模态与视觉:** 论文的研究对象是“文本到图像扩散模型”，这是典型的多模态与视觉领域。根据您的规则，除非多模态模型被用作智能体感知环境的工具，否则应被排除。在此论文中，扩散模型本身就是研究的核心，而非工具，因此符合排除条件。 3.  **缺乏正面指标 (第二步正面指标):** 论文中完全没有出现您关注的核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` (智能体记忆), `Self-Correction`, `Collaboration` 等。它提到的“Memorization”是指模型对训练数据的记忆，而非智能体的记忆机制。 综上所述，尽管这篇论文在生成模型安全领域可能是一项有价值的工作，但其研究焦点是**扩散模型的防御机制**，而非**LLM智能体的构建与演化**。它明确属于您设定的“安全与对齐”和“多模态与视觉”两大排除类别，因此应被排除。"
    },
    {
        "index": "#32",
        "title": "QGEC : Quantum Golay Code Error Correction",
        "link": "/arxiv/2512.11307",
        "arxiv_id": "2512.11307",
        "authors": "Hideo Mukai, Hoshitaro Ohnishi",
        "subjects": "Machine Learning, Quantum Physics",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.273483",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 这篇论文的核心贡献是提出了一种名为QGEC（Quantum Golay Code Error Correction）的**量子纠错方法**。它属于量子计算和信息论的交叉领域。 - 论文使用Transformer模型作为**解码器**来评估其提出的QGEC方法的性能。在这里，Transformer（一种LLM的基础架构）是作为一个解决特定领域问题（量子纠错解码）的工具或组件，而不是论文研究的主体。 - 根据筛选标准，这完全符合“**非演化型应用**”的排除条件。论文的本质是将一个已有的模型架构应用到量子计算这一特定领域，去解决该领域的纠错问题，而不是构建、改进或演化LLM智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我的研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 虽然提到了Transformer，但它仅被用作一个功能性的解码模型，不具备任何智能体的特性。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全与对齐、多模态与视觉等排除标准，但第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中Transformer的解码过程不属于智能体的自主规划或多步推理框架（如ReAct）。它是一个针对特定输入（syndrome measurements）进行预测（错误位置）的模型，属于非Agentic的推理范畴。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。它只是比较了在不同编码（Golay code vs. toric code）下，固定架构的Transformer解码器的性能。这不涉及智能体通过经验进行自我完善。 **最终决策**: 综合以上分析，该论文的核心是**量子计算领域的一项应用研究**，它利用Transformer模型作为工具来解决量子纠错问题。它完全没有涉及LLM智能体的构建、规划、记忆、工具使用、多智能体协作或自我演化等核心议题。因此，这篇论文与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#34",
        "title": "Features Emerge as Discrete States: The First Application of SAEs to 3D Representations",
        "link": "/arxiv/2512.11263",
        "arxiv_id": "2512.11263",
        "authors": "Albert Miao, Chenliang Zhou, Jiawei Zhou, Cengiz Oztireli",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.274389",
        "filter_reason": "这篇论文不符合研究范围，应被排除。判断依据如下： 1.  **第一步：核心判断——论文本质是模型可解释性，而非智能体构建。** 论文的核心贡献是“首次将稀疏自编码器（SAEs）应用于3D表征”，旨在分析和解释一个3D重建VAE模型的内部特征。其研究目标是理解模型的“特征学习动态”和“隐藏状态”，这属于模型可解释性（Interpretability / Explainability）的范畴。它没有构建、改进或演化任何形式的LLM智能体。因此，根据第一步的排除规则，这属于“非演化型应用”，即将一种分析技术（SAE）应用于特定领域（3D视觉）去理解该领域的模型，应被排除。 2.  **第三步：排除标准——论文明确命中两个排除类别。** *   **安全与对齐：** 论文的核心是关于`Interpretability`（可解释性）和`Explainability`（XAI）。摘要中明确提到其工作是“translating the hidden state into human ideas”（将隐藏状态转化为人类可理解的想法）和“provides a framework to explain the model's feature learning dynamics”（提供一个解释模型特征学习动态的框架）。这完全符合排除标准中关于`Interpretability`和`Explainability`的描述。 *   **多模态与视觉：** 论文的研究对象是“3D Representations”（3D表征）和“3D reconstruction VAE”，这明确属于`3D Vision`的研究领域。虽然智能体可以使用视觉作为工具，但在这篇论文中，视觉模型本身就是被分析和解释的核心，而不是智能体框架的一部分。 3.  **第二步：正面指标——论文完全不包含核心关注点。** 论文的标题和摘要中完全没有出现任何与我的研究焦点相关的关键词，例如`Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration`等。这进一步证实了它与我的研究目标无关。 **总结：** 该论文是一项关于模型可解释性的前沿研究，但其焦点是3D视觉模型的内部机制，而非LLM智能体的构建、协作或演化。它直接命中了“安全与对齐”中的可解释性以及“多模态与视觉”这两项明确的排除标准。因此，尽管它可能是一篇优秀的论文，但与“LLM智能体及其演化”这一核心课题完全无关。"
    },
    {
        "index": "#42",
        "title": "On the failure of ReLU activation for physics-informed machine learning",
        "link": "/arxiv/2512.11184",
        "arxiv_id": "2512.11184",
        "authors": "Conor Rowan",
        "subjects": "Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.283474",
        "filter_reason": "这篇论文不符合研究范围，应予以排除。我的判断过程如下： 1.  **第一步：核心判断——论文本质不符** 该论文的核心贡献是**诊断了ReLU激活函数在物理信息机器学习（Physics-Informed Machine Learning）中表现不佳的根本原因**。它指出，问题源于自动微分在处理ReLU不连续性时无法正确计算二阶导数，从而导致梯度错误。这属于典型的**将机器学习技术（神经网络）应用于特定领域（物理学、微分方程求解）的研究**。其本质是解决该领域的数值计算和模型训练的技术细节问题，而非构建、改进或演化LLM智能体。根据筛选标准第一步的排除规则1（非演化型应用），应予以排除。 2.  **第二步：正面指标——完全不匹配** 论文的研究焦点是神经网络激活函数和自动微分，与我的核心关注点完全无关。论文中完全没有出现任何与研究焦点相关的正面指标，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。 3.  **第三步与第四步：排除标准与特殊情况** 该论文不涉及安全对齐或多模态等排除领域，但其核心内容与研究目标的偏差是根本性的。它既不涉及智能体的推理与规划框架，也不涉及任何自我演化机制。 **最终决策**: 该论文的研究对象是神经网络在科学计算中的技术细节，与LLM智能体的构建、协作或演化机制毫无关联。它属于一个完全不同的研究领域（科学计算与数值分析），因此与研究目标严重不符，最终判断为 **False**。"
    },
    {
        "index": "#45",
        "title": "Harnessing Rich Multi-Modal Data for Spatial-Temporal Homophily-Embedded Graph Learning Across Domains and Localities",
        "link": "/arxiv/2512.11178",
        "arxiv_id": "2512.11178",
        "authors": "Takuya Kurihana, Xiaojian Zhang, Wing Yee Au, Hon Yung Wong",
        "subjects": "Machine Learning, Social and Information Networks",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.285009",
        "filter_reason": "这篇论文不符合您的研究范围，应予以排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个**异构数据融合管道**和一种**图学习方法**，用于解决智慧城市领域的跨领域、跨地域数据分析问题。其本质是**将一种机器学习模型（图学习）作为工具，应用到特定领域（智慧城市分析）**，以处理和预测城市数据（如交通、犯罪报告）。这完全符合筛选标准中的**排除规则 #1：非演化型应用**。论文没有构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等任何核心范式或智能体能力。这进一步确认了该论文与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的研究焦点是**数据科学**和**城市计算**，而非人工智能安全、对齐或多模态智能体。虽然标题中提到了 \"Multi-Modal Data\"，但这里的“多模态”指的是城市数据的异构性（如时间序列、空间数据、报告文本等），其目的是为了数据融合，而不是作为智能体感知和交互环境的工具。因此，这不属于您关注的多模态智能体范畴。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体规划或自我演化相关的特殊情况。它提出的框架是一个静态的数据处理和模型训练流程，不具备自主规划、工具使用或自我完善的能力。 **最终决策**： 综合以上分析，这篇论文的核心是**面向智慧城市应用的数据融合与图学习框架**，属于典型的应用型研究。它没有涉及LLM智能体的构建、多智能体交互或自我演化机制。因此，它完全不符合您关于“LLM智能体及其演化”的研究课题要求，应被明确排除。"
    },
    {
        "index": "#47",
        "title": "The Vekua Layer: Exact Physical Priors for Implicit Neural Representations via Generalized Analytic Functions",
        "link": "/arxiv/2512.11138",
        "arxiv_id": "2512.11138",
        "authors": "Vladimer Khasia",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.285922",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一种名为“Vekua Layer (VL)”的新型神经网络层，它是一种用于隐式神经表示（INRs）的可微分谱方法。其本质是**一种改进的神经网络架构/数学方法**，旨在更高效、更精确地求解偏微分方程（PDEs）和表示物理场。这与我的核心目标——**构建、改进或演化LLM智能体**——完全无关。论文中完全没有提及LLM、智能体框架、或任何与Agentic AI相关的概念。因此，根据第一步的核心判断标准，该论文应被**排除**。 2.  **第二步：正面指标** 论文中没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等。其研究焦点是物理先验、谱方法和偏微分方程求解，属于科学计算和神经表示领域，而非智能体研究。 3.  **第三步：排除标准** 虽然论文没有直接触及安全与对齐（Safety/Alignment）或多模态（Vision）等排除关键词，但这并不代表它符合要求。它的研究领域与我的课题存在根本性的偏差。它属于一种**非演化型应用**，甚至更进一步，它连LLM或智能体框架都没有使用，而是提出了一种底层的、通用的神经网络技术来解决特定领域（物理模拟）的问题。 4.  **第四步：处理特殊和模糊情况** 论文不涉及任何与智能体相关的推理/规划框架（如ReAct），也不涉及任何自我演化机制。它提出的“迭代”是指传统的梯度下降优化过程，而其核心创新恰恰在于**避免**了这种迭代优化。因此，所有特殊情况均不适用。 **最终决策**: 该论文的核心贡献是提出一种用于科学计算的神经网络层，其研究目标是改进物理场的表示和偏微分方程的求解效率。这与我关于“LLM智能体及其演化”的研究课题在研究对象、核心贡献和研究范式上均无交集。因此，这篇论文应被明确排除。"
    },
    {
        "index": "#54",
        "title": "Memoryless Policy Iteration for Episodic POMDPs",
        "link": "/arxiv/2512.11082",
        "arxiv_id": "2512.11082",
        "authors": "Roy van Zuijlen, Duarte Antunes",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.293301",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断依据如下： 1.  **核心贡献不匹配 (第一步)**: *   论文的核心贡献是提出了一种新的算法（\"Memoryless Policy Iteration\"），用于解决经典的强化学习问题——部分可观察马尔可夫决策过程。这是一个关于**通用智能体决策理论**的算法研究，属于经典的强化学习领域。 *   我的研究目标是 **\"LLM智能体及其演化\"**，核心关注点是**基于大语言模型构建的智能体**。这篇论文从头至尾没有提及大语言模型、Transformer或任何与LLM相关的技术。因此，它的核心贡献并非构建、改进或演化LLM智能体。 2.  **缺乏关键正面指标 (第二步)**: *   尽管论文标题和摘要中出现了 \"Policy\"（策略）、\"POMDPs\"（与智能体决策相关）等词汇，但它完全缺失了我研究范围内的核心范式关键词，如 `LLM-based Agents`, `Agentic AI`, `Self-Evolving` 等。 *   它所讨论的 \"Memoryless\"（无记忆）和 \"Planning\"（规划）是在POMDP的数学框架下进行的，这与LLM智能体通过记忆模块、工具调用和自我反思进行规划的概念有本质区别。 3.  **不属于特殊情况的例外 (第四步)**: *   这篇论文不属于“自我演化的应用”这一例外情况，因为它没有提出任何新的“自我演化”机制。其“Policy Iteration”（策略迭代）是一种经典的优化算法，而非智能体通过经验或反思进行自我完善和迭代的机制。 **结论**: 该论文是一篇关于经典强化学习算法的理论研究，虽然其研究对象（智能体策略）与我的研究有遥远的理论联系，但它完全脱离了“LLM”这一核心载体。因此，它严格地属于“非演化型应用”或更准确地说是“非LLM基础的智能体算法研究”，不符合我为“LLM智能体及其演化”课题设定的筛选标准。"
    },
    {
        "index": "#52",
        "title": "Investigating ECG Diagnosis with Ambiguous Labels using Partial Label Learning",
        "link": "/arxiv/2512.11095",
        "arxiv_id": "2512.11095",
        "authors": "Sana Rahmani, Javad Hashemi, Ali Etemad",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.292241",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是首次系统性地研究了“部分标签学习”这一机器学习方法在“心电图（ECG）诊断”这一特定医疗领域的应用。它评估了多种PLL算法在处理ECG诊断中标签歧义问题的有效性。 - **是否符合要求**: 这完全符合筛选标准中的**排除项1：“非演化型应用”**。论文将一个已有的机器学习框架（PLL）作为工具，应用到一个特定领域（医疗/生物）去解决该领域的问题（ECG诊断的标签歧义）。它没有构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文不涉及安全与对齐或多模态等排除项，但它已经因为第一步的核心判断被排除。这一步的排除标准是补充性的，用于处理那些看似相关但实际焦点偏离的论文。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的自主规划或多步推理框架。 - **自我演化的应用**: 论文不涉及任何“自我演化”机制。它应用的是已有的PLL算法，而不是提出一种新的能让智能体自我完善的方法。因此，关于“自我演化的应用”的例外保留规则不适用。 **最终决策**: 该论文是一篇典型的医疗AI应用研究，其核心是解决特定领域（ECG诊断）的数据和模型问题，而非研究LLM智能体的内在机制、架构或演化能力。它的研究范式是“应用机器学习方法解决领域问题”，与您“构建和演化LLM智能体”的核心目标完全不符。因此，应果断排除。"
    },
    {
        "index": "#62",
        "title": "Learning Minimal Representations of Fermionic Ground States",
        "link": "/arxiv/2512.11767",
        "arxiv_id": "2512.11767",
        "authors": "Felix Frohnert, Emiel Koridon, Stefano Polla",
        "subjects": "Quantum Physics, Strongly Correlated Electrons, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.297884",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是提出了一种**用于量子物理计算**的无监督机器学习框架。它利用自编码器神经网络来发现和压缩“费米子基态”的表示，并将训练好的解码器作为一种变分拟设来求解量子系统的能量最小化问题。 - **是否符合要求**: 这篇论文的本质是将一个通用的机器学习模型（自编码器，而非LLM）作为工具，应用在**量子物理**这一特定领域，以解决该领域的科学计算问题。这完全符合筛选标准中第一条排除规则：“非演化型应用”，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。尽管这里用的是自编码器而非LLM，但其应用逻辑完全一致。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词。例如，没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文中的“Tool Use”指的是将解码器用作物理计算的“工具”，这与智能体自主调用外部API或工具的Agentic能力完全不同。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然该论文不涉及安全对齐或多模态等排除项，但它已经触发了第一步中更根本的“非演化型应用”排除规则。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划框架，也不涉及任何自我演化机制。因此，特殊情况的例外条款不适用。 **最终决策**: 综合以上分析，这篇论文是一篇典型的**交叉学科应用研究**，其核心贡献在于**计算物理领域**，而非人工智能智能体的构建、改进或演化。它研究的对象是量子系统，方法是自编码器，目标是解决物理问题，与您关于“LLM智能体及其演化”的研究课题在研究对象、方法和目标上均无交集。因此，应果断排除。"
    },
    {
        "index": "#58",
        "title": "MoB: Mixture of Bidders",
        "link": "/arxiv/2512.10969",
        "arxiv_id": "2512.10969",
        "authors": "Dev Vyas",
        "subjects": "Machine Learning",
        "date": "2025-11-30",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.295471",
        "filter_reason": "这篇论文不符合你的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“Mixture of Bidders (MoB)”的新颖神经网络架构，用于解决Mixture of Experts (MoE)模型在持续学习场景下遇到的灾难性遗忘问题。它通过引入VCG拍卖机制来替代传统的学习门控网络，从而实现专家的无状态路由。 - **本质分析**: 这是一篇关于**神经网络模型架构**和**持续学习算法**的论文。它关注的是如何改进模型内部的参数更新和模块选择机制，以防止知识遗忘。 - **是否符合**: **不符合**。论文的核心是构建一个更优的模型架构，而不是构建、改进或演化一个具有自主规划、工具使用或反思能力的LLM智能体。它属于“基础设施”或模型底层优化的范畴，而非Agentic AI。 2.  **第二步：正面指标——是否包含核心关注点？** 论文中出现了“autonomous self-monitoring experts”等看似相关的词汇，但需要深入分析其含义。 - **智能体能力**: 论文不涉及`Planning`、`Tool Use`、`Memory`（在智能体语境下）、`Self-Reflection`等。其“self-monitoring”是指专家模块内部检测自身知识巩固状态的固定算法，而非智能体对自身行为和目标的反思。 - **多智能体**: 论文中的“专家”和“竞标”是模型路由机制的**隐喻**，而非真正的多智能体系统。这些“专家”之间没有`Communication`、`Collaboration`或`Negotiation`，它们只是通过一个中心化的拍卖机制被动地竞争处理数据的权利。 - **演化机制**: 论文解决了持续学习中的“遗忘”问题，但这不等于“自我演化”。其提出的VCG拍卖机制是一个**固定的、预先设计好的算法**，而不是智能体通过与环境交互、反思经验来动态调整和自我完善的迭代过程。 - **结论**: 论文没有命中任何核心正面指标。 3.  **第三步：排除标准——是否为研究焦点之外？** 论文不涉及安全、对齐或多模态等排除标准，但其核心内容已在第一步被判定为模型架构研究，因此无需深入此步。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划框架。 - **自我演化的应用**: 论文的核心是提出一种新的路由机制，而不是一种新的“自我演化”机制。因此，关于“自我演化应用的例外”规则不适用。 **最终决策**: 综合以上分析，这篇论文《MoB: Mixture of Bidders》虽然创新性地使用了博弈论思想来改进模型架构，但其本质是针对持续学习的模型内部机制优化，而非关于LLM智能体的构建、协作或演化。它研究的“专家”是模型组件，而非自主智能体。因此，该论文与你的研究目标“LLM智能体及其演化”不符，应予以排除。"
    },
    {
        "index": "#57",
        "title": "TECM*: A Data-Driven Assessment to Reinforcement Learning Methods and Application to Heparin Treatment Strategy for Surgical Sepsis",
        "link": "/arxiv/2512.10973",
        "arxiv_id": "2512.10973",
        "authors": "Jiang Liu, Yujie Li, Chan Zhou, Yihao Xie, Qilong Sun, Xin Shu, Peiwei Li, Chunyong Yang, Yiziting Zhu, Jiaqi Zhu, Yuwen Chen, Bo An, Hao Wu, Bin Yi",
        "subjects": "Machine Learning",
        "date": "2025-12-02",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.295043",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献是提出一个**基于强化学习（RL）的框架**，用于优化针对外科脓毒症患者的肝素治疗方案。其创新点在于：1) 将离散的临床评分转换为连续值以用于RL的状态和奖励函数；2) 提出一个名为TECM的评估矩阵来衡量治疗效果。 - **与筛选标准的匹配**: 这篇论文的本质是**将强化学习方法应用到一个特定的垂直领域（医疗）**，以解决该领域的具体问题（优化肝素治疗）。这完全符合**排除标准 1: 非演化型应用**。它并没有构建、改进或演化一个通用的LLM智能体框架，而是将RL作为一种工具来解决领域问题。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中完全没有提及任何与我的研究焦点相关的关键词或概念。例如，它没有涉及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning` (在智能体框架层面), `Tool Use`, `Memory`, `Self-Reflection` 等。论文中的“策略”是RL策略，而非智能体的自主规划。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文虽然提到了“interpretable”（可解释），但这只是对其框架特性的一个描述，并非其核心研究贡献。其核心贡献是治疗优化框架本身，而不是可解释性方法的研究。因此，它不完全属于“安全与对齐”的排除范畴，但已经通过第一步被排除了。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“策略优化”是RL算法在特定状态空间和奖励函数下的学习过程，不属于我所关注的“智能体如何进行自主规划和多步推理”的范畴。 - **自我演化的应用**: 论文没有提出任何新的“自我演化”机制。它应用的是标准的RL算法（如DQN, CQL），因此不适用该例外规则。 **最终决策**: 综合以上分析，这篇论文是一篇典型的AI应用研究，它利用强化学习技术解决医疗领域的具体问题。它的核心贡献在于领域应用和方法论适配，而非构建或演化LLM智能体。因此，它完全不符合我关于“LLM智能体及其演化”的研究课题要求，应予以排除。"
    },
    {
        "index": "#63",
        "title": "LUCID: Learning-Enabled Uncertainty-Aware Certification of Stochastic Dynamical Systems",
        "link": "/arxiv/2512.11750",
        "arxiv_id": "2512.11750",
        "authors": "Ernesto Casablanca, Oliver Schön, Paolo Zuliani, Sadegh Soudjani",
        "subjects": "Systems and Control, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.298382",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建了一个名为 LUCID 的**安全认证引擎**，用于为黑盒随机动力系统提供形式化的安全保证。其本质是**AI安全**和**形式化验证**领域的研究，而非构建、改进或演化LLM智能体。它关注的是如何“证明”一个系统是安全的，而不是如何让一个智能体变得更智能或更自主。这直接命中了第一步中的“基础设施”排除规则，因为它是一个用于验证的工具，而非智能体本身。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文的标题和摘要反复强调其核心目标是“Ensuring the safety”（确保安全）、“certifying safety”（认证安全）和“formal safety guarantees”（形式化的安全保证）。根据我的筛选标准，只要论文的主要贡献是关于 `Safety`（安全），就应一律排除。这篇论文是典型的AI安全研究，与我的研究焦点“Agentic AI”有本质区别。 3.  **正面指标 (第二步):** 论文中完全没有出现我所关注的核心范式和能力相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与我的研究目标无关。 4.  **特殊和模糊情况 (第四步):** 该论文不涉及任何关于智能体推理/规划或自我演化的内容，因此不适用特殊情况的例外规则。 **总结:** 该论文的核心贡献是开发一个用于**安全认证**的工具，属于AI安全和形式化方法的范畴。它既不涉及LLM智能体的构建、协作或演化，也不关注智能体的核心能力（如规划、工具使用）。其研究焦点“安全”明确属于我的排除标准。因此，尽管它涉及“AI-enabled systems”，但其研究目标与我的“LLM智能体及其演化”课题完全不同，应予以排除。"
    },
    {
        "index": "#65",
        "title": "Stable spectral neural operator for learning stiff PDE systems from limited data",
        "link": "/arxiv/2512.11686",
        "arxiv_id": "2512.11686",
        "authors": "Rui Zhang, Han Wan, Yang Liu, Hao Sun",
        "subjects": "Computational Physics, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.299433",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文本质分析** 论文的核心贡献是提出了一种名为“稳定谱神经算子”的新型神经网络架构（SSNO），用于从稀疏数据中学习刚性偏微分方程（PDE）系统。这是一个典型的**科学计算**或**物理信息神经网络**领域的研究。它旨在解决一个特定领域（科学和工程）的建模问题，而不是构建或研究智能体本身。因此，该论文完全符合第一步排除标准中的第一条：**“非演化型应用”**，即它将一种新的神经网络模型作为工具应用到了特定领域（PDE建模），其核心贡献在于模型架构本身，而非智能体的构建、改进或演化。 2.  **第二步：正面指标——核心关注点缺失** 论文的标题和摘要中完全没有出现任何与我核心关注点相关的正面指标。例如，它没有提及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何关键词。其讨论的核心是“神经算子”、“PDE系统”、“时空动力学”和“频域”，这些都与我的研究焦点无关。 3.  **第三步：排除标准——不适用但进一步确认** 虽然这篇论文不涉及安全、对齐或多模态等排除标准，但这并不改变其被排除的命运。其根本原因在于第一步的核心判断，它属于“非演化型应用”，这已经足够将其排除。 4.  **第四步：特殊和模糊情况处理** 该论文不涉及任何与智能体相关的推理或规划，更没有提出任何“自我演化”机制。SSNO是一个固定的、训练后不再改变的模型，它不具备通过经验、反思或环境反馈进行自我完善的能力。因此，关于自我演化应用的例外情况也不适用。 **最终决策**: 综合以上分析，这篇论文的核心是提出一种用于科学计算的新型神经网络架构，属于应用型研究，与“LLM智能体及其演化”这一研究课题的内核——即构建、改进和演化具有自主性的智能体——完全偏离。因此，我做出**排除**的最终判断。"
    },
    {
        "index": "#68",
        "title": "Neural Network-based Partial-Linear Single-Index Models for Environmental Mixtures Analysis",
        "link": "/arxiv/2512.11593",
        "arxiv_id": "2512.11593",
        "authors": "Hyungrok Do, Yuyan Wang, Mengling Liu, Myeonggyun Lee",
        "subjects": "Applications, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.300900",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 `NeuralPLSI` 的新颖神经网络模型框架，用于解决环境健康领域的特定问题——分析复杂环境混合物对健康的影响。这完全符合筛选标准中的 **排除规则1：非演化型应用**。该论文并非关于构建、改进或演化LLM智能体，而是将一种新的深度学习模型（一种半参数回归模型）作为工具应用到了一个特定的科学领域（环境健康）。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我研究焦点相关的正面指标。摘要和标题中未提及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等任何核心概念。其方法论是“神经网络”和“半参数回归”，与Agentic AI的范式无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文提到了 `interpretability`（可解释性），但这并非其主要贡献，而是其模型设计的一个特性（“bridges semiparametric regression modeling interpretability...”）。因此，它不直接触犯“安全与对齐”的排除规则，但其核心内容已经在此前的步骤中被排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划框架（如ReAct, ToT），也没有提出任何自我演化机制。它是一个标准的监督学习模型，用于预测和推断，因此不适用任何例外保留规则。 **最终决策**: 综合以上分析，这篇论文的本质是应用机器学习研究，而非Agentic AI研究。它的核心目标是解决环境健康领域的统计建模问题，而不是构建或演化具有自主性、规划能力或协作能力的LLM智能体。因此，它与我的研究课题“LLM智能体及其演化”完全不相关，应予以排除。"
    },
    {
        "index": "#64",
        "title": "ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning",
        "link": "/arxiv/2512.11727",
        "arxiv_id": "2512.11727",
        "authors": "Yuze He, Ferdi Kossmann, Srinivasan Seshan, Peter Steenkiste",
        "subjects": "Distributed, Parallel, and Cluster Computing, Machine Learning, Networking and Internet Architecture",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.298897",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为ECCO的**视频分析框架**，旨在通过利用摄像头间的相关性来**降低连续学习（continuous retraining）的计算和通信成本**。这完全符合第一步中的排除标准： *   **非演化型应用**: 论文将一个连续学习框架应用到了**视频分析**这一特定领域，以解决该领域模型重训练成本高的问题。它的目标是优化系统效率和可扩展性，而不是构建或演化一个具有自主性的智能体。 *   **基础设施**: 论文明确提出了“GPU分配器”和“传输控制器”，其核心贡献在于系统层面的资源优化和部署效率，这属于基础设施研究的范畴。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我研究焦点相关的正面指标。它没有提及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等任何核心概念。虽然提到了“continuous learning”，但这指的是模型参数的更新，而非智能体层面的自我反思或能力演化。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，这篇论文直接命中了排除标准。论文的整个研究背景是**视频分析**和**视觉任务**，属于 `Vision` 范畴。根据规则，除非视觉是作为智能体感知环境的工具，否则应排除。在此论文中，视觉是研究的核心主题，而非工具。 4.  **第四步：处理特殊和模糊情况** 论文中的“continuous learning”可能让人联想到“自我演化”。但根据核心规则，这并不适用。 *   **自我演化的应用**: 该例外情况要求论文的核心贡献是提出一种**新的“自我演化”机制**。ECCO的机制（为相似漂移的摄像头组训练共享模型）是一种针对特定视频分析任务的**系统级优化策略**，而不是一种通用的、可迁移的智能体自我完善或迭代演化的方法论。因此，该例外情况不成立。 **最终决策**: 综合以上分析，这篇论文的本质是关于**视频分析系统的资源优化**，而非关于**LLM智能体的构建、协作或演化**。它的研究问题、技术方案和评估指标都与我的核心目标“LLM智能体及其演化”相去甚远。因此，应予以排除。"
    },
    {
        "index": "#49",
        "title": "Refining Graphical Neural Network Predictions Using Flow Matching for Optimal Power Flow with Constraint-Satisfaction Guarantee",
        "link": "/arxiv/2512.11127",
        "arxiv_id": "2512.11127",
        "authors": "Kshitiz Khanal",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.286863",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文本质是“非演化型应用”** 论文的核心贡献是提出一个结合图神经网络（GNN）和连续流匹配（CFM）的两阶段框架，用于解决电力系统领域的一个特定问题——直流最优潮流（DC-OPF）。其目标是加速该领域问题的求解，并保证解的物理可行性。这完全符合筛选标准中“非演化型应用”的定义：**将一个新颖的机器学习方法（GNN+CFM）作为工具应用到特定领域（电力系统）去解决该领域的问题**。论文的焦点是解决DC-OPF问题，而不是构建一个通用的、具有自主能力的LLM智能体。 2.  **与核心研究焦点不符** *   **单智能体**: 论文中的框架不具备智能体的核心特征。它没有自主的`Planning`（规划）过程，没有`Memory`（记忆）机制，不涉及`Tool Use`（工具使用），也没有`Self-Reflection`（自我反思）。它是一个针对特定优化任务的端到端模型，而非一个能够自主决策和行动的智能体。 *   **多智能体**: 论文完全没有涉及多智能体系统，没有讨论智能体间的`Collaboration`（协作）、`Communication`（通信）或`Social Learning`（社会学习）。 *   **自我演化**: 论文中的第二阶段“Refining”（精炼）是关键，但这并非“自我演化”。这里的精炼是通过CFM这一数学优化技术，将第一阶段GNN生成的可行解向最优解调整。这个过程是模型设计的一部分，是针对**输出结果**的数学优化，而不是**智能体本身**通过经验、反思或环境反馈进行的自我完善和迭代。它不符合“Self-Evolving”的内涵。 3.  **缺乏正面指标，且模型基础非LLM** 论文摘要中完全没有出现任何核心范式或智能体能力相关的正面指标（如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Improvement` 等）。更重要的是，论文的核心模型是**图神经网络（GNN）**，而不是**大语言模型（LLM）**。我的研究课题是“LLM智能体及其演化”，一个不以LLM为基础的模型从根本上就偏离了研究范围。 **总结**: 该论文是一篇优秀的、将前沿机器学习技术应用于工程领域的交叉学科研究。然而，它的核心贡献在于**应用创新**，而非**智能体架构或演化机制的创新**。它研究的是一个解决特定领域问题的计算框架，而不是一个具有自主性、规划能力和演化能力的Agentic AI。因此，根据第一步的核心判断标准，这篇论文应被明确排除。"
    },
    {
        "index": "#74",
        "title": "FRQI Pairs method for image classification using Quantum Recurrent Neural Network",
        "link": "/arxiv/2512.11499",
        "arxiv_id": "2512.11499",
        "authors": "Rafał Potempa, Michał Kordasz, Sundas Naqeeb Khan, Krzysztof Werner, Kamil Wereszczyński, Krzysztof Simiński, Krzysztof A. Cyran",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.302958",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“FRQI Pairs”的新方法，该方法结合了量子循环神经网络（QRNN）和一种量子图像表示（FRQI），用于解决**图像分类**问题。这完全符合筛选标准中的**排除项 1: 非演化型应用**。论文的本质是将一种新颖的量子机器学习模型应用于一个特定领域（计算机视觉），而不是构建、改进或演化一个LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与您研究焦点相关的正面指标。它没有提及 `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心范式或智能体能力。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的。论文的核心是**图像分类**，这明确属于筛选标准中的**排除项：多模态与视觉**。虽然该研究使用了量子计算这一前沿技术，但其应用场景和核心贡献是视觉任务，而非将视觉作为智能体感知环境的工具。 4.  **第四步：处理特殊和模糊情况** 本论文情况非常清晰，不涉及任何需要特殊处理的模糊情况。它既不是关于智能体的推理/规划，也没有提出任何自我演化机制。 **最终决策**：综合以上分析，该论文的核心贡献是量子机器学习在图像分类领域的应用，与“LLM智能体及其演化”这一研究课题的核心目标（构建、改进或演化智能体）完全偏离。因此，应果断排除。"
    },
    {
        "index": "#69",
        "title": "Safe Bayesian optimization across noise models via scenario programming",
        "link": "/arxiv/2512.11580",
        "arxiv_id": "2512.11580",
        "authors": "Abdullah Tokmak, Thomas B. Schön, Dominik Baumann",
        "subjects": "Optimization and Control, Machine Learning, Systems and Control",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.301236",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断依据如下： 1.  **核心贡献不符 (第一步核心判断):** 论文的核心贡献是提出一种新的“安全贝叶叶斯优化”算法。贝叶斯优化是一种用于黑盒函数优化的机器学习技术，而非构建智能体的框架。论文的目标是“安全地调整控制策略”，这属于经典的控制理论和优化领域，而不是构建、改进或演化LLM智能体。因此，它属于“非演化型应用”，即将一种算法（Safe BO）应用到特定领域（机器人控制）来解决该领域的问题。 2.  **命中明确的排除标准 (第三步排除标准):** 论文的标题和摘要反复强调“Safe Bayesian optimization”和“safety guarantees”。根据我的筛选标准，只要论文的主要贡献是关于 `Safety` (安全)，就应该被排除。这篇论文的核心创新点就在于其安全保证机制，因此它完全符合排除条件。 3.  **缺乏核心关注点 (第二步正面指标):** 论文中完全没有出现任何与我研究焦点相关的关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步证明了它与我的研究课题无关。 综上所述，尽管这篇论文在安全和优化领域可能是一项有价值的研究，但其研究对象是贝叶斯优化算法，而非LLM智能体。它的核心贡献是算法的安全性，这与我关注的“LLM智能体及其演化”这一核心目标完全偏离。因此，应予以排除。"
    },
    {
        "index": "#72",
        "title": "Super-Resolved Canopy Height Mapping from Sentinel-2 Time Series Using LiDAR HD Reference Data across Metropolitan France",
        "link": "/arxiv/2512.11524",
        "arxiv_id": "2512.11524",
        "authors": "Ekaterina Kalinicheva, Florian Helen, Stéphane Mermoz, Florian Mouret, Milena Planells",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.302273",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 该论文的核心贡献是提出了一个名为 `THREASURE-Net` 的深度学习框架，用于从卫星时间序列数据中生成高分辨率的树高图。这是一个典型的**非演化型应用**。它将深度学习模型作为工具，应用于遥感领域解决一个具体的科学问题（森林监测），而不是研究如何构建、改进或演化LLM智能体本身。 - **结论**: 根据第一步的筛选标准，该论文应被**排除**。 2.  **第二步：正面指标** - 论文摘要中完全没有出现任何与您核心关注点相关的关键词或概念，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - **结论**: 该论文不满足任何正面指标。 3.  **第三步：排除标准** - 论文的研究核心是处理 `Sentinel-2` 卫星影像和 `LiDAR` 数据，这属于**视觉和多模态**研究的范畴。根据您的规则，除非这些视觉技术被用作智能体感知环境的工具，否则应被排除。在此论文中，视觉处理本身就是研究的核心，而非服务于智能体。 - **结论**: 该论文符合排除标准。 4.  **第四步：处理特殊和模糊情况** - 论文没有涉及智能体的规划或推理框架，它是一个端到端的回归和超分辨率模型。 - 论文也没有提出任何“自我演化”机制，其模型是经过一次训练后进行评估的，不具备自我完善和迭代的能力。 - **结论**: 特殊情况的例外条款不适用。 **最终决策**: 综合以上分析，这篇论文是一篇专注于遥感应用和计算机视觉技术的论文，其核心贡献是解决特定领域（林业监测）的问题，与您关于“LLM智能体及其演化”的研究课题（包括单智能体、多智能体和自我演化）完全无关。因此，最终判断为 **False**（排除）。"
    },
    {
        "index": "#51",
        "title": "Limits and Gains of Test-Time Scaling in Vision-Language Reasoning",
        "link": "/arxiv/2512.11109",
        "arxiv_id": "2512.11109",
        "authors": "Mohammadjavad Ahmadpour, Amirmahdi Meighani, Payam Taebi, Omid Ghahroodi, Amirmohammad Izadi, Mahdieh Soleymani Baghshah",
        "subjects": "Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.291653",
        "filter_reason": "这篇论文不符合你的研究范围，核心原因如下： 1.  **核心贡献不符 (第一步核心判断)**: 论文的核心贡献是一项关于“测试时缩放”在“视觉语言模型”上应用的**实证研究**，它分析和评估了现有方法（如迭代式自我完善）的“局限性与收益”。它并没有提出一个**新的LLM智能体构建、改进或演化的方法论或框架**。你的目标是筛选那些核心贡献在于“构建”或“改进”智能体本身的论文，而这篇论文的性质更偏向于“分析”和“评估”。 2.  **触发了明确的排除标准 (第三步排除标准)**: 论文的研究对象是“视觉语言模型”和“视觉语言推理”。根据你的筛选标准，主要关注`Vision`, `Vision-Language`, `VLMs`的论文应被排除，除非它们仅被用作智能体感知环境的工具。在这篇论文中，多模态推理本身就是研究的核心主题，而不是一个更大智能体框架的附属部分。因此，它直接触发了排除规则。 3.  **对“自我演化”的理解偏差 (第四步特殊情况)**: 虽然论文提到了“迭代式自我完善”，这与你的“自我演化”方向相关。但是，根据筛选规则，只有当论文的核心贡献是**提出一种新的自我演化机制**时才应保留。本文仅仅是**应用并分析**了一个已有的自我完善技术，并未提出新机制。因此，这个例外情况不适用。 综上所述，该论文本质上是一篇关于多模态模型推理优化的研究，其焦点在于VLMs而非Agentic AI的架构或演化。尽管它涉及了自我完善等概念，但其研究核心和贡献与你的“LLM智能体及其演化”课题目标不一致，故应排除。"
    },
    {
        "index": "#70",
        "title": "In-Context Learning for Seismic Data Processing",
        "link": "/arxiv/2512.11575",
        "arxiv_id": "2512.11575",
        "authors": "Fabian Fuchs, Mario Ruben Fernandez, Norman Ettrich, Janis Keuper",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.301604",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是“非演化型应用”** 论文的核心贡献是提出了一种名为 `ContextSeisNet` 的模型，并将其应用于**地震数据处理**这一特定领域。其目标是解决该领域内的具体问题（如空间不一致性、用户控制缺失）。这完全符合筛选标准中“排除”项的第一条：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如生物、医疗、金融、法律、机器人控制等）”。在这里，`ContextSeisNet`（一种情境学习模型）就是被用作解决地球物理领域问题的工具。 2.  **第二步：缺乏正面指标** 论文摘要中完全没有出现您关注的核心范式和能力关键词。例如，它没有涉及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，它也没有讨论智能体的核心能力，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 或多智能体间的 `Collaboration`。论文的“in-context learning”是指模型根据输入的示例进行调整，这是一种模型能力，而非一个自主智能体的框架。 3.  **第四步：处理特殊和模糊情况——区分“情境学习”与“自我演化”** 这是最关键的一点。论文的核心机制是“in-context learning”（情境学习），即模型在推理时根据提供的示例来调整其行为。这**不等于**您研究焦点中的“自我演化”。 - **情境学习**：模型在单次交互中，根据给定的上下文（prompt中的示例）动态调整输出，但模型本身的权重和核心能力是固定的，不会因为这次交互而永久改变或提升。 - **自我演化**：智能体通过经验、反思或环境反馈，**迭代地、持续地改进自身的策略、知识库甚至模型结构**，实现长期的成长和性能提升。 该论文的模型不具备自我演化的特性，它只是在推理时表现出更强的灵活性和适应性。因此，它不符合“自我演化”的研究方向，也不适用“自我演化的应用”这一例外规则。 **结论**: 该论文的本质是利用一种先进的机器学习技术（情境学习）来解决一个特定垂直领域（地震数据处理）的工程问题。它没有构建、改进或演化任何形式的LLM智能体，其贡献在于应用层面，而非Agentic AI的基础方法论。因此，它应被排除。"
    },
    {
        "index": "#75",
        "title": "DOS: Distilling Observable Softmaps of Zipfian Prototypes for Self-Supervised Point Representation",
        "link": "/arxiv/2512.11465",
        "arxiv_id": "2512.11465",
        "authors": "Mohamed Abdelsamad, Michael Ulrich, Bin Yang, Miao Zhang, Yakov Miron, Abhinav Valada",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.303310",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质不符** - **核心贡献分析**: 论文的核心贡献是提出了一种名为DOS的**自监督学习（SSL）框架**，用于学习**3D点云的表示**。其目标是解决3D点云在无监督学习中的几何不规则、语义分布不均衡等问题，并在语义分割和3D目标检测等任务上取得更好的效果。 - **与筛选标准的匹配**: 这篇论文的本质是**计算机视觉**和**表示学习**领域的研究，而非关于构建或演化智能体。它完全符合第一步排除标准中的 **“非演化型应用”**——即提出一种新的机器学习方法（DOS框架）并将其应用于特定领域（3D视觉）来解决该领域的问题。论文中没有构建任何具有自主规划、工具使用或反思能力的智能体。 2.  **第二步：正面指标——缺乏核心关注点** - 论文的标题和摘要中完全没有出现任何与我的研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等任何关键词。这进一步确认了它与我的研究课题无关。 3.  **第三步：排除标准——明确属于排除类别** - 论文的研究内容明确属于 **“多模态与视觉”** 排除标准。它聚焦于 `3D point cloud representations`（3D点云表示）、`semantic segmentation`（语义分割）和 `3D object detection`（3D目标检测），这些都是典型的计算机视觉任务。根据规则，除非视觉是智能体感知环境的工具且不是研究核心，否则应排除。在此论文中，3D视觉本身就是研究的核心，因此应被排除。 4.  **第四步：处理特殊和模糊情况** - 论文中提到的 `self-distills`（自蒸馏）可能会引起误解，但它是一种模型训练技术，指模型从自身的一个更大版本或集成版本中学习，与智能体通过经验和环境反馈进行“自我演化”或“自我完善”的机制完全不同。它不涉及智能体的行为迭代或能力提升。 **最终决策**: 综合以上分析，该论文是一篇关于3D点云自监督表示学习的计算机视觉论文，其核心贡献与研究课题“LLM智能体及其演化”在目标、方法和范式上均无交集。因此，最终判断为 **False**，予以排除。"
    },
    {
        "index": "#79",
        "title": "Out-of-Distribution Segmentation via Wasserstein-Based Evidential Uncertainty",
        "link": "/arxiv/2512.11373",
        "arxiv_id": "2512.11373",
        "authors": "Arnold Brosch, Abdelrahman Eldesokey, Michael Felsberg, Kira Maag",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.304915",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种用于**计算机视觉**任务（语义分割）的新方法。具体来说，它通过引入一种基于Wasserstein损失的证据分割框架，来提升模型在处理分布外（OOD）对象时的分割性能。这完全属于**“非演化型应用”**的排除范畴。论文将一个深度神经网络作为工具，应用于计算机视觉领域（自动驾驶）解决特定问题（OOD分割），其核心并非构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标。没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，也没有涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 是的，这篇论文明确触犯了排除标准。其研究内容是**“多模态与视觉”**领域的核心问题——`Semantic Segmentation`（语义分割）。尽管它处理的是“开放世界”和“不确定性”问题，但其载体是视觉模型，而非LLM智能体。我的研究焦点是LLM驱动的智能体架构和演化机制，而不是视觉模型本身。 4.  **第四步：处理特殊和模糊情况** 此处没有模糊情况。论文不涉及推理/规划的智能体框架，也不涉及自我演化机制。它纯粹是一个针对视觉任务的模型改进工作。 **最终决策**: 综合以上分析，该论文是一篇典型的计算机视觉领域的论文，其核心贡献在于改进视觉模型的分割能力和不确定性量化。它与“LLM智能体及其演化”这一研究课题在研究对象、核心贡献和技术路线上完全无关。因此，必须排除。"
    },
    {
        "index": "#80",
        "title": "Maritime object classification with SAR imagery using quantum kernel methods",
        "link": "/arxiv/2512.11367",
        "arxiv_id": "2512.11367",
        "authors": "John Tanner, Nicholas Davies, Pascal Elahi, Casey R. Myers, Du Huynh, Wei Liu, Mark Reynolds, Jingbo Wang",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.305278",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是**首次将量子核方法应用于SAR图像的海上目标分类任务**。它提出并验证了一种新的机器学习分类技术（QKM）在特定领域（海上监视）的有效性，并将其与经典方法进行比较。 - **是否符合要求**: 这完全符合第一步中的**排除标准1：“非演化型应用”**。论文是将一种机器学习模型（QKM）作为工具，应用到特定领域（SAR图像分析）去解决该领域的分类问题（区分船只与非船只）。它没有构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何一个核心概念。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 该论文的研究内容属于**排除标准2：“多模态与视觉”**。其核心是处理和分析SAR（一种雷达图像）数据，这属于视觉理解的范畴。根据规则，除非视觉是作为智能体感知环境的工具，否则应被排除。在此论文中，视觉数据是研究的**核心对象**，而不是智能体框架的一部分。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划框架，也不涉及任何自我演化机制，因此特殊规则不适用。 **最终决策**: 综合以上分析，这篇论文的研究范式是**量子机器学习在特定视觉任务上的应用**，与您的研究课题“LLM智能体及其演化”在研究对象、核心贡献和技术路线上存在根本性的差异。论文的核心是改进一种分类算法，而不是构建或演化一个具有自主性、规划能力或协作能力的智能体。因此，它不符合您的筛选要求。"
    },
    {
        "index": "#82",
        "title": "Integrated Prediction and Multi-period Portfolio Optimization",
        "link": "/arxiv/2512.11273",
        "arxiv_id": "2512.11273",
        "authors": "Qi Deng, Yuxuan Linghu, Zhiyuan Liu",
        "subjects": "Computational Engineering, Finance, and Science, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.305934",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为IPMO（Integrated Prediction and Multi-period Portfolio Optimization）的**金融模型**，用于解决多期投资组合优化问题。它通过端到端学习的方式，将资产回报预测模块与一个可微的凸优化层相结合，以提高投资组合的风险调整后收益。这完全符合筛选标准中的**“非演化型应用”**排除项。论文的本质是将机器学习（甚至没有特指LLM）作为工具，应用于金融领域解决特定问题，而不是构建、改进或演化一个通用的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所关注的核心范式和能力的关键词。它没有讨论 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。虽然涉及“优化”，但这指的是数学上的投资组合权重优化，而非智能体的自主 `Planning`。论文不涉及智能体的 `Tool Use`、`Memory`、`Self-Reflection`、`Collaboration` 或 `Self-Improvement` 等任何核心能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文不直接涉及安全对齐或多模态，但第一步的排除已经足够有力。这篇论文的研究焦点是**金融工程**和**运筹优化**，与您关注的Agentic AI方向相去甚远。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“优化”是数学规划问题，是投资组合决策的核心，但它不具备智能体规划的自主性、环境交互性和工具使用能力。它是一个封闭的数学求解过程，因此应被排除。 - **自我演化的应用**: 论文虽然提出了一个端到端的训练框架，但这属于标准的机器学习模型训练范式，而非智能体在运行中通过经验、反思或环境反馈进行“自我演化”的机制。因此，不适用例外保留规则。 **最终决策**: 该论文的核心贡献是针对金融领域的特定问题（多期投资组合优化）提出了一种新的机器学习与优化相结合的方法。它不属于构建、改进或演化LLM智能体的研究，而是一个典型的“AI for Finance”应用型研究。因此，它完全不符合您关于“LLM智能体及其演化”的研究课题要求，应予以排除。"
    },
    {
        "index": "#77",
        "title": "Emergence of Nonequilibrium Latent Cycles in Unsupervised Generative Modeling",
        "link": "/arxiv/2512.11415",
        "arxiv_id": "2512.11415",
        "authors": "Marco Baiesi, Alberto Rosso",
        "subjects": "Statistical Mechanics, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.304133",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种新的**无监督生成模型**。该模型借鉴了非平衡统计物理学的思想，通过构建一个马尔可夫链，在潜在空间中自发地产生“非平衡循环”，从而提升生成性能。其本质是**基础模型研究**，旨在改进生成模型本身对数据分布的建模能力，而不是构建、改进或演化一个具有自主性的LLM智能体。因此，根据第一步的排除标准，这属于“非演化型应用”的范畴（更准确地说是基础模型研究），应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我研究焦点相关的正面指标。它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving`。同样，它也未涉及智能体的核心能力，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。论文中的“cycles”（循环）是指潜在空间中的概率流，而非智能体的行为迭代或代际演化。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不直接涉及安全与对齐或多模态等排除项，但第一步的核心判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文讨论的是模型内部的动力学和概率转移，与智能体如何进行任务规划或多步推理无关。 - **自我演化的应用**: 论文中的“emergence”（涌现）和“cycles”（循环）是模型训练达到稳态后的一种静态属性，用于描述其内部结构，而不是一个智能体通过经验或反馈进行动态自我完善和迭代的机制。因此，这不属于“自我演化”的例外情况。 **最终决策**: 综合以上分析，该论文是一篇关于生成模型的理论性研究，其核心贡献在于提出了一种结合非平衡物理思想的新模型架构，以提升生成效果。这与我的研究目标——“构建、改进或演化LLM智能体”——在本质上是完全不同的领域。因此，这篇论文应被排除。"
    },
    {
        "index": "#89",
        "title": "Data-Driven Model Reduction using WeldNet: Windowed Encoders for Learning Dynamics",
        "link": "/arxiv/2512.11090",
        "arxiv_id": "2512.11090",
        "authors": "Biraj Dahal, Jiahui Cheng, Hao Liu, Rongjie Lai, Wenjing Liao",
        "subjects": "Machine Learning, Machine Learning, Numerical Analysis",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.309036",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 **WeldNet** 的数据驱动非线性模型降维框架，用于为复杂的物理演化系统（如微分方程描述的系统）构建低维代理模型。其本质是**科学计算与工程领域**的一种计算方法，旨在降低模拟复杂物理过程的成本。 这完全符合**排除标准**中的第一条：**非演化型应用**。该论文将深度学习模型（自编码器、传播器网络）作为工具，应用于解决特定领域（物理系统建模）的问题，其目标并非构建、改进或演化一个具有自主性的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何我关注的核心范式或能力关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。论文中提到的 \"evolution\" 是指物理系统状态随时间的**演化**，而非AI智能体的**自我演化**。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不属于安全与对齐或多模态与视觉的排除范畴，但它属于更根本的“非Agentic应用”范畴。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划。 - **自我演化的应用**: 论文虽然研究“演化系统”，但如前所述，这是物理动力学，并非AI智能体的自我演化机制。因此，不适用例外保留规则。 **最终决策**: 综合以上分析，这篇论文的研究焦点是**科学计算中的模型降维**，与我的研究课题“LLM智能体及其演化”在目标、方法和核心贡献上存在根本性的差异。它是一项将深度学习技术应用于传统科学工程的优秀工作，但并不涉及构建或研究具有自主性、规划能力或演化能力的AI智能体。因此，应予以排除。"
    },
    {
        "index": "#93",
        "title": "An Efficient Variant of One-Class SVM with Lifelong Online Learning Guarantees",
        "link": "/arxiv/2512.11052",
        "arxiv_id": "2512.11052",
        "authors": "Joe Suk, Samory Kpotufe",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.310375",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为SONAR的新型、高效的One-Class SVM（一类支持向量机）算法，用于解决非平稳流数据中的异常检测问题。其本质是**一种改进的传统机器学习算法**，而非构建或演化LLM智能体。论文完全不涉及LLM（大语言模型），也没有提出任何智能体框架。因此，根据“非演化型应用”的排除规则，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现我关注的核心范式或能力关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Planning`, `Tool Use`, `Self-Reflection` 等。虽然摘要中提到了 `lifelong online learning`（终身在线学习），但这在本文的语境下指的是模型算法能够适应数据分布的持续变化，是一种**模型层面的适应性**，而不是智能体通过经验、反思或环境反馈进行**主动的自我完善和迭代**。它缺乏智能体的自主性、规划能力和目标导向性。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文的研究焦点是异常检测和在线学习算法，虽然不属于安全对齐或多模态等明确排除的领域，但其核心问题域（异常检测）本身就在我的研究焦点（LLM智能体及其演化）之外。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的推理或规划。 - **自我演化的应用**: 这是最可能引起混淆的一点。尽管论文提出了一个能适应数据变化的“终身学习”机制，但这并非我定义的“自我演化”。我的“自我演化”是指智能体作为一个自主实体，通过与环境交互、反思自身行为来迭代改进其能力（如规划、工具使用策略）。而本文的SONAR算法是被动的适应数据流，它没有自主目标，不进行反思，也不使用工具。因此，它不符合“自我演化”的核心定义，也不适用“例外保留”规则。 **最终决策**: 综合以上分析，该论文是一篇关于改进传统机器学习算法（One-Class SVM）的研究，其核心贡献与LLM智能体、多智能体系统或智能体的自我演化机制无关。它属于将一种算法应用于特定领域（异常检测）的研究，不符合我的核心研究目标。因此，最终判断为 **False**。"
    },
    {
        "index": "#90",
        "title": "TPV: Parameter Perturbations Through the Lens of Test Prediction Variance",
        "link": "/arxiv/2512.11089",
        "arxiv_id": "2512.11089",
        "authors": "Devansh Arpit",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.309346",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——排除** 论文的核心贡献是提出了一种名为“测试预测方差”（TPV）的新度量标准，用于分析深度神经网络的泛化能力。它研究了模型输出对参数扰动的敏感性，并将其应用于模型剪枝等优化任务。这篇论文的本质是**深度学习理论**和**模型优化**，而非构建、改进或演化LLM智能体。它完全不属于“构建LLM智能体”、“多智能体系统”或“自我演化”的方法论或新框架范畴。因此，根据第一步的核心判断标准，应予以排除。 2.  **第二步：正面指标——完全不匹配** 论文摘要中完全没有出现任何您所关注的核心范式或能力关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。这进一步证实了该论文与您的研究焦点无关。 3.  **第三步：排除标准——不适用但已排除** 虽然这篇论文不主要关注安全与对齐或多模态，但它已经在第一步被明确排除，因为其研究主题（泛化理论、模型剪枝）与您的核心目标（LLM智能体及其演化）存在根本性偏差。 4.  **第四步：处理特殊和模糊情况——不适用** 该论文不涉及推理/规划框架或自我演化机制，因此此处的特殊规则不适用。 **最终决策**：该论文是一篇关于深度学习基础理论和模型优化的研究。它的核心贡献是理解模型泛化和提出一种新的模型剪枝方法，这与您关于“LLM智能体及其演化”的研究课题（聚焦于智能体的构建、协作与自我演化）完全无关。因此，最终判断为 **False**，应排除。"
    },
    {
        "index": "#91",
        "title": "Provable Recovery of Locally Important Signed Features and Interactions from Random Forest",
        "link": "/arxiv/2512.11081",
        "arxiv_id": "2512.11081",
        "authors": "Kata Vuk, Nicolas Alexander Ihlo, Merle Behr",
        "subjects": "Machine Learning, Machine Learning, Methodology",
        "date": "2025-12-11",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.309679",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** - **论文核心贡献**: 这篇论文的核心是提出一种针对**随机森林**模型的**局部特征和交互重要性**的解释方法。它旨在理解单个预测中哪些特征及其组合是关键的，并为此提供了理论保证。 - **与我的研究目标的关系**: 我的核心目标是筛选关于**构建、改进或演化LLM智能体**的论文。该论文的研究对象是传统的机器学习模型“随机森林”，而非LLM智能体。其核心是**模型可解释性**，而不是智能体的构建、规划、工具使用或自我演化。因此，在第一步的核心判断中，该论文就应被排除。 2.  **第二步：正面指标** - 论文摘要中完全没有出现我关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。也没有提及智能体的核心能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准** - 这是最关键的排除依据。根据筛选标准第三步，主要贡献在于 `Interpretability` (可解释性) 或 `Explainability (XAI)` 的论文应被排除。这篇论文的标题和摘要明确指出其研究内容是“Feature and Interaction Importance (FII) methods”和“local interpretations”，这完全属于“可解释性”的研究范畴。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划框架，也未提出任何自我演化机制。因此，特殊情况的规则不适用。 **最终决策**: 综合以上分析，这篇论文是一篇关于传统机器学习模型（随机森林）的可解释性研究。尽管它在其自身领域可能具有重要的理论价值，但它与我的研究课题“LLM智能体及其演化”在研究对象、核心贡献和研究范式上完全不匹配。因此，最终判断为 **False**，予以排除。"
    },
    {
        "index": "#86",
        "title": "Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration",
        "link": "/arxiv/2512.11200",
        "arxiv_id": "2512.11200",
        "authors": "Adilet Metinov, Gulida M. Kudakeeva, Gulnara D. Kabaeva",
        "subjects": "Distributed, Parallel, and Cluster Computing, Machine Learning, Programming Languages",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.307825",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是基础设施优化。** 论文的核心贡献是建立“GPU原生编译”的理论基础，以解决AI代码生成系统中的延迟瓶颈。其研究内容聚焦于编译技术、CPU-GPU数据传输、并行计算和硬件加速。根据筛选标准，这明确属于“基础设施”范畴，应被直接排除。论文的目标是提升代码生成和迭代的*速度*，而不是构建或改进LLM智能体的*智能行为*或*演化机制*。 2.  **第二步：正面指标——缺乏核心关注点。** 尽管摘要末尾提到了“对自我改进AI系统的启示”，但这并非论文的核心贡献。论文的主体内容并未涉及`Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`或`Self-Evolving`等核心范式或智能体能力。其关键词是“编译”、“延迟”、“GPU”，与您的研究焦点关联度极低。 3.  **第四步：处理特殊和模糊情况——“自我改进”的提及不构成例外。** 摘要中提到的“对自我改进AI系统的启示”是一个典型的模糊点。然而，根据筛选规则，只有当论文的**核心贡献是提出一种新的“自我演化”机制**时，才能作为例外被保留。在这篇论文中，“自我改进”只是一个被讨论的未来可能性或应用前景，而论文本身提出和验证的核心是**编译方法**，而非自我演化机制。因此，该例外情况不适用。 **结论**：该论文本质上是一篇关于AI系统性能优化和硬件加速的研究，属于计算机系统或编译器领域。它虽然与AI系统相关，但其贡献点在于底层的“如何更快地运行”，而非您所关注的顶层的“智能体如何更智能地行动和演化”。因此，它严格地落在了排除标准之内，不符合您关于“LLM智能体及其演化”的研究课题。"
    },
    {
        "index": "#95",
        "title": "Boosted Random Forests for Predicting Treatment Failure of Chemotherapy Regimens",
        "link": "/arxiv/2512.10995",
        "arxiv_id": "2512.10995",
        "authors": "Muhammad Usamah Shahid, Muddassar Farooq",
        "subjects": "Quantitative Methods, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.311000",
        "filter_reason": "这篇论文不符合研究范围。 我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 该论文的核心贡献是利用**提升随机森林**这一传统机器学习模型，基于电子病历（EMR）数据来预测化疗方案的失败概率。 - 这完全符合第一步中的**排除标准1：非演化型应用**。论文将一个机器学习模型（随机森林）作为工具，应用于医疗（肿瘤学）这一特定领域，以解决该领域的具体问题（预测治疗失败）。论文中完全没有提及LLM、智能体、多智能体系统或任何形式的自我演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文标题和摘要中未出现任何核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。 - 论文也未涉及任何智能体能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 - 因此，该论文不满足任何正面指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文提到了“可解释性”，但这只是作为模型选择的一个考量因素（“三轴 - 性能、复杂度和可解释性 - 设计探索框架”），而非论文的核心研究贡献。论文的核心是预测模型本身，而不是一种新的可解释性方法。因此，它不触及“安全与对齐”的排除红线。 - 论文与多模态和视觉无关。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及推理/规划或自我演化的应用，因此此步不适用。 5.  **第五步：最终决策** - 综合以上分析，该论文的研究焦点是**医疗领域的预测模型构建与评估**，而非**LLM智能体的构建、改进或演化**。它是一个典型的将机器学习技术应用于垂直领域的案例，与我的研究课题“LLM智能体及其演化”完全无关。因此，应明确排除。"
    },
    {
        "index": "#87",
        "title": "CADKnitter: Compositional CAD Generation from Text and Geometry Guidance",
        "link": "/arxiv/2512.11199",
        "arxiv_id": "2512.11199",
        "authors": "Tri Le, Khang Nguyen, Baoru Huang, Tung D. Ta, Anh Nguyen",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.308238",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - 论文的核心贡献是提出了一个名为 `CADKnitter` 的**组合式CAD生成框架**，其核心技术是一种**几何引导的扩散采样策略**。 - 这篇论文的本质是**生成式AI在特定领域（计算机辅助设计）的应用**，它旨在解决如何生成符合约束的CAD模型这一具体问题。 - 根据筛选标准，这属于典型的**“非演化型应用”**。它没有构建、改进或演化一个具有自主规划、工具使用或反思能力的LLM智能体，而是将一个生成模型（扩散模型）作为工具来解决CAD领域的任务。因此，在第一步就应该被排除。 2.  **第二步：正面指标** - 论文的标题和摘要中完全没有出现任何与您核心关注点相关的关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准** - 论文明确提到了其核心技术是**“扩散采样策略”**。根据您的筛选标准，关于 `Diffusion Models` 的研究通常需要排除，除非它们被用作智能体感知环境的工具。在这篇论文中，扩散模型是研究的**核心贡献本身**，而不是一个智能体的组件，因此符合排除条件。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理/规划框架，也没有提出任何自我演化机制。因此，特殊情况的例外条款不适用。 **最终决策**: 综合以上分析，这篇论文的核心是**生成式建模**，而非**智能体研究**。它提出的是一个用于解决特定领域（CAD）问题的生成框架，其贡献在于模型架构和数据集，而非智能体的构建、协作或演化机制。因此，它完全不符合您关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#96",
        "title": "STARK denoises spatial transcriptomics images via adaptive regularization",
        "link": "/arxiv/2512.10994",
        "arxiv_id": "2512.10994",
        "authors": "Sharvaj Kubal, Naomi Graham, Matthieu Heitz, Andrew Warren, Michael P. Friedlander, Yaniv Plan, Geoffrey Schiebinger",
        "subjects": "Machine Learning, Machine Learning, Optimization and Control, Statistics Theory",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.311394",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为STARK的新算法，用于对**空间转录组学图像进行去噪**。这是一种应用于生物信息学领域的特定图像处理技术。论文详细描述了其数学原理（核岭回归、图拉普拉斯正则化）和迭代优化过程。这完全符合筛选标准中的**“非演化型应用”**排除项，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。尽管本文没有使用LLM，但其本质是应用一种新的机器学习方法解决特定领域的科学问题，而非构建或研究智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与您研究焦点相关的正面指标。摘要中未提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心范式或智能体能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文的研究对象是“空间转录组学图像”，这属于**“视觉”**范畴。根据您的筛选标准，除非视觉技术被用作智能体感知环境的工具，否则应予以排除。在本论文中，图像处理本身就是研究的核心，而不是服务于某个智能体框架的组件，因此符合排除条件。 4.  **第四步：处理特殊和模糊情况** 一个潜在的模糊点是论文的“迭代”和“自适应”更新机制。然而，这需要与“自我演化”严格区分。您所定义的“自我演化”是指**智能体**通过经验、反思或环境反馈进行自我完善和迭代。而STARK的迭代过程是一个**优化算法**的内部机制（交替最小化），用于收敛到一个更优的图像估计结果。它不涉及一个具有自主性、规划或目标的智能体在演化其行为、策略或架构。因此，这属于算法层面的迭代优化，而非智能体层面的自我演化，不符合第四步中关于“自我演化机制”的例外保留规则。 **最终决策**: 综合以上分析，该论文是一篇专注于计算生物学和图像处理的算法研究，其核心贡献与LLM智能体、多智能体系统或自我演化机制完全无关。因此，它不符合您的研究目标，应被排除。"
    },
    {
        "index": "#100",
        "title": "RMSup: Physics-Informed Radio Map Super-Resolution for Compute-Enhanced Integrated Sensing and Communications",
        "link": "/arxiv/2512.10965",
        "arxiv_id": "2512.10965",
        "authors": "Qiming Zhang, Xiucheng Wang, Nan Cheng, Zhisheng Yin, Xiang Li",
        "subjects": "Signal Processing, Machine Learning, Systems and Control",
        "date": "2025-11-29",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.315057",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 \"RMSup\" 的物理信息超分辨率框架，用于在无线通信领域构建高保真的无线电地图。这是一个典型的**非演化型应用**。它将一个深度学习模型（一个边界感知双头网络）作为工具，应用到特定的工程领域（无线通信、感知通信一体化ISAC）来解决该领域的问题（无线电地图构建）。论文完全没有涉及构建、改进或演化任何形式的LLM智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何与我研究焦点相关的正面指标。摘要中未提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心概念。虽然文中提到了 \"prompts\"，但根据上下文（\"extracts Helmholtz equation-informed boundary and singularity prompts\"），这里的 \"prompts\" 指的是从物理方程和测量中提取的、作为神经网络条件输入的提示信息，而非LLM意义上的提示词。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不属于安全对齐或多模态视觉的排除范畴，但它已经被第一步的核心判断排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划或自我演化机制，因此不适用特殊情况的例外规则。 **最终决策**：综合以上分析，这篇论文的研究对象是无线信号处理和物理信息神经网络，其核心目标是解决特定领域的工程问题。它与我的研究课题 \"LLM智能体及其演化\" 在研究对象、核心贡献和技术路线上完全无关。因此，应予以排除。"
    },
    {
        "index": "#97",
        "title": "Generalization of Long-Range Machine Learning Potentials in Complex Chemical Spaces",
        "link": "/arxiv/2512.10989",
        "arxiv_id": "2512.10989",
        "authors": "Michal Sanocki, Julija Zavadlav",
        "subjects": "Chemical Physics, Machine Learning",
        "date": "2025-12-08",
        "category": "cs.LG",
        "crawl_time": "2025-12-15T11:00:04.311709",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是关于**机器学习原子间势**的改进与评估。它旨在解决计算化学和材料科学领域中的一个具体问题：如何提升MLIP模型在复杂化学空间中的泛化能力。论文的贡献在于提出了一种评估框架（有偏的训练-测试划分）并验证了长程修正方案对模型泛化性的重要性。这完全属于**“非演化型应用”**的排除范畴。它并非构建、改进或演化LLM智能体，而是将一种特定类型的机器学习模型（MLIPs，并非LLM）应用于特定科学领域（化学/材料科学）来解决该领域的问题。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标。它不涉及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式，也不讨论 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等智能体能力。其讨论的焦点是 `Generalization`, `Machine Learning Potentials`, `Atomistic Simulations`，这些均与我的研究目标无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不涉及安全与对齐或多模态等排除项，但它在第一步的核心判断中已经被明确排除。 4.  **第四步：处理特殊和模糊情况** 论文不涉及智能体的推理/规划，也不涉及自我演化机制。它研究的是静态模型的泛化性能，而非智能体通过经验进行迭代和自我完善的过程。因此，关于“自我演化的应用”的例外规则不适用。 **最终决策**: 综合以上分析，该论文是一篇典型的计算化学领域的应用研究，其核心贡献是改进和评估一种用于原子模拟的机器学习模型。它与“LLM智能体及其演化”这一课题在研究对象、核心贡献和研究范式上均无交集。因此，应予以排除。"
    }
]