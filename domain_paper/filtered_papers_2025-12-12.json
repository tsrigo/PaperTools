[
    {
        "index": "#7",
        "title": "Query Optimization Beyond Data Systems: The Case for Multi-Agent Systems",
        "link": "/arxiv/2512.11001",
        "arxiv_id": "2512.11001",
        "authors": "Zoi Kaoudi, Ioana Giurgiu",
        "summary": "The proliferation of large language models (LLMs) has accelerated the adoption of agent-based workflows, where multiple autonomous agents reason, invoke functions, and collaborate to compose complex data pipelines. However, current approaches to building such agentic architectures remain largely ad hoc, lacking generality, scalability, and systematic optimization. Existing systems often rely on fixed models and single execution engines and are unable to efficiently optimize multiple agents operating over heterogeneous data sources and query engines. This paper presents a vision for a next-generation query optimization framework tailored to multi-agent workflows. We argue that optimizing these workflows can benefit from redesigning query optimization principles to account for new challenges: orchestration of diverse agents, cost efficiency under expensive LLM calls and across heterogeneous engines, and redundancy across tasks. Led by a real-world example and building on an analysis of multi-agent workflows, we outline our envisioned architecture and the main research challenges of building a multi-agent query optimization framework, which aims at enabling automated model selection, workflow composition, and execution across heterogeneous engines. This vision establishes the groundwork for query optimization in emerging multi-agent architectures and opens up a set of future research directions.",
        "subjects": "Databases, Multiagent Systems",
        "date": "2025-12-10",
        "category": "cs.MA",
        "crawl_time": "2025-12-15T11:00:03.480704",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具应用到一个特定领域，而是将**多智能体系统本身作为研究对象**。其核心贡献是提出一个**用于优化和编排多智能体工作流的框架**。这直接对应了您研究目标中的“改进LLM智能体”，特别是在“多智能体”方向上。论文指出了当前构建多智能体架构的不足，并提出了一个系统性的解决方案，这属于构建和改进智能体方法论的范畴，而非简单的应用。 2.  **第二步：正面指标** - 论文摘要中包含了大量与您研究焦点高度相关的正面指标： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 - **智能体能力**: 提到了 `reason` (推理), `invoke functions` (工具使用), `collaborate` (协作)。 - **多智能体**: 明确讨论了 `collaboration` (协作), `orchestration of diverse agents` (智能体编排), `workflow composition` (工作流组合)，这些都是多智能体系统研究的关键问题。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐问题。 - 论文也未聚焦于 `Vision`, `MLLMs` 等多模态技术。因此，它没有触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文讨论的“workflow composition”（工作流组合）和“orchestration”（编排）是典型的智能体高层规划与执行问题，而非提升LLM底层的数学或逻辑推理能力。因此，它符合保留条件。 - **基础设施的模糊性**: 论文标题中的“Query Optimization”和“Data Systems”可能让人误以为是基础设施研究。然而，摘要明确指出，这个优化框架是**“tailored to multi-agent workflows”**（为多智能体工作流量身定制）的。它解决的是多智能体协作中的**模型选择、工作流组合、执行成本和冗余**等核心问题。这属于智能体架构层面的优化，是构建高效、可扩展的多智能体系统的关键，而非底层的硬件或部署优化。因此，它应被视为智能体研究的一部分，而非被排除的基础设施研究。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出一个**面向多智能体系统的优化框架**，旨在解决如何更高效地构建、编排和运行多智能体工作流。这完全契合您研究课题中的“多智能体”方向，属于对LLM智能体本身的构建和改进。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#4",
        "title": "AutoFSM: A Multi-agent Framework for FSM Code Generation with IR and SystemC-Based Testing",
        "link": "/arxiv/2512.11398",
        "arxiv_id": "2512.11398",
        "authors": "Qiuming Luo, Yanming Lei, Kunzhong Wu, Yixuan Cao, Chengjian Liu",
        "summary": "With the rapid advancement of large language models (LLMs) in code generation, their applications in hardware design are receiving growing attention. However, existing LLMs face several challenges when generating Verilog code for finite state machine (FSM) control logic, including frequent syntax errors, low debugging efficiency, and heavy reliance on test benchmarks. To address these challenges, this paper proposes AutoFSM, a multi-agent collaborative framework designed for FSM code generation tasks. AutoFSM introduces a structurally clear intermediate representation (IR) to reduce syntax error rate during code generation and provides a supporting toolchain to enable automatic translation from IR to Verilog. Furthermore, AutoFSM is the first to integrate SystemC-based modeling with automatic testbench generation, thereby improving debugging efficiency and feedback quality. To systematically evaluate the framework's performance, we construct SKT-FSM, the first hierarchical FSM benchmark in the field, comprising 67 FSM samples across different complexity levels. Experimental results show that, under the same base LLM, AutoFSM consistently outperforms the open-source framework MAGE on the SKT-FSM benchmark, achieving up to an 11.94% improvement in pass rate and up to a 17.62% reduction in syntax error rate. These results demonstrate the potential of combining LLMs with structured IR and automated testing to improve the reliability and scalability of register-transfer level (RTL) code generation.",
        "subjects": "Software Engineering, Multiagent Systems",
        "date": "2025-12-12",
        "category": "cs.MA",
        "crawl_time": "2025-12-15T11:00:03.479952",
        "filter_reason": "这篇论文符合我的研究范围，应当保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 **AutoFSM** 的 **多智能体协作框架**。它的核心贡献并非简单地将LLM应用于硬件设计领域，而是**构建了一个新的方法论框架**来解决该领域的特定问题。论文详细描述了该框架如何通过多个智能体的协作、引入中间表示（IR）和自动化测试工具链来提升代码生成的质量和效率。这完全符合“构建、改进或演化LLM智能体”的核心目标，特别是“多智能体系统”这一方向。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Multi-agent Framework` (多智能体框架) 在标题和摘要中被明确提及。 - **多智能体**: `Collaboration` (协作) 是该框架的核心特征，摘要中描述其为“多智能体协作框架”。 - **智能体能力**: `Tool Use / Tool Augmentation` (工具使用/工具增强) 体现在其“支持工具链”和“SystemC-based modeling with automatic testbench generation”上，这些都是智能体用来完成任务的外部工具。 3.  **第三步：排除标准** - 论文不涉及任何关于安全、对齐、可解释性或视觉多模态的内容，因此没有触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的多智能体框架隐含了任务分解和协作规划的过程。例如，一个智能体可能负责生成结构化的IR，另一个负责翻译，还有一个负责测试，这本身就是一种复杂的、基于智能体的任务规划和执行，而非简单的LLM基础推理能力提升。 - **自我演化的应用**: 虽然这不属于自我演化的范畴，但关键在于其核心贡献是框架本身。即使应用领域（硬件设计）非常具体，但由于其贡献是提出了一种新的多智能体协作范式，根据筛选规则，它应该被保留。 **最终决策**: 这篇论文的核心贡献是 **构建了一个新颖的多智能体协作框架**，以解决FSM代码生成的复杂问题。它详细阐述了智能体之间如何分工、协作以及使用工具，这直接对应了我研究课题中的“多智能体”方向。尽管其应用场景是硬件设计，但论文的焦点和价值在于**Agentic框架的设计和实现**，而非应用本身。因此，这篇论文高度相关，符合筛选要求。"
    },
    {
        "index": "#9",
        "title": "Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning",
        "link": "/arxiv/2512.11485",
        "arxiv_id": "2512.11485",
        "authors": "Xuanbo Su, Yingfang Zhang, Hao Luo, Xiaoteng Liu, Leo Huang",
        "summary": "Large language models (LLMs) adapt to tasks via gradient fine-tuning (heavy computation, catastrophic forgetting) or In-Context Learning (ICL: low robustness, poor mistake learning). To fix this, we introduce Mistake Notebook Learning (MNL), a training-free framework with a persistent knowledge base of abstracted error patterns. Unlike prior instance/single-trajectory memory methods, MNL uses batch-wise error abstraction: it extracts generalizable guidance from multiple failures, stores insights in a dynamic notebook, and retains only baseline-outperforming guidance via hold-out validation (ensuring monotonic improvement). We show MNL nearly matches Supervised Fine-Tuning (93.9% vs 94.3% on GSM8K) and outperforms training-free alternatives on GSM8K, Spider, AIME, and KaggleDBQA. On KaggleDBQA (Qwen3-8B), MNL hits 28% accuracy (47% relative gain), outperforming Memento (15.1%) and Training-Free GRPO (22.1) - proving it's a strong training-free alternative for complex reasoning.",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.605654",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“Mistake Notebook Learning (MNL)”的训练免费框架。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心并非简单地将LLM应用于某个领域，也不是单纯提升LLM的基础推理能力。它提出的是一个具有**持久性知识库**、能够从过去的错误中学习并实现**单调改进**的框架。这个框架的本质是构建一个能够自我完善和迭代的系统，这完全符合“自我演化”的定义。因此，这篇论文应被**保留**。 2.  **第二步：正面指标** 论文高度符合我的核心关注点： *   **自我演化**: 论文明确提出了一个确保“单调改进”的框架，这是自我演化的核心特征。 *   **记忆**: “持久性知识库”和“动态笔记本”是典型的智能体记忆机制。 *   **自我反思/自我修正**: 论文的核心机制是“从多个失败中提取可泛化的指导”，这正是自我反思和自我修正的过程。 *   **迭代改进**: 整个MNL框架就是一个迭代改进的过程。 3.  **第三步：排除标准** 论文不涉及安全、对齐或多模态等排除领域，因此无需排除。 4.  **第四步：处理特殊和模糊情况** 这篇论文处于“推理”和“自我演化”的交叉点，需要仔细甄别。 *   **推理/规划**: 虽然论文的实验集中在数学、代码等推理任务上，但其核心贡献**不是**一种新的CoT变体或微调方法来直接提升LLM的Token预测能力。相反，它提出的是一个**元框架**，这个框架通过记忆和反思来**优化LLM在任务中的学习过程**。这个框架本身具有Agentic和自我演化的属性。 *   **自我演化的应用**: 根据规则，即使论文的应用领域是“复杂推理”，但其核心是提出一种新的“自我演化”机制（MNL框架），因此应该被保留。MNL框架的“从错误中学习”和“确保单调改进”是典型的自我演化机制。 **最终决策**: 这篇论文的核心贡献是构建了一个名为MNL的**自我演化框架**。该框架通过引入一个持久性的“错误笔记本”作为记忆模块，实现了从历史失败中抽象模式、进行自我反思和修正，并确保了性能的单调提升。这完全符合我研究课题中“自我演化”方向的核心目标，即研究智能体如何通过经验、反思进行自我完善和迭代。因此，这篇论文与我的研究范围高度相关。"
    },
    {
        "index": "#15",
        "title": "Unifying Dynamic Tool Creation and Cross-Task Experience Sharing through Cognitive Memory Architecture",
        "link": "/arxiv/2512.11303",
        "arxiv_id": "2512.11303",
        "authors": "Jiarun Liu, Shiyue Xu, Yang Li, Shangkun Liu, Yongli Yu, Peng Cao",
        "summary": "Large Language Model agents face fundamental challenges in adapting to novel tasks due to limitations in tool availability and experience reuse. Existing approaches either rely on predefined tools with limited coverage or build tools from scratch without leveraging past experiences, leading to inefficient exploration and suboptimal performance. We introduce SMITH (Shared Memory Integrated Tool Hub), a unified cognitive architecture that seamlessly integrates dynamic tool creation with cross-task experience sharing through hierarchical memory organization. SMITH organizes agent memory into procedural, semantic, and episodic components, enabling systematic capability expansion while preserving successful execution patterns. Our approach formalizes tool creation as iterative code generation within controlled sandbox environments and experience sharing through episodic memory retrieval with semantic similarity matching. We further propose a curriculum learning strategy based on agent-ensemble difficulty re-estimation. Extensive experiments on the GAIA benchmark demonstrate SMITH's effectiveness, achieving 81.8% Pass@1 accuracy and outperforming state-of-the-art baselines including Alita (75.2%) and Memento (70.9%). Our work establishes a foundation for building truly adaptive agents that continuously evolve their capabilities through principled integration of tool creation and experience accumulation.",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.644798",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献与你的研究目标高度契合。以下是根据筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为SMITH的全新**认知架构**，用于构建和改进LLM智能体。它的核心贡献不是将现有智能体应用到一个新领域，而是创造了一个能让智能体**动态创建工具**和**跨任务共享经验**的框架。这直接命中了“构建、改进或演化LLM智能体”的核心目标。它不属于非演化型应用、非Agentic推理或基础设施研究。 2.  **第二步：正面指标** - 论文包含了大量你的核心关注点： - **核心范式**: 论文围绕 `LLM-based Agents` 展开，并提出了一个统一的 `Cognitive Architecture`。 - **智能体能力**: 明确涉及 `Tool Use / Tool Augmentation` (动态工具创建)、`Memory` (认知记忆架构，包含程序性、语义性和情景性记忆)。 - **演化机制**: 核心贡献之一就是 `Self-Evolving` 机制，通过 `Cross-Task Experience Sharing` (跨任务经验共享) 和 `Iterative Improvement` (迭代代码生成) 来实现智能体能力的持续演化。摘要最后一句明确指出，其目标是构建“持续演化其能力的自适应智能体”。 3.  **第三步：排除标准** - 论文完全不涉及安全与对齐（Safety, Alignment等），也没有涉及多模态与视觉（Vision, MLLMs等）。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的SMITH架构是一个典型的Agentic框架，它通过工具创建和经验检索来支持智能体在复杂任务中进行多步规划和执行。这完全符合“保留”的条件，而不是单纯提升LLM的基础推理能力。 - **自我演化的应用**: 论文的核心就是提出一种新的“自我演化”机制（通过记忆共享工具创建经验），因此即使它是在GAIA这个通用智能体基准上测试的，也完全符合保留的例外规则。 **最终决策**: 这篇论文的核心贡献是**SMITH，一个统一的认知架构**，它通过整合动态工具创建和基于记忆的跨任务经验共享，显著提升了LLM智能体的适应性和演化能力。这直接对应了你研究范围中的**单智能体**（工具使用、记忆）和**自我演化**（经验共享、自我完善）两个核心方向。因此，这篇论文是高度相关且应被保留的前沿研究。"
    },
    {
        "index": "#19",
        "title": "When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents",
        "link": "/arxiv/2512.11277",
        "arxiv_id": "2512.11277",
        "authors": "Mrinal Rawat, Arkajyoti Chakraborty, Neha Gupta, Roberto Pieraccini",
        "summary": "Supervised fine-tuning (SFT) has emerged as one of the most effective ways to improve the performance of large language models (LLMs) in downstream tasks. However, SFT can have difficulty generalizing when the underlying data distribution changes, even when the new data does not fall completely outside the training domain. Recent reasoning-focused models such as o1 and R1 have demonstrated consistent gains over their non-reasoning counterparts, highlighting the importance of reasoning for improved generalization and reliability. However, collecting high-quality reasoning traces for SFT remains challenging -- annotations are costly, subjective, and difficult to scale. To address this limitation, we leverage Reinforcement Learning (RL) to enable models to learn reasoning strategies directly from task outcomes. We propose a pipeline in which LLMs generate reasoning steps that guide both the invocation of tools (e.g., function calls) and the final answer generation for conversational agents. Our method employs Group Relative Policy Optimization (GRPO) with rewards designed around tool accuracy and answer correctness, allowing the model to iteratively refine its reasoning and actions. Experimental results demonstrate that our approach improves both the quality of reasoning and the precision of tool invocations, achieving a 1.5% relative improvement over the SFT model (trained without explicit thinking) and a 40% gain compared to the base of the vanilla Qwen3-1.7B model. These findings demonstrate the promise of unifying reasoning and action learning through RL to build more capable and generalizable conversational agents.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.647217",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于提出了一种新的方法来构建和演化LLM智能体。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具去解决某个特定领域的问题，而是提出了一种新的训练范式（基于强化学习）来**改进LLM智能体本身的核心能力**。论文的核心是让智能体通过与环境（任务结果）的交互，自主地学习和优化其“推理”和“行动”策略，这直接属于构建和演化LLM智能体的范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文的研究对象是 `LLM-based Agents`（对话智能体），并使用了强化学习（一种可用于演化的机制）。 - **智能体能力**: 论文的核心是 `Reasoning`（推理步骤）和 `Tool Use`（工具调用）的协同，这正是单智能体研究的关键。 - **演化机制**: 论文的核心贡献在于提出了一种 `Self-Evolving` 机制。通过强化学习（GRPO）和基于任务结果的奖励信号，模型能够 `Iterative Refine`（迭代式改进）其推理和行动，这是一种典型的自我完善和演化过程。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。它的焦点是提升智能体的性能和泛化能力，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它研究的不是LLM本身的基础数学或逻辑推理能力，而是**智能体如何在一个框架内进行推理，并用推理来指导其行动（工具调用）**。这种“Reasoning-Action Synergy”（推理-行动协同）是Agentic AI的核心特征，超越了单纯的Chain-of-Thought。 - **自我演化的应用**: 虽然论文在对话智能体任务上进行验证，但其核心是提出一种通用的**自我演化机制**（通过RL从任务结果中学习推理），而不是仅仅展示一个应用。因此，它完全符合保留标准。 **最终决策**: 该论文的核心贡献是提出了一种新颖的强化学习框架，使LLM智能体能够通过与环境反馈的交互，自主地、迭代地优化其推理过程和工具使用能力。这直接命中了您研究目标中的“单智能体”（推理、工具使用）和“自我演化”（自我完善、迭代改进）两个核心方向。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#28",
        "title": "KBQA-R1: Reinforcing Large Language Models for Knowledge Base Question Answering",
        "link": "/arxiv/2512.10999",
        "arxiv_id": "2512.10999",
        "authors": "Xin Sun, Zhongqi Chen, Xing Zheng, Qiang Liu, Shu Wu, Bowen Song, Zilei Wang, Weiqiang Wang, Liang Wang",
        "summary": "Knowledge Base Question Answering (KBQA) challenges models to bridge the gap between natural language and strict knowledge graph schemas by generating executable logical forms. While Large Language Models (LLMs) have advanced this field, current approaches often struggle with a dichotomy of failure: they either generate hallucinated queries without verifying schema existence or exhibit rigid, template-based reasoning that mimics synthesized traces without true comprehension of the environment. To address these limitations, we present \\textbf{KBQA-R1}, a framework that shifts the paradigm from text imitation to interaction optimization via Reinforcement Learning. Treating KBQA as a multi-turn decision process, our model learns to navigate the knowledge base using a list of actions, leveraging Group Relative Policy Optimization (GRPO) to refine its strategies based on concrete execution feedback rather than static supervision. Furthermore, we introduce \\textbf{Referenced Rejection Sampling (RRS)}, a data synthesis method that resolves cold-start challenges by strictly aligning reasoning traces with ground-truth action sequences. Extensive experiments on WebQSP, GrailQA, and GraphQuestions demonstrate that KBQA-R1 achieves state-of-the-art performance, effectively grounding LLM reasoning in verifiable execution.",
        "subjects": "Computation and Language",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.656817",
        "filter_reason": "这篇论文符合你的研究范围，应被保留。我的判断过程如下： **第一步：核心判断——这篇论文的本质是什么？** 这篇论文的核心贡献是提出一个名为 **KBQA-R1** 的新框架。它没有简单地将现有LLM或智能体框架应用于知识库问答（KBQA）任务，而是从根本上重新定义了任务的解决范式：从“文本模仿”转变为“**交互优化**”。 论文将KBQA任务建模为一个“**多回合决策过程**”，模型（智能体）通过一系列“**动作**”来“**导航知识库**”。这完全符合LLM智能体的定义——一个在环境中（知识库）通过行动（查询、验证）来达成目标（回答问题）的自主实体。 更重要的是，它引入了强化学习（GRPO）机制，让智能体能够根据“**具体的执行反馈**”来“**优化其策略**”。这是一种明确的**自我演化**机制，智能体通过与环境的交互和反馈进行自我完善和迭代，而不是仅仅依赖静态的监督数据。 因此，这篇论文的本质是**构建和改进一个具有自我演化能力的LLM智能体**，符合“保留”标准。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文包含了多个核心关注点： - **核心范式**: 论文的核心是构建一个 `LLM-based Agent`，并探讨了其 `Self-Evolving` 机制。 - **智能体能力**: 论文聚焦于智能体的 `Planning`（多回合决策过程）和 `Tool Use`（将知识库作为可交互的环境/工具）。 - **演化机制**: 论文的核心创新点之一就是 `Self-Improvement` / `Iterative Improvement`，通过强化学习（GRPO）基于环境反馈进行策略优化。 **第三步：排除标准——是否为我的研究焦点之外？** 论文的主要贡献不涉及安全与对齐（Safety, Alignment等），也不涉及多模态或视觉。因此，没有触发排除标准。 **第四步：处理特殊和模糊情况** 1.  **推理/规划**: 这篇论文完美地符合“保留”条件。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个**智能体框架**来解决复杂的、需要多步推理的KBQA任务。其“多回合决策过程”和“导航知识库”正是智能体规划的体现。 2.  **自我演化的应用**: 这正是“保留”的例外情况。虽然论文的应用领域是特定的KBQA，但其**核心贡献是提出了一种新的“自我演化”机制**（通过GRPO进行交互优化）。根据你的要求，这种提出新演化机制的论文，即使应用在特定领域，也应该保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的LLM智能体框架（KBQA-R1），该框架将任务视为多回合决策过程，并利用强化学习实现了基于环境反馈的自我演化。这完全契合你关于“LLM智能体及其演化”的研究目标，特别是在“单智能体”和“自我演化”两个方向上。因此，最终判断为 **True**。"
    },
    {
        "index": "#38",
        "title": "FutureWeaver: Planning Test-Time Compute for Multi-Agent Systems with Modularized Collaboration",
        "link": "/arxiv/2512.11213",
        "arxiv_id": "2512.11213",
        "authors": "Dongwon Jung, Peng Shi, Yi Zhang",
        "summary": "Scaling test-time computation improves large language model performance without additional training. Recent work demonstrates that techniques such as repeated sampling, self-verification, and self-reflection can significantly enhance task success by allocating more inference-time compute. However, applying these techniques across multiple agents in a multi-agent system is difficult: there does not exist principled mechanisms to allocate compute to foster collaboration among agents, to extend test-time scaling to collaborative interactions, or to distribute compute across agents under explicit budget constraints. To address this gap, we propose FutureWeaver, a framework for planning and optimizing test-time compute allocation in multi-agent systems under fixed budgets. FutureWeaver introduces modularized collaboration, formalized as callable functions that encapsulate reusable multi-agent workflows. These modules are automatically derived through self-play reflection by abstracting recurring interaction patterns from past trajectories. Building on these modules, FutureWeaver employs a dual-level planning architecture that optimizes compute allocation by reasoning over the current task state while also speculating on future steps. Experiments on complex agent benchmarks demonstrate that FutureWeaver consistently outperforms baselines across diverse budget settings, validating its effectiveness for multi-agent collaboration in inference-time optimization.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2025-12-15T11:00:03.667348",
        "filter_reason": "这篇论文完全符合我的研究范围，应被保留。以下是我的详细判断过程： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出了一个名为 **FutureWeaver** 的新框架。这个框架并非将现有智能体作为工具应用到某个特定领域，而是专注于**改进多智能体系统本身的运作机制**。它解决了“如何在多智能体系统中规划和分配测试时计算资源以促进协作”这一核心问题。 - **判断**: 这完全符合“构建、改进或演化 LLM智能体”的核心目标。因此，在第一步即判定为 **保留**。 2.  **第二步：正面指标** - 论文摘要中包含了大量与我研究焦点高度相关的核心范式和能力关键词： - **多智能体**: `Multi-Agent Systems`, `Collaboration`, `collaborative interactions`。这直接命中了我的第二个研究方向。 - **智能体能力**: `Planning`, `Self-Reflection`, `self-play reflection`。这命中了我的第一个研究方向（单智能体）。 - **演化机制**: `self-play reflection` 和从过去轨迹中抽象模式，体现了通过经验进行自我完善和迭代的机制，与我的第三个研究方向（自我演化）高度相关。 - **结论**: 论文在多个核心关注点上都有明确体现，相关性极高。 3.  **第三步：排除标准** - 论文的主要贡献是关于提升多智能体系统的协作效率和性能，而非安全、对齐或可解释性。摘要中未提及 `Safety`, `Alignment`, `Hallucination` 等关键词。 - 论文也未涉及视觉或多模态内容，其核心是语言模型和计算分配。 - **结论**: 论文未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的“双层规划架构”是典型的 **Agentic Planning**。它不是在提升LLM的基础数学或逻辑推理能力，而是在构建一个让智能体系统（多个智能体）如何进行高层规划和资源分配的框架。这完全符合“保留”的条件。 - **自我演化的应用**: 虽然这不是一个应用论文，但其核心机制“通过自我博弈反思自动派生模块”本身就蕴含了**自我演化**的思想。系统通过反思过去的交互经验，演化出更高效的协作模块（工作流），这是一种系统层面的自我完善。 5.  **第五步：最终决策** - **综合分析**: 这篇论文的核心贡献是构建了一个新颖的框架（FutureWeaver）来**改进多智能体系统的协作与规划能力**。它直接解决了多智能体研究中的一个关键挑战：如何在资源约束下优化智能体间的协作。其提出的“模块化协作”和“双层规划”机制，以及通过“自我博弈反思”来生成模块的方法，都是对LLM智能体构建和演化的直接贡献。 - **最终判断**: 该论文精准地落在我的研究焦点“多智能体”和“自我演化”的交叉领域，并且其方法论具有创新性。因此，最终判定为 **True**，必须保留。"
    },
    {
        "index": "#11",
        "title": "AgentBalance: Backbone-then-Topology Design for Cost-Effective Multi-Agent Systems under Budget Constraints",
        "link": "/arxiv/2512.11426",
        "arxiv_id": "2512.11426",
        "authors": "Shuowei Cai, Yansong Ning, Hao Liu",
        "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) are becoming indispensable building blocks for web-scale applications such as web search, social network analytics, and online customer support, where cost-effectiveness is increasingly the primary constraint for large-scale deployment. While recent work improves MAS cost-effectiveness by shaping inter-agent communication topologies and selecting agent backbones, it rarely models and optimizes under explicit token-cost and latency budgets that reflect deployment constraints. This often leads to topology-first designs and suboptimal cost-effectiveness when budgets are binding. We present AgentBalance, a framework for constructing cost-effective MAS under explicit token-cost and latency budgets via a backbone-then-topology design. AgentBalance first performs backbone-oriented agent generation, constructing agents with heterogeneous backbones through LLM pool construction, pool selection, and role-backbone matching. It then performs adaptive MAS topology generation, guiding inter-agent communication via agent representation learning, gating, and latency-aware topology synthesis. Experiments on benchmarks with 14 candidate LLM backbones show that AgentBalance achieves up to 10% and 22% performance gains under matched token-cost and latency budgets, respectively, and yields strong AUC on performance-versus-budget curves across benchmarks. AgentBalance also functions as a plug-in for existing MAS, improving performance under the same token-cost and latency constraints, and it generalizes well to unseen LLMs for practical, budget-aware deployment. Code: https://github.com/usail-hkust/AgentBalance",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.232231",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为 `AgentBalance` 的**新框架**，用于在预算（token成本和延迟）约束下，**构建和优化**多智能体系统（MAS）。其核心方法是“backbone-then-topology”设计，即先为智能体选择合适的主干模型，再设计它们之间的通信拓扑。这直接对应了您研究目标中的“**构建、改进或演化 LLM智能体**”，特别是“**改进**”这一方向。它不是将现有智能体框架应用到某个领域，而是提出了一个关于如何**设计智能体系统本身**的方法论，因此不属于“非演化型应用”或“基础设施”的排除范畴。 2.  **第二步：正面指标——高度相关** 论文明确包含了多个核心关注点： *   **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)` 是论文的绝对核心主题。 *   **多智能体**: 论文的核心贡献在于优化 `inter-agent communication topologies`（智能体间通信拓扑），这直接关系到多智能体系统的 `Collaboration`（协作）和 `Communication`（通信）效率。 3.  **第三步：排除标准——未触发** 论文的研究焦点是成本效益和性能优化，不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐问题。同时，它完全基于文本LLM的token成本，不涉及 `Vision` 或 `MLLMs` 等多模态内容。 4.  **第四步：处理特殊和模糊情况——不适用** 论文不涉及推理/规划的底层机制改进，也不涉及自我演化，因此该步骤的特殊规则不适用。 **最终决策**: 这篇论文的核心贡献在于提出了一种**改进多智能体系统设计**的新框架 `AgentBalance`，旨在解决大规模部署中的成本效益问题。它直接贡献于“**多智能体**”这一研究方向，通过优化智能体的“主干模型选择”和“通信拓扑结构”来提升整个系统的性能。这完全符合您筛选“核心贡献在于构建、改进或演化 LLM智能体”的论文的要求。因此，应予以保留。"
    },
    {
        "index": "#12",
        "title": "Towards Trustworthy Multi-Turn LLM Agents via Behavioral Guidance",
        "link": "/arxiv/2512.11421",
        "arxiv_id": "2512.11421",
        "authors": "Gonca Gürsun",
        "summary": "Large Language Models demonstrate strong reasoning and generation abilities, yet their behavior in multi-turn tasks often lacks reliability and verifiability. We present a task completion framework that enables LLM-based agents to act under explicit behavioral guidance in environments described by reinforcement learning formalisms with defined observation, action, and reward signals. The framework integrates three components: a lightweight task profiler that selects reasoning and generation strategies, a reasoning module that learns verifiable observation - action mappings, and a generation module that enforces constraint-compliant outputs through validation or deterministic synthesis. We show that as the agent interacts with the environment, these components co-evolve, yielding trustworthy behavior.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.232480",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出一个“任务完成框架”，该框架使LLM智能体能够在多轮任务中表现出可靠且可验证的行为。这直接属于“构建、改进或演化LLM智能体的方法论或新框架”。论文明确指出，框架的三个组件（任务分析器、推理模块、生成模块）在智能体与环境交互时会“共同演化”，这直接命中了“自我演化”的核心目标。因此，这篇论文不是简单的应用，而是关于智能体构建和演化的基础性工作。 2.  **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **核心范式**: `LLM-based Agents` (标题和摘要中明确提及)。 *   **智能体能力**: `Planning` / `Reasoning` (摘要中的 \"reasoning module that learns verifiable observation - action mappings\" 描述了智能体的规划和推理能力)。 *   **演化机制**: `Self-Evolving` / `Co-evolve` (摘要中的 \"these components co-evolve\" 是最关键的正面指标，直接对应您的研究焦点“自我演化”)。 3.  **第三步：排除标准——未触犯** 论文标题中的 \"Trustworthy\" 可能会引起关于“安全与对齐”的担忧。然而，摘要明确将其定义为“reliability”（可靠性）和“verifiability”（可验证性），并且这是通过其提出的框架和演化机制**实现的结果**，而非论文研究的**核心内容**。论文的主要贡献是那个能够实现这种可靠行为的、可演化的框架本身，而不是对安全、对齐或可解释性的理论分析。因此，它不属于被排除的类别。 4.  **第四步：特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文中的推理是智能体在环境中的行为推理，即学习“观察-行动映射”，这完全符合“智能体如何进行规划或在复杂任务中进行多步推理”的保留标准。 *   **自我演化**: 论文的核心亮点之一就是“co-evolve”机制，这完全符合“自我演化”的定义，即智能体通过与环境交互进行自我完善和迭代。 **最终决策**: 该论文的核心贡献在于构建了一个新颖的LLM智能体框架，其最突出的特点是框架内的组件能够“共同演化”，从而提升智能体在多轮任务中的可靠性和可验证性。这精准地契合了您研究课题中的“单智能体”（规划、推理）和“自我演化”两个核心方向。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#14",
        "title": "TriFlow: A Progressive Multi-Agent Framework for Intelligent Trip Planning",
        "link": "/arxiv/2512.11271",
        "arxiv_id": "2512.11271",
        "authors": "Yuxing Chen, Basem Suleiman, Qifan Chen",
        "summary": "Real-world trip planning requires transforming open-ended user requests into executable itineraries under strict spatial, temporal, and budgetary constraints while aligning with user preferences. Existing LLM-based agents struggle with constraint satisfaction, tool coordination, and efficiency, often producing infeasible or costly plans. To address these limitations, we present TriFlow, a progressive multi-agent framework that unifies structured reasoning and language-based flexibility through a three-stage pipeline of retrieval, planning, and governance. By this design, TriFlow progressively narrows the search space, assembles constraint-consistent itineraries via rule-LLM collaboration, and performs bounded iterative refinement to ensure global feasibility and personalisation. Evaluations on TravelPlanner and TripTailor benchmarks demonstrated state-of-the-art results, achieving 91.1% and 97% final pass rates, respectively, with over 10x runtime efficiency improvement compared to current SOTA.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.233025",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为 **TriFlow 的渐进式多智能体框架**。摘要明确指出，该框架是为了解决“现有LLM智能体在约束满足、工具协调和效率方面的局限性”。这表明论文的本质是**构建和改进LLM智能体（特别是多智能体系统）的方法论**，而不是简单地将一个已有的智能体应用到旅行规划领域。因此，它通过了第一步的核心判断，不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** 论文包含了多个您的核心关注点： *   **核心范式**: `Multi-Agent Systems (MAS)` - 标题和摘要中明确提及。 *   **智能体能力**: `Planning` - 框架的核心三阶段之一就是“规划”。`Tool Use / Tool Augmentation` - 摘要中提到了“工具协调”和“规则-LLM协作”。`Self-Correction` - 摘要中的“有界迭代优化”是自我修正的一种体现。 *   **多智能体**: `Collaboration` - “规则-LLM协作”体现了智能体（或组件）间的协作。 这些正面指标进一步确认了论文与您研究方向的强相关性。 3.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全与对齐（Safety, Alignment）、多模态（Vision）等排除标准。其焦点完全集中在智能体的框架设计和能力提升上。 4.  **第四步：处理特殊和模糊情况——符合保留条件** *   **推理/规划**: 论文中的规划部分，明确是关于智能体如何在一个复杂任务（旅行规划）中进行多步推理和决策（通过三阶段管道）。这完全符合“保留”的条件，因为它研究的是智能体的规划框架，而非LLM本身的基础推理能力。 *   **自我演化的应用**: 虽然论文的核心不是提出一种全新的“自我演化”机制，但其“迭代优化”环节与自我修正和自我完善紧密相关，属于智能体能力演化的范畴。 **最终决策**: 综合以上分析，这篇论文的核心是**构建一个新的多智能体框架（TriFlow）来提升LLM智能体在复杂规划任务中的表现**。它直接贡献于“多智能体”和“单智能体（规划、工具使用、自我修正）”这两个研究方向，与您的研究目标“LLM智能体及其演化”高度契合。因此，最终判断为 **True**。"
    },
    {
        "index": "#15",
        "title": "A-LAMP: Agentic LLM-Based Framework for Automated MDP Modeling and Policy Generation",
        "link": "/arxiv/2512.11270",
        "arxiv_id": "2512.11270",
        "authors": "Hong Je-Gal, Chan-Bin Yi, Hyun-Suk Lee",
        "summary": "Applying reinforcement learning (RL) to real-world tasks requires converting informal descriptions into a formal Markov decision process (MDP), implementing an executable environment, and training a policy agent. Automating this process is challenging due to modeling errors, fragile code, and misaligned objectives, which often impede policy training. We introduce an agentic large language model (LLM)-based framework for automated MDP modeling and policy generation (A-LAMP), that automatically translates free-form natural language task descriptions into an MDP formulation and trained policy. The framework decomposes modeling, coding, and training into verifiable stages, ensuring semantic alignment throughout the pipeline. Across both classic control and custom RL domains, A-LAMP consistently achieves higher policy generation capability than a single state-of-the-art LLM model. Notably, even its lightweight variant, which is built on smaller language models, approaches the performance of much larger models. Failure analysis reveals why these improvements occur. In addition, a case study also demonstrates that A-LAMP generates environments and policies that preserve the task's optimality, confirming its correctness and reliability.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.233285",
        "filter_reason": "这篇论文完全符合我的研究范围，应予以保留。我的判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是**构建一个全新的、基于LLM的智能体框架（A-LAMP）**，用于自动化完成一个复杂的多步骤任务：将自然语言描述转换为MDP模型、生成可执行环境并训练策略。这并非简单地将一个已有的智能体框架（如ReAct）应用到强化学习领域，而是**提出了一种新的方法论和框架**来解决“自动化RL流程”这一挑战。因此，它不属于“非演化型应用”的排除范畴，其本质是关于“构建LLM智能体”。 2.  **第二步：正面指标 (高度匹配)** 论文与我的核心关注点高度契合： *   **核心范式**: 标题和摘要中明确使用了 `Agentic LLM-Based Framework`，直接命中核心关键词。 *   **智能体能力**: A-LAMP框架的工作流程——将“自动化MDP建模和策略生成”这一复杂任务**分解为建模、编码、训练等多个可验证的阶段**——是典型的智能体**规划**能力。同时，它利用LLM生成代码和MDP定义，这属于**工具使用**。摘要中提到的“失败分析”也体现了某种形式的**自我反思**。 3.  **第三步：排除标准 (不适用)** 论文的研究焦点是提升智能体的自动化构建能力和任务执行效率，完全不涉及安全、对齐、可解释性或多模态等排除标准。 4.  **第四步：处理特殊和模糊情况 (符合保留条件)** *   **推理/规划**: 这篇论文是“智能体如何进行规划或在复杂任务中进行多步推理”的绝佳范例。它不是在研究如何提升LLM本身的基础数学或逻辑推理能力，而是在构建一个能够自主规划并执行一系列复杂操作（建模、编码、训练）的智能体框架。这完全符合保留条件。 **总结**: 该论文的核心贡献在于**构建了一个新颖的LLM智能体框架（A-LAMP）**，该框架通过**规划和工具使用**来自动化完成一个复杂的、多阶段的任务。这直接对应了我研究目标中的“构建LLM智能体”以及“单智能体”方向下的“规划”和“工具使用”子方向。因此，这篇论文是高度相关的前沿研究，必须保留。"
    },
    {
        "index": "#31",
        "title": "Atomic Action Slicing: Planner-Aligned Options for Generalist VLA Agents",
        "link": "/arxiv/2512.11584",
        "arxiv_id": "2512.11584",
        "authors": "Stefan Tabakov, Asen Popov, Dimitar Dimitrov, S. Ensiye Kiyamousavi, Vladimir Hristov, Boris Kraychev",
        "summary": "Current vision-language-action (VLA) models generalize poorly, particularly when tasks require new compositions of skills or objects. We introduce Atomic Action Slicing (AAS), a planner-aligned approach that decomposes long-horizon demonstrations into short, typed atomic actions that are easier for planners to use and policies to learn. Using LIBERO demonstrations, AAS produces a validated dataset of 2,124 atomic segments labeled with action type, temporal span, and confidence. A stronger segmenter (Gemini 2.5 Pro) closely matches planner-defined plans and remains robust under keyframe jitter, while smaller models perform worse on multi-object tasks. Fine-tuning CLIP-RT+ on our atomic dataset improves task success from 94.2% to 95.3% on LIBERO-Goal and 83.8% to 88.8% on LIBERO-Long. We publicly release the GATE-VLAP dataset on HuggingFace(https://huggingface.co/datasets/gate-institute/GATE-VLAP-datasets)",
        "subjects": "Machine Learning, Artificial Intelligence, Robotics",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.238281",
        "filter_reason": "这篇论文符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出了一种名为“原子动作切片”的新方法。这种方法论旨在通过将长期任务分解为更短、更基础的原子动作，来改进智能体的规划过程和学习效率。这直接属于“构建、改进或演化 LLM智能体”的范畴，因为它不是简单应用现有智能体，而是在改进智能体内部的核心组件——规划器与策略的学习方式。因此，它通过了第一步的核心判断。 2.  **第二步：正面指标 (强相关)** 论文的核心贡献与你的研究焦点高度匹配。摘要中明确提到了 `Planner-Aligned`（与规划器对齐），并且其目标是让任务“easier for planners to use”（让规划器更容易使用）。这直接命中了“单智能体”方向下的 `Planning`（规划）这一核心能力。论文提出的方法论本质上是一种增强智能体规划能力的框架。 3.  **第三步：排除标准 (未触发)** - **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题。 - **多模态与视觉**: 这是本案例的关键点。虽然论文标题和摘要提到了 `VLA (Vision-Language-Action)` 模型，看似属于多模态范畴，但其核心贡献并非视觉模型本身。根据你的筛选规则：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，视觉是智能体感知和执行任务的环境/输入模态，但论文的核心创新点在于如何处理和分解任务序列（即AAS方法），以服务于规划器。因此，视觉是背景，而“规划”是核心，这符合例外情况，不应被排除。 4.  **第四步：特殊和模糊情况 (适用保留规则)** - **推理/规划**: 这篇论文是关于智能体如何进行规划的典型案例。它提出了一种新的框架（AAS）来辅助规划器进行更有效的长时程任务分解，完全符合“保留”的条件。它不是在提升LLM的基础推理能力，而是在构建一个更高级的Agentic规划框架。 **最终决策**: 综合以上分析，该论文的核心贡献在于提出了一种改进智能体规划能力的新方法论（AAS）。尽管它应用于视觉-语言-动作（VLA）领域，但其研究本质是关于智能体的规划框架，这与你的研究目标“构建、改进或演化 LLM智能体”中的“单智能体”方向高度一致。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#88",
        "title": "Scalable Data Synthesis for Computer Use Agents with Step-Level Filtering",
        "link": "/arxiv/2512.10962",
        "arxiv_id": "2512.10962",
        "authors": "Yifei He, Pranit Chawla, Yaser Souri, Subhojit Som, Xia Song",
        "summary": "Computer use agents (CUAs) can operate real-world digital interfaces but remain difficult to train due to the high cost of graphical user interface (GUI) interaction and the scarcity of high-quality trajectory data. Existing datasets rely on human demonstrations, limiting scalability. A natural alternative is to synthesize data from strong CUAs, yet their rollouts are highly noisy, with incorrect or suboptimal actions consisting a large proportion of the steps, making naive imitation ineffective. To tackle this challenge, we introduce a scalable data synthesis pipeline that transforms noisy rollouts into reliable supervision without human annotation. The core idea is step-level filtering, which evaluates actions individually to retain only correct steps, complemented by reasoning augmentation for improved planning. Using this pipeline, we construct WebSTAR, a dataset of 13.3K trajectories and 100K graded, reasoning-rich steps synthesized from OpenAI's computer-use-preview model. We train Qwen-2.5-VL-Instruct models (7B and 32B) on WebSTAR. On WebVoyager, our 7B model surpasses SoTA open-source CUA model UI-TARS-1.5-7B by more than 15% with only supervised finetuning. Building on step-level grading, we further create WebSCORE, a dataset of graded step-level actions, and train StepRM, a 7B multimodal reward model distilled from o4-mini, which matches its grading quality while being far more efficient to deploy at scale. Our results establish step-level filtering as a key principle for scalable CUA training and construct two new datasets (WebSTAR, WebSCORE) and a lightweight reward model (StepRM) as practical tools to advance robust and efficient CUAs.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-22",
        "category": "cs.AI",
        "crawl_time": "2025-12-15T11:00:04.290074",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于提出了一种**构建和改进LLM智能体**的新方法论。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具去解决一个特定领域的问题，而是**提出了一种全新的、可扩展的数据合成管道（step-level filtering）来解决训练LLM智能体（特别是Computer Use Agents, CUAs）的核心瓶颈**。CUA本身就是一种典型的LLM智能体，它通过工具（计算机界面）与环境交互。论文的核心贡献是“如何构建更好的智能体”，而不是“用智能体做什么”，因此它直接命中了“构建、改进或演化LLM智能体”这一核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文通篇围绕 `LLM-based Agents` (即Computer Use Agents) 展开。 - **智能体能力**: 论文明确提到了 `Planning`（通过reasoning augmentation改进规划）和 `Tool Use`（使用GUI作为工具）。更重要的是，其核心的“step-level filtering”机制，本质上是一种**离线的自我修正/自我反思**。它评估智能体的行为轨迹，过滤掉错误步骤，保留正确步骤，这为智能体的学习和改进提供了高质量的监督信号，是智能体能力提升的关键环节。 - **演化机制**: 整个数据合成和训练流程体现了 `Iterative Improvement`（迭代改进）的思想，即利用一个更强的智能体来生成数据，用于训练一个更弱的智能体，从而实现性能的迭代提升。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐或可解释性，因此不触发排除标准。 - 论文虽然使用了多模态模型（`Qwen-2.5-VL`），但这完全符合您设定的例外情况。在这里，视觉能力是智能体**感知图形用户界面（GUI）这一环境的必要工具**，而不是研究的核心。研究的核心是**训练方法论**，而非视觉模型本身。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确讨论了如何通过“reasoning augmentation”来改进智能体的规划能力，这属于智能体框架下的多步推理，符合保留条件。 - **自我演化的应用**: 虽然论文的核心不是提出一个在运行时自我演化的智能体，但它提出的训练方法是实现智能体性能迭代和改进的关键技术，与“演化”的精神高度一致。 **最终决策**: 这篇论文的核心贡献是提出了一种名为“step-level filtering”的创新方法论，用于解决LLM智能体（特别是计算机使用智能体）训练中的数据难题。它直接服务于**构建和改进更强大的LLM智能体**这一目标，涉及了智能体的规划、工具使用和自我修正等核心能力。因此，这篇论文与您关于“LLM智能体及其演化”的研究课题高度相关，应该被保留。"
    }
]