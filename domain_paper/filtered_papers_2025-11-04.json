[
    {
        "index": "#5",
        "title": "From Solo to Symphony: Orchestrating Multi-Agent Collaboration with Single-Agent Demos",
        "link": "/arxiv/2511.02762",
        "arxiv_id": "2511.02762",
        "authors": "Xun Wang, Zhuoran Li, Yanshan Lin, Hai Zhong, Longbo Huang",
        "summary": "Training a team of agents from scratch in multi-agent reinforcement learning (MARL) is highly inefficient, much like asking beginners to play a symphony together without first practicing solo. Existing methods, such as offline or transferable MARL, can ease this burden, but they still rely on costly multi-agent data, which often becomes the bottleneck. In contrast, solo experiences are far easier to obtain in many important scenarios, e.g., collaborative coding, household cooperation, and search-and-rescue. To unlock their potential, we propose Solo-to-Collaborative RL (SoCo), a framework that transfers solo knowledge into cooperative learning. SoCo first pretrains a shared solo policy from solo demonstrations, then adapts it for cooperation during multi-agent training through a policy fusion mechanism that combines an MoE-like gating selector and an action editor. Experiments across diverse cooperative tasks show that SoCo significantly boosts the training efficiency and performance of backbone algorithms. These results demonstrate that solo demonstrations provide a scalable and effective complement to multi-agent data, making cooperative learning more practical and broadly applicable.",
        "subjects": "Machine Learning, Multiagent Systems",
        "date": "2025-11-04",
        "category": "cs.MA",
        "crawl_time": "2025-11-05T11:00:03.918866",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为 **Solo-to-Collaborative RL (SoCo)** 的新**框架**。这个框架旨在解决多智能体强化学习（MARL）中训练效率低下的根本性问题。它不是将已有的智能体框架应用到一个新领域（如医疗或金融），而是提出了一种**构建和改进多智能体系统**的新方法论。具体来说，它通过“策略融合机制”将单智能体的知识迁移并适配到多智能体协作场景中。这完全符合您“核心贡献在于构建、改进或演化LLM智能体”的要求，尤其是在“多智能体”方向上。 2.  **第二步：正面指标——高度匹配** 论文摘要中明确包含了您关注的核心范式和能力： *   **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对主题。`Collaboration`（协作）是其解决的核心问题。 *   **智能体能力**: 论文虽然未直接使用 `Planning` 一词，但“orchestrating multi-agent collaboration”（编排多智能体协作）和“cooperative learning”（合作学习）本质上就是关于多智能体如何进行联合规划和行动决策，这与您的关注点高度一致。 3.  **第三步：排除标准——未触发** 论文的研究焦点是提升多智能体系统的训练效率和性能，完全不涉及 `Safety`、`Alignment`、`Interpretability` 或 `Vision` 等排除领域。因此，该标准不适用。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 论文的研究内容属于“推理/规划”的范畴。它不是在提升LLM本身的基础数学或逻辑推理能力，而是在研究**智能体（特别是多智能体）如何进行协作规划和决策**。这完全符合您“保留关于智能体如何进行规划或在复杂任务中进行多步推理”的规则。 **总结**: 该论文的本质是提出了一种创新的**多智能体系统构建与优化方法**。它解决了多智能体训练中的一个关键瓶颈（数据稀缺），并提出了一套完整的技术框架（SoCo）来利用单智能体数据提升多智能体协作的效率和性能。这直接命中了您研究课题中的“多智能体”方向，并且是关于“构建、改进”智能体的核心方法论研究，而非简单的应用。因此，这篇论文是您应该保留的高质量前沿研究。"
    },
    {
        "index": "#3",
        "title": "EvoMem: Improving Multi-Agent Planning with Dual-Evolving Memory",
        "link": "/arxiv/2511.01912",
        "arxiv_id": "2511.01912",
        "authors": "Wenzhe Fan, Ning Yan, Masood Mortazavi",
        "summary": "Planning has been a cornerstone of artificial intelligence for solving complex problems, and recent progress in LLM-based multi-agent frameworks have begun to extend this capability. However, the role of human-like memory within these frameworks remains largely unexplored. Understanding how agents coordinate through memory is critical for natural language planning, where iterative reasoning, constraint tracking, and error correction drive the success. Inspired by working memory model in cognitive psychology, we present EvoMem, a multi-agent framework built on a dual-evolving memory mechanism. The framework consists of three agents (Constraint Extractor, Verifier, and Actor) and two memory modules: Constraint Memory (CMem), which evolves across queries by storing task-specific rules and constraints while remains fixed within a query, and Query-feedback Memory (QMem), which evolves within a query by accumulating feedback across iterations for solution refinement. Both memory modules are reset at the end of each query session. Evaluations on trip planning, meeting planning, and calendar scheduling show consistent performance improvements, highlighting the effectiveness of EvoMem. This success underscores the importance of memory in enhancing multi-agent planning.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Machine Learning",
        "date": "2025-11-01",
        "category": "cs.MA",
        "crawl_time": "2025-11-05T11:00:03.918306",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了“多智能体”和“自我演化”两个核心方向。 1.  **第一步：核心判断 (保留)** 论文的核心本质是**构建一个新的LLM多智能体框架**。它提出了一个名为EvoMem的框架，其核心创新是一种“双演化记忆机制”。这并非将现有框架简单应用于某个领域，而是对智能体架构本身的改进和创新，因此符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标 (高度匹配)** 论文包含了大量您关注的核心指标： *   **核心范式**: `Multi-Agent Systems (MAS)` 和 `Self-Evolving`。标题和摘要中反复强调“Multi-Agent”和“Evolving”。 *   **智能体能力**: `Planning` 是论文的核心主题，`Memory` 是其核心创新点。 *   **多智能体**: 论文明确提出了由三个智能体（Constraint Extractor, Verifier, Actor）组成的系统，它们通过记忆进行协作，这直接对应了`Collaboration`和`Communication`。 *   **演化机制**: 论文的精髓在于其演化机制。它详细描述了两种记忆模块（CMem和QMem）如何在不同时间尺度上进行演化（`evolves across queries` 和 `evolves within a query`），这完全符合`Self-Improvement`和`Iterative Improvement`的定义。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献是关于智能体的架构和演化机制，而非安全、对齐或多模态技术。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文研究的是智能体如何通过记忆和协作进行复杂的多步规划，这属于智能体框架层面的规划，符合保留条件。 *   **自我演化的应用**: 论文虽然应用在旅行规划等具体任务上，但其核心是提出一种新的“自我演化”记忆机制。根据您的规则，即使应用在特定领域，只要核心是新的演化机制，就应该保留。本论文正是这种情况。 **结论**: 该论文的核心贡献是提出了一种带有双演化记忆机制的多智能体规划框架，精准地落在您“多智能体”和“自我演化”的研究焦点上。它不是简单的应用，而是对智能体能力的根本性增强，因此是您应该保留的高质量前沿论文。"
    },
    {
        "index": "#6",
        "title": "Modeling Hawkish-Dovish Latent Beliefs in Multi-Agent Debate-Based LLMs for Monetary Policy Decision Classification",
        "link": "/arxiv/2511.02469",
        "arxiv_id": "2511.02469",
        "authors": "Kaito Takano, Masanori Hirano, Kei Nakagawa",
        "summary": "Accurately forecasting central bank policy decisions, particularly those of the Federal Open Market Committee(FOMC) has become increasingly important amid heightened economic uncertainty. While prior studies have used monetary policy texts to predict rate changes, most rely on static classification models that overlook the deliberative nature of policymaking. This study proposes a novel framework that structurally imitates the FOMC's collective decision-making process by modeling multiple large language models(LLMs) as interacting agents. Each agent begins with a distinct initial belief and produces a prediction based on both qualitative policy texts and quantitative macroeconomic indicators. Through iterative rounds, agents revise their predictions by observing the outputs of others, simulating deliberation and consensus formation. To enhance interpretability, we introduce a latent variable representing each agent's underlying belief(e.g., hawkish or dovish), and we theoretically demonstrate how this belief mediates the perception of input information and interaction dynamics. Empirical results show that this debate-based approach significantly outperforms standard LLMs-based baselines in prediction accuracy. Furthermore, the explicit modeling of beliefs provides insights into how individual perspectives and social influence shape collective policy forecasts.",
        "subjects": "Computational Finance, Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-04",
        "category": "cs.MA",
        "crawl_time": "2025-11-05T11:00:03.919126",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程和核心依据如下：** 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将LLM应用于金融预测领域。其核心贡献在于**提出了一种新颖的多智能体框架**，该框架通过模拟FOMC的辩论过程来解决问题。论文的核心是关于**如何构建和设计一个多智能体系统（Multi-Agent Systems）**，让LLM智能体在其中进行交互、辩论和迭代更新。这完全符合“构建、改进LLM智能体”的核心目标，而不是“非演化型应用”。 2.  **第二步：正面指标** - 论文命中了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 - **多智能体**: 论文明确研究了智能体间的 `Collaboration`（协作形成共识）、`Communication`（通过观察彼此输出进行通信）和 `Social Learning`（受他人影响而修正预测）。 - **演化机制**: 智能体通过“迭代轮次”来“修正其预测”，这是一种明确的 `Iterative Improvement`（迭代改进）和 `Self-Correction`（自我修正）机制，属于“自我演化”的范畴。 3.  **第三步：排除标准** - 论文虽然提到了“增强可解释性”，但这并非其主要贡献。可解释性是通过引入“潜在信念”变量来更好地理解和分析智能体行为的一种**手段**，其研究的核心依然是**多智能体框架的设计、构建与验证**。因此，这不触发“安全与对齐”或“可解释性”作为主要贡献的排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”的一个绝佳范例。尽管其应用场景是特定的“货币政策决策分类”，但其核心贡献是提出了一种**新的自我演化机制**——即基于多智能体辩论和信念更新的迭代改进框架。根据筛选规则“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”，这篇论文应被保留。 **最终决策**: 综合以上分析，该论文的核心贡献在于构建了一个创新的**多智能体辩论框架**，并研究了智能体通过交互和迭代进行**自我修正和演化**的机制。这直接命中了研究课题的“多智能体”和“自我演化”两个核心方向。因此，这篇论文与研究目标高度相关，应被筛选出来。"
    },
    {
        "index": "#4",
        "title": "Controlling Performance and Budget of a Centralized Multi-agent LLM System with Reinforcement Learning",
        "link": "/arxiv/2511.02755",
        "arxiv_id": "2511.02755",
        "authors": "Bowen Jin, TJ Collins, Donghan Yu, Mert Cemri, Shenao Zhang, Mengyu Li, Jay Tang, Tian Qin, Zhiyang Xu, Jiarui Lu, Guoli Yin, Jiawei Han, Zirui Wang",
        "summary": "Large language models (LLMs) exhibit complementary strengths across domains and come with varying inference costs, motivating the design of multi-agent LLM systems where specialized models collaborate efficiently. Existing approaches predominantly rely on decentralized frameworks, which invoke multiple LLMs for every input and thus lead to substantial and uncontrolled inference costs. In this work, we introduce a centralized multi-LLM framework, where a controller LLM selectively coordinates a pool of expert models in a cost-efficient and cost-controllable manner. We formulate this coordination problem as reinforcement learning with dual objectives: maximizing task performance while minimizing the overall inference cost. In addition, we expect the multi-agent system to have adapted behavior with different budget conditions during inference. To this end, we propose CoRL, a reinforcement learning framework that optimizes the performance cost trade-off in a controllable multi-budget setting. Experiments on four diverse benchmarks demonstrate that CoRL enables a single system to surpass the best expert LLM under high-budget settings, while maintaining strong performance in more economical low-budget modes, highlighting the effectiveness of centralized coordination for scalable and cost-efficient multi-agent LLM systems.",
        "subjects": "Computation and Language",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.310100",
        "filter_reason": "这篇论文完全符合您的研究范围，核心贡献在于构建和改进一个多智能体LLM系统。 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体框架应用到某个特定领域，而是提出了一种全新的**集中式多智能体LLM框架**。其核心贡献是设计了一个“控制器LLM”来协调一组“专家模型”，这是一种关于如何**构建和改进**多智能体系统的方法论创新。它解决了现有去中心化方法成本高昂且不可控的问题，因此属于对智能体系统本身的改进，而非简单的应用。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 - **多智能体**: 论文的核心是智能体间的 `Collaboration`（协作）和 `Communication`（通信），通过一个中央控制器来优化这种协作。 - **智能体能力**: “控制器LLM”的职责是进行规划和决策（`Planning`），决定在特定任务和预算下调用哪个专家模型，这是一种高级的智能体能力。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment`、`Interpretability` 或 `Vision` 等排除领域。其焦点完全在智能体的系统架构和协调机制上。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“控制器LLM”所执行的协调和选择任务，完全符合“智能体如何进行规划或在复杂任务中进行多步推理”的保留标准。它不是在提升单个LLM的基础推理能力，而是在构建一个能够进行高级规划和资源分配的智能体系统。 **最终决策**: 该论文的核心贡献是提出了一种名为CoRL的强化学习框架，用于构建一个**集中式、成本可控的多智能体LLM系统**。这直接命中了您研究范围中的“多智能体”方向，并且是关于“构建、改进LLM智能体”的方法论创新。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#2",
        "title": "MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning",
        "link": "/arxiv/2511.02805",
        "arxiv_id": "2511.02805",
        "authors": "Qianhao Yuan, Jie Lou, Zichao Li, Jiawei Chen, Yaojie Lu, Hongyu Lin, Le Sun, Debing Zhang, Xianpei Han",
        "summary": "Typical search agents concatenate the entire interaction history into the LLM context, preserving information integrity but producing long, noisy contexts, resulting in high computation and memory costs. In contrast, using only the current turn avoids this overhead but discards essential information. This trade-off limits the scalability of search agents. To address this challenge, we propose MemSearcher, an agent workflow that iteratively maintains a compact memory and combines the current turn with it. At each turn, MemSearcher fuses the user's question with the memory to generate reasoning traces, perform search actions, and update memory to retain only information essential for solving the task. This design stabilizes context length across multi-turn interactions, improving efficiency without sacrificing accuracy. To optimize this workflow, we introduce multi-context GRPO, an end-to-end RL framework that jointly optimize reasoning, search strategies, and memory management of MemSearcher Agents. Specifically, multi-context GRPO samples groups of trajectories under different contexts and propagates trajectory-level advantages across all conversations within them. Trained on the same dataset as Search-R1, MemSearcher achieves significant improvements over strong baselines on seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on Qwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher even outperforms 7B-based baselines, demonstrating that striking a balance between information integrity and efficiency yields both higher accuracy and lower computational overhead. The code and models will be publicly available at https://github.com/icip-cas/MemSearcher",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.309044",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具去解决某个特定领域的问题，而是直接针对现有LLM智能体（特别是搜索智能体）的架构缺陷（长上下文、高计算成本）提出了一个全新的解决方案。其核心贡献是构建了一个名为 **MemSearcher** 的新智能体工作流，并为此设计了一个新的训练框架 **multi-context GRPO**。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。 2.  **第二步：正面指标** - 论文高度匹配您的核心关注点： - **核心范式**: 论文明确提出了一个 `LLM-based Agent` 工作流。 - **智能体能力**: 论文的核心创新点在于 **`Memory`** 管理（维护紧凑记忆、更新记忆），同时涉及 **`Planning`**（生成推理轨迹）和 **`Tool Use`**（执行搜索行动）。其工作流（推理-行动-更新记忆）与 `ReAct` 范式高度一致。 - **演化机制**: 论文提出的端到端强化学习框架（`multi-context GRPO`）旨在联合优化智能体的推理、搜索和记忆管理策略，这是一种通过训练进行**`Self-Improvement`**（自我完善）和**`Iterative Improvement`**（迭代改进）的机制，与“自我演化”方向紧密相关。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或幻觉等主题，因此没有触发排除标准。 - 论文也未涉及多模态或视觉内容，因此同样没有触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的推理是嵌入在智能体行动循环中的，是智能体为了完成任务而进行的规划，属于典型的Agentic推理，而非提升LLM本身基础能力的非Agentic推理。因此，符合保留条件。 - **自我演化的应用**: 虽然论文在搜索任务上进行了验证，但其核心是提出一种新的智能体架构和训练方法，而不是一个简单的应用。其训练方法本身就是一种演化机制，因此符合保留条件。 **总结**: 该论文的核心贡献是 **MemSearcher**，一个创新的LLM智能体框架，它通过引入动态记忆管理机制，解决了现有智能体的效率瓶颈。同时，它还提出了一个端到端的强化学习方法来优化这个智能体的核心能力（推理、工具使用、记忆）。这完全属于您研究课题中的 **“单智能体”** 方向，并触及了 **“自我演化”** 的训练机制。因此，这篇论文是您应该保留的前沿研究。"
    },
    {
        "index": "#25",
        "title": "Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for Understanding Anything",
        "link": "/arxiv/2511.02834",
        "arxiv_id": "2511.02834",
        "authors": "Huawei Lin, Yunzhi Shi, Tong Geng, Weijie Zhao, Wei Wang, Ravender Pal Singh",
        "summary": "Multimodal large language models (MLLMs) have shown strong capabilities but remain limited to fixed modality pairs and require costly fine-tuning with large aligned datasets. Building fully omni-capable models that can integrate text, images, audio, and video remains impractical and lacks robust reasoning support. In this paper, we propose an Agent-Omni framework that coordinates existing foundation models through a master-agent system, enabling flexible multimodal reasoning without retraining. The master agent interprets user intent, delegates subtasks to modality-specific agents, and integrates their outputs into coherent responses. Extensive experiments across text, image, audio, video, and omni benchmarks show that Agent-Omni consistently achieves state-of-the-art performance, particularly on tasks requiring complex cross-modal reasoning. Its agent-based design enables seamless integration of specialized foundation models, ensuring adaptability to diverse inputs while maintaining transparency and interpretability. In addition, the framework is modular and easily extensible, allowing future improvements as stronger models become available. %We release an open-source implementation to support continued research on scalable and reliable omni-modal reasoning.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.339923",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步核心判断：论文的核心贡献是构建一个新的多智能体框架。** 论文的核心并非简单应用现有智能体，而是提出了一个名为 \"Agent-Omni\" 的全新框架。该框架通过一个“主-智能体系统”来协调多个“特定模态的智能体”，这本质上是在构建一个多智能体系统（Multi-Agent Systems）来解决复杂问题。这完全符合“保留”标准中“构建LLM智能体、多智能体系统或自我演化的方法论或新框架”的要求。 2.  **第二步正面指标：论文高度契合您的核心关注点。** -   **核心范式**: 论文明确提出了一个 `Multi-Agent Systems (MAS)`，其“主-智能体系统”设计是典型的多智能体协作范式。 -   **智能体能力**: 主智能体负责“解释用户意图、委派子任务”，这直接对应了 `Planning`（规划）能力。它将其他模态的智能体作为工具来使用，这完全符合 `Tool Use / Tool Augmentation` 的定义。 -   **多智能体**: 整个框架的运作依赖于智能体间的 `Collaboration`（协作）和 `Communication`（通信），主智能体与模态智能体之间必须有信息交换才能完成任务。 3.  **第三步排除标准：论文成功规避了排除项。** -   **安全与对齐**: 论文虽然提到了 \"transparency and interpretability\"，但这只是其框架设计带来的一个优点，而非论文的主要研究贡献。论文的核心是框架的构建与性能，而非安全或对齐技术本身。 -   **多模态与视觉**: 这是本论文最巧妙的地方。虽然论文处理的是多模态任务，但它完全符合您设定的例外情况——“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，文本、图像、音频、视频等模态是智能体需要处理的“环境”或“对象”，而论文的“研究核心”是那个负责协调、规划和整合的“Agent-Omni框架”本身。它研究的是“如何用智能体架构来解决多模态问题”，而不是“如何改进多模态模型”。 4.  **第四步特殊与模糊情况处理：** -   **推理/规划**: 论文明确属于“保留”情况。它不是在改进LLM的基础推理能力，而是在构建一个能让智能体进行复杂多步推理（跨模态推理）的Agentic框架。主智能体的“委派子任务”和“整合输出”就是一种高级的规划和推理过程。 **总结**: 该论文的核心贡献在于提出了一种新颖的多智能体协作框架，通过主智能体进行规划和工具调用，来协同多个专业智能体完成复杂的跨模态任务。这完全属于您研究焦点中的“多智能体”和“单智能体”方向，是关于如何构建和改进LLM智能体的前沿研究。因此，应予以保留。"
    },
    {
        "index": "#28",
        "title": "VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual Representation",
        "link": "/arxiv/2511.02778",
        "arxiv_id": "2511.02778",
        "authors": "Kevin Qinghong Lin, Yuhao Zheng, Hangyu Ran, Dantong Zhu, Dongxing Mao, Linjie Li, Philip Torr, Alex Jinpeng Wang",
        "summary": "Code has emerged as a precise and executable medium for reasoning and action in the agent era. Yet, progress has largely focused on language-centric tasks such as program synthesis and debugging, leaving visual-centric coding underexplored. Inspired by how humans reason over sketches, we advocate SVG code as a compact, interpretable, and executable visual representation. We introduce VCode, a benchmark that reframes multimodal understanding as code generation: given an image, a model must produce SVG that preserves symbolic meaning for downstream reasoning. VCode covers three domains - general commonsense (MM-Vet), professional disciplines (MMMU), and visual-centric perception (CV-Bench). To assess symbolic fidelity, we propose CodeVQA, a novel evaluation protocol in which a policy model answers questions over rendered SVGs; correct answers indicate faithful symbolic preservation. Empirically, frontier VLMs struggle to generate faithful SVGs, revealing a persistent gap between language-centric and visual-centric coding. To close this gap, we introduce VCoder, an agentic framework that augments VLMs along two axes: (i) Thinking with Revision, which iteratively analyzes discrepancies and refines SVG code; and (ii) Acting with Visual Tools, where detectors and parsers supply structured cues such as objects, shapes, and text beyond the model's intrinsic capacity. Across benchmarks, frontier VLMs with strong reasoning capabilities score well overall yet remain limited in professional knowledge and 3D reasoning. VCoder delivers a 12.3-point overall gain over the top-performing Claude-4-Opus. Human studies show that both humans and VLMs perform worse on rendered SVGs, their consistency reveals the promise of symbolic visual representation. The benchmark and code are available at https://github.com/CSU-JPG/VCode.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.341280",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进一个LLM智能体框架。 1.  **核心判断 (第一步):** 论文的本质是提出一个名为 **VCoder** 的新颖 **agentic framework** (智能体框架)。它不是简单地将现有模型应用于某个领域，而是设计了一个新的方法论来增强VLMs在复杂任务上的能力。因此，它通过了第一步的核心判断，应该被**保留**。 2.  **正面指标 (第二步):** 论文包含了多个您关注的核心正面指标： *   **核心范式:** 论文明确提出了一个 \"agentic framework\"，直接命中 `Agentic AI` 和 `LLM-based Agents`。 *   **智能体能力:** VCoder框架的两个核心组件完美对应了您的研究焦点： *   `Thinking with Revision`: 这是一个典型的 **自我反思** 和 **自我修正** 机制，通过迭代分析差异来优化输出，属于 `Self-Correction` 和 `Self-Reflection` 范畴。 *   `Acting with Visual Tools`: 这明确描述了 **工具使用** (`Tool Use / Tool Augmentation`)，智能体调用外部检测器和解析器来获取自身无法直接感知的结构化信息。 *   **演化机制:** `Thinking with Revision` 的迭代优化过程，本身就是一种 **自我完善** (`Self-Improvement`) 和 **迭代改进** (`Iterative Improvement`) 的演化机制。 3.  **排除标准 (第三步):** *   **安全与对齐:** 论文完全不涉及安全、对齐或可解释性等问题。 *   **多模态与视觉:** 这是本论文最需要辨析的一点。虽然论文处理的是视觉任务（图像到SVG），但它完全符合您设定的例外情况：“**除非它们被用作智能体感知环境的工具，而不是研究的核心**”。在这里，视觉输入是智能体需要理解和交互的“环境”，而VLM是智能体的“大脑”。论文的核心贡献**不是**一个新的VLM模型或视觉算法，而是**如何构建一个智能体框架（VCoder）来组织和利用这些能力**。因此，它没有被排除。 4.  **特殊和模糊情况 (第四步):** *   **推理/规划:** 论文提出的 `Thinking with Revision` 是一个在智能体框架内的多步推理和规划过程，完全符合“保留”标准。 *   **自我演化的应用:** 论文的核心贡献是提出了一种新的“自我演化/修正”机制（`Thinking with Revision`），并将其应用于视觉领域。这完全符合您设定的“保留（例外）”规则。 **最终决策 (第五步):** 综合以上分析，这篇论文的核心贡献是 **VCoder，一个集成了自我反思和工具使用能力的LLM智能体框架**。它直接回应了您研究课题中的“单智能体”方向，特别是在“自我反思”和“工具使用”这两个子方向上做出了明确的创新。尽管其应用场景是多模态视觉，但研究的焦点始终是智能体架构本身，而非视觉模型或应用本身。因此，这篇论文是您研究范围内的前沿和高相关度文献。"
    },
    {
        "index": "#30",
        "title": "The Collaboration Gap",
        "link": "/arxiv/2511.02687",
        "arxiv_id": "2511.02687",
        "authors": "Tim R. Davidson, Adam Fourney, Saleema Amershi, Robert West, Eric Horvitz, Ece Kamar",
        "summary": "The trajectory of AI development suggests that we will increasingly rely on agent-based systems composed of independently developed agents with different information, privileges, and tools. The success of these systems will critically depend on effective collaboration among these heterogeneous agents, even under partial observability. Despite intense interest, few empirical studies have evaluated such agent-agent collaboration at scale. We propose a collaborative maze-solving benchmark that (i) isolates collaborative capabilities, (ii) modulates problem complexity, (iii) enables scalable automated grading, and (iv) imposes no output-format constraints, preserving ecological plausibility. Using this framework, we evaluate 32 leading open- and closed-source models in solo, homogeneous, and heterogeneous pairings. Our results reveal a \"collaboration gap\": models that perform well solo often degrade substantially when required to collaborate. Collaboration can break down dramatically; for instance, small distilled models that solve mazes well alone may fail almost completely in certain pairings. We find that starting with the stronger agent often improves outcomes, motivating a \"relay inference\" approach where the stronger agent leads before handing off to the weaker one, closing much of the gap. Our findings argue for (1) collaboration-aware evaluation, (2) training strategies developed to enhance collaborative capabilities, and (3) interaction design that reliably elicits agents' latent skills, guidance that applies to AI-AI and human-AI collaboration.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.342240",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个外部领域（如生物、金融）的问题，而是**直接研究LLM智能体本身的核心能力缺陷**。其核心贡献在于： 1.  **识别并量化了一个关键问题**：提出了“协作差距”这一概念，揭示了单个强大的智能体在协作环境中性能可能下降的现象。 2.  **提出了改进方法**：设计了一种名为“接力推理”的新交互范式，以改善异构智能体间的协作效果。 3.  **构建了评估基础设施**：提出了一个专门用于评估智能体协作能力的基准。 - 这些贡献直接指向了**“改进LLM智能体”**这一核心目标，特别是多智能体系统中的协作效率问题，因此完全符合保留标准。 2.  **第二步：正面指标** - 论文高度匹配你的核心关注点，尤其是**多智能体**方向。 - **核心范式**: 论文明确研究 `Multi-Agent Systems (MAS)`，特别是由不同模型构成的 `heterogeneous agents`（异构智能体）。 - **多智能体**: `Collaboration` 是论文的绝对核心主题。摘要中反复出现 `collaboration`, `collaborative capabilities`, `agent-agent collaboration`。同时，`Communication` 是协作的隐含前提。 - **智能体能力**: 迷宫求解任务本身需要 `Planning`（规划）能力，论文评估的是智能体在协作场景下的规划与执行。 3.  **第三步：排除标准** - 论文的主要贡献**不涉及**安全、对齐、可解释性或多模态。它的焦点是智能体的性能和交互机制，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的研究内容完全符合“保留”条件。它不是在提升LLM的基础数学或逻辑推理能力，而是在研究**智能体如何在复杂任务（迷宫求解）中进行多步规划和协作**，这正是Agentic AI的核心议题。 5.  **第五步：最终决策** - 综合来看，这篇论文是一篇典型的、高质量的多智能体系统研究。它不仅通过实证揭示了现有LLM智能体在协作中的一个普遍且重要的问题，还提出了具体的解决方案和评估方法。其核心贡献直接服务于“构建、改进或演化LLM智能体”的目标，特别是你研究焦点中的**“多智能体”**方向。因此，这篇论文与你的研究课题高度相关，必须保留。"
    },
    {
        "index": "#35",
        "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents to Deliberation",
        "link": "/arxiv/2511.02303",
        "arxiv_id": "2511.02303",
        "authors": "Zhiwei Zhang, Xiaomin Li, Yudi Lin, Hui Liu, Ramraj Chandradevan, Linlin Wu, Minhua Lin, Fali Wang, Xianfeng Tang, Qi He, Suhang Wang",
        "summary": "Large Language Models (LLMs) trained with reinforcement learning and verifiable rewards have achieved strong results on complex reasoning tasks. Recent work extends this paradigm to a multi-agent setting, where a meta-thinking agent proposes plans and monitors progress while a reasoning agent executes subtasks through sequential conversational turns. Despite promising performance, we identify a critical limitation: lazy agent behavior, in which one agent dominates while the other contributes little, undermining collaboration and collapsing the setup to an ineffective single agent. In this paper, we first provide a theoretical analysis showing why lazy behavior naturally arises in multi-agent reasoning. We then introduce a stable and efficient method for measuring causal influence, helping mitigate this issue. Finally, as collaboration intensifies, the reasoning agent risks getting lost in multi-turn interactions and trapped by previous noisy responses. To counter this, we propose a verifiable reward mechanism that encourages deliberation by allowing the reasoning agent to discard noisy outputs, consolidate instructions, and restart its reasoning process when necessary. Extensive experiments demonstrate that our framework alleviates lazy agent behavior and unlocks the full potential of multi-agent framework for complex reasoning tasks.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.349493",
        "filter_reason": "这篇论文完全符合您的研究范围，核心贡献在于改进多智能体LLM框架，属于“多智能体”方向的前沿研究。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个外部领域的问题，而是**直接针对多智能体LLM框架本身进行改进**。它识别并解决了现有多智能体推理框架中的一个关键缺陷——“懒惰智能体”行为，并提出了新的理论分析和方法论来优化智能体间的协作。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标，证明其高度相关性： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 - **多智能体**: 论文深入探讨了 `Collaboration`（协作）问题，并分析了智能体间的 `Communication`（通信）模式。 - **智能体能力**: 论文涉及 `Planning`（由meta-thinking agent执行）和一种高级的 `Self-Correction` / `Deliberation`（通过可验证奖励机制，允许推理智能体丢弃噪声输出并重启推理过程）。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐议题。 - 论文也未涉及 `Vision`、`MLLMs` 等多模态内容，其焦点纯粹在于基于文本的LLM智能体交互框架。 - 因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文虽然标题和摘要中多次提及“Reasoning”，但其焦点并非提升LLM本身的基础数学或逻辑推理能力。相反，它研究的是**在多智能体协作框架下，如何通过结构化的交互和奖励机制来促进有效的、多步的推理过程**。这完全符合“保留”的条件，因为它是在构建一个更优的Agentic推理框架。 **总结**: 该论文的核心贡献是提出了一种新的多智能体LLM框架，通过理论分析和引入“因果影响测量”与“可验证奖励机制”两种新方法，有效解决了多智能体协作中的“懒惰行为”和“信息噪声”问题。这直接推动了多智能体系统（Multi-Agent）的演进，使其在复杂推理任务中发挥更大潜力。因此，这篇论文是您研究课题“LLM智能体及其演化”中“多智能体”方向的理想筛选对象。"
    },
    {
        "index": "#39",
        "title": "Training Proactive and Personalized LLM Agents",
        "link": "/arxiv/2511.02208",
        "arxiv_id": "2511.02208",
        "authors": "Weiwei Sun, Xuhui Zhou, Weihua Du, Xingyao Wang, Sean Welleck, Graham Neubig, Maarten Sap, Yiming Yang",
        "summary": "While existing work focuses primarily on task success, we argue that effective real-world agents require optimizing three dimensions: productivity (task completion), proactivity (asking essential questions), and personalization (adapting to diverse user preferences). We introduce UserVille, an interactive environment with LLM-based user simulators enabling diverse, configurable user preferences. Leveraging UserVille, we introduce PPP, a multi-objective reinforcement learning approach that jointly optimizes all three dimensions: Productivity, Proactivity, and Personalization. Experiments on software engineering and deep research tasks show that agents trained with PPP achieve substantial improvements over strong baselines such as GPT-5 (+21.6 on average), demonstrating the ability to ask strategic clarifying questions, adapt to unseen user preferences, and improve task success through better interaction. This work demonstrates that explicitly optimizing for user-centered interaction is critical for building practical and effective AI agents.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.351828",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**构建和改进LLM智能体**，而非将其作为工具应用。摘要明确提出了两个核心创新：`PPP`（一种多目标强化学习方法）和`UserVille`（一个交互式环境）。这两个贡献都是为了**训练和优化LLM智能体本身**，使其具备更强的主动性和个性化能力。这直接命中了你“构建、改进或演化LLM智能体”的核心目标，因此应被保留。 2.  **正面指标 (第二步):** 论文包含了多个你的核心关注点： *   **核心范式:** 论文标题和摘要反复提及 `LLM Agents`，完全符合 `Agentic AI` 和 `LLM-based Agents` 的范式。 *   **智能体能力:** 论文聚焦于提升智能体的 `Proactivity`（主动性，通过提问澄清问题，这与规划和交互相关）和 `Personalization`（个性化，适应不同用户偏好，这与记忆和适应能力相关）。这些都是单智能体研究中的关键能力。 3.  **排除标准 (第三步):** 论文的主要贡献不涉及任何排除标准。它的焦点是提升智能体的交互效率和任务表现，而不是安全、对齐、可解释性或多模态技术。 4.  **特殊和模糊情况 (第四步):** 论文的研究内容可以被视为对智能体**规划和交互能力**的深化。它不是在提升LLM的基础数学或逻辑推理，而是在研究智能体如何通过与用户的交互（提问、适应）来更好地完成复杂任务。这完全符合“保留”关于智能体如何进行规划和多步推理的论文这一规则。 **总结:** 该论文提出了一种新的训练框架（PPP）和环境，旨在从方法论层面**改进LLM智能体的核心能力**（主动性和个性化）。其本质是关于“如何构建一个更好的智能体”，这与你的研究课题“LLM智能体及其演化”高度契合，特别是其中的“单智能体”方向。因此，这篇论文应该被保留。"
    },
    {
        "index": "#29",
        "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in Dynamic Environments for LLM Tool-Use Agents",
        "link": "/arxiv/2511.02734",
        "arxiv_id": "2511.02734",
        "authors": "Jiayu Liu, Cheng Qian, Zhaochen Su, Qing Zong, Shijue Huang, Bingxiang He, Yi R. Fung",
        "summary": "Current evaluations of Large Language Model (LLM) agents primarily emphasize task completion, often overlooking resource efficiency and adaptability. This neglects a crucial capability: agents' ability to devise and adjust cost-optimal plans in response to changing environments. To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities. Situated in the travel-planning domain, CostBench comprises tasks solvable via multiple sequences of atomic and composite tools with diverse, customizable costs. It also supports four types of dynamic blocking events, such as tool failures and cost changes, to simulate real-world unpredictability and necessitate agents to adapt in real time. Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and performance further dropping by around 40% under dynamic conditions. By diagnosing these weaknesses, CostBench lays the groundwork for developing future agents that are both economically rational and robust.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.341875",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了一个名为 **CostBench** 的基准。基准是评估和驱动技术进步的核心方法论工具。CostBench 专门用于评估 LLM 智能体在动态环境下的**成本最优规划和适应能力**。这直接服务于“构建、改进或演化 LLM 智能体”的核心目标。它不是将智能体作为工具去解决一个旅行规划问题，而是创建一个标准来衡量和诊断智能体在解决这类问题时的能力缺陷，从而为未来构建更优的智能体指明方向。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文包含了大量您关注的核心指标： - **核心范式**: `LLM-based Agents` (标题和摘要中明确提及)。 - **智能体能力**: `Planning` (cost-optimal planning, replanning), `Tool Use / Tool Augmentation` (LLM Tool-Use Agents, sequences of tools), `Adaptation` (adaptation in dynamic environments)。这些都属于“单智能体”研究范畴下的核心能力。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐或多模态，因此不触及任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”条件。它研究的不是提升 LLM 本身的基础数学或逻辑推理能力，而是**智能体如何进行规划**，特别是在多轮交互中考虑成本和动态变化的规划。这与 ReAct、ToT 等 Agentic 框架的研究精神一脉相承，关注的是智能体的行为和决策过程。 **总结**: 该论文的本质是提出一个用于评估和诊断 LLM 智能体核心能力（规划、工具使用、适应性）的新基准。通过揭示当前智能体在成本意识和动态适应方面的不足，它为未来构建更强大、更理性的智能体奠定了基础。这完全契合您“筛选出那些核心贡献在于构建、改进或演化 LLM 智能体的论文”的核心目标，特别是聚焦于“单智能体”方向。因此，这是一篇高度相关且有价值的前沿论文。"
    },
    {
        "index": "#41",
        "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating Individual Behavior in Purchasing Flood Insurance",
        "link": "/arxiv/2511.02119",
        "arxiv_id": "2511.02119",
        "authors": "Ziheng Geng, Jiachen Liu, Ran Cao, Lu Cheng, Dan M. Frangopol, Minghui Cheng",
        "summary": "Flood insurance is an effective strategy for individuals to mitigate disaster-related losses. However, participation rates among at-risk populations in the United States remain strikingly low. This gap underscores the need to understand and model the behavioral mechanisms underlying insurance decisions. Large language models (LLMs) have recently exhibited human-like intelligence across wide-ranging tasks, offering promising tools for simulating human decision-making. This study constructs a benchmark dataset to capture insurance purchase probabilities across factors. Using this dataset, the capacity of LLMs is evaluated: while LLMs exhibit a qualitative understanding of factors, they fall short in estimating quantitative probabilities. To address this limitation, InsurAgent, an LLM-empowered agent comprising five modules including perception, retrieval, reasoning, action, and memory, is proposed. The retrieval module leverages retrieval-augmented generation (RAG) to ground decisions in empirical survey data, achieving accurate estimation of marginal and bivariate probabilities. The reasoning module leverages LLM common sense to extrapolate beyond survey data, capturing contextual information that is intractable for traditional models. The memory module supports the simulation of temporal decision evolutions, illustrated through a roller coaster life trajectory. Overall, InsurAgent provides a valuable tool for behavioral modeling and policy analysis.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-11-03",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.352912",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建一个新的LLM智能体框架**。论文的核心贡献是提出了名为 \"InsurAgent\" 的智能体，并详细描述了其包含五个模块（感知、检索、推理、行动、记忆）的架构。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。 - 虽然论文的应用领域是洪水保险，但它并非简单地将一个已有的智能体框架（如ReAct）直接应用。相反，它为了解决特定问题（LLM在定量概率估计上的不足）而**设计了新的模块**（特别是结合RAG的检索模块和支持时间演化的记忆模块）。因此，它不属于“非演化型应用”的排除范畴，其核心贡献在于智能体本身的构建方法。 2.  **第二步：正面指标** - 论文包含了多个核心关注点，相关性很高： - **核心范式**: `LLM-based Agents` (标题和摘要中明确提及)。 - **智能体能力**: - `Tool Use / Tool Augmentation`: 论文的 `retrieval` 模块明确使用了检索增强生成（RAG），这是一种典型的工具使用能力，让智能体能够利用外部知识库。 - `Memory`: 论文明确提出了 `memory` 模块，用于“支持时间决策演化的模拟”，这是智能体研究中的一个关键能力。 - `Reasoning`: 论文包含 `reasoning` 模块，利用LLM的常识进行推断，这是智能体决策循环的核心部分。 3.  **第三步：排除标准** - 论文的主要贡献是关于智能体的行为建模和架构设计，不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐问题。 - 论文是纯文本智能体，不涉及 `Vision`, `MLLMs` 等多模态内容。 - 因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的 `reasoning` 模块是智能体框架的一部分，用于在特定任务中进行决策，这符合“保留”关于智能体如何进行推理的论文的条件。它不是关于提升LLM底层数学或逻辑能力的研究。 - **自我演化的应用**: 虽然论文的核心不是提出一种普适的“自我演化”机制，但其 `memory` 模块支持“时间决策演化”，这与“自我演化”中的“通过经验进行迭代”思想有交集。更重要的是，根据第一步的判断，其核心贡献是构建智能体，因此应用领域不影响其被保留。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于**提出了一种具有模块化架构（特别是工具使用和记忆能力）的新型LLM智能体**。这直接命中了研究课题中“单智能体”方向下的“工具使用”和“记忆”等子方向。尽管其应用场景是保险这一特定领域，但其方法论贡献是通用且前沿的，完全符合“构建、改进或演化LLM智能体”的核心目标。因此，应判定为 **True**。"
    },
    {
        "index": "#37",
        "title": "SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL Tuning",
        "link": "/arxiv/2511.02280",
        "arxiv_id": "2511.02280",
        "authors": "Fangxun Shu, Yongjie Ye, Yue Liao, Zijian Kang, Weijie Yin, Jiacong Wang, Xiao Liang, Shuicheng Yan, Chao Feng",
        "summary": "We introduce SAIL-RL, a reinforcement learning (RL) post-training framework that enhances the reasoning capabilities of multimodal large language models (MLLMs) by teaching them when and how to think. Existing approaches are limited by outcome-only supervision, which rewards correct answers without ensuring sound reasoning, and by uniform thinking strategies, which often lead to overthinking on simple tasks and underthinking on complex ones. SAIL-RL addresses these challenges with a dual reward system: the Thinking Reward, which evaluates reasoning quality through factual grounding, logical coherence, and answer consistency, and the Judging Reward, which adaptively determines whether deep reasoning or direct answering is appropriate. Experiments on the state-of-the-art SAIL-VL2 show that SAIL-RL improves reasoning and multimodal understanding benchmarks at both 4B and 8B scales, achieving competitive performance against commercial closed-source models such as GPT-4o, and substantially reduces hallucinations, establishing it as a principled framework for building more reliable and adaptive MLLMs. The code will be available at https://github.com/BytedanceDouyinContent/SAIL-RL.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-11-04",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.350614",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了一个名为 SAIL-RL 的**强化学习后训练框架**。这个框架的本质不是简单应用现有模型，而是构建一个**新的方法论**，用于教导模型“何时以及如何思考”。这直接触及了智能体的核心能力——**自主决策与规划**。它不是将LLM作为工具解决特定领域问题，而是改进LLM本身成为一个更智能的“思考者”，因此符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点。其核心范式是 **Agentic AI**，因为它旨在构建一个能自主判断和行动的模型。 - 在智能体能力方面，它直接涉及了 **Planning**（通过“Judging Reward”决定是否启动深度推理）和 **Self-Reflection**（通过“Thinking Reward”评估推理过程的质量）。整个框架旨在实现一种高级的、自适应的推理过程，这与 ReAct 等智能体框架的精神内核一致。 3.  **第三步：排除标准** - **安全与对齐**：虽然摘要中提到了“substantially reduces hallucinations”（大幅减少幻觉），但这被定位为 SAIL-RL 框架带来的一个**积极结果**，而非论文的**主要研究贡献**。论文的核心是提出“如何教会模型思考”的框架，而不是“如何解决幻觉问题”。因此，它没有触发此排除规则。 - **多模态与视觉**：这是最需要权衡的一点。论文确实聚焦于 MLLMs。然而，根据筛选标准的核心精神，我们应该判断“MLLM”是研究的**核心**还是**载体**。在这篇论文中，SAIL-RL 框架——即“双奖励机制来引导适应性思考”——才是其核心理论贡献。这个方法论本身是通用的，可以应用于纯文本LLM。MLLM在这里更多是作为验证该框架有效性的实验平台。因此，它不属于“将视觉作为研究核心”而被排除的情况。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**：这篇论文完美地符合“保留”条件。它不是在提升LLM的基础Token预测能力，而是在构建一个**控制推理过程的元框架**。其“Judging Reward”机制让模型能够像智能体一样，根据任务复杂度自主选择“直接回答”或“深度思考”，这是一种高级的规划和资源分配能力，远超传统的Chain-of-Thought变体。 **最终决策**： 综合以上分析，尽管论文的实验对象是MLLMs，但其**最根本、最核心的贡献**在于提出了一种新颖的、用于增强智能体**自主规划与自我反思能力**的通用框架（SAIL-RL）。这项工作直接推动了“如何构建更智能、更自适应的LLM智能体”这一前沿问题，与您“LLM智能体及其演化”的研究课题，特别是“单智能体”方向中的“规划”和“自我反思”子方向，高度契合。因此，应判定为符合要求。"
    },
    {
        "index": "#48",
        "title": "CudaForge: An Agent Framework with Hardware Feedback for CUDA Kernel Optimization",
        "link": "/arxiv/2511.01884",
        "arxiv_id": "2511.01884",
        "authors": "Zijian Zhang, Rong Wang, Shiyang Li, Yuebo Luo, Mingyi Hong, Caiwen Ding",
        "summary": "Developing efficient CUDA kernels is increasingly critical for AI applications such as large-scale LLM training. However, manual kernel design is both costly and time-consuming, motivating automatic approaches that leverage LLMs for code generation. Existing methods for automatic kernel generation, however, often produce low-efficiency kernels, incur high computational overhead, and fail to generalize across settings. In this work, we propose CudaForge, a training-free multi-agent workflow for CUDA kernel generation and optimization. Our workflow is inspired by the iterative workflow of human experts, which contains steps such as developing initial kernels, testing correctness, analyzing hardware feedback, and iterative improvement. More specifically, CudaForge employs two LLM agents: a Coder and a Judge, that iteratively generate, correct, and optimize CUDA kernels, while integrating hardware feedback such as Nsight Compute (NCU) metrics. In extensive evaluations, we show that CudaForge, by leveraging base models like OpenAI-o3, achieves 97.6\\% correctness of generated kernels and an average 1.68$\\times$ speedup over PyTorch baselines, substantially surpassing state-of-the-art models including OpenAI-o3 and Kevin on KernelBench. Beyond accuracy and speed, CudaForge demonstrates strong generalization across GPUs (A100, RTX 6000, 4090, 3090) and base models (OpenAI-o3, GPT-5, gpt-oss-120B, Claude-Sonnet-4, QwQ-32B), while maintaining high efficiency. In particular, generating an optimized kernel takes about 26.5 minutes on one RTX6000 and incurs about \\$ 0.3 API cost, which is significantly cheaper than existing agentic work that costs 6 H100 hours and \\$ 5 API cost per kernel. Our results highlight that multi-agent, training-free workflows can enable cost-effective, generalizable, and high-performance CUDA kernel optimization. Code available at https://github.com/OptimAI-Lab/CudaForge",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language, Distributed, Parallel, and Cluster Computing",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-11-05T11:00:04.363332",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建了一个新颖的多智能体自我演化框架。以下是我的详细判断过程： 1.  **第一步：核心判断——保留** 论文的核心并非CUDA内核优化这一具体应用，而是提出了一种名为 **CudaForge 的“免训练的多智能体工作流”**。摘要明确指出，该工作流包含“迭代生成、纠正和优化”的步骤，其本质是一个方法论和框架。这直接命中了“构建、改进或演化 LLM智能体”的核心目标。它不是简单地将LLM作为工具应用，而是设计了一个让LLM智能体协同工作的系统。 2.  **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **多智能体**: 明确提出了一个包含 `Coder` 和 `Judge` 两个角色的 `Multi-Agent Systems`。 *   **自我演化**: 整个框架的核心是 `Iterative Improvement`（迭代改进）。`Coder` 生成代码，`Judge` 基于反馈进行评判，然后 `Coder` 再进行修正，这是一个典型的 `Self-Evolving` 或 `Self-Improvement` 循环。 *   **工具使用**: 智能体整合了“硬件反馈”，如 Nsight Compute (NCU) 指标。这完全符合 `Tool Use / Tool Augmentation` 的定义，智能体利用外部工具（硬件性能分析器）来指导其行为。 *   **协作**: `Coder` 和 `Judge` 两个智能体之间存在明确的 `Collaboration` 和分工。 3.  **第三步：排除标准——不适用** 论文的主要贡献不涉及安全、对齐、可解释性或多模态视觉，因此不触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 这篇论文是“自我演化的应用”这一特殊情况的完美例证。虽然它被应用在“CUDA内核优化”这一特定领域，但根据您的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” CudaForge的核心创新正是这个**带有硬件反馈的多智能体迭代优化机制**，而非优化结果本身。这个机制具有通用性，可以迁移到其他需要代码生成、测试和迭代的场景。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个由 `Coder` 和 `Judge` 组成的多智能体系统，该系统通过迭代循环和工具使用（硬件反馈）实现了自我演化和完善。这精准地契合了您研究课题中的 **“多智能体”** 和 **“自我演化”** 两个核心方向。因此，这篇论文是高度相关且应被保留的前沿研究。"
    },
    {
        "index": "#3",
        "title": "Kosmos: An AI Scientist for Autonomous Discovery",
        "link": "/arxiv/2511.02824",
        "arxiv_id": "2511.02824",
        "authors": "Ludovico Mitchener, Angela Yiu, Benjamin Chang, Mathieu Bourdenx, Tyler Nadolski, Arvis Sulovari, Eric C. Landsness, Daniel L. Barabasi, Siddharth Narayanan, Nicky Evans, Shriya Reddy, Martha Foiani, Aizad Kamal, Leah P. Shriver, Fang Cao, Asmamaw T. Wassie, Jon M. Laurent, Edwin Melville-Green, Mayk Caldas, Albert Bou, Kaleigh F. Roberts, Sladjana Zagorac, Timothy C. Orr, Miranda E. Orr, Kevin J. Zwezdaryk, Ali E. Ghareeb, Laurie McCoy, Bruna Gomes, Euan A. Ashley, Karen E. Duff, Tonio Buonassisi, Tom Rainforth, Randall J. Bateman, Michael Skarlinski, Samuel G. Rodriques, Michaela M. Hinks, Andrew D. White",
        "summary": "Data-driven scientific discovery requires iterative cycles of literature search, hypothesis generation, and data analysis. Substantial progress has been made towards AI agents that can automate scientific research, but all such agents remain limited in the number of actions they can take before losing coherence, thus limiting the depth of their findings. Here we present Kosmos, an AI scientist that automates data-driven discovery. Given an open-ended objective and a dataset, Kosmos runs for up to 12 hours performing cycles of parallel data analysis, literature search, and hypothesis generation before synthesizing discoveries into scientific reports. Unlike prior systems, Kosmos uses a structured world model to share information between a data analysis agent and a literature search agent. The world model enables Kosmos to coherently pursue the specified objective over 200 agent rollouts, collectively executing an average of 42,000 lines of code and reading 1,500 papers per run. Kosmos cites all statements in its reports with code or primary literature, ensuring its reasoning is traceable. Independent scientists found 79.4% of statements in Kosmos reports to be accurate, and collaborators reported that a single 20-cycle Kosmos run performed the equivalent of 6 months of their own research time on average. Furthermore, collaborators reported that the number of valuable scientific findings generated scales linearly with Kosmos cycles (tested up to 20 cycles). We highlight seven discoveries made by Kosmos that span metabolomics, materials science, neuroscience, and statistical genetics. Three discoveries independently reproduce findings from preprinted or unpublished manuscripts that were not accessed by Kosmos at runtime, while four make novel contributions to the scientific literature.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.136642",
        "filter_reason": "这篇论文完全符合你的研究范围，应该被保留。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**构建了一个名为Kosmos的新型AI智能体框架**，而不是简单地将现有智能体作为工具应用到科学领域。摘要明确指出，与之前的系统不同，Kosmos的核心创新在于引入了一个“结构化世界模型”来协调“数据分析智能体”和“文献搜索智能体”。这个新框架解决了现有智能体在长期任务中“失去连贯性”的关键问题。因此，这篇论文的本质是关于**构建和改进LLM智能体的方法论**，完全符合“保留”标准。 2.  **正面指标 (第二步):** 论文包含了大量你的核心关注点： *   **核心范式:** 论文明确提出了一个 `LLM-based Agent` (AI Scientist) 和一个 `Multi-Agent System` (数据分析智能体与文献搜索智能体协同工作)。 *   **智能体能力:** Kosmos展现了高级的智能体能力，包括 `Planning` (执行迭代循环以达成目标)、`Tool Use` (执行代码、搜索文献) 和 `Memory` (通过“结构化世界模型”实现信息共享和长期连贯性)。 *   **演化机制:** 论文提到Kosmos的发现数量随其运行周期线性扩展，这体现了其 `Iterative Improvement` (迭代改进) 的能力，属于自我演化的范畴。 3.  **排除标准 (第三步):** 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态问题。它专注于智能体的架构和能力，因此没有触发任何排除标准。 4.  **特殊和模糊情况处理 (第四步):** *   **推理/规划:** Kosmos的整个工作流程（文献搜索 -> 假设生成 -> 数据分析 -> 报告合成）是一个典型的复杂多步 `Agentic Planning` 过程，而非提升LLM基础推理能力。 *   **自我演化的应用:** 这是最关键的一点。虽然论文将Kosmos应用到了具体的科学领域（代谢组学、材料科学等），但根据你的筛选规则，这属于“例外”情况。论文的核心是提出一种**新的智能体架构（结构化世界模型）**，这种架构本身实现了智能体在复杂任务中的长期连贯和迭代改进。因此，它不是“非演化型应用”，而是“提出一种新的自我演化/迭代机制的应用”，应该被保留。 **最终决策 (第五步):** 综合以上分析，这篇论文的核心贡献在于提出了一种创新的、基于世界模型的多智能体协作框架，以实现LLM智能体在复杂、长期任务中的自主发现。它直接触及了你研究课题中的“单智能体”（规划、记忆、工具使用）、“多智能体”（协作）和“自我演化”（迭代改进）三个核心方向。因此，这篇论文与你的研究目标高度相关，必须保留。"
    },
    {
        "index": "#15",
        "title": "Knowledge Graph-enhanced Large Language Model for Incremental Game PlayTesting",
        "link": "/arxiv/2511.02534",
        "arxiv_id": "2511.02534",
        "authors": "Enhong Mu, Jinyu Cai, Yijun Lu, Mingyue Zhang, Kenji Tei, Jialong Li",
        "summary": "The rapid iteration and frequent updates of modern video games pose significant challenges to the efficiency and specificity of testing. Although automated playtesting methods based on Large Language Models (LLMs) have shown promise, they often lack structured knowledge accumulation mechanisms, making it difficult to conduct precise and efficient testing tailored for incremental game updates. To address this challenge, this paper proposes a KLPEG framework. The framework constructs and maintains a Knowledge Graph (KG) to systematically model game elements, task dependencies, and causal relationships, enabling knowledge accumulation and reuse across versions. Building on this foundation, the framework utilizes LLMs to parse natural language update logs, identify the scope of impact through multi-hop reasoning on the KG, enabling the generation of update-tailored test cases. Experiments in two representative game environments, Overcooked and Minecraft, demonstrate that KLPEG can more accurately locate functionalities affected by updates and complete tests in fewer steps, significantly improving both playtesting effectiveness and efficiency.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.188888",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为KLPEG的框架，该框架通过结合知识图谱（KG）和大型语言模型（LLM）来执行增量游戏测试。我的判断过程如下： 1.  **第一步：核心判断——保留** 这篇论文的本质不是简单地将LLM作为工具应用于游戏测试领域。它的核心贡献在于**构建了一个具有特定能力的LLM智能体框架**。该框架通过引入知识图谱作为结构化的记忆系统，解决了现有LLM智能体在长期任务中缺乏知识积累和复用能力的问题。因此，它符合“构建、改进LLM智能体”的核心要求，应予以保留。 2.  **第二步：正面指标——高度相关** 论文内容与我的核心关注点高度契合： *   **Agentic AI / LLM-based Agents**: KLPEG本身就是一个LLM智能体框架。 *   **Memory**: 论文的核心创新点就是使用知识图谱（KG）作为智能体的**长期、结构化记忆**，用于积累和复用游戏知识。这直接命中了“单智能体”研究方向的关键能力。 *   **Planning / Reasoning**: 框架利用LLM在知识图谱上进行**多跳推理**，以确定游戏更新的影响范围并生成测试用例。这是一个典型的智能体规划和推理过程。 *   **Self-Evolving / Iterative Improvement**: 框架能够“维护”知识图谱，并实现“跨版本的知识积累和复用”。这意味着智能体能够从新的环境反馈（游戏更新日志）中学习，不断调整和优化其行为，这是一种**自我演化和迭代改进**的体现，完全符合“自我演化”的研究方向。 3.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性或多模态视觉模型。它使用的LLM是用于处理文本（更新日志）和推理，视觉（游戏画面）并非其研究核心。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文中的推理是智能体框架（KLPEG）为了完成任务（生成测试用例）而执行的多步规划过程，而非提升LLM本身的基础数学或逻辑能力，因此符合保留条件。 *   **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它应用在“游戏测试”这一特定领域，但其核心贡献是提出了一种**新的“自我演化”机制**（通过KG进行知识积累和跨版本复用）。根据筛选规则，这种情况应该保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个集成了**结构化记忆**和**多步推理**能力的LLM智能体，并且该智能体具备通过环境反馈进行**自我演化和迭代改进**的特性。这完全符合我关于“LLM智能体及其演化”的研究课题，特别是在“单智能体”的记忆、规划能力和“自我演化”机制上做出了明确的贡献。因此，最终判断为 **True (保留)**。"
    },
    {
        "index": "#18",
        "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for Long-Horizon Task Planning",
        "link": "/arxiv/2511.02424",
        "arxiv_id": "2511.02424",
        "authors": "Jae-Woo Choi, Hyungmin Kim, Hyobin Ong, Minsu Jang, Dohyung Kim, Jaehong Kim, Youngwoo Yoon",
        "summary": "Recent advancements in large language models (LLMs) have enabled significant progress in decision-making and task planning for embodied autonomous agents. However, most existing methods still struggle with complex, long-horizon tasks because they rely on a monolithic trajectory that entangles all past decisions and observations, attempting to solve the entire task in a single unified process. To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree. Each subgoal is handled by an LLM agent node capable of reasoning, acting, and further expanding the tree, while control flow nodes coordinate the execution strategies of agent nodes. In addition, we integrate two complementary memory systems: each agent node retrieves goal-specific, subgoal-level examples from episodic memory and shares environment-specific observations through working memory. Experiments on the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently outperforms strong task-planning baselines such as ReAct across diverse LLMs. Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5 72B, nearly doubling ReAct's 31%.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.196227",
        "filter_reason": "这篇论文完全符合研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一种名为 **ReAcTree** 的新颖方法论，用于构建和改进LLM智能体。其核心贡献不是将现有智能体应用于某个领域，而是设计了一个新的智能体框架（分层智能体树）来解决现有智能体在长视距任务规划中的局限性。这直接命中了“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文高度符合核心关注点。它明确属于 **Agentic AI** 和 **LLM-based Agents** 范畴。 - 其核心贡献集中在 **单智能体** 方向，特别是 **规划** 能力。它提出了一种新的分层规划方法，是对现有规划范式（如ReAct）的改进。 - 同时，论文还涉及了智能体的另一项关键能力：**记忆**。它集成了情景记忆和工作记忆系统来增强智能体性能。 - 关键词如 `Planning`, `ReAct`, `Memory` 均在摘要中明确出现，表明其与研究焦点高度相关。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性等排除标准。 - 虽然实验在具身智能体数据集上进行，可能涉及视觉感知，但论文的核心是**规划框架**本身，而不是视觉或多模态技术。视觉是智能体与环境交互的一部分，而非研究的核心创新点。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**：这篇论文是“保留”的典型案例。它不是在提升LLM的基础数学或逻辑推理能力，而是在构建一个让智能体能够进行复杂、多步、长视距任务规划的**新框架**。这与ReAct、ToT等属于同一研究脉络，是Agentic AI的核心研究内容。 **最终决策**：该论文的核心贡献是提出了一种新的LLM智能体架构，旨在通过分层规划和记忆机制来增强智能体的长视距任务解决能力。这完全符合“单智能体”方向下的“规划”和“记忆”子方向，是关于如何构建和改进LLM智能体的前沿研究。因此，应判定为符合要求。"
    },
    {
        "index": "#24",
        "title": "Deep Ideation: Designing LLM Agents to Generate Novel Research Ideas on Scientific Concept Network",
        "link": "/arxiv/2511.02238",
        "arxiv_id": "2511.02238",
        "authors": "Keyu Zhao, Weiquan Lin, Qirui Zheng, Fengli Xu, Yong Li",
        "summary": "Novel research ideas play a critical role in advancing scientific inquiries. Recent advancements in Large Language Models (LLMs) have demonstrated their potential to generate novel research ideas by leveraging large-scale scientific literature. However, previous work in research ideation has primarily relied on simplistic methods, such as keyword co-occurrence or semantic similarity. These approaches focus on identifying statistical associations in the literature but overlook the complex, contextual relationships between scientific concepts, which are essential to effectively leverage knowledge embedded in human literature. For instance, papers that simultaneously mention \"keyword A\" and \"keyword B\" often present research ideas that integrate both concepts. Additionally, some LLM-driven methods propose and refine research ideas using the model's internal knowledge, but they fail to effectively utilize the scientific concept network, limiting the grounding of ideas in established research. To address these challenges, we propose the Deep Ideation framework to address these challenges, integrating a scientific network that captures keyword co-occurrence and contextual relationships, enriching LLM-driven ideation. The framework introduces an explore-expand-evolve workflow to iteratively refine research ideas, using an Idea Stack to track progress. A critic engine, trained on real-world reviewer feedback, guides the process by providing continuous feedback on the novelty and feasibility of ideas. Our experiments show that our approach improves the quality of generated ideas by 10.67% compared to other methods, with ideas surpassing top conference acceptance levels. Human evaluation highlights their practical value in scientific research, and ablation studies confirm the effectiveness of each component in the workflow. Code repo is available at https://github.com/kyZhao-1/Deep-Ideation.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.199480",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和演化一个LLM智能体。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用于科学领域，而是**提出了一种全新的LLM智能体框架**。论文的核心是“Deep Ideation framework”的设计，包括其工作流、组件和交互机制。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标，尤其是在“单智能体”和“自我演化”方向上： - **核心范式**: 论文明确提出了一个`LLM-based Agents`框架。 - **智能体能力**: - `Planning`: 论文提出了一个`explore-expand-evolve`工作流，这是一个典型的多步规划和执行框架。 - `Memory`: 使用`Idea Stack`来跟踪想法的演进过程，这是一种结构化的记忆机制。 - `Self-Correction / Self-Reflection`: 引入了`critic engine`，通过提供持续的反馈来指导智能体进行自我反思和修正，这是智能体自我完善的关键。 - **演化机制**: - `Self-Improvement / Iterative Improvement`: 整个`explore-expand-evolve`工作流就是一个迭代改进和自我演化的过程，旨在通过循环反馈来提升想法的质量。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。`critic engine`的目的是评估想法的“新颖性”和“可行性”，属于任务导向的评估，而非AI安全或对齐研究。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的规划是智能体层面的。它不是在改进LLM的基础推理能力，而是在构建一个让智能体能够进行复杂任务规划和执行的框架。这符合“保留”标准。 - **自我演化的应用**: 这篇论文是“自我演化的应用”的一个绝佳范例。虽然它被应用在“科学思想生成”这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**（即带有批评引擎的探索-扩展-演化工作流）。根据您的规则，这种提出新机制的应用论文应该被保留。 **最终决策**: 综合以上分析，这篇论文的核心是设计一个具备规划、记忆和自我反思/纠正能力的LLM智能体，并通过一个迭代的工作流实现自我演化。它直接贡献于“单智能体”和“自我演化”的研究方向，与您的课题高度相关。因此，最终判断为 **True**。"
    },
    {
        "index": "#25",
        "title": "TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning in Tabular Data",
        "link": "/arxiv/2511.02219",
        "arxiv_id": "2511.02219",
        "authors": "Changjiang Jiang, Fengchang Yu, Haihua Chen, Wei Lu, Jin Zeng",
        "summary": "Complex reasoning over tabular data is crucial in real-world data analysis, yet large language models (LLMs) often underperform due to complex queries, noisy data, and limited numerical capabilities. To address these issues, we propose \\method, a framework consisting of: (1) a query decomposer that breaks down complex questions, (2) a table sanitizer that cleans and filters noisy tables, and (3) a program-of-thoughts (PoT)-based reasoner that generates executable code to derive the final answer from the sanitized table. To ensure unbiased evaluation and mitigate data leakage, we introduce a new dataset, CalTab151, specifically designed for complex numerical reasoning over tables. Experimental results demonstrate that \\method consistently outperforms existing methods, achieving state-of-the-art (SOTA) performance with 8.79%, 6.08%, and 19.87% accuracy improvement on TAT-QA, TableBench, and \\method, respectively. Moreover, our framework integrates seamlessly with mainstream LLMs, providing a robust solution for complex tabular numerical reasoning. These findings highlight the effectiveness of our framework in enhancing LLM performance for complex tabular numerical reasoning. Data and code are available upon request.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.200076",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个名为 TabDSR 的**框架**，该框架通过分解、清理和推理三个步骤来解决复杂表格数据推理问题。这并非简单地将LLM作为工具应用于表格领域，而是构建了一个具有特定工作流的**方法论**。该框架包含了智能体行为的关键要素，因此其本质是关于构建和改进LLM智能体的，应**保留**。 2.  **正面指标 (第二步):** 论文明确包含了我的核心关注点： *   **智能体能力:** 论文中的 `query decomposer` (查询分解器) 本质上是一种**规划**能力，它将复杂任务分解为可执行的子步骤。`program-of-thoughts (PoT)-based reasoner` 通过生成可执行代码来获得答案，这是一种典型的**工具使用**。这两个组件是单智能体研究的核心。 3.  **排除标准 (第三步):** 论文的研究焦点不涉及安全与对齐，也未将多模态或视觉作为研究核心，因此不触发排除标准。 4.  **特殊和模糊情况处理 (第四步):** *   **推理/规划:** 这篇论文是关于智能体如何进行规划和多步推理的典型案例。它不是在提升LLM底层的数学或逻辑推理能力，而是构建了一个外部框架（包含规划和工具使用）来弥补LLM的不足。根据规则“如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理……则保留”，这篇论文应被保留。 **总结:** 尽管论文的应用领域是表格数据分析，但其核心贡献在于提出了一种新的**智能体框架**，该框架集成了**规划**和**工具使用**等关键Agentic能力来解决复杂任务。这完全符合我研究目标中“构建、改进LLM智能体”以及“单智能体”方向下的“规划”和“工具使用”子方向。因此，这篇论文是高度相关的前沿研究，应被筛选出来。"
    },
    {
        "index": "#27",
        "title": "Optimal-Agent-Selection: State-Aware Routing Framework for Efficient Multi-Agent Collaboration",
        "link": "/arxiv/2511.02200",
        "arxiv_id": "2511.02200",
        "authors": "Jingbo Wang, Sendong Zhao, Haochun Wang, Yuzheng Fan, Lizhe Zhang, Yan Liu, Ting Liu",
        "summary": "The emergence of multi-agent systems powered by large language models (LLMs) has unlocked new frontiers in complex task-solving, enabling diverse agents to integrate unique expertise, collaborate flexibly, and address challenges unattainable for individual models. However, the full potential of such systems is hindered by rigid agent scheduling and inefficient coordination strategies that fail to adapt to evolving task requirements. In this paper, we propose STRMAC, a state-aware routing framework designed for efficient collaboration in multi-agent systems. Our method separately encodes interaction history and agent knowledge to power the router, which adaptively selects the most suitable single agent at each step for efficient and effective collaboration. Furthermore, we introduce a self-evolving data generation approach that accelerates the collection of high-quality execution paths for efficient system training. Experiments on challenging collaborative reasoning benchmarks demonstrate that our method achieves state-of-the-art performance, achieving up to 23.8% improvement over baselines and reducing data collection overhead by up to 90.1% compared to exhaustive search.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.206466",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是提出了两个关键创新： 1.  **STRMAC框架**：一个用于多智能体系统的“状态感知路由框架”。其本质是提出一种新的方法论来改进多智能体之间的协作效率。 2.  **自我演化数据生成方法**：一种用于加速系统训练的“self-evolving data generation approach”。 这两个贡献都直接聚焦于**构建、改进和演化LLM智能体系统**，而非将现有智能体作为工具应用于特定领域。因此，根据第一步的核心判断标准，这篇论文应被**保留**。 **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中包含了大量与您研究焦点高度相关的正面指标： *   **核心范式**: `Multi-Agent Systems (MAS)` (明确提及), `Self-Evolving` (明确提及)。 *   **多智能体**: `Collaboration` (明确提及), `Agent` (多次提及)。 *   **演化机制**: `Self-Evolving` (明确提及), `Iterative Improvement` (隐含在框架的自适应选择中)。 这些关键词密集出现，表明论文与您的研究方向高度契合。 **第三步：排除标准——是否为我的研究焦点之外？** 论文摘要中完全没有提及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐相关的内容，也未涉及 `Vision`, `MLLMs` 等多模态主题。因此，没有触发任何排除标准。 **第四步：处理特殊和模糊情况** 1.  **推理/规划**: 论文提出的“state-aware routing framework”本质上是一种高级的**规划和协调机制**。它通过编码交互历史和智能体知识，来决定下一步选择哪个智能体行动，这完全符合您对“智能体如何进行规划或在复杂任务中进行多步推理”的关注点，应予以保留。 2.  **自我演化的应用**: 论文明确提出了“self-evolving data generation approach”。这并非简单地将智能体应用于某个领域，而是**提出了一种新的自我演化机制**作为核心贡献之一。根据您的规则，即使它被应用在特定领域（如摘要中的“collaborative reasoning benchmarks”），也应该保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于**改进多智能体系统的协作框架（Multi-Agent方向）**，并为此提出了一种**自我演化的数据生成机制（Self-Evolving方向）**。它直接回应了您研究课题中的两个核心方向，且不涉及任何排除标准。因此，这是一篇与您研究目标高度相关的前沿论文，应被筛选出来。"
    },
    {
        "index": "#40",
        "title": "1 PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts",
        "link": "/arxiv/2511.02780",
        "arxiv_id": "2511.02780",
        "authors": "Vivi Andersson, Sofia Bobadilla, Harald Hobbelhagen, Martin Monperrus",
        "summary": "Smart contracts operate in a highly adversarial environment, where vulnerabilities can lead to substantial financial losses. Thus, smart contracts are subject to security audits. In auditing, proof-of-concept (PoC) exploits play a critical role by demonstrating to the stakeholders that the reported vulnerabilities are genuine, reproducible, and actionable. However, manually creating PoCs is time-consuming, error-prone, and often constrained by tight audit schedules. We introduce POCO, an agentic framework that automatically generates executable PoC exploits from natural-language vulnerability descriptions written by auditors. POCO autonomously generates PoC exploits in an agentic manner by interacting with a set of code-execution tools in a Reason-Act-Observe loop. It produces fully executable exploits compatible with the Foundry testing framework, ready for integration into audit reports and other security tools. We evaluate POCO on a dataset of 23 real-world vulnerability reports. POCO consistently outperforms the prompting and workflow baselines, generating well-formed and logically correct PoCs. Our results demonstrate that agentic frameworks can significantly reduce the effort required for high-quality PoCs in smart contract audits. Our contribution provides readily actionable knowledge for the smart contract security community.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Software Engineering",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.219017",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 **PoCo 的新框架**。其核心贡献并非简单地将LLM应用于智能合约安全领域，而是**构建了一个具有自主性的智能体框架**来解决特定问题。摘要中明确使用了 \"agentic framework\"、\"autonomously generates... in an agentic manner\" 等关键词，并详细描述了其工作机制——通过 \"Reason-Act-Observe loop\" 与工具交互。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是简单的应用，而是对智能体工作模式的一种新实现。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `Agentic AI`, `LLM-based Agents` - **智能体能力**: `Planning` (Reason-Act-Observe循环本身就是一种规划和执行策略), `Tool Use / Tool Augmentation` (与代码执行工具集交互) - **推理模式**: `ReAct` (Reason-Act-Observe 是 ReAct 范式的直接体现) - 这些正面指标强烈表明该论文与您的研究焦点高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 这是本案例中最需要辨析的一点。虽然论文的应用领域是“安全”，但其**主要贡献并非一种新的安全理论、对齐方法或可解释性技术**。它的贡献是**一种新的智能体框架**，并用这个框架去完成一个安全任务。因此，它属于“用于安全的AI”，而非“AI安全”。根据筛选标准“只要论文的主要贡献是关于 Safety...一律排除”，这篇论文的主要贡献是Agentic框架，因此**不应被排除**。 - **多模态与视觉**: 不涉及。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确提出了一个基于 \"Reason-Act-Observe\" 循环的规划与执行框架。这完全符合“保留”的条件，即“关于智能体如何进行规划或在复杂任务中进行多步推理”。 5.  **第五步：最终决策** - 综合以上分析，尽管论文的应用领域是智能合约安全，但其核心贡献在于**构建了一个新颖的LLM智能体框架**，该框架展示了智能体在规划、工具使用和循环执行方面的能力。这直接对齐了您“构建、改进或演化LLM智能体”的核心目标，特别是“单智能体”方向下的“规划”和“工具使用”子方向。因此，这篇论文是高度相关且应被保留的前沿研究。"
    },
    {
        "index": "#33",
        "title": "Human-AI Co-Embodied Intelligence for Scientific Experimentation and Manufacturing",
        "link": "/arxiv/2511.02071",
        "arxiv_id": "2511.02071",
        "authors": "Xinyi Lin, Yuyang Zhang, Yuanhang Gan, Juntao Chen, Hao Shen, Yichun He, Lijun Li, Ze Yuan, Shuang Wang, Chaohao Wang, Rui Zhang, Na Li, Jia Liu",
        "summary": "Scientific experiment and manufacture rely on complex, multi-step procedures that demand continuous human expertise for precise execution and decision-making. Despite advances in machine learning and automation, conventional models remain confined to virtual domains, while real-world experiment and manufacture still rely on human supervision and expertise. This gap between machine intelligence and physical execution limits reproducibility, scalability, and accessibility across scientific and manufacture workflows. Here, we introduce human-AI co-embodied intelligence, a new form of physical AI that unites human users, agentic AI, and wearable hardware into an integrated system for real-world experiment and intelligent manufacture. In this paradigm, humans provide precise execution and control, while agentic AI contributes memory, contextual reasoning, adaptive planning, and real-time feedback. The wearable interface continuously captures the experimental and manufacture processes, facilitates seamless communication between humans and AI for corrective guidance and interpretable collaboration. As a demonstration, we present Agentic-Physical Experimentation (APEX) system, coupling agentic reasoning with physical execution through mixed-reality. APEX observes and interprets human actions, aligns them with standard operating procedures, provides 3D visual guidance, and analyzes every step. Implemented in a cleanroom for flexible electronics fabrication, APEX system achieves context-aware reasoning with accuracy exceeding general multimodal large language models, corrects errors in real time, and transfers expertise to beginners. These results establish a new class of agentic-physical-human intelligence that extends agentic reasoning beyond computation into the physical domain, transforming scientific research and manufacturing into autonomous, traceable, interpretable, and scalable processes.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-03",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.209822",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和扩展了LLM智能体的范式。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心并非简单地将一个已有的智能体框架应用到制造领域，而是提出了一种名为“人机协同具身智能”的**新范式**和**新框架**。摘要明确指出，该框架“将人类用户、智能体AI和可穿戴硬件整合为一个集成系统”，并详细定义了其中“智能体AI”的角色和贡献。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。它不是非演化型应用，因为它本身就在定义一种新的智能体形态。 2.  **第二步：正面指标——高度匹配** 论文包含了大量您关注的核心关键词和概念： *   **核心范式**: `Agentic AI` (明确提及 \"agentic AI\" 和 \"agentic reasoning\")。 *   **智能体能力**: `Planning` (\"adaptive planning\"), `Memory` (\"memory\"), `Self-Correction` (\"corrects errors in real time\"), `ReAct` (其观察、推理、行动的循环模式与ReAct范式高度一致)。 这些正面指标表明，论文的研究焦点与您的“单智能体”方向高度契合。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 论文的主要贡献是关于智能体的系统架构和能力，而非安全、对齐或可解释性。虽然提到了“interpretable collaboration”，但这是作为系统的一个特性，而非研究的核心贡献。 *   **多模态与视觉**: 论文提到了“3D visual guidance”和“mixed-reality”，但根据筛选规则，这些是作为“智能体感知环境和与人类交互的工具”，而不是研究的核心。研究的核心是智能体的推理、规划和记忆能力，而非视觉模型本身。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文明确讨论了“智能体推理”和“自适应规划”，这属于智能体在复杂任务中的多步推理和规划，符合保留条件。它不是在改进LLM的基础数学或逻辑能力。 *   **自我演化的应用**: 虽然这不完全是“自我演化”的论文，但它遵循了该规则的内在逻辑：**核心贡献是提出一种新的智能体机制，即使它被应用在特定领域（制造），也应该保留。** 这篇论文的核心是“人机协同具身智能”这一新机制，制造领域是其验证和展示的舞台。 **最终决策**: 这篇论文的核心贡献是提出了一种名为“人机协同具身智能”的新型LLM智能体框架。它详细阐述了智能体在该框架中的核心能力，包括记忆、规划、推理和自我修正，并将其成功应用于物理世界。这完全符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标，特别是与您的“单智能体”研究方向高度相关。因此，应予以保留。"
    },
    {
        "index": "#67",
        "title": "EvoDev: An Iterative Feature-Driven Framework for End-to-End Software Development with LLM-based Agents",
        "link": "/arxiv/2511.02399",
        "arxiv_id": "2511.02399",
        "authors": "Junwei Liu, Chen Xu, Chong Wang, Tong Bai, Weitong Chen, Kaseng Wong, Yiling Lou, Xin Peng",
        "summary": "Recent advances in large language model agents offer the promise of automating end-to-end software development from natural language requirements. However, existing approaches largely adopt linear, waterfall-style pipelines, which oversimplify the iterative nature of real-world development and struggle with complex, large-scale projects. To address these limitations, we propose EvoDev, an iterative software development framework inspired by feature-driven development. EvoDev decomposes user requirements into a set of user-valued features and constructs a Feature Map, a directed acyclic graph that explicitly models dependencies between features. Each node in the feature map maintains multi-level information, including business logic, design, and code, which is propagated along dependencies to provide context for subsequent development iterations. We evaluate EvoDev on challenging Android development tasks and show that it outperforms the best-performing baseline, Claude Code, by a substantial margin of 56.8%, while improving single-agent performance by 16.0%-76.6% across different base LLMs, highlighting the importance of dependency modeling, context propagation, and workflow-aware agent design for complex software projects. Our work summarizes practical insights for designing iterative, LLM-driven development frameworks and informs future training of base LLMs to better support iterative software development.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.264267",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步核心判断 (保留)**: 论文的核心贡献并非简单地将LLM智能体应用于软件开发领域，而是提出了一种名为 **EvoDev** 的全新**迭代式框架**。这个框架旨在解决现有LLM智能体在处理复杂任务时采用的“线性、瀑布式”流程的局限性。因此，论文的本质是**构建和改进LLM智能体的方法论**，而非单纯的应用。这直接命中了您“核心贡献在于构建、改进或演化LLM智能体”的目标。 2.  **第二步正面指标 (高度相关)**: *   **核心范式**: 论文明确围绕 `LLM-based Agents` 展开，并提出了一个新框架。 *   **智能体能力**: EvoDev框架的核心机制，如构建“Feature Map”（特征图）来建模依赖关系、沿依赖关系传播上下文信息，这些都属于智能体**高级规划**和**记忆/上下文管理**的范畴。 *   **演化机制**: 论文的标题和摘要反复强调 **\"Iterative\"**（迭代）和 **\"Evolutionary\"**（演化，体现在名称EvoDev中）。它提出的框架本身就是一种让智能体在复杂任务中进行迭代、循环式工作并自我完善的机制，这与您关注的“自我演化”方向高度契合。 3.  **第四步特殊与模糊情况处理**: *   **自我演化的应用**: 这篇论文是“自我演化的应用”这一规则的完美例证。虽然它的应用领域是“软件开发”，但其**核心贡献是提出一种新的“自我演化/迭代”机制**（即EvoDev框架）。根据您的规则，这种情况应该**保留**。论文的价值在于这个框架本身可以被泛化到其他需要复杂迭代规划的领域，而不仅仅是Android开发。 **总结**: 论文的核心是提出一个创新的、迭代的、具备高级规划和上下文传播能力的LLM智能体框架（EvoDev）。它直接回应了您对“构建、改进或演化LLM智能体”的核心需求，特别是在“单智能体”的“规划”和“自我演化”的“迭代改进”子方向上。因此，这篇论文是您研究课题下的高质量前沿文献。"
    },
    {
        "index": "#84",
        "title": "LACY: A Vision-Language Model-based Language-Action Cycle for Self-Improving Robotic Manipulation",
        "link": "/arxiv/2511.02239",
        "arxiv_id": "2511.02239",
        "authors": "Youngjin Hong, Houjian Yu, Mingen Li, Changhyun Choi",
        "summary": "Learning generalizable policies for robotic manipulation increasingly relies on large-scale models that map language instructions to actions (L2A). However, this one-way paradigm often produces policies that execute tasks without deeper contextual understanding, limiting their ability to generalize or explain their behavior. We argue that the complementary skill of mapping actions back to language (A2L) is essential for developing more holistic grounding. An agent capable of both acting and explaining its actions can form richer internal representations and unlock new paradigms for self-supervised learning. We introduce LACY (Language-Action Cycle), a unified framework that learns such bidirectional mappings within a single vision-language model. LACY is jointly trained on three synergistic tasks: generating parameterized actions from language (L2A), explaining observed actions in language (A2L), and verifying semantic consistency between two language descriptions (L2C). This enables a self-improving cycle that autonomously generates and filters new training data through an active augmentation strategy targeting low-confidence cases, thereby improving the model without additional human labels. Experiments on pick-and-place tasks in both simulation and the real world show that LACY improves task success rates by 56.46% on average and yields more robust language-action grounding for robotic manipulation. Project page: https://vla2026.github.io/LACY/",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.284136",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 LACY (Language-Action Cycle) 的统一框架，该框架通过构建一个“语言-动作”双向映射的循环，实现了智能体的自我改进。这完全符合您的研究范围，具体判断依据如下： 1.  **第一步：核心判断——保留** - 论文的核心并非简单地将LLM应用于机器人控制这一特定领域，而是提出了一种全新的、能够让智能体**自我演化**的方法论。其核心创新点在于“自我改进循环”，即智能体通过“解释自己的行为”来生成新的训练数据，从而在没有人类标注的情况下迭代提升自身能力。这直接命中了您研究目标中的“自我演化”方向，属于构建和改进LLM智能体的方法论，因此应予以保留。 2.  **第二步：正面指标——高度匹配** - 论文明确包含了多个核心关注点： - **自我演化**: 标题和摘要中反复强调 `Self-Improving`，并详细描述了其“自我改进循环”机制。 - **自我反思**: 论文中提出的 A2L (Action-to-Language) 能力，即“解释观察到的动作”，是智能体进行自我反思的一种具体实现形式。 - **迭代改进**: 摘要中提到“autonomously generates and filters new training data... improving the model without additional human labels”，清晰地描述了一个迭代优化的过程。 3.  **第三步：排除标准——未触犯** - **安全与对齐**: 论文的主要贡献是提升智能体的能力和自我完善机制，而非研究其安全性、可解释性或对齐问题。 - **多模态与视觉**: 尽管论文使用了 `Vision-Language Model`，但根据筛选标准，这里的视觉模块是作为智能体**感知环境的工具**而存在的。研究的核心不是VLM模型本身，而是如何利用VLM构建一个能够进行语言-动作循环和自我演化的智能体框架。因此，这符合“除非它们被用作智能体感知环境的工具”的例外情况，不应被排除。 4.  **第四步：处理特殊和模糊情况——适用例外规则** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美范例。虽然其应用领域是“机器人操作”，但其**核心贡献**是提出了一种新颖的“自我演化”机制。根据您的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 因此，这篇论文必须被保留。 **总结**: 该论文的本质是提出了一种让智能体通过“行动-解释”的闭环进行自我学习和迭代优化的新框架。其核心贡献在于**自我演化机制**的设计，而非在机器人领域的应用本身。这与您的研究课题“LLM智能体及其演化”，特别是“自我演化”方向，高度契合。因此，最终判断为 **True**。"
    },
    {
        "index": "#114",
        "title": "TRACE: Textual Reasoning for Affordance Coordinate Extraction",
        "link": "/arxiv/2511.01999",
        "arxiv_id": "2511.01999",
        "authors": "Sangyun Park, Jin Kim, Yuchen Cui, Matthew S. Brown",
        "summary": "Vision-Language Models (VLMs) struggle to translate high-level instructions into the precise spatial affordances required for robotic manipulation. While visual Chain-of-Thought (CoT) methods exist, they are often computationally intensive. In this work, we introduce TRACE (Textual Reasoning for Affordance Coordinate Extraction), a novel methodology that integrates a textual Chain of Reasoning (CoR) into the affordance prediction process. We use this methodology to create the TRACE dataset, a large-scale collection created via an autonomous pipeline that pairs instructions with explicit textual rationales. By fine-tuning a VLM on this data, our model learns to externalize its spatial reasoning before acting. Our experiments show that our TRACE-tuned model achieves state-of-the-art performance, reaching 48.1% accuracy on the primary Where2Place (W2P) benchmark (a 9.6% relative improvement) and 55.0% on the more challenging W2P(h) subset. Crucially, an ablation study demonstrates that performance scales directly with the amount of reasoning data used, confirming the CoR's effectiveness. Furthermore, analysis of the model's attention maps reveals an interpretable reasoning process where focus shifts dynamically across reasoning steps. This work shows that training VLMs to generate a textual CoR is an effective and robust strategy for enhancing the precision, reliability, and interpretability of VLM-based robot control. Our dataset and code are available at https://github.com/jink-ucla/TRACE",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-11-03",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.316108",
        "filter_reason": "这篇论文符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将现有技术应用于机器人领域，而是提出了一种名为TRACE的**新方法论**。该方法论的核心是让智能体在执行物理操作前，通过生成“文本推理链”来外化其空间推理过程。这直接关系到如何**构建和改进LLM智能体的推理与规划能力**，属于Agentic AI的核心范畴，而非单纯的应用。 2.  **第二步：正面指标** - 论文高度符合您的核心关注点： - **智能体能力**: 论文的核心贡献`Textual Chain of Reasoning (CoR)`是一种**规划**和**自我反思**机制。智能体通过“externalize its spatial reasoning before acting”（在行动前外化其空间推理）来提升决策的精确性和可靠性，这与`ReAct`等智能体范式一脉相承。 - **核心范式**: 研究对象是基于VLM的智能体，完全属于`LLM-based Agents`的范畴。 3.  **第三步：排除标准** - **安全与对齐**: 论文虽然提到了“interpretable reasoning process”（可解释的推理过程），但这只是其方法带来的一个有益副作用，并非论文的**主要贡献**。论文的核心目标是提升智能体的性能（precision, reliability），而不是研究可解释性、安全或对齐本身。因此，不适用排除规则。 - **多模态与视觉**: 论文确实涉及VLMs和视觉，但这完全符合您设定的例外情况：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉是智能体感知物理世界的工具，而**研究的核心是智能体如何利用文本推理来处理这些感知信息并进行规划**。创新点在于推理框架，而非视觉模型本身。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是典型的“保留”案例。它不是在研究如何提升LLM的基础数学或逻辑能力，而是在研究一个**具身智能体如何进行多步规划和推理**以完成复杂任务（机器人操作）。其“推理后行动”的模式是Agentic AI研究的核心。 5.  **第五步：最终决策** - 综合来看，这篇论文的核心贡献是提出了一种新的智能体推理框架（TRACE），用于增强基于VLM的单智能体在物理世界中的规划和行动能力。它精准地命中了您研究范围中的“单智能体”方向，特别是“规划”和“自我反思”子方向。尽管它以机器人技术为应用背景，但其方法论的创新具有通用性，完全符合您筛选“构建、改进或演化LLM智能体”论文的核心目标。因此，应判定为符合要求。"
    },
    {
        "index": "#123",
        "title": "Tool Zero: Training Tool-Augmented LLMs via Pure RL from Scratch",
        "link": "/arxiv/2511.01934",
        "arxiv_id": "2511.01934",
        "authors": "Yirong Zeng, Xiao Ding, Yutai Hou, Yuxian Wang, Li Du, Juyi Dai, Qiuyang Ding, Duyu Tang, Dandan Tu, Weiwen Liu, Bing Qin, Ting Liu",
        "summary": "Training tool-augmented LLMs has emerged as a promising approach to enhancing language models' capabilities for complex tasks. The current supervised fine-tuning paradigm relies on constructing extensive domain-specific datasets to train models. However, this approach often struggles to generalize effectively to unfamiliar or intricate tool-use scenarios. Recently, reinforcement learning (RL) paradigm can endow LLMs with superior reasoning and generalization abilities. In this work, we address a key question: Can the pure RL be used to effectively elicit a model's intrinsic reasoning capabilities and enhance the tool-agnostic generalization? We propose a dynamic generalization-guided reward design for rule-based RL, which progressively shifts rewards from exploratory to exploitative tool-use patterns. Based on this design, we introduce the Tool-Zero series models. These models are trained to enable LLMs to autonomously utilize general tools by directly scaling up RL from Zero models (i.e., base models without post-training). Experimental results demonstrate that our models achieve over 7% performance improvement compared to both SFT and RL-with-SFT models under the same experimental settings. These gains are consistently replicated across cross-dataset and intra-dataset evaluations, validating the effectiveness and robustness of our methods.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-02",
        "category": "cs.AI",
        "crawl_time": "2025-11-05T11:00:05.326041",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** - 论文的核心贡献是提出了一种名为 \"Tool Zero\" 的新方法，这是一种**全新的训练范式**，旨在**构建和改进**具备工具使用能力的LLM智能体。 - 它不是将现有智能体应用到某个特定领域，而是专注于**如何从零开始训练**一个更强大的智能体本身。其核心是方法论创新，而非应用创新。 - 论文的研究内容 \"tool-augmented LLMs\" 直接对应了您研究焦点中的**单智能体**方向下的**工具使用**能力。 2.  **第二步：正面指标 (高度匹配)** - 论文明确包含了多个核心关注点： - **智能体能力**: `Tool Use / Tool Augmentation` 是论文的绝对核心。同时，论文旨在提升模型的 `Reasoning` 和 `Generalization` 能力，这些都是智能体在复杂任务中表现的关键。 - **演化机制**: 论文提出的“纯强化学习”训练方法，通过一个动态的奖励机制，引导模型从探索转向利用，这本质上是一种通过环境反馈进行**迭代改进**和**能力演化**的过程。虽然不是“自我反思”，但RL训练本身就是一种强大的演化学习机制。 3.  **第三步：排除标准 (未触发)** - 论文的主要贡献是提升智能体的能力和泛化性，不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐议题。 - 论文不涉及多模态或视觉内容，完全聚焦于语言模型和通用工具的使用。 4.  **第四步：特殊和模糊情况 (符合保留规则)** - **推理/规划**: 论文研究的是智能体如何通过工具进行多步推理和解决复杂问题，这完全符合“保留”标准。它不是在改进LLM的基础数学能力，而是在构建一个能够使用工具进行推理的智能体框架。 - **自我演化的应用**: 此处不适用，因为论文本身就是提出一种通用的演化训练方法，而非特定领域的应用。 **总结**: 该论文的核心是提出一种创新的、基于纯强化学习的训练框架，用于**构建**和**改进**LLM智能体的核心能力——工具使用和泛化。这直接命中了您“构建、改进或演化LLM智能体”的核心目标，并且属于“单智能体”研究范畴。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#15",
        "title": "Curriculum Design for Trajectory-Constrained Agent: Compressing Chain-of-Thought Tokens in LLMs",
        "link": "/arxiv/2511.02690",
        "arxiv_id": "2511.02690",
        "authors": "Georgios Tzannetos, Parameswaran Kamalaruban, Adish Singla",
        "summary": "Training agents to operate under strict constraints during deployment, such as limited resource budgets or stringent safety requirements, presents significant challenges, especially when these constraints render the task complex. In this work, we propose a curriculum learning strategy that gradually tightens constraints during training, enabling the agent to incrementally master the deployment requirements. Inspired by self-paced learning techniques in unconstrained reinforcement learning (RL), our approach facilitates a smoother transition to challenging environments by initially training on simplified versions of the constraints and progressively introducing the full deployment conditions. We provide a theoretical analysis using an RL agent in a binary-tree Markov Decision Process (MDP) to demonstrate that our curriculum strategy can accelerate training relative to a baseline approach that imposes the trajectory constraints from the outset. Moreover, we empirically validate the effectiveness and generality of our method across both RL and large language model (LLM) agents in diverse settings, including a binary-tree MDP, a multi-task navigation domain, and a math reasoning task with two benchmarks. These results highlight the potential of curriculum design in enhancing the efficiency and performance of agents operating under complex trajectory constraints during deployment. Moreover, when applied to LLMs, our strategy enables compression of output chain-of-thought tokens, achieving a substantial inference speedup on consumer hardware, demonstrating its effectiveness for resource-constrained deployment.",
        "subjects": "Machine Learning",
        "date": "2025-11-04",
        "category": "cs.LG",
        "crawl_time": "2025-11-05T11:00:05.237014",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非将现有智能体应用于某个领域，而是提出了一种全新的**课程学习策略**，用于**训练和改进**智能体（包括LLM智能体）。该方法论旨在让智能体更好地适应部署时的严格约束（如资源限制）。这直接命中了您“构建、改进或演化 LLM智能体”的核心目标。它不是关于应用，而是关于如何构建一个更强大的智能体。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个核心关注点： *   **核心范式**: 论文明确研究 `LLM-based Agents`。 *   **智能体能力**: 论文的核心应用之一是优化 `Chain-of-Thought` (CoT) 的生成，这直接关联到智能体的**规划和多步推理**能力。它提出的方法让智能体在保持推理效果的同时，能生成更短的思维链，这是一种对智能体推理效率的**改进**。 3.  **第四步：处理特殊和模糊情况 (关键判断点)** 这篇论文的判断关键在于如何理解其与“推理/规划”的关系。 *   **保留**: 根据您的规则，“如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）”，则应保留。这篇论文正是如此。它没有发明一种新的CoT*提示技巧*来提升LLM的基础能力，而是提出了一种**新的训练框架**，让智能体*学会*如何进行更高效的推理。这是一种在智能体层面的、系统性的改进，完全符合“Agentic框架”的定义。其成果“压缩CoT tokens”是这种训练框架带来的智能体能力提升，而非研究本身。 4.  **第三步：排除标准 (未触发)** 论文的主要贡献是关于智能体的训练效率和性能，不涉及安全、对齐、可解释性或多模态等排除领域。 **总结**: 该论文的核心是提出一种用于**改进LLM智能体**的**训练方法论**，使其在资源受限的环境下能进行更高效的规划和推理。这完全属于您研究范围中的“单智能体”方向，特别是关于“规划”和“改进”的子方向。它不是对LLM基础能力的微调，也不是一个简单的应用，而是一个关于如何构建更优智能体的框架性研究，因此应被保留。"
    },
    {
        "index": "#105",
        "title": "Agentic World Modeling for 6G: Near-Real-Time Generative State-Space Reasoning",
        "link": "/arxiv/2511.02748",
        "arxiv_id": "2511.02748",
        "authors": "Farhad Rezazadeh, Hatim Chergui, Merouane Debbah, Houbing Song, Dusit Niyato, Lingjia Liu",
        "summary": "We argue that sixth-generation (6G) intelligence is not fluent token prediction but the capacity to imagine and choose -- to simulate future scenarios, weigh trade-offs, and act with calibrated uncertainty. We reframe open radio access network (O-RAN) near-real-time (Near-RT) control via counterfactual dynamics and a world modeling (WM) paradigm that learns an action-conditioned generative state space. This enables quantitative \"what-if\" forecasting beyond large language models (LLMs) as the primary modeling primitive. Actions such as physical resource blocks (PRBs) are treated as first-class control inputs in a causal world model, and both aleatoric and epistemic uncertainty are modeled for prediction and what-if analysis. An agentic, model predictive control (MPC)-based cross-entropy method (CEM) planner operates over short horizons, using prior-mean rollouts within data-driven PRB bounds to maximize a deterministic reward. The model couples multi-scale structured state-space mixtures (MS3M) with a compact stochastic latent to form WM-MS3M, summarizing key performance indicators (KPIs) histories and predicting next-step KPIs under hypothetical PRB sequences. On realistic O-RAN traces, WM-MS3M cuts mean absolute error (MAE) by 1.69% versus MS3M with 32% fewer parameters and similar latency, and achieves 35-80% lower root mean squared error (RMSE) than attention/hybrid baselines with 2.3-4.1x faster inference, enabling rare-event simulation and offline policy screening.",
        "subjects": "Networking and Internet Architecture, Machine Learning",
        "date": "2025-11-04",
        "category": "cs.LG",
        "crawl_time": "2025-11-05T11:00:05.299489",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** - **保留**。这篇论文的核心贡献并非简单地将现有智能体框架应用于6G领域，而是提出了一种全新的**智能体世界建模范式**。其本质是构建一个具备“想象和选择”能力的智能体框架，该框架包含一个“世界模型”和一个“智能体规划器”。这完全符合“构建、改进LLM智能体”的核心目标，即使它并非直接基于LLM Token预测，而是探索了超越LLM的智能体建模新路径。它不是“非演化型应用”，因为它贡献的是方法论本身。 **第二步：正面指标——论文是否包含我的核心关注点？** - 论文明确包含了多个核心关注点： - **核心范式**: 摘要中直接使用了 `Agentic` 一词，并提出了 `World Modeling (WM)` 范式，这与 `Agentic AI` 紧密相关。 - **智能体能力**: 论文的核心是关于智能体的**规划**能力。它提出了一个“`agentic, model predictive control (MPC)-based cross-entropy method (CEM) planner`”，这直接命中了“单智能体”方向下的“规划”子方向。其“what-if” forecasting能力也体现了高级的推理能力。 **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及任何排除标准。其焦点是智能体的决策与规划框架，而非安全、对齐或多模态感知。 **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”的典型案例。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个完整的智能体框架来解决复杂环境下的多步规划和决策问题。其提出的“世界模型+规划器”架构，与ReAct、ToT等一脉相承，都是为了让智能体能够更好地进行规划和行动，是Agentic AI研究的核心议题。 **第五步：最终决策** 综合以上分析，尽管论文的应用领域是6G通信，但其**核心贡献是方法论层面的创新**——提出了一种新的智能体架构（世界模型+规划器）来实现复杂的、基于模拟的规划和决策。这完全契合我研究课题中“单智能体”方向，特别是“规划”这一子方向。因此，这篇论文是高度相关的前沿研究，应该被保留。"
    },
    {
        "index": "#126",
        "title": "An Automated Framework for Strategy Discovery, Retrieval, and Evolution in LLM Jailbreak Attacks",
        "link": "/arxiv/2511.02356",
        "arxiv_id": "2511.02356",
        "authors": "Xu Liu, Yan Chen, Kan Ling, Yichi Zhu, Hengrun Zhang, Guisheng Fan, Huiqun Yu",
        "summary": "The widespread deployment of Large Language Models (LLMs) as public-facing web services and APIs has made their security a core concern for the web ecosystem. Jailbreak attacks, as one of the significant threats to LLMs, have recently attracted extensive research. In this paper, we reveal a jailbreak strategy which can effectively evade current defense strategies. It can extract valuable information from failed or partially successful attack attempts and contains self-evolution from attack interactions, resulting in sufficient strategy diversity and adaptability. Inspired by continuous learning and modular design principles, we propose ASTRA, a jailbreak framework that autonomously discovers, retrieves, and evolves attack strategies to achieve more efficient and adaptive attacks. To enable this autonomous evolution, we design a closed-loop \"attack-evaluate-distill-reuse\" core mechanism that not only generates attack prompts but also automatically distills and generalizes reusable attack strategies from every interaction. To systematically accumulate and apply this attack knowledge, we introduce a three-tier strategy library that categorizes strategies into Effective, Promising, and Ineffective based on their performance scores. The strategy library not only provides precise guidance for attack generation but also possesses exceptional extensibility and transferability. We conduct extensive experiments under a black-box setting, and the results show that ASTRA achieves an average Attack Success Rate (ASR) of 82.7%, significantly outperforming baselines.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-11-04",
        "category": "cs.LG",
        "crawl_time": "2025-11-05T11:00:05.320804",
        "filter_reason": "这篇论文符合研究范围，应予以保留。判断依据如下： 1.  **核心贡献是自我演化框架 (第一步 & 第四步)**: 论文的核心贡献是提出了一个名为 ASTRA 的自动化框架，其核心机制是一个闭环的“攻击-评估-提炼-重用”流程。这个流程使得智能体能够从每次与环境的交互（攻击尝试）中自动学习和提炼策略，并将其存储在一个策略库中用于未来的决策。这本质上是一个**自我演化**的智能体框架。它通过经验（攻击结果）进行自我完善和迭代，完全符合“自我演化”这一核心研究方向。 2.  **符合“自我演化的应用”例外规则 (第四步)**: 尽管论文的应用领域是 LLM 安全中的“越狱攻击”，这属于 `Security` 范畴，但根据筛选标准第四步的特殊规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” 本论文正是这种情况。它的核心创新点在于**如何实现智能体的自主演化**，而不是越狱攻击本身的具体技术细节。这个演化框架具有潜在的通用性，可以迁移到其他需要策略演化的任务中。 3.  **包含核心关注点 (第二步)**: 论文中包含了多个核心关注点的关键词和概念，如 `Self-Evolving` (自我演化)、`Autonomous` (自主)、`Self-Improvement` (自我改进，通过提炼策略实现)、`Iterative Improvement` (迭代改进，通过闭环机制实现)。其策略库也扮演了 `Memory` (记忆) 的角色，为智能体的规划提供指导。 4.  **排除标准的适用性分析 (第三步)**: 虽然论文主题涉及 `Security`，但如前所述，其主要贡献并非安全攻防技术本身，而是构建智能体的方法论。因此，不应简单地因为主题是安全就将其排除。排除规则的意图是排除那些以安全、对齐等为主要研究目标的论文，而本论文的研究目标是**构建一个能够自我演化的智能体**，安全只是其验证框架有效性的实验场。 综上所述，该论文提出了一种新颖的、具有闭环反馈和策略库的自我演化智能体框架，其核心贡献与研究课题中的“自我演化”方向高度契合，因此应被保留。"
    }
]