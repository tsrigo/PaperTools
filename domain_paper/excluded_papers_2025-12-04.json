[
    {
        "index": "#4",
        "title": "Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking",
        "link": "/arxiv/2512.05012",
        "arxiv_id": "2512.05012",
        "authors": "Francielle Vargas, Daniel Pedronette",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.386121",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“Self-Explaining Contrastive Evidence Re-Ranking (CER)”的新方法，用于改进检索增强生成（RAG）系统中的检索环节。该方法通过对比学习微调嵌入模型，并为检索结果生成可解释的归因理由，以提高检索的事实性和透明度，并减少幻觉。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断**：这篇论文的本质是改进RAG系统中的一个**组件（检索器）**，而不是构建或演化一个完整的LLM智能体。虽然RAG可以被看作是智能体工具使用能力的一种，但本文的焦点在于如何让“检索”这个工具本身变得更准确、更可解释，而不是研究智能体如何**规划**、**反思**或**演化**其使用工具的策略。因此，它不属于构建、改进或演化LLM智能体的核心方法论，更偏向于对现有技术的优化。 2.  **第二步：正面指标**：论文摘要中完全没有出现我关注的核心范式（如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`）或智能体核心能力（如 `Planning`, `Self-Reflection`, `Self-Improvement`）等关键词。这进一步表明其研究焦点与我的目标不符。 3.  **第三步：排除标准**：这是最关键的判断依据。论文摘要明确指出，其方法旨在“mitigates the potential for **hallucinations** in RAG systems”（减轻RAG系统中的幻觉）、“provides **transparent**, evidence-based retrieval”（提供透明的、基于证据的检索）以及“enhances reliability, especially in **safety-critical** domains”（增强可靠性，尤其是在安全关键领域）。这些目标——**减少幻觉、提供透明性/可解释性、提升安全性**——完全符合筛选标准中明确排除的“安全与对齐”类别。论文的核心贡献是解决RAG系统的安全性和可靠性问题，而非智能体的架构或演化。 综上所述，尽管该研究对提升LLM应用的质量有重要价值，但其核心贡献在于RAG系统的安全与可解释性优化，而非LLM智能体的构建、协作或自我演化。因此，它不符合我的研究范围。"
    },
    {
        "index": "#6",
        "title": "LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics",
        "link": "/arxiv/2512.04957",
        "arxiv_id": "2512.04957",
        "authors": "Weiye Shi, Zhaowei Zhang, Shaoheng Yan, Yaodong Yang",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.387084",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 该论文的核心贡献是构建了一个新的多语言体裁分类数据集，并利用这个数据集来**分析和评估**LLMs对深层语言学特征（如句法、隐喻、语音）的理解能力。其本质是一项关于LLM语言能力的**分析性研究**，而非构建、改进或演化LLM智能体的方法论研究。 - **排除规则应用**: 这篇论文明确属于“非演化型应用”。它将LLM作为一个分类工具，应用于一个特定的自然语言处理任务（体裁分类），以解决一个语言学领域的问题（LLM是否能理解深层语言特征）。论文没有提出任何新的智能体框架、规划方法、工具使用机制或自我演化策略。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。它不涉及 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等任何核心概念。其研究焦点是语言学和模型能力评估，与智能体的构建和演化无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然这篇论文没有直接触及“安全与对齐”或“多模态与视觉”等排除标准，但第一步的判断已经足够有力地将其排除。这一步进一步确认了它不属于您关心的其他排除领域。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“推理”仅限于分类任务中的模式识别，不涉及智能体在复杂任务中的多步自主规划或决策。因此，它属于被排除的“非Agentic的推理”范畴。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制，因此相关的例外规则不适用。 **最终决策**: 综合以上分析，该论文是一项关于LLM语言学能力的实证研究，其核心目标是评估和理解模型，而不是构建或演化一个具有自主性、规划能力或演化能力的智能体。因此，它完全不符合您关于“LLM智能体及其演化”的研究课题，应予以排除。"
    },
    {
        "index": "#3",
        "title": "Arbitrage: Efficient Reasoning via Advantage-Aware Speculation",
        "link": "/arxiv/2512.05033",
        "arxiv_id": "2512.05033",
        "authors": "Monishwaran Maheswaran, Rishabh Tiwari, Yuezhou Hu, Kerem Dilmen, Coleman Hooper, Haocheng Xi, Nicholas Lee, Mehrdad Farajtabar, Michael W. Mahoney, Kurt Keutzer, Amir Gholami",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.385882",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是推理优化，而非智能体构建。** 论文的核心贡献是提出了一种名为 \"Arbitrage\" 的框架，其目标是**加速LLM在推理任务中的推理过程**，特别是通过优化投机解码来减少计算延迟和成本。这属于对LLM**推理执行效率**的改进，而不是对智能体本身能力或架构的构建。根据筛选标准，这属于“非Agentic的推理”和“基础设施”的范畴，因为它关注的是如何让已有的推理过程（如Chain of Thoughts）跑得更快，而不是设计一个能自主规划、使用工具或演化的智能体。 2.  **正面指标缺失 (第二步): 未涉及核心关注点。** 论文摘要中完全没有出现我关注的核心范式和能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。其焦点始终是 `Speculative Decoding`, `inference latency`, `efficiency`，这些都指向模型推理的性能优化，而非智能体的行为或能力。 3.  **特殊情况的澄清 (第四步): 区分“推理过程”与“智能体规划”。** 筛选标准中明确指出，应保留关于“智能体如何进行规划或在复杂任务中进行多步推理”的论文。然而，本文并非研究智能体如何制定计划或分解任务，而是研究如何**加速生成一个已经存在的推理步骤序列**。它是在LLM生成Token的层面做优化，而不是在智能体决策和行动的更高层面做创新。因此，它不符合“保留”的条件，而更符合“排除”条件中关于“提高LLM本身基础推理能力”的描述（尽管这里是提高效率而非能力本身）。 **总结**: 尽管这篇论文在提升LLM推理效率方面可能是一项有价值的工作，但它的贡献点在于**模型推理的工程优化**，而非**智能体的方法论创新**。我的研究焦点是Agentic AI的构建、协作与演化，而这篇论文并未触及这些核心议题。因此，它不符合我的筛选要求。"
    },
    {
        "index": "#9",
        "title": "DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution",
        "link": "/arxiv/2512.04838",
        "arxiv_id": "2512.04838",
        "authors": "L. D. M. S. Sai Teja, N. Siva Gopala Krishna, Ufaq Khan, Muhammad Haris Khan, Partha Pakray, Atul Mishra",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.387940",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是构建一个名为 `Info-Mask` 的框架，用于**检测和分割**混合作者（人类与AI）的文本，并提供可解释的归因。其本质是**AI生成内容的检测与溯源**，而不是构建、改进或演化一个能够自主执行任务的LLM智能体。因此，该论文属于“非演化型应用”，应被排除。 2.  **第二步：正面指标** 论文中完全没有出现您所关注的核心范式或智能体能力相关的关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving` 等。论文中提到的“协作”是指人类与AI共同创作文本这一现象，而不是智能体之间的协作机制。因此，它不包含任何正面指标。 3.  **第三步：排除标准** 这是最关键的排除依据。该论文的研究目标与贡献完全落在“安全与对齐”的范畴内。 *   **安全与对齐**: 论文摘要明确指出其研究具有“对真实性、信任和人类监督的关键意义”。其核心贡献之一是“人类可解释的归因”，这直接对应了 `Interpretability (XAI)`。整个研究都是为了解决AI内容滥用带来的信任和安全问题。根据您的筛选标准，只要论文的主要贡献是关于 `Safety`, `Trust`, `Interpretability` 等，就应一律排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及推理/规划或自我演化的特殊情况，因此此步不适用。 **最终决策**: 综合以上分析，尽管这篇论文涉及LLM，但其研究焦点是**AI文本检测、可解释性和安全性**，而非您所关注的**LLM智能体的构建、协作与演化**。论文的核心贡献是解决一个安全与对齐领域的问题，因此明确不符合您的研究目标，应予以排除。"
    },
    {
        "index": "#1",
        "title": "Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning",
        "link": "/arxiv/2512.05105",
        "arxiv_id": "2512.05105",
        "authors": "Purbesh Mitra, Sennur Ulukus",
        "subjects": "Computation and Language, Artificial Intelligence, Information Theory, Machine Learning, Signal Processing",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.385213",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“语义软自举”的自蒸馏训练技术，用于提升大型语言模型在长上下文推理任务（特别是数学问题）上的表现，其目标是替代传统的强化学习方法。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** - 论文的核心是一种**新的模型训练/微调方法**（自蒸馏技术），旨在提升LLM在特定领域（数学推理）的基础能力。它没有构建一个具有自主性、规划或工具使用能力的智能体框架。 - 该论文明确属于**排除标准中的“非Agentic的推理”**。它研究的是如何通过改进训练过程来提高LLM的内在推理能力，而不是如何设计一个能够自主规划、使用工具或与环境交互的智能体。论文中的“推理”是指模型内部的数学逻辑推导，而非智能体的任务执行流程。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文中没有出现 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式关键词。 - 虽然提到了 `reasoning`，但其上下文是关于模型的基础数学能力，而非智能体的 `Planning` 或 `ReAct` 框架。 - 论文中的 `Self-Distillation` 和 `Self-Improvement` 是在模型训练层面（离线）的术语，指的是模型从自身生成的数据中学习，这与智能体在运行时通过经验和反思进行“自我演化”的机制有本质区别。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文的主要贡献不涉及安全、对齐或多模态，因此不触及相关排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这是最关键的判断点。根据规则，应排除“只是关于提高LLM本身基础Token预测的数学或逻辑能力”的论文。本文提出的SSB方法正是为了提升LLM在数学问题上的基础推理准确率，它是一种训练技巧的优化，而非智能体架构的创新。因此，应被排除。 - **自我演化的应用**: 论文的核心贡献并非一种“自我演化机制”。SSB是一种静态的、离线的训练数据生成和模型微调流程，而不是一个能让智能体在部署后持续学习和迭代的动态机制。 **最终决策**: 综合以上分析，这篇论文的本质是改进LLM的基础推理训练方法，而非构建、改进或演化LLM智能体。它的研究焦点是模型能力的提升，而非智能体框架的设计。因此，它不符合“LLM智能体及其演化”这一研究课题的核心要求，应予以排除。"
    },
    {
        "index": "#10",
        "title": "DaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors",
        "link": "/arxiv/2512.04799",
        "arxiv_id": "2512.04799",
        "authors": "Gianluca Barmina, Nathalie Carmen Hau Norman, Peter Schneider-Kamp, Lukas Galke",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.388194",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心判断 (第一步):** 这篇论文的本质是提出一个新的**评估基准**，用于衡量LLM在“丹麦语语言可接受性判断”这一特定NLP任务上的表现。其核心贡献在于**数据集的构建和评估方法的设计**，而非构建、改进或演化LLM智能体本身。这完全符合筛选标准中的第一条排除规则：“非演化型应用”，即论文将LLM作为评估对象，以解决语言学评估领域的问题，而不是研究如何让LLM变得更像智能体。 2.  **正面指标缺失 (第二步):** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`、`Planning`、`Tool Use`、`Self-Reflection`、`Multi-Agent`、`Collaboration` 或 `Self-Evolving` 等。论文的研究内容是静态的评估，而非动态的、自主的智能体行为。 3.  **与特殊情况的对比 (第四步):** *   **推理/规划:** 论文研究的“语言可接受性判断”是一种基础的语言能力评估，更接近于对LLM底层语言模型的判断能力进行测试，而不是研究智能体如何在复杂任务中进行多步规划和推理。因此，它属于“非Agentic的推理”范畴，应被排除。 *   **自我演化:** 论文完全没有提出任何“自我演化”机制。它只是创建了一个更难的测试集，这与智能体通过经验进行自我完善和迭代是完全不同的概念。 综上所述，该论文是一项扎实的NLP评估研究，但其焦点是**评估方法**，而非**智能体构建**。它没有为LLM智能体的规划、记忆、工具使用、协作或自我演化等核心能力做出任何贡献，因此与我的研究课题“LLM智能体及其演化”不相关。"
    },
    {
        "index": "#8",
        "title": "Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates",
        "link": "/arxiv/2512.04844",
        "arxiv_id": "2512.04844",
        "authors": "Atsuki Yamaguchi, Terufumi Morishita, Aline Villavicencio, Nikolaos Aletras",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.387648",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“源数据屏蔽更新”的微调策略，用于在将指令LLM适配到新语言时减轻灾难性遗忘。这是一个关于模型训练和参数优化的技术，而非关于智能体的构建或演化。 根据我的筛选标准，判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** - 论文的核心是解决模型微调过程中的一个技术难题（灾难性遗忘），提出了一种选择性参数更新的方法。它没有构建任何具有自主规划、工具使用或记忆能力的LLM智能体，也没有涉及多智能体系统或自我演化框架。 - 该研究属于模型训练/适配方法的范畴，更接近于“基础设施”或“基础模型改进”，而非“Agentic AI”。因此，根据第一步的排除规则，应予以排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现任何与我的研究焦点相关的关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent`, `Self-Evolving`, `Self-Reflection` 等。这进一步确认了它与我的研究范围无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文不涉及安全对齐或多模态等排除项，但第一步的核心判断已经足以将其排除。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及智能体推理/规划，也未提出任何自我演化机制。它是一种静态的、一次性的模型更新技术，因此不适用任何例外保留规则。 **最终决策**：这篇论文的核心是改进LLM的微调过程，而不是构建或演化LLM智能体。它属于模型训练技术的研究，与我的“LLM智能体及其演化”这一核心目标不符。因此，应将其排除。"
    },
    {
        "index": "#12",
        "title": "Challenging the Abilities of Large Language Models in Italian: a Community Initiative",
        "link": "/arxiv/2512.04759",
        "arxiv_id": "2512.04759",
        "authors": "Malvina Nissim, Danilo Croce, Viviana Patti, Pierpaolo Basile, Giuseppe Attanasio, Elio Musacchio, Matteo Rinaldi, Federico Borazio, Maria Francis, Jacopo Gili, Daniel Scalena, Begoña Altuna, Ekhi Azurmendi, Valerio Basile, Luisa Bentivogli, Arianna Bisazza, Marianna Bolognesi, Dominique Brunato, Tommaso Caselli, Silvia Casola, Maria Cassese, Mauro Cettolo, Claudia Collacciani, Leonardo De Cosmo, Maria Pia Di Buono, Andrea Esuli, Julen Etxaniz, Chiara Ferrando, Alessia Fidelangeli, Simona Frenda, Achille Fusco, Marco Gaido, Andrea Galassi, Federico Galli, Luca Giordano, Mattia Goffetti, Itziar Gonzalez-Dios, Lorenzo Gregori, Giulia Grundler, Sandro Iannaccone, Chunyang Jiang, Moreno La Quatra, Francesca Lagioia, Soda Marem Lo, Marco Madeddu, Bernardo Magnini, Raffaele Manna, Fabio Mercorio, Paola Merlo, Arianna Muti, Vivi Nastase, Matteo Negri, Dario Onorati, Elena Palmieri, Sara Papi, Lucia Passaro, Giulia Pensa, Andrea Piergentili, Daniele Potertì, Giovanni Puccetti, Federico Ranaldi, Leonardo Ranaldi, Andrea Amelio Ravelli, Martina Rosola, Elena Sofia Ruzzetti, Giuseppe Samo, Andrea Santilli, Piera Santin, Gabriele Sarti, Giovanni Sartor, Beatrice Savoldi, Antonio Serino, Andrea Seveso, Lucia Siciliani, Paolo Torroni, Rossella Varvara, Andrea Zaninello, Asya Zanollo, Fabio Massimo Zanzotto, Kamyar Zeinalipour, Andrea Zugarini",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.389229",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是评估，而非构建或演化。** 论文的核心贡献是创建了一个名为CALAMITA的意大利语LLM评估基准。摘要明确指出，这是一个“benchmarking initiative”（基准测试倡议），其目标是“systematic evaluation of these models”（系统性评估这些模型）。论文的重点在于“methodology”（方法论）、“evaluation pipeline”（评估管道）和“report results”（报告结果）。这完全属于评估研究的范畴，而不是关于如何构建、改进或演化LLM智能体的方法论或新框架。根据筛选标准，这应被排除。 2.  **第二步：正面指标——完全缺失核心关注点。** 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词。例如，它没有提及 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。虽然提到了“collaboration”（协作），但上下文明确是指“80多位来自学术界、产业界和公共部门的贡献者”共同构建基准，而不是指智能体之间的协作。 3.  **第四步：处理特殊和模糊情况——属于非Agentic的推理评估。** 论文确实评估了LLM的“commonsense reasoning”（常识推理）能力。然而，根据筛选标准，这属于“排除”情况：论文只是评估LLM在特定任务上的基础推理能力，而没有提出一种新的、涉及智能体自主规划或多步推理的Agentic框架（如ReAct或ToT）。它是在衡量能力，而不是在构建具备该能力的智能体。 **结论**: 该论文是一项关于LLM评估（特别是针对意大利语）的重要工作，但其核心贡献是基准测试和评估方法论，而非LLM智能体的构建、协作或演化机制。它与您“LLM智能体及其演化”的核心研究目标不符，因此应被排除。"
    },
    {
        "index": "#11",
        "title": "AdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages",
        "link": "/arxiv/2512.04765",
        "arxiv_id": "2512.04765",
        "authors": "Pooja Singh, Sandeep Kumar",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.388432",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是构建了一个名为“AdiBhashaa”的**社区策展的基准数据集**，用于评估机器翻译模型在印度部落语言上的表现。其工作重点在于数据创建、验证和模型评估，而非提出新的智能体框架或演化机制。这直接触发了**排除规则1：“非演化型应用”**。该论文将大型语言模型（LLM）作为评估对象之一，应用于解决特定领域（低资源语言的机器翻译）的问题，其核心是数据和基准，而不是智能体本身。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与我研究焦点相关的正面指标。例如，它没有提及 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving`、`Self-Reflection` 等任何关键词。这进一步确认了该论文与我的研究目标无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然该论文没有触及安全、对齐或多模态等排除标准，但第一步的判断已经足够明确，无需依赖此步。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何关于智能体推理/规划或自我演化机制的特殊情况。它是一个纯粹的应用型、资源型研究。 5.  **第五步：最终决策** 综合以上分析，这篇论文的本质是**为机器翻译任务创建数据集和基准**，属于自然语言处理（NLP）的资源构建领域。它没有提出任何关于如何构建、改进或演化LLM智能体的新方法或框架。因此，它完全不符合我关于“LLM智能体及其演化”的研究课题要求。尽管该研究在促进技术公平性方面具有重要价值，但它不属于我的筛选范围。"
    },
    {
        "index": "#14",
        "title": "Model Whisper: Steering Vectors Unlock Large Language Models' Potential in Test-time",
        "link": "/arxiv/2512.04748",
        "arxiv_id": "2512.04748",
        "authors": "Xinyue Kang, Diwei Shi, Li Chen",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.389767",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出一种名为“Test-Time Steering Vectors (TTSV)”的测试时适应方法。该方法通过在输入前添加一个可优化的向量，在不改变LLM参数的情况下，引导模型产生更自信、更准确的输出。这本质上是一种提升LLM**基础推理能力**的技术，而非构建或改进一个**智能体**。论文中没有涉及任何智能体的核心组件，如自主规划、工具使用、记忆模块或自我反思循环。因此，它属于“非Agentic的推理”这一排除类别。 2.  **正面指标缺失（第二步）：** 论文摘要中完全没有出现您关注的核心范式和智能体能力关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。这进一步表明其研究焦点与您的目标不符。 3.  **特殊情况分析（第四步）：** 根据“推理/规划”的特殊处理规则，该论文应被排除。它研究的是如何通过一种外部优化技术（最小化输出熵）来提升LLM在单次推理中的表现，而不是研究一个智能体如何通过多步规划、与环境交互或使用工具来完成任务。它改进的是模型本身的“推理引擎”，而不是一个具备自主性的“智能体框架”。 综上所述，尽管这篇论文在提升LLM任务性能方面可能是一个有价值的工作，但其本质是一种非智能体的推理增强技术，与您关于“LLM智能体及其演化”的核心研究目标（构建、改进或演化智能体本身）存在根本性偏差。因此，应予以排除。"
    },
    {
        "index": "#15",
        "title": "SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs",
        "link": "/arxiv/2512.04746",
        "arxiv_id": "2512.04746",
        "authors": "Wenhua Cheng, Weiwei Zhang, Heng Guo, Haihao Shen",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.390025",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为SignRoundV2的训练后量化框架，用于解决大型语言模型（LLM）在极端低位宽（如2-bit）下的性能退化问题。其研究重点在于通过改进量化算法（如敏感性度量和量化尺度搜索）来提升模型部署的效率和性能。 根据您的筛选标准，我的判断过程如下： 1.  **第一步：核心判断——这篇论文的本质是什么？** 论文的核心是关于**模型量化和部署优化**。这完全符合筛选标准中第一步的排除规则：“排除主要关注模型基础设施、部署优化、硬件加速的研究。” 该论文旨在让已有的LLM模型在资源受限的环境中更高效地运行，而不是构建或改进一个具有自主能力的智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的标题和摘要中完全没有出现任何与您研究焦点相关的正面指标。它没有提及 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent`、`Self-Evolving` 等任何核心概念。其贡献点在于量化技术本身，而非智能体的能力或架构。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不属于“安全与对齐”或“多模态与视觉”的排除范围，但它明确属于“基础设施”这一排除类别。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及推理/规划或自我演化的特殊情况，因此无需特殊处理。 **最终决策**： 综合以上分析，这篇论文的本质是LLM的部署优化技术，属于基础设施研究。它没有提出任何关于构建、改进或演化LLM智能体的新方法或框架。因此，它完全不符合您关于“LLM智能体及其演化”的研究目标，应予以排除。"
    },
    {
        "index": "#2",
        "title": "Structured Document Translation via Format Reinforcement Learning",
        "link": "/arxiv/2512.05100",
        "arxiv_id": "2512.05100",
        "authors": "Haiyue Song, Johannes Eschbach-Dymanus, Hour Kaing, Sumire Honda, Hideki Tanaka, Bianka Buschbeck, Masao Utiyama",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.385545",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为“Format Reinforcement Learning (FormatRL)”的新方法，用于解决**结构化文档翻译**这一特定领域的问题。该方法通过强化学习技术，直接优化模型在翻译XML/HTML等结构化文档时的格式保真度和翻译质量。 这完全符合**排除标准中的“非演化型应用”**。论文的本质是将一种训练技术（强化学习）应用于一个特定任务（文档翻译），以提升该任务的性能，而不是构建或研究一个具有通用能力的LLM智能体。它没有提出新的智能体框架、智能体能力或演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现您所列出的任何核心关注点。它不涉及 `Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving` 等核心范式，也没有讨论 `Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Collaboration` 或 `Self-Improvement` 等智能体能力。其核心是模型训练层面的优化，而非智能体架构或行为层面的创新。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然论文没有触及安全对齐或多模态等排除项，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的强化学习（`Group Relative Policy Optimization`）是一种训练算法，用于优化模型输出，使其更符合结构化要求。这与智能体在环境中进行多步自主规划和决策的`Agentic`推理有本质区别。因此，它属于被排除的“非Agentic的推理/优化”范畴。 - **自我演化的应用**: 论文的核心贡献是一种新的训练方法，而不是一种智能体在运行时进行自我完善的机制。因此，它不符合“自我演化”的定义，也不适用于该例外情况。 **最终决策**: 综合以上分析，这篇论文的核心是针对特定NLP任务（结构化翻译）的训练方法创新，而非关于LLM智能体的构建、协作或演化。它将模型和训练技术作为解决领域问题的工具，这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体”的核心目标不符。因此，应将其排除。"
    },
    {
        "index": "#18",
        "title": "LexGenius: An Expert-Level Benchmark for Large Language Models in Legal General Intelligence",
        "link": "/arxiv/2512.04578",
        "arxiv_id": "2512.04578",
        "authors": "Wenjin Liu, Haoran Luo, Xin Feng, Xiang Ji, Lijuan Zhou, Rui Mao, Jiapu Wang, Shirui Pan, Erik Cambria",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.390864",
        "filter_reason": "这篇论文不符合研究范围。 根据筛选标准的第一步“核心判断”，这篇论文的核心贡献是构建一个评估基准，而不是构建、改进或演化LLM智能体。论文提出了LexGenius，一个用于评估LLM在法律领域通用智能能力的基准。 这完全符合第一步中的排除标准1：“非演化型应用”。论文将LLM作为评估对象，并将其应用限定在法律这一特定领域，旨在解决该领域的评估问题，而非提出新的智能体方法论或框架。其研究目标是“评估”和“促进发展”，但实现方式是提供一个评测工具，而不是创造一种新的智能体能力。 论文的摘要中未提及任何与“Agentic AI”、“Multi-Agent Systems”、“Self-Evolving”、“Planning”、“Tool Use”等核心关注点相关的正面指标。其研究焦点是“评估”，而非“构建”或“演化”。 因此，尽管该研究对法律AI领域有重要价值，但其本质是评测工具的开发，不属于“LLM智能体及其演化”的核心研究范畴。"
    },
    {
        "index": "#16",
        "title": "OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models",
        "link": "/arxiv/2512.04738",
        "arxiv_id": "2512.04738",
        "authors": "Zhuoyue Wan, Wentao Hu, Chen Jason Zhang, Yuanfeng Song, Shuaimin Li, Ruiqiang Xiao, Xiao-Yong Wei, Raymond Chi-Wing Wong",
        "subjects": "Computation and Language, Artificial Intelligence, Databases",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.390325",
        "filter_reason": "这篇论文不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一个名为 OsmT 的**特定领域语言模型**，用于在自然语言和一种结构化查询语言（OverpassQL）之间进行翻译。其本质是解决数据库/地理信息系统（GIS）领域的一个具体问题：如何让用户用自然语言查询 OpenStreetMap 数据。这完全符合**排除标准 1.1：非演化型应用**。该论文将一个语言模型（并为其设计了特定的增强机制）作为工具，应用在地理空间查询这个特定领域，而不是构建一个通用的、具有自主性的 LLM 智能体。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中提到的 \"Tag Retrieval Augmentation (TRA)\" 机制，虽然形式上类似于“工具使用”，但其本质是**模型架构层面的增强**，目的是为了在翻译任务中注入特定领域的知识（OSM标签），以提高生成查询的准确性。这与智能体**自主决策、规划并调用外部工具**来解决复杂问题的范式有本质区别。论文没有涉及 `Planning`、`Memory`、`Self-Reflection`、`Multi-Agent` 或 `Self-Evolving` 等任何核心的智能体能力或范式。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除标准，但其核心问题定位（自然语言到数据库查询的转换）已经使其偏离了 Agentic AI 的核心研究轨道。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文解决的是单步翻译问题，不涉及智能体在复杂任务中的多步规划或推理框架。因此，它不属于“保留”的范畴。 - **自我演化的应用**: 论文没有提出任何“自我演化”机制。OsmT 是一个静态的、经过训练和增强的模型，不具备通过经验或反馈进行自我完善的能力。 **最终决策**: 综合以上分析，这篇论文的核心贡献是**一个用于特定领域（地理空间查询）的翻译模型**，而不是一个关于如何构建、改进或演化 LLM 智能体的方法论或框架。它属于将 LLM 作为工具解决特定领域问题的应用型研究，因此与您关于 \"LLM智能体及其演化\" 的核心研究目标不符，应予以排除。"
    },
    {
        "index": "#17",
        "title": "Geschlechtsübergreifende Maskulina im Sprachgebrauch Eine korpusbasierte Untersuchung zu lexemspezifischen Unterschieden",
        "link": "/arxiv/2512.04683",
        "arxiv_id": "2512.04683",
        "authors": "Carolin Mueller-Spitzer, Samira Ochs, Jan Oliver Ruediger, Sascha Wolfer",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.390577",
        "filter_reason": "这篇论文完全不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **论文核心贡献分析**: 这篇论文的核心是一项**语料库语言学研究**。它通过人工标注和分析德语新闻文本，探讨了“泛指阳性词”的使用规律、分布和语言学特征。其研究方法是基于语料库的统计分析，而非构建或改进任何人工智能模型或智能体。 - **判断**: 该论文的本质是语言学分析，与“构建、改进或演化LLM智能体”毫无关系。因此，在第一步就应被**排除**。它既不属于构建智能体的方法论，也不属于将智能体作为工具的应用（它甚至没有使用LLM），而是纯粹的语言学领域研究。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文的标题和摘要中完全没有出现任何与我研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等。这进一步确认了它与我的研究课题无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 虽然论文没有触及安全、对齐或多模态等具体的排除标准，但其研究领域——语言学——本身就完全在我的研究焦点“LLM智能体及其演化”之外。 4.  **第四步：处理特殊和模糊情况** - 该论文不涉及任何与智能体相关的推理、规划或自我演化机制，因此不适用特殊情况的判断规则。 **最终决策**: 这篇论文是一项纯粹的、针对德语性别语言现象的语料库语言学研究。它的核心贡献在于揭示特定语言结构在真实文本中的使用模式，而非提出任何关于LLM智能体的新框架、新能力或演化机制。因此，它与我的研究目标“LLM智能体及其演化”完全不相关，应被排除。"
    },
    {
        "index": "#13",
        "title": "EtCon: Edit-then-Consolidate for Reliable Knowledge Editing",
        "link": "/arxiv/2512.04753",
        "arxiv_id": "2512.04753",
        "authors": "Ruilin Li, Yibin Wang, Wenhong Zhu, Chenglin Li, Jinghao Zhang, Chenliang Li, Junchi Yan, Jiaqi Wang",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.389518",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“EtCon”的知识编辑新范式，旨在更可靠地更新大型语言模型（LLM）中的特定事实，并解决现有方法在终身学习场景中表现不佳的问题。其核心机制包括一个“编辑”阶段（TPSFT）和一个“巩固”阶段（GRPO），以防止过拟合并确保新知识与模型的推理行为对齐。 根据您的筛选标准，这篇论文不符合研究范围，原因如下： 1.  **第一步：核心判断——论文本质不符。** 论文的核心是关于**知识编辑**，这是一种修改模型内部参数化知识的技术。它关注的是如何改变LLM“知道什么”，而不是如何构建一个能够自主行动、规划或演化的智能体。这属于对**LLM模型本身的改进**，而非对**LLM智能体的构建或演化**。它没有提出新的智能体框架、多智能体交互协议或自我演化的循环机制。因此，它不属于“构建、改进或演化LLM智能体”的范畴。 2.  **第二步：缺乏正面指标。** 尽管论文提到了“CoT-based inference policy”，但这只是其巩固阶段的优化目标，而非论文的核心贡献。论文本身并未涉及 `Agentic AI`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent` 或 `Self-Evolving` 等核心智能体范式或能力的研究。它的焦点是模型知识的可靠性，而非智能体的行为能力。 3.  **第四步：特殊情况的排除。** 论文触及了“推理”，但根据规则，应被排除。它并非研究“智能体如何进行规划或多步推理”，而是研究如何将新知识“注入”模型，使其在生成时（包括CoT推理时）能够正确使用这些知识。这更接近于对模型基础能力的微调，而非设计一个智能体的推理框架。同样，它也不符合“自我演化”的例外情况，因为知识编辑是一个外部施加的过程，而非智能体自主进行的自我完善。 **总结**: 该论文是一项关于模型微调和知识管理的重要研究，但其技术焦点在于**静态地修改模型的知识库**，而不是**动态地构建或演化一个智能体系统**。我的研究目标是“Agentic AI”，关注智能体的行为、交互和演化循环，而这篇论文的贡献在于模型层面的知识编辑，因此应被排除。"
    },
    {
        "index": "#22",
        "title": "UW-BioNLP at ChemoTimelines 2025: Thinking, Fine-Tuning, and Dictionary-Enhanced LLM Systems for Chemotherapy Timeline Extraction",
        "link": "/arxiv/2512.04518",
        "arxiv_id": "2512.04518",
        "authors": "Tianmai M. Zhang, Zhaoyi Sun, Sihang Zeng, Chenxi Li, Neil F. Abernethy, Barbara D. Lam, Fei Xia, Meliha Yetisgen",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.391961",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是“非演化型应用”** 论文的核心目标是解决一个特定的生物医学信息提取任务——从临床笔记中提取化疗时间线。这是参加一个名为 \"ChemoTimelines 2025\" 的特定领域评测。论文描述了如何运用和调整现有的LLM技术（如思维链、微调）来更好地完成这个特定任务。这完全符合筛选标准中的“非演化型应用”排除项：**将LLM作为工具应用到特定领域（医疗）去解决该领域的问题**。论文的核心贡献在于应用，而非构建新的智能体框架或演化机制。 2.  **正面指标缺失（第二步）：未涉及核心关注点** 尽管论文提到了 \"chain-of-thought thinking\"，但这里的“思考”是作为一种提升信息提取准确性的提示技巧，而非智能体自主规划、工具使用或自我反思的框架。论文没有提出任何关于 `Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Collaboration` 或 `Self-Improvement` 的新方法论。其工作流程是一个标准的“提取-后处理”流水线，而不是一个具备自主能力的智能体循环。 3.  **特殊情况的澄清（第四步）：推理与自我演化的误读** - **关于推理/规划**：论文中的思维链（CoT）是为了让LLM在从单篇笔记中提取事件时表现更好，它不属于智能体在复杂任务中进行多步自主规划的范畴（如ReAct）。它更像是一种提升模型基础能力（在此场景下是信息抽取）的技巧，而非构建一个Agentic框架。 - **关于自我演化**：论文使用了监督微调（SFT）和直接偏好优化（DPO）。这些是离线的模型训练和优化方法，用于在部署前提升模型在特定任务上的性能。它们不等同于智能体在部署后通过与环境交互、进行经验学习或自我反思来实现的“自我演化”机制。 **总结**：该论文是一篇典型的应用型研究，其价值在于为生物医学领域的特定任务提供了有效的技术方案和实验分析。然而，它的核心贡献并非构建、改进或演化LLM智能体本身，因此与您关于“LLM智能体及其演化”的核心研究目标不符。"
    },
    {
        "index": "#25",
        "title": "Sarcasm Detection on Reddit Using Classical Machine Learning and Feature Engineering",
        "link": "/arxiv/2512.04396",
        "arxiv_id": "2512.04396",
        "authors": "Subrata Karmaker",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.397941",
        "filter_reason": "这篇论文完全不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心是关于使用**经典机器学习方法**（如逻辑回归、SVM、朴素贝叶斯）和**显式特征工程**来解决特定领域（Reddit上的反讽检测）的**分类问题**。论文明确指出其研究“不依赖神经网络”。这与我的核心目标——筛选关于“构建、改进或演化LLM智能体”的论文——完全背道而驰。该论文属于典型的**非演化型应用**，它将一个静态的、非智能体的模型应用于一个特定任务，没有涉及任何智能体框架、规划、工具使用或演化机制。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中完全没有出现任何我关注的核心范式或能力关键词。例如，它没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use`、`Memory` 或 `Self-Reflection`。这进一步确认了它与我的研究焦点无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文不直接涉及安全与对齐或多模态，但它在第一步的核心判断中已经被明确排除。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与智能体相关的推理/规划框架，更没有提出任何自我演化机制。因此，特殊情况的例外条款不适用。 **最终决策**：这篇论文的核心贡献是为一个特定的NLP分类任务（反讽检测）提供一个基于传统机器学习的基线。它既没有使用LLM，也没有构建任何形式的智能体，更没有涉及智能体的演化。因此，它被严格排除。"
    },
    {
        "index": "#20",
        "title": "AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees",
        "link": "/arxiv/2512.04550",
        "arxiv_id": "2512.04550",
        "authors": "Yangning Li, Shaoshen Chen, Yinghui Li, Yankai Chen, Hai-Tao Zheng, Hui Wang, Wenhao Jiang, Philip S. Yu",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.391401",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 `AdmTree` 的框架，用于**压缩长上下文**，以解决自注意力机制的计算瓶颈。其本质是**模型基础设施**或**基础模型效率优化**的研究。它关注的是如何让LLM更高效地处理长文本输入，而不是如何让LLM表现得像一个智能体。根据筛选标准，应排除“主要关注模型基础设施、部署优化”的研究。因此，在这一步，该论文应被**排除**。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文的摘要和标题中完全没有出现我的核心关注点，如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Collaboration` 等关键词。它讨论的是“语义保真度”、“信息密度”和“分层抽象”，这些都是关于文本处理本身，而非智能体的行为或能力。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除领域，但它命中了更根本的“基础设施”排除项。 4.  **第四步：处理特殊和模糊情况。** 该论文不涉及推理/规划或自我演化的特殊情况。它解决的是输入端的效率问题，而非智能体在任务执行中的决策或演化问题。 **最终决策**: 综合以上分析，这篇论文的核心是**提升LLM处理长上下文的计算效率**，属于模型基础设施层面的优化。我的研究焦点是**LLM智能体的构建、协作与演化机制**，关注的是智能体的行为、能力和迭代过程。虽然高效的长上下文处理是高级智能体的重要支撑技术，但这篇论文本身并未提出任何与智能体规划、工具使用、多智能体交互或自我演化相关的框架或方法论。因此，它不符合我的核心研究目标，应予以排除。"
    },
    {
        "index": "#19",
        "title": "ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning",
        "link": "/arxiv/2512.04555",
        "arxiv_id": "2512.04555",
        "authors": "Pritam Kadasi, Abhishek Upperwal, Mayank SIngh",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.391109",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为ADAPT的元学习算法，用于在预算约束下优化多任务指令微调过程中的任务采样比例。其本质是一种**高效的模型训练方法论**，而非构建或改进LLM智能体的框架。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断——排除** 论文的核心是关于如何更有效地训练一个基础LLM，通过动态调整不同任务的训练数据配额来提升模型在下游任务（如推理、阅读理解）上的表现。这完全符合排除标准中的第二条：“非Agentic的推理: 如果论文只是关于提高LLM的基础推理能力...但其方法不涉及智能体自主规划、工具使用或自我演化框架。” ADAPT算法本身不构成一个智能体，它没有规划、记忆、工具使用或自我反思的能力。它是一个训练阶段的优化器，而不是一个运行时的智能体架构。 2.  **第二步：正面指标——不匹配** 论文摘要中完全没有出现我核心关注点的任何关键词，例如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。它关注的是 `instruction tuning`（指令微调）和 `meta-learning`（元学习），这些属于模型训练范畴，而非智能体行为设计。 3.  **第三步：排除标准——不直接相关，但已排除** 论文不涉及安全、对齐或多模态等排除领域，但第一步的判断已经足够将其排除。 4.  **第四步：处理特殊和模糊情况——强化排除** - **推理/规划**: 论文确实旨在提升模型的推理能力，但其方法是改进训练过程（一种非Agentic的微调方法），而不是设计一个新的Agentic推理框架（如ReAct或ToT）。因此，根据规则，应予以排除。 - **自我演化**: 尽管算法名称“ADAPT”和其“自适应课程”听起来有“演化”的意味，但这指的是**训练过程的演化**，而非**智能体自身的演化**。我的研究焦点是智能体在部署后如何通过经验和反馈进行自我完善，而这篇论文研究的是如何在训练阶段更聪明地“喂养”数据给模型。二者有本质区别。 **最终决策**: 该论文的核心贡献在于一种创新的**模型训练技术**，旨在提升基础LLM的能力上限。它并不涉及构建具有自主性、规划能力或演化能力的智能体。因此，它不符合我关于“LLM智能体及其演化”的研究范围，应予以排除。"
    },
    {
        "index": "#24",
        "title": "RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning",
        "link": "/arxiv/2512.04457",
        "arxiv_id": "2512.04457",
        "authors": "Guoshenghui Zhao, Huawei Lin, Weijie Zhao",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.397695",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是模型安全与对齐技术，而非智能体构建。** - 论文的核心贡献是提出了一种名为 \"RapidUn\" 的**高效“遗忘”框架**。其目标是“从大型语言模型中移除特定数据影响”，特别是“忘记有害行为”。 - 这是一种**模型编辑或对齐技术**，旨在修改模型内部参数以满足安全或合规要求，而不是构建一个具有自主规划、工具使用或反思能力的**智能体**。它没有涉及智能体的核心架构或行为模式，因此不符合“构建、改进或演化 LLM智能体”的核心目标。 2.  **排除标准 (第三步): 论文明确属于“安全与对齐”范畴。** - 摘要中明确指出，该技术的目的是“forgetting harmful behavior”（忘记有害行为）。这直接对应了筛选标准中的 `Safety` (安全) 和 `Alignment` (对齐)。 - 根据您的规则，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Explainability (XAI)`, `Alignment` ... 一律排除”。这篇论文的主要贡献完全落在这个排除区间内。 3.  **正面指标缺失 (第二步): 论文不包含任何与智能体相关的核心关注点。** - 论文的研究内容与 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving` 等核心范式无关。 - 它也未涉及 `Planning`, `Tool Use`, `Memory`, `Self-Reflection`, `Collaboration` 等任何智能体关键能力或多智能体交互机制。 **总结**: 尽管这篇论文在LLM安全领域可能是一项有价值的工作，但其研究焦点是**模型的安全编辑与对齐**，而非**智能体的构建、协作或演化**。它与您“LLM智能体及其演化”的研究课题方向完全不同，因此应被排除。"
    },
    {
        "index": "#21",
        "title": "EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion",
        "link": "/arxiv/2512.04545",
        "arxiv_id": "2512.04545",
        "authors": "Pengfei Cao, Zeao Ji, Daojian Zeng, Jun Zhao, Kang Liu",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.391660",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 EvoEdit 的终身知识编辑方法，旨在高效、持续地修改大型语言模型（LLM）内部过时的知识，而无需完全重新训练。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断** 论文的本质是**知识编辑**，而非构建或演化LLM智能体。知识编辑关注的是如何修改模型参数中的静态事实知识，这属于对模型底层能力的维护和更新。它没有涉及智能体的核心要素，如自主规划、工具使用、与环境的交互循环或基于经验的自我学习机制。因此，它更接近于“非Agentic的推理/知识”范畴，应被排除。 2.  **第二步：正面指标** 尽管标题中包含 \"Evo\"（演化），但摘要明确指出其核心是 \"Lifelong Free-text Knowledge Editing\"（终身自由文本知识编辑）。这与研究焦点中的 `Self-Evolving`（智能体通过经验、反思或环境反馈进行自我完善）有本质区别。论文没有提及 `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent` 等任何核心智能体能力的关键词。因此，正面指标缺失。 3.  **第三步：排除标准** 论文不涉及安全、对齐或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的规划或多步推理框架。它关注的是事实知识的准确性，而非智能体如何运用知识进行决策。 - **自我演化的应用**: 这是关键的判断点。虽然论文提出了“终身编辑”，但这并非研究焦点所定义的“自我演化”。研究焦点中的“自我演化”是指智能体**自主地**从经验、反思或环境反馈中学习和完善自身。而 EvoEdit 的机制是**被动地**接收外部的、以自然语言形式表达的“编辑请求”来更新知识。这是一种外部的、人为驱动的模型维护手段，而非智能体内在的、自主的演化过程。因此，它不符合“自我演化机制”的例外保留条件。 **最终决策**: 该论文的核心是知识编辑技术，旨在解决LLM知识更新的问题，而不是构建或演化一个具有自主性的LLM智能体。其“终身编辑”机制是外部驱动的，与智能体“自我演化”的内涵不符。因此，这篇论文不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#23",
        "title": "MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection",
        "link": "/arxiv/2512.04492",
        "arxiv_id": "2512.04492",
        "authors": "Yuanshuo Zhang, Aohua Li, Bo Chen, Jingbo Sun, Xiaobing Zhao",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.397443",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心目标是筛选那些核心贡献在于**构建、改进或演化LLM智能体本身**的论文，而该论文的核心贡献是**提出一个用于特定NLP任务（立场检测）的专用框架**。 以下是我的详细判断过程： 1.  **第一步：核心判断——本质是应用而非智能体构建** - 论文的核心是MSME框架，其最终目标是提升“零样本立场检测”这一特定任务的性能。虽然它采用了多阶段、多模块的结构，但这些模块（知识专家、标签专家、语用专家）是高度定制化、专门为解决立场检测问题中的特定挑战（如背景知识、反讽）而设计的。 - 这完全符合第一步排除标准中的“**非演化型应用**”：将一个结构化的LLM使用框架应用到特定领域（这里是NLP的立场检测）去解决该领域的问题。论文的创新点在于**应用层面的框架设计**，而非提出一种通用的、可迁移的LLM智能体构建方法论。 2.  **第二步：正面指标分析——仅有表面相似性** - 论文确实包含一些看似相关的指标，如“多阶段”过程（类似规划）和“知识准备”（类似工具使用）。然而，这些元素是作为解决立场检测任务的**固定流水线**存在的，而不是一个具备自主性、通用性的智能体能力。 - 尤其需要注意的是，论文中的“Multi-Expert”并非我研究焦点中的“Multi-Agent System”。多智能体系统强调的是多个**自主智能体**之间的协作、通信或博弈。而MSME中的“专家”是单个系统内部的**功能模块**，由一个“Meta-Judge”进行静态整合，它们之间没有自主的交互或社会性学习。 3.  **第四步：处理特殊情况——推理/规划的定位** - 根据第四步的规则，我需要区分“智能体的规划”和“非Agentic的推理”。MSME的多阶段流程是一个**预设的、固定的推理流水线**，而不是一个智能体在动态环境中自主学习和生成的规划策略。它与ReAct、ToT这类旨在提升LLM通用多步推理能力的范式有本质区别，后者的贡献在于**推理范式本身**，而MSME的贡献在于**将一个定制化的推理范式成功应用于特定任务**。 **结论**: 该论文的本质是利用LLM构建了一个复杂的、模块化的应用系统来解决立场检测问题。它的核心贡献是**任务驱动的应用创新**，而非**智能体本身的架构或能力创新**。因此，它虽然形式上与智能体有相似之处，但研究焦点与我的“LLM智能体及其演化”课题不符，应予以排除。"
    },
    {
        "index": "#26",
        "title": "MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation",
        "link": "/arxiv/2512.04386",
        "arxiv_id": "2512.04386",
        "authors": "Zhou Yang, Shunyan Luo, Jiazhen Zhu, Fang Jin",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.398209",
        "filter_reason": "这篇论文不符合您的研究范围，应予以排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个名为“MASE”的框架，用于解释NLP模型的决策过程，其本质是**模型可解释性**研究。它并不涉及构建、改进或演化LLM智能体。根据筛选标准，这属于“非演化型应用”的范畴，其目标是解释模型，而非创造或演化一个具有自主性的智能体。 2.  **排除标准 (第三步):** 这是最关键的排除依据。论文摘要明确指出其研究目标是解决“interpretability remains elusive”（可解释性仍然难以捉摸）的问题，并提出了一个“model-agnostic interpretation methods”（模型无关的解释方法）。这直接命中了您设定的排除标准：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability` (可解释性), `Explainability (XAI)`...一律排除。” 3.  **正面指标缺失 (第二步):** 论文中完全没有出现您关注的核心范式和能力相关的关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Multi-Agent Systems`, `Self-Evolving` 等。这进一步确认了它与您的研究焦点无关。 综上所述，尽管MASE是一个在NLP可解释性领域可能有价值的贡献，但其研究核心与“LLM智能体及其演化”这一课题完全偏离。因此，根据您的严格筛选标准，应将其排除。"
    },
    {
        "index": "#28",
        "title": "ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation",
        "link": "/arxiv/2512.04350",
        "arxiv_id": "2512.04350",
        "authors": "Yiming Xu, Yuan Yuan, Vijay Viswanathan, Graham Neubig",
        "subjects": "Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.398727",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心贡献不符 (第一步核心判断)**: 论文的核心贡献是提出了一种名为 `ClusterFusion` 的**文本聚类算法**。它创新地将LLM作为聚类流程的核心组件，而不是像之前工作那样仅作为辅助模块。然而，这本质上是一种**算法创新**，属于“非演化型应用”。论文的目标是解决文本聚类这一特定NLP任务，而不是构建、改进或演化一个具有自主性的LLM智能体。LLM在这里被用作一个强大的“函数”来执行主题摘要和分配，而不是一个能够自主规划、使用工具或进行自我反思的智能体。 2.  **缺乏关键智能体特征 (第二步正面指标)**: 论文中完全没有提及我的研究焦点所包含的关键概念。它不涉及智能体的 `Planning` (规划)、`Memory` (记忆)、`Tool Use` (工具使用，在智能体主动使用外部工具的意义上)、`Self-Reflection` (自我反思)，也不涉及 `Multi-Agent` (多智能体) 的协作或通信，更没有 `Self-Evolving` (自我演化) 的机制。其流程是固定的：划分 -> 摘要 -> 分配，这是一个静态的算法流水线，而非一个动态的、自主的智能体框架。 3.  **属于应用层研究，而非智能体架构研究**: 尽管论文将LLM置于“核心”地位，但这指的是在聚类算法中的核心地位，而非在智能体架构中的核心地位。我的研究目标是“Agentic AI”，关注的是智能体本身的架构和能力演化。而该论文关注的是如何利用LLM的能力来提升一个下游任务（聚类）的性能。这符合第一步排除标准中的“将LLM作为工具应用到特定领域去解决该领域的问题”。 综上所述，尽管 `ClusterFusion` 是一篇在文本聚类领域可能很有价值的论文，但其研究本质是算法应用，而非LLM智能体的构建或演化。因此，它被排除在我的研究范围之外。"
    },
    {
        "index": "#27",
        "title": "LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving",
        "link": "/arxiv/2512.04374",
        "arxiv_id": "2512.04374",
        "authors": "Muyu Pan, Matthew Walter, Dheeraj Kodakandla, Mahfuza Farooque",
        "subjects": "Computation and Language, Formal Languages and Automata Theory",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.398473",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出一个名为 `LangSAT` 的框架，用于解决布尔可满足性问题（SAT）。这个框架结合了NLP（用于将自然语言转换为逻辑表达式）和强化学习（用于优化SAT求解器中的启发式选择）。这完全符合筛选标准中的 **“非演化型应用”** 排除项。论文将NLP模型和RL智能体作为工具，应用于一个特定领域（形式验证、逻辑推理），以解决该领域的问题（提高SAT求解效率）。其核心贡献是针对SAT求解的，而非构建一个通用的、可演化的LLM智能体框架。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文中虽然提到了“RL agent”，但这个智能体是一个传统的强化学习智能体，用于在特定任务（选择启发式）中学习最优策略，它不具备您所关注的LLM智能体的核心能力，如 `Planning`、`Memory`、`Self-Reflection` 或 `Tool Use`。论文的另一个组件 `Lang2Logic` 是一个翻译工具，而非一个自主的智能体。因此，论文缺乏您所关注的核心范式和能力指标。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够做出排除决定。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的RL智能体是在一个封闭、定义明确的环境（SAT求解过程）中学习策略，这不属于您所关注的“智能体在复杂任务中进行多步推理或自主规划”的范畴。它更接近于对一个传统算法的组件进行优化，而非构建一个通用的Agentic推理框架。 - **自我演化的应用**: 论文没有提出任何新的“自我演化”机制。它使用的是标准的RL训练方法，这不属于您定义的“通过经验、反思或环境反馈进行自我完善和迭代”的自我演化范畴。 **最终决策**: 该论文的本质是 **应用型研究**，它利用NLP和RL技术来改进一个特定的传统算法（SAT求解器）。其核心贡献在于 **领域应用的优化**，而不是 **LLM智能体本身的构建、改进或演化**。因此，它与您“LLM智能体及其演化”的核心研究目标不符，应予以排除。"
    },
    {
        "index": "#31",
        "title": "Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification",
        "link": "/arxiv/2512.04257",
        "arxiv_id": "2512.04257",
        "authors": "Mansour Essgaer, Khamis Massud, Rabia Al Mamlook, Najah Ghmaid",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.399598",
        "filter_reason": "这篇论文完全不符合我的研究范围。我的判断依据如下： 1.  **第一步：核心判断——论文本质不符** - 该论文的核心贡献是应用传统的机器学习模型（逻辑回归、支持向量机、朴素贝叶斯）来解决一个特定的计算语言学问题：利比亚方言识别。 - 这完全属于筛选标准中明确排除的 **“非演化型应用”**。论文没有构建、改进或演化任何形式的LLM智能体，甚至没有使用LLM作为工具。它是一项纯粹的、针对特定领域（方言识别）的NLP分类任务研究。 2.  **第二步：正面指标——缺乏核心关注点** - 论文摘要中完全没有出现任何与我研究焦点相关的正面指标。没有提及 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving` 等核心范式。 - 同样，也没有涉及任何智能体能力，如 `Planning`、`Tool Use`、`Memory`、`Self-Reflection` 等。论文的研究内容是特征工程和分类器性能比较，与智能体无关。 3.  **第三步和第四步：排除标准与特殊情况** - 虽然论文不属于“安全与对齐”或“多模态与视觉”的排除类别，但其在第一步的判断已经足够明确。 - 论文的研究内容也不涉及“推理/规划”或“自我演化”的特殊情况。它只是在比较不同静态分类器的分类效果。 **总结**: 该论文是一项关于传统机器学习在方言识别领域应用的研究，其核心贡献、方法论和研究目标都与“LLM智能体及其演化”这一课题毫无关联。因此，根据筛选标准，必须将其排除。"
    },
    {
        "index": "#29",
        "title": "DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle",
        "link": "/arxiv/2512.04324",
        "arxiv_id": "2512.04324",
        "authors": "Fangyu Lei, Jinxiang Meng, Yiming Huang, Junjie Zhao, Yitong Zhang, Jianwen Luo, Xin Zou, Ruiyi Yang, Wenbo Shi, Yan Gao, Shizhu He, Zuo Wang, Qian Liu, Yang Wang, Ke Wang, Jun Zhao, Kang Liu",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.399081",
        "filter_reason": "这篇论文不符合你的研究范围，尽管其主题与LLM智能体高度相关。以下是根据你的筛选标准进行的详细判断： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是**构建了一个基准测试**，而不是构建、改进或演化LLM智能体本身。标题和摘要都明确指出，DAComp是一个“Benchmark”（基准测试），其目的是为了“Benchmarking Data Agents”（评估数据智能体）。论文的主要工作是设计任务、定义评估指标（包括LLM-judge），并用这个基准来测试现有智能体的能力，从而揭示它们的不足。这完全符合“非演化型应用”的排除规则，因为它没有提出新的智能体方法论或框架，而是将现有智能体作为评估对象，以推动该领域的发展。你的核心目标是筛选出**构建**智能体的论文，而这是**评估**智能体的论文。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中确实包含了大量正面指标，如 `Data Agents`、`Planning`、`Tool Use` (SQL, coding)、`Self-Reflection` (interpretation of intermediate results)。然而，这些关键词是用来**描述基准测试所要衡量的能力**，而不是论文本身提出的新能力或新框架。论文的贡献在于“如何衡量这些能力”，而不是“如何实现这些能力”。因此，虽然主题相关，但贡献点不符。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 该论文不涉及安全、对齐或多模态等排除标准，因此这一步不适用。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文讨论了智能体在开放式任务中的“战略规划”，但它并没有提出一种新的规划算法或框架。它只是测试现有智能体在规划任务上的表现。根据规则，这属于“排除”情况。 - **自我演化的应用**: 论文不涉及自我演化机制。 **最终决策**: 综合以上分析，这篇论文的核心贡献是**评估工具**，而非**智能体构建方法**。虽然它对于研究LLM智能体的研究人员来说非常有价值，可以帮助他们了解当前技术的瓶颈，但它本身并不满足你“核心贡献在于构建、改进或演化LLM智能体”的筛选要求。因此，应将其排除。"
    },
    {
        "index": "#33",
        "title": "DraCo: Draft as CoT for Text-to-Image Preview and Rare Concept Generation",
        "link": "/arxiv/2512.05112",
        "arxiv_id": "2512.05112",
        "authors": "Dongzhi Jiang, Renrui Zhang, Haodong Li, Zhuofan Zong, Ziyu Guo, Jun He, Claire Guo, Junyan Ye, Rongyao Fang, Weijia Li, Rui Liu, Hongsheng Li",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.400227",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是提出了一种名为 `DraCo` 的新方法，用于改进**文本到图像生成**的质量。它通过生成一个低分辨率草稿图像作为“思维链”的一部分，来指导和验证最终的图像生成过程。这本质上是一种**改进多模态模型（MLLM）生成能力**的技术，而不是构建一个具有自主性、规划或工具使用能力的LLM智能体。因此，根据第一步的排除标准，这属于“非演化型应用”，即将一种推理范式应用到了特定的视觉生成领域，其核心是解决该领域（图像生成）的问题，而非构建通用的智能体框架。 2.  **第二步：正面指标——是否包含核心关注点？** 尽管论文中出现了 `CoT` (Chain-of-Thought)、`planning`、`verification` 和 `refinement` 等看似相关的词汇，但它们的上下文至关重要。这里的“规划”是指对图像内容的视觉规划（生成草稿），“验证”是检查草图与文本提示的语义对齐，“精炼”是超分辨率修复。这些步骤是**一个固定的、为生成单张图像而设计的算法流程**，而不是一个智能体在动态环境中进行自主决策、使用工具或进行多步推理的框架。因此，这些正面指标在此处并不指向您研究的核心。 3.  **第三步：排除标准——是否为研究焦点之外？** **这是最关键的排除依据。** 论文明确聚焦于 `multimodal large language models (MLLMs)` 和 `text-to-image generation`。根据您的排除标准，“多模态与视觉”是明确的排除项，除非它们被用作智能体感知环境的工具。在这篇论文中，视觉生成本身就是研究的**核心**，而不是智能体的一个辅助功能。因此，该论文完全落在了您的研究焦点之外。 4.  **第四步：处理特殊和模糊情况** - **推理/规划:** 论文中的“规划”是针对图像内容的静态规划，而非智能体在任务执行中的动态行动规划。它不符合“智能体如何进行规划或在复杂任务中进行多步推理”的保留条件。 - **自我演化:** 论文的“精炼”步骤是生成管线中的一次性修正，不涉及智能体通过经验或反馈进行自我完善和迭代的学习机制。因此，它不属于“自我演化”的范畴。 **最终决策:** 综合以上分析，该论文的核心贡献是**一种新颖的文本到图像生成技术**，而非LLM智能体的构建、改进或演化。虽然它借鉴了CoT等概念，但其应用场景和本质属于多模态生成领域，与您“LLM智能体及其演化”的核心研究目标不符。因此，应将其排除。"
    },
    {
        "index": "#30",
        "title": "SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats",
        "link": "/arxiv/2512.04292",
        "arxiv_id": "2512.04292",
        "authors": "Chinmay Gondhalekar, Urjitkumar Patel, Fang-Chun Yeh",
        "subjects": "Computation and Language",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.399329",
        "filter_reason": "根据您提供的筛选标准，我的判断过程如下： 1.  **第一步：核心判断** - **论文的本质是什么？** 这篇论文的核心贡献是提出一个名为 SQuARE 的**混合检索框架**，专门用于处理复杂的表格数据问答。其创新点在于“结构化查询”和“自适应检索”的引擎设计，通过计算表格复杂度来动态选择检索路径（结构化分块或SQL）。 - **是否符合保留标准？** 不符合。论文虽然提到了一个“轻量级智能体”，但这个智能体是作为SQuARE系统内部的一个**组件**，其功能是“在置信度低时监督检索、优化或组合结果”。这并非论文的核心贡献，论文的核心是整个检索引擎的架构设计。因此，这篇论文属于**“非演化型应用”**，它构建了一个解决特定领域（表格理解）问题的系统，并使用了一个类似智能体的模块作为工具，但其本身并未提出构建、改进或演化LLM智能体的通用方法论或新框架。 2.  **第二步：正面指标** - 论文中出现了 `Agent` 和 `Refinement` (优化) 等词汇，看似相关。然而，这些词汇被严格限制在SQuARE这个特定检索系统的上下文中。该智能体不具备通用的规划、记忆或工具使用能力，其“优化”行为也是针对检索结果的组合，而非智能体能力的自我提升。因此，这些正面指标非常微弱，不足以改变第一步的判断。 3.  **第三步：排除标准** - 论文不涉及安全、对齐或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况** - **推理/规划：** 论文中的智能体执行“优化”和“组合”操作，这是一种简单的推理形式。但它不是关于智能体如何进行自主规划或在复杂任务中进行多步推理的框架研究，而是一个针对特定任务（检索结果后处理）的启发式规则。因此，它更偏向于系统设计，而非Agentic推理研究。 - **自我演化的应用：** 论文没有提出任何“自我演化”机制。智能体的优化是一次性的、基于规则的，而不是通过经验或反馈进行迭代学习和自我完善。 **最终决策：** 综合以上分析，这篇论文的核心贡献是**一个针对表格数据的检索系统**，而不是一个LLM智能体的方法论。文中的“智能体”只是一个实现特定功能（结果优化）的内部模块，而非研究的主体。因此，该论文属于将智能体概念作为工具应用于特定领域的范畴，不符合您“核心贡献在于构建、改进或演化LLM智能体”的研究目标。应予以排除。"
    },
    {
        "index": "#37",
        "title": "The AI Consumer Index (ACE)",
        "link": "/arxiv/2512.04921",
        "arxiv_id": "2512.04921",
        "authors": "Julien Benchek, Rohit Shetty, Benjamin Hunsberger, Ajay Arun, Zach Richards, Brendan Foody, Osvald Nitski, Bertie Vidgen",
        "subjects": "Artificial Intelligence, Computation and Language, Human-Computer Interaction",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.401353",
        "filter_reason": "这篇论文不符合您的研究范围，核心原因在于其贡献的本质是**评估**而非**构建**。 1.  **核心判断 (第一步)**: 论文的核心贡献是提出了一个名为“AI Consumer Index (ACE)”的**基准**，用于评估现有前沿AI模型在消费者任务上的表现。它没有提出任何新的LLM智能体架构、改进现有智能体的规划/记忆/工具使用能力，也没有涉及多智能体系统或自我演化机制。根据筛选标准第一步，这明确属于“非演化型应用”的排除范畴。论文将LLM（及其工具使用能力）作为评估对象，应用在“消费者任务评估”这一特定领域，其研究焦点是“衡量表现”，而不是“创造或演化智能体”。 2.  **正面指标 (第二步)**: 论文中提到了“websearch turned on”，这与“工具使用”相关。然而，这仅仅是评估时开启的一个已有功能，并非论文提出的创新点。论文并未包含任何关于`Planning`, `Memory`, `Self-Reflection`, `Collaboration`, `Self-Evolving`等核心范式或能力的贡献。因此，正面指标非常薄弱。 3.  **排除标准 (第三步)**: 论文提到了模型在特定任务上“prone to hallucination”（容易产生幻觉）。但这只是评估过程中的一个发现，论文的主要贡献并非提出解决幻觉的新方法。因此，虽然涉及了“幻觉”这一关键词，但并未触达“主要贡献是关于幻觉”的排除标准。不过，这进一步印证了论文的评估性质。 4.  **特殊与模糊情况 (第四步)**: 该论文不涉及推理/规划框架的创新，也不涉及自我演化机制的应用。 **最终决策**: 综合来看，该论文是一篇重要的**评测**工作，为衡量LLM智能体在真实世界任务中的能力提供了有价值的基准。然而，您的研究目标是筛选那些**核心贡献在于构建、改进或演化LLM智能体**的论文。该论文关注的是“如何衡量”，而非“如何实现”，因此与您的研究焦点“Agentic AI的构建与演化”存在根本性的偏离，应予以排除。"
    },
    {
        "index": "#39",
        "title": "Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case",
        "link": "/arxiv/2512.04834",
        "arxiv_id": "2512.04834",
        "authors": "Vignesh Kumar Kembu, Pierandrea Morandini, Marta Bianca Maria Ranzini, Antonino Nocera",
        "subjects": "Artificial Intelligence, Computation and Language, Information Retrieval",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.401919",
        "filter_reason": "这篇论文不符合我的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是应用评估，而非智能体构建。** 论文的核心贡献是“探索开源多语言LLM在意大利语电子健康记录（EHR）信息提取任务上的能力”。这本质上是一项**实证评估研究**，旨在测试现有LLM在特定领域（医疗保健）和特定任务（信息提取）上的表现。它没有提出任何新的LLM智能体框架、改进智能体的规划/记忆/工具使用能力，也没有涉及多智能体系统或自我演化机制。因此，该论文完全符合第一步排除标准中的“**非演化型应用**”，即只是将LLM作为工具应用到特定领域去解决该领域的问题。 2.  **第二步：正面指标——完全缺失。** 论文的标题和摘要中，完全没有出现任何与我核心关注点相关的正面指标关键词，例如 `Agentic AI`, `Multi-Agent Systems`, `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection` 等。其焦点是 `Multilingual Capability` 和 `Information Retrieval`，这属于LLM的基础能力评估，而非智能体研究。 3.  **第三步：排除标准——不直接相关，但已排除。** 论文不涉及安全、对齐或多模态等排除标准，但第一步的判断已经足够将其排除。 4.  **第四步：特殊和模糊情况——不适用。** 论文不涉及智能体规划框架，也未提出任何自我演化机制，因此特殊情况的规则不适用。 **最终决策**：该论文是一项关于LLM在特定下游任务（医疗信息提取）上的性能评估研究，其核心贡献不在于构建、改进或演化LLM智能体。这与我研究“LLM智能体及其演化”的核心目标——关注智能体的方法论、框架和演化机制——背道而驰。因此，应予以排除。"
    },
    {
        "index": "#36",
        "title": "Algorithmic Thinking Theory",
        "link": "/arxiv/2512.04923",
        "arxiv_id": "2512.04923",
        "authors": "MohammadHossein Bateni, Vincent Cohen-Addad, Yuzhou Gu, Silvio Lattanzi, Simon Meierhans, Christopher Mohri",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.401053",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。核心判断依据如下： 1.  **核心贡献不符（第一步）**: 论文的核心贡献是提出一个用于分析“推理算法”的**理论框架**。它将LLM视为一个“概率神谕”，并形式化地分析如何通过迭代和聚合来改进推理结果。这属于对**推理过程本身的理论建模**，而不是构建、改进或演化一个具有自主性的LLM智能体。 2.  **落入“非Agentic的推理”排除项（第一步）**: 根据您的筛选标准，需要排除“只是关于提高LLM的基础推理能力...但其方法不涉及智能体自主规划、工具使用或自我演化框架”的论文。这篇论文正是如此。它关注的是如何设计一个更好的“推理算法”，而不是如何设计一个能够自主规划、使用工具、进行反思的“智能体”。论文中没有提及任何关于智能体架构、记忆模块、工具调用或环境交互的内容。 3.  **缺乏核心关注点（第二步）**: 尽管摘要中提到了“iterative improvement”，但这被描述为一种算法设计原则，而非智能体的“自我演化”或“自我完善”能力。论文完全没有出现您关注的核心范式，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving`，也没有提及智能体能力，如 `Planning`, `Tool Use`, `Memory`, `Self-Reflection` 等。 4.  **特殊情况分析（第四步）**: 在“推理/规划”的特殊情况处理中，您明确指出要保留“关于智能体如何进行规划...的论文（如 ReAct、ToT）”，而排除“只是关于提高LLM本身基础Token预测的数学或逻辑能力”的论文。本文更接近后者，它是在一个更抽象的算法层面讨论推理，而不是在智能体的行为循环（如ReAct的Think-Act-Observe）中讨论规划。 **总结**: 该论文是一篇关于LLM推理算法的理论研究，虽然前沿且与高级推理相关，但其焦点是“算法”而非“智能体”。它缺乏您研究课题所要求的“Agentic”核心要素，即一个能够自主行动、规划和演化的实体。因此，它不符合您的筛选要求。"
    },
    {
        "index": "#44",
        "title": "Limit cycles for speech",
        "link": "/arxiv/2512.04642",
        "arxiv_id": "2512.04642",
        "authors": "Adamantios I. Gafos, Stephan R. Kuberski",
        "subjects": "Neurons and Cognition, Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.408533",
        "filter_reason": "这篇论文完全不符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献是**提出一种新的表示方法，用于揭示人类言语产生过程中发音动作的极限环组织结构**。这是一篇典型的计算神经科学、生物力学或语音学领域的研究论文，其研究对象是人类大脑和发音器官的生物物理特性，而非人工智能或LLM智能体。论文中完全没有提及LLM、智能体或任何相关的人工智能框架。因此，根据第一步的核心判断标准，该论文应被**排除**，因为它既不是关于构建LLM智能体，也不是关于多智能体系统或自我演化。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** 论文摘要中完全没有出现任何与您研究焦点相关的正面指标关键词，例如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent`, `Self-Evolving`, `Planning`, `Tool Use`, `Memory`, `Self-Correction`, `Collaboration` 等。这进一步确认了它与您的研究方向无关。 3.  **第三步：排除标准——是否为我的研究焦点之外？** 虽然这篇论文没有触发您设定的“安全与对齐”或“多模态与视觉”等排除标准，但这仅仅是因为它处于一个完全不同的研究领域。它不属于AI研究的范畴，因此这些标准不适用。 4.  **第四步：处理特殊和模糊情况** 该论文不涉及任何与“推理/规划”或“自我演化的应用”相关的特殊情况。其研究内容是纯粹的基础生物科学问题。 **最终决策：** 综合以上分析，这篇论文的研究对象是人类言语的生物物理机制，核心贡献是揭示发音动作中的极限环。这与您关于“LLM智能体及其演化”的研究目标——即构建、改进或演化基于LLM的智能体系统——没有任何交集。因此，该论文应被明确排除。"
    },
    {
        "index": "#38",
        "title": "STELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions",
        "link": "/arxiv/2512.04871",
        "arxiv_id": "2512.04871",
        "authors": "Junjie Fan, Hongye Zhao, Linduo Wei, Jiayu Rao, Guijia Li, Jiaxin Yuan, Wenqi Xu, Yong Qi",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.401649",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。判断依据如下： 1.  **核心判断（第一步）：论文的本质是“非演化型应用”** 论文的核心贡献是提出一个名为STELA的框架，用于解决**时间序列预测**这一特定领域的问题。其方法是通过一种新颖的“语义抽象”机制来增强输入给LLM的信息，从而提升预测效果。这完全符合**排除规则1：非演化型应用**。论文的本质是将LLM（以及一种新的提示策略）作为工具，应用于一个垂直领域，而不是研究如何构建、改进或演化LLM智能体本身。 2.  **缺乏核心关注点（第二步）** 论文中完全没有提及我的核心关注点。它没有涉及`Agentic AI`、`Multi-Agent Systems`或`Self-Evolving`等核心范式。在智能体能力方面，它没有讨论`Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或`Self-Reflection`（自我反思）。LLM在这里的角色更像是一个被精心设计的提示词所引导的“推理引擎”，而不是一个具备自主能力的智能体。 3.  **对推理/规划的特殊情况分析（第四步）** 虽然论文提到了“guiding the LLM to model intrinsic dynamics”（引导LLM建模内在动态），但这属于**排除情况**。它并非关于智能体如何进行自主规划和多步决策（如ReAct框架），而是关于如何通过改进输入提示来提升LLM在特定任务（时间序列预测）上的基础推理能力。这是一种高级的提示工程或数据增强技术，而非Agentic框架的创新。 综上所述，该论文的研究焦点是“如何更好地利用LLM解决时间序列预测问题”，而我的研究焦点是“如何构建、改进和演化LLM智能体”。二者存在本质区别。因此，这篇论文不符合筛选要求。"
    },
    {
        "index": "#43",
        "title": "SEASON: Mitigating Temporal Hallucination in Video Large Language Models via Self-Diagnostic Contrastive Decoding",
        "link": "/arxiv/2512.04643",
        "arxiv_id": "2512.04643",
        "authors": "Chang-Hsun Wu, Kai-Po Chang, Yu-Yang Sheng, Hung-Kai Chung, Kuei-Chun Wang, Yu-Chiang Frank Wang",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.408284",
        "filter_reason": "这篇论文不符合您的研究范围，核心原因在于其研究焦点是模型层面的错误修正，而非智能体的构建、协作或演化。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断——排除** 论文的核心贡献是提出了一种名为“自诊断对比解码”（SEASON）的**训练无关的解码方法**，用于减轻视频大语言模型在生成内容时出现的“时间幻觉”。这本质上是一种**模型输出层面的优化技术**，而不是构建或改进一个具有自主规划、工具使用或记忆能力的LLM智能体。它属于“非演化型应用”，即将一种技术应用于特定领域（视频理解）以解决该领域的问题（幻觉），而非提出新的智能体框架。 2.  **第二步：正面指标——不匹配** 论文中没有出现您关注的核心范式关键词，如 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Self-Evolving` 等。虽然标题中包含 \"Self-Diagnostic\"，但摘要明确指出这是一种针对每个输出token的动态诊断和解码策略，并非智能体层面的自我反思或自我修正机制。因此，它不满足任何正面指标。 3.  **第三步：排除标准——明确命中** 这篇论文明确命中了两个关键的排除标准： *   **安全与对齐**: 论文的核心贡献是关于 **`Hallucination` (幻觉)** 的缓解。根据您的规则，“只要论文的主要贡献是关于 `... Hallucination` (幻觉)，一律排除。” *   **多模态与视觉**: 论文的研究对象是 **`Video Large Language Models` (VideoLLMs)**，属于 `Vision-Language` 范畴。虽然视觉可以作为智能体的工具，但在这篇论文中，视觉模型本身就是被研究和改进的核心对象，而不是一个智能体框架的组成部分。 4.  **第四步：处理特殊和模糊情况——不适用** 论文虽然涉及“时间推理”，但其方法是在解码阶段通过对比来增强输出的时间一致性，这更接近于“提高LLM本身基础Token预测的...能力”，而不是关于“智能体如何进行规划或在复杂任务中进行多步推理”的框架。因此，它属于应被排除的推理类型。 **最终决策**: 该论文的核心是改进VideoLLMs的输出保真度，减少其在时间维度上的幻觉。这是一项关于多模态模型错误修正的研究，与您关注的“LLM智能体的构建、协作与自我演化”这一核心目标相去甚远。因此，应予以排除。"
    },
    {
        "index": "#41",
        "title": "Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective",
        "link": "/arxiv/2512.04691",
        "arxiv_id": "2512.04691",
        "authors": "Jae Hee Lee, Anne Lauscher, Stefano V. Albrecht",
        "subjects": "Artificial Intelligence, Computation and Language, Multiagent Systems",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.407657",
        "filter_reason": "这篇论文不符合研究范围，应被排除。 我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献并非构建、改进或演化LLM智能体的能力。根据摘要，这是一篇“立场论文”，其核心目标是“确保多智能体LLM系统（MALMs）的伦理行为”。它提出的研究议程是围绕“伦理”和“可解释性”展开的，而不是提出一个新的智能体框架、规划方法或演化机制。因此，它不符合“保留”标准，而更偏向于排除项。 2.  **第二步：正面指标** 论文确实包含了一些正面指标，如 `Multi-Agent Systems (MAS)`。然而，这些词汇是作为研究的**对象**出现的，而不是作为研究的**核心贡献**。论文并未提出新的协作、通信或社会学习方法，而是讨论如何对已有的多智能体系统进行伦理分析和对齐。因此，这些正面指标不足以使其被保留。 3.  **第三步：排除标准** 这是最关键的一步。论文的核心贡献与排除标准高度吻合： *   **安全与对齐**: 论文明确指出其目标是“确保伦理行为”，并提出了“有针对性的参数高效对齐技术”。这直接命中了 `Safety` 和 `Alignment` 这两个排除关键词。 *   **可解释性**: 论文的副标题和核心方法论是“从机制可解释性的角度”，并致力于“通过机制可解释性阐明产生涌现行为的内部机制”。这直接命中了 `Interpretability` (可解释性) 这个排除关键词。 根据筛选规则，“只要论文的主要贡献是关于 `Safety`, `Interpretability`, `Alignment` ... 一律排除”。这篇论文的主要贡献恰恰是这三者的结合体。 4.  **第四步：处理特殊和模糊情况** 论文不涉及特殊的推理/规划或自我演化应用场景，因此无需特殊处理。 **最终决策**: 综合以上分析，尽管论文的标题和研究对象涉及“多智能体系统”，但其核心贡献完全集中在“安全、对齐与可解释性”这一研究方向上。它探讨的是如何**控制和理解**智能体的行为，而不是如何**构建、增强或演化**智能体的能力。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标背道而驰。因此，该论文应被明确排除。"
    },
    {
        "index": "#42",
        "title": "Topology Matters: Measuring Memory Leakage in Multi-Agent LLMs",
        "link": "/arxiv/2512.04668",
        "arxiv_id": "2512.04668",
        "authors": "Jinbo Liu, Defu Cao, Yifei Wei, Tianyao Su, Yuan Liang, Yushun Dong, Yue Zhao, Xiyang Hu",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computation and Language",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.407978",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断** 论文的核心贡献是提出了一个名为MAMA的**测量框架**，用于**量化**多智能体LLM系统中的**记忆泄漏**问题。它并没有构建、改进或演化LLM智能体的核心能力（如规划、工具使用或学习机制），而是提出了一种**评估和攻击**现有智能体系统安全性的方法。因此，它的本质是安全分析，而非智能体能力的构建或演化。 2.  **第二步：正面指标** 论文确实包含了一些正面指标，如`Multi-Agent Systems (MAS)`、`Memory`和`Communication`（多轮交互）。这表明它与多智能体领域相关，但这并不足以使其符合您更具体的研究目标。 3.  **第三步：排除标准（关键步骤）** 这篇论文明确触犯了排除标准。其核心主题是关于**安全**和**隐私**。 -   论文标题和摘要中反复出现的关键词是 \"Memory Leakage\"（记忆泄漏）、\"Attack\"（攻击）、\"Personally Identifiable Information (PII)\"（个人可识别信息）和 \"Privacy Risk\"（隐私风险）。 -   论文的最终目标是提供 \"actionable guidance\"（可行的指导）来降低隐私风险，这属于典型的安全与对齐研究。 根据您的筛选标准：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`...一律排除。” 这篇论文的主要贡献完全落在`Security`范畴内，因此必须被排除。 4.  **第四步：处理特殊和模糊情况** 本论文不涉及推理/规划或自我演化的特殊情况。 **最终决策**： 尽管这篇论文研究了多智能体系统（Multi-Agent），但其研究焦点是**系统的安全漏洞分析**，而不是**智能体能力的构建、改进或演化**。您的核心目标是筛选那些致力于让智能体变得更“智能”、更“自主”或更能“自我进化”的论文。而本文的贡献在于如何“攻击”和“防护”智能体，属于AI安全领域，与您设定的Agentic AI核心研究方向（规划、工具使用、协作、演化）存在本质区别。因此，该论文不符合您的要求。"
    },
    {
        "index": "#40",
        "title": "MemLoRA: Distilling Expert Adapters for On-Device Memory Systems",
        "link": "/arxiv/2512.04763",
        "arxiv_id": "2512.04763",
        "authors": "Massimo Bini, Ondrej Bohdal, Umberto Michieli, Zeynep Akata, Mete Ozay, Taha Ceritli",
        "subjects": "Machine Learning, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.402203",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是基础设施优化，而非智能体框架创新。** 论文的核心贡献是提出 `MemLoRA`，一个旨在解决“记忆增强型LLM”在**设备端部署**时成本过高问题的系统。其核心技术手段是使用适配器和知识蒸馏来压缩模型，使其能在小型语言模型（SLM）上高效运行。这完全符合第一步排除标准中的“基础设施：排除主要关注模型基础设施、部署优化的研究”。论文的出发点是“如何让记忆系统在本地设备上跑起来”，而不是“如何构建一个更智能、会演化的智能体”。 2.  **排除标准（第三步）：论文的核心贡献包含多模态视觉。** 论文明确提出了 `MemLoRA-V`，一个视觉扩展版本，并将“集成小视觉语言模型（SVLMs）”和“实现原生视觉理解”作为其核心贡献之一进行阐述。根据我的筛选标准，只要论文的主要贡献涉及视觉或多模态（除非它们仅被用作智能体感知的工具），就应被排除。在这里，视觉能力是系统的一个核心卖点，而非一个简单的工具。 3.  **与研究焦点的偏差：** 我的研究焦点是智能体的“构建、改进或演化”，具体体现在规划、工具使用、自我反思、多智能体协作和自我演化等**动态能力**上。这篇论文虽然涉及“记忆”这一智能体的重要组件，但其研究重点在于记忆系统的**静态实现和部署效率**，而非智能体如何利用记忆进行规划、反思或自我演化。论文没有提出新的智能体行为范式或演化机制。 综上所述，尽管论文标题中包含“Memory”这一相关关键词，但其本质是关于模型部署效率和多模态扩展的基础设施研究，这与我寻找“LLM智能体及其演化”核心方法论的目标相悖。因此，应予以排除。"
    },
    {
        "index": "#46",
        "title": "Mitigating Object and Action Hallucinations in Multimodal LLMs via Self-Augmented Contrastive Alignment",
        "link": "/arxiv/2512.04356",
        "arxiv_id": "2512.04356",
        "authors": "Kai-Po Chang, Wei-Yuan Cheng, Chi-Pin Huang, Fu-En Yang, Yu-Chiang Frank Wang",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.409096",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一种名为 SANTA 的框架，用于**减轻多模态大模型（MLLMs）在视频描述任务中的幻觉问题**。这属于对模型基础能力的改进，特别是提升其输出内容的忠实度。它并未涉及构建一个具有自主规划、工具使用或记忆能力的智能体框架，也未涉及多智能体系统或智能体的自我演化机制。因此，根据第一步的排除标准，它属于“非Agentic的推理”范畴，应被排除。 2.  **排除标准 (第三步):** 论文的标题和摘要都明确指出，其研究目标是 **Mitigating Object and Action Hallucinations**（减轻对象和动作幻觉）。这直接命中了您设定的排除标准：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Explainability (XAI)`, `Alignment` (对齐), `Watermarking` (水印), 或 `Hallucination` (幻觉)，一律排除。” 减轻幻觉是模型安全与对齐领域的一个核心子问题，而非Agentic AI的核心。 3.  **处理模糊情况 (第四步):** 论文中提到的 `Self-Augmented`（自我增强）一词可能引起误解，但根据摘要描述，这是一种**数据增强技术**，通过模型自身生成“幻觉”样本来构建对比负样本，用于训练阶段的对比学习。它**不是**一个智能体在运行时通过经验、反思或环境反馈进行自我完善和迭代的“自我演化”机制。因此，它不符合“自我演化”的定义。 综上所述，该论文的研究焦点是**多模态模型的对齐与幻觉消除**，而非**LLM智能体的构建、协作或演化**。尽管它使用了“自我增强”这样的术语，但其本质是模型训练和优化技术，与您研究的Agentic AI核心方向（规划、工具使用、多智能体协作、自我演化）无关。因此，最终判断为排除。"
    },
    {
        "index": "#47",
        "title": "Text-Only Training for Image Captioning with Retrieval Augmentation and Modality Gap Correction",
        "link": "/arxiv/2512.04309",
        "arxiv_id": "2512.04309",
        "authors": "Rui Fonseca, Bruno Martins, Gil Rocha",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.409358",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是应用而非智能体构建** 论文的核心贡献是提出了一种名为TOMCap的**图像描述训练方法**。其目标是解决一个特定领域（计算机视觉与自然语言处理交叉领域）的问题：如何在不依赖人工标注的图像-文本对的情况下训练图像描述模型。这完全符合筛选标准中“非演化型应用”的排除项，即“将LLM（或一个已有的框架）作为工具应用到特定领域去解决该领域的问题”。论文的重点是训练技巧和数据效率，而不是构建一个具有自主性、规划或演化能力的智能体。 2.  **第三步：排除标准——核心属于多模态与视觉研究** 论文的研究对象是“图像描述”，其核心技术涉及“CLIP表示”、“模态鸿沟”等，这些都是典型的多模态与视觉研究方向。根据筛选标准，“只要论文的主要贡献是关于多模态与视觉……一律排除”。虽然论文使用了语言模型，但视觉模态是其研究的核心和出发点，而不是作为智能体感知环境的一个工具。因此，该论文明确属于应被排除的类别。 3.  **第二步：正面指标——缺乏任何Agentic相关特征** 通读标题和摘要，论文完全没有提及任何与您研究焦点相关的正面指标。它没有涉及`Planning`（规划）、`Memory`（记忆）、`Tool Use`（工具使用，这里的检索增强是训练方法的一部分，而非智能体自主决策的工具）、`Self-Reflection`（自我反思）、`Multi-Agent`（多智能体）或`Self-Evolving`（自我演化）等概念。其研究范式是传统的模型训练与评估，而非Agentic AI。 4.  **第四步：特殊情况——不适用** 论文不涉及智能体级别的推理或规划，也没有提出任何“自我演化”机制。因此，关于推理/规划和自我演化应用的例外规则不适用。 **总结**: 尽管这篇论文在图像描述领域可能是一项有价值的工作，但其本质是针对特定多模态任务的训练方法创新，与您关于“LLM智能体及其演化”的核心研究目标——即构建、改进和演化智能体本身的能力与框架——完全偏离。因此，应果断排除。"
    },
    {
        "index": "#50",
        "title": "Can machines perform a qualitative data analysis? Reading the debate with Alan Turing",
        "link": "/arxiv/2512.04121",
        "arxiv_id": "2512.04121",
        "authors": "Stefano De Paoli",
        "subjects": "Computers and Society, Artificial Intelligence, Computation and Language",
        "date": "2025-12-02",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.410170",
        "filter_reason": "这篇论文不符合您的研究范围，我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - **核心贡献分析**: 这篇论文的核心贡献并非构建、改进或演化LLM智能体。根据摘要，它是一篇**反思性和哲学性**的论文。它通过回顾文献、引用图灵的思想，来**重构和辩论**“LLM是否能进行定性数据分析”这一议题。论文的重点是提出一个新的研究视角（从“原则上能否”转向“能否产生与人类可比的分析”），并以图灵的写作风格来分析反对观点。 - **结论**: 论文的本质是**对现有应用的批判性反思和哲学探讨**，而不是提出新的智能体方法论或框架。因此，根据第一步的排除标准，它应被排除。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文摘要中完全没有出现您列出的任何核心范式或能力关键词，如 `Agentic AI`, `Planning`, `Tool Use`, `Self-Reflection`, `Multi-Agent`, `Self-Evolving` 等。它讨论的是“定性分析”这一任务本身，而非执行该任务的智能体架构或演化机制。 3.  **第四步：处理特殊和模糊情况** - **推理/规划**: 虽然定性分析可以被视为一种复杂的推理，但这篇论文并未提出一种新的**智能体推理框架**（如ReAct或ToT）。它讨论的是机器执行该任务的**可能性与评估标准**，而不是智能体**如何**通过规划、工具使用等步骤去完成它。因此，它属于“排除”范畴，即不是关于改进智能体的推理过程。 - **自我演化的应用**: 论文完全没有涉及任何“自我演化”机制。它只是讨论LLM在特定任务上的应用，不涉及自我完善或迭代。 **最终决策**: 综合以上分析，这篇论文是一篇关于LLM在特定领域（定性数据分析）应用的哲学思辨和辩论性文章。它的核心贡献在于**重塑研究问题和辩论视角**，而非**构建或演化LLM智能体**。这与您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标完全不符。因此，应予以排除。"
    },
    {
        "index": "#49",
        "title": "Network of Theseus (like the ship)",
        "link": "/arxiv/2512.04198",
        "arxiv_id": "2512.04198",
        "authors": "Vighnesh Subramaniam, Colin Conwell, Boris Katz, Andrei Barbu, Brian Cheung",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.409921",
        "filter_reason": "这篇论文不符合我的研究范围。我的核心判断依据如下： 1.  **核心贡献不匹配 (第一步核心判断)**: 论文的核心贡献是提出了一种名为 \"Network of Theseus (NoT)\" 的方法，其本质是一种**模型架构转换技术**。它旨在将一个已训练的神经网络（如 GPT-2）的架构逐步替换为另一个完全不同的架构（如 RNN），同时保持其性能。这属于**模型工程和基础设施优化**的范畴，而非构建或改进智能体的方法论。我的研究焦点是智能体的行为、能力和演化机制，而不是其底层物理架构的替换。 2.  **不属于 Agentic AI 范畴 (第一步排除标准)**: 论文完全没有涉及智能体的核心能力。它没有讨论智能体如何进行**规划**、如何使用**工具**、如何拥有**记忆**或进行**自我反思**。它只是将 GPT-2 作为一个被转换的静态对象，而不是一个自主行动的智能体。因此，它不属于 \"Agentic AI\" 的研究范畴。 3.  **“演化”概念的混淆 (第四步特殊情况和第一步排除)**: 虽然论文标题和“逐步转换”的过程可能让人联想到“演化”，但这是一种**架构层面的、由外部驱动的演化**，而非我研究目标中定义的**自我演化**。我所关注的“自我演化”是指智能体通过与环境的交互、经验积累或自我反思来**自主地**改进其策略、知识或能力。而 NoT 是一种外部工程师执行的“器官移植”手术，模型本身并未参与或主导这个演化过程。因此，它不符合“自我演化”的核心定义。 4.  **缺乏正面指标 (第二步)**: 论文摘要中完全没有出现任何我关注的核心范式或能力关键词，例如 `Agentic AI`, `Multi-Agent Systems`, `Planning`, `Tool Use`, `Self-Reflection`, `Self-Improvement` 等。这进一步证明了其研究焦点与我的课题相去甚远。 **总结**: 该论文是一项关于神经网络架构优化的创新工作，但它解决的是模型部署和效率问题，属于基础设施层面。它并未构建、改进或研究任何形式的 LLM 智能体，其“演化”也非智能体的自主行为。因此，根据筛选标准，这篇论文应被排除。"
    },
    {
        "index": "#3",
        "title": "Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control",
        "link": "/arxiv/2512.04653",
        "arxiv_id": "2512.04653",
        "authors": "Pouria Yazdani, Arash Rezaali, Monireh Abdoos",
        "subjects": "Multiagent Systems, Artificial Intelligence, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.MA",
        "crawl_time": "2025-12-05T11:00:05.429345",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** - 论文的核心贡献是提出了一种名为“半中心化训练，去中心化执行”（SEMI-CTDE）的**多智能体深度强化学习（MARL）架构**，用于解决**交通信号控制**这一特定领域的问题。 - 这完全符合**排除标准1：非演化型应用**。论文并非构建一个通用的LLM智能体框架，而是将已有的智能体范式（深度强化学习）应用到一个特定领域（交通），并针对该领域的挑战提出了一个新颖的训练架构。其本质是应用驱动的算法改进，而非对LLM智能体本身的构建或演化。 2.  **第二步：正面指标——论文是否包含我的核心关注点？** - 论文确实包含了 `Multi-Agent Systems (MAS)` 的关键词，并且涉及了智能体间的协作（通过中心化训练和区域信息共享）。 - **然而，最关键的一点是，论文中的智能体是基于深度强化学习（DRL）的，而不是基于大语言模型（LLM）的。** 您的研究焦点是“**LLM智能体**及其演化”，而这篇论文完全没有提及LLM。因此，它缺少了最核心的正面指标 `LLM-based Agents`。 3.  **第三步：排除标准——是否为我的研究焦点之外？** - 论文不涉及安全对齐或多模态视觉等排除项，但第一步的排除已经足够有力。 4.  **第四步：处理特殊和模糊情况** - 论文中的“规划”是DRL智能体通过强化学习训练出的策略，用于在不同交通状态下选择信号灯动作。这与LLM智能体利用语言模型进行任务分解、步骤规划（如ReAct, ToT）有本质区别，属于非Agentic的推理范畴。 **最终决策**: 尽管这篇论文在多智能体系统（MARL）领域可能是一项有价值的工作，但它的技术基础是深度强化学习，而非大语言模型。您的研究目标是筛选关于**LLM智能体**的构建、改进和演化的论文。该论文的核心贡献是针对特定应用（交通控制）的DRL智能体训练架构，不属于LLM智能体的研究范畴。因此，应将其排除。"
    },
    {
        "index": "#2",
        "title": "Complementary Characterization of Agent-Based Models via Computational Mechanics and Diffusion Models",
        "link": "/arxiv/2512.04771",
        "arxiv_id": "2512.04771",
        "authors": "Roberto Garrone",
        "subjects": "Multiagent Systems, Machine Learning",
        "date": "2025-12-04",
        "category": "cs.MA",
        "crawl_time": "2025-12-05T11:00:05.429079",
        "filter_reason": "这篇论文不符合我的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**分析**已有的“基于智能体的模型”的输出，而不是**构建、改进或演化**LLM智能体本身。摘要中明确指出，其目标是“characterizing the output of agent-based models (ABMs)”（表征基于智能体的模型的输出），并提出了一种“framework for the structural analysis of ABM outputs”（用于分析ABM输出的结构框架）。这属于将机器学习方法（扩散模型）作为一种分析工具，应用于研究智能体模型的行为，这完全符合第一步排除标准中的“非演化型应用”。 2.  **研究焦点不匹配:** 我的研究焦点是“LLM智能体及其演化”，关注智能体本身的内在能力（如规划、工具使用）和演化机制。而该论文的研究对象是“Agent-Based Models (ABMs)”，这是一个更广泛的、通常指代基于规则的模拟模型（如社会学、经济学中的仿真）的术语，并非特指基于LLM的现代智能体。论文全文未提及LLM、规划、工具使用、自我反思等核心Agentic AI概念。 3.  **贡献性质不同:** 该论文的贡献在于提出了一种新的**分析框架**，结合了计算力学和扩散模型来理解ABM的动态行为和分布特性。这是一种元层面的研究，即“研究智能体的方法”，而不是“创造智能体的方法”。我的目标是筛选后者。 综上所述，尽管论文标题中包含“Agent-Based Models”，但其本质是利用机器学习工具对传统模拟模型进行事后分析，与构建和演化LLM智能体的核心目标相去甚远。因此，应予以排除。"
    },
    {
        "index": "#52",
        "title": "Retrieval-Augmented Few-Shot Prompting Versus Fine-Tuning for Code Vulnerability Detection",
        "link": "/arxiv/2512.04106",
        "arxiv_id": "2512.04106",
        "authors": "Fouad Trad, Ali Chehab",
        "subjects": "Software Engineering, Artificial Intelligence, Computation and Language, Cryptography and Security",
        "date": "2025-11-28",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.410722",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断 (第一步): 论文本质是“非演化型应用”** 论文的核心贡献是提出并验证了一种“检索增强提示”方法，用于提升LLM在“代码漏洞检测”这一特定领域的任务性能。它比较了不同的提示策略和微调方法，其本质是**将LLM作为一个工具来优化特定应用场景的效果**，而不是构建、改进或演化LLM智能体本身。这完全符合第一步排除标准中的“非演化型应用”。 2.  **缺乏核心关注点 (第二步): 未涉及任何Agentic AI核心范式** 论文的研究焦点是提示工程和模型性能比较，完全没有提及您关注的核心范式。摘要中找不到任何关于 `Agentic AI`、`Planning`、`Tool Use`、`Memory`、`Self-Reflection`、`Multi-Agent` 或 `Self-Evolving` 的概念。LLM在这里只是一个被动的推理器，接收静态的、经过优化的输入，然后产生输出，不具备任何自主性、规划能力或演化机制。 3.  **特殊情况的排除 (第四步): 属于“非Agentic的推理”** 虽然论文涉及LLM的推理能力（识别代码漏洞），但它不属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。它没有提出像ReAct或ToT那样的新Agentic框架，而是停留在如何通过更好的上下文示例（检索增强）来引导单次推理。这更接近于“提高LLM本身基础Token预测”在特定任务上的表现，而非构建一个能够自主规划和行动的智能体。 **总结**: 该论文是一篇典型的LLM应用研究，专注于通过改进提示技术来解决一个具体的下游任务（代码安全）。它没有对LLM智能体的架构、能力或演化机制做出任何方法论上的贡献。因此，它严格地落在了您研究范围的“排除”区域。"
    },
    {
        "index": "#48",
        "title": "Balancing Safety and Helpfulness in Healthcare AI Assistants through Iterative Preference Alignment",
        "link": "/arxiv/2512.04210",
        "arxiv_id": "2512.04210",
        "authors": "Huy Nghiem, Swetasudha Panda, Devashish Khatwani, Huy V. Nguyen, Krishnaram Kenthapadi, Hal Daumé",
        "subjects": "Artificial Intelligence, Computation and Language, Computers and Society",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.409642",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是安全对齐，而非智能体构建或演化。** 论文的核心贡献是提出一个“迭代式部署后对齐框架”，用于在医疗保健领域平衡AI助手的安全性与实用性。其方法论核心是应用KTO和DPO这两种偏好学习技术来微调模型，使其能更好地识别和拒绝有害查询。这本质上是一个关于**模型对齐**的研究，而不是关于如何构建一个具有规划、工具使用或记忆能力的LLM智能体。它属于“非演化型应用”，即将对齐技术应用于特定领域（医疗）来解决该领域的安全问题。 2.  **第二步：正面指标——论文缺乏核心关注点。** 论文中几乎没有出现您所关注的核心范式和能力关键词。它没有讨论`Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）等智能体核心能力，也未涉及`Multi-Agent`（多智能体）或`Self-Evolving`（自我演化）的机制。虽然提到了“迭代”，但这是对齐过程中的迭代，而非智能体在任务执行中的自我完善和迭代。 3.  **第三步：排除标准——论文完全命中“安全与对齐”的排除项。** 这是最关键的排除依据。论文的标题、摘要和核心方法论都紧紧围绕`Safety`（安全）、`Helpfulness`（实用性，与对齐相关）、`Preference Alignment`（偏好对齐）、`KTO`、`DPO`等关键词展开。根据您的筛选标准，“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Alignment`……一律排除”。这篇论文是典型的安全对齐研究，因此被明确排除。 4.  **第四步：处理特殊和模糊情况——“迭代”不等于“自我演化”。** 论文中的“迭代”指的是通过多轮的偏好优化来调整模型行为，这是一个由外部反馈（人类偏好或安全信号）驱动的模型微调过程。它不符合您所定义的“智能体通过经验、反思或环境反馈进行自我完善和迭代”的“自我演化”概念。这里的演化是模型参数层面的被动调整，而非智能体在自主行动中的主动学习和进化。 **最终决策**：综合以上分析，该论文的核心贡献是LLM的安全对齐技术及其在特定领域的应用，而非LLM智能体的构建、能力增强或自我演化机制。它与您的研究焦点“Agentic AI”及其三个方向（单智能体、多智能体、自我演化）均不匹配，且明确属于排除类别。因此，最终判断为 **False**。"
    },
    {
        "index": "#53",
        "title": "Human-Centred Evaluation of Text-to-Image Generation Models for Self-expression of Mental Distress: A Dataset Based on GPT-4o",
        "link": "/arxiv/2512.04087",
        "arxiv_id": "2512.04087",
        "authors": "Sui He, Shenbin Qian",
        "subjects": "Neurons and Cognition, Computation and Language, Computer Vision and Pattern Recognition, Computers and Society, Human-Computer Interaction",
        "date": "2025-10-26",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.410999",
        "filter_reason": "这篇论文不符合您的研究范围，应予以排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是“非演化型应用”** 论文的核心贡献是构建了一个用于评估文本到图像生成模型在心理健康领域效果的数据集。它将GPT-4o作为一个现成的工具，根据特定提示生成图像，然后通过人类评估来验证这些图像的有效性。整个过程没有构建新的LLM智能体框架，没有提出新的多智能体协作机制，也没有设计任何让智能体自我演化的方法。这完全符合筛选标准中“非演化型应用”的排除条款，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。 2.  **第三步：排除标准——论文焦点在“多模态与视觉”** 论文的标题和摘要明确指出，其研究核心是“文本到图像生成模型”和“多模态研究”。虽然它使用了LLM（GPT-4o），但LLM在这里的角色是图像生成的“引擎”或“工具”，而不是研究的主体。研究的焦点在于生成的图像本身以及它们在特定应用场景下的评估，这直接命中了“多模态与视觉”的排除标准。 3.  **第二步：正面指标——缺乏核心关注点** 论文中完全没有涉及您所关注的核心Agentic AI概念。它没有讨论智能体的`Planning`（规划）、`Memory`（记忆）、`Tool Use`（工具使用，指智能体自主选择和使用工具）、`Self-Reflection`（自我反思），也没有涉及多智能体的`Collaboration`（协作）或`Communication`（通信）。文中的“Tool Use”仅指研究者使用GPT-4o这个工具，而非智能体自主的行为。 **总结**: 该论文是一项有价值的应用研究，属于人机交互和多模态学习领域。然而，它的核心贡献是数据集和评估方法，而非LLM智能体的构建、改进或演化。因此，它严格地落在了您研究范围的排除区域之外。"
    },
    {
        "index": "#51",
        "title": "Towards Contextual Sensitive Data Detection",
        "link": "/arxiv/2512.04120",
        "arxiv_id": "2512.04120",
        "authors": "Liang Telkamp, Madelon Hulsebos",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computation and Language, Computers and Society, Databases, Information Retrieval",
        "date": "2025-12-02",
        "category": "cs.CL",
        "crawl_time": "2025-12-05T11:00:05.410454",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **第一步：核心判断——论文本质是应用，而非智能体构建。** 论文的核心贡献是提出了两种用于“上下文敏感数据检测”的机制（`type contextualization` 和 `domain contextualization`）。其研究目标是解决数据安全和隐私保护问题。虽然论文中使用了大型语言模型（LLMs）作为辅助工具来检测数据类型和提供解释，但LLM本身是作为实现该应用目标的工具，而不是研究的主体。这完全符合筛选标准中的第一条排除规则：**“非演化型应用”**，即将LLM作为工具应用到特定领域（此处为数据安全领域）去解决该领域的问题。 2.  **第三步：排除标准——论文聚焦于安全与对齐。** 论文的研究主题是“敏感数据检测”，这直接归属于**“安全与对齐”**的研究范畴。根据您的筛选标准，只要论文的主要贡献是关于`Security`（安全）或`Privacy`（隐私），就应一律排除。这篇论文的整个动机、方法和评估都围绕着如何更安全地处理数据，与您关注的Agentic AI的构建与演化无关。 3.  **第二步：正面指标——论文缺乏核心关注点。** 论文中完全没有出现您所列出的任何核心范式或能力关键词。它没有讨论`Agentic AI`、`Multi-Agent Systems`或`Self-Evolving`，也没有涉及智能体的`Planning`、`Tool Use`（智能体自主使用工具，而非研究者使用LLM作为工具）、`Memory`或`Self-Reflection`等能力。论文中的LLM是一个被动的分析工具，而不是一个主动的、具有自主性的智能体。 **总结:** 该论文的本质是利用LLM的能力来改进一个特定的数据安全任务。它没有提出任何关于如何构建、改进或演化LLM智能体本身的新方法论或框架。因此，尽管它可能是一篇在数据安全领域有价值的论文，但它完全偏离了您关于“LLM智能体及其演化”的核心研究目标。根据筛选标准，应果断排除。"
    },
    {
        "index": "#5",
        "title": "Chameleon: Adaptive Adversarial Agents for Scaling-Based Visual Prompt Injection in Multimodal AI Systems",
        "link": "/arxiv/2512.04895",
        "arxiv_id": "2512.04895",
        "authors": "M Zeeshan, Saud Satti",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-12-04",
        "category": "cs.MA",
        "crawl_time": "2025-12-05T11:00:05.429840",
        "filter_reason": "这篇论文不符合您的研究范围，应被排除。我的判断依据如下： 1.  **核心判断（第一步）：论文的本质是安全研究，而非智能体构建。** 论文的核心贡献是提出了一种名为“Chameleon”的**对抗性攻击框架**，用于发现和利用多模态AI系统（特别是VLMs）在图像预处理（如下采样）中的安全漏洞。尽管它使用了“agent-based optimization mechanism”（基于智能体的优化机制），但这里的“智能体”是作为执行攻击的工具，其目的是为了生成更有效的对抗样本，而不是为了构建、改进或演化一个具有通用能力的LLM智能体。因此，这篇论文的本质属于**安全与对齐**研究，而非Agentic AI的核心方法论研究。 2.  **排除标准（第三步）：明确触发了两个硬性排除规则。** *   **安全与对齐：** 论文的摘要明确指出其目标是“expose and exploit scaling vulnerabilities”（暴露和利用缩放漏洞）、“craft highly robust adversarial examples”（制作高度鲁棒的对抗性样本）以及“compromise agentic pipelines”（破坏智能体流程）。这些都是典型的安全研究主题。根据筛选标准，只要论文的主要贡献是关于`Security`，就应一律排除。 *   **多模态与视觉：** 论文的研究对象是“Multimodal Artificial Intelligence (AI) systems, particularly Vision-Language Models (VLMs)”，其攻击方法是“Visual Prompt Injection”。这表明论文的核心是围绕视觉和多模态技术展开的，而不是将它们作为智能体感知环境的辅助工具。根据筛选标准，核心关注`Vision`或`VLMs`的论文应被排除。 3.  **对模糊情况的处理（第四步）：智能体在此处是攻击工具，而非研究主体。** 论文中提到的“adaptive adversarial agents”（自适应对抗智能体）和“iterative, agent-based optimization mechanism”（迭代的、基于智能体的优化机制）可能会引起混淆。然而，根据核心规则，我们需要区分“使用智能体”和“研究智能体”。这篇论文是前者：它设计了一个智能体系统来完成一个特定任务（生成对抗扰动），但论文的创新点和贡献在于这个攻击方法本身，而不是在于这个智能体如何进行规划、记忆或自我演化以提升其通用智能水平。这与您研究“LLM智能体及其演化”的核心目标——即探索智能体本身的能力和演化机制——背道而驰。 综上所述，尽管论文标题和摘要中包含了“Agents”等关键词，但其核心贡献和研究焦点完全落在“安全”和“多模态视觉”这两个被明确排除的领域。因此，该论文不符合您的筛选要求。"
    },
    {
        "index": "#4",
        "title": "Detecting Perspective Shifts in Multi-agent Systems",
        "link": "/arxiv/2512.05013",
        "arxiv_id": "2512.05013",
        "authors": "Eric Bridgeford, Hayden Helm",
        "subjects": "Artificial Intelligence, Multiagent Systems, Methodology",
        "date": "2025-12-04",
        "category": "cs.MA",
        "crawl_time": "2025-12-05T11:00:05.429597",
        "filter_reason": "这篇论文不符合你的研究范围，应予以排除。我的判断过程如下： 1.  **第一步：核心判断——论文的本质是什么？** 论文的核心贡献并非构建、改进或演化LLM智能体。通读摘要，其核心是提出一个名为“Temporal Data Kernel Perspective Space (TDKPS)”的框架，以及一系列用于“检测行为变化”的假设检验方法。摘要最后一句明确指出：“TDKPS is the first principled framework for **monitoring behavioral dynamics** in black-box multi-agent systems”。这表明，论文的本质是**监控和分析**已有的多智能体系统，而不是**设计和构建**新的智能体或其演化机制。它属于对智能体行为的“诊断”或“观测”工具，而非智能体本身的“构造”方法。因此，根据第一步的核心判断标准，应予以排除。 2.  **第二步：正面指标分析** 论文确实包含了你的核心关注点，如 `Multi-Agent Systems (MAS)` 和 `evolving`。然而，这些词汇出现的语境是作为被**研究对象**，而不是作为被**创造物**。论文研究的是“演化的数字人格”，但并未提出一种新的、让智能体得以演化的方法。它只是利用一个演化的系统来验证其行为检测框架的有效性。因此，尽管关键词匹配，但其贡献方向与你的目标不符。 3.  **第三步：排除标准分析** 论文不涉及安全对齐或多模态视觉，因此未触及相关排除标准。 4.  **第四步：特殊和模糊情况处理** 论文不涉及推理/规划的特殊情况。对于“自我演化的应用”，论文虽然提到了“evolving digital personas”，但其核心贡献是TDKPS这个监控框架，而不是那个“自我演化”的机制本身。因此，不符合“保留例外”的条件。 **最终决策**： 综合以上分析，这篇论文的核心贡献是提出了一种**监控和分析多智能体系统行为动态的理论与方法**。它属于“智能体可观测性”或“智能体分析”的研究范畴，而不是你核心目标所关注的“构建、改进或演化LLM智能体”的范畴。虽然它研究的是多智能体系统，但其工作性质是“观察者”而非“建造者”。因此，该论文与你的研究目标存在本质差异，应予以排除。"
    }
]