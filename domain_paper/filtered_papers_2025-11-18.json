[
    {
        "index": "#1",
        "title": "Enhancing Agentic Autonomous Scientific Discovery with Vision-Language Model Capabilities",
        "link": "/arxiv/2511.14631",
        "arxiv_id": "2511.14631",
        "authors": "Kahaan Gandhi, Boris Bolliet, Inigo Zubeldia",
        "summary": "We show that multi-agent systems guided by vision-language models (VLMs) improve end-to-end autonomous scientific discovery. By treating plots as verifiable checkpoints, a VLM-as-a-judge evaluates figures against dynamically generated domain-specific rubrics, enabling agents to correct their own errors and steer exploratory data analysis in real-time. Case studies in cosmology and astrochemistry demonstrate recovery from faulty reasoning paths and adaptation to new datasets without human intervention. On a 10-task benchmark for data-driven discovery, VLM-augmented systems achieve pass at 1 scores of 0.7-0.8, compared to 0.2-0.3 for code-only and 0.4-0.5 for code-and-text baselines, while also providing auditable reasoning traces that improve interpretability. Code available here: https://github.com/CMBAgents/cmbagent",
        "subjects": "Computation and Language, Artificial Intelligence, Computer Vision and Pattern Recognition, Multiagent Systems",
        "date": "2025-11-18",
        "category": "cs.MA",
        "crawl_time": "2025-11-19T11:00:04.123852",
        "filter_reason": "这篇论文符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献并非简单地将LLM智能体应用于科学发现领域，而是提出了一种**新颖的智能体框架和方法论**。其核心创新点在于“VLM-as-a-judge”机制，即利用视觉语言模型（VLM）作为评判者，使智能体能够“纠正自己的错误”并“实时引导探索性数据分析”。这属于**构建和改进LLM智能体**的范畴，而非简单的非演化型应用。 2.  **第二步：正面指标——高度相关** - 论文明确包含了多个核心关注点： - **多智能体**: 摘要开篇即提到“multi-agent systems”。 - **自我修正**: 论文的核心机制是让智能体“correct their own errors”，这是自我演化的关键能力之一。 - **自我反思**: “recovery from faulty reasoning paths”体现了智能体的反思和纠错能力。 - **工具使用**: VLM在这里被用作一个高级的“验证工具”或“评判工具”，图表被用作“verifiable checkpoints”，这完全符合智能体工具使用的定义。 3.  **第三步：排除标准——不构成排除理由** - **安全与对齐**: 论文虽然提到了“improve interpretability”（提高可解释性），但这被描述为系统带来的一个**附加好处**，而非论文的**主要贡献**。其核心贡献是VLM增强的多智能体框架本身，因此不因涉及可解释性而被排除。 - **多模态与视觉**: 论文虽然使用了VLM，但它的角色是作为智能体系统内部的一个**功能性组件**（评判者），用于感知和验证图表这一环境信息。研究的核心是**如何利用VLM来增强智能体的自主性和纠错能力**，而不是VLM模型本身。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外规则。 4.  **第四步：处理特殊和模糊情况——符合保留条件** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。它虽然应用于“科学发现”这一特定领域，但其核心是提出了一种新的**自我修正机制**（VLM-as-a-judge），使智能体能够从错误中恢复并适应新数据。这种机制本身就是对智能体演化能力的一种构建和改进，因此应该被保留。 **最终决策**: 综合以上分析，该论文的核心贡献在于提出了一种创新的、由VLM增强的多智能体框架，该框架通过引入“评判者”角色，赋予了智能体强大的自我修正和实时适应能力。这直接命中了你研究目标中的“多智能体”和“自我演化”方向，并且是关于“构建、改进或演化LLM智能体”的方法论研究，而非简单的领域应用。因此，这篇论文高度相关，应予以保留。"
    },
    {
        "index": "#5",
        "title": "AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance",
        "link": "/arxiv/2511.14043",
        "arxiv_id": "2511.14043",
        "authors": "Chandrachur Bhattacharya, Sibendu Som",
        "summary": "AI Scientific Assistant Core (AISAC) is an integrated multi-agent system developed at Argonne National Laboratory for scientific and engineering workflows. AISAC builds on established technologies - LangGraph for orchestration, FAISS for vector search, and SQLite for persistence - and integrates them into a unified system prototype focused on transparency, provenance tracking, and scientific adaptability. The system implements a Router-Planner-Coordinator workflow and an optional Evaluator role, using prompt-engineered agents coordinated via LangGraph's StateGraph and supported by helper agents such as a Researcher. Each role is defined through custom system prompts that enforce structured JSON outputs. A hybrid memory approach (FAISS + SQLite) enables both semantic retrieval and structured conversation history. An incremental indexing strategy based on file hashing minimizes redundant re-embedding when scientific corpora evolve. A configuration-driven project bootstrap layer allows research teams to customize tools, prompts, and data sources without modifying core code. All agent decisions, tool invocations, and retrievals are logged and visualized through a custom Gradio interface, providing step-by-step transparency for each reasoning episode. The authors have applied AISAC to multiple research areas at Argonne, including specialized deployments for waste-to-products research and energy process safety, as well as general-purpose scientific assistance, demonstrating its cross-domain applicability.",
        "subjects": "Artificial Intelligence, Computation and Language, Multiagent Systems",
        "date": "2025-11-18",
        "category": "cs.MA",
        "crawl_time": "2025-11-19T11:00:04.124994",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个现有框架应用到科学领域，而是**提出并构建了一个全新的、集成的多智能体系统（AISAC）**。其核心贡献在于该系统的架构设计、工作流程（Router-Planner-Coordinator）、记忆机制（混合记忆）以及设计原则（透明性、可追溯性）。这完全符合“构建、改进LLM智能体”的核心目标。它不是一篇“非演化型应用”论文，因为论文的重点是系统本身，而非其在特定科学问题上的应用结果。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提到了 `Multi-Agent System`。 - **智能体能力**: 包含了 `Planning`（Planner角色）、`Tool Use`（检索工具）、`Memory`（混合记忆方法）。 - **多智能体**: 描述了多个角色（Router, Planner, Coordinator, Researcher）的 `Collaboration`（协作）与 `Communication`（通信）机制。 - 这些正面指标强烈表明该论文与我的研究范围高度相关。 3.  **第三步：排除标准** - 论文虽然提到了 `Transparency`（透明性），但这并非其研究焦点，而是作为其智能体系统的一个关键设计特性，旨在提升系统的可信度和可调试性。论文的主要贡献不是关于安全、对齐或可解释性的理论或方法，因此不触及排除标准。 - 论文不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的 `Router-Planner-Coordinator` 工作流，明确属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。这符合保留条件，因为它是一个新的Agentic框架，而不是对LLM基础推理能力的非Agentic改进。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献是**构建了一个新颖的多智能体系统架构**，详细阐述了其内部组件、工作流和设计哲学。尽管它以科学辅助为应用背景，但其研究重心在于智能体系统的构建方法本身，完全符合“多智能体”这一研究方向，并触及了“单智能体”的规划、记忆等能力。因此，这篇论文是符合研究范围的前沿论文，应被保留。"
    },
    {
        "index": "#4",
        "title": "Collaborative QA using Interacting LLMs. Impact of Network Structure, Node Capability and Distributed Data",
        "link": "/arxiv/2511.14098",
        "arxiv_id": "2511.14098",
        "authors": "Adit Jain, Vikram Krishnamurthy, Yiming Zhang",
        "summary": "In this paper, we model and analyze how a network of interacting LLMs performs collaborative question-answering (CQA) in order to estimate a ground truth given a distributed set of documents. This problem is interesting because LLMs often hallucinate when direct evidence to answer a question is lacking, and these effects become more pronounced in a network of interacting LLMs. The hallucination spreads, causing previously accurate LLMs to hallucinate. We study interacting LLMs and their hallucination by combining novel ideas of mean-field dynamics (MFD) from network science and the randomized utility model from economics to construct a useful generative model. We model the LLM with a latent state that indicates if it is truthful or not with respect to the ground truth, and extend a tractable analytical model considering an MFD to model the diffusion of information in a directed network of LLMs. To specify the probabilities that govern the dynamics of the MFD, we propose a randomized utility model. For a network of LLMs, where each LLM has two possible latent states, we posit sufficient conditions for the existence and uniqueness of a fixed point and analyze the behavior of the fixed point in terms of the incentive (e.g., test-time compute) given to individual LLMs. We experimentally study and analyze the behavior of a network of $100$ open-source LLMs with respect to data heterogeneity, node capability, network structure, and sensitivity to framing on multiple semi-synthetic datasets.",
        "subjects": "Artificial Intelligence, Multiagent Systems, Social and Information Networks, Systems and Control",
        "date": "2025-11-18",
        "category": "cs.MA",
        "crawl_time": "2025-11-19T11:00:04.124738",
        "filter_reason": "这篇论文符合研究范围，应被保留。 判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决一个外部领域问题（如法律或医疗），而是**研究一个由多个LLM智能体组成的网络系统本身的行为和动态**。其核心贡献是构建了一个**分析模型**（结合了平均场动力学和随机效用模型）来理解和预测多智能体系统中的信息扩散和幻觉传播现象。这完全符合“构建、改进或演化LLM智能体”中的“改进”范畴，因为它为如何设计和理解多智能体系统提供了理论基础。 2.  **第二步：正面指标** - 论文高度符合多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 - **多智能体**: 论文明确研究了 `Collaboration` (协作式问答)、`Communication` (交互式LLM、信息扩散) 和 `Agent Society` (LLM网络)。 - 这些正面指标强烈表明该论文与你的研究焦点高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 论文虽然提到了 `Hallucination` (幻觉)，但其**主要贡献并非提出一种新的安全或对齐技术**。相反，它是将“幻觉传播”作为一个现象来建模和分析，以理解多智能体系统的内在动态。这与“主要贡献是关于安全”的排除标准有本质区别。因此，不应被排除。 - **多模态与视觉**: 论文不涉及此内容。 4.  **第四步：处理特殊和模糊情况** - 此处不适用。 5.  **第五步：最终决策** - 综合来看，该论文的核心是**对多智能体系统进行理论建模和分析**，探索了网络结构、节点能力等因素如何影响智能体间的协作与信息传播。这直接服务于“改进LLM智能体”的目标，特别是在多智能体方向上。它不是简单的应用，而是对Agentic AI系统本身的基础性研究，因此完全符合你的筛选要求。"
    },
    {
        "index": "#2",
        "title": "DataSage: Multi-agent Collaboration for Insight Discovery with External Knowledge Retrieval, Multi-role Debating, and Multi-path Reasoning",
        "link": "/arxiv/2511.14299",
        "arxiv_id": "2511.14299",
        "authors": "Xiaochuan Liu, Yuanfeng Song, Xiaoming Yin, Xing Chen",
        "summary": "In today's data-driven era, fully automated end-to-end data analytics, particularly insight discovery, is critical for discovering actionable insights that assist organizations in making effective decisions. With the rapid advancement of large language models (LLMs), LLM-driven agents have emerged as a promising paradigm for automating data analysis and insight discovery. However, existing data insight agents remain limited in several key aspects, often failing to deliver satisfactory results due to: (1) insufficient utilization of domain knowledge, (2) shallow analytical depth, and (3) error-prone code generation during insight generation. To address these issues, we propose DataSage, a novel multi-agent framework that incorporates three innovative features including external knowledge retrieval to enrich the analytical context, a multi-role debating mechanism to simulate diverse analytical perspectives and deepen analytical depth, and multi-path reasoning to improve the accuracy of the generated code and insights. Extensive experiments on InsightBench demonstrate that DataSage consistently outperforms existing data insight agents across all difficulty levels, offering an effective solution for automated data insight discovery.",
        "subjects": "Artificial Intelligence, Computation and Language, Multiagent Systems",
        "date": "2025-11-18",
        "category": "cs.MA",
        "crawl_time": "2025-11-19T11:00:04.124167",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为 **DataSage 的新颖多智能体框架**。它不是简单地将一个已有的智能体框架应用到数据分析领域，而是**构建和改进**了一个多智能体系统本身。论文明确指出现有智能体的不足，并提出了三个创新性的机制来解决这些问题。这完全符合“核心贡献在于构建、改进或演化 LLM 智能体”的要求。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** 论文命中了多个核心关注点： *   **核心范式**: 论文标题和摘要中明确提到了 `Multi-agent Collaboration` 和 `Multi-agent framework`，直接对应你的 `Multi-Agent Systems (MAS)` 研究方向。 *   **智能体能力**: 论文提出的 `External Knowledge Retrieval` 属于 `Tool Use / Tool Augmentation`。`Multi-path reasoning` 是一种复杂的 `Reasoning` 机制，用于提高任务执行的准确性。 *   **多智能体**: 论文的亮点是 `Multi-role Debating` 机制，这直接对应了 `Collaboration`、`Communication` 和 `Negotiation` 等多智能体间的交互模式。 3.  **第三步：排除标准——未触发** 论文的研究焦点是提升智能体在数据分析任务中的性能和深度，主要贡献在于其框架设计。摘要中完全没有提及 `Safety`、`Alignment`、`Interpretability` 或 `Hallucination` 等安全与对齐相关的内容。同样，它也不涉及 `Vision` 或 `MLLMs` 等多模态内容。因此，该论文没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 论文中的 `Multi-path reasoning` 是作为智能体框架的一部分，用于提高生成代码和洞察的准确性。这属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴，因此应该保留，而不是被排除为“非Agentic的推理”。 **最终决策**: 这篇论文的核心是提出一个创新的**多智能体协作框架**，其贡献在于智能体架构本身的设计（多角色辩论、工具使用、多路径推理），而非其在特定领域的简单应用。它精准地命中了你研究课题中的“多智能体”方向，并融合了“工具使用”和“规划推理”等关键能力。因此，这篇论文是高度相关且有价值的前沿研究，**结果为 True**。"
    },
    {
        "index": "#9",
        "title": "Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning",
        "link": "/arxiv/2511.14460",
        "arxiv_id": "2511.14460",
        "authors": "Mingyue Cheng, Jie Ouyang, Shuo Yu, Ruiran Yan, Yucong Luo, Zirui Liu, Daoyu Wang, Qi Liu, Enhong Chen",
        "summary": "Large Language Models (LLMs) are increasingly being explored for building Agents capable of active environmental interaction (e.g., via tool use) to solve complex problems. Reinforcement Learning (RL) is considered a key technology with significant potential for training such Agents; however, the effective application of RL to LLM Agents is still in its nascent stages and faces considerable challenges. Currently, this emerging field lacks in-depth exploration into RL approaches specifically tailored for the LLM Agent context, alongside a scarcity of flexible and easily extensible training frameworks designed for this purpose. To help advance this area, this paper first revisits and clarifies Reinforcement Learning methodologies for LLM Agents by systematically extending the Markov Decision Process (MDP) framework to comprehensively define the key components of an LLM Agent. Secondly, we introduce Agent-R1, a modular, flexible, and user-friendly training framework for RL-based LLM Agents, designed for straightforward adaptation across diverse task scenarios and interactive environments. We conducted experiments on Multihop QA benchmark tasks, providing initial validation for the effectiveness of our proposed methods and framework.",
        "subjects": "Computation and Language",
        "date": "2025-11-18",
        "category": "cs.CL",
        "crawl_time": "2025-11-19T11:00:04.538085",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一种新的训练方法（端到端强化学习）和一个配套的框架（Agent-R1）来**构建和改进LLM智能体**。它不是将现有智能体作为工具应用到一个新领域，而是专注于智能体本身的训练方法论和框架构建。这直接命中了您“核心贡献在于构建、改进或演化LLM智能体”的目标。它不属于“非演化型应用”、“非Agentic的推理”或“基础设施”的排除范畴。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了大量您关注的核心关键词和概念： *   **核心范式**: `LLM-based Agents` (标题和摘要中反复出现)。 *   **智能体能力**: `Tool Use` (明确提及 \"via tool use\")。虽然未直接提及 `Planning`，但通过强化学习训练智能体进行多跳问答，本质上是在训练其多步规划和决策能力。 *   **演化机制**: `Reinforcement Learning` (RL) 本身就是一种通过环境反馈进行迭代优化的机制，这与您关注的“自我演化”中的“通过经验或环境反馈进行自我完善和迭代”高度契合。论文的核心就是提出一种让智能体自我演化的新路径。 3.  **第三步：排除标准——未触发** 论文的研究焦点是提升智能体的能力，而非其安全性、可解释性或对齐问题。摘要中也完全没有提及视觉或多模态相关内容，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 论文的研究内容属于“推理/规划”的保留范畴。它不是在提升LLM的基础数学或逻辑能力，而是在研究如何让**智能体**在复杂任务（Multihop QA）中进行多步推理和与环境的交互，这正是Agentic AI的核心研究问题。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种用于训练和改进LLM智能体的新方法论（基于RL）和新框架（Agent-R1）。它直接解决了如何让智能体通过环境反馈进行自我演化的问题，并涉及了工具使用等关键能力。因此，这篇论文与您关于“LLM智能体及其演化”的研究课题高度相关，应当被保留。"
    },
    {
        "index": "#33",
        "title": "Knowledge-Grounded Agentic Large Language Models for Multi-Hazard Understanding from Reconnaissance Reports",
        "link": "/arxiv/2511.14010",
        "arxiv_id": "2511.14010",
        "authors": "Chenchen Kuai, Zihao Li, Braden Rosen, Stephanie Paan, Navid Jafari, Jean-Louis Briaud, Yunlong Zhang, Youssef M. A. Hashash, Yang Zhou",
        "summary": "Post-disaster reconnaissance reports contain critical evidence for understanding multi-hazard interactions, yet their unstructured narratives make systematic knowledge transfer difficult. Large language models (LLMs) offer new potential for analyzing these reports, but often generate unreliable or hallucinated outputs when domain grounding is absent. This study introduces the Mixture-of-Retrieval Agentic RAG (MoRA-RAG), a knowledge-grounded LLM framework that transforms reconnaissance reports into a structured foundation for multi-hazard reasoning. The framework integrates a Mixture-of-Retrieval mechanism that dynamically routes queries across hazard-specific databases while using agentic chunking to preserve contextual coherence during retrieval. It also includes a verification loop that assesses evidence sufficiency, refines queries, and initiates targeted searches when information remains incomplete. We construct HazardRecQA by deriving question-answer pairs from GEER reconnaissance reports, which document 90 global events across seven major hazard types. MoRA-RAG achieves up to 94.5 percent accuracy, outperforming zero-shot LLMs by 30 percent and state-of-the-art RAG systems by 10 percent, while reducing hallucinations across diverse LLM architectures. MoRA-RAG also enables open-weight LLMs to achieve performance comparable to proprietary models. It establishes a new paradigm for transforming post-disaster documentation into actionable, trustworthy intelligence for hazard resilience.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.CL",
        "crawl_time": "2025-11-19T11:00:04.561484",
        "filter_reason": "这篇论文符合筛选标准，应该保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用到一个新领域，而是**提出了一种新的LLM智能体框架**。其核心贡献是“Mixture-of-Retrieval Agentic RAG (MoRA-RAG)”这个框架本身，而不是它在灾害理解这个特定领域的应用结果。论文明确将其定义为一个“knowledge-grounded LLM framework”和“Agentic”框架，这直接命中了“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 摘要中明确提到了 `Agentic Large Language Models` 和 `Agentic RAG`。 - **智能体能力**: - **工具使用**: `Mixture-of-Retrieval mechanism` 是一种动态使用外部知识库（工具）的机制。 - **自我反思/自我修正**: 论文的核心亮点之一是 `verification loop`，该循环会“评估证据充分性、优化查询，并在信息不完整时启动针对性搜索”。这是一个典型的智能体自我反思和迭代的机制。 - **规划**: 整个框架的动态路由和查询优化过程，体现了智能体为完成复杂任务（多灾害理解）而进行的规划和行动序列。 3.  **第三步：排除标准** - **安全与对齐**: 论文虽然提到了“reducing hallucinations”（减少幻觉），但这只是其框架带来的一个**效果**，而非论文的主要研究贡献。论文的核心是提出一个能实现这一效果的智能体架构，而不是研究幻觉本身或对齐技术。因此，这不触发排除标准。 - **多模态与视觉**: 论文不涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”条件。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个智能体框架，使其能够在特定任务（多灾害推理）中进行多步、迭代的规划和推理。其`verification loop`和`query refinement`是智能体规划过程的体现。 **最终决策**: 这篇论文的核心贡献是构建了一个名为MoRA-RAG的新型LLM智能体框架。该框架集成了动态工具使用（Mixture-of-Retrieval）和自我修正（verification loop）等关键智能体能力，以解决复杂任务。尽管其应用场景是灾害管理这一特定领域，但其方法论贡献是普适的，完全符合“构建、改进LLM智能体”的研究目标，特别是“单智能体”方向下的规划、工具使用和自我反思子方向。因此，应予以保留。"
    },
    {
        "index": "#40",
        "title": "SciRAG: Adaptive, Citation-Aware, and Outline-Guided Retrieval and Synthesis for Scientific Literature",
        "link": "/arxiv/2511.14362",
        "arxiv_id": "2511.14362",
        "authors": "Hang Ding, Yilun Zhao, Tiansheng Hu, Manasi Patwardhan, Arman Cohan",
        "summary": "The accelerating growth of scientific publications has intensified the need for scalable, trustworthy systems to synthesize knowledge across diverse literature. While recent retrieval-augmented generation (RAG) methods have improved access to scientific information, they often overlook citation graph structure, adapt poorly to complex queries, and yield fragmented, hard-to-verify syntheses. We introduce SciRAG, an open-source framework for scientific literature exploration that addresses these gaps through three key innovations: (1) adaptive retrieval that flexibly alternates between sequential and parallel evidence gathering; (2) citation-aware symbolic reasoning that leverages citation graphs to organize and filter supporting documents; and (3) outline-guided synthesis that plans, critiques, and refines answers to ensure coherence and transparent attribution. Extensive experiments across multiple benchmarks such as QASA and ScholarQA demonstrate that SciRAG outperforms prior systems in factual accuracy and synthesis quality, establishing a new foundation for reliable, large-scale scientific knowledge aggregation.",
        "subjects": "Digital Libraries, Computation and Language",
        "date": "2025-11-18",
        "category": "cs.CL",
        "crawl_time": "2025-11-19T11:00:04.570252",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将RAG技术应用于科学文献领域，而是提出了一个名为SciRAG的**新框架**。该框架通过三个关键创新来构建一个更智能、更自主的文献处理系统。这完全符合“构建、改进LLM智能体”的核心目标。它不是非演化型应用，因为其价值在于方法论本身，而非应用结果。 2.  **第二步：正面指标** - 论文包含了多个我关注的核心范式和能力指标： - **Agentic AI / LLM-based Agents**: SciRAG本身就是一个智能体框架，用于自主完成复杂的文献探索任务。 - **Planning**: 论文明确提到 `outline-guided synthesis`（大纲引导的综合），其中包含 `plans`（规划）步骤，这是智能体规划能力的直接体现。 - **Tool Use / Tool Augmentation**: `adaptive retrieval`（自适应检索）和 `citation-aware symbolic reasoning`（引文感知的符号推理）是智能体使用高级工具（检索策略、引文图）的典型例子。 - **Self-Correction / Self-Reflection**: 摘要中明确指出，该框架会 `critiques, and refines answers`（批判和优化答案），这正是智能体自我反思和自我修正能力的核心。 3.  **第三步：排除标准** - 论文的主要贡献不在于安全、对齐、可解释性或多模态。虽然提到了“transparent attribution”（透明的归属），但其目的是为了验证答案的可靠性，属于提升智能体任务表现的一部分，而非以可解释性（XAI）为核心研究目标。因此，不触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何进行规划和多步推理的绝佳范例。它不是在改进LLM的基础数学或逻辑能力，而是在构建一个上层框架，让智能体能够规划（生成大纲）、执行（检索和推理）和优化（批判和修正），以完成一个复杂任务。这完全符合“保留”的条件。 **总结**: SciRAG论文的核心是提出一个集成了**规划、工具使用和自我反思**能力的LLM智能体框架。它通过自适应检索、引文图推理和大纲引导的综合，显著提升了智能体在复杂任务中的自主性和表现。这完全契合我研究课题中的“单智能体”方向，特别是关于智能体规划、工具使用和自我反思的子方向。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#48",
        "title": "EchoAgent: Guideline-Centric Reasoning Agent for Echocardiography Measurement and Interpretation",
        "link": "/arxiv/2511.13948",
        "arxiv_id": "2511.13948",
        "authors": "Matin Daghyani, Lyuyang Wang, Nima Hashemi, Bassant Medhat, Baraa Abdelsamad, Eros Rojas Velez, XiaoXiao Li, Michael Y. C. Tsang, Christina Luong, Teresa S. M. Tsang, Purang Abolmaesumi",
        "summary": "Purpose: Echocardiographic interpretation requires video-level reasoning and guideline-based measurement analysis, which current deep learning models for cardiac ultrasound do not support. We present EchoAgent, a framework that enables structured, interpretable automation for this domain. Methods: EchoAgent orchestrates specialized vision tools under Large Language Model (LLM) control to perform temporal localization, spatial measurement, and clinical interpretation. A key contribution is a measurement-feasibility prediction model that determines whether anatomical structures are reliably measurable in each frame, enabling autonomous tool selection. We curated a benchmark of diverse, clinically validated video-query pairs for evaluation. Results: EchoAgent achieves accurate, interpretable results despite added complexity of spatiotemporal video analysis. Outputs are grounded in visual evidence and clinical guidelines, supporting transparency and traceability. Conclusion: This work demonstrates the feasibility of agentic, guideline-aligned reasoning for echocardiographic video analysis, enabled by task-specific tools and full video-level automation. EchoAgent sets a new direction for trustworthy AI in cardiac ultrasound.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language, Machine Learning",
        "date": "2025-11-17",
        "category": "cs.CL",
        "crawl_time": "2025-11-19T11:00:04.580053",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于医疗领域，而是提出了一个名为 **EchoAgent** 的**新框架**。该框架的核心在于LLM如何**编排**和**自主选择**专门的视觉工具来完成复杂任务。摘要中明确指出，其关键贡献是一个“measurement-feasibility prediction model”，该模型使智能体能够进行“autonomous tool selection”。这直接对应了“构建、改进LLM智能体”的核心目标，属于方法论层面的创新，而非单纯的应用。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **核心范式**: 论文标题和摘要反复强调 \"Agent\"，明确属于 `Agentic AI` 和 `LLM-based Agents` 范畴。 *   **智能体能力**: 论文的核心机制是LLM控制工具，这直接对应了 `Tool Use / Tool Augmentation`。其“自主工具选择”机制是智能体 `Planning` 和决策能力的体现。整个工作流程（LLM根据视频和问题，决定使用哪个工具，然后根据工具结果进行下一步推理）是 `ReAct` 范式的典型应用。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 论文提到了 \"interpretable\" 和 \"guideline-aligned\"，但这是其框架设计带来的**结果**，是为了保证医疗任务输出的可靠性，而非论文的**核心研究贡献**。论文的核心是那个能实现自主工具选择的智能体框架，而不是一种新的可解释性或对齐方法。 *   **多模态与视觉**: 论文确实处理了视频数据，但完全符合特殊规则。视觉模型在这里是作为智能体感知环境的**工具**，由LLM进行调用。研究的核心是**如何调用**以及**何时调用**这些工具，而不是视觉模型本身。因此，这不构成排除理由。 4.  **第四步：处理特殊情况——符合保留规则** 这篇论文是“推理/规划”规则的完美范例。它不是在提升LLM本身的基础推理能力，而是在构建一个能让LLM在复杂、多步骤任务中通过使用工具进行推理的**智能体框架**。其“自主工具选择”机制正是对智能体规划能力的一种具体改进和创新。 **最终决策**: 尽管论文的应用领域是高度专业的“超声心动图”，但其核心贡献在于提出了一种具有新颖规划与工具选择机制的LLM智能体框架。这完全符合我研究课题中“单智能体”方向，特别是“规划”和“工具使用”这两个子方向。因此，这篇论文是高度相关且有价值的前沿研究，应被筛选出来。"
    },
    {
        "index": "#4",
        "title": "ReflexGrad: Three-Way Synergistic Architecture for Zero-Shot Generalization in LLM Agents",
        "link": "/arxiv/2511.14584",
        "arxiv_id": "2511.14584",
        "authors": "Ankush Kadu, Ashwanth Krishnan",
        "summary": "Enabling agents to learn from experience and generalize across diverse tasks without task-specific training remains a fundamental challenge in reinforcement learning and decision-making. While recent approaches have explored episodic memory (Reflexion), gradient-based prompt optimization (TextGrad),and hierarchical task decomposition independently, their potential for synergistic integration remains unexplored. We introduce ReflexGrad, a novel architecture that tightly couples three complementary mechanisms: (1) LLM-based hierarchical TODO decomposition for strategic planning, (2) history-aware causal reflection that analyzes recent action patterns to identify failure root causes and enable within-trial learning, and (3) gradient-based optimization for systematic improvement. Unlike prior work relying on few-shot demonstrations, our system achieves true zero-shot generalization through pure LLM semantic reasoning,requiring no task-specific examples, fine-tuning, or hardcoded similarity metrics. Evaluated on ALFWorld benchmark tasks, ReflexGrad demonstrates 67% zero-shot success rate on Trial 0 without any prior task experience or demonstrations, establishing effective performance on first exposure. Through empirical analysis, we identify the architectural mechanisms underlying stable convergence (zero action loops) and effective cross-task transfer (67% to 78% improvement).Our work demonstrates that synergistic integration of complementary learning mechanisms enables robust zero-shot generalization that approaches few-shot baselines from prior work.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.LG",
        "crawl_time": "2025-11-19T11:00:05.403199",
        "filter_reason": "这篇论文完全符合你的研究范围，应该被保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一个名为 `ReflexGrad` 的新颖架构，用于构建和改进LLM智能体。它不是将现有智能体应用于某个特定领域，而是专注于智能体本身的学习和泛化机制。其本质是关于“构建、改进或演化 LLM智能体”的方法论，完全符合你的核心目标。 2.  **第二步：正面指标** - 论文摘要中包含了大量与你研究焦点高度相关的核心范式和能力关键词： - **单智能体**: 论文明确提到了 `Planning` (\"hierarchical TODO decomposition for strategic planning\")、`Memory` (\"history-aware causal reflection\") 和 `Self-Reflection` (\"analyzes recent action patterns to identify failure root causes\")。 - **自我演化**: 论文的核心就是关于智能体的自我完善。它提到了 `Self-Improvement` (\"gradient-based optimization for systematic improvement\") 和 `within-trial learning`。整个 `ReflexGrad` 架构就是一种新的“自我演化”机制，它结合了反思和梯度优化来迭代改进智能体的表现。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment`、`Hallucination` 等安全与对齐问题。 - 论文也未涉及 `Vision`、`MLLMs` 等多模态内容，其评估基准 `ALFWorld` 是一个基于文本的交互环境。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的规划是作为智能体框架的一部分（\"LLM-based hierarchical TODO decomposition\"），旨在让智能体在复杂任务中自主决策，这完全符合“保留”的条件，而不是单纯提升LLM的基础推理能力。 - **自我演化的应用**: 虽然论文在 `ALFWorld` 基准上进行了测试，但其核心是提出一种通用的“自我演化”架构，而不是一个特定领域的应用。因此，它符合保留规则。 **总结**: 该论文的核心贡献是提出了一种新的LLM智能体架构 `ReflexGrad`，该架构通过协同整合规划、反思和梯度优化三种机制，实现了智能体的零样本泛化和自我完善。这直接命中了你研究范围中的“单智能体”和“自我演化”两个核心方向。因此，这篇论文是高度相关且前沿的研究，应被筛选出来。"
    },
    {
        "index": "#109",
        "title": "Orion: A Unified Visual Agent for Multimodal Perception, Advanced Visual Reasoning and Execution",
        "link": "/arxiv/2511.14210",
        "arxiv_id": "2511.14210",
        "authors": "N Dinesh Reddy, Sudeep Pillai",
        "summary": "We introduce Orion, a visual agent framework that can take in any modality and generate any modality. Using an agentic framework with multiple tool-calling capabilities, Orion is designed for visual AI tasks and achieves state-of-the-art results. Unlike traditional vision-language models that produce descriptive outputs, Orion orchestrates a suite of specialized computer vision tools, including object detection, keypoint localization, panoptic segmentation, Optical Character Recognition, and geometric analysis, to execute complex multi-step visual workflows. The system achieves competitive performance on MMMU, MMBench, DocVQA, and MMLongBench while extending monolithic vision-language models to production-grade visual intelligence. By combining neural perception with symbolic execution, Orion enables autonomous visual reasoning, marking a transition from passive visual understanding to active, tool-driven visual intelligence.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-11-18",
        "category": "cs.LG",
        "crawl_time": "2025-11-19T11:00:05.485965",
        "filter_reason": "这篇论文符合筛选要求，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个新的**智能体框架**。摘要明确指出其核心贡献是 \"a visual agent framework\"（一个视觉智能体框架），其关键机制是 \"orchestrates a suite of specialized computer vision tools... to execute complex multi-step visual workflows\"（编排一套专门的计算机视觉工具来执行复杂的多步视觉工作流）。这完全符合“构建、改进LLM智能体”的核心目标。它不是简单地将现有智能体应用到一个领域，而是提出了一个新的智能体架构和方法论。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Agentic AI`, `LLM-based Agents`。摘要直接使用了 \"agentic framework\" 和 \"visual agent\"。 - **智能体能力**: `Tool Use / Tool Augmentation` 是这篇论文最核心的贡献之一，它通过调用多种视觉工具来完成任务。`Planning` 能力也体现在 \"execute complex multi-step visual workflows\" 中，这表明智能体能够规划和执行一系列步骤。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题。 - **多模态与视觉**: 这是需要仔细判断的一点。虽然论文标题和内容都围绕 \"Visual\" 和 \"Multimodal\"，但它并未被排除。根据筛选规则，除非视觉是研究的核心，否则应保留。在这里，**研究的核心是“智能体框架”**，而视觉是这个智能体感知和交互的**环境/领域**。论文的贡献在于“如何构建一个能使用工具解决视觉问题的智能体”，而不是“如何构建一个更好的视觉模型”。因此，它符合“被用作智能体感知环境的工具”这一例外情况，不应被排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确涉及智能体的规划和多步推理。它不是在提升LLM本身的基础推理能力，而是在构建一个能让LLM通过调用工具、执行工作流来完成复杂任务的框架。这完全符合“保留”的条件。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献是构建了一个具备工具使用和规划能力的单智能体框架。尽管其应用领域是视觉，但其研究焦点和方法论完全属于“Agentic AI”的范畴，特别是“单智能体”方向下的“工具使用”和“规划”子方向。因此，这篇论文与你的研究课题高度相关，应该被保留。"
    },
    {
        "index": "#111",
        "title": "AsyncVLA: Asynchronous Flow Matching for Vision-Language-Action Models",
        "link": "/arxiv/2511.14148",
        "arxiv_id": "2511.14148",
        "authors": "Yuhua Jiang, Shuang Cheng, Yan Ding, Feifei Gao, Biqing Qi",
        "summary": "Vision-language-action (VLA) models have recently emerged as a powerful paradigm for building generalist robots. However, traditional VLA models that generate actions through flow matching (FM) typically rely on rigid and uniform time schedules, i.e., synchronous FM (SFM). Without action context awareness and asynchronous self-correction, SFM becomes unstable in long-horizon tasks, where a single action error can cascade into failure. In this work, we propose asynchronous flow matching VLA (AsyncVLA), a novel framework that introduces temporal flexibility in asynchronous FM (AFM) and enables self-correction in action generation. AsyncVLA breaks from the vanilla SFM in VLA models by generating the action tokens in a non-uniform time schedule with action context awareness. Besides, our method introduces the confidence rater to extract confidence of the initially generated actions, enabling the model to selectively refine inaccurate action tokens before execution. Moreover, we propose a unified training procedure for SFM and AFM that endows a single model with both modes, improving KV-cache utilization. Extensive experiments on robotic manipulation benchmarks demonstrate that AsyncVLA is data-efficient and exhibits self-correction ability. AsyncVLA achieves state-of-the-art results across general embodied evaluations due to its asynchronous generation in AFM. Our code is available at https://github.com/YuhuaJiang2002/AsyncVLA.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2025-11-18",
        "category": "cs.LG",
        "crawl_time": "2025-11-19T11:00:05.486644",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。 **判断过程如下:** 1.  **第一步：核心判断** - **论文本质**: 论文的核心贡献是提出了一个名为 `AsyncVLA` 的新框架，用于改进 Vision-Language-Action (VLA) 模型。VLA 模型本质上是一种具身智能体，它接收视觉和语言指令并生成行动。因此，这篇论文的核心是关于**构建和改进一个智能体**。 - **关键创新**: 论文的核心创新点在于引入了 `asynchronous flow matching (AFM)` 和 `self-correction` 机制。这并非简单地将现有智能体应用于新领域，而是对智能体内部行动生成和修正机制的**根本性改进**。 - **结论**: 论文的核心是关于构建和改进智能体的方法论，符合“保留”标准。 2.  **第二步：正面指标** - 论文明确提到了 `self-correction`（自我修正），这是 `Self-Evolving`（自我演化）方向下的一个关键子方向。 - 论文引入了 `confidence rater`（置信度评估器）来评估自身生成的动作，这是一种 `Self-Reflection`（自我反思）能力的体现。 - 论文处理的是长时程任务中的行动序列，这涉及到智能体的 `Planning`（规划）和执行能力。 - **结论**: 论文包含了多个核心关注点，尤其是“自我演化”相关的指标。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性，因此不在此排除范围内。 - **多模态与视觉**: 论文标题和摘要中提到了 `Vision-Language-Action (VLA)`。根据筛选规则，如果视觉/多模态是“被用作智能体感知环境的工具，而不是研究的核心”，则不应排除。在本论文中，视觉是智能体感知世界以生成行动的必要输入，但研究的核心是**行动生成的异步机制和自我修正能力**，而非视觉模型本身。因此，它符合例外情况，不应被排除。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 论文提出了一种新的“自我修正”机制（属于自我演化），并将其应用于机器人领域。根据筛选规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 这条规则完全适用于此论文。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出了一种名为 `AsyncVLA` 的新框架，其核心创新在于为 VLA 智能体引入了**异步行动生成**和**自我修正**能力。这直接对应了研究课题中的“自我演化”方向，特别是“自我完善和迭代”这一子方向。尽管论文的应用领域是机器人技术，但其方法论贡献是普适的，旨在提升智能体本身的能力，而非解决特定领域问题。因此，该论文精准地符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#1",
        "title": "AutoTool: Efficient Tool Selection for Large Language Model Agents",
        "link": "/arxiv/2511.14650",
        "arxiv_id": "2511.14650",
        "authors": "Jingyi Jia, Qinbin Li",
        "summary": "Large Language Model (LLM) agents have emerged as powerful tools for automating complex tasks by leveraging the reasoning and decision-making abilities of LLMs. However, a major bottleneck in current agent frameworks lies in the high inference cost of tool selection, especially in approaches like ReAct that repeatedly invoke the LLM to determine which tool to use at each step. In this work, we propose AutoTool, a novel graph-based framework that bypasses repeated LLM inference by exploiting a key empirical observation: tool usage inertia - the tendency of tool invocations to follow predictable sequential patterns. AutoTool constructs a directed graph from historical agent trajectories, where nodes represent tools and edges capture transition probabilities, effectively modeling the inertia in tool selection. It further integrates parameter-level information to refine tool input generation. By traversing this structured representation, AutoTool efficiently selects tools and their parameters with minimal reliance on LLM inference. Extensive experiments across diverse agent tasks demonstrate that AutoTool reduces inference costs by up to 30% while maintaining competitive task completion rates, offering a practical and scalable enhancement for inference-heavy frameworks. Our work highlights the promise of integrating statistical structure into LLM agent design for greater efficiency without sacrificing performance.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.AI",
        "crawl_time": "2025-11-19T11:00:05.491860",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**改进LLM智能体**。它没有将LLM智能体作为一个现成工具去解决某个外部领域（如生物、金融）的问题，而是直接针对现有LLM智能体框架（如ReAct）中的一个核心瓶颈——工具选择的推理成本过高——提出了一个全新的解决方案（AutoTool框架）。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **核心范式**: 摘要中明确提到了 `LLM agents` 和 `agent frameworks`。 - **智能体能力**: 论文的全部核心都围绕着 `Tool Use / Tool Augmentation`，并直接与 `ReAct` 这一经典智能体范式进行对比和优化。 - 这些指标强烈表明该论文与研究焦点高度相关。 3.  **第三步：排除标准** - 论文未触发任何排除标准。其主要贡献是关于效率优化，而非安全、对齐、可解释性或多模态。因此，可以安全地通过此步筛选。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文涉及了智能体的推理过程，特别是ReAct中的工具选择步骤。根据规则，应**保留**。因为它不是在研究如何提升LLM本身的基础数学或逻辑推理能力，而是在研究如何让智能体在执行复杂任务（多步推理）时更高效地进行工具选择，这属于智能体框架层面的优化，是典型的Agentic AI研究。 5.  **第五步：最终决策** - **综合判断**: 该论文的核心贡献是提出了一种名为AutoTool的新颖框架，通过构建工具使用图来预测和优化LLM智能体的工具选择行为，从而显著降低推理成本。这直接属于“单智能体”研究方向下的“工具使用”子方向，是对现有智能体方法论的一次实质性改进。它完全符合筛选“核心贡献在于构建、改进或演化LLM智能体”的论文的要求。因此，最终决策为保留。"
    },
    {
        "index": "#14",
        "title": "Run, Ruminate, and Regulate: A Dual-process Thinking System for Vision-and-Language Navigation",
        "link": "/arxiv/2511.14131",
        "arxiv_id": "2511.14131",
        "authors": "Yu Zhong, Zihao Zhang, Rui Zhang, Lingdong Huang, Haihan Gao, Shuo Wang, Da Li, Ruijian Han, Jiaming Guo, Shaohui Peng, Di Huang, Yunji Chen",
        "summary": "Vision-and-Language Navigation (VLN) requires an agent to dynamically explore complex 3D environments following human instructions. Recent research underscores the potential of harnessing large language models (LLMs) for VLN, given their commonsense knowledge and general reasoning capabilities. Despite their strengths, a substantial gap in task completion performance persists between LLM-based approaches and domain experts, as LLMs inherently struggle to comprehend real-world spatial correlations precisely. Additionally, introducing LLMs is accompanied with substantial computational cost and inference latency. To address these issues, we propose a novel dual-process thinking framework dubbed R3, integrating LLMs' generalization capabilities with VLN-specific expertise in a zero-shot manner. The framework comprises three core modules: Runner, Ruminator, and Regulator. The Runner is a lightweight transformer-based expert model that ensures efficient and accurate navigation under regular circumstances. The Ruminator employs a powerful multimodal LLM as the backbone and adopts chain-of-thought (CoT) prompting to elicit structured reasoning. The Regulator monitors the navigation progress and controls the appropriate thinking mode according to three criteria, integrating Runner and Ruminator harmoniously. Experimental results illustrate that R3 significantly outperforms other state-of-the-art methods, exceeding 3.28% and 3.30% in SPL and RGSPL respectively on the REVERIE benchmark. This pronounced enhancement highlights the effectiveness of our method in handling challenging VLN tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.AI",
        "crawl_time": "2025-11-19T11:00:05.504232",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进一个LLM智能体。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心并非简单地将LLM应用于视觉语言导航（VLN）这一特定领域，而是提出了一种名为R3的**新颖的双过程思维框架**。这个框架本身就是一个智能体架构，它包含`Runner`（快速执行者）、`Ruminator`（深度反思者）和`Regulator`（模式调节器）三个模块，共同协作以完成任务。 - 这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是在解决一个VLN领域的具体问题，而是在**提出一种通用的、更高级的智能体思考模式**，并用VLN任务来验证其有效性。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** - 论文包含了多个核心关注点： - **智能体能力**: `Planning`（导航本身就是一种规划）、`Self-Reflection`（`Ruminator`模块的“沉思”机制就是一种深度反思）、`ReAct`（`Ruminator`使用CoT进行推理，并与环境交互，其思想与ReAct范式高度一致）。 - **核心范式**: 论文的核心是构建一个`LLM-based Agent`，其`Ruminator`模块直接使用了多模态LLM作为“大脑”。 3.  **第三步：排除标准——不适用** - **安全与对齐**: 论文未涉及安全、对齐、可解释性等内容。 - **多模态与视觉**: 虽然论文涉及视觉（VLN任务），但它完全符合排除标准中的例外情况——“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉是智能体感知3D环境的输入模态，是智能体与外界交互的一部分。论文的**核心贡献是R3这个智能体框架本身，而不是视觉模型或视觉处理技术**。 4.  **第四步：处理特殊和模糊情况——符合保留条件** - **推理/规划**: 论文明确是关于智能体如何在复杂任务（VLN）中进行规划和多步推理。`Ruminator`模块的CoT推理和`Regulator`的模式切换，正是智能体层面规划和推理的体现，而非提升LLM本身的基础Token预测能力。因此，符合保留条件。 **最终决策**: 这篇论文的核心贡献是提出了一种名为R3的**新型LLM智能体架构**，该架构通过模拟人类的双过程思维（快速直觉与慢速反思），显著提升了智能体在复杂环境中的任务执行能力。这直接对准了您研究目标中的**“单智能体”**方向，特别是在**“规划”**和**“自我反思”**这两个子方向上做出了创新。尽管其应用场景是VLN，但这仅仅是验证其智能体框架有效性的试验场，其方法论具有通用性。因此，这篇论文是您应该保留的前沿研究。"
    },
    {
        "index": "#156",
        "title": "From Legacy Fortran to Portable Kokkos: An Autonomous Agentic AI Workflow",
        "link": "/arxiv/2509.12443",
        "arxiv_id": "2509.12443",
        "authors": "Sparsh Gupta, Kamalavasan Kamalakkannan, Maxim Moraru, Galen Shipman, Patrick Diehl",
        "summary": "Scientific applications continue to rely on legacy Fortran codebases originally developed for homogeneous, CPU-based systems. As High-Performance Computing (HPC) shifts toward heterogeneous GPU-accelerated architectures, many accelerators lack native Fortran bindings, creating an urgent need to modernize legacy codes for portability. Frameworks like Kokkos provide performance portability and a single-source C++ abstraction, but manual Fortran-to-Kokkos porting demands significant expertise and time. Large language models (LLMs) have shown promise in source-to-source code generation, yet their use in fully autonomous workflows for translating and optimizing parallel code remains largely unexplored, especially for performance portability across diverse hardware. This paper presents an agentic AI workflow where specialized LLM \"agents\" collaborate to translate, validate, compile, run, test, debug, and optimize Fortran kernels into portable Kokkos C++ programs. Results show the pipeline modernizes a range of benchmark kernels, producing performance-portable Kokkos codes across hardware partitions. Paid OpenAI models such as GPT-5 and o4-mini-high executed the workflow for only a few U.S. dollars, generating optimized codes that surpassed Fortran baselines, whereas open-source models like Llama4-Maverick often failed to yield functional codes. This work demonstrates the feasibility of agentic AI for Fortran-to-Kokkos transformation and offers a pathway for autonomously modernizing legacy scientific applications to run portably and efficiently on diverse supercomputers. It further highlights the potential of LLM-driven agentic systems to perform structured, domain-specific reasoning tasks in scientific and systems-oriented applications.",
        "subjects": "Software Engineering",
        "date": "2025-09-15",
        "category": "cs.LG",
        "crawl_time": "2025-11-19T11:00:05.520604",
        "filter_reason": "这篇论文的核心贡献在于提出并验证了一个**“自主智能体AI工作流”**，用于解决复杂的代码现代化任务。根据您的筛选标准，这篇论文完全符合要求，应予以保留。具体判断过程如下： 1.  **第一步：核心判断 (保留)** - 论文的本质并非简单地将LLM作为工具应用于HPC领域，而是**构建了一个由多个专业化LLM智能体协作的框架**。摘要中明确指出，这是一个“agentic AI workflow”，其中“specialized LLM 'agents' collaborate to translate, validate, compile, run, test, debug, and optimize”。这清晰地表明，论文的核心是关于**如何构建和组织智能体**来完成复杂任务，而不是仅仅报告一个应用结果。 - 该工作流包含了智能体的关键特征：自主性、多步执行、工具使用（编译器、测试运行器）和自我修正（debug, optimize）。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标 (高度相关)** - **核心范式**: 论文标题和摘要中直接出现了 `Agentic AI` 和 `LLM-based Agents`。多个智能体的协作也符合 `Multi-Agent Systems (MAS)` 的范畴。 - **智能体能力**: 工作流描述的“translate, validate, compile, run, test, debug, and optimize”过程，完美体现了智能体的 `Planning`（规划整个流程）、`Tool Use`（调用编译器、测试环境）和 `Self-Correction`（根据测试和性能结果进行调试和优化）能力。 - **多智能体**: 摘要中明确使用了 `collaborate` 一词，表明智能体之间存在协作关系，这是多智能体研究的核心。 3.  **第三步：排除标准 (未触发)** - 论文的主要贡献不是关于安全、对齐或可解释性。 - 论文不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况 (符合保留条件)** - **推理/规划**: 该论文是典型的智能体规划和推理案例。它不是在提升LLM的基础推理能力，而是在构建一个让智能体能够进行复杂、多步骤、结构化推理和执行的框架。这完全符合“保留”标准。 **结论**: 尽管论文的应用领域是具体的HPC代码现代化，但其**核心贡献是方法论层面的**——即提出并验证了一个新颖的、由多智能体协作构成的自主工作流。这个工作流展示了智能体如何通过规划、工具使用和自我修正来解决一个复杂的现实世界问题。这完全契合您研究课题中“构建、改进LLM智能体”和“多智能体协作”的核心目标。因此，这篇论文是高度相关且应被筛选出来的前沿研究。"
    },
    {
        "index": "#16",
        "title": "APD-Agents: A Large Language Model-Driven Multi-Agents Collaborative Framework for Automated Page Design",
        "link": "/arxiv/2511.14101",
        "arxiv_id": "2511.14101",
        "authors": "Xinpeng Chen, Xiaofeng Han, Kaihao Zhang, Guochao Ren, Yujie Wang, Wenhao Cao, Yang Zhou, Jianfeng Lu, Zhenbo Song",
        "summary": "Layout design is a crucial step in developing mobile app pages. However, crafting satisfactory designs is time-intensive for designers: they need to consider which controls and content to present on the page, and then repeatedly adjust their size, position, and style for better aesthetics and structure. Although many design software can now help to perform these repetitive tasks, extensive training is needed to use them effectively. Moreover, collaborative design across app pages demands extra time to align standards and ensure consistent styling. In this work, we propose APD-agents, a large language model (LLM) driven multi-agent framework for automated page design in mobile applications. Our framework contains OrchestratorAgent, SemanticParserAgent, PrimaryLayoutAgent, TemplateRetrievalAgent, and RecursiveComponentAgent. Upon receiving the user's description of the page, the OrchestratorAgent can dynamically can direct other agents to accomplish users' design task. To be specific, the SemanticParserAgent is responsible for converting users' descriptions of page content into structured data. The PrimaryLayoutAgent can generate an initial coarse-grained layout of this page. The TemplateRetrievalAgent can fetch semantically relevant few-shot examples and enhance the quality of layout generation. Besides, a RecursiveComponentAgent can be used to decide how to recursively generate all the fine-grained sub-elements it contains for each element in the layout. Our work fully leverages the automatic collaboration capabilities of large-model-driven multi-agent systems. Experimental results on the RICO dataset show that our APD-agents achieve state-of-the-art performance.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.AI",
        "crawl_time": "2025-11-19T11:00:05.505217",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程和核心依据如下：** 1.  **第一步：核心判断——保留** - **论文本质**: 这篇论文的核心贡献是提出了一种名为 **APD-agents** 的新型LLM驱动的多智能体协作框架。它详细定义了多个具有不同职责的智能体（如OrchestratorAgent, SemanticParserAgent等）以及它们之间如何动态协作来完成自动化页面设计任务。 - **符合保留标准**: 论文的核心是关于**构建多智能体系统（Multi-Agent Systems）**的方法论和新框架。它并非简单地将一个已有的智能体框架作为工具应用到页面设计领域，而是**提出并实现了一个全新的、专门化的多智能体协作架构**。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** - 论文包含了大量核心关注点的正面指标： - **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)`。 - **多智能体**: `Collaboration`（协作）是论文的核心，`Communication`（通信）由智能体间的交互所隐含。 - **智能体能力**: `Planning`（规划）能力体现在`OrchestratorAgent`动态指导其他智能体，以及`PrimaryLayoutAgent`生成初始布局。`Tool Use`（工具使用）体现在`TemplateRetrievalAgent`检索模板。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不涉及安全、对齐、可解释性或水印等问题。 - 论文处理的是页面布局的结构化数据和用户描述，不涉及视觉、多模态模型或扩散模型作为其研究核心。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的规划是**智能体层面的规划**。`OrchestratorAgent`负责任务分解和调度，这完全符合“智能体如何进行规划或在复杂任务中进行多步推理”的保留标准，而非提升LLM本身的基础推理能力。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建了一个新颖的多智能体协作框架**，以解决自动化页面设计这一复杂任务。它完美契合研究课题中的 **“多智能体”** 方向，特别是智能体间的**协作、通信和规划**机制。尽管其应用场景是页面设计，但论文的焦点和价值在于其提出的**Agentic框架本身**，而非应用结果。因此，这篇论文是高度相关且应被保留的前沿研究。"
    },
    {
        "index": "#57",
        "title": "Agentic Video Intelligence: A Flexible Framework for Advanced Video Exploration and Understanding",
        "link": "/arxiv/2511.14446",
        "arxiv_id": "2511.14446",
        "authors": "Hong Gao, Yiming Bao, Xuezhen Tu, Yutong Xu, Yue Jin, Yiyang Mu, Bin Zhong, Linan Yue, Min-Ling Zhang",
        "summary": "Video understanding requires not only visual recognition but also complex reasoning. While Vision-Language Models (VLMs) demonstrate impressive capabilities, they typically process videos largely in a single-pass manner with limited support for evidence revisit and iterative refinement. While recently emerging agent-based methods enable long-horizon reasoning, they either depend heavily on expensive proprietary models or require extensive agentic RL training. To overcome these limitations, we propose Agentic Video Intelligence (AVI), a flexible and training-free framework that can mirror human video comprehension through system-level design and optimization. AVI introduces three key innovations: (1) a human-inspired three-phase reasoning process (Retrieve-Perceive-Review) that ensures both sufficient global exploration and focused local analysis, (2) a structured video knowledge base organized through entity graphs, along with multi-granularity integrated tools, constituting the agent's interaction environment, and (3) an open-source model ensemble combining reasoning LLMs with lightweight base CV models and VLM, eliminating dependence on proprietary APIs or RL training. Experiments on LVBench, VideoMME-Long, LongVideoBench, and Charades-STA demonstrate that AVI achieves competitive performance while offering superior interpretability.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.AI",
        "crawl_time": "2025-11-19T11:00:05.535822",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 \"Agentic Video Intelligence (AVI)\" 的**新框架**。其核心贡献并非简单地将现有智能体应用于视频领域，而是**构建**了一个具有特定设计（三阶段推理过程、知识库、工具集成）的智能体框架来解决视频理解中的挑战。这直接命中了“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文标题和摘要中包含了大量核心关注点的关键词： - **核心范式**: `Agentic AI`, `LLM-based Agents` (通过框架设计体现)。 - **智能体能力**: - `Planning`: 论文明确提出了一个 \"human-inspired three-phase reasoning process (Retrieve-Perceive-Review)\"，这是一种结构化的规划和推理机制。 - `Memory`: 提出了 \"a structured video knowledge base organized through entity graphs\"，这是智能体的记忆系统。 - `Tool Use / Tool Augmentation`: 明确提到了 \"multi-granularity integrated tools\" 和 \"model ensemble combining reasoning LLMs with lightweight base CV models and VLM\"，这表明智能体能够调用多种工具来感知和交互。 - `Self-Correction / Self-Reflection`: \"Review\" 阶段本身就蕴含了自我反思和修正的意味，确保了分析的准确性。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主要贡献是框架设计和性能，而非安全、对齐或可解释性。虽然摘要末尾提到了 \"superior interpretability\"，但这被描述为框架带来的一个**优点**，而非其核心研究贡献。 - **多模态与视觉**: 这是本案例的关键点。虽然论文聚焦于视频，但它完全符合筛选标准中的例外情况：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，视觉模型（CV models, VLM）被明确地作为智能体工具箱的一部分，是智能体与环境（视频）交互的“眼睛”和“感知器”。**研究的核心是智能体的架构和推理流程，而不是视觉模型本身**。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文是“保留”的典型范例。它不是在改进LLM的基础数学或逻辑能力，而是在构建一个**智能体层面的规划和推理框架**（Retrieve-Perceive-Review），用于处理复杂的多步任务（视频理解）。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建了一个新颖的、免训练的LLM智能体框架（AVI）**，该框架在规划、记忆和工具使用等关键能力上做出了创新。尽管其应用领域是视频理解，但其研究焦点完全在于智能体本身的架构设计，而非视觉技术或特定领域应用。因此，这篇论文与您关于“LLM智能体及其演化”的研究课题高度相关，应当被保留。"
    },
    {
        "index": "#84",
        "title": "Towards Deploying VLA without Fine-Tuning: Plug-and-Play Inference-Time VLA Policy Steering via Embodied Evolutionary Diffusion",
        "link": "/arxiv/2511.14178",
        "arxiv_id": "2511.14178",
        "authors": "Zhuo Li, Junjia Liu, Zhipeng Dong, Tao Teng, Quentin Rouxel, Darwin Caldwell, Fei Chen",
        "summary": "Vision-Language-Action (VLA) models have demonstrated significant potential in real-world robotic manipulation. However, pre-trained VLA policies still suffer from substantial performance degradation during downstream deployment. Although fine-tuning can mitigate this issue, its reliance on costly demonstration collection and intensive computation makes it impractical in real-world settings. In this work, we introduce VLA-Pilot, a plug-and-play inference-time policy steering method for zero-shot deployment of pre-trained VLA without any additional fine-tuning or data collection. We evaluate VLA-Pilot on six real-world downstream manipulation tasks across two distinct robotic embodiments, encompassing both in-distribution and out-of-distribution scenarios. Experimental results demonstrate that VLA-Pilot substantially boosts the success rates of off-the-shelf pre-trained VLA policies, enabling robust zero-shot generalization to diverse tasks and embodiments. Experimental videos and code are available at: https://rip4kobe.github.io/vla-pilot/.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.AI",
        "crawl_time": "2025-11-19T11:00:05.546548",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 VLA-Pilot 的方法，它是一种在推理时通过“具身演化扩散”机制来引导和改进预训练视觉-语言-动作（VLA）模型策略的框架。我的判断过程如下： 1.  **第一步：核心判断——保留。** 论文的核心并非简单地将VLA模型应用于机器人任务，而是提出了一种**全新的方法论**来**改进和演化**已有智能体的性能。其核心机制“演化扩散”和“推理时策略引导”直接对应了研究目标中的“自我演化”方向。它不是静态的应用，而是一个动态的、迭代优化的过程，因此不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配。** 论文包含了多个核心关注点： *   **核心范式**: `Self-Evolving` 和 `Evolutionary Algorithms` 是论文标题和摘要的核心，明确指出了其演化属性。 *   **演化机制**: `Self-Improvement` 和 `Iterative Improvement` 是该方法论的直接体现。VLA-Pilot通过一个迭代过程来提升智能体的策略，使其在下游任务中表现更好。 *   **智能体能力**: 虽然没有直接提及规划或记忆，但“策略引导”本身就是一种高级的决策和行动选择能力，是智能体在环境中行动的核心。 3.  **第三步：排除标准——未触发。** *   **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题。 *   **多模态与视觉**: 这是本案例的关键点。虽然论文研究对象是VLA（一种多模态模型），但根据筛选标准，除非多模态是研究的核心，否则应排除。在这里，**VLA是“被演化”的对象，而不是研究的核心贡献**。论文的核心是那个“演化”的**方法**，而不是VLA模型本身。因此，这符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外情况。 4.  **第四步：处理特殊和模糊情况——完美契合。** 该论文是“自我演化的应用”这一特殊情况的典型范例。筛选标准明确指出：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” 本文的核心贡献正是“具身演化扩散”这一新的自我演化机制，并将其应用于机器人操作这一特定领域。因此，它完全符合保留条件。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种新颖的、无需微调的、在推理时进行自我演化的智能体策略优化框架。这完全符合我研究课题中“自我演化”的核心目标。尽管其应用背景是机器人技术，但其方法论本身具有普适性，是对Agentic AI如何自我完善和迭代的重要探索。因此，这篇论文应该被保留。"
    },
    {
        "index": "#98",
        "title": "NeuroPath: Neurobiology-Inspired Path Tracking and Reflection for Semantically Coherent Retrieval",
        "link": "/arxiv/2511.14096",
        "arxiv_id": "2511.14096",
        "authors": "Junchen Li, Rongzheng Wang, Yihong Huang, Qizhi Chen, Jiasheng Zhang, Shuang Liang",
        "summary": "Retrieval-augmented generation (RAG) greatly enhances large language models (LLMs) performance in knowledge-intensive tasks. However, naive RAG methods struggle with multi-hop question answering due to their limited capacity to capture complex dependencies across documents. Recent studies employ graph-based RAG to capture document connections. However, these approaches often result in a loss of semantic coherence and introduce irrelevant noise during node matching and subgraph construction. To address these limitations, we propose NeuroPath, an LLM-driven semantic path tracking RAG framework inspired by the path navigational planning of place cells in neurobiology. It consists of two steps: Dynamic Path Tracking and Post-retrieval Completion. Dynamic Path Tracking performs goal-directed semantic path tracking and pruning over the constructed knowledge graph (KG), improving noise reduction and semantic coherence. Post-retrieval Completion further reinforces these benefits by conducting second-stage retrieval using intermediate reasoning and the original query to refine the query goal and complete missing information in the reasoning path. NeuroPath surpasses current state-of-the-art baselines on three multi-hop QA datasets, achieving average improvements of 16.3% on recall@2 and 13.5% on recall@5 over advanced graph-based RAG methods. Moreover, compared to existing iter-based RAG methods, NeuroPath achieves higher accuracy and reduces token consumption by 22.8%. Finally, we demonstrate the robustness of NeuroPath across four smaller LLMs (Llama3.1, GLM4, Mistral0.3, and Gemma3), and further validate its scalability across tasks of varying complexity. Code is available at https://github.com/KennyCaty/NeuroPath.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-11-18",
        "category": "cs.AI",
        "crawl_time": "2025-11-19T11:00:05.551880",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出一个名为 **NeuroPath** 的新框架。这个框架并非简单地将LLM应用于问答任务，而是构建了一个具有**自主规划和反思能力**的LLM智能体。其两个核心步骤——“Dynamic Path Tracking”（动态路径跟踪）和“Post-retrieval Completion”（检索后补全）——分别对应了智能体的**规划**和**自我反思/自我纠正**能力。LLM在其中扮演了核心的决策者角色，在知识图（环境）中进行目标导向的路径导航（规划），并根据中间推理结果来完善路径（反思）。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。 2.  **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **智能体能力**: 论文明确提到了 `Planning`（通过“goal-directed semantic path tracking”实现）、`Self-Reflection` / `Self-Correction`（通过“Post-retrieval Completion”实现）。其工作流程与 `ReAct` (Reason-Act) 范式高度相似，即推理、行动、观察、再反思的循环。 *   **核心范式**: 论文本质上是在研究 `Agentic AI` 和 `LLM-based Agents`，它将LLM从一个被动的问答模型提升为一个主动的、在结构化环境中进行规划和决策的智能体。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于提升智能体在复杂任务中的性能，而非安全、对齐或可解释性。同时，它也不涉及多模态或视觉内容，其操作对象是文本知识库和知识图。 4.  **第四步：特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文的研究重点正是**智能体如何进行规划**。它不是在改进LLM底层的数学或逻辑推理能力，而是在构建一个外部的、让LLM能够进行多步规划和反思的框架。这完全符合“保留”关于智能体规划研究的规则。 *   **自我演化**: 虽然论文没有明确提出“自我演化”的跨代际概念，但其“Post-retrieval Completion”步骤体现了**单次任务内的迭代改进和自我完善**，这与自我演化的精神内核（通过反馈进行迭代优化）是一致的，属于自我反思的范畴。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种新颖的、受神经生物学启发的LLM智能体框架。该框架赋予了LLM在知识图谱上进行**自主规划**和**自我反思**的能力，以解决复杂的多跳问答问题。这直接命中了您研究焦点中的“单智能体”方向，特别是“规划”和“自我反思”这两个子方向。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#117",
        "title": "LoCoBench-Agent: An Interactive Benchmark for LLM Agents in Long-Context Software Engineering",
        "link": "/arxiv/2511.13998",
        "arxiv_id": "2511.13998",
        "authors": "Jielin Qiu, Zuxin Liu, Zhiwei Liu, Rithesh Murthy, Jianguo Zhang, Haolin Chen, Shiyu Wang, Ming Zhu, Liangwei Yang, Juntao Tan, Roshan Ram, Akshara Prabhakar, Tulika Awalgaonkar, Zixiang Chen, Zhepeng Cen, Cheng Qian, Shelby Heinecke, Weiran Yao, Silvio Savarese, Caiming Xiong, Huan Wang",
        "summary": "As large language models (LLMs) evolve into sophisticated autonomous agents capable of complex software development tasks, evaluating their real-world capabilities becomes critical. While existing benchmarks like LoCoBench~\\cite{qiu2025locobench} assess long-context code understanding, they focus on single-turn evaluation and cannot capture the multi-turn interactive nature, tool usage patterns, and adaptive reasoning required by real-world coding agents. We introduce \\textbf{LoCoBench-Agent}, a comprehensive evaluation framework specifically designed to assess LLM agents in realistic, long-context software engineering workflows. Our framework extends LoCoBench's 8,000 scenarios into interactive agent environments, enabling systematic evaluation of multi-turn conversations, tool usage efficiency, error recovery, and architectural consistency across extended development sessions. We also introduce an evaluation methodology with 9 metrics across comprehension and efficiency dimensions. Our framework provides agents with 8 specialized tools (file operations, search, code analysis) and evaluates them across context lengths ranging from 10K to 1M tokens, enabling precise assessment of long-context performance. Through systematic evaluation of state-of-the-art models, we reveal several key findings: (1) agents exhibit remarkable long-context robustness; (2) comprehension-efficiency trade-off exists with negative correlation, where thorough exploration increases comprehension but reduces efficiency; and (3) conversation efficiency varies dramatically across models, with strategic tool usage patterns differentiating high-performing agents. As the first long-context LLM agent benchmark for software engineering, LoCoBench-Agent establishes a rigorous foundation for measuring agent capabilities, identifying performance gaps, and advancing autonomous software development at scale.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-17",
        "category": "cs.AI",
        "crawl_time": "2025-11-19T11:00:05.557859",
        "filter_reason": "这篇论文的核心贡献是构建了一个名为 **LoCoBench-Agent** 的交互式评估框架，专门用于衡量LLM智能体在长上下文软件工程任务中的能力。根据我的筛选标准，这篇论文完全符合要求，应被保留。 1.  **第一步：核心判断——保留** 论文的本质不是将LLM智能体作为工具去解决一个软件工程问题，而是**构建了一个用于评估和推动LLM智能体发展的方法论和框架**。这个框架（LoCoBench-Agent）本身就是一个关于“如何衡量智能体能力”的贡献，它直接服务于“构建、改进或演化LLM智能体”这一核心目标。它不属于“非演化型应用”，因为它关注的是智能体本身的能力边界和评估方法，而非应用结果。 2.  **第二步：正面指标——高度相关** 论文与我的核心关注点高度契合，尤其是在“单智能体”方向： *   **核心范式**: 论文明确围绕 `LLM-based Agents` 展开。 *   **智能体能力**: 论文的核心评估指标直接对应了智能体的关键能力，包括 `Tool Use` (提供了8个专用工具并评估其使用效率)、`Planning` (通过多轮交互和复杂任务评估其推理和规划能力)、以及 `Self-Correction` (明确评估了 `error recovery` 能力)。摘要中提到的“adaptive reasoning”和“multi-turn conversations”也指向了智能体的自主规划和交互能力。 3.  **第三步：排除标准——未触及** 论文的主要贡献是关于智能体的能力评估，不涉及安全、对齐、可解释性或视觉多模态等排除领域。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 论文的研究内容属于“推理/规划”的特殊情况。它不是在提升LLM本身的基础推理能力，而是在**评估智能体在复杂、真实环境中的多步推理和规划能力**。这完全符合“保留”的条件，即“关于智能体如何进行规划或在复杂任务中进行多步推理”。 **结论**: 该论文虽然不是提出一个新的智能体架构，但它提出了一个**衡量和推动智能体发展的关键基础设施——评估基准**。对于任何致力于“构建、改进或演化LLM智能体”的研究者来说，一个严谨、全面的评估框架是不可或缺的。因此，这篇论文的核心贡献直接服务于我的研究目标，是筛选范围内的前沿工作。"
    }
]