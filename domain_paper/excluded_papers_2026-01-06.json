[
    {
        "index": "#4",
        "title": "Software-Defined Agentic Serving",
        "link": "/arxiv/2601.03197",
        "arxiv_id": "2601.03197",
        "authors": "Saurabh Agarwal, Marco Laju, Jayanth Srinivasa, Myungjin Lee, Aditya Akella",
        "subjects": "Distributed, Parallel, and Cluster Computing, Multiagent Systems",
        "date": "2026-01-06",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.900799",
        "filter_reason": "这篇论文的核心贡献在于提出了一种受SDN（软件定义网络）启发的“智能体服务框架”，旨在解决多智能体LLM流水线在复杂度增长时的服务适应性问题。其关注点在于“服务范式”、“运行时状态控制”和“通信属性”，属于系统架构和基础设施层面的优化。 根据筛选标准的第一步（核心判断），该研究明确属于“基础设施”排除类别，即主要关注模型基础设施、部署优化的研究。虽然论文涉及“Agentic”和“Multi-Agent”的概念，但其目的是为了优化服务效率和响应能力，而不是为了构建、改进或演化智能体本身的AI能力（如规划、记忆、工具使用或自我演化机制）。因此，它不符合“构建、改进或演化 LLM智能体”这一核心研究目标。"
    },
    {
        "index": "#1",
        "title": "Modellierung und Simulation der Dynamik von Fussgängerströmen",
        "link": "/arxiv/2601.02526",
        "arxiv_id": "2601.02526",
        "authors": "Péter Molnár",
        "subjects": "Multiagent Systems",
        "date": "2026-01-05",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.899876",
        "filter_reason": "这篇论文不符合筛选标准，具体判断过程如下： 1.  **核心判断（第一步）**： *   论文的核心主题是“行人流动力学的建模与模拟”，基于“社会力理论”。这属于经典的**基于物理的建模**或**传统多智能体系统**在交通工程/复杂系统领域的应用，而非基于大语言模型（LLM）的智能体研究。 *   论文的研究对象是物理世界中的行人，而非由LLM驱动的数字智能体。 2.  **缺失关键要素**： *   论文中完全没有提及大语言模型、Transformer架构或任何与LLM相关的内容。 *   虽然摘要中提到了“演化算法”和“多智能体”（指多个行人的交互），但这些是传统ABM（Agent-based Modeling）中的概念，用于优化建筑布局或模拟人群自组织行为，并不属于用户定义的“LLM智能体及其演化”的研究范畴。 3.  **结论**： *   该论文属于交通工程、物理模拟或复杂系统科学领域，与“LLM智能体”这一核心研究课题无关。因此，根据第一步的排除规则（非LLM相关研究），应予以排除。"
    },
    {
        "index": "#10",
        "title": "Evolutionary Algorithms for Computing Nash Equilibria in Dynamic Games",
        "link": "/arxiv/2601.02397",
        "arxiv_id": "2601.02397",
        "authors": "Alireza Rezaee",
        "subjects": "Neural and Evolutionary Computing, Computer Science and Game Theory, Multiagent Systems",
        "date": "2025-12-27",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.902551",
        "filter_reason": "这篇论文不符合我的研究范围，核心原因如下： 1.  **缺乏核心要素 (LLM)**: 论文的核心贡献是提出用于计算动态博弈中纳什均衡的演化算法（如协同演化遗传算法、混合遗传算法粒子群优化）。这属于经典的博弈论和运筹优化领域，完全未涉及大语言模型或基于LLM的智能体。 2.  **不符合“自我演化”的定义**: 虽然标题和摘要中提到了“Evolutionary Algorithms”（演化算法），但在本研究课题的语境下，“自我演化”指的是智能体通过经验、反思或环境反馈进行自我完善和迭代（如Self-Refine, Iterative Improvement）。而该论文中的“演化算法”是一种用于寻找纳什均衡的数学优化技术，并非智能体能力的自我进化机制。 3.  **多智能体语境不符**: 尽管论文涉及“Dynamic Games”和“Multi-agent decision making”，但这指的是博弈论中的玩家，而非“LLM-based Multi-Agent Systems”（LLM多智能体系统）。我的研究焦点是LLM智能体之间的协作、通信与社会学习，而非经典控制论或经济学模型中的博弈求解。 综上所述，该论文属于传统计算博弈论范畴，与“LLM智能体及其演化”这一核心目标无关，因此予以排除。"
    },
    {
        "index": "#11",
        "title": "Permission Manifests for Web Agents",
        "link": "/arxiv/2601.02371",
        "arxiv_id": "2601.02371",
        "authors": "Samuele Marro, Alan Chan, Xinxing Ren, Lewis Hammond, Jesse Wright, Gurjyot Wanga, Tiziano Piccardi, Nuno Campos, Tobin South, Jialin Yu, Alex Pentland, Philip Torr, Jiaxin Pei",
        "subjects": "Computers and Society, Artificial Intelligence, Multiagent Systems, Networking and Internet Architecture",
        "date": "2025-12-07",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.902893",
        "filter_reason": "1.  **核心贡献分析 (第一步)**: 这篇论文的核心贡献是提出了一种名为 `agent-permissions.json` 的**治理机制和协议标准**（类似于 robots.txt 的扩展），用于规范 Web 智能体与网站之间的交互权限。 它并没有提出新的**LLM智能体架构**、**规划算法**、**多智能体协作机制**或**自我演化算法**。论文的重点在于“管理”和“权限控制”，而非“构建”或“改进”智能体本身的能力。 2.  **排除标准判定 (第三步)**: 根据筛选标准中的“安全与对齐”排除项，主要贡献涉及 `Security`（安全）、`Alignment`（对齐）或治理机制的论文应被排除。本文旨在建立一种合规框架，使智能体的行为符合网站所有者的偏好，这本质上属于**AI 安全、治理与对齐** 的范畴，而非 Agentic AI 的核心能力研究（如规划、记忆、工具使用或演化）。 3.  **结论**: 尽管论文的研究对象是 Web Agents，但其研究内容属于智能体的外部治理协议，而非智能体内部机制的构建、改进或演化。因此，它不符合您关于“LLM智能体及其演化”的核心研究目标。"
    },
    {
        "index": "#1",
        "title": "PET-TURTLE: Deep Unsupervised Support Vector Machines for Imbalanced Data Clusters",
        "link": "/arxiv/2601.03237",
        "arxiv_id": "2601.03237",
        "authors": "Javier Salazar Cavazos",
        "subjects": "Machine Learning, Image and Video Processing, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.181290",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断过程如下： 1.  **核心贡献分析（第一步）**： *   该论文的核心贡献是提出了一种名为 **PET-TURTLE** 的深度聚类算法，用于处理不平衡数据簇。它是对现有 TURTLE 算法的改进，主要涉及支持向量机（SVM）、超平面优化和无监督学习技术。 *   论文的本质属于**机器学习算法**（特别是聚类分析）的研究，而非关于构建、改进或演化 LLM 智能体。 2.  **与筛选标准的对比**： *   **非 Agentic AI**：论文虽然提到了基础视觉、音频和语言模型，但仅将其作为获取潜在表示的特征提取器，并未涉及智能体的规划、工具使用、记忆或反思等核心能力。 *   **缺乏正面指标（第二步）**：论文内容完全不包含 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use` 或 `Memory` 等任何核心范式或关键词。 *   **排除依据**：该研究属于传统的深度学习/无监督学习领域，与“LLM智能体及其演化”这一课题无直接关联。 综上所述，该论文是一篇关于聚类算法的机器学习论文，不符合筛选条件。"
    },
    {
        "index": "#3",
        "title": "Critic-Guided Reinforcement Unlearning in Text-to-Image Diffusion",
        "link": "/arxiv/2601.03213",
        "arxiv_id": "2601.03213",
        "authors": "Mykola Vysotskyi, Zahar Kohut, Mariia Shpir, Taras Rumezhak, Volodymyr Karpiv",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.182804",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下核心判断： 1.  **核心主题不符 (第一步 & 第三步)**: *   论文的研究对象是 **Text-to-Image Diffusion Models** (文生图扩散模型)，而非 **LLM-based Agents** (基于大语言模型的智能体)。 *   虽然论文使用了强化学习 (RL)，但其目的是为了优化扩散模型的去噪过程，而非构建具有自主规划、工具使用或记忆能力的智能体。 2.  **触犯排除标准：安全与对齐 (第三步)**: *   论文的核心贡献在于 **Machine Unlearning** (机器遗忘)，旨在从模型中移除特定概念。这明确属于 **Safety** (安全)、**Security** (安全) 和 **Alignment** (对齐) 的范畴。 *   根据筛选标准第三步，只要论文的主要贡献是关于 Safety、Security 或 Alignment，一律排除。 3.  **触犯排除标准：多模态与视觉 (第三步)**: *   论文专注于视觉生成领域。虽然我的研究允许将视觉作为智能体的感知工具，但本论文是将视觉模型本身作为被修改和优化的对象，而非作为智能体架构的一部分，因此属于排除范围。 综上所述，该论文属于模型安全与对齐领域的研究，且针对的是扩散模型而非LLM智能体，因此被排除。"
    },
    {
        "index": "#4",
        "title": "Counterfactual Fairness with Graph Uncertainty",
        "link": "/arxiv/2601.03203",
        "arxiv_id": "2601.03203",
        "authors": "Davi Valério, Chrysoula Zerva, Mariana Pinto, Ricardo Santos, André Carreiro",
        "subjects": "Machine Learning, Artificial Intelligence, Computers and Society",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.183650",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心贡献不符 (第一步 - 核心判断)**: 论文的核心贡献是提出一种名为 \"CF-GU\" 的偏差评估程序，用于在因果图不确定的情况下评估机器学习模型的“反事实公平性”。这属于机器学习伦理和公平性领域，而非构建、改进或演化 LLM 智能体的方法论。 2.  **触犯排除标准 (第三步 - 排除标准)**: *   **安全与对齐**: 论文明确聚焦于 \"Evaluating machine learning (ML) model bias\"（评估ML模型偏差）和 \"Counterfactual Fairness\"（反事实公平性）。根据筛选标准，只要论文的主要贡献是关于 `Safety`、`Security` 或 `Alignment`（对齐，公平性通常归于此列），一律排除。 *   **图技术**: 论文的核心技术手段涉及 \"causal graph\"（因果图）、\"Causal Discovery\"（因果发现）和 \"Directed Acyclic Graphs (DAGs)\"。虽然这是因果推断，但筛选标准中明确排除了涉及知识图谱、图神经网络等图相关技术的论文。尽管因果图与知识图谱不同，但该论文完全依赖图结构作为核心，且已因“公平性”这一强排除项被过滤。 3.  **缺乏正面指标 (第二步 - 正面指标)**: 论文中未出现任何关于 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use` 或 `Memory` 等核心范式或能力指标。 综上所述，该论文属于机器学习安全与对齐领域的研究，与 LLM 智能体的构建、多智能体协作或自我演化机制无关，因此予以排除。"
    },
    {
        "index": "#6",
        "title": "Sparse Knowledge Distillation: A Mathematical Framework for Probability-Domain Temperature Scaling and Multi-Stage Compression",
        "link": "/arxiv/2601.03195",
        "arxiv_id": "2601.03195",
        "authors": "Aaron R. Flouro, Shawn P. Chadwick",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.185051",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献分析**：该论文的核心贡献在于提出了一种关于“稀疏知识蒸馏”的统一数学理论框架。它主要关注概率域软化算子、多阶段剪枝的同伦路径形式化以及收敛保证。其本质是**模型压缩**和**模型优化**技术，旨在提高模型的效率或减小模型体积。 2.  **第一步（核心判断）不符**： *   论文的研究内容属于**基础设施**或**部署优化**范畴（即如何让模型更小、更快），而非构建具有自主性、规划能力或工具使用能力的LLM智能体。 *   它不涉及构建Agentic LLM、多智能体系统（MAS）或自我演化的方法论。 3.  **第二步（正面指标）缺失**： *   论文中未出现 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving` 等核心范式。 *   论文未涉及智能体的关键能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Reflection`（自我反思）。 4.  **结论**：尽管模型压缩对于实际部署智能体可能有辅助作用，但该论文本身并未研究智能体的行为、架构或演化机制，而是纯粹的理论与算法优化研究。因此，根据筛选标准的第一步和第三步（基础设施），应予以排除。"
    },
    {
        "index": "#5",
        "title": "Empowering Reliable Visual-Centric Instruction Following in MLLMs",
        "link": "/arxiv/2601.03198",
        "arxiv_id": "2601.03198",
        "authors": "Weilei He, Feng Ju, Zhiyuan Fan, Rui Min, Minhao Cheng, Yi R. Fung",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.184343",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心贡献不符 (第一步)**: 论文的核心是提出了一个新的基准（VC-IFEval）和配套数据集，用于评估和提升多模态大语言模型（MLLMs）的“视觉指令遵循”能力。这属于模型基础能力的评估与基准测试，而非构建、改进或演化 LLM智能体（Agentic LLM）的方法论或新框架。 2.  **触犯排除标准 (第三步)**: 论文明确聚焦于 **多模态与视觉**（Multimodal & Vision），即 MLLMs 的视觉理解能力。根据筛选标准，涉及 Vision、MLLMs 等多模态技术的论文通常被排除，除非视觉仅作为智能体感知环境的工具。而在本文中，视觉指令遵循是研究的核心主体，而非智能体框架中的一个组件。 3.  **缺乏智能体特征 (第二步)**: 论文关注的是模型如何忠实地响应用户指令（Instruction Following），这属于模型对齐或基础能力范畴，并未涉及智能体的关键特征，如自主规划、工具使用、记忆机制、自我反思或多智能体协作等。 综上所述，该论文属于多模态模型评估领域，不属于 LLM智能体及其演化的研究范畴。"
    },
    {
        "index": "#2",
        "title": "Stigmergic Swarming Agents for Fast Subgraph Isomorphism",
        "link": "/arxiv/2601.02449",
        "arxiv_id": "2601.02449",
        "authors": "H. Van Dyke Parunak",
        "subjects": "Multiagent Systems, Discrete Mathematics",
        "date": "2026-01-05",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.900168",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#7",
        "title": "MixTTE: Multi-Level Mixture-of-Experts for Scalable and Adaptive Travel Time Estimation",
        "link": "/arxiv/2601.02943",
        "arxiv_id": "2601.02943",
        "authors": "Wenzhao Jiang, Jindong Han, Ruiqian Han, Hao Liu",
        "subjects": "Machine Learning, Multiagent Systems",
        "date": "2026-01-06",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.901718",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#5",
        "title": "Computationally Efficient Estimation of Localized Treatment Effects in High-Dimensional Design Spaces using Gaussian Process Regression",
        "link": "/arxiv/2601.03105",
        "arxiv_id": "2601.03105",
        "authors": "Abdulrahman A. Ahmed, M. Amin Rahimian, Qiushi Chen, Praveen Kumar",
        "subjects": "Applications, Multiagent Systems, Social and Information Networks, Physics and Society",
        "date": "2026-01-06",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.901140",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#6",
        "title": "ReCCur: A Recursive Corner-Case Curation Framework for Robust Vision-Language Understanding in Open and Edge Scenarios",
        "link": "/arxiv/2601.03011",
        "arxiv_id": "2601.03011",
        "authors": "Yihan Wei, Shenghai Yuan, Tianchen Deng, Boyang Lou, Enwen Hu",
        "subjects": "Computer Vision and Pattern Recognition, Multiagent Systems",
        "date": "2026-01-06",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.901457",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#8",
        "title": "Image, Word and Thought: A More Challenging Language Task for the Iterated Learning Model",
        "link": "/arxiv/2601.02911",
        "arxiv_id": "2601.02911",
        "authors": "Hyoyeon Lee, Seth Bullock, Conor Houghton",
        "subjects": "Computation and Language, Machine Learning, Multiagent Systems",
        "date": "2026-01-06",
        "category": "cs.MA",
        "crawl_time": "2026-01-08T11:00:03.902021",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#8",
        "title": "Predicting Time Pressure of Powered Two-Wheeler Riders for Proactive Safety Interventions",
        "link": "/arxiv/2601.03173",
        "arxiv_id": "2601.03173",
        "authors": "Sumit S. Shevtekar, Chandresh K. Maurya, Gourab Sil, Subasish Das",
        "subjects": "Machine Learning, Human-Computer Interaction",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.191403",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献是提出了一个名为 \"MotoTimePressure\" 的深度学习模型（结合卷积预处理、时间注意力机制等），用于预测两轮车骑行者的时间压力，以支持交通安全干预。这属于典型的**非演化型应用**，即将深度学习模型应用于智能交通系统（ITS）和交通安全领域。论文完全没有涉及 LLM（大语言模型）、Agentic AI（智能体）、多智能体系统或自我演化机制。 2.  **缺乏正面指标（第二步）**：论文中未出现任何关于 LLM-based Agents、Planning（智能体规划）、Tool Use、Multi-Agent Collaboration 或 Self-Evolving 等核心范式或能力的讨论。 3.  **排除标准（第三步）**：论文的研究焦点是交通安全和碰撞预测，属于特定垂直领域的应用研究，而非通用的智能体架构或演化算法研究。 综上所述，该论文是一篇关于交通工程和深度学习应用的文章，与“LLM智能体及其演化”这一核心课题无关，因此予以排除。"
    },
    {
        "index": "#7",
        "title": "Decentralized Autoregressive Generation",
        "link": "/arxiv/2601.03184",
        "arxiv_id": "2601.03184",
        "authors": "Stepan Maschan, Haoxuan Qu, Jun Liu",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.190877",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心判断（第一步）**：论文的核心贡献在于提出了“Decentralized Discrete Flow Matching objective”这一生成模型的理论框架，并探讨了去中心化与中心化训练设置的等价性。这属于模型生成机制和训练优化方法论的范畴，而非构建、改进或演化 LLM智能体。论文并未涉及智能体的自主性、规划、工具使用或交互。 2.  **排除标准（第三步）**：论文明确涉及多模态与视觉领域。摘要中提到实验对象是“multimodal language models”（如 LLaVA 和 InternVL），并使用了“fixed CLIP vision encoder”和“ViT”。根据筛选标准，涉及 Vision、MLLMs 等多模态技术的论文通常被排除，除非视觉仅作为智能体感知环境的工具。在此文中，多模态模型本身是研究主体，而非服务于 Agentic AI 的工具。 3.  **缺乏正面指标（第二步）**：论文内容未包含任何 Agentic AI 的核心范式或能力关键词（如 Planning, Tool Use, Memory, Multi-Agent Collaboration, Self-Evolving 等）。虽然标题中包含“Decentralized”（去中心化），但在文中它指的是生成概率的数学表达和训练设置，而非多智能体系统中的协作或通信机制。 综上所述，该论文属于多模态模型训练与生成理论的研究，偏离了“LLM智能体及其演化”这一核心课题。"
    },
    {
        "index": "#11",
        "title": "Rapid Augmentations for Time Series (RATS): A High-Performance Library for Time Series Augmentation",
        "link": "/arxiv/2601.03159",
        "arxiv_id": "2601.03159",
        "authors": "Wadie Skaf, Felix Kern, Aryamaan Basu Roy, Tejas Pradhan, Roman Kalkreuth, Holger Hoos",
        "subjects": "Machine Learning, Artificial Intelligence, Performance",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.193153",
        "filter_reason": "这篇论文的核心贡献是开发了一个名为 RATS 的高性能时间序列增强库，主要关注的是软件工程的性能优化（使用 Rust 重写以提升速度和减少内存占用）。 根据筛选标准进行判断： 1.  **第一步（核心判断）**：该研究属于典型的“基础设施”或“部署优化”范畴，旨在解决现有 Python 库的性能瓶颈，而非构建、改进或演化 LLM 智能体。论文中完全没有涉及 LLM、Agentic AI 或智能体框架的内容。 2.  **第二步（正面指标）**：论文不包含任何关于 Agentic AI、Multi-Agent Systems、Self-Evolving、Planning、Tool Use 等核心范式或能力的描述。 3.  **第三步（排除标准）**：虽然不属于安全或多模态排除项，但它明确属于“基础设施”排除项（主要关注模型基础设施、部署优化）。 综上所述，该论文是一个关于时间序列数据处理工具的工程优化研究，与“LLM智能体及其演化”的研究课题完全无关，因此予以排除。"
    },
    {
        "index": "#12",
        "title": "Prompt-Counterfactual Explanations for Generative AI System Behavior",
        "link": "/arxiv/2601.03156",
        "arxiv_id": "2601.03156",
        "authors": "Sofie Goethals, Foster Provost, João Sedoc",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language, Computers and Society",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.193715",
        "filter_reason": "这篇论文的核心贡献在于提出了一种用于解释生成式AI系统行为的“提示词-反事实解释”框架，旨在帮助决策者理解输入提示词如何导致特定的输出特征（如毒性、偏见等）。 根据筛选标准，该论文被排除的原因如下： 1.  **触犯排除标准（第三步）**：论文的主要贡献明确属于 **Interpretability (可解释性)** 和 **Explainable AI (XAI)** 范畴。筛选标准中明确规定，只要论文的主要贡献是关于 `Interpretability` 或 `Explainability`，一律排除。 2.  **不符合核心目标（第一步）**：我的研究焦点是“构建、改进或演化 LLM智能体”。这篇论文并没有构建新的智能体架构，也没有提出多智能体协作机制或自我演化算法。它只是将生成式AI系统作为一个黑盒对象进行分析，试图解释其行为，而非改进其作为智能体的能力（如规划、工具使用或反思）。 3.  **非Agentic核心**：虽然论文提到了“prompt engineering”和“red-teaming”，但这只是其解释框架的应用场景，并非论文的核心方法论创新。论文并未涉及智能体的自主性、规划或工具使用等Agentic AI的关键特征。 综上所述，该论文属于可解释性研究，不符合关于LLM智能体构建与演化的研究范围。"
    },
    {
        "index": "#2",
        "title": "From Entropy to Epiplexity: Rethinking Information for Computationally Bounded Intelligence",
        "link": "/arxiv/2601.03220",
        "arxiv_id": "2601.03220",
        "authors": "Marc Finzi, Shikai Qiu, Yiding Jiang, Pavel Izmailov, J. Zico Kolter, Andrew Gordon Wilson",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.182091",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献不符（第一步核心判断）**： *   论文的核心贡献是提出了一种名为 \"Epiplexity\" 的新的信息论度量，用于量化计算受限的观察者能从数据中学到什么。这属于**信息论**和**数据评估/选择**的理论研究，而非构建、改进或演化 LLM 智能体的方法论或新框架。 *   论文虽然提到了“计算受限的智能”，但这指的是理论上的学习系统极限，而非具备自主规划、工具使用或反思能力的 Agentic AI 实体。 2.  **缺乏关键指标（第二步正面指标）**： *   论文中未涉及任何关于 `Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving` 的核心范式。 *   摘要中没有提及智能体的关键能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Collaboration`（协作）或 `Self-Reflection`（自我反思）。 3.  **不属于特殊例外情况（第四步）**： *   该论文不涉及智能体的推理或规划框架，也不涉及自我演化的机制。它关注的是数据本身的属性（信息含量）以及如何通过数据选择来改善泛化能力，这属于数据层面的优化，而非智能体架构或演化机制的层面。 综上所述，该论文属于基础理论或数据科学范畴，与“LLM智能体及其演化”的研究焦点无关，因此予以排除。"
    },
    {
        "index": "#15",
        "title": "Time-Aware Synthetic Control",
        "link": "/arxiv/2601.03099",
        "arxiv_id": "2601.03099",
        "authors": "Saeyoung Rho, Cyrus Illick, Samhitha Narasipura, Alberto Abadie, Daniel Hsu, Vishal Misra",
        "subjects": "Machine Learning, Econometrics, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.200682",
        "filter_reason": "这篇论文完全不符合我的研究范围。根据第一步“核心判断”，我的目标是筛选关于构建、改进或演化 LLM智能体 的论文。 1.  **核心贡献不符**: 该论文的核心贡献是提出一种名为 TASC (Time-Aware Synthetic Control) 的统计方法，用于处理时间序列面板数据的观察性因果推断。它主要依赖于状态空间模型、卡尔曼滤波和期望最大化算法，属于传统的统计学或时间序列分析领域。 2.  **缺乏 Agentic AI 元素**: 论文中没有涉及大语言模型（LLM）、智能体架构、规划、工具使用、多智能体协作或自我演化机制。 3.  **非 LLM 应用**: 虽然论文涉及应用（政策评估、体育预测），但它既没有使用 LLM 作为工具，也没有提出任何与智能体相关的框架。 因此，该论文属于因果推断和时间序列分析的基础方法研究，与 LLM智能体及其演化的研究课题无关。"
    },
    {
        "index": "#9",
        "title": "Dynamic Hyperparameter Importance for Efficient Multi-Objective Optimization",
        "link": "/arxiv/2601.03166",
        "arxiv_id": "2601.03166",
        "authors": "Daphne Theodorakopoulos, Marcel Wever, Marius Lindauer",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.191942",
        "filter_reason": "这篇论文的核心贡献是提出一种基于动态超参数重要性（HPI）的多目标优化（MOO）方法，用于加速机器学习模型的超参数搜索过程。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：论文的研究对象是“超参数优化算法”和“多目标优化（MOO）”，旨在解决模型选择中的权衡问题（如准确率与推理时间的平衡）。这属于机器学习的基础设施或优化算法范畴，而非构建、改进或演化 LLM智能体。论文中并未涉及任何智能体架构、规划、记忆或工具使用等Agentic特性。 2.  **正面指标（第二步）**：论文完全不包含 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving` 等核心范式。虽然标题中有“Multi-Objective”，但这指的是优化目标的多样性，而非“Multi-Agent”（多智能体）系统。 3.  **排除标准（第三步）**：虽然未触发安全或多模态等排除项，但其本质属于模型基础设施与优化，不符合第一步中关于“基础设施”的排除原则（主要关注模型基础设施、部署优化等的研究）。 综上所述，该论文属于传统的机器学习优化领域，与“LLM智能体及其演化”的研究课题无关，因此予以排除。"
    },
    {
        "index": "#14",
        "title": "One Sample to Rule Them All: Extreme Data Efficiency in RL Scaling",
        "link": "/arxiv/2601.03111",
        "arxiv_id": "2601.03111",
        "authors": "Yiyuan Li, Zhen Huang, Yanan Wu, Weixun Wang, Xuefeng Li, Yijia Luo, Wenbo Su, Bo Zheng, Pengfei Liu",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.194932",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为“polymath learning”（博学家学习）的框架，通过强化学习（RL）和精心设计的单个合成样本（sample engineering）来提升大语言模型的基础推理能力（如数学、物理、化学等领域的逻辑推理）。 根据筛选标准的第一步（核心判断），该论文属于“非Agentic的推理”排除类别。虽然论文涉及推理，但其重点在于通过改进训练数据和RL策略来增强模型底层的Token预测和逻辑能力，而非构建具有自主规划、工具使用、记忆或自我反思机制的智能体架构。论文中未提及任何关于Agent框架、多智能体协作或自我演化机制的内容，因此不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#13",
        "title": "PersonaLedger: Generating Realistic Financial Transactions with Persona Conditioned LLMs and Rule Grounded Feedback",
        "link": "/arxiv/2601.03149",
        "arxiv_id": "2601.03149",
        "authors": "Dehao Yuan, Tyler Farnan, Stefan Tesliuc, Doron L Bergman, Yulun Wu, Xiaoyu Liu, Minghui Liu, James Montgomery, Nam H Nguyen, C. Bayan Bruss, Furong Huang",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.194312",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 \"PersonaLedger\" 的生成引擎，用于生成**合成金融交易数据**（Synthetic Financial Transactions）。 根据筛选标准的第一步（核心判断），该论文属于**排除**类别中的“非演化型应用”。具体分析如下： 1.  **本质是应用而非智能体构建**：论文虽然使用了LLM，并将其与规则引擎结合形成闭环，但其目的是为了解决金融领域的数据隐私和稀缺问题，生成逼真的交易数据集，而不是为了构建、改进或演化一个具有自主规划、工具使用或自我反思能力的LLM智能体。 2.  **缺乏Agentic核心特征**：尽管文中提到了LLM与引擎的交互，但这属于数据生成的模拟机制，而非智能体的自主决策或任务执行过程。论文并未涉及智能体的规划、记忆机制、多智能体协作或自我演化等核心Agentic AI研究方向。 3.  **特定领域应用**：论文明确指出其目标是支持“金融AI”中的预测和异常检测模型评估，这完全符合“将LLM应用到特定领域（金融）去解决该领域问题”的排除标准。 综上所述，该论文属于数据生成与金融应用范畴，不符合关于“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#18",
        "title": "Audit Me If You Can: Query-Efficient Active Fairness Auditing of Black-Box LLMs",
        "link": "/arxiv/2601.03087",
        "arxiv_id": "2601.03087",
        "authors": "David Hartmann, Lena Pohlmann, Lelia Hanslik, Noah Gießing, Bettina Berendt, Pieter Delobelle",
        "subjects": "Machine Learning, Computation and Language, Computers and Society",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.202355",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 BAFA 的算法，用于对黑盒 LLM 进行高效的公平性审计。它主要关注如何通过主动查询来评估 LLM 的偏见和公平性指标。 根据筛选标准，该论文不符合我的研究目标，原因如下： 1.  **触犯排除标准（第三步）**：论文的主要贡献集中在 **Fairness Auditing**（公平性审计）和 **Bias**（偏见）检测上。这属于 **Safety**（安全）和 **Alignment**（对齐）的研究范畴。根据指令，只要论文的主要贡献是关于安全、对齐或相关伦理指标的，一律排除。 2.  **不符合核心判断（第一步）**：论文的本质不是构建、改进或演化 LLM 智能体，而是对现有的 LLM 进行评估和测试。它不涉及智能体的规划、工具使用、多智能体协作或自我演化机制。 因此，尽管这是一篇关于 LLM 的研究，但其焦点在于评估模型的社会属性（公平性）而非构建 Agentic 能力，故予以排除。"
    },
    {
        "index": "#16",
        "title": "From Muscle to Text with MyoText: sEMG to Text via Finger Classification and Transformer-Based Decoding",
        "link": "/arxiv/2601.03098",
        "arxiv_id": "2601.03098",
        "authors": "Meghna Roy Chowdhury, Shreyas Sen, Yi Ding",
        "subjects": "Machine Learning, Neural and Evolutionary Computing",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.201297",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 MyoText 的分层框架，用于将表面肌电图信号转换为文本，旨在解决可穿戴和混合现实系统中的无键盘文本输入问题。 根据筛选标准，该论文不符合研究要求，具体原因如下： 1.  **属于非演化型应用**：论文的研究重点在于生物医学信号处理（sEMG）与人机交互（HCI）领域的应用。虽然它使用了 Transformer (T5) 模型来重构句子，但这仅是将其作为序列生成的工具，而非构建具有自主性、规划能力或工具使用能力的 LLM 智能体。这完全符合第一步排除标准中的“非演化型应用”（将模型应用到特定领域解决该领域问题）。 2.  **缺乏 Agentic 核心要素**：论文中未涉及任何智能体的关键特性，如自主规划、记忆机制、工具使用、自我反思或多智能体协作。 3.  **非自我演化**：论文的方法论是基于监督学习的分类和生成（CNN-BiLSTM + T5），不包含通过经验、反思或环境反馈进行自我完善和迭代的演化机制。 综上所述，该论文属于特定领域的应用技术研究，而非关于 LLM 智能体构建或演化的研究，因此予以排除。"
    },
    {
        "index": "#21",
        "title": "When the Coffee Feature Activates on Coffins: An Analysis of Feature Extraction and Steering for Mechanistic Interpretability",
        "link": "/arxiv/2601.03047",
        "arxiv_id": "2601.03047",
        "authors": "Raphael Ronge, Markus Maier, Frederick Eberhardt",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.203897",
        "filter_reason": "这篇论文的核心贡献在于对**机制可解释性**和**AI安全**的研究，具体涉及使用稀疏自编码器（SAEs）进行特征提取和特征引导，并评估其在安全监督中的可靠性。 根据筛选标准，判断过程如下： 1.  **核心判断（第一步）**：论文的本质并非构建、改进或演化LLM智能体，而是试图通过分析神经激活模式来理解和控制模型的内部行为。 2.  **排除标准（第三步）**：这是最关键的排除依据。筛选标准明确规定，只要论文的主要贡献是关于 `Safety`（安全）、`Interpretability`（可解释性）或 `Explainability (XAI)`，一律排除。该论文标题和摘要均明确指出其研究重点是 \"Mechanistic Interpretability\"（机制可解释性）和 \"AI safety\"（AI安全），旨在解决人类监督和安全关键应用中的问题，而非提升智能体的规划、工具使用、协作或自我演化能力。 3.  **焦点不符**：论文虽然提到了 \"control of model output\"（模型输出的控制），但这属于安全对齐领域的控制，而非Agentic AI中智能体自主规划或执行任务的能力。 综上所述，该论文属于被明确排除的“安全与对齐”及“可解释性”范畴，不符合关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#19",
        "title": "Real-Time Adaptive Anomaly Detection in Industrial IoT Environments",
        "link": "/arxiv/2601.03085",
        "arxiv_id": "2601.03085",
        "authors": "Mahsa Raeiszadeh, Amin Ebrahimzadeh, Roch H. Glitho, Johan Eker, Raquel A. F. Mini",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.202843",
        "filter_reason": "这篇论文不符合研究范围，具体判断依据如下： 1.  **核心贡献不符（第一步核心判断）**： *   论文的核心是提出一种用于**工业物联网 (IIoT)** 环境下的**实时异常检测**算法。 *   该方法结合了多源预测模型和概念漂移适应技术，旨在解决特定领域（工业网络、数据流）的数据处理问题。 *   这完全属于**非演化型应用**，即利用机器学习技术解决特定垂直领域的问题，而非构建、改进或演化 LLM 智能体。 2.  **缺乏核心关注点（第二步正面指标）**： *   论文中未提及任何关于 `LLM-based Agents`、`Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving` 的内容。 *   论文不涉及智能体的关键能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Reflection`（自我反思）。 3.  **技术路线偏差**： *   论文关注的是传统的数据流分析、预测模型和概念漂移处理，属于数据挖掘或时间序列分析范畴，与基于大语言模型的智能体架构或演化机制无关联。 综上所述，该论文属于特定领域的应用研究，不涉及 LLM 智能体的构建或演化，因此予以排除。"
    },
    {
        "index": "#24",
        "title": "Multi-Distribution Robust Conformal Prediction",
        "link": "/arxiv/2601.02998",
        "arxiv_id": "2601.02998",
        "authors": "Yuqi Yang, Ying Jin",
        "subjects": "Machine Learning, Methodology, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.205501",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“多分布鲁棒共形预测”的统计机器学习方法，旨在解决在多个异构源分布下构建具有有限样本覆盖保证的预测集问题。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：论文的研究重点是“共形预测”和“分布鲁棒性”，属于机器学习理论中的不确定性量化范畴。它并不涉及构建、改进或演化 LLM 智能体，也没有提出任何关于 Agentic AI、Multi-Agent Systems 或 Self-Evolving 的方法论或框架。 2.  **正面指标（第二步）**：论文中完全没有出现“Agentic AI”、“Planning”、“Tool Use”、“Multi-Agent”、“Self-Evolving”等核心关键词，也不涉及智能体的规划、记忆、工具使用或协作能力。 3.  **排除标准（第三步）**：虽然论文提到了“fairness”（公平性），但这并非其作为安全/对齐研究被排除的主要原因，主要原因在于其本质是统计预测理论，与“LLM智能体及其演化”这一研究课题完全无关。 综上所述，该论文属于机器学习理论/统计学习方法研究，不符合关于 LLM 智能体及其演化的研究目标，因此予以排除。"
    },
    {
        "index": "#10",
        "title": "On the Convergence Behavior of Preconditioned Gradient Descent Toward the Rich Learning Regime",
        "link": "/arxiv/2601.03162",
        "arxiv_id": "2601.03162",
        "authors": "Shuai Jiang, Alexey Voronin, Eric Cyr, Ben Southworth",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.192442",
        "filter_reason": "这篇论文的核心贡献在于研究预条件梯度下降（PGD）对神经网络的谱偏差和“顿悟”现象的影响，属于优化理论和神经网络学习动力学的范畴。 根据筛选标准进行判断： 1.  **第一步（核心判断）**：论文的本质是分析优化算法（PGD）的收敛行为和神经网络的泛化机制，而非构建、改进或演化 LLM智能体。它不涉及智能体的架构设计、多智能体交互或自我演化的方法论。这属于基础理论或基础设施层面的研究，而非 Agentic AI 的应用。 2.  **第二步（正面指标）**：论文中未出现任何关于 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Planning`、`Tool Use` 或 `Self-Reflection` 等核心范式或能力的指标。 3.  **第三步（排除标准）**：虽然论文未涉及安全、对齐或多模态，但其研究焦点（优化动力学、谱偏差、NTK regime）完全偏离了“LLM智能体及其演化”这一研究课题。 综上所述，该论文是一篇关于神经网络优化理论的基础研究，不符合关于 LLM智能体构建与演化的研究目标。"
    },
    {
        "index": "#29",
        "title": "RPIQ: Residual-Projected Multi-Collaboration Closed-Loop and Single Instance Quantization for Visually Impaired Assistance",
        "link": "/arxiv/2601.02888",
        "arxiv_id": "2601.02888",
        "authors": "Xuanyu Wang, Haisen Su, Jingtao Zhang, Xiangxiang Wang, Yongbin Yu, Manping Fan, Bo Gong, Siqi Chen, Mingsheng Cao, Liyong Ren",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.213511",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为 RPIQ 的**量化框架**，旨在解决大模型在辅助设备上部署时的内存消耗和推理成本问题。 根据筛选标准，我的判断过程如下： 1.  **第一步（核心判断）- 排除基础设施与部署优化**： 论文的研究重点是模型压缩、量化策略以及计算效率的提升（如将模型压缩至4位、减少峰值内存）。这完全属于**基础设施**和**部署优化**的范畴，而非构建、改进或演化 LLM 智能体的方法论。因此，根据第一步的排除标准第3条，应予以排除。 2.  **第二步（正面指标）- 缺乏Agentic核心要素**： 尽管论文标题中包含 \"Multi-Collaboration\"（多协作），但摘要明确解释这是指量化过程中的“多协作闭环补偿方案”，属于数学算法层面的迭代优化，而非“多智能体系统”中智能体之间的协作、通信或博弈。论文未涉及智能体的规划、工具使用、记忆或自我反思等核心能力。 3.  **第三步（排除标准）- 应用非核心**： 虽然论文的应用场景是“视障辅助”，但这只是量化技术的一个应用落地案例，论文并未提出针对该场景的新型智能体架构或演化机制。 综上所述，该论文属于模型工程与部署优化领域，不符合“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#20",
        "title": "Joint Encoding of KV-Cache Blocks for Scalable LLM Serving",
        "link": "/arxiv/2601.03067",
        "arxiv_id": "2601.03067",
        "authors": "Joseph Kampeas, Emir Haleva",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.203358",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为“联合编码”的方法，用于压缩LLM推理过程中的KV-Cache（键值缓存），旨在解决内存瓶颈并提高高并发场景下的服务吞吐量。 根据筛选标准第一步（核心判断），该研究明确属于“基础设施”和“部署优化”范畴。它关注的是模型服务的底层效率、内存管理和硬件资源利用，而非构建、改进或演化LLM智能体的方法论或新框架。 此外，论文中未涉及任何关于智能体的规划、工具使用、自我反思、多智能体协作或自我演化机制（第二步正面指标）。尽管KV-Cache是LLM推理的一部分，但对其进行压缩优化属于系统工程问题，与“Agentic AI”的研究焦点（智能体的行为、架构与演化）无关。 因此，该论文不符合“LLM智能体及其演化”的研究范围，应予以排除。"
    },
    {
        "index": "#30",
        "title": "Domain Generalization for Time Series: Enhancing Drilling Regression Models for Stick-Slip Index Prediction",
        "link": "/arxiv/2601.02884",
        "arxiv_id": "2601.02884",
        "authors": "Hana Yahia, Bruno Figliuzzi, Florent Di Meglio, Laurent Gerbaud, Stephane Menand, Mohamed Mahjoub",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.214085",
        "filter_reason": "这篇论文的核心贡献是针对钻井工程中的时间序列数据，比较和应用域泛化技术（如对抗域泛化ADG和不变风险最小化IRM）来预测粘滑指数（SSI）。这是一个典型的特定领域应用研究，属于石油工程或工业时间序列分析范畴。 根据筛选标准第一步（核心判断），该论文明确属于“非演化型应用”的排除类别。它将机器学习回归模型作为工具应用到钻井这一特定领域，旨在解决该领域的振动预测问题，而非构建、改进或演化LLM智能体。 此外，论文中完全不涉及LLM、Agentic AI、多智能体系统或自我演化机制。虽然提到了迁移学习，但这仅是模型训练策略的一部分，用于提高模型在不同油井上的泛化性能，并不等同于智能体的自我演化或迭代改进框架。因此，该论文完全不符合“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#31",
        "title": "Quantum-Enhanced Neural Contextual Bandit Algorithms",
        "link": "/arxiv/2601.02870",
        "arxiv_id": "2601.02870",
        "authors": "Yuqi Huang, Vincent Y. F Tan, Sharu Theresa Jose",
        "subjects": "Machine Learning, Information Theory, Quantum Physics",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.214635",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心领域不匹配 (第一步 - 核心判断)**: *   论文的核心研究对象是 **量子神经网络** 和 **上下文老虎机** 算法，而非 **大语言模型 (LLM)**。我的研究课题明确限定为 \"LLM智能体及其演化\"，该论文完全不涉及LLM作为智能体核心组件的构建或应用。 2.  **缺乏Agentic AI的关键特征 (第一步 & 第二步)**: *   虽然上下文老虎机属于序列决策问题，但该论文的重点在于提出一种名为 `QNTK-UCB` 的算法，利用量子神经正切核来解决量子神经网络训练中的不稳定性和参数缩放问题。 *   论文未涉及智能体的核心能力，如 **规划**、**工具使用**、**记忆** 或 **自我反思**。它侧重于底层算法的数学优化和理论分析（如遗憾界限 Regret bounds），而非智能体的架构设计或行为演化。 3.  **不属于自我演化或多智能体系统 (第一步 & 第二步)**: *   论文虽然提到了算法的改进，但这属于优化算法层面的提升，而非智能体通过经验、反思或环境反馈进行的 **自我演化**。 *   论文未涉及 **多智能体协作**、通信或博弈。 综上所述，这是一篇关于量子计算与强化学习算法交叉领域的理论性论文，属于基础算法优化范畴，与LLM智能体的构建、改进或演化无关。因此，应予以排除。"
    },
    {
        "index": "#32",
        "title": "Electricity Price Forecasting: Bridging Linear Models, Neural Networks and Online Learning",
        "link": "/arxiv/2601.02856",
        "arxiv_id": "2601.02856",
        "authors": "Btissame El Mahtout, Florian Ziel",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.215178",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献不匹配 (第一步 - 核心判断)**： *   该论文的核心贡献是提出一种结合线性和非线性结构的新型**多变量神经网络方法**，用于解决**电力价格预测**这一特定领域的问题。 *   这完全属于**非演化型应用**。论文利用神经网络作为预测工具，而非构建或演化具有自主性的 LLM 智能体。 2.  **缺乏 Agentic AI 核心要素 (第二步 - 正面指标)**： *   论文中未涉及任何关于 `Agentic AI`、`LLM-based Agents` 或 `Multi-Agent Systems` 的概念。 *   论文关注的是预测精度（RMSE/MAE）和计算成本，而非智能体的核心能力如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Reflection`（自我反思）。 3.  **技术路线偏差**： *   论文讨论的是传统的神经网络结构和在线学习在时间序列预测中的应用，而非基于 LLM 的智能体架构或演化机制。 综上所述，该论文是一篇典型的能源/金融领域的时间序列预测应用论文，与“LLM智能体及其演化”的研究课题无关，因此予以排除。"
    },
    {
        "index": "#33",
        "title": "Stratified Hazard Sampling: Minimal-Variance Event Scheduling for CTMC/DTMC Discrete Diffusion and Flow Models",
        "link": "/arxiv/2601.02799",
        "arxiv_id": "2601.02799",
        "authors": "Seunghwan Jang, SooJean Han",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.215913",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献不符 (第一步 - 核心判断)**： *   该论文的核心贡献是提出了一种名为 \"Stratified Hazard Sampling (SHS)\" 的**采样算法**（Inference Principle），用于优化基于 CTMC/DTMC 的离散扩散模型和流匹配模型的生成过程。 *   它解决的是生成模型推理过程中的**方差问题**（variance in the number and timing of edits），旨在提高生成的稳定性和质量，而非构建、改进或演化 LLM 智能体。 2.  **属于基础设施/推理优化而非 Agentic AI (第一步 & 第三步 - 排除标准)**： *   这篇论文属于生成式模型的基础算法研究，更偏向于**模型基础设施**或**推理优化**（Inference Optimization），而非 Agentic AI 的方法论。 *   虽然摘要中提到了 \"self-correction\"（自我修正），但在这里它指的是数学模型中 token 替换的机制（即模型如何修正噪声），而不是智能体在任务执行中的自我反思或自我修正能力。 3.  **缺乏关键指标 (第二步 - 正面指标)**： *   论文中没有涉及任何关于智能体规划、工具使用、记忆机制、多智能体协作或自我演化框架的内容。 综上所述，该论文是关于生成模型底层采样技术的改进，与 LLM 智能体及其演化的研究课题无关，因此予以排除。"
    },
    {
        "index": "#28",
        "title": "Bridging Mechanistic Interpretability and Prompt Engineering with Gradient Ascent for Interpretable Persona Control",
        "link": "/arxiv/2601.02896",
        "arxiv_id": "2601.02896",
        "authors": "Harshvardhan Saini, Yiming Tang, Dianbo Liu",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.212919",
        "filter_reason": "这篇论文的核心贡献在于提出一种基于梯度上升的提示工程方法，用于控制和解释大语言模型的行为人设（如阿谀奉承、幻觉等）。 根据筛选标准，我的判断过程如下： 1.  **核心判断（第一步）**：论文的本质是关于“机制可解释性”和“提示工程”的结合，旨在解决模型行为控制问题，而非构建、改进或演化LLM智能体的架构或框架。它不属于Agentic AI、多智能体系统或自我演化的方法论研究。 2.  **排除标准（第三步）**：这是最关键的排除依据。论文摘要中明确提到其研究背景是“**AI safety**”（AI安全），并致力于解决“**sycophancy**”（阿谀奉承）和“**hallucination**”（幻觉）问题。同时，论文强调“**mechanistic interpretability**”（机制可解释性）和“**interpretable persona control**”（可解释的人设控制）。根据筛选标准，只要论文的主要贡献涉及 Safety、Interpretability、Explainability 或 Hallucination，一律排除。 3.  **研究焦点不符**：我的研究焦点是智能体的规划、工具使用、多智能体协作及自我演化机制。而该论文关注的是如何通过优化提示词来对齐模型的内部表征，属于模型安全与对齐领域，与Agentic AI的核心能力（如自主规划、工具调用、多步推理框架）无直接关联。 综上所述，该论文属于安全与对齐方向的研究，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#17",
        "title": "ATLAS: Adaptive Test-Time Latent Steering with External Verifiers for Enhancing LLMs Reasoning",
        "link": "/arxiv/2601.03093",
        "arxiv_id": "2601.03093",
        "authors": "Tuc Nguyen, Thai Le",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.201788",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#22",
        "title": "Causal Manifold Fairness: Enforcing Geometric Invariance in Representation Learning",
        "link": "/arxiv/2601.03032",
        "arxiv_id": "2601.03032",
        "authors": "Vidhi Rathore",
        "subjects": "Machine Learning, Artificial Intelligence, Computers and Society",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.204392",
        "filter_reason": "这篇论文不符合研究范围，具体判断依据如下： 1.  **核心判断 (第一步 - 排除)**: 论文的核心贡献是提出 \"Causal Manifold Fairness (CMF)\"，这是一个结合了因果推断和几何深度学习的表征学习框架，旨在解决机器学习中的公平性问题。这属于基础的机器学习算法和表征学习研究，而非关于构建、改进或演化 LLM智能体 的方法论。 2.  **排除标准 (第三步 - 安全与对齐)**: 论文的主要研究目标是 \"Fairness\"（公平性），即消除模型对敏感属性（如种族、性别）的偏见。在人工智能研究中，公平性通常被归类为 AI Safety（安全）、Security（安全）或 Alignment（对齐）的子领域。根据筛选标准，只要论文的主要贡献涉及对齐或安全，一律排除。 3.  **缺乏正面指标 (第二步)**: 论文中未出现任何关于 Agentic AI、LLM-based Agents、Multi-Agent Systems 或 Self-Evolving 的核心范式或关键词。它不涉及智能体的规划、工具使用、记忆、多智能体协作或自我演化机制。 综上所述，该论文属于算法公平性与表征学习领域，与 \"LLM智能体及其演化\" 的研究课题无关，因此予以排除。"
    },
    {
        "index": "#37",
        "title": "CRoPE: Efficient Parametrization of Rotary Positional Embedding",
        "link": "/arxiv/2601.02728",
        "arxiv_id": "2601.02728",
        "authors": "Beicheng Lou, Zifei Xu",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.223461",
        "filter_reason": "该论文的核心贡献在于提出了一种新的旋转位置编码参数化方法，旨在通过复数线性变换减少Transformer模型注意力块中的参数数量，从而提高模型的参数效率。这属于基础模型架构优化或模型基础设施层面的研究，而非构建、改进或演化LLM智能体的方法论。论文未涉及智能体的规划、工具使用、记忆、多智能体协作或自我演化等Agentic AI的核心要素，因此根据筛选标准第一步中的“基础设施”排除规则，该论文不符合研究目标。"
    },
    {
        "index": "#23",
        "title": "In-Context Reinforcement Learning through Bayesian Fusion of Context and Value Prior",
        "link": "/arxiv/2601.03015",
        "arxiv_id": "2601.03015",
        "authors": "Anaïs Berkes, Vincent Taboga, Donna Vakalis, David Rolnick, Yoshua Bengio",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.204997",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#36",
        "title": "Scalable Tree Ensemble Proximities in Python",
        "link": "/arxiv/2601.02735",
        "arxiv_id": "2601.02735",
        "authors": "Adrien Aumon, Guy Wolf, Kevin R. Moon, Jake S. Rhodes",
        "subjects": "Machine Learning, Data Structures and Algorithms, Performance",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.223003",
        "filter_reason": "1.  **核心贡献分析**: 该论文的核心贡献是针对传统机器学习中的“树集成方法”（如随机森林），提出了一种名为“可分离加权叶碰撞邻近度”的数学框架。其目的是通过稀疏矩阵分解来优化相似度计算的效率和内存占用，属于传统机器学习算法优化的范畴。 2.  **不符合研究目标**: 我的研究课题是“LLM智能体及其演化”，核心关注点必须是基于大语言模型（LLM）的智能体构建、多智能体系统或自我演化机制。 3.  **筛选判定**: *   **第一步（核心判断）**: 该论文完全不涉及构建LLM智能体、多智能体系统或自我演化。它既不是关于LLM的应用，也不是关于LLM的基础设施，而是关于传统统计机器学习模型（随机森林）的计算优化。因此，它属于非相关领域。 *   **第二步（正面指标）**: 论文中没有出现任何与Agentic AI、LLM、Planning、Tool Use或Multi-Agent相关的关键词或概念。 综上所述，该论文属于传统机器学习算法研究，与LLM智能体及其演化的研究范围无关，故排除。"
    },
    {
        "index": "#38",
        "title": "Scaling Laws of Machine Learning for Optimal Power Flow",
        "link": "/arxiv/2601.02706",
        "arxiv_id": "2601.02706",
        "authors": "Xinyi Liu, Xuan He, Yize Chen",
        "subjects": "Machine Learning, Systems and Control",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.223949",
        "filter_reason": "这篇论文的核心贡献是研究机器学习（具体是深度神经网络 DNNs 和物理信息神经网络 PINNs）在电力系统“最优潮流”（OPF）任务中的缩放定律，即数据规模和计算资源如何影响模型的预测误差、约束违反和速度。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：该论文属于典型的“非演化型应用”。它将现有的机器学习模型（DNNs/PINNs）作为工具应用于特定的工程领域（电力系统），旨在解决该领域的特定问题（OPF求解速度与性能），而非构建、改进或演化 LLM 智能体。 2.  **正面指标（第二步）**：论文中未涉及任何关于 Agentic AI、LLM-based Agents、Multi-Agent Systems 或 Self-Evolving 的核心范式或能力（如规划、工具使用、自我反思等）。 3.  **排除标准（第三步）**：虽然论文未涉及安全或多模态等排除项，但其本质是特定垂直领域的应用研究，且使用的模型基础是 DNNs/PINNs 而非 LLMs，完全偏离了“LLM智能体及其演化”的研究焦点。 综上所述，该论文不符合筛选要求。"
    },
    {
        "index": "#39",
        "title": "Topology-Independent Robustness of the Weighted Mean under Label Poisoning Attacks in Heterogeneous Decentralized Learning",
        "link": "/arxiv/2601.02682",
        "arxiv_id": "2601.02682",
        "authors": "Jie Peng, Weiyu Li, Stefan Vlaski, Qing Ling",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.224459",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心贡献不匹配 (第一步 - 核心判断)**: *   论文的核心是关于**去中心化学习** 和 **分布式机器学习系统** 的算法分析，具体研究的是在标签投毒攻击下的聚合器鲁棒性。 *   虽然论文中提到了 \"agents\"（智能体），但在这里指的是分布式网络中的计算节点，而非具备感知、规划、工具使用等能力的 **LLM智能体**。这属于分布式系统或联邦学习的范畴，而非 Agentic AI。 2.  **触犯排除标准 (第三步 - 排除标准)**: *   论文的主要贡献集中在 **Safety** (安全) 和 **Security** (安全防护) 上，具体研究如何防御恶意攻击和标签投毒。根据筛选标准，只要论文的主要贡献是关于 Safety 或 Security 的，一律排除。 3.  **缺乏核心关注点 (第二步 - 正面指标)**: *   论文不涉及任何 LLM智能体的核心能力，如 `Planning` (规划)、`Tool Use` (工具使用)、`Memory` (记忆) 或 `Self-Reflection` (自我反思)。 *   论文也不涉及多智能体协作或自我演化机制，而是关注网络拓扑结构对聚合算法性能的影响。 综上所述，这是一篇关于分布式学习系统安全性的论文，而非关于构建、改进或演化 LLM智能体的研究，因此予以排除。"
    },
    {
        "index": "#27",
        "title": "ChemBART: A Pre-trained BART Model Assisting Organic Chemistry Analysis",
        "link": "/arxiv/2601.02915",
        "arxiv_id": "2601.02915",
        "authors": "Kenan Li, Yijian Zhang, Jin Wang, Haipeng Gan, Zeying Sun, Xiaoguang Lei, Hao Dong",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.212304",
        "filter_reason": "根据您的筛选标准，这篇论文**不符合**您的研究范围，具体判断过程如下： 1.  **第一步：核心判断（非演化型应用）** *   **核心贡献分析**：论文的核心在于提出了 **ChemBART**，这是一个基于化学反应数据（SMILES）进行预训练的 **BART 模型**。其主要贡献是构建了一个特定领域的语言模型，以解决有机化学分析中的具体任务（如前驱体预测、产率回归、分子性质分类）。 *   **判定**：这属于典型的“非演化型应用”。论文虽然使用了强化学习和蒙特卡洛树搜索（MCTS）来辅助合成路线设计，但这些是化学规划（CASP）领域的常规技术手段，并非论文提出的创新性智能体框架。论文的本质是将 LLM 应用于化学领域，而非构建或演化通用的 LLM 智能体。 2.  **第二步：正面指标（缺乏 Agentic 核心要素）** *   论文虽然涉及了“规划”（合成路线设计），但这属于特定领域的优化问题，而非通用的智能体自主规划能力研究。 *   论文中未体现您关注的核心 Agentic 范式，如 `Tool Use`（除了作为化学任务一部分的 MCTS 外，没有通用工具使用机制）、`Memory`、`Self-Reflection` 或 `Multi-Agent Collaboration`。 3.  **第四步：特殊与模糊情况处理** *   **推理/规划**：虽然论文提到了多步合成路线设计，但这属于化学领域的特定任务求解，而非关于智能体如何进行复杂推理或规划的方法论创新。论文的重点在于“预训练模型”本身，而非智能体的“规划框架”。 **结论**：该论文属于**垂直领域（化学）的专用模型应用**，而非关于 LLM 智能体架构、多智能体系统或自我演化机制的研究，因此予以排除。"
    },
    {
        "index": "#41",
        "title": "MAFS: Multi-head Attention Feature Selection for High-Dimensional Data via Deep Fusion of Filter Methods",
        "link": "/arxiv/2601.02668",
        "arxiv_id": "2601.02668",
        "authors": "Xiaoyan Sun, Qingyu Meng, Yalu Wen",
        "subjects": "Machine Learning, Methodology",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.225617",
        "filter_reason": "1.  **核心贡献分析**: 该论文提出了一种名为 MAFS 的特征选择框架，旨在解决高维生物医学数据（如癌症基因表达、阿尔茨海默病数据）中的特征筛选问题。其核心创新在于结合了统计先验与多头注意力机制，以提高特征选择的稳定性、可解释性和非线性建模能力。 2.  **第一步判断 (核心判断)**: 论文明确属于 **\"非演化型应用\" (Non-Evolving Applications)**。虽然论文使用了深度学习技术（多头注意力），但它并非关于构建、改进或演化 LLM 智能体。相反，它是将一个算法框架应用到了特定的垂直领域（生物医学/精准医疗）去解决该领域的数据处理问题，完全不符合 \"LLM智能体及其演化\" 的核心目标。 3.  **第二步与第三步判断**: 论文中未包含任何关于 Agentic AI、Multi-Agent Systems 或 Self-Evolving 的核心范式或能力（如规划、工具使用、协作、自我反思等）。它关注的是数据挖掘层面的特征工程，而非智能体的架构设计或演化机制。 4.  **结论**: 该论文的研究焦点是生物医学数据特征选择方法，与 LLM 智能体的构建、多智能体系统或自我演化机制无关，因此予以排除。"
    },
    {
        "index": "#42",
        "title": "When Prompting Meets Spiking: Graph Sparse Prompting via Spiking Graph Prompt Learning",
        "link": "/arxiv/2601.02662",
        "arxiv_id": "2601.02662",
        "authors": "Bo Jiang, Weijun Zhao, Beibei Wang, Jin Tang",
        "subjects": "Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.226150",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 SpikingGPF (Spiking Graph Prompt Feature) 的方法，旨在利用脉冲神经元机制为预训练图神经网络（GNN）学习稀疏的图提示，以解决现有图提示特征在节点特征维度上的冗余和噪声敏感问题。 根据筛选标准，该论文被排除的原因如下： 1.  **触发了明确的排除标准（图相关技术）**：我的筛选标准第三条明确指出，涉及“图神经网络等图相关技术的论文”属于排除范围。该论文的研究对象是 GNN 模型，而非 LLM 智能体。 2.  **核心贡献不匹配**：论文的核心在于改进 GNN 的提示学习和特征处理，属于图深度学习领域的模型优化，与“LLM智能体及其演化”这一核心目标无关。 3.  **缺乏 Agentic 特性**：论文未涉及智能体的规划、工具使用、记忆、多智能体协作或自我演化等关键能力。 综上所述，该论文属于图神经网络（GNN）领域的研究，不符合 LLM 智能体的研究范围。"
    },
    {
        "index": "#46",
        "title": "Threat Detection in Social Media Networks Using Machine Learning Based Network Analysis",
        "link": "/arxiv/2601.02581",
        "arxiv_id": "2601.02581",
        "authors": "Aditi Sanjay Agrawal",
        "subjects": "Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.233533",
        "filter_reason": "这篇论文不符合研究范围，具体判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献是提出一种基于人工神经网络（ANN）的机器学习框架，用于检测社交媒体网络流量中的恶意行为。这属于典型的**非演化型应用**，即将机器学习模型作为工具应用到网络安全这一特定领域，而非关于构建、改进或演化 LLM 智能体的方法论研究。 2.  **缺乏核心关注点（第二步）**：论文摘要中完全没有提及 LLM、Agentic AI、Multi-Agent Systems 或 Self-Evolving 等核心范式。它也不涉及智能体的关键能力（如规划、工具使用、记忆）或多智能体协作机制。 3.  **触犯排除标准（第三步）**：论文的主要研究焦点是网络安全中的威胁检测，属于安全领域的应用研究，且使用的是传统的 ANN 而非 LLM 智能体架构。 综上所述，该论文属于传统的网络安全应用研究，与“LLM智能体及其演化”这一课题无关，因此予以排除。"
    },
    {
        "index": "#45",
        "title": "Chronicals: A High-Performance Framework for LLM Fine-Tuning with 3.51x Speedup over Unsloth",
        "link": "/arxiv/2601.02609",
        "arxiv_id": "2601.02609",
        "authors": "Arjun S. Nair",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language, Distributed, Parallel, and Cluster Computing, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.233099",
        "filter_reason": "这篇论文的核心贡献是提出了一个名为 Chronicals 的 LLM 微调训练框架，旨在通过融合 Triton 内核、优化交叉熵计算、改进 LoRA+ 学习率以及序列打包等技术手段，解决微调过程中的内存瓶颈并显著提升训练速度（达到 3.51x 加速）。 根据筛选标准： 1.  **第一步（核心判断）**：该论文明确属于“基础设施”范畴，主要关注模型基础设施、部署优化和硬件加速（训练效率），而非构建、改进或演化 LLM 智能体的方法论。根据排除规则，此类研究应被排除。 2.  **第二步（正面指标）**：论文内容未涉及 Agentic AI、Multi-Agent Systems 或 Self-Evolving 等核心范式，也不包含规划、工具使用、自我反思或多智能体协作等智能体关键能力的研究。 3.  **第三步（排除标准）**：论文完全聚焦于训练系统的底层优化，符合“基础设施”排除标准。 综上所述，该论文虽然对 LLM 训练效率有显著提升，但与“LLM智能体及其演化”的研究课题无关，因此不符合筛选要求。"
    },
    {
        "index": "#34",
        "title": "RadioDiff-Flux: Efficient Radio Map Construction via Generative Denoise Diffusion Model Trajectory Midpoint Reuse",
        "link": "/arxiv/2601.02790",
        "arxiv_id": "2601.02790",
        "authors": "Xiucheng Wang, Peilin Zheng, Honggang Jia, Nan Cheng, Ruijin Sun, Conghao Zhou, Xuemin Shen",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.221734",
        "filter_reason": "这篇论文不符合我的研究范围，依据如下： 1.  **核心判断（非Agentic及非演化型应用）**： *   论文的核心贡献是提出了一种名为 \"RadioDiff-Flux\" 的**两阶段潜在扩散框架**，用于解决无线通信（6G）领域中的**无线电地图构建**问题。 *   这属于将生成式模型（Diffusion Models）应用于特定垂直领域（通信工程）的典型**非演化型应用**。论文关注的是如何通过复用轨迹中点来加速扩散模型的推理过程，而非构建或演化智能体。 2.  **缺乏LLM智能体要素**： *   论文的技术基础是扩散模型，而非大语言模型（LLM）。 *   论文中未涉及任何Agentic AI的核心要素，如智能体的规划、工具使用、记忆机制、自我反思或多智能体协作。 3.  **不符合自我演化定义**： *   虽然论文提到了“动态细化”和“适应动态条件”，但这指的是模型对输入信号（发射机位置、环境条件）的推理适应，而非智能体通过经验或反馈进行的**自我完善、自我迭代或演化学习**。 综上所述，该论文属于通信领域的算法优化研究，与“LLM智能体及其演化”这一课题无关，因此予以排除。"
    },
    {
        "index": "#48",
        "title": "CutisAI: Deep Learning Framework for Automated Dermatology and Cancer Screening",
        "link": "/arxiv/2601.02562",
        "arxiv_id": "2601.02562",
        "authors": "Rohit Kaushik, Eva Kaushik",
        "subjects": "Machine Learning, Image and Video Processing",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.234659",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下判断： 1.  **核心判断（第一步 - 排除非演化型应用）**：论文的核心贡献是提出一个名为 \"Conformal Bayesian Dermatological Classifier (CBDC)\" 的深度学习框架，用于**皮肤病学诊断和癌症筛查**。这是一个典型的将深度学习模型（具体为卷积神经网络 CNN）应用于特定垂直领域（医疗/生物）的研究，属于“非演化型应用”，因此应被排除。 2.  **技术路线不符**：论文明确提到其方法结合了统计学习理论、拓扑数据分析 (TDA) 和贝叶斯共形推断，并涉及卷积神经网络 (CNN) 的嵌入。这表明该研究是基于传统深度学习或计算机视觉技术，而非基于大语言模型（LLM）的智能体技术。 3.  **缺乏核心关注点（第二步）**：摘要中完全没有提及任何与 LLM智能体相关的关键词，如 `Agentic AI`、`LLM-based Agents`、`Multi-Agent`、`Self-Evolving`、`Planning`、`Tool Use` 或 `Memory` 等。 4.  **排除标准（第三步）**：虽然论文涉及了“可解释性”和“不确定性量化”，但其核心是医疗诊断应用，而非智能体的安全或对齐研究。此外，论文处理的是皮肤科图像数据，属于视觉/多模态应用范畴，且并未作为智能体感知环境的工具出现。 综上所述，该论文属于医疗AI领域的深度学习方法论研究，与“LLM智能体及其演化”这一课题无关。"
    },
    {
        "index": "#47",
        "title": "LendNova: Towards Automated Credit Risk Assessment with Language Models",
        "link": "/arxiv/2601.02573",
        "arxiv_id": "2601.02573",
        "authors": "Kiarash Shamsi, Danijel Novokmet, Joshua Peters, Mao Lin Liu, Paul K Edwards, Vahab Khoshdel",
        "subjects": "Machine Learning, Artificial Intelligence, Computational Engineering, Finance, and Science",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.234147",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心判断（第一步 - 排除非演化型应用）**： 论文的核心贡献是提出了一个名为 \"LendNova\" 的自动化端到端流水线，用于解决金融领域的特定问题——信用风险评估。虽然它利用了语言模型来处理原始文本并替代传统的特征工程，但其本质是将LLM作为一种工具应用到垂直领域（金融），而非构建、改进或演化LLM智能体的通用方法论或新框架。这属于典型的“非演化型应用”，因此应被排除。 2.  **缺乏Agentic核心特征（第二步 - 缺失正面指标）**： 尽管摘要中提到了“智能信用风险智能体”，但论文描述的技术细节主要集中在“自动捕获模式”、“学习相关表示”和“替代手动预处理步骤”。这些属于传统的NLP任务优化和流水线自动化，并未体现Agentic AI的核心能力，如自主规划、工具使用、记忆机制、自我反思或多智能体协作。 3.  **不符合研究目标**： 我的研究焦点在于Agentic AI的构建与演化（单智能体、多智能体、自我演化）。LendNova的目标是提高金融决策的准确性和效率，属于应用层研究，而非智能体架构或演化机制的底层研究。 综上所述，该论文属于LLM在金融领域的垂直应用，不符合“LLM智能体及其演化”的课题要求。"
    },
    {
        "index": "#49",
        "title": "Normalized Conditional Mutual Information Surrogate Loss for Deep Neural Classifiers",
        "link": "/arxiv/2601.02543",
        "arxiv_id": "2601.02543",
        "authors": "Linfeng Ye, Zhixiang Chi, Konstantinos N. Plataniotis, En-hui Yang",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Information Theory",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.235212",
        "filter_reason": "这篇论文的核心贡献是提出了一种新的信息论代理损失函数——归一化条件互信息（NCMI），作为训练深度神经网络（DNN）分类器时交叉熵（CE）的替代品，旨在提升图像识别和全幻灯片成像（WSI）等分类任务的准确率。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：该论文属于基础模型训练优化（Loss Function Design）的研究，而非构建、改进或演化 LLM智能体。它不涉及智能体的自主规划、工具使用、记忆机制或自我演化框架。 2.  **正面指标（第二步）**：论文中未包含任何关于 Agentic AI、Multi-Agent Systems、Self-Evolving、Planning、Tool Use 等核心范式或能力的讨论。 3.  **排除标准（第三步）**：虽然论文涉及图像识别（视觉领域），但根本原因在于其研究焦点是提升分类器的预测准确率，而非 Agentic AI 的架构或行为。 综上所述，该论文主要关注深度学习的基础训练理论，与“LLM智能体及其演化”的研究课题无关，因此予以排除。"
    },
    {
        "index": "#52",
        "title": "hdlib 2.0: Extending Machine Learning Capabilities of Vector-Symbolic Architectures",
        "link": "/arxiv/2601.02509",
        "arxiv_id": "2601.02509",
        "authors": "Fabio Cumbo, Kabir Dhillon, Daniel Blankenberg",
        "subjects": "Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.241935",
        "filter_reason": "这篇论文的核心贡献是扩展了一个名为 `hdlib` 的 Python 库，用于向量-符号架构（VSA）和超维计算。其主要内容包括增强监督分类、回归、聚类、图学习模型以及量子机器学习模型。 根据筛选标准，该论文被排除的原因如下： 1.  **非Agentic研究**：论文完全未涉及 LLM 智能体、多智能体系统或自我演化机制。它关注的是 VSA 这一特定的计算范式和基础机器学习算法，而非智能体的构建、规划、工具使用或演化。 2.  **基础设施/工具库**：根据第一步的排除标准，这篇论文主要关注的是一个软件库的功能扩展，属于基础设施范畴，而非智能体的方法论或新框架。 3.  **涉及图技术**：摘要中明确提到了 \"graph-based learning model\"，触发了第三步中关于“图”相关技术的排除标准。 综上所述，该论文属于基础计算架构和机器学习库的更新，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#44",
        "title": "Credit Assignment via Neural Manifold Noise Correlation",
        "link": "/arxiv/2601.02636",
        "arxiv_id": "2601.02636",
        "authors": "Byungwoo Kang, Maceo Richards, Bernardo Sabatini",
        "subjects": "Machine Learning, Artificial Intelligence, Neurons and Cognition",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.232439",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“神经流形噪声相关性 (NMNC)”的方法，用于解决神经网络中的信用分配问题。这属于底层机器学习算法和神经科学启发式学习机制的范畴，主要关注的是神经元和突触层面的梯度估计与优化。 根据筛选标准的第一步（核心判断），该论文不符合“构建、改进或演化 LLM智能体”的要求。它既没有涉及LLM智能体的架构设计（如规划、记忆、工具使用），也没有涉及多智能体系统或智能体层面的自我演化机制。虽然论文讨论了“学习”和“演化”的概念，但这是指网络参数的优化过程，而非Agentic AI中的智能体自我完善或迭代。此外，论文主要在CIFAR-10和ImageNet等视觉数据集上进行验证，与LLM智能体的研究焦点无关。因此，该论文应被排除。"
    },
    {
        "index": "#35",
        "title": "Q-Regularized Generative Auto-Bidding: From Suboptimal Trajectories to Optimal Policies",
        "link": "/arxiv/2601.02754",
        "arxiv_id": "2601.02754",
        "authors": "Mingming Zhang, Na Li, Zhuang Feiqing, Hongyang Zheng, Jiangbing Zhou, Wang Wuyin, Sheng-jie Sun, XiaoWei Chen, Junxiong Zhu, Lixin Zou, Chenliang Li",
        "subjects": "Machine Learning, Artificial Intelligence, Information Retrieval",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.222444",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#55",
        "title": "mHC-GNN: Manifold-Constrained Hyper-Connections for Graph Neural Networks",
        "link": "/arxiv/2601.02451",
        "arxiv_id": "2601.02451",
        "authors": "Subhankar Mishra",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.243416",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 mHC-GNN 的图神经网络架构，旨在解决图神经网络中的过平滑问题并提高其表达能力。 根据筛选标准，该论文被排除的原因如下： 1.  **触犯明确的排除标准（第三步）**：我的筛选标准中明确指出，涉及“图神经网络等图相关技术的论文”属于排除范围。这篇论文完全专注于 GNN 架构的改进。 2.  **核心判断不符（第一步）**：论文的本质是深度学习模型架构层面的优化（针对 GNN 的连接方式和流混合矩阵），而非构建、改进或演化 LLM 智能体。它不涉及智能体的规划、工具使用、记忆或多智能体协作等 Agentic AI 的核心要素。 3.  **缺乏正面指标（第二步）**：论文中未出现任何关于 LLM-based Agents、Multi-Agent Systems 或 Self-Evolving 的核心范式或关键词。 综上所述，该论文属于图深度学习领域的基础架构研究，与 LLM 智能体及其演化的研究课题无关。"
    },
    {
        "index": "#54",
        "title": "Polynomial Convergence of Riemannian Diffusion Models",
        "link": "/arxiv/2601.02499",
        "arxiv_id": "2601.02499",
        "authors": "Xingyu Xu, Ziyi Zhang, Yorie Nakahira, Guannan Qu, Yuejie Chi",
        "subjects": "Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.242949",
        "filter_reason": "这篇论文的核心贡献在于对**黎曼流形上的扩散模型**进行理论数学分析，证明了其在特定条件下的多项式收敛性。 根据筛选标准，我的判断过程如下： 1.  **核心判断（第一步）**：论文的研究对象是**扩散模型**的数学理论（收敛性证明、采样误差分析），而非**LLM智能体**。它不涉及构建、改进或演化智能体的方法论或新框架。这属于生成式模型的基础理论或数学分析范畴，而非Agentic AI的研究。 2.  **正面指标（第二步）**：论文中未出现任何关于 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use` 或 `Memory` 等核心范式或能力的描述。 3.  **排除标准（第三步）**：虽然扩散模型是现代AI的一部分，但本文主要关注的是数学性质（收敛率、步长、流形几何），而非智能体的应用或架构。它不属于我的研究焦点（单智能体、多智能体、自我演化）。 综上所述，该论文属于生成式模型的基础数学理论研究，与“LLM智能体及其演化”这一课题无关，因此予以排除。"
    },
    {
        "index": "#40",
        "title": "Uni-FinLLM: A Unified Multimodal Large Language Model with Modular Task Heads for Micro-Level Stock Prediction and Macro-Level Systemic Risk Assessment",
        "link": "/arxiv/2601.02677",
        "arxiv_id": "2601.02677",
        "authors": "Gongao Zhang, Haijiang Zeng, Lu Jiang",
        "subjects": "Machine Learning, Risk Management, Statistical Finance",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.225105",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心判断（第一步）：属于“非演化型应用”** 论文的核心贡献是构建一个名为 Uni-FinLLM 的**多模态大语言模型**，旨在解决金融领域的特定任务（股票预测、信用风险评估、系统性风险检测）。虽然它使用了LLM作为backbone，但其本质是将LLM作为一种工具应用于垂直领域（金融），而非提出新的LLM智能体构建方法、多智能体协作框架或自我演化机制。这符合第一步中的排除标准：“如果论文只是将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。 2.  **排除标准（第三步）：涉及“多模态与视觉”** 论文明确提出了“Unified Multimodal Large Language Model”（统一多模态大语言模型），其核心创新点在于处理文本、数值时间序列和视觉数据。根据筛选标准，涉及多模态（特别是视觉）且核心贡献在于多模态融合而非智能体架构的论文应当被排除。 3.  **缺乏核心关注点（第二步）** 论文中没有体现任何关于 Agentic AI 的核心特征，如智能体的规划、工具使用、记忆、自我反思，也没有涉及多智能体协作或自我演化机制。它主要关注的是通过跨模态注意力和多任务优化来提高预测准确率，属于预测模型而非智能体系统。 综上所述，该论文是一篇典型的金融垂直领域的多模态模型应用研究，不属于 LLM智能体及其演化的研究范畴。"
    },
    {
        "index": "#59",
        "title": "Shallow-circuit Supervised Learning on a Quantum Processor",
        "link": "/arxiv/2601.03235",
        "arxiv_id": "2601.03235",
        "authors": "Luca Candelori, Swarnadeep Majumder, Antonio Mezzacapo, Javier Robledo Moreno, Kharen Musaelian, Santhanam Nagarajan, Sunil Pinnamaneni, Kunal Sharma, Dario Villani",
        "subjects": "Quantum Physics, Machine Learning, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.245724",
        "filter_reason": "这篇论文完全不符合我的研究范围，具体判断依据如下： 1.  **核心领域不符（第一步）**：该论文的核心贡献是提出一种基于线性哈密顿量的量子机器学习方法，并在量子处理器上进行实验。这属于量子计算和量子机器学习领域，而非大语言模型（LLM）或智能体领域。论文未涉及构建、改进或演化 LLM智能体。 2.  **缺乏关键指标（第二步）**：论文中不包含任何关于 Agentic AI、LLM-based Agents、Multi-Agent Systems 或 Self-Evolving 的核心范式或关键词。它关注的是量子态、哈密顿量和量子对角化，而非智能体的规划、工具使用、记忆或多智能体协作。 3.  **触发排除标准（第三步）**：论文主要关注在 IBM Heron 量子处理器（硬件）上运行算法，这属于模型基础设施和硬件加速的研究范畴。根据筛选标准，主要关注模型基础设施、部署优化、硬件加速的研究应予以排除。 综上所述，该论文是一篇关于量子计算算法的论文，与“LLM智能体及其演化”这一课题无任何关联。"
    },
    {
        "index": "#58",
        "title": "Self-Supervised Learning from Noisy and Incomplete Data",
        "link": "/arxiv/2601.03244",
        "arxiv_id": "2601.03244",
        "authors": "Julián Tachella, Mike Davies",
        "subjects": "Machine Learning, Machine Learning, Image and Video Processing",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.245114",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献不匹配 (第一步 - 核心判断)**: *   论文的核心主题是利用**自监督学习** 技术来解决**逆问题**，特别是在成像领域从噪声或不完整数据中恢复信号。 *   这属于传统的机器学习、计算机视觉或信号处理范畴，而非关于构建、改进或演化 **LLM智能体** 的研究。它没有涉及智能体的架构、规划、记忆或工具使用等Agentic特性。 2.  **概念混淆 (第一步 & 第四步 - 特殊情况)**: *   虽然标题中包含 \"Self-Supervised\"（自监督），但这与我的研究焦点 \"Self-Evolving\"（自我演化）有本质区别。 *   **自监督学习**是指一种利用无标签数据进行模型训练的范式（如BERT、MAE），而**自我演化**是指智能体通过经验、反思或环境反馈在运行过程中不断完善自身的能力或策略。该论文讨论的是前者，而非后者。 3.  **属于非演化型应用 (第一步 - 排除)**: *   论文将自监督学习方法作为一种工具，应用于特定的科学工程问题（成像逆问题）。根据筛选标准，这属于将算法应用到特定领域的“非演化型应用”，应予以排除。 4.  **缺乏核心指标 (第二步 - 正面指标)**: *   论文中未出现任何关于 `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems`, `Planning`, `Tool Use` 或 `Self-Reflection` 等核心范式或能力的关键词。 综上所述，该论文是一篇关于计算机视觉/信号处理领域的自监督学习方法论文，与 LLM智能体及其演化的研究课题无关。"
    },
    {
        "index": "#43",
        "title": "Prioritized Replay for RL Post-training",
        "link": "/arxiv/2601.02648",
        "arxiv_id": "2601.02648",
        "authors": "Mehdi Fatemi",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.231881",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#53",
        "title": "GEM-Style Constraints for PEFT with Dual Gradient Projection in LoRA",
        "link": "/arxiv/2601.02500",
        "arxiv_id": "2601.02500",
        "authors": "Brian Tekmen, Jason Yin, Qianqian Tong",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.242447",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 I-GEM 的优化算法，用于在 LoRA（Low-Rank Adapter）子空间内解决持续学习中的灾难性遗忘问题。这属于模型训练优化和基础设施范畴，而非构建、改进或演化 LLM 智能体的方法论。 具体判断依据如下： 1.  **核心判断（第一步）**: 论文本质是关于参数高效微调（PEFT）和持续学习（CL）的数学优化方法（梯度投影），旨在提升训练效率和稳定性，而非构建具有自主性、规划或工具使用能力的智能体框架。 2.  **正面指标缺失（第二步）**: 论文中未涉及 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent Systems` 或 `Self-Reflection` 等智能体核心范式或能力。 3.  **排除标准（第三步）**: 该研究主要关注模型的基础设施层面（训练算法、LoRA适配器优化），而非智能体的行为或架构演化。 综上所述，尽管论文涉及“持续学习”（随时间学习），但其重点在于数学约束和计算优化，不符合“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#51",
        "title": "LLM-Enhanced Reinforcement Learning for Time Series Anomaly Detection",
        "link": "/arxiv/2601.02511",
        "arxiv_id": "2601.02511",
        "authors": "Bahareh Golchin, Banafsheh Rekabdar, Danielle Justo",
        "subjects": "Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.236211",
        "filter_reason": "根据筛选标准，这篇论文不符合研究范围，具体判断如下： 1.  **核心判断（第一步）：** 该论文的核心贡献在于提出一种用于**时间序列异常检测**的统一框架。虽然它结合了LLM和强化学习（RL），但其最终目标是解决特定领域（金融、医疗、传感器网络等）的数据分析问题，而非构建、改进或演化LLM智能体本身。 根据第一步的排除标准，这属于典型的**“非演化型应用”**，即“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题”。 2.  **排除标准分析：** *   论文中的“LSTM-based RL agent”仅仅是执行异常检测任务的一个组件，其架构（LSTM+RL）并非针对Agentic AI的通用能力（如复杂规划、工具使用、自我反思）进行创新。 *   论文的评估指标是“检测准确率”，而非智能体的通用性、演化能力或交互能力。 3.  **结论：** 尽管论文涉及了Agent（RL agent）和LLM，但其本质是利用这些技术解决时间序列领域的具体任务，而非对Agentic AI方法论或智能体演化机制的研究。因此，应予以排除。"
    },
    {
        "index": "#62",
        "title": "Finite Memory Belief Approximation for Optimal Control in Partially Observable Markov Decision Processes",
        "link": "/arxiv/2601.03132",
        "arxiv_id": "2601.03132",
        "authors": "Mintae Kim",
        "subjects": "Systems and Control, Information Theory, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.258361",
        "filter_reason": "这篇论文不符合研究范围，依据如下： 1.  **核心判断（第一步）**：论文的核心贡献是针对部分可观测马尔可夫决策过程（POMDP）中的最优控制问题，提出了一种有限记忆信念近似的数学理论。这属于经典的控制理论或理论强化学习范畴，而非构建、改进或演化 LLM 智能体的方法论。 2.  **缺乏 LLM 背景**：论文全文未提及大语言模型，也未涉及如何利用 LLM 作为智能体的大脑。虽然 POMDP 是智能体的理论基础之一，但本文侧重于数学推导（如 Wasserstein 度量、LQG 系统的性能界限），而非 Agentic AI 的系统实现或框架设计。 3.  **非 Agentic AI 焦点**：尽管论文讨论了“记忆”和“控制”，但这属于控制理论中的状态估计和策略优化，并不涉及 LLM 智能体所关注的工具使用、自然语言规划、自我反思或多智能体交互等核心能力。 综上所述，该论文是一篇理论控制数学论文，与“LLM智能体及其演化”的研究课题无关，应予以排除。"
    },
    {
        "index": "#50",
        "title": "Multi-scale Graph Autoregressive Modeling: Molecular Property Prediction via Next Token Prediction",
        "link": "/arxiv/2601.02530",
        "arxiv_id": "2601.02530",
        "authors": "Zhuoyang Jiang, Yaosen Min, Peiran Jin, Lei Chen",
        "subjects": "Machine Learning, Quantitative Methods",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.235707",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下核心判断： 1.  **非演化型应用 (第一步排除规则)**: 论文的核心贡献是提出了一种名为 \"CamS\" 的图到序列表示方法，用于解决**分子属性预测**这一特定领域（化学/生物信息学）的问题。它虽然使用了 LLaMA 这一 LLM 架构，但仅仅是将其作为预测分子属性的工具，并未涉及构建、改进或演化 LLM 智能体。 2.  **涉及图技术 (第三步排除标准)**: 论文的研究重点在于 \"Graph Autoregressive Modeling\"（图自回归建模）和 \"molecular graphs\"（分子图）。根据筛选标准，涉及知识图谱、图神经网络等图相关技术的论文属于排除范围。尽管论文将图转换为序列，但其本质是处理图结构数据，而非构建智能体。 3.  **缺乏 Agentic 核心特征**: 论文中完全没有提及智能体的关键能力，如规划、工具使用、记忆、自我反思、多智能体协作或自我演化机制。它关注的是通过 Next Token Prediction (NTP) 进行属性预测，属于基础模型能力在特定数据上的应用，而非 Agentic AI 的研究。 综上所述，该论文属于特定领域的应用型研究（化学分子预测）且涉及图技术，不符合 \"LLM智能体及其演化\" 的研究目标。"
    },
    {
        "index": "#63",
        "title": "LeafLife: An Explainable Deep Learning Framework with Robustness for Grape Leaf Disease Recognition",
        "link": "/arxiv/2601.03124",
        "arxiv_id": "2601.03124",
        "authors": "B. M. Shahria Alam, Md. Nasim Ahmed",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.258844",
        "filter_reason": "这篇论文完全不符合我的研究范围，具体判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献是构建一个基于深度学习模型（InceptionV3 和 Xception）的葡萄叶病害识别系统。这属于典型的“非演化型应用”，即将模型应用于农业/植物病理学这一特定领域来解决分类问题，而非关于构建、改进或演化 LLM 智能体的方法论。 2.  **排除标准（第三步）**： *   **多模态与视觉**：论文主要处理的是图像数据（葡萄叶图像），使用的是卷积神经网络（CNN），属于计算机视觉范畴。根据筛选标准，涉及视觉技术的论文通常被排除，除非视觉仅作为智能体感知环境的工具，而在此处视觉识别本身就是研究目的。 *   **非 Agentic**：论文中完全没有涉及智能体的概念，没有规划、记忆、工具使用或自主行动等 Agentic AI 的核心特征。 3.  **缺乏正面指标**：论文未提及任何与 LLM、智能体框架、自我演化或多智能体系统相关的关键词或技术。 综上所述，该论文是一篇纯粹的计算机视觉应用研究，与“LLM智能体及其演化”这一课题无关。"
    },
    {
        "index": "#65",
        "title": "ToxiGAN: Toxic Data Augmentation via LLM-Guided Directional Adversarial Generation",
        "link": "/arxiv/2601.03121",
        "arxiv_id": "2601.03121",
        "authors": "Peiran Li, Jan Fillies, Adrian Paschke",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.259867",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下核心判断： 1.  **核心贡献不符（第一步 - 排除非演化型应用）**: 论文的核心是提出 \"ToxiGAN\"，这是一个用于**数据增强**的框架，旨在解决**毒性分类**这一特定领域的问题。它虽然使用了LLM作为生成中性文本的辅助工具，但本质上并不是在构建、改进或演化一个具有自主规划、记忆或工具使用能力的LLM智能体。这属于将LLM作为工具应用到特定领域的应用型研究，而非Agentic AI的方法论研究。 2.  **触犯排除标准（第三步 - 安全与对齐）**: 论文的研究焦点明确集中在“有毒语言”、“仇恨言论”和“毒性分类”上。根据筛选标准，只要论文的主要贡献是关于 `Safety`（安全）或 `Security`（在此语境下指对抗性攻击与防御），一律排除。该论文旨在通过对抗生成提高分类器的鲁棒性，属于安全与防御领域的范畴。 综上所述，该论文既不涉及Agentic AI的构建（单智能体、多智能体或自我演化），又属于明确排除的安全与对齐方向，因此判定为不符合。"
    },
    {
        "index": "#60",
        "title": "AnatomiX, an Anatomy-Aware Grounded Multimodal Large Language Model for Chest X-Ray Interpretation",
        "link": "/arxiv/2601.03191",
        "arxiv_id": "2601.03191",
        "authors": "Anees Ur Rehman Hashmi, Numan Saeed, Christoph Lippert",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.246255",
        "filter_reason": "根据您的筛选标准，这篇论文不符合您的研究范围，具体判断过程如下： 1.  **核心判断（第一步 - 排除非演化型应用）**： *   该论文的核心贡献是构建了一个名为 **AnatomiX** 的“解剖学感知多模态大语言模型”（Multimodal Large Language Model），专门用于解决**胸部X光解读**这一特定医疗领域的问题。 *   这属于典型的“非演化型应用”。论文的重点在于改进模型在视觉-语言任务中的解剖学对应和空间推理能力，而不是构建具有自主性、规划能力或工具使用能力的 **LLM智能体**。 2.  **排除标准（第三步 - 多模态与视觉）**： *   论文明确属于 **多模态与视觉** 范畴。其核心创新点在于处理视觉信息（X光图像）和建立解剖结构对应关系，而非将视觉作为智能体感知环境的一个工具组件。研究焦点是 MLLM 的架构设计和性能提升，而非 Agentic AI 的机制。 3.  **缺乏核心关注点（第二步）**： *   论文中未涉及任何 Agentic AI 的核心范式，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Self-Reflection`（自我反思）或 `Multi-Agent`（多智能体）协作。 *   虽然摘要中提到了“受放射科工作流程启发”，但这指的是模型处理数据的两阶段流水线（先识别结构，再执行下游任务），而非智能体的自主决策循环。 综上所述，该论文是一篇关于医疗多模态模型的应用型研究，缺乏关于智能体构建、演化或交互的核心贡献，因此予以排除。"
    },
    {
        "index": "#68",
        "title": "Explainable Fuzzy GNNs for Leak Detection in Water Distribution Networks",
        "link": "/arxiv/2601.03062",
        "arxiv_id": "2601.03062",
        "authors": "Qusai Khaled, Pasquale De Marinis, Moez Louati, David Ferras, Laura Genga, Uzay Kaymak",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.261494",
        "filter_reason": "这篇论文不符合筛选要求，主要基于以下判断： 1.  **核心贡献不符 (第一步)**: 论文的核心是提出一种用于水务网络泄漏检测的“可解释模糊图神经网络”（FGENConv）。这属于将深度学习模型（GNN）应用于特定工程领域（水务/液压工程）的应用研究，而非构建、改进或演化 LLM智能体。 2.  **违反排除标准 (第三步)**: 筛选标准明确指出“涉及知识图谱，图神经网络等图相关技术的论文”需要排除。本文主要研究的是图神经网络（GNN）的架构改进及其可解释性，直接触发了排除条件。 3.  **缺乏Agentic特性**: 论文完全不涉及大语言模型（LLM）、智能体规划、工具使用、多智能体协作或自我演化机制。它关注的是利用传感器数据进行节点分类（泄漏检测），而非智能体的自主行为或演化。 综上所述，该论文属于特定领域的GNN应用研究，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#67",
        "title": "Do LLMs Encode Functional Importance of Reasoning Tokens?",
        "link": "/arxiv/2601.03066",
        "arxiv_id": "2601.03066",
        "authors": "Janvijay Singh, Dilek Hakkani-Tür",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.260915",
        "filter_reason": "这篇论文的核心贡献在于提出一种名为“贪婪剪枝”的诊断方法，用于分析LLM生成的推理链中Token的功能重要性，并通过剪枝来压缩推理链长度，进而应用于模型蒸馏。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：该论文的本质是关于LLM推理链的内部机制分析和压缩技术，而非构建、改进或演化LLM智能体。它没有涉及智能体的架构设计、工具使用、记忆机制或多智能体交互。 2.  **非Agentic的推理（第四步）**：论文重点在于优化LLM生成的基础推理链（Token级别的剪枝和蒸馏），旨在提高推理效率或理解模型内部表示，这属于“非Agentic的推理”范畴。它没有涉及智能体在复杂任务中的自主规划、行动循环或环境交互框架。 3.  **结论**：尽管论文涉及“Reasoning”，但它侧重于模型层面的推理链优化而非智能体层面的规划能力，因此不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#70",
        "title": "Lil: Less is Less When Applying Post-Training Sparse-Attention Algorithms in Long-Decode Stage",
        "link": "/arxiv/2601.03043",
        "arxiv_id": "2601.03043",
        "authors": "Junhao Hu, Fangze Li, Mingtao Xu, Feifan Meng, Shiju Zhao, Tiancheng Hu, Ting Peng, Anmin Liu, Wenrui Huang, Chenxu Liu, Ziyue Hua, Tao Xie",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.262625",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断过程如下： 1.  **核心判断（第一步）**： *   论文的核心贡献在于提出一种**早停算法**（early-stopping algorithm）和关于**稀疏注意力**（sparse-attention）的理论分析，旨在解决LLM在解码阶段的**推理效率**（inference efficiency）和**内存/时间复杂度**问题。 *   这完全属于**基础设施**（Infrastructure）和**部署优化**（Deployment Optimization）的范畴。根据筛选标准的第一步排除规则，应排除主要关注模型基础设施、部署优化的研究。 2.  **缺乏Agentic核心要素（第二步）**： *   论文虽然提到了在“推理密集型基准测试”上进行评估，但其方法本身并不涉及智能体的构建、规划、工具使用、记忆或自我反思。 *   它没有提出任何新的Agentic框架、多智能体协作机制或自我演化策略。 3.  **关于推理的特殊情况（第四步）**： *   虽然论文涉及“推理”，但它关注的是如何通过减少Token消耗来加速推理过程（工程优化），而不是智能体如何进行多步规划或逻辑推理（Agentic能力）。因此，它不符合“保留”关于智能体推理框架的规则。 综上所述，该论文是一篇关于LLM推理效率优化的工程类论文，而非关于LLM智能体构建、多智能体系统或自我演化的方法论研究，因此予以排除。"
    },
    {
        "index": "#57",
        "title": "Physical Transformer",
        "link": "/arxiv/2601.02433",
        "arxiv_id": "2601.02433",
        "authors": "Tao Xu, Zhixin Hu, Li Luo, Momiao Xiong",
        "subjects": "Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.244516",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为“物理Transformer”的新型神经网络架构，旨在将Transformer的计算机制与几何表示及物理动力学（如哈密顿量、神经微分流形）相结合。 根据筛选标准，我的判断过程如下： 1.  **核心判断（第一步）**：论文的本质是**基础模型架构的创新**，而非构建LLM智能体。作者试图通过物理学的视角（如哈密顿力学）来重新解释和改进Transformer内部的计算过程（注意力头、前馈块的演化），这属于模型底层机制的研究，而非智能体的构建、改进或演化。 2.  **焦点不符（第二步）**：尽管摘要中提到了“推理任务”和“控制”，但这里的“推理”被表述为流形上的受控信息流，属于数学和物理层面的建模，并不涉及Agentic AI的核心范式（如自主规划、工具使用、记忆机制、自我反思等）。 3.  **排除非Agentic推理（第四步）**：论文关注的是提高模型在数值积分和动力系统任务上的稳定性与准确性，这属于提升模型基础能力或特定数学能力，而非研究智能体如何在复杂环境中进行多步自主决策或与环境交互。 综上所述，该论文属于基础模型架构与理论的研究，不符合“LLM智能体及其演化”这一关于Agentic AI的研究课题范围。"
    },
    {
        "index": "#69",
        "title": "Temporal Graph Network: Hallucination Detection in Multi-Turn Conversation",
        "link": "/arxiv/2601.03051",
        "arxiv_id": "2601.03051",
        "authors": "Vidhi Rathore, Sambu Aneesh, Himanshu Singh",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.261991",
        "filter_reason": "根据您提供的筛选标准，这篇论文**不符合**您的研究范围，具体判断依据如下： 1.  **触发了核心排除标准（第三步：安全与对齐）**： *   论文的核心贡献明确在于提出一种用于检测对话中“幻觉”的方法。 *   您的筛选标准明确规定：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`... 或 `Hallucination` (幻觉)，一律排除。” 因此，无论其技术细节如何，仅凭“Hallucination Detection”这一核心目标就应直接排除。 2.  **触发了技术路线排除标准（第三步：图）**： *   论文的方法论核心是利用“时序图网络”和“消息传递”来建模对话。 *   您的筛选标准明确指出：“图：涉及知识图谱，图神经网络等图相关技术的论文”属于排除范围。该论文主要依赖图神经网络（GNN）技术，而非LLM智能体的架构演化。 3.  **不符合核心研究目标（第一步：核心判断）**： *   您的核心目标是筛选关于“构建、改进或演化 LLM智能体”的论文（Agentic AI, Multi-Agent, Self-Evolving）。 *   该论文侧重于对现有对话系统输出的**评估和检测**（Evaluation/Detection），而非构建具有自主规划、工具使用或自我演化能力的智能体。它没有涉及智能体的行动循环、多智能体协作或自我完善机制。 综上所述，该论文属于安全/评估领域且使用了图神经网络技术，与“LLM智能体及其演化”的研究课题不符，故予以排除。"
    },
    {
        "index": "#64",
        "title": "Gradient descent reliably finds depth- and gate-optimal circuits for generic unitaries",
        "link": "/arxiv/2601.03123",
        "arxiv_id": "2601.03123",
        "authors": "Janani Gomathi, Alex Meiburg",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.259326",
        "filter_reason": "这篇论文的核心贡献是关于**量子计算**领域的量子电路综合，具体研究了如何利用梯度下降算法高效地找到针对通用酉算子的深度和门最优量子电路。这与我的研究课题 \"LLM智能体及其演化\" 没有任何关联。 根据第一步的核心判断标准，该论文既不是关于构建或改进LLM智能体，也不涉及多智能体系统或自我演化机制。它属于量子算法优化和物理学范畴，而非人工智能智能体研究。因此，该论文完全不符合我的研究范围，应予以排除。"
    },
    {
        "index": "#71",
        "title": "PiDR: Physics-Informed Inertial Dead Reckoning for Autonomous Platforms",
        "link": "/arxiv/2601.03040",
        "arxiv_id": "2601.03040",
        "authors": "Arup Kumar Sahoo, Itzik Klein",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.268567",
        "filter_reason": "这篇论文不符合我的研究范围，依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出一种名为 PiDR 的“物理信息惯性航位推算框架”，旨在解决自主平台（如移动机器人和水下航行器）在无外部信号（如GNSS）情况下的导航精度问题。这属于**机器人控制**和**传感器融合**领域的应用研究，而非构建、改进或演化 LLM 智能体。论文中提到的“深度学习模型”是用于处理传感器数据的物理信息神经网络，而非大语言模型（LLM）。 2.  **排除标准（第一步 & 第三步）：** *   **非演化型应用：** 该研究是将深度学习方法应用于特定的物理/工程领域（惯性导航），属于典型的“将模型作为工具应用到特定领域”的情况，符合排除标准。 *   **缺乏 Agentic 属性：** 论文关注的是轨迹预测和误差修正，不涉及 LLM 智能体的核心特征，如自主规划、工具使用、记忆机制或自我反思。 综上所述，该论文与 LLM 智能体、多智能体系统或自我演化机制无关，因此予以排除。"
    },
    {
        "index": "#72",
        "title": "Flow Matching and Diffusion Models via PointNet for Generating Fluid Fields on Irregular Geometries",
        "link": "/arxiv/2601.03030",
        "arxiv_id": "2601.03030",
        "authors": "Ali Kashefi",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning, Computational Physics",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.269148",
        "filter_reason": "这篇论文的核心贡献在于提出了结合 PointNet 的流匹配和扩散模型框架，用于在非规则几何体上预测流体流场（如速度和压力场）。这是一个典型的将生成式深度学习模型应用于计算流体动力学（CFD）和物理模拟的研究。 根据筛选标准，该论文不符合要求的原因如下： 1.  **核心判断（第一步）**：论文属于“非演化型应用”。它将深度学习模型作为工具应用于物理/工程领域（流体力学），解决的是物理场的预测问题，而非构建、改进或演化 LLM 智能体。 2.  **缺乏 Agentic 属性（第二步）**：论文中完全没有涉及 LLM、智能体规划、工具使用、记忆、自我反思或多智能体协作等核心 Agentic AI 范式。 3.  **研究焦点不符**：该研究属于科学机器学习或几何深度学习范畴，与“LLM智能体及其演化”这一课题无直接关联。 因此，该论文被排除。"
    },
    {
        "index": "#56",
        "title": "WebGym: Scaling Training Environments for Visual Web Agents with Realistic Tasks",
        "link": "/arxiv/2601.02439",
        "arxiv_id": "2601.02439",
        "authors": "Hao Bai, Alexey Taymanov, Tong Zhang, Aviral Kumar, Spencer Whitehead",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.243994",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#73",
        "title": "Dementia-R1: Reinforced Pretraining and Reasoning from Unstructured Clinical Notes for Real-World Dementia Prognosis",
        "link": "/arxiv/2601.03018",
        "arxiv_id": "2601.03018",
        "authors": "Choonghan Kim, Hyunmin Hwang, Hangeol Chang, Jaemin Kim, Jinse Park, Jae-Sung Lim, Jong Chul Ye",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.269758",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心判断（非演化型应用）**：论文的核心贡献是提出一个名为 \"Dementia-R1\" 的框架，用于解决特定领域的任务——即从临床笔记中进行痴呆症预后预测。这属于将LLM和强化学习（RL）技术应用到医疗领域的应用型研究，而非构建通用的LLM智能体或智能体演化框架。根据筛选标准第一步中的“排除：非演化型应用”，应予以排除。 2.  **非Agentic的推理**：虽然摘要中提到了 \"reasoning about disease progression\"（关于疾病进展的推理），但这指的是通过 \"Cold-Start RL\" 策略改进模型对医疗文本的内部理解和预测能力，属于提升模型基础推理能力的范畴。论文并未涉及智能体的自主规划、工具使用、记忆机制或自我反思循环等Agentic AI的核心特征。 3.  **缺乏自我演化机制**：尽管论文使用了强化学习（RL），但这里的RL是作为一种训练方法来优化模型在特定医疗任务上的表现，而不是智能体在环境中通过经验进行自我完善、迭代或演化的机制。 综上所述，该论文属于医疗垂直领域的应用研究，不涉及LLM智能体的构建、多智能体协作或自我演化机制，因此不符合筛选要求。"
    },
    {
        "index": "#76",
        "title": "Low-Resource Heuristics for Bahnaric Optical Character Recognition Improvement",
        "link": "/arxiv/2601.02965",
        "arxiv_id": "2601.02965",
        "authors": "Phat Tran, Phuoc Pham, Hung Trinh, Tho Quan",
        "subjects": "Computation and Language, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.271380",
        "filter_reason": "这篇论文不符合研究范围，依据如下： 1.  **核心判断（第一步 - 排除）**： *   论文的核心贡献是针对特定低资源语言（Bahnar语）提出一种**光学字符识别（OCR）**的改进方法。 *   该方法结合了表格/非表格检测技术和基于概率的后处理启发式算法，旨在解决文档数字化中的图像质量差和识别错误问题。 *   这属于典型的**非演化型应用**，即将特定技术（OCR及启发式规则）应用于特定领域（语言学/文档数字化），并未涉及构建、改进或演化 LLM智能体。 2.  **缺乏核心关注点（第二步）**： *   论文中未出现任何关于 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving` 的核心范式。 *   论文未涉及智能体的关键能力，如 `Planning`（规划）、`Tool Use`（工具使用，除非OCR被视为单纯的工具而非智能体本身）、`Memory`（记忆）或 `Self-Reflection`（自我反思）。 3.  **结论**： 该论文属于传统的自然语言处理（NLP）和计算机视觉（CV）交叉领域的应用研究，专注于OCR技术的优化，与“LLM智能体及其演化”这一研究课题无直接关联。因此，根据筛选标准的第一步（非演化型应用）予以排除。"
    },
    {
        "index": "#75",
        "title": "Reliability-Aware Adaptive Self-Consistency for Efficient Sampling in LLM Reasoning",
        "link": "/arxiv/2601.02970",
        "arxiv_id": "2601.02970",
        "authors": "Junseok Kim, Nakyeong Yang, Kyungmin Min, Kyomin Jung",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.270853",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为 ReASC (Reliability-Aware Adaptive Self-Consistency) 的**自适应采样策略**，旨在优化大语言模型（LLM）在推理过程中的 Self-Consistency（自一致性）方法，以降低推理成本并提高准确性。 根据筛选标准，我的判断过程如下： 1.  **第一步（核心判断）- 非Agentic的推理**： 该论文的研究焦点是改进 LLM 的**基础推理能力**（通过优化采样和响应聚合机制），属于推理解码层面的优化。虽然它涉及“Reasoning”，但并不涉及构建具有自主性、工具使用或环境交互能力的“智能体”。它解决的是如何更高效地让模型输出正确答案（如数学题 GSM8K），而不是如何构建一个能规划、行动和反思的 Agentic 框架。因此，它属于“非Agentic的推理”排除范畴。 2.  **第四步（特殊情况）- 推理/规划的界定**： 标准明确指出：“排除：如果只是关于提高LLM本身基础Token预测的数学或逻辑能力（如新的数据集、非Agentic的微调方法）”。ReASC 本质上是一种改进的解码/采样算法，用于提升模型在逻辑任务上的表现，并未引入智能体的核心要素（如 ReAct 循环、工具调用、记忆机制或多步规划框架）。 3.  **缺乏核心指标**： 论文中未出现 `Agentic AI`、`Tool Use`、`Multi-Agent`、`Self-Evolving` 或 `Planning`（指智能体层面的规划）等核心范式指标。其关注点在于 `Sampling`（采样）、`Inference Cost`（推理成本）和 `Confidence`（置信度），这些属于模型推理优化的范畴，而非智能体架构或演化机制的研究。 综上所述，该论文属于 LLM 推理优化研究，而非 LLM 智能体构建或演化研究，因此不符合筛选要求。"
    },
    {
        "index": "#61",
        "title": "Can Embedding Similarity Predict Cross-Lingual Transfer? A Systematic Study on African Languages",
        "link": "/arxiv/2601.03168",
        "arxiv_id": "2601.03168",
        "authors": "Tewodros Kederalah Idris, Prasenjit Mitra, Roald Eiselen",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.257867",
        "filter_reason": "这篇论文的核心贡献在于通过系统性实验，评估不同的嵌入相似度指标（如 cosine gap, CSLS 等）在预测跨语言迁移（特别是针对非洲语言）效果方面的能力。 根据筛选标准第一步（核心判断），该论文的本质属于**NLP基础研究**（表示学习与跨语言迁移），而非构建、改进或演化 LLM 智能体。它没有提出任何关于智能体规划、工具使用、记忆机制、多智能体协作或自我演化的方法论或新框架。 根据筛选标准第二步（正面指标），论文中完全不包含 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent Systems` 或 `Self-Evolving` 等核心关注点。虽然它涉及模型选择，但这属于静态模型评估，而非智能体的动态演化或自主行为。 因此，该论文不符合“LLM智能体及其演化”的研究范围，应予以排除。"
    },
    {
        "index": "#79",
        "title": "Enhanced 3D Gravity Inversion Using ResU-Net with Density Logging Constraints: A Dual-Phase Training Approach",
        "link": "/arxiv/2601.02890",
        "arxiv_id": "2601.02890",
        "authors": "Siyuan Dong, Jinghuai Gao, Shuai Zhou, Baohai Wu, Hongfa Jia",
        "subjects": "Geophysics, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.273056",
        "filter_reason": "这篇论文完全不符合我的研究范围，具体判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献是提出一种基于 ResU-Net（一种卷积神经网络架构）的 3D 重力反演方法，用于解决地球物理学领域的数据拟合和地质勘探问题。这属于典型的“非演化型应用”，即利用深度学习作为工具解决特定垂直领域（地球物理/重力勘探）的问题，而非构建或演化 LLM 智能体。 2.  **技术栈不符**：论文使用的是 ResU-Net（CNN），而非大语言模型（LLM）。我的研究焦点是 LLM-based Agents，该论文完全不涉及 LLM 或自然语言处理技术。 3.  **缺乏 Agentic 特征（第二步）**：论文中没有任何关于智能体规划、工具使用、记忆、自我反思或多智能体协作的内容。其“双阶段训练”仅是模型微调的一种策略，并非智能体的自我演化或迭代改进机制。 综上所述，该论文是一篇地球物理与深度学习交叉的应用型论文，与 LLM 智能体及其演化的研究课题无关。"
    },
    {
        "index": "#78",
        "title": "TA-Prompting: Enhancing Video Large Language Models for Dense Video Captioning via Temporal Anchors",
        "link": "/arxiv/2601.02908",
        "arxiv_id": "2601.02908",
        "authors": "Wei-Yuan Cheng, Kai-Po Chang, Chi-Pin Huang, Fu-En Yang, Yu-Chiang Frank Wang",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.272467",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **触发了排除标准（多模态与视觉）**： 根据第三步排除标准，涉及 `Vision`、`Vision-Language`、`Video Understanding` 的论文通常需要排除，除非它们仅作为智能体感知环境的工具。这篇论文的核心研究对象是 **Video Large Language Models (VideoLLMs)**，旨在解决 **Dense Video Captioning（密集视频字幕生成）** 这一具体的视觉-语言任务。视觉理解是论文的核心贡献，而非仅仅是智能体的辅助工具。 2.  **缺乏 Agentic AI 的核心特征**： 论文的核心贡献是提出了一种名为 \"TA-Prompting\" 的方法，通过时间锚点来提高事件定位的准确性。这属于模型在特定任务（视频理解）上的性能优化，并不涉及第一步中定义的智能体核心要素（如 **Planning**、**Tool Use**、**Memory**、**Self-Reflection**）或第二步中的多智能体协作与自我演化机制。 3.  **属于特定领域的应用优化**： 该论文致力于解决视频领域中的“事件边界识别”和“字幕生成”问题，属于将大模型应用于特定视觉领域的非演化型应用，而非构建具有通用能力的 LLM 智能体或研究智能体的演化机制。 综上所述，该论文属于视觉-语言模型的应用研究，而非 LLM 智能体的构建、改进或演化研究，因此予以排除。"
    },
    {
        "index": "#80",
        "title": "STIPP: Space-time in situ postprocessing over the French Alps using proper scoring rules",
        "link": "/arxiv/2601.02882",
        "arxiv_id": "2601.02882",
        "authors": "David Landry, Isabelle Gouttevin, Hugo Merizen, Claire Monteleoni, Anastase Charantonis",
        "subjects": "Atmospheric and Oceanic Physics, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.278795",
        "filter_reason": "这篇论文不符合研究范围，依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出一种名为 STIPP 的机器学习模型，用于解决气象学领域的特定问题——即针对法国阿尔卑斯山地区的天气预报进行时空一致性后处理。这属于典型的“非演化型应用”，即将机器学习技术应用于特定垂直领域（气象/天气），而非构建、改进或演化 LLM 智能体本身。 2.  **缺乏核心关注点（第二步）：** 论文中未涉及任何关于 Agentic AI、LLM-based Agents、Multi-Agent Systems 或 Self-Evolving 的核心范式。它也不包含智能体的关键能力（如规划、工具使用、记忆、自我反思）或多智能体机制（如协作、通信）。 3.  **技术本质不符：** 论文关注的是数值天气预报的统计后处理和生成建模，旨在提高温度、风速等气象要素的预测精度，这与 LLM 智能体的架构设计或演化机制无任何关联。 综上所述，该论文属于气象数据科学的应用研究，完全偏离了“LLM智能体及其演化”的研究课题，因此予以排除。"
    },
    {
        "index": "#81",
        "title": "HAL: Inducing Human-likeness in LLMs with Alignment",
        "link": "/arxiv/2601.02813",
        "arxiv_id": "2601.02813",
        "authors": "Masum Hasan, Junjie Zhao, Ehsan Hoque",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.279321",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 HAL 的框架，旨在通过可解释的数据驱动奖励信号来对齐语言模型，使其在对话中更像人类。 根据筛选标准，我的判断过程如下： 1.  **核心判断（第一步）**：论文的本质是关于模型对齐和偏好优化，旨在改进 LLM 的对话风格（人类相似性），而非构建具有自主规划、工具使用或记忆能力的 LLM 智能体。它不涉及 Agentic AI 的核心架构或方法论。 2.  **排除标准（第三步）**：这是最关键的排除依据。筛选标准明确指出，只要论文的主要贡献是关于 `Alignment`（对齐）或 `Interpretability`（可解释性），一律排除。该论文标题即包含 \"Alignment\"，摘要中反复强调 \"aligning language models\"、\"preference optimization\" 以及 \"interpretable and explainable way\"。这完全符合排除标准中关于“安全与对齐”的条款。 3.  **缺乏正面指标（第二步）**：论文未涉及任何 Agentic AI 的核心范式或能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Multi-Agent Systems`（多智能体系统）或 `Self-Evolving`（自我演化）机制。 综上所述，该论文属于模型对齐与微调领域的研究，不符合“LLM智能体及其演化”这一课题的研究范围。"
    },
    {
        "index": "#82",
        "title": "COFFEE: COdesign Framework for Feature Enriched Embeddings in Ads-Ranking Systems",
        "link": "/arxiv/2601.02807",
        "arxiv_id": "2601.02807",
        "authors": "Sohini Roychowdhury, Doris Wang, Qian Ge, Joy Mu, Srihari Reddy",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.279850",
        "filter_reason": "这篇论文的核心贡献是提出一个用于广告推荐系统的协同设计框架（COFFEE），旨在通过整合多源数据、延长用户历史和丰富事件属性来优化用户和广告的嵌入表示，从而提高点击率（CTR）预测和AUC。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：该论文属于典型的“非演化型应用”。它将模型（主要是嵌入和推荐算法）应用于特定的商业领域（广告排名），解决的是该领域的预测准确率和表征学习问题，而非构建、改进或演化LLM智能体。 2.  **正面指标（第二步）**：论文中未包含任何Agentic AI的核心范式或能力，如规划、工具使用、记忆、自我反思、多智能体协作或自我演化机制。 3.  **排除标准（第三步）**：虽然论文提到了“多模态嵌入”，但这仅作为丰富推荐系统特征的手段，并非作为智能体感知环境的工具，且研究焦点不在智能体本身。 综上所述，该论文的研究焦点是推荐系统算法优化，与“LLM智能体及其演化”这一课题无关，因此予以排除。"
    },
    {
        "index": "#83",
        "title": "Fast Conformal Prediction using Conditional Interquantile Intervals",
        "link": "/arxiv/2601.02769",
        "arxiv_id": "2601.02769",
        "authors": "Naixin Guo, Rui Luo, Zhixin Zhou",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.280356",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 \"Conformal Interquantile Regression (CIR)\" 的共形回归方法，旨在高效构建具有保证覆盖率的预测区间。这属于统计机器学习中的不确定性量化或回归分析领域。 根据筛选标准进行判断： 1.  **核心判断（第一步）**: 论文的研究重点是统计预测区间的构建和计算效率优化，并未涉及构建、改进或演化 LLM智能体。它不包含智能体的规划、记忆、工具使用或自我反思等核心要素。因此，它不属于 Agentic AI、Multi-Agent Systems 或 Self-Evolving 的范畴。 2.  **正面指标（第二步）**: 论文中未出现任何关于 `Agentic AI`、`LLM-based Agents`、`Planning`、`Tool Use`、`Self-Reflection` 或 `Multi-Agent` 等核心范式或能力的描述。 3.  **排除标准（第三步）**: 虽然论文未明确涉及安全或多模态等排除项，但其本质是基础统计/机器学习方法的改进，而非智能体研究。 综上所述，该论文属于统计推断与回归分析的基础研究，与 \"LLM智能体及其演化\" 的研究课题无关，因此予以排除。"
    },
    {
        "index": "#74",
        "title": "Learning to Act Robustly with View-Invariant Latent Actions",
        "link": "/arxiv/2601.02994",
        "arxiv_id": "2601.02994",
        "authors": "Youngjoon Jeong, Junha Chun, Taesup Kim",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.270275",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 VILA (View-Invariant Latent Action) 的框架，旨在解决基于视觉的机器人策略在面对视角变化时的鲁棒性问题。这属于机器人控制和计算机视觉领域，而非 LLM智能体研究。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：论文本质是关于机器人视觉策略的表示学习，而非构建、改进或演化 LLM智能体。它不涉及 Agentic AI 的核心架构（如记忆、反思、工具使用）。 2.  **排除标准（第三步）**：论文明确聚焦于 \"Vision-based robotic policies\" 和 \"view-invariant visual representations\"。根据“多模态与视觉”的排除规则，涉及视觉技术且将其作为研究核心（而非仅作为智能体感知环境的辅助工具）的论文应被排除。 3.  **缺乏正面指标（第二步）**：论文未提及 LLM、智能体规划、多智能体协作或自我演化机制。 综上所述，该论文属于视觉机器人控制领域，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#85",
        "title": "Adversarial Contrastive Learning for LLM Quantization Attacks",
        "link": "/arxiv/2601.02680",
        "arxiv_id": "2601.02680",
        "authors": "Dinghong Song, Zhiwei Xu, Hai Wan, Xibin Zhao, Pengfei Su, Dong Li",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.318161",
        "filter_reason": "这篇论文的核心贡献在于提出了一种针对大语言模型（LLM）量化的对抗性攻击方法（Adversarial Contrastive Learning, ACL），旨在诱导量化后的模型产生恶意行为（如越狱、广告注入等）。 根据筛选标准，该论文被排除的原因如下： 1.  **触犯排除标准（安全与对齐）**：论文的主要研究焦点集中在 `Security`（安全风险）、`Attacks`（攻击）、`Jailbreak`（越狱）以及模型的安全性评估上。根据第三步排除标准，只要论文的主要贡献是关于 Safety 或 Security 的，一律排除。 2.  **非核心研究范围**：论文的研究背景是模型量化，这属于基础设施和部署优化的范畴，而非构建、改进或演化 LLM 智能体。 3.  **缺乏Agentic特征**：论文未涉及智能体的规划、工具使用、多智能体协作或自我演化等核心 Agentic AI 范式。 综上所述，该论文属于模型安全与部署领域，不符合“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#86",
        "title": "Extracting books from production language models",
        "link": "/arxiv/2601.02671",
        "arxiv_id": "2601.02671",
        "authors": "Ahmed Ahmed, A. Feder Cooper, Sanmi Koyejo, Percy Liang",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.318824",
        "filter_reason": "这篇论文的核心贡献在于研究如何从生产级的大型语言模型中提取受版权保护的训练数据（记忆提取），并评估了不同模型在安全措施下的数据泄露风险。根据筛选标准，该论文主要涉及 **安全与对齐**（Safety, Copyright, Extraction Attacks）领域，而非构建、改进或演化LLM智能体。尽管论文中提到了“迭代继续提示”，但这仅作为数据提取的技术手段，并非为了实现智能体的自主规划、工具使用或自我演化机制。因此，该论文完全不符合“LLM智能体及其演化”的研究范围，应予以排除。"
    },
    {
        "index": "#90",
        "title": "SWaRL: Safeguard Code Watermarking via Reinforcement Learning",
        "link": "/arxiv/2601.02602",
        "arxiv_id": "2601.02602",
        "authors": "Neusha Javidnia, Ruisi Zhang, Ashish Kundu, Farinaz Koushanfar",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.321528",
        "filter_reason": "这篇论文的核心贡献是提出一种名为 SWaRL 的代码水印框架，旨在通过强化学习在代码生成中嵌入可验证的签名以保护知识产权。 根据筛选标准，判断依据如下： 1.  **触犯排除标准 (第三步)**：论文的研究主题明确属于 **`Watermarking` (水印)** 和 **`Security` (安全)** 范畴。筛选标准明确规定，只要论文的主要贡献是关于 `Safety`, `Security`, 或 `Watermarking`，一律排除。 2.  **不符合核心目标 (第一步)**：论文的本质并非构建、改进或演化 LLM智能体。虽然它使用了强化学习（RL）和 LoRA 技术，但这些技术手段是为了实现“水印嵌入”这一特定安全目标，而不是为了赋予智能体规划、工具使用、自我反思或协作等 Agentic 能力。 3.  **非自我演化 (第四步)**：尽管论文涉及模型微调和参数更新，但这属于模型的安全加固或特定功能注入，并不涉及智能体通过经验、反思或环境反馈进行能力上的“自我完善”或“迭代演化”。 综上所述，该论文属于安全与水印领域的研究，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#89",
        "title": "Hierarchical temporal receptive windows and zero-shot timescale generalization in biologically constrained scale-invariant deep networks",
        "link": "/arxiv/2601.02618",
        "arxiv_id": "2601.02618",
        "authors": "Aakash Sarkar, Marc W. Howard",
        "subjects": "Neurons and Cognition, Artificial Intelligence, Computation and Language, Machine Learning, Neural and Evolutionary Computing",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.320925",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献不符 (第一步 - 核心判断)**: 论文的核心在于提出一种受生物学约束的深度网络架构（SITH-RNN），旨在模拟人类认知中的时间感受野和尺度不变性。这属于认知科学或神经科学启发的深度学习模型架构研究，而非构建、改进或演化 LLM智能体。 2.  **缺乏Agentic特性 (第一步 & 第二步 - 正面指标)**: 虽然论文涉及语言分类任务，但其重点在于网络的时间处理机制和零样本时间尺度泛化能力，并未涉及智能体的自主规划、工具使用、记忆管理或自我反思等 Agentic AI 的核心能力。它研究的是模型底层的序列处理机制，而非智能体的行为框架。 3.  **不属于研究焦点 (第一步 & 第四步)**: 该研究不涉及多智能体系统，也不涉及智能体的自我演化机制（如通过经验迭代改进）。它关注的是模型架构本身的生物学合理性和时间尺度泛化能力，属于基础模型架构或认知建模范畴，而非 Agentic AI 范畴。 综上所述，该论文属于认知建模与神经网络架构研究，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#66",
        "title": "Grad-ELLM: Gradient-based Explanations for Decoder-only LLMs",
        "link": "/arxiv/2601.03089",
        "arxiv_id": "2601.03089",
        "authors": "Xin Huang, Antoni B. Chan",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.260347",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#91",
        "title": "Compressed code: the hidden effects of quantization and distillation on programming tokens",
        "link": "/arxiv/2601.02563",
        "arxiv_id": "2601.02563",
        "authors": "Viacheslav Siniaev, Iaroslav Chelombitko, Aleksey Komissarov",
        "subjects": "Software Engineering, Computation and Language, Machine Learning, Programming Languages",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.327289",
        "filter_reason": "这篇论文的核心贡献在于分析模型压缩技术（量化、蒸馏）对编程语言Token表示的影响，以及提供在生产环境中优化模型实现的指导。 根据筛选标准进行判断： 1.  **第一步（核心判断）**：论文的研究焦点属于**基础设施**和**部署优化**（Infrastructure/Deployment Optimization），具体涉及量化、蒸馏和模型缩放。它并不涉及构建、改进或演化LLM智能体的方法论或新框架，也不属于Agentic AI、Multi-Agent Systems或Self-Evolving的研究范畴。 2.  **第二步（正面指标）**：论文中未出现任何关于智能体规划、工具使用、记忆、自我反思、多智能体协作或自我演化机制等核心范式或能力指标。 3.  **第三步（排除标准）**：虽然论文未涉及安全对齐或多模态，但其本质是对模型底层Token表示和压缩技术的分析，属于模型工程与优化领域，与“LLM智能体及其演化”的研究目标无关。 综上所述，该论文主要关注模型压缩与Token分析，不符合筛选要求。"
    },
    {
        "index": "#87",
        "title": "Empirical Comparison of Encoder-Based Language Models and Feature-Based Supervised Machine Learning Approaches to Automated Scoring of Long Essays",
        "link": "/arxiv/2601.02659",
        "arxiv_id": "2601.02659",
        "authors": "Kuo Wang, Haowei Hua, Pengfei Yan, Hong Jiao, Dan Song",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.319486",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下筛选标准的分析： 1.  **核心判断（第一步 - 排除非演化型应用）**： *   该论文的核心贡献是针对特定领域（教育/自动评分）的实证研究，比较了基于编码器的语言模型（如BERT、RoBERTa）和基于特征的监督机器学习方法在长作文评分上的表现。 *   这属于典型的“非演化型应用”。论文将现有的语言模型作为工具直接应用于文本分类/回归任务（评分），并没有提出任何关于构建、改进或演化 LLM智能体的新方法论或新框架。 2.  **正面指标缺失（第二步）**： *   论文中完全不涉及 Agentic AI 的核心范式，如智能体规划、工具使用、记忆机制、自我反思等。 *   也不涉及多智能体系统或自我演化机制。 3.  **模型类型不符**： *   论文主要关注的是 Encoder-based 模型（BERT系列）和传统的集成学习方法，而非基于 LLM 的智能体架构。 综上所述，该论文属于特定领域的应用研究，缺乏关于智能体架构、交互或演化的核心贡献，因此被排除。"
    },
    {
        "index": "#92",
        "title": "First Provably Optimal Asynchronous SGD for Homogeneous and Heterogeneous Data",
        "link": "/arxiv/2601.02523",
        "arxiv_id": "2601.02523",
        "authors": "Artavazd Maranjyan",
        "subjects": "Optimization and Control, Distributed, Parallel, and Cluster Computing, Machine Learning, Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.327817",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献分析**：该论文的核心贡献在于提出了一种用于大规模神经网络训练的异步随机梯度下降（ASGD）优化算法（包括 Ringmaster ASGD, Ringleader ASGD 和 ATA）。其研究重点在于解决分布式训练中的计算效率、同步延迟、时间复杂度以及硬件资源分配问题。 2.  **第一步（核心判断）- 排除**：根据筛选标准，该研究属于典型的**基础设施**和**部署优化**范畴。论文关注的是如何利用数千个GPU/TPU更高效地训练模型，属于底层系统优化，而非构建、改进或演化LLM智能体的方法论。 3.  **第三步（排除标准）- 明确违反**：筛选标准明确指出要排除“主要关注模型基础设施、部署优化、硬件加速的研究”。这篇论文完全聚焦于这些方面，不涉及智能体的规划、工具使用、多智能体协作或自我演化机制。 综上所述，尽管该研究对提升大模型训练效率有重要意义，但它不属于“LLM智能体及其演化”的研究范畴，因此予以排除。"
    },
    {
        "index": "#88",
        "title": "Statistical Inference for Fuzzy Clustering",
        "link": "/arxiv/2601.02656",
        "arxiv_id": "2601.02656",
        "authors": "Qiuyi Wu, Zihan Zhu, Anru R. Zhang",
        "subjects": "Methodology, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.320137",
        "filter_reason": "1.  **核心贡献分析**: 该论文的核心贡献是提出了一种针对加权模糊c均值（WFCM）的统计推断框架，旨在解决生物医学数据（如单细胞RNA-seq和阿尔茨海默病影像数据）中聚类大小不平衡的问题，并提供不确定性量化。 2.  **第一步（核心判断）**: 论文完全不涉及大语言模型（LLM）、智能体构建、多智能体系统或自我演化机制。它属于传统的机器学习/统计学方法在特定垂直领域（生物医学）的应用，符合“非演化型应用”的排除标准。 3.  **第二步（正面指标）**: 论文中未包含任何关于Agentic AI、规划、工具使用、记忆、自我反思、多智能体协作或演化算法等核心范式或能力指标。 4.  **结论**: 该论文属于统计学与生物信息学范畴，与“LLM智能体及其演化”的研究课题毫无关联，因此予以排除。"
    },
    {
        "index": "#95",
        "title": "VocalBridge: Latent Diffusion-Bridge Purification for Defeating Perturbation-Based Voiceprint Defenses",
        "link": "/arxiv/2601.02444",
        "arxiv_id": "2601.02444",
        "authors": "Maryam Abbasihafshejani, AHM Nazmus Sakib, Murtuza Jadliwala",
        "subjects": "Sound, Artificial Intelligence, Cryptography and Security, Machine Learning, Audio and Speech Processing",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.329521",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 \"VocalBridge\" 的净化框架，旨在通过潜在扩散模型去除语音中的保护性扰动，从而击败基于扰动的声纹防御系统，以恢复可克隆的声音。 根据筛选标准，该论文不符合研究要求，原因如下： 1.  **核心判断不符（第一步）**：论文的本质属于对抗性攻击与防御领域，专注于音频信号处理和声纹安全，而非构建、改进或演化 LLM智能体。虽然文中提到了 Whisper（一种ASR模型），但它仅作为辅助引导，并非论文的核心主体，也不涉及智能体的规划、记忆或工具使用等 Agentic 特性。 2.  **触发排除标准（第三步）**：论文明确涉及 `Security`（安全）、`Privacy`（隐私）、`Defenses`（防御）、`Adversaries`（对手）以及 `Robustness`（鲁棒性）。根据筛选规则，只要论文的主要贡献是关于安全与对齐（包括对抗性攻击和防御机制），一律排除。 综上所述，该论文属于语音安全与对抗性机器学习范畴，与 \"LLM智能体及其演化\" 的研究目标无关。"
    },
    {
        "index": "#98",
        "title": "Deep Learning Superresolution for 7T Knee MR Imaging: Impact on Image Quality and Diagnostic Performance",
        "link": "/arxiv/2601.02436",
        "arxiv_id": "2601.02436",
        "authors": "Pinzhen Chen, Libo Xu, Boyang Pan, Jing Li, Yuting Wang, Ran Xiong, Xiaoli Gou, Long Qing, Wenjing Hou, Nan-jie Gong, Wei Chen",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.331282",
        "filter_reason": "这篇论文不符合筛选标准，具体分析如下： 1.  **核心贡献不符（第一步 - 核心判断）**： *   该论文的核心贡献是提出一种基于深度学习（混合注意力Transformer模型）的**超分辨率技术**，用于提升7T膝关节MRI（磁共振成像）的图像质量。 *   这属于**计算机视觉**和**医学影像分析**领域的研究，而非关于构建、改进或演化LLM智能体的研究。 *   根据第一步的排除规则，这属于典型的“非演化型应用”，即只是将深度学习模型应用到特定的医疗领域（膝关节诊断）解决该领域的图像处理问题。 2.  **触犯排除标准（第三步 - 排除标准）**： *   论文明确涉及**多模态与视觉**（医学图像处理、MRI成像）。虽然视觉可以作为智能体的工具，但在本论文中，视觉处理（超分辨率）本身就是研究的核心目的，并没有涉及任何LLM智能体框架或Agentic AI的应用。 3.  **缺乏正面指标（第二步）**： *   论文中没有出现任何关于Agentic AI、LLM-based Agents、Multi-Agent Systems、Planning、Tool Use（作为智能体能力）、Self-Evolving等核心关键词或概念。 综上所述，该论文是一篇纯粹的医学影像处理应用论文，与“LLM智能体及其演化”的研究课题完全无关，因此予以排除。"
    },
    {
        "index": "#99",
        "title": "Quantifying Quanvolutional Neural Networks Robustness for Speech in Healthcare Applications",
        "link": "/arxiv/2601.02432",
        "arxiv_id": "2601.02432",
        "authors": "Ha Tran, Bipasha Kashyap, Pubudu N. Pathirana",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.331791",
        "filter_reason": "这篇论文的核心贡献是评估量子卷积神经网络（QNNs）在医疗保健语音应用（情感识别和语音病理检测）中的鲁棒性，并将其与经典的卷积神经网络（CNNs）进行了对比。 根据筛选标准，该论文被排除的原因如下： 1.  **核心判断不符（第一步）**：论文的研究对象是量子机器学习模型（QNN）和经典CNN，而非大语言模型（LLM）或基于LLM的智能体。论文属于“非演化型应用”，即利用特定模型架构解决特定领域（医疗语音处理）的问题，并未涉及构建、改进或演化LLM智能体的方法论。 2.  **缺乏核心关注点（第二步）**：论文中未包含任何关于Agentic AI、多智能体系统、自我演化机制、智能体规划、工具使用或记忆等核心范式或能力的讨论。 3.  **研究焦点偏离**：论文关注的是模型架构（量子与经典）在噪声环境下的鲁棒性评估，属于模型评估与应用研究，完全不在“LLM智能体及其演化”的研究范围内。 因此，该论文不符合您的研究目标。"
    },
    {
        "index": "#102",
        "title": "Spiking Heterogeneous Graph Attention Networks",
        "link": "/arxiv/2601.02401",
        "arxiv_id": "2601.02401",
        "authors": "Buqing Cao, Qian Peng, Xiang Xie, Liang Chen, Min Shi, Jianxun Liu",
        "subjects": "Neural and Evolutionary Computing, Machine Learning, Social and Information Networks",
        "date": "2025-12-31",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.338849",
        "filter_reason": "这篇论文的核心贡献是提出了一种结合脉冲神经网络（SNN）的异构图注意力网络，旨在解决异构图神经网络（HGNN）计算成本高、内存消耗大的问题，主要应用于节点分类任务。 根据您的筛选标准，该论文不符合要求的原因如下： 1.  **触犯排除标准（第三步）**：论文明确涉及“异构图神经网络”、“元路径”和“节点分类”，属于典型的图相关技术研究。根据筛选标准中“图：涉及知识图谱，图神经网络等图相关技术的论文”应予以排除。 2.  **核心判断不符（第一步）**：论文的本质是优化深度学习模型架构（GNN + SNN）以提高能效和推理速度，而非构建、改进或演化LLM智能体。它不涉及智能体的规划、工具使用、记忆或多智能体协作等Agentic AI的核心要素。 3.  **缺乏正面指标**：论文未包含任何关于Agentic AI、LLM-based Agents、Multi-Agent Systems或Self-Evolving的关键词或概念。 综上所述，该论文属于图神经网络领域的架构优化研究，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#84",
        "title": "Which Deep Learner? A Systematic Evaluation of Advanced Deep Forecasting Models Accuracy and Efficiency for Network Traffic Prediction",
        "link": "/arxiv/2601.02694",
        "arxiv_id": "2601.02694",
        "authors": "Eilaf MA Babai, Aalaa MA Babai, Koji Okamura",
        "subjects": "Networking and Internet Architecture, Machine Learning",
        "date": "2026-01-06",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.317492",
        "filter_reason": "这篇论文的核心贡献是对用于网络流量预测的深度学习模型（包括Transformer和传统深度学习方法）进行系统性的评估和比较，旨在找出在准确性、效率和鲁棒性方面表现最佳的模型。 根据筛选标准，该论文不符合研究要求，原因如下： 1.  **核心判断（非演化型应用）**：论文属于典型的“非演化型应用”。它将深度学习模型作为工具应用于特定的垂直领域（网络管理/网络流量预测），解决的是时间序列预测问题，而非构建、改进或演化LLM智能体。 2.  **缺乏Agentic特性**：论文的研究焦点是模型的预测精度、资源消耗（时间、内存、能量）以及对异常和缺失数据的鲁棒性。这些属于基础模型性能评估，完全不涉及智能体的核心特性，如自主规划、工具使用、记忆机制、自我反思或多智能体协作。 3.  **研究焦点不匹配**：我的研究目标是“LLM智能体及其演化”，而该论文关注的是“深度预测模型”和“时间序列分析”，两者在研究对象和方法论上存在本质区别。 综上所述，该论文是一篇关于深度学习模型在特定领域应用评估的文章，不属于Agentic AI的研究范畴。"
    },
    {
        "index": "#96",
        "title": "Mitigating Long-Tailed Anomaly Score Distributions with Importance-Weighted Loss",
        "link": "/arxiv/2601.02440",
        "arxiv_id": "2601.02440",
        "authors": "Jungi Lee, Jungkwon Kim, Chi Zhang, Sangmin Kim, Kwangsun Yoo, Seok-Joo Byun",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.330054",
        "filter_reason": "这篇论文的核心贡献是提出了一种用于异常检测的**重要性加权损失函数**，旨在解决工业应用中长尾异常分数分布（LTD）导致的模型训练偏差问题。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：该论文属于**非演化型应用**。它专注于计算机视觉和信号处理领域的特定算法改进（即改进损失函数以提升异常检测性能），并未涉及构建、改进或演化 LLM智能体、多智能体系统或自我演化框架。 2.  **排除标准（第三步）**：论文明确涉及**视觉**领域，其实验基于“三个基准图像数据集和三个真实世界高光谱成像数据集”。虽然视觉可以作为智能体的工具，但在此论文中，视觉任务是研究核心，而非服务于智能体架构。 3.  **正面指标（第二步）**：论文中完全不包含 Agentic AI、LLM-based Agents、Planning、Tool Use、Multi-Agent Systems 或 Self-Evolving 等核心范式或关键词。 综上所述，该论文属于传统的机器学习/计算机视觉应用研究，与“LLM智能体及其演化”的研究课题无关，因此予以排除。"
    },
    {
        "index": "#104",
        "title": "Cross-Platform Digital Discourse Analysis of the Israel-Hamas Conflict: Sentiment, Topics, and Event Dynamics",
        "link": "/arxiv/2601.02367",
        "arxiv_id": "2601.02367",
        "authors": "Despoina Antonakaki, Sotiris Ioannidis",
        "subjects": "Computers and Society, Artificial Intelligence, Computation and Language, Information Retrieval, Machine Learning, Social and Information Networks",
        "date": "2025-11-27",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.340082",
        "filter_reason": "根据筛选标准，这篇论文不符合研究要求，具体判断如下： 1.  **核心判断（第一步 - 排除非演化型应用）**： *   该论文的核心贡献在于构建了一个用于分析社交媒体数据（Telegram, Twitter/X, Reddit）的**数据集**和**分析管道**（Pipeline），旨在研究以巴冲突中的数字话语、情感和事件动态。 *   这属于典型的**社会科学应用研究**。论文将现有的NLP模型（如BERTopic、Transformer情感模型）作为工具，应用于特定的政治/社会领域（地缘政治冲突分析）。 *   论文并未提出新的LLM智能体架构、多智能体协作框架，也没有涉及智能体的自我演化机制。它仅仅是“使用”模型处理文本数据，而非“构建”或“改进”智能体本身。 2.  **正面指标缺失（第二步）**： *   论文中未出现 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving` 等核心范式。 *   虽然提到了“Transformer-based models”，但这仅作为情感分析的工具，不具备 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Correction`（自我修正）等智能体关键能力。 3.  **概念混淆澄清（第四步）**： *   摘要中提到的 \"evolution of digital conflict communication\" 指的是**社会传播现象的演化**（即舆论如何随时间变化），而非AI智能体的**自我演化**（Self-Evolving，即模型通过反馈自我完善）。这属于完全不同的研究领域。 综上所述，该论文属于将NLP技术应用于社会科学的垂直领域应用，缺乏关于LLM智能体构建、多智能体系统或自我演化机制的核心贡献，因此予以排除。"
    },
    {
        "index": "#93",
        "title": "Variational (Energy-Based) Spectral Learning: A Machine Learning Framework for Solving Partial Differential Equations",
        "link": "/arxiv/2601.02492",
        "arxiv_id": "2601.02492",
        "authors": "M. M. Hammad",
        "subjects": "Numerical Analysis, Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.328359",
        "filter_reason": "这篇论文完全不符合“LLM智能体及其演化”的研究范围，具体判断依据如下： 1.  **核心贡献不匹配 (第一步 - 核心判断)**： *   该论文的核心贡献是提出了一种名为“变分谱学习 (VSL)”的机器学习框架，用于求解偏微分方程。 *   这属于“AI for Science”（科学计算）或数值分析的范畴，而非构建或演化智能体。论文中并未涉及任何大语言模型（LLM）作为核心组件。 2.  **缺乏Agentic特性 (第一步 & 第二步 - 正面指标)**： *   论文关注的是数学方程的数值求解、谱展开和梯度优化，完全不涉及智能体的关键特性，如规划、工具使用、记忆、自我反思或多智能体协作。 *   文中提到的“优化”是指数学上的目标函数最小化，而非智能体的自我演化或自我完善机制。 3.  **属于非演化型应用 (第一步 - 排除标准)**： *   该研究是将机器学习方法（TensorFlow/Keras）应用于特定领域（数学/物理）来解决PDE问题。根据筛选标准，这种将基础模型或ML工具应用于特定垂直领域且不涉及智能体框架构建的论文，属于“非演化型应用”，应当排除。 综上所述，该论文是一篇关于科学计算和数值方法的论文，与LLM智能体、多智能体系统或自我演化机制无关。"
    },
    {
        "index": "#94",
        "title": "A Spatio-Temporal Deep Learning Approach For High-Resolution Gridded Monsoon Prediction",
        "link": "/arxiv/2601.02445",
        "arxiv_id": "2601.02445",
        "authors": "Parashjyoti Borah, Sanghamitra Sarkar, Ranjan Phukan",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.328992",
        "filter_reason": "这篇论文完全不符合我的研究范围，依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出一种基于卷积神经网络（CNN）的深度学习框架，用于解决气象学领域的特定问题——印度夏季季风的高分辨率网格预测。这属于典型的“非演化型应用”，即利用深度学习模型（而非LLM智能体）作为工具去解决特定领域（气象/气候）的问题。它不涉及构建、改进或演化LLM智能体。 2.  **技术路线不符：** 论文明确指出其方法是将预测任务重构为“时空计算机视觉任务”，使用CNN架构处理多通道图像数据。这与我的研究焦点“LLM智能体”及其相关技术（如规划、工具使用、记忆机制等）毫无关联。 3.  **缺乏关键指标（第二步）：** 论文中未包含任何关于Agentic AI、Multi-Agent Systems、Self-Evolving、Planning、Tool Use或Memory等核心范式或能力的描述。 综上所述，该论文是一篇纯粹的气象预测领域的应用型深度学习研究，不属于LLM智能体及其演化的范畴。"
    },
    {
        "index": "#101",
        "title": "SpikySpace: A Spiking State Space Model for Energy-Efficient Time Series Forecasting",
        "link": "/arxiv/2601.02411",
        "arxiv_id": "2601.02411",
        "authors": "Kaiwen Tang, Jiaqi Zheng, Yuze Jin, Yupeng Qiu, Guangda Sun, Zhanglu Yan, Weng-Fai Wong",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Machine Learning",
        "date": "2026-01-02",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.338261",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心判断（第一步）：** *   **非LLM智能体研究**：论文的核心贡献是提出了一种名为 \"SpikySpace\" 的脉冲状态空间模型，结合了脉冲神经网络（SNN）和状态空间模型（SSM）。这属于新型神经网络架构的设计，而非基于大语言模型（LLM）的智能体研究。 *   **非演化型应用**：论文的目标是解决时间序列预测中的能耗和延迟问题，属于将特定模型架构应用于特定领域（交通管理、工业监测等）的应用型研究，不涉及智能体的构建、改进或演化。 2.  **排除标准（第三步）：** *   **基础设施与硬件优化**：论文的重点在于通过脉冲计算和神经形态芯片友好的设计来降低能耗，这更偏向于模型基础设施、硬件加速和部署优化，而非Agentic AI的算法或机制研究。 3.  **缺乏核心指标（第二步）：** *   论文中未涉及任何关于 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving` 的范式。 *   不包含智能体的核心能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Self-Reflection`（自我反思）或 `Collaboration`（协作）。 综上所述，该论文主要关注的是针对时间序列预测的高效神经网络架构设计，与“LLM智能体及其演化”这一课题无直接关联，因此予以排除。"
    },
    {
        "index": "#100",
        "title": "NitroGen: An Open Foundation Model for Generalist Gaming Agents",
        "link": "/arxiv/2601.02427",
        "arxiv_id": "2601.02427",
        "authors": "Loïc Magne, Anas Awadalla, Guanzhi Wang, Yinzhen Xu, Joshua Belofsky, Fengyuan Hu, Joohwan Kim, Ludwig Schmidt, Georgia Gkioxari, Jan Kautz, Yisong Yue, Yejin Choi, Yuke Zhu, Linxi \"Jim\" Fan",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2026-01-04",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.337683",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心判断（非LLM智能体）**：论文的核心贡献是构建一个“视觉-动作基础模型”，主要利用行为克隆在游戏视频上进行训练。虽然它涉及“智能体”，但其本质是基于视觉输入的具身智能或强化学习/模仿学习模型，而非以大语言模型（LLM）为核心大脑的“LLM智能体”。它缺乏LLM智能体典型的语言推理、规划或工具使用特征。 2.  **触发排除标准（多模态与视觉）**：根据第三步排除标准，涉及 `Vision`、`Vision-Language` 的论文通常需要排除，除非视觉仅作为智能体感知环境的工具。在本文中，视觉是模型架构的核心输入模态，且论文重点在于视觉-动作的映射，而非LLM的决策逻辑，因此属于被排除的多模态/视觉模型范畴。 3.  **缺乏核心关注点**：论文未涉及 `Agentic AI` 的核心范式（如ReAct、ToT等），也未涉及多智能体协作或自我演化机制，而是侧重于跨游戏的泛化能力和行为克隆技术。 综上所述，该论文属于具身智能或视觉运动控制领域，而非LLM智能体及其演化的研究范畴。"
    },
    {
        "index": "#1",
        "title": "Automated Semantic Rules Detection (ASRD) for Emergent Communication Interpretation",
        "link": "/arxiv/2601.03254",
        "arxiv_id": "2601.03254",
        "authors": "Bastien Vanderplaetse, Xavier Siebert, Stéphane Dupont",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.286451",
        "filter_reason": "1.  **核心贡献分析**：该论文的核心贡献是提出了一种名为 ASRD（自动语义规则检测）的算法，用于提取和分析多智能体在 Lewis Game 中交换的消息模式。其目的是为了解决涌现语言的可解释性问题，即通过将消息模式与输入数据属性关联来简化对涌现通信的分析。 2.  **触犯排除标准**：根据第三步排除标准，主要贡献涉及 `Interpretability` (可解释性) 或 `Explainability (XAI)` 的论文一律排除。本文明确指出其研究焦点在于 \"interpretability of emergent languages\"（涌现语言的可解释性），属于对智能体行为的分析工具，而非智能体本身的构建。 3.  **不符合核心目标**：我的研究目标是筛选关于“构建、改进或演化 LLM智能体”的论文。虽然本文背景涉及多智能体系统，但它并没有提出新的智能体架构、协作机制或自我演化框架，而是针对智能体产生的通信数据进行事后分析。 4.  **结论**：该论文属于可解释性分析范畴，而非 Agentic AI 的方法论或框架研究，因此不符合筛选要求。"
    },
    {
        "index": "#2",
        "title": "STReasoner: Empowering LLMs for Spatio-Temporal Reasoning in Time Series via Spatial-Aware Reinforcement Learning",
        "link": "/arxiv/2601.03248",
        "arxiv_id": "2601.03248",
        "authors": "Juntong Ni, Shiyu Wang, Ming Jin, Qi He, Wei Jin",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.287174",
        "filter_reason": "根据您的筛选标准，这篇论文不符合您的研究范围，主要基于以下核心判断： 1.  **触犯明确的排除标准（图相关技术）**： 在第三步“排除标准”中，您明确指出排除涉及“知识图谱，图神经网络等图相关技术的论文”。该论文的标题和摘要中多次强调其核心是处理“Spatial dependencies”（空间依赖）和“Graph structure”（图结构），并提出了“Spatial-Aware”（空间感知）的强化学习算法。这表明图技术是该论文方法论的核心组成部分，因此直接触犯了排除规则。 2.  **属于“非演化型应用”**： 根据第一步的排除规则，该论文是将LLM应用于特定领域（时间序列分析、交通网络、电网等）来解决该领域的推理问题。虽然它提出了STReasoner框架，但其核心目标是提升“时空推理”这一特定领域的任务能力，而非构建通用的LLM智能体架构、规划机制或自我演化框架。 3.  **非核心的Agentic研究**： 尽管摘要中提到了“多智能体数据合成管道”，但这仅用于生成基准数据，并非论文的核心贡献（STReasoner模型）。STReasoner本身主要关注的是通过强化学习来增强模型对时空逻辑的推理能力，这属于特定领域的推理增强，而非智能体的自主规划、工具使用或记忆机制等Agentic AI的核心焦点。 综上所述，该论文侧重于特定领域（时空/时间序列）的推理优化且涉及图技术，不符合您关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#103",
        "title": "How to Discover Knowledge for FutureG: Contextual RAG and LLM Prompting for O-RAN",
        "link": "/arxiv/2601.02382",
        "arxiv_id": "2601.02382",
        "authors": "Nathan Conger, Nathan Scollar, Kemal Davaslioglu, Yalin E. Sagduyu, Sastry Kompella",
        "subjects": "Networking and Internet Architecture, Artificial Intelligence, Information Retrieval, Machine Learning",
        "date": "2025-12-18",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.339515",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下分析： 1.  **核心判断（第一步 - 排除非演化型应用）**： 论文的核心贡献是提出一种名为 \"Contextual Retrieval-Augmented Generation (Contextual RAG)\" 的检索增强问答框架，并将其应用于特定的垂直领域——O-RAN（5G/6G无线网络）。这属于将LLM/RAG技术作为工具应用到特定领域（电信/网络工程）去解决该领域的文档理解和问答问题。根据筛选标准中的“排除 1：非演化型应用”，这类论文应予以排除。 2.  **缺乏Agentic核心要素（第二步）**： 虽然论文提到了 \"Chain-of-Thought (CoT)\"，但它仅作为一种提示策略用于评估问答效果，而非作为智能体自主规划或推理的核心框架。论文没有涉及智能体的关键能力，如自主规划、工具使用（Tool Use，这里RAG是被优化的对象，而非智能体主动调用的工具之一）、记忆机制或自我反思。 3.  **不属于自我演化（第四步）**： 尽管论文提到了“动态领域”和“数据演化”，但其解决方法是通过改进检索策略（Contextual RAG）来适应外部数据的变化，而不是智能体通过经验、反思或环境反馈进行自我完善、迭代或参数更新。因此，它不符合“自我演化”的定义。 综上所述，该论文是一篇典型的领域应用型论文，侧重于RAG技术的改进在特定通信领域的应用，而非关于LLM智能体构建、多智能体系统或自我演化机制的研究。"
    },
    {
        "index": "#6",
        "title": "DIP: Dynamic In-Context Planner For Diffusion Language Models",
        "link": "/arxiv/2601.03199",
        "arxiv_id": "2601.03199",
        "authors": "Yang Li, Han Meng, Chenan Wang, Haipeng Chen",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.290264",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心贡献属于基础设施与效率优化**：论文的核心目标是解决扩散语言模型（DLMs）在上下文长度增加时的计算成本问题，并提出了一种名为 DIP 的上下文优化方法。其核心贡献在于实现“推理加速”和降低计算成本，这属于模型基础设施或部署优化的范畴，符合第一步中的排除标准（基础设施）。 2.  **并非 Agentic AI 的规划**：尽管标题中包含 \"Planner\"，但摘要明确指出这是一种 \"context-optimization method\"（上下文优化方法），用于动态选择和插入上下文示例。这里的“规划”是指对输入提示的优化，而非智能体在复杂任务中的自主规划、行动决策或工具使用。它不涉及智能体的自主性、记忆机制或与环境的交互。 3.  **缺乏智能体演化或协作机制**：论文未涉及多智能体系统、智能体间的通信协作，也未涉及智能体通过经验或反馈进行自我演化的机制。 综上所述，该论文主要关注模型推理效率的提升，而非构建、改进或演化 LLM 智能体的方法论，因此予以排除。"
    },
    {
        "index": "#97",
        "title": "TAP-ViTs: Task-Adaptive Pruning for On-Device Deployment of Vision Transformers",
        "link": "/arxiv/2601.02437",
        "arxiv_id": "2601.02437",
        "authors": "Zhibo Wang, Zuoyuan Zhang, Xiaoyi Pang, Qile Zhang, Xuanyi Hao, Shuguo Zhuo, Peng Sun",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2026-01-05",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.330622",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#9",
        "title": "Maximizing Local Entropy Where It Matters: Prefix-Aware Localized LLM Unlearning",
        "link": "/arxiv/2601.03190",
        "arxiv_id": "2601.03190",
        "authors": "Naixin Zhai, Pengyang Shao, Binbin Zheng, Fei Shen, Long Bai, Xun Yang",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.297968",
        "filter_reason": "1.  **核心贡献分析**: 该论文的核心贡献是提出了一种名为 PALU (Prefix-Aware Localized Unlearning) 的框架，旨在解决“机器遗忘”问题。其目标是让大模型有效地“遗忘”敏感知识，同时尽量保持模型的通用性能。这属于模型安全、隐私保护和模型修改的范畴。 2.  **排除标准匹配 (第三步)**: 根据筛选标准中的第三步“排除标准”，只要论文的主要贡献是关于 `Safety` (安全)、`Security` (安全/隐私) 或 `Alignment` (对齐) 的，一律排除。机器遗忘是模型安全和隐私领域的一个核心子问题，因此该论文直接触发了排除规则。 3.  **与研究目标不符**: 论文的研究焦点不在于构建、改进或演化 LLM智能体。它没有涉及智能体的规划、工具使用、多智能体协作或自我演化机制。虽然它涉及对模型行为的调整，但这种调整是基于安全目的的参数优化，而非赋予智能体自主性或提升其在复杂任务中的Agentic能力。 综上所述，该论文属于模型安全与隐私领域，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#12",
        "title": "Decoupling the Effect of Chain-of-Thought Reasoning: A Human Label Variation Perspective",
        "link": "/arxiv/2601.03154",
        "arxiv_id": "2601.03154",
        "authors": "Beiduo Chen, Tiancheng Hu, Caiqi Zhang, Robert Litschko, Anna Korhonen, Barbara Plank",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.300069",
        "filter_reason": "1.  **核心判断**: 这篇论文的核心贡献是对 Chain-of-Thought (CoT) 推理机制的实证分析和解耦。它旨在探究 CoT 文本与模型内在先验如何共同影响模型的输出分布和准确性，特别是针对“人类标签变异性”这一特定任务。 2.  **排除依据**: 根据筛选标准第一步中的“非Agentic的推理”排除规则，该论文应被排除。尽管论文涉及 CoT（思维链），但其研究重点是分析 CoT 作为一种推理机制如何影响模型的基础预测能力和分布校准，而不是构建一个具有自主规划、工具使用或记忆能力的 LLM 智能体。 3.  **不符合研究焦点**: 论文未涉及 Agentic AI 的核心要素（如智能体框架、工具调用、自我反思、多智能体协作或自我演化机制）。它属于对 LLM 基础推理行为的分析研究，而非智能体系统的构建或改进。"
    },
    {
        "index": "#14",
        "title": "Limited Linguistic Diversity in Embodied AI Datasets",
        "link": "/arxiv/2601.03136",
        "arxiv_id": "2601.03136",
        "authors": "Selma Wanna, Agnes Luhtaru, Jonathan Salfity, Ryan Barron, Juston Moore, Cynthia Matuszek, Mitch Pryor",
        "subjects": "Computation and Language, Artificial Intelligence, Robotics",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.306923",
        "filter_reason": "这篇论文不符合我的研究范围，依据如下： 1.  **核心贡献不符 (第一步 - 核心判断)**: *   论文的核心是对现有的具身AI（Embodied AI）数据集进行**审计和分析**，重点在于评估这些数据集中指令语言的多样性（如词汇丰富度、重复率、句法复杂性等）。 *   这属于**数据集分析**或**数据质量评估**的研究，而非构建、改进或演化LLM智能体的方法论或新框架。论文没有提出新的智能体架构、规划机制、工具使用流程或多智能体协作协议。 2.  **缺乏Agentic AI的核心要素 (第二步 - 正面指标)**: *   论文不涉及智能体的关键能力，如规划、记忆、自我反思、工具使用或自我演化。 *   它也不涉及多智能体系统（MAS）中的协作、通信或社会学习。 3.  **触及排除领域 (第三步 - 排除标准)**: *   论文主要关注 **Vision-Language-Action (VLA) models** 和 **Embodied AI**，这属于多模态与具身智能的范畴。虽然我的筛选标准中提到“除非它们被用作智能体感知环境的工具”，但本论文的研究对象是**数据集本身的语言特征**，而不是利用视觉工具来增强LLM智能体的能力。因此，它属于被排除的多模态/视觉基础研究，而非Agentic AI的核心研究。 综上所述，该论文是一篇关于数据集特性的分析文章，而非关于LLM智能体构建或演化的研究，因此予以排除。"
    },
    {
        "index": "#4",
        "title": "MalruleLib: Large-Scale Executable Misconception Reasoning with Step Traces for Modeling Student Thinking in Mathematics",
        "link": "/arxiv/2601.03217",
        "arxiv_id": "2601.03217",
        "authors": "Xinghe Chen, Naiming Liu, Shashank Sonkar",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.288905",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下判断： 1.  **核心判断（非Agentic应用）**：论文的核心贡献是构建了一个名为 \"MalruleLib\" 的框架和数据集，用于生成数学误解的推理步骤，旨在评估LLM建模学生思维的能力。这属于**教育AI**领域的特定应用，而非构建、改进或演化LLM智能体本身。根据筛选标准第一步中的“排除非演化型应用”，该论文将LLM作为工具应用于教育领域（数学学生建模），因此应被排除。 2.  **缺乏Agentic特性**：论文关注的是“误解推理”和“学生思维建模”，这是对LLM基础推理能力的评估（Benchmark/Dataset构建），而非赋予LLM智能体的自主性、规划、工具使用或记忆等Agentic核心能力。虽然提到了“可执行程序”，但这指的是生成测试数据的机制，而非智能体在运行时调用工具的能力。 3.  **基础设施性质**：摘要中明确提到 \"We release MalruleLib as infrastructure for educational AI\"，表明其主要贡献是基础设施（数据集/评估框架），而非智能体的算法或架构创新。 综上所述，该论文属于教育领域的应用与评估研究，不涉及LLM智能体的构建、多智能体协作或自我演化机制。"
    },
    {
        "index": "#15",
        "title": "Improving Indigenous Language Machine Translation with Synthetic Data and Language-Specific Preprocessing",
        "link": "/arxiv/2601.03135",
        "arxiv_id": "2601.03135",
        "authors": "Aashish Dhawan, Christopher Driggers-Ellis, Christan Grant, Daisy Zhe Wang",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.307447",
        "filter_reason": "这篇论文的核心贡献在于利用合成数据和特定语言的预处理技术来改善低资源土著语言的神经机器翻译（NMT）效果。 根据筛选标准的第一步“核心判断”，该论文属于典型的“非演化型应用”。论文将 mBART 模型作为工具应用于特定的垂直领域（语言翻译），重点在于数据增强（合成数据）和数据处理（预处理），旨在解决特定领域的翻译任务，而非构建、改进或演化 LLM 智能体。 虽然论文涉及“合成数据生成”，但这仅是用于训练静态翻译模型的数据增强手段，并不涉及智能体的自我演化、自我反思或迭代改进机制。论文中也没有体现任何关于智能体规划、工具使用、多智能体协作或 Agentic AI 的核心范式。 因此，该论文完全不符合“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#105",
        "title": "FUSE : Failure-aware Usage of Subagent Evidence for MultiModal Search and Recommendation",
        "link": "/arxiv/2601.02365",
        "arxiv_id": "2601.02365",
        "authors": "Tushar Vatsa, Vibha Belavadi, Priya Shanmugasundaram, Suhas Suresha, Dewang Sultania",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-11-15",
        "category": "cs.LG",
        "crawl_time": "2026-01-08T11:00:05.340660",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#7",
        "title": "X-MuTeST: A Multilingual Benchmark for Explainable Hate Speech Detection and A Novel LLM-consulted Explanation Framework",
        "link": "/arxiv/2601.03194",
        "arxiv_id": "2601.03194",
        "authors": "Mohammad Zia Ur Rehman, Sai Kartheek Reddy Kasu, Shashivardhan Reddy Koppula, Sai Rithwik Reddy Chirra, Shwetank Shekhar Singh, Nagendra Kumar",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.296186",
        "filter_reason": "解析失败"
    },
    {
        "index": "#21",
        "title": "Learning to Diagnose and Correct Moral Errors: Towards Enhancing Moral Sensitivity in Large Language Models",
        "link": "/arxiv/2601.03079",
        "arxiv_id": "2601.03079",
        "authors": "Bocheng Chen, Han Zi, Xi Chen, Xitong Zhang, Kristen Johnson, Guangliang Liu",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.310461",
        "filter_reason": "根据筛选标准，这篇论文不符合研究要求，主要基于以下判断： 1.  **触发了第三步的“排除标准”**：论文的核心目标是“增强大语言模型的道德敏感性”以及“纠正道德错误”。这明确属于 `Safety`（安全）和 `Alignment`（对齐）的研究范畴。根据指令，只要论文的主要贡献是关于对齐或安全的，一律排除。 2.  **不属于核心研究焦点**：虽然论文中提到了“诊断和纠正错误”，这看似类似于智能体的自我反思，但其应用场景和目的仅限于道德判断和价值观对齐，而非为了提升智能体在复杂任务中的 `Planning`（规划）、`Tool Use`（工具使用）或解决实际问题的 `Agentic` 能力。 3.  **非自我演化机制**：论文提出的“语用推理方法”旨在通过特定视角处理道德话语，这属于模型对齐的技术手段，而非智能体通过经验、反思或环境反馈进行能力迭代的“自我演化”框架。 综上所述，该论文属于LLM安全与对齐领域，而非LLM智能体构建或演化的研究，因此予以排除。"
    },
    {
        "index": "#3",
        "title": "Multi-RADS Synthetic Radiology Report Dataset and Head-to-Head Benchmarking of 41 Open-Weight and Proprietary Language Models",
        "link": "/arxiv/2601.03232",
        "arxiv_id": "2601.03232",
        "authors": "Kartik Bose, Abhinandan Kumar, Raghuraman Soundararajan, Priya Mudgil, Samonee Ralmilay, Niharika Dutta, Manphool Singhal, Arun Kumar, Saugata Sen, Anurima Patra, Priya Ghosh, Abanti Das, Amit Gupta, Ashish Verma, Dipin Sudhakaran, Ekta Dhamija, Himangi Unde, Ishan Kumar, Krithika Rangarajan, Prerna Garg, Rachel Sequeira, Sudhin Shylendran, Taruna Yadav, Tej Pal, Pankaj Gupta",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.288194",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#23",
        "title": "Detecting Hallucinations in Retrieval-Augmented Generation via Semantic-level Internal Reasoning Graph",
        "link": "/arxiv/2601.03052",
        "arxiv_id": "2601.03052",
        "authors": "Jianpeng Hu, Yanzeng Li, Jialun Zhong, Wenfa Qi, Lei Zou",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.346623",
        "filter_reason": "这篇论文不符合筛选要求，主要基于以下判断： 1.  **触发排除标准（核心原因）**：根据筛选标准第三步，主要贡献涉及 `Hallucination`（幻觉）的论文属于“安全与对齐”范畴，应一律排除。该论文的标题和摘要明确指出其核心目标是“Detecting Hallucinations”（检测幻觉），这直接违背了排除标准。 2.  **核心贡献不符**：论文的核心在于提出一种基于语义级内部推理图的检测方法，用于评估RAG系统的忠实度。这属于模型评估、可解释性或安全性研究，而非构建、改进或演化LLM智能体的方法论。 3.  **非Agentic研究**：尽管论文中提到了“Internal Reasoning Graph”（内部推理图），但这是一种用于分析模型内部注意力机制和归因的技术手段，旨在作为判别器进行检测，而非智能体用于自主行动、规划或自我演化的框架。 综上所述，该论文属于安全与评估领域，不属于LLM智能体构建或演化的研究范畴。"
    },
    {
        "index": "#26",
        "title": "BaseCal: Unsupervised Confidence Calibration via Base Model Signals",
        "link": "/arxiv/2601.03042",
        "arxiv_id": "2601.03042",
        "authors": "Hexiang Tan, Wanli Yang, Junwei Zhang, Xin Chen, Rui Tang, Du Su, Jingang Wang, Yuanzhuo Wang, Fei Sun, Xueqi Cheng",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.349048",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为 BaseCal 的方法，用于校准后训练大语言模型（PoLLMs）的置信度，以解决其过度自信的问题。该方法通过利用基础模型的信号（如重评估或隐藏状态投影）来实现无监督的校准。 根据筛选标准，该论文不符合我的研究目标，原因如下： 1.  **核心判断不符**：论文的本质是关于模型输出的**置信度校准**和**可靠性评估**，属于模型评估或基础模型属性优化的范畴。它并未涉及构建、改进或演化 LLM智能体的方法论或新框架。 2.  **缺乏Agentic特征**：论文未涉及任何智能体的核心能力，如规划、工具使用、记忆、自我反思或多智能体协作等。 3.  **非自我演化**：虽然论文提到了“Base Model”和“Post-trained Model”的对比，但其目的是校准概率分布，而非让智能体通过经验、反思或环境反馈进行自我完善和迭代。 综上所述，该论文属于模型评估与校准领域的研究，而非 Agentic AI 或智能体演化的研究，因此予以排除。"
    },
    {
        "index": "#16",
        "title": "The Anatomy of Conversational Scams: A Topic-Based Red Teaming Analysis of Multi-Turn Interactions in LLMs",
        "link": "/arxiv/2601.03134",
        "arxiv_id": "2601.03134",
        "authors": "Xiangzhe Yuan, Zhenhao Zhang, Haoming Tang, Siying Hu",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.307904",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下分析： 1.  **核心贡献分析 (第一步)**: 论文的核心在于对LLM在多轮对话中的安全风险（特别是诈骗）进行红队测试和分析。它关注的是“安全评估”、“攻击策略”和“防御机制”，属于安全领域的研究，而非构建、改进或演化LLM智能体的新架构或方法论。 2.  **触发排除标准 (第三步)**: 根据筛选标准第三步，只要论文的主要贡献是关于 `Safety`（安全）或 `Security`（安全），一律排除。该论文明确指出其研究目的是系统研究多轮诈骗场景中的风险，并分析安全护栏的激活和失败，这完全属于安全与对齐的研究范畴。 3.  **工具与目的的区别**: 虽然论文使用了 \"LLM-to-LLM simulation framework\"（这本质上是一个多智能体交互设置），但这只是作为进行红队测试和安全分析的工具/实验手段，而不是为了改进多智能体的协作、通信或演化能力。 综上所述，尽管论文涉及了多轮交互和模拟，但其本质是安全研究，而非Agentic AI的构建或演化，因此应予以排除。"
    },
    {
        "index": "#5",
        "title": "UltraLogic: Enhancing LLM Reasoning through Large-Scale Data Synthesis and Bipolar Float Reward",
        "link": "/arxiv/2601.03205",
        "arxiv_id": "2601.03205",
        "authors": "Yile Liu, Yixian Liu, Zongwei Li, Yufei Huang, Xinhua Feng, Zhichao Hu, Jinglu Hu, Jianfeng Yan, Fengzong Lian, Yuhong Liu",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.289680",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#27",
        "title": "NorwAI's Large Language Models: Technical Report",
        "link": "/arxiv/2601.03034",
        "arxiv_id": "2601.03034",
        "authors": "Jon Atle Gulla, Peng Liu, Lemei Zhang",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.349672",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下判断： 1.  **核心贡献不符（第一步核心判断）**：该论文是一篇技术报告，其核心贡献在于构建针对挪威语和斯堪的纳维亚语的**基础大语言模型**。内容涵盖了模型架构、预训练数据、分词器设计、微调策略和部署评估。这属于**模型基础设施**和基础模型训练的范畴，而非构建、改进或演化LLM智能体的方法论或新框架。 2.  **缺乏Agentic要素（第二步正面指标）**：虽然摘要中提到了“assistant-style capabilities”（助手风格能力），但这通常指的是指令遵循能力，并不等同于具备自主规划、工具使用、记忆或自我反思能力的Agentic AI。论文中未涉及任何关于智能体规划、工具增强、多智能体协作或自我演化机制的研究。 3.  **触犯排除标准（第一步排除标准）**：根据筛选标准，主要关注模型基础设施、部署优化的研究应被排除。该论文重点在于模型的训练过程和语言适应性优化，属于基础模型研发，而非智能体系统的研发。 综上所述，该论文属于基础模型构建与基础设施领域，与“LLM智能体及其演化”的研究焦点无关。"
    },
    {
        "index": "#29",
        "title": "LittiChoQA: Literary Texts in Indic Languages Chosen for Question Answering",
        "link": "/arxiv/2601.03025",
        "arxiv_id": "2601.03025",
        "authors": "Aarya Khandelwal, Ritwik Mishra, Rajiv Ratn Shah",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.350893",
        "filter_reason": "这篇论文的核心贡献在于构建了一个名为 **LittiChoQA** 的长文本问答数据集，并评估了现有多语言大语言模型在该数据集上的表现。 根据筛选标准，我的判断过程如下： 1.  **核心判断（第一步）**：论文的本质是**数据集构建与模型评估**，而非构建、改进或演化 LLM 智能体。它主要关注的是特定领域（印度文学文本）的长语境问答能力，属于将 LLM 应用于特定 NLP 任务的范畴，符合“非演化型应用”的排除标准。 2.  **缺乏 Agentic 核心要素（第二步）**：论文摘要中未涉及任何智能体相关的核心范式或能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆机制）、`Multi-Agent`（多智能体协作）或 `Self-Evolving`（自我演化）。虽然提到了“长语境”，但这仅作为模型处理文本长度的能力评估，而非智能体架构中的记忆或规划模块。 3.  **研究焦点不符**：我的研究焦点是 Agentic AI 的方法论和框架，而该论文侧重于资源稀缺语言的数据集填补和基础模型性能的基准测试。 综上所述，该论文属于基础 NLP 资源与评估研究，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#19",
        "title": "Who Laughs with Whom? Disentangling Influential Factors in Humor Preferences across User Clusters and LLMs",
        "link": "/arxiv/2601.03103",
        "arxiv_id": "2601.03103",
        "authors": "Soichiro Murakami, Hidetaka Kamigaito, Hiroya Takamura, Manabu Okumura",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.309465",
        "filter_reason": "这篇论文的核心贡献在于分析幽默偏好，通过聚类用户和利用Bradley-Terry-Luce模型来解构影响幽默的因素，并探索LLM如何通过角色提示来模拟这些偏好。 根据筛选标准，该论文不符合研究目标，原因如下： 1.  **核心判断（第一步）**：该论文属于“非演化型应用”。它将LLM作为一个工具来评估或模拟特定领域（幽默/心理学）的用户偏好，而不是构建、改进或演化LLM智能体本身。论文中提到的“Persona prompting”仅是一种静态的提示工程技巧，用于偏置模型输出，并不涉及智能体的自主规划、工具使用或记忆机制。 2.  **缺乏Agentic特征（第二步）**：论文未涉及任何核心的智能体能力，如规划、工具增强、自我反思、多智能体协作或自我演化机制。 3.  **结论**：这是一篇关于LLM在特定人文/心理学任务上的评估与对齐研究，而非关于Agentic AI架构或演化的研究，因此予以排除。"
    },
    {
        "index": "#11",
        "title": "WebAnchor: Anchoring Agent Planning to Stabilize Long-Horizon Web Reasoning",
        "link": "/arxiv/2601.03164",
        "arxiv_id": "2601.03164",
        "authors": "Yu Xinmiao, Zhang Liwen, Feng Xiaocheng, Jiang Yong, Qin Bing, Xie Pengjun, Zhou Jingren",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.299359",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#13",
        "title": "Self-Verification is All You Need To Pass The Japanese Bar Examination",
        "link": "/arxiv/2601.03144",
        "arxiv_id": "2601.03144",
        "authors": "Andrew Shin",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.300682",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#33",
        "title": "SentGraph: Hierarchical Sentence Graph for Multi-hop Retrieval-Augmented Question Answering",
        "link": "/arxiv/2601.03014",
        "arxiv_id": "2601.03014",
        "authors": "Junli Liang, Pengfei Zhou, Wangqiu Zhou, Wenjie Qing, Qi Zhao, Ziwen Wang, Qi Song, Xiangyang Li",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.363802",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心贡献不符 (第一步)**: 论文的核心贡献是提出一种名为 \"SentGraph\" 的**检索增强生成 (RAG) 框架**，旨在通过构建句子级的图结构来优化多跳问答中的证据检索。这属于信息检索和自然语言处理中的推理增强技术，而非构建、改进或演化 LLM 智能体。它没有涉及智能体的自主规划、工具使用循环、记忆机制或自我演化框架。 2.  **触犯排除标准 (第三步)**: 论文明确涉及**图**相关技术。摘要中提到 \"sentence-level graph-based RAG framework\"、\"hierarchical sentence graph\"、\"graph-guided evidence selection\"。根据筛选标准中的排除项，涉及知识图谱、图神经网络等图相关技术的论文应予以排除。 3.  **非Agentic的推理 (第四步)**: 虽然论文涉及 \"multi-hop reasoning\"（多跳推理），但其方法是通过离线构建图结构和在线路径扩展来改进检索到的上下文质量，而非通过智能体的自主规划或行动来解决问题。这属于改进模型输入质量的非Agentic推理优化，而非智能体的行为逻辑。 综上所述，该论文侧重于利用图结构改进RAG的检索效果，不属于 LLM智能体构建、多智能体系统或自我演化的研究范畴。"
    },
    {
        "index": "#32",
        "title": "MMFormalizer: Multimodal Autoformalization in the Wild",
        "link": "/arxiv/2601.03017",
        "arxiv_id": "2601.03017",
        "authors": "Jing Xiong, Qi Han, Yunta Hsieh, Hui Shen, Huajian Xin, Chaofan Tao, Chenyang Zhao, Hengyuan Zhang, Taiqiang Wu, Zhen Zhang, Haochen Wang, Zhongwei Wan, Lingpeng Kong, Ngai Wong",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.363234",
        "filter_reason": "1.  **核心判断 (非Agentic核心)**: 该论文的核心贡献是提出一个名为 \"MMFormalizer\" 的框架，用于解决 \"Autoformalization\"（自动形式化）问题，即将自然语言和视觉信息转化为形式化的数学/物理陈述。这属于特定领域（数学、物理）的推理与翻译任务，而非构建具有自主性、规划能力或工具使用能力的 LLM智能体架构。 2.  **触犯排除标准 (多模态与视觉)**: 论文标题明确包含 \"Multimodal\"（多模态），摘要中强调处理 \"visual elements\"（视觉元素）和 \"perceptually grounded primitives\"（感知基础的原语）。根据筛选标准第三步，涉及多模态与视觉技术的论文通常在排除之列，除非视觉仅作为智能体感知环境的工具。在本研究中，视觉处理是解决自动形式化任务的核心手段，而非服务于智能体的演化或交互框架。 3.  **缺乏Agentic特征**: 尽管论文提到了 \"recursive grounding\"（递归基础）和 \"adaptive recursive termination\"（自适应递归终止），这些是针对形式化生成过程的算法设计，而非智能体的 \"Planning\"（规划）、\"Memory\"（记忆）、\"Tool Use\"（工具使用）或 \"Self-Evolution\"（自我演化）。论文侧重于提升模型在特定领域的逻辑转换和推理准确性，而非智能体的行为模式或演化机制。 综上所述，该论文属于多模态推理与形式化方法的研究，不符合 \"LLM智能体及其演化\" 的研究范围。"
    },
    {
        "index": "#37",
        "title": "P-Check: Advancing Personalized Reward Model via Learning to Generate Dynamic Checklist",
        "link": "/arxiv/2601.02986",
        "arxiv_id": "2601.02986",
        "authors": "Kwangwook Seo, Dongha Lee",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.365841",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为 P-Check 的**个性化奖励建模框架**，旨在通过生成动态清单来对齐模型判断与用户偏好。 根据筛选标准，我的判断过程如下： 1.  **核心判断（第一步）**：论文的本质是关于**奖励模型**和**对齐**的研究，而非构建、改进或演化 LLM 智能体。虽然它涉及生成“清单”，但这用于评估输出质量，而非指导智能体在环境中的行动、规划或工具使用。 2.  **排除标准（第三步）**：这是最关键的排除依据。筛选标准明确规定：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Explainability (XAI)`, `Alignment` (对齐)... 一律排除”。本论文明确聚焦于“Personalized Reward Modeling”和“Align model judgments with individual preferences”，完全属于对齐研究范畴。 3.  **正面指标缺失（第二步）**：论文未涉及 `Agentic AI` 的核心能力（如自主规划、工具使用、记忆机制）或多智能体系统，也不涉及智能体的自我演化机制。 综上所述，该论文属于对齐研究，不符合我关于“LLM智能体及其演化”的研究范围，因此予以排除。"
    },
    {
        "index": "#18",
        "title": "Discovering and Causally Validating Emotion-Sensitive Neurons in Large Audio-Language Models",
        "link": "/arxiv/2601.03115",
        "arxiv_id": "2601.03115",
        "authors": "Xiutian Zhao, Björn Schuller, Berrak Sisman",
        "subjects": "Computation and Language, Audio and Speech Processing",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.308979",
        "filter_reason": "1.  **核心贡献分析**: 该论文的核心贡献在于对大音频语言模型进行**可解释性**研究。具体而言，它旨在发现并因果验证模型内部的“情感敏感神经元”，通过干预这些神经元来分析模型如何处理情感信息。这属于模型内部机制的分析和理解范畴。 2.  **排除标准匹配**: 根据筛选标准第三步（排除标准），主要关注 `Interpretability` (可解释性) 或 `Explainability (XAI)` 的论文应被排除。本文明确指出是“neuron-level interpretability study”（神经元级可解释性研究），完全符合排除条件。 3.  **研究目标不符**: 该研究不涉及构建、改进或演化LLM智能体。它没有提出新的Agentic框架、规划方法、工具使用机制、多智能体协作策略或自我演化算法。它是对现有模型能力的解释性分析，而非智能体架构或能力的开发。 综上所述，这篇论文属于模型可解释性研究，不符合关于“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#42",
        "title": "LLM-Augmented Changepoint Detection: A Framework for Ensemble Detection and Automated Explanation",
        "link": "/arxiv/2601.02957",
        "arxiv_id": "2601.02957",
        "authors": "Fabian Lukassen, Christoph Weisser, Michael Schlee, Manish Kumar, Anton Thielmann, Benjamin Saefken, Thomas Kneib",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.374003",
        "filter_reason": "这篇论文不符合筛选标准，应予以排除。具体判断依据如下： 1.  **核心判断（非演化型应用）**: 论文的核心贡献是提出一个用于“变点检测”的统计学框架，属于时间序列分析领域的特定应用。虽然它使用了LLM来生成解释，但LLM在这里仅作为一个辅助工具（解释器），用于增强统计结果的可读性，而非论文的研究主体。这符合第一步排除标准中的“非演化型应用”，即只是将LLM作为工具应用到特定领域去解决该领域的问题。 2.  **缺乏Agentic特性**: 论文未涉及构建具有自主性、规划能力、记忆机制或工具使用能力的LLM智能体。虽然提到了RAG（检索增强生成），但这仅是为了获取文档信息以生成解释，并非构建一个能够自主规划、反思或与环境交互的智能体架构。 3.  **不符合研究焦点**: 您的研究焦点在于Agentic AI（单智能体、多智能体、自我演化）的方法论或新框架。本文关注的是如何结合统计方法和LLM进行数据分析，而非智能体本身的构建、改进或演化机制。 综上所述，该论文属于应用型研究，而非关于LLM智能体架构或演化的基础研究，因此不符合您的要求。"
    },
    {
        "index": "#28",
        "title": "Reducing Hallucinations in LLMs via Factuality-Aware Preference Learning",
        "link": "/arxiv/2601.03027",
        "arxiv_id": "2601.03027",
        "authors": "Sindhuja Chaduvula, Ahmed Y. Radwan, Azib Farooq, Yani Ioannou, Shaina Raza",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.350290",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为 F-DPO (Factuality-aware Direct Preference Optimization) 的方法，旨在通过偏好学习来减少大语言模型（LLM）的幻觉并提高事实性。 根据筛选标准，判断过程如下： 1.  **符合排除标准（第三步）**：论文的主要研究焦点明确集中在 **`Hallucination` (幻觉)** 和 **`Alignment` (对齐)** 上。筛选标准明确规定：“只要论文的主要贡献是关于 Safety, Security, Interpretability, Explainability (XAI), Alignment (对齐), Watermarking (水印), 或 Hallucination (幻觉)，一律排除。” 因此，该论文直接触发了排除条件。 2.  **不符合核心目标（第一步）**：论文的核心是改进 LLM 的基础训练和对齐方法（DPO 的变体），以提升模型输出的真实性，而非构建、改进或演化 LLM 智能体。它不涉及智能体的规划、工具使用、记忆机制，也不涉及多智能体协作或智能体的自我演化机制。 3.  **缺乏正面指标（第二步）**：论文内容未涉及 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent Systems` 或 `Self-Evolving` 等核心范式或能力。 综上所述，该论文属于模型对齐与安全性研究，不属于 LLM 智能体及其演化的研究范畴。"
    },
    {
        "index": "#38",
        "title": "Mechanistic Knobs in LLMs: Retrieving and Steering High-Order Semantic Features via Sparse Autoencoders",
        "link": "/arxiv/2601.02978",
        "arxiv_id": "2601.02978",
        "authors": "Ruikang Zhang, Shuo Wang, Qi Su",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.366286",
        "filter_reason": "该论文不符合筛选标准，具体判断过程如下： 1.  **核心贡献分析**：这篇论文的核心属于**机制可解释性**领域。它提出了一种基于稀疏自编码器（SAE）的框架，旨在检索和引导LLM内部的高阶语义特征（如人格特质），以实现对模型生成行为的精确控制。其重点在于理解模型内部的表征和通过干预激活来调节输出，而非构建智能体系统。 2.  **触犯排除标准**：根据筛选标准的第三步（排除标准），主要贡献涉及 `Interpretability` (可解释性) 的论文应被排除。该论文明确指出其工作属于 \"Mechanistic Interpretability (MI)\"，旨在通过干预内部特征来调节行为，这完全属于模型解释与控制的范畴。 3.  **不符合核心目标**：论文并未涉及构建、改进或演化LLM智能体（Agentic LLM），也没有涉及多智能体系统或自我演化机制。它没有讨论智能体的规划、工具使用、记忆或协作等关键能力，而是聚焦于底层的特征提取和激活干预。 综上所述，该论文属于模型解释与控制方向，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#36",
        "title": "Mechanistic Interpretability of Large-Scale Counting in LLMs through a System-2 Strategy",
        "link": "/arxiv/2601.02989",
        "arxiv_id": "2601.02989",
        "authors": "Hosein Hasani, Mohammadali Banayeeanzade, Ali Nafisi, Sadegh Mohammadian, Fatemeh Askari, Mobin Bagherian, Amirmohammad Izadi, Mahdieh Soleymani Baghshah",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.365411",
        "filter_reason": "根据您的筛选标准，这篇论文**不符合**您的研究范围，具体判断依据如下： 1.  **核心判断（第一步）：** *   该论文的核心贡献在于对LLM在“计数”任务上的**机制可解释性**分析，并提出了一种测试时的策略来改进这一特定能力。 *   这属于**非Agentic的推理**研究。虽然论文提到了“System-2”和“分解任务”，但这旨在解决模型内部的数学/逻辑计数能力（基础Token预测和逻辑处理），而非构建具有自主规划、工具使用或环境交互能力的智能体框架。 *   论文并未涉及构建、改进或演化LLM智能体本身，而是针对模型架构在特定任务上的局限性进行修补和分析。 2.  **排除标准（第三步）：** *   论文标题明确指出是“Mechanistic Interpretability”（机制可解释性），摘要中提到使用“observational and causal mediation analyses”（观测分析和因果中介分析）来理解底层机制。 *   这完全符合**排除标准**中的“Interpretability (可解释性)”和“Explainability (XAI)”类别。只要论文的主要贡献是关于可解释性，根据您的规则应一律排除。 3.  **特殊与模糊情况处理（第四步）：** *   尽管论文提到了System-2策略，但这并非用于智能体的规划或行动，而是用于改进模型的基础算术/逻辑能力。根据第四步的排除规则：“如果只是关于提高LLM本身基础Token预测的数学或逻辑能力”，应当排除。 综上所述，该论文主要关注模型内部机制的可解释性以及基础逻辑能力的提升，不属于Agentic AI、Multi-Agent Systems或Self-Evolving的研究范畴。"
    },
    {
        "index": "#44",
        "title": "Pearmut: Human Evaluation of Translation Made Trivial",
        "link": "/arxiv/2601.02933",
        "arxiv_id": "2601.02933",
        "authors": "Vilém Zouhar, Tom Kocmi",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.374896",
        "filter_reason": "这篇论文的核心贡献是开发了一个名为 \"Pearmut\" 的**人类评估平台**，旨在简化和自动化机器翻译等任务中的人类评估流程。 根据筛选标准进行判断： 1.  **第一步（核心判断）**：论文的本质属于**基础设施**或**工具开发**。它解决的是评估流程的工程和运营开销问题，而不是构建、改进或演化 LLM 智能体本身。它不涉及智能体的架构设计、规划能力、记忆机制或多智能体协作。 2.  **第三步（排除标准）**：该研究明确属于被排除的“基础设施”范畴。虽然它提到了“active learning-based assignment strategies”（基于主动学习的分配策略），但这是指分配评估任务给人类标注者的算法，而非智能体的自我学习或演化机制。 综上所述，该论文关注的是评估工具的易用性和流程优化，与“LLM智能体及其演化”的研究目标（Agentic AI 的构建与演化）无关，因此予以排除。"
    },
    {
        "index": "#45",
        "title": "Memorization, Emergence, and Explaining Reversal Failures: A Controlled Study of Relational Semantics in LLMs",
        "link": "/arxiv/2601.02931",
        "arxiv_id": "2601.02931",
        "authors": "Yihua Zhu, Qianying Liu, Jiaxin Wang, Fei Cheng, Chaoran Liu, Akiko Aizawa, Sadao Kurohashi, Hidetoshi Shimodaira",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.375426",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献不符 (第一步)**：论文的核心是研究自回归LLM如何学习关系语义（如对称性、反转逻辑），并解释模型在反转任务中失败的原因（归因于自回归顺序偏差）。这属于对LLM基础推理能力和内部机制的机理研究，而非构建、改进或演化LLM智能体。根据第一步的排除标准，这属于“非Agentic的推理”，即关注LLM本身的逻辑预测能力，而非智能体的自主规划或工具使用框架。 2.  **触发排除标准 (第三步)**：论文明确提出了“controlled Knowledge Graph-based synthetic framework”（基于知识图谱的合成框架）来生成训练数据。根据第三步的排除标准，涉及知识图谱的论文属于排除范围。 3.  **缺乏核心关注点 (第二步)**：论文未涉及任何Agentic AI的核心范式（如ReAct、规划、工具使用）、多智能体系统（协作、通信）或自我演化机制（自我完善、迭代改进）。 综上所述，该论文是一篇关于LLM逻辑语义和模型行为的理论分析文章，而非关于LLM智能体架构或演化的研究，因此予以排除。"
    },
    {
        "index": "#39",
        "title": "Correct, Concise and Complete: Multi-stage Training For Adaptive Reasoning",
        "link": "/arxiv/2601.02972",
        "arxiv_id": "2601.02972",
        "authors": "Nathanaël Carraz Rakotonirina, Ren Pang, Neha Anna John, Michael Bohlke-Schneider, Momchil Hardalov",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.366792",
        "filter_reason": "解析失败"
    },
    {
        "index": "#30",
        "title": "MedDialogRubrics: A Comprehensive Benchmark and Evaluation Framework for Multi-turn Medical Consultations in Large Language Models",
        "link": "/arxiv/2601.03023",
        "arxiv_id": "2601.03023",
        "authors": "Lecheng Gong, Weimin Fang, Ting Yang, Dongjie Tao, Chunxiao Guo, Peng Wei, Bo Xie, Jinqun Guan, Zixiao Chen, Fang Shi, Jinjie Gu, Junwei Liu",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.362017",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#50",
        "title": "Transparent Semantic Change Detection with Dependency-Based Profiles",
        "link": "/arxiv/2601.02891",
        "arxiv_id": "2601.02891",
        "authors": "Bach Phan-Tat, Kris Heylen, Dirk Geeraerts, Stefano De Pascale, Dirk Speelman",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.378288",
        "filter_reason": "这篇论文不符合筛选标准，具体分析如下： 1.  **核心判断（第一步）**： *   该论文的核心贡献是提出一种基于依存共现模式的计算方法，用于解决**词汇语义变化检测**这一特定语言学/NLP任务。 *   这属于典型的**非演化型应用**。论文关注的是“语言词汇含义随时间的改变”，而非“智能体能力的演化”或“智能体系统的构建”。它没有涉及构建LLM智能体、多智能体系统或智能体的自我演化机制。 2.  **正面指标缺失（第二步）**： *   论文中不包含任何关于 `Agentic AI`、`Planning`（规划）、`Tool Use`（工具使用）、`Multi-Agent Systems`（多智能体系统）或 `Self-Evolving`（自我演化）的核心范式或能力。 3.  **排除标准确认（第三步）**： *   虽然论文提到了“可解释性”，但其主要贡献并非针对LLM智能体的安全或对齐，而是针对语言学分析方法的可解释性。更重要的是，它完全偏离了“LLM智能体及其演化”这一研究课题。 综上所述，该论文属于语言学分析领域的应用研究，与LLM智能体的构建、改进或演化无关，因此应被排除。"
    },
    {
        "index": "#51",
        "title": "Revisiting Data Compression with Language Modeling",
        "link": "/arxiv/2601.02875",
        "arxiv_id": "2601.02875",
        "authors": "Chen-Han Tsai",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.378689",
        "filter_reason": "这篇论文的核心贡献是探索利用大语言模型（LLM）进行数据压缩的方法，旨在通过LLM的预测能力来降低文本、代码及字节流数据的压缩率。 根据筛选标准，我的判断过程如下： 1.  **核心判断（第一步）**：该论文属于“非演化型应用”。它将LLM作为一个静态的工具或算法组件应用于“数据压缩”这一特定领域，并没有涉及构建、改进或演化LLM智能体。论文中没有任何关于智能体架构、自主规划、工具使用或环境交互的内容。 2.  **正面指标（第二步）**：论文完全不包含Agentic AI、Multi-Agent Systems或Self-Evolving等核心范式，也未涉及规划、记忆、自我反思等智能体能力。 3.  **排除标准（第三步）**：虽然论文涉及多模态数据，但其核心任务是压缩而非视觉智能体的构建，因此不属于保留范围。 综上所述，该论文的研究焦点是数据压缩算法，而非LLM智能体的构建或演化，因此不符合我的研究范围。"
    },
    {
        "index": "#34",
        "title": "Large Reasoning Models Are (Not Yet) Multilingual Latent Reasoners",
        "link": "/arxiv/2601.02996",
        "arxiv_id": "2601.02996",
        "authors": "Yihong Liu, Raoyuan Zhao, Hinrich Schütze, Michael A. Hedderich",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.364266",
        "filter_reason": "这篇论文的核心贡献在于通过截断策略和表征分析，研究大型推理模型（LRMs）在多语言环境下的“潜在推理”机制，即模型在生成文本推理步骤之前是否已在隐藏状态中计算出答案。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：该论文属于“非Agentic的推理”。它关注的是模型内部的基础推理能力和隐藏状态的演化过程，旨在解释模型如何进行数学计算，而非构建具有自主规划、工具使用或记忆能力的LLM智能体。 2.  **排除标准（第四步）**：虽然论文涉及“推理”，但它并不涉及智能体如何在复杂任务中进行多步规划或构建新的Agentic框架。文中提到的“内部演化”是指Token生成过程中隐藏状态的变化，而非智能体通过经验或反馈进行的“自我演化”或自我完善。 3.  **研究焦点不符**：我的研究焦点是Agentic AI（单智能体、多智能体、自我演化），而本论文更偏向于模型分析、可解释性以及基础模型能力的评估，不属于智能体构建或演化的范畴。 因此，该论文不符合我的研究范围。"
    },
    {
        "index": "#35",
        "title": "Stable-RAG: Mitigating Retrieval-Permutation-Induced Hallucinations in Retrieval-Augmented Generation",
        "link": "/arxiv/2601.02993",
        "arxiv_id": "2601.02993",
        "authors": "Qianchi Zhang, Hainan Zhang, Liang Pang, Hongwei Zheng, Zhiming Zheng",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.364893",
        "filter_reason": "根据筛选标准，这篇论文不符合研究要求，具体判断如下： 1.  **触犯排除标准（第三步）：** 论文的核心贡献明确指向解决“幻觉”问题。摘要中提到“mitigating retrieval-permutation-induced hallucinations”（减轻检索排列引起的幻觉）以及“align hallucinated outputs toward the correct answer”（将幻觉输出对齐到正确答案）。根据第三步排除标准，只要论文的主要贡献是关于 `Hallucination` (幻觉) 的，一律排除。 2.  **核心判断（第一步）：** 论文的本质是对检索增强生成（RAG）这一特定技术组件的优化，旨在提高模型在处理不同检索顺序时的鲁棒性和一致性。这属于对模型基础生成机制或RAG管道的改进，而非构建具有自主规划、工具使用或记忆机制的LLM智能体（Agentic LLM）。 3.  **缺乏Agentic特征（第二步）：** 尽管RAG常被视为智能体的工具之一，但本文并未涉及智能体的核心范式，如 `Planning`（规划）、`Self-Reflection`（自我反思）或 `Multi-Agent`（多智能体）协作。它关注的是解码过程中的隐藏状态聚类和稳定性，而非智能体的行为演化或架构设计。 综上所述，该论文属于RAG优化与幻觉缓解领域的研究，不属于LLM智能体及其演化的研究范畴。"
    },
    {
        "index": "#56",
        "title": "The performances of the Chinese and U.S. Large Language Models on the Topic of Chinese Culture",
        "link": "/arxiv/2601.02830",
        "arxiv_id": "2601.02830",
        "authors": "Feiyan Liu, Chenxun Zhuo, Siyan Zhao, Bao Ge, Tianming Liu",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.381277",
        "filter_reason": "根据筛选标准，该论文不符合研究要求，具体判断过程如下： 1.  **第一步（核心判断）- 排除**： *   该论文的核心贡献是对中美大语言模型在“中国文化”这一特定领域的表现进行**评估和比较**（Benchmarking/Evaluation）。 *   论文并未提出任何关于构建LLM智能体、多智能体系统或自我演化的新方法论或新框架。 *   这属于典型的**非演化型应用**，即仅将LLM作为工具应用于特定领域（文化研究）来解决该领域的问题（评估文化理解能力），而非研究智能体本身的架构或演化机制。 2.  **第二步（正面指标）- 缺失**： *   论文中未涉及任何核心范式，如 `Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving`。 *   论文也不包含智能体能力的关键词，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Correction`（自我修正）。 3.  **结论**： *   该论文属于模型评估与跨文化比较研究，与“LLM智能体及其演化”这一关注智能体构建、协作与演化的核心课题无关，因此予以排除。"
    },
    {
        "index": "#43",
        "title": "Enhancing Multilingual RAG Systems with Debiased Language Preference-Guided Query Fusion",
        "link": "/arxiv/2601.02956",
        "arxiv_id": "2601.02956",
        "authors": "Jeonghyun Park, Byeongjeong Kim, Seojin Hwang, Hwanhee Lee",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.374448",
        "filter_reason": "这篇论文不符合我的研究范围，理由如下： 1.  **核心贡献分析（第一步判断）**： 论文的核心贡献在于提出了一种名为 `DELTA` 的多语言检索增强生成（mRAG）框架，以及一种名为 `DeLP` 的去偏评估指标。其研究重点在于解决 RAG 系统在多语言环境下的语言偏好偏差和检索优化问题。这属于 **RAG 系统本身的优化**（Infrastructure/System Optimization），而非构建具有自主性、规划能力或工具使用能力的 **LLM智能体**。 2.  **缺乏 Agentic 核心要素（第二步与第四步判断）**： 虽然检索（RAG）可以被视为智能体的一种工具能力，但本论文并未涉及智能体的构建。论文中缺乏 Agentic AI 的关键特征，如： *   **自主规划**：没有涉及智能体如何分解任务或制定多步计划。 *   **工具使用与循环**：没有涉及智能体自主决策调用工具并基于反馈进行迭代的循环机制。 *   **自我演化**：没有涉及智能体通过经验或反思进行自我完善的机制。 论文主要关注的是信息检索（IR）层面的查询融合和去偏技术，而非智能体的架构或行为逻辑。 3.  **归类为非演化型应用/基础设施**： 该研究旨在改进特定任务（多语言问答/检索）的系统性能，属于对底层 RAG 管道的优化，而非对智能体范式的创新。根据筛选标准中的“基础设施”排除项，主要关注模型基础设施或特定系统组件（如检索器）优化的研究应予以排除。 综上所述，该论文属于多语言信息检索与 RAG 系统优化领域，不属于 LLM 智能体构建、多智能体协作或自我演化的研究范畴。"
    },
    {
        "index": "#52",
        "title": "LongBench Pro: A More Realistic and Comprehensive Bilingual Long-Context Evaluation Benchmark",
        "link": "/arxiv/2601.02872",
        "arxiv_id": "2601.02872",
        "authors": "Ziyang Chen, Xing Wu, Junlong Jia, Chaochen Gao, Qi Fu, Debing Zhang, Songlin Hu",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.379181",
        "filter_reason": "这篇论文不符合筛选标准，具体判断过程如下： 1.  **核心贡献不符 (第一步)**: 论文的核心贡献是提出了一个名为 \"LongBench Pro\" 的**评估基准**，旨在测试大语言模型在长上下文场景下的理解能力。根据筛选标准，我们需要保留的是关于“构建、改进或演化 LLM智能体”的方法论或新框架。本文属于模型评估与数据集构建的范畴，而非智能体架构或演化机制的设计。 2.  **非Agentic核心焦点 (第二步)**: 论文主要关注的是 LLM 的基础能力——即“长上下文理解”，而非 Agentic AI 的核心能力（如规划、工具使用、记忆、自我反思等）。虽然摘要中提到了“thinking”范式，但这仅是评估模型时的一个发现或评估维度，并非论文提出的核心智能体机制。 3.  **基础设施/工具属性 (第一步)**: 该论文致力于解决评估工具的不足，属于研究基础设施中的 Benchmarks 部分。根据筛选标准，主要关注模型基础设施（包括评估基准）的研究通常被排除，除非该基准直接用于衡量智能体的演化（本文主要衡量的是长文本理解）。 综上所述，该论文是一篇关于模型评估基准的研究，而非关于 LLM 智能体构建或演化的研究，因此予以排除。"
    },
    {
        "index": "#58",
        "title": "MiMo-V2-Flash Technical Report",
        "link": "/arxiv/2601.02780",
        "arxiv_id": "2601.02780",
        "authors": "Bangjun Xiao, Bingquan Xia, Bo Yang, Bofei Gao, Bowen Shen, Chen Zhang, Chenhong He, Chiheng Lou, Fuli Luo, Gang Wang, Gang Xie, Hailin Zhang, Hanglong Lv, Hanyu Li, Heyu Chen, Hongshen Xu, Houbin Zhang, Huaqiu Liu, Jiangshan Duo, Jianyu Wei, Jiebao Xiao, Jinhao Dong, Jun Shi, Junhao Hu, Kainan Bao, Kang Zhou, Lei Li, Liang Zhao, Linghao Zhang, Peidian Li, Qianli Chen, Shaohui Liu, Shihua Yu, Shijie Cao, Shimao Chen, Shouqiu Yu, Shuo Liu, Tianling Zhou, Weijiang Su, Weikun Wang, Wenhan Ma, Xiangwei Deng, Bohan Mao, Bowen Ye, Can Cai, Chenghua Wang, Chengxuan Zhu, Chong Ma, Chun Chen, Chunan Li, Dawei Zhu, Deshan Xiao, Dong Zhang, Duo Zhang, Fangyue Liu, Feiyu Yang, Fengyuan Shi, Guoan Wang, Hao Tian, Hao Wu, Heng Qu, Hongfei Yi, Hongxu An, Hongyi Guan, Xing Zhang, Yifan Song, Yihan Yan, Yihao Zhao, Yingchun Lai, Yizhao Gao, Yu Cheng, Yuanyuan Tian, Yudong Wang, Zhen Tang, Zhengju Tang, Zhengtao Wen, Zhichao Song, Zhixian Zheng, Zihan Jiang, Jian Wen, Jiarui Sun, Jiawei Li, Jinlong Xue, Jun Xia, Kai Fang, Menghang Zhu, Nuo Chen, Qian Tu, Qihao Zhang, Qiying Wang, Rang Li, Rui Ma, Shaolei Zhang, Shengfan Wang, Shicheng Li, Shuhao Gu, Shuhuai Ren, Sirui Deng, Tao Guo, Tianyang Lu, Weiji Zhuang, Weikang Zhang, Weimin Xiong, Wenshan Huang, Wenyu Yang, Xin Zhang, Xing Yong, Xu Wang, Xueyang Xie, Yilin Jiang, Yixin Yang, Yongzhe He, Yu Tu, Yuanliang Dong, Yuchen Liu, Yue Ma, Yue Yu, Yuxing Xiang, Zhaojun Huang, Zhenru Lin, Zhipeng Xu, Zhiyang Chen, Zhonghua Deng, Zihan Zhang, Zihao Yue",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.388229",
        "filter_reason": "根据筛选标准，这篇论文不符合我的研究范围，具体判断过程如下： 1.  **核心判断（第一步）：** *   这篇论文的核心贡献是提出了一种新的**基础模型架构**（Mixture-of-Experts, MoE）及其训练和推理优化方法（如 Multi-Teacher On-Policy Distillation, MOPD 和 Speculative Decoding）。 *   虽然摘要中提到该模型 \"designed for... agentic capabilities\"（旨在具备智能体能力），但论文本身的研究重点在于**如何构建、训练和加速这个模型**（属于模型基础设施和工程优化），而不是在于**构建智能体的框架、多智能体交互机制或智能体的自我演化算法**。 *   根据第一步的排除标准，主要关注模型基础设施、部署优化的研究应被排除。 2.  **排除标准（第三步）：** *   该论文属于**基础设施**范畴。它详细描述了参数量、注意力机制、预训练数据量、蒸馏范式和解码速度提升，这些都是关于模型底层的构建和性能优化，而非 Agentic AI 的方法论研究。 3.  **关于“自我演化”的辨析（第四步）：** *   论文中提到的 \"Multi-Teacher On-Policy Distillation\" (MOPD) 是一种模型训练/压缩技术，属于模型后训练阶段的方法，而非智能体在运行时通过经验、反思或环境反馈进行的“自我演化”机制。因此，它不符合“自我演化”这一研究焦点的定义。 **结论：** 该论文是一篇关于基础模型架构与训练效率的技术报告，而非关于 LLM 智能体构建、多智能体系统或自我演化机制的研究，因此予以排除。"
    },
    {
        "index": "#53",
        "title": "Training Language Models with homotokens Leads to Delayed Overfitting",
        "link": "/arxiv/2601.02867",
        "arxiv_id": "2601.02867",
        "authors": "Adrian Cosma, Stefan Ruseti, Emilian Radoi, Mihai Dascalu",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.379631",
        "filter_reason": "1.  **核心贡献分析 (第一步判断)**: 这篇论文的核心贡献在于提出了一种名为 \"homotokens\" 的数据增强方法，以及相应的轻量级训练架构。其目的是通过利用同一种词汇的不同子词分段来提高语言模型的泛化能力，并延迟过拟合。这属于**基础模型训练优化**（Training Optimization）和**数据增强**（Data Augmentation）的范畴，而非构建、改进或演化 LLM 智能体。 2.  **缺乏 Agentic 核心要素 (第二步与第四步判断)**: 论文的研究焦点在于模型内部的 tokenization 层和训练过程中的泛化性能，完全没有涉及智能体的关键特性。 *   **单智能体**: 论文未涉及规划、工具使用、记忆或自我反思等智能体能力。 *   **多智能体**: 论文未涉及智能体间的协作、通信或博弈。 *   **自我演化**: 虽然论文提到了 \"improves generalization\"（提高泛化能力），但这指的是模型在静态训练阶段通过数据增强学到的更好表示，而不是智能体在部署后通过经验、反思或环境反馈进行的**自我完善和迭代**（Self-Evolving）。 3.  **结论**: 该论文属于提升 LLM 基础能力的训练方法论研究，而非 Agentic AI 的架构或演化机制研究。因此，它不符合您关于 \"LLM智能体及其演化\" 的研究课题要求。"
    },
    {
        "index": "#54",
        "title": "To Generate or Discriminate? Methodological Considerations for Measuring Cultural Alignment in LLMs",
        "link": "/arxiv/2601.02858",
        "arxiv_id": "2601.02858",
        "authors": "Saurabh Kumar Pandey, Sougata Saha, Monojit Choudhury",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.380054",
        "filter_reason": "这篇论文不符合研究课题的要求，主要基于以下判断依据： 1.  **触犯排除标准（第三步）：** 论文的核心主题是“Cultural Alignment”（文化对齐）以及如何测量模型在文化方面的“stereotypical and biased”（刻板印象和偏见）。根据筛选标准，凡是主要贡献涉及 `Alignment`（对齐）、`Safety`（安全）或评估模型偏见的研究，一律排除。这篇论文旨在提出一种评估方法（ISDP）来更准确地测量文化对齐度，属于对齐研究范畴。 2.  **核心贡献不符（第一步）：** 论文的核心贡献在于提出一种新的评估方法论（从生成转向判别任务），以解决现有评估方法中的混淆因素。这属于模型评估或基准测试领域，而非构建、改进或演化 LLM 智能体的方法论或新框架。 3.  **缺乏 Agentic 特征（第二步）：** 论文未涉及任何智能体相关的核心能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）、`Multi-Agent Collaboration`（多智能体协作）或 `Self-Evolving`（自我演化）机制。它关注的是静态的模型输出属性（文化一致性），而非智能体的动态行为或架构演化。 综上所述，该论文属于对齐与评估研究，与“LLM智能体及其演化”的核心目标无关，因此排除。"
    },
    {
        "index": "#60",
        "title": "Window-based Membership Inference Attacks Against Fine-tuned Large Language Models",
        "link": "/arxiv/2601.02751",
        "arxiv_id": "2601.02751",
        "authors": "Yuetian Chen, Yuntao Du, Kaiyuan Zhang, Ashish Kundu, Charles Fleming, Bruno Ribeiro, Ninghui Li",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.405464",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为WBC（Window-Based Comparison）的成员推断攻击方法，旨在通过分析局部损失信号来判断特定数据是否被用于微调大语言模型，从而揭示模型的隐私漏洞。 根据筛选标准第三步（排除标准），该研究的主要贡献明确属于 **Security（安全）** 和 **Privacy（隐私）** 范畴。虽然研究对象是LLM，但其目的并非构建、改进或演化LLM智能体（Agentic AI），也不涉及智能体的规划、工具使用、多智能体协作或自我演化机制。因此，该论文完全符合排除条件，不符合您的研究目标。"
    },
    {
        "index": "#49",
        "title": "Linear Script Representations in Speech Foundation Models Enable Zero-Shot Transliteration",
        "link": "/arxiv/2601.02906",
        "arxiv_id": "2601.02906",
        "authors": "Ryan Soh-Eun Shim, Kwanghee Choi, Kalvin Chang, Ming-Hao Hsu, Florian Eichin, Zhizheng Wu, Alane Suhr, Michael A. Hedderich, David Harwath, David R. Mortensen, Barbara Plank",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.377834",
        "filter_reason": "这篇论文的核心贡献在于分析语音基础模型（如Whisper）的内部激活空间，发现“书写系统”在其中是线性编码的，并据此提出了一种在推理时通过修改激活来控制语音识别输出书写系统的方法。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：论文的研究对象是“语音基础模型”和“语音识别/音译”，而非“LLM智能体”。其核心贡献是模型内部表征的分析与操控，并不涉及构建、改进或演化LLM智能体的方法论或新框架。它不属于Agentic AI、Multi-Agent Systems或Self-Evolving的范畴。 2.  **正面指标（第二步）**：论文中未包含任何关于智能体规划、工具使用、记忆、自我反思、多智能体协作或自我演化机制等核心范式或能力。 3.  **排除标准（第三步）**：虽然论文涉及模型内部机制，但其主要目的是解决语音识别中输出文字书写系统的确定性问题，这与Agentic AI的研究焦点完全无关。 综上所述，该论文属于语音处理与模型表征学习领域，不符合“LLM智能体及其演化”的研究范围，因此予以排除。"
    },
    {
        "index": "#57",
        "title": "Punctuation-aware Hybrid Trainable Sparse Attention for Large Language Models",
        "link": "/arxiv/2601.02819",
        "arxiv_id": "2601.02819",
        "authors": "Junxiang Qiu, Shuo Wang, Zhengsu Chen, Hengheng Zhang, Jinda Lu, Changcheng Li, Qi Tian",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.381783",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出了一种名为 **PHSA (Punctuation-aware Hybrid Sparse Attention)** 的**稀疏注意力机制**。其目的是解决长上下文建模中密集注意力的计算复杂度问题，通过利用标点符号作为语义边界来优化信息处理。这属于**模型架构优化**和**基础设施**层面的研究，旨在提升底层模型的效率和长文本处理能力，而非构建、改进或演化 LLM 智能体。 2.  **正面指标缺失（第二步）：** 论文中未涉及任何关于 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving` 的核心范式。也没有提及智能体的关键能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Reflection`（自我反思）。 3.  **排除标准匹配（第三步）：** 根据筛选标准中的“基础设施”一项，主要关注模型基础设施、部署优化、硬件加速的研究应被排除。本文专注于优化 Attention 机制以减少计算开销和信息损失，属于典型的模型架构与效率优化研究，与 Agentic AI 的研究焦点无关。 综上所述，该论文属于底层模型架构优化领域，而非智能体构建或演化领域，因此予以排除。"
    },
    {
        "index": "#46",
        "title": "RAL2M: Retrieval Augmented Learning-To-Match Against Hallucination in Compliance-Guaranteed Service Systems",
        "link": "/arxiv/2601.02917",
        "arxiv_id": "2601.02917",
        "authors": "Mengze Hong, Di Jiang, Jiangtao Wen, Zhiyang Su, Yawen Li, Yanjie Sun, Guan Wang, Chen Jason Zhang",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.375936",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#63",
        "title": "Mitigating Prompt-Induced Hallucinations in Large Language Models via Structured Reasoning",
        "link": "/arxiv/2601.02739",
        "arxiv_id": "2601.02739",
        "authors": "Jinbo Hao, Kai Yang, Qingzhen Su, Yang Chen, Yifan Li, Chao Jiang",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.407618",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下三个核心原因： 1.  **触犯排除标准（安全与对齐）：** 论文的核心目标是解决大语言模型的“幻觉”问题。根据筛选标准第三步，只要论文的主要贡献是关于 `Hallucination` (幻觉) 的，一律排除。该论文旨在提高推理的准确性和可验证性以减少幻觉，属于模型安全与对齐的范畴，而非构建智能体。 2.  **触犯排除标准（图技术）：** 摘要明确提到引入代码模块来引导“知识图谱”探索。根据筛选标准第三步，涉及知识图谱等图相关技术的论文属于排除范围。 3.  **缺乏Agentic核心特征（非Agentic的推理）：** 论文提出的方法是基于“知识蒸馏链式模型”和“思维链”来约束推理过程。虽然涉及推理，但这属于提升模型基础能力的范畴（即非Agentic的推理），并未涉及智能体的自主规划、工具使用、记忆机制或自我演化框架。它没有构建一个能够自主行动或演化的智能体，而是优化了模型内部的生成过程。 综上所述，该论文主要关注模型的安全性和基础推理能力的优化，而非LLM智能体的构建、协作或演化，因此予以排除。"
    },
    {
        "index": "#48",
        "title": "Beyond the Black Box: Theory and Mechanism of Large Language Models",
        "link": "/arxiv/2601.02907",
        "arxiv_id": "2601.02907",
        "authors": "Zeyu Gan, Ruifeng Ren, Wei Yao, Xiaolin Hu, Gengze Xu, Chen Qian, Huayi Tang, Zixuan Gong, Xinhao Yao, Pengwei Tang, Zhenxing Dou, Yong Liu",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.377020",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#62",
        "title": "Language Hierarchization Provides the Optimal Solution to Human Working Memory Limits",
        "link": "/arxiv/2601.02740",
        "arxiv_id": "2601.02740",
        "authors": "Luyao Chen, Weibo Gao, Junjie Wu, Jinshan Wu, Angela D. Friederici",
        "subjects": "Computation and Language, Applications",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.406913",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献不符 (第一步 - 核心判断)**: *   论文的核心贡献在于从认知科学和语言学的角度，解释“人类语言为何具有层级结构”，并提出这种层级结构是解决人类工作记忆限制的最优解。 *   这是一项关于**人类认知机制**和**自然语言本质**的理论研究，而非关于构建、改进或演化 **LLM智能体** 的方法论或新框架。 2.  **缺乏Agentic AI的关键要素 (第二步 - 正面指标)**: *   论文中虽然提到了“工作记忆”，但这指的是人类认知心理学中的记忆容量限制，而非LLM智能体架构中的组件。 *   论文未涉及任何智能体核心范式，如 `Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving`。 *   论文未涉及智能体的关键能力，如 `Planning`（规划）、`Tool Use`（工具使用）或 `Self-Reflection`（自我反思）。 3.  **研究领域的偏差**: *   尽管论文使用了“计算模拟”，但其目的是验证关于人类语言的假设，属于认知语言学或理论计算语言学范畴，与“LLM智能体及其演化”这一计算机科学/人工智能课题无直接关联。 综上所述，该论文属于认知科学领域的理论研究，不涉及LLM智能体的构建或演化，因此予以排除。"
    },
    {
        "index": "#64",
        "title": "Adversarial Question Answering Robustness: A Multi-Level Error Analysis and Mitigation Study",
        "link": "/arxiv/2601.02700",
        "arxiv_id": "2601.02700",
        "authors": "Agniv Roy Choudhury, Vignesh Ponselvan Rajasingh",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.408243",
        "filter_reason": "根据筛选标准，这篇论文不符合我的研究范围，具体判断过程如下： 1.  **核心判断（第一步）**： *   论文的核心贡献是研究Transformer模型（如ELECTRA）在对抗性攻击下的鲁棒性，并提出缓解策略（如实体感知对比学习）。 *   这属于**模型鲁棒性**和**对抗性防御**的研究，而非构建、改进或演化LLM智能体。论文没有涉及智能体的自主规划、工具使用、记忆或多智能体协作等Agentic AI的核心要素。 2.  **排除标准（第三步）**： *   论文明确聚焦于“Adversarial Question Answering Robustness”（对抗性问答鲁棒性）和“Mitigation”（缓解策略）。根据筛选标准，主要贡献关于**安全**和**鲁棒性**的研究属于明确的排除范围。 3.  **缺乏正面指标（第二步）**： *   论文中未出现 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning`、`Tool Use` 等核心范式或能力指标。它关注的是模型在特定任务（QA）上的输入输出稳定性，而非智能体的行为演化。 综上所述，该论文属于模型安全与鲁棒性领域，与“LLM智能体及其演化”的研究课题无关，因此予以排除。"
    },
    {
        "index": "#67",
        "title": "Iterative Structured Pruning for Large Language Models with Multi-Domain Calibration",
        "link": "/arxiv/2601.02674",
        "arxiv_id": "2601.02674",
        "authors": "Guangxin Wu, Hao Zhang, Zhang Zhibin, Jiafeng Guo, Xueqi Cheng",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.415161",
        "filter_reason": "这篇论文的核心贡献在于提出了一种用于大语言模型（LLM）的“结构化剪枝”框架，旨在通过移除冗余通道来减少模型的计算开销、内存占用和推理延迟，从而解决模型部署的效率问题。 根据筛选标准第一步的“排除”规则，该研究明确属于“基础设施”范畴，主要关注模型基础设施、部署优化和硬件加速（文中提到“maintains compatibility with standard hardware accelerators”）。虽然它涉及LLM，但其目标并非构建、改进或演化LLM智能体的行为、规划能力或交互机制，也不涉及多智能体协作或自我演化。因此，它不符合“LLM智能体及其演化”这一研究课题的核心目标。"
    },
    {
        "index": "#69",
        "title": "Multi-Turn Jailbreaking of Aligned LLMs via Lexical Anchor Tree Search",
        "link": "/arxiv/2601.02670",
        "arxiv_id": "2601.02670",
        "authors": "Devang Kulshreshtha, Hang Su, Chinmay Hegde, Haohan Wang",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.416115",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“词汇锚点树搜索”（LATS）的方法，用于对齐大语言模型进行“越狱”攻击。 根据筛选标准第三步（排除标准），我的研究范围明确排除了主要贡献关于 `Safety`（安全）、`Security`（安保）或 `Alignment`（对齐）的论文。尽管该论文涉及了“树搜索”这一通常与规划相关的技术，但其应用场景是生成对抗性查询以绕过模型的安全防御机制，而非构建或改进具有自主规划、工具使用或自我演化能力的智能体框架。 因此，这篇论文属于安全与对抗性攻击领域，不符合我关于“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#71",
        "title": "When Do Tools and Planning Help LLMs Think? A Cost- and Latency-Aware Benchmark",
        "link": "/arxiv/2601.02663",
        "arxiv_id": "2601.02663",
        "authors": "Subha Ghoshal, Ali Al-Bustami",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.417167",
        "filter_reason": "1.  **核心贡献不符 (第一步)**: 该论文的核心贡献是提出一个“成本和延迟感知的基准”，旨在评估工具和规划在特定任务中的有效性，而非提出一种新的构建、改进或演化LLM智能体的方法论或框架。它属于评估与分析类研究，而非智能体构建类研究。 2.  **触犯排除标准 - 图技术 (第三步)**: 论文摘要明确提到涉及“基于图结构知识的以事件为中心的问答”以及使用了“DBpedia SPARQL”等工具。根据筛选标准，涉及知识图谱及图相关技术的论文属于明确排除范围。 3.  **应用导向而非架构改进 (第一步)**: 论文将现有的智能体框架应用于特定领域（Event-QA和Reddit ChangeMyView）来解决具体问题并测试性能指标（延迟、成本），这符合“非演化型应用”的排除特征，即主要关注点在于应用效果而非智能体本身的演化或架构创新。"
    },
    {
        "index": "#74",
        "title": "Scalable Construction of a Lung Cancer Knowledge Base: Profiling Semantic Reasoning in LLMs",
        "link": "/arxiv/2601.02604",
        "arxiv_id": "2601.02604",
        "authors": "Cesar Felipe Martínez Cisneros, Jesús Ulises Quiroz Bautista, Claudia Anahí Guzmán Solano, Bogdan Kaleb García Rivera, Iván García Pacheco, Yalbi Itzel Balderas Martínez, Kolawole John Adebayoc, Ignacio Arroyo Fernández",
        "subjects": "Computation and Language",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.418650",
        "filter_reason": "1.  **核心贡献分析**：该论文的核心贡献在于提出了一种构建肺癌知识库的流程，并利用该知识库对T5模型进行监督微调，以提升其在生物医学领域的语义推理性能。这属于数据工程和特定领域微调的研究，而非智能体架构的研究。 2.  **第一步（核心判断）- 非演化型应用**：论文明确将LLM应用于生物医学（肿瘤学）这一特定垂直领域。它并没有提出新的LLM智能体框架、多智能体协作机制或自我演化算法，而是将LLM作为提升领域NLP能力的工具，符合“非演化型应用”的排除标准。 3.  **第三步（排除标准）- 图相关技术**：论文的核心方法论涉及“知识图谱”技术。摘要中明确提到了使用Open Information Extraction (OpenIE)提取三元组、构建结构化知识库以及知识表示。根据筛选标准，涉及知识图谱的论文属于排除范围。 4.  **缺乏Agentic特征**：论文关注的是通过微调数据集来改善模型的语义表示能力，而非智能体的自主规划、工具使用、记忆或自我反思能力。 综上所述，该论文属于特定领域的应用研究且涉及知识图谱技术，不符合“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#77",
        "title": "DataParasite Enables Scalable and Repurposable Online Data Curation",
        "link": "/arxiv/2601.02578",
        "arxiv_id": "2601.02578",
        "authors": "Mengyi Sun",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.425172",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断过程： 1.  **核心贡献分析**: 论文的核心贡献是提出了 **DataParasite**，这是一个用于在线数据收集的模块化工程化管道。其目的是解决计算社会科学领域中数据集组装劳动密集、成本高且难以复现的问题。 2.  **第一步：核心判断（排除）**: 根据筛选标准的第一步，这篇论文属于 **“非演化型应用”**。 *   虽然摘要中提到了 \"agentic search\"（智能体搜索），但这只是该系统利用的一个现有能力，而非论文的研究重点。 *   论文并没有提出新的智能体架构、新的规划方法、新的多智能体协作协议，也没有涉及智能体的自我演化机制。 *   它是将LLM/智能体技术作为工具，应用到了“计算社会科学”和“数据整理”这一特定领域，旨在解决数据采集的效率和成本问题，而非解决智能体本身的构建或演化问题。 3.  **第二步与第三步验证**: *   论文缺乏关于 `Agentic AI` 核心范式（如规划、记忆、自我反思）的创新性研究。 *   它不属于安全、对齐或多模态的排除类别，但完全符合“将已有框架应用到特定领域解决领域问题”的排除规则。 综上所述，该论文侧重于数据工程和应用工具的开发，而非LLM智能体本身的构建、改进或演化，因此应予以排除。"
    },
    {
        "index": "#78",
        "title": "Fact-Checking with Large Language Models via Probabilistic Certainty and Consistency",
        "link": "/arxiv/2601.02574",
        "arxiv_id": "2601.02574",
        "authors": "Haoran Wang, Maryam Khalid, Qiong Wu, Jian Gao, Cheng Cao",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.425670",
        "filter_reason": "根据您的筛选标准，这篇论文**不符合**您的研究范围，具体判断过程如下： 1.  **触发了第三步的“排除标准”（安全与对齐/幻觉）：** 您的筛选标准明确规定：“只要论文的主要贡献是关于 `Safety`, `Security`, `Interpretability`, `Explainability (XAI)`, `Alignment`, `Watermarking`, 或 `Hallucination` (幻觉)，一律排除。” 这篇论文的标题和摘要明确指出其核心目标是解决 LLM 的 **\"hallucinated responses\" (幻觉)** 问题，并致力于提高 **\"factual accuracy\" (事实准确性)**。虽然它提出了一种框架（PCC），但其核心贡献在于通过置信度估计来缓解幻觉，这属于模型的安全性和可靠性研究范畴，而非 Agentic AI 的构建或演化。 2.  **第一步核心判断（非演化型应用）：** 尽管论文中提到了 \"adaptive verification strategy\"（自适应验证策略）和 \"routing mechanism\"（路由机制，即决定是直接回答还是检索），这看起来像是一种简单的工具使用或决策形式。但是，论文的本质是将 LLM 应用于 **\"Fact-Checking\"（事实核查）** 这一特定任务。它并没有提出通用的智能体规划、记忆或自我演化机制，而是针对事实准确性这一特定指标进行了优化。根据第一步的排除规则，这属于将 LLM 作为工具应用到特定领域（事实核查）去解决该领域问题（幻觉/准确性）的情况。 3.  **缺乏核心的 Agentic 特征：** 虽然论文涉及了“检索”，但这通常被视为 RAG（检索增强生成）的一部分，而非完整的 Agentic 行为（如自主规划、多步推理、自我反思以改进自身能力）。论文的重点在于“不确定性量化”和“一致性检查”，而非智能体的架构演化或复杂任务解决能力。 综上所述，由于该论文的主要贡献集中在解决 **幻觉** 和提高 **事实准确性** 上，直接触发了排除标准，因此应当排除。"
    },
    {
        "index": "#59",
        "title": "EComStage: Stage-wise and Orientation-specific Benchmarking for Large Language Models in E-commerce",
        "link": "/arxiv/2601.02752",
        "arxiv_id": "2601.02752",
        "authors": "Kaiyan Zhao, Zijie Meng, Zheyong Xie, Jin Duan, Yao Hu, Zuozhu Liu, Shaosheng Cao",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.404564",
        "filter_reason": "根据筛选标准的第一步（核心判断），这篇论文的核心贡献在于提出了一个名为 EComStage 的**基准**，用于评估 LLM 在电商领域的表现，而非提出了一种新的**构建、改进或演化** LLM 智能体的方法论或框架。 具体分析如下： 1.  **核心贡献不符**：论文的主要工作是构建评估数据集和评估协议，旨在衡量现有模型在感知、规划和行动阶段的表现。它属于“评估”范畴，而非“构建/改进/演化”智能体本身。 2.  **特定领域应用**：该研究专注于电商这一特定垂直领域，旨在解决该领域的评估问题。虽然它涉及智能体的规划等能力，但这只是作为评估对象，而非提出的创新机制。 3.  **缺乏演化或改进机制**：论文未涉及自我演化、自我反思或多智能体协作等能够推动智能体能力进化的机制。 综上所述，该论文属于应用评估类研究，不符合“构建、改进或演化 LLM 智能体”的核心研究目标。"
    },
    {
        "index": "#65",
        "title": "Boosting Accuracy and Interpretability in Multilingual Hate Speech Detection Through Layer Freezing and Explainable AI",
        "link": "/arxiv/2601.02697",
        "arxiv_id": "2601.02697",
        "authors": "Meysam Shirdel Bilehsavar, Negin Mahmoudi, Mohammad Jalili Torkamani, Kiana Kiashemshaki",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.414135",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下判断： 1.  **核心贡献不符 (第一步)**: 论文的核心是利用层冻结技术优化Transformer模型（BERT, RoBERTa等）在特定任务（多语言仇恨言论检测和情感分析）上的性能，并引入LIME框架进行可解释性分析。这属于典型的**非演化型应用**，即将模型作为工具应用于NLP分类任务，而非构建、改进或演化LLM智能体。 2.  **触犯排除标准 (第三步)**: *   **安全与对齐**: 论文的研究主题是“仇恨言论检测”，旨在通过识别有害内容来维护“更安全的数字环境”，这直接属于 `Safety` 和 `Security` 范畴。 *   **可解释性**: 论文明确将集成 `Local Interpretable Model-agnostic Explanations (LIME)` 框架作为核心贡献之一，旨在增强模型的可解释性，这属于 `Interpretability` (可解释性) 和 `Explainability (XAI)`，是明确的排除项。 3.  **缺乏Agentic特征**: 论文未涉及任何智能体相关的核心要素，如规划、工具使用、记忆、自我反思、多智能体协作或自我演化机制。 综上所述，该论文属于应用型安全研究，与“LLM智能体及其演化”的研究目标无关。"
    },
    {
        "index": "#79",
        "title": "LoRA-Drop: Temporal LoRA Decoding for Efficient LLM Inference",
        "link": "/arxiv/2601.02569",
        "arxiv_id": "2601.02569",
        "authors": "Hossein Rajabzadeh, Maryam Dialameh, Chul B. Park, Il-Min Kim, Hyock Ju Kwon",
        "subjects": "Computation and Language",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.426160",
        "filter_reason": "这篇论文的核心贡献在于提出了一种名为 \"LoRA-Drop\" 的推理加速框架，旨在通过时间计算调度和LoRA修正来减少LLM解码过程中的计算量和KV缓存占用，从而实现高效的LLM推理。 根据筛选标准，我的判断过程如下： 1.  **第一步（核心判断）- 基础设施排除**：论文明确指出这是一个 \"plug-and-play inference framework\"（即插即用的推理框架），其核心目标是解决 \"sequential decoding\"（顺序解码）的瓶颈，关注的是 \"Efficient LLM Inference\"（高效LLM推理）。这完全属于**模型基础设施**和**部署优化**的范畴。根据筛选标准中的“排除”项，主要关注模型基础设施、部署优化的研究应予以排除。 2.  **研究焦点不匹配**：我的研究焦点是 \"Agentic AI\"（智能体），即构建具有规划、工具使用、记忆或自我演化能力的智能体。虽然论文在推理基准（如GSM8K, MATH）上进行了评估，但其方法本身并未涉及智能体的架构设计、自主规划、工具调用或多智能体协作机制。它解决的是模型运行速度和资源消耗的问题，而非智能体的能力或演化机制。 3.  **非Agentic的推理**：论文涉及推理任务，但它是通过优化Transformer层的计算来加速推理过程，而非提出一种新的Agentic推理框架（如ReAct, ToT等）。这属于底层计算优化，而非智能体层面的认知架构改进。 综上所述，该论文属于基础设施与部署优化领域，不符合关于 \"LLM智能体及其演化\" 的研究范围。"
    },
    {
        "index": "#70",
        "title": "Towards Comprehensive Stage-wise Benchmarking of Large Language Models in Fact-Checking",
        "link": "/arxiv/2601.02669",
        "arxiv_id": "2601.02669",
        "authors": "Hongzhan Lin, Zixin Chen, Zhiqi Shen, Ziyang Luo, Zhen Ye, Jing Ma, Tat-Seng Chua, Guandong Xu",
        "subjects": "Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.416640",
        "filter_reason": "这篇论文不符合筛选标准，具体分析如下： 1.  **核心贡献不符（第一步判断）**： *   论文的核心贡献是提出了一个名为 **FactArena** 的**评估框架**，用于对 LLM 在事实核查任务中进行全面的、分阶段的基准测试。 *   虽然该框架内部集成了 LLM 驱动的事实核查流程（包括声明分解、工具增强交互等）和裁判智能体，但这些组件是作为**评估手段**存在的，旨在构建一个自动化的竞技场来给模型打分和排名，而不是旨在提出一种新型的 LLM 智能体架构或改进智能体的内在能力。 *   根据第一步的排除规则，该论文属于评估/基准测试范畴，而非核心在于“构建、改进或演化 LLM 智能体”的方法论研究。 2.  **关于“演化”的误读（第四步判断）**： *   摘要中提到的 \"arena-driven claim-evolution module\" 指的是**测试数据（声明）的演化**，即自适应地生成更具挑战性的测试样本，以探测模型的鲁棒性。 *   这并不符合研究目标中定义的“自我演化”，即智能体通过经验或反馈进行自我完善和迭代。这里的演化是针对测试集的，而非智能体本身。 3.  **研究焦点偏差**： *   论文的主要目标是诊断 LLM 的事实推理能力和盲点，属于模型评估领域，而非 Agentic AI 的架构创新或演化机制研究。 综上所述，尽管论文涉及了工具使用和智能体交互的概念，但其本质是评估工具而非智能体构建或演化的研究，因此予以排除。"
    },
    {
        "index": "#76",
        "title": "Reconstructing Item Characteristic Curves using Fine-Tuned Large Language Models",
        "link": "/arxiv/2601.02580",
        "arxiv_id": "2601.02580",
        "authors": "Christopher Ormerod",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.424702",
        "filter_reason": "这篇论文不符合我的研究范围，依据如下： 1.  **核心判断（非演化型应用）**：论文的核心贡献在于提出一种利用微调后的LLM来模拟学生答题响应，从而重构项目特征曲线（ICCs）以用于心理测量学（Item Response Theory, IRT）参数估计的方法。这属于将LLM作为工具应用到**教育测量**这一特定领域的应用研究，而非构建、改进或演化LLM智能体本身。 2.  **缺乏Agentic特性**：论文中的LLM仅作为响应生成器，根据能力描述符输出答案。该方法并未涉及智能体的核心要素，如自主规划、工具使用、记忆机制、自我反思或与环境交互的循环。 3.  **非自我演化机制**：虽然论文使用了微调技术，但这属于模型训练的范畴，而非智能体通过经验、反思或环境反馈进行自我完善和迭代的“自我演化”框架。 综上所述，该论文属于特定领域的应用研究，不符合关于“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#73",
        "title": "Improved Evidence Extraction for Document Inconsistency Detection with LLMs",
        "link": "/arxiv/2601.02627",
        "arxiv_id": "2601.02627",
        "authors": "Nelvin Tan, Yaowen Zhang, James Asikin Cheung, Fusheng Liu, Yu-Ching Shih, Dong Yang",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.418162",
        "filter_reason": "根据您提供的筛选标准，这篇论文不符合研究范围，具体判断过程如下： 1.  **核心判断（第一步 - 排除非演化型应用）**： *   该论文的核心贡献是提出了一种 \"redact-and-retry\"（编辑重试）框架和新的评估指标，旨在解决 **\"文档不一致性检测\"（Document Inconsistency Detection）** 这一特定领域的任务。 *   这属于典型的将LLM作为工具应用到特定领域（NLP/文档分析）去解决该领域具体问题的研究。论文的重点在于提升特定任务（证据提取）的性能，而非构建、改进或演化通用的LLM智能体架构。 2.  **Agentic属性分析（第二步与第四步）**： *   虽然论文中提到了 \"redact-and-retry\" 框架，这看起来像是一种迭代机制，但它被严格限制在提取证据这一特定任务中，并不具备Agentic AI的核心特征（如自主规划、工具使用、与环境交互或通用的问题解决能力）。 *   这种机制更接近于一种针对特定任务的提示工程策略或推理链优化，而非智能体的自我演化或自我反思机制。 3.  **结论**： *   论文属于应用型研究，而非智能体架构或演化机制的研究。因此，根据第一步中的“非演化型应用”排除标准，应予以排除。"
    },
    {
        "index": "#81",
        "title": "Losses that Cook: Topological Optimal Transport for Structured Recipe Generation",
        "link": "/arxiv/2601.02531",
        "arxiv_id": "2601.02531",
        "authors": "Mattia Ottoborgo, Daniele Rege Cambrin, Paolo Garza",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.427051",
        "filter_reason": "这篇论文不符合研究目标，主要基于以下判断： 1.  **核心贡献不符 (第一步 - 核心判断)**: *   论文的核心贡献是提出了一种新的**拓扑损失函数**，用于改进**食谱生成**的质量。这属于自然语言生成（NLG）领域的训练目标优化，而非构建或演化LLM智能体。 *   根据筛选标准，这属于“非演化型应用”。论文仅仅是将生成模型应用于特定领域（烹饪），旨在解决该领域文本生成的准确性和结构问题，并没有涉及智能体的架构、行为或演化机制。 2.  **缺乏关键指标 (第二步 - 正面指标)**: *   论文中没有出现任何关于 `Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving` 的核心范式。 *   论文未涉及智能体的关键能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Reflection`（自我反思）。 3.  **排除项确认**: *   该研究侧重于模型训练时的损失函数设计，以提升生成文本的指标（如食材准确性、时间/温度精度），这与“LLM智能体及其演化”的研究焦点（自主性、交互性、演化性）完全不同。 综上所述，该论文属于特定领域的文本生成优化研究，不属于LLM智能体或其演化的范畴，因此予以排除。"
    },
    {
        "index": "#82",
        "title": "PCEval: A Benchmark for Evaluating Physical Computing Capabilities of Large Language Models",
        "link": "/arxiv/2601.02404",
        "arxiv_id": "2601.02404",
        "authors": "Inpyo Song, Eunji Jeon, Jangwon Lee",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-31",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.427516",
        "filter_reason": "这篇论文的核心贡献是提出了一个名为 **PCEval** 的基准测试，用于评估大语言模型在**物理计算** 领域的能力（即生成电路和兼容代码的能力）。 根据筛选标准，该论文不符合要求的原因如下： 1.  **核心判断不符 (第一步)**: - 论文的核心是**评估** 而非**构建**。它没有提出新的LLM智能体架构、多智能体系统或自我演化框架。 - 该研究属于将LLM应用到特定领域（物理计算/硬件控制）的能力评估，符合“非演化型应用”或特定领域基准测试的排除范畴。它关注的是LLM在特定垂直领域的表现，而非Agentic AI的通用机制（如规划、记忆、工具使用的改进）。 2.  **缺乏核心关注点 (第二步)**: - 论文虽然涉及代码生成，但其焦点在于“物理面包板布局”和“引脚连接”等硬件特定约束，而非智能体的自主规划、工具使用、自我反思或多智能体协作等Agentic核心能力。 3.  **非Agentic的推理 (第四步)**: - 论文评估的是LLM对硬件实现约束的推理能力，这属于特定领域的逻辑推理，而非智能体在复杂任务中的多步规划或基于环境的交互演化。 综上所述，这是一篇关于特定领域（物理计算）模型能力评估的论文，而非关于LLM智能体构建或演化的研究，因此予以排除。"
    },
    {
        "index": "#85",
        "title": "Multi-Modal Data-Enhanced Foundation Models for Prediction and Control in Wireless Networks: A Survey",
        "link": "/arxiv/2601.03181",
        "arxiv_id": "2601.03181",
        "authors": "Han Zhang, Mohammad Farzanullah, Mohammad Ghassemi, Akram Bin Sediq, Ali Afana, Melike Erol-Kantarci",
        "subjects": "Networking and Internet Architecture, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.434636",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心判断（非演化型应用）**：根据第一步的排除规则，该论文属于将基础模型应用到特定领域（无线网络）的综述。虽然摘要中提到了“通用AI智能体”的愿景，但论文的核心内容是讨论如何利用FMs解决无线网络中的“预测任务”和“控制任务”，而非构建、改进或演化LLM智能体的方法论本身。它将模型作为工具应用于特定垂直领域，而非研究智能体的架构或演化机制。 2.  **排除标准（多模态与特定领域）**：论文标题明确指出是“Multi-Modal Data-Enhanced”（多模态数据增强），且摘要重点讨论多模态FMs在无线网络中的应用。根据第三步的排除标准，涉及多模态且核心并非将其作为智能体感知环境的工具（而是作为数据处理的核心）的论文应被排除。此外，无线网络管理属于特定的应用领域，不符合研究Agentic AI核心机制的目标。 3.  **缺乏核心关注点**：论文并未涉及第二步中的核心范式，如多智能体协作、自我演化机制、智能体的规划或记忆模块等。它侧重于网络层面的预测与控制，而非智能体层面的能力演化。 综上所述，这是一篇关于基础模型在无线通信领域应用的综述，不属于LLM智能体及其演化的核心研究范畴。"
    },
    {
        "index": "#80",
        "title": "ModeX: Evaluator-Free Best-of-N Selection for Open-Ended Generation",
        "link": "/arxiv/2601.02535",
        "arxiv_id": "2601.02535",
        "authors": "Hyeong Kyu Choi, Sharon Li",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.426593",
        "filter_reason": "1.  **核心贡献分析**: 这篇论文的核心贡献是提出了一种名为 **ModeX** 的算法框架，用于在开放性文本生成任务中从多个候选结果中选择最佳输出。它本质上是一种**解码策略**或**输出选择机制**，利用相似度图和谱聚类技术来识别语义共识，从而替代传统的外部评估器或奖励模型。 2.  **与筛选标准的匹配度**: *   **第一步（核心判断）**: 论文的研究焦点是“如何从多个生成样本中选出最好的一个”，这属于**推理优化**或**模型推理基础设施**的范畴，而非构建具有自主性、规划能力或工具使用能力的**LLM智能体**。它没有涉及智能体的架构设计、循环机制或与环境的交互。 *   **第二步（正面指标）**: 论文中未出现 `Agentic AI`、`Tool Use`、`Memory`、`Multi-Agent` 或 `Self-Evolving` 等核心范式。虽然它涉及“推理”，但这是指通过选择机制提高最终答案的质量，而非智能体在复杂任务中的多步规划或决策过程。 *   **第四步（特殊情况）**: 尽管论文在数学推理和代码生成等任务上进行了验证，但其方法本身并不涉及智能体的自我演化机制，也不是关于智能体如何进行规划，而是关于如何通过后处理算法筛选输出。 3.  **结论**: 该论文属于**非Agentic的推理优化**研究，旨在改进LLM的输出质量而非构建或演化智能体系统。因此，它不符合“LLM智能体及其演化”这一研究课题的核心要求。"
    },
    {
        "index": "#93",
        "title": "SastBench: A Benchmark for Testing Agentic SAST Triage",
        "link": "/arxiv/2601.02941",
        "arxiv_id": "2601.02941",
        "authors": "Jake Feiglin, Guy Dar",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.438633",
        "filter_reason": "根据您的筛选标准，这篇论文不符合您的研究范围，具体分析如下： 1.  **核心贡献不符 (第一步 - 核心判断)**: *   您的核心目标是筛选出核心贡献在于“构建、改进或演化 LLM智能体”的论文。 *   该论文的核心贡献是提出了 **SastBench**，这是一个用于评估智能体在特定任务（SAST分类）上表现的**基准数据集**，而不是一种新的智能体架构、规划算法、多智能体协作机制或自我演化框架。 *   论文虽然涉及“Agentic SAST Triage”，但其本质是构建评估工具，而非构建智能体本身。 2.  **属于非演化型应用 (第一步 - 排除标准)**: *   该论文将LLM智能体应用于特定的垂直领域——**网络安全**（具体是静态应用程序安全测试 SAST）。 *   尽管它涉及智能体，但其目的是解决该领域的具体问题（误报过滤），而非提出通用的智能体技术改进。根据您的规则，将已有智能体概念应用到特定领域（如安全、医疗等）而不涉及新的智能体演化机制的论文应予以排除。 3.  **缺乏方法论创新**: *   论文提到评估了不同的智能体并进行了比较分析，但这属于评估工作，而非对智能体能力的“构建”或“改进”。它没有提出新的规划、记忆、工具使用或自我反思机制。 综上所述，该论文属于特定领域的基准构建与应用评估，而非LLM智能体核心技术的创新或演化，因此被排除。"
    },
    {
        "index": "#94",
        "title": "Logical Phase Transitions: Understanding Collapse in LLM Logical Reasoning",
        "link": "/arxiv/2601.02902",
        "arxiv_id": "2601.02902",
        "authors": "Xinglang Zhang, Yunyao Zhang, ZeLiang Chen, Junqing Yu, Wei Yang, Zikai Song",
        "subjects": "Artificial Intelligence, Computation and Language, Logic in Computer Science",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.439163",
        "filter_reason": "解析失败"
    },
    {
        "index": "#75",
        "title": "FlowPlan-G2P: A Structured Generation Framework for Transforming Scientific Papers into Patent Descriptions",
        "link": "/arxiv/2601.02589",
        "arxiv_id": "2601.02589",
        "authors": "Kris W Pan, Yongmin Yoo",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.424260",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#84",
        "title": "Fine-tuning Small Language Models as Efficient Enterprise Search Relevance Labelers",
        "link": "/arxiv/2601.03211",
        "arxiv_id": "2601.03211",
        "authors": "Yue Kang, Zhuoyi Huang, Benji Schussheim, Diana Licon, Dina Atia, Shixing Cao, Jacob Danovitch, Kunho Kim, Billy Norcilien, Jonah Karpman, Mahmound Sayed, Mike Taylor, Tao Sun, Pavel Metrikov, Vipul Agarwal, Chris Quirk, Ye-Yi Wang, Nick Craswell, Irene Shaffer, Tianwei Chen, Sulaiman Vesal, Soundar Srinivasan",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.428936",
        "filter_reason": "这篇论文不符合筛选标准，具体分析如下： 1.  **核心判断（第一步）**：论文的核心贡献在于提出一种微调小语言模型（SLM）的方法，用于解决企业搜索中的“相关性标注”问题。这属于将LLM/SLM作为工具应用到特定垂直领域（企业搜索/信息检索）的**非演化型应用**。其本质是模型蒸馏和特定任务优化，而非构建或演化LLM智能体。 2.  **缺乏Agentic特征（第二步）**：论文中未体现智能体的核心能力。虽然使用了LLM生成合成数据和BM25进行检索，但这属于数据处理流水线，而非智能体的自主规划、工具使用、记忆或自我反思机制。论文没有涉及智能体在环境中的交互或决策过程。 3.  **非自我演化（第四步）**：论文提到的“蒸馏”和“微调”是标准的模型训练技术，旨在获得一个高效的静态标注器，而非智能体通过经验、反思或环境反馈进行的自我完善和迭代演化。 综上所述，该论文属于信息检索与模型压缩领域的应用研究，偏离了“LLM智能体及其演化”的核心研究目标。"
    },
    {
        "index": "#103",
        "title": "Dynamic Quantization Error Propagation in Encoder-Decoder ASR Quantization",
        "link": "/arxiv/2601.02455",
        "arxiv_id": "2601.02455",
        "authors": "Xinyu Wang, Yajie Luo, Yihong Wu, Liheng Ma, Ziyu Zhao, Jingrui Tian, Lei Ding, Yufei Cui, Xiao-Wen Chang",
        "subjects": "Sound, Computation and Language, Audio and Speech Processing",
        "date": "2026-01-05",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.448920",
        "filter_reason": "1.  **核心贡献分析**: 该论文的核心贡献是提出了一种名为 FADE (Fine-grained Alpha for Dynamic Quantization Error Propagation) 的方法，用于解决自动语音识别（ASR）模型在边缘设备上进行量化时的误差传播问题。其研究重点在于模型压缩、量化技术以及部署稳定性。 2.  **筛选标准判定**: *   **第一步（核心判断）**: 论文的研究内容属于**模型基础设施**和**部署优化**范畴，而非构建、改进或演化 LLM 智能体。它不涉及智能体的自主规划、工具使用、记忆机制或多智能体协作。 *   **第三步（排除标准）**: 明确排除了主要关注模型基础设施、部署优化的研究。量化是为了在资源受限的设备上运行模型，属于工程优化，不属于 Agentic AI 的方法论研究。 3.  **结论**: 尽管论文涉及 Encoder-Decoder 架构，但其本质是针对 ASR 模型的量化算法改进，与“LLM智能体及其演化”这一研究课题完全无关，因此予以排除。"
    },
    {
        "index": "#105",
        "title": "LLM-as-evaluator in Strategy Research: A Normative, Variance-Aware Protocol",
        "link": "/arxiv/2601.02370",
        "arxiv_id": "2601.02370",
        "authors": "Arnaldo Camuffo, Alfonso Gambardella, Saeid Kazemi, Jakub Malachowski, Abhinav Pandey",
        "subjects": "Computers and Society, Computation and Language",
        "date": "2025-12-02",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.455084",
        "filter_reason": "1.  **核心贡献分析**: 该论文的核心贡献是提出了一种用于在战略研究中使用LLM作为评估者的协议。它主要关注LLM作为测量工具在社会科学研究中的可靠性、不稳定性（方差）以及如何规范其使用流程。 2.  **第一步判断（核心判断）**: 这篇论文属于典型的“非演化型应用”。它将LLM作为工具应用于“战略研究”这一特定领域，目的是解决该领域中文本语料库评估的方法论问题，而非构建、改进或演化LLM智能体本身。 3.  **研究焦点匹配度**: 论文完全不涉及Agentic AI（如智能体的自主规划、工具使用、记忆机制）、Multi-Agent Systems（多智能体协作与博弈）或Self-Evolving（自我演化与迭代）。 4.  **结论**: 论文关注的是社会科学研究方法中的测量工具标准化，而非LLM智能体的技术架构或演化机制，因此严格排除在筛选范围之外。"
    },
    {
        "index": "#92",
        "title": "DNACHUNKER: Learnable Tokenization for DNA Language Models",
        "link": "/arxiv/2601.03019",
        "arxiv_id": "2601.03019",
        "authors": "Taewon Kim, Jihwan Shin, Hyomin Kim, Youngmok Jung, Jonhoon Lee, Won-Chul Lee, Insu Han, Sungsoo Ahn",
        "subjects": "Genomics, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.438124",
        "filter_reason": "这篇论文不符合筛选标准，具体判断过程如下： 1.  **核心贡献分析**：该论文的核心贡献是提出了一种名为 **DNACHUNKER** 的**可学习动态DNA分词机制**。它主要关注如何优化DNA语言模型的输入处理（分词），通过学习将DNA序列分割成可变长度的块，以提高模型在基因组学任务上的表现。 2.  **第一步（核心判断）**： *   论文的研究对象是 **DNA语言模型** 的基础架构组件（分词器），而非 **LLM智能体**。 *   论文未涉及智能体的构建、规划、工具使用、记忆或自我反思等Agentic特性。 *   这属于将语言模型技术应用于特定领域（生物/基因组学）的基础模型优化，符合“非演化型应用”或基础模型架构改进的排除标准。 3.  **第二步（正面指标）**： *   论文中未包含 `Agentic AI`、`Multi-Agent Systems`、`Self-Evolving`、`Planning` 或 `Tool Use` 等任何核心范式或智能体能力指标。 综上所述，该论文聚焦于生物信息学领域的模型分词技术优化，与“LLM智能体及其演化”的研究课题无关，因此予以排除。"
    },
    {
        "index": "#83",
        "title": "WearVox: An Egocentric Multichannel Voice Assistant Benchmark for Wearables",
        "link": "/arxiv/2601.02391",
        "arxiv_id": "2601.02391",
        "authors": "Zhaojiang Lin, Yong Xu, Kai Sun, Jing Zheng, Yin Huang, Surya Teja Appini, Krish Narang, Renjie Tao, Ishan Kapil Jain, Siddhant Arora, Ruizhi Li, Yiteng Huang, Kaushik Patnaik, Wenfang Xu, Suwon Shon, Yue Liu, Ahmed A Aly, Anuj Kumar, Florian Metze, Xin Luna Dong",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2025-12-25",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.428180",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#104",
        "title": "Detecting and Mitigating Treatment Leakage in Text-Based Causal Inference: Distillation and Sensitivity Analysis",
        "link": "/arxiv/2601.02400",
        "arxiv_id": "2601.02400",
        "authors": "Adel Daoud, Richard Johansson, Connor T. Jerzak",
        "subjects": "Econometrics, Computation and Language, General Economics, Machine Learning",
        "date": "2025-12-30",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.449425",
        "filter_reason": "这篇论文不符合筛选标准，应予以排除。具体判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献在于解决“文本因果推断”中的统计偏差问题（即“处理泄漏”），并提出了文本蒸馏方法来消除这种偏差。这属于将文本处理技术应用于特定领域（社会科学/统计学）的**非演化型应用**，而非构建、改进或演化LLM智能体的方法论。 2.  **缺乏核心关注点（第二步）**：论文内容完全不涉及Agentic AI的核心范式，如智能体的规划、工具使用、记忆、自我反思，也不涉及多智能体系统或自我演化机制。 3.  **特定领域应用（第三步）**：论文明确提到了在“International Monetary Fund structural adjustment programs”（国际货币基金组织结构调整项目）等具体领域的实证应用，这属于典型的跨学科应用研究，而非Agentic AI的基础架构或算法研究。 综上所述，该论文属于统计学与NLP结合的应用研究，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#87",
        "title": "Accurate Table Question Answering with Accessible LLMs",
        "link": "/arxiv/2601.03137",
        "arxiv_id": "2601.03137",
        "authors": "Yangfan Jiang, Fei Wei, Ergute Bao, Yaliang Li, Bolin Ding, Yin Yang, Xiaokui Xiao",
        "subjects": "Databases, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.435619",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#88",
        "title": "Automatic Prompt Engineering with No Task Cues and No Tuning",
        "link": "/arxiv/2601.03130",
        "arxiv_id": "2601.03130",
        "authors": "Faisal Chowdhury, Nandana Mihindukulasooriya, Niharika S D'Souza, Horst Samulowitz, Neeru Gupta, Tomasz Hanusiak, Michal Kapitonow",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.436114",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#4",
        "title": "A framework for assuring the accuracy and fidelity of an AI-enabled Digital Twin of en route UK airspace",
        "link": "/arxiv/2601.03120",
        "arxiv_id": "2601.03120",
        "authors": "Adam Keane, Nick Pepper, Chris Burr, Amy Hodgkin, Dewi Gould, John Korna, Marc Thomas",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.385763",
        "filter_reason": "这篇论文的核心贡献是提出一个针对“数字孪生”的“保证框架”，旨在确保该仿真环境（英国航路空域）的准确性、保真度以及符合监管要求。虽然文中提到了“AI Air Traffic Control agents”，但它们仅作为在该数字孪生环境中被测试的对象，而非研究的主体。论文并未涉及智能体的构建、规划、工具使用、多智能体协作或自我演化机制。根据筛选标准，该论文主要关注“Safety”（安全）、“Assurance”（保证/验证）以及特定领域（航空/空中交通管制）的应用基础设施，而非LLM智能体的核心算法或架构演进。因此，它属于非演化型应用及安全/对齐范畴，不符合筛选要求。"
    },
    {
        "index": "#13",
        "title": "Quantum-enhanced long short-term memory with attention for spatial permeability prediction in oilfield reservoirs",
        "link": "/arxiv/2601.02818",
        "arxiv_id": "2601.02818",
        "authors": "Muzhen Zhang, Yujie Cheng, Zhanxiang Lei",
        "subjects": "Artificial Intelligence, Quantum Physics",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.391876",
        "filter_reason": "这篇论文的核心贡献是提出了一种用于油田储层渗透率预测的量子增强长短期记忆网络（QLSTMA）模型。 根据筛选标准第一步（核心判断），该论文属于典型的“非演化型应用”。它将一种特定的神经网络架构（量子增强LSTM）应用在石油工程和地质科学这一特定垂直领域，旨在解决地质参数预测问题，而非构建、改进或演化LLM智能体。 此外，该论文使用的模型基础是LSTM（循环神经网络），并非大语言模型（LLM），且文中未涉及智能体的规划、工具使用、记忆机制、自我反思或多智能体协作等Agentic AI的核心特征。因此，该论文完全不符合“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#98",
        "title": "Time-Scaling Is What Agents Need Now",
        "link": "/arxiv/2601.02714",
        "arxiv_id": "2601.02714",
        "authors": "Zhi Liu, Guangzhi Wang",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2026-01-06",
        "category": "cs.CL",
        "crawl_time": "2026-01-08T11:00:05.446295",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#12",
        "title": "Sample-Efficient Neurosymbolic Deep Reinforcement Learning",
        "link": "/arxiv/2601.02850",
        "arxiv_id": "2601.02850",
        "authors": "Celeste Veronese, Daniele Meli, Alessandro Farinelli",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.391438",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心领域不匹配 (第一步 - 核心判断)**: *   您的研究目标是 **\"LLM智能体及其演化\"**，核心关注点是基于大语言模型构建的智能体。 *   该论文的核心贡献是提出一种 **\"神经符号深度强化学习\"** 方法。它结合的是传统的深度神经网络和符号逻辑规则，旨在解决强化学习中的样本效率和泛化问题。 *   论文中完全没有提及大语言模型、Transformer架构或提示工程，因此它不属于LLM智能体的研究范畴。 2.  **缺乏Agentic AI的关键特征 (第二步 - 正面指标)**: *   虽然强化学习也涉及智能体，但本文的智能体是基于DRL的，而非基于LLM的。 *   论文未涉及您关注的LLM智能体核心能力，如基于LLM的规划、工具使用、记忆机制或自我反思。 *   文中提到的\"在线推理\"是指基于逻辑规则的符号推理，而非LLM的生成式推理。 3.  **技术路线差异**: *   该论文关注的是Q值重缩放、动作分布偏置等DRL算法细节，属于传统AI控制与决策领域，而非当前以LLM为核心的Agentic AI研究前沿。 综上所述，该论文属于深度强化学习与神经符号AI的结合，未涉及LLM智能体的构建或演化，因此予以排除。"
    },
    {
        "index": "#11",
        "title": "M3MAD-Bench: Are Multi-Agent Debates Really Effective Across Domains and Modalities?",
        "link": "/arxiv/2601.02854",
        "arxiv_id": "2601.02854",
        "authors": "Ao Li, Jinghui Zhang, Luyu Li, Yuxiang Duan, Lang Gao, Mingcai Chen, Weijun Qin, Shaopeng Li, Fengxian Ji, Ning Liu, Lizhen Cui, Xiuying Chen, Yuntao Du",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.391001",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下两点核心原因： 1.  **核心贡献是基准测试而非智能体构建**： 根据第一步“核心判断”，我的目标是筛选出核心贡献在于“构建、改进或演化 LLM智能体”的论文。这篇论文的核心贡献是提出了一个名为 **M3MAD-Bench 的基准**，用于评估现有的多智能体辩论方法。虽然它涉及多智能体系统，但其本质属于**评估基础设施**和**测评方法**的研究，而非提出新的智能体架构、规划机制或自我演化算法。 2.  **触发了多模态排除标准**： 根据第三步“排除标准”，研究焦点涉及“多模态与视觉”的论文通常需要排除，除非视觉仅作为智能体感知环境的工具而非研究核心。该论文明确指出其基准涵盖了“**Multi-modal inputs**（多模态输入）”和“**vision-language datasets（视觉语言数据集）”，并将跨模态比较作为核心研究点之一。这表明多模态评估是该论文的核心组成部分，符合排除条件。 综上所述，该论文属于评估与基准类研究，且聚焦于多模态评估，不符合“构建、改进或演化 LLM智能体”的核心研究目标。"
    },
    {
        "index": "#6",
        "title": "Rationale-Grounded In-Context Learning for Time Series Reasoning with Multimodal Large Language Models",
        "link": "/arxiv/2601.02968",
        "arxiv_id": "2601.02968",
        "authors": "Qingxiang Liu, Zhiqing Cui, Xiaoliang Luo, Yuqian Wu, Zhuoyang Jiang, Huaiyu Wan, Sheng Sun, Lvchun Wang, Wei Yu, Yuxuan Liang",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.387220",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#10",
        "title": "SimRPD: Optimizing Recruitment Proactive Dialogue Agents through Simulator-Based Data Evaluation and Selection",
        "link": "/arxiv/2601.02871",
        "arxiv_id": "2601.02871",
        "authors": "Zhiyong Cao, Dunqiang Liu, Qi Dai, Haojun Xu, Huaiyan Xu, Huan He, Yafei Liu, Siyuan Liu, XiaoLin Lin, Ke Ma, Ruqian Shi, Sijia Yao, Hao Wang, Sicheng Zhou",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.390417",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#24",
        "title": "Orchestral AI: A Framework for Agent Orchestration",
        "link": "/arxiv/2601.02577",
        "arxiv_id": "2601.02577",
        "authors": "Alexander Roman, Jacob Roman",
        "subjects": "Artificial Intelligence, Instrumentation and Methods for Astrophysics, High Energy Physics - Phenomenology",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.397317",
        "filter_reason": "这篇论文的核心贡献在于提出一个名为 Orchestral 的轻量级 Python 框架，旨在解决跨不同 LLM 提供商的 API 兼容性、工具调用集成以及开发流程中的工程复杂性（如类型安全、流式传输支持等）。 根据筛选标准的第一步（核心判断）和排除标准： 1.  **本质属于基础设施**：该论文主要关注的是软件工程层面的基础设施，即如何统一接口、消除厂商锁定、简化代码部署和调试。这完全符合第一步排除标准中的第3点：“基础设施：排除主要关注模型基础设施、部署优化、硬件加速的研究”。 2.  **缺乏智能体层面的创新**：虽然摘要中提到该框架支持记忆管理、子智能体等功能，但这些是该框架**集成**或**支持**的现有能力，并非论文本身提出的新颖智能体架构、规划算法、多智能体协作机制或自我演化算法。论文没有在“Agentic AI”的核心科学问题（如如何让智能体更聪明、如何协作、如何自我进化）上做出理论或方法论的贡献。 因此，尽管该论文与 LLM 智能体的开发有关，但其本质是开发工具和工程框架，不符合您关于“构建、改进或演化 LLM智能体”的核心研究目标。"
    },
    {
        "index": "#21",
        "title": "Inferring Causal Graph Temporal Logic Formulas to Expedite Reinforcement Learning in Temporally Extended Tasks",
        "link": "/arxiv/2601.02666",
        "arxiv_id": "2601.02666",
        "authors": "Hadi Partovi Aria, Zhe Xu",
        "subjects": "Artificial Intelligence, Logic in Computer Science",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.395823",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心判断（第一步）**：论文的核心贡献是提出了一种名为 GTL-CIRL 的强化学习框架，用于加速时延任务的学习过程。该方法结合了因果图时序逻辑和高斯过程进行贝叶斯优化。虽然它涉及决策制定，但它完全基于传统的强化学习（RL）和符号逻辑方法，**并未涉及大语言模型（LLM）**，因此不属于“LLM智能体”的研究范畴。 2.  **排除标准（第三步）**：论文明确聚焦于**图（Graph）**相关技术。摘要中提到“Decision-making tasks often unfold on graphs”（决策任务往往在图上展开）、“Causal Graph Temporal Logic”（因果图时序逻辑）以及“network structure”（网络结构）。根据筛选标准，涉及知识图谱、图神经网络等图相关技术的论文属于排除范围。 3.  **研究焦点不匹配**：我的研究焦点是 Agentic AI（基于LLM的单智能体、多智能体或自我演化）。该论文关注的是通过挖掘逻辑公式来提高RL的样本效率和可解释性，属于传统控制理论或系统优化的范畴，缺乏LLM智能体的核心特征（如基于LLM的规划、工具使用、自然语言交互或多智能体协作）。 综上所述，该论文既不包含LLM组件，又属于被明确排除的图技术研究领域，因此判定为不符合。"
    },
    {
        "index": "#26",
        "title": "Textual Explanations and Their Evaluations for Reinforcement Learning Policy",
        "link": "/arxiv/2601.02514",
        "arxiv_id": "2601.02514",
        "authors": "Ahmad Terra, Mohit Ahmed, Rafia Inam, Elena Fersman, Martin Törngren",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.398171",
        "filter_reason": "这篇论文的核心贡献在于提出一种用于生成和评估强化学习（RL）策略文本解释的可解释强化学习（XRL）框架。 根据筛选标准，我的判断过程如下： 1.  **触犯排除标准（第三步）**：我的筛选标准明确指出，只要论文的主要贡献是关于 `Interpretability` (可解释性) 或 `Explainability (XAI)`，一律排除。该论文的研究重点正是如何让RL策略变得“可解释”，属于典型的XAI研究范畴。 2.  **不符合核心目标（第一步）**：我的核心目标是筛选关于“构建、改进或演化 LLM智能体”的论文。虽然这篇论文使用了LLM来生成文本解释，但LLM在这里仅被用作生成解释内容的工具，而非论文的研究主体。论文并未涉及智能体的架构设计、自主规划、工具使用、多智能体协作或自我演化机制。 3.  **非Agentic AI**：论文关注的是对已有RL策略的事后解释，而非智能体在环境中的交互、决策或演化过程。 综上所述，该论文属于可解释性研究，而非LLM智能体及其演化的研究，因此不符合筛选要求。"
    },
    {
        "index": "#23",
        "title": "An Empirical Study of On-Device Translation for Real-Time Live-Stream Chat on Mobile Devices",
        "link": "/arxiv/2601.02641",
        "arxiv_id": "2601.02641",
        "authors": "Jeiyoon Park, Daehwan Lee, Changmin Yeo, Yongshin Han, Minseop Kim",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.396682",
        "filter_reason": "这篇论文的核心贡献在于研究端侧AI模型在移动设备上的实际部署问题，具体涉及资源消耗（CPU利用率、热条件）、模型选择以及特定任务（直播聊天翻译）的领域适应性。 根据筛选标准，该论文不符合研究目标，原因如下： 1.  **第一步（核心判断）- 基础设施排除**：论文明确关注的是“实际部署”、“设备CPU利用率”和“热条件”，这属于模型基础设施和部署优化的范畴，而非构建或演化智能体的方法论。 2.  **第一步（核心判断）- 非演化型应用排除**：论文将模型作为工具应用于“直播聊天翻译”这一特定垂直领域，旨在解决翻译效率和部署问题，并未涉及智能体的自主规划、工具使用、多智能体协作或自我演化机制。 3.  **缺乏正面指标**：论文内容未包含Agentic AI、Multi-Agent Systems或Self-Evolving等核心范式，也未涉及规划、记忆、自我反思等智能体关键能力。 综上所述，该论文属于工程部署与特定领域应用研究，与“LLM智能体及其演化”的研究方向无关，因此予以排除。"
    },
    {
        "index": "#14",
        "title": "Causal-Enhanced AI Agents for Medical Research Screening",
        "link": "/arxiv/2601.02814",
        "arxiv_id": "2601.02814",
        "authors": "Duc Ngo, Arya Rahgoza",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.392290",
        "filter_reason": "这篇论文不符合筛选要求，主要基于以下核心判断： 1.  **触发排除标准（图相关技术）**：论文摘要明确指出其核心方法是 \"integrating explicit causal reasoning with dual-level knowledge graphs\"（将显式因果推理与双层知识图谱相结合），并生成 \"directed acyclic graphs\"（有向无环图）。根据筛选标准第三步，涉及知识图谱等图相关技术的论文属于明确排除范围。 2.  **触发排除标准（安全与对齐/幻觉）**：论文的核心动机和贡献在于解决 \"hallucinations\"（幻觉）问题，并强调 \"trustworthy medical AI\"（值得信赖的医疗AI）和 \"enhanced interpretability\"（增强的可解释性）。根据筛选标准第三步，主要贡献是关于幻觉、安全或可解释性的论文一律排除。 3.  **非演化型应用**：虽然标题中包含 \"Agents\"，但该论文本质上是一个针对特定领域（医学研究筛选）的应用研究。它利用现有的LLM结合知识图谱和因果推理来解决特定任务，而非提出一种通用的、具有自我演化能力的新型智能体架构或演化机制。 综上所述，尽管论文涉及智能体概念，但其核心依赖图技术且主要关注点在于解决幻觉和安全性问题，属于明确的排除类别。"
    },
    {
        "index": "#33",
        "title": "Recursive querying of neural networks via weighted structures",
        "link": "/arxiv/2601.03201",
        "arxiv_id": "2601.03201",
        "authors": "Martin Grohe, Christoph Standke, Juno Steegmans, Jan Van den Bussche",
        "subjects": "Logic in Computer Science, Artificial Intelligence, Databases",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.400644",
        "filter_reason": "1.  **核心贡献分析**: 该论文的核心贡献是提出了一种基于逻辑（特别是加权结构上的函数不动点逻辑）的声明式查询语言，用于查询神经网络（被视为加权结构），旨在解决模型的验证和解释问题。这属于数据库理论、形式化方法和可解释性研究的范畴。 2.  **第一步（核心判断）**: 论文并非关于构建、改进或演化 LLM智能体。它将神经网络视为静态的“意向数据”进行查询和分析，而不是研究如何让模型具备自主性、规划能力或演化能力。 3.  **第三步（排除标准）**: 论文明确指出其目标是“verification and interpretation”（验证和解释），这直接触发了排除标准中的“Interpretability (可解释性)”以及相关的安全验证条款。根据指令，只要主要贡献涉及可解释性，一律排除。 4.  **第二步（正面指标缺失）**: 论文中完全没有涉及 Agentic AI、Multi-Agent Systems 或 Self-Evolving 等核心范式，也未提及 Planning、Tool Use、Memory、Self-Correction 等智能体关键能力。 综上所述，该论文是一篇关于神经网络形式化查询与解释的理论计算机科学论文，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#28",
        "title": "The Sonar Moment: Benchmarking Audio-Language Models in Audio Geo-Localization",
        "link": "/arxiv/2601.03227",
        "arxiv_id": "2601.03227",
        "authors": "Ruixing Zhang, Zihan Liu, Leilei Sun, Tongyu Zhu, Weifeng Lv",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.398962",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心判断（第一步）：** 论文的核心贡献是构建了一个名为 AGL1K 的**基准**和一个评估指标，用于衡量音频语言模型在音频地理定位任务上的表现。这属于**评估与基准测试**工作，而非构建、改进或演化 LLM 智能体的方法论或新框架。论文没有提出新的智能体架构、规划算法或自我演化机制。 2.  **排除标准（第三步）：** 论文明确聚焦于 **Audio-Language Models (ALMs)** 和 **Audio Geo-Localization**，属于**多模态（音频-语言）**领域。根据筛选标准，除非多模态技术仅作为智能体感知环境的工具，否则应排除。本文的研究核心是音频地理定位这一特定任务的能力，而非智能体的通用框架或演化机制。 3.  **缺乏 Agentic 特征（第二步）：** 尽管摘要中提到了“推理”和“可解释性”，但这指的是模型在处理音频信号时的表现分析，而非智能体的自主规划、工具使用、记忆机制或多智能体协作等核心 Agentic 能力。 综上所述，该论文属于多模态模型的特定领域应用评估，不涉及 LLM 智能体的构建或演化，因此予以排除。"
    },
    {
        "index": "#29",
        "title": "The Fake Friend Dilemma: Trust and the Political Economy of Conversational AI",
        "link": "/arxiv/2601.03222",
        "arxiv_id": "2601.03222",
        "authors": "Jacob Erickson",
        "subjects": "Computers and Society, Artificial Intelligence, Human-Computer Interaction",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.399231",
        "filter_reason": "1.  **核心判断**: 这篇论文的本质并非关于构建、改进或演化LLM智能体的技术方法。根据摘要，论文的核心贡献是提出了“假友困境”这一社会技术框架，旨在分析对话式AI系统中的信任问题、用户自主权以及商业利益对AI行为的影响。这属于对AI系统社会影响和伦理层面的分析，而非智能体架构或算法的创新。 2.  **排除标准**: 严格对照第三步排除标准，该论文的主要贡献集中在 `Safety`（安全）、`Alignment`（对齐）以及AI伦理（如操纵、监控资本主义）领域。摘要中明确引用了“AI alignment”文献，并讨论了“mitigation strategies”（缓解策略），这完全符合“安全与对齐”的排除类别。 3.  **研究焦点不符**: 我的研究焦点是Agentic AI的技术实现（如规划、工具使用、多智能体协作、自我演化机制）。虽然论文涉及“AI agents”，但它是将智能体作为被审视的对象，讨论其与人类的社会关系，而非提升智能体本身的智能水平或演化能力。 综上所述，该论文属于AI伦理与社会学研究，不符合“LLM智能体及其演化”的技术筛选要求。"
    },
    {
        "index": "#16",
        "title": "LLM Agent Framework for Intelligent Change Analysis in Urban Environment using Remote Sensing Imagery",
        "link": "/arxiv/2601.02757",
        "arxiv_id": "2601.02757",
        "authors": "Zixuan Xiao, Jun Ma",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.393204",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#17",
        "title": "The Path Ahead for Agentic AI: Challenges and Opportunities",
        "link": "/arxiv/2601.02749",
        "arxiv_id": "2601.02749",
        "authors": "Nadia Sibai, Yara Ahmed, Serry Sibaee, Sawsan AlHalawani, Adel Ammar, Wadii Boulila",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.393882",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#46",
        "title": "Transformers self-organize like newborn visual systems when trained in prenatal worlds",
        "link": "/arxiv/2601.03117",
        "arxiv_id": "2601.03117",
        "authors": "Lalit Pandey, Samantha M. W. Wood, Justin N. Wood",
        "subjects": "Neurons and Cognition, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.410671",
        "filter_reason": "根据筛选标准，这篇论文不符合我的研究范围，具体判断过程如下： 1.  **核心判断（第一步）**：这篇论文的本质是**认知科学与神经科学**的交叉研究。它利用Transformer模型作为工具，来模拟和验证生物大脑（特别是新生儿视觉系统）在产前发育过程中的自组织机制。其核心贡献在于揭示了Transformer与大脑在视觉皮层发育上的相似性，而非构建、改进或演化LLM智能体本身。它不涉及智能体的自主规划、工具使用或目标导向行为。 2.  **排除标准（第三步）**：论文明确聚焦于**视觉系统**。摘要中提到的核心概念包括“视觉输入”、“视网膜波”、“边缘敏感”、“形状敏感”等。这属于视觉和多模态研究的范畴。根据筛选标准，虽然视觉可以作为智能体的感知工具，但在这篇论文中，视觉是研究的核心主题（即研究模型如何像视觉系统一样发育），而非作为智能体框架的一部分。 3.  **关于“自组织”与“自我演化”的区分（第四步）**：虽然标题中提到了“self-organize”（自组织），但这指的是模型内部特征（如对边缘、形状的敏感度）在训练过程中的**生物学发育现象**，属于表征学习的范畴。这与Agentic AI中的“自我演化”（即智能体通过经验、反思或环境反馈来完善自身的能力、策略或逻辑）有着本质的区别。 综上所述，该论文属于神经科学启发的基础模型研究，而非LLM智能体及其演化的研究，因此予以排除。"
    },
    {
        "index": "#20",
        "title": "Learning from Prompt itself: the Hierarchical Attribution Prompt Optimization",
        "link": "/arxiv/2601.02683",
        "arxiv_id": "2601.02683",
        "authors": "Dongyu Chen, Jian Ma, Xianpeng Zhang, Lei Zhang, Haonan Lu, Chen Chen, Chuangchuang Wang, Kai Tang",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.395376",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#54",
        "title": "Motion Blur Robust Wheat Pest Damage Detection with Dynamic Fuzzy Feature Fusion",
        "link": "/arxiv/2601.03046",
        "arxiv_id": "2601.03046",
        "authors": "Han Zhang, Yanwei Wang, Fang Li, Hongjun Wang",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.419751",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心判断（第一步 - 排除）**： *   论文的核心贡献是提出了一种名为 DFRCP (Dynamic Fuzzy Robust Convolutional Pyramid) 的计算机视觉模块，用于改进 YOLOv11 在运动模糊下的目标检测性能。 *   这属于典型的**非演化型应用**，即将深度学习模型（YOLOv11）应用于特定领域（农业/小麦虫害检测）解决视觉感知问题，而非构建或演化 LLM 智能体。 2.  **排除标准（第三步 - 多模态与视觉）**： *   论文的研究内容完全属于计算机视觉领域，涉及图像处理、特征融合和边缘设备部署。 *   根据筛选标准，涉及 `Vision`、`Video Understanding` 等图相关技术的论文，除非它们被用作智能体感知环境的工具（且核心是智能体框架），否则一律排除。本文的核心是视觉算法本身的改进，而非智能体的应用。 3.  **缺乏正面指标（第二步）**： *   论文中未出现任何关于 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 或 `Self-Evolving` 的核心范式。 *   也不涉及智能体的关键能力，如 `Planning`（规划）、`Tool Use`（工具使用）、`Memory`（记忆）或 `Self-Reflection`（自我反思）。 综上所述，该论文是一篇纯粹的计算机视觉应用类论文，与 LLM 智能体及其演化的研究课题无关。"
    },
    {
        "index": "#57",
        "title": "Validating Generalist Robots with Situation Calculus and STL Falsification",
        "link": "/arxiv/2601.03038",
        "arxiv_id": "2601.03038",
        "authors": "Changwen Li, Rongjie Yan, Chih-Hong Cheng, Jian Zhang",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.421340",
        "filter_reason": "1.  **核心贡献分析**: 论文的核心贡献是提出一种用于验证通才机器人的两层框架，结合了情境演算和STL（信号时序逻辑）证伪技术。其重点在于“测试”和“验证”现有系统的正确性，而非“构建”或“改进”智能体本身。 2.  **筛选标准匹配**: *   **第一步（核心判断）**: 论文属于基础设施或验证方法论的范畴，而非构建LLM智能体、多智能体系统或自我演化机制。它关注的是如何发现智能体（如NVIDIA GR00T控制器）的失败案例，而不是如何让智能体变得更强或更自主。 *   **排除项**: 符合“基础设施”排除标准（关注验证/测试基础设施），同时也属于将形式化方法（Situation Calculus）应用于特定领域（机器人控制）的非演化型应用。 3.  **结论**: 尽管研究对象是通才机器人（可能包含LLM），但论文的研究焦点是验证技术，不符合“构建、改进或演化LLM智能体”的核心目标。"
    },
    {
        "index": "#62",
        "title": "JPU: Bridging Jailbreak Defense and Unlearning via On-Policy Path Rectification",
        "link": "/arxiv/2601.03005",
        "arxiv_id": "2601.03005",
        "authors": "Xi Wang, Songlei Jian, Shasha Li, Xiaopeng Li, Zhaoye Li, Bin Ji, Baosheng Wang, Jie Yu",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.423863",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 JPU (Jailbreak Path Unlearning) 的方法，旨在通过修正模型内部的“越狱路径”来防御越狱攻击，属于机器遗忘和安全防御的范畴。 根据筛选标准，判断过程如下： 1.  **核心判断（第一步）**：论文的核心并非构建、改进或演化 LLM 智能体，而是针对 LLM 的安全性问题（越狱攻击）提出防御机制。它不属于 Agentic AI、Multi-Agent Systems 或 Self-Evolving 的方法论研究。 2.  **排除标准（第三步）**：这是最关键的排除依据。筛选标准明确指出，只要论文的主要贡献是关于 `Safety`（安全）、`Security`（安全性）或 `Alignment`（对齐），一律排除。该论文明确聚焦于“Jailbreak Defense”（越狱防御）和“Safety anchors”（安全锚点），完全符合排除条件。 3.  **正面指标（第二步）**：论文中未涉及 `Agentic AI`、`Planning`、`Tool Use`、`Multi-Agent` 或 `Self-Evolving` 等核心关注点。 综上所述，尽管这是一篇关于 LLM 的研究，但其焦点在于安全防御而非智能体的构建与演化，因此不符合您的研究范围。"
    },
    {
        "index": "#65",
        "title": "ULS+: Data-driven Model Adaptation Enhances Lesion Segmentation",
        "link": "/arxiv/2601.02988",
        "arxiv_id": "2601.02988",
        "authors": "Rianne Weber, Niels Rocholl, Max de Grauw, Mathias Prokop, Ewoud Smit, Alessa Hering",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.430512",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献是提出一种改进版的病灶分割模型（ULS+），属于计算机视觉和医学影像分析领域。这完全属于“非演化型应用”，即利用深度学习模型解决特定领域（医疗）的分割问题，而非构建、改进或演化 LLM智能体。 2.  **排除标准（第三步）**：论文明确涉及“Lesion Segmentation”（病灶分割）、“CT scans”（CT扫描）和“input image sizes”（输入图像尺寸），这属于视觉和多模态技术的范畴。根据筛选标准，除非视觉技术仅作为智能体感知环境的工具，否则应予以排除。在此文中，视觉处理是研究的核心任务，而非服务于智能体架构。 3.  **自我演化的界定（第四步）**：虽然摘要中提到了“data-driven updates”（数据驱动的更新），但这指的是利用新数据集对模型进行再训练或适配，属于标准的模型迭代流程，并不涉及智能体通过经验、反思或环境反馈进行的“自我演化”机制（如自我反思、自我修正等）。 综上所述，该论文是一篇典型的医学影像处理论文，与 LLM智能体、多智能体系统或自我演化机制无关，因此予以排除。"
    },
    {
        "index": "#66",
        "title": "LAMS-Edit: Latent and Attention Mixing with Schedulers for Improved Content Preservation in Diffusion-Based Image and Style Editing",
        "link": "/arxiv/2601.02987",
        "arxiv_id": "2601.02987",
        "authors": "Wingwa Fu, Takayuki Okatani",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.430946",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 LAMS-Edit 的方法，用于改进基于扩散模型的图像和风格编辑技术。它主要关注计算机视觉领域，通过混合潜在表示和注意力图来优化图像编辑过程中的内容保留。 根据筛选标准，该论文被排除的原因如下： 1.  **触犯排除标准（第三步）**：论文明确涉及 `Diffusion Models`（扩散模型）和 `Image Editing`（图像编辑），属于“多模态与视觉”范畴。虽然我的标准中提到“除非它们被用作智能体感知环境的工具”，但在这篇论文中，扩散模型是研究的核心对象，而非作为智能体框架中的一个组件或工具。 2.  **不符合核心目标（第一步）**：论文的核心是改进图像生成的算法效果，而非构建、改进或演化 LLM智能体。它不涉及智能体的规划、记忆、工具使用、多智能体协作或自我演化机制。 综上所述，该论文属于计算机视觉领域的算法优化，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#48",
        "title": "Text-Guided Layer Fusion Mitigates Hallucination in Multimodal LLMs",
        "link": "/arxiv/2601.03100",
        "arxiv_id": "2601.03100",
        "authors": "Chenchen Lin, Sanbao Su, Rachel Luo, Yuxiao Chen, Yan Wang, Marco Pavone, Fei Miao",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.411628",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 TGIF (Text-Guided Inter-layer Fusion) 的轻量级模块，用于改进多模态大语言模型（MLLMs）中视觉编码器层与语言模型之间的特征融合机制，旨在减少视觉幻觉并增强视觉对齐能力。 根据筛选标准，该论文被排除的原因如下： 1.  **触犯排除标准（多模态与视觉）**：论文的研究对象是 MLLMs（多模态大语言模型），核心在于优化视觉特征的提取与融合。根据第三步排除标准，涉及 `Vision-Language` 和 `MLLMs` 的论文通常被排除，除非它们仅作为智能体感知环境的工具。在此文中，MLLM 的架构优化本身就是研究核心，而非作为智能体框架的一部分。 2.  **触犯排除标准（安全与对齐）**：论文明确指出其研究目标是“Mitigates Hallucination”（减轻幻觉）和“strengthen visual grounding”（加强视觉对齐）。根据第三步排除标准，只要论文的主要贡献是关于 `Hallucination` (幻觉) 或 `Alignment` (对齐/视觉对齐)，一律排除。 3.  **不符合核心目标**：论文未涉及任何关于智能体构建、规划、工具使用、多智能体协作或自我演化的内容。它属于模型架构层面的优化，而非 Agentic AI 的方法论研究。 综上所述，该论文属于多模态模型架构优化与幻觉消除领域，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#70",
        "title": "MoE Adapter for Large Audio Language Models: Sparsity, Disentanglement, and Gradient-Conflict-Free",
        "link": "/arxiv/2601.02967",
        "arxiv_id": "2601.02967",
        "authors": "Yishu Lei, Shuwei He, Jing Hu, Dan Zhang, Xianlong Luo, Danxiang Zhu, Shikun Feng, Rui Liu, Jingzhou He, Yu Sun, Hua Wu, Haifeng Wang",
        "subjects": "Sound, Artificial Intelligence, Audio and Speech Processing",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.433058",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心贡献不符 (第一步 & 第三步)**: *   论文的核心是提出一种名为 **MoE-Adapter** 的架构，用于改进 **Large Audio Language Models (大型音频语言模型)** 的音频输入处理能力。 *   这属于 **多模态** 领域的研究，具体是针对音频模态的模型架构优化（解决声学信息的异构性和梯度冲突问题）。 *   根据筛选标准第三步，涉及多模态（此处为音频）的论文通常被排除，除非它们仅作为智能体感知环境的工具。而在本论文中，音频模态和MoE架构是研究的核心，而非服务于智能体框架的工具。 2.  **缺乏 Agentic AI 核心要素 (第二步)**: *   论文未涉及任何智能体的关键能力，如规划、工具使用、记忆、自我反思、自我修正或多智能体协作。 *   摘要中提到的 \"dynamic gating mechanism\" 是用于路由音频 token 到不同的专家以进行特征解耦，属于模型内部的特征工程，而非智能体的决策或行动规划。 3.  **属于基础设施/架构优化而非智能体演化 (第一步)**: *   论文关注的是模型组件（Adapter）的稀疏性和优化效果，属于模型基础设施或架构层面的改进，而非构建、改进或演化 LLM 智能体的方法论。 综上所述，该论文是一篇关于多模态模型架构优化的文章，与 \"LLM智能体及其演化\" 的研究课题无关。"
    },
    {
        "index": "#53",
        "title": "On the Intrinsic Limits of Transformer Image Embeddings in Non-Solvable Spatial Reasoning",
        "link": "/arxiv/2601.03048",
        "arxiv_id": "2601.03048",
        "authors": "Siyi Lyu, Quan Liu, Feng Yan",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computational Complexity",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.419256",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#35",
        "title": "UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision",
        "link": "/arxiv/2601.03193",
        "arxiv_id": "2601.03193",
        "authors": "Ruiyan Han, Zhen Fang, XinYu Sun, Yuchen Ma, Ziheng Wang, Yu Zeng, Zehui Chen, Lin Chen, Wenxuan Huang, Wei-Jie Xu, Yi Cao, Feng Zhao",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.401381",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下分析： 1.  **核心主题不匹配 (第一步 & 第三步)**: *   论文的核心研究对象是“统一多模态模型”，特别是针对“文本到图像生成”能力的改进。虽然标题中包含“Self-Improving”，但其目标是提升模型的生成质量，而非构建或演化具有自主规划、工具使用能力的“LLM智能体”。 *   根据第三步排除标准，论文主要涉及 `Vision`、`Vision-Language` 和 `Diffusion Models`（图像生成），且视觉生成是研究的核心而非智能体感知环境的工具，因此属于明确的排除范畴。 2.  **方法论性质 (第一步 & 第四步)**: *   尽管论文提出了将模型划分为 Proposer、Solver 和 Judge 三个角色，并使用了 Self-Play 机制，但这本质上是一种**模型训练/微调策略**（Self-Generated Supervision / Distillation），旨在通过内部生成的监督信号来优化模型参数，解决“传导性失语症”问题。 *   这不属于 Agentic AI 的研究范畴（即智能体在环境中的交互、决策或任务执行），而是属于模型训练优化的范畴。 综上所述，该论文属于多模态模型训练与优化的研究，而非 LLM 智能体的构建、协作或演化，因此予以排除。"
    },
    {
        "index": "#73",
        "title": "PrismVAU: Prompt-Refined Inference System for Multimodal Video Anomaly Understanding",
        "link": "/arxiv/2601.02927",
        "arxiv_id": "2601.02927",
        "authors": "Iñaki Erregue, Kamal Nasrollahi, Sergio Escalera",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.439678",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心判断（非演化型应用）**：论文的核心贡献是提出一个名为 PrismVAU 的系统，用于解决“视频异常理解”这一特定领域的计算机视觉任务。虽然它使用了 MLLM（多模态大语言模型），但其本质是将模型作为工具应用于视频分析领域，而非构建、改进或演化通用的 LLM 智能体架构。 2.  **排除标准（多模态与视觉）**：论文明确聚焦于“Multimodal Video Anomaly Understanding”（多模态视频异常理解）。根据第三步排除标准，涉及视觉、视频理解的论文通常被排除，除非视频仅作为智能体感知环境的工具。在本研究中，视频处理和异常检测是研究的核心主体，而非智能体架构的辅助组件。 3.  **缺乏 Agentic 特征**：尽管论文提到了“Prompt Optimization”（提示优化），但这属于针对特定任务（VAU）的参数优化手段，而非智能体的自我演化机制。该系统不具备 Agentic AI 的核心特征，如自主规划、工具使用、记忆机制或在复杂环境中的多步决策能力。它更像是一个针对视频数据的推理流水线，而非一个自主智能体。 综上所述，该论文属于特定领域的应用研究（视频分析），而非关于 LLM 智能体构建或演化的方法论研究，因此予以排除。"
    },
    {
        "index": "#43",
        "title": "Unified Thinker: A General Reasoning Modular Core for Image Generation",
        "link": "/arxiv/2601.03127",
        "arxiv_id": "2601.03127",
        "authors": "Sashuai Zhou, Qiang Zhou, Jijin Hu, Hanqing Yang, Yue Cao, Junpeng Ma, Yinchao Ma, Jun Song, Tiezheng Ge, Cheng Yu, Bo Zheng, Zhou Zhao",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.409222",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#77",
        "title": "LOST-3DSG: Lightweight Open-Vocabulary 3D Scene Graphs with Semantic Tracking in Dynamic Environments",
        "link": "/arxiv/2601.02905",
        "arxiv_id": "2601.02905",
        "authors": "Sara Micol Ferraina, Michele Brienza, Francesco Argenziano, Emanuele Musumeci, Vincenzo Suriani, Domenico D. Bloisi, Daniele Nardi",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.441908",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断依据： 1.  **核心贡献不符（第一步 - 核心判断）**： 论文的核心贡献是提出了一种名为 LOST-3DSG 的**轻量级开放词汇3D场景图**（3D Scene Graphs），用于在动态环境中跟踪物体。这属于**机器人感知与环境表示**的研究范畴，而非构建、改进或演化 LLM 智能体的方法论。它解决的是特定领域（机器人视觉/SLAM）的问题，属于“非演化型应用”。 2.  **触犯排除标准（第三步 - 排除标准）**： *   **图相关技术**：论文标题和摘要明确指出其核心是“3D Scene Graphs”（3D场景图）。根据筛选标准，涉及知识图谱、图神经网络等图相关技术的论文属于排除范围。 *   **多模态与视觉**：尽管论文旨在避免使用重型视觉模型（如CLIP），但其应用场景是3D视觉环境，并在TIAGo机器人上进行实验，本质上属于视觉/机器人领域的研究，而非 Agentic AI 的核心架构研究。 3.  **缺乏核心关注点（第二步 - 正面指标）**： 论文未涉及任何关于智能体规划、工具使用、自我反思、多智能体协作或自我演化机制的内容。它关注的是如何利用 word2vec 和句子嵌入来构建高效的场景表示，而不是智能体的行为逻辑或演化能力。 综上所述，该论文属于机器人视觉与图表示学习领域的应用研究，不符合“LLM智能体及其演化”的研究课题要求。"
    },
    {
        "index": "#74",
        "title": "DCG ReID: Disentangling Collaboration and Guidance Fusion Representations for Multi-modal Vehicle Re-Identification",
        "link": "/arxiv/2601.02924",
        "arxiv_id": "2601.02924",
        "authors": "Aihua Zheng, Ya Gao, Shihao Li, Chenglong Li, Jin Tang",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.440219",
        "filter_reason": "这篇论文不符合研究范围，具体判断依据如下： 1.  **核心领域不符 (第一步 - 核心判断)**: *   论文的核心贡献是提出一种名为 **DCG-ReID** 的方法，用于解决 **多模态车辆重识别** 问题。这属于计算机视觉领域的特定应用研究，而非构建或演化 LLM 智能体。 *   论文主要关注如何融合 RGB、NIR 和 TIR 等视觉模态的特征，属于“非演化型应用”，即利用深度学习模型解决特定领域（交通监控/车辆检索）的问题。 2.  **触发排除标准 (第三步 - 排除标准)**: *   **多模态与视觉**: 论文明确涉及多模态数据处理和视觉理解，属于被明确排除的“多模态与视觉”范畴。虽然标题中出现了 \"Collaboration\"（协作），但在文中它指的是模态间特征的“协作融合”，而非智能体之间的协作行为。 3.  **缺乏核心指标 (第二步 - 正面指标)**: *   论文中未包含任何关于 `Agentic AI`、`LLM-based Agents`、`Planning`、`Tool Use` 或 `Self-Evolving` 的核心范式或能力。它不涉及大语言模型、智能体框架或演化算法。 综上所述，该论文是一篇纯粹的计算机视觉应用论文，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#83",
        "title": "UniSRCodec: Unified and Low-Bitrate Single Codebook Codec with Sub-Band Reconstruction",
        "link": "/arxiv/2601.02776",
        "arxiv_id": "2601.02776",
        "authors": "Zhisheng Zhang, Xiang Li, Yixuan Zhou, Jing Peng, Shengbo Cai, Guoyang Zeng, Zhiyong Wu",
        "subjects": "Sound, Artificial Intelligence, Multimedia",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.451830",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 UniSRCodec 的神经音频编解码器，旨在解决音频压缩和重建中的保真度与带宽问题。 根据筛选标准进行判断： 1.  **核心判断（第一步）**：论文的本质属于音频信号处理和模型架构设计，而非构建、改进或演化 LLM 智能体。它不涉及 Agentic AI 的核心要素（如规划、记忆、工具使用等），也不涉及多智能体系统或自我演化机制。 2.  **正面指标（第二步）**：论文中未出现任何与智能体相关的核心范式或能力关键词（如 Agentic AI, Planning, Tool Use, Multi-Agent Systems 等）。 3.  **排除标准（第三步）**：虽然论文涉及离散信号处理，但其研究焦点是音频编解码技术本身，而非将其作为智能体感知环境的工具来研究智能体的行为。 综上所述，该论文属于音频处理领域的基础模型研究，完全偏离了“LLM智能体及其演化”这一研究课题，因此予以排除。"
    },
    {
        "index": "#82",
        "title": "Closing the Reality Gap: Zero-Shot Sim-to-Real Deployment for Dexterous Force-Based Grasping and Manipulation",
        "link": "/arxiv/2601.02778",
        "arxiv_id": "2601.02778",
        "authors": "Haoyu Dong, Zhengmao He, Yang Li, Zhibin Li, Xinyu Yi, Zhe Zhao",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.451276",
        "filter_reason": "这篇论文不符合我的研究范围，理由如下： 1.  **核心领域不符（第一步 - 核心判断）**： *   论文的核心贡献是提出一种基于强化学习（RL）的 **Sim-to-Real（仿真到现实）** 框架，用于解决机器人灵巧手的抓取和操作控制问题。 *   该研究属于 **机器人控制** 和 **传统强化学习** 范畴，而非 **LLM智能体**。论文中完全没有涉及大语言模型（LLM）作为核心决策组件。 2.  **缺乏Agentic AI的关键要素（第二步 - 正面指标）**： *   论文的方法论基于非对称演员-评论家 PPO（Asymmetric actor-critic PPO）管线，关注的是物理层面的触觉反馈、力矩校准和驱动器动力学建模。 *   它不具备 LLM 智能体的关键特征，如基于语言的规划、工具使用、记忆机制或自我反思。 3.  **属于非演化型应用（第一步 - 排除标准）**： *   虽然论文提到了“Sim-to-Real”的迁移，但这指的是从仿真环境迁移到物理硬件，而非智能体通过经验或反思进行的“自我演化”或“自我完善”。 *   这是一个典型的将算法（RL）应用于特定领域（机器人抓取）的案例，符合“非演化型应用”的排除规则。 综上所述，该论文是关于机器人底层控制策略的训练与部署，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#67",
        "title": "Interpretable All-Type Audio Deepfake Detection with Audio LLMs via Frequency-Time Reinforcement Learning",
        "link": "/arxiv/2601.02983",
        "arxiv_id": "2601.02983",
        "authors": "Yuankun Xie, Xiaoxuan Guo, Jiayi Zhou, Tao Wang, Jian Liu, Ruibo Fu, Xiaopeng Wang, Haonan Cheng, Long Ye",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.431462",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心贡献不符 (第一步 - 核心判断)**: 论文的核心目标是解决“音频深度伪造检测”这一特定领域的安全问题，并提出了一种名为“FT-GRPO”的训练方法来提高检测性能和可解释性。这属于将LLM（Audio LLMs）作为工具应用于特定安全领域的**非演化型应用**，而非构建、改进或演化LLM智能体的方法论。 2.  **触犯排除标准 (第三步 - 排除标准)**: 论文明确聚焦于 **Safety/Security**（深度伪造检测）和 **Interpretability/Explainability**（生成可解释的决策依据）。根据筛选标准，只要论文的主要贡献是关于安全、对齐或可解释性，一律排除。尽管论文使用了强化学习，但其目的是为了优化分类器的解释能力，而非智能体的自我演化或自主规划。 3.  **缺乏Agentic特征 (第二步 - 正面指标)**: 论文中虽然提到了“Chain-of-Thought (CoT)”，但这里的CoT是作为**解释性依据**服务于分类任务的，而非用于智能体的自主规划、推理或工具调用。论文不涉及智能体的自主性、记忆机制、工具使用或多智能体协作等Agentic AI的核心特征。 综上所述，该论文属于安全领域的应用研究，而非LLM智能体架构或演化的研究，因此予以排除。"
    },
    {
        "index": "#52",
        "title": "IBISAgent: Reinforcing Pixel-Level Visual Reasoning in MLLMs for Universal Biomedical Object Referring and Segmentation",
        "link": "/arxiv/2601.03054",
        "arxiv_id": "2601.03054",
        "authors": "Yankai Jiang, Qiaoru Li, Binlu Xu, Haoran Sun, Chao Ding, Junting Dong, Yuxiang Cai, Xuhong Zhang, Jianwei Yin",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.413601",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#84",
        "title": "Netflix Artwork Personalization via LLM Post-training",
        "link": "/arxiv/2601.02764",
        "arxiv_id": "2601.02764",
        "authors": "Hyunji Nam, Sejoon Oh, Emma Kong, Yesu Feng, Moumita Bhattacharya",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.452309",
        "filter_reason": "这篇论文的核心贡献在于利用LLM的后训练技术来解决Netflix平台上的个性化艺术品推荐问题。根据筛选标准的第一步（核心判断），该研究属于典型的“非演化型应用”。论文将LLM作为一个工具应用于特定的垂直领域（娱乐/推荐系统），旨在提升用户满意度和参与度，而非提出新的LLM智能体架构、多智能体协作框架或自我演化机制。此外，论文中未涉及任何Agentic AI的关键特征（如自主规划、工具使用、记忆机制、自我反思或多智能体交互），也不符合“自我演化”的例外情况（即提出新的演化机制）。因此，该论文不符合关于“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#64",
        "title": "Towards Faithful Reasoning in Comics for Small MLLMs",
        "link": "/arxiv/2601.02991",
        "arxiv_id": "2601.02991",
        "authors": "Chengcheng Feng, Haojie Yin, Yucheng Jin, Kaizhu Huang",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.430029",
        "filter_reason": "这篇论文的核心贡献是提出一种针对小型多模态大语言模型（MLLMs）的推理框架，旨在解决漫画和幽默理解等视觉问答（VQA）任务中的问题。根据筛选标准，该论文不符合研究要求，原因如下： 1.  **触犯排除标准（多模态与视觉）**：论文明确研究对象是“Small MLLMs”（小型多模态大语言模型），且核心任务是“Comic-based visual question answering”（基于漫画的视觉问答）以及“meme understanding”（表情包理解）。根据第三步排除标准，涉及多模态与视觉（Vision, MLLMs, Video Understanding等）的论文通常应被排除，除非视觉仅作为智能体感知环境的工具而非研究核心。本文的研究核心在于提升模型对视觉内容的理解与推理能力，而非构建智能体架构。 2.  **属于非Agentic的推理**：虽然论文提到了“Chain-of-Thought (CoT)”和“Reasoning”，但其目的是为了改进模型在特定视觉任务（回答问题）中的输出质量，而非构建具有自主规划、工具使用或记忆机制的智能体。根据第一步和第四步的判断规则，这属于提高模型基础推理能力的范畴，而非Agentic AI的规划或框架构建。 3.  **非演化型应用**：论文虽然使用了GRPO（一种强化学习算法）进行微调，但这属于模型训练层面的优化，而非智能体在运行时的自我演化或自我完善机制。其应用场景（漫画、幽默理解）属于特定领域的应用问题，不符合核心目标中关于构建或演化LLM智能体的要求。 综上所述，该论文侧重于多模态模型的视觉推理能力优化，而非LLM智能体的构建、协作或演化，因此予以排除。"
    },
    {
        "index": "#71",
        "title": "The World is Not Mono: Enabling Spatial Understanding in Large Audio-Language Models",
        "link": "/arxiv/2601.02954",
        "arxiv_id": "2601.02954",
        "authors": "Yuhuan You, Lai Wei, Xihong Wu, Tianshu Qu",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.433547",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心贡献不符（第一步）：** 论文的核心贡献在于构建和改进**大型音频-语言模型**，具体包括设计混合特征投影器、构建双耳音频数据集以及通过训练课程提升模型的**空间感知能力**。这属于多模态模型架构与感知能力的提升，而非构建、改进或演化 LLM 智能体。 2.  **触犯排除标准（第三步）：** 研究明确属于**多模态**领域。虽然论文标题和摘要主要涉及音频而非视觉，但根据筛选标准中的“多模态与视觉”排除项，除非多模态技术仅作为智能体感知环境的工具，否则主要关注多模态模型本身构建的论文应被排除。本文的研究重点是让模型理解“空间音频”，这是模型感知层的改进，而非 Agentic 层的构建。 3.  **缺乏 Agentic 特征（第二步）：** 论文虽然提到了“推理”，但这是指基于音频内容的语义和空间推理，而非智能体的自主规划、工具使用或记忆机制。文中未涉及任何智能体框架（如 ReAct, ToT 等）或多智能体协作机制。 4.  **关于“演化”的误读（第四步）：** 摘要中提到的“evolve the model's capabilities”是指通过强化学习（GRPO）训练来提升模型在特定任务上的性能，属于模型训练策略，而非“自我演化”智能体机制（即智能体在运行时通过经验、反思进行自我完善和迭代）。 综上所述，该论文属于多模态感知模型的研究，不属于 LLM 智能体及其演化的范畴。"
    },
    {
        "index": "#89",
        "title": "Foreground-Aware Dataset Distillation via Dynamic Patch Selection",
        "link": "/arxiv/2601.02727",
        "arxiv_id": "2601.02727",
        "authors": "Longzhen Li, Guang Li, Ren Togo, Keisuke Maeda, Takahiro Ogawa, Miki Haseyama",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.456596",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下判断： 1.  **核心领域不匹配（第一步核心判断）**：论文的核心贡献是提出一种“前景感知的数据集蒸馏”方法，旨在通过动态补丁选择生成紧凑的合成数据集以降低训练成本。这属于计算机视觉（CV）和机器学习训练优化的范畴，完全未涉及构建、改进或演化 LLM 智能体。 2.  **触犯排除标准——多模态与视觉（第三步）**：论文的研究内容完全围绕图像处理展开，涉及“图像”、“补丁”、“前景对象”以及视觉模型“Grounded SAM2”。虽然提示中提到视觉模型可作为智能体的工具，但在此论文中，视觉技术是研究对象本身（用于数据集压缩），而非服务于智能体框架的感知模块。因此，它属于应排除的纯视觉研究。 3.  **缺乏核心关注点（第二步）**：论文中没有任何关于 Agentic AI、LLM-based Agents、Multi-Agent Systems 或 Self-Evolving 的讨论。它也不涉及智能体的规划、记忆、工具使用、自我反思或多智能体协作等核心能力。 综上所述，该论文是一篇关于数据集压缩和视觉处理的优化类论文，与 LLM 智能体及其演化的研究课题无关。"
    },
    {
        "index": "#90",
        "title": "Privacy-Preserving AI-Enabled Decentralized Learning and Employment Records System",
        "link": "/arxiv/2601.02720",
        "arxiv_id": "2601.02720",
        "authors": "Yuqiao Xu, Mina Namazi, Sahith Reddy Jalapally, Osama Zafar, Youngjin Yoo, Erman Ayday",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.457171",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下判断： 1.  **核心贡献不符（第一步 - 核心判断）**：论文的核心是构建一个基于区块链和可信执行环境（TEE）的**去中心化学习与就业记录（LER）系统**。虽然它使用了NLP技术进行技能提取，但这只是系统中的一个组件，其本质是将AI技术应用于特定领域（教育/就业记录管理）以解决隐私和安全问题，属于“非演化型应用”，而非构建或演化LLM智能体本身。 2.  **触犯排除标准（第三步 - 排除标准）**：论文的主要贡献集中在**安全与对齐**以及**基础设施**上。摘要中反复强调“Privacy-Preserving”（隐私保护）、“Security”（安全）、“Confidential”（机密）、“Unforgeable”（不可伪造）以及区块链和TEE等底层基础设施。根据筛选标准，主要关注安全、隐私或基础设施的研究应予以排除。 3.  **缺乏核心指标（第二步 - 正面指标）**：论文未涉及任何Agentic AI的核心范式或能力，如智能体的规划、工具使用、记忆、自我反思，也不涉及多智能体协作或自我演化机制。 综上所述，该论文属于安全与隐私领域的应用型研究，不属于LLM智能体及其演化的研究范畴。"
    },
    {
        "index": "#93",
        "title": "Multi-channel multi-speaker transformer for speech recognition",
        "link": "/arxiv/2601.02688",
        "arxiv_id": "2601.02688",
        "authors": "Guo Yifan, Tian Yao, Suo Hongbin, Wan Yulong",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.458686",
        "filter_reason": "1.  **核心贡献分析**：该论文提出了一种名为 \"M2Former\" 的多通道多说话人 Transformer 模型，旨在解决远场多说话人自动语音识别（ASR）问题。其核心贡献在于改进声学特征编码和信号处理能力，以降低词错误率（WER）。 2.  **第一步（核心判断）**：论文属于典型的“非演化型应用”。它将深度学习模型应用于语音处理这一特定垂直领域，并未涉及构建、改进或演化 LLM 智能体的方法论。 3.  **研究焦点不符**： *   **非 Agentic**：论文未涉及智能体的自主规划、工具使用、记忆或反思机制。 *   **非 Multi-Agent**：标题中的 \"Multi-speaker\" 指的是音频信号中的多个说话人，而非人工智能领域的 \"Multi-Agent Systems\"（多智能体协作系统）。 *   **非 Self-Evolving**：论文未提出任何自我完善或迭代演化的机制。 4.  **结论**：该论文属于语音识别领域的模型架构优化研究，与 \"LLM智能体及其演化\" 的研究课题完全无关，因此予以排除。"
    },
    {
        "index": "#80",
        "title": "Breaking Self-Attention Failure: Rethinking Query Initialization for Infrared Small Target Detection",
        "link": "/arxiv/2601.02837",
        "arxiv_id": "2601.02837",
        "authors": "Yuteng Liu, Duanni Meng, Maoxun Yuan, Xingxing Wei",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.443499",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 SEF-DETR 的新框架，用于解决**红外小目标检测**这一计算机视觉领域的特定问题。论文主要关注的是改进目标检测模型（基于DETR）中的自注意力机制和查询初始化策略，以提高在复杂背景下的检测性能。 根据筛选标准，该论文不符合研究要求，原因如下： 1.  **核心判断（第一步）**：论文属于典型的“非演化型应用”。它将深度学习模型（DETR）应用于特定的视觉领域（红外检测），旨在解决该领域的检测精度问题，而非构建、改进或演化 LLM智能体。 2.  **排除标准（第三步）**：论文明确属于“多模态与视觉”范畴。其核心研究内容是图像处理和目标检测，而非将视觉作为智能体感知环境的工具。 3.  **技术本质**：虽然论文提到了“Query Initialization”，但这指的是目标检测模型（如DETR）内部的可学习嵌入参数，与 LLM智能体的规划、工具调用或推理无关。 综上所述，该论文是一篇计算机视觉领域的应用型论文，与“LLM智能体及其演化”的研究课题无关，因此予以排除。"
    },
    {
        "index": "#91",
        "title": "CREAM: Continual Retrieval on Dynamic Streaming Corpora with Adaptive Soft Memory",
        "link": "/arxiv/2601.02708",
        "arxiv_id": "2601.02708",
        "authors": "HuiJeong Son, Hyeongu Kang, Sunho Kim, Subeen Ho, SeongKu Kang, Dongha Lee, Susik Yoon",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.457734",
        "filter_reason": "根据您提供的筛选标准，这篇论文**不符合**您的研究范围。以下是详细的判断过程： 1.  **核心判断（第一步）：** *   **论文本质：** 这篇论文的核心贡献是提出一种名为 CREAM 的**信息检索（IR）框架**，用于解决动态数据流中的检索性能下降问题。它属于“信息检索”和“持续学习”领域，而非“LLM智能体”领域。 *   **排除依据：** 论文虽然提到了“记忆”和“自适应”，但这里的“记忆”是指检索系统中的存储机制（用于存储查询和文档的语义），而不是智能体架构中的记忆模块（如用于存储历史经验、反思结果的组件）。论文并未涉及构建具有自主规划、工具使用或决策能力的智能体。 2.  **正面指标缺失（第二步）：** *   论文中没有出现 `Agentic AI`、`LLM-based Agents`、`Multi-Agent Systems` 等核心范式。 *   虽然涉及 `Adaptive`（自适应）和 `Continual`（持续），但这指的是模型对**数据分布变化**的适应（持续学习），而不是智能体通过**经验、反思或环境反馈**进行的自我完善或能力演化（Self-Evolving）。 *   缺乏智能体的关键能力特征，如 `Planning`（规划）、`Tool Use`（工具使用，除了检索本身作为任务外）、`Self-Reflection`（自我反思）等。 3.  **排除标准确认（第三步）：** *   该论文不属于安全对齐或多模态范畴，但它属于**非演化型应用**或**基础设施优化**的变种。它致力于优化检索系统这一特定组件的性能，而不是研究如何构建或演化一个能够自主行动的智能体。 **总结：** 该论文主要解决的是信息检索系统在动态环境下的适应性问题，属于传统的机器学习/检索系统优化范畴，而非 Agentic AI 的研究。它没有构建智能体，也没有涉及智能体的规划、协作或自我演化机制。因此，应予以排除。"
    },
    {
        "index": "#97",
        "title": "Effective Online 3D Bin Packing with Lookahead Parcels Using Monte Carlo Tree Search",
        "link": "/arxiv/2601.02649",
        "arxiv_id": "2601.02649",
        "authors": "Jiangyi Fang, Bowen Zhou, Haotian Wang, Xin Zhu, Leye Wang",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.460824",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下核心判断： 1.  **核心贡献不涉及LLM智能体 (第一步核心判断)**: 论文的核心是解决物流领域的“在线3D装箱”问题。其提出的方法论基于**深度强化学习 (DRL)** 和 **蒙特卡洛树搜索 (MCTS)**，并将其建模为模型预测控制 (MPC) 问题。全篇摘要未提及大语言模型 (LLM) 或基于LLM的智能体架构。因此，它不属于构建、改进或演化LLM智能体的范畴。 2.  **属于非演化型应用 (第一步排除标准)**: 该研究是将DRL和MCTS算法应用于特定的垂直领域（物流、机器人控制）以解决具体的优化问题（装箱效率、空间浪费）。这符合“非演化型应用”的排除标准，即只是将算法作为工具应用到特定领域，而非提出新的Agentic AI框架。 3.  **缺乏关键正面指标 (第二步)**: 论文中没有出现 `LLM-based Agents`、`Agentic AI`、`Tool Use`（在LLM语境下）、`Self-Reflection` 或 `Multi-Agent` 等核心范式关键词。虽然涉及“Planning”（通过MCTS），但这是针对装箱任务的搜索规划，而非LLM智能体的自主规划能力。 综上所述，该论文属于机器人控制与运筹优化领域的应用研究，与“LLM智能体及其演化”的研究课题无关。"
    },
    {
        "index": "#99",
        "title": "DreamLoop: Controllable Cinemagraph Generation from a Single Photograph",
        "link": "/arxiv/2601.02646",
        "arxiv_id": "2601.02646",
        "authors": "Aniruddha Mahapatra, Long Mai, Cusuh Ham, Feng Liu",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.461825",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 DreamLoop 的视频合成框架，旨在利用视频扩散模型从单张照片生成可控的 Cinemagraph（部分动态的循环图像）。 根据筛选标准，我的判断过程如下： 1.  **核心判断（第一步）**：论文的本质属于计算机视觉和生成式AI领域，主要解决的是图像动画化和视频生成问题。它并不涉及构建、改进或演化 LLM 智能体，也不包含多智能体系统或自我演化机制。 2.  **排除标准（第三步）**：论文明确涉及“多模态与视觉”技术。虽然视觉技术可以作为智能体的感知工具，但在本论文中，视觉生成是研究的核心目标，而非服务于智能体的决策或演化过程。 3.  **结论**：该论文的研究焦点与“LLM智能体及其演化”这一课题完全无关，属于被明确排除的视觉生成类研究。"
    },
    {
        "index": "#103",
        "title": "LAsset: An LLM-assisted Security Asset Identification Framework for System-on-Chip (SoC) Verification",
        "link": "/arxiv/2601.02624",
        "arxiv_id": "2601.02624",
        "authors": "Md Ajoad Hasan, Dipayan Saha, Khan Thamid Hasan, Nashmin Alam, Azim Uddin, Sujan Kumar Saha, Mark Tehranipoor, Farimah Farahmandi",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.463134",
        "filter_reason": "这篇论文不符合筛选标准，应予以排除。具体判断依据如下： 1.  **核心判断（非演化型应用）**： 论文的核心贡献是提出了一个名为 \"LAsset\" 的框架，用于解决特定领域——**片上系统硬件安全验证**中的问题（即识别安全资产）。这属于将LLM作为工具应用到特定垂直领域（硬件工程/安全）的典型应用，而非构建通用的LLM智能体架构或研究智能体的基础演化机制。 2.  **缺乏Agentic核心特征**： 摘要中描述的方法主要是利用LLM进行“结构和语义分析”以及“识别资产”，这本质上属于信息提取或分类任务。文中并未提及智能体的核心能力，如自主规划、工具使用、记忆机制、自我反思或多智能体协作等。 3.  **排除标准（特定领域应用）**： 根据第一步的排除规则，凡是“将LLM（或一个已有的Agentic / Multi-Agent框架）作为工具应用到特定领域去解决该领域的问题（例如...安全...）”的论文均需排除。本文正是将LLM应用于硬件安全领域的资产识别，因此不符合研究目标。 综上所述，该论文属于LLM在特定工程领域的应用研究，而非关于LLM智能体构建、改进或演化的基础研究。"
    },
    {
        "index": "#87",
        "title": "Hypothesize-Then-Verify: Speculative Root Cause Analysis for Microservices with Pathwise Parallelism",
        "link": "/arxiv/2601.02736",
        "arxiv_id": "2601.02736",
        "authors": "Lingzhe Zhang, Tong Jia, Yunpeng Zhai, Leyi Pan, Chiming Duan, Minghua He, Pei Xiao, Ying Li",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.453982",
        "filter_reason": "根据筛选标准，这篇论文不符合研究范围，主要基于以下判断： 1.  **核心判断（第一步 - 排除非演化型应用）**： *   该论文的核心贡献是提出 **SpecRCA**，这是一个专门用于**微服务**系统中进行**根因分析（RCA）**的框架。 *   虽然它利用了LLM并采用了 \"hypothesize-then-verify\"（假设-验证）的推理模式，但其本质是将LLM作为一种工具应用到**AIOps/系统运维**这一特定垂直领域，以解决该领域的具体问题（故障定位）。 *   论文的目标是提升RCA的准确性和效率，而不是构建、改进或演化通用的LLM智能体架构。因此，它属于“非演化型应用”，应予以排除。 2.  **缺乏核心关注点（第二步）**： *   论文并未涉及 `Agentic AI` 的核心构建块（如通用的记忆机制、工具学习框架、自我反思循环）或 `Multi-Agent Systems`（智能体间的协作、通信、博弈）。 *   尽管包含 \"hypothesize-then-verify\" 步骤，但这仅是针对特定任务（RCA）的算法设计，而非关于智能体如何进行通用规划或自我演化的方法论创新。 3.  **不符合特殊例外情况（第四步）**： *   该论文不属于“自我演化的应用”这一例外情况，因为它并没有提出一种新的自我演化或自我完善机制，而是提出了一种针对特定诊断任务的并行验证框架。 综上所述，该论文属于LLM在特定领域的应用研究，而非关于LLM智能体本身架构或演化的基础研究，因此不符合筛选要求。"
    },
    {
        "index": "#116",
        "title": "Enhancing Debugging Skills with AI-Powered Assistance: A Real-Time Tool for Debugging Support",
        "link": "/arxiv/2601.02504",
        "arxiv_id": "2601.02504",
        "authors": "Elizaveta Artser, Daniil Karol, Anna Potriasaeva, Aleksei Rostovskii, Katsiaryna Dzialets, Ekaterina Koshchenko, Xiaotian Su, April Yi Wang, Anastasiia Birillo",
        "subjects": "Software Engineering, Artificial Intelligence, Computers and Society",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.467375",
        "filter_reason": "根据筛选标准，这篇论文不符合我的研究范围，具体判断过程如下： 1.  **核心判断（第一步）**： *   该论文的核心贡献是开发了一个集成在IDE中的“AI驱动调试助手”，旨在解决编程教育和软件开发中的调试问题。 *   这属于典型的**非演化型应用**。论文虽然使用了LLM和RAG技术，但将其作为工具应用于特定的垂直领域（软件工程/教育），目的是辅助人类进行调试，而不是为了构建、改进或演化LLM智能体本身的架构或能力。 2.  **正面指标缺失（第二步）**： *   论文主要关注的是“实时支持”、“分析代码”、“建议断点”以及通过“程序切片”和“自定义启发式方法”来优化LLM调用。 *   这些内容并不涉及我关注的核心范式，如智能体的自主规划、多智能体间的协作博弈，或智能体的自我演化/迭代机制。 3.  **排除标准确认（第三步）**： *   虽然论文未涉及安全、对齐或多模态等排除项，但它被第一步的“非演化型应用”规则直接排除。 综上所述，该论文属于应用层的研究，而非Agentic AI的基础方法论或框架研究，因此予以排除。"
    },
    {
        "index": "#107",
        "title": "Annealed Langevin Posterior Sampling (ALPS): A Rapid Algorithm for Image Restoration with Multiscale Energy Models",
        "link": "/arxiv/2601.02594",
        "arxiv_id": "2601.02594",
        "authors": "Jyothi Rikhab Chand, Mathews Jacob",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.464491",
        "filter_reason": "这篇论文的核心贡献是提出一种名为 Annealed Langevin Posterior Sampling (ALPS) 的算法，用于解决成像领域的逆问题（如图像修复和MRI重建）。该研究主要关注能量基模型 (EBM) 和扩散模型的蒸馏技术，属于计算机视觉和图像处理领域。 根据筛选标准，该论文不符合要求的原因如下： 1.  **触犯排除标准（多模态与视觉）**：论文的核心研究内容是图像恢复，属于视觉和多模态范畴。根据第三步排除标准，涉及视觉且核心不是作为智能体感知环境工具的论文应被排除。 2.  **缺乏智能体要素**：论文未涉及 LLM、智能体构建、规划、工具使用、多智能体协作或自我演化机制。 3.  **非演化型应用**：这是一个针对特定领域（图像处理）的算法优化与应用，而非关于构建或演化 LLM智能体的方法论研究。"
    },
    {
        "index": "#112",
        "title": "AI-exposed jobs deteriorated before ChatGPT",
        "link": "/arxiv/2601.02554",
        "arxiv_id": "2601.02554",
        "authors": "Morgan R. Frank, Alireza Javadian Sabet, Lisa Simon, Sarah H. Bana, Renzhe Yu",
        "subjects": "General Economics, Artificial Intelligence, Computers and Society",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.466071",
        "filter_reason": "这篇论文的核心贡献是关于人工智能（特别是生成式AI）对劳动力市场和经济指标的影响分析，属于经济学或社会科学研究范畴，而非计算机科学或人工智能系统的技术构建。 根据筛选标准的第一步“核心判断”，该论文并不涉及构建、改进或演化LLM智能体的方法论或新框架。它没有提出任何关于Agentic AI（单智能体）、Multi-Agent Systems（多智能体）或Self-Evolving（自我演化）的技术架构或算法。 根据第一步的“排除标准”，这属于典型的“非演化型应用”。论文将AI（或AI暴露度）作为研究对象，分析其对就业、薪资和失业风险的社会经济影响，而不是将LLM作为工具去构建一个具有自主规划、工具使用或自我演化能力的智能体系统。 因此，该论文完全不符合“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#121",
        "title": "Evaluating the Diagnostic Classification Ability of Multimodal Large Language Models: Insights from the Osteoarthritis Initiative",
        "link": "/arxiv/2601.02443",
        "arxiv_id": "2601.02443",
        "authors": "Li Wang, Xi Chen, XiangWen Deng, HuaHui Yi, ZeKun Jiang, Kang Li, Jian Li",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Image and Video Processing",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.468992",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断： 1.  **核心判断（第一步）：属于“非演化型应用”** 论文的核心贡献是评估多模态大语言模型（MLLMs）在特定医疗领域（膝骨关节炎X光片分类）的诊断能力。它通过消融研究分析视觉编码器、连接器和LLM组件对分类准确率的影响。这属于将LLM/MLLM作为工具应用到医疗领域的应用型研究，而非构建、改进或演化LLM智能体的方法论研究。 2.  **排除标准（第三步）：触犯“多模态与视觉”排除项** 论文的研究焦点在于多模态大语言模型（MLLMs）的架构组件（特别是视觉编码器和连接器）及其在视觉任务（图像分类）上的表现。根据筛选标准，涉及视觉、多模态且核心在于模型本身视觉能力而非作为智能体感知工具的研究，应当被排除。 3.  **缺乏核心关注点（第二步）：无Agentic特征** 论文中没有涉及任何关于智能体规划、工具使用、记忆、自我反思、多智能体协作或自我演化机制的内容。其关注点在于模型架构的组件分析和分类任务的性能优化，这与“LLM智能体及其演化”的研究目标完全无关。 综上所述，该论文是一篇典型的医疗多模态模型评估与应用论文，不符合Agentic AI的研究方向。"
    },
    {
        "index": "#101",
        "title": "TAAF: A Trace Abstraction and Analysis Framework Synergizing Knowledge Graphs and LLMs",
        "link": "/arxiv/2601.02632",
        "arxiv_id": "2601.02632",
        "authors": "Alireza Ezaz, Ghazal Khodabandeh, Majid Babaei, Naser Ezzati-Jivan",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.462457",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心贡献属于特定领域应用（非演化型应用）**：论文的核心目标是解决软件工程领域的问题，即分析操作系统内核或大型应用程序（如Chrome、MySQL）的执行追踪数据。它提出了一种名为TAAF的框架，将LLM作为工具来解释追踪数据，而不是为了构建、改进或演化LLM智能体本身。根据第一步的排除标准，这属于将LLM应用到特定领域解决该领域问题的情况。 2.  **触犯了明确的排除标准（图相关技术）**：论文标题和摘要明确指出其核心方法是“Synergizing Knowledge Graphs and LLMs”（协同知识图谱和LLMs），并且详细描述了如何从追踪事件构建“时间索引的知识图谱”。根据第三步的排除标准，涉及知识图谱的论文应予以排除。 3.  **缺乏Agentic特征**：虽然论文提到了LLM进行推理，但这仅限于基于子图回答自然语言问题，属于传统的问答或推理任务，并不涉及智能体的自主规划、工具使用、记忆机制或自我反思等Agentic AI的核心特征。 综上所述，该论文主要关注软件系统的调试与优化工具，且严重依赖知识图谱技术，不属于LLM智能体及其演化的研究范畴。"
    },
    {
        "index": "#124",
        "title": "Focus on What Matters: Fisher-Guided Adaptive Multimodal Fusion for Vulnerability Detection",
        "link": "/arxiv/2601.02438",
        "arxiv_id": "2601.02438",
        "authors": "Yun Bian, Yi Chen, HaiQuan Wang, ShiHao Li, Zhe Cui",
        "subjects": "Software Engineering, Artificial Intelligence, Cryptography and Security",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.469966",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 TaCCS-DFA 的框架，用于解决软件漏洞检测这一特定领域的二分类问题。其方法主要涉及结合自然代码序列（NCS）和代码属性图（CPG）进行多模态融合，并利用 Fisher 信息进行自适应的特征融合。 根据筛选标准，该论文不符合要求的原因如下： 1.  **非演化型应用 (第一步排除标准)**: 论文将预训练语言模型（CodeT5）作为特征提取器或分类器，应用于软件安全（漏洞检测）这一垂直领域。这属于将 LLM 作为工具解决特定领域问题，而非构建、改进或演化 LLM 智能体本身。 2.  **涉及图技术 (第三步排除标准)**: 论文明确使用了代码属性图（CPG）和图神经网络（GNN）作为核心组件之一。根据筛选标准，“涉及知识图谱，图神经网络等图相关技术的论文”属于排除范围。 3.  **缺乏 Agentic 特性**: 论文中没有涉及智能体的规划、工具使用、记忆、自我反思、多智能体协作或自我演化等核心 Agentic AI 特征。 综上所述，该论文属于软件工程与安全领域的应用研究，而非 LLM 智能体的架构或演化研究，因此予以排除。"
    },
    {
        "index": "#126",
        "title": "WebCoderBench: Benchmarking Web Application Generation with Comprehensive and Interpretable Evaluation Metrics",
        "link": "/arxiv/2601.02430",
        "arxiv_id": "2601.02430",
        "authors": "Chenxu Liu, Yingjie Fu, Wei Yang, Ying Zhang, Tao Xie",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.470581",
        "filter_reason": "这篇"
    },
    {
        "index": "#130",
        "title": "Watch Wider and Think Deeper: Collaborative Cross-modal Chain-of-Thought for Complex Visual Reasoning",
        "link": "/arxiv/2601.02422",
        "arxiv_id": "2601.02422",
        "authors": "Wenting Lu, Didi Zhu, Tao Shen, Donglin Zhu, Ayong Ye, Chao Wu",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-04",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.472406",
        "filter_reason": "这篇论文不符合我的研究范围，主要基于以下判断依据： 1.  **核心贡献属于多模态推理而非Agentic AI**： 论文的核心是提出 \"CoCoT (Collaborative Cross-modal Thought)\" 框架，旨在解决多模态（视觉-语言）场景下的推理问题。其重点在于改进模型如何处理图像区域和语言线索的整合（Dynamic Multi-Region Grounding 和 Relation-Aware Reasoning），以提升视觉问答（VQA）的性能。这属于多模态大语言模型（MLLMs）的基础能力提升，而非构建具有自主性、规划或工具使用能力的LLM智能体。 2.  **触犯了“多模态与视觉”的排除标准**： 根据筛选标准第三步，涉及 `Vision`、`Vision-Language`、`MLLMs` 的论文通常需要排除，除非视觉仅作为智能体感知环境的工具。在本论文中，视觉推理是研究的核心主题，而非辅助智能体执行任务的工具，因此应当排除。 3.  **属于非Agentic的推理**： 虽然论文涉及 \"Chain-of-Thought\"（思维链），但根据筛选标准第四步，这属于提高模型本身基础Token预测或逻辑能力的范畴（此处特指视觉逻辑），而不是关于智能体如何进行自主规划或在复杂任务中采取行动的Agentic框架。论文中的 \"Collaborative\" 指的是图像区域之间的协作，而非多智能体之间的协作。 综上所述，该论文侧重于视觉-语言模型的算法改进，而非LLM智能体的构建、多智能体系统或自我演化机制。"
    },
    {
        "index": "#131",
        "title": "Multimodal Sentiment Analysis based on Multi-channel and Symmetric Mutual Promotion Feature Fusion",
        "link": "/arxiv/2601.02415",
        "arxiv_id": "2601.02415",
        "authors": "Wangyuan Zhu, Jun Yu",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.472757",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献是提出一种名为“对称相互促进（SMP）”的跨模态特征融合方法，用于解决多模态情感分析中的特征提取和融合问题。这属于典型的多模态深度学习应用研究，而非构建、改进或演化 LLM智能体（Agentic LLM）的方法论或新框架。 2.  **触犯排除标准（第三步）**：根据筛选标准中的“多模态与视觉”排除项，涉及多模态（本文明确提及视觉和听觉模态）且核心在于多模态特征融合技术（而非将其作为智能体感知环境的工具）的论文应当排除。本文的研究重点完全在于多模态特征的处理机制，不涉及智能体架构。 3.  **缺乏正面指标（第二步）**：论文内容未包含任何 Agentic AI 的核心范式（如 Planning, Tool Use, Memory, ReAct 等），也未涉及多智能体系统（MAS）或自我演化机制。 综上所述，该论文属于多模态情感分析领域的应用型研究，与“LLM智能体及其演化”这一课题无关，因此予以排除。"
    },
    {
        "index": "#132",
        "title": "MIAR: Modality Interaction and Alignment Representation Fuison for Multimodal Emotion",
        "link": "/arxiv/2601.02414",
        "arxiv_id": "2601.02414",
        "authors": "Jichao Zhu, Jun Yu",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.473047",
        "filter_reason": "1.  **核心判断**: 这篇论文的核心贡献是提出了一种名为 MIAR 的网络架构，旨在解决多模态情感识别（MER）中的模态融合与对齐问题。这属于典型的多模态深度学习算法研究，而非关于构建、改进或演化 LLM 智能体的方法论。 2.  **排除标准**: 论文的研究重点在于处理文本、视觉和音频三种模态的特征交互与对齐。根据第三步排除标准，涉及“多模态与视觉”且其核心是模型架构本身而非作为智能体感知环境工具的论文，应予以排除。 3.  **缺乏 Agentic 特征**: 论文中完全没有涉及智能体的核心概念，如规划、工具使用、记忆机制、自我反思、多智能体协作或自我演化机制。因此，它不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#133",
        "title": "Socially-Aware Recommender Systems Mitigate Opinion Clusterization",
        "link": "/arxiv/2601.02412",
        "arxiv_id": "2601.02412",
        "authors": "Lukas Schüepp, Carmen Amo Alonso, Florian Dörfler, Giulia De Pasquale",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2026-01-02",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.473346",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心领域不符 (第一步 - 核心判断)**: 论文的核心贡献是提出一种“社交网络感知推荐系统”，旨在解决推荐系统中的意见极化和回声室效应。这属于推荐系统和网络科学的研究范畴，而非构建、改进或演化 LLM 智能体。论文中未提及 LLM、智能体架构或 Agentic AI 的核心组件。 2.  **涉及图相关技术 (第三步 - 排除标准)**: 摘要明确指出该系统利用了“用户社交网络的拓扑结构”来促进多样化。根据筛选标准，涉及图相关技术（如社交网络分析、图结构）的论文属于排除范围。 3.  **非演化型应用 (第一步 - 排除标准)**: 虽然摘要中提到了“用户偏好的演化”，但这指的是用户行为在推荐算法影响下的动态变化模型，而非智能体通过自我反思或经验进行“自我演化”的机制。这是将算法应用于特定领域（社交网络/推荐）解决该领域问题，而非研究智能体本身的演化能力。 综上所述，该论文属于推荐系统领域的应用研究，不涉及 LLM 智能体的构建或演化，因此予以排除。"
    },
    {
        "index": "#122",
        "title": "Understanding Pure Textual Reasoning for Blind Image Quality Assessment",
        "link": "/arxiv/2601.02441",
        "arxiv_id": "2601.02441",
        "authors": "Yuan Li, Shin'ya Nishida",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.469278",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心判断（非演化型应用）**：论文的核心贡献在于分析“文本推理”在“盲图像质量评估（BIQA）”这一特定视觉任务中的作用机制。它将 Chain-of-Thought (CoT) 和 Self-Consistency 等推理范式作为工具应用于图像质量预测领域，而非构建、改进或演化 LLM 智能体本身。根据第一步的排除规则，这属于将已有框架应用于特定领域的非演化型应用。 2.  **排除标准（多模态与视觉）**：论文的研究焦点是“Blind Image Quality Assessment”（盲图像质量评估），属于计算机视觉和图像处理领域。尽管论文使用了文本推理，但其核心目的是解决视觉任务中的问题，而非研究智能体如何感知环境。根据第三步的排除标准，涉及视觉且核心为视觉任务的论文应被排除。 3.  **缺乏 Agentic 特征**：虽然论文提到了 Chain-of-Thought 和 Self-Consistency，但它们在这里被用作提升图像质量分数预测准确性的推理技术，而非智能体的自主规划、工具使用、记忆或自我反思机制。论文没有涉及任何智能体架构、多智能体协作或自我演化机制。 综上所述，该论文属于视觉领域的应用研究，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#136",
        "title": "Expert-Guided Explainable Few-Shot Learning with Active Sample Selection for Medical Image Analysis",
        "link": "/arxiv/2601.02409",
        "arxiv_id": "2601.02409",
        "authors": "Longwei Wang, Ifrat Ikhtear Uddin, KC Santosh",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2026-01-02",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.474250",
        "filter_reason": "这篇论文不符合筛选要求，主要基于以下判断： 1.  **核心判断（第一步）**：论文的核心贡献是提出一种用于医学图像分析的少样本学习和主动学习方法（EGxFSL 和 xGAL），旨在解决医疗领域的数据稀缺和模型可解释性问题。这属于将机器学习模型应用于特定垂直领域（医疗）的“非演化型应用”，而非构建、改进或演化 LLM 智能体的方法论。论文中未涉及 LLM、智能体架构或 Agentic 行为。 2.  **排除标准（第三步）**： *   **安全与对齐**：论文明确将“Lack of model interpretability”（缺乏模型可解释性）作为要解决的关键挑战，并提出了“Explainable Few-Shot Learning”（可解释少样本学习）。根据筛选标准，主要贡献涉及 `Interpretability` (可解释性) 的论文应予以排除。 *   **多模态与视觉**：论文的研究对象是医学图像（MRI、胸部 X 光），属于 `Vision` 和 `Medical Image Analysis` 范畴。虽然视觉可以作为智能体的工具，但在此论文中，视觉处理是核心任务本身，而非服务于智能体演化的工具，因此符合排除条件。 综上所述，该论文属于医疗图像处理与可解释性研究，与“LLM智能体及其演化”的研究方向无关。"
    },
    {
        "index": "#129",
        "title": "A large-scale nanocrystal database with aligned synthesis and properties enabling generative inverse design",
        "link": "/arxiv/2601.02424",
        "arxiv_id": "2601.02424",
        "authors": "Kai Gu, Yingping Liang, Senliang Peng, Aotian Guo, Haizheng Zhong, Ying Fu",
        "subjects": "Materials Science, Artificial Intelligence",
        "date": "2026-01-04",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.472035",
        "filter_reason": "这篇论文的核心贡献在于构建了一个纳米晶体合成-属性数据库（NSP）以及用于逆向设计的生成模型（NanoDesigner），属于**材料科学**领域的应用研究，而非LLM智能体架构或演化机制的研究。 具体判断依据如下： 1.  **符合“非演化型应用”排除标准**：论文虽然使用了LLM（NanoExtractor用于信息提取，NanoDesigner用于生成合成路线），但LLM仅作为解决材料科学领域特定问题（数据提取和逆向设计）的工具。论文的研究焦点是纳米晶体的发现和合成，而非LLM智能体本身的构建、改进或演化。 2.  **缺乏Agentic核心特征**：论文中提到的LLM应用（信息提取和生成式设计）属于传统的自然语言处理（NLP）任务或生成式AI任务，并未涉及智能体的核心能力，如自主规划、工具使用、记忆机制、自我反思或多智能体协作。 3.  **不属于自我演化**：尽管论文提到了“生成式逆向设计”，但这指的是生成化学合成路径，而非智能体通过经验或环境反馈进行自我完善和迭代的“自我演化”机制。 综上所述，该论文属于将LLM应用于特定领域的应用型研究，不符合“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#139",
        "title": "AI-Native Integrated Sensing and Communications for Self-Organizing Wireless Networks: Architectures, Learning Paradigms, and System-Level Design",
        "link": "/arxiv/2601.02398",
        "arxiv_id": "2601.02398",
        "authors": "S. Zhang, M. Feizarefi, A. F. Mirzaei",
        "subjects": "Networking and Internet Architecture, Artificial Intelligence",
        "date": "2025-12-29",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.475206",
        "filter_reason": "1.  **核心主题不匹配 (第一步 - 核心判断)**: *   这篇论文的核心主题是 **无线网络**，具体涉及 \"Integrated Sensing and Communications (ISAC)\"（通感一体化）和 \"Self-Organizing Wireless Networks\"（自组织无线网络）。 *   论文的研究目标是解决通信基础设施中的资源分配、拓扑控制和移动性管理问题，属于 **基础设施** 和 **通信工程** 领域，而非构建或演化 LLM 智能体。 2.  **属于非演化型应用 (第一步 - 排除标准)**: *   尽管论文提到了 \"AI-native\" 和 \"Multi-agent coordination\"，但这里的 AI（主要是深度强化学习等）是被作为 **工具** 应用于无线网络这一特定领域，以优化网络性能（如延迟、可靠性、吞吐量）。 *   这符合排除标准中的 \"非演化型应用\"：将已有的 AI 框架应用到特定领域（通信/网络）解决该领域的问题。 3.  **缺乏 LLM 智能体相关要素 (第二步 - 正面指标)**: *   摘要中完全没有提及 Large Language Models (LLMs)、自然语言处理、或基于 LLM 的规划、记忆、工具使用等核心 Agentic 能力。 *   虽然提到了 \"Multi-agent coordination\"，但这指的是网络节点间的协调，而非 LLM 智能体之间的协作或社会学习。 4.  **涉及基础设施与硬件 (第三步 - 排除标准)**: *   论文明确讨论了 \"ISAC signal models\"（信号模型）、\"radio sensing\"（无线电感知）、\"hardware acceleration\"（隐含在系统级设计中）以及网络架构。这属于模型基础设施和底层硬件/网络优化的范畴，明确在排除标准之外。 综上所述，该论文是一篇关于无线通信网络架构与优化的综述，与 \"LLM智能体及其演化\" 的研究课题无直接关联。"
    },
    {
        "index": "#140",
        "title": "Self-Supervised Masked Autoencoders with Dense-Unet for Coronary Calcium Removal in limited CT Data",
        "link": "/arxiv/2601.02392",
        "arxiv_id": "2601.02392",
        "authors": "Mo Chen",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-25",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.475471",
        "filter_reason": "这篇论文不符合研究范围，主要基于以下判断： 1.  **核心判断（第一步）**：论文的核心贡献是提出一种名为 `Dense-MAE` 的自监督学习框架，用于解决医学图像处理中的特定问题（从CT血管造影数据中去除冠状动脉钙化）。这属于**非演化型应用**，即将深度学习模型（Dense-Unet）应用于医疗领域，而非构建或演化 LLM 智能体。 2.  **排除标准（第三步）**：论文明确涉及**视觉与多模态**技术。摘要中提到的 \"Computed Tomography Angiography (CTA)\"、\"3D point clouds\"、\"volumetric medical data\" 以及 \"inpainting\" 均属于计算机视觉和医学图像分析范畴。根据筛选标准，涉及视觉技术的论文除非是作为智能体感知环境的工具，否则一律排除，而本文的研究核心正是视觉模型本身的改进。 3.  **缺乏正面指标（第二步）**：论文中未出现任何关于 LLM、Agentic AI、规划、工具使用、多智能体协作或自我演化机制的关键词或概念。 综上所述，该论文是一篇典型的医学图像处理研究，与 \"LLM智能体及其演化\" 的课题无关。"
    },
    {
        "index": "#106",
        "title": "LongDA: Benchmarking LLM Agents for Long-Document Data Analysis",
        "link": "/arxiv/2601.02598",
        "arxiv_id": "2601.02598",
        "authors": "Yiyang Li, Zheyuan Zhang, Tianyi Ma, Zehong Wang, Keerthiram Murugesan, Chuxu Zhang, Yanfang Ye",
        "subjects": "Digital Libraries, Artificial Intelligence",
        "date": "2026-01-05",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.464165",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#141",
        "title": "Tree of Preferences for Diversified Recommendation",
        "link": "/arxiv/2601.02386",
        "arxiv_id": "2601.02386",
        "authors": "Hanyang Yuan, Ning Tang, Tongya Zheng, Jiarong Xu, Xintong Hu, Renhong Huang, Shunyu Liu, Jiacong Hu, Jiawei Chen, Mingli Song",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-12-24",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.475827",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下分析： 1.  **核心判断（第一步）：** *   **本质为应用研究：** 该论文的核心目标是解决推荐系统中的“多样性推荐”问题。虽然它利用了LLM的推理能力来挖掘用户偏好，但其最终目的是训练一个“通用推荐器”，而非构建、改进或演化LLM智能体本身。 *   **属于非演化型应用：** 论文将LLM作为工具应用于特定领域（推荐系统），用于生成合成数据或增强数据理解，这完全符合“排除标准”中的“非演化型应用”。 2.  **缺乏Agentic核心特征（第二步）：** *   尽管论文提到了“Tree of Preferences (ToP)”和“Reasoning”，但这指的是LLM在处理用户画像时的逻辑推理过程，而非智能体的自主规划、工具使用或记忆机制。 *   论文中没有涉及智能体在环境中的行动、多智能体间的协作或通信，也不包含智能体自我演化的机制。 3.  **特殊案例分析（第四步）：** *   关于推理：论文中的推理是用于理解用户偏好，属于LLM的基础能力应用，而非智能体在复杂任务中的多步规划或决策框架。 *   关于自我演化：论文虽然使用了合成数据来优化模型，但这属于推荐系统的训练优化方法，并非智能体通过经验或反思进行的自我完善和迭代。 综上所述，该论文属于推荐系统领域的应用研究，利用LLM作为辅助工具提升推荐效果，不属于LLM智能体架构、多智能体系统或自我演化的研究范畴。"
    },
    {
        "index": "#142",
        "title": "Base Station Deployment under EMF constrain by Deep Reinforcement learning",
        "link": "/arxiv/2601.02385",
        "arxiv_id": "2601.02385",
        "authors": "Mohammed Mallik, Guillaume Villemaud",
        "subjects": "Networking and Internet Architecture, Artificial Intelligence",
        "date": "2025-12-23",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.476117",
        "filter_reason": "这篇论文不符合筛选标准，具体判断过程如下： 1.  **核心判断（第一步）：** *   论文的核心贡献是提出一种结合条件生成对抗网络（cGAN）和深度Q网络（DQN）的框架，用于解决电信网络中基站（BS）的最优部署问题。 *   该研究属于**非演化型应用**。它将深度学习技术（DQN和cGAN）作为工具应用到了特定的工程领域（电信/网络设计），旨在解决信号覆盖和电磁场（EMF）约束下的基站选址问题，而不是构建或改进通用的LLM智能体框架。 2.  **技术路线不匹配（核心依据）：** *   论文使用的是**深度强化学习（DQN）**和**生成对抗网络**，而非**大语言模型（LLM）**。 *   您的研究课题明确限定为“**LLM**智能体及其演化”。虽然DQN属于智能体的一种，但缺乏LLM作为核心推理或决策组件，因此不属于“LLM-based Agents”的范畴。 3.  **缺乏核心关注点（第二步）：** *   论文不涉及任何LLM智能体的核心能力，如基于自然语言的规划、工具使用、记忆机制、自我反思或多智能体协作。 综上所述，该论文是一篇典型的通信网络工程优化论文，使用了传统的深度学习方法，与LLM智能体及其演化的研究目标无关，因此予以排除。"
    },
    {
        "index": "#144",
        "title": "The Refutability Gap: Challenges in Validating Reasoning by Large Language Models",
        "link": "/arxiv/2601.02380",
        "arxiv_id": "2601.02380",
        "authors": "Elchanan Mossel",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.476711",
        "filter_reason": "这篇论文的核心贡献在于从科学哲学（波普尔的证伪原则）和方法论的角度，批判性地分析了当前关于LLM推理能力的研究中存在的验证问题（如数据不透明、缺乏可复现性、选择偏差等），并提出了提高科学透明度和可复现性的指南。 根据筛选标准： 1.  **核心判断（第一步）**：该论文并没有构建新的LLM智能体，也没有提出改进智能体规划、记忆或工具使用的新框架。它不属于构建、改进或演化LLM智能体的方法论研究，而是属于对AI研究本身的“元研究”或“评估方法论”范畴。 2.  **正面指标（第二步）**：论文虽然提到了“Reasoning”，但并非关注智能体如何进行自主规划或多步推理的机制，而是关注如何“验证”推理声明的科学性。它不包含Agentic AI、Multi-Agent Systems或Self-Evolving等核心范式。 3.  **排除标准（第三步）**：虽然不属于明确列出的安全或多模态排除项，但其本质是关于研究规范和评估标准的讨论，而非智能体技术的创新。 综上所述，该论文不符合“构建、改进或演化 LLM智能体”这一核心研究目标。"
    },
    {
        "index": "#135",
        "title": "The Vibe-Check Protocol: Quantifying Cognitive Offloading in AI Programming",
        "link": "/arxiv/2601.02410",
        "arxiv_id": "2601.02410",
        "authors": "Aizierjiang Aiersilan",
        "subjects": "Software Engineering, Artificial Intelligence, Computers and Society, Graphics",
        "date": "2026-01-02",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.473967",
        "filter_reason": "这篇论文不符合筛选标准，应予以排除。具体判断过程如下： 1.  **核心判断（第一步）**： *   论文的核心贡献是提出了一个名为 **Vibe-Check Protocol (VCP)** 的基准测试框架，旨在评估软件工程教育中 \"Vibe Coding\"（即学生使用AI智能体编程）的教学效果和对学生认知的影响。 *   这属于将LLM智能体作为工具应用到**教育**这一特定领域的应用研究，而非构建、改进或演化LLM智能体本身的方法论。论文关注的是“人类的学习效果”和“认知卸载”，而不是“智能体的能力”或“智能体的演化”。 2.  **排除标准（第三步及第一步）**： *   **非演化型应用**：论文虽然涉及AI智能体，但重点在于研究人类如何使用这些智能体以及由此产生的教育后果（技能保留、概念理解），这完全符合“非演化型应用”的排除定义。 *   **非Agentic的改进**：论文没有提出任何关于智能体规划、记忆、工具使用或多智能体协作的新机制。它提出的指标（如 $M_{CSR}$, $M_{HT}$, $E_{gap}$）是用来衡量**学生**表现的，而不是用来衡量或提升**智能体**性能的。 3.  **结论**： *   该论文属于教育技术或人机交互（HCI）领域的研究，其本质是评估AI工具在特定场景下的应用价值，而非Agentic AI的技术演进。因此，它不符合“构建、改进或演化 LLM智能体”这一核心研究目标。"
    },
    {
        "index": "#145",
        "title": "Movement Primitives in Robotics: A Comprehensive Survey",
        "link": "/arxiv/2601.02379",
        "arxiv_id": "2601.02379",
        "authors": "Nolan B. Gutierrez, William J. Beksi",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.477065",
        "filter_reason": "这篇论文不符合研究范围，具体判断依据如下： 1.  **核心领域不匹配 (第一步 - 核心判断)**: *   论文的核心主题是“机器人技术”中的“运动基元”，主要关注的是机器人控制轨迹的表示、生成以及通过人类演示进行学习。这属于传统的机器人控制或机器人学习领域，而非基于大语言模型（LLM）的智能体研究。 *   论文并未涉及构建、改进或演化 LLM智能体的方法论或新框架。 2.  **缺乏关键指标 (第二步 - 正面指标)**: *   摘要中完全没有提及 `LLM-based Agents`、`Agentic AI`、`Multi-Agent Systems` 或 `Self-Evolving` 等核心范式。 *   论文讨论的是低级的运动控制和轨迹生成，而非智能体的高级认知能力（如规划、记忆、工具使用）。 3.  **属于特定领域应用 (第一步 - 排除标准)**: *   该论文本质上是对机器人控制领域中特定技术（运动基元）的综述。虽然它提到了“autonomous systems”（自主系统），但在本文语境下指的是物理机器人，而非软件层面的 LLM智能体。这属于将特定技术应用于机器人领域的非演化型应用研究，与“LLM智能体及其演化”这一课题无关。 综上所述，该论文属于机器人控制与规划范畴，不涉及 LLM智能体的构建或演化，因此予以排除。"
    },
    {
        "index": "#148",
        "title": "Distillation-based Scenario-Adaptive Mixture-of-Experts for the Matching Stage of Multi-scenario Recommendation",
        "link": "/arxiv/2601.02368",
        "arxiv_id": "2601.02368",
        "authors": "Ruibing Wang, Shuhan Guo, Haotong Du, Quanming Yao",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-11-28",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.480365",
        "filter_reason": "这篇论文的核心贡献是提出一种名为 DSMOE 的模型架构，用于解决**多场景推荐系统**中匹配阶段的问题。论文主要关注的是通过混合专家模型和知识蒸馏技术来优化推荐算法的检索质量，特别是在长尾场景下的表现。 根据筛选标准进行判断： 1.  **核心判断（第一步）**: 该论文属于典型的**非演化型应用**。它将特定的模型架构应用于推荐系统这一垂直领域，旨在解决该领域的具体问题（如匹配阶段的优化、长尾数据稀疏），而非构建、改进或演化 LLM 智能体。 2.  **正面指标（第二步）**: 论文中未出现任何关于 Agentic AI、Multi-Agent Systems、Self-Evolving、Planning、Tool Use 或 Memory 等核心智能体研究的关键词或概念。 3.  **排除标准（第三步）**: 虽然未涉及安全或多模态排除项，但其本质属于推荐系统的研究，与“LLM智能体及其演化”的研究课题完全无关。 综上所述，该论文不符合研究范围，应予以排除。"
    },
    {
        "index": "#146",
        "title": "LeafTutor: An AI Agent for Programming Assignment Tutoring",
        "link": "/arxiv/2601.02375",
        "arxiv_id": "2601.02375",
        "authors": "Madison Bochard, Tim Conser, Alyssa Duran, Lazaro Martull, Pu Tian, Yalong Wu",
        "subjects": "Computers and Society, Artificial Intelligence, Software Engineering",
        "date": "2025-12-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.479613",
        "filter_reason": "根据筛选标准，这篇论文不符合研究要求，具体判断如下： 1.  **核心判断（第一步）：** 该论文属于 **“非演化型应用”**。论文的核心贡献是构建了一个名为 LeafTutor 的系统，旨在解决 STEM 教育领域（具体为编程作业辅导）的师资短缺问题。虽然它使用了 LLM 智能体技术，但其研究焦点在于“教育应用”和“辅导效果评估”（如与人类导师的对比），而非提出新的智能体架构、规划算法、记忆机制或多智能体协作框架。 2.  **排除依据：** 根据第一步的排除规则，如果论文只是将 LLM（或已有的 Agentic 框架）作为工具应用到特定领域（此处为教育/编程辅导）去解决该领域的问题，应当予以排除。该论文没有展示对 LLM 智能体本身能力的“构建、改进或演化”，而是侧重于应用层的实现和效果验证。 3.  **结论：** 尽管论文涉及 Agentic AI 的应用，但缺乏对智能体底层机制的创新或演化，因此不符合“构建、改进或演化 LLM 智能体”这一核心研究目标。"
    },
    {
        "index": "#127",
        "title": "A Dynamic Retrieval-Augmented Generation System with Selective Memory and Remembrance",
        "link": "/arxiv/2601.02428",
        "arxiv_id": "2601.02428",
        "authors": "Okan Bursa",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2026-01-04",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.470875",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#154",
        "title": "TWIST: Training-free and Label-free Short Text Clustering through Iterative Vector Updating with LLMs",
        "link": "/arxiv/2510.06747",
        "arxiv_id": "2510.06747",
        "authors": "I-Fan Lin, Faegheh Hasibi, Suzan Verberne",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.482353",
        "filter_reason": "这篇论文的核心贡献是提出一种名为 TWIST 的**短文本聚类方法**，旨在解决客户聊天机器人中用户意图聚类的问题。虽然该方法使用了 LLM 进行“迭代向量更新”，但这属于算法层面的优化，而非构建或演化 LLM 智能体。 具体判断依据如下： 1.  **核心判断（第一步）**：该论文属于“非演化型应用”。它将 LLM 作为工具用于特定的 NLP 任务（文本聚类），以改进聚类效果，而不是构建一个具有自主规划、工具使用或记忆能力的智能体架构。 2.  **缺乏 Agentic 特征**：论文中未涉及智能体的核心要素（如 Planning、Tool Use、Memory、ReAct 等），也没有涉及多智能体协作或智能体能力的自我演化机制。 3.  **关于“迭代”的界定**：尽管摘要中提到了“迭代细化”，但这指的是聚类算法中向量表示的优化过程，而非智能体通过经验或反思进行自我完善和迭代的“自我演化”机制。 因此，该论文不符合关于“LLM智能体及其演化”的研究范围。"
    },
    {
        "index": "#150",
        "title": "TextBridgeGNN: Pre-training Graph Neural Network for Cross-Domain Recommendation via Text-Guided Transfer",
        "link": "/arxiv/2601.02366",
        "arxiv_id": "2601.02366",
        "authors": "Yiwen Chen, Yiqing Wu, Huishi Luo, Fuzhen Zhuang, Deqing Wang",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.481074",
        "filter_reason": "这篇论文不符合我的研究范围，具体判断依据如下： 1.  **核心贡献属于特定领域应用（第一步排除标准）**： 论文的核心贡献是提出了 `TextBridgeGNN`，这是一个用于解决**跨域推荐** 问题的图神经网络预训练框架。这属于将模型应用于特定垂直领域（推荐系统）的研究，而非构建通用的LLM智能体架构或演化机制。 2.  **涉及图相关技术（第三步排除标准）**： 论文明确聚焦于 `Graph Neural Network (GNN)`、`interaction graphs`（交互图）以及 `graph-based collaborative filtering`（基于图的协同过滤）。根据筛选标准第三步，涉及知识图谱、图神经网络（GNN）等图相关技术的论文属于明确的排除类别。 3.  **缺乏Agentic核心特性（第一步与第二步）**： 尽管论文中提到了利用预训练语言模型（PLM）来提供语义信息，但PLM在这里仅作为辅助特征提取器或“语义桥梁”，并未作为智能体的核心控制器。论文完全不涉及智能体的规划、工具使用、记忆机制、自我反思或多智能体协作等Agentic AI的核心能力。 4.  **非自我演化机制（第四步）**： 论文讨论的是传统的机器学习范式——预训练和微调，属于迁移学习范畴，而非智能体通过环境反馈或自我反思进行的动态自我完善或迭代演化。 综上所述，该论文是一篇关于推荐系统和图神经网络的论文，与LLM智能体及其演化的研究目标无关。"
    },
    {
        "index": "#153",
        "title": "The Impact of LLM-Generated Reviews on Recommender Systems: Textual Shifts, Performance Effects, and Strategic Platform Control",
        "link": "/arxiv/2601.02362",
        "arxiv_id": "2601.02362",
        "authors": "Itzhak Ziv, Moshe Unger, Hilah Geva",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-11-02",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.482079",
        "filter_reason": "这篇论文不符合我的研究范围，依据如下： 1.  **核心判断（非演化型应用）**： 论文的核心贡献在于研究“LLM生成的评论”对“推荐系统”性能和商业结果的影响。虽然论文使用了LLM来生成合成评论，但LLM在这里仅被作为一个生成文本内容的工具，而非研究的主体。论文的研究焦点是推荐系统的表现、数据质量分析以及平台策略，而非构建、改进或演化LLM智能体本身。 2.  **缺乏Agentic AI核心要素**： 论文摘要中未涉及任何关于智能体规划、工具使用、记忆机制、自我反思、多智能体协作或自我演化等Agentic AI的关键概念。它关注的是数据（文本）层面的变化对下游推荐任务的影响，属于典型的数据挖掘或推荐系统领域的研究。 3.  **符合排除标准**： 根据第一步的排除规则，该论文属于“非演化型应用”，即“将LLM（或一个已有的框架）作为工具应用到特定领域去解决该领域的问题”。这里的特定领域是推荐系统，研究目的是优化推荐效果而非演化智能体。 综上所述，该论文属于推荐系统领域的应用研究，不涉及LLM智能体的构建或演化机制，因此予以排除。"
    },
    {
        "index": "#138",
        "title": "ProSoftArena: Benchmarking Hierarchical Capabilities of Multimodal Agents in Professional Software Environments",
        "link": "/arxiv/2601.02399",
        "arxiv_id": "2601.02399",
        "authors": "Jiaxin Ai, Yukang Feng, Fanrui Zhang, Jianwen Sun, Zizhen Li, Chuanhao Li, Yifan Chang, Wenxiao Wu, Ruoxi Wang, Mingliang Zhai, Kaipeng Zhang",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-30",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.474919",
        "filter_reason": "API调用错误: Connection error."
    },
    {
        "index": "#152",
        "title": "Towards Trustworthy LLM-Based Recommendation via Rationale Integration",
        "link": "/arxiv/2601.02364",
        "arxiv_id": "2601.02364",
        "authors": "Chung Park, Taesan Kim, Hyeongjun Yun, Dongjoon Hong, Junui Hong, Kijung Park, MinCheol Cho, Mira Myong, Jihoon Oh, Min sung Choi",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-11-07",
        "category": "cs.AI",
        "crawl_time": "2026-01-08T11:00:05.481780",
        "filter_reason": "这篇论文不符合筛选标准，主要基于以下判断： 1.  **核心贡献属于非演化型应用**：论文的核心是构建一个基于LLM的推荐系统（LLM-Rec），旨在解决推荐系统领域的特定问题（准确性和信任感）。根据第一步的排除规则，这属于将LLM作为工具应用到特定领域（推荐系统）的应用型研究，而非构建通用的LLM智能体架构或演化机制。 2.  **触犯排除标准（可解释性）**：论文明确指出其目标是增强系统的“Interpretability”（可解释性）和“Trustworthiness”（可信度），并通过生成“rationales”（理由）来实现这一点。根据第三步的排除标准，只要论文的主要贡献是关于 `Interpretability` (可解释性) 或 `Explainability` (XAI)，一律排除。 3.  **缺乏Agentic核心特征**：虽然论文提到了“Chain-of-Thought (CoT) style”，但这里CoT仅被用作生成解释文本的格式，以辅助推荐任务，而非用于智能体的自主规划、工具调用或环境交互。论文未涉及智能体的记忆、自我反思、多智能体协作或自我演化等核心Agentic能力。 综上所述，该论文属于推荐系统领域的可解释性应用研究，不属于LLM智能体及其演化的研究范畴。"
    }
]