[
    {
        "index": "#6",
        "title": "A Multi-agent Text2SQL Framework using Small Language Models and Execution Feedback",
        "link": "/arxiv/2512.18622",
        "arxiv_id": "2512.18622",
        "authors": "Thanh Dat Hoang, Thanh Trung Huynh, Matthias Weidlich, Thanh Tam Nguyen, Tong Chen, Hongzhi Yin, Quoc Viet Hung Nguyen",
        "summary": "Text2SQL, the task of generating SQL queries from natural language text, is a critical challenge in data engineering. Recently, Large Language Models (LLMs) have demonstrated superior performance for this task due to their advanced comprehension and generation capabilities. However, privacy and cost considerations prevent companies from using Text2SQL solutions based on external LLMs offered as a service. Rather, small LLMs (SLMs) that are openly available and can hosted in-house are adopted. These SLMs, in turn, lack the generalization capabilities of larger LLMs, which impairs their effectiveness for complex tasks such as Text2SQL. To address these limitations, we propose MATS, a novel Text2SQL framework designed specifically for SLMs. MATS uses a multi-agent mechanism that assigns specialized roles to auxiliary agents, reducing individual workloads and fostering interaction. A training scheme based on reinforcement learning aligns these agents using feedback obtained during execution, thereby maintaining competitive performance despite a limited LLM size. Evaluation results using on benchmark datasets show that MATS, deployed on a single- GPU server, yields accuracy that are on-par with large-scale LLMs when using significantly fewer parameters. Our source code and data are available at https://github.com/thanhdath/mats-sql.",
        "subjects": "Databases, Artificial Intelligence, Computation and Language, Human-Computer Interaction, Multiagent Systems",
        "date": "2025-12-21",
        "category": "cs.MA",
        "crawl_time": "2025-12-24T11:00:05.298011",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心贡献符合 \"Multi-Agent\" 方向**：论文的核心是提出了一种名为 MATS 的新型框架，明确使用了 \"Multi-agent mechanism\"（多智能体机制）。该机制通过为辅助智能体分配专门角色来减少工作量并促进交互，这直接对应了研究焦点中的“多智能体”及其子方向（协作、通信）。 2.  **包含 \"Self-Evolving\" 机制**：论文提出了一种基于强化学习的训练方案，利用 \"execution feedback\"（执行反馈）来对齐智能体。这符合筛选标准中的“自我演化”定义，即“智能体通过经验、反思或环境反馈进行自我完善和迭代”。这种通过反馈循环来改进智能体性能的方法是 Agentic AI 的关键特征。 3.  **属于构建新框架而非单纯应用**：虽然论文的应用场景是 Text2SQL（数据工程领域），但论文的本质并非简单地将现有智能体作为工具应用，而是为了解决小语言模型（SLM）的局限性，专门构建了一个新的多智能体框架和训练机制。根据筛选标准第四步（处理特殊和模糊情况），只要核心是提出新的机制（如自我演化或多智能体协作），即使应用在特定领域，也应保留。 综上所述，该论文在多智能体协作和基于反馈的自我改进方面做出了实质性贡献，符合 \"LLM智能体及其演化\" 的研究范围。"
    },
    {
        "index": "#4",
        "title": "MemEvolve: Meta-Evolution of Agent Memory Systems",
        "link": "/arxiv/2512.18746",
        "arxiv_id": "2512.18746",
        "authors": "Guibin Zhang, Haotian Ren, Chong Zhan, Zhenhong Zhou, Junhao Wang, He Zhu, Wangchunshu Zhou, Shuicheng Yan",
        "summary": "Self-evolving memory systems are unprecedentedly reshaping the evolutionary paradigm of large language model (LLM)-based agents. Prior work has predominantly relied on manually engineered memory architectures to store trajectories, distill experience, and synthesize reusable tools, enabling agents to evolve on the fly within environment interactions. However, this paradigm is fundamentally constrained by the staticity of the memory system itself: while memory facilitates agent-level evolving, the underlying memory architecture cannot be meta-adapted to diverse task contexts. To address this gap, we propose MemEvolve, a meta-evolutionary framework that jointly evolves agents' experiential knowledge and their memory architecture, allowing agent systems not only to accumulate experience but also to progressively refine how they learn from it. To ground MemEvolve in prior research and foster openness in future self-evolving systems, we introduce EvolveLab, a unified self-evolving memory codebase that distills twelve representative memory systems into a modular design space (encode, store, retrieve, manage), providing both a standardized implementation substrate and a fair experimental arena. Extensive evaluations on four challenging agentic benchmarks demonstrate that MemEvolve achieves (I) substantial performance gains, improving frameworks such as SmolAgent and Flash-Searcher by up to $17.06\\%$; and (II) strong cross-task and cross-LLM generalization, designing memory architectures that transfer effectively across diverse benchmarks and backbone models.",
        "subjects": "Computation and Language, Multiagent Systems",
        "date": "2025-12-21",
        "category": "cs.MA",
        "crawl_time": "2025-12-24T11:00:05.296950",
        "filter_reason": "这篇论文完全符合筛选标准，属于核心保留的论文。具体判断依据如下： 1.  **核心贡献精准匹配 (第一步 & 第二步)**： *   论文的核心贡献是提出了 **MemEvolve**，这是一个“元演化框架”，旨在联合演化智能体的经验知识和**记忆架构**。 *   这直接对应了研究课题中的 **“自我演化”** 方向。论文不仅关注智能体如何利用记忆进行演化，更进一步提出了让记忆架构本身进行“元适应”和“演化”的机制。 *   论文涉及的核心能力是 **Memory (记忆)**，这是 Agentic AI 的关键组件之一。 2.  **符合研究焦点**： *   论文明确指出其研究对象是 **\"LLM-based agents\"**，旨在解决现有智能体记忆架构静态化的问题。 *   它不是将智能体作为工具应用到某个垂直领域（如医疗、金融），而是专注于改进智能体本身的底层架构和演化机制，因此不属于“非演化型应用”。 3.  **无排除项触发 (第三步)**： *   论文不涉及安全、对齐、多模态视觉或图神经网络等排除领域。 *   虽然论文提到了 \"EvolveLab\" 代码库，但这是为了支持其提出的演化算法和框架，属于方法论的一部分，而非单纯的基础设施研究。 综上所述，该论文在“自我演化”和“智能体记忆机制”方面提出了创新性的框架，高度契合“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#1",
        "title": "GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators",
        "link": "/arxiv/2512.19682",
        "arxiv_id": "2512.19682",
        "authors": "Jiacheng Guo, Ling Yang, Peter Chen, Qixin Xiao, Yinjie Wang, Xinzhe Juan, Jiahao Qiu, Ke Shen, Mengdi Wang",
        "summary": "Training capable Large Language Model (LLM) agents is critically bottlenecked by the high cost and static nature of real-world interaction data. We address this by introducing GenEnv, a framework that establishes a difficulty-aligned co-evolutionary game between an agent and a scalable, generative environment simulator. Unlike traditional methods that evolve models on static datasets, GenEnv instantiates a dataevolving: the simulator acts as a dynamic curriculum policy, continuously generating tasks specifically tailored to the agent's ``zone of proximal development''. This process is guided by a simple but effective $α$-Curriculum Reward, which aligns task difficulty with the agent's current capabilities. We evaluate GenEnv on five benchmarks, including API-Bank, ALFWorld, BFCL, Bamboogle, and TravelPlanner. Across these tasks, GenEnv improves agent performance by up to \\textbf{+40.3\\%} over 7B baselines and matches or exceeds the average performance of larger models. Compared to Gemini 2.5 Pro-based offline data augmentation, GenEnv achieves better performance while using 3.3$\\times$ less data. By shifting from static supervision to adaptive simulation, GenEnv provides a data-efficient pathway for scaling agent capabilities.",
        "subjects": "Computation and Language",
        "date": "2025-12-22",
        "category": "cs.CL",
        "crawl_time": "2025-12-24T11:00:05.270480",
        "filter_reason": "这篇论文完全符合筛选标准，应予以保留。具体判断依据如下： 1.  **核心判断（符合）**： 论文的核心贡献是提出了 **GenEnv** 这一新框架，旨在解决训练LLM智能体时数据成本高且静态的问题。其本质是构建一种**智能体与环境模拟器之间的协同演化机制**，这直接属于“构建、改进或演化 LLM智能体”的方法论研究，而非将现有智能体简单应用到特定领域。 2.  **正面指标（高度匹配）**： *   **核心范式**：论文明确涉及 `LLM-based Agents` 和 `Self-Evolving`（特别是 `Co-Evolution` 协同演化）。 *   **演化机制**：GenEnv 建立了一个动态的课程策略，通过 `Co-Evolutionary Game`（协同演化博弈）让环境根据智能体的能力生成任务，这完全符合“自我演化”和“迭代改进”的研究焦点。 *   **智能体能力**：虽然侧重于训练数据生成，但其目的是提升智能体在 `ALFWorld`、`API-Bank` 等需要 `Planning`（规划）和 `Tool Use`（工具使用）的基准测试上的表现。 3.  **排除标准（无冲突）**： 论文不涉及安全对齐、多模态视觉核心研究或图神经网络，因此不触犯任何排除规则。 4.  **特殊与模糊情况（符合）**： 论文提出的“协同演化”机制属于典型的自我演化范畴。尽管它在多个基准（如TravelPlanner）上进行了评估，但这些仅用于验证智能体能力的提升，论文的核心在于提出了一种新的**演化训练框架**，而非单纯的应用。 综上所述，该论文通过提出智能体与环境的协同演化框架来提升智能体能力，精准契合“LLM智能体及其演化”这一研究课题。"
    },
    {
        "index": "#89",
        "title": "Toward Training Superintelligent Software Agents through Self-Play SWE-RL",
        "link": "/arxiv/2512.18552",
        "arxiv_id": "2512.18552",
        "authors": "Yuxiang Wei, Zhiqing Sun, Emily McMilin, Jonas Gehring, David Zhang, Gabriel Synnaeve, Daniel Fried, Lingming Zhang, Sida Wang",
        "summary": "While current software agents powered by large language models (LLMs) and agentic reinforcement learning (RL) can boost programmer productivity, their training data (e.g., GitHub issues and pull requests) and environments (e.g., pass-to-pass and fail-to-pass tests) heavily depend on human knowledge or curation, posing a fundamental barrier to superintelligence. In this paper, we present Self-play SWE-RL (SSR), a first step toward training paradigms for superintelligent software agents. Our approach takes minimal data assumptions, only requiring access to sandboxed repositories with source code and installed dependencies, with no need for human-labeled issues or tests. Grounded in these real-world codebases, a single LLM agent is trained via reinforcement learning in a self-play setting to iteratively inject and repair software bugs of increasing complexity, with each bug formally specified by a test patch rather than a natural language issue description. On the SWE-bench Verified and SWE-Bench Pro benchmarks, SSR achieves notable self-improvement (+10.4 and +7.8 points, respectively) and consistently outperforms the human-data baseline over the entire training trajectory, despite being evaluated on natural language issues absent from self-play. Our results, albeit early, suggest a path where agents autonomously gather extensive learning experiences from real-world software repositories, ultimately enabling superintelligent systems that exceed human capabilities in understanding how systems are constructed, solving novel challenges, and autonomously creating new software from scratch.",
        "subjects": "Software Engineering, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-12-21",
        "category": "cs.CL",
        "crawl_time": "2025-12-24T11:00:05.405607",
        "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心贡献符合“自我演化”与“Agentic AI”方向**： 论文提出了“Self-play SWE-RL (SSR)”这一新框架，其核心在于通过**自我对弈**和**强化学习**来训练软件智能体。这直接对应了研究课题中的“自我演化”方向，特别是智能体通过环境反馈（测试补丁）进行自我完善和迭代改进的能力。 2.  **符合“自我演化的应用”例外规则**： 虽然论文的应用场景是软件工程，但根据筛选标准第四步，只要论文的核心贡献是提出一种新的“自我演化”机制，即使应用在特定领域也应保留。本文的核心不在于单纯解决某个具体的编程问题，而在于提出了一种让智能体**自主收集经验**、**自我注入并修复Bug**的训练范式，这属于智能体演化机制的创新。 3.  **具备明确的Agentic特征**： 论文明确研究对象是“Software Agents”，并使用了“Agentic reinforcement learning”方法。智能体在沙盒环境中进行多步交互（注入Bug、修复Bug），体现了智能体的自主性和工具使用能力。 综上所述，该论文不仅涉及LLM智能体的构建，更重点解决了智能体如何通过自我对弈实现能力演化和自我提升，高度契合“LLM智能体及其演化”的研究目标。"
    },
    {
        "index": "#64",
        "title": "Learning Hierarchical Procedural Memory for LLM Agents through Bayesian Selection and Contrastive Refinement",
        "link": "/arxiv/2512.18950",
        "arxiv_id": "2512.18950",
        "authors": "Saman Forouzandeh, Wei Peng, Parham Moradi, Xinghuo Yu, Mahdi Jalili",
        "summary": "We present MACLA, a framework that decouples reasoning from learning by maintaining a frozen large language model while performing all adaptation in an external hierarchical procedural memory. MACLA extracts reusable procedures from trajectories, tracks reliability via Bayesian posteriors, selects actions through expected-utility scoring, and refines procedures by contrasting successes and failures. Across four benchmarks (ALFWorld, WebShop, TravelPlanner, InterCodeSQL), MACLA achieves 78.1 percent average performance, outperforming all baselines. On ALFWorld unseen tasks, MACLA reaches 90.3 percent with 3.1 percent positive generalization. The system constructs memory in 56 seconds, 2800 times faster than the state-of-the-art LLM parameter-training baseline, compressing 2851 trajectories into 187 procedures. Experimental results demonstrate that structured external memory with Bayesian selection and contrastive refinement enables sample-efficient, interpretable, and continually improving agents without LLM parameter updates.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-22",
        "category": "cs.LG",
        "crawl_time": "2025-12-24T11:00:06.362795",
        "filter_reason": "这篇论文完全符合筛选标准，属于核心研究范围内的“单智能体”与“自我演化”方向的交叉研究。 1.  **核心判断**: *   论文提出了 **MACLA** 框架，其核心贡献在于构建了一种新的 **LLM智能体** 架构。该架构通过解耦推理与学习，利用外部分层程序记忆来增强智能体的能力。 *   这不是简单的应用型论文，而是提出了关于智能体如何存储记忆、如何从经验中学习以及如何自我完善的方法论。 2.  **符合核心关注点**: *   **单智能体**: 论文专注于提升单个智能体的能力，特别是 **Memory (记忆)** 机制的构建。它提出了“分层程序记忆”，这是智能体研究中的关键组件。 *   **自我演化**: 论文明确提到了“continually improving agents”（持续改进的智能体）。其核心机制包括从轨迹中提取可复用程序、通过 **Contrastive Refinement (对比精炼)** 来修正程序，以及利用贝叶斯选择跟踪可靠性。这完全符合“自我演化”中定义的“通过经验、反思或环境反馈进行自我完善和迭代”的标准。 *   **正面指标匹配**: 涉及 `Memory`, `Self-Correction` (通过对比精炼实现), `Iterative Improvement`。 3.  **排除标准检查**: *   论文不涉及安全对齐、多模态视觉核心研究或图技术。 *   虽然在 ALFWorld 等基准上测试，但这些是通用的智能体决策基准，而非生物、医疗等特定垂直领域的非演化型应用。 综上所述，该论文致力于解决LLM智能体的记忆构建和自我迭代学习问题，属于构建和演化LLM智能体的前沿研究，应予以保留。"
    },
    {
        "index": "#53",
        "title": "Sophia: A Persistent Agent Framework of Artificial Life",
        "link": "/arxiv/2512.18202",
        "arxiv_id": "2512.18202",
        "authors": "Mingyang Sun, Feng Hong, Weinan Zhang",
        "summary": "The development of LLMs has elevated AI agents from task-specific tools to long-lived, decision-making entities. Yet, most architectures remain static and reactive, tethered to manually defined, narrow scenarios. These systems excel at perception (System 1) and deliberation (System 2) but lack a persistent meta-layer to maintain identity, verify reasoning, and align short-term actions with long-term survival. We first propose a third stratum, System 3, that presides over the agent's narrative identity and long-horizon adaptation. The framework maps selected psychological constructs to concrete computational modules, thereby translating abstract notions of artificial life into implementable design requirements. The ideas coalesce in Sophia, a \"Persistent Agent\" wrapper that grafts a continuous self-improvement loop onto any LLM-centric System 1/2 stack. Sophia is driven by four synergistic mechanisms: process-supervised thought search, narrative memory, user and self modeling, and a hybrid reward system. Together, they transform repetitive reasoning into a self-driven, autobiographical process, enabling identity continuity and transparent behavioral explanations. Although the paper is primarily conceptual, we provide a compact engineering prototype to anchor the discussion. Quantitatively, Sophia independently initiates and executes various intrinsic tasks while achieving an 80% reduction in reasoning steps for recurring operations. Notably, meta-cognitive persistence yielded a 40% gain in success for high-complexity tasks, effectively bridging the performance gap between simple and sophisticated goals. Qualitatively, System 3 exhibited a coherent narrative identity and an innate capacity for task organization. By fusing psychological insight with a lightweight reinforcement-learning core, the persistent agent architecture advances a possible practical pathway toward artificial life.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-20",
        "category": "cs.AI",
        "crawl_time": "2025-12-24T11:00:06.512934",
        "filter_reason": "这篇论文完全符合筛选标准，属于核心研究范围内的“单智能体”与“自我演化”方向的交叉研究。 1.  **核心判断（第一步）：** 论文的核心贡献是构建了一个名为 Sophia 的“持久智能体框架”，并提出了“System 3”这一新的架构层级。这属于构建和改进 LLM 智能体的方法论，而非将现有智能体简单应用于特定领域（如医疗、金融），因此符合保留条件。 2.  **正面指标匹配（第二步）：** *   **Agentic AI / 单智能体：** 论文详细探讨了智能体的规划、记忆（Narrative Memory）、自我建模以及长期适应性，这些都是单智能体研究的核心能力。 *   **自我演化：** 摘要中明确提到该框架包含“continuous self-improvement loop”（连续自我改进循环）和“long-horizon adaptation”（长期适应性），这直接对应了研究焦点中的“自我演化”机制。 *   **核心范式：** 论文涉及 `Self-Reflection`（通过 System 3 验证推理）、`Memory` 和 `Iterative Improvement`。 3.  **排除标准检查（第三步）：** 论文不涉及安全对齐、多模态视觉核心研究或图神经网络，因此未被排除。 4.  **特殊处理（第四步）：** 论文虽然涉及推理，但其重点在于通过智能体架构（System 3）来实现持久性和自我驱动的推理过程，而非单纯优化 LLM 的基础 Token 预测能力或数学逻辑，因此属于 Agentic 的推理范畴，应予保留。 综上所述，该论文提出了一个新的智能体框架来解决智能体的身份持久性和自我完善问题，高度契合“LLM智能体及其演化”的研究课题。"
    },
    {
        "index": "#57",
        "title": "Propose, Solve, Verify: Self-Play Through Formal Verification",
        "link": "/arxiv/2512.18160",
        "arxiv_id": "2512.18160",
        "authors": "Alex Wilf, Pranjal Aggarwal, Bryan Parno, Daniel Fried, Louis-Philippe Morency, Paul Pu Liang, Sean Welleck",
        "summary": "Training models through self-play alone (without any human data) has been a longstanding goal in AI, but its effectiveness for training large language models remains unclear, particularly in code generation where rewards based on unit tests are brittle and prone to error propagation. We study self-play in the verified code generation setting, where formal verification provides reliable correctness signals. We introduce Propose, Solve, Verify (PSV) a simple self-play framework where formal verification signals are used to create a proposer capable of generating challenging synthetic problems and a solver trained via expert iteration. We use PSV to train PSV-Verus, which across three benchmarks improves pass@1 by up to 9.6x over inference-only and expert-iteration baselines. We show that performance scales with the number of generated questions and training iterations, and through ablations identify formal verification and difficulty-aware proposal as essential ingredients for successful self-play.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-20",
        "category": "cs.AI",
        "crawl_time": "2025-12-24T11:00:06.514848",
        "filter_reason": "这篇论文完全符合筛选标准，属于“自我演化”和“多智能体”的核心研究范畴。 1.  **核心贡献判断 (第一步)**: 论文的核心贡献是提出了 \"Propose, Solve, Verify\" (PSV) 框架。这是一个基于自我博弈的训练框架，旨在通过形式验证信号来训练模型。这不仅仅是将LLM作为工具应用，而是提出了一种新的**训练和演化方法论**。 2.  **符合核心关注点 (第二步)**: *   **自我演化**: 论文明确使用了 \"Self-Play\"（自我博弈）、\"Expert Iteration\"（专家迭代）和 \"Generational Evolution\"（隐含在迭代训练中）的概念。模型通过生成问题、解决问题和验证结果的循环，实现了性能的自我提升和迭代。 *   **多智能体**: 框架中包含两个核心角色——\"Proposer\"（提议者，负责生成合成问题）和 \"Solver\"（求解器，负责解决问题）。这两个角色通过交互和对抗/协作（生成难题 vs 解决难题）共同进化，符合多智能体系统的定义。 3.  **特殊与模糊情况处理 (第四步)**: 虽然论文的应用场景是代码生成，但其核心在于提出了一种新的“自我演化”机制（Self-Play through Formal Verification）。根据筛选标准第四步中的“自我演化的应用”规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”。因此，尽管涉及代码领域，由于其核心贡献在于演化框架本身，应当保留。 综上所述，该论文聚焦于通过自我博弈和专家迭代机制实现LLM的自我演化，符合“LLM智能体及其演化”的研究课题。"
    }
]