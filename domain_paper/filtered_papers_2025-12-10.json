[
    {
        "index": "#2",
        "title": "GAIR: GUI Automation via Information-Joint Reasoning and Group Reflection",
        "link": "/arxiv/2512.09396",
        "arxiv_id": "2512.09396",
        "authors": "Zishu Wei, Qixiang Ma, Xavier Hu, Yuhang Liu, Hui Zang, Yudong Zhao, Tao Wang, Shengyu Zhang, Fei Wu",
        "summary": "Building AI systems for GUI automation task has attracted remarkable research efforts, where MLLMs are leveraged for processing user requirements and give operations. However, GUI automation includes a wide range of tasks, from document processing to online shopping, from CAD to video editing. Diversity between particular tasks requires MLLMs for GUI automation to have heterogeneous capabilities and master multidimensional expertise, raising problems on constructing such a model. To address such challenge, we propose GAIR: GUI Automation via Information-Joint Reasoning and Group Reflection, a novel MLLM-based GUI automation agent framework designed for integrating knowledge and combining capabilities from heterogeneous models to build GUI automation agent systems with higher performance. Since different GUI-specific MLLMs are trained on different dataset and thus have different strengths, GAIR introduced a general-purpose MLLM for jointly processing the information from multiple GUI-specific models, further enhancing performance of the agent framework. The general-purpose MLLM also serves as decision maker, trying to execute a reasonable operation based on previously gathered information. When the general-purpose model thinks that there isn't sufficient information for a reasonable decision, GAIR would transit into group reflection status, where the general-purpose model would provide GUI-specific models with different instructions and hints based on their strengths and weaknesses, driving them to gather information with more significance and accuracy that can support deeper reasoning and decision. We evaluated the effectiveness and reliability of GAIR through extensive experiments on GUI benchmarks.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.MA",
        "crawl_time": "2025-12-11T11:00:05.068560",
        "filter_reason": "这篇论文完全符合您的研究范围，应当保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质是提出一个名为GAIR的**新颖的LLM智能体框架**。它的核心贡献并非简单地将现有智能体应用于GUI自动化领域，而是**构建了一个具有独特架构和反思机制的智能体系统**来解决该领域的挑战。因此，它不属于“非演化型应用”的排除范畴，其核心是关于“构建、改进LLM智能体”的方法论。 **第二步：正面指标——高度匹配** 论文包含了多个您关注的核心正面指标： 1.  **核心范式**: 论文明确提出了一个 `LLM-based Agent` 框架。 2.  **智能体能力**: 论文的核心机制 `Information-Joint Reasoning` 涉及 `Planning` 和 `Reasoning`。更关键的是，它提出了 `Group Reflection` 机制，这直接对应了 `Self-Reflection` 和 `Self-Correction`。 3.  **多智能体**: GAIR的架构包含一个通用模型和多个GUI专用模型，由通用模型进行协调和决策，这体现了多智能体系统中协作与分工的思想。 4.  **演化机制**: `Group Reflection` 是一种明确的**自我演化**机制。当智能体（通用模型）判断信息不足时，它会进入反思状态，通过指导其他模型来获取更高质量的信息，从而迭代优化自身的决策能力。这完全符合“通过经验、反思进行自我完善和迭代”的定义。 **第三步：排除标准——未触发** 1.  **安全与对齐**: 论文未涉及安全、对齐、可解释性等主题。 2.  **多模态与视觉**: 虽然论文使用了MLLMs来处理GUI（视觉信息），但它们是作为智能体**感知环境的工具**。研究的核心是GAIR这个框架本身，而不是MLLMs的视觉能力。这符合您设定的“除非它们被用作智能体感知环境的工具，而不是研究的核心”的例外情况。 **第四步：处理特殊和模糊情况——符合保留规则** 1.  **推理/规划**: 论文的推理是嵌入在智能体框架中的多步决策过程，属于智能体的规划能力，而非提升LLM本身的基础推理能力。 2.  **自我演化的应用**: 这是本论文最关键的亮点。它完美地符合了“自我演化的应用”的保留规则。论文的核心贡献正是提出了一种**新的“自我演化”机制**，即使它被应用在GUI自动化这个特定领域，也应该被保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是构建了一个名为GAIR的LLM智能体框架，其创新点在于引入了“Group Reflection”这一**自我反思与演化机制**，使智能体能够迭代优化其信息收集和决策过程。该研究直接命中了您“单智能体”和“自我演化”两个核心方向，并且其多模型协作的架构也与“多智能体”思想相关。因此，这篇论文是您研究课题“LLM智能体及其演化”的典型前沿范例，应予以保留。"
    },
    {
        "index": "#3",
        "title": "WOLF: Werewolf-based Observations for LLM Deception and Falsehoods",
        "link": "/arxiv/2512.09187",
        "arxiv_id": "2512.09187",
        "authors": "Mrinal Agarwal, Saad Rana, Theo Sundoro, Hermela Berhe, Spencer Kim, Vasu Sharma, Sean O'Brien, Kevin Zhu",
        "summary": "Deception is a fundamental challenge for multi-agent reasoning: effective systems must strategically conceal information while detecting misleading behavior in others. Yet most evaluations reduce deception to static classification, ignoring the interactive, adversarial, and longitudinal nature of real deceptive dynamics. Large language models (LLMs) can deceive convincingly but remain weak at detecting deception in peers. We present WOLF, a multi-agent social deduction benchmark based on Werewolf that enables separable measurement of deception production and detection. WOLF embeds role-grounded agents (Villager, Werewolf, Seer, Doctor) in a programmable LangGraph state machine with strict night-day cycles, debate turns, and majority voting. Every statement is a distinct analysis unit, with self-assessed honesty from speakers and peer-rated deceptiveness from others. Deception is categorized via a standardized taxonomy (omission, distortion, fabrication, misdirection), while suspicion scores are longitudinally smoothed to capture both immediate judgments and evolving trust dynamics. Structured logs preserve prompts, outputs, and state transitions for full reproducibility. Across 7,320 statements and 100 runs, Werewolves produce deceptive statements in 31% of turns, while peer detection achieves 71-73% precision with ~52% overall accuracy. Precision is higher for identifying Werewolves, though false positives occur against Villagers. Suspicion toward Werewolves rises from ~52% to over 60% across rounds, while suspicion toward Villagers and the Doctor stabilizes near 44-46%. This divergence shows that extended interaction improves recall against liars without compounding errors against truthful roles. WOLF moves deception evaluation beyond static datasets, offering a dynamic, controlled testbed for measuring deceptive and detective capacity in adversarial multi-agent interaction.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.MA",
        "crawl_time": "2025-12-11T11:00:05.068857",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步核心判断 (保留):** 论文的核心贡献是构建了一个名为 **WOLF** 的 **多智能体社交演绎基准**。它不是一个简单的应用，而是提出了一个全新的、结构化的 **多智能体系统框架**。摘要中明确提到，WOLF是一个“programmable LangGraph state machine”，用于研究“adversarial multi-agent interaction”。这完全符合“构建、改进LLM智能体”或“构建多智能体系统”的核心要求。 2.  **第二步正面指标 (高度匹配):** 论文包含了大量你的核心关注点： *   **核心范式:** 论文的核心是 `Multi-Agent Systems (MAS)`，研究的是LLM智能体之间的交互。 *   **多智能体:** 论文深入探讨了智能体间的 `Communication` (辩论回合)、`Collaboration` (村民合作) 与 `Negotiation`/博弈 (狼人欺骗)。它还研究了 `Social Learning` 和 `Agent Society` 的动态，即“演化的信任动态”。 *   **智能体能力:** 智能体需要进行复杂的 `Planning` (如何欺骗、如何投票)、利用 `Memory` (记住历史言论和投票来建立怀疑度)、以及 `Self-Reflection` (自我评估言论的诚实度)。 3.  **第三步排除标准 (未触发):** *   论文虽然研究“欺骗”，但其主要贡献并非 `Safety` 或 `Alignment`。它的目标是**衡量和评估**智能体在对抗环境下的欺骗与反欺骗能力，这是一个关于**智能体能力边界**的研究，而不是如何让智能体更安全或更对齐。因此，它不属于安全与对齐的排除范畴。 *   论文不涉及多模态或视觉内容。 4.  **第四步特殊/模糊情况 (不适用):** 论文的核心就是多智能体框架本身，不涉及推理/规划或自我演化应用的模糊地带。 **总结:** 这篇论文的核心贡献是**构建了一个用于研究LLM智能体在复杂、对抗性社交环境中进行欺骗和推理的多智能体基准和框架**。它直接命中了你研究焦点中的“多智能体”方向，并深入探讨了智能体间的通信、博弈、记忆和规划等关键能力。因此，这是一篇与你研究课题高度相关的前沿论文，应该被保留。"
    },
    {
        "index": "#7",
        "title": "MOA: Multi-Objective Alignment for Role-Playing Agents",
        "link": "/arxiv/2512.09756",
        "arxiv_id": "2512.09756",
        "authors": "Chonghua Liao, Ke Wang, Yuchuan Wu, Fei Huang, Yongbin Li",
        "summary": "Role-playing agents (RPAs) must simultaneously master many conflicting skills -- following multi-turn instructions, exhibiting domain knowledge, and adopting a consistent linguistic style. Existing work either relies on supervised fine-tuning (SFT) that over-fits surface cues and yields low diversity, or applies reinforcement learning (RL) that fails to learn multiple dimensions for comprehensive RPA optimization. We present MOA (Multi-Objective Alignment), a reinforcement-learning framework that enables multi-dimensional, fine-grained rubric optimization for general RPAs. MOA introduces a novel multi-objective optimization strategy that trains simultaneously on multiple fine-grained rubrics to boost optimization performance. Besides, to address the issues of model output diversity and quality, we have also employed thought-augmented rollout with off-policy guidance. Extensive experiments on challenging benchmarks such as PersonaGym and RoleMRC show that MOA enables an 8B model to match or even outperform strong baselines such as GPT-4o and Claude across numerous dimensions. This demonstrates the great potential of MOA in building RPAs that can simultaneously meet the demands of role knowledge, persona style, diverse scenarios, and complex multi-turn conversations.",
        "subjects": "Computation and Language",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-11T11:00:05.203159",
        "filter_reason": "这篇论文符合您的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一个名为MOA（Multi-Objective Alignment）的**强化学习框架**，其目标是**构建和改进**一种特定的LLM智能体——角色扮演智能体。它不是将现有智能体作为工具应用到某个领域，而是专注于如何让智能体本身变得更强大、更全面。因此，它通过了第一步的核心判断。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文明确研究 `LLM-based Agents` (Role-Playing Agents)。 - **智能体能力**: 论文旨在提升智能体的多项核心能力，包括遵循多轮指令（涉及`Planning`）、展现领域知识、保持一致的语言风格。这些是衡量一个智能体是否优秀的关键指标。 - **演化机制**: 论文使用强化学习（RL）框架来优化智能体，这本质上是一种通过反馈进行迭代和`Self-Improvement`（自我完善）的机制。其目标是让智能体在多个维度上持续优化，这与“自我演化”的方向高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 这是本论文最需要仔细辨析的一点。虽然标题和摘要中多次出现 \"Alignment\"（对齐），但这里的对齐**不是**指您筛选标准中需要排除的 `Safety`、`Security` 或 `Ethical Alignment`（安全、伦理对齐）。这里的 \"Multi-Objective Alignment\" 指的是将智能体的行为与**多个细粒度的任务目标（rubrics）**进行对齐，例如“角色知识”、“人格风格”、“多轮对话能力”等。这是一种**功能性对齐**或**任务对齐**，其目的是提升智能体的综合性能，而非解决安全问题。因此，它**不触发**排除标准。 - **多模态与视觉**: 论文完全聚焦于文本对话和语言风格，不涉及视觉或多模态内容，因此不触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文关注的是智能体在复杂多轮对话场景下的综合表现，这属于智能体层面的规划和推理能力，而非LLM基础的数学或逻辑推理。因此，符合保留条件。 - **自我演化的应用**: 论文的核心就是提出一种新的优化框架（可以视为一种演化机制），因此完全符合保留条件。 5.  **第五步：最终决策** - **核心贡献**: 论文的核心贡献是构建了一个新的框架（MOA），用于**改进和演化**LLM智能体（特别是角色扮演智能体），使其能够同时掌握多种复杂技能。 - **与研究目标的契合度**: 该研究直接对应您的核心目标“构建、改进或演化LLM智能体”。它属于**单智能体**研究范畴，因为它专注于提升单个智能体的能力；同时，其通过强化学习进行迭代优化的方法，也触及了**自我演化**的核心理念。 综上所述，尽管标题中的\"Alignment\"一词可能引起误解，但论文的实质内容是关于如何通过一种新颖的多目标优化框架来**提升LLM智能体的综合能力**，这与您的研究课题高度相关。因此，最终判断为保留。"
    },
    {
        "index": "#18",
        "title": "RouteRAG: Efficient Retrieval-Augmented Generation from Text and Graph via Reinforcement Learning",
        "link": "/arxiv/2512.09487",
        "arxiv_id": "2512.09487",
        "authors": "Yucan Guo, Miao Su, Saiping Guan, Zihao Sun, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",
        "summary": "Retrieval-Augmented Generation (RAG) integrates non-parametric knowledge into Large Language Models (LLMs), typically from unstructured texts and structured graphs. While recent progress has advanced text-based RAG to multi-turn reasoning through Reinforcement Learning (RL), extending these advances to hybrid retrieval introduces additional challenges. Existing graph-based or hybrid systems typically depend on fixed or handcrafted retrieval pipelines, lacking the ability to integrate supplementary evidence as reasoning unfolds. Besides, while graph evidence provides relational structures crucial for multi-hop reasoning, it is substantially more expensive to retrieve. To address these limitations, we introduce \\model{}, an RL-based framework that enables LLMs to perform multi-turn and adaptive graph-text hybrid RAG. \\model{} jointly optimizes the entire generation process via RL, allowing the model to learn when to reason, what to retrieve from either texts or graphs, and when to produce final answers, all within a unified generation policy. To guide this learning process, we design a two-stage training framework that accounts for both task outcome and retrieval efficiency, enabling the model to exploit hybrid evidence while avoiding unnecessary retrieval overhead. Experimental results across five question answering benchmarks demonstrate that \\model{} significantly outperforms existing RAG baselines, highlighting the benefits of end-to-end RL in supporting adaptive and efficient retrieval for complex reasoning.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-11T11:00:05.206291",
        "filter_reason": "这篇论文的核心贡献是提出了一个名为 `RouteRAG` 的新框架，该框架使用强化学习（RL）来让LLM在生成答案的过程中，自主地、动态地决定何时进行推理、从文本或图数据库中检索什么内容、以及何时给出最终答案。 根据筛选标准，我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将RAG技术应用于某个领域，而是提出了一种**构建和改进LLM智能体**的新方法论。`RouteRAG`框架赋予了LLM一个统一的生成策略，使其能够根据当前状态自主决策（推理、检索、终止），这完全符合“构建LLM智能体”的定义。它不是非演化型应用，因为其核心是提出一个自适应的、可学习的框架，而非一个固定的应用方案。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **智能体能力**: `Planning`（规划何时推理、检索和回答）、`Tool Use / Tool Augmentation`（将文本和图检索作为工具，并学习选择使用哪个工具）。 - **核心范式**: 其工作方式与 `ReAct` (Reasoning and Acting) 范式高度相似，在推理和行动（检索）之间交替进行，并通过RL进行端到端优化。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态问题，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”的典型案例。它研究的不是提升LLM本身的基础推理能力，而是构建一个**智能体框架**来指导LLM在复杂任务中进行多步推理和规划。模型学习的是一个决策策略，这属于典型的Agentic AI研究范畴。 **最终决策**: 综合来看，`RouteRAG`的核心贡献在于构建了一个具有自主规划和工具使用能力的LLM智能体框架。它通过强化学习让智能体学会了如何高效地、自适应地利用外部知识（文本和图）来完成复杂任务。这完全符合我研究课题中“单智能体”方向下的“规划”和“工具使用”子方向。因此，这篇论文应该被保留。"
    },
    {
        "index": "#27",
        "title": "CORE: A Conceptual Reasoning Layer for Large Language Models",
        "link": "/arxiv/2512.09222",
        "arxiv_id": "2512.09222",
        "authors": "Vishwas Hegde, Vindhya Shigehalli",
        "summary": "Large language models handle single-turn generation well, but multi-turn interactions still require the model to reconstruct user intent and task state from an expanding token history because internal representations do not persist across turns. This token-first paradigm leads to drift, inconsistent reasoning modes, and growing prompts as conversations deepen. We propose CORE, a concept-first interaction layer that improves multi-turn stability without modifying model weights. CORE combines a small library of universal cognitive operators with a persistent Local Concept - a compact semantic state capturing the task, constraints, preferences, and intermediate results. Each model call receives only this concept state, the user's latest instruction, and the selected operator, eliminating the need to replay full history. A preliminary prototype simulating CORE's behavior shows about 42% reduction in cumulative prompt tokens, though this number reflects prototype conditions and should not be interpreted as a real-world performance estimate. CORE offers a model-agnostic mechanism that separates conceptual reasoning from language generation, suggesting a scalable direction for more stable multi-turn systems.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-11T11:00:05.208787",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接聚焦于**构建和改进LLM智能体**。 1.  **核心判断 (第一步):** 论文的本质是提出一种名为CORE的新框架/方法论，用于解决LLM在多轮交互中的核心缺陷。它不是将LLM作为工具应用于某个特定领域，也不是单纯提升LLM的基础推理能力，而是构建了一个位于LLM之上的“概念推理层”。这个层通过引入持久化的状态和结构化的算子，直接改进了智能体的架构。因此，根据第一步的核心判断标准，这篇论文应该**保留**。 2.  **正面指标 (第二步):** 论文与你的核心关注点高度契合： *   **智能体能力:** 论文的核心贡献之一是解决**记忆**问题。它提出的“持久的局部概念”是一种高级的、结构化的记忆机制，远超简单的对话历史回放，直接解决了“内部表示不会在轮次之间持续存在”这一智能体关键痛点。 *   **智能体能力:** 论文明确提出了“概念推理”，旨在解决多轮交互中的“不一致的推理模式”和“漂移”问题。这属于**规划/推理**的范畴，其提出的“认知算子”与ReAct等范式在思想上是一致的，都是为智能体的自主行动提供结构化的指导框架。 *   **核心范式:** 整篇论文都在讨论如何构建一个更稳定、更高效的`LLM-based Agent`系统。 3.  **排除标准 (第三步):** 论文的主要贡献不涉及安全、对齐、可解释性或多模态。它的焦点是智能体的性能和架构稳定性，因此没有触发任何排除标准。 4.  **特殊和模糊情况 (第四步):** *   **推理/规划:** 这篇论文是“保留”情况的完美范例。它不是提出一个新的数学数据集来微调模型，而是提出了一个**智能体框架**，该框架通过分离“概念推理”和“语言生成”来改进智能体在复杂、多步任务中的表现。这完全符合你对Agentic框架的研究兴趣。 **总结:** 这篇论文的核心贡献是提出了一种名为CORE的**智能体架构改进方案**。它通过引入一种新颖的**持久化记忆机制**（局部概念）和**结构化的推理流程**（认知算子），直接解决了LLM智能体在多轮交互中的记忆和推理稳定性问题。这完全属于你研究范围中的“单智能体”方向，特别是“记忆”和“规划”子方向。因此，这篇论文是高度相关且应该被筛选出来的前沿研究。"
    },
    {
        "index": "#36",
        "title": "SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments",
        "link": "/arxiv/2512.09897",
        "arxiv_id": "2512.09897",
        "authors": "Haoye Lu, Pavan Seshadri, Kaheer Suleman",
        "summary": "Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods typically employ a pretrained, unaltered LLM whose parameters remain fixed throughout training, providing no opportunity for adaptation to the target task. To address these limitations, we introduce SCOPE (Subgoal-COnditioned Pretraining for Efficient planning), a one-shot hierarchical planner that leverages LLM-generated subgoals only at initialization to pretrain a lightweight student model. Unlike prior approaches that distill LLM knowledge by repeatedly prompting the model to adaptively generate subgoals during training, our method derives subgoals directly from example trajectories. This design removes the need for repeated LLM queries, significantly improving efficiency, though at the cost of reduced explainability and potentially suboptimal subgoals. Despite their suboptimality, our results on the TextCraft environment show that LLM-generated subgoals can still serve as a strong starting point for hierarchical goal decomposition in text-based planning tasks. Compared to the LLM-based hierarchical agent ADaPT (Prasad et al., 2024), which achieves a 0.52 success rate, our method reaches 0.56 and reduces inference time from 164.4 seconds to just 3.0 seconds.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-10",
        "category": "cs.CL",
        "crawl_time": "2025-12-11T11:00:05.211408",
        "filter_reason": "这篇论文符合筛选标准，应被保留。 **判断过程如下:** 1.  **第一步：核心判断** *   **论文本质**: 这篇论文的核心贡献是提出了一种名为SCOPE的新框架，用于构建和改进LLM智能体的规划能力。它并非将LLM或现有智能体框架简单地应用到一个新领域，而是针对现有LLM规划智能体（如ADaPT）在推理时需要反复调用LLM导致效率低下的问题，提出了一种创新的解决方案：在初始化时利用LLM生成子目标来预训练一个轻量级学生模型，从而在后续推理中摆脱对LLM的依赖。这本质上是对智能体架构和训练过程的改进。 *   **结论**: **保留**。论文的核心是关于“构建、改进LLM智能体”的方法论，完全符合第一步的保留标准。 2.  **第二步：正面指标** *   论文明确涉及了多个核心关注点： *   `Agentic AI` / `LLM-based Agents`: 整篇论文都在讨论如何构建一个基于LLM的规划智能体。 *   `Planning`: 这是论文最核心的关键词和贡献点，提出了一种新的“分层规划”方法。 *   `ReAct`: 虽然没有直接使用ReAct这个词，但其分层规划、目标分解的思想与ReAct等Agentic推理范式一脉相承。 *   **结论**: 论文在“单智能体”方向的“规划”能力上具有很强的正面指标。 3.  **第三步：排除标准** *   论文的主要贡献不在于安全、对齐、可解释性或水印。虽然它提到了其方法可能导致“可解释性降低”，但这只是效率提升带来的一个副作用，而非研究的主要贡献。 *   论文的研究环境是纯文本的，不涉及视觉或多模态内容。 *   **结论**: 未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 该论文是典型的关于“智能体如何进行规划”的研究。它提出了一个具体的Agentic框架（SCOPE）来解决复杂任务中的多步推理问题，完全符合“保留”的条件，而非仅仅提升LLM本身的基础数学或逻辑能力。 *   **自我演化**: 论文不涉及自我演化。LLM作为“一次性教师”后便不再参与，学生模型也是预训练后固定下来的，不会根据经验进行自我完善。但这不影响其被保留，因为研究课题的三个方向是“或”的关系。 5.  **第五步：最终决策** *   综合以上分析，论文“SCOPE”的核心贡献在于提出了一种新颖的、更高效的LLM智能体规划框架。它直接解决了现有Agentic LLM在规划任务中的一个关键瓶颈（计算效率），属于对智能体本身的构建和改进。该研究精准地落在“单智能体”范畴下的“规划”子方向，与研究课题“LLM智能体及其演化”的核心目标高度契合。因此，应将其保留。"
    },
    {
        "index": "#18",
        "title": "Training One Model to Master Cross-Level Agentic Actions via Reinforcement Learning",
        "link": "/arxiv/2512.09706",
        "arxiv_id": "2512.09706",
        "authors": "Kaichen He, Zihao Wang, Muyao Li, Anji Liu, Yitao Liang",
        "summary": "The paradigm of agentic AI is shifting from engineered complex workflows to post-training native models. However, existing agents are typically confined to static, predefined action spaces--such as exclusively using APIs, GUI events, or robotic commands. This rigidity limits their adaptability in dynamic environments where the optimal granularity of interaction varies contextually. To bridge this gap, we propose CrossAgent, a unified agentic model that masters heterogeneous action spaces and autonomously selects the most effective interface for each step of a trajectory. We introduce a comprehensive training pipeline that integrates cold-start supervised fine-tuning with a Multi-Turn Group Relative Policy Optimization (GRPO) algorithm. This approach enables the agent to learn adaptive action switching--balancing high-level efficiency with low-level precision--without human-specified rules. Extensive experiments on over 800 tasks in the open-world Minecraft environment demonstrate that CrossAgent achieves state-of-the-art performance. By dynamically leveraging the strengths of diverse action spaces, our model significantly outperforms fixed-action baselines, exhibiting superior generalization and efficiency in long-horizon reasoning. All code and models are available at https://github.com/CraftJarvis/OpenHA",
        "subjects": "Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-11T11:00:06.031128",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接聚焦于构建和改进LLM智能体。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 `CrossAgent` 的新颖智能体模型和相应的训练流程。它的核心贡献不是将现有智能体应用于某个领域，而是**解决智能体本身的一个根本性局限**：即现有智能体被限制在静态、预定义的行动空间中。论文通过构建一个能够自主选择不同粒度行动（如高级API调用或低级GUI操作）的统一模型，直接推动了LLM智能体构建技术的发展。这完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Agentic AI` (摘要中明确提及)。 - **智能体能力**: - `Planning`: 论文强调智能体能够“autonomously selects the most effective interface for each step of a trajectory”（为轨迹的每一步自主选择最有效的接口），这本质上是一种动态规划和决策能力。同时，摘要提到了“long-horizon reasoning”（长期推理），这是规划能力的核心体现。 - `Tool Use / Tool Augmentation`: 论文的核心就是让智能体掌握“heterogeneous action spaces”（异构行动空间），例如API、GUI事件等，这正是高级工具使用能力的体现。 - **演化机制**: 论文通过强化学习（`Multi-Turn Group Relative Policy Optimization (GRPO) algorithm`）来训练智能体，使其能够“learn adaptive action switching”（学习自适应行动切换），这是一种通过环境反馈进行自我完善和迭代的学习机制，与“自我演化”的理念高度契合。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐（Safety, Alignment, Interpretability等），也不以多模态或视觉模型本身为核心研究对象。虽然实验在Minecraft环境中进行（该环境有视觉输入），但论文的焦点是智能体的**行动决策逻辑**，而非视觉感知模型。因此，它没有触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何在复杂任务中进行多步推理和规划的典型案例。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个能让LLM在动态环境中进行有效规划和行动的框架。因此，根据规则，应该**保留**。 - **自我演化的应用**: 这篇论文虽然应用在Minecraft这个特定环境中，但其核心贡献是提出了一种新的**自适应行动选择机制和训练方法**，这是一种通用的智能体能力增强方案。根据规则，这种提出新“自我演化”或“自我完善”机制的论文，即使应用在特定领域，也应该**保留**。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心是构建一个名为 `CrossAgent` 的新型LLM智能体，它通过创新的训练方法，掌握了在异构行动空间中进行自主规划和工具使用的能力。这直接命中了你研究目标中的“单智能体”方向，并触及了“自我演化”的训练机制。它不是简单的应用，而是对智能体核心能力的根本性改进。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#86",
        "title": "An End-to-end Planning Framework with Agentic LLMs and PDDL",
        "link": "/arxiv/2512.09629",
        "arxiv_id": "2512.09629",
        "authors": "Emanuele La Malfa, Ping Zhu, Samuele Marro, Sara Bernardini, Michael Wooldridge",
        "summary": "We present an end-to-end framework for planning supported by verifiers. An orchestrator receives a human specification written in natural language and converts it into a PDDL (Planning Domain Definition Language) model, where the domain and problem are iteratively refined by sub-modules (agents) to address common planning requirements, such as time constraints and optimality, as well as ambiguities and contradictions that may exist in the human specification. The validated domain and problem are then passed to an external planning engine to generate a plan. The orchestrator and agents are powered by Large Language Models (LLMs) and require no human intervention at any stage of the process. Finally, a module translates the final plan back into natural language to improve human readability while maintaining the correctness of each step. We demonstrate the flexibility and effectiveness of our framework across various domains and tasks, including the Google NaturalPlan benchmark and PlanBench, as well as planning problems like Blocksworld and the Tower of Hanoi (where LLMs are known to struggle even with small instances). Our framework can be integrated with any PDDL planning engine and validator (such as Fast Downward, LPG, POPF, VAL, and uVAL, which we have tested) and represents a significant step toward end-to-end planning aided by LLMs.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-11T11:00:06.093530",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的筛选标准高度契合。以下是我的详细判断过程： 1.  **第一步：核心判断——保留** - **论文本质**: 这篇论文的核心贡献是提出一个全新的、端到端的**规划框架**。这个框架并非简单地将LLM作为工具应用于某个领域，而是构建了一个由多个LLM驱动的智能体（一个`orchestrator`和多个`sub-modules (agents)`）协同工作的系统。这个系统的目的是解决复杂的规划问题，其方法论本身就是关于“构建LLM智能体”的。 - **排除项检查**: - **非演化型应用**: 论文不是将已有框架应用于生物或金融，其贡献在于框架本身，因此不属于此项排除。 - **非Agentic的推理**: 论文明确提出了一个`Agentic`框架，涉及多个智能体协同、迭代完善，这远超出了提升LLM基础推理能力的范畴。 - **基础设施**: 论文不涉及硬件或部署优化。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文标题和摘要中明确提到了 `Agentic LLMs`，其描述的系统本质上是一个 `Multi-Agent System` (MAS)。 - **智能体能力**: 论文的核心是 `Planning`。它通过多个智能体协作，实现了对规划问题的迭代完善，这体现了 `Self-Correction` 或 `Self-Refinement` 的能力。同时，它将外部 `PDDL` 规划引擎作为工具使用，完全符合 `Tool Use / Tool Augmentation` 的定义。 - **多智能体**: 论文明确提到了 `orchestrator` 和 `sub-modules (agents)`，描述了一个由多个智能体角色分工、协作完成任务的系统。 - **演化机制**: 摘要中的 \"iteratively refined by sub-modules (agents)\" 直接对应了 `Iterative Improvement` 这一演化机制。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不涉及安全、对齐、可解释性或水印。 - 论文不涉及视觉或多模态内容，PDDL是符号化的规划语言，不属于排除范围。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 这篇论文是“保留”情况的完美范例。它不是在研究如何让LLM本身更会做数学题，而是在研究如何构建一个**智能体框架**来让LLM解决复杂的规划任务。这与 `ReAct`、`ToT` 等Agentic规划范式一脉相承，是其方法论的创新和扩展。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建了一个由多个LLM智能体协同工作的、具备工具使用和自我完善能力的规划框架**。这直接命中了您研究课题中的“单智能体”和“多智能体”方向，并触及了“自我演化”的迭代改进机制。因此，这篇论文是您需要筛选的前沿论文，应予以保留。"
    },
    {
        "index": "#97",
        "title": "Architectures for Building Agentic AI",
        "link": "/arxiv/2512.09458",
        "arxiv_id": "2512.09458",
        "authors": "Sławomir Nowaczyk",
        "summary": "This chapter argues that the reliability of agentic and generative AI is chiefly an architectural property. We define agentic systems as goal-directed, tool-using decision makers operating in closed loops, and show how reliability emerges from principled componentisation (goal manager, planner, tool-router, executor, memory, verifiers, safety monitor, telemetry), disciplined interfaces (schema-constrained, validated, least-privilege tool calls), and explicit control and assurance loops. Building on classical foundations, we propose a practical taxonomy-tool-using agents, memory-augmented agents, planning and self-improvement agents, multi-agent systems, and embodied or web agents - and analyse how each pattern reshapes the reliability envelope and failure modes. We distil design guidance on typed schemas, idempotency, permissioning, transactional semantics, memory provenance and hygiene, runtime governance (budgets, termination conditions), and simulate-before-actuate safeguards.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-10",
        "category": "cs.LG",
        "crawl_time": "2025-12-11T11:00:06.103898",
        "filter_reason": "这篇论文完全符合你的研究范围，是一篇高度相关的核心文献。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出一个用于构建Agentic AI的**架构框架**和**分类法**。它不是将智能体作为工具去解决某个特定领域的问题，而是直接研究智能体本身应该如何被设计和构建。这完全符合“核心贡献在于构建、改进或演化LLM智能体”的要求。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了你关注的所有核心范式和能力： *   **核心范式**: 明确提到了 `Agentic AI` 和 `Multi-Agent Systems`。 *   **单智能体能力**: 详细列出了智能体的关键组件，包括 `planner` (规划), `tool-router` (工具使用), `memory` (记忆), `verifiers` (自我修正), 以及 `self-improvement agents` (自我演化)。 *   **多智能体**: 明确将 `multi-agent systems` 作为其分类法中的一个重要类别。 *   **演化机制**: 直接提到了 `self-improvement agents`，这与你的“自我演化”方向完全一致。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 虽然摘要中提到了 `safety monitor` 和 `reliability`，但论文的**主旨**是探讨如何通过**架构设计**来实现可靠性，安全只是其中一个组件。论文的核心是“如何构建”，而不是“如何对齐”。因此，它不属于被排除的安全与对齐研究。 *   **多模态与视觉**: 论文未涉及相关内容。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文明确将 `planner` 作为智能体架构的核心组件之一，并讨论了其在闭环决策中的作用，这完全符合“保留”关于智能体规划框架的论文的标准。 **最终决策**: 这篇论文的标题和摘要清晰地表明，其核心贡献是**系统性地梳理和提出构建Agentic AI的架构原则和分类方法**。它直接覆盖了你研究的三个核心方向（单智能体、多智能体、自我演化），并深入探讨了规划、工具使用、记忆等关键能力。这并非一篇应用型或基础设施型论文，而是一篇关于Agentic AI“如何构建”的框架性、方法论论文，与你的研究目标高度契合。因此，应予以保留。"
    },
    {
        "index": "#4",
        "title": "Comparing AI Agents to Cybersecurity Professionals in Real-World Penetration Testing",
        "link": "/arxiv/2512.09882",
        "arxiv_id": "2512.09882",
        "authors": "Justin W. Lin, Eliot Krzysztof Jones, Donovan Julian Jasper, Ethan Jun-shen Ho, Anna Wu, Arnold Tianyi Yang, Neil Perry, Andy Zou, Matt Fredrikson, J. Zico Kolter, Percy Liang, Dan Boneh, Daniel E. Ho",
        "summary": "We present the first comprehensive evaluation of AI agents against human cybersecurity professionals in a live enterprise environment. We evaluate ten cybersecurity professionals alongside six existing AI agents and ARTEMIS, our new agent scaffold, on a large university network consisting of ~8,000 hosts across 12 subnets. ARTEMIS is a multi-agent framework featuring dynamic prompt generation, arbitrary sub-agents, and automatic vulnerability triaging. In our comparative study, ARTEMIS placed second overall, discovering 9 valid vulnerabilities with an 82% valid submission rate and outperforming 9 of 10 human participants. While existing scaffolds such as Codex and CyAgent underperformed relative to most human participants, ARTEMIS demonstrated technical sophistication and submission quality comparable to the strongest participants. We observe that AI agents offer advantages in systematic enumeration, parallel exploitation, and cost -- certain ARTEMIS variants cost $18/hour versus $60/hour for professional penetration testers. We also identify key capability gaps: AI agents exhibit higher false-positive rates and struggle with GUI-based tasks.",
        "subjects": "Artificial Intelligence, Cryptography and Security, Computers and Society",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-11T11:00:06.173077",
        "filter_reason": "这篇论文符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将现有AI智能体应用于网络安全领域，而是**提出并构建了一个全新的多智能体框架ARTEMIS**。摘要明确指出“ARTEMIS, our new agent scaffold”并将其描述为“a multi-agent framework featuring dynamic prompt generation, arbitrary sub-agents, and automatic vulnerability triaging”。这表明论文的本质是关于**构建和改进LLM智能体**的方法论，直接命中了您“构建、改进或演化LLM智能体”的核心目标。它不属于“非演化型应用”的排除范畴，因为其价值在于框架本身的设计，而非应用结果。 2.  **第二步：正面指标——高度相关** 论文包含了多个您关注的核心范式和能力： *   **核心范式**: 明确提到了 `Multi-Agent Systems (MAS)`，这是您研究的三大方向之一。 *   **智能体能力**: “dynamic prompt generation”和“automatic vulnerability triaging”暗示了智能体具备复杂的规划和自我修正能力。“parallel exploitation”则体现了工具使用和任务协调能力。 *   **多智能体**: “multi-agent framework”和“arbitrary sub-agents”直接指向了智能体间的协作与分工。 3.  **第三步：排除标准——未触发** 尽管论文主题是“网络安全”，但其主要贡献是关于**如何构建一个能执行渗透测试任务的智能体框架**，而不是研究智能体自身的`Safety`、`Security`或`Alignment`问题。因此，它没有触发“安全与对齐”的排除标准。论文也未涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况——符合核心规则** 这篇论文的情况与“自我演化的应用”的例外规则精神一致。虽然它被应用在“渗透测试”这一特定领域，但其**核心贡献是提出一种新的多智能体框架（方法论）**，而不仅仅是展示应用效果。研究的重点在于“如何构建ARTEMIS”，这正是您所关注的“构建、改进或演化LLM智能体”的范畴。 **最终决策**: 综合分析，该论文的核心是提出并评估一个名为ARTEMIS的新型多智能体框架，旨在解决复杂的现实世界任务。这完全符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的目标，特别是与您的“多智能体”研究方向高度契合。因此，应予以保留。"
    },
    {
        "index": "#51",
        "title": "Advancing LLM-Based Security Automation with Customized Group Relative Policy Optimization for Zero-Touch Networks",
        "link": "/arxiv/2512.09485",
        "arxiv_id": "2512.09485",
        "authors": "Xinye Cao, Yihan Lin, Guoshun Nan, Qinchuan Zhou, Yuhang Luo, Yurui Gao, Zeliang Zhang, Haolang Lu, Qimei Cui, Yanzhao Hou, Xiaofeng Tao, Tony Q. S. Quek",
        "summary": "Zero-Touch Networks (ZTNs) represent a transformative paradigm toward fully automated and intelligent network management, providing the scalability and adaptability required for the complexity of sixth-generation (6G) networks. However, the distributed architecture, high openness, and deep heterogeneity of 6G networks expand the attack surface and pose unprecedented security challenges. To address this, security automation aims to enable intelligent security management across dynamic and complex environments, serving as a key capability for securing 6G ZTNs. Despite its promise, implementing security automation in 6G ZTNs presents two primary challenges: 1) automating the lifecycle from security strategy generation to validation and update under real-world, parallel, and adversarial conditions, and 2) adapting security strategies to evolving threats and dynamic environments. This motivates us to propose SecLoop and SA-GRPO. SecLoop constitutes the first fully automated framework that integrates large language models (LLMs) across the entire lifecycle of security strategy generation, orchestration, response, and feedback, enabling intelligent and adaptive defenses in dynamic network environments, thus tackling the first challenge. Furthermore, we propose SA-GRPO, a novel security-aware group relative policy optimization algorithm that iteratively refines security strategies by contrasting group feedback collected from parallel SecLoop executions, thereby addressing the second challenge. Extensive real-world experiments on five benchmarks, including 11 MITRE ATT&CK processes and over 20 types of attacks, demonstrate the superiority of the proposed SecLoop and SA-GRPO. We will release our platform to the community, facilitating the advancement of security automation towards next generation communications.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-11T11:00:06.188354",
        "filter_reason": "这篇论文符合筛选要求，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个已有的LLM智能体框架应用到安全领域，而是**提出了两个核心创新**：`SecLoop`，一个集成了LLM的、用于安全策略全生命周期管理的自动化框架；以及`SA-GRPO`，一个用于迭代优化安全策略的算法。`SecLoop`本身就是一个LLM智能体框架（具备生成、编排、响应、反馈的循环），而`SA-GRPO`则是一个明确的**自我演化机制**。因此，论文的核心贡献在于构建和演化LLM智能体，符合保留标准。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (SecLoop框架)。 - **自我演化**: `Self-Evolving`, `Self-Improvement`, `Iterative Improvement` (SA-GRPO算法的核心功能是“iteratively refines security strategies”)。 - **多智能体**: 论文中提到“contrasting group feedback collected from parallel SecLoop executions”，这暗示了多个智能体实例并行运行并进行交互学习，符合多智能体系统的特征。 - **智能体能力**: `Planning` (security strategy generation), `Self-Correction` (通过SA-GRPO进行策略精炼)。 3.  **第三步：排除标准** - **安全与对齐**: 这是本篇论文最需要仔细辨析的地方。虽然论文的标题和摘要充满了`Security`（安全）这个词，但它的主要贡献**并非**提出一种新的安全理论、攻击检测方法或对齐技术。相反，它的贡献是**提出了一种能让智能体在安全这个复杂任务中进行自我演化的新方法**。研究的焦点是“智能体如何演化”，而不是“如何实现安全”。因此，它不应被归为“主要贡献是关于安全”的排除类别。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美例证。论文的核心是提出一种新的“自我演化”机制（`SA-GRPO`），并将其应用在“网络安全自动化”这个特定领域。根据筛选规则，“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域...也应该保留”。因此，这篇论文应该被保留。 **最终决策**: 综合以上分析，尽管论文的应用领域是网络安全，但其核心贡献在于构建了一个全新的LLM智能体框架（`SecLoop`）和一个创新的自我演化算法（`SA-GRPO`）。这完全契合“LLM智能体及其演化”的研究课题，特别是“自我演化”这一核心方向。因此，这篇论文高度相关，应被保留。"
    },
    {
        "index": "#90",
        "title": "Evolving Excellence: Automated Optimization of LLM-based Agents",
        "link": "/arxiv/2512.09108",
        "arxiv_id": "2512.09108",
        "authors": "Paul Brookes, Vardan Voskanyan, Rafail Giavrimis, Matthew Truscott, Mina Ilieva, Chrystalla Pavlou, Alexandru Staicu, Manal Adham, Will Evers- Hood, Jingzhi Gong, Kejia Zhang, Matvey Fedoseev, Vishal Sharma, Roman Bauer, Zheng Wang, Hema Nair, Wei Jie, Tianhua Xu, Aurora Constantin, Leslie Kanthan, Michail Basios",
        "summary": "Agentic AI systems built on large language models (LLMs) offer significant potential for automating complex workflows, from software development to customer support. However, LLM agents often underperform due to suboptimal configurations; poorly tuned prompts, tool descriptions, and parameters that typically require weeks of manual refinement. Existing optimization methods either are too complex for general use or treat components in isolation, missing critical interdependencies. We present ARTEMIS, a no-code evolutionary optimization platform that jointly optimizes agent configurations through semantically-aware genetic operators. Given only a benchmark script and natural language goals, ARTEMIS automatically discovers configurable components, extracts performance signals from execution logs, and evolves configurations without requiring architectural modifications. We evaluate ARTEMIS on four representative agent systems: the \\emph{ALE Agent} for competitive programming on AtCoder Heuristic Contest, achieving a \\textbf{$13.6\\%$ improvement} in acceptance rate; the \\emph{Mini-SWE Agent} for code optimization on SWE-Perf, with a statistically significant \\textbf{10.1\\% performance gain}; and the \\emph{CrewAI Agent} for cost and mathematical reasoning on Math Odyssey, achieving a statistically significant \\textbf{$36.9\\%$ reduction} in the number of tokens required for evaluation. We also evaluate the \\emph{MathTales-Teacher Agent} powered by a smaller open-source model (Qwen2.5-7B) on GSM8K primary-level mathematics problems, achieving a \\textbf{22\\% accuracy improvement} and demonstrating that ARTEMIS can optimize agents based on both commercial and local models.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-11T11:00:06.201714",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献与你的研究目标高度契合。以下是根据筛选标准的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 **ARTEMIS** 的方法论和平台，其核心功能是 **自动优化和演化 LLM 智能体**。论文明确指出，LLM智能体因配置不佳（如提示词、工具描述、参数）而表现不佳，而ARTEMIS通过“演化优化平台”和“遗传算子”来自动发现和改进这些配置。这完全符合“构建、改进或演化 LLM智能体”的核心要求，特别是属于 **自我演化** 的范畴。它不是将智能体作为工具去解决某个领域问题，而是研究如何让智能体本身变得更好。 2.  **第二步：正面指标** - 论文包含了大量你的核心关注点： - **核心范式**: `LLM-based Agents`, `Self-Evolving`, `Evolutionary Algorithms` (通过 \"evolutionary optimization platform\" 和 \"genetic operators\" 体现)。 - **演化机制**: `Self-Improvement` (整个平台的目标), `Generational Evolution` (通过遗传算法实现), `Iterative Improvement` (优化过程的本质)。 - 这些关键词和概念在摘要中密集出现，表明论文的研究焦点与你的方向高度一致。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐问题。 - 论文也未涉及 `Vision`, `MLLMs` 等多模态内容。 - 因此，该论文没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 论文虽然将ARTEMIS应用到了多个具体领域（如编程竞赛、代码优化、数学推理），但其 **核心贡献是提出了一种通用的、新颖的“自我演化”机制**。这完全符合你设定的“例外”规则：即使应用在特定领域，只要核心是提出新的自我演化机制，就应该保留。ARTEMIS本身就是这个机制。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出一个名为ARTEMIS的自动化演化平台，用于优化LLM智能体的配置。这直接命中了你研究课题中的 **“自我演化”** 方向。它不是简单的应用，也不是关于基础模型能力或基础设施的研究，而是专注于如何让智能体系统通过演化机制实现自我完善和性能提升。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#111",
        "title": "Training Multi-Image Vision Agents via End2End Reinforcement Learning",
        "link": "/arxiv/2512.08980",
        "arxiv_id": "2512.08980",
        "authors": "Chengqi Dong, Chuhuai Yue, Hang He, Rongge Mao, Fenghe Tang, S Kevin Zhou, Zekun Xu, Xiaohan Wang, Jiajun Chai, Wei Lin, Guojun Yin",
        "summary": "Recent VLM-based agents aim to replicate OpenAI O3's ``thinking with images\" via tool use, but most open-source methods limit input to a single image, falling short on real-world multi-image QA tasks. To address this, we propose IMAgent, an open-source vision agent trained via end-to-end reinforcement learning dedicated for complex multi-image tasks. By leveraging a multi-agent system, we generate challenging and visually-rich multi-image QA pairs to fully activate the tool-use potential of the base VLM. Through manual verification, we obtain MIFG-QA, comprising 10k samples for training and evaluation. With deeper reasoning steps, VLMs may increasingly ignore visual inputs. We therefore develop two specialized tools for visual reflection and confirmation, allowing the model to proactively reallocate its attention to image content during inference. Benefiting from our well-designed action-trajectory two-level mask strategy, IMAgent achieves stable tool use behavior via pure RL training without requiring costly supervised fine-tuning data. Extensive experiments demonstrate that IMAgent maintains strong performance on existing single-image benchmarks while achieving substantial improvements on our proposed multi-image dataset, with our analysis providing actionable insights for the research community. Codes and data will be released soon.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-12-05",
        "category": "cs.AI",
        "crawl_time": "2025-12-11T11:00:06.209198",
        "filter_reason": "这篇论文符合研究范围，应被保留。 **判断过程和核心依据如下：** 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为IMAgent的新型视觉智能体，并详细描述了如何通过端到端强化学习来训练它。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是简单地将现有智能体应用于某个领域，而是在创造一个新的智能体架构和训练范式。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `LLM-based Agents` (基于VLM的智能体), `Multi-Agent Systems` (用于数据生成)。 - **智能体能力**: `Tool Use` (核心主题，开发了专门的工具), `Self-Reflection` (设计了视觉反思工具), `Planning` (隐含在多步推理和工具使用中)。 - **多智能体**: 明确提到使用`Multi-Agent System`来生成训练数据。 - 这些正面指标强烈表明该论文与您的研究方向高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题，此项通过。 - **多模态与视觉**: 这是本案例的关键点。虽然论文标题和内容都围绕“Vision”，但其研究核心**并非**提出新的视觉模型或视觉理解算法。相反，VLM在这里是作为智能体感知环境的**工具**或“大脑”。论文的核心贡献在于智能体的**架构设计**（如何让智能体处理多图）、**训练方法**（端到端RL）和**工具设计**（视觉反思工具）。这完全符合排除标准中的例外条款：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。因此，不应因此排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文讨论的是智能体如何通过工具使用和反思来完成复杂的多图像任务，这属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴，应予以保留。它不是在改进VLM本身的基础视觉推理能力，而是在构建一个能利用这种能力的智能体框架。 5.  **第五步：最终决策** - **综合分析**：该论文的核心贡献是构建了一个新的智能体框架（IMAgent），并提出了创新的训练方法（纯RL）和工具设计（视觉反思）。它同时触及了您研究焦点的两个核心方向：**单智能体**（工具使用、自我反思）和**多智能体**（利用多智能体系统进行数据生成）。尽管涉及视觉，但视觉是作为智能体的感知输入，而非研究主体。因此，这篇论文是关于“LLM智能体及其演化”的典型前沿研究，完全符合您的筛选要求。"
    },
    {
        "index": "#126",
        "title": "AI Co-Artist: A LLM-Powered Framework for Interactive GLSL Shader Animation Evolution",
        "link": "/arxiv/2512.08951",
        "arxiv_id": "2512.08951",
        "authors": "Kamer Ali Yuksel, Hassan Sawaf",
        "summary": "Creative coding and real-time shader programming are at the forefront of interactive digital art, enabling artists, designers, and enthusiasts to produce mesmerizing, complex visual effects that respond to real-time stimuli such as sound or user interaction. However, despite the rich potential of tools like GLSL, the steep learning curve and requirement for programming fluency pose substantial barriers for newcomers and even experienced artists who may not have a technical background. In this paper, we present AI Co-Artist, a novel interactive system that harnesses the capabilities of large language models (LLMs), specifically GPT-4, to support the iterative evolution and refinement of GLSL shaders through a user-friendly, visually-driven interface. Drawing inspiration from the user-guided evolutionary principles pioneered by the Picbreeder platform, our system empowers users to evolve shader art using intuitive interactions, without needing to write or understand code. AI Co-Artist serves as both a creative companion and a technical assistant, allowing users to explore a vast generative design space of real-time visual art. Through comprehensive evaluations, including structured user studies and qualitative feedback, we demonstrate that AI Co-Artist significantly reduces the technical threshold for shader creation, enhances creative outcomes, and supports a wide range of users in producing professional-quality visual effects. Furthermore, we argue that this paradigm is broadly generalizable. By leveraging the dual strengths of LLMs-semantic understanding and program synthesis, our method can be applied to diverse creative domains, including website layout generation, architectural visualizations, product prototyping, and infographics.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Graphics",
        "date": "2025-11-27",
        "category": "cs.AI",
        "crawl_time": "2025-12-11T11:00:06.214018",
        "filter_reason": "这篇论文符合我的研究范围，应被保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非简单地将LLM应用于创意编码领域，而是提出了一种**新颖的“自我演化”框架**。标题和摘要中反复强调的“Evolution”（演化）和“iterative evolution and refinement”（迭代演化和精炼）是其核心。这直接命中了我的研究焦点之一“自我演化”。它不是在解决一个特定的着色器问题，而是在构建一个能够让用户引导智能体（LLM）不断迭代、完善其产出（着色器代码）的系统。因此，它不属于“非演化型应用”的排除范畴。 2.  **正面指标 (第二步):** 论文包含了多个核心关注点。 *   **自我演化:** 这是论文最核心的范式，其机制借鉴了交互式演化计算，并由LLM驱动。 *   **迭代改进:** 摘要明确提到“iterative evolution and refinement”，这与自我演化的目标一致。 *   **工具使用:** LLM在这里扮演了智能体的角色，其核心能力之一是“程序合成”，即生成和修改GLSL代码。这可以被视为智能体使用其内部能力作为工具来完成演化任务。 3.  **排除标准 (第三步):** 论文未触发任何排除标准。虽然其输出是视觉内容，但研究的核心并非视觉模型或多模态理解，而是**如何驱动一个演化过程**。视觉是演化结果的表现形式，而非研究的技术主体。论文也未涉及安全、对齐等被排除的主题。 4.  **特殊和模糊情况 (第四步):** 这篇论文是“自我演化的应用”这一特殊情况的完美范例。 *   **保留 (例外):** 论文的核心是提出一种新的“自我演化”机制——即一个由用户引导、LLM驱动的交互式演化框架。尽管它被应用在“GLSL Shader Animation”这个特定领域，但其方法论贡献是普适的（作者也明确指出“this paradigm is broadly generalizable”）。因此，根据筛选规则，这种提出新演化机制的论文，即使有特定应用场景，也应该被保留。 **总结:** 该论文的本质是构建一个**自我演化的LLM智能体框架**。它探索了如何将LLM的代码生成能力与交互式演化思想相结合，以实现一个能够根据用户反馈持续迭代和改进其产出的智能系统。这完全符合我关于“LLM智能体及其演化”中“自我演化”方向的研究目标。因此，最终判断为保留。"
    }
]