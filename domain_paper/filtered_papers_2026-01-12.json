[
    {
        "index": "#2",
        "title": "Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards",
        "link": "/arxiv/2601.06021",
        "arxiv_id": "2601.06021",
        "authors": "Jiajie Zhang, Xin Lv, Ling Feng, Lei Hou, Juanzi Li",
        "summary": "Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose \\textbf{Citation-aware Rubric Rewards (CaRR)}, a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce \\textbf{Citation-aware Group Relative Policy Optimization (C-GRPO)}, which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.246335",
        "filter_reason": "论文明确研究基于LLM的深度搜索智能体，提出了一种强化学习框架来训练智能体进行证据链构建和推理，属于单智能体的工具使用与自我演化范畴，且不涉及被排除的纯应用或纯推理内容。"
    },
    {
        "index": "#5",
        "title": "Distilling Feedback into Memory-as-a-Tool",
        "link": "/arxiv/2601.05960",
        "arxiv_id": "2601.05960",
        "authors": "Víctor Gallego",
        "summary": "We propose a framework that amortizes the cost of inference-time reasoning by converting transient critiques into retrievable guidelines, through a file-based memory system and agent-controlled tool calls. We evaluate this method on the Rubric Feedback Bench, a novel dataset for rubric-based learning. Experiments demonstrate that our augmented LLMs rapidly match the performance of test-time refinement pipelines while drastically reducing inference cost.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.248256",
        "filter_reason": "论文明确提出了包含“基于文件的记忆系统”和“智能体控制的工具调用”的框架，涉及单智能体的记忆机制、工具使用以及通过反馈进行自我完善，符合LLM智能体的研究范围。"
    },
    {
        "index": "#6",
        "title": "Can We Predict Before Executing Machine Learning Agents?",
        "link": "/arxiv/2601.05930",
        "arxiv_id": "2601.05930",
        "authors": "Jingsheng Zheng, Jintian Zhang, Yujie Luo, Yuren Mao, Yunjun Gao, Lun Du, Huajun Chen, Ningyu Zhang",
        "summary": "Autonomous machine learning agents have revolutionized scientific discovery, yet they remain constrained by a Generate-Execute-Feedback paradigm. Previous approaches suffer from a severe Execution Bottleneck, as hypothesis evaluation relies strictly on expensive physical execution. To bypass these physical constraints, we internalize execution priors to substitute costly runtime checks with instantaneous predictive reasoning, drawing inspiration from World Models. In this work, we formalize the task of Data-centric Solution Preference and construct a comprehensive corpus of 18,438 pairwise comparisons. We demonstrate that LLMs exhibit significant predictive capabilities when primed with a Verified Data Analysis Report, achieving 61.5% accuracy and robust confidence calibration. Finally, we instantiate this framework in FOREAGENT, an agent that employs a Predict-then-Verify loop, achieving a 6x acceleration in convergence while surpassing execution-based baselines by +6%. Our code and dataset will be publicly available soon at https://github.com/zjunlp/predict-before-execute.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.248978",
        "filter_reason": "论文明确提出了名为 \"FOREAGENT\" 的智能体，旨在解决自主机器学习智能体中的“执行瓶颈”问题。该研究通过引入“预测-验证”循环来优化智能体的工作流，属于单智能体机制（规划与执行优化）的研究范畴。"
    },
    {
        "index": "#22",
        "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis",
        "link": "/arxiv/2601.05808",
        "arxiv_id": "2601.05808",
        "authors": "Xiaoshuai Song, Haofei Chang, Guanting Dong, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen",
        "summary": "Large language models (LLMs) are expected to be trained to act as agents in various real-world environments, but this process relies on rich and varied tool-interaction sandboxes. However, access to real systems is often restricted; LLM-simulated environments are prone to hallucinations and inconsistencies; and manually built sandboxes are hard to scale. In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis. EnvScaler comprises two components. First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation. Then, ScenGenerator generates multiple task scenarios and rule-based trajectory validation functions for each environment. With EnvScaler, we synthesize 191 environments and about 7K scenarios, and apply them to Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Qwen3 series models. Results on three benchmarks show that EnvScaler significantly improves LLMs' ability to solve tasks in complex environments involving multi-turn, multi-tool interactions. We release our code and data at https://github.com/RUC-NLPIR/EnvScaler.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.267285",
        "filter_reason": "该论文专注于构建用于LLM智能体的工具交互环境，旨在通过程序化合成生成多样化的环境来训练智能体，提升其在复杂场景下的多轮、多工具交互能力，属于单智能体中的“工具使用”研究范畴。"
    },
    {
        "index": "#30",
        "title": "Stephanie2: Thinking, Waiting, and Making Decisions Like Humans in Step-by-Step AI Social Chat",
        "link": "/arxiv/2601.05657",
        "arxiv_id": "2601.05657",
        "authors": "Hao Yang, Hongyuan Lu, Dingkang Yang, Wenliang Yang, Peng Sun, Xiaochuan Zhang, Jun Xiao, Kefan He, Wai Lam, Yang Liu, Xinhua Zeng",
        "summary": "Instant-messaging human social chat typically progresses through a sequence of short messages. Existing step-by-step AI chatting systems typically split a one-shot generation into multiple messages and send them sequentially, but they lack an active waiting mechanism and exhibit unnatural message pacing. In order to address these issues, we propose Stephanie2, a novel next-generation step-wise decision-making dialogue agent. With active waiting and message-pace adaptation, Stephanie2 explicitly decides at each step whether to send or wait, and models latency as the sum of thinking time and typing time to achieve more natural pacing. We further introduce a time-window-based dual-agent dialogue system to generate pseudo dialogue histories for human and automatic evaluations. Experiments show that Stephanie2 clearly outperforms Stephanie1 on metrics such as naturalness and engagement, and achieves a higher pass rate on human evaluation with the role identification Turing test.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.276248",
        "filter_reason": "论文提出了一个具有分步决策能力的对话智能体，能够主动决定发送消息还是等待，并模拟思考时间，涉及单智能体的决策机制以及双智能体系统的交互，符合LLM智能体的研究范围。"
    },
    {
        "index": "#33",
        "title": "GIFT: Games as Informal Training for Generalizable LLMs",
        "link": "/arxiv/2601.05633",
        "arxiv_id": "2601.05633",
        "authors": "Nuoyan Lyu, Bingbing Xu, Weihao Meng, Yige Yuan, Yang Zhang, Zhiyong Huang, Tat-Seng Chua, Huawei Shen",
        "summary": "While Large Language Models (LLMs) have achieved remarkable success in formal learning tasks such as mathematics and code generation, they still struggle with the \"practical wisdom\" and generalizable intelligence, such as strategic creativity and social reasoning, that characterize human cognition. This gap arises from a lack of informal learning, which thrives on interactive feedback rather than goal-oriented instruction. In this paper, we propose treating Games as a primary environment for LLM informal learning, leveraging their intrinsic reward signals and abstracted complexity to cultivate diverse competencies. To address the performance degradation observed in multi-task learning, we introduce a Nested Training Framework. Unlike naive task mixing optimizing an implicit \"OR\" objective, our framework employs sequential task composition to enforce an explicit \"AND\" objective, compelling the model to master multiple abilities simultaneously to achieve maximal rewards. Using GRPO-based reinforcement learning across Matrix Games, TicTacToe, and Who's the Spy games, we demonstrate that integrating game-based informal learning not only prevents task interference but also significantly bolsters the model's generalization across broad ability-oriented benchmarks. The framework and implementation are publicly available.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.277663",
        "filter_reason": "论文利用游戏（如矩阵博弈、井字棋、谁是卧底）作为环境，通过强化学习（GRPO）训练LLM的战略创造力和社会推理能力，涉及多智能体博弈与通过反馈自我完善，符合“多智能体：博弈”及“自我演化”的研究范围。"
    },
    {
        "index": "#39",
        "title": "Generation-Based and Emotion-Reflected Memory Update: Creating the KEEM Dataset for Better Long-Term Conversation",
        "link": "/arxiv/2601.05548",
        "arxiv_id": "2601.05548",
        "authors": "Jeonghyun Kang, Hongjin Kim, Harksoo Kim",
        "summary": "In this work, we introduce the Keep Emotional and Essential Memory (KEEM) dataset, a novel generation-based dataset designed to enhance memory updates in long-term conversational systems. Unlike existing approaches that rely on simple accumulation or operation-based methods, which often result in information conflicts and difficulties in accurately tracking a user's current state, KEEM dynamically generates integrative memories. This process not only preserves essential factual information but also incorporates emotional context and causal relationships, enabling a more nuanced understanding of user interactions. By seamlessly updating a system's memory with both emotional and essential data, our approach promotes deeper empathy and enhances the system's ability to respond meaningfully in open-domain conversations.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.280332",
        "filter_reason": "论文专注于长期对话系统中的记忆更新机制，提出了动态生成整合记忆的方法。记忆是LLM智能体的核心组件之一（属于单智能体研究范围中的“记忆”），该研究旨在提升智能体在长期交互中跟踪用户状态和情感语境的能力，符合筛选条件。"
    },
    {
        "index": "#43",
        "title": "CHisAgent: A Multi-Agent Framework for Event Taxonomy Construction in Ancient Chinese Cultural Systems",
        "link": "/arxiv/2601.05520",
        "arxiv_id": "2601.05520",
        "authors": "Xuemei Tang, Chengxi Yan, Jinghang Gu, Chu-Ren Huang",
        "summary": "Despite strong performance on many tasks, large language models (LLMs) show limited ability in historical and cultural reasoning, particularly in non-English contexts such as Chinese history. Taxonomic structures offer an effective mechanism to organize historical knowledge and improve understanding. However, manual taxonomy construction is costly and difficult to scale. Therefore, we propose \\textbf{CHisAgent}, a multi-agent LLM framework for historical taxonomy construction in ancient Chinese contexts. CHisAgent decomposes taxonomy construction into three role-specialized stages: a bottom-up \\textit{Inducer} that derives an initial hierarchy from raw historical corpora, a top-down \\textit{Expander} that introduces missing intermediate concepts using LLM world knowledge, and an evidence-guided \\textit{Enricher} that integrates external structured historical resources to ensure faithfulness. Using the \\textit{Twenty-Four Histories}, we construct a large-scale, domain-aware event taxonomy covering politics, military, diplomacy, and social life in ancient China. Extensive reference-free and reference-based evaluations demonstrate improved structural coherence and coverage, while further analysis shows that the resulting taxonomy supports cross-cultural alignment.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.287291",
        "filter_reason": "该论文提出了一个名为CHisAgent的多智能体LLM框架，包含Inducer、Expander和Enricher三个具有特定角色的智能体，它们通过协作（自底向上、自顶向下、证据引导）来完成分类法构建任务。这完全符合“多智能体：协作”的研究范围，且核心贡献在于智能体框架本身而非单纯的历史领域应用。"
    },
    {
        "index": "#44",
        "title": "FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse",
        "link": "/arxiv/2601.05505",
        "arxiv_id": "2601.05505",
        "authors": "Yubo Hou, Zhisheng Chen, Tao Wan, Zengchang Qin",
        "summary": "The stateless architecture of Large Language Models inherently lacks the mechanism to preserve dynamic context, compelling agents to redundantly reprocess history to maintain long-horizon autonomy. While latent memory offers a solution, current approaches are hindered by architectural segregation, relying on auxiliary encoders that decouple memory from the reasoning backbone. We propose FlashMem, a framework that distills intrinsic memory directly from transient reasoning states via computation reuse. Leveraging the property that internal representations uniquely encode input trajectories, FlashMem identifies the last hidden state as a sufficient statistic for the interaction history. This enables a Shared-KV Consolidator to synthesize memory by attending directly to the backbone's frozen cache, eliminating redundant re-parameterization. Furthermore, a parameter-free Cognitive Monitor leverages attention entropy to adaptively trigger consolidation only when high epistemic uncertainty is detected. Experiments demonstrate that FlashMem matches the performance of heavy baselines while reducing inference latency by 5 times, effectively bridging the gap between efficiency and persistent cognition.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.287716",
        "filter_reason": "论文提出了FlashMem框架，旨在解决LLM智能体在长期自主任务中缺乏动态上下文保存机制的问题，属于单智能体研究中的“记忆”范畴。虽然涉及推理延迟优化，但其核心在于通过计算重用提取内在记忆以增强智能体的持久认知能力，而非单纯的基础设施部署优化。"
    },
    {
        "index": "#45",
        "title": "MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards",
        "link": "/arxiv/2601.05488",
        "arxiv_id": "2601.05488",
        "authors": "Zhiyu Shen, Ziming Wu, Fuming Lai, Shaobing Lian, Yanghui Rao",
        "summary": "Maintaining consistency in long-term dialogues remains a fundamental challenge for LLMs, as standard retrieval mechanisms often fail to capture the temporal evolution of historical states. While memory-augmented frameworks offer a structured alternative, current systems rely on static prompting of closed-source models or suffer from ineffective training paradigms with sparse rewards. We introduce MemBuilder, a reinforcement learning framework that trains models to orchestrate multi-dimensional memory construction with attributed dense rewards. MemBuilder addresses two key challenges: (1) Sparse Trajectory-Level Rewards: we employ synthetic session-level question generation to provide dense intermediate rewards across extended trajectories; and (2) Multi-Dimensional Memory Attribution: we introduce contribution-aware gradient weighting that scales policy updates based on each component's downstream impact. Experimental results show that MemBuilder enables a 4B-parameter model to outperform state-of-the-art closed-source baselines, exhibiting strong generalization across long-term dialogue benchmarks.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.288156",
        "filter_reason": "该论文专注于LLM智能体的核心组件——长期记忆构建。它提出利用强化学习框架来训练模型构建多维记忆，属于单智能体研究中的“记忆”范畴，且涉及通过反馈进行自我完善，符合筛选标准。"
    },
    {
        "index": "#53",
        "title": "Lost in Execution: On the Multilingual Robustness of Tool Calling in Large Language Models",
        "link": "/arxiv/2601.05366",
        "arxiv_id": "2601.05366",
        "authors": "Zheng Luo, T Pranav Kutralingam, Ogochukwu N Okoani, Wanpeng Xu, Hua Wei, Xiyang Hu",
        "summary": "Large Language Models (LLMs) are increasingly deployed as agents that invoke external tools through structured function calls. While recent work reports strong tool-calling performance under standard English-centric evaluations, the robustness of tool calling under multilingual user interactions remains underexplored. In this work, we introduce MLCL, a diagnostic benchmark, and conduct a systematic evaluation of multilingual tool calling across Chinese, Hindi, and the low-resource language Igbo. Through fine-grained error analysis, we show that many failures occur despite correct intent understanding and tool selection. We identify parameter value language mismatch as a dominant failure mode, where models generate semantically appropriate parameter values in the user's language, violating language-invariant execution conventions. We further evaluate several inference-time system strategies and find that while these strategies substantially reduce language-induced execution errors, none of them can fully recover English-level performance.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-08",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.297186",
        "filter_reason": "该论文研究了大语言模型作为智能体调用外部工具的能力，属于单智能体研究中的“工具使用”范畴。虽然涉及多语言鲁棒性，但其核心是评估和改进智能体的工具调用能力，而非纯应用或纯推理。"
    },
    {
        "index": "#69",
        "title": "MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization",
        "link": "/arxiv/2601.05475",
        "arxiv_id": "2601.05475",
        "authors": "Jiefu Ou, Sapana Chaudhary, Kaj Bostrom, Nathaniel Weir, Shuai Zhang, Huzefa Rangwala, George Karypis",
        "summary": "Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we explore inference-time search algorithms that guide the LLM to discover better solutions through iterative refinement based on execution feedback. Our approach, called MaxCode unifies existing search methods under a max-reward reinforcement learning framework, making the observation and action-value functions modular for modification. To enhance the observation space, we integrate a natural language critique model that converts raw execution feedback into diagnostic insights about errors and performance bottlenecks, and the best-discounted reward seen so far. Together, these provide richer input to the code proposal function. To improve exploration during search, we train a generative reward-to-go model using action values from rollouts to rerank potential solutions. Testing on the KernelBench (CUDA) and PIE (C++) optimization benchmarks shows that MaxCode improves optimized code performance compared to baselines, achieving 20.3% and 10.1% relative improvements in absolute speedup value and relative speedup ranking, respectively.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.309893",
        "filter_reason": "该论文提出了一个基于强化学习搜索框架的代码优化方法，核心在于LLM通过执行反馈进行迭代细化和自我完善。其中集成了自然语言批判模型进行自我反思，并利用推理时搜索算法进行规划，符合单智能体中关于工具使用、自我反思和自我演化的定义。"
    },
    {
        "index": "#81",
        "title": "Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring",
        "link": "/arxiv/2601.05256",
        "arxiv_id": "2601.05256",
        "authors": "Eirini Baltzi, Tilemachos Moumouris, Athena Psalta, Vasileios Tsironis, Konstantinos Karantzalos",
        "summary": "Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separately. NAIAD introduces an agentic AI assistant that leverages Large Language Models (LLMs) and external analytical tools to deliver a holistic solution for inland water monitoring using Earth Observation (EO) data. Designed for both experts and non-experts, NAIAD provides a single-prompt interface that translates natural-language queries into actionable insights. Through Retrieval-Augmented Generation (RAG), LLM reasoning, external tool orchestration, computational graph execution, and agentic reflection, it retrieves and synthesizes knowledge from curated sources to produce tailored reports. The system integrates diverse tools for weather data, Sentinel-2 imagery, remote-sensing index computation (e.g., NDCI), chlorophyll-a estimation, and established platforms such as CyFi. Performance is evaluated using correctness and relevancy metrics, achieving over 77% and 85% respectively on a dedicated benchmark covering multiple user-expertise levels. Preliminary results show strong adaptability and robustness across query types. An ablation study on LLM backbones further highlights Gemma 3 (27B) and Qwen 2.5 (14B) as offering the best balance between computational efficiency and reasoning performance.",
        "subjects": "Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Information Retrieval",
        "date": "2025-10-20",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.320489",
        "filter_reason": "论文提出了 NAIAD 系统，明确描述了其作为“agentic AI assistant”的架构，涉及 LLM 推理、外部工具编排和智能体反思，符合单智能体中“工具使用”和“自我反思”的研究范围。尽管应用于内陆水监测领域，但其核心贡献在于智能体系统的设计与实现，而非单纯的应用效果展示。"
    },
    {
        "index": "#3",
        "title": "StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management",
        "link": "/arxiv/2601.05890",
        "arxiv_id": "2601.05890",
        "authors": "Ruizhe Zhang, Xinke Jiang, Zhibang Yang, Zhixin Zhang, Jiaran Gao, Yuzhen Xiao, Hongbin Lai, Xu Chu, Junfeng Zhao, Yasha Wang",
        "summary": "Multi-agent systems based on large language models, particularly centralized architectures, have recently shown strong potential for complex and knowledge-intensive tasks. However, central agents often suffer from unstable long-horizon collaboration due to the lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. To address both task-level memory inefficiency and the inability to reuse coordination experience, we propose StackPlanner, a hierarchical multi-agent framework with explicit memory control. StackPlanner addresses these challenges by decoupling high-level coordination from subtask execution with active task-level memory control, and by learning to retrieve and exploit reusable coordination experience via structured experience memory and reinforcement learning. Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of our approach in enabling reliable long-horizon multi-agent collaboration.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.360834",
        "filter_reason": "该论文提出了一个基于大语言模型的集中式分层多智能体框架，重点解决多智能体协作中的记忆管理和协调问题，属于多智能体与记忆机制的研究范畴。"
    },
    {
        "index": "#4",
        "title": "From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation",
        "link": "/arxiv/2601.05787",
        "arxiv_id": "2601.05787",
        "authors": "Zezhou Wang, Ziyun Zhang, Xiaoyi Zhang, Zhuzhong Qian, Yan Lu",
        "summary": "Vision-language models are increasingly deployed as computer-use agents (CUAs) that operate desktops and browsers. Top-performing CUAs are framework-based systems that decompose planning and execution, while end-to-end screenshot-to-action policies are easier to deploy but lag behind on benchmarks such as OSWorld-Verified. GUI datasets like OSWorld pose two bottlenecks: they expose only a few hundred interactive, verifiable tasks and environments, and expert trajectories must be gathered by interacting with these environments, making such data hard to scale. We therefore ask how reinforcement learning from verifiable rewards (RLVR) can best exploit a small pool of exist expert trajectories to train end-to-end policies. Naively mixing these off-policy traces into on-policy RLVR is brittle: even after format conversion, expert trajectories exhibit structural mismatch and distribution shift from the learner. We propose BEPA (Bi-Level Expert-to-Policy Assimilation), which turns static expert traces into policy-aligned guidance via self-rolled reachable trajectories under the base policy (LEVEL-1) and a per-task, dynamically updated cache used in RLVR (LEVEL-2). On OSWorld-Verified, BEPA improves UITARS1.5-7B success from 22.87% to 32.13% and raises a held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web. Our code and data are available at: https://github.com/LEON-gittech/Verl_GUI.git",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.361109",
        "filter_reason": "该论文专注于GUI智能体（计算机使用智能体），提出了通过强化学习和专家轨迹来增强智能体策略的方法。研究内容涉及智能体的规划、执行以及通过反馈进行自我完善，符合单智能体和自我演化的研究范围。尽管使用了视觉输入，但核心在于智能体的能力提升而非纯视觉模型研究。"
    },
    {
        "index": "#5",
        "title": "DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation",
        "link": "/arxiv/2601.05746",
        "arxiv_id": "2601.05746",
        "authors": "Zhenghao Li, Zhi Zheng, Wei Chen, Jielun Zhao, Yong Chen, Tong Xu, Enhong Chen",
        "summary": "Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.361391",
        "filter_reason": "论文明确提出了基于大语言模型的多智能体辩论框架，涉及多智能体之间的协作、通信以及工具使用，符合多智能体研究范围。"
    },
    {
        "index": "#16",
        "title": "Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models",
        "link": "/arxiv/2601.05570",
        "arxiv_id": "2601.05570",
        "authors": "Cooper Lin, Maohao Ran, Yanting Zhang, Zhenglin Wan, Hongwei Fan, Yibo Xu, Yike Guo, Wei Xue, Jun Song",
        "summary": "Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid \"Boy Scout\" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a \"transparency tax\" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general safety and professional utility, we introduce Crisis-Bench, a multi-agent Partially Observable Markov Decision Process (POMDP) that evaluates LLMs in high-stakes corporate crises. Spanning 80 diverse storylines across 8 industries, Crisis-Bench tasks an LLM-based Public Relations (PR) Agent with navigating a dynamic 7-day corporate crisis simulation while managing strictly separated Private and Public narrative states to enforce rigorous information asymmetry. Unlike traditional benchmarks that rely on static ground truths, we introduce the Adjudicator-Market Loop: a novel evaluation metric where public sentiment is adjudicated and translated into a simulated stock price, creating a realistic economic incentive structure. Our results expose a critical dichotomy: while some models capitulate to ethical concerns, others demonstrate the capacity for Machiavellian, legitimate strategic withholding in order to stabilize the simulated stock price. Crisis-Bench provides the first quantitative framework for assessing \"Reputation Management\" capabilities, arguing for a shift from rigid moral absolutism to context-aware professional alignment.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.364574",
        "filter_reason": "论文提出了Crisis-Bench，这是一个多智能体部分可观察马尔可夫决策过程（POMDP）基准测试，用于评估LLM智能体在动态危机模拟中的战略行为。该研究涉及智能体的规划、状态管理（记忆）以及与模拟环境的交互，符合单智能体和多智能体的研究范围。尽管涉及对齐讨论，但其核心贡献在于构建智能体评估框架而非单纯的对齐或应用研究。"
    },
    {
        "index": "#22",
        "title": "PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering",
        "link": "/arxiv/2601.05465",
        "arxiv_id": "2601.05465",
        "authors": "Yu Liu, Wenxiao Zhang, Cong Cao, Wenxuan Lu, Fangfang Yuan, Diandian Guo, Kun Peng, Qiang Sun, Kaiyan Zhang, Yanbing Liu, Jin B. Hong, Bowen Zhou, Zhiyuan Ma",
        "summary": "Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to resolve complex queries. However, reliable deployment is hindered by two obstacles. 1) Retrieval Collapse: iterative retrieval over large corpora fails to locate intermediate evidence containing bridge answers without reasoning-guided planning, causing downstream reasoning to collapse. 2) Learning Instability: end-to-end trajectory training suffers from weak credit assignment across reasoning chains and poor error localization across modules, causing overfitting to benchmark-specific heuristics that limit transferability and stability. To address these problems, we propose PRISMA, a decoupled RL-guided framework featuring a Plan-Retrieve-Inspect-Solve-Memoize architecture. PRISMA's strength lies in reasoning-guided collaboration: the Inspector provides reasoning-based feedback to refine the Planner's decomposition and fine-grained retrieval, while enforcing evidence-grounded reasoning in the Solver. We optimize individual agent capabilities via Two-Stage Group Relative Policy Optimization (GRPO). Stage I calibrates the Planner and Solver as specialized experts in planning and reasoning, while Stage II utilizes Observation-Aware Residual Policy Optimization (OARPO) to enhance the Inspector's ability to verify context and trigger targeted recovery. Experiments show that PRISMA achieves state-of-the-art performance on ten benchmarks and can be deployed efficiently in real-world scenarios.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.366566",
        "filter_reason": "论文提出了一个名为PRISMA的多智能体架构，包含Planner、Inspector和Solver等组件，明确涉及智能体间的协作与通信。同时，该架构涵盖了规划、记忆和自我反思等核心智能体特征，符合多智能体和单智能体的研究范围。"
    },
    {
        "index": "#28",
        "title": "Effects of personality steering on cooperative behavior in Large Language Model agents",
        "link": "/arxiv/2601.05302",
        "arxiv_id": "2601.05302",
        "authors": "Mizuki Sakai, Mizuki Yokoyama, Wakaba Tateishi, Genki Ichinose",
        "summary": "Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based on the Big Five framework, we first measure basic personality profiles of three models, GPT-3.5-turbo, GPT-4o, and GPT-5, using the Big Five Inventory. We then compare behavior under baseline and personality-informed conditions, and further analyze the effects of independently manipulating each personality dimension to extreme values. Our results show that agreeableness is the dominant factor promoting cooperation across all models, while other personality traits have limited impact. Explicit personality information increases cooperation but can also raise vulnerability to exploitation, particularly in earlier-generation models. In contrast, later-generation models exhibit more selective cooperation. These findings indicate that personality steering acts as a behavioral bias rather than a deterministic control mechanism.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-08",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.368201",
        "filter_reason": "该论文研究LLM智能体在重复囚徒困境博弈中的合作行为，属于多智能体协作与博弈的研究范畴，符合筛选条件。"
    },
    {
        "index": "#85",
        "title": "Over-Searching in Search-Augmented Large Language Models",
        "link": "/arxiv/2601.05503",
        "arxiv_id": "2601.05503",
        "authors": "Roy Xie, Deepak Gopinath, David Qiu, Dong Lin, Haitian Sun, Saloni Potdar, Bhuwan Dhingra",
        "summary": "Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.385161",
        "filter_reason": "该论文研究了搜索增强型LLM中的“过度搜索”问题，重点分析了模型何时以及如何“调用搜索工具”。这属于单智能体研究中的“工具使用”范畴，涉及智能体对工具调用的决策机制和优化。"
    },
    {
        "index": "#98",
        "title": "PRISM: Protocol Refinement through Intelligent Simulation Modeling",
        "link": "/arxiv/2601.05356",
        "arxiv_id": "2601.05356",
        "authors": "Brian Hsu, Priyanka V Setty, Rory M Butler, Ryan Lewis, Casey Stone, Rebecca Weinberg, Thomas Brettin, Rick Stevens, Ian Foster, Arvind Ramanathan",
        "summary": "Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.",
        "subjects": "Robotics, Artificial Intelligence, Multiagent Systems, Quantitative Methods",
        "date": "2026-01-08",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.389021",
        "filter_reason": "论文提出了PRISM框架，明确使用了基于语言模型的智能体来协同生成和完善实验步骤。文中涉及多智能体协作、规划与批判循环（自我反思）以及工具使用（协调机器人仪器），完全符合LLM智能体的研究范围。"
    },
    {
        "index": "#115",
        "title": "KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits",
        "link": "/arxiv/2601.05257",
        "arxiv_id": "2601.05257",
        "authors": "Hou-Wan Long, Yicheng Song, Zidong Wang, Tianshu Sun",
        "summary": "Sponsored search advertising (SSA) requires advertisers to constantly adjust keyword strategies. While bid adjustment and keyword generation are well-studied, keyword pruning-refining keyword sets to enhance campaign performance-remains under-explored. This paper addresses critical inefficiencies in current practices as evidenced by a dataset containing 0.5 million SSA records from a pharmaceutical advertiser on search engine Meituan, China's largest delivery platform. We propose KP-Agent, an LLM agentic system with domain tool set and a memory module. By modeling keyword pruning within a contextual bandit framework, KP-Agent generates code snippets to refine keyword sets through reinforcement learning. Experiments show KP-Agent improves cumulative profit by up to 49.28% over baselines.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-10-20",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.393746",
        "filter_reason": "论文提出了KP-Agent，这是一个包含领域工具集和记忆模块的LLM智能体系统。它利用LLM生成代码片段（工具使用）并结合上下文赌博机框架进行决策，符合单智能体研究范围中的“工具使用”和“记忆”特征。虽然应用于广告领域，但其核心贡献在于智能体架构与机制，而非纯应用。"
    },
    {
        "index": "#1",
        "title": "Conformity Dynamics in LLM Multi-Agent Systems: The Roles of Topology and Self-Social Weighting",
        "link": "/arxiv/2601.05606",
        "arxiv_id": "2601.05606",
        "authors": "Chen Han, Jin Tan, Bohan Yu, Wenzhen Zheng, Xijin Tang",
        "summary": "Large Language Models (LLMs) are increasingly instantiated as interacting agents in multi-agent systems (MAS), where collective decisions emerge through social interaction rather than independent reasoning. A fundamental yet underexplored mechanism in this process is conformity, the tendency of agents to align their judgments with prevailing group opinions. This paper presents a systematic study of how network topology shapes conformity dynamics in LLM-based MAS through a misinformation detection task. We introduce a confidence-normalized pooling rule that controls the trade-off between self-reliance and social influence, enabling comparisons between two canonical decision paradigms: Centralized Aggregation and Distributed Consensus. Experimental results demonstrate that network topology critically governs both the efficiency and robustness of collective judgments. Centralized structures enable immediate decisions but are sensitive to hub competence and exhibit same-model alignment biases. In contrast, distributed structures promote more robust consensus, while increased network connectivity speeds up convergence but also heightens the risk of wrong-but-sure cascades, in which agents converge on incorrect decisions with high confidence. These findings characterize the conformity dynamics in LLM-based MAS, clarifying how network topology and self-social weighting jointly shape the efficiency, robustness, and failure modes of collective decision-making.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-09",
        "category": "cs.MA",
        "crawl_time": "2026-01-13T12:06:36.688511",
        "filter_reason": "该论文明确研究了LLM多智能体系统（MAS）中的社会交互、从众动态、网络拓扑以及决策范式（集中式与分布式），属于多智能体协作与通信的研究范畴。"
    },
    {
        "index": "#3",
        "title": "EvidFuse: Writing-Time Evidence Learning for Consistent Text-Chart Data Reporting",
        "link": "/arxiv/2601.05487",
        "arxiv_id": "2601.05487",
        "authors": "Huanxiang Lin, Qianyue Wang, Jinwu Hu, Bailin Chen, Qing Du, Mingkui Tan",
        "summary": "Data-driven reports communicate decision-relevant insights by tightly interleaving narrative text with charts grounded in underlying tables. However, current LLM-based systems typically generate narratives and visualizations in staged pipelines, following either a text-first-graph-second or a graph-first-text-second paradigm. These designs often lead to chart-text inconsistency and insight freezing, where the intermediate evidence space becomes fixed and the model can no longer retrieve or construct new visual evidence as the narrative evolves, resulting in shallow and predefined analysis. To address the limitations, we propose \\textbf{EvidFuse}, a training-free multi-agent framework that enables writing-time text-chart interleaved generation for data-driven reports. EvidFuse decouples visualization analysis from long-form drafting via two collaborating components: a \\textbf{Data-Augmented Analysis Agent}, equipped with Exploratory Data Analysis (EDA)-derived knowledge and access to raw tables, and a \\textbf{Real-Time Evidence Construction Writer} that plans an outline and drafts the report while intermittently issuing fine-grained analysis requests. This design allows visual evidence to be constructed and incorporated exactly when the narrative requires it, directly constraining subsequent claims and enabling on-demand expansion of the evidence space. Experiments demonstrate that EvidFuse attains the top rank in both LLM-as-a-judge and human evaluations on chart quality, chart-text alignment, and report-level usefulness.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-09",
        "category": "cs.MA",
        "crawl_time": "2026-01-13T12:06:36.689051",
        "filter_reason": "该论文提出了EvidFuse，这是一个用于文本-图表生成的多智能体框架。它涉及两个协作组件（智能体）：数据增强分析智能体和实时证据构建编写器，展示了智能体协作、规划（大纲规划）和工具使用（访问原始表格）等核心智能体特征，符合多智能体协作的研究范围。"
    }
]