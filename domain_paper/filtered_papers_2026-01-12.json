[
    {
        "index": "#2",
        "title": "Chaining the Evidence: Robust Reinforcement Learning for Deep Search Agents with Citation-Aware Rubric Rewards",
        "link": "/arxiv/2601.06021",
        "arxiv_id": "2601.06021",
        "authors": "Jiajie Zhang, Xin Lv, Ling Feng, Lei Hou, Juanzi Li",
        "summary": "Reinforcement learning (RL) has emerged as a critical technique for enhancing LLM-based deep search agents. However, existing approaches primarily rely on binary outcome rewards, which fail to capture the comprehensiveness and factuality of agents' reasoning process, and often lead to undesirable behaviors such as shortcut exploitation and hallucinations. To address these limitations, we propose \\textbf{Citation-aware Rubric Rewards (CaRR)}, a fine-grained reward framework for deep search agents that emphasizes reasoning comprehensiveness, factual grounding, and evidence connectivity. CaRR decomposes complex questions into verifiable single-hop rubrics and requires agents to satisfy these rubrics by explicitly identifying hidden entities, supporting them with correct citations, and constructing complete evidence chains that link to the predicted answer. We further introduce \\textbf{Citation-aware Group Relative Policy Optimization (C-GRPO)}, which combines CaRR and outcome rewards for training robust deep search agents. Experiments show that C-GRPO consistently outperforms standard outcome-based RL baselines across multiple deep search benchmarks. Our analysis also validates that C-GRPO effectively discourages shortcut exploitation, promotes comprehensive, evidence-grounded reasoning, and exhibits strong generalization to open-ended deep research tasks. Our code and data are available at https://github.com/THUDM/CaRR.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.246335",
        "filter_reason": "论文明确研究基于LLM的深度搜索智能体，提出了一种强化学习框架来训练智能体进行证据链构建和推理，属于单智能体的工具使用与自我演化范畴，且不涉及被排除的纯应用或纯推理内容。"
    },
    {
        "index": "#5",
        "title": "Distilling Feedback into Memory-as-a-Tool",
        "link": "/arxiv/2601.05960",
        "arxiv_id": "2601.05960",
        "authors": "Víctor Gallego",
        "summary": "We propose a framework that amortizes the cost of inference-time reasoning by converting transient critiques into retrievable guidelines, through a file-based memory system and agent-controlled tool calls. We evaluate this method on the Rubric Feedback Bench, a novel dataset for rubric-based learning. Experiments demonstrate that our augmented LLMs rapidly match the performance of test-time refinement pipelines while drastically reducing inference cost.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.248256",
        "filter_reason": "论文明确提出了包含“基于文件的记忆系统”和“智能体控制的工具调用”的框架，涉及单智能体的记忆机制、工具使用以及通过反馈进行自我完善，符合LLM智能体的研究范围。"
    },
    {
        "index": "#6",
        "title": "Can We Predict Before Executing Machine Learning Agents?",
        "link": "/arxiv/2601.05930",
        "arxiv_id": "2601.05930",
        "authors": "Jingsheng Zheng, Jintian Zhang, Yujie Luo, Yuren Mao, Yunjun Gao, Lun Du, Huajun Chen, Ningyu Zhang",
        "summary": "Autonomous machine learning agents have revolutionized scientific discovery, yet they remain constrained by a Generate-Execute-Feedback paradigm. Previous approaches suffer from a severe Execution Bottleneck, as hypothesis evaluation relies strictly on expensive physical execution. To bypass these physical constraints, we internalize execution priors to substitute costly runtime checks with instantaneous predictive reasoning, drawing inspiration from World Models. In this work, we formalize the task of Data-centric Solution Preference and construct a comprehensive corpus of 18,438 pairwise comparisons. We demonstrate that LLMs exhibit significant predictive capabilities when primed with a Verified Data Analysis Report, achieving 61.5% accuracy and robust confidence calibration. Finally, we instantiate this framework in FOREAGENT, an agent that employs a Predict-then-Verify loop, achieving a 6x acceleration in convergence while surpassing execution-based baselines by +6%. Our code and dataset will be publicly available soon at https://github.com/zjunlp/predict-before-execute.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.248978",
        "filter_reason": "论文明确提出了名为 \"FOREAGENT\" 的智能体，旨在解决自主机器学习智能体中的“执行瓶颈”问题。该研究通过引入“预测-验证”循环来优化智能体的工作流，属于单智能体机制（规划与执行优化）的研究范畴。"
    },
    {
        "index": "#22",
        "title": "EnvScaler: Scaling Tool-Interactive Environments for LLM Agent via Programmatic Synthesis",
        "link": "/arxiv/2601.05808",
        "arxiv_id": "2601.05808",
        "authors": "Xiaoshuai Song, Haofei Chang, Guanting Dong, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen",
        "summary": "Large language models (LLMs) are expected to be trained to act as agents in various real-world environments, but this process relies on rich and varied tool-interaction sandboxes. However, access to real systems is often restricted; LLM-simulated environments are prone to hallucinations and inconsistencies; and manually built sandboxes are hard to scale. In this paper, we propose EnvScaler, an automated framework for scalable tool-interaction environments via programmatic synthesis. EnvScaler comprises two components. First, SkelBuilder constructs diverse environment skeletons through topic mining, logic modeling, and quality evaluation. Then, ScenGenerator generates multiple task scenarios and rule-based trajectory validation functions for each environment. With EnvScaler, we synthesize 191 environments and about 7K scenarios, and apply them to Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for Qwen3 series models. Results on three benchmarks show that EnvScaler significantly improves LLMs' ability to solve tasks in complex environments involving multi-turn, multi-tool interactions. We release our code and data at https://github.com/RUC-NLPIR/EnvScaler.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.267285",
        "filter_reason": "该论文专注于构建用于LLM智能体的工具交互环境，旨在通过程序化合成生成多样化的环境来训练智能体，提升其在复杂场景下的多轮、多工具交互能力，属于单智能体中的“工具使用”研究范畴。"
    },
    {
        "index": "#30",
        "title": "Stephanie2: Thinking, Waiting, and Making Decisions Like Humans in Step-by-Step AI Social Chat",
        "link": "/arxiv/2601.05657",
        "arxiv_id": "2601.05657",
        "authors": "Hao Yang, Hongyuan Lu, Dingkang Yang, Wenliang Yang, Peng Sun, Xiaochuan Zhang, Jun Xiao, Kefan He, Wai Lam, Yang Liu, Xinhua Zeng",
        "summary": "Instant-messaging human social chat typically progresses through a sequence of short messages. Existing step-by-step AI chatting systems typically split a one-shot generation into multiple messages and send them sequentially, but they lack an active waiting mechanism and exhibit unnatural message pacing. In order to address these issues, we propose Stephanie2, a novel next-generation step-wise decision-making dialogue agent. With active waiting and message-pace adaptation, Stephanie2 explicitly decides at each step whether to send or wait, and models latency as the sum of thinking time and typing time to achieve more natural pacing. We further introduce a time-window-based dual-agent dialogue system to generate pseudo dialogue histories for human and automatic evaluations. Experiments show that Stephanie2 clearly outperforms Stephanie1 on metrics such as naturalness and engagement, and achieves a higher pass rate on human evaluation with the role identification Turing test.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.276248",
        "filter_reason": "论文提出了一个具有分步决策能力的对话智能体，能够主动决定发送消息还是等待，并模拟思考时间，涉及单智能体的决策机制以及双智能体系统的交互，符合LLM智能体的研究范围。"
    },
    {
        "index": "#33",
        "title": "GIFT: Games as Informal Training for Generalizable LLMs",
        "link": "/arxiv/2601.05633",
        "arxiv_id": "2601.05633",
        "authors": "Nuoyan Lyu, Bingbing Xu, Weihao Meng, Yige Yuan, Yang Zhang, Zhiyong Huang, Tat-Seng Chua, Huawei Shen",
        "summary": "While Large Language Models (LLMs) have achieved remarkable success in formal learning tasks such as mathematics and code generation, they still struggle with the \"practical wisdom\" and generalizable intelligence, such as strategic creativity and social reasoning, that characterize human cognition. This gap arises from a lack of informal learning, which thrives on interactive feedback rather than goal-oriented instruction. In this paper, we propose treating Games as a primary environment for LLM informal learning, leveraging their intrinsic reward signals and abstracted complexity to cultivate diverse competencies. To address the performance degradation observed in multi-task learning, we introduce a Nested Training Framework. Unlike naive task mixing optimizing an implicit \"OR\" objective, our framework employs sequential task composition to enforce an explicit \"AND\" objective, compelling the model to master multiple abilities simultaneously to achieve maximal rewards. Using GRPO-based reinforcement learning across Matrix Games, TicTacToe, and Who's the Spy games, we demonstrate that integrating game-based informal learning not only prevents task interference but also significantly bolsters the model's generalization across broad ability-oriented benchmarks. The framework and implementation are publicly available.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.277663",
        "filter_reason": "论文利用游戏（如矩阵博弈、井字棋、谁是卧底）作为环境，通过强化学习（GRPO）训练LLM的战略创造力和社会推理能力，涉及多智能体博弈与通过反馈自我完善，符合“多智能体：博弈”及“自我演化”的研究范围。"
    },
    {
        "index": "#39",
        "title": "Generation-Based and Emotion-Reflected Memory Update: Creating the KEEM Dataset for Better Long-Term Conversation",
        "link": "/arxiv/2601.05548",
        "arxiv_id": "2601.05548",
        "authors": "Jeonghyun Kang, Hongjin Kim, Harksoo Kim",
        "summary": "In this work, we introduce the Keep Emotional and Essential Memory (KEEM) dataset, a novel generation-based dataset designed to enhance memory updates in long-term conversational systems. Unlike existing approaches that rely on simple accumulation or operation-based methods, which often result in information conflicts and difficulties in accurately tracking a user's current state, KEEM dynamically generates integrative memories. This process not only preserves essential factual information but also incorporates emotional context and causal relationships, enabling a more nuanced understanding of user interactions. By seamlessly updating a system's memory with both emotional and essential data, our approach promotes deeper empathy and enhances the system's ability to respond meaningfully in open-domain conversations.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.280332",
        "filter_reason": "论文专注于长期对话系统中的记忆更新机制，提出了动态生成整合记忆的方法。记忆是LLM智能体的核心组件之一（属于单智能体研究范围中的“记忆”），该研究旨在提升智能体在长期交互中跟踪用户状态和情感语境的能力，符合筛选条件。"
    },
    {
        "index": "#43",
        "title": "CHisAgent: A Multi-Agent Framework for Event Taxonomy Construction in Ancient Chinese Cultural Systems",
        "link": "/arxiv/2601.05520",
        "arxiv_id": "2601.05520",
        "authors": "Xuemei Tang, Chengxi Yan, Jinghang Gu, Chu-Ren Huang",
        "summary": "Despite strong performance on many tasks, large language models (LLMs) show limited ability in historical and cultural reasoning, particularly in non-English contexts such as Chinese history. Taxonomic structures offer an effective mechanism to organize historical knowledge and improve understanding. However, manual taxonomy construction is costly and difficult to scale. Therefore, we propose \\textbf{CHisAgent}, a multi-agent LLM framework for historical taxonomy construction in ancient Chinese contexts. CHisAgent decomposes taxonomy construction into three role-specialized stages: a bottom-up \\textit{Inducer} that derives an initial hierarchy from raw historical corpora, a top-down \\textit{Expander} that introduces missing intermediate concepts using LLM world knowledge, and an evidence-guided \\textit{Enricher} that integrates external structured historical resources to ensure faithfulness. Using the \\textit{Twenty-Four Histories}, we construct a large-scale, domain-aware event taxonomy covering politics, military, diplomacy, and social life in ancient China. Extensive reference-free and reference-based evaluations demonstrate improved structural coherence and coverage, while further analysis shows that the resulting taxonomy supports cross-cultural alignment.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.287291",
        "filter_reason": "该论文提出了一个名为CHisAgent的多智能体LLM框架，包含Inducer、Expander和Enricher三个具有特定角色的智能体，它们通过协作（自底向上、自顶向下、证据引导）来完成分类法构建任务。这完全符合“多智能体：协作”的研究范围，且核心贡献在于智能体框架本身而非单纯的历史领域应用。"
    },
    {
        "index": "#44",
        "title": "FlashMem: Distilling Intrinsic Latent Memory via Computation Reuse",
        "link": "/arxiv/2601.05505",
        "arxiv_id": "2601.05505",
        "authors": "Yubo Hou, Zhisheng Chen, Tao Wan, Zengchang Qin",
        "summary": "The stateless architecture of Large Language Models inherently lacks the mechanism to preserve dynamic context, compelling agents to redundantly reprocess history to maintain long-horizon autonomy. While latent memory offers a solution, current approaches are hindered by architectural segregation, relying on auxiliary encoders that decouple memory from the reasoning backbone. We propose FlashMem, a framework that distills intrinsic memory directly from transient reasoning states via computation reuse. Leveraging the property that internal representations uniquely encode input trajectories, FlashMem identifies the last hidden state as a sufficient statistic for the interaction history. This enables a Shared-KV Consolidator to synthesize memory by attending directly to the backbone's frozen cache, eliminating redundant re-parameterization. Furthermore, a parameter-free Cognitive Monitor leverages attention entropy to adaptively trigger consolidation only when high epistemic uncertainty is detected. Experiments demonstrate that FlashMem matches the performance of heavy baselines while reducing inference latency by 5 times, effectively bridging the gap between efficiency and persistent cognition.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.287716",
        "filter_reason": "论文提出了FlashMem框架，旨在解决LLM智能体在长期自主任务中缺乏动态上下文保存机制的问题，属于单智能体研究中的“记忆”范畴。虽然涉及推理延迟优化，但其核心在于通过计算重用提取内在记忆以增强智能体的持久认知能力，而非单纯的基础设施部署优化。"
    },
    {
        "index": "#45",
        "title": "MemBuilder: Reinforcing LLMs for Long-Term Memory Construction via Attributed Dense Rewards",
        "link": "/arxiv/2601.05488",
        "arxiv_id": "2601.05488",
        "authors": "Zhiyu Shen, Ziming Wu, Fuming Lai, Shaobing Lian, Yanghui Rao",
        "summary": "Maintaining consistency in long-term dialogues remains a fundamental challenge for LLMs, as standard retrieval mechanisms often fail to capture the temporal evolution of historical states. While memory-augmented frameworks offer a structured alternative, current systems rely on static prompting of closed-source models or suffer from ineffective training paradigms with sparse rewards. We introduce MemBuilder, a reinforcement learning framework that trains models to orchestrate multi-dimensional memory construction with attributed dense rewards. MemBuilder addresses two key challenges: (1) Sparse Trajectory-Level Rewards: we employ synthetic session-level question generation to provide dense intermediate rewards across extended trajectories; and (2) Multi-Dimensional Memory Attribution: we introduce contribution-aware gradient weighting that scales policy updates based on each component's downstream impact. Experimental results show that MemBuilder enables a 4B-parameter model to outperform state-of-the-art closed-source baselines, exhibiting strong generalization across long-term dialogue benchmarks.",
        "subjects": "Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.288156",
        "filter_reason": "该论文专注于LLM智能体的核心组件——长期记忆构建。它提出利用强化学习框架来训练模型构建多维记忆，属于单智能体研究中的“记忆”范畴，且涉及通过反馈进行自我完善，符合筛选标准。"
    },
    {
        "index": "#53",
        "title": "Lost in Execution: On the Multilingual Robustness of Tool Calling in Large Language Models",
        "link": "/arxiv/2601.05366",
        "arxiv_id": "2601.05366",
        "authors": "Zheng Luo, T Pranav Kutralingam, Ogochukwu N Okoani, Wanpeng Xu, Hua Wei, Xiyang Hu",
        "summary": "Large Language Models (LLMs) are increasingly deployed as agents that invoke external tools through structured function calls. While recent work reports strong tool-calling performance under standard English-centric evaluations, the robustness of tool calling under multilingual user interactions remains underexplored. In this work, we introduce MLCL, a diagnostic benchmark, and conduct a systematic evaluation of multilingual tool calling across Chinese, Hindi, and the low-resource language Igbo. Through fine-grained error analysis, we show that many failures occur despite correct intent understanding and tool selection. We identify parameter value language mismatch as a dominant failure mode, where models generate semantically appropriate parameter values in the user's language, violating language-invariant execution conventions. We further evaluate several inference-time system strategies and find that while these strategies substantially reduce language-induced execution errors, none of them can fully recover English-level performance.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2026-01-08",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.297186",
        "filter_reason": "该论文研究了大语言模型作为智能体调用外部工具的能力，属于单智能体研究中的“工具使用”范畴。虽然涉及多语言鲁棒性，但其核心是评估和改进智能体的工具调用能力，而非纯应用或纯推理。"
    },
    {
        "index": "#69",
        "title": "MaxCode: A Max-Reward Reinforcement Learning Framework for Automated Code Optimization",
        "link": "/arxiv/2601.05475",
        "arxiv_id": "2601.05475",
        "authors": "Jiefu Ou, Sapana Chaudhary, Kaj Bostrom, Nathaniel Weir, Shuai Zhang, Huzefa Rangwala, George Karypis",
        "summary": "Large Language Models (LLMs) demonstrate strong capabilities in general coding tasks but encounter two key challenges when optimizing code: (i) the complexity of writing optimized code (such as performant CUDA kernels and competition-level CPU code) requires expertise in systems, algorithms and specific languages and (ii) requires interpretation of performance metrics like timing and device utilization beyond binary correctness. In this work, we explore inference-time search algorithms that guide the LLM to discover better solutions through iterative refinement based on execution feedback. Our approach, called MaxCode unifies existing search methods under a max-reward reinforcement learning framework, making the observation and action-value functions modular for modification. To enhance the observation space, we integrate a natural language critique model that converts raw execution feedback into diagnostic insights about errors and performance bottlenecks, and the best-discounted reward seen so far. Together, these provide richer input to the code proposal function. To improve exploration during search, we train a generative reward-to-go model using action values from rollouts to rerank potential solutions. Testing on the KernelBench (CUDA) and PIE (C++) optimization benchmarks shows that MaxCode improves optimized code performance compared to baselines, achieving 20.3% and 10.1% relative improvements in absolute speedup value and relative speedup ranking, respectively.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.309893",
        "filter_reason": "该论文提出了一个基于强化学习搜索框架的代码优化方法，核心在于LLM通过执行反馈进行迭代细化和自我完善。其中集成了自然语言批判模型进行自我反思，并利用推理时搜索算法进行规划，符合单智能体中关于工具使用、自我反思和自我演化的定义。"
    },
    {
        "index": "#81",
        "title": "Naiad: Novel Agentic Intelligent Autonomous System for Inland Water Monitoring",
        "link": "/arxiv/2601.05256",
        "arxiv_id": "2601.05256",
        "authors": "Eirini Baltzi, Tilemachos Moumouris, Athena Psalta, Vasileios Tsironis, Konstantinos Karantzalos",
        "summary": "Inland water monitoring is vital for safeguarding public health and ecosystems, enabling timely interventions to mitigate risks. Existing methods often address isolated sub-problems such as cyanobacteria, chlorophyll, or other quality indicators separately. NAIAD introduces an agentic AI assistant that leverages Large Language Models (LLMs) and external analytical tools to deliver a holistic solution for inland water monitoring using Earth Observation (EO) data. Designed for both experts and non-experts, NAIAD provides a single-prompt interface that translates natural-language queries into actionable insights. Through Retrieval-Augmented Generation (RAG), LLM reasoning, external tool orchestration, computational graph execution, and agentic reflection, it retrieves and synthesizes knowledge from curated sources to produce tailored reports. The system integrates diverse tools for weather data, Sentinel-2 imagery, remote-sensing index computation (e.g., NDCI), chlorophyll-a estimation, and established platforms such as CyFi. Performance is evaluated using correctness and relevancy metrics, achieving over 77% and 85% respectively on a dedicated benchmark covering multiple user-expertise levels. Preliminary results show strong adaptability and robustness across query types. An ablation study on LLM backbones further highlights Gemma 3 (27B) and Qwen 2.5 (14B) as offering the best balance between computational efficiency and reasoning performance.",
        "subjects": "Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Information Retrieval",
        "date": "2025-10-20",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T12:06:35.320489",
        "filter_reason": "论文提出了 NAIAD 系统，明确描述了其作为“agentic AI assistant”的架构，涉及 LLM 推理、外部工具编排和智能体反思，符合单智能体中“工具使用”和“自我反思”的研究范围。尽管应用于内陆水监测领域，但其核心贡献在于智能体系统的设计与实现，而非单纯的应用效果展示。"
    },
    {
        "index": "#3",
        "title": "StackPlanner: A Centralized Hierarchical Multi-Agent System with Task-Experience Memory Management",
        "link": "/arxiv/2601.05890",
        "arxiv_id": "2601.05890",
        "authors": "Ruizhe Zhang, Xinke Jiang, Zhibang Yang, Zhixin Zhang, Jiaran Gao, Yuzhen Xiao, Hongbin Lai, Xu Chu, Junfeng Zhao, Yasha Wang",
        "summary": "Multi-agent systems based on large language models, particularly centralized architectures, have recently shown strong potential for complex and knowledge-intensive tasks. However, central agents often suffer from unstable long-horizon collaboration due to the lack of memory management, leading to context bloat, error accumulation, and poor cross-task generalization. To address both task-level memory inefficiency and the inability to reuse coordination experience, we propose StackPlanner, a hierarchical multi-agent framework with explicit memory control. StackPlanner addresses these challenges by decoupling high-level coordination from subtask execution with active task-level memory control, and by learning to retrieve and exploit reusable coordination experience via structured experience memory and reinforcement learning. Experiments on multiple deep-search and agent system benchmarks demonstrate the effectiveness of our approach in enabling reliable long-horizon multi-agent collaboration.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.360834",
        "filter_reason": "该论文提出了一个基于大语言模型的集中式分层多智能体框架，重点解决多智能体协作中的记忆管理和协调问题，属于多智能体与记忆机制的研究范畴。"
    },
    {
        "index": "#4",
        "title": "From Off-Policy to On-Policy: Enhancing GUI Agents via Bi-level Expert-to-Policy Assimilation",
        "link": "/arxiv/2601.05787",
        "arxiv_id": "2601.05787",
        "authors": "Zezhou Wang, Ziyun Zhang, Xiaoyi Zhang, Zhuzhong Qian, Yan Lu",
        "summary": "Vision-language models are increasingly deployed as computer-use agents (CUAs) that operate desktops and browsers. Top-performing CUAs are framework-based systems that decompose planning and execution, while end-to-end screenshot-to-action policies are easier to deploy but lag behind on benchmarks such as OSWorld-Verified. GUI datasets like OSWorld pose two bottlenecks: they expose only a few hundred interactive, verifiable tasks and environments, and expert trajectories must be gathered by interacting with these environments, making such data hard to scale. We therefore ask how reinforcement learning from verifiable rewards (RLVR) can best exploit a small pool of exist expert trajectories to train end-to-end policies. Naively mixing these off-policy traces into on-policy RLVR is brittle: even after format conversion, expert trajectories exhibit structural mismatch and distribution shift from the learner. We propose BEPA (Bi-Level Expert-to-Policy Assimilation), which turns static expert traces into policy-aligned guidance via self-rolled reachable trajectories under the base policy (LEVEL-1) and a per-task, dynamically updated cache used in RLVR (LEVEL-2). On OSWorld-Verified, BEPA improves UITARS1.5-7B success from 22.87% to 32.13% and raises a held-out split from 5.74% to 10.30%, with consistent gains on MMBench-GUI and Online-Mind2Web. Our code and data are available at: https://github.com/LEON-gittech/Verl_GUI.git",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.361109",
        "filter_reason": "该论文专注于GUI智能体（计算机使用智能体），提出了通过强化学习和专家轨迹来增强智能体策略的方法。研究内容涉及智能体的规划、执行以及通过反馈进行自我完善，符合单智能体和自我演化的研究范围。尽管使用了视觉输入，但核心在于智能体的能力提升而非纯视觉模型研究。"
    },
    {
        "index": "#5",
        "title": "DynaDebate: Breaking Homogeneity in Multi-Agent Debate with Dynamic Path Generation",
        "link": "/arxiv/2601.05746",
        "arxiv_id": "2601.05746",
        "authors": "Zhenghao Li, Zhi Zheng, Wei Chen, Jielun Zhao, Yong Chen, Tong Xu, Enhong Chen",
        "summary": "Recent years have witnessed the rapid development of Large Language Model-based Multi-Agent Systems (MAS), which excel at collaborative decision-making and complex problem-solving. Recently, researchers have further investigated Multi-Agent Debate (MAD) frameworks, which enhance the reasoning and collaboration capabilities of MAS through information exchange and debate among multiple agents. However, existing approaches often rely on unguided initialization, causing agents to adopt identical reasoning paths that lead to the same errors. As a result, effective debate among agents is hindered, and the final outcome frequently degenerates into simple majority voting. To solve the above problem, in this paper, we introduce Dynamic Multi-Agent Debate (DynaDebate), which enhances the effectiveness of multi-agent debate through three key mechanisms: (1) Dynamic Path Generation and Allocation, which employs a dedicated Path Generation Agent to generate diverse and logical solution paths with adaptive redundancy; (2) Process-Centric Debate, which shifts the focus from surface-level outcome voting to rigorous step-by-step logic critique to ensure process correctness; (3) A Trigger-Based Verification Agent, which is activated upon disagreement and uses external tools to objectively resolve deadlocks. Extensive experiments demonstrate that DynaDebate achieves superior performance across various benchmarks, surpassing existing state-of-the-art MAD methods.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.361391",
        "filter_reason": "论文明确提出了基于大语言模型的多智能体辩论框架，涉及多智能体之间的协作、通信以及工具使用，符合多智能体研究范围。"
    },
    {
        "index": "#16",
        "title": "Crisis-Bench: Benchmarking Strategic Ambiguity and Reputation Management in Large Language Models",
        "link": "/arxiv/2601.05570",
        "arxiv_id": "2601.05570",
        "authors": "Cooper Lin, Maohao Ran, Yanting Zhang, Zhenglin Wan, Hongwei Fan, Yibo Xu, Yike Guo, Wei Xue, Jun Song",
        "summary": "Standard safety alignment optimizes Large Language Models (LLMs) for universal helpfulness and honesty, effectively instilling a rigid \"Boy Scout\" morality. While robust for general-purpose assistants, this one-size-fits-all ethical framework imposes a \"transparency tax\" on professional domains requiring strategic ambiguity and information withholding, such as public relations, negotiation, and crisis management. To measure this gap between general safety and professional utility, we introduce Crisis-Bench, a multi-agent Partially Observable Markov Decision Process (POMDP) that evaluates LLMs in high-stakes corporate crises. Spanning 80 diverse storylines across 8 industries, Crisis-Bench tasks an LLM-based Public Relations (PR) Agent with navigating a dynamic 7-day corporate crisis simulation while managing strictly separated Private and Public narrative states to enforce rigorous information asymmetry. Unlike traditional benchmarks that rely on static ground truths, we introduce the Adjudicator-Market Loop: a novel evaluation metric where public sentiment is adjudicated and translated into a simulated stock price, creating a realistic economic incentive structure. Our results expose a critical dichotomy: while some models capitulate to ethical concerns, others demonstrate the capacity for Machiavellian, legitimate strategic withholding in order to stabilize the simulated stock price. Crisis-Bench provides the first quantitative framework for assessing \"Reputation Management\" capabilities, arguing for a shift from rigid moral absolutism to context-aware professional alignment.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.364574",
        "filter_reason": "论文提出了Crisis-Bench，这是一个多智能体部分可观察马尔可夫决策过程（POMDP）基准测试，用于评估LLM智能体在动态危机模拟中的战略行为。该研究涉及智能体的规划、状态管理（记忆）以及与模拟环境的交互，符合单智能体和多智能体的研究范围。尽管涉及对齐讨论，但其核心贡献在于构建智能体评估框架而非单纯的对齐或应用研究。"
    },
    {
        "index": "#22",
        "title": "PRISMA: Reinforcement Learning Guided Two-Stage Policy Optimization in Multi-Agent Architecture for Open-Domain Multi-Hop Question Answering",
        "link": "/arxiv/2601.05465",
        "arxiv_id": "2601.05465",
        "authors": "Yu Liu, Wenxiao Zhang, Cong Cao, Wenxuan Lu, Fangfang Yuan, Diandian Guo, Kun Peng, Qiang Sun, Kaiyan Zhang, Yanbing Liu, Jin B. Hong, Bowen Zhou, Zhiyuan Ma",
        "summary": "Answering real-world open-domain multi-hop questions over massive corpora is a critical challenge in Retrieval-Augmented Generation (RAG) systems. Recent research employs reinforcement learning (RL) to end-to-end optimize the retrieval-augmented reasoning process, directly enhancing its capacity to resolve complex queries. However, reliable deployment is hindered by two obstacles. 1) Retrieval Collapse: iterative retrieval over large corpora fails to locate intermediate evidence containing bridge answers without reasoning-guided planning, causing downstream reasoning to collapse. 2) Learning Instability: end-to-end trajectory training suffers from weak credit assignment across reasoning chains and poor error localization across modules, causing overfitting to benchmark-specific heuristics that limit transferability and stability. To address these problems, we propose PRISMA, a decoupled RL-guided framework featuring a Plan-Retrieve-Inspect-Solve-Memoize architecture. PRISMA's strength lies in reasoning-guided collaboration: the Inspector provides reasoning-based feedback to refine the Planner's decomposition and fine-grained retrieval, while enforcing evidence-grounded reasoning in the Solver. We optimize individual agent capabilities via Two-Stage Group Relative Policy Optimization (GRPO). Stage I calibrates the Planner and Solver as specialized experts in planning and reasoning, while Stage II utilizes Observation-Aware Residual Policy Optimization (OARPO) to enhance the Inspector's ability to verify context and trigger targeted recovery. Experiments show that PRISMA achieves state-of-the-art performance on ten benchmarks and can be deployed efficiently in real-world scenarios.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.366566",
        "filter_reason": "论文提出了一个名为PRISMA的多智能体架构，包含Planner、Inspector和Solver等组件，明确涉及智能体间的协作与通信。同时，该架构涵盖了规划、记忆和自我反思等核心智能体特征，符合多智能体和单智能体的研究范围。"
    },
    {
        "index": "#28",
        "title": "Effects of personality steering on cooperative behavior in Large Language Model agents",
        "link": "/arxiv/2601.05302",
        "arxiv_id": "2601.05302",
        "authors": "Mizuki Sakai, Mizuki Yokoyama, Wakaba Tateishi, Genki Ichinose",
        "summary": "Large language models (LLMs) are increasingly used as autonomous agents in strategic and social interactions. Although recent studies suggest that assigning personality traits to LLMs can influence their behavior, how personality steering affects cooperation under controlled conditions remains unclear. In this study, we examine the effects of personality steering on cooperative behavior in LLM agents using repeated Prisoner's Dilemma games. Based on the Big Five framework, we first measure basic personality profiles of three models, GPT-3.5-turbo, GPT-4o, and GPT-5, using the Big Five Inventory. We then compare behavior under baseline and personality-informed conditions, and further analyze the effects of independently manipulating each personality dimension to extreme values. Our results show that agreeableness is the dominant factor promoting cooperation across all models, while other personality traits have limited impact. Explicit personality information increases cooperation but can also raise vulnerability to exploitation, particularly in earlier-generation models. In contrast, later-generation models exhibit more selective cooperation. These findings indicate that personality steering acts as a behavioral bias rather than a deterministic control mechanism.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-08",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.368201",
        "filter_reason": "该论文研究LLM智能体在重复囚徒困境博弈中的合作行为，属于多智能体协作与博弈的研究范畴，符合筛选条件。"
    },
    {
        "index": "#85",
        "title": "Over-Searching in Search-Augmented Large Language Models",
        "link": "/arxiv/2601.05503",
        "arxiv_id": "2601.05503",
        "authors": "Roy Xie, Deepak Gopinath, David Qiu, Dong Lin, Haitian Sun, Saloni Potdar, Bhuwan Dhingra",
        "summary": "Search-augmented large language models (LLMs) excel at knowledge-intensive tasks by integrating external retrieval. However, they often over-search -- unnecessarily invoking search tool even when it does not improve response quality, which leads to computational inefficiency and hallucinations by incorporating irrelevant context. In this work, we conduct a systematic evaluation of over-searching across multiple dimensions, including query types, model categories, retrieval conditions, and multi-turn conversations. Our finding shows: (i) search generally improves answer accuracy on answerable queries but harms abstention on unanswerable ones; (ii) over-searching is more pronounced in complex reasoning models and deep research systems, is exacerbated by noisy retrieval, and compounds across turns in multi-turn conversations; and (iii) the composition of retrieved evidence is crucial, as the presence of negative evidence improves abstention. To quantify over-searching, we introduce Tokens Per Correctness (TPC), an evaluation metric that captures the performance-cost trade-off for search-augmented LLMs. Lastly, we investigate mitigation approaches at both the query and retrieval levels and release the OverSearchQA to foster continued research into efficient search-augmented LLMs.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.385161",
        "filter_reason": "该论文研究了搜索增强型LLM中的“过度搜索”问题，重点分析了模型何时以及如何“调用搜索工具”。这属于单智能体研究中的“工具使用”范畴，涉及智能体对工具调用的决策机制和优化。"
    },
    {
        "index": "#98",
        "title": "PRISM: Protocol Refinement through Intelligent Simulation Modeling",
        "link": "/arxiv/2601.05356",
        "arxiv_id": "2601.05356",
        "authors": "Brian Hsu, Priyanka V Setty, Rory M Butler, Ryan Lewis, Casey Stone, Rebecca Weinberg, Thomas Brettin, Rick Stevens, Ian Foster, Arvind Ramanathan",
        "summary": "Automating experimental protocol design and execution remains as a fundamental bottleneck in realizing self-driving laboratories. We introduce PRISM (Protocol Refinement through Intelligent Simulation Modeling), a framework that automates the design, validation, and execution of experimental protocols on a laboratory platform composed of off-the-shelf robotic instruments. PRISM uses a set of language-model-based agents that work together to generate and refine experimental steps. The process begins with automatically gathering relevant procedures from web-based sources describing experimental workflows. These are converted into structured experimental steps (e.g., liquid handling steps, deck layout and other related operations) through a planning, critique, and validation loop. The finalized steps are translated into the Argonne MADSci protocol format, which provides a unified interface for coordinating multiple robotic instruments (Opentrons OT-2 liquid handler, PF400 arm, Azenta plate sealer and peeler) without requiring human intervention between steps. To evaluate protocol-generation performance, we benchmarked both single reasoning models and multi-agent workflow across constrained and open-ended prompting paradigms. The resulting protocols were validated in a digital-twin environment built in NVIDIA Omniverse to detect physical or sequencing errors before execution. Using Luna qPCR amplification and Cell Painting as case studies, we demonstrate PRISM as a practical end-to-end workflow that bridges language-based protocol generation, simulation-based validation, and automated robotic execution.",
        "subjects": "Robotics, Artificial Intelligence, Multiagent Systems, Quantitative Methods",
        "date": "2026-01-08",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.389021",
        "filter_reason": "论文提出了PRISM框架，明确使用了基于语言模型的智能体来协同生成和完善实验步骤。文中涉及多智能体协作、规划与批判循环（自我反思）以及工具使用（协调机器人仪器），完全符合LLM智能体的研究范围。"
    },
    {
        "index": "#115",
        "title": "KP-Agent: Keyword Pruning in Sponsored Search Advertising via LLM-Powered Contextual Bandits",
        "link": "/arxiv/2601.05257",
        "arxiv_id": "2601.05257",
        "authors": "Hou-Wan Long, Yicheng Song, Zidong Wang, Tianshu Sun",
        "summary": "Sponsored search advertising (SSA) requires advertisers to constantly adjust keyword strategies. While bid adjustment and keyword generation are well-studied, keyword pruning-refining keyword sets to enhance campaign performance-remains under-explored. This paper addresses critical inefficiencies in current practices as evidenced by a dataset containing 0.5 million SSA records from a pharmaceutical advertiser on search engine Meituan, China's largest delivery platform. We propose KP-Agent, an LLM agentic system with domain tool set and a memory module. By modeling keyword pruning within a contextual bandit framework, KP-Agent generates code snippets to refine keyword sets through reinforcement learning. Experiments show KP-Agent improves cumulative profit by up to 49.28% over baselines.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-10-20",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T12:06:35.393746",
        "filter_reason": "论文提出了KP-Agent，这是一个包含领域工具集和记忆模块的LLM智能体系统。它利用LLM生成代码片段（工具使用）并结合上下文赌博机框架进行决策，符合单智能体研究范围中的“工具使用”和“记忆”特征。虽然应用于广告领域，但其核心贡献在于智能体架构与机制，而非纯应用。"
    },
    {
        "index": "#1",
        "title": "Conformity Dynamics in LLM Multi-Agent Systems: The Roles of Topology and Self-Social Weighting",
        "link": "/arxiv/2601.05606",
        "arxiv_id": "2601.05606",
        "authors": "Chen Han, Jin Tan, Bohan Yu, Wenzhen Zheng, Xijin Tang",
        "summary": "Large Language Models (LLMs) are increasingly instantiated as interacting agents in multi-agent systems (MAS), where collective decisions emerge through social interaction rather than independent reasoning. A fundamental yet underexplored mechanism in this process is conformity, the tendency of agents to align their judgments with prevailing group opinions. This paper presents a systematic study of how network topology shapes conformity dynamics in LLM-based MAS through a misinformation detection task. We introduce a confidence-normalized pooling rule that controls the trade-off between self-reliance and social influence, enabling comparisons between two canonical decision paradigms: Centralized Aggregation and Distributed Consensus. Experimental results demonstrate that network topology critically governs both the efficiency and robustness of collective judgments. Centralized structures enable immediate decisions but are sensitive to hub competence and exhibit same-model alignment biases. In contrast, distributed structures promote more robust consensus, while increased network connectivity speeds up convergence but also heightens the risk of wrong-but-sure cascades, in which agents converge on incorrect decisions with high confidence. These findings characterize the conformity dynamics in LLM-based MAS, clarifying how network topology and self-social weighting jointly shape the efficiency, robustness, and failure modes of collective decision-making.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-09",
        "category": "cs.MA",
        "crawl_time": "2026-01-13T12:06:36.688511",
        "filter_reason": "该论文明确研究了LLM多智能体系统（MAS）中的社会交互、从众动态、网络拓扑以及决策范式（集中式与分布式），属于多智能体协作与通信的研究范畴。"
    },
    {
        "index": "#3",
        "title": "EvidFuse: Writing-Time Evidence Learning for Consistent Text-Chart Data Reporting",
        "link": "/arxiv/2601.05487",
        "arxiv_id": "2601.05487",
        "authors": "Huanxiang Lin, Qianyue Wang, Jinwu Hu, Bailin Chen, Qing Du, Mingkui Tan",
        "summary": "Data-driven reports communicate decision-relevant insights by tightly interleaving narrative text with charts grounded in underlying tables. However, current LLM-based systems typically generate narratives and visualizations in staged pipelines, following either a text-first-graph-second or a graph-first-text-second paradigm. These designs often lead to chart-text inconsistency and insight freezing, where the intermediate evidence space becomes fixed and the model can no longer retrieve or construct new visual evidence as the narrative evolves, resulting in shallow and predefined analysis. To address the limitations, we propose \\textbf{EvidFuse}, a training-free multi-agent framework that enables writing-time text-chart interleaved generation for data-driven reports. EvidFuse decouples visualization analysis from long-form drafting via two collaborating components: a \\textbf{Data-Augmented Analysis Agent}, equipped with Exploratory Data Analysis (EDA)-derived knowledge and access to raw tables, and a \\textbf{Real-Time Evidence Construction Writer} that plans an outline and drafts the report while intermittently issuing fine-grained analysis requests. This design allows visual evidence to be constructed and incorporated exactly when the narrative requires it, directly constraining subsequent claims and enabling on-demand expansion of the evidence space. Experiments demonstrate that EvidFuse attains the top rank in both LLM-as-a-judge and human evaluations on chart quality, chart-text alignment, and report-level usefulness.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-09",
        "category": "cs.MA",
        "crawl_time": "2026-01-13T12:06:36.689051",
        "filter_reason": "该论文提出了EvidFuse，这是一个用于文本-图表生成的多智能体框架。它涉及两个协作组件（智能体）：数据增强分析智能体和实时证据构建编写器，展示了智能体协作、规划（大纲规划）和工具使用（访问原始表格）等核心智能体特征，符合多智能体协作的研究范围。"
    },
    {
        "index": "#5",
        "title": "Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning",
        "link": "/arxiv/2601.07782",
        "arxiv_id": "2601.07782",
        "authors": "Wei Fang, James Glass",
        "summary": "LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.024286",
        "filter_reason": "该论文专注于LLM智能体的**工具使用**和**规划**能力。它提出了TOOLQP框架，通过将指令分解为子任务并动态生成查询来改进工具检索，直接属于单智能体的研究范围。"
    },
    {
        "index": "#9",
        "title": "Is Agentic RAG worth it? An experimental comparison of RAG approaches",
        "link": "/arxiv/2601.07711",
        "arxiv_id": "2601.07711",
        "authors": "Pietro Ferrazzi, Milica Cvjeticanin, Alessio Piraccini, Davide Giannuzzi",
        "summary": "Retrieval-Augmented Generation (RAG) systems are usually defined by the combination of a generator and a retrieval component that extracts textual context from a knowledge base to answer user queries. However, such basic implementations exhibit several limitations, including noisy or suboptimal retrieval, misuse of retrieval for out-of-scope queries, weak query-document matching, and variability or cost associated with the generator. These shortcomings have motivated the development of \"Enhanced\" RAG, where dedicated modules are introduced to address specific weaknesses in the workflow. More recently, the growing self-reflective capabilities of Large Language Models (LLMs) have enabled a new paradigm, which we refer to as \"Agentic\" RAG. In this approach, the LLM orchestrates the entire process-deciding which actions to perform, when to perform them, and whether to iterate-thereby reducing reliance on fixed, manually engineered modules. Despite the rapid adoption of both paradigms, it remains unclear which approach is preferable under which conditions. In this work, we conduct an extensive, empirically driven evaluation of Enhanced and Agentic RAG across multiple scenarios and dimensions. Our results provide practical insights into the trade-offs between the two paradigms, offering guidance on selecting the most effective RAG design for real-world applications, considering both costs and performance.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.032371",
        "filter_reason": "论文明确研究了“Agentic RAG”，其中LLM作为智能体自主编排整个过程（决定动作、时机、迭代），这直接涉及单智能体的规划、工具使用和自我反思能力，符合研究范围。"
    },
    {
        "index": "#11",
        "title": "Exploring the Meta-level Reasoning of Large Language Models via a Tool-based Multi-hop Tabular Question Answering Task",
        "link": "/arxiv/2601.07696",
        "arxiv_id": "2601.07696",
        "authors": "Nick Ferguson, Alan Bundy, Kwabena Nuamah",
        "summary": "Recent advancements in Large Language Models (LLMs) are increasingly focused on \"reasoning\" ability, a concept with many overlapping definitions in the LLM discourse. We take a more structured approach, distinguishing meta-level reasoning (denoting the process of reasoning about intermediate steps required to solve a task) from object-level reasoning (which concerns the low-level execution of the aforementioned steps.) We design a novel question answering task, which is based around the values of geopolitical indicators for various countries over various years. Questions require breaking down into intermediate steps, retrieval of data, and mathematical operations over that data. The meta-level reasoning ability of LLMs is analysed by examining the selection of appropriate tools for answering questions. To bring greater depth to the analysis of LLMs beyond final answer accuracy, our task contains 'essential actions' against which we can compare the tool call output of LLMs to infer the strength of reasoning ability. We find that LLMs demonstrate good meta-level reasoning on our task, yet are flawed in some aspects of task understanding. We find that n-shot prompting has little effect on accuracy; error messages encountered do not often deteriorate performance; and provide additional evidence for the poor numeracy of LLMs. Finally, we discuss the generalisation and limitation of our findings to other task domains.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.033777",
        "filter_reason": "论文研究了LLM在多跳问答任务中的工具使用和规划能力（将问题分解为步骤），重点分析了工具选择和工具调用输出，符合单智能体中“工具使用”和“规划”的研究范围。"
    },
    {
        "index": "#16",
        "title": "Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments",
        "link": "/arxiv/2601.07606",
        "arxiv_id": "2601.07606",
        "authors": "Bingyang Ye, Shan Chen, Jingxuan Tu, Chen Liu, Zidi Xiong, Samuel Schmidgall, Danielle S. Bitterman",
        "summary": "Large language models are increasingly being used to assess and forecast research ideas, yet we lack scalable ways to evaluate the quality of models' judgments about these scientific ideas. Towards this goal, we introduce PoT, a semi-verifiable benchmarking framework that links scientific idea judgments to downstream signals that become observable later (e.g., citations and shifts in researchers' agendas). PoT freezes a pre-cutoff snapshot of evidence in an offline sandbox and asks models to forecast post-cutoff outcomes, enabling verifiable evaluation when ground truth arrives, scalable benchmarking without exhaustive expert annotation, and analysis of human-model misalignment against signals such as peer-review awards. In addition, PoT provides a controlled testbed for agent-based research judgments that evaluate scientific ideas, comparing tool-using agents to non-agent baselines under prompt ablations and budget scaling. Across 30,000+ instances spanning four benchmark domains, we find that, compared with non-agent baselines, higher interaction budgets generally improve agent performance, while the benefit of tool use is strongly task-dependent. By combining time-partitioned, future-verifiable targets with an offline sandbox for tool use, PoT supports scalable evaluation of agents on future-facing scientific idea judgment tasks.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.041975",
        "filter_reason": "论文明确提出了一个用于评估“基于智能体的研究判断”的基准，重点比较了“使用工具的智能体”与非智能体基线，涉及工具使用和交互预算，符合单智能体（工具使用）的研究范围。"
    },
    {
        "index": "#17",
        "title": "ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents",
        "link": "/arxiv/2601.07582",
        "arxiv_id": "2601.07582",
        "authors": "Huhai Zou, Tianhao Sun, Chuanjiang He, Yu Tian, Zhenyang Li, Li Jin, Nayu Liu, Jiang Zhong, Kaiwen Wei",
        "summary": "Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. While existing memory mechanisms offer basic storage and retrieval capabilities, they are hindered by two primary limitations: (1) rigid memory granularity often disrupts semantic integrity, resulting in fragmented and incoherent memory units; (2) prevalent flat retrieval paradigms rely solely on surface-level semantic similarity, neglecting the structural cues of discourse required to navigate and locate specific episodic contexts. To mitigate these limitations, drawing inspiration from Event Segmentation Theory, we propose ES-Mem, a framework incorporating two core components: (1) a dynamic event segmentation module that partitions long-term interactions into semantically coherent events with distinct boundaries; (2) a hierarchical memory architecture that constructs multi-layered memories and leverages boundary semantics to anchor specific episodic memory for precise context localization. Evaluations on two memory benchmarks demonstrate that ES-Mem yields consistent performance gains over baseline methods. Furthermore, the proposed event segmentation module exhibits robust applicability on dialogue segmentation datasets.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.042560",
        "filter_reason": "论文研究了长期对话智能体的记忆机制，提出了基于事件分割的分层记忆架构，属于单智能体研究范围中的“记忆”方向。"
    },
    {
        "index": "#28",
        "title": "GROKE: Vision-Free Navigation Instruction Evaluation via Graph Reasoning on OpenStreetMap",
        "link": "/arxiv/2601.07375",
        "arxiv_id": "2601.07375",
        "authors": "Farzad Shami, Subhrasankha Dey, Nico Van de Weghe, Henrikki Tenkanen",
        "summary": "The evaluation of navigation instructions remains a persistent challenge in Vision-and-Language Navigation (VLN) research. Traditional reference-based metrics such as BLEU and ROUGE fail to capture the functional utility of spatial directives, specifically whether an instruction successfully guides a navigator to the intended destination. Although existing VLN agents could serve as evaluators, their reliance on high-fidelity visual simulators introduces licensing constraints and computational costs, and perception errors further confound linguistic quality assessment. This paper introduces GROKE(Graph-based Reasoning over OSM Knowledge for instruction Evaluation), a vision-free training-free hierarchical LLM-based framework for evaluating navigation instructions using OpenStreetMap data. Through systematic ablation studies, we demonstrate that structured JSON and textual formats for spatial information substantially outperform grid-based and visual graph representations. Our hierarchical architecture combines sub-instruction planning with topological graph navigation, reducing navigation error by 68.5% compared to heuristic and sampling baselines on the Map2Seq dataset. The agent's execution success, trajectory fidelity, and decision patterns serve as proxy metrics for functional navigability given OSM-visible landmarks and topology, establishing a scalable and interpretable evaluation paradigm without visual dependencies. Code and data are available at https://anonymous.4open.science/r/groke.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.053751",
        "filter_reason": "该论文提出了一个基于LLM的分层框架（GROKE），用于执行导航指令评估。它涉及单智能体的核心能力——规划（子指令规划）和导航（拓扑图导航），符合“单智能体：规划”的研究范围。论文明确为“无视觉”，避开了多模态/视觉的排除项，且重点在于智能体的架构设计与执行能力，而非纯应用或基础设施优化。"
    },
    {
        "index": "#35",
        "title": "Controlled Self-Evolution for Algorithmic Code Optimization",
        "link": "/arxiv/2601.07348",
        "arxiv_id": "2601.07348",
        "authors": "Tu Hu, Ronghao Chen, Shuo Zhang, Jianghao Yin, Mou Xiao Feng, Jingping Liu, Shaolei Zhang, Wenqi Jiang, Yuqi Fang, Sen Hu, Yi Xu, Huacan Wang",
        "summary": "Self-evolution methods enhance code generation through iterative \"generate-verify-refine\" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks.To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels.Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.",
        "subjects": "Computation and Language, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.062662",
        "filter_reason": "该论文提出了“受控自我演化”（CSE）框架，通过迭代“生成-验证-优化”循环实现自我完善，符合“自我演化”的研究范围。同时，文中包含“多样化规划初始化”和“分层进化记忆”等组件，涉及单智能体的规划与记忆机制。"
    },
    {
        "index": "#37",
        "title": "Beyond Literal Mapping: Benchmarking and Improving Non-Literal Translation Evaluation",
        "link": "/arxiv/2601.07338",
        "arxiv_id": "2601.07338",
        "authors": "Yanzhi Tian, Cunxiang Wang, Zeming Liu, Heyan Huang, Wenbo Yu, Dawei Song, Jie Tang, Yuhang Guo",
        "summary": "Large Language Models (LLMs) have significantly advanced Machine Translation (MT), applying them to linguistically complex domains-such as Social Network Services, literature etc. In these scenarios, translations often require handling non-literal expressions, leading to the inaccuracy of MT metrics. To systematically investigate the reliability of MT metrics, we first curate a meta-evaluation dataset focused on non-literal translations, namely MENT. MENT encompasses four non-literal translation domains and features source sentences paired with translations from diverse MT systems, with 7,530 human-annotated scores on translation quality. Experimental results reveal the inaccuracies of traditional MT metrics and the limitations of LLM-as-a-Judge, particularly the knowledge cutoff and score inconsistency problem. To mitigate these limitations, we propose RATE, a novel agentic translation evaluation framework, centered by a reflective Core Agent that dynamically invokes specialized sub-agents. Experimental results indicate the efficacy of RATE, achieving an improvement of at least 3.2 meta score compared with current metrics. Further experiments demonstrate the robustness of RATE to general-domain MT evaluation. Code and dataset are available at: https://github.com/BITHLP/RATE.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.063748",
        "filter_reason": "论文提出了 RATE，一个基于智能体的翻译评估框架，其中包含一个具有自我反思能力的核心智能体，并能动态调用专门的子智能体。这涉及了单智能体的自我反思、工具使用以及多智能体协作，符合 LLM 智能体的研究范围。"
    },
    {
        "index": "#45",
        "title": "The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents",
        "link": "/arxiv/2601.07264",
        "arxiv_id": "2601.07264",
        "authors": "Weihao Xuan, Qingcheng Zeng, Heli Qi, Yunze Xiao, Junjue Wang, Naoto Yokoya",
        "summary": "Autonomous agents based on large language models (LLMs) are rapidly evolving to handle multi-turn tasks, but ensuring their trustworthiness remains a critical challenge. A fundamental pillar of this trustworthiness is calibration, which refers to an agent's ability to express confidence that reliably reflects its actual performance. While calibration is well-established for static models, its dynamics in tool-integrated agentic workflows remain underexplored. In this work, we systematically investigate verbalized calibration in tool-use agents, revealing a fundamental confidence dichotomy driven by tool type. Specifically, our pilot study identifies that evidence tools (e.g., web search) systematically induce severe overconfidence due to inherent noise in retrieved information, while verification tools (e.g., code interpreters) can ground reasoning through deterministic feedback and mitigate miscalibration. To robustly improve calibration across tool types, we propose a reinforcement learning (RL) fine-tuning framework that jointly optimizes task accuracy and calibration, supported by a holistic benchmark of reward designs. We demonstrate that our trained agents not only achieve superior calibration but also exhibit robust generalization from local training environments to noisy web settings and to distinct domains such as mathematical reasoning. Our results highlight the necessity of domain-specific calibration strategies for tool-use agents. More broadly, this work establishes a foundation for building self-aware agents that can reliably communicate uncertainty in high-stakes, real-world deployments.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.073199",
        "filter_reason": "论文明确研究基于LLM的“tool-use agents”（工具使用智能体），分析了工具集成智能体工作流中的校准问题，并提出了通过强化学习微调来构建具有自我意识的智能体。这完全符合“单智能体：工具使用”的研究范围。"
    },
    {
        "index": "#53",
        "title": "ReMIND: Orchestrating Modular Large Language Models for Controllable Serendipity A REM-Inspired System Design for Emergent Creative Ideation",
        "link": "/arxiv/2601.07121",
        "arxiv_id": "2601.07121",
        "authors": "Makoto Sato",
        "summary": "Large language models (LLMs) are used not only for problem solving but also for creative ideation; however, eliciting serendipitous insights that are both novel and internally coherent remains difficult. While stochastic sampling promotes novelty, it often degrades consistency. Here, we propose ReMIND, a REM-inspired modular framework for ideation. ReMIND consists of four stages: wake, which generates a stable low-temperature semantic baseline; dream, which performs high-temperature exploratory generation; judge, which applies coarse evaluation to filter incoherent outputs and extract candidate ideas; and re-wake, which re-articulates selected ideas into coherent final outputs. By instantiating each stage as an independent LLM, ReMIND enables functional separation between exploration and consolidation. Parameter sweeps show that ReMIND reliably induces semantic exploration while preserving downstream stability. Embedding-based analyses confirm substantial semantic displacement during the dream phase, whereas external evaluations reveal that high-quality ideas emerge sporadically rather than as extrema along any single metric. These results suggest that serendipitous ideation in LLMs is a rare-event process best approached through system level design that shapes the conditions under which valuable ideas can emerge and be stabilized. ReMIND provides a general framework for studying the computational basis of serendipity and illustrates how modular LLM orchestration can bridge exploration and stabilization.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.082656",
        "filter_reason": "该论文提出了ReMIND框架，通过将四个独立的LLM实例化为不同的模块（Wake, Dream, Judge, Re-wake）来协同完成创意构思任务。这属于多智能体协作（角色分工）和自我反思（Judge阶段评估与过滤）的研究范畴，符合LLM智能体的研究范围。"
    },
    {
        "index": "#68",
        "title": "RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction",
        "link": "/arxiv/2601.06966",
        "arxiv_id": "2601.06966",
        "authors": "Haonan Bian, Zhiyuan Yao, Sen Hu, Zishan Xu, Shaolei Zhang, Yifu Guo, Ziliang Yang, Xueran Han, Huacan Wang, Ronghao Chen",
        "summary": "As Large Language Models (LLMs) evolve from static dialogue interfaces to autonomous general agents, effective memory is paramount to ensuring long-term consistency. However, existing benchmarks primarily focus on casual conversation or task-oriented dialogue, failing to capture **\"long-term project-oriented\"** interactions where agents must track evolving goals. To bridge this gap, we introduce **RealMem**, the first benchmark grounded in realistic project scenarios. RealMem comprises over 2,000 cross-session dialogues across eleven scenarios, utilizing natural user queries for evaluation. We propose a synthesis pipeline that integrates Project Foundation Construction, Multi-Agent Dialogue Generation, and Memory and Schedule Management to simulate the dynamic evolution of memory. Experiments reveal that current memory systems face significant challenges in managing the long-term project states and dynamic context dependencies inherent in real-world projects. Our code and datasets are available at [https://github.com/AvatarMemory/RealMemBench](https://github.com/AvatarMemory/RealMemBench).",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.179126",
        "filter_reason": "论文明确研究LLM作为自主通用智能体的记忆机制（属于单智能体核心能力），并在数据构建中使用了多智能体对话生成，符合LLM智能体的研究范围。"
    },
    {
        "index": "#71",
        "title": "TreePS-RAG: Tree-based Process Supervision for Reinforcement Learning in Agentic RAG",
        "link": "/arxiv/2601.06922",
        "arxiv_id": "2601.06922",
        "authors": "Tianhua Zhang, Kun Li, Junan Li, Yunxiang Li, Hongyin Luo, Xixin Wu, James Glass, Helen Meng",
        "summary": "Agentic retrieval-augmented generation (RAG) formulates question answering as a multi-step interaction between reasoning and information retrieval, and has recently been advanced by reinforcement learning (RL) with outcome-based supervision. While effective, relying solely on sparse final rewards limits step-wise credit assignment and provides weak guidance for intermediate reasoning and actions. Recent efforts explore process-level supervision, but typically depend on offline constructed training data, which risks distribution shift, or require costly intermediate annotations. We present TreePS-RAG, an online, tree-based RL framework for agentic RAG that enables step-wise credit assignment while retaining standard outcome-only rewards. Our key insight is to model agentic RAG reasoning as a rollout tree, where each reasoning step naturally maps to a node. This tree structure allows step utility to be estimated via Monte Carlo estimation over its descendant outcomes, yielding fine-grained process advantages without requiring intermediate labels. To make this paradigm practical, we introduce an efficient online tree construction strategy that preserves exploration diversity under a constrained computational budget. With a rollout cost comparable to strong baselines like Search-R1, experiments on seven multi-hop and general QA benchmarks across multiple model scales show that TreePS-RAG consistently and significantly outperforms both outcome-supervised and leading process-supervised RL methods.",
        "subjects": "Computation and Language",
        "date": "2026-01-11",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.181236",
        "filter_reason": "论文明确研究“Agentic RAG”，将问答视为推理与信息检索（工具使用）之间的多步交互。它提出了一种基于树的强化学习框架来优化智能体的决策过程，属于单智能体和自我演化的研究范畴。"
    },
    {
        "index": "#79",
        "title": "AgentHallu: Benchmarking Automated Hallucination Attribution of LLM-based Agents",
        "link": "/arxiv/2601.06818",
        "arxiv_id": "2601.06818",
        "authors": "Xuannan Liu, Xiao Yang, Zekun Li, Peipei Li, Ran He",
        "summary": "As LLM-based agents operate over sequential multi-step reasoning, hallucinations arising at intermediate steps risk propagating along the trajectory, thus degrading overall reliability. Unlike hallucination detection in single-turn responses, diagnosing hallucinations in multi-step workflows requires identifying which step causes the initial divergence. To fill this gap, we propose a new research task, automated hallucination attribution of LLM-based agents, aiming to identify the step responsible for the hallucination and explain why. To support this task, we introduce AgentHallu, a comprehensive benchmark with: (1) 693 high-quality trajectories spanning 7 agent frameworks and 5 domains, (2) a hallucination taxonomy organized into 5 categories (Planning, Retrieval, Reasoning, Human-Interaction, and Tool-Use) and 14 sub-categories, and (3) multi-level annotations curated by humans, covering binary labels, hallucination-responsible steps, and causal explanations. We evaluate 13 leading models, and results show the task is challenging even for top-tier models (like GPT-5, Gemini-2.5-Pro). The best-performing model achieves only 41.1\\% step localization accuracy, where tool-use hallucinations are the most challenging at just 11.6\\%. We believe AgentHallu will catalyze future research into developing robust, transparent, and reliable agentic systems.",
        "subjects": "Computation and Language",
        "date": "2026-01-11",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.191359",
        "filter_reason": "该论文专注于LLM智能体，提出了针对智能体工作流中幻觉归因的基准测试。研究内容明确涉及智能体的核心能力，如规划、工具使用和多步推理，属于单智能体研究范畴。虽然涉及幻觉（可靠性），但重点在于评估智能体轨迹而非被排除的安全对齐或纯推理问题。"
    },
    {
        "index": "#92",
        "title": "IDRBench: Interactive Deep Research Benchmark",
        "link": "/arxiv/2601.06676",
        "arxiv_id": "2601.06676",
        "authors": "Yingchaojie Feng, Qiang Huang, Xiaoya Xie, Zhaorui Yang, Jun Yu, Wei Chen, Anthony K. H. Tung",
        "summary": "Deep research agents powered by Large Language Models (LLMs) can perform multi-step reasoning, web exploration, and long-form report generation. However, most existing systems operate in an autonomous manner, assuming fully specified user intent and evaluating only final outputs. In practice, research goals are often underspecified and evolve during exploration, making sustained interaction essential for robust alignment. Despite its importance, interaction remains largely invisible to existing deep research benchmarks, which neither model dynamic user feedback nor quantify its costs. We introduce IDRBench, the first benchmark for systematically evaluating interactive deep research. IDRBench combines a modular multi-agent research framework with on-demand interaction, a scalable reference-grounded user simulator, and an interaction-aware evaluation suite that jointly measures interaction benefits (quality and alignment) and costs (turns and tokens). Experiments across seven state-of-the-art LLMs show that interaction consistently improves research quality and robustness, often outweighing differences in model capacity, while revealing substantial trade-offs in interaction efficiency.",
        "subjects": "Computation and Language, Artificial Intelligence, Human-Computer Interaction",
        "date": "2026-01-10",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.203098",
        "filter_reason": "论文明确提出了针对LLM驱动的深度研究智能体的基准，涉及多智能体框架、Web探索（工具使用）以及通过交互反馈进行动态调整（自我反思/演化），符合多智能体协作及单智能体工具使用的研究范围。"
    },
    {
        "index": "#99",
        "title": "MedEinst: Benchmarking the Einstellung Effect in Medical LLMs through Counterfactual Differential Diagnosis",
        "link": "/arxiv/2601.06636",
        "arxiv_id": "2601.06636",
        "authors": "Wenting Chen, Zhongrui Zhu, Guolin Huang, Wenxuan Wang",
        "summary": "Despite achieving high accuracy on medical benchmarks, LLMs exhibit the Einstellung Effect in clinical diagnosis--relying on statistical shortcuts rather than patient-specific evidence, causing misdiagnosis in atypical cases. Existing benchmarks fail to detect this critical failure mode. We introduce MedEinst, a counterfactual benchmark with 5,383 paired clinical cases across 49 diseases. Each pair contains a control case and a \"trap\" case with altered discriminative evidence that flips the diagnosis. We measure susceptibility via Bias Trap Rate--probability of misdiagnosing traps despite correctly diagnosing controls. Extensive Evaluation of 17 LLMs shows frontier models achieve high baseline accuracy but severe bias trap rates. Thus, we propose ECR-Agent, aligning LLM reasoning with Evidence-Based Medicine standard via two components: (1) Dynamic Causal Inference (DCI) performs structured reasoning through dual-pathway perception, dynamic causal graph reasoning across three levels (association, intervention, counterfactual), and evidence audit for final diagnosis; (2) Critic-Driven Graph and Memory Evolution (CGME) iteratively refines the system by storing validated reasoning paths in an exemplar base and consolidating disease-specific knowledge into evolving illness graphs. Source code is to be released.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.211577",
        "filter_reason": "论文提出了名为 ECR-Agent 的智能体架构，该架构包含“Critic-Driven Graph and Memory Evolution (CGME)”组件，涉及记忆存储和迭代完善，符合“单智能体”中的记忆机制以及“自我演化”的研究范围。尽管论文应用于医疗领域，但其核心贡献在于智能体的架构设计（动态因果推理、记忆演化），而非单纯的应用部署。"
    },
    {
        "index": "#122",
        "title": "Structured Episodic Event Memory",
        "link": "/arxiv/2601.06411",
        "arxiv_id": "2601.06411",
        "authors": "Zhengxuan Lu, Dongfang Li, Yukun Shi, Beilun Wang, Longyue Wang, Baotian Hu",
        "summary": "Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of long-term interaction. To address this, we propose Structured Episodic Event Memory (SEEM), a hierarchical framework that synergizes a graph memory layer for relational facts with a dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency.",
        "subjects": "Computation and Language",
        "date": "2026-01-10",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.233582",
        "filter_reason": "论文明确提出了针对自主智能体的结构化情景事件记忆（SEEM）框架，旨在解决智能体在长期交互中的记忆组织和动态关联问题，属于单智能体研究中的“记忆”范畴。"
    },
    {
        "index": "#123",
        "title": "Value of Information: A Framework for Human-Agent Communication",
        "link": "/arxiv/2601.06407",
        "arxiv_id": "2601.06407",
        "authors": "Yijiang River Dong, Tiancheng Hu, Zheng Hui, Caiqi Zhang, Ivan Vulić, Andreea Bobu, Nigel Collier",
        "summary": "Large Language Model (LLM) agents deployed for real-world tasks face a fundamental dilemma: user requests are underspecified, yet agents must decide whether to act on incomplete information or interrupt users for clarification. Existing approaches either rely on brittle confidence thresholds that require task-specific tuning, or fail to account for the varying stakes of different decisions. We introduce a decision-theoretic framework that resolves this trade-off through the Value of Information (VoI), enabling agents to dynamically weigh the expected utility gain from asking questions against the cognitive cost imposed on users. Our inference-time method requires no hyperparameter tuning and adapts seamlessly across contexts-from casual games to medical diagnosis. Experiments across four diverse domains (20 Questions, medical diagnosis, flight booking, and e-commerce) show that VoI consistently matches or exceeds the best manually-tuned baselines, achieving up to 1.36 utility points higher in high-cost settings. This work provides a parameter-free framework for adaptive agent communication that explicitly balances task risk, query ambiguity, and user effort.",
        "subjects": "Computation and Language",
        "date": "2026-01-10",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.234095",
        "filter_reason": "该论文提出了一个基于信息价值（VoI）的决策理论框架，用于解决LLM智能体在信息不足时是直接行动还是向用户提问的决策问题。这属于单智能体的决策与交互机制研究，符合LLM智能体的研究范围。"
    },
    {
        "index": "#137",
        "title": "Amory: Building Coherent Narrative-Driven Agent Memory through Agentic Reasoning",
        "link": "/arxiv/2601.06282",
        "arxiv_id": "2601.06282",
        "authors": "Yue Zhou, Xiaobo Guo, Belhassen Bayar, Srinivasan H. Sengamedu",
        "summary": "Long-term conversational agents face a fundamental scalability challenge as interactions extend over time: repeatedly processing entire conversation histories becomes computationally prohibitive. Current approaches attempt to solve this through memory frameworks that predominantly fragment conversations into isolated embeddings or graph representations and retrieve relevant ones in a RAG style. While computationally efficient, these methods often treat memory formation minimally and fail to capture the subtlety and coherence of human memory. We introduce Amory, a working memory framework that actively constructs structured memory representations through enhancing agentic reasoning during offline time. Amory organizes conversational fragments into episodic narratives, consolidates memories with momentum, and semanticizes peripheral facts into semantic memory. At retrieval time, the system employs coherence-driven reasoning over narrative structures. Evaluated on the LOCOMO benchmark for long-term reasoning, Amory achieves considerable improvements over previous state-of-the-art, with performance comparable to full context reasoning while reducing response time by 50%. Analysis shows that momentum-aware consolidation significantly enhances response quality, while coherence-driven retrieval provides superior memory coverage compared to embedding-based approaches.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.251358",
        "filter_reason": "该论文专注于解决长期对话智能体的记忆问题，提出了通过智能体推理构建结构化记忆（情景记忆和语义记忆）的框架。这属于单智能体研究中的“记忆”范畴，符合筛选条件。"
    },
    {
        "index": "#143",
        "title": "Operation Veja: Fixing Fundamental Concepts Missing from Modern Roleplaying Training Paradigms",
        "link": "/arxiv/2601.06039",
        "arxiv_id": "2601.06039",
        "authors": "Yueze Liu, Ajay Nagi Reddy Kumdam, Ronit Kanjilal, Hao Yang, Yichi Zhang",
        "summary": "Modern roleplaying models are increasingly sophisticated, yet they consistently struggle to capture the essence of believable, engaging characters. We argue this failure stems from training paradigms that overlook the dynamic interplay of a character's internal world. Current approaches, including Retrieval-Augmented Generation (RAG), fact-based priming, literature-based learning, and synthetic data generation, exhibit recurring limitations in modeling the deliberative, value-conflicted reasoning that defines human interaction. In this paper, we identify four core concepts essential for character authenticity: Values, Experiences, Judgments, and Abilities (VEJA). We propose the VEJA framework as a new paradigm for data curation that addresses these systemic limitations. To illustrate the qualitative ceiling enabled by our framework, we present a pilot study comparing a manually curated, VEJA-grounded dataset against a state-of-the-art synthetic baseline. Using an LLM-as-judge evaluation, our findings demonstrate a significant quality gap, suggesting that a shift toward conceptually grounded data curation, as embodied by VEJA, is necessary for creating roleplaying agents with genuine depth and narrative continuity. The full dataset is available at https://github.com/HyouinKyoumaIRL/Operation-Veja",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.265976",
        "filter_reason": "该论文明确提出了VEJA框架，旨在通过改进数据策览来增强角色扮演智能体的内部状态（价值观、经历、判断、能力）和推理能力。这属于单智能体研究范畴，涉及智能体的记忆、自我反思和行为建模，旨在提升智能体的深度和叙事连续性。"
    },
    {
        "index": "#145",
        "title": "OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent",
        "link": "/arxiv/2601.07779",
        "arxiv_id": "2601.07779",
        "authors": "Bowen Yang, Kaiming Jin, Zhenyu Wu, Zhaoyang Liu, Qiushi Sun, Zehao Li, JingJing Xie, Zhoumianze Liu, Fangzhi Xu, Kanzhi Cheng, Qingyun Li, Yian Wang, Yu Qiao, Zun Wang, Zichen Ding",
        "summary": "While Vision-Language Models (VLMs) have significantly advanced Computer-Using Agents (CUAs), current frameworks struggle with robustness in long-horizon workflows and generalization in novel domains. These limitations stem from a lack of granular control over historical visual context curation and the absence of visual-aware tutorial retrieval. To bridge these gaps, we introduce OS-Symphony, a holistic framework that comprises an Orchestrator coordinating two key innovations for robust automation: (1) a Reflection-Memory Agent that utilizes milestone-driven long-term memory to enable trajectory-level self-correction, effectively mitigating visual context loss in long-horizon tasks; (2) Versatile Tool Agents featuring a Multimodal Searcher that adopts a SeeAct paradigm to navigate a browser-based sandbox to synthesize live, visually aligned tutorials, thereby resolving fidelity issues in unseen scenarios. Experimental results demonstrate that OS-Symphony delivers substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Human-Computer Interaction",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.267795",
        "filter_reason": "该论文提出了一个名为 OS-Symphony 的计算机使用智能体框架，核心研究内容包括智能体的记忆机制、自我反思、工具使用以及多智能体协作，完全符合 LLM 智能体的研究范围。虽然涉及视觉模型，但重点在于智能体架构而非视觉模型本身。"
    },
    {
        "index": "#148",
        "title": "Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning",
        "link": "/arxiv/2601.07641",
        "arxiv_id": "2601.07641",
        "authors": "Jiaxuan Lu, Ziyu Kong, Yemin Wang, Rong Fu, Haiyuan Wan, Cheng Yang, Wenjie Lou, Haoran Sun, Lilong Wang, Yankai Jiang, Xiaosong Wang, Xiao Sun, Dongzhan Zhou",
        "summary": "The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.",
        "subjects": "Artificial Intelligence, Computation and Language, Multiagent Systems",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.274904",
        "filter_reason": "该论文提出了Test-Time Tool Evolution (TTE)框架，旨在解决LLM智能体在科学推理任务中依赖静态工具的问题。它属于单智能体研究范畴，重点探讨了智能体的工具使用和自我演化（工具演化）能力，符合筛选条件中关于单智能体和自我演化的定义。"
    },
    {
        "index": "#152",
        "title": "LRAS: Advanced Legal Reasoning with Agentic Search",
        "link": "/arxiv/2601.07296",
        "arxiv_id": "2601.07296",
        "authors": "Yujin Zhou, Chuxue Cao, Jinluan Yang, Lijun Wu, Conghui He, Sirui Han, Yike Guo",
        "summary": "While Large Reasoning Models (LRMs) have demonstrated exceptional logical capabilities in mathematical domains, their application to the legal field remains hindered by the strict requirements for procedural rigor and adherence to legal logic. Existing legal LLMs, which rely on \"closed-loop reasoning\" derived solely from internal parametric knowledge, frequently suffer from lack of self-awareness regarding their knowledge boundaries, leading to confident yet incorrect conclusions. To address this challenge, we present Legal Reasoning with Agentic Search (LRAS), the first framework designed to transition legal LLMs from static and parametric \"closed-loop thinking\" to dynamic and interactive \"Active Inquiry\". By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32\\%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. We will release our data and models for further exploration soon.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.277049",
        "filter_reason": "论文提出了“Legal Reasoning with Agentic Search (LRAS)”框架，旨在将模型从静态推理转变为动态的“Active Inquiry”（主动询问）。这涉及智能体行为（搜索/询问）和自我反思（Introspective Imitation Learning），符合单智能体（工具使用、自我反思）的研究范围，尽管应用于法律领域，但其核心贡献在于智能体框架而非单纯的应用。"
    },
    {
        "index": "#154",
        "title": "Lost in the Noise: How Reasoning Models Fail with Contextual Distractors",
        "link": "/arxiv/2601.07226",
        "arxiv_id": "2601.07226",
        "authors": "Seongyun Lee, Yongrae Jo, Minju Seo, Moontae Lee, Minjoon Seo",
        "summary": "Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current sanitized benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. We find that prompting, context engineering, SFT, and outcome-reward only RL fail to ensure robustness; in contrast, our proposed Rationale-Aware Reward (RARE) significantly strengthens resilience by incentivizing the identification of helpful information within noise. Finally, we uncover an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrate via attention visualization that models disproportionately focus on distractor tokens, providing vital insights for building the next generation of robust, reasoning-capable agents.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-14T11:00:05.278022",
        "filter_reason": "论文明确研究了智能体AI系统和智能体工作流，重点评估了工具使用任务和RAG场景下的鲁棒性。它分析了智能体如何处理噪声工具输出，并旨在构建鲁棒的、具备推理能力的智能体，符合单智能体（工具使用、推理）的研究范围。"
    },
    {
        "index": "#7",
        "title": "DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning",
        "link": "/arxiv/2601.07611",
        "arxiv_id": "2601.07611",
        "authors": "Zhuoyang Zou, Abolfazl Ansari, Delvin Ce Zhang, Dongwon Lee, Wenpeng Yin",
        "summary": "Paper weakness identification using single-agent or multi-agent LLMs has attracted increasing attention, yet existing approaches exhibit key limitations. Many multi-agent systems simulate human roles at a surface level, missing the underlying criteria that lead experts to assess complementary intellectual aspects of a paper. Moreover, prior methods implicitly assume identified weaknesses are valid, ignoring reviewer bias, misunderstanding, and the critical role of author rebuttals in validating review quality. Finally, most systems output unranked weakness lists, rather than prioritizing the most consequential issues for users. In this work, we propose DIAGPaper, a novel multi-agent framework that addresses these challenges through three tightly integrated modules. The customizer module simulates human-defined review criteria and instantiates multiple reviewer agents with criterion-specific expertise. The rebuttal module introduces author agents that engage in structured debate with reviewer agents to validate and refine proposed weaknesses. The prioritizer module learns from large-scale human review practices to assess the severity of validated weaknesses and surfaces the top-K severest ones to users. Experiments on two benchmarks, AAAR and ReviewCritique, demonstrate that DIAGPaper substantially outperforms existing methods by producing more valid and more paper-specific weaknesses, while presenting them in a user-oriented, prioritized manner.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.687252",
        "filter_reason": "该论文提出了一个多智能体框架（DIAGPaper），包含审稿人代理和作者代理，通过结构化辩论进行协作与通信，以识别和验证论文弱点。这完全符合多智能体（协作、通信）的研究范围。"
    },
    {
        "index": "#8",
        "title": "Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents",
        "link": "/arxiv/2601.07577",
        "arxiv_id": "2601.07577",
        "authors": "Yunfan Li, Bingbing Xu, Xueyun Tian, Xiucheng Xu, Huawei Shen",
        "summary": "Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.687549",
        "filter_reason": "该论文专注于解决LLM智能体在长视界任务中的规划问题，提出了任务解耦规划（TDP）框架，涉及规划器和执行器等智能体架构，属于单智能体规划的研究范畴。"
    },
    {
        "index": "#10",
        "title": "JudgeFlow: Agentic Workflow Optimization via Block Judge",
        "link": "/arxiv/2601.07477",
        "arxiv_id": "2601.07477",
        "authors": "Zihan Ma, Zhikai Zhao, Chuanbo Hua, Federico Berto, Jinkyoo Park",
        "summary": "Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose {\\our{}}, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces -- particularly failed runs -- and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate {\\our{}} on mathematical reasoning and code generation benchmarks, where {\\our{}} achieves superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.688177",
        "filter_reason": "该论文专注于优化基于LLM的智能体工作流。它提出了一种“评估-判断-优化-更新”流水线，利用Judge模块分析执行轨迹并定位问题逻辑块，进而由LLM优化器修改工作流结构。这属于“自我演化”（通过反馈自我完善）和“单智能体”（自我反思/工作流结构）的研究范畴，而非纯推理或纯应用研究。"
    },
    {
        "index": "#11",
        "title": "Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory",
        "link": "/arxiv/2601.07470",
        "arxiv_id": "2601.07470",
        "authors": "Sirui Liang, Pengfei Cao, Jian Zhao, Wenhao Teng, Xiangwen Liao, Jun Zhao, Kang Liu",
        "summary": "Large language model (LLM) agents increasingly rely on accumulated memory to solve long-horizon decision-making tasks. However, most existing approaches store memory in fixed representations and reuse it at a single or implicit level of abstraction, which limits generalization and often leads to negative transfer when distribution shift. This paper proposes the Meta-Cognitive Memory Abstraction method (MCMA), which treats memory abstraction as a learnable cognitive skill rather than a fixed design choice. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization, it determines how memories should be structured, abstracted, and reused. Memories are further organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.688518",
        "filter_reason": "该论文专注于LLM智能体的核心组件——记忆管理，提出了元认知记忆抽象方法（MCMA）来优化智能体的记忆结构、抽象和重用能力，属于单智能体研究中的“记忆”与“自我反思”范畴。"
    },
    {
        "index": "#13",
        "title": "Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents",
        "link": "/arxiv/2601.07468",
        "arxiv_id": "2601.07468",
        "authors": "Miao Su, Yucan Guo, Zhongni Hou, Long Bai, Zixuan Li, Yufei Zhang, Guojun Yin, Wei Lin, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",
        "summary": "Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. However, existing methods fail to properly model the temporal dimension of memory in two aspects: 1) Temporal inaccuracy: memories are organized by dialogue time rather than their actual occurrence time; 2) Temporal fragmentation: existing methods focus on point-wise memory, losing durative information that captures persistent states and evolving patterns. To address these limitations, we propose Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. During memory construction, it first builds a semantic timeline rather than a dialogue one. Then, it consolidates temporally continuous and semantically related information into a durative memory. During memory utilization, it incorporates the query's temporal intent on the semantic timeline, enabling the retrieval of temporally appropriate durative memories and providing time-valid, duration-consistent context to support response generation. Experiments on LongMemEval and LoCoMo show that TSM consistently outperforms existing methods and achieves up to 12.2% absolute improvement in accuracy, demonstrating the effectiveness of the proposed method.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.689267",
        "filter_reason": "论文专注于为个性化LLM智能体设计一种记忆框架（TSM），旨在解决记忆的时间维度建模问题。这直接符合“单智能体：记忆”的研究范围。"
    },
    {
        "index": "#19",
        "title": "Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure",
        "link": "/arxiv/2601.07342",
        "arxiv_id": "2601.07342",
        "authors": "Nicolas Tacheny",
        "summary": "Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis(RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model. In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. We define an investigation protocol that structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information. This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures, but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.691088",
        "filter_reason": "论文明确提出了一个LLM智能体框架，利用工具使用和结构化推理协议（调查协议）自主导航基础设施模型进行诊断。这符合单智能体研究范围中的“工具使用”和“规划”特征，且侧重于智能体架构而非纯领域应用。"
    },
    {
        "index": "#20",
        "title": "ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging",
        "link": "/arxiv/2601.07309",
        "arxiv_id": "2601.07309",
        "authors": "Zhuoka Feng, Kang Chen, Sihan Zhao, Kai Xiong, Yaoning Wang, Minshen Yu, Junjie Nian, Changyi Xiao, Yixin Cao, Yugang Jiang",
        "summary": "Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.691442",
        "filter_reason": "论文明确研究LLM智能体，提出了一种通过模型合并技术将多个专家智能体整合为一个通用型智能体的方法，旨在解决智能体在不同交互环境中的泛化能力问题，属于LLM智能体的研究范畴。"
    },
    {
        "index": "#28",
        "title": "Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration",
        "link": "/arxiv/2601.07224",
        "arxiv_id": "2601.07224",
        "authors": "Yang Zhao, Yangou Ouyang, Xiao Ding, Hepeng Wang, Bibo Cai, Kai Xiong, Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin, Ting Liu",
        "summary": "While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. We propose PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the model's existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22$\\times$. Our findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.694234",
        "filter_reason": "论文明确针对LLM智能体的训练方法，提出了基于梯度浓度的SFT与RL数据分配框架，并在WebShop和ALFWorld等智能体基准上进行了验证，属于智能体训练与自我演化范畴。"
    },
    {
        "index": "#30",
        "title": "Active Context Compression: Autonomous Memory Management in LLM Agents",
        "link": "/arxiv/2601.07190",
        "arxiv_id": "2601.07190",
        "authors": "Nikhil Verma",
        "summary": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors. Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control. This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold). The Focus Agent autonomously decides when to consolidate key learnings into a persistent \"Knowledge\" block and actively withdraws (prunes) the raw interaction history. Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents). Focus performed 6.0 autonomous compressions per task on average, with token savings up to 57% on individual instances. We demonstrate that capable models can autonomously self-regulate their context when given appropriate tools and prompting, opening pathways for cost-aware agentic systems without sacrificing task performance.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.694900",
        "filter_reason": "该论文提出了Focus Agent，专注于LLM智能体的自主记忆管理（上下文压缩），属于单智能体研究中的记忆与自我反思范畴，且涉及智能体通过反馈进行自我调节（自我演化），符合筛选标准。"
    },
    {
        "index": "#35",
        "title": "Dr. Zero: Self-Evolving Search Agents without Training Data",
        "link": "/arxiv/2601.07055",
        "arxiv_id": "2601.07055",
        "authors": "Zhenrui Yue, Kartikeya Upasani, Xianjun Yang, Suyu Ge, Shaoliang Nie, Yuning Mao, Zhe Liu, Dong Wang",
        "summary": "As high-quality data becomes increasingly difficult to obtain, data-free self-evolution has emerged as a promising paradigm. This approach allows large language models (LLMs) to autonomously generate and solve complex problems, thereby improving their reasoning capabilities. However, multi-turn search agents struggle in data-free self-evolution due to the limited question diversity and the substantial compute required for multi-step reasoning and tool using. In this work, we introduce Dr. Zero, a framework enabling search agents to effectively self-evolve without any training data. In particular, we design a self-evolution feedback loop where a proposer generates diverse questions to train a solver initialized from the same base model. As the solver evolves, it incentivizes the proposer to produce increasingly difficult yet solvable tasks, thus establishing an automated curriculum to refine both agents. To enhance training efficiency, we also introduce hop-grouped relative policy optimization (HRPO). This method clusters structurally similar questions to construct group-level baselines, effectively minimizing the sampling overhead in evaluating each query's individual difficulty and solvability. Consequently, HRPO significantly reduces the compute requirements for solver training without compromising performance or stability. Extensive experiment results demonstrate that the data-free Dr. Zero matches or surpasses fully supervised search agents, proving that complex reasoning and search capabilities can emerge solely through self-evolution.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.696657",
        "filter_reason": "论文标题和摘要明确提到了“Search Agents”（搜索智能体）和“Self-Evolving”（自我演化）。研究内容涉及通过反馈循环让智能体在没有训练数据的情况下自主生成问题并提升推理和工具使用能力，符合“自我演化”和“单智能体（工具使用）”的研究范围，且不属于排除项。"
    },
    {
        "index": "#36",
        "title": "CloneMem: Benchmarking Long-Term Memory for AI Clones",
        "link": "/arxiv/2601.07023",
        "arxiv_id": "2601.07023",
        "authors": "Sen Hu, Zhiyu Zhang, Yuxiang Wei, Xueran Han, Zhenheng Tang, Huacan Wang, Ronghao Chen",
        "summary": "AI Clones aim to simulate an individual's thoughts and behaviors to enable long-term, personalized interaction, placing stringent demands on memory systems to model experiences, emotions, and opinions over time. Existing memory benchmarks primarily rely on user-agent conversational histories, which are temporally fragmented and insufficient for capturing continuous life trajectories. We introduce CloneMem, a benchmark for evaluating longterm memory in AI Clone scenarios grounded in non-conversational digital traces, including diaries, social media posts, and emails, spanning one to three years. CloneMem adopts a hierarchical data construction framework to ensure longitudinal coherence and defines tasks that assess an agent's ability to track evolving personal states. Experiments show that current memory mechanisms struggle in this setting, highlighting open challenges for life-grounded personalized AI. Code and dataset are available at https://github.com/AvatarMemory/CloneMemBench",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.697070",
        "filter_reason": "该论文提出了一个针对AI智能体（AI Clones）长期记忆能力的基准，重点评估智能体在模拟个人行为时对经历、情绪和观点的记忆与追踪能力，属于单智能体研究中的“记忆”范畴，符合筛选条件。"
    },
    {
        "index": "#41",
        "title": "ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration",
        "link": "/arxiv/2601.06860",
        "arxiv_id": "2601.06860",
        "authors": "Yifei Chen, Guanting Dong, Zhicheng Dou",
        "summary": "Large Language Models (LLMs) can extend their parameter knowledge limits by adopting the Tool-Integrated Reasoning (TIR) paradigm. However, existing LLM-based agent training framework often focuses on answers' accuracy, overlooking specific alignment for behavior patterns. Consequently, agent often exhibits ineffective actions during TIR tasks, such as redundant and insufficient tool calls. How to calibrate erroneous behavioral patterns when executing TIR tasks, thereby exploring effective trajectories, remains an open-ended problem. In this paper, we propose ET-Agent, a training framework for calibrating agent's tool-use behavior through two synergistic perspectives: Self-evolving Data Flywheel and Behavior Calibration Training. Specifically, we introduce a self-evolutionary data flywheel to generate enhanced data, used to fine-tune LLM to improve its exploration ability. Based on this, we implement an two-phases behavior-calibration training framework. It is designed to progressively calibrate erroneous behavioral patterns to optimal behaviors. Further in-depth experiments confirm the superiority of \\ourmodel{} across multiple dimensions, including correctness, efficiency, reasoning conciseness, and tool execution accuracy. Our ET-Agent framework provides practical insights for research in the TIR field. Codes can be found in https://github.com/asilverlight/ET-Agent",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.698768",
        "filter_reason": "该论文提出了ET-Agent框架，专注于LLM智能体的工具使用行为校准，属于单智能体研究范畴；同时引入了自我演化数据飞轮机制，符合自我演化的研究范围。不属于排除的纯应用、纯推理或基础设施优化等类别。"
    },
    {
        "index": "#47",
        "title": "No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning",
        "link": "/arxiv/2601.06794",
        "arxiv_id": "2601.06794",
        "authors": "Zhicong Li, Lingjie Jiang, Yulan Hu, Xingchen Zeng, Yixia Li, Xiangwen Zhang, Guanhua Chen, Zheng Pan, Xin Li, Yong Liu",
        "summary": "Critique-guided reinforcement learning (RL) has emerged as a powerful paradigm for training LLM agents by augmenting sparse outcome rewards with natural-language feedback. However, current methods often rely on static or offline critic models, which fail to adapt as the policy evolves. In on-policy RL, the agent's error patterns shift over time, causing stationary critics to become stale and providing feedback of diminishing utility. To address this, we introduce ECHO (Evolving Critic for Hindsight-Guided Optimization)}, a framework that jointly optimizes the policy and critic through a synchronized co-evolutionary loop. ECHO utilizes a cascaded rollout mechanism where the critic generates multiple diagnoses for an initial trajectory, followed by policy refinement to enable group-structured advantage estimation. We address the challenge of learning plateaus via a saturation-aware gain shaping objective, which rewards the critic for inducing incremental improvements in high-performing trajectories. By employing dual-track GRPO updates, ECHO ensures the critic's feedback stays synchronized with the evolving policy. Experimental results show that ECHO yields more stable training and higher long-horizon task success across open-world environments.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.700749",
        "filter_reason": "论文提出了ECHO框架，专注于训练LLM智能体，通过策略与批评模型的协同演化来优化智能体在开放世界环境中的表现。这符合研究范围中的“自我演化（通过反馈自我完善）”及“单智能体”方向，不属于排除的纯应用、纯推理或基础设施优化。"
    },
    {
        "index": "#48",
        "title": "From Text to Simulation: A Multi-Agent LLM Workflow for Automated Chemical Process Design",
        "link": "/arxiv/2601.06776",
        "arxiv_id": "2601.06776",
        "authors": "Xufei Tian, Wenli Du, Shaoyi Yang, Han Hu, Hui Xin, Shifeng Qu, Ke Ye",
        "summary": "Process simulation is a critical cornerstone of chemical engineering design. Current automated chemical design methodologies focus mainly on various representations of process flow diagrams. However, transforming these diagrams into executable simulation flowsheets remains a time-consuming and labor-intensive endeavor, requiring extensive manual parameter configuration within simulation software. In this work, we propose a novel multi-agent workflow that leverages the semantic understanding capabilities of large language models(LLMs) and enables iterative interactions with chemical process simulation software, achieving end-to-end automated simulation from textual process specifications to computationally validated software configurations for design enhancement. Our approach integrates four specialized agents responsible for task understanding, topology generation, parameter configuration, and evaluation analysis, respectively, coupled with Enhanced Monte Carlo Tree Search to accurately interpret semantics and robustly generate configurations. Evaluated on Simona, a large-scale process description dataset, our method achieves a 31.1% improvement in the simulation convergence rate compared to state-of-the-art baselines and reduces the design time by 89. 0% compared to the expert manual design. This work demonstrates the potential of AI-assisted chemical process design, which bridges the gap between conceptual design and practical implementation. Our workflow is applicable to diverse process-oriented industries, including pharmaceuticals, petrochemicals, food processing, and manufacturing, offering a generalizable solution for automated process design.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.701065",
        "filter_reason": "论文提出了一种多智能体LLM工作流，包含四个专门的智能体（任务理解、拓扑生成、参数配置、评估分析）进行协作，并涉及与仿真软件的交互（工具使用）。这符合“多智能体：协作”和“工具使用”的研究范围。尽管应用于化工领域，但其核心贡献在于智能体架构和工作流设计，而非单纯的领域应用。"
    },
    {
        "index": "#51",
        "title": "Agentic AI Empowered Intent-Based Networking for 6G",
        "link": "/arxiv/2601.06640",
        "arxiv_id": "2601.06640",
        "authors": "Genze Jiang, Kezhi Wang, Xiaomin Chen, Yizhou Huang",
        "summary": "The transition towards sixth-generation (6G) wireless networks necessitates autonomous orchestration mechanisms capable of translating high-level operational intents into executable network configurations. Existing approaches to Intent-Based Networking (IBN) rely upon either rule-based systems that struggle with linguistic variation or end-to-end neural models that lack interpretability and fail to enforce operational constraints. This paper presents a hierarchical multi-agent framework where Large Language Model (LLM) based agents autonomously decompose natural language intents, consult domain-specific specialists, and synthesise technically feasible network slice configurations through iterative reasoning-action (ReAct) cycles. The proposed architecture employs an orchestrator agent coordinating two specialist agents, i.e., Radio Access Network (RAN) and Core Network agents, via ReAct-style reasoning, grounded in structured network state representations. Experimental evaluation across diverse benchmark scenarios shows that the proposed system outperforms rule-based systems and direct LLM prompting, with architectural principles applicable to Open RAN (O-RAN) deployments. The results also demonstrate that whilst contemporary LLMs possess general telecommunications knowledge, network automation requires careful prompt engineering to encode context-dependent decision thresholds, advancing autonomous orchestration capabilities for next-generation wireless systems.",
        "subjects": "Artificial Intelligence, Networking and Internet Architecture",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.702068",
        "filter_reason": "该论文提出了一个分层多智能体框架，包含编排器智能体和领域专家智能体（RAN和核心网络），它们通过ReAct循环进行协作和通信以解决网络配置问题。这完全符合“多智能体：协作、通信”的研究范围，且核心贡献在于智能体架构而非单纯的基础设施优化。"
    },
    {
        "index": "#54",
        "title": "DRAGON: LLM-Driven Decomposition and Reconstruction Agents for Large-Scale Combinatorial Optimization",
        "link": "/arxiv/2601.06502",
        "arxiv_id": "2601.06502",
        "authors": "Shengkai Chen, Zhiguang Cao, Jianan Zhou, Yaoxin Wu, Senthilnath Jayavelu, Zhuoyi Lin, Xiaoli Li, Shili Xiang",
        "summary": "Large Language Models (LLMs) have recently shown promise in addressing combinatorial optimization problems (COPs) through prompt-based strategies. However, their scalability and generalization remain limited, and their effectiveness diminishes as problem size increases, particularly in routing problems involving more than 30 nodes. We propose DRAGON, which stands for Decomposition and Reconstruction Agents Guided OptimizatioN, a novel framework that combines the strengths of metaheuristic design and LLM reasoning. Starting from an initial global solution, DRAGON autonomously identifies regions with high optimization potential and strategically decompose large-scale COPs into manageable subproblems. Each subproblem is then reformulated as a concise, localized optimization task and solved through targeted LLM prompting guided by accumulated experiences. Finally, the locally optimized solutions are systematically reintegrated into the original global context to yield a significantly improved overall outcome. By continuously interacting with the optimization environment and leveraging an adaptive experience memory, the agents iteratively learn from feedback, effectively coupling symbolic reasoning with heuristic search. Empirical results show that, unlike existing LLM-based solvers limited to small-scale instances, DRAGON consistently produces feasible solutions on TSPLIB, CVRPLIB, and Weibull-5k bin packing benchmarks, and achieves near-optimal results (0.16% gap) on knapsack problems with over 3M variables. This work shows the potential of feedback-driven language agents as a new paradigm for generalizable and interpretable large-scale optimization.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.703088",
        "filter_reason": "论文提出了DRAGON框架，明确使用了“Agents”和“language agents”概念。文中描述了智能体自主识别区域、分解问题（规划）、利用自适应经验记忆（记忆）、与环境交互并从反馈中迭代学习（自我反思/演化）。这完全符合单智能体和自我演化的研究范围，且不属于纯应用或纯推理排除项。"
    },
    {
        "index": "#60",
        "title": "HiMem: Hierarchical Long-Term Memory for LLM Long-Horizon Agents",
        "link": "/arxiv/2601.06377",
        "arxiv_id": "2601.06377",
        "authors": "Ningning Zhang, Xingxing Yang, Zhizhong Tan, Weiping Deng, Wenyong Wang",
        "summary": "Although long-term memory systems have made substantial progress in recent years, they still exhibit clear limitations in adaptability, scalability, and self-evolution under continuous interaction settings. Inspired by cognitive theories, we propose HiMem, a hierarchical long-term memory framework for long-horizon dialogues, designed to support memory construction, retrieval, and dynamic updating during sustained interactions. HiMem constructs cognitively consistent Episode Memory via a Topic-Aware Event--Surprise Dual-Channel Segmentation strategy, and builds Note Memory that captures stable knowledge through a multi-stage information extraction pipeline. These two memory types are semantically linked to form a hierarchical structure that bridges concrete interaction events and abstract knowledge, enabling efficient retrieval without sacrificing information fidelity. HiMem supports both hybrid and best-effort retrieval strategies to balance accuracy and efficiency, and incorporates conflict-aware Memory Reconsolidation to revise and supplement stored knowledge based on retrieval feedback. This design enables continual memory self-evolution over long-term use. Experimental results on long-horizon dialogue benchmarks demonstrate that HiMem consistently outperforms representative baselines in accuracy, consistency, and long-term reasoning, while maintaining favorable efficiency. Overall, HiMem provides a principled and scalable design paradigm for building adaptive and self-evolving LLM-based conversational agents. The code is available at https://github.com/jojopdq/HiMem.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.705014",
        "filter_reason": "该论文提出了HiMem，这是一个专门为LLM长跨度智能体设计的分层长期记忆框架。它重点研究了智能体的核心组件——记忆（包括记忆构建、检索和动态更新），并引入了冲突感知的记忆再巩固机制以实现自我演化。这完全符合单智能体研究范围中的“记忆”和“自我演化”标准。"
    },
    {
        "index": "#65",
        "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation",
        "link": "/arxiv/2601.06328",
        "arxiv_id": "2601.06328",
        "authors": "Ziqiao Xi, Shuang Liang, Qi Liu, Jiaqing Zhang, Letian Peng, Fang Nan, Meshal Nayim, Tianhui Zhang, Rishika Mundada, Lianhui Qin, Biwei Huang, Kun Zhou",
        "summary": "Tool-using LLM agents still struggle in open-world settings with large tool pools, long-horizon objectives, wild constraints, and unreliable tool states. For scalable and realistic training and testing, we introduce an open-world tool-using environment, built on 5,571 format unified tools across 204 commonly used apps. It includes a task creation engine that synthesizes long-horizon, multi-tool workflows with wild constraints, and a state controller that injects interruptions and failures to stress-test robustness. On top of this environment, we develop a tool select-then-execute agent framework with a planner-actor decomposition to separate deliberate reasoning and self-correction from step-wise execution. Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents. Our code and data will be publicly released.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.706944",
        "filter_reason": "论文专注于LLM智能体的工具使用能力，提出了一个开放世界环境用于智能体测试，并开发了包含规划器和执行者的智能体框架，涉及规划、自我修正等单智能体核心能力，符合筛选标准。"
    },
    {
        "index": "#66",
        "title": "PCoKG: Personality-aware Commonsense Reasoning with Debate",
        "link": "/arxiv/2601.06234",
        "arxiv_id": "2601.06234",
        "authors": "Weijie Li, Zhongqing Wang, Guodong Zhou",
        "summary": "Most commonsense reasoning models overlook the influence of personality traits, limiting their effectiveness in personalized systems such as dialogue generation. To address this limitation, we introduce the Personality-aware Commonsense Knowledge Graph (PCoKG), a structured dataset comprising 521,316 quadruples. We begin by employing three evaluators to score and filter events from the ATOMIC dataset, selecting those that are likely to elicit diverse reasoning patterns across different personality types. For knowledge graph construction, we leverage the role-playing capabilities of large language models (LLMs) to perform reasoning tasks. To enhance the quality of the generated knowledge, we incorporate a debate mechanism consisting of a proponent, an opponent, and a judge, which iteratively refines the outputs through feedback loops. We evaluate the dataset from multiple perspectives and conduct fine-tuning and ablation experiments using multiple LLM backbones to assess PCoKG's robustness and the effectiveness of its construction pipeline. Our LoRA-based fine-tuning results indicate a positive correlation between model performance and the parameter scale of the base models. Finally, we apply PCoKG to persona-based dialogue generation, where it demonstrates improved consistency between generated responses and reference outputs. This work bridges the gap between commonsense reasoning and individual cognitive differences, enabling the development of more personalized and context-aware AI systems.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.707230",
        "filter_reason": "论文提出了一种由支持者、反对者和法官组成的辩论机制，通过多智能体交互（协作与博弈）来迭代完善知识图谱的构建，符合“多智能体：协作、通信、博弈”的研究范围。"
    },
    {
        "index": "#74",
        "title": "HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants",
        "link": "/arxiv/2601.06152",
        "arxiv_id": "2601.06152",
        "authors": "Hailong Li, Feifei Li, Wenhui Que, Xingyu Fan",
        "summary": "Large language models (LLMs) power many interactive systems such as chatbots, customer-service agents, and personal assistants. In knowledge-intensive scenarios requiring user-specific personalization, conventional retrieval-augmented generation (RAG) pipelines exhibit limited memory capacity and insufficient coordination between retrieval mechanisms and user-specific conversational history, leading to redundant clarification, irrelevant documents, and degraded user experience. Inspired by the hippocampus-neocortex memory mechanism, we propose HiMeS, an AI-assistant architecture that fuses short-term and long-term memory. Our contributions are fourfold: (1) A short-term memory extractor is trained end-to-end with reinforcement learning to compress recent dialogue and proactively pre-retrieve documents from the knowledge base, emulating the cooperative interaction between the hippocampus and prefrontal cortex. (2) A partitioned long-term memory network stores user-specific information and re-ranks retrieved documents, simulating distributed cortical storage and memory reactivation. (3) On a real-world industrial dataset, HiMeS significantly outperforms a cascaded RAG baseline on question-answering quality. (4) Ablation studies confirm the necessity of both memory modules and suggest a practical path toward more reliable, context-aware, user-customized LLM-based assistants.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.709606",
        "filter_reason": "该论文提出了一种受海马体启发的记忆系统，用于构建个性化AI助手，重点解决了LLM在知识密集型场景中的短期与长期记忆融合问题。这直接属于LLM智能体研究范围中的“单智能体：记忆”模块，且不属于排除的纯应用或纯推理范畴。"
    },
    {
        "index": "#75",
        "title": "NL2Dashboard: A Lightweight and Controllable Framework for Generating Dashboards with LLMs",
        "link": "/arxiv/2601.06126",
        "arxiv_id": "2601.06126",
        "authors": "Boshen Shi, Kexin Yang, Yuanbo Yang, Guanguang Chang, Ce Chi, Zhendong Wang, Xing Wang, Junlan Feng",
        "summary": "While Large Language Models (LLMs) have demonstrated remarkable proficiency in generating standalone charts, synthesizing comprehensive dashboards remains a formidable challenge. Existing end-to-end paradigms, which typically treat dashboard generation as a direct code generation task (e.g., raw HTML), suffer from two fundamental limitations: representation redundancy due to massive tokens spent on visual rendering, and low controllability caused by the entanglement of analytical reasoning and presentation. To address these challenges, we propose NL2Dashboard, a lightweight framework grounded in the principle of Analysis-Presentation Decoupling. We introduce a structured intermediate representation (IR) that encapsulates the dashboard's content, layout, and visual elements. Therefore, it confines the LLM's role to data analysis and intent translation, while offloading visual synthesis to a deterministic rendering engine. Building upon this framework, we develop a multi-agent system in which the IR-driven algorithm is instantiated as a suite of tools. Comprehensive experiments conducted with this system demonstrate that NL2Dashboard significantly outperforms state-of-the-art baselines across diverse domains, achieving superior visual quality, significantly higher token efficiency, and precise controllability in both generation and modification tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-04",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.709972",
        "filter_reason": "摘要明确提到开发了一个“多智能体系统”，并将算法实例化为工具，符合多智能体协作和工具使用的研究范围。"
    },
    {
        "index": "#73",
        "title": "PsyAgent: Constructing Human-like Agents Based on Psychological Modeling and Contextual Interaction",
        "link": "/arxiv/2601.06158",
        "arxiv_id": "2601.06158",
        "authors": "Zibin Meng, Kani Chen",
        "summary": "Human-like agents require modeling how dispositions interact with social structure. We present PsyAgent, which couples a Big Five trait prior with Bourdieu's cognitive-social co-structure. PsyAgent comprises: (i) Individual Structure (IS), a machine-usable profile encoding traits and facets, cognitive style, values, cultural and educational capital, and salient life episodes; and (ii) Multi-Scenario Contexting (MSC), role-relationship-norm frames spanning eight arenas (work, family, friendship, strangers and civic life, solitude and self-regulation, romance, learning, and public expression). At inference, fixed structured prompts bind the active scenario to the agent profile, yielding behavior that is stable yet context-sensitive. We instantiate IS and MSC to synthesize supervision (role-play dialogues, decision probes, feedback trajectories) and then fine-tune a small LLM. The resulting model produces consistent, identifiable persona-aligned behaviors for specified Big Five configurations and matches or exceeds several larger untuned LLMs and other untuned baselines on our metrics: persona consistency, contextual appropriateness, style matching, trait identifiability, and long-horizon stability. Ablations show IS chiefly improves trait fidelity and stylistic stability, while MSC drives norm awareness and decision fit; both are necessary for cross-scenario performance. PsyAgent offers a precise, data-efficient architecture for personality-grounded agents.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.709332",
        "filter_reason": "论文提出了PsyAgent，一种基于LLM的智能体架构，旨在通过心理建模（大五人格特质）和语境交互构建类人智能体。研究内容涉及智能体的记忆（个体结构、生活片段）和语境感知行为，属于单智能体研究范畴（记忆、人设建模），且不属于排除的纯应用或纯推理领域。"
    },
    {
        "index": "#78",
        "title": "Dreaming Is Not a Bug: A Jung-Inspired Dream Layer for Multi-Agent LLM Companions",
        "link": "/arxiv/2601.06115",
        "arxiv_id": "2601.06115",
        "authors": "V. Cheung",
        "summary": "Inspired by a personal dream about knowledge-sharing barriers in an everyday hardware project, this paper proposes a Jung-inspired \"Dream Layer\" for LLM companions, reframing controlled offline hallucinations as a resource for learning and relationship-building rather than a mere reliability bug. Drawing on Jung's notion of the collective unconscious as a shared repository of archetypal forms, we introduce an Artificial Collective Unconscious (ACU): a shared dream pool where agents contribute de-identified, abstract Interaction Templates that are later re-instantiated as idiosyncratic Dream Narratives. The Dream Layer runs strictly offline: logic-enforcing modules are relaxed and sampling temperature is increased, yielding safe but deliberately bizarre narratives (e.g., travel sequences with mismatched currencies) that augment data for rare events and edge-case safety tests; to harness risk productively, we add a governance stack of strict abstraction, temporal delays, and ephemeral memory. Through behavioural simulations of everyday dialogue and long-horizon adaptation tasks, we show that the Dream Layer enables a critical decoupling: agents remain firm on safety constraints (e.g., security policies) while becoming flexible in narrative strategy (e.g., using shared archetypal metaphors to resolve deadlocks), conceptually reframing hallucination so that online, unmarked instances remain bugs, whereas bounded, marked, and delayed ones become a goldmine for synthetic scenarios and deepened companionship, echoing anti-overfitting dream mechanisms proposed in contemporary neuroscience.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.710891",
        "filter_reason": "论文标题明确提到了“Multi-Agent LLM Companions”（多智能体LLM同伴），摘要中提出了“人工集体无意识（ACU）”作为智能体共享交互模板的池，涉及多智能体之间的资源共享、协作以及长期适应任务，符合多智能体（协作、通信）的研究范围。"
    },
    {
        "index": "#80",
        "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions",
        "link": "/arxiv/2601.06112",
        "arxiv_id": "2601.06112",
        "authors": "Aayush Gupta",
        "summary": "Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production. We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $ε$, and (iii) fault tolerance under controlled tool/API failures at intensity $λ$. ReliabilityBench contributes a unified reliability surface $R(k,ε,λ)$, \\textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift). We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes. Perturbations alone reduce success from 96.9% at $ε=0$ to 88.1% at $ε=0.2$. Rate limiting is the most damaging fault in ablations. ReAct is more robust than Reflexion under combined stress, and Gemini 2.0 Flash achieves comparable reliability to GPT-4o at much lower cost. ReliabilityBench provides a systematic framework for assessing production readiness of LLM agents.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.711451",
        "filter_reason": "该论文专注于评估工具使用LLM智能体的可靠性，涉及单智能体架构（ReAct, Reflexion）的评估，涵盖了工具使用和自我反思等核心智能体能力，符合单智能体研究范围。"
    },
    {
        "index": "#81",
        "title": "LLM-Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions",
        "link": "/arxiv/2601.06111",
        "arxiv_id": "2601.06111",
        "authors": "Aayush Gupta, Farahan Raza Sheikh",
        "summary": "Predicting how populations respond to policy interventions is a fundamental challenge in computational social science and public policy. Traditional approaches rely on aggregate statistical models that capture historical correlations but lack mechanistic interpretability and struggle with novel policy scenarios. We present a general framework for constructing Social Digital Twins - virtual population replicas where Large Language Models (LLMs) serve as cognitive engines for individual agents. Each agent, characterized by demographic and psychographic attributes, receives policy signals and outputs multi-dimensional behavioral probability vectors. A calibration layer maps aggregated agent responses to observable population-level metrics, enabling validation against real-world data and deployment for counterfactual policy analysis. We instantiate this framework in the domain of pandemic response, using COVID-19 as a case study with rich observational data. On a held-out test period, our calibrated digital twin achieves a 20.7% improvement in macro-averaged prediction error over gradient boosting baselines across six behavioral categories. Counterfactual experiments demonstrate monotonic and bounded responses to policy variations, establishing behavioral plausibility. The framework is domain-agnostic: the same architecture applies to transportation policy, economic interventions, environmental regulations, or any setting where policy affects population behavior. We discuss implications for policy simulation, limitations of the approach, and directions for extending LLM-based digital twins beyond pandemic response.",
        "subjects": "Artificial Intelligence, Computers and Society",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.711726",
        "filter_reason": "该论文提出了一个基于LLM的社会数字孪生框架，其中LLM充当个体智能体的认知引擎，用于模拟群体行为。这属于多智能体系统的研究范畴。尽管使用了COVID-19作为案例研究，但论文的核心贡献是通用的智能体框架架构，而非纯医疗应用，因此符合筛选条件。"
    },
    {
        "index": "#86",
        "title": "Automatic Question Generation for Intuitive Learning Utilizing Causal Graph Guided Chain of Thought Reasoning",
        "link": "/arxiv/2601.06098",
        "arxiv_id": "2601.06098",
        "authors": "Nicholas X. Wang, Neel V. Parpia, Aaryan D. Parikh, Aggelos K. Katsaggelos",
        "summary": "Intuitive learning is crucial for developing deep conceptual understanding, especially in STEM education, where students often struggle with abstract and interconnected concepts. Automatic question generation has become an effective strategy for personalized and adaptive learning. However, its effectiveness is hindered by hallucinations in large language models (LLMs), which may generate factually incorrect, ambiguous, or pedagogically inconsistent questions. To address this issue, we propose a novel framework that combines causal-graph-guided Chain-of-Thought (CoT) reasoning with a multi-agent LLM architecture. This approach ensures the generation of accurate, meaningful, and curriculum-aligned questions. Causal graphs provide an explicit representation of domain knowledge, while CoT reasoning facilitates a structured, step-by-step traversal of related concepts. Dedicated LLM agents are assigned specific tasks such as graph pathfinding, reasoning, validation, and output, all working within domain constraints. A dual validation mechanism-at both the conceptual and output stages-greatly reduces hallucinations. Experimental results demonstrate up to a 70% improvement in quality compared to reference methods and yielded highly favorable outcomes in subjective evaluations.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-02",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.713372",
        "filter_reason": "论文明确提出了一个“多智能体LLM架构”，其中包含专门的智能体负责图寻路、推理、验证和输出等特定任务，这些智能体通过协作来减少幻觉并生成高质量问题。这符合多智能体协作的研究范围。"
    },
    {
        "index": "#160",
        "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework",
        "link": "/arxiv/2601.07122",
        "arxiv_id": "2601.07122",
        "authors": "Yixiao Peng, Hao Hu, Feiyang Li, Xinye Cao, Yingchang Jiang, Jipeng Tang, Guoshun Nan, Yuling Liu",
        "summary": "While virtualization and resource pooling empower cloud networks with structural flexibility and elastic scalability, they inevitably expand the attack surface and challenge cyber resilience. Reinforcement Learning (RL)-based defense strategies have been developed to optimize resource deployment and isolation policies under adversarial conditions, aiming to enhance system resilience by maintaining and restoring network availability. However, existing approaches lack robustness as they require retraining to adapt to dynamic changes in network structure, node scale, attack strategies, and attack intensity. Furthermore, the lack of Human-in-the-Loop (HITL) support limits interpretability and flexibility. To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs). Inspired by MITRE ATT&CK's Tactics-Techniques model, CyberOps-Bots features a two-layer architecture: (1) An upper-level LLM agent with four modules--ReAct planning, IPDRR-based perception, long-short term memory, and action/tool integration--performs global awareness, human intent recognition, and tactical planning; (2) Lower-level RL agents, developed via heterogeneous separated pre-training, execute atomic defense actions within localized network regions. This synergy preserves LLM adaptability and interpretability while ensuring reliable RL execution. Experiments on real cloud datasets show that, compared to state-of-the-art algorithms, CyberOps-Bots maintains network availability 68.5% higher and achieves a 34.7% jumpstart performance gain when shifting the scenarios without retraining. To our knowledge, this is the first study to establish a robust LLM-RL framework with HITL support for cloud defense. We will release our framework to the community, facilitating the advancement of robust and autonomous defense in cloud networks.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.739385",
        "filter_reason": "该论文提出了一个分层多智能体框架，其中上层LLM智能体明确使用了ReAct规划、长短期记忆和工具集成（符合单智能体标准），并与下层RL智能体进行协作（符合多智能体标准）。尽管应用于网络防御领域，但论文的核心贡献在于LLM智能体的架构设计（LLM与RL的结合），而非单纯的应用或AI安全对齐研究。"
    },
    {
        "index": "#191",
        "title": "Personality-Aware Reinforcement Learning for Persuasive Dialogue with LLM-Driven Simulation",
        "link": "/arxiv/2601.06877",
        "arxiv_id": "2601.06877",
        "authors": "Donghuo Zeng, Roberto Legaspi, Kazushi Ikeda",
        "summary": "Effective persuasive dialogue agents adapt their strategies to individual users, accounting for the evolution of their psychological states and intentions throughout conversations. We present a personality-aware reinforcement learning approach comprising three main modules: (1) a Strategy-Oriented Interaction Framework, which serves as an agenda-based strategy controller that selects strategy-level actions and generate responses via Maximal Marginal Relevance (MMR) retrieval to ensure contextual relevance, diversity, and scalable data generation; (2) Personality-Aware User Representation Learning, which produces an 81-dimensional mixed-type embedding predicted at each turn from recent exchanges and appended to the reinforcement learning state; and (3) a Dueling Double DQN (D3QN) model and Reward Prediction, in which the policy is conditioned on dialogue history and turn-level personality estimates and trained using a composite reward incorporating agreement intent, donation amount, and changeof-mind penalties. We use an agenda-based LLM simulation pipeline to generate diverse interactions, from which personality estimation is inferred from the generated utterances. Experiments on the PersuasionForGood (P4G) dataset augmented with simulated dialogues reveal three main findings: (i) turn-level personality conditioning improves policy adaptability and cumulative persuasion rewards; (ii) LLM-driven simulation enhances generalization to unseen user behaviors; and (iii) incorporating a change-of-mind penalty reduces post-agreement retractions while slightly improving donation outcomes. These results demonstrate that structured interaction, dynamic personality estimation, and behaviorally informed rewards together yield more effective persuasive policies.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.750513",
        "filter_reason": "该论文提出了一个基于强化学习的说服对话智能体，包含策略规划（议程式策略控制器）、记忆与状态表征（个性化用户表征学习）以及利用LLM进行环境模拟，符合单智能体的研究范围。"
    },
    {
        "index": "#204",
        "title": "MemGovern: Enhancing Code Agents through Learning from Governed Human Experiences",
        "link": "/arxiv/2601.06789",
        "arxiv_id": "2601.06789",
        "authors": "Qihao Wang, Ziming Cheng, Shuo Zhang, Fan Liu, Rui Xu, Heng Lian, Kunyi Wang, Xiaoming Yu, Jianghao Yin, Sen Hu, Yue Hu, Shaolei Zhang, Yanbing Liu, Ronghao Chen, Huacan Wang",
        "summary": "While autonomous software engineering (SWE) agents are reshaping programming paradigms, they currently suffer from a \"closed-world\" limitation: they attempt to fix bugs from scratch or solely using local context, ignoring the immense historical human experience available on platforms like GitHub. Accessing this open-world experience is hindered by the unstructured and fragmented nature of real-world issue-tracking data. In this paper, we introduce MemGovern, a framework designed to govern and transform raw GitHub data into actionable experiential memory for agents. MemGovern employs experience governance to convert human experience into agent-friendly experience cards and introduces an agentic experience search strategy that enables logic-driven retrieval of human expertise. By producing 135K governed experience cards, MemGovern achieves a significant performance boost, improving resolution rates on the SWE-bench Verified by 4.65%. As a plug-in approach, MemGovern provides a solution for agent-friendly memory infrastructure.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.755617",
        "filter_reason": "论文明确研究代码智能体，核心贡献是MemGovern框架，旨在通过将GitHub数据转化为可操作的经验记忆来增强智能体能力，属于单智能体研究中的“记忆”范畴，符合筛选条件。"
    },
    {
        "index": "#230",
        "title": "CEDAR: Context Engineering for Agentic Data Science",
        "link": "/arxiv/2601.06606",
        "arxiv_id": "2601.06606",
        "authors": "Rishiraj Saha Roy, Chris Hinze, Luzian Hahn, Fabian Kuech",
        "summary": "We demonstrate CEDAR, an application for automating data science (DS) tasks with an agentic setup. Solving DS problems with LLMs is an underexplored area that has immense market value. The challenges are manifold: task complexities, data sizes, computational limitations, and context restrictions. We show that these can be alleviated via effective context engineering. We first impose structure into the initial prompt with DS-specific input fields, that serve as instructions for the agentic system. The solution is then materialized as an enumerated sequence of interleaved plan and code blocks generated by separate LLM agents, providing a readable structure to the context at any step of the workflow. Function calls for generating these intermediate texts, and for corresponding Python code, ensure that data stays local, and only aggregate statistics and associated instructions are injected into LLM prompts. Fault tolerance and context management are introduced via iterative code generation and smart history rendering. The viability of our agentic data scientist is demonstrated using canonical Kaggle challenges.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.763954",
        "filter_reason": "论文提出了一个用于自动化数据科学的智能体框架（CEDAR），涉及规划（生成计划块）、工具使用（函数调用和代码生成）、记忆与上下文管理（智能历史渲染），符合单智能体及多智能体的研究范围。"
    },
    {
        "index": "#244",
        "title": "ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking",
        "link": "/arxiv/2601.06487",
        "arxiv_id": "2601.06487",
        "authors": "Qiang Zhang, Boli Chen, Fanrui Zhang, Ruixue Ding, Shihang Wang, Qiuchen Wang, Yinfeng Huang, Haonan Zhang, Rongxiang Zhu, Pengyong Wang, Ailin Ren, Xin Li, Pengjun Xie, Jiawei Liu, Ning Guo, Jingren Zhou, Zheng-Jun Zha",
        "summary": "Reinforcement learning has substantially improved the performance of LLM agents on tasks with verifiable outcomes, but it still struggles on open-ended agent tasks with vast solution spaces (e.g., complex travel planning). Due to the absence of objective ground-truth for these tasks, current RL algorithms largely rely on reward models that assign scalar scores to individual responses. We contend that such pointwise scoring suffers from an inherent discrimination collapse: the reward model struggles to distinguish subtle advantages among different trajectories, resulting in scores within a group being compressed into a narrow range. Consequently, the effective reward signal becomes dominated by noise from the reward model, leading to optimization stagnation. To address this, we propose ArenaRL, a reinforcement learning paradigm that shifts from pointwise scalar scoring to intra-group relative ranking. ArenaRL introduces a process-aware pairwise evaluation mechanism, employing multi-level rubrics to assign fine-grained relative scores to trajectories. Additionally, we construct an intra-group adversarial arena and devise a tournament-based ranking scheme to obtain stable advantage signals. Empirical results confirm that the built seeded single-elimination scheme achieves nearly equivalent advantage estimation accuracy to full pairwise comparisons with O(N^2) complexity, while operating with only O(N) complexity, striking an optimal balance between efficiency and precision. Furthermore, to address the lack of full-cycle benchmarks for open-ended agents, we build Open-Travel and Open-DeepResearch, two high-quality benchmarks featuring a comprehensive pipeline covering SFT, RL training, and multi-dimensional evaluation. Extensive experiments show that ArenaRL substantially outperforms standard RL baselines, enabling LLM agents to generate more robust solutions for complex real-world tasks.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.768536",
        "filter_reason": "该论文提出了一种名为ArenaRL的强化学习范式，旨在通过锦标赛式相对排序来提升LLM智能体在开放式任务（如复杂旅行规划）中的表现。研究涉及智能体的自我演化（通过反馈自我完善）和规划能力，属于单智能体研究范畴，且侧重于算法改进而非纯应用或基础设施。"
    },
    {
        "index": "#264",
        "title": "Beyond BeautifulSoup: Benchmarking LLM-Powered Web Scraping for Everyday Users",
        "link": "/arxiv/2601.06301",
        "arxiv_id": "2601.06301",
        "authors": "Arth Bhardwaj, Nirav Diwan, Gang Wang",
        "summary": "Web scraping has historically required technical expertise in HTML parsing, session management, and authentication circumvention, which limited large-scale data extraction to skilled developers. We argue that large language models (LLMs) have democratized web scraping, enabling low-skill users to execute sophisticated operations through simple natural language prompts. While extensive benchmarks evaluate these tools under optimal expert conditions, we show that without extensive manual effort, current LLM-based workflows allow novice users to scrape complex websites that would otherwise be inaccessible. We systematically benchmark what everyday users can do with off-the-shelf LLM tools across 35 sites spanning five security tiers, including authentication, anti-bot, and CAPTCHA controls. We devise and evaluate two distinct workflows: (a) LLM-assisted scripting, where users prompt LLMs to generate traditional scraping code but maintain manual execution control, and (b) end-to-end LLM agents, which autonomously navigate and extract data through integrated tool use. Our results demonstrate that end-to-end agents have made complex scraping accessible - requiring as little as a single prompt with minimal refinement (less than 5 changes) to complete workflows. We also highlight scenarios where LLM-assisted scripting may be simpler and faster for static sites. In light of these findings, we provide simple procedures for novices to use these workflows and gauge what adversaries could achieve using these.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Software Engineering",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.780362",
        "filter_reason": "论文明确研究并基准测试了“端到端LLM智能体”，重点评估了智能体的“工具使用”和“自主导航”能力，符合单智能体的研究范围。"
    },
    {
        "index": "#268",
        "title": "Automated QoR improvement in OpenROAD with coding agents",
        "link": "/arxiv/2601.06268",
        "arxiv_id": "2601.06268",
        "authors": "Amur Ghose, Junyeong Jang, Andrew B. Kahng, Jakang Lee",
        "summary": "EDA development and innovation has been constrained by scarcity of expert engineering resources. While leading LLMs have demonstrated excellent performance in coding and scientific reasoning tasks, their capacity to advance EDA technology itself has been largely untested. We present AuDoPEDA, an autonomous, repository-grounded coding system built atop OpenAI models and a Codex-class agent that reads OpenROAD, proposes research directions, expands them into implementation steps, and submits executable diffs. Our contributions include (i) a closed-loop LLM framework for EDA code changes; (ii) a task suite and evaluation protocol on OpenROAD for PPA-oriented improvements; and (iii) end-to-end demonstrations with minimal human oversight. Experiments in OpenROAD achieve routed wirelength reductions of up to 5.9%, and effective clock period reductions of up to 10.0%.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.782403",
        "filter_reason": "论文提出了一个名为AuDoPEDA的自主编码系统，明确使用了“coding agents”这一术语。该系统具备单智能体的核心特征：自主性、规划（提出研究方向）、工具使用（读取代码库、提交可执行差异）以及闭环反馈机制，完全符合LLM智能体的研究范围。"
    },
    {
        "index": "#321",
        "title": "Latent Space Communication via K-V Cache Alignment",
        "link": "/arxiv/2601.06123",
        "arxiv_id": "2601.06123",
        "authors": "Lucio M. Dery, Zohar Yahav, Henry Prior, Qixuan Feng, Jiajun Shen, Arthur Szlam",
        "summary": "Solving increasingly complex problems with large language models (LLMs) necessitates a move beyond individual models and towards multi-model systems that can effectively collaborate. While text has traditionally served as the medium for inter-model communication, a richer and more efficient exchange is possible if models can access each other's internal states directly. In this paper, we propose learning a shared representation space that aligns the k-v caches of multiple models, creating a high-bandwidth channel for collaboration without altering the underlying pre-trained parameters. We do so by augmenting each model with adapters to translate its state into and out of this shared space. Via a suite of experiments with Gemma-2 models, we demonstrate that this approach not only enables seamless inter-model communication but also improves individual model performance. We also show that the shared space allows for the direct transfer of learned skills, such as soft prompts, between different models. Our work represents a significant step towards a future where models can fluidly share knowledge and capabilities.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-04",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.799807",
        "filter_reason": "论文主要研究多模型系统之间的协作与通信机制，通过K-V缓存对齐实现模型间的高效信息交换，符合“多智能体：协作、通信”的研究范围。"
    },
    {
        "index": "#351",
        "title": "Autonomous QA Agent: A Retrieval-Augmented Framework for Reliable Selenium Script Generation",
        "link": "/arxiv/2601.06034",
        "arxiv_id": "2601.06034",
        "authors": "Dudekula Kasim Vali",
        "summary": "Software testing is critical in the software development lifecycle, yet translating requirements into executable test scripts remains manual and error-prone. While Large Language Models (LLMs) can generate code, they often hallucinate non-existent UI elements. We present the Autonomous QA Agent, a Retrieval-Augmented Generation (RAG) system that grounds Selenium script generation in project-specific documentation and HTML structure. By ingesting diverse formats (Markdown, PDF, HTML) into a vector database, our system retrieves relevant context before generation. Evaluation on 20 e-commerce test scenarios shows our RAG approach achieves 100% (20/20) syntax validity and 90% (18/20, 95% CI: [85%, 95%], p < 0.001) execution success, compared to 30% for standard LLM generation. While our evaluation is limited to a single domain, our method significantly reduces hallucinations by grounding generation in actual DOM structure, demonstrating RAG's potential for automated UI testing.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-28",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.809361",
        "filter_reason": "该论文提出了一个“Autonomous QA Agent”，利用RAG（检索增强生成）作为记忆机制，并生成Selenium脚本（工具使用），属于单智能体研究范畴（记忆、工具使用），且不属于排除的纯应用领域（如医疗/金融）或纯推理研究。"
    },
    {
        "index": "#355",
        "title": "AI-Assisted Authoring for Transparent, Data-Driven Documents",
        "link": "/arxiv/2601.06027",
        "arxiv_id": "2601.06027",
        "authors": "Alfonso Piscitelli, Cristina David, Mattia De Rosa, Ali Mohammed, Federico Nanni, Jacob Pake, Roly Perera, Jessy Sodimu, Chenyiqiu Zheng",
        "summary": "We introduce _transparent documents_, interactive web-based scholarly articles which allow readers to explore the relationship to the underlying data by hovering over fragments of text, and present an LLM-based tool for authoring transparent documents, building on recent developments in data provenance for general-purpose programming languages. As a target platform, our implementation uses Fluid, an open source programming language with a provenance-tracking runtime. Our agent-based tool supports a human author during the creation of transparent documents, identifying fragments of text which can be computed from data, such as numerical values selected from records or computed by aggregations like sum and mean, comparatives and superlatives like _better than_ and _largest_, trend-adjectives like _growing_, and similar quantitative or semi-quantitative phrases, and then attempts to synthesise a suitable Fluid query over the data which generates the target string. The resulting expression is inserted into the article's web page, turning the static text fragment into an interactable data-driven element able to reveal the data that underwrites the natural language claim. We evaluate our approach on a subset of SciGen, an open source dataset consisting of tables from scientific articles and their corresponding descriptions, which we extend with hand-generated counterfactual test cases to evaluate how well machine-generated expressions generalise. Our results show that gpt4o is often able to synthesise compound expressions extensionally compatible with our gold solutions.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Computational Engineering, Finance, and Science, Information Retrieval, Programming Languages",
        "date": "2025-10-27",
        "category": "cs.AI",
        "crawl_time": "2026-01-14T11:00:05.810595",
        "filter_reason": "论文明确提出了一个“基于智能体的工具”，利用LLM（GPT-4o）辅助人类作者进行文档创作。该智能体具备工具使用能力，能够识别文本片段并合成Fluid查询与外部系统交互，符合单智能体（工具使用）的研究范围。"
    },
    {
        "index": "#5",
        "title": "DarwinTOD: LLM Driven Lifelong Self Evolution for Task Oriented Dialog Systems",
        "link": "/arxiv/2601.07248",
        "arxiv_id": "2601.07248",
        "authors": "Shuyu Zhang, Yujie Liu, Xinru Wang, Cheng Zhang, Yanmin Zhu, Bin Li",
        "summary": "Traditional task-oriented dialog systems are unable to evolve from ongoing interactions or adapt to new domains after deployment, that is a critical limitation in real-world dynamic environments. Continual learning approaches depend on episodic retraining with human curated data, failing to achieve autonomy lifelong improvement. While evolutionary computation and LLM driven self improvement offer promising mechanisms for dialog optimization, they lack a unified framework for holistic, iterative strategy refinement. To bridge this gap, we propose DarwinTOD, a lifelong self evolving dialog framework that systematically integrates these two paradigms, enabling continuous strategy optimization from a zero-shot base without task specific fine-tuning. DarwinTOD maintains an Evolvable Strategy Bank and operates through a dual-loop process: online multi-agent dialog execution with peer critique, and offline structured evolutionary operations that refine the strategy bank using accumulated feedback. This closed-loop design enables autonomous continuous improvement without human intervention. Extensive experiments show that DarwinTOD surpasses previous state-of-the-art methods and exhibits continuous performance gains throughout evolution. Our work provides a novel framework for building dialog systems with lifelong self evolution capabilities.",
        "subjects": "Multiagent Systems, Human-Computer Interaction",
        "date": "2026-01-12",
        "category": "cs.MA",
        "crawl_time": "2026-01-14T11:00:07.143855",
        "filter_reason": "论文提出了DarwinTOD框架，核心研究内容包括LLM驱动的终身自我演化（符合自我演化标准）以及在线多智能体对话执行与同行评审机制（符合多智能体标准），属于Agentic AI的研究范畴。"
    },
    {
        "index": "#6",
        "title": "Agents of Diffusion: Enhancing Diffusion Language Models with Multi-Agent Reinforcement Learning for Structured Data Generation (Extended Version)",
        "link": "/arxiv/2601.07152",
        "arxiv_id": "2601.07152",
        "authors": "Aja Khanal, Kaushik T. Ranade, Rishabh Agrawal, Kalyan S. Basu, Apurva Narayan",
        "summary": "Generating high-quality structured data such as JSON records, remains a fundamental challenge for large language models (LLMs), particularly when semantic richness must coexist with strict schema adherence. While autoregressive LLMs offer strong structural consistency, they often struggle with semantic variation and output diversity. In contrast, diffusion language models (DLMs) introduce powerful mechanisms for semantic richness and bidirectional decoding, yet lack the inductive biases needed for reliable structure preservation. We present Agents of Diffusion (AoD), a novel framework that unifies the generative flexibility of DLMs with the reasoning capabilities of autoregressive models through language-mediated reinforcement learning. AoD frames structured text generation as a multi-agent alignment process, where a prompt optimization agent collaborates with a judge agent to iteratively guide a DLM using natural language feedback. This approach enables controllable, schema-consistent generation without modifying model parameters or relying on handcrafted constraints. AoD advances the state of controllable generation by demonstrating that diffusion models, when supervised by cooperative agents, can achieve both high semantic novelty and structural fidelity. Across multiple structured data benchmarks, AoD consistently outperforms diffusion and autoregressive baselines, establishing a new path forward for structure-aware, diversity-enhanced text synthesis.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-12",
        "category": "cs.MA",
        "crawl_time": "2026-01-14T11:00:07.144120",
        "filter_reason": "论文提出了一个名为“Agents of Diffusion”的框架，明确采用了多智能体架构，包含“提示优化智能体”和“判别智能体”。这些智能体通过协作和自然语言反馈来引导生成过程，符合“多智能体：协作、通信”的研究范围。"
    },
    {
        "index": "#4",
        "title": "SwarmFoam: An OpenFOAM Multi-Agent System Based on Multiple Types of Large Language Models",
        "link": "/arxiv/2601.07252",
        "arxiv_id": "2601.07252",
        "authors": "Chunwei Yang, Yankai Wang, Jianxiang Tang, Haojie Qu, Ziqiang Zou, YuLiu, Chunrui Deng, Zhifang Qiu, Ming Ding",
        "summary": "Numerical simulation is one of the mainstream methods in scientific research, typically performed by professional engineers. With the advancement of multi-agent technology, using collaborating agents to replicate human behavior shows immense potential for intelligent Computational Fluid Dynamics (CFD) simulations. Some muti-agent systems based on Large Language Models have been proposed. However, they exhibit significant limitations when dealing with complex geometries. This paper introduces a new multi-agent simulation framework, SwarmFoam. SwarmFoam integrates functionalities such as Multi-modal perception, Intelligent error correction, and Retrieval-Augmented Generation, aiming to achieve more complex simulations through dual parsing of images and high-level instructions. Experimental results demonstrate that SwarmFoam has good adaptability to simulation inputs from different modalities. The overall pass rate for 25 test cases was 84%, with natural language and multi-modal input cases achieving pass rates of 80% and 86.7%, respectively. The work presented by SwarmFoam will further promote the development of intelligent agent methods for CFD.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-12",
        "category": "cs.MA",
        "crawl_time": "2026-01-14T11:00:07.143572",
        "filter_reason": "该论文提出了一个基于多种大语言模型的多智能体系统，专注于智能体之间的协作、智能纠错（自我反思）以及检索增强生成（RAG），符合研究范围中关于“多智能体：协作”和“工具使用”的定义。尽管论文涉及CFD领域应用和多模态输入，但其核心贡献在于构建智能体框架而非单纯的应用落地或多模态模型开发。"
    },
    {
        "index": "#9",
        "title": "Bi-Mem: Bidirectional Construction of Hierarchical Memory for Personalized LLMs via Inductive-Reflective Agents",
        "link": "/arxiv/2601.06490",
        "arxiv_id": "2601.06490",
        "authors": "Wenyu Mao, Haosong Tan, Shuchang Liu, Haoyang Liu, Yifan Xu, Huaxiang Ji, Xiang Wang",
        "summary": "Constructing memory from users' long-term conversations overcomes LLMs' contextual limitations and enables personalized interactions. Recent studies focus on hierarchical memory to model users' multi-granular behavioral patterns via clustering and aggregating historical conversations. However, conversational noise and memory hallucinations can be amplified during clustering, causing locally aggregated memories to misalign with the user's global persona. To mitigate this issue, we propose Bi-Mem, an agentic framework ensuring hierarchical memory fidelity through bidirectional construction. Specifically, we deploy an inductive agent to form the hierarchical memory: it extracts factual information from raw conversations to form fact-level memory, aggregates them into thematic scenes (i.e., local scene-level memory) using graph clustering, and infers users' profiles as global persona-level memory. Simultaneously, a reflective agent is designed to calibrate local scene-level memories using global constraints derived from the persona-level memory, thereby enforcing global-local alignment. For coherent memory recall, we propose an associative retrieval mechanism: beyond initial hierarchical search, a spreading activation process allows facts to evoke contextual scenes, while scene-level matches retrieve salient supporting factual information. Empirical evaluations demonstrate that Bi-Mem achieves significant improvements in question answering performance on long-term personalized conversational tasks.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-10",
        "category": "cs.MA",
        "crawl_time": "2026-01-14T11:00:07.144910",
        "filter_reason": "论文提出了一个名为Bi-Mem的智能体框架，利用归纳智能体和反思智能体来构建和校准分层记忆。这属于单智能体研究范畴中的“记忆”和“自我反思”能力，符合筛选条件。"
    },
    {
        "index": "#11",
        "title": "DemMA: Dementia Multi-Turn Dialogue Agent with Expert-Guided Reasoning and Action Simulation",
        "link": "/arxiv/2601.06373",
        "arxiv_id": "2601.06373",
        "authors": "Yutong Song, Jiang Wu, Kazi Sharif, Honghui Xu, Nikil Dutt, Amir Rahmani",
        "summary": "Simulating dementia patients with large language models (LLMs) is challenging due to the need to jointly model cognitive impairment, emotional dynamics, and nonverbal behaviors over long conversations. We present DemMA, an expert-guided dementia dialogue agent for high-fidelity multi-turn patient simulation. DemMA constructs clinically grounded dementia personas by integrating pathology information, personality traits, and subtype-specific memory-status personas informed by clinical experts. To move beyond text-only simulation, DemMA explicitly models nonverbal behaviors, including motion, facial expressions, and vocal cues. We further introduce a Chain-of-Thought distillation framework that trains a single LLM to jointly generate reasoning traces, patient utterances, and aligned behavioral actions within one forward pass, enabling efficient deployment without multi-agent inference. Extensive evaluations with experts, medical students, and LLM judges demonstrate that DemMA significantly outperforms strong baselines across multiple metrics.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-10",
        "category": "cs.MA",
        "crawl_time": "2026-01-14T11:00:07.145433",
        "filter_reason": "论文提出了 DemMA，一个用于模拟痴呆症患者的单智能体系统。它涉及智能体核心能力，如记忆（构建人格）和行动（模拟非语言行为），并提出了特定的智能体训练框架（CoT 蒸馏），而不仅仅是将现有智能体应用于医疗任务。"
    }
]