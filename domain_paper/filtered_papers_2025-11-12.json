[
    {
        "index": "#9",
        "title": "Enabling Agents to Communicate Entirely in Latent Space",
        "link": "/arxiv/2511.09149",
        "arxiv_id": "2511.09149",
        "authors": "Zhuoyun Du, Runze Wang, Huiyu Bai, Zouying Cao, Xiaoyong Zhu, Bo Zheng, Wei Chen, Haochao Ying",
        "summary": "While natural language is the de facto communication medium for LLM-based agents, it presents a fundamental constraint. The process of downsampling rich, internal latent states into discrete tokens inherently limits the depth and nuance of information that can be transmitted, thereby hindering collaborative problem-solving. Inspired by human mind-reading, we propose Interlat (Inter-agent Latent Space Communication), a paradigm that leverages the last hidden states of an LLM as a representation of its mind for direct transmission (termed latent communication). An additional compression process further compresses latent communication via entirely latent space reasoning. Experiments demonstrate that Interlat outperforms both fine-tuned chain-of-thought (CoT) prompting and single-agent baselines, promoting more exploratory behavior and enabling genuine utilization of latent information. Further compression not only substantially accelerates inference but also maintains competitive performance through an efficient information-preserving mechanism. We position this work as a feasibility study of entirely latent space inter-agent communication, and our results highlight its potential, offering valuable insights for future research.",
        "subjects": "Machine Learning, Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-12",
        "category": "cs.MA",
        "crawl_time": "2025-11-13T11:00:04.817246",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的筛选标准高度契合。以下是我的详细判断过程： 1.  **第一步：核心判断——保留** - **论文本质**: 这篇论文的核心贡献是提出了一种名为 `Interlat` 的全新**通信范式**。它不是将现有智能体框架应用于某个领域，而是从根本上**改进**了多智能体系统（Multi-Agent Systems）中智能体之间的通信方式。它让智能体绕过自然语言，直接在模型的潜在空间进行信息交换。 - **符合性**: 这完全符合“核心贡献在于构建、改进或演化LLM智能体”的要求。它属于对多智能体系统基础架构的**改进**，旨在解决“协作问题解决”中的信息瓶颈问题。因此，根据第一步的核心判断，应予以**保留**。 2.  **第二步：正面指标——高度相关** - **核心范式**: 论文明确聚焦于 `LLM-based Agents` 和 `Multi-Agent Systems (MAS)`。 - **多智能体**: 摘要中反复出现 `communication`、`collaborative problem-solving`、`inter-agent` 等关键词，直接命中了您研究焦点中的“多智能体”方向，特别是其子方向“通信”与“协作”。 - **智能体能力**: 论文通过提出新的通信机制，旨在提升智能体在协作任务中的表现，这间接促进了更高级的规划和问题解决能力。 3.  **第三步：排除标准——未触及** - **安全与对齐**: 论文的主要贡献是关于通信效率和协作性能，不涉及 `Safety`、`Alignment`、`Interpretability` 等议题。 - **多模态与视觉**: 论文的研究对象是基于文本的LLM，未涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 论文虽然提到了 `chain-of-thought (CoT)` 和 `latent space reasoning`，但其目的并非提升LLM本身的基础数学或逻辑推理能力。相反，它是在**多智能体协作的背景下**，探讨一种更高效的推理和通信机制。这完全符合“保留关于智能体如何进行规划或在复杂任务中进行多步推理”的规则。 **最终决策**: 这篇论文的核心是提出一种创新的、旨在提升多智能体协作效率的通信框架 `Interlat`。它直接解决了多智能体系统中的一个根本性挑战（自然语言通信的信息损失），并提出了一个可行的解决方案。这与您研究课题中的“多智能体”方向，特别是“通信”与“协作”子方向，完美匹配。因此，这篇论文是您应该重点保留的前沿研究。"
    },
    {
        "index": "#10",
        "title": "Solving a Million-Step LLM Task with Zero Errors",
        "link": "/arxiv/2511.09030",
        "arxiv_id": "2511.09030",
        "authors": "Elliot Meyerson, Giuseppe Paolo, Roberto Dailey, Hormoz Shahrzad, Olivier Francon, Conor F. Hayes, Xin Qiu, Babak Hodjat, Risto Miikkulainen",
        "summary": "LLMs have achieved remarkable breakthroughs in reasoning, insights, and tool use, but chaining these abilities into extended processes at the scale of those routinely executed by humans, organizations, and societies has remained out of reach. The models have a persistent error rate that prevents scale-up: for instance, recent experiments in the Towers of Hanoi benchmark domain showed that the process inevitably becomes derailed after at most a few hundred steps. Thus, although LLM research is often still benchmarked on tasks with relatively few dependent logical steps, there is increasing attention on the ability (or inability) of LLMs to perform long range tasks. This paper describes MAKER, the first system that successfully solves a task with over one million LLM steps with zero errors, and, in principle, scales far beyond this level. The approach relies on an extreme decomposition of a task into subtasks, each of which can be tackled by focused microagents. The high level of modularity resulting from the decomposition allows error correction to be applied at each step through an efficient multi-agent voting scheme. This combination of extreme decomposition and error correction makes scaling possible. Thus, the results suggest that instead of relying on continual improvement of current LLMs, massively decomposed agentic processes (MDAPs) may provide a way to efficiently solve problems at the level of organizations and societies.",
        "subjects": "Artificial Intelligence, Computation and Language, Multiagent Systems",
        "date": "2025-11-12",
        "category": "cs.MA",
        "crawl_time": "2025-11-13T11:00:04.817548",
        "filter_reason": "这篇论文完全符合研究范围，其核心贡献直接命中了“多智能体”和“单智能体”的关键方向。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM作为工具去解决某个特定领域的问题，而是提出了一种名为MAKER的**新系统/新框架**。该框架的核心是关于如何构建一个能够执行超长任务链的LLM智能体系统。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **多智能体**: 论文明确提出了“microagents”（微智能体）和“multi-agent voting scheme”（多智能体投票方案）。这表明其核心是一个**多智能体系统 (MAS)**，智能体之间通过协作（投票）来完成任务。 - **自我修正**: 论文的核心创新之一是通过多智能体投票机制在每一步进行“error correction”（错误修正）。这直接对应了`Self-Correction`这一关键能力。 - **规划**: 解决一个百万步的任务，必然涉及到极其复杂的任务分解和执行规划。论文提出的“extreme decomposition”（极端分解）就是一种高级的规划策略。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐、可解释性或幻觉，也未涉及多模态或视觉。因此，它没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何进行规划和多步推理的完美范例。它不是在改进LLM本身的基础推理能力（如数学计算），而是在构建一个**新的Agentic框架（MAKER/MDAPs）**来克服LLM在长链推理中的错误累积问题。这完全符合“保留”的条件。 **最终决策:** 论文的核心贡献是提出了一种名为MAKER的**大规模分解的智能体过程（MDAPs）**。该方法通过将任务极端分解为多个子任务，并由**多个微智能体**通过**投票协作**的方式执行和修正，从而实现了百万步任务的零错误完成。 这个贡献直接属于： - **多智能体**：提出了一个由微智能体构成并通过投票协作的系统。 - **单智能体**：解决了智能体在长程任务中的规划和自我修正问题。 因此，该论文不仅符合，而且是“LLM智能体及其演化”这一研究课题下的高质量前沿文献。"
    },
    {
        "index": "#4",
        "title": "Convergence dynamics of Agent-to-Agent Interactions with Misaligned objectives",
        "link": "/arxiv/2511.08710",
        "arxiv_id": "2511.08710",
        "authors": "Romain Cosentino, Sarath Shekkizhar, Adam Earle",
        "summary": "We develop a theoretical framework for agent-to-agent interactions in multi-agent scenarios. We consider the setup in which two language model based agents perform iterative gradient updates toward their respective objectives in-context, using the output of the other agent as input. We characterize the generation dynamics associated with the interaction when the agents have misaligned objectives, and show that this results in a biased equilibrium where neither agent reaches its target - with the residual errors predictable from the objective gap and the geometry induced by the prompt of each agent. We establish the conditions for asymmetric convergence and provide an algorithm that provably achieves an adversarial result, producing one-sided success. Experiments with trained transformer models as well as GPT$5$ for the task of in-context linear regression validate the theory. Our framework presents a setup to study, predict, and defend multi-agent systems; explicitly linking prompt design and interaction setup to stability, bias, and robustness.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-11-11",
        "category": "cs.MA",
        "crawl_time": "2025-11-13T11:00:04.815893",
        "filter_reason": "这篇论文符合你的研究范围，核心依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是**开发一个理论框架来分析和理解多智能体系统的交互动态**。它没有将LLM智能体作为工具去解决一个外部领域的问题，而是直接研究智能体本身的行为。虽然它没有提出一个全新的“构建”智能体的框架，但它提供了**“改进”和“理解”多智能体系统**的基础理论和分析方法。这完全符合你筛选标准中“改进LLM智能体”和“多智能体系统”的范畴。它不是非演化型应用，也不是非Agentic的推理或基础设施研究。 2.  **正面指标 (第二步):** 论文明确包含了你的核心关注点。 *   **核心范式:** 论文标题和摘要反复提及 `Agent-to-Agent Interactions` 和 `multi-agent scenarios`，直接命中 `Multi-Agent Systems (MAS)`。 *   **多智能体:** 研究内容是智能体间的 `Communication`（“using the output of the other agent as input”）和一种对抗性的交互（`Misaligned objectives`），这属于多智能体研究的核心议题。 3.  **排除标准 (第三步):** 论文没有触发排除标准。 *   **安全与对齐:** 尽管论文提到了 `Misaligned objectives` 和 `defend multi-agent systems`，但这只是其研究的**背景和案例**，而不是其**核心贡献**。论文的核心是提出一个关于“收敛动态”的通用理论框架，用以分析、预测和控制这类交互。它的主要贡献是理论和方法论，而非一个具体的对齐或安全技术。因此，它不应被排除。 *   **多模态与视觉:** 论文不涉及多模态内容。 4.  **最终决策 (第五步):** 综合来看，这篇论文通过理论建模的方式，深入探讨了LLM多智能体系统在目标不一致情况下的交互行为、稳定性和收敛性。这种对智能体系统底层动态的深刻理解，是设计更鲁棒、更高效、更可控的多智能体系统的理论基础，完全符合你关于“LLM智能体及其演化”课题中“多智能体”方向的研究目标。它为该领域提供了重要的理论洞见和分析工具，因此应该被保留。"
    },
    {
        "index": "#11",
        "title": "AI Founding Fathers: A Case Study of GIS Search in Multi-Agent Pipelines",
        "link": "/arxiv/2511.09005",
        "arxiv_id": "2511.09005",
        "authors": "Alvin Chauhan",
        "summary": "Although Large Language Models (LLMs) show exceptional fluency, efforts persist to extract stronger reasoning capabilities from them. Drawing on search-based interpretations of LLM computation, this paper advances a systematic framework for understanding LLM reasoning and optimization. Namely, that enhancing reasoning is best achieved by structuring a multi-agent pipeline to ensure a traversal of the search space in a gradual, incremental, and sequential (GIS) manner. Stated succinctly, high-quality reasoning is a controlled, incremental search. To test this framework, we investigate the efficacy of recursive refinement (RR)--an iterative process of self-criticism, adversarial stress-testing, and integrating critical feedback--as a practical method for implementing GIS search. We designed an experiment comparing a simple, linear pipeline against a complex, explicitly structured pipeline leveraging a recursive refinement layer. The multi-agent models were constructed to reflect the historical personas of three US Founding Fathers (Hamilton, Jefferson, and Madison) using RAG-powered corpora and were prompted to generate responses to three contemporary political issues. Model performance was evaluated using a two-tiered approach: a quantitative score from an LLM arbiter agent and qualitative human judgment. Our results revealed that the complex model consistently outperformed the simple model across all nine test cases with an average arbiter-outputted score of 88.3 versus 71.7. The complex model's arguments were superior in analytical depth, structural nuance, and strategic framing. We conclude that recursive refinement is a robust architectural feature for enhancing LLM reasoning via GIS search.",
        "subjects": "Artificial Intelligence, Computation and Language, Multiagent Systems",
        "date": "2025-11-12",
        "category": "cs.MA",
        "crawl_time": "2025-11-13T11:00:04.817807",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于某个领域，而是提出了一种**系统性的框架（GIS搜索）和一种具体的架构特性（递归精炼）**来增强LLM的推理能力。这个框架的本质是**构建一个多智能体流水线**，通过智能体之间的协作和迭代来完成任务。这直接命中了您“构建、改进LLM智能体”的核心目标。它不是非演化型应用，因为它提出的是一种新的智能体架构和方法论。 2.  **第二步：正面指标——高度匹配** 论文包含了多个您关注的核心范式和能力： *   **多智能体**: 论文明确提出了“multi-agent pipeline”，并设计了三个具有不同角色的智能体（Hamilton, Jefferson, Madison）进行协作。 *   **自我演化**: 论文的核心机制“recursive refinement (RR)”被描述为“一个包含自我批评、对抗性压力测试和整合关键反馈的迭代过程”。这完全符合您定义的“自我完善和迭代”的演化机制，特别是`Self-Refine`和`Iterative Improvement`。 *   **规划/推理**: 论文的整个框架都是为了解决复杂任务中的多步推理问题，其提出的GIS搜索是一种结构化的推理方法，属于智能体规划能力的范畴。 3.  **第三步：排除标准——不适用** 论文的主要贡献是关于智能体架构和推理增强，不涉及安全、对齐、可解释性或多模态技术。因此，不触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文的研究内容是关于“智能体如何进行规划或在复杂任务中进行多步推理”，它通过构建一个多智能体系统（GIS搜索）来实现这一点，因此属于“保留”的范畴。 *   **自我演化的应用**: 论文虽然以“当代政治议题”作为案例研究，但其核心是验证“递归精炼”这一**新的自我演化机制**的有效性。这完全符合您设定的“例外”规则：即使应用在特定领域，只要核心贡献是新的自我演化机制，就应该保留。 **总结**: 该论文的核心贡献是提出了一种名为“GIS搜索”的多智能体协作框架，并通过“递归精炼”这一自我演化机制来实现。这精准地覆盖了您研究课题中的“多智能体”和“自我演化”两个核心方向。论文中的应用场景（政治议题）仅作为验证其架构有效性的实验，而非论文的主要贡献。因此，这篇论文是您研究范围内的前沿高质量文献。"
    },
    {
        "index": "#6",
        "title": "Self-Correcting Large Language Models: Generation vs. Multiple Choice",
        "link": "/arxiv/2511.09381",
        "arxiv_id": "2511.09381",
        "authors": "Hossein A. Rahmani, Satyapriya Krishna, Xi Wang, Mohammadmehdi Naghiaei, Emine Yilmaz",
        "summary": "Large language models have recently demonstrated remarkable abilities to self-correct their responses through iterative refinement, often referred to as self-consistency or self-reflection. However, the dynamics of this self-correction mechanism may differ substantially depending on whether the model is tasked with open-ended text generation or with selecting the most appropriate response from multiple predefined options. In this paper, we conduct a systematic investigation of these two paradigms by comparing performance trends and error-correction behaviors across various natural language understanding and reasoning tasks, covering language models of different scales and families. Our experimental results reveal distinct patterns of improvement and failure modes: \\textit{While open-ended generation often benefits from the flexibility of re-interpretation and compositional refinement, multiple-choice selection can leverage clearer solution boundaries but may be limited by the provided options}. This contrast also reflects the dual demands faced by emerging agentic LLM applications: effective agents must not only generate and refine open-ended plans or explanations, but also make reliable discrete choices when operating within constrained action spaces. Our findings, therefore, highlight that the design of self-correction mechanisms should take into account the interaction between task structure and output space, with implications for both knowledge-intensive reasoning and decision-oriented applications of LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-12",
        "category": "cs.CL",
        "crawl_time": "2025-11-13T11:00:05.602710",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非将LLM作为工具应用于特定领域，也不是提升LLM的基础推理能力。它的核心是**系统性研究“自我修正”这一机制**。自我修正是LLM智能体实现“自我反思”和“自我演化”的关键环节。论文通过对比不同任务范式下的自我修正行为，为如何设计和改进智能体的自我修正能力提供了深刻的见解。这完全符合“改进或演化LLM智能体”的核心目标。 2.  **正面指标 (第二步):** 论文明确包含了多个核心关注点： *   **智能体能力:** `Self-Correction` (自我修正) 和 `Self-Reflection` (自我反思) 是论文的绝对核心主题。 *   **演化机制:** 论文研究的“迭代优化”本质上是一种 `Iterative Improvement` (迭代改进) 的演化机制。 *   **核心范式:** 摘要中明确提到其发现对“新兴的agentic LLM applications”具有启示意义，直接点明了其与 `Agentic AI` 的关联。 3.  **排除标准 (第三步):** 论文的主要贡献不涉及安全、对齐、可解释性或多模态等领域，因此没有触发任何排除标准。 4.  **特殊和模糊情况处理 (第四步):** *   **推理/规划:** 这篇论文完美地符合“保留”条件。它不是在研究如何让LLM更好地解数学题，而是在研究**智能体在执行任务时如何进行自我修正**。摘要中明确指出，有效的智能体“必须能够生成和优化开放式的计划”，这正是智能体规划与反思能力的体现。论文的研究成果直接指导了如何构建更可靠的智能体决策和规划循环。 **总结:** 该论文的本质是对LLM智能体的一项核心能力——自我修正——进行深入的机理分析。它揭示了在不同任务结构下，这一能力的表现模式和局限性，并明确指出其研究结论对于“设计未来的智能体”至关重要。因此，这篇论文虽然不是提出一个全新的智能体框架，但它为“改进和演化LLM智能体”提供了关键的理论基础和设计指导，完全符合您关于“单智能体”和“自我演化”的研究焦点。"
    },
    {
        "index": "#21",
        "title": "LoopTool: Closing the Data-Training Loop for Robust LLM Tool Calls",
        "link": "/arxiv/2511.09148",
        "arxiv_id": "2511.09148",
        "authors": "Kangning Zhang, Wenxiang Jiao, Kounianhua Du, Yuan Lu, Weiwen Liu, Weinan Zhang, Lei Zhang, Yong Yu",
        "summary": "Augmenting Large Language Models (LLMs) with external tools enables them to execute complex, multi-step tasks. However, tool learning is hampered by the static synthetic data pipelines where data generation and model training are executed as two separate, non-interactive processes. This approach fails to adaptively focus on a model's specific weaknesses and allows noisy labels to persist, degrading training efficiency. We introduce LoopTool, a fully automated, model-aware data evolution framework that closes this loop by tightly integrating data synthesis and model training. LoopTool iteratively refines both the data and the model through three synergistic modules: (1) Greedy Capability Probing (GCP) diagnoses the model's mastered and failed capabilities; (2) Judgement-Guided Label Verification (JGLV) uses an open-source judge model to find and correct annotation errors, progressively purifying the dataset; and (3) Error-Driven Data Expansion (EDDE) generates new, challenging samples based on identified failures. This closed-loop process operates within a cost-effective, open-source ecosystem, eliminating dependence on expensive closed-source APIs. Experiments show that our 8B model trained with LoopTool significantly surpasses its 32B data generator and achieves new state-of-the-art results on the BFCL-v3 and ACEBench benchmarks for its scale. Our work demonstrates that closed-loop, self-refining data pipelines can dramatically enhance the tool-use capabilities of LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-11-12",
        "category": "cs.CL",
        "crawl_time": "2025-11-13T11:00:05.652697",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献精准地命中了“自我演化”和“单智能体”两个研究方向。 **1. 核心判断 (第一步):** - **保留**。这篇论文的本质不是将LLM作为工具应用，也不是提升LLM的基础推理能力，而是提出了一种全新的方法论框架——**LoopTool**。这个框架的核心是**“closing the data-training loop”**（闭合数据-训练循环），旨在通过一个自动化的、迭代的流程来**演化**LLM的工具使用能力。这完全符合“构建、改进或演化LLM智能体”的核心目标。 **2. 正面指标分析 (第二步):** - **自我演化**: 论文的核心贡献就是一个“data evolution framework”（数据演化框架）。摘要中明确使用了“iteratively refines”（迭代优化）、“closed-loop”（闭环）、“self-refining data pipelines”（自我精炼的数据管道）等词汇，这些都是“自我演化”方向的典型特征。其三个模块（GCP诊断、JGLV净化、EDDE扩展）共同构成了一个完整的自我诊断、自我修正、自我增强的演化循环。 - **单智能体**: 论文的研究目标是“enhance the tool-use capabilities of LLMs”（增强LLM的工具使用能力）。“工具使用”是单智能体研究的核心能力之一。因此，该论文直接为提升单智能体的关键能力做出了贡献。 **3. 排除标准分析 (第三步):** - 论文不涉及安全、对齐、可解释性等排除项。 - 论文不涉及多模态或视觉，其焦点完全在文本工具调用上。 **4. 特殊情况处理 (第四步):** - **自我演化的应用**: 这篇论文并非一个应用，其提出的“自我演化”机制本身就是核心贡献。即使它被应用在工具调用这个特定任务上，根据您的规则，这种提出新演化机制的论文也应该被保留。 - **推理/规划**: 论文虽然不直接提出新的规划算法，但它通过演化数据来提升智能体执行复杂任务（通常需要规划和推理）的能力，这属于对智能体能力的系统性改进，而非对LLM基础推理能力的微调，因此符合保留标准。 **结论:** 该论文的核心贡献是提出了一种名为LoopTool的**自我演化框架**，用于**迭代式地改进LLM智能体的工具使用能力**。这完美契合了您研究课题中的“自我演化”和“单智能体（工具使用）”两个核心方向。它不是简单的应用，而是对智能体能力提升方法论的探索，因此是高度相关的前沿论文。"
    },
    {
        "index": "#25",
        "title": "Thinking Forward and Backward: Multi-Objective Reinforcement Learning for Retrieval-Augmented Reasoning",
        "link": "/arxiv/2511.09109",
        "arxiv_id": "2511.09109",
        "authors": "Wenda Wei, Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Lixin Su, Shuaiqiang Wang, Dawei Yin, Maarten de Rijke, Xueqi Cheng",
        "summary": "Retrieval-augmented generation (RAG) has proven to be effective in mitigating hallucinations in large language models, yet its effectiveness remains limited in complex, multi-step reasoning scenarios.Recent efforts have incorporated search-based interactions into RAG, enabling iterative reasoning with real-time retrieval. Most approaches rely on outcome-based supervision, offering no explicit guidance for intermediate steps. This often leads to reward hacking and degraded response quality. We propose Bi-RAR, a novel retrieval-augmented reasoning framework that evaluates each intermediate step jointly in both forward and backward directions. To assess the information completeness of each step, we introduce a bidirectional information distance grounded in Kolmogorov complexity, approximated via language model generation probabilities. This quantification measures both how far the current reasoning is from the answer and how well it addresses the question. To optimize reasoning under these bidirectional signals, we adopt a multi-objective reinforcement learning framework with a cascading reward structure that emphasizes early trajectory alignment. Empirical results on seven question answering benchmarks demonstrate that Bi-RAR surpasses previous methods and enables efficient interaction and reasoning with the search engine during training and inference.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-11-12",
        "category": "cs.CL",
        "crawl_time": "2025-11-13T11:00:05.654655",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体的推理框架。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质是提出一个名为 `Bi-RAR` 的新颖框架，用于改进检索增强推理。这并非简单地将现有LLM或智能体框架应用于某个领域，而是**构建了一个新的方法论**来解决智能体在复杂任务中的推理问题。论文的核心是关于智能体如何进行多步推理、与环境（搜索引擎）交互、并优化其行为轨迹，这完全符合“构建、改进LLM智能体”的核心目标。它不是非演化型应用，也不是非Agentic的基础推理，而是聚焦于智能体的推理过程本身。 **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **智能体能力**: *   `Planning` (规划): 论文的核心是优化“推理轨迹”，这本质上是一种规划过程。它通过强化学习来决定下一步的检索和推理动作。 *   `Tool Use / Tool Augmentation` (工具使用): 论文明确将“检索”和“与搜索引擎的交互”作为智能体使用的工具来增强其推理能力。 *   `Self-Correction / Self-Reflection` (自我纠正/反思): 论文提出的“双向评估”机制，即在每个中间步骤同时评估其与问题和答案的距离，是一种显式的自我反思和纠正机制，旨在防止推理路径偏离。 *   **核心范式**: 论文的工作与 `ReAct` (Reason+Act) 范式高度相关，可以看作是对该范式在多步推理场景下的一种深化和改进，通过更精细的奖励信号来指导智能体的行为。 **第三步：排除标准——未触发** 论文的主要贡献是提升推理效率和效果，并未涉及安全、对齐、可解释性或多模态等排除领域。因此，没有触发任何排除标准。 **第四步：处理特殊和模糊情况——符合保留条件** *   **推理/规划**: 这篇论文是“关于智能体如何进行规划或在复杂任务中进行多步推理”的典型范例。它不是在改进LLM本身的数学或逻辑能力，而是在构建一个**外部的、迭代的、与环境交互的推理框架**。这正是Agentic AI研究的核心，因此应该保留。 **第五步：最终决策** 综合以上分析，该论文的核心贡献是提出了一种新的LLM智能体框架 (`Bi-RAR`)，该框架通过引入双向评估和多目标强化学习，显著增强了智能体在复杂任务中的规划、工具使用和自我反思能力。这与您的研究课题“LLM智能体及其演化”中的“单智能体”方向（特别是规划、工具使用、自我反思）高度契合。因此，最终判断为 **True**。"
    },
    {
        "index": "#35",
        "title": "BioVerge: A Comprehensive Benchmark and Study of Self-Evaluating Agents for Biomedical Hypothesis Generation",
        "link": "/arxiv/2511.08866",
        "arxiv_id": "2511.08866",
        "authors": "Fuyi Yang, Chenchen Ye, Mingyu Derek Ma, Yijia Xiao, Matthew Yang, Wei Wang",
        "summary": "Hypothesis generation in biomedical research has traditionally centered on uncovering hidden relationships within vast scientific literature, often using methods like Literature-Based Discovery (LBD). Despite progress, current approaches typically depend on single data types or predefined extraction patterns, which restricts the discovery of novel and complex connections. Recent advances in Large Language Model (LLM) agents show significant potential, with capabilities in information retrieval, reasoning, and generation. However, their application to biomedical hypothesis generation has been limited by the absence of standardized datasets and execution environments. To address this, we introduce BioVerge, a comprehensive benchmark, and BioVerge Agent, an LLM-based agent framework, to create a standardized environment for exploring biomedical hypothesis generation at the frontier of existing scientific knowledge. Our dataset includes structured and textual data derived from historical biomedical hypotheses and PubMed literature, organized to support exploration by LLM agents. BioVerge Agent utilizes a ReAct-based approach with distinct Generation and Evaluation modules that iteratively produce and self-assess hypothesis proposals. Through extensive experimentation, we uncover key insights: 1) different architectures of BioVerge Agent influence exploration diversity and reasoning strategies; 2) structured and textual information sources each provide unique, critical contexts that enhance hypothesis generation; and 3) self-evaluation significantly improves the novelty and relevance of proposed hypotheses.",
        "subjects": "Computation and Language",
        "date": "2025-11-12",
        "category": "cs.CL",
        "crawl_time": "2025-11-13T11:00:05.692034",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于生物医学领域，而是提出了一个名为 \"BioVerge Agent\" 的**LLM智能体框架**。这个框架的核心机制是包含一个 \"Generation\" 模块和一个 \"Evaluation\" 模块，能够**迭代地产生和自我评估假设**。这直接对应了您研究目标中的“构建、改进或演化 LLM智能体”，特别是“自我演化”方向。因此，它不属于“非演化型应用”的排除范畴。 2.  **第四步：处理特殊和模糊情况——适用例外规则** 这篇论文是“自我演化的应用”的典型案例。虽然其应用场景是特定的生物医学领域，但根据您设定的核心规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” BioVerge Agent的“自我评估”和“迭代改进”机制正是这种新的自我演化方法论，是该论文的核心创新点，因此应当保留。 3.  **第二步：正面指标——高度相关** 论文中包含了大量您关注的核心关键词和概念： *   **核心范式**: `LLM-based Agents` (明确提及), `Self-Evolving` (通过`Self-Evaluating`体现)。 *   **智能体能力**: `ReAct` (明确提及), `Self-Reflection` / `Self-Correction` (通过`self-assess`和`self-evaluation`体现)。 *   **演化机制**: `Self-Improvement` (通过`iteratively produce and self-assess`体现), `Iterative Improvement`。 这些正面指标进一步确认了论文与您研究焦点的高度契合性。 4.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性或多模态视觉，因此没有触及任何排除标准。 **总结**: 论文的核心是构建一个具有**自我评估和迭代改进能力**的LLM智能体框架，这完全属于“自我演化”的研究范畴。尽管它以生物医学假设生成为应用场景，但其核心贡献在于智能体本身的演化机制，而非应用本身。因此，这篇论文是您研究课题下的高质量前沿文献。"
    },
    {
        "index": "#39",
        "title": "Structured Uncertainty guided Clarification for LLM Agents",
        "link": "/arxiv/2511.08798",
        "arxiv_id": "2511.08798",
        "authors": "Manan Suri, Puneet Mathur, Nedim Lipka, Franck Dernoncourt, Ryan A. Rossi, Dinesh Manocha",
        "summary": "LLM agents extend large language models with tool-calling capabilities, but ambiguous user instructions often lead to incorrect invocations and task failures. We introduce a principled formulation of structured uncertainty over tool-call parameters, modeling joint tool-argument clarification as a POMDP with Expected Value of Perfect Information (EVPI) objective for optimal question selection and aspect-based cost modeling to prevent redundancy. Our SAGE-Agent leverages this structured uncertainty to achieve superior efficiency: increasing coverage on ambiguous tasks by 7-39\\% while reducing clarification questions by 1.5-2.7$\\times$ compared to strong prompting and uncertainty-based baselines. We present ClarifyBench, the first multi-turn tool-augmented disambiguation benchmark with realistic LLM-based user simulation across diverse domains including document editing, vehicle control, and travel booking. Additionally, we demonstrate that structured uncertainty provides effective training signals for reinforcement learning, boosting When2Call accuracy from 36.5\\% to 65.2\\% (3B model) and 36.7\\% to 62.9\\% (7B model) through uncertainty-weighted GRPO training. These results establish structured uncertainty as a principled, efficient approach for tool-augmented agents, improving both task success and interaction efficiency in real-world scenarios.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-11",
        "category": "cs.CL",
        "crawl_time": "2025-11-13T11:00:05.694811",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于**构建和改进LLM智能体**。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决一个外部领域的问题，而是聚焦于LLM智能体本身的一个核心缺陷——**在处理模糊指令时容易失败**。论文的核心贡献是提出了一种名为“结构化不确定性”的新方法论，并基于此构建了“SAGE-Agent”框架。这个框架旨在**改进智能体的工具使用能力**，使其能够主动澄清模糊指令，从而提高任务成功率。这完全属于“构建、改进LLM智能体”的范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (论文标题和摘要中多次提及)。 - **智能体能力**: - `Tool Use / Tool Augmentation`: 这是论文的核心主题，研究如何改进智能体的工具调用。 - `Planning`: 论文将澄清过程建模为POMDP（部分可观察马尔可夫决策过程），并使用EVPI（完美信息期望值）来选择最优问题，这是一种典型的智能体规划行为。 - `Self-Correction`: 智能体通过主动提问来纠正自己对模糊指令的潜在错误理解，这是一种高级的自我纠错机制。 3.  **第三步：排除标准** - 论文的主要贡献**不涉及**安全与对齐（Safety, Alignment）、可解释性（Interpretability）或多模态（Vision）。虽然“不确定性”与可解释性有一定关联，但本文的目标是利用不确定性来**提升智能体的决策效率和任务成功率**，而不是为了解释模型本身。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“智能体规划”的典型范例。它研究的不是LLM底层的数学或逻辑推理能力，而是智能体在交互环境中如何规划下一步行动（是直接调用工具，还是先向用户提问）。这完全符合保留条件。 5.  **第五步：最终决策** - 综合以上分析，该论文的核心贡献是提出了一种新的方法论（结构化不确定性）和框架（SAGE-Agent）来**改进LLM智能体的工具使用和规划能力**。它直接解决了智能体在现实世界中面临的一个关键挑战（指令模糊性），并提供了系统性的解决方案。因此，这篇论文与您的研究方向，特别是**“单智能体”中的“工具使用”和“规划”子方向**，高度契合。"
    },
    {
        "index": "#49",
        "title": "Chopping Trees: Semantic Similarity Based Dynamic Pruning for Tree-of-Thought Reasoning",
        "link": "/arxiv/2511.08595",
        "arxiv_id": "2511.08595",
        "authors": "Joongho Kim, Xirui Huang, Zarreen Reza, Gabriel Grand, Kevin Zhu, Ryan Lagasse",
        "summary": "Tree-of-Thought (ToT) reasoning boosts the problem-solving abilities of Large Language Models (LLMs) but is computationally expensive due to semantic redundancy, where distinct branches explore equivalent reasoning paths. We introduce Semantic Similarity-Based Dynamic Pruning (SSDP), a lightweight method that, to the best of our knowledge, is the first framework to integrate online semantic merging into parallelized tree search, enabling the clustering and pruning of redundant steps in real time. Across reasoning benchmarks, including GSM8K and MATH500, SSDP achieves up to a 2.3x speedup over state-of-the-art tree-search baselines while maintaining competitive accuracy (typically within 5% of the strongest baseline) and reducing the number of explored nodes by 85-90%, demonstrating a practical approach to efficient, scalable LLM reasoning. The implementation of SSDP is publicly available at https://github.com/kimjoonghokim/SSDP.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-30",
        "category": "cs.CL",
        "crawl_time": "2025-11-13T11:00:05.727530",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了一种名为“语义相似性动态剪枝（SSDP）”的新方法，用于优化“思维树”推理框架。ToT是一种典型的LLM智能体规划和多步推理范式。该论文并非将ToT作为工具应用于某个特定领域，而是直接对ToT这一Agentic框架本身进行改进，旨在提升其效率。因此，它不属于“非演化型应用”或“非Agentic的推理”，而是对智能体核心能力的直接增强。 2.  **第二步：正面指标** - 论文的核心内容与多个正面指标高度相关： - **核心范式**: `Agentic AI`, `LLM-based Agents`。ToT是Agentic AI的关键研究方向。 - **智能体能力**: `Planning`。ToT本质上是一种复杂的规划和搜索策略，而SSDP是对这一规划过程的优化，使其更高效、更可扩展。论文的核心就是改进智能体的规划能力。 3.  **第三步：排除标准** - 论文的研究焦点是提升推理效率和速度，不涉及安全、对齐、可解释性或视觉多模态等内容。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这是最关键的一点。根据筛选规则，“如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架），则保留”。这篇论文完美符合这一条件。它研究的不是LLM底层的数学或逻辑能力，而是智能体在解决复杂问题时采用的**高层搜索和规划策略**（即ToT），并提出了一种优化该策略的机制。这完全属于“单智能体”研究中“规划”方向的范畴。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于**改进LLM智能体的规划与推理框架（ToT）**，通过引入动态剪枝机制，显著提升了智能体在复杂任务中的推理效率。这直接对应了研究课题中“单智能体”方向下的“规划”子方向。因此，该论文与你的研究范围高度相关，应予以保留。"
    },
    {
        "index": "#60",
        "title": "History-Aware Reasoning for GUI Agents",
        "link": "/arxiv/2511.09127",
        "arxiv_id": "2511.09127",
        "authors": "Ziwei Wang, Leyang Yang, Xiaoxuan Tang, Sheng Zhou, Dajun Chen, Wei Jiang, Yong Li",
        "summary": "Advances in Multimodal Large Language Models have significantly enhanced Graphical User Interface (GUI) automation. Equipping GUI agents with reliable episodic reasoning capabilities is essential for bridging the gap between users' concise task descriptions and the complexities of real-world execution. Current methods integrate Reinforcement Learning (RL) with System-2 Chain-of-Thought, yielding notable gains in reasoning enhancement. For long-horizon GUI tasks, historical interactions connect each screen to the goal-oriented episode chain, and effectively leveraging these clues is crucial for the current decision. However, existing native GUI agents exhibit weak short-term memory in their explicit reasoning, interpreting the chained interactions as discrete screen understanding, i.e., unawareness of the historical interactions within the episode. This history-agnostic reasoning challenges their performance in GUI automation. To alleviate this weakness, we propose a History-Aware Reasoning (HAR) framework, which encourages an agent to reflect on its own errors and acquire episodic reasoning knowledge from them via tailored strategies that enhance short-term memory in long-horizon interaction. The framework mainly comprises constructing a reflective learning scenario, synthesizing tailored correction guidelines, and designing a hybrid RL reward function. Using the HAR framework, we develop a native end-to-end model, HAR-GUI-3B, which alters the inherent reasoning mode from history-agnostic to history-aware, equipping the GUI agent with stable short-term memory and reliable perception of screen details. Comprehensive evaluations across a range of GUI-related benchmarks demonstrate the effectiveness and generalization of our method.",
        "subjects": "Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Human-Computer Interaction",
        "date": "2025-11-12",
        "category": "cs.CL",
        "crawl_time": "2025-11-13T11:00:05.743924",
        "filter_reason": "这篇论文完全符合您的筛选标准，应被保留。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决一个特定领域的问题（如“用GUI智能体自动订票”），而是**提出了一种新的框架（HAR）来改进LLM智能体本身的核心能力**。其核心贡献是“History-Aware Reasoning”框架，旨在解决GUI智能体在长期任务中的记忆和推理缺陷。这直接命中了您“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个您关注的核心范式和能力： - **智能体能力**: 论文明确提到了 `Memory`（记忆，特别是短期记忆和情景记忆）、`Self-Reflection`（自我反思，“reflect on its own errors”）、`Self-Improvement`（自我完善，“acquire episodic reasoning knowledge from them”）以及 `Planning`（规划，隐含在“long-horizon GUI tasks”和“goal-oriented episode chain”中）。 - **演化机制**: “reflect on its own errors and acquire episodic reasoning knowledge from them”是一种典型的通过经验进行自我完善的机制，属于 `Self-Improvement` 和 `Iterative Improvement` 的范畴。 - 这些指标表明，论文的研究内容与您的“单智能体”和“自我演化”两个方向高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及 `Safety`, `Alignment`, `Hallucination` 等主题，其焦点是提升智能体的性能和推理能力，因此不在此排除范围内。 - **多模态与视觉**: 论文标题和摘要提到了“GUI Agents”和“Multimodal Large Language Models”。这是一个需要仔细判断的点。根据您的规则“除非它们被用作智能体感知环境的工具，而不是研究的核心”，这篇论文**符合保留条件**。论文的核心创新点不是一种新的视觉模型或多模态融合技术，而是**如何利用视觉信息（屏幕截图）和历史交互信息进行更好的推理**。视觉在这里是智能体感知环境的工具，而研究的核心是背后的推理框架（HAR），因此不应被排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”情况的完美范例。它不是在研究如何提升LLM基础的数学或逻辑能力，而是在研究一个**智能体**如何在复杂、多步的任务（GUI自动化）中进行规划和推理。它提出的HAR框架是一种新的Agentic推理框架，完全符合保留标准。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献是提出了一种名为HAR的新框架，通过增强智能体的记忆和自我反思能力，来改进其在复杂任务中的推理表现。这完全符合您对“单智能体”和“自我演化”方向的研究需求。论文虽然涉及视觉，但视觉是作为智能体感知的工具，而非研究核心。因此，这篇论文是高质量、高度相关的前沿研究，应被**保留**。"
    },
    {
        "index": "#6",
        "title": "BarrierBench : Evaluating Large Language Models for Safety Verification in Dynamical Systems",
        "link": "/arxiv/2511.09363",
        "arxiv_id": "2511.09363",
        "authors": "Ali Taheri, Alireza Taban, Sadegh Soudjani, Ashutosh Trivedi",
        "summary": "Safety verification of dynamical systems via barrier certificates is essential for ensuring correctness in autonomous applications. Synthesizing these certificates involves discovering mathematical functions with current methods suffering from poor scalability, dependence on carefully designed templates, and exhaustive or incremental function-space searches. They also demand substantial manual expertise--selecting templates, solvers, and hyperparameters, and designing sampling strategies--requiring both theoretical and practical knowledge traditionally shared through linguistic reasoning rather than formalized methods. This motivates a key question: can such expert reasoning be captured and operationalized by language models? We address this by introducing an LLM-based agentic framework for barrier certificate synthesis. The framework uses natural language reasoning to propose, refine, and validate candidate certificates, integrating LLM-driven template discovery with SMT-based verification, and supporting barrier-controller co-synthesis to ensure consistency between safety certificates and controllers. To evaluate this capability, we introduce BarrierBench, a benchmark of 100 dynamical systems spanning linear, nonlinear, discrete-time, and continuous-time settings. Our experiments assess not only the effectiveness of LLM-guided barrier synthesis but also the utility of retrieval-augmented generation and agentic coordination strategies in improving its reliability and performance. Across these tasks, the framework achieves more than 90% success in generating valid certificates. By releasing BarrierBench and the accompanying toolchain, we aim to establish a community testbed for advancing the integration of language-based reasoning with formal verification in dynamical systems. The benchmark is publicly available at https://hycodev.com/dataset/barrierbench",
        "subjects": "Artificial Intelligence, Systems and Control",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.074190",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用，而是**提出了一种新的LLM智能体框架**。摘要明确指出其核心贡献是 \"introducing an LLM-based agentic framework for barrier certificate synthesis\"（引入一个用于障碍证书合成的基于LLM的智能体框架）。它描述了该框架如何通过自然语言推理来“提议、精炼和验证”候选证书，这属于构建和改进LLM智能体的方法论。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提到了 `LLM-based agentic framework`。 - **智能体能力**: 框架的运作机制 \"propose, refine, and validate\" 体现了 `Self-Refine` 和 `Self-Correction` 的能力。与 `SMT-based verification` 的集成是典型的 `Tool Use`。整个证书合成过程是一个复杂的多步任务，涉及 `Planning`。 - **演化机制**: \"propose, refine, and validate\" 的循环迭代过程，正是一种 `Iterative Improvement` 的演化机制。 3.  **第三步：排除标准** - **安全与对齐**: 这是本案例最关键的一点。虽然论文标题和摘要多次提及 \"Safety Verification\"，但其**主要贡献并非安全理论本身或对齐技术**。相反，它是在探索如何用LLM智能体这一**新范式**去解决一个传统的安全问题。论文的核心是关于“如何构建这个智能体”，而不是“如何定义一种新的安全属性”。根据筛选标准“只要论文的主要贡献是关于 Safety...一律排除”，本文的主要贡献是Agentic框架，因此不应被排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文完美符合“保留”条件。它研究的是智能体如何在一个复杂的、需要形式化验证的领域进行规划和多步推理，而不是提升LLM本身的基础数学或逻辑能力。 - **自我演化的应用**: 论文提出的框架包含一个“提议-精炼-验证”的自我精炼循环，这本身就是一种自我演化机制。即使它被应用在“动力系统安全验证”这一特定领域，根据规则“如果论文的核心是提出一种新的‘自我演化’机制...也应该保留”，本文也应被保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个具备工具使用和自我精炼能力的LLM智能体框架，用以解决一个复杂的专业领域问题。它完全符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标。尽管其应用领域是“安全”，但这并非其方法论贡献的焦点。因此，最终判断为 **True**。"
    },
    {
        "index": "#24",
        "title": "Lumine: An Open Recipe for Building Generalist Agents in 3D Open Worlds",
        "link": "/arxiv/2511.08892",
        "arxiv_id": "2511.08892",
        "authors": "Weihao Tan, Xiangyang Li, Yunhao Fang, Heyuan Yao, Shi Yan, Hao Luo, Tenglong Ao, Huihui Li, Hongbin Ren, Bairen Yi, Yujia Qin, Bo An, Libin Liu, Guang Shi",
        "summary": "We introduce Lumine, the first open recipe for developing generalist agents capable of completing hours-long complex missions in real time within challenging 3D open-world environments. Lumine adopts a human-like interaction paradigm that unifies perception, reasoning, and action in an end-to-end manner, powered by a vision-language model. It processes raw pixels at 5 Hz to produce precise 30 Hz keyboard-mouse actions and adaptively invokes reasoning only when necessary. Trained in Genshin Impact, Lumine successfully completes the entire five-hour Mondstadt main storyline on par with human-level efficiency and follows natural language instructions to perform a broad spectrum of tasks in both 3D open-world exploration and 2D GUI manipulation across collection, combat, puzzle-solving, and NPC interaction. In addition to its in-domain performance, Lumine demonstrates strong zero-shot cross-game generalization. Without any fine-tuning, it accomplishes 100-minute missions in Wuthering Waves and the full five-hour first chapter of Honkai: Star Rail. These promising results highlight Lumine's effectiveness across distinct worlds and interaction dynamics, marking a concrete step toward generalist agents in open-ended environments.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.093191",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **核心判断 (第一步):** - **保留**: 论文的核心贡献是提出一个名为 \"Lumine\" 的 \"open recipe\"（开放配方/方法论），用于构建能够在复杂3D开放世界中执行长期任务的通用智能体。这直接对应了您筛选标准中的“构建、改进LLM智能体的方法论或新框架”。论文的本质不是简单应用，而是提出一种新的智能体构建范式。 2.  **正面指标 (第二步):** - 论文明确聚焦于 **`Agentic AI`** 和 **`LLM-based Agents`** (尽管其核心模型是VLM，但属于广义上的LLM智能体)。 - 其能力描述包含了智能体的核心要素：统一了**`perception`** (感知)、**`reasoning`** (推理) 和 **`action`** (行动)，并强调完成 \"hours-long complex missions\"，这直接指向了智能体的**`Planning`** (规划) 和多步执行能力。 - \"adaptively invokes reasoning only when necessary\" 的描述，体现了智能体在推理和行动之间的智能切换，这与 **`ReAct`** 等核心范式高度相关。 3.  **排除标准 (第三步):** - **安全与对齐**: 论文未涉及安全、对齐、可解释性等内容。 - **多模态与视觉**: 这是本论文最需要辨析的一点。论文确实由一个 \"vision-language model\" 驱动，但关键在于，**视觉能力在这里是作为智能体感知环境的工具**，而不是研究的核心贡献。论文的核心是“如何构建一个智能体”，而这个智能体恰好需要视觉来感知3D世界。这完全符合您筛选标准中的例外情况：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。因此，不应因此排除。 4.  **特殊和模糊情况 (第四步):** - **推理/规划**: 论文描述的推理是服务于智能体完成复杂任务的，是智能体框架的一部分，而非提升LLM本身的基础数学或逻辑能力。因此，符合保留条件。 **最终决策 (第五步):** 综合分析，这篇论文的核心贡献在于提出了一种构建通用智能体的新框架和方法论，该智能体具备规划、推理和行动等核心能力。虽然它应用在3D游戏领域并使用了视觉模型，但其研究焦点是智能体架构本身，而非应用或视觉技术。因此，它精准地命中了您“单智能体”研究方向的核心，是一篇高度相关的前沿论文，应当保留。"
    },
    {
        "index": "#15",
        "title": "OR-R1: Automating Modeling and Solving of Operations Research Optimization Problem via Test-Time Reinforcement Learning",
        "link": "/arxiv/2511.09092",
        "arxiv_id": "2511.09092",
        "authors": "Zezhen Ding, Zhen Tan, Jiheng Zhang, Tianlong Chen",
        "summary": "Optimization modeling and solving are fundamental to the application of Operations Research (OR) in real-world decision making, yet the process of translating natural language problem descriptions into formal models and solver code remains highly expertise intensive. While recent advances in large language models (LLMs) have opened new opportunities for automation, the generalization ability and data efficiency of existing LLM-based methods are still limited, asmost require vast amounts of annotated or synthetic data, resulting in high costs and scalability barriers. In this work, we present OR-R1, a data-efficient training framework for automated optimization modeling and solving. OR-R1 first employs supervised fine-tuning (SFT) to help the model acquire the essential reasoning patterns for problem formulation and code generation from limited labeled data. In addition, it improves the capability and consistency through Test-Time Group Relative Policy Optimization (TGRPO). This two-stage design enables OR-R1 to leverage both scarce labeled and abundant unlabeled data for effective learning. Experiments show that OR-R1 achieves state-of-the-art performance with an average solving accuracy of $67.7\\%$, using only $1/10$ the synthetic data required by prior methods such as ORLM, exceeding ORLM's solving accuracy by up to $4.2\\%$. Remarkably, OR-R1 outperforms ORLM by over $2.4\\%$ with just $100$ synthetic samples. Furthermore, TGRPO contributes an additional $3.1\\%-6.4\\%$ improvement in accuracy, significantly narrowing the gap between single-attempt (Pass@1) and multi-attempt (Pass@8) performance from $13\\%$ to $7\\%$. Extensive evaluations across diverse real-world benchmarks demonstrate that OR-R1 provides a robust, scalable, and cost-effective solution for automated OR optimization problem modeling and solving, lowering the expertise and data barriers for industrial OR applications.",
        "subjects": "Artificial Intelligence, Optimization and Control",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.083676",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 OR-R1 的框架，其关键创新在于 Test-Time Group Relative Policy Optimization (TGRPO) 机制。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于运筹学（OR）领域。虽然其应用场景是OR问题，但其核心贡献是提出了一种**新的方法论（TGRPO）**，使得LLM在执行任务时能够通过强化学习进行自我完善和迭代。这完全符合“构建、改进或演化 LLM智能体”的核心目标。它不是非演化型应用，因为其核心创新点就在于“演化”机制本身。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **自我演化**: TGRPO 是一种在测试时（推理时）通过环境反馈（求解结果的准确性）来优化模型策略的机制，这本质上是一种**自我完善**和**迭代改进**的过程。 - **Agentic AI**: OR-R1 作为一个自动化系统，执行了从理解自然语言、建模、生成代码到求解的复杂多步任务，这体现了智能体的自主规划和执行能力。 - **自我反思**: TGRPO 机制可以看作是一种高级的自我反思，模型根据其输出结果的好坏来调整其后续的生成策略。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态等问题，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是最关键的判断点。根据筛选规则，“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 本论文正是这种情况。它的核心是 TGRPO 这一**自我演化机制**，而运筹学问题只是验证该机制有效性的试验场。因此，它符合保留的例外条款。 - **推理/规划**: 论文研究的不是LLM基础的数学或逻辑推理能力，而是如何构建一个智能体框架来完成一个复杂的、需要多步规划和工具使用（调用求解器）的任务。这符合保留条件。 **最终决策**: 综合以上分析，尽管论文的应用领域是运筹学，但其核心贡献在于提出了一种新颖的、通用的**自我演化机制（TGRPO）**，该机制能够让LLM智能体在执行任务过程中通过反馈进行自我完善。这与研究课题中的“自我演化”方向高度契合，因此应该被保留。"
    },
    {
        "index": "#25",
        "title": "UCO: A Multi-Turn Interactive Reinforcement Learning Method for Adaptive Teaching with Large Language Models",
        "link": "/arxiv/2511.08873",
        "arxiv_id": "2511.08873",
        "authors": "Shouang Wei, Min Zhang, Xin Lin, Bo Jiang, Kun Kuang, Zhongxiang Dai",
        "summary": "Large language models (LLMs) are shifting from answer providers to intelligent tutors in educational settings, yet current supervised fine-tuning methods only learn surface teaching patterns without dynamic adaptation capabilities. Recent reinforcement learning approaches address this limitation but face two critical challenges. First, they evaluate teaching effectiveness solely based on whether students produce correct outputs, unable to distinguish whether students genuinely understand or echo teacher-provided answers during interaction. Second, they cannot perceive students' evolving cognitive states in real time through interactive dialogue, thus failing to adapt teaching strategies to match students' cognitive levels dynamically. We propose the Unidirectional Cognitive Optimization (UCO) method to address these challenges. UCO uses a multi-turn interactive reinforcement learning paradigm where the innovation lies in two synergistic reward functions: the Progress Reward captures students' cognitive advancement, evaluating whether students truly transition from confusion to comprehension, while the Scaffold Reward dynamically identifies each student's Zone of Proximal Development (ZPD), encouraging teachers to maintain productive teaching within this zone. We evaluate UCO by comparing it against 11 baseline models on BigMath and MathTutorBench benchmarks. Experimental results demonstrate that our UCO model outperforms all models of equivalent scale and achieves performance comparable to advanced closed-source models. The code and data are available at https://github.com/Mind-Lab-ECNU/UCO.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.093657",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于提出了一种让LLM智能体实现“自我演化”的新方法。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于教育领域，而是提出了一种名为UCO（Unidirectional Cognitive Optimization）的**新方法论**，用于构建和改进一个能够自适应教学的LLM智能体。论文的核心是解决现有教学智能体“无法动态适应”和“无法感知学生认知状态演化”的问题。这直接对应了您研究目标中的“改进或演化LLM智能体”。它不是非演化型应用，因为其核心贡献是演化机制本身。 2.  **第二步：正面指标** - 论文高度契合您的核心关注点： - **核心范式**: 论文围绕 `LLM-based Agents` 展开，研究的是一个作为“智能导师”的智能体。 - **自我演化**: 这是论文最核心的贡献。UCO方法通过 `Multi-Turn Interactive Reinforcement Learning`（多轮交互式强化学习）范式，让智能体在与学生的互动中不断调整和优化其教学策略。这完全符合 `Self-Evolving`、`Self-Improvement` 和 `Iterative Improvement` 的定义。 - **智能体能力**: 论文中的智能体通过 `Progress Reward` 和 `Scaffold Reward` 两个奖励函数来评估自身行为并进行调整，这本质上是一种高级的 `Self-Reflection` 和 `Self-Correction` 机制。智能体需要根据学生的实时反馈来规划下一步的教学行为，这也涉及了 `Planning` 能力。 3.  **第三步：排除标准** - 论文的主要贡献是关于智能体的自适应学习机制，而非安全、对齐或多模态技术。因此，它没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然论文的应用场景是教育（一个特定领域），但其**核心贡献是提出了一种全新的“自我演化”机制**——即通过两个协同的奖励函数来驱动智能体在交互中实现动态适应和自我完善。根据您的规则，这种情况应该保留。 - **推理/规划**: 论文中的智能体不是在进行基础的数学推理，而是在进行更高层次的“教学策略规划”。它需要规划如何通过多轮对话引导学生，这完全属于Agentic AI的范畴，应予以保留。 **总结**: 该论文的核心贡献是UCO方法，一种通过交互式强化学习让LLM智能体（教师）能够感知学生认知状态并动态自我调整教学策略的框架。这直接命中了您研究焦点中的“自我演化”方向，并涉及“单智能体”的规划与反思能力。它不是简单的应用，而是对智能体演化机制的深刻探索，因此是您课题下的高相关性前沿论文。"
    },
    {
        "index": "#21",
        "title": "AlphaCast: A Human Wisdom-LLM Intelligence Co-Reasoning Framework for Interactive Time Series Forecasting",
        "link": "/arxiv/2511.08947",
        "arxiv_id": "2511.08947",
        "authors": "Xiaohan Zhang, Tian Gao, Mingyue Cheng, Bokai Pan, Ze Guo, Yaguo Liu, Xiaoyu Tao",
        "summary": "Time series forecasting plays a critical role in high-stakes domains such as energy, healthcare, and climate. Although recent advances have improved accuracy, most approaches still treat forecasting as a static one-time mapping task, lacking the interaction, reasoning, and adaptability of human experts. This gap limits their usefulness in complex real-world environments. To address this, we propose AlphaCast, a human wisdom-large language model (LLM) intelligence co-reasoning framework that redefines forecasting as an interactive process. The key idea is to enable step-by-step collaboration between human wisdom and LLM intelligence to jointly prepare, generate, and verify forecasts. The framework consists of two stages: (1) automated prediction preparation, where AlphaCast builds a multi-source cognitive foundation comprising a feature set that captures key statistics and time patterns, a domain knowledge base distilled from corpora and historical series, a contextual repository that stores rich information for each time window, and a case base that retrieves optimal strategies via pattern clustering and matching; and (2) generative reasoning and reflective optimization, where AlphaCast integrates statistical temporal features, prior knowledge, contextual information, and forecasting strategies, triggering a meta-reasoning loop for continuous self-correction and strategy refinement. Extensive experiments on short- and long-term datasets show that AlphaCast consistently outperforms state-of-the-art baselines in predictive accuracy. Code is available at this repository: https://github.com/SkyeGT/AlphaCast_Official .",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.086563",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于时间序列预测领域，而是提出了一个名为AlphaCast的**新框架**。该框架将预测任务重新定义为一个**交互式、多步骤的推理过程**，其本质是构建一个具有特定能力的LLM智能体。这完全符合“构建、改进或演化LLM智能体”的核心目标。它不是一次性的应用，而是一个具有持续优化能力的系统。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了大量您关注的核心指标： *   **智能体能力**: *   `Memory`: 框架明确构建了“多源认知基础”，包括特征集、领域知识库、上下文信息库和案例库，这是典型的智能体记忆机制。 *   `Self-Correction` / `Self-Reflection`: 摘要中明确提到框架包含“反思优化”阶段，并触发“元推理循环”以进行“持续的自我修正和策略优化”。这直接命中了自我反思和自我修正的核心。 *   **演化机制**: *   `Self-Improvement` / `Iterative Improvement`: “持续的自我修正和策略优化”是自我演化的典型表现。智能体通过反思和验证，不断迭代改进其预测策略，这正是“自我演化”方向的核心研究内容。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于智能体框架的设计和性能提升，而非安全、对齐、可解释性或多模态。因此，所有排除标准均不适用。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文提出的“元推理循环”是关于智能体如何在复杂任务中进行多步规划和推理的，这属于Agentic框架的范畴，而非提升LLM基础推理能力。 *   **自我演化的应用**: 这是本案例的关键。虽然论文应用在“时间序列预测”这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**（即元推理循环下的持续自我修正和策略优化）。根据您的筛选规则第四条第二款，这种情况应作为例外**保留**。论文的价值在于这个可迁移的演化框架，而不仅仅是其在预测任务上的表现。 **最终决策**: 该论文的核心是构建一个具备记忆、自我反思和自我演化能力的LLM智能体框架（AlphaCast）。它通过一个元推理循环实现了策略的持续优化，完美契合您研究课题中的“自我演化”方向。尽管其应用场景是时间序列预测，但其方法论贡献是普适的，属于Agentic AI的核心研究。因此，应判定为 **True (保留)**。"
    },
    {
        "index": "#30",
        "title": "WMPO: World Model-based Policy Optimization for Vision-Language-Action Models",
        "link": "/arxiv/2511.09515",
        "arxiv_id": "2511.09515",
        "authors": "Fangqi Zhu, Zhengyang Yan, Zicong Hong, Quanxin Shou, Xiao Ma, Song Guo",
        "summary": "Vision-Language-Action (VLA) models have shown strong potential for general-purpose robotic manipulation, but their reliance on expert demonstrations limits their ability to learn from failures and perform self-corrections. Reinforcement learning (RL) addresses these through self-improving interactions with the physical environment, but suffers from high sample complexity on real robots. We introduce World-Model-based Policy Optimization (WMPO), a principled framework for on-policy VLA RL without interacting with the real environment. In contrast to widely used latent world models, WMPO focuses on pixel-based predictions that align the \"imagined\" trajectories with the VLA features pretrained with web-scale images. Crucially, WMPO enables the policy to perform on-policy GRPO that provides stronger performance than the often-used off-policy methods. Extensive experiments in both simulation and real-robot settings demonstrate that WMPO (i) substantially improves sample efficiency, (ii) achieves stronger overall performance, (iii) exhibits emergent behaviors such as self-correction, and (iv) demonstrates robust generalization and lifelong learning capabilities.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.095956",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为WMPO（World Model-based Policy Optimization）的新框架，用于训练和改进视觉-语言-动作（VLA）模型，使其具备自我修正和终身学习的能力。根据您的筛选标准，该论文完全符合要求。 以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将现有智能体应用到一个新领域，而是提出了一种全新的、**用于改进智能体自身能力的方法论框架（WMPO）**。其核心目标是解决VLA模型无法从失败中学习和进行自我修正的问题，这直接触及了“自我演化”的核心。因此，它不是“非演化型应用”，而是关于“如何演化”的研究。 2.  **第二步：正面指标** - 论文摘要中包含了多个核心关注点： - **自我演化**: 论文的核心就是让智能体通过强化学习（RL）进行自我完善。 - **自我修正**: 明确指出WMPO框架使智能体展现出“emergent behaviors such as self-correction”。 - **终身学习**: 同样明确提到了“lifelong learning capabilities”。 - **规划/策略**: 论文主题是“Policy Optimization”（策略优化），这是智能体规划和决策能力的核心。 - 这些正面指标高度集中，强烈表明该论文与您的研究方向高度相关。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐、可解释性等内容。 - **多模态与视觉**: 论文标题和摘要中提到了“Vision-Language-Action (VLA) models”。这是一个需要仔细判断的点。然而，根据筛选标准中的核心规则：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，**视觉（Vision）是智能体感知物理世界的工具，而研究的核心是“如何通过世界模型让这个智能体进行自我演化和策略优化”**。因此，这不应成为排除的理由。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美范例。它的应用领域是机器人控制，但其**核心贡献是提出了一种新的“自我演化”机制（WMPO）**。根据您的规则，这种情况应该保留。论文的价值在于这个机制本身，而不是它在机器人任务上的表现。 **最终决策**: 综合以上分析，该论文的核心贡献在于构建了一个让LLM智能体（具体为VLA模型）能够通过模拟环境进行自我修正和终身学习的新框架。它直接推动了“自我演化”这一研究方向，尽管其应用背景是机器人技术，但其方法论具有普适性，完全符合您筛选“构建、改进或演化LLM智能体”论文的核心目标。因此，最终判断为 **True**。"
    },
    {
        "index": "#66",
        "title": "Tele-LLM-Hub: Building Context-Aware Multi-Agent LLM Systems for Telecom Networks",
        "link": "/arxiv/2511.09087",
        "arxiv_id": "2511.09087",
        "authors": "Vijay K Shah, Cong Shen",
        "summary": "This paper introduces Tele-LLM-Hub, a user friendly low-code solution for rapid prototyping and deployment of context aware multi-agent (MA) Large Language Model (LLM) systems tailored for 5G and beyond. As telecom wireless networks become increasingly complex, intelligent LLM applications must share a domainspecific understanding of network state. We propose TeleMCP, the Telecom Model Context Protocol, to enable structured and context-rich communication between agents in telecom environments. Tele-LLM-Hub actualizes TeleMCP through a low-code interface that supports agent creation, workflow composition, and interaction with software stacks such as srsRAN. Key components include a direct chat interface, a repository of pre-built systems, an Agent Maker leveraging finetuning with our RANSTRUCT framework, and an MA-Maker for composing MA workflows. The goal of Tele-LLM-Hub is to democratize the design of contextaware MA systems and accelerate innovation in next-generation wireless networks.",
        "subjects": "Networking and Internet Architecture, Artificial Intelligence",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.131430",
        "filter_reason": "这篇论文符合你的研究范围，应被保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于电信领域，而是提出了一套**构建和部署多智能体LLM系统的方法论和框架**。其核心贡献是 `Tele-LLM-Hub` 这个低代码平台和 `TeleMCP` 这个通信协议。这完全符合“构建、改进或演化LLM智能体”的核心目标。 - **排除项分析**: 1.  **非演化型应用**: 论文虽然应用于电信网络，但其重点在于**如何构建**（`Building`）一个上下文感知的多智能体系统，而不是仅仅用现有智能体去解决一个电信问题。它提供了`Agent Maker`和`MA-Maker`等工具，让用户可以创建和组合智能体工作流。因此，它不属于“非演化型应用”的排除范畴。 2.  **非Agentic的推理**: 论文明确聚焦于多智能体系统，不涉及基础LLM推理能力的提升。 3.  **基础设施**: `Tele-LLM-Hub` 是一个应用层的框架和平台，用于智能体的编排和工作流组合，而非底层的模型部署优化或硬件加速，因此不属于被排除的基础设施研究。 **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提到了 `Multi-Agent (MA) Large Language Model (LLM) systems`。 - **多智能体**: 论文的核心是解决智能体间的 `Communication` 问题（通过`TeleMCP`协议），并支持智能体 `Collaboration` 的工作流组合（`MA-Maker`）。 - **智能体能力**: 提到了 `Tool Use`，即智能体与 `srsRAN` 等软件栈的交互。 **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐（Safety, Alignment等），也不涉及多模态与视觉（Vision, MLLMs等）。因此，没有触发排除标准。 **第四步：处理特殊和模糊情况** - 本论文不涉及自我演化或基础推理的特殊情况，无需额外判断。 **第五步：最终决策** 综合以上分析，该论文的核心贡献在于提出了一种新的**多智能体系统构建框架和通信协议**，旨在解决特定领域（电信）中智能体上下文感知和协作的挑战。这完全符合你研究目标中的“多智能体”方向，即关注智能体间的协作、通信和工作流编排。尽管它有明确的应用背景，但其贡献是方法论层面的，因此应被保留。"
    },
    {
        "index": "#78",
        "title": "Think, Remember, Navigate: Zero-Shot Object-Goal Navigation with VLM-Powered Reasoning",
        "link": "/arxiv/2511.08942",
        "arxiv_id": "2511.08942",
        "authors": "Mobin Habibpour, Fatemeh Afghah",
        "summary": "While Vision-Language Models (VLMs) are set to transform robotic navigation, existing methods often underutilize their reasoning capabilities. To unlock the full potential of VLMs in robotics, we shift their role from passive observers to active strategists in the navigation process. Our framework outsources high-level planning to a VLM, which leverages its contextual understanding to guide a frontier-based exploration agent. This intelligent guidance is achieved through a trio of techniques: structured chain-of-thought prompting that elicits logical, step-by-step reasoning; dynamic inclusion of the agent's recent action history to prevent getting stuck in loops; and a novel capability that enables the VLM to interpret top-down obstacle maps alongside first-person views, thereby enhancing spatial awareness. When tested on challenging benchmarks like HM3D, Gibson, and MP3D, this method produces exceptionally direct and logical trajectories, marking a substantial improvement in navigation efficiency over existing approaches and charting a path toward more capable embodied agents.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-11-12",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.143145",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非简单地将一个现有框架应用于机器人导航领域，而是提出了一种**新的智能体框架**。该框架的核心创新在于“将VLM的角色从被动观察者转变为主动的战略家”，并详细阐述了如何通过结构化思维链、动态记忆（动作历史）和多模态工具（地图+视图）来实现这一转变。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它研究的是“如何构建一个会规划、有记忆的具身智能体”，而不是“用智能体解决导航问题”。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个我核心关注点的关键词和能力： *   **核心范式**: 论文构建了一个典型的 `Agentic AI` / `LLM-based Agent` (这里是VLM-based)。 *   **智能体能力**: *   `Planning`: 论文明确指出将“高层规划外包给VLM”，这是其核心贡献。 *   `Memory`: 通过“动态包含智能体最近的动作历史”来防止陷入循环，这是一种短期记忆机制。 *   `Tool Use`: VLM将“自上而下的障碍地图”和“第一人称视图”作为工具来增强空间感知，这是典型的工具使用能力。 *   `ReAct` / `CoT`: 使用了“结构化的思维链提示”来引导逻辑推理。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题。 *   **多模态与视觉**: 虽然论文使用了VLM，但它完全符合排除标准中的例外情况。VLM在这里是作为智能体**感知环境的工具**，研究的核心是智能体如何利用这个工具进行规划和推理，而不是VLM模型本身。因此，不应被排除。 4.  **第四步：特殊和模糊情况 (符合保留条件)** *   **推理/规划**: 论文是关于智能体如何在复杂任务（导航）中进行多步推理和高层规划的典型案例，属于应保留的范畴。 **总结**: 该论文的本质是提出了一种新的单智能体框架，重点解决了智能体在具身任务中的**规划**、**记忆**和**工具使用**问题。尽管其应用场景是机器人导航，但其核心贡献在于智能体架构和能力的创新，这与我“构建、改进LLM智能体”的核心目标高度一致，属于“单智能体”研究方向的优秀范例。因此，最终判断为 **True**。"
    },
    {
        "index": "#112",
        "title": "Bio AI Agent: A Multi-Agent Artificial Intelligence System for Autonomous CAR-T Cell Therapy Development with Integrated Target Discovery, Toxicity Prediction, and Rational Molecular Design",
        "link": "/arxiv/2511.08649",
        "arxiv_id": "2511.08649",
        "authors": "Yi Ni, Liwei Zhu, Shuai Li",
        "summary": "Chimeric antigen receptor T-cell (CAR-T) therapy represents a paradigm shift in cancer treatment, yet development timelines of 8-12 years and clinical attrition rates exceeding 40-60% highlight critical inefficiencies in target selection, safety assessment, and molecular optimization. We present Bio AI Agent, a multi-agent artificial intelligence system powered by large language models that enables autonomous CAR-T development through collaborative specialized agents. The system comprises six autonomous agents: Target Selection Agent for multi-parametric antigen prioritization across >10,000 cancer-associated targets, Toxicity Prediction Agent for comprehensive safety profiling integrating tissue expression atlases and pharmacovigilance databases, Molecular Design Agent for rational CAR engineering, Patent Intelligence Agent for freedom-to-operate analysis, Clinical Translation Agent for regulatory compliance, and Decision Orchestration Agent for multi-agent coordination. Retrospective validation demonstrated autonomous identification of high-risk targets including FcRH5 (hepatotoxicity) and CD229 (off-tumor toxicity), patent infringement risks for CD38+SLAMF7 combinations, and generation of comprehensive development roadmaps. By enabling parallel processing, specialized reasoning, and autonomous decision-making superior to monolithic AI systems, Bio AI Agent addresses critical gaps in precision oncology development and has potential to accelerate translation of next-generation immunotherapies from discovery to clinic.",
        "subjects": "Quantitative Methods, Artificial Intelligence",
        "date": "2025-11-11",
        "category": "cs.AI",
        "crawl_time": "2025-11-13T11:00:06.192251",
        "filter_reason": "这篇论文符合您的研究范围，应当被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非简单地将一个已有的LLM或智能体框架作为工具应用于生物领域。其核心贡献在于**构建了一个全新的、名为“Bio AI Agent”的多智能体系统**。论文详细描述了该系统的架构，包括六个具有不同专业分工的自主智能体（靶点选择、毒性预测、分子设计等）以及一个负责协调的“决策编排智能体”。这完全符合“构建、改进或演化LLM智能体”的核心目标，特别是“多智能体系统”这一方向。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文标题和摘要的核心。 - **多智能体**: 明确提到了 `Collaboration`（协作的专业智能体）、`Agent Society`（由多个专业智能体组成的系统），并通过“决策编排智能体”实现了 `Communication` 和协调。 - **智能体能力**: 整个系统展现了高级的 `Planning`（生成全面的开发路线图）和 `Tool Use`（整合组织表达图谱和药物警戒数据库）能力。 3.  **第三步：排除标准** - 论文虽然涉及“毒性预测”和“安全分析”，但这只是智能体执行的任务，并非论文的研究贡献。论文的贡献是**构建了能够执行这些任务的智能体**，而不是提出新的安全或对齐理论。因此，这不属于被排除的“安全与对齐”类别。 - 论文不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的智能体系统执行的是复杂的多步任务规划（从靶点发现到临床转化的全流程），这属于智能体层面的规划和推理，符合保留标准。 - **自我演化的应用**: 虽然这篇论文不涉及“自我演化”，但它触及了一个关键的模糊点：**应用 vs. 方法论**。这篇论文虽然应用在CAR-T疗法开发这一特定领域，但其核心贡献是**方法论层面的创新**——即提出了一种新的多智能体协作框架。它论证了这种多智能体架构在处理复杂任务时优于“单体AI系统”。因此，它不是一篇简单的“非演化型应用”论文，而是一篇以应用为场景来验证其新智能体框架的论文，这与您的研究目标高度一致。 **最终决策**: 综合以上分析，这篇论文的核心贡献是**提出并验证了一个新颖的多智能体协作框架**。尽管其应用场景是生物医学，但其研究焦点在于智能体本身的架构设计、分工协作与自主决策能力，这完全契合您研究课题中的“多智能体”方向。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#3",
        "title": "AutoSynth: Automated Workflow Optimization for High-Quality Synthetic Dataset Generation via Monte Carlo Tree Search",
        "link": "/arxiv/2511.09488",
        "arxiv_id": "2511.09488",
        "authors": "Shuzhen Bi, Chang Song, Siyu Song, Jinze Lv, Jian Chen, Xinyun Wang, Aimin Zhou, Hao Hao",
        "summary": "Supervised fine-tuning (SFT) of large language models (LLMs) for specialized tasks requires high-quality datasets, but manual curation is prohibitively expensive. Synthetic data generation offers scalability, but its effectiveness relies on complex, multi-stage workflows, integrating prompt engineering and model orchestration. Existing automated workflow methods face a cold start problem: they require labeled datasets for reward modeling, which is especially problematic for subjective, open-ended tasks with no objective ground truth. We introduce AutoSynth, a framework that automates workflow discovery and optimization without reference datasets by reframing the problem as a Monte Carlo Tree Search guided by a novel dataset-free hybrid reward. This reward enables meta-learning through two LLM-as-judge components: one evaluates sample quality using dynamically generated task-specific metrics, and another assesses workflow code and prompt quality. Experiments on subjective educational tasks show that while expert-designed workflows achieve higher human preference rates (96-99% win rates vs. AutoSynth's 40-51%), models trained on AutoSynth-generated data dramatically outperform baselines (40-51% vs. 2-5%) and match or surpass expert workflows on certain metrics, suggesting discovery of quality dimensions beyond human intuition. These results are achieved while reducing human effort from 5-7 hours to just 30 minutes (>90% reduction). AutoSynth tackles the cold start issue in data-centric AI, offering a scalable, cost-effective method for subjective LLM tasks. Code: https://github.com/bisz9918-maker/AutoSynth.",
        "subjects": "Machine Learning",
        "date": "2025-11-12",
        "category": "cs.LG",
        "crawl_time": "2025-11-13T11:00:06.126657",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 AutoSynth 的自动化框架，用于发现和优化生成高质量合成数据集的工作流。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用到一个特定领域，而是提出了一种**新的方法论和框架**。该框架的核心是使用蒙特卡洛树搜索（MCTS）来自主地探索和优化一个由“提示工程”和“模型编排”组成的复杂工作流。这完全符合“构建、改进或演化LLM智能体”的研究范畴。它不是一个静态的应用，而是一个能够自主行动和优化的动态系统。 2.  **第二步：正面指标分析** - **自我演化**: 这是论文最核心的亮点。AutoSynth通过MCTS进行迭代搜索，并使用一个新颖的、无需参考数据集的混合奖励信号来指导搜索方向。这个奖励机制由两个“LLM-as-judge”组件构成，分别评估生成样本的质量和工作流本身的质量。整个过程是一个典型的**迭代改进**和**自我完善**的过程，系统通过反馈（奖励信号）来学习并演化出更优的工作流，完全符合“自我演化”的定义。 - **单智能体**: AutoSynth框架本身可以被看作一个高级的智能体。它有明确的目标（生成高质量数据集），具备**规划**能力（使用MCTS来规划下一步要探索的工作流节点），使用了**工具**（调用LLM生成数据、执行代码），并且包含了**自我反思**机制（LLM-as-judge评估自身生成的工作流和输出）。这超越了简单的LLM推理，进入了Agentic AI的层面。 - **核心范式与能力**: 论文涉及了 `Self-Evolving`, `Planning`, `Tool Use`, `Self-Reflection`, `Iterative Improvement` 等多个核心关注点。 3.  **第三步：排除标准检查** - 论文的主要贡献不是关于安全、对齐、可解释性或多模态。它的焦点是优化和自动化，因此没有触发任何排除标准。 4.  **第四步：特殊和模糊情况处理** - **自我演化的应用**: 论文虽然将AutoSynth应用在了“主观教育任务”上，但其核心贡献是提出了一种通用的“自我演化”机制（基于MCTS和无数据集奖励的工作流优化）。根据筛选规则，这种情况应该**保留**。研究的价值在于这个机制本身，而非其在教育领域的具体应用。 - **推理/规划**: 论文中的MCTS是一种高级的规划和搜索算法，用于在复杂的决策空间（工作流组合）中找到最优解。这属于智能体在复杂任务中进行多步规划和推理的范畴，而不是提升LLM本身的基础数学或逻辑能力，因此符合保留条件。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个能够**自我演化**的智能体框架（AutoSynth），该框架通过**规划**（MCTS）和**自我反思**（LLM-as-judge）来自动优化复杂的工作流。这直接命中了“LLM智能体及其演化”研究课题中的“自我演化”和“单智能体”两个核心方向。因此，这篇论文高度符合研究要求，应予以保留。"
    }
]