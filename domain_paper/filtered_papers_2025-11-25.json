[
    {
        "index": "#10",
        "title": "VideoChat-M1: Collaborative Policy Planning for Video Understanding via Multi-Agent Reinforcement Learning",
        "link": "/arxiv/2511.19524",
        "arxiv_id": "2511.19524",
        "authors": "Boyu Chen, Zikang Wang, Zhengrong Yue, Kainan Yan, Chenyun Yu, Yi Huang, Zijun Liu, Yafei Wen, Xiaoxin Chen, Yang Liu, Peng Li, Yali Wang",
        "summary": "By leveraging tool-augmented Multimodal Large Language Models (MLLMs), multi-agent frameworks are driving progress in video understanding. However, most of them adopt static and non-learnable tool invocation mechanisms, which limit the discovery of diverse clues essential for robust perception and reasoning regarding temporally or spatially complex videos. To address this challenge, we propose a novel Multi-agent system for video understanding, namely VideoChat-M1. Instead of using a single or fixed policy, VideoChat-M1 adopts a distinct Collaborative Policy Planning (CPP) paradigm with multiple policy agents, which comprises three key processes. (1) Policy Generation: Each agent generates its unique tool invocation policy tailored to the user's query; (2) Policy Execution: Each agent sequentially invokes relevant tools to execute its policy and explore the video content; (3) Policy Communication: During the intermediate stages of policy execution, agents interact with one another to update their respective policies. Through this collaborative framework, all agents work in tandem, dynamically refining their preferred policies based on contextual insights from peers to effectively respond to the user's query. Moreover, we equip our CPP paradigm with a concise Multi-Agent Reinforcement Learning (MARL) method. Consequently, the team of policy agents can be jointly optimized to enhance VideoChat-M1's performance, guided by both the final answer reward and intermediate collaborative process feedback. Extensive experiments demonstrate that VideoChat-M1 achieves SOTA performance across eight benchmarks spanning four tasks. Notably, on LongVideoBench, our method outperforms the SOTA model Gemini 2.5 pro by 3.6% and GPT-4o by 15.6%.",
        "subjects": "Computer Vision and Pattern Recognition, Multiagent Systems",
        "date": "2025-11-24",
        "category": "cs.MA",
        "crawl_time": "2025-11-26T11:00:03.797425",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将现有智能体框架应用于视频领域，而是**提出了一种全新的多智能体系统方法论**。其核心贡献是“协作策略规划”范式和配套的“多智能体强化学习”优化方法。这直接对应了您研究目标中的“构建、改进或演化 LLM智能体”，特别是“多智能体”方向。 2.  **第二步：正面指标** - 论文包含了大量您关注的核心指标： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。 - **智能体能力**: `Planning` (策略规划)、`Tool Use / Tool Augmentation` (工具调用策略) 是其关键组成部分。 - **多智能体**: `Collaboration` (协作框架)、`Communication` (策略通信) 是其创新点。 - **演化机制**: 通过 `Multi-Agent Reinforcement Learning (MARL)`，智能体团队被联合优化，策略被动态更新，这完全符合 `Self-Improvement` 和 `Iterative Improvement` 的定义，是一种群体层面的演化。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐等问题。 - **多模态与视觉**: 这是需要特别注意的一点。虽然论文的应用领域是“视频理解”，并使用了“MLLMs”，但它完全符合您设定的例外情况：“**除非它们被用作智能体感知环境的工具，而不是研究的核心**”。在这篇论文中，视频和MLLMs是智能体操作的**环境和感知工具**，而论文的**研究核心**是智能体之间如何协作、规划和演化的**框架本身**，而不是提出新的视觉模型或视频理解技术。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的“协作策略规划”是典型的智能体规划框架，属于保留范畴。 - **自我演化的应用**: 论文的核心贡献之一就是提出了一种新的“演化机制”（通过MARL进行联合优化），并将其应用于视频理解领域。这完全符合您设定的“保留（例外）”规则。 **核心依据总结**: 该论文的核心贡献在于构建了一个**可学习、可演化的多智能体协作框架**。它通过引入多个策略智能体、动态的通信机制以及多智能体强化学习，显著改进了智能体团队在复杂任务中的表现。这精准地命中了您研究课题中的“多智能体”和“自我演化”两个核心方向。尽管其应用场景是多模态视频理解，但方法论本身是关于智能体架构和演化的，因此应被保留。"
    },
    {
        "index": "#2",
        "title": "Complex Instruction Following with Diverse Style Policies in Football Games",
        "link": "/arxiv/2511.19885",
        "arxiv_id": "2511.19885",
        "authors": "Chenglu Sun, Shuo Shen, Haonan Hu, Wei Zhou, Chen Chen",
        "summary": "Despite advancements in language-controlled reinforcement learning (LC-RL) for basic domains and straightforward commands (e.g., object manipulation and navigation), effectively extending LC-RL to comprehend and execute high-level or abstract instructions in complex, multi-agent environments, such as football games, remains a significant challenge. To address this gap, we introduce Language-Controlled Diverse Style Policies (LCDSP), a novel LC-RL paradigm specifically designed for complex scenarios. LCDSP comprises two key components: a Diverse Style Training (DST) method and a Style Interpreter (SI). The DST method efficiently trains a single policy capable of exhibiting a wide range of diverse behaviors by modulating agent actions through style parameters (SP). The SI is designed to accurately and rapidly translate high-level language instructions into these corresponding SP. Through extensive experiments in a complex 5v5 football environment, we demonstrate that LCDSP effectively comprehends abstract tactical instructions and accurately executes the desired diverse behavioral styles, showcasing its potential for complex, real-world applications.",
        "subjects": "Multiagent Systems, Machine Learning",
        "date": "2025-11-25",
        "category": "cs.MA",
        "crawl_time": "2025-11-26T11:00:03.795096",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将一个现有智能体框架应用于足球领域，而是提出了一种全新的方法论框架——**Language-Controlled Diverse Style Policies (LCDSP)**。这个框架旨在解决“如何在复杂多智能体环境中理解和执行高级抽象指令”这一根本性挑战。因此，它的本质是**构建和改进多智能体系统**，符合您筛选标准的第一条。 2.  **第二步：正面指标分析** - 论文明确涉及了您的核心关注点： - **多智能体**: 研究背景是“complex 5v5 football environment”，这是一个典型的多智能体协作与博弈场景。 - **智能体能力**: 论文的核心是让智能体能够“comprehend and execute high-level or abstract instructions”，这直接关联到智能体的**规划**和指令理解能力。其提出的“Style Interpreter (SI)”模块，本质上是将高级语言指令翻译为可执行策略的规划器。 - **核心范式**: 论文属于**Multi-Agent Systems (MAS)**的研究范畴，虽然其技术路径是Language-Controlled RL (LC-RL)而非纯粹的LLM-based Agent，但其研究目标——构建能够理解语言、在复杂环境中自主行动的智能体——与Agentic AI的核心思想高度一致。 3.  **第三步：排除标准分析** - 论文不涉及安全、对齐、可解释性或视觉多模态等排除领域。其焦点完全集中在智能体的行为控制和指令执行上。 4.  **第四步：特殊和模糊情况处理** - **推理/规划**: 这篇论文是关于智能体如何进行规划的典型案例。它不是在提升LLM的基础推理能力，而是在构建一个能让智能体（由RL策略驱动）根据语言指令进行行为规划和执行的完整框架。这完全符合“保留”的条件。 - **自我演化的应用**: 此处不适用，因为论文的核心贡献不是自我演化机制。 **核心依据总结**: 尽管这篇论文的技术实现是基于LC-RL而非直接使用LLM作为智能体的“大脑”，但其研究目标与您“LLM智能体及其演化”的课题高度契合。它聚焦于**多智能体系统**中的核心难题——**高级指令的遵循与多样化行为的生成**，并提出了一种新颖的**构建性框架（LCDSP）**。这完全符合您“核心贡献在于构建、改进或演化LLM智能体（或更广义的Agentic AI）”的目标。它不是一篇应用型论文，而是一篇方法论型论文，探讨的是如何让智能体在复杂环境中变得更“聪明”、更“可控”，这正是Agentic AI研究的核心。因此，应判定为符合要求。"
    },
    {
        "index": "#9",
        "title": "A Layered Protocol Architecture for the Internet of Agents",
        "link": "/arxiv/2511.19699",
        "arxiv_id": "2511.19699",
        "authors": "Charles Fleming, Vijoy Pandey, Ramana Kompella, Luca Muscariello",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable performance improvements and the ability to learn domain-specific languages (DSLs), including APIs and tool interfaces. This capability has enabled the creation of AI agents that can perform preliminary computations and act through tool calling, now being standardized via protocols like MCP. However, LLMs face fundamental limitations: their context windows cannot grow indefinitely, constraining their memory and computational capacity. Agent collaboration emerges as essential for solving increasingly complex problems, mirroring how computational systems rely on different types of memory to scale. The \"Internet of Agents\" (IoA) represents the communication stack that enables agents to scale by distributing computation across collaborating entities. Current network architectural stacks (OSI and TCP/IP) were designed for data delivery between hosts and processes, not for agent collaboration with semantic understanding. To address this gap, we propose two new layers: an \\textbf{Agent Communication Layer (L8)} and an \\textbf{Agent Semantic Negotiation Layer (L9)}. L8 formalizes the \\textit{structure} of communication, standardizing message envelopes, speech-act performatives (e.g., REQUEST, INFORM), and interaction patterns (e.g., request-reply, publish-subscribe), building on protocols like MCP. L9, which does not exist today, formalizes the \\textit{meaning} of communication, enabling agents to discover, negotiate, and lock a \"Shared Context\" -- a formal schema defining the concepts, tasks, and parameters relevant to their interaction. Together, these layers provide the foundation for scalable, distributed agent collaboration, enabling the next generation of multi-agentic systems.",
        "subjects": "Networking and Internet Architecture, Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-24",
        "category": "cs.MA",
        "crawl_time": "2025-11-26T11:00:03.797095",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进多智能体系统。 1.  **第一步：核心判断** - **保留**。这篇论文的本质并非将现有智能体框架作为工具去解决某个特定领域的问题，也不是关于提升LLM本身的基础推理能力。它的核心贡献是提出一个全新的、用于构建“Internet of Agents”的**方法论和框架**——一个分层协议架构。这个架构旨在解决多智能体系统在扩展和协作时遇到的根本性通信问题，因此属于“构建、改进LLM智能体”的范畴，特别是多智能体方向。 2.  **第二步：正面指标** - 论文高度契合您的核心关注点。它明确聚焦于 **`Multi-Agent Systems (MAS)`**，并深入探讨了 **`Collaboration`**、**`Communication`** 和 **`Negotiation`**。其提出的“Agent Semantic Negotiation Layer (L9)”直接解决了智能体间如何建立“Shared Context”这一高级协作问题，这是构建复杂多智能体社会的关键。 3.  **第三步：排除标准** - 论文不涉及安全、对齐、可解释性或视觉等多模态问题。其焦点纯粹在于智能体间的交互架构，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **基础设施 vs. Agentic框架**: 这篇论文的关键在于区分“模型基础设施”和“Agentic框架”。您要排除的是硬件、部署优化等底层技术。而这篇论文提出的“协议架构”是**应用在智能体交互层面的框架**，是关于智能体如何组织、通信和协作的顶层设计。它不是为了让LLM跑得更快，而是为了让LLM智能体能更好地协同工作。因此，它属于Agentic AI的核心研究，而非要排除的基础设施。 **最终决策**: 该论文的核心贡献是提出一个创新的分层协议（L8和L9层），旨在为大规模、分布式的LLM智能体协作提供通信和语义协商的基础。这直接推动了“多智能体”方向的发展，为构建更复杂、更智能的智能体社会提供了新的方法论和框架。因此，这篇论文与您关于“LLM智能体及其演化”的研究课题高度相关，应该被保留。"
    },
    {
        "index": "#5",
        "title": "VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis",
        "link": "/arxiv/2511.20085",
        "arxiv_id": "2511.20085",
        "authors": "Chujie Wang, Zhiyuan Luo, Ruiqi Liu, Can Ran, Shenghua Fan, Xi Chen, Chu He",
        "summary": "The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-25",
        "category": "cs.MA",
        "crawl_time": "2025-11-26T11:00:03.795930",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出一个名为“VICoT”的**新型多模态智能体框架**。摘要明确指出“we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT)”。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。它并非简单地将现有框架应用于遥感领域，而是**创造了一个新的框架**来解决该领域的复杂推理问题。 2.  **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **核心范式**: 论文标题和摘要都明确提到了 `Agent` 和 `Framework`，属于 `Agentic AI` 和 `LLM-based Agents` 范畴。 *   **智能体能力**: 论文的核心机制是“dynamically incorporating visual tools into the chain of thought”，这直接对应了 `Tool Use / Tool Augmentation`。同时，其“explicit multi-round reasoning”和“stack-based reasoning structure”也紧密关联 `Planning` 和 `Reasoning` 能力。 3.  **第三步：排除标准——不适用** *   **安全与对齐**: 论文的主要贡献是关于智能体的推理框架，而非安全、对齐或可解释性。虽然标题中提到了“Interpretable”（可解释的），但从摘要看，这是其框架带来的一个**特性**，而非研究的**核心贡献**。其核心贡献是框架本身的设计和性能。 *   **多模态与视觉**: 这是一个关键点。虽然论文涉及视觉，但它完全符合特殊规则：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉信息正是VICoT智能体用来进行推理的**工具**（“visual tools”），研究的核心是这个**智能体框架**如何整合和使用这些工具，而不是视觉模型本身。 4.  **第四步：处理特殊和模糊情况——符合保留条件** *   **推理/规划**: 论文是关于智能体如何进行规划和多步推理的。它提出了一个“stack-based reasoning structure”和“Vision-Interleaved Chain-of-Thought”，这属于智能体层面的推理框架，而非提升LLM基础Token预测能力，因此应保留。 *   **自我演化的应用**: 虽然这篇论文不直接涉及“自我演化”，但它遵循了同样的逻辑：核心贡献是**提出一种新的智能体机制**（VICoT框架），即使它被应用在特定领域（遥感分析），也应该保留。遥感领域是验证其框架有效性的试验场，而非研究主题本身。 **最终决策**: 该论文的核心是构建一个新颖的LLM智能体框架（VICoT），专注于增强智能体的工具使用和多步推理能力。尽管它以遥感分析为应用背景，并涉及视觉模态，但其贡献在于智能体架构和方法论本身，完全符合您“构建、改进LLM智能体”的核心目标，特别是“单智能体”方向的研究焦点。因此，应判定为 **True**。"
    },
    {
        "index": "#18",
        "title": "AppSelectBench: Application-Level Tool Selection Benchmark",
        "link": "/arxiv/2511.19957",
        "arxiv_id": "2511.19957",
        "authors": "Tianyi Chen, Michael Solodko, Sen Wang, Jongwoo Ko, Junheng Hao, Colby Banbury, Sara Abdali, Saeed Amizadeh, Qing Xiao, Yinheng Li, Tianyu Ding, Kamran Ghasedi Dizaji, Suzhen Zheng, Hao Fan, Justin Wagle, Pashmina Cameron, Kazuhito Koishida",
        "summary": "Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking fine-grained tools such as APIs, is a fundamental capability. It determines whether the agent initializes the correct environment, avoids orchestration confusion, and efficiently focuses on relevant context. However, existing benchmarks primarily assess fine-grained API selection, offering limited insight into whether models can reason across and choose between different applications. To fill this gap, we introduce AppSelectBench, a comprehensive benchmark for evaluating application selection in CUAs. AppSelectBench contains a novel user task generation pipeline that produces realistic, diverse, and semantically grounded user intents at scale, together with unified evaluation protocols covering random, heuristic, zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers one hundred widely used desktop applications and includes more than one hundred thousand realistic, diverse, and semantically grounded user tasks. Extensive experiments across both closed-source and open-source large language models reveal systematic strengths and weaknesses in inter-application reasoning, showing that even the most capable models still struggle to make consistent application choices. Together, these results establish AppSelectBench as a foundation for studying and advancing application level reasoning, an essential yet underexplored capability of intelligent CUAs. The source is available at https://github.com/microsoft/appselectbench.",
        "subjects": "Computation and Language",
        "date": "2025-11-25",
        "category": "cs.CL",
        "crawl_time": "2025-11-26T11:00:03.896439",
        "filter_reason": "这篇论文的核心贡献是构建了一个名为 `AppSelectBench` 的基准，用于评估计算机使用智能体在应用层面的工具选择能力。根据您的筛选标准，这篇论文完全符合您的研究范围，具体判断过程如下： 1.  **第一步：核心判断** - **保留**: 这篇论文的本质不是将LLM智能体作为工具去解决一个特定领域（如生物、金融）的问题，而是聚焦于智能体研究本身。它提出了一种新的**评估方法论和框架**，专门用于衡量和推动LLM智能体的一项核心能力——应用级工具选择。这直接服务于“**改进**LLM智能体”这一核心目标。没有有效的评估基准，就无法系统性地改进智能体的能力。因此，它属于构建/改进智能体方法论的研究范畴。 2.  **第二步：正面指标** - 论文明确涉及了多个核心关注点： - **核心范式**: `Agentic AI`, `LLM-based Agents` (论文中称为 Computer Using Agents, CUAs)。 - **智能体能力**: `Tool Use / Tool Augmentation` 是论文的绝对核心。更进一步，它探讨的是工具使用前的**规划**环节，即决定使用哪个应用程序，这直接关联到 `Planning` 能力。论文中提到的 \"inter-application reasoning\"（跨应用推理）正是智能体在复杂任务中进行多步规划和决策的体现。 3.  **第三步：排除标准** - 论文的主要贡献是基准测试，不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐议题。 - 论文虽然提到桌面应用，但其研究焦点是智能体选择应用的**推理过程**，而非视觉或多模态感知本身，因此不触犯多模态排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它不是在提升LLM的基础数学或逻辑能力，而是在研究**智能体如何进行规划**——具体来说，是在任务开始时，如何通过推理选择正确的宏观工具（应用程序）。这是智能体自主规划和执行复杂任务链条中的关键一环，是典型的Agentic Reasoning。 **结论**: 尽管这篇论文没有提出一个新的智能体架构或算法，但它提供了一个至关重要的**研究基础设施**，专门用于衡量和驱动LLM智能体在**工具使用和规划**这一核心能力上的进步。对于“LLM智能体及其演化”这一研究课题而言，构建能够精准评估智能体能力的基准，与构建智能体本身同等重要。因此，这篇论文是您研究范围内一篇非常相关且有价值的前沿论文，应当保留。"
    },
    {
        "index": "#27",
        "title": "Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search",
        "link": "/arxiv/2511.19648",
        "arxiv_id": "2511.19648",
        "authors": "Manil Shrestha, Edward Kim",
        "summary": "Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-24",
        "category": "cs.CL",
        "crawl_time": "2025-11-26T11:00:03.898670",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于知识图谱问答（KGQA）这一特定领域，而是提出了两种新颖的**混合算法框架**来解决该领域中的效率与可验证性问题。其中，“LLM-Guided Planning”是一种明确的**智能体规划方法论**。它将LLM用作一个规划器，生成高层策略（关系序列），然后由符号化的搜索算法（BFS）来执行。这本质上是关于**如何构建一个高效的、具备规划能力的LLM智能体**，而非仅仅是一个应用。因此，它通过了第一步的核心判断，应被保留。 2.  **第二步：正面指标——高度匹配** 论文命中了多个核心正面指标： *   **智能体能力**: 论文的标题和摘要都明确提到了 `Planning`。其提出的“LLM-Guided Planning”框架，正是对智能体规划能力的一种构建和改进。 *   **工具使用**: 在这个框架中，LLM（规划器）生成的“关系序列”可以被看作是对工具（知识图谱中的关系和节点）的调用指令。整个广度优先搜索（BFS）过程，可以视为智能体在结构化环境中使用工具执行计划的过程。这完全符合 `Tool Use` 的范畴。 *   **核心范式**: 整个研究是围绕 `LLM-based Agents` 展开的，探讨如何设计其架构以实现特定目标。 3.  **第三步：排除标准——未命中** 论文的主要贡献是关于智能体的规划架构和效率优化，不涉及 `Safety`, `Alignment`, `Interpretability` 或 `Vision` 等排除标准中的主题。其关注点在于“如何做”（How），而非“是否安全”（Safety）或“如何对齐”（Alignment）。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 这篇论文是“智能体规划”的典型范例。它不是在提升LLM本身的基础推理能力（如数学计算），而是在构建一个**让LLM能够进行复杂、多步、可验证推理的系统架构**。这正是您筛选标准中“保留”的情况：关于智能体如何进行规划或在复杂任务中进行多步推理的研究。论文中提到的“structured planning proving more transferable than direct answer generation”也进一步强调了其贡献在于方法论层面，而非特定任务的表现。 **总结**: 该论文的核心是提出了一种名为“LLM-Guided Planning”的新颖智能体框架，用于解决复杂的多步推理问题。它直接贡献于您研究课题中的“单智能体”方向，特别是“规划”和“工具使用”这两个子方向。因此，这篇论文与您的研究目标高度相关，应当被筛选出来。"
    },
    {
        "index": "#39",
        "title": "Fara-7B: An Efficient Agentic Model for Computer Use",
        "link": "/arxiv/2511.19663",
        "arxiv_id": "2511.19663",
        "authors": "Ahmed Awadallah, Yash Lara, Raghav Magazine, Hussein Mozannar, Akshay Nambi, Yash Pandya, Aravind Rajeswaran, Corby Rosset, Alexey Taymanov, Vibhav Vineet, Spencer Whitehead, Andrew Zhao",
        "summary": "Progress in computer use agents (CUAs) has been constrained by the absence of large and high-quality datasets that capture how humans interact with a computer. While LLMs have thrived on abundant textual data, no comparable corpus exists for CUA trajectories. To address these gaps, we introduce FaraGen, a novel synthetic data generation system for multi-step web tasks. FaraGen can propose diverse tasks from frequently used websites, generate multiple solution attempts, and filter successful trajectories using multiple verifiers. It achieves high throughput, yield, and diversity for multi-step web tasks, producing verified trajectories at approximately $1 each. We use this data to train Fara-7B, a native CUA model that perceives the computer using only screenshots, executes actions via predicted coordinates, and is small enough to run on-device. We find that Fara-7B outperforms other CUA models of comparable size on benchmarks like WebVoyager, Online-Mind2Web, and WebTailBench -- our novel benchmark that better captures under-represented web tasks in pre-existing benchmarks. Furthermore, Fara-7B is competitive with much larger frontier models, illustrating key benefits of scalable data generation systems in advancing small efficient agentic models. We are making Fara-7B open-weight on Microsoft Foundry and HuggingFace, and we are releasing WebTailBench.",
        "subjects": "Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-11-24",
        "category": "cs.CL",
        "crawl_time": "2025-11-26T11:00:03.907292",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建和改进一个LLM智能体**。其核心贡献有两个：1）提出了`FaraGen`，一个用于生成智能体训练数据的合成系统；2）使用该数据训练了`Fara-7B`，一个专门用于计算机使用的新型智能体模型。这直接对应了您“构建、改进或演化LLM智能体”的核心目标。它并非简单地将现有智能体应用于某个领域，而是提出了构建该领域智能体的新方法论和新模型。 2.  **第二步：正面指标** - 论文包含了多个核心关注点。标题和摘要中明确提到了`Agentic Model`。 - 智能体能力方面，它涉及了`Tool Use`（将计算机作为工具，通过截图感知和坐标执行操作）和`Planning`（执行多步骤的web任务）。 - 论文的核心是提出一个可扩展的数据生成系统来“advancing small efficient agentic models”，这直接指向了对智能体本身的改进。 3.  **第三步：排除标准** - 论文不涉及安全、对齐或可解释性等排除主题。 - 虽然论文使用了视觉信息（`screenshots`），但这完全符合您设定的特殊规则：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉是智能体感知计算机环境的一种方式，是智能体框架的一部分，而不是论文研究的核心（核心是智能体模型和数据生成方法）。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**：论文聚焦于智能体如何执行多步骤任务，这属于智能体规划能力的范畴，应予以保留。它不是关于提升LLM底层的数学或逻辑推理能力。 - **自我演化的应用**：此规则不直接适用，但论文提出的`FaraGen`系统可以看作是一种“演化”智能体能力的基础设施，通过生成更高质量、更多样化的数据来迭代改进智能体模型。 **最终决策**： 综合以上分析，这篇论文的核心贡献在于提出了一种构建新型计算机使用智能体（Agentic LLM）的完整方法论，包括数据生成和模型训练。它精准地落在您研究范围的“单智能体”方向，特别是“工具使用”和“规划”子方向上。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#38",
        "title": "Scaling Agentic Reinforcement Learning for Tool-Integrated Reasoning in VLMs",
        "link": "/arxiv/2511.19773",
        "arxiv_id": "2511.19773",
        "authors": "Meng Lu, Ran Xu, Yi Fang, Wenxuan Zhang, Yue Yu, Gaurav Srivastava, Yuchen Zhuang, Mohamed Elhoseiny, Charles Fleming, Carl Yang, Zhengzhong Tu, Yang Xie, Guanghua Xiao, Hanrui Wang, Di Jin, Wenqi Shi, Xuan Wang",
        "summary": "While recent vision-language models (VLMs) demonstrate strong image understanding, their ability to \"think with images\", i.e., to reason through multi-step visual interactions, remains limited. We introduce VISTA-Gym, a scalable training environment for incentivizing tool-integrated visual reasoning capabilities in VLMs. VISTA-Gym unifies diverse real-world multimodal reasoning tasks (7 tasks from 13 datasets in total) with a standardized interface for visual tools (e.g., grounding, parsing), executable interaction loops, verifiable feedback signals, and efficient trajectory logging, enabling visual agentic reinforcement learning at scale. While recent VLMs exhibit strong text-only reasoning, both proprietary and open-source models still struggle with tool selection, invocation, and coordination. With VISTA-Gym, we train VISTA-R1 to interleave tool-use with agentic reasoning via multi-turn trajectory sampling and end-to-end reinforcement learning. Extensive experiments across 11 public reasoning-intensive VQA benchmarks show that VISTA-R1-8B outperforms state-of-the-art baselines with similar sizes by 9.51%-18.72%, demonstrating VISTA-Gym as an effective training ground to unlock the tool-integrated reasoning capabilities for VLMs.",
        "subjects": "Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-11-24",
        "category": "cs.CL",
        "crawl_time": "2025-11-26T11:00:03.906973",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体。我的判断过程如下： 1.  **第一步：核心判断 (保留)** 论文的核心本质是**构建和改进一个具有工具使用能力的视觉语言智能体**。它提出了两个核心贡献：1) **VISTA-Gym**，一个专门用于训练智能体进行工具集成推理的规模化环境；2) **VISTA-R1**，一个通过强化学习在该环境中训练出的新智能体模型。这完全符合“构建、改进或演化LLM智能体”的核心目标，而不是简单地将现有智能体作为工具应用到某个领域。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个核心关注点： *   **核心范式**: 明确提到了 `Agentic Reinforcement Learning`，直接命中 `Agentic AI`。 *   **智能体能力**: 论文的主题是 `Tool-Integrated Reasoning`，直接命中 `Tool Use / Tool Augmentation`。同时，其方法涉及多步交互和推理，与 `Planning` 和 `ReAct` 范式高度相关。 *   **演化机制**: 论文使用 `end-to-end reinforcement learning` 和 `multi-turn trajectory sampling` 来训练智能体，这是一种通过环境反馈和经验进行迭代优化的过程，符合 `Self-Improvement` 和 `Iterative Improvement` 的精神。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题。 *   **多模态与视觉**: 这是一个关键但需要仔细判断的点。虽然论文研究对象是VLMs，但它的**研究核心并非VLM模型本身**（如改进其视觉编码器或预训练方法），而是**如何让VLM作为“大脑”的智能体学会“思考与行动”**。VLM在这里是智能体的感知和推理模块，而论文的贡献在于训练这个智能体使用工具、与环境交互的方法论。这完全符合筛选标准中的例外情况：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。本文的研究核心是智能体的训练框架和能力，而非视觉模型。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文研究的不是VLM基础的单步视觉问答能力，而是智能体如何通过多轮交互、调用工具来完成复杂的视觉推理任务。这属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴，因此应该保留。 5.  **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一套新的方法论（训练环境+强化学习算法）来**构建和提升LLM智能体（特别是VLM智能体）的工具使用和复杂推理能力**。它精准地命中了您研究焦点中的“单智能体”方向，特别是“工具使用”和“规划”子方向。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#5",
        "title": "Improving Language Agents through BREW",
        "link": "/arxiv/2511.20297",
        "arxiv_id": "2511.20297",
        "authors": "Shashank Kirtania, Param Biyani, Priyanshu Gupta, Yasharth Bajpai, Roshni Iyer, Sumit Gulwani, Gustavo Soares",
        "summary": "Large Language Model (LLM)-based agents are increasingly applied to tasks requiring structured reasoning, tool use, and environmental adaptation, such as data manipulation, multistep planning, and computer-use automation. However, despite their versatility, current training paradigms for model weight optimization methods, like PPO and GRPO, remain relatively impractical with their high computational overhead for rollout convergence. In addition, the resulting agent policies are difficult to interpret, adapt, or incrementally improve. To address this, we investigate creating and refining structured memory of experiential learning of an agent from its environment as an alternative route to agent optimization. We introduce BREW (Bootstrapping expeRientially-learned Environmental knoWledge), a framework for agent optimization for downstream tasks via KB construction and refinement. In our formulation, we introduce an effective method for partitioning agent memory for more efficient retrieval and refinement. BREW uses task graders and behavior rubrics to learn insights while leveraging state-space search for ensuring robustness from the noise and non-specificity in natural language. Empirical results on real world, domain-grounded benchmarks -- OSWorld, $τ^2$Bench, and SpreadsheetBench -- show BREW achieves $10-20\\%$ improvement in task precision, $10-15\\%$ reduction in API/tool calls leading to faster execution time, all while maintaining computational efficiency on par with base models. Unlike prior work where memory is treated as static context, we establish the KB as a modular and controllable substrate for agent optimization -- an explicit lever for shaping behavior in a transparent, interpretable, and extensible manner.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.549241",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接命中了“LLM智能体及其演化”中的“单智能体”和“自我演化”两个核心方向。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质是提出一种名为BREW的新框架，用于**优化和改进LLM智能体**。它没有将智能体作为工具去解决某个特定领域的问题，而是聚焦于**如何让智能体本身变得更好**。论文的核心是“创建和提炼智能体经验学习的结构化记忆”，并将其作为“智能体优化的另一条途径”，这完全符合“构建、改进或演化 LLM智能体”的核心目标。因此，它不是“非演化型应用”，应予以保留。 **第二步：正面指标——高度匹配** 论文摘要中包含了大量与你研究焦点高度相关的正面指标： - **核心范式**: `LLM-based Agents` (明确提及), `Self-Evolving` (其核心思想是迭代改进和优化)。 - **智能体能力**: `Tool Use` (在背景和结果中提及), `Memory` (这是论文的核心贡献点，即结构化记忆/知识库), `Self-Correction/Self-Reflection` (通过“refining”记忆和“learning insights”实现)。 - **演化机制**: `Self-Improvement` (论文标题和摘要的核心), `Iterative Improvement` (明确提及“incrementally improve”和“refinement”)。 这些指标表明，论文的研究内容与你的兴趣点高度一致。 **第三步：排除标准——未触发** - **安全与对齐**: 论文虽然提到了“interpretable”（可解释性），但这是作为其方法（将知识库作为模块化基底）带来的一个**优点或特性**，而非论文的**主要贡献**。论文的主要贡献是BREW这个优化框架本身，而不是研究如何让智能体更安全或更对齐。因此，不触发排除标准。 - **多模态与视觉**: 论文未涉及任何视觉或多模态内容。 **第四步：处理特殊和模糊情况——符合保留规则** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它在OSWorld、SpreadsheetBench等具体领域的基准上进行了测试，但其**核心贡献是BREW这一全新的“自我演化”机制**。论文明确指出，与以往将记忆视为静态上下文不同，他们将知识库（KB）作为“一个用于塑造行为的明确杠杆”，这正是你关注的“通过经验进行自我完善和迭代”的机制。因此，根据你的规则，即使有应用背景，也应保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种通过构建和迭代提炼结构化记忆（知识库）来优化LLM智能体的新框架BREW。这直接对应了你研究目标中的“改进”和“演化”LLM智能体，特别是聚焦于“记忆”和“自我完善”这两个子方向。它不是简单的应用，也不是基础模型能力的提升，而是关于智能体架构和演化机制的根本性研究。因此，这篇论文与你的研究课题高度相关，必须保留。"
    },
    {
        "index": "#2",
        "title": "NNGPT: Rethinking AutoML with Large Language Models",
        "link": "/arxiv/2511.20333",
        "arxiv_id": "2511.20333",
        "authors": "Roman Kochnev, Waleed Khalid, Tolgay Atinc Uzun, Xi Zhang, Yashkumar Sanjaybhai Dhameliya, Furui Qin, Chandini Vysyaraju, Raghuvir Duvvuri, Avi Goyal, Dmitry Ignatov, Radu Timofte",
        "summary": "Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.",
        "subjects": "Artificial Intelligence, Machine Learning, Neural and Evolutionary Computing",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.548427",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与“自我演化”和“单智能体”方向高度契合。 1.  **核心判断 (第一步):** - **保留**。这篇论文的本质不是简单地将LLM应用于AutoML领域，而是提出了一种名为NNGPT的**新框架**，该框架的核心机制是让LLM能够**自我完善**。摘要中明确指出，NNGPT通过“生成、评估和自我完善的闭环系统”来“持续微调LLM”，这直接命中了“自我演化”的定义。它构建了一个能够自主迭代和改进的智能体系统，而非一个静态的应用工具。 2.  **正面指标 (第二步):** - 论文包含了大量核心关注点： - **自我演化:** `self-improving`, `self-improvement`, `continuous fine-tuning`, `learns from result`。 - **单智能体:** 整个NNGPT框架就是一个复杂的单智能体，它具备多种能力： - **规划:** `zero-shot architecture synthesis`, `hyperparameter optimization (HPO)`。 - **工具使用:** 它集成了代码生成与执行、检索增强（NN-RAG）、强化学习等多种工具和流水线。 - **记忆/反思:** `retrieval-augmented synthesis (NN-RAG)` 和从执行结果中学习的闭环机制体现了记忆和反思能力。 3.  **排除标准 (第三步):** - 论文的主要贡献并非安全、对齐或多模态研究。虽然提到了“computer vision”，但这只是该自我演化智能体所应用的**领域**，而不是研究的核心。根据第三步的规则，只要多模态/视觉不是研究的核心，而是作为智能体解决任务的背景，就不应排除。这里的核心是AutoML的演化过程，而非视觉技术本身。 4.  **特殊和模糊情况 (第四步):** - **自我演化的应用:** 这是最关键的一点。该论文完美符合第四步中的“例外”情况。虽然它被应用于“神经网络开发”这一特定领域，但其**核心贡献是提出了一种新的“自我演化”机制**——即通过生成-评估-学习的闭环来持续优化LLM自身。因此，即使有特定应用背景，也应保留。 - **推理/规划:** 论文中的架构合成和超参数优化是智能体在复杂任务中进行规划和多步决策的体现，属于Agentic框架内的推理，应保留。 **总结:** 该论文的核心贡献是构建了一个能够**自我演化**的LLM智能体框架（NNGPT）。它通过一个包含规划、工具使用、记忆和从反馈中学习的闭环系统，实现了AutoML能力的自主迭代。这完全符合您对“自我演化”和“单智能体”方向的研究目标，因此应被保留。"
    },
    {
        "index": "#13",
        "title": "\"Are We Done Yet?\": A Vision-Based Judge for Autonomous Task Completion of Computer Use Agents",
        "link": "/arxiv/2511.20067",
        "arxiv_id": "2511.20067",
        "authors": "Marta Sumyk, Oleksandr Kosovan",
        "summary": "Computer Use Agents (CUAs) are designed to autonomously operate digital interfaces, yet they often fail to reliably determine whether a given task has been completed. We present an autonomous evaluation and feedback framework that uses vision-language models to assess task completion directly from screenshots and task descriptions. Our dataset covers 42 built-in macOS applications and 1,260 human-labeled tasks across a wide range of scenarios. Our framework achieves up to 73 percent accuracy in task success detection and yields an average relative improvement of 27 percent in overall task success when evaluator feedback is applied. These results show that vision-based evaluation can serve as an effective feedback mechanism that improves the reliability and self-correction of autonomous computer-use agents.",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.551583",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **核心判断 (第一步):** - **保留**。这篇论文的本质不是将LLM智能体作为一个工具去解决某个外部领域（如生物、金融）的问题，而是**直接针对LLM智能体本身的核心缺陷进行改进**。论文的核心贡献是构建了一个“自主评估和反馈框架”，这个框架的目的是提升“Computer Use Agents”的可靠性和自我修正能力。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **正面指标 (第二步):** - 论文明确涉及了多个核心关注点： - **Agentic AI / LLM-based Agents**: 研究对象是“Computer Use Agents”，是典型的LLM智能体。 - **Self-Correction / Self-Improvement**: 摘要中明确指出，该框架“improves the reliability and **self-correction** of autonomous computer-use agents”，并且通过反馈带来了“average relative improvement of 27 percent”。这直接命中了“自我演化”方向下的“自我修正”和“迭代改进”子方向。 - **Tool Use**: Computer Use Agent本身就是一种工具使用范式，而论文提出的视觉评估框架可以被看作是智能体用于自我评估和迭代的“元工具”。 3.  **排除标准 (第三步):** - **安全与对齐**: 论文的主要贡献是提升智能体的任务完成能力和可靠性，而非安全、对齐或可解释性。因此不在此排除范围内。 - **多模态与视觉**: 这是本篇论文最需要辨析的一点。论文确实使用了“vision-language models”，但根据你的核心规则：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，VLM正是被用作智能体**感知任务完成状态（环境）的工具**，研究的核心是**基于这个感知的反馈框架和自我演化机制**，而不是VLM模型本身。因此，它符合例外情况，不应被排除。 4.  **特殊和模糊情况 (第四步):** - **自我演化的应用**: 论文提出的框架是一种通用的“自我演化”机制（通过外部反馈进行自我修正），虽然应用在“Computer Use”这个场景，但其核心贡献是机制本身，这与你的要求“如果论文的核心是提出一种新的‘自我演化’机制...也应该保留”完全一致。 **最终决策 (第五步):** 综合以上分析，这篇论文的核心贡献是提出了一种新颖的、基于视觉反馈的框架，用于增强LLM智能体的自我修正和迭代改进能力。这直接属于你研究焦点中的“自我演化”方向，并且深刻触及了智能体的自主性和可靠性。因此，这篇论文高度相关，应该被**保留 (True)**。"
    },
    {
        "index": "#14",
        "title": "Reducing Latency of LLM Search Agent via Speculation-based Algorithm-System Co-Design",
        "link": "/arxiv/2511.20048",
        "arxiv_id": "2511.20048",
        "authors": "Zixiao Huang, Wen Zeng, Tianyu Fu, Tengxuan Liu, Yizhou Sun, Ke Hong, Xinhao Yang, Chengchun Liu, Yan Li, Quanlu Zhang, Guohao Dai, Zhenhua Zhu, Yu Wang",
        "summary": "LLM-based search agents achieve strong performance but suffer from severe latency, as each step requires serialized LLM reasoning followed by action of tool execution. We revisit this bottleneck through the lens of speculation. While traditional predict-verify speculation paradigm can break serial execution, its benefit remains limited, as it retains the full original workload and adds extra inference overhead. We observe that early agent steps often involve simple evidence-gathering, where correct actions can often be predicted without full reasoning. Building on these observations, we present SPAgent, an algorithm-system co-design framework that expands the role of speculation in search agents to reduce latency. Algorithmically, SPAgent introduces a two-phase adaptive speculation mechanism that selectively omits verification when safe. System-wise, a two-level scheduler regulates speculative requests based on engine load to ensure speculation remains beneficial. We implement SPAgent in real-world systems. Across extensive experimental settings, SPAgent achieves up to $1.65\\times$ end-to-end speedup while maintaining same or even achieving higher accuracy, enabling practical deployment of multi-step search agents.",
        "subjects": "Artificial Intelligence, Machine Learning, Performance",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.551945",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**改进LLM智能体**。其核心贡献是提出了一个名为SPAgent的新框架，通过算法-系统协同设计来**优化LLM搜索智能体的性能**（具体是降低延迟）。这完全符合“构建、改进或演化LLM智能体”的核心目标。它不是将智能体作为工具应用到某个领域，也不是关于基础模型推理能力或纯粹的基础设施研究，而是直接针对智能体运行效率这一核心问题提出创新方案。 2.  **第二步：正面指标** - 论文明确涉及了多个核心关注点： - **核心范式**: `LLM-based Agents` (标题和摘要中多次提及)。 - **智能体能力**: `Tool Use` (摘要中明确提到 \"action of tool execution\")，以及隐含的 `Planning` (多步搜索智能体必然涉及规划)。论文的核心优化对象就是“推理-行动”循环，这与`ReAct`范式紧密相关。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。其焦点是性能优化，而非安全、对齐或多模态问题。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于**智能体如何进行规划和推理**的典型范例。它没有去改变LLM本身的基础数学或逻辑能力，而是优化了智能体在执行任务时的“推理-行动”循环（即ReAct循环）。通过引入“推测”机制，它改变了智能体执行步骤的串行模式，这是一种对智能体规划和执行过程的**架构性改进**，完全符合保留条件。 - **基础设施**: 虽然标题和摘要中提到了 \"Algorithm-System Co-Design\" 和 \"scheduler\"，但这并非一篇纯粹的基础设施论文。其核心创新是**算法层面**的“两阶段自适应推测机制”，系统层面的设计是为了支撑和实现这一算法创新，确保其在实际环境中有效。论文的最终目标是提升智能体本身的效率和实用性，因此其本质属于对智能体的改进，而非底层部署优化。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种新颖的算法-系统协同设计框架（SPAgent），用于**改进LLM智能体的运行效率和性能**。它直接针对智能体的“推理-行动”循环进行优化，属于单智能体研究方向下的重要改进工作。因此，该论文与您关于“LLM智能体及其演化”的研究课题高度相关，应被保留。"
    },
    {
        "index": "#15",
        "title": "M$^3$Prune: Hierarchical Communication Graph Pruning for Efficient Multi-Modal Multi-Agent Retrieval-Augmented Generation",
        "link": "/arxiv/2511.19969",
        "arxiv_id": "2511.19969",
        "authors": "Weizi Shao, Taolin Zhang, Zijie Zhou, Chen Chen, Chengyu Wang, Xiaofeng He",
        "summary": "Recent advancements in multi-modal retrieval-augmented generation (mRAG), which enhance multi-modal large language models (MLLMs) with external knowledge, have demonstrated that the collective intelligence of multiple agents can significantly outperform a single model through effective communication. Despite impressive performance, existing multi-agent systems inherently incur substantial token overhead and increased computational costs, posing challenges for large-scale deployment. To address these issues, we propose a novel Multi-Modal Multi-agent hierarchical communication graph PRUNING framework, termed M$^3$Prune. Our framework eliminates redundant edges across different modalities, achieving an optimal balance between task performance and token overhead. Specifically, M$^3$Prune first applies intra-modal graph sparsification to textual and visual modalities, identifying the edges most critical for solving the task. Subsequently, we construct a dynamic communication topology using these key edges for inter-modal graph sparsification. Finally, we progressively prune redundant edges to obtain a more efficient and hierarchical topology. Extensive experiments on both general and domain-specific mRAG benchmarks demonstrate that our method consistently outperforms both single-agent and robust multi-agent mRAG systems while significantly reducing token consumption.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.552225",
        "filter_reason": "这篇论文符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将一个已有的智能体框架应用到新领域，而是提出了一种名为 M$^3$Prune 的新**框架**，其核心贡献在于**改进**现有的多智能体系统。它解决的是多智能体系统固有的“token开销大”和“计算成本高”的问题。因此，它的核心是关于“改进LLM智能体”的方法论，符合你的核心目标。 2.  **第二步：正面指标** - 论文明确包含了你的核心关注点。标题和摘要中多次出现 `Multi-Agent`、`Communication`、`Collaboration`（通过“collective intelligence”体现）等关键词。其核心贡献“hierarchical communication graph pruning”直接针对多智能体系统中的**通信效率**问题，这是多智能体研究中的一个重要子方向。 3.  **第三步：排除标准** - **安全与对齐**：论文未涉及安全、对齐或可解释性等问题，其焦点是性能和效率，因此不在此排除范围内。 - **多模态与视觉**：这是一个需要仔细判断的点。论文标题和摘要提到了 `Multi-Modal` 和 `visual modalities`。然而，根据你的筛选规则核心思想：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，多模态（文本和视觉）是智能体执行任务的**背景和环境**，但论文的**核心创新点**是“如何修剪智能体之间的通信图”，而不是如何处理多模态信息。M$^3$Prune 框架是一种通用的、优化智能体间通信拓扑结构的方法，其价值在于提升多智能体系统的效率，而非多模态技术本身。因此，它不应被排除。 4.  **第四步：处理特殊和模糊情况** - 此处不适用。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献是提出了一种新的、用于提升多智能体系统通信效率的框架。它直接属于你的研究焦点“多智能体”方向，特别是关于智能体间“协作”与“通信”的改进。虽然涉及多模态，但这只是应用场景，而非研究核心。因此，这篇论文与你的研究课题高度相关，应被**保留**。"
    },
    {
        "index": "#18",
        "title": "RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation",
        "link": "/arxiv/2511.19895",
        "arxiv_id": "2511.19895",
        "authors": "Yuanyuan Lin, Xiangyu Ouyang, Teng Zhang, Kaixin Sui",
        "summary": "Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.558115",
        "filter_reason": "这篇论文符合我的研究范围，其核心贡献在于构建和改进一个LLM智能体框架。我的判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一种名为 `RPM-MCTS` 的新方法/框架。这个框架并非简单地将LLM应用于代码生成领域，而是围绕LLM构建了一个复杂的决策和修正流程。它通过蒙特卡洛树搜索（MCTS）进行路径规划，通过知识检索作为过程奖励模型（PRM）来评估中间步骤，并利用沙箱执行反馈进行自我修正。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是简单的应用，而是一个具有通用性的智能体框架，只是以代码生成为例进行验证。 2.  **第二步：正面指标——高度匹配** 论文包含了多个我核心关注点的正面指标： *   **智能体能力:** *   `Planning`: 论文的核心是使用MCTS进行搜索和规划，以找到最优的代码生成路径。 *   `Self-Correction`: 明确提到利用“sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections”，这是典型的自我修正机制。 *   `Tool Use`: “sandbox execution”本身就是一个工具，智能体通过执行代码（使用工具）来获得反馈。 *   **核心范式:** 论文的工作本质上是 `Agentic AI` 和 `LLM-based Agents` 的一个实例，它构建了一个能够自主规划、执行和修正的智能体。 3.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性，也未涉及多模态或视觉。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留条件** *   **推理/规划:** 这篇论文是“关于智能体如何进行规划或在复杂任务中进行多步推理”的典型范例。它没有停留在提升LLM本身的基础推理能力，而是设计了一个外部的、结构化的框架（MCTS + PRM + Feedback）来引导和修正LLM的推理过程。这与ReAct、ToT等Agentic框架一脉相承，属于应保留的范畴。 **总结:** 该论文的核心是 `RPM-MCTS`，一个集成了规划、工具使用和自我修正能力的LLM智能体新框架。虽然其验证场景是代码生成，但其方法论贡献是普适的，直接命中了我研究目标中的“单智能体”方向，特别是“规划”、“工具使用”和“自我反思/修正”等子方向。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#25",
        "title": "NOEM$^{3}$A: A Neuro-Symbolic Ontology-Enhanced Method for Multi-Intent Understanding in Mobile Agents",
        "link": "/arxiv/2511.19780",
        "arxiv_id": "2511.19780",
        "authors": "Ioannis Tzachristas, Aifen Sui",
        "summary": "We introduce a neuro-symbolic framework for multi-intent understanding in mobile AI agents by integrating a structured intent ontology with compact language models. Our method leverages retrieval-augmented prompting, logit biasing and optional classification heads to inject symbolic intent structure into both input and output representations. We formalize a new evaluation metric-Semantic Intent Similarity (SIS)-based on hierarchical ontology depth, capturing semantic proximity even when predicted intents differ lexically. Experiments on a subset of ambiguous/demanding dialogues of MultiWOZ 2.3 (with oracle labels from GPT-o3) demonstrate that a 3B Llama model with ontology augmentation approaches GPT-4 accuracy (85% vs 90%) at a tiny fraction of the energy and memory footprint. Qualitative comparisons show that ontology-augmented models produce more grounded, disambiguated multi-intent interpretations. Our results validate symbolic alignment as an effective strategy for enabling accurate and efficient on-device NLU.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-24",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.560104",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一种名为 NOEM$^{3}$A 的**新框架**，其目标是**改进**移动AI智能体的一个核心能力：多意图理解。这并非简单地将现有智能体框架应用于某个领域，而是提出了一种方法论（神经符号+本体论增强）来**构建和改进**LLM智能体的内部组件。因此，它符合“核心贡献在于构建、改进或演化LLM智能体”的保留标准。它不属于“非演化型应用”，因为其贡献是方法论层面的，而非应用层面的。 2.  **第二步：正面指标——高度相关** 论文明确提到了 `Mobile AI Agents`，直接命中了 `Agentic AI` 和 `LLM-based Agents` 的核心范式。其使用的 `retrieval-augmented prompting` 技术可以被视为一种 `Tool Use / Tool Augmentation` 的形式，即智能体从外部知识库（本体论）中检索信息来增强自身能力，这是智能体的关键能力之一。 3.  **第三步：排除标准——未触发** 论文的主要目标是提升智能体意图理解的准确性和效率，而非研究安全、对齐、可解释性或水印。同时，论文完全基于文本，不涉及视觉或多模态内容。因此，它没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** 这篇论文的研究焦点是智能体的“感知与理解”环节，而非“规划与执行”环节。虽然它没有直接讨论规划、记忆或自我演化，但**意图理解是智能体进行有效规划和行动的绝对前提**。一个无法准确理解用户意图的智能体，其后续的规划、工具使用等能力都无从谈起。因此，提出一种创新方法来显著提升这一基础能力，完全属于“构建、改进LLM智能体”的核心范畴。它是对单智能体能力（Agentic）中一个基础但至关重要的子方向的深化研究。 **最终决策**: 综合来看，该论文提出了一种新颖的神经符号框架来增强LLM智能体的意图理解能力，这直接贡献于“构建和改进LLM智能体”这一核心目标。它聚焦于智能体的一个基础能力（NLU），并提出了有效的解决方案，尽管不涉及规划、多智能体或自我演化，但其作为智能体能力基石的改进工作，与我的研究课题高度相关。因此，最终判断为 **True**。"
    },
    {
        "index": "#29",
        "title": "HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization",
        "link": "/arxiv/2511.19669",
        "arxiv_id": "2511.19669",
        "authors": "Souradip Poddar, Chia-Tung Ho, Ziming Wei, Weidong Cao, Haoxing Ren, David Z. Pan",
        "summary": "Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-24",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.561311",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是提出一个名为“HeaRT”的**“基于智能体的框架”**和**“基础性推理引擎”**。摘要明确指出，其目标是解决现有AI设计算法中“缺乏自适应机制”的问题，并迈向“智能、自适应、类人设计优化”。这表明论文的本质是**构建和改进一个LLM智能体框架**，而不是简单地将现有框架应用于特定领域。因此，它不属于“非演化型应用”的排除范畴。 2.  **正面指标 (第二步):** 论文包含了多个核心关注点。 *   **核心范式:** 标题和摘要中明确提到了 `Agentic Framework`。 *   **智能体能力:** 论文的核心是一个 `Reasoning` 引擎，并使用 `Hierarchical Circuit Reasoning Tree`，这直接关联到智能体的规划和多步推理能力。 *   **演化机制:** 摘要中强调了解决“缺乏自适应机制”的问题，并在实验中展示了“设计适应任务”，这直接对应了 `Self-Evolving` 和 `Adaptive` 的核心概念。 3.  **排除标准 (第三步):** 论文内容不涉及安全、对齐或多模态等排除领域。 4.  **特殊情况处理 (第四步):** *   **推理/规划:** 论文提出的“HeaRT”框架及其“分层电路推理树”是典型的智能体规划和推理机制，完全符合保留条件。 *   **自我演化的应用:** 这是最关键的一点。虽然论文的应用领域是“AMS设计优化”，但其核心贡献是提出了一种**新的自适应机制**。根据筛选规则，“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”。HeaRT框架的“自适应”和“适应能力”正是这种新机制的体现，因此即使应用在特定工程领域，也应被保留。 **最终决策 (第五步):** 综合分析，这篇论文的核心贡献在于构建了一个具有自适应推理能力的LLM智能体框架（HeaRT），直接命中了我的研究焦点“单智能体”和“自我演化”。它不是一篇简单的应用论文，而是一篇关于智能体架构和演化机制的方法论研究。因此，它完全符合我的筛选要求。"
    },
    {
        "index": "#81",
        "title": "Agent0-VL: Exploring Self-Evolving Agent for Tool-Integrated Vision-Language Reasoning",
        "link": "/arxiv/2511.19900",
        "arxiv_id": "2511.19900",
        "authors": "Jiaqi Liu, Kaiwen Xiong, Peng Xia, Yiyang Zhou, Haonian Ji, Lu Feng, Siwei Han, Mingyu Ding, Huaxiu Yao",
        "summary": "Vision-language agents have achieved remarkable progress in a variety of multimodal reasoning tasks; however, their learning remains constrained by the limitations of human-annotated supervision. Recent self-rewarding approaches attempt to overcome this constraint by allowing models to act as their own critics or reward providers. Yet, purely text-based self-evaluation struggles to verify complex visual reasoning steps and often suffers from evaluation hallucinations. To address these challenges, inspired by recent advances in tool-integrated reasoning, we propose Agent0-VL, a self-evolving vision-language agent that achieves continual improvement with tool-integrated reasoning. Agent0-VL incorporates tool usage not only into reasoning but also into self-evaluation and self-repair, enabling the model to introspect, verify, and refine its reasoning through evidence-grounded analysis. It unifies two synergistic roles within a single LVLM: a Solver that performs multi-turn tool-integrated reasoning, and a Verifier that generates structured feedback and fine-grained self-rewards through tool-grounded critique. These roles interact through a Self-Evolving Reasoning Cycle, where tool-based verification and reinforcement learning jointly align the reasoning and evaluation distributions for stable self-improvement. Through this zero-external-reward evolution, Agent0-VL aligns its reasoning and verification behaviors without any human annotation or external reward models, achieving continual self-improvement. Experiments on geometric problem solving and visual scientific analysis show that Agent0-VL achieves an 12.5% improvement over the base model. Our code is available at \\href{https://github.com/aiming-lab/Agent0/Agent0-VL}{this https URL}.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-11-25",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.591686",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献与你的研究目标高度契合。以下是根据筛选标准的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具去解决一个特定领域的问题，而是**提出了一种全新的、名为“Agent0-VL”的自我演化智能体框架**。其核心贡献在于构建和改进智能体本身，特别是其自我演化的能力。论文详细描述了该智能体的内部架构（Solver和Verifier角色）和演化机制（Self-Evolving Reasoning Cycle），这完全符合“构建、改进或演化 LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文摘要中包含了大量与你核心关注点高度匹配的关键词和概念： - **核心范式**: `Self-Evolving Agent` (自我演化智能体)。 - **智能体能力**: `Tool-Integrated Reasoning` (工具集成推理), `Self-Evaluation` (自我评估), `Self-Repair` (自我修复), `Self-Improvement` (自我改进)。 - **演化机制**: `Self-Evolving Reasoning Cycle` (自我演化推理循环), `Generational Evolution` (通过强化学习实现的代际演化), `Iterative Improvement` (迭代改进)。 - 这些指标表明，论文的研究内容正是你关注的焦点。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐、可解释性等内容，因此不在此排除范围内。 - **多模态与视觉**: 这是一个关键点。虽然论文标题和内容都涉及“Vision-Language”，但根据你的规则“除非它们被用作智能体感知环境的工具，而不是研究的核心”，这篇论文**应该被保留**。在这里，视觉能力是智能体用来感知和解决几何、科学分析等任务的**环境输入**，而论文的**研究核心是那个能够处理视觉信息并进行自我演化的智能体框架**，而不是视觉模型本身。其创新点在于如何让智能体在视觉-语言任务上实现自我演化，而非视觉技术的突破。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。论文的核心贡献是提出一种**新的“自我演化”机制**（Self-Evolving Reasoning Cycle），并将其应用于视觉-语言推理领域。根据你的规则，即使应用在特定领域，只要核心是新的演化机制，就应该保留。 - **推理/规划**: 论文提出的“tool-integrated reasoning”和“Self-Evolving Reasoning Cycle”是典型的智能体规划和多步推理框架，远超于提升LLM基础推理能力的范畴，因此符合保留条件。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建一个具有自我演化能力的视觉语言智能体框架。它不仅直接命中了你的“自我演化”研究方向，还深度融合了“单智能体”方向中的工具使用、自我反思等关键能力。尽管涉及视觉，但视觉是作为智能体与环境交互的媒介，而非研究核心。因此，这篇论文是与你研究课题高度相关的前沿研究，**必须保留**。"
    },
    {
        "index": "#109",
        "title": "Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation",
        "link": "/arxiv/2511.19647",
        "arxiv_id": "2511.19647",
        "authors": "Jennifer Grannen, Michelle Pan, Kenneth Llontop, Cherie Ho, Mark Zolotas, Jeannette Bohg, Dorsa Sadigh",
        "summary": "Foundation models (FM) have unlocked powerful zero-shot capabilities in vision and language, yet their reliance on internet pretraining data leaves them brittle in unstructured, real-world settings. The messy, real-world data encountered during deployment (e.g. occluded or multilingual text) remains massively underrepresented in existing corpora. Robots, as embodied agents, are uniquely positioned to close this gap: they can act in physical environments to collect large-scale, real-world data that enriches FM training with precisely the examples current models lack. We introduce the Robot-Powered Data Flywheel, a framework that transforms robots from FM consumers into data generators. By deploying robots equipped with FMs in the wild, we enable a virtuous cycle: robots perform useful tasks while collecting real-world data that improves both domain-specific adaptation and domain-adjacent generalization. We instantiate this framework with Scanford, a mobile manipulator deployed in the East Asia Library for 2 weeks. Scanford autonomously scans shelves, identifies books using a vision-language model (VLM), and leverages the library catalog to label images without human annotation. This deployment both aids librarians and produces a dataset to finetune the underlying VLM, improving performance on the domain-specific in-the-wild library setting and on domain-adjacent multilingual OCR benchmarks. Using data collected from 2103 shelves, Scanford improves VLM performance on book identification from 32.0% to 71.8% and boosts domain-adjacent multilingual OCR from 24.8% to 46.6% (English) and 30.8% to 38.0% (Chinese), while saving an ~18.7 hrs of human time. These results highlight how robot-powered data flywheels can both reduce human effort in real deployments and unlock new pathways for continually adapting FMs to the messiness of reality. More details are at: https://scanford-robot.github.io",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-11-24",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.610113",
        "filter_reason": "这篇论文的核心贡献是提出了一个名为“Robot-Powered Data Flywheel”（机器人驱动的数据飞轮）的**新框架**。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将机器人或LLM作为工具去解决图书馆管理问题。它的核心贡献在于构建了一个**方法论框架**，该框架描述了一个具身智能体（机器人）如何通过与物理环境的交互，持续收集数据，并利用这些数据来迭代式地改进（演化）驱动其自身行为的基础模型（VLM）。这个“数据飞轮”的闭环过程——行动、收集数据、改进模型、再行动——正是“自我演化”的典型体现。 2.  **第二步：正面指标** - 论文完美命中了多个核心正面指标： - **自我演化**: “virtuous cycle”（良性循环）、“continually adapting FMs”（持续适应基础模型）等描述直接点明了其自我演化的核心。 - **自我完善**: 论文明确指出，收集的数据被用来“improves both domain-specific adaptation and domain-adjacent generalization”（改进特定领域适应性和邻近领域泛化能力）。 - **迭代改进**: “Flywheel”（飞轮）和“continual”（持续）的概念本身就蕴含了迭代改进的机制。 - **智能体能力**: 机器人作为“embodied agents”（具身智能体），其行为包括“autonomously scans shelves”（自主扫描）、“identifies books using a vision-language model”（使用VLM识别书籍）、“leverages the library catalog to label images”（利用图书馆目录标注图像），这展示了智能体的自主规划和工具使用能力。 3.  **第三步：排除标准** - **安全与对齐**: 论文未涉及安全、对齐或可解释性等问题。 - **多模态与视觉**: 论文确实使用了VLM，但它符合“被用作智能体感知环境的工具，而不是研究的核心”这一例外情况。研究的核心是**如何利用VLM感知到的信息来驱动智能体的自我演化**，而不是VLM模型本身。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是最关键的一点。虽然论文的应用场景是特定的（图书馆），但它完全符合“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”的规则。这里的“Robot-Powered Data Flywheel”就是一种新颖的自我演化机制，图书馆部署只是该机制的一个实例化验证。因此，不能将其归为“非演化型应用”而排除。 **最终决策**: 该论文的核心贡献在于构建了一个让具身智能体通过与环境交互实现自我演化的框架。它直接命中了我的研究焦点之一——“自我演化”，并详细阐述了智能体如何通过经验（收集的数据）进行自我完善和迭代。因此，这篇论文高度相关，符合筛选要求。"
    },
    {
        "index": "#96",
        "title": "Prune-Then-Plan: Step-Level Calibration for Stable Frontier Exploration in Embodied Question Answering",
        "link": "/arxiv/2511.19768",
        "arxiv_id": "2511.19768",
        "authors": "Noah Frahm, Prakrut Patel, Yue Zhang, Shoubin Yu, Mohit Bansal, Roni Sengupta",
        "summary": "Large vision-language models (VLMs) have improved embodied question answering (EQA) agents by providing strong semantic priors for open-vocabulary reasoning. However, when used directly for step-level exploration, VLMs often exhibit frontier oscillations, unstable back-and-forth movements caused by overconfidence and miscalibration, leading to inefficient navigation and degraded answer quality. We propose Prune-Then-Plan, a simple and effective framework that stabilizes exploration through step-level calibration. Instead of trusting raw VLM scores, our method prunes implausible frontier choices using a Holm-Bonferroni inspired pruning procedure and then delegates final decisions to a coverage-based planner. This separation converts overconfident predictions into conservative, interpretable actions by relying on human-level judgments to calibrate the step-level behavior of VLMs. Integrated into the 3D-Mem EQA framework, our approach achieves relative improvements of up to 49% and 33% in visually grounded SPL and LLM-Match metrics respectively over baselines. Overall, our method achieves better scene coverage under equal exploration budgets on both OpenEQA and EXPRESS-Bench datasets.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Robotics",
        "date": "2025-11-24",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.601212",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将一个已有的智能体框架简单地应用到新领域，而是**提出了一种新的方法论框架（Prune-Then-Plan）来解决LLM/VLM智能体在执行任务时的一个核心问题**。它针对的是智能体在“探索”这一具体行为上的不稳定性（前沿振荡），通过“剪枝”和“规划”两个步骤来校准和改进智能体的决策过程。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **`Agentic AI` / `LLM-based Agents`**: 论文研究对象是具身问答智能体，是Agentic AI的典型范例。 - **`Planning`**: 论文标题和核心贡献都围绕“Plan”，提出了一种新的规划策略来稳定探索。 - **`Self-Correction`**: “Prune-Then-Plan”机制本质上是一种自我校准和自我修正。它识别出VLM预测中的“过度自信”问题，并通过一个外部程序来纠正其行为，从而避免错误的行动。这属于智能体自我完善能力的范畴。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性，尽管其方法带来了“可解释的行动”，但这只是一个副产品，而非研究核心。 - **多模态与视觉**: 论文使用了VLM（Vision-Language Models），但根据筛选规则的例外情况，这里的VLM是作为智能体**感知环境的工具**。论文的核心贡献并非改进VLM本身，而是改进**如何使用VLM的输出来指导智能体的行动**。研究的焦点是智能体的决策框架，而非视觉或语言模型。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“智能体如何进行规划”的绝佳范例。它不是在提升VLM的基础推理能力，而是在构建一个更高层次的智能体框架，来管理和校准VLM在多步探索任务中的输出。这完全符合“保留”的条件。 **最终决策**: 该论文的核心贡献是提出了一种名为“Prune-Then-Plan”的新框架，用于改进LLM/VLM智能体在具身任务中的规划和探索稳定性。它直接解决了智能体在执行过程中的一个关键缺陷（过度自信导致的行动振荡），属于对单智能体“规划”和“自我修正”能力的增强。虽然它使用了VLM，但研究焦点在于智能体框架本身，而非视觉模型。因此，这篇论文高度契合“LLM智能体及其演化”的研究课题，特别是“单智能体”方向。"
    },
    {
        "index": "#124",
        "title": "AttackPilot: Autonomous Inference Attacks Against ML Services With LLM-Based Agents",
        "link": "/arxiv/2511.19536",
        "arxiv_id": "2511.19536",
        "authors": "Yixin Wu, Rui Wen, Chi Cui, Michael Backes, Yang Zhang",
        "summary": "Inference attacks have been widely studied and offer a systematic risk assessment of ML services; however, their implementation and the attack parameters for optimal estimation are challenging for non-experts. The emergence of advanced large language models presents a promising yet largely unexplored opportunity to develop autonomous agents as inference attack experts, helping address this challenge. In this paper, we propose AttackPilot, an autonomous agent capable of independently conducting inference attacks without human intervention. We evaluate it on 20 target services. The evaluation shows that our agent, using GPT-4o, achieves a 100.0% task completion rate and near-expert attack performance, with an average token cost of only $0.627 per run. The agent can also be powered by many other representative LLMs and can adaptively optimize its strategy under service constraints. We further perform trace analysis, demonstrating that design choices, such as a multi-agent framework and task-specific action spaces, effectively mitigate errors such as bad plans, inability to follow instructions, task context loss, and hallucinations. We anticipate that such agents could empower non-expert ML service providers, auditors, or regulators to systematically assess the risks of ML services without requiring deep domain expertise.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-11-24",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.619962",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献是构建了一个名为 **AttackPilot** 的**自主LLM智能体**。它并非简单地将现有智能体框架应用于安全领域，而是**提出并设计了一个新的智能体框架**，使其能够独立、自主地执行复杂的推理攻击任务。 - 摘要中明确指出，论文的贡献在于智能体的设计，例如“多智能体框架”和“特定于任务的动作空间”，这些设计旨在解决智能体在执行任务时遇到的普遍性问题（如规划失败、指令跟随失败、上下文丢失等）。这完全符合“**构建、改进LLM智能体**”的核心目标。 - 因此，它不属于“非演化型应用”的排除范畴，因为其核心是智能体方法论的创新，而非攻击技术本身。 2.  **第二步：正面指标——高度相关** - 论文包含了大量核心关注点的关键词和概念： - **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)` - **智能体能力**: `Planning` (通过“mitigates errors such as bad plans”体现), `Self-Correction` (通过“adaptively optimize its strategy”体现) - 这些正面指标强烈表明该论文与您的研究方向高度契合。 3.  **第三步：排除标准——不适用** - **安全与对齐**: 这是本案例最需要辨析的一点。虽然论文的主题是“推理攻击”，属于安全领域，但筛选标准的关键在于“**主要贡献**”。这篇论文的主要贡献**不是**提出一种新的攻击方法或分析安全风险，而是**构建了一个能够执行攻击任务的智能体**。它的研究焦点是“如何构建一个能自主完成复杂任务的智能体”，而“推理攻击”只是这个智能体执行的具体任务和应用场景。因此，它没有违反“主要贡献是关于安全”的排除规则。 - **多模态与视觉**: 论文不涉及此内容。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 论文明确讨论了智能体的规划能力，并提出了“多智能体框架”来“减轻糟糕的计划”等错误。这完全符合“保留关于智能体如何进行规划或在复杂任务中进行多步推理的论文”的规则。 **最终决策**: 综合以上分析，这篇论文的本质是**提出了一种新颖的、基于多智能体框架的LLM智能体架构**，用于解决一个需要复杂规划和自主执行的挑战性任务。它的核心贡献在于智能体系统的设计与实现，而非其应用领域（安全）本身。因此，该论文精准地契合了您关于“构建、改进LLM智能体”的研究目标，应被**保留**。"
    },
    {
        "index": "#135",
        "title": "Evolution without an Oracle: Driving Effective Evolution with LLM Judges",
        "link": "/arxiv/2511.19489",
        "arxiv_id": "2511.19489",
        "authors": "Zhe Zhao, Yuheng Yang, Haibin Wen, Xiaojie Qiu, Zaixi Zhang, Qingfu Zhang",
        "summary": "The integration of Large Language Models (LLMs) with Evolutionary Computation (EC) has unlocked new frontiers in scientific discovery but remains shackled by a fundamental constraint: the reliance on an Oracle--an objective, machine-computable fitness function. This paper breaks this barrier by asking: Can evolution thrive in a purely subjective landscape governed solely by LLM judges? We introduce MADE (Multi-Agent Decomposed Evolution), a framework that tames the inherent noise of subjective evaluation through \"Problem Specification.\" By decomposing vague instructions into specific, verifiable sub-requirements, MADE transforms high-variance LLM feedback into stable, precise selection pressure. The results are transformative: across complex benchmarks like DevAI and InfoBench, MADE outperforms strong baselines by over 50% in software requirement satisfaction (39.9% to 61.9%) and achieves a 95% perfect pass rate on complex instruction following. This work validates a fundamental paradigm shift: moving from optimizing \"computable metrics\" to \"describable qualities,\" thereby unlocking evolutionary optimization for the vast open-ended domains where no ground truth exists.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-23",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.623223",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了“自我演化”和“多智能体”两个核心方向。 以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM或现有框架作为工具去解决某个特定领域（如生物、金融）的问题。它的核心贡献是提出了一种名为 MADE (Multi-Agent Decomposed Evolution) 的**新框架和新方法论**。这个方法论旨在解决LLM与演化计算结合时的一个根本性瓶颈：对客观“预言机”的依赖。因此，论文的核心是**构建和改进一种演化机制**，这完全符合您“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Self-Evolving` (论文标题和摘要的核心), `Evolutionary Algorithms` (摘要明确提及), `Multi-Agent Systems (MAS)` (框架名称 MADE 即为 Multi-Agent Decomposed Evolution)。 - **演化机制**: `Self-Improvement`, `Iterative Improvement` (演化计算的本质)。 - 论文提出的框架通过“问题分解”和“LLM评判”来驱动演化，这是一种新颖的智能体协作与演化范式，与您的研究焦点高度契合。 3.  **第三步：排除标准** - 论文的主要贡献并非关于安全、对齐、可解释性或多模态。它专注于演化算法本身的机制创新，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 论文在 DevAI 和 InfoBench 等基准上进行了测试。根据您的规则，即使论文应用在特定领域，只要其**核心贡献是提出一种新的“自我演化”机制**，就应该保留。这篇论文正是如此，其核心是 MADE 框架，而非在软件需求领域的应用本身。因此，符合保留的例外情况。 - **推理/规划**: 论文不涉及提升LLM的基础推理能力，而是构建一个更高层次的演化框架，因此不属于被排除的范畴。 5.  **第五步：最终决策** - **综合判断**：该论文提出了一种创新的演化框架 MADE，它利用多智能体协作的方式（分解问题）和LLM作为主观评判者，实现了在没有客观适应度函数（预言机）情况下的有效演化。这直接推动了“自我演化”领域的前沿，并涉及“多智能体”的协作模式。其贡献是方法论层面的，旨在解锁演化优化在更广阔开放领域的应用潜力，完全符合您关于“LLM智能体及其演化”的研究课题，特别是“自我演化”和“多智能体”方向。因此，应予以保留。"
    },
    {
        "index": "#138",
        "title": "Z-Space: A Multi-Agent Tool Orchestration Framework for Enterprise-Grade LLM Automation",
        "link": "/arxiv/2511.19483",
        "arxiv_id": "2511.19483",
        "authors": "Qingsong He, Jing Nan, Jiayu Jiao, Liangjie Tang, Xiaodong Xu, Mengmeng Sun, Qingyao Wang, Minghui Yan",
        "summary": "Large Language Models can break through knowledge and timeliness limitations by invoking external tools within the Model Context Protocol framework to achieve automated execution of complex tasks. However, with the rapid growth of enterprise-scale MCP services, efficiently and accurately matching target functionalities among thousands of heterogeneous tools has become a core challenge restricting system practicality. Existing approaches generally rely on full-prompt injection or static semantic retrieval, facing issues including semantic disconnection between user queries and tool descriptions, context inflation in LLM input, and high inference latency. To address these challenges, this paper proposes Z-Space, a data-generation-oriented multi-agent collaborative tool invocation framework Z-Space. The Z-Space framework establishes a multi-agent collaborative architecture and tool filtering algorithm: (1) A structured semantic understanding of user queries is achieved through an intent parsing model; (2) A tool filtering module (FSWW) based on fused subspace weighted algorithm realizes fine-grained semantic alignment between intents and tools without parameter tuning; (3) An inference execution agent is constructed to support dynamic planning and fault-tolerant execution for multi-step tasks. This framework has been deployed in the Eleme platform's technical division, serving large-scale test data generation scenarios across multiple business units including Taotian, Gaode, and Hema. Production data demonstrates that the system reduces average token consumption in tool inference by 96.26\\% while achieving a 92\\% tool invocation accuracy rate, significantly enhancing the efficiency and reliability of intelligent test data generation systems.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-23",
        "category": "cs.AI",
        "crawl_time": "2025-11-26T11:00:04.629376",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个已有的LLM智能体应用到某个领域，而是**提出了一种全新的、名为Z-Space的多智能体协作框架**。其核心贡献在于解决“在数千个异构工具中高效准确地匹配目标功能”这一挑战，这属于构建和改进LLM智能体（特别是多智能体系统）的方法论范畴。因此，它符合第一步的“保留”标准。 2.  **第二步：正面指标** - 论文包含了多个核心关注点，相关性非常高： - **核心范式**: `Multi-Agent Systems (MAS)` - 论文标题和摘要明确指出这是一个“多智能体协作工具调用框架”。 - **智能体能力**: `Tool Use / Tool Augmentation` - 整个框架的核心就是“工具调用”和“工具编排”。`Planning` - 摘要中提到构建了“推理执行智能体，以支持动态规划和容错执行”。 - **多智能体**: `Collaboration` - 摘要明确指出是“多智能体协作架构”。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等问题。它专注于智能体的架构和效率优化，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“推理执行智能体”负责“动态规划和容错执行”，这完全符合“保留”的条件，因为它是在智能体框架内进行规划和多步推理，而不是在改进LLM本身的基础推理能力。 - **自我演化的应用**: 虽然论文被应用于“企业级”的“测试数据生成”场景，但这并不构成排除理由。根据核心规则，论文的核心是提出一种新的**多智能体协作框架**，而不是仅仅展示一个应用。这个应用场景是用来验证其框架有效性的，其贡献在于方法论本身，而非应用结果。因此，它不属于“非演化型应用”的排除范畴。 **最终决策:** 综合以上分析，该论文的核心贡献是构建了一个新颖的**多智能体协作框架（Z-Space）**，以解决LLM智能体在复杂任务中的**工具使用**和**规划**效率问题。这完全符合研究课题中关于“多智能体”以及“单智能体能力（规划、工具使用）”的核心方向。因此，最终判断为 **True**。"
    },
    {
        "index": "#23",
        "title": "CLIMATEAGENT: Multi-Agent Orchestration for Complex Climate Data Science Workflows",
        "link": "/arxiv/2511.20109",
        "arxiv_id": "2511.20109",
        "authors": "Hyeonjae Kim, Chenyue Li, Wen Deng, Mengxi Jin, Wen Huang, Mengqian Lu, Binhang Yuan",
        "summary": "Climate science demands automated workflows to transform comprehensive questions into data-driven statements across massive, heterogeneous datasets. However, generic LLM agents and static scripting pipelines lack climate-specific context and flexibility, thus, perform poorly in practice. We present ClimateAgent, an autonomous multi-agent framework that orchestrates end-to-end climate data analytic workflows. ClimateAgent decomposes user questions into executable sub-tasks coordinated by an Orchestrate-Agent and a Plan-Agent; acquires data via specialized Data-Agents that dynamically introspect APIs to synthesize robust download scripts; and completes analysis and reporting with a Coding-Agent that generates Python code, visualizations, and a final report with a built-in self-correction loop. To enable systematic evaluation, we introduce Climate-Agent-Bench-85, a benchmark of 85 real-world tasks spanning atmospheric rivers, drought, extreme precipitation, heat waves, sea surface temperature, and tropical cyclones. On Climate-Agent-Bench-85, ClimateAgent achieves 100% task completion and a report quality score of 8.32, outperforming GitHub-Copilot (6.27) and a GPT-5 baseline (3.26). These results demonstrate that our multi-agent orchestration with dynamic API awareness and self-correcting execution substantially advances reliable, end-to-end automation for climate science analytic tasks.",
        "subjects": "Machine Learning",
        "date": "2025-11-25",
        "category": "cs.LG",
        "crawl_time": "2025-11-26T11:00:04.716588",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断——论文的本质是构建新的多智能体框架。** 论文的核心贡献并非将现有LLM智能体应用于气候科学领域，而是提出了一个名为 `ClimateAgent` 的**全新的自主多智能体框架**。摘要明确指出，其目标是解决“通用LLM智能体”的不足，通过构建一个多智能体系统来编排端到端的工作流。这直接命中了你筛选标准中的“保留”条件：“论文的核心是关于构建LLM智能体、多智能体系统或自我演化的方法论或新框架”。虽然论文在气候科学领域进行验证，但其创新点在于智能体的架构和协作机制，而非气候科学发现本身，因此不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——论文高度聚焦于你的核心关注点。** 论文包含了大量与你研究方向高度相关的正面指标： *   **核心范式**: 明确提出了 `Multi-Agent Systems (MAS)`。 *   **智能体能力**: 涉及 `Planning` (通过Plan-Agent)、`Tool Use` (通过Data-Agents动态内省API) 和 `Self-Correction` (Coding-Agent内置的自我纠正循环)。 *   **多智能体**: 论文的精髓在于 `Orchestration` (编排) 和 `Collaboration` (协作)，通过Orchestrate-Agent协调多个专业化智能体共同完成任务。 这些指标表明，论文深入探讨了多智能体的协作、规划和工具使用等核心Agentic能力。 3.  **第三步：排除标准——论文不涉及安全、对齐或多模态等焦点之外的内容。** 论文的研究焦点是智能体的任务执行能力和工作流自动化，没有涉及安全、对齐、可解释性或水印等内容。同时，它也不以视觉或多模态模型为核心研究点。 4.  **第四步：特殊和模糊情况处理——论文的规划与自我纠正属于Agentic范畴。** 论文中的规划是由专门的 `Plan-Agent` 和 `Orchestrate-Agent` 完成的，这属于智能体如何进行任务分解和多步推理的范畴，符合“保留”标准。其 `self-correction loop` 是智能体在执行过程中进行自我反思和修正的机制，这与“自我演化”方向中的自我完善紧密相关。 **总结:** 该论文的核心贡献是设计并实现了一个具有创新架构的多智能体系统，以解决复杂工作流自动化问题。它详细阐述了智能体间的协作机制、规划能力、工具使用以及自我纠正策略。这完全契合你“构建、改进或演化LLM智能体”的核心目标，尤其是在“多智能体”方向上，并触及了“自我演化”的子方向。因此，这篇论文应被保留。"
    },
    {
        "index": "#134",
        "title": "Agint: Agentic Graph Compilation for Software Engineering Agents",
        "link": "/arxiv/2511.19635",
        "arxiv_id": "2511.19635",
        "authors": "Abhi Chivukula, Jay Somasundaram, Vijay Somasundaram",
        "summary": "LLM-based coding agents are increasingly common but still face challenges in context management, latency, reliability, reproducibility, and scalability. We present Agint, an agentic graph compiler, interpreter, and runtime that incrementally and hierarchically converts natural-language instructions into typed, effect-aware code DAGs. Agint introduces explicit type floors (text to data to spec to code) grounded in semantic graph transformations and a hybrid LLM and function-based JIT runtime. This enables dynamic graph refinement, reproducible and optimizable execution, speculative evaluation, and interoperability with existing developer tools. Agint's typed graph bindings improve reliability and allow concurrent composition of concurrent codebases by construction, supporting accelerated development with smaller and faster models, lower latency, efficient context utilization, and higher throughput. Hierarchical compilation allows scalable graph edits, while the graph structure supports reproducibility and efficient parallel generation. Agint provides a composable unix-style toolchain: dagify (DAG compiler), dagent (hybrid JIT runtime), schemagin (schema generator), and datagin (data transformer) for realtime, low-latency code and dataflow creation. Human developers and coding agents refine graphs through the Agint CLI, while non-technical users use Agint Flow GUI for visual editing, conversational refinement, and debugging to promote prototype agentic workflows to production code. This continuous co-creation model allows teams to prototype quickly, refine seamlessly, and deploy reliably, bridging natural language, compiler methods, and developer tooling to enable a new generation of composable, team-centric coding agents at scale.",
        "subjects": "Software Engineering, Machine Learning",
        "date": "2025-11-24",
        "category": "cs.LG",
        "crawl_time": "2025-11-26T11:00:04.748141",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： **第一步：核心判断——保留** 论文的核心贡献是提出了一种名为 **Agint** 的全新框架，它是一个“agentic graph compiler, interpreter, and runtime”（智能体图编译器、解释器和运行时）。这并非简单地将现有LLM或智能体框架应用于软件工程领域，而是**构建和改进LLM智能体本身的方法论和基础设施**。它旨在解决LLM编码智能体在上下文管理、延迟、可靠性等方面的根本性挑战。因此，它不属于“非演化型应用”的排除范畴，其本质是关于如何构建一个更强大的智能体。 **第二步：正面指标——高度相关** 论文包含了多个核心关注点： - **核心范式**: 论文标题和摘要中明确提到了 `Agentic AI` 和 `LLM-based Agents`。 - **智能体能力**: - **规划**: Agint将自然语言指令“incrementally and hierarchically converts”为“typed, effect-aware code DAGs”（有向无环图）。这本质上是一种结构化的任务规划和执行路径生成，是智能体规划能力的核心体现。 - **自我反思/修正**: 摘要中提到“dynamic graph refinement”（动态图精炼）和“conversational refinement”（对话式精炼），这直接对应了智能体的自我修正和自我反思能力。 - **工具使用**: 整个框架都是为了生成和执行代码，这是智能体最核心的工具使用能力之一。此外，它还支持与“existing developer tools”的互操作性。 **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等排除领域。其焦点完全集中在智能体的架构和能力提升上。 **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 论文提出的图编译和DAG生成机制，正是关于智能体如何进行复杂任务规划和多步推理的**新Agentic框架**。它不是在提升LLM的基础数学或逻辑推理能力，而是在构建一个让智能体能够更好地规划和执行的系统，完全符合“保留”条件。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于**提出了一种创新的、基于图编译的LLM智能体框架（Agint）**，旨在从根本上提升智能体在复杂任务（如软件工程）中的规划、执行、可靠性和自我修正能力。它直接贡献于“构建、改进或演化LLM智能体”这一核心目标，并且与“单智能体”方向下的“规划”和“自我反思”子方向高度契合。因此，这篇论文是您研究课题下的前沿和高相关度文献，应予以保留。"
    }
]