[
    {
        "index": "#5",
        "title": "CXRAgent: Director-Orchestrated Multi-Stage Reasoning for Chest X-Ray Interpretation",
        "link": "/arxiv/2510.21324",
        "arxiv_id": "2510.21324",
        "authors": "Jinhui Lou, Yan Yang, Zhou Yu, Zhenqi Fu, Weidong Han, Qingming Huang, Jun Yu",
        "summary": "Chest X-ray (CXR) plays a pivotal role in clinical diagnosis, and a variety of task-specific and foundation models have been developed for automatic CXR interpretation. However, these models often struggle to adapt to new diagnostic tasks and complex reasoning scenarios. Recently, LLM-based agent models have emerged as a promising paradigm for CXR analysis, enhancing model's capability through tool coordination, multi-step reasoning, and team collaboration, etc. However, existing agents often rely on a single diagnostic pipeline and lack mechanisms for assessing tools' reliability, limiting their adaptability and credibility. To this end, we propose CXRAgent, a director-orchestrated, multi-stage agent for CXR interpretation, where a central director coordinates the following stages: (1) Tool Invocation: The agent strategically orchestrates a set of CXR-analysis tools, with outputs normalized and verified by the Evidence-driven Validator (EDV), which grounds diagnostic outputs with visual evidence to support reliable downstream diagnosis; (2) Diagnostic Planning: Guided by task requirements and intermediate findings, the agent formulates a targeted diagnostic plan. It then assembles an expert team accordingly, defining member roles and coordinating their interactions to enable adaptive and collaborative reasoning; (3) Collaborative Decision-making: The agent integrates insights from the expert team with accumulated contextual memories, synthesizing them into an evidence-backed diagnostic conclusion. Experiments on various CXR interpretation tasks show that CXRAgent delivers strong performance, providing visual evidence and generalizes well to clinical tasks of different complexity. Code and data are valuable at this \\href{https://github.com/laojiahuo2003/CXRAgent/}{link}.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-24",
        "category": "cs.MA",
        "crawl_time": "2025-10-27T11:00:03.828564",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 CXRAgent 的新型LLM智能体框架，其本质是关于**构建和改进LLM智能体**，因此完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断 (保留)** 论文的核心并非简单地将现有智能体应用于医疗领域，而是**提出了一种全新的、结构化的智能体架构**。其核心创新点在于 \"director-orchestrated, multi-stage\"（导演编排的多阶段）这一方法论。这直接命中了“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。它不是一篇“非演化型应用”论文，因为其重点在于智能体内部的协作与推理机制，而非最终的诊断结果本身。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量您关注的核心关键词和概念： *   **核心范式**: `LLM-based agent models`, `team collaboration` (指向Multi-Agent)。 *   **智能体能力**: `Tool coordination` (Tool Use), `multi-step reasoning` (Planning), `contextual memories` (Memory)。 *   **多智能体**: `assembles an expert team`, `defining member roles`, `coordinating their interactions`, `collaborative reasoning`, `Collaborative Decision-making`。这些描述清晰地表明论文构建了一个多智能体协作系统。 *   **规划**: `Diagnostic Planning` 是一个明确的规划阶段。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性，而是智能体的架构和性能。 *   **多模态与视觉**: 这是一个关键点。虽然论文处理的是Chest X-Ray（视觉数据），但根据您的特殊规则，视觉模型在这里是作为智能体调用的**工具**（\"a set of CXR-analysis tools\"）。研究的核心是智能体如何**编排和验证**这些工具的输出（\"Evidence-driven Validator (EDV)\"），而不是视觉模型本身。因此，这不构成排除理由。 4.  **第四步：特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文明确提出了一个多阶段的推理框架，包括工具调用、诊断规划和协作决策，这完全符合“保留”关于智能体规划和多步推理框架的论文。 *   **自我演化的应用**: 虽然这篇论文不涉及“自我演化”，但它完美地诠释了“核心贡献是提出一种新机制，即使应用在特定领域也应保留”的原则。其核心是“director-orchestrated”这一新机制，CXR解读只是其验证和展示的舞台。 **最终决策**: 该论文的核心是构建一个具有创新架构（导演编排、多阶段、专家团队协作）的LLM智能体。它深入探讨了您研究焦点中的**单智能体**（规划、工具使用、记忆）和**多智能体**（协作、通信、团队组建）方向。尽管其应用场景是医疗影像，但其贡献在于智能体方法论本身，而非应用领域的突破。因此，这篇论文是您研究课题“LLM智能体及其演化”的优质前沿文献，应予以保留。"
    },
    {
        "index": "#2",
        "title": "HIKMA: Human-Inspired Knowledge by Machine Agents through a Multi-Agent Framework for Semi-Autonomous Scientific Conferences",
        "link": "/arxiv/2510.21370",
        "arxiv_id": "2510.21370",
        "authors": "Zain Ul Abideen Tariq, Mahmood Al-Zubaidi, Uzair Shah, Marco Agus, Mowafa Househ",
        "summary": "HIKMA Semi-Autonomous Conference is the first experiment in reimagining scholarly communication through an end-to-end integration of artificial intelligence into the academic publishing and presentation pipeline. This paper presents the design, implementation, and evaluation of the HIKMA framework, which includes AI dataset curation, AI-based manuscript generation, AI-assisted peer review, AI-driven revision, AI conference presentation, and AI archival dissemination. By combining language models, structured research workflows, and domain safeguards, HIKMA shows how AI can support - not replace traditional scholarly practices while maintaining intellectual property protection, transparency, and integrity. The conference functions as a testbed and proof of concept, providing insights into the opportunities and challenges of AI-enabled scholarship. It also examines questions about AI authorship, accountability, and the role of human-AI collaboration in research.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computation and Language, Digital Libraries",
        "date": "2025-10-24",
        "category": "cs.MA",
        "crawl_time": "2025-10-27T11:00:03.827678",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于学术会议这一特定领域，而是**提出并详细描述了一个名为HIKMA的“多智能体框架”**。摘要明确指出，论文介绍了该框架的“设计、实现和评估”。这个框架包含了多个承担不同角色的智能体（如AI稿件生成、AI辅助同行评审、AI驱动的修订等），它们协同工作以完成一个复杂的端到端流程。因此，论文的本质是关于**构建一个多智能体系统**，这完全符合我研究范围中的“多智能体”方向。它不是在“使用”一个已有的智能体框架，而是在“构建”和“呈现”一个新的框架。 **第二步：正面指标——论文是否包含我的核心关注点？** - 论文包含了多个核心正面指标： - **核心范式**: 标题和摘要中明确出现了 `Multi-Agent Framework` 和 `Machine Agents`。 - **多智能体**: 整个框架的设计就是为了让不同智能体进行 `Collaboration`（协作），共同完成学术出版的全流程。这涉及到智能体间的分工与工作流协调。 - **智能体能力**: 框架中的智能体执行了复杂的任务，如“AI驱动的修订”，这暗示了 `Self-Correction` 或 `Self-Refine` 的能力。整个“结构化的研究工作流”也体现了智能体的 `Planning` 和执行能力。 **第三步：排除标准——是否为我的研究焦点之外？** - 论文没有触发主要的排除标准。 - **安全与对齐**: 虽然摘要提到了“领域保障措施”、“知识产权保护”和“完整性”，但这些是作为该多智能体框架在设计时需要考虑的**约束和特性**，而非论文的**核心贡献**。论文的核心是框架的架构和工作流，而不是提出一种新的安全或对齐算法。因此，不应因此排除。 - **多模态与视觉**: 论文未涉及视觉或多模态内容。 **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的“结构化的研究工作流”是智能体进行规划和多步推理的体现。它不是在提升LLM本身的基础推理能力，而是在构建一个让智能体能够按计划执行复杂任务的框架，这符合保留条件。 **第五步：最终决策** 综合以上分析，尽管这篇论文以一个具体的应用场景（半自主科学会议）作为其试验床和概念验证，但其**核心贡献在于构建了一个新颖的多智能体协作框架**。该框架的设计、实现和评估是论文的主体，直接对应我研究目标中的“构建、改进或演化LLM智能体”以及“多智能体”方向。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#8",
        "title": "Sketch2BIM: A Multi-Agent Human-AI Collaborative Pipeline to Convert Hand-Drawn Floor Plans to 3D BIM",
        "link": "/arxiv/2510.20838",
        "arxiv_id": "2510.20838",
        "authors": "Abir Khan Ratul, Sanjay Acharjee, Somin Park, Md Nazmus Sakib",
        "summary": "This study introduces a human-in-the-loop pipeline that converts unscaled, hand-drawn floor plan sketches into semantically consistent 3D BIM models. The workflow leverages multimodal large language models (MLLMs) within a multi-agent framework, combining perceptual extraction, human feedback, schema validation, and automated BIM scripting. Initially, sketches are iteratively refined into a structured JSON layout of walls, doors, and windows. Later, these layouts are transformed into executable scripts that generate 3D BIM models. Experiments on ten diverse floor plans demonstrate strong convergence: openings (doors, windows) are captured with high reliability in the initial pass, while wall detection begins around 83% and achieves near-perfect alignment after a few feedback iterations. Across all categories, precision, recall, and F1 scores remain above 0.83, and geometric errors (RMSE, MAE) progressively decrease to zero through feedback corrections. This study demonstrates how MLLM-driven multi-agent reasoning can make BIM creation accessible to both experts and non-experts using only freehand sketches.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-16",
        "category": "cs.MA",
        "crawl_time": "2025-10-27T11:00:03.829397",
        "filter_reason": "这篇论文符合筛选标准，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为一个工具应用于建筑领域，而是**构建了一个新颖的多智能体框架**来解决一个复杂任务。其核心贡献在于这个“Multi-Agent Human-AI Collaborative Pipeline”（多智能体人机协同流水线）的设计与实现。论文详细描述了如何将任务分解为多个智能体（感知提取、模式验证、自动化脚本编写等）并协同工作，这完全符合“构建LLM智能体”的核心目标。它不是非演化型应用，因为其方法论本身就是一种新的智能体架构。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 在标题和摘要中被明确提及，是论文的核心。 - **智能体能力**: `Tool Use` 体现在智能体生成“可执行脚本”来创建3D模型。`Self-Correction` 体现在“iteratively refined”和“feedback corrections”的迭代优化过程中。 - **多智能体**: `Collaboration` 体现在“Multi-Agent Human-AI Collaborative Pipeline”和“multi-agent reasoning”中，描述了智能体之间以及智能体与人类之间的协作。 - 这些正面指标强烈表明该论文与我的研究焦点高度相关。 3.  **第三步：排除标准** - 论文虽然使用了 `MLLMs` (多模态大语言模型)，但它是作为智能体进行“perceptual extraction”（感知提取）的工具，用于理解手绘草图。这完全符合筛选标准中的例外情况：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。本研究的核心是**多智能体框架**，而非MLLM模型本身。 - 论文不涉及安全、对齐等排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文描述了一个完整的多步任务流程（草图 -> JSON -> 脚本 -> 3D模型），由不同智能体分工协作完成，这是一个典型的Agentic规划和执行过程，应予以保留。 - **自我演化的应用**: 论文中的迭代优化和反馈修正机制，虽然不是完全自主的“自我演化”，但属于“自我完善”的范畴，并且是构建在多智能体框架之上的，进一步增强了其相关性。 **最终决策**: 综合以上分析，这篇论文的核心贡献是**提出并验证了一个用于解决复杂现实世界任务的多智能体协作框架**。它展示了如何通过多个专门的LLM智能体（以及人类）的协同、工具使用和迭代反馈来完成一个端到端的目标。这完全符合我研究课题中“构建、改进或演化LLM智能体”的核心目标，特别是“多智能体”这一方向。因此，应判定为 **True**。"
    },
    {
        "index": "#3",
        "title": "\\textsc{autoresearcher}: Automating Knowledge-Grounded and Transparent Research Ideation with Multi-Agent Collaboration",
        "link": "/arxiv/2510.20844",
        "arxiv_id": "2510.20844",
        "authors": "Jiawei Zhou, Ruicheng Zhu, Mengshi Chen, Jianwei Wang, Kai Wang",
        "summary": "Effective research relies on organizing extensive information and stimulating novel solutions. Agentic systems have recently emerged as a promising tool to automate literature-based ideation. However, current systems often remain black-box. Their outputs may appear plausible but weakly grounded, with limited transparency or control for researchers. Our work introduces \\textsc{autoresearcher}, a multi-agent demo system for knowledge-grounded and transparent ideation. Specifically, \\textsc{autoresearcher} integrates meticulously designed four stages into a unified framework: (A) Structured Knowledge Curation, (B) Diversified Idea Generation, (C) Multi-stage Idea Selection, and (D) Expert Panel Review \\& Synthesis. Different from prior pipelines, our system not only exposes intermediate reasoning states, execution logs, and tunable agents for inspections, but also enables the generation of hypotheses that are both diverse and evidence-aligned. Our design is also domain-agnostic: as long as literature sources exist, the same pipeline can be instantiated in any scientific field. As an illustrative case, we demonstrate \\textsc{autoresearcher} on a graph-mining case study ($k$-truss breaking problem), where it generates distinct, plausible hypotheses with evidence and critiques. A live demo and source code are available at https://github.com/valleysprings/AutoResearcher.",
        "subjects": "Multiagent Systems",
        "date": "2025-10-20",
        "category": "cs.MA",
        "crawl_time": "2025-10-27T11:00:03.827982",
        "filter_reason": "这篇论文完全符合您的研究范围，核心贡献在于构建和改进一个多智能体系统。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM或智能体作为工具应用到一个新领域，而是提出了一种新的**多智能体协作框架** (`autoresearcher`)。其核心贡献是这个框架本身的设计，包括其四个阶段的流程（知识整理、想法生成、想法筛选、专家评审）以及对透明度和可控性的改进。这直接命中了您研究目标中的“构建、改进LLM智能体”和“多智能体”方向。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)`，标题和摘要中明确提及。 - **多智能体**: `Collaboration` (协作)，标题和摘要中明确提及。 - **智能体能力**: `Planning` (规划)，论文设计的四阶段流程本身就是一种复杂的任务规划和执行框架。 - 这些正面指标强烈表明该论文与您的研究高度相关。 3.  **第三步：排除标准** - 论文没有触及安全与对齐（Safety, Alignment等）或多模态（Vision, MLLMs等）等排除领域。 - 值得注意的是，论文提到了 `transparent` (透明)。但这并非其主要贡献。论文的重点是**如何通过设计一个多智能体框架来实现透明化**，而不是提出一种新的可解释性理论或方法。透明度是其Agentic框架的一个关键特性，用于解决现有系统的“黑箱”问题，其研究焦点仍然是**Agentic AI的构建与改进**，因此不应被排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文提出的四阶段框架是一个典型的Agentic规划与执行流程，完全符合“保留”标准。它不是在改进LLM的基础推理能力，而是在构建一个能让智能体进行复杂多步任务（研究构思）的系统。 - **自我演化的应用**: 虽然这篇论文不涉及自我演化，但其处理方式与“自我演化的应用”的例外规则逻辑一致：核心贡献是**框架本身**，而图挖掘的案例研究仅仅是该框架的一个**演示**，证明了其领域通用性。这进一步确认了论文的核心是方法论，而非特定应用。 **最终决策**: 综合以上分析，这篇论文的核心贡献是提出一个新颖的、透明的、多智能体协作框架 (`autoresearcher`) 来自动化研究构思。这完全符合您“构建、改进LLM智能体”的核心目标，并且精准地落在“多智能体”这一研究方向上。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#1",
        "title": "ColorEcosystem: Powering Personalized, Standardized, and Trustworthy Agentic Service in massive-agent Ecosystem",
        "link": "/arxiv/2510.21566",
        "arxiv_id": "2510.21566",
        "authors": "Fangwen Wu, Zheng Wu, Jihong Wang, Yunku Chen, Ruiguang Pei, Heyuan Huang, Xin Liao, Xingyu Lou, Huarong Deng, Zhihui Fu, Weiwen Liu, Zhuosheng Zhang, Weinan Zhang, Jun Wang",
        "summary": "With the rapid development of (multimodal) large language model-based agents, the landscape of agentic service management has evolved from single-agent systems to multi-agent systems, and now to massive-agent ecosystems. Current massive-agent ecosystems face growing challenges, including impersonal service experiences, a lack of standardization, and untrustworthy behavior. To address these issues, we propose ColorEcosystem, a novel blueprint designed to enable personalized, standardized, and trustworthy agentic service at scale. Concretely, ColorEcosystem consists of three key components: agent carrier, agent store, and agent audit. The agent carrier provides personalized service experiences by utilizing user-specific data and creating a digital twin, while the agent store serves as a centralized, standardized platform for managing diverse agentic services. The agent audit, based on the supervision of developer and user activities, ensures the integrity and credibility of both service providers and users. Through the analysis of challenges, transitional forms, and practical considerations, the ColorEcosystem is poised to power personalized, standardized, and trustworthy agentic service across massive-agent ecosystems. Meanwhile, we have also implemented part of ColorEcosystem's functionality, and the relevant code is open-sourced at https://github.com/opas-lab/color-ecosystem.",
        "subjects": "Multiagent Systems, Computation and Language",
        "date": "2025-10-24",
        "category": "cs.MA",
        "crawl_time": "2025-10-27T11:00:03.827346",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断——论文的本质是构建和改进多智能体系统。** 论文的核心贡献是提出了一个名为 `ColorEcosystem` 的“蓝图”或框架，用于管理和赋能“大规模智能体生态系统”。这并非将现有智能体框架简单应用于某个垂直领域，而是直接针对多智能体系统在规模化后出现的管理、标准化和可信度等根本性问题，提出了一套全新的系统架构和解决方案。这完全符合“构建、改进或演化 LLM智能体”的核心目标，特别是在“多智能体”这个方向上。 2.  **第二步：正面指标——论文高度聚焦于多智能体系统的核心议题。** 论文摘要中明确包含了多个核心正面指标： *   **核心范式**: `Multi-Agent Systems (MAS)` 和 `massive-agent ecosystems` 是论文的绝对主题。 *   **多智能体**: 论文提出的 `agent store`（标准化平台）和 `agent audit`（可信度监督）机制，本质上是在解决大规模智能体社会中的协作、标准化和治理问题，这与 `Collaboration`、`Agent Society` 等概念紧密相关。 *   **智能体能力**: `agent carrier` 组件通过用户数据和数字孪生提供个性化服务，这涉及到智能体的 `Memory` 和个性化能力。 3.  **第三步：排除标准——论文未触及明确的排除红线。** *   **安全与对齐**: 论文虽然提到了 `Trustworthy` 和 `Audit`，但其主要贡献是提出一个**系统架构**来实现这些目标，而不是研究新的安全算法、对齐理论或可解释性技术本身。这里的“可信”是作为大规模智能体生态系统的一个功能性需求来讨论的，是系统设计的一部分，而非研究的核心理论贡献。因此，它不属于被排除的“主要关注安全与对齐”的论文。 *   **多模态与视觉**: 论文在背景介绍中提及了`(multimodal) large language model-based agents`，但这只是为了说明其技术背景。论文提出的 `ColorEcosystem` 框架本身与多模态或视觉技术无关，其核心是系统层面的设计。 4.  **第四步与第五步：最终决策——论文是关于多智能体系统架构的前沿研究。** 综合来看，这篇论文的研究焦点非常清晰：它不是在讨论单个智能体的推理或工具使用，也不是在讨论自我演化机制，而是**将研究层次提升到了“生态系统”的宏观层面**，探讨如何构建一个能够支持海量智能体共存、协作并提供可信服务的系统架构。这属于“多智能体”研究中非常前沿和重要的方向，即如何从“系统”和“社会”的视角去构建和演化智能体集合。 因此，该论文的核心贡献在于提出了一种构建和改进大规模多智能体系统的新方法论，完全符合你关于“LLM智能体及其演化”中“多智能体”方向的研究目标。应予以保留。"
    },
    {
        "index": "#20",
        "title": "PARL: Prompt-based Agents for Reinforcement Learning",
        "link": "/arxiv/2510.21306",
        "arxiv_id": "2510.21306",
        "authors": "Yarik Menchaca Resendiz, Roman Klinger",
        "summary": "Large language models (LLMs) have demonstrated high performance on tasks expressed in natural language, particularly in zero- or few-shot settings. These are typically framed as supervised (e.g., classification) or unsupervised (e.g., clustering) problems. However, limited work evaluates LLMs as agents in reinforcement learning (RL) tasks (e.g., playing games), where learning occurs through interaction with an environment and a reward system. While prior work focused on representing tasks that rely on a language representation, we study structured, non-linguistic reasoning - such as interpreting positions in a grid world. We therefore introduce PARL (Prompt-based Agent for Reinforcement Learning), a method that uses LLMs as RL agents through prompting, without any fine-tuning. PARL encodes actions, states, and rewards in the prompt, enabling the model to learn through trial-and-error interaction. We evaluate PARL on three standard RL tasks that do not entirely rely on natural language. We show that it can match or outperform traditional RL agents in simple environments by leveraging pretrained knowledge. However, we identify performance limitations in tasks that require complex mathematical operations or decoding states and actions.",
        "subjects": "Computation and Language",
        "date": "2025-10-24",
        "category": "cs.CL",
        "crawl_time": "2025-10-27T11:00:04.130060",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **论文的核心贡献是什么？** 论文的核心贡献是提出了一种名为PARL（Prompt-based Agent for Reinforcement Learning）的新方法，该方法通过提示工程将大型语言模型（LLM）用作强化学习（RL）智能体，而无需微调。 - **是否符合保留条件？** **符合**。这篇论文的本质是关于“构建LLM智能体的方法论或新框架”。它不是将一个已有的智能体框架应用到某个领域，而是提出了一种让LLM本身成为智能体的新范式。这完全符合筛选标准第一步中的“保留”条件。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (论文标题和摘要明确指出)。 - **智能体能力**: 论文的核心是让LLM通过与环境交互进行学习，这涉及到智能体的基本决策循环。其“trial-and-error interaction”和“encoding actions, states, and rewards”的机制，与`ReAct`（Reasoning and Acting）范式高度相关，属于智能体在环境中的`Planning`和`Reasoning`能力。 3.  **第三步：排除标准** - 论文不涉及安全与对齐（Safety, Alignment）、可解释性等主题。 - 论文虽然提到了“grid world”，但这是作为结构化、非语言的环境，研究的核心不是视觉或多模态，而是智能体在此环境中的推理和决策能力。因此，不触及多模态与视觉的排除红线。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于“智能体如何进行规划或在复杂任务中进行多步推理”的典型案例。它研究的是LLM作为智能体，如何在一个需要结构化推理的RL任务中行动和学习，而不是仅仅提升LLM本身的数学或逻辑能力。因此，根据规则，应该**保留**。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于提出了一种构建LLM智能体的新框架（PARL），使其能够在强化学习环境中通过交互进行学习。这直接命中了研究课题中“单智能体”方向的核心，即智能体的规划与推理能力。它不是简单的应用，而是对智能体构建方法本身的探索。因此，这篇论文与“LLM智能体及其演化”的研究目标高度相关，应被筛选出来。"
    },
    {
        "index": "#43",
        "title": "DeepAgent: A General Reasoning Agent with Scalable Toolsets",
        "link": "/arxiv/2510.21618",
        "arxiv_id": "2510.21618",
        "authors": "Xiaoxi Li, Wenxiang Jiao, Jiarui Jin, Guanting Dong, Jiajie Jin, Yinuo Wang, Hao Wang, Yutao Zhu, Ji-Rong Wen, Yuan Lu, Zhicheng Dou",
        "summary": "Large reasoning models have demonstrated strong problem-solving abilities, yet real-world tasks often require external tools and long-horizon interactions. Existing agent frameworks typically follow predefined workflows, which limit autonomous and global task completion. In this paper, we introduce DeepAgent, an end-to-end deep reasoning agent that performs autonomous thinking, tool discovery, and action execution within a single, coherent reasoning process. To address the challenges of long-horizon interactions, particularly the context length explosion from multiple tool calls and the accumulation of interaction history, we introduce an autonomous memory folding mechanism that compresses past interactions into structured episodic, working, and tool memories, reducing error accumulation while preserving critical information. To teach general-purpose tool use efficiently and stably, we develop an end-to-end reinforcement learning strategy, namely ToolPO, that leverages LLM-simulated APIs and applies tool-call advantage attribution to assign fine-grained credit to the tool invocation tokens. Extensive experiments on eight benchmarks, including general tool-use tasks (ToolBench, API-Bank, TMDB, Spotify, ToolHop) and downstream applications (ALFWorld, WebShop, GAIA, HLE), demonstrate that DeepAgent consistently outperforms baselines across both labeled-tool and open-set tool retrieval scenarios. This work takes a step toward more general and capable agents for real-world applications. The code and demo are available at https://github.com/RUC-NLPIR/DeepAgent.",
        "subjects": "Artificial Intelligence, Computation and Language, Information Retrieval, Machine Learning",
        "date": "2025-10-24",
        "category": "cs.CL",
        "crawl_time": "2025-10-27T11:00:04.157656",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建和改进LLM智能体**。它提出了一个名为“DeepAgent”的全新智能体框架，其核心贡献在于解决现有智能体框架的局限性（如预定义工作流、长时程交互中的上下文爆炸等）。这并非将已有智能体作为工具去解决某个特定领域的问题，而是对智能体本身的结构和能力进行创新，因此完全符合“保留”标准。 2.  **第二步：正面指标** - 论文包含了大量您关注的核心指标： - **核心范式**: 论文明确提出了一个 `LLM-based Agent` (`DeepAgent`)。 - **智能体能力**: 论文的核心贡献集中在**单智能体**的多个关键能力上： - **`Planning`**: 论文强调智能体进行“自主思考”和完成“长时程交互”，这本质上是复杂的规划与推理过程。 - **`Tool Use / Tool Augmentation`**: 这是论文的核心创新点之一。它不仅关注工具使用，还提出了“工具发现”和一种新的端到端强化学习策略 `ToolPO` 来教授工具使用。 - **`Memory`**: 论文为解决长时程交互问题，专门引入了“自主记忆折叠机制”，这是对智能体记忆能力的直接改进和构建。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`, `Alignment`, `Interpretability` 等安全与对齐问题。 - 论文的核心是推理和工具使用，而非 `Vision` 或多模态模型本身，因此不触及多模态排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的研究内容属于典型的Agentic推理。它关注的是智能体如何在一个连贯的流程中整合思考、工具调用和行动，以完成复杂任务。这完全符合“保留”关于智能体规划和多步推理的论文的要求，而非仅仅提升LLM的基础数学或逻辑能力。 5.  **第五步：最终决策** - **综合判断**：DeepAgent论文的核心贡献在于构建了一个新的、更通用的LLM智能体框架，并针对性地解决了智能体在规划、记忆和工具使用方面的关键挑战。这与您研究目标中的“单智能体”方向高度契合，是该方向下的前沿研究。因此，最终决策为 **True**。"
    },
    {
        "index": "#44",
        "title": "Doc-Researcher: A Unified System for Multimodal Document Parsing and Deep Research",
        "link": "/arxiv/2510.21603",
        "arxiv_id": "2510.21603",
        "authors": "Kuicai Dong, Shurui Huang, Fangda Ye, Wei Han, Zhi Zhang, Dexun Li, Wenjun Li, Qu Yang, Gang Wang, Yichao Wang, Chen Zhang, Yong Liu",
        "summary": "Deep Research systems have revolutionized how LLMs solve complex questions through iterative reasoning and evidence gathering. However, current systems remain fundamentally constrained to textual web data, overlooking the vast knowledge embedded in multimodal documents Processing such documents demands sophisticated parsing to preserve visual semantics (figures, tables, charts, and equations), intelligent chunking to maintain structural coherence, and adaptive retrieval across modalities, which are capabilities absent in existing systems. In response, we present Doc-Researcher, a unified system that bridges this gap through three integrated components: (i) deep multimodal parsing that preserves layout structure and visual semantics while creating multi-granular representations from chunk to document level, (ii) systematic retrieval architecture supporting text-only, vision-only, and hybrid paradigms with dynamic granularity selection, and (iii) iterative multi-agent workflows that decompose complex queries, progressively accumulate evidence, and synthesize comprehensive answers across documents and modalities. To enable rigorous evaluation, we introduce M4DocBench, the first benchmark for Multi-modal, Multi-hop, Multi-document, and Multi-turn deep research. Featuring 158 expert-annotated questions with complete evidence chains across 304 documents, M4DocBench tests capabilities that existing benchmarks cannot assess. Experiments demonstrate that Doc-Researcher achieves 50.6% accuracy, 3.4xbetter than state-of-the-art baselines, validating that effective document research requires not just better retrieval, but fundamentally deep parsing that preserve multimodal integrity and support iterative research. Our work establishes a new paradigm for conducting deep research on multimodal document collections.",
        "subjects": "Information Retrieval, Computation and Language",
        "date": "2025-10-24",
        "category": "cs.CL",
        "crawl_time": "2025-10-27T11:00:04.157996",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是构建一个名为 `Doc-Researcher` 的统一系统。其核心贡献之一是提出了一个“**迭代多智能体工作流**”，用于分解复杂查询、积累证据并综合答案。这直接属于“构建、改进LLM智能体”的范畴，特别是“多智能体系统”方向。它不是简单地将现有智能体框架应用于一个新领域，而是提出了一个新的、集成了多模态处理能力的智能体系统架构。 2.  **第二步：正面指标** - 论文包含了多个核心关注点，相关性非常高： - **核心范式**: 明确提到了 `Multi-Agent Systems (MAS)`（“迭代多智能体工作流”）。 - **智能体能力**: 涉及 `Planning`（“分解复杂查询”），并且整个“迭代推理和证据收集”过程是典型的智能体行为。 - **多智能体**: 明确涉及 `Collaboration`（多智能体工作流协同工作）。 3.  **第三步：排除标准** - **多模态与视觉**: 论文确实大量涉及多模态（`Multimodal Document Parsing`）。但是，根据筛选规则，只要它们是“被用作智能体感知环境的工具，而不是研究的核心”，就不应排除。在这篇论文中，多模态解析是智能体系统的一个关键组件，是智能体用来理解和处理环境的工具。论文的核心是**智能体如何利用这个工具进行深度研究**，而不是多模态解析技术本身。因此，这不构成排除的理由。 - **安全与对齐**: 论文未涉及这些排除领域。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文描述的“迭代推理”和“分解复杂查询”是在一个多智能体框架内进行的，属于智能体规划和多步推理的范畴，符合保留条件。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献是提出了一种新颖的**多智能体系统**，该系统通过协作的方式，利用先进的工具（多模态解析和检索）来解决复杂的深度研究问题。这完全符合研究课题中的“多智能体”方向。因此，最终判断为 **True**，应该保留。"
    },
    {
        "index": "#39",
        "title": "Code-enabled language models can outperform reasoning models on diverse tasks",
        "link": "/arxiv/2510.20909",
        "arxiv_id": "2510.20909",
        "authors": "Cedegao E. Zhang, Cédric Colas, Gabriel Poesia, Joshua B. Tenenbaum, Jacob Andreas",
        "summary": "Reasoning models (RMs), language models (LMs) trained with reinforcement learning to produce long-form natural language reasoning, have been remarkably successful, but they still require large amounts of computation and data to train, and can be slow and expensive to run. In this paper, we show that standard instruct LMs can already be elicited to be strong reasoners at a level comparable to or even surpassing their corresponding RMs (e.g., DeepSeek V3 vs R1) without finetuning, across diverse domains from instruction following and creative generation to mathematical reasoning. This is achieved by CodeAdapt, our simple recipe that combines the CodeAct framework, where LMs interleave natural language reasoning with code execution in a multi-step fashion, with few-shot bootstrap in-context learning from as few as five training problems. Analyzing four matched pairs of LMs and RMs, we find that CodeAdapt enables three LMs to outperform the corresponding RMs on average over eight tasks (up to 22.9%) while being 10-81% more token efficient, and delivers superior performance on six tasks when averaged over the four models (up to 35.7%). Furthermore, the code-augmented reasoning traces display rich and varied problem-solving strategies. Our findings support that (1) CodeAdapt-style learning and reasoning may be robust and domain general and (2) code-enabled LMs are cognitively grounded and powerful systems, potentially providing a strong foundation for in-weight reinforcement learning.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-27T11:00:04.150859",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 论文的核心贡献是提出了一种名为 **`CodeAdapt`** 的新方法论。这个方法论并非将现有智能体框架简单应用于某个领域，而是**构建和改进**了一个LLM智能体的工作范式。它结合了`CodeAct`框架，让LLM能够以多步方式交错进行自然语言推理和代码执行。这本质上是在定义和优化一个智能体的行为模式，完全符合“构建、改进或演化LLM智能体”的核心目标。因此，它不属于“非演化型应用”或“非Agentic的推理”的排除范畴。 **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **核心范式**: 论文的核心是`LLM-based Agents`，其方法论`CodeAdapt`基于`CodeAct`框架，这是一个典型的智能体框架。 *   **智能体能力**: *   `Tool Use / Tool Augmentation`: 论文的精髓在于让LLM使用“代码执行”作为工具来增强其推理能力。 *   `Planning`: 论文明确指出其方法是“multi-step fashion”（多步方式），这直接对应智能体的规划和多步推理能力。 *   `ReAct`: `CodeAct`框架与`ReAct`（Reason+Act）范式高度相似，只是将“Act”具体化为“代码执行”，这属于Agentic AI的核心推理模式。 **第三步：排除标准——未触发** 论文内容完全不涉及安全与对齐、多模态与视觉等排除标准。其焦点纯粹在于提升智能体的推理性能。 **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 这篇论文是“关于智能体如何进行规划或在复杂任务中进行多步推理”的绝佳范例。它不是在改进LLM的基础Token预测能力，而是在构建一个**框架**，让LLM通过工具使用（代码）和规划（多步）来解决复杂问题。这与“只是关于提高LLM本身基础Token预测的数学或逻辑能力”有本质区别，因此应**保留**。 **第五步：最终决策** 综合以上分析，该论文的核心贡献是提出了一种新的、能显著提升LLM推理能力的智能体框架（`CodeAdapt`）。它直接隶属于您研究焦点中的**“单智能体”**方向，特别是在**“规划”**和**“工具使用”**这两个子方向上做出了明确的创新。因此，这篇论文与您的研究课题高度相关，必须保留。"
    },
    {
        "index": "#40",
        "title": "Shoot First, Ask Questions Later? Building Rational Agents that Explore and Act Like People",
        "link": "/arxiv/2510.20886",
        "arxiv_id": "2510.20886",
        "authors": "Gabriel Grand, Valerio Pepe, Jacob Andreas, Joshua B. Tenenbaum",
        "summary": "Many high-stakes applications of AI require forming data-driven hypotheses and making targeted guesses; e.g., in scientific and diagnostic settings. Given limited resources, to what extent do agents based on language models (LMs) act rationally? We develop methods to benchmark and enhance agentic information-seeking, drawing on insights from human behavior. First, we introduce a strategic decision-oriented dialogue task called Collaborative Battleship, in which a partially-informed Captain must balance exploration (asking questions) and action (taking shots), while a fully-informed Spotter must provide accurate answers under an information bottleneck. Compared to human players (N=42), we find that LM agents struggle to ground answers in context, generate informative questions, and select high-value actions. Next, to address these gaps, we develop novel Monte Carlo inference strategies for LMs based on principles from Bayesian Experimental Design (BED). For Spotter agents, our approach boosts accuracy by up to 14.7% absolute over LM-only baselines; for Captain agents, it raises expected information gain (EIG) by up to 0.227 bits (94.2% of the achievable noise ceiling). Combined, these components yield sharper targeting (+0.303-0.374 F1), and enable weaker LMs, such as Llama-4-Scout, to outperform both humans (8% -> 82% win rate) and frontier models (0% -> 67% win rate vs. GPT-5) at ~1% of GPT-5's cost. We replicate these findings on Guess Who? where our methods significantly boost accuracy (+28.3-42.4 p.p.), demonstrating their general applicability for building rational information-seeking agents.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-27T11:00:04.151253",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质是**构建和改进LLM智能体**。其核心贡献并非将现有智能体框架应用于某个领域，而是提出了一种**全新的方法论**——基于贝叶斯实验设计（BED）的蒙特卡洛推理策略——来**增强智能体的信息寻求和决策能力**。这直接命中了您“构建、改进或演化LLM智能体”的核心目标。它不属于“非演化型应用”，因为其核心是提出一种通用的智能体改进方法，而非解决特定领域问题。 **第二步：正面指标——高度匹配** 论文包含了多个您关注的核心范式和能力： *   **核心范式**: 论文明确研究 `LLM-based Agents`，并且其“Collaborative Battleship”任务涉及两个角色（Captain和Spotter）的互动，属于 `Multi-Agent Systems (MAS)` 的范畴，特别是 `Collaboration`（协作）和 `Communication`（通信）。 *   **智能体能力**: 论文的核心是研究智能体如何平衡“探索”与“行动”，这是一个典型的 `Planning`（规划）问题。智能体通过“提问”来获取信息，这可以看作是一种广义上的 `Tool Use`（工具使用，将提问作为获取信息的工具）。其目标是提升智能体的“理性决策”能力，这与智能体的自主性和高级认知功能紧密相关。 **第三步：排除标准——未触发** 论文的主要贡献不涉及安全与对齐（Safety, Alignment）、可解释性（Interpretability），也没有涉及多模态或视觉。因此，所有排除标准均未触发。 **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文研究的正是智能体在复杂任务中的多步推理和规划问题（如何决定是提问还是射击）。它不是在改进LLM本身的基础数学或逻辑能力，而是在构建一个让智能体能够更理性地进行规划和决策的框架。这完全符合“保留”的条件。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于提出了一种新颖的推理策略来**构建更理性的信息寻求智能体**，并展示了其在多智能体协作场景下的有效性。它直接对齐了您研究课题中的“单智能体”（规划、决策）和“多智能体”（协作、通信）方向。因此，这篇论文是高度相关且应被筛选出来的前沿研究。"
    },
    {
        "index": "#52",
        "title": "Magellan: Guided MCTS for Latent Space Exploration and Novelty Generation",
        "link": "/arxiv/2510.21341",
        "arxiv_id": "2510.21341",
        "authors": "Lufan Chang",
        "summary": "Large Language Models (LLMs) often struggle with generating truly innovative ideas, typically defaulting to high-probability, familiar concepts within their training data's \"gravity wells.\" While advanced search-based methods like Tree of Thoughts (ToT) attempt to mitigate this, they are fundamentally limited by their reliance on unprincipled, inconsistent self-evaluation heuristics to guide exploration. To address this gap, we introduce \\textbf{Magellan}, a novel framework that reframes creative generation as a principled, guided exploration of an LLM's latent conceptual space. At its core, Magellan employs Monte Carlo Tree Search (MCTS) governed by a hierarchical guidance system. For long-range direction, a \"semantic compass\" vector, formulated via orthogonal projection, steers the search towards relevant novelty. For local, step-by-step decisions, a landscape-aware value function replaces flawed self-evaluation with an explicit reward structure that balances intrinsic coherence, extrinsic novelty, and narrative progress. Extensive experiments demonstrate that Magellan significantly outperforms strong baselines, including ReAct and ToT, in generating scientific ideas with superior plausibility and innovation. Our work shows that for creative discovery, a principled, guided search is more effective than unconstrained agency, paving the way for LLMs to become more capable partners in innovation.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-24",
        "category": "cs.CL",
        "crawl_time": "2025-10-27T11:00:04.160682",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： **第一步：核心判断——保留** 论文的核心贡献是提出一个名为 **Magellan** 的新颖框架。这个框架并非简单地将LLM应用于某个领域，而是构建了一个**方法论**来解决LLM在生成创新内容时的局限性。它通过引入蒙特卡洛树搜索（MCTS）和分层引导系统，来**改进LLM的生成过程**。这本质上是在**构建和改进一个LLM智能体**，使其具备更强的探索和创新能力，因此符合“构建、改进或演化LLM智能体”的核心要求。它不属于非演化型应用、非Agentic的推理或基础设施研究。 **第二步：正面指标——高度相关** 论文包含了大量您关注的核心指标： *   **核心范式**: 论文明确提出了一个新的 **Agentic AI** 框架，其核心是引导LLM进行探索，这属于 **LLM-based Agents** 的范畴。 *   **智能体能力**: 论文的焦点是 **Planning**。它使用MCTS进行搜索，这是一种高级的规划和决策算法。论文明确将 **ReAct** 和 **Tree of Thoughts (ToT)** 作为基线进行比较，这直接定位了其在智能体规划和多步推理领域的工作。其提出的“landscape-aware value function”可以看作是一种结构化的 **Self-Correction** 或 **Self-Reflection** 机制，用以替代不可靠的自我评估。 **第三步：排除标准——未触发** 论文的研究焦点是提升智能体的创新生成能力，不涉及安全、对齐、可解释性或水印等问题。同时，它也不涉及多模态或视觉，其研究对象是纯文本的LLM。 **第四步：处理特殊和模糊情况——符合保留条件** 这篇论文是“推理/规划”特殊情况的完美例证。 *   **保留**: 论文的核心是关于**智能体如何进行规划和在复杂任务中进行多步推理**。它没有停留在改进LLM的基础数学或逻辑能力，而是构建了一个新的Agentic框架（Magellan），通过MCTS和引导机制来优化智能体的**决策和生成路径**。这与ReAct、ToT等经典Agentic规划范式一脉相承，并提出了改进方案。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出一个创新的LLM智能体框架，旨在通过高级的规划（MCTS）和引导机制来增强智能体的探索和创新能力。它直接对齐了您研究目标中的“单智能体”方向，特别是“规划”这一子方向。因此，这篇论文是高度相关且前沿的，应被**保留**。"
    },
    {
        "index": "#6",
        "title": "Huxley-Gödel Machine: Human-Level Coding Agent Development by an Approximation of the Optimal Self-Improving Machine",
        "link": "/arxiv/2510.21614",
        "arxiv_id": "2510.21614",
        "authors": "Wenyi Wang, Piotr Piękos, Li Nanbo, Firas Laakom, Yimeng Chen, Mateusz Ostaszewski, Mingchen Zhuge, Jürgen Schmidhuber",
        "summary": "Recent studies operationalize self-improvement through coding agents that edit their own codebases. They grow a tree of self-modifications through expansion strategies that favor higher software engineering benchmark performance, assuming that this implies more promising subsequent self-modifications. However, we identify a mismatch between the agent's self-improvement potential (metaproductivity) and its coding benchmark performance, namely the Metaproductivity-Performance Mismatch. Inspired by Huxley's concept of clade, we propose a metric ($\\mathrm{CMP}$) that aggregates the benchmark performances of the descendants of an agent as an indicator of its potential for self-improvement. We show that, in our self-improving coding agent development setting, access to the true $\\mathrm{CMP}$ is sufficient to simulate how the Gödel Machine would behave under certain assumptions. We introduce the Huxley-Gödel Machine (HGM), which, by estimating $\\mathrm{CMP}$ and using it as guidance, searches the tree of self-modifications. On SWE-bench Verified and Polyglot, HGM outperforms prior self-improving coding agent development methods while using less wall-clock time. Last but not least, HGM demonstrates strong transfer to other coding datasets and large language models. The agent optimized by HGM on SWE-bench Verified with GPT-5-mini and evaluated on SWE-bench Lite with GPT-5 achieves human-level performance, matching the best officially checked results of human-engineered coding agents. Our code is available at https://github.com/metauto-ai/HGM.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-27T11:00:04.747347",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。其核心贡献是提出了一种名为 Huxley-Gödel Machine (HGM) 的新框架，用于指导LLM智能体进行高效的自我改进和演化，这与您的研究目标高度契合。 以下是详细的判断过程： 1.  **第一步：核心判断——保留** - 论文的本质是关于**构建和演化LLM智能体**。摘要明确指出，该研究关注“self-improving coding agent development”（自我改进的编码智能体开发），并提出了一个新框架HGM来“searches the tree of self-modifications”（搜索自我修改树）。这完全符合“构建、改进或演化 LLM智能体”的核心要求。 - 它不属于排除项： - 它不是“非演化型应用”，因为其核心贡献是**自我演化的方法论**（HGM框架和CMP度量），而不是将智能体应用于某个领域。 - 它不是“非Agentic的推理”，因为它关注的是智能体如何进行自我修改和演化，而不是提升LLM的基础推理能力。 - 它不是“基础设施”研究。 2.  **第二步：正面指标——高度匹配** - 论文摘要中包含了大量您关注的核心范式和能力关键词： - **核心范式**: `Self-Evolving`, `Self-Improving`, `LLM-based Agents`。 - **演化机制**: `Self-Improvement`, `Iterative Improvement`（体现在搜索自我修改树的过程中）。 - 这些正面指标非常密集，表明论文与您的研究焦点直接相关。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不涉及安全、对齐、可解释性等。 - 论文的研究对象是编码智能体，属于文本/代码范畴，不涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况——完美契合** - **自我演化的应用**: 这篇论文是“自我演化应用”例外情况的绝佳范例。虽然论文的应用场景是“coding agent”，但其核心价值在于提出了一种**新的、通用的自我演化机制**（HGM框架和用于评估演化潜力的CMP度量）。论文的创新点在于“如何让智能体更好地自我演化”，而不是“智能体在编码任务上表现如何”。因此，它完全符合您的要求，应作为关于“自我演化”的核心研究保留。 **最终决策**: 该论文的核心贡献是提出了一种创新的LLM智能体自我演化框架（HGM），直接命中了您的研究焦点“自我演化”。它不是简单的应用，而是对智能体演化机制本身的深入探索和创新，属于前沿的方法论研究。因此，这篇论文与您的研究课题高度相关，必须保留。"
    },
    {
        "index": "#8",
        "title": "Co-Sight: Enhancing LLM-Based Agents via Conflict-Aware Meta-Verification and Trustworthy Reasoning with Structured Facts",
        "link": "/arxiv/2510.21557",
        "arxiv_id": "2510.21557",
        "authors": "Hongwei Zhang, Ji Lu, Shiqing Jiang, Chenxiang Zhu, Li Xie, Chen Zhong, Haoran Chen, Yurui Zhu, Yongsheng Du, Yanqin Gao, Lingjun Huang, Baoli Wang, Fang Tan, Peng Zou",
        "summary": "Long-horizon reasoning in LLM-based agents often fails not from generative weakness but from insufficient verification of intermediate reasoning. Co-Sight addresses this challenge by turning reasoning into a falsifiable and auditable process through two complementary mechanisms: Conflict-Aware Meta-Verification (CAMV) and Trustworthy Reasoning with Structured Facts (TRSF). CAMV reformulates verification as conflict identification and targeted falsification, allocating computation only to disagreement hotspots among expert agents rather than to full reasoning chains. This bounds verification cost to the number of inconsistencies and improves efficiency and reliability. TRSF continuously organizes, validates, and synchronizes evidence across agents through a structured facts module. By maintaining verified, traceable, and auditable knowledge, it ensures that all reasoning is grounded in consistent, source-verified information and supports transparent verification throughout the reasoning process. Together, TRSF and CAMV form a closed verification loop, where TRSF supplies structured facts and CAMV selectively falsifies or reinforces them, yielding transparent and trustworthy reasoning. Empirically, Co-Sight achieves state-of-the-art accuracy on GAIA (84.4%) and Humanity's Last Exam (35.5%), and strong results on Chinese-SimpleQA (93.8%). Ablation studies confirm that the synergy between structured factual grounding and conflict-aware verification drives these improvements. Co-Sight thus offers a scalable paradigm for reliable long-horizon reasoning in LLM-based agents. Code is available at https://github.com/ZTE-AICloud/Co-Sight/tree/cosight2.0_benchmarks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-27T11:00:04.753612",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建和改进LLM智能体的方法论。以下是根据你的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为Co-Sight的新框架，用于增强LLM智能体的长时程推理能力。它不是将现有智能体作为工具应用到某个特定领域，而是专注于改进智能体内部的推理和验证机制。其核心贡献是方法论和框架创新，完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文高度匹配你的核心关注点： - **核心范式**: 摘要中明确提到 \"LLM-based agents\"，并提出了一个可扩展的 \"scalable paradigm\"。 - **智能体能力**: 论文的核心是解决 \"Long-horizon reasoning\" 问题，这直接关联到 `Planning` 和 `Reasoning`。其提出的 \"Conflict-Aware Meta-Verification\" 和 \"closed verification loop\" 机制，本质上是一种高级的 `Self-Correction` 和 `Self-Reflection` 过程。TRSF模块则扮演了结构化 `Memory` 的角色。 - **多智能体**: 摘要中提到 \"disagreement hotspots among expert agents\" 和 \"synchronizes evidence across agents\"，表明该框架涉及多个智能体（或专家模块）之间的协作与验证，符合 `Multi-Agent Systems` 的研究方向。 3.  **第三步：排除标准** - 论文未触发任何排除标准。 - **安全与对齐**: 虽然论文追求 \"trustworthy reasoning\"，但其目标是通过技术框架提升智能体的可靠性和准确性，而不是研究AI安全、伦理对齐或可解释性本身。它属于智能体能力提升的范畴，而非安全对齐研究。 - **多模态与视觉**: 论文未涉及视觉或多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”的典型案例。它不是在研究如何提升LLM的基础数学或逻辑能力，而是在研究一个智能体**如何进行规划和多步推理**，并提出了一个包含验证和反思的全新Agentic框架（Co-Sight），这与ReAct、ToT等属于同一研究范式。 **总结**: 该论文的核心贡献是Co-Sight框架，它通过引入冲突感知的元验证（CAMV）和基于结构化事实的可信推理（TRSF）两个新机制，构建了一个闭环的验证系统，显著提升了LLM智能体在复杂任务中的长时程推理能力。这直接对应了你研究课题中的“单智能体”（规划、自我反思）和“多智能体”（协作、验证）方向。因此，这篇论文是与你研究高度相关的前沿文献，应予以保留。"
    },
    {
        "index": "#16",
        "title": "Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning",
        "link": "/arxiv/2510.21302",
        "arxiv_id": "2510.21302",
        "authors": "Sanghyun Ahn, Wonje Choi, Junyong Lee, Jinwoo Park, Honguk Woo",
        "summary": "Recent advances in large language models (LLMs) have enabled the automatic generation of executable code for task planning and control in embodied agents such as robots, demonstrating the potential of LLM-based embodied intelligence. However, these LLM-based code-as-policies approaches often suffer from limited environmental grounding, particularly in dynamic or partially observable settings, leading to suboptimal task success rates due to incorrect or incomplete code generation. In this work, we propose a neuro-symbolic embodied task planning framework that incorporates explicit symbolic verification and interactive validation processes during code generation. In the validation phase, the framework generates exploratory code that actively interacts with the environment to acquire missing observations while preserving task-relevant states. This integrated process enhances the grounding of generated code, resulting in improved task reliability and success rates in complex environments. We evaluate our framework on RLBench and in real-world settings across dynamic, partially observable scenarios. Experimental results demonstrate that our framework improves task success rates by 46.2% over Code-as-Policies baselines and attains over 86.8% executability of task-relevant actions, thereby enhancing the reliability of task planning in dynamic environments.",
        "subjects": "Artificial Intelligence, Robotics",
        "date": "2025-10-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-27T11:00:04.757502",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体。以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个**新的神经符号框架**，用于改进现有的“Code-as-Policies”方法。它不是简单地将LLM或现有智能体框架应用到机器人领域，而是针对现有智能体在动态环境中的局限性（环境感知不足），提出了一套包含**符号验证**和**交互式验证**的改进方法论。这直接属于“构建、改进LLM智能体”的范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文围绕 `LLM-based Agents` 在 `Embodied Task Planning` 中的应用和改进展开。 - **智能体能力**: 论文的核心是关于 `Planning`（任务规划）。更重要的是，它提出的“交互式验证”过程，通过生成探索性代码与环境交互来获取信息，这是一种高级的 `Tool Use`（将代码作为与环境交互的工具）和 `Self-Correction`（通过验证和探索来修正初始规划的不足）能力的体现。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment` 或 `Interpretability`，尽管其目标是提升“可靠性”，但这是从任务成功率的角度出发，而非安全对齐。 - 论文虽然应用于“具身智能体”，可能涉及视觉感知，但其研究核心是**规划框架**，而不是视觉模型本身。视觉在这里是智能体感知环境的工具，而非研究的核心贡献，因此不触犯多模态排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是典型的关于**智能体如何进行规划**的研究。它不是在改进LLM本身的数学或逻辑推理能力，而是在构建一个能让智能体在复杂、动态环境中进行更可靠规划的框架。这完全符合“保留”的条件。 - **自我演化的应用**: 虽然论文应用于机器人领域，但其核心是提出一种新的智能体框架（包含验证和自我修正机制），这与“自我演化的应用”中“保留例外”的原则精神一致——核心贡献是机制本身，而非应用领域。 **最终决策**: 这篇论文的核心贡献是提出一个创新的神经符号框架，通过引入符号验证和交互式环境探索，显著提升了LLM智能体在动态环境中的任务规划可靠性和成功率。它直接对智能体的规划和自我修正能力进行了构建和改进，完全契合您研究课题中的“单智能体”方向，特别是规划和工具使用子方向。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#31",
        "title": "From Questions to Queries: An AI-powered Multi-Agent Framework for Spatial Text-to-SQL",
        "link": "/arxiv/2510.21045",
        "arxiv_id": "2510.21045",
        "authors": "Ali Khosravi Kazazi, Zhenlong Li, M. Naser Lessani, Guido Cervone",
        "summary": "The complexity of Structured Query Language (SQL) and the specialized nature of geospatial functions in tools like PostGIS present significant barriers to non-experts seeking to analyze spatial data. While Large Language Models (LLMs) offer promise for translating natural language into SQL (Text-to-SQL), single-agent approaches often struggle with the semantic and syntactic complexities of spatial queries. To address this, we propose a multi-agent framework designed to accurately translate natural language questions into spatial SQL queries. The framework integrates several innovative components, including a knowledge base with programmatic schema profiling and semantic enrichment, embeddings for context retrieval, and a collaborative multi-agent pipeline as its core. This pipeline comprises specialized agents for entity extraction, metadata retrieval, query logic formulation, SQL generation, and a review agent that performs programmatic and semantic validation of the generated SQL to ensure correctness (self-verification). We evaluate our system using both the non-spatial KaggleDBQA benchmark and a new, comprehensive SpatialQueryQA benchmark that includes diverse geometry types, predicates, and three levels of query complexity. On KaggleDBQA, the system achieved an overall accuracy of 81.2% (221 out of 272 questions) after the review agent's review and corrections. For spatial queries, the system achieved an overall accuracy of 87.7% (79 out of 90 questions), compared with 76.7% without the review agent. Beyond accuracy, results also show that in some instances the system generates queries that are more semantically aligned with user intent than those in the benchmarks. This work makes spatial analysis more accessible, and provides a robust, generalizable foundation for spatial Text-to-SQL systems, advancing the development of autonomous GIS.",
        "subjects": "Artificial Intelligence, Databases, Information Retrieval",
        "date": "2025-10-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-27T11:00:04.775694",
        "filter_reason": "这篇论文符合研究范围。 **判断过程和核心依据如下:** 1.  **第一步：核心判断——保留** 论文的本质是提出一个**新的多智能体框架**来解决空间Text-to-SQL问题。摘要中明确指出“a collaborative multi-agent pipeline as its core”（一个协作式多智能体流水线作为其核心）。这表明，论文的核心贡献并非简单地将现有LLM或智能体框架应用于一个新领域（非演化型应用），而是**构建和设计了一个具有特定角色分工和协作流程的智能体系统**。因此，根据第一步的筛选标准，应予以保留。 2.  **第二步：正面指标——高度相关** 论文包含了多个核心关注点，进一步确认了其相关性： *   **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。 *   **智能体能力**: 论文中的 `review agent` 执行了 `Self-Correction` 和 `Self-Verification`，这属于单智能体能力中的自我反思与修正。 *   **多智能体**: 论文明确提到了 `Collaboration`（协作），并设计了包含实体提取、元数据检索、逻辑公式化、SQL生成和审查等多个专门智能体的流水线，体现了智能体间的分工与合作。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于智能体框架的设计和性能提升，不涉及安全、对齐、可解释性或视觉等多模态问题。因此，未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文的多智能体流水线（从实体提取到最终SQL审查）本身就是一个复杂的多步推理和任务规划过程。它不是在提升LLM的基础推理能力，而是在构建一个让智能体能够协同完成复杂任务的框架，这完全符合“保留”的条件。 *   **自我演化的应用**: 虽然这不完全是“自我演化”，但审查智能体的`Self-Correction`机制是自我完善的一种形式，是研究目标中“自我演化”方向的一个重要子集。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于**构建了一个创新的、包含自我修正机制的多智能体协作框架**。它直接对应了研究课题中的“多智能体”和“单智能体（自我反思/修正）”两个核心方向。尽管其应用场景是空间Text-to-SQL，但其方法论本身——即如何设计、组织和协作多个智能体以解决复杂问题——正是“LLM智能体及其演化”研究所关注的前沿内容。因此，这篇论文高度符合筛选要求。"
    },
    {
        "index": "#56",
        "title": "REvolution: An Evolutionary Framework for RTL Generation driven by Large Language Models",
        "link": "/arxiv/2510.21407",
        "arxiv_id": "2510.21407",
        "authors": "Kyungjun Min, Kyumin Cho, Junhwan Jang, Seokhyeong Kang",
        "summary": "Large Language Models (LLMs) are used for Register-Transfer Level (RTL) code generation, but they face two main challenges: functional correctness and Power, Performance, and Area (PPA) optimization. Iterative, feedback-based methods partially address these, but they are limited to local search, hindering the discovery of a global optimum. This paper introduces REvolution, a framework that combines Evolutionary Computation (EC) with LLMs for automatic RTL generation and optimization. REvolution evolves a population of candidates in parallel, each defined by a design strategy, RTL implementation, and evaluation feedback. The framework includes a dual-population algorithm that divides candidates into Fail and Success groups for bug fixing and PPA optimization, respectively. An adaptive mechanism further improves search efficiency by dynamically adjusting the selection probability of each prompt strategy according to its success rate. Experiments on the VerilogEval and RTLLM benchmarks show that REvolution increased the initial pass rate of various LLMs by up to 24.0 percentage points. The DeepSeek-V3 model achieved a final pass rate of 95.5\\%, comparable to state-of-the-art results, without the need for separate training or domain-specific tools. Additionally, the generated RTL designs showed significant PPA improvements over reference designs. This work introduces a new RTL design approach by combining LLMs' generative capabilities with EC's broad search power, overcoming the local-search limitations of previous methods.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Software Engineering",
        "date": "2025-10-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-27T11:00:04.804826",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用于RTL（寄存器传输级）代码生成领域。它的核心贡献是提出了一种名为`REvolution`的**新框架**，该框架将演化计算（EC）与LLM相结合。这个框架本身是一种方法论，其核心机制是“演化一个候选种群”，这完全符合“构建、改进或演化LLM智能体”的目标。它不是在解决一个RTL领域的特定问题，而是在创造一种能让LLM在复杂任务中自我演化和优化的通用性方法。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Self-Evolving` (标题和摘要中明确提到 \"Evolutionary Framework\", \"Evolutionary Computation\")。 - **演化机制**: `Self-Improvement` (通过演化算法进行优化), `Iterative Improvement` (演化过程本身就是迭代改进), `Generational Evolution` (演化一个种群)。 - 这些指标强烈表明论文与“自我演化”方向高度相关。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐或多模态。它专注于算法和框架的创新，因此不触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是本案例的关键。虽然论文的应用领域是RTL生成，属于特定领域，但其核心贡献是提出了一种**新的“自我演化”机制**。根据筛选规则中的例外条款：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域...也应该保留。” `REvolution`框架通过维护一个种群、根据反馈（功能正确性、PPA）进行选择和变异，实现了智能体（在此案例中是RTL设计策略）的自我完善和迭代。这完全符合“自我演化”的定义，因此应当保留。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于构建了一个结合了演化计算和LLM的**自我演化框架**。它展示了如何通过种群演化、反馈驱动和自适应机制来提升LLM在复杂任务中的表现。这直接对应了研究课题中的“**自我演化**”方向，提供了一种让智能体通过环境反馈进行自我完善和迭代的创新方法。因此，尽管其应用场景是RTL，但其方法论层面的贡献使其完全符合筛选要求。"
    },
    {
        "index": "#38",
        "title": "Compositional Monte Carlo Tree Diffusion for Extendable Planning",
        "link": "/arxiv/2510.21361",
        "arxiv_id": "2510.21361",
        "authors": "Jaesik Yoon, Hyeonseo Cho, Sungjin Ahn",
        "summary": "Monte Carlo Tree Diffusion (MCTD) integrates diffusion models with structured tree search to enable effective trajectory exploration through stepwise reasoning. However, MCTD remains fundamentally limited by training trajectory lengths. While periodic replanning allows plan concatenation for longer plan generation, the planning process remains locally confined, as MCTD searches within individual trajectories without access to global context. We propose Compositional Monte Carlo Tree Diffusion (C-MCTD), a framework that elevates planning from individual trajectory optimization to reasoning over complete plan compositions. C-MCTD introduces three complementary components: (1) Online Composer, which performs globally-aware planning by searching across entire plan compositions; (2) Distributed Composer, which reduces search complexity through parallel exploration from multiple starting points; and (3) Preplan Composer, which accelerates inference by leveraging cached plan graphs.",
        "subjects": "Machine Learning",
        "date": "2025-10-24",
        "category": "cs.LG",
        "crawl_time": "2025-10-27T11:00:05.006938",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出一个名为“组合蒙特卡洛树扩散（C-MCTD）”的新**框架**。这个框架旨在解决现有规划方法（MCTD）的局限性，将规划从“单个轨迹优化”提升到“对完整计划组合进行推理”。这直接对应了您研究目标中的“构建、改进或演化 LLM智能体”，特别是**单智能体方向下的“规划”能力**。它不是一个简单的应用，而是对智能体核心规划能力的根本性改进。 2.  **第二步：正面指标 (高度匹配)** 论文内容与您的核心关注点高度契合： *   **核心范式**: 论文提出了一个用于智能体规划的**新框架**。 *   **智能体能力**: 论文的主题就是**规划**，并且涉及了复杂的**多步推理**，摘要中明确提到“stepwise reasoning”和“reasoning over complete plan compositions”。这正是Agentic AI中规划能力的前沿探索。 3.  **第四步：处理特殊和模糊情况 (符合保留规则)** 根据您对“推理/规划”的特殊规则，这篇论文应被**保留**。它不是在提升LLM本身的基础数学或逻辑能力，而是在研究**智能体如何进行规划**。它提出了一种新的结构化搜索和推理机制（C-MCTD框架），以实现更长、更全局的规划，这与ReAct、ToT等Agentic规划框架的研究范式一脉相承，属于对智能体规划过程的改进。 4.  **第三步：排除标准 (未触发)** 论文的主要贡献不涉及安全、对齐、可解释性，也未将多模态或视觉作为研究核心，因此没有触发任何排除标准。 **总结**: 该论文的核心是提出一种创新的、可扩展的智能体规划框架（C-MCTD），旨在提升智能体在复杂任务中的全局规划和推理能力。这完全符合您对“单智能体”方向，特别是“规划”子方向的筛选要求。因此，应将其保留。"
    },
    {
        "index": "#98",
        "title": "Towards Scalable Oversight with Collaborative Multi-Agent Debate in Error Detection",
        "link": "/arxiv/2510.20963",
        "arxiv_id": "2510.20963",
        "authors": "Yongqiang Chen, Gang Niu, James Cheng, Bo Han, Masashi Sugiyama",
        "summary": "Accurate detection of errors in large language models (LLM) responses is central to the success of scalable oversight, or providing effective supervision to superhuman intelligence. Yet, self-diagnosis is often unreliable on complex tasks unless aided by reliable external feedback. Multi-agent debate (MAD) seems to be a natural alternative to external feedback: multiple LLMs provide complementary perspectives and cross-checks for error detection. However, prior MAD protocols frame debate as a zero-sum game, where the debaters compete to win the game instead of seeking the truth. Consequently, it leads to debate hacking: debaters tend to mislead the judge by misinterpreting the task or presenting overconfident claims, which introduce more mistakes and underperform single-agent methods. To mitigate the issue, we introduce a new collaborative MAD protocol, termed ColMAD, that reframes MAD as a non-zero sum game. Specifically, ColMAD encourages multiple agents to criticize each other in a supportive way, such that they can complement the missing points of each other. Therefore, the judge agent can make a more informative conclusion based on more comprehensive evidence. Empirically, we show that ColMAD significantly outperforms previous competitive MAD by 19% and brings non-trivial improvements over single-agent methods in error detection.",
        "subjects": "Machine Learning",
        "date": "2025-10-23",
        "category": "cs.LG",
        "crawl_time": "2025-10-27T11:00:05.023860",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一种新的多智能体协作框架（ColMAD），用于改进现有多智能体辩论（MAD）的效率。它不是简单地将一个已有的智能体框架应用到“错误检测”这个任务上，而是**改进了智能体之间的交互协议和协作机制本身**。其核心贡献在于方法论创新，即如何让多个LLM智能体更有效地协作，这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **核心范式**: `Multi-Agent Systems (MAS)` (论文的核心是Multi-Agent Debate)。 - **多智能体**: `Collaboration` (标题和摘要中明确提出的“协作式”方法), `Communication` (智能体之间相互批评、提供证据)。 - 这些指标直接对应您研究焦点中的**“多智能体”**方向，特别是智能体间的协作与通信机制。 3.  **第三步：排除标准** - **安全与对齐**: 虽然论文提到了“Scalable Oversight”（可扩展的监督），这与AI安全和对齐领域有密切关系，但论文的**主要贡献并非一种新的安全或对齐理论**。相反，它提出的是一种**技术实现路径**（一种新的多智能体框架）来达成“错误检测”这一具体目标。研究的焦点是“如何让智能体更好地协作”，而不是“如何定义或实现安全对齐”。因此，它不应被归为以安全对齐为核心贡献的论文而被排除。 - **多模态与视觉**: 论文内容仅涉及文本LLM，不涉及多模态内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文探讨的是多个智能体如何通过结构化的辩论和协作来达成更准确的判断，这属于智能体在复杂任务中的多步推理和决策过程，符合“保留”标准。它不是在研究LLM本身的基础推理能力（如数学计算），而是在研究一个基于LLM的智能体系统如何进行推理。 **最终决策**: 该论文的核心贡献是提出了一种新颖的协作式多智能体框架（ColMAD），旨在通过改变智能体间的交互模式（从竞争到协作）来提升系统在特定任务（错误检测）上的表现。这直接属于您研究范围中的**“多智能体”**方向，特别是关于**“协作”与“通信”**的子方向。它是一篇方法论驱动的论文，而非应用驱动的论文，因此是您需要筛选的前沿研究。"
    }
]