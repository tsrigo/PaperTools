[
    {
        "index": "#7",
        "title": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework",
        "link": "/arxiv/2511.03179",
        "arxiv_id": "2511.03179",
        "authors": "Varun Kumar, George Em Karniadakis",
        "summary": "The engineering design process often demands expertise from multiple domains, leading to complex collaborations and iterative refinements. Traditional methods can be resource-intensive and prone to inefficiencies. To address this, we formalize the engineering design process through a multi-agent AI framework that integrates structured design and review loops. The framework introduces specialized knowledge-driven agents that collaborate to generate and refine design candidates. As an exemplar, we demonstrate its application to the aerodynamic optimization of 4-digit NACA airfoils. The framework consists of three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems Engineer. The Graph Ontologist employs a Large Language Model (LLM) to construct two domain-specific knowledge graphs from airfoil design literature. The Systems Engineer, informed by a human manager, formulates technical requirements that guide design generation and evaluation. The Design Engineer leverages the design knowledge graph and computational tools to propose candidate airfoils meeting these requirements. The Systems Engineer reviews and provides feedback both qualitative and quantitative using its own knowledge graph, forming an iterative feedback loop until a design is validated by the manager. The final design is then optimized to maximize performance metrics such as the lift-to-drag ratio. Overall, this work demonstrates how collaborative AI agents equipped with structured knowledge representations can enhance efficiency, consistency, and quality in the engineering design process.",
        "subjects": "Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-11-05",
        "category": "cs.MA",
        "crawl_time": "2025-11-06T11:00:07.607150",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。 以下是根据您的筛选标准进行的详细判断过程： 1.  **第一步：核心判断** - **判断结果**: 保留。 - **核心依据**: 论文的核心贡献在于提出了一种**知识引导的多智能体框架**，用于自动化工程设计流程。这完全符合您筛选标准第一步中的“保留”条件：论文的核心是关于**构建多智能体系统（Multi-Agent Systems）**的方法论，而不仅仅是将已有框架应用到特定领域。虽然论文的应用领域是工程设计，但其本质是构建一个由多个专业化智能体（Graph Ontologist, Design Engineer, Systems Engineer）组成的协作系统，这正是您研究的焦点。 2.  **第二步：正面指标** - **判断结果**: 高度匹配。 - **核心依据**: 论文包含了多个您关注的核心正面指标： - **核心范式**: 明确提出了 `Multi-Agent Systems (MAS)` 框架。 - **多智能体**: 详细描述了智能体间的 `Collaboration`（协作）和 `Communication`（通过反馈循环进行通信）。 - **智能体能力**: `Tool Use`（Design Engineer 使用计算工具）、`Planning`（Systems Engineer 制定技术要求，整个迭代循环是一种规划过程）。 - **演化机制**: `Iterative Improvement`（通过反馈循环进行迭代优化）。 这些指标表明，论文的研究内容与您的“多智能体”和“单智能体”方向高度相关。 3.  **第三步：排除标准** - **判断结果**: 未触发排除标准。 - **核心依据**: 论文的主要贡献是关于智能体框架的设计和协作机制，并未涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题。同时，虽然LLM被用作处理文本的工具，但论文的核心并非多模态或视觉模型研究，因此也未触发相关排除项。 4.  **第四步：处理特殊和模糊情况** - **判断结果**: 符合保留规则。 - **核心依据**: - **推理/规划**: 论文中的规划是**智能体层面的规划**。Systems Engineer制定目标，Design Engineer执行，并通过反馈循环进行调整。这属于“关于智能体如何进行规划或在复杂任务中进行多步推理”的范畴，因此应该保留。它不是关于提升LLM本身的基础推理能力。 - **自我演化的应用**: 这篇论文不属于“自我演化”的应用，因为它没有提出智能体自我完善能力的机制。但是，它完全符合“多智能体”的核心方向，因此无需依赖“自我演化”的例外规则来保留。 5.  **第五步：最终决策** - **综合分析**: 该论文的研究焦点是**如何设计和构建一个有效的多智能体协作系统**，这正是您“多智能体”研究方向的核心内容。其工程应用（翼型设计）是作为验证框架有效性的案例，而非论文本身的核心贡献。论文清晰地定义了智能体的角色、交互方式和协作流程，完全符合您筛选“构建、改进或演化LLM智能体”论文的目标。 因此，最终判断为 **True**。"
    },
    {
        "index": "#2",
        "title": "ALAS: Transactional and Dynamic Multi-Agent LLM Planning",
        "link": "/arxiv/2511.03094",
        "arxiv_id": "2511.03094",
        "authors": "Longling Geng, Edward Y. Chang",
        "summary": "Large language models enable flexible multi-agent planning but remain fragile in practice: verification is often circular, state changes are not tracked for repair, and small faults trigger costly global recomputation. We present ALAS, a stateful, disruption-aware framework that separates planning from non-circular validation, records a versioned execution log for grounded checks and restore points, and performs localized repair that preserves work in progress. The validator operates independently of the planning LLM with fresh, bounded context, avoiding self-check loops and mid-context attrition. The repair protocol edits only the minimal affected region under explicit policies (retry, catch, timeout, backoff, idempotency keys, compensation, loop guards) defined in a canonical workflow IR that maps to Amazon States Language and Argo Workflows. On job-shop scheduling suites (DMU, TA) across five classical benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent baselines, achieving 83.7% success, reducing token usage by 60%, and running 1.82times faster under comparable settings. A minimal reliability study shows that the validator detects injected structural faults with low overhead, and that localized repair contains runtime perturbations with a bounded edit radius and less makespan degradation than global recompute. Results indicate that the combination of validator isolation, versioned execution logs, and localized repair provides measurable efficiency, feasibility, and scalability for multi-agent LLM planning. Code and seeds will be released.",
        "subjects": "Multiagent Systems",
        "date": "2025-11-05",
        "category": "cs.MA",
        "crawl_time": "2025-11-06T11:00:07.605773",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断为“保留”。以下是根据你的筛选标准进行的详细分析： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出一个名为 **ALAS** 的新框架，用于解决现有“多智能体LLM规划”系统中的脆弱性问题。它不是简单地将LLM应用到一个领域，而是**构建和改进一个多智能体系统本身**。论文提出的“分离式验证”、“版本化执行日志”和“局部化修复”都是对智能体架构和运行机制的实质性创新。 - **结论**: 符合“保留”标准，因为它直接贡献了一个构建和改进多智能体系统的方法论。 2.  **第二步：正面指标** - 论文摘要中包含了大量你的核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` (标题和摘要中多次提及)。 - **智能体能力**: `Planning` (标题和摘要的核心)，`Self-Correction` (通过“localized repair”和“validator”机制实现)。 - **多智能体**: 论文的研究对象就是多智能体系统，其评估基准也是多智能体基线。 - **结论**: 论文高度契合你的研究焦点，命中了多个关键正面指标。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主要贡献是关于提升多智能体规划的**效率、可行性和可扩展性**，而非安全、对齐或可解释性。 - **多模态与视觉**: 论文完全聚焦于基于文本的LLM和规划逻辑，不涉及视觉或多模态内容。 - **结论**: 未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“智能体规划”的典型范例。它研究的不是如何提升LLM本身的基础数学或逻辑推理能力，而是**如何构建一个更鲁棒的智能体框架来执行复杂的多步规划和任务**。其提出的验证和修复机制，正是对智能体在动态环境中进行规划和行动的改进，完全符合“保留”条件。 5.  **第五步：最终决策** - **综合分析**: 该论文的核心是提出一个创新的、有状态、能感知中断的多智能体LLM规划框架（ALAS）。它通过引入独立的验证器、版本化日志和局部化修复协议，显著提升了多智能体系统的鲁棒性和效率。这直接对应了你研究课题中的“多智能体”方向，并深入探讨了“规划”和“自我修正”这两个关键子方向。论文的贡献是方法论层面的，而非应用层面，因此是关于“LLM智能体及其演化”研究的前沿和高价值论文。 **核心依据**: 论文的核心贡献是**构建和改进一个多智能体LLM规划框架（ALAS）**，旨在解决现有智能体系统在规划、验证和修复方面的根本性挑战。这完全符合你“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标。"
    },
    {
        "index": "#8",
        "title": "Scaling Multi-Agent Environment Co-Design with Diffusion Models",
        "link": "/arxiv/2511.03100",
        "arxiv_id": "2511.03100",
        "authors": "Hao Xiang Li, Michael Amir, Amanda Prorok",
        "summary": "The agent-environment co-design paradigm jointly optimises agent policies and environment configurations in search of improved system performance. With application domains ranging from warehouse logistics to windfarm management, co-design promises to fundamentally change how we deploy multi-agent systems. However, current co-design methods struggle to scale. They collapse under high-dimensional environment design spaces and suffer from sample inefficiency when addressing moving targets inherent to joint optimisation. We address these challenges by developing Diffusion Co-Design (DiCoDe), a scalable and sample-efficient co-design framework pushing co-design towards practically relevant settings. DiCoDe incorporates two core innovations. First, we introduce Projected Universal Guidance (PUG), a sampling technique that enables DiCoDe to explore a distribution of reward-maximising environments while satisfying hard constraints such as spatial separation between obstacles. Second, we devise a critic distillation mechanism to share knowledge from the reinforcement learning critic, ensuring that the guided diffusion model adapts to evolving agent policies using a dense and up-to-date learning signal. Together, these improvements lead to superior environment-policy pairs when validated on challenging multi-agent environment co-design benchmarks including warehouse automation, multi-agent pathfinding and wind farm optimisation. Our method consistently exceeds the state-of-the-art, achieving, for example, 39% higher rewards in the warehouse setting with 66% fewer simulation samples. This sets a new standard in agent-environment co-design, and is a stepping stone towards reaping the rewards of co-design in real world domains.",
        "subjects": "Machine Learning, Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-05",
        "category": "cs.MA",
        "crawl_time": "2025-11-06T11:00:07.607414",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **核心判断 (第一步):** - **保留**。这篇论文的本质不是将现有智能体框架应用到一个新领域，而是提出了一种全新的方法论框架——**Diffusion Co-Design (DiCoDe)**。这个框架的核心是**“智能体-环境协同设计”**，即同时优化智能体策略和其所处的环境配置。这是一种构建和改进多智能体系统（Multi-Agent Systems）的元级别方法论，完全符合你“构建、改进或演化LLM智能体”的核心目标。 2.  **正面指标 (第二步):** - 论文明确属于 **`Multi-Agent Systems (MAS)`** 范畴，并在多个多智能体基准（如仓库自动化、多智能体路径规划）上进行了验证。 - 论文的核心机制涉及一个**迭代和适应的过程**。摘要中提到，其“critic distillation机制确保了引导扩散模型能够适应**演化的智能体策略**”。这直接命中了你的“演化”关注点，特别是**`Iterative Improvement`**和**`Evolutionary`**的概念。虽然这不是智能体“自我”演化，而是系统（智能体+环境）的共同演化，但这正是“LLM智能体及其演化”这一宏大课题下的一个重要前沿方向。 3.  **排除标准 (第三步):** - 论文的主要贡献不涉及安全、对齐或可解释性。 - 论文虽然使用了Diffusion Models，但它是作为生成和优化环境配置的工具，而不是研究的核心（核心是协同设计框架），因此不违反多模态排除规则。 4.  **特殊和模糊情况 (第四步):** - 这篇论文完美地诠释了“自我演化的应用”这一规则的例外情况。尽管它应用在仓库、风力发电场等具体领域，但其**核心贡献是提出了一种新的“协同演化”机制**。因此，它应该被保留。 **总结:** 该论文的核心贡献是提出了一种名为DiCoDe的、可扩展的多智能体与环境协同设计框架。它直接命中了你研究焦点中的**“多智能体”**方向，并深刻探讨了系统层面的**“演化”**机制（智能体与环境的共同演化）。它不是简单的应用型论文，而是方法论创新，因此是关于“LLM智能体及其演化”研究课题下的一篇高质量前沿论文，应当保留。"
    },
    {
        "index": "#9",
        "title": "AI Agents with Decentralized Identifiers and Verifiable Credentials",
        "link": "/arxiv/2511.02841",
        "arxiv_id": "2511.02841",
        "authors": "Sandro Rodriguez Garzon, Awid Vaziry, Enis Mert Kuzu, Dennis Enrique Gehrmann, Buse Varkan, Alexander Gaballa, Axel Küpper",
        "summary": "LLM-based AI agents still lack the technical means to automatically build nuanced and differentiated trust in other agents at the beginning of an agent-to-agent dialogue. But autonomous and interoperable trust establishing becomes a fundamental prerequisite once agents start to operate beyond isolated environments and engage in dialogues across individual or organizational boundaries. A promising way to fill this gap in Agentic AI is to equip agents with long-lived digital identities and introduce tamper-proof and flexible identity-bound attestations of agents, provisioned by commonly trusted third parties and designed for cross-domain verifiability. This article presents a conceptual framework and a prototypical multi-agent system, where each agent is endowed with a self-sovereign digital identity. It combines a unique and ledger-anchored Decentralized Identifier (DID) of an agent with a set of third-party issued Verifiable Credentials (VCs). This enables agents at the start of a dialog to prove ownership of their self-controlled DIDs for authentication purposes and to establish various cross-domain trust relationships through the spontaneous exchange of their self-hosted DID-bound VCs. A comprehensive evaluation of the prototypical implementation demonstrates technical feasibility but also reveals limitations once an agent's LLM is in sole charge to control the respective security procedures.",
        "subjects": "Cryptography and Security, Multiagent Systems",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-11-06T11:00:07.607706",
        "filter_reason": "这篇论文符合你的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献并非将LLM智能体作为工具应用于某个特定领域，而是提出了一个**新的概念框架和原型系统**，旨在解决LLM智能体在多智能体环境下的一个根本性问题：身份认证与信任建立。 - 这直接属于“构建、改进LLM智能体”的范畴，特别是针对**多智能体系统**的架构和能力改进。它不是关于基础设施优化，而是关于智能体交互机制的顶层设计。 2.  **第二步：正面指标——高度相关** - 论文明确包含了你的核心关注点：`Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems (MAS)`。 - 其研究内容直接触及多智能体交互的基石：`Communication`（通信）和`Collaboration`（协作）的前提——信任。虽然摘要中没有直接出现“Collaboration”一词，但建立跨域信任关系是实现有效协作的必要条件。 3.  **第三步：排除标准——不适用** - **关于安全与对齐**：这是最需要辨析的一点。虽然论文使用了`Decentralized Identifiers (DID)`、`Verifiable Credentials (VC)`、`authentication`、`security procedures`等与安全强相关的术语，但其**主要贡献并非安全技术本身**。论文的目标是提出一种**赋能智能体**的方法，使其能够在开放环境中自主建立信任。这里的“安全”是作为实现“自主信任”这一Agentic能力的**手段**，而非研究的最终目的。因此，它不属于被排除的“主要贡献是关于安全与对齐”的论文。它是一篇关于智能体架构的论文，恰好利用了安全工具。 4.  **第四步：处理特殊和模糊情况——不适用** - 论文不涉及推理/规划或自我演化的特殊情况。 **最终决策**: 该论文的核心是提出一个**多智能体框架**，通过为智能体赋予可验证的数字身份，解决了它们在跨域交互时的信任建立问题。这直接对应了你研究焦点中的**“多智能体”**方向，特别是智能体间的通信与协作机制。它不是一篇应用论文，也不是一篇安全论文，而是一篇关于如何**构建和改进多智能体系统**的方法论论文，完全符合你的筛选要求。"
    },
    {
        "index": "#3",
        "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning",
        "link": "/arxiv/2511.03724",
        "arxiv_id": "2511.03724",
        "authors": "Richard Dewey, Janos Botyanszki, Ciamac C. Moallemi, Andrew T. Zheng",
        "summary": "AI researchers have long focused on poker-like games as a testbed for environments characterized by multi-player dynamics, imperfect information, and reasoning under uncertainty. While recent breakthroughs have matched elite human play at no-limit Texas hold'em, the multi-player dynamics are subdued: most hands converge quickly with only two players engaged through multiple rounds of bidding. In this paper, we present Solly, the first AI agent to achieve elite human play in reduced-format Liar's Poker, a game characterized by extensive multi-player engagement. We trained Solly using self-play with a model-free, actor-critic, deep reinforcement learning algorithm. Solly played at an elite human level as measured by win rate (won over 50% of hands) and equity (money won) in heads-up and multi-player Liar's Poker. Solly also outperformed large language models (LLMs), including those with reasoning abilities, on the same metrics. Solly developed novel bidding strategies, randomized play effectively, and was not easily exploitable by world-class human players.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-05",
        "category": "cs.MA",
        "crawl_time": "2025-11-06T11:00:07.606044",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的筛选标准高度契合。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心是构建一个名为“Solly”的AI智能体，并详细阐述了其训练方法。该方法论的核心是“self-play with a model-free, actor-critic, deep reinforcement learning algorithm”。这完全符合您筛选标准中的“构建LLM智能体（Agentic LLM）、多智能体系统或自我演化的方法论或新框架”。它不是将已有框架简单应用，而是提出并实现了一个在特定复杂环境中达到顶尖水平的智能体及其演化训练机制。因此，根据第一步的核心判断，应予以保留。 2.  **第二步：正面指标——高度相关** 论文包含了多个您关注的核心正面指标： *   **核心范式**: 论文明确提出了一个“AI agent”，并且其研究环境是“multi-player dynamics”，直接命中了`Agentic AI`和`Multi-Agent Systems (MAS)`。 *   **演化机制**: 论文的训练核心是“self-play”（自我博弈），这是一种典型的`Self-Improvement`和`Iterative Improvement`机制，属于`Self-Evolving`的范畴。智能体通过与自己对战不断迭代，从而演化出高级策略。 *   **多智能体**: 论文的研究重点是“extensive multi-player engagement”，这直接关联到多智能体间的`博弈`和`Communication`（通过出价进行间接沟通）。 3.  **第三步：排除标准——未触发** 论文的主要贡献是智能体的性能和策略，而非安全性、可解释性或对齐问题。同时，研究内容不涉及视觉或多模态。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文中的智能体在游戏中需要进行复杂的推理和规划，但这是在智能体框架下实现的，其贡献在于整个智能体系统，而非提出一种新的通用推理方法。这符合“保留”的条件。 *   **自我演化的应用**: 这篇论文的核心贡献之一就是提出并验证了一种“自我演化”机制（self-play with RL），即使它应用在“Liar's Poker”这个特定领域，根据您的规则（“如果论文的核心是提出一种新的‘自我演化’机制...也应该保留”），也必须保留。 **最终决策**: 这篇论文的核心贡献在于**构建了一个多智能体系统，并使用一种自我演化机制（self-play强化学习）使其掌握了复杂的博弈策略**。这精准地命中了您研究焦点的“多智能体”和“自我演化”两个方向。它不是对现有工具的应用，而是对智能体构建和演化方法论的探索，是典型的Agentic AI前沿研究。因此，最终判断为 **True**。"
    },
    {
        "index": "#11",
        "title": "SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties",
        "link": "/arxiv/2511.03542",
        "arxiv_id": "2511.03542",
        "authors": "Roberta Di Marino, Giovanni Dioguardi, Antonio Romano, Giuseppe Riccio, Mariano Barone, Marco Postiglione, Flora Amato, Vincenzo Moscato",
        "summary": "Medical question answering systems face deployment challenges including hallucinations, bias, computational demands, privacy concerns, and the need for specialized expertise across diverse domains. Here, we present SOLVE-Med, a multi-agent architecture combining domain-specialized small language models for complex medical queries. The system employs a Router Agent for dynamic specialist selection, ten specialized models (1B parameters each) fine-tuned on specific medical domains, and an Orchestrator Agent that synthesizes responses. Evaluated on Italian medical forum data across ten specialties, SOLVE-Med achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697, outperforming standalone models up to 14B parameters while enabling local deployment. Our code is publicly available on GitHub: https://github.com/PRAISELab-PicusLab/SOLVE-Med.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-11-05",
        "category": "cs.CL",
        "crawl_time": "2025-11-06T11:00:08.264750",
        "filter_reason": "这篇论文符合筛选要求，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文的核心贡献是什么？** 论文的核心贡献是提出了一种名为 SOLVE-Med 的**多智能体架构**。它不是简单地将一个已有的智能体框架应用到医疗领域，而是设计了一个包含 `Router Agent`（路由智能体）和 `Orchestrator Agent`（编排智能体）的新颖协作框架，来动态地选择和整合多个领域专家模型。 - **是否符合保留标准？** 符合。这篇论文的本质是关于**构建和改进多智能体系统**的方法论。它定义了智能体的角色、交互方式和整体工作流程，这完全属于“构建LLM智能体”的范畴。它不是“非演化型应用”，因为其核心创新点在于智能体架构本身，而非其在医疗领域的应用结果。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。 - **多智能体**: 论文详细描述了智能体间的 `Collaboration`（协作）和 `Communication`（通信）机制。`Router Agent` 负责决策和分发任务，`Orchestrator Agent` 负责整合信息，这体现了智能体社会中的分工与合作。 3.  **第三步：排除标准** - **安全与对齐**: 论文摘要中提到了 \"hallucinations\"（幻觉）和 \"bias\"（偏见），但它们是作为该系统旨在解决的**挑战**被提出的，而不是论文的**核心贡献**。论文的核心是提出架构，而不是提出一种新的对齐或安全方法。因此，不触发排除标准。 - **多模态与视觉**: 论文未涉及视觉或多模态内容，不相关。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: `Router Agent` 的“动态专家选择”功能是一种高级的**规划**和决策行为。它不是在提升LLM本身的基础推理能力，而是在构建一个能够进行任务分解和分发的智能体框架。这符合“保留”标准。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献在于设计了一个新颖的多智能体协作框架（SOLVE-Med），以解决复杂任务。它清晰地定义了不同智能体的角色和协作机制，完全符合研究课题中“多智能体”这一核心方向。尽管其应用场景是医疗领域，但其方法论贡献是普适的，属于Agentic AI的前沿研究。因此，应予以保留。"
    },
    {
        "index": "#22",
        "title": "EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation",
        "link": "/arxiv/2511.03370",
        "arxiv_id": "2511.03370",
        "authors": "Yunbo Long, Yuhan Liu, Alexandra Brintrup",
        "summary": "The deployment of large language models (LLMs) in automated negotiation has set a high performance benchmark, but their computational cost and data privacy requirements render them unsuitable for many privacy-sensitive, on-device applications such as mobile assistants, embodied AI agents or private client interactions. While small language models (SLMs) offer a practical alternative, they suffer from a significant performance gap compared to LLMs in playing emotionally charged complex personas, especially for credit negotiation. This paper introduces EQ-Negotiator, a novel framework that bridges this capability gap using emotional personas. Its core is a reasoning system that integrates game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional states online, without pre-training. This allows EQ-Negotiator to equip SLMs with the strategic intelligence to counter manipulation while de-escalating conflict and upholding ethical standards. Through extensive agent-to-agent simulations across diverse credit negotiation scenarios, including adversarial debtor strategies like cheating, threatening, and playing the victim, we show that a 7B parameter language model with EQ-Negotiator achieves better debt recovery and negotiation efficiency than baseline LLMs more than 10 times its size. This work advances persona modeling from descriptive character profiles to dynamic emotional architectures that operate within privacy constraints. Besides, this paper establishes that strategic emotional intelligence, not raw model scale, is the critical factor for success in automated negotiation, paving the way for effective, ethical, and privacy-preserving AI negotiators that can operate on the edge.",
        "subjects": "Computation and Language",
        "date": "2025-11-05",
        "category": "cs.CL",
        "crawl_time": "2025-11-06T11:00:08.275575",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体，而非简单的应用。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质是提出一个名为 **EQ-Negotiator** 的新颖框架。它的核心贡献不是“如何用LLM解决信贷谈判问题”，而是“**如何构建一个具备动态情感建模和战略推理能力的智能体框架**”。该框架通过集成博弈论和隐马尔可夫模型（HMM），使小语言模型（SLM）能够在线学习和适应对手的情感状态，从而获得超越其模型规模的智能体能力。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是将已有智能体作为工具应用，而是创造了一个新的智能体架构。 **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **核心范式**: 论文的核心是 `Agentic AI` 和 `LLM-based Agents`。其评估方式是 `agent-to-agent simulations`，这直接关联到 `Multi-Agent Systems (MAS)` 的研究范式。 *   **智能体能力**: 论文的核心机制是一个 `reasoning system`，涉及 `Planning`（博弈论部分）和一种形式的 `Self-Correction`（根据HMM追踪到的情感状态动态调整策略）。 *   **多智能体**: `Negotiation` 是多智能体交互的经典场景，论文通过智能体间的对抗性模拟来验证框架，这属于多智能体研究的范畴。 *   **演化机制**: 论文中的HMM能够“在线学习和追踪债务人情感状态”，这是一种在单次交互中基于环境反馈进行迭代和适应的机制，符合“通过环境反馈进行自我完善和迭代”的 `Self-Evolving` 精神。 **第三步：排除标准——未命中** *   **安全与对齐**: 论文虽然提到了“upholding ethical standards”，但这只是其框架设计的一个考量或特性，而非论文的核心研究贡献。论文的焦点是智能体的能力和架构，而不是安全或对齐技术本身。 *   **多模态与视觉**: 论文完全不涉及视觉或多模态内容。 **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文的推理系统（博弈论+HMM）是智能体框架的一部分，用于在复杂交互中进行战略规划，完全符合“保留”条件。它不是在改进LLM的基础推理能力，而是在构建一个更高层次的智能体推理循环。 *   **自我演化的应用**: 这篇论文是“自我演化应用”的一个绝佳例外。虽然应用在“信贷谈判”这一特定领域，但其核心贡献是提出了一种新的“动态情感架构”和“在线学习”机制，这正是您所关注的“自我演化”机制的一种体现。因此，根据规则，应当保留。 **最终决策** 综合以上分析，这篇论文的核心是构建一个创新的智能体框架（EQ-Negotiator），该框架赋予了语言模型动态情感建模和在线适应的能力，并通过多智能体模拟进行了验证。它直接触及了您研究焦点中的“多智能体”和“自我演化”方向，其贡献在于智能体架构本身的演进，而非其在特定领域的应用。因此，这篇论文与您的研究课题高度相关，应当被保留。"
    },
    {
        "index": "#2",
        "title": "AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and Sample-Efficient Analog Circuit Sizing",
        "link": "/arxiv/2511.03697",
        "arxiv_id": "2511.03697",
        "authors": "Mohsen Ahmadzadeh, Kaichang Chen, Georges Gielen",
        "summary": "Analog/mixed-signal circuits are key for interfacing electronics with the physical world. Their design, however, remains a largely handcrafted process, resulting in long and error-prone design cycles. While the recent rise of AI-based reinforcement learning and generative AI has created new techniques to automate this task, the need for many time-consuming simulations is a critical bottleneck hindering the overall efficiency. Furthermore, the lack of explainability of the resulting design solutions hampers widespread adoption of the tools. To address these issues, a novel agentic AI framework for sample-efficient and explainable analog circuit sizing is presented. It employs a multi-agent workflow where specialized Large Language Model (LLM)-based agents collaborate to interpret the circuit topology, to understand the design goals, and to iteratively refine the circuit's design parameters towards the target goals with human-interpretable reasoning. The adaptive simulation strategy creates an intelligent control that yields a high sample efficiency. The AnaFlow framework is demonstrated for two circuits of varying complexity and is able to complete the sizing task fully automatically, differently from pure Bayesian optimization and reinforcement learning approaches. The system learns from its optimization history to avoid past mistakes and to accelerate convergence. The inherent explainability makes this a powerful tool for analog design space exploration and a new paradigm in analog EDA, where AI agents serve as transparent design assistants.",
        "subjects": "Machine Learning, Artificial Intelligence, Hardware Architecture",
        "date": "2025-11-05",
        "category": "cs.LG",
        "crawl_time": "2025-11-06T11:00:08.611779",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接对应了你的研究焦点。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于电路设计领域，而是提出了一个**新颖的“智能体AI框架”**。摘要明确指出这是一个“novel agentic AI framework”，并且详细描述了其工作机制：一个由专门的LLM智能体协作的“多智能体工作流”。这完全符合“构建、改进或演化LLM智能体”的核心目标。它不是非演化型应用，因为其框架本身就包含了迭代和学习的机制。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了大量与你研究焦点直接相关的正面指标： *   **核心范式**: `Agentic AI`, `LLM-based Agents`, `Multi-Agent Systems (MAS)`。 *   **多智能体**: `Collaboration`（“specialized...agents collaborate”）。 *   **演化机制**: `Self-Improvement`（“iteratively refine”），`Iterative Improvement`（“learns from its optimization history to avoid past mistakes and to accelerate convergence”）。这表明智能体具备从经验中学习和自我完善的能力，是典型的自我演化特征。 *   **智能体能力**: `Planning`（隐含在“iteratively refine...towards the target goals”中），`Tool Use`（隐含在“adaptive simulation strategy”中，仿真作为一种工具）。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 论文提到了“Explainable”（可解释性），但这并非论文的主要贡献。它的主要贡献是那个智能体框架，而可解释性是该框架带来的一个**特性或优势**（“with human-interpretable reasoning”），而不是研究的核心主题。因此，它不属于被排除的“主要关注可解释性”的论文。 *   **多模态与视觉**: 论文内容完全不涉及视觉或多模态模型。 4.  **第四步：处理特殊和模糊情况——适用例外规则** *   **自我演化的应用**: 这篇论文是“自我演化应用”的一个完美范例。虽然它被应用在“模拟电路尺寸调整”这个特定领域，但其核心是提出了一种**新的自我演化机制**（多智能体协作、从历史中学习、迭代优化）。根据你的筛选规则，这种情况应该被保留。 **核心依据总结**: 该论文的本质是提出了一种新的**多智能体协作框架**，该框架能够让智能体通过**迭代优化和从历史经验中学习**来完成复杂任务。这直接命中了你研究范围中的**“多智能体”**和**“自我演化”**两个核心方向。尽管其应用场景是电路设计，但其方法论上的创新——即如何构建、协作和演化LLM智能体——正是你课题所关注的前沿。因此，这篇论文是高度相关且应该被保留的。"
    },
    {
        "index": "#15",
        "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework",
        "link": "/arxiv/2511.03023",
        "arxiv_id": "2511.03023",
        "authors": "Sina Montazeri, Yunhe Feng, Kewei Sha",
        "summary": "Open data repositories hold potential for evidence-based decision-making, yet are inaccessible to non-experts lacking expertise in dataset discovery, schema mapping, and statistical analysis. Large language models show promise for individual tasks, but end-to-end analytical workflows expose fundamental limitations: attention dilutes across growing contexts, specialized reasoning patterns interfere, and errors propagate undetected. We present PublicAgent, a multi-agent framework that addresses these limitations through decomposition into specialized agents for intent clarification, dataset discovery, analysis, and reporting. This architecture maintains focused attention within agent contexts and enables validation at each stage. Evaluation across five models and 50 queries derives five design principles for multi-agent LLM systems. First, specialization provides value independent of model strength--even the strongest model shows 97.5% agent win rates, with benefits orthogonal to model scale. Second, agents divide into universal (discovery, analysis) and conditional (report, intent) categories. Universal agents show consistent effectiveness (std dev 12.4%) while conditional agents vary by model (std dev 20.5%). Third, agents mitigate distinct failure modes--removing discovery or analysis causes catastrophic failures (243-280 instances), while removing report or intent causes quality degradation. Fourth, architectural benefits persist across task complexity with stable win rates (86-92% analysis, 84-94% discovery), indicating workflow management value rather than reasoning enhancement. Fifth, wide variance in agent effectiveness across models (42-96% for analysis) requires model-aware architecture design. These principles guide when and why specialization is necessary for complex analytical workflows while enabling broader access to public data through natural language interfaces.",
        "subjects": "Artificial Intelligence",
        "date": "2025-11-04",
        "category": "cs.AI",
        "crawl_time": "2025-11-06T11:00:08.725958",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非简单地将LLM应用于“开放数据分析”这一特定领域，而是提出了一个名为 **PublicAgent 的多智能体框架**，并从中提炼出了 **五项关于多智能体LLM系统的设计原则**。这完全符合“构建、改进或演化 LLM智能体”的核心目标。它不是在“用”智能体，而是在“研究如何构建”智能体系统，其贡献是方法论层面的，具有普适性指导意义。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了大量与你研究焦点直接相关的正面指标： *   **核心范式**: `Multi-Agent Systems (MAS)`，`LLM-based Agents`。 *   **多智能体**: 论文的核心就是研究多个专门化智能体（意图澄清、数据集发现、分析、报告）如何协同工作，这直接对应了“智能体间的协作”。 *   **智能体能力**: 整个框架的设计就是为了解决复杂任务中的注意力分散和错误传播问题，这本质上是一种高级的 **`Planning`**（工作流规划）和任务分解。 3.  **第三步：排除标准——未触发** 论文的研究焦点是智能体的架构设计和性能分析，没有涉及安全、对齐、可解释性或视觉等多模态内容。因此，所有排除标准均不适用。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 该论文是关于智能体如何通过分工协作来完成一个复杂的端到端分析工作流，这属于典型的 **Agentic 框架下的规划与执行**，而非提升LLM本身的基础推理能力。因此，符合保留条件。 *   **自我演化的应用**: 虽然这篇论文不直接关于“自我演化”，但它完美地诠释了“应用”与“核心贡献”的区别。它的应用场景是数据分析，但其核心贡献是关于多智能体系统设计的通用原则，这正是你所寻找的。 **总结**: 这篇论文的核心是提出并分析了一个多智能体框架，旨在解决复杂任务中的固有挑战，并从中提炼出具有指导意义的设计原则。这直接命中了你研究课题中的 **“多智能体”** 方向，并且其贡献在于 **“构建”和“改进”** 智能体系统本身，而非简单的应用。因此，这篇论文是高度相关且有价值的前沿研究，应被筛选出来。"
    },
    {
        "index": "#19",
        "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents",
        "link": "/arxiv/2511.03690",
        "arxiv_id": "2511.03690",
        "authors": "Xingyao Wang, Simon Rosenberg, Juan Michelini, Calvin Smith, Hoang Tran, Engel Nyst, Rohit Malhotra, Xuhui Zhou, Valerie Chen, Robert Brennan, Graham Neubig",
        "summary": "Agents are now used widely in the process of software development, but building production-ready software engineering agents is a complex task. Deploying software agents effectively requires flexibility in implementation and experimentation, reliable and secure execution, and interfaces for users to interact with agents. In this paper, we present the OpenHands Software Agent SDK, a toolkit for implementing software development agents that satisfy these desiderata. This toolkit is a complete architectural redesign of the agent components of the popular OpenHands framework for software development agents, which has 64k+ GitHub stars. To achieve flexibility, we design a simple interface for implementing agents that requires only a few lines of code in the default case, but is easily extensible to more complex, full-featured agents with features such as custom tools, memory management, and more. For security and reliability, it delivers seamless local-to-remote execution portability, integrated REST/WebSocket services. For interaction with human users, it can connect directly to a variety of interfaces, such as visual workspaces (VS Code, VNC, browser), command-line interfaces, and APIs. Compared with existing SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and built-in security analysis. Empirical results on SWE-Bench Verified and GAIA benchmarks demonstrate strong performance. Put together, these elements allow the OpenHands Software Agent SDK to provide a practical foundation for prototyping, unlocking new classes of custom applications, and reliably deploying agents at scale.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-05",
        "category": "cs.AI",
        "crawl_time": "2025-11-06T11:00:08.727874",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出了一个名为 \"OpenHands Software Agent SDK\" 的工具包。根据摘要，这个SDK是一个“用于实现软件开发智能体的工具包”，其目标是提供一个“可组合和可扩展的基础”。这直接命中了你筛选标准中的“构建、改进或演化 LLM智能体的论文”。它不是将智能体作为工具去解决一个特定领域的问题，而是提供了一个构建智能体的**方法论和框架**，这正是你研究的核心。虽然它涉及了部署和执行等基础设施元素，但这些是作为支撑智能体运行的框架特性而存在的，论文的本质是关于智能体框架的设计与实现，而非纯粹的基础设施研究。 2.  **第二步：正面指标 (高度相关)** 论文摘要中明确包含了多个你关注的核心范式和能力： *   **核心范式**: 论文通篇都在讨论 `LLM-based Agents` 和 `Agentic AI`。 *   **智能体能力**: 摘要明确指出该框架支持 `custom tools` (工具使用) 和 `memory management` (记忆)，这些都是单智能体研究的关键子方向。一个用于“软件开发”的智能体，其内在必然涉及复杂的`规划`能力，该框架的设计目标就是为了支持这类复杂任务。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文提到了 \"built-in security analysis\"，但这只是SDK提供的一个功能特性，并非论文的主要研究贡献。论文的核心是SDK这个智能体构建框架本身，而不是安全分析技术。 *   **多模态与视觉**: 论文未涉及视觉或多模态内容。 4.  **第四步：特殊和模糊情况 (不适用)** 该论文不属于推理/规划或自我演化应用的模糊情况，它是一个纯粹的智能体构建框架论文。 **总结**: 这篇论文的核心是提供一个**构建和部署LLM智能体的基础框架（SDK）**。它通过提供模块化、可扩展的接口，降低了构建具备工具使用、记忆等能力的生产级智能体的门槛。这完全符合你“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标，并且直接关联到你的“单智能体”研究方向。因此，这篇论文应该被保留。"
    },
    {
        "index": "#66",
        "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring",
        "link": "/arxiv/2511.03153",
        "arxiv_id": "2511.03153",
        "authors": "Khouloud Oueslati, Maxime Lamothe, Foutse Khomh",
        "summary": "Large Language Models (LLMs) have substantially influenced various software engineering tasks. Indeed, in the case of software refactoring, traditional LLMs have shown the ability to reduce development time and enhance code quality. However, these LLMs often rely on static, detailed instructions for specific tasks. In contrast, LLM-based agents can dynamically adapt to evolving contexts and autonomously make decisions by interacting with software tools and executing workflows. In this paper, we explore the potential of LLM-based agents in supporting refactoring activities. Specifically, we introduce RefAgent, a multi-agent LLM-based framework for end-to-end software refactoring. RefAgent consists of specialized agents responsible for planning, executing, testing, and iteratively refining refactorings using self-reflection and tool-calling capabilities. We evaluate RefAgent on eight open-source Java projects, comparing its effectiveness against a single-agent approach, a search-based refactoring tool, and historical developer refactorings. Our assessment focuses on: (1) the impact of generated refactorings on software quality, (2) the ability to identify refactoring opportunities, and (3) the contribution of each LLM agent through an ablation study. Our results show that RefAgent achieves a median unit test pass rate of 90%, reduces code smells by a median of 52.5%, and improves key quality attributes (e.g., reusability) by a median of 8.6%. Additionally, it closely aligns with developer refactorings and the search-based tool in identifying refactoring opportunities, attaining a median F1-score of 79.15% and 72.7%, respectively. Compared to single-agent approaches, RefAgent improves the median unit test pass rate by 64.7% and the median compilation success rate by 40.1%. These findings highlight the promise of multi-agent architectures in advancing automated software refactoring.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-05",
        "category": "cs.AI",
        "crawl_time": "2025-11-06T11:00:08.743760",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的核心贡献是提出并构建了一个名为 `RefAgent` 的**多智能体LLM框架**。摘要明确指出，他们“introduce RefAgent, a multi-agent LLM-based framework for end-to-end software refactoring”。论文的本质是关于**如何构建一个多智能体系统**来解决复杂任务，而不是简单地将现有LLM或智能体框架作为工具应用到软件工程领域。因此，它通过了第一步的核心判断，属于“保留”类别。 **第二步：正面指标——高度匹配** 论文包含了大量你的核心关注点，相关性极强： - **核心范式**: 论文标题和摘要中直接出现了 `Multi-agent LLM-based Framework`，完美命中 `Multi-Agent Systems (MAS)` 和 `LLM-based Agents`。 - **智能体能力**: 摘要中明确指出，该框架由“specialized agents responsible for **planning**, executing, testing, and iteratively refining refactorings using **self-reflection** and **tool-calling** capabilities”。这直接命中了 `Planning`、`Tool Use`、`Self-Reflection` 等关键能力。 - **多智能体**: 论文的核心就是多智能体架构，并且通过与“single-agent approach”进行对比，突出了多智能体协作的优势，这直接关联到 `Collaboration`。 - **演化机制**: “iteratively refining refactorings using self-reflection” 描述了一个通过自我反思进行迭代改进的过程，这属于 `Self-Improvement` 和 `Iterative Improvement` 的范畴，与“自我演化”方向紧密相关。 **第三步：排除标准——不适用** 论文的研究焦点是智能体框架的设计、构建和评估，不涉及安全、对齐、可解释性或多模态视觉等内容。因此，第三步的排除标准不适用。 **第四步：处理特殊和模糊情况——符合核心规则** - **推理/规划**: 论文中的规划是**智能体框架内的规划**（agents responsible for planning），用于协调多步工作流，而不是提升LLM本身的基础推理能力。这完全符合“保留”的条件。 - **自我演化的应用**: 虽然论文的应用领域是“软件重构”，但其核心贡献是提出了一种**新的多智能体协作与自我反思机制**。这符合第四步规则2的“例外”情况：即使应用在特定领域，但核心是提出新的智能体机制，因此应该保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的多智能体LLM框架（`RefAgent`），该框架集成了规划、工具使用、自我反思和迭代改进等关键能力。它直接对应了你研究课题中的“多智能体”和“自我演化”两个核心方向。尽管其应用场景是软件重构，但论文的重点在于智能体架构本身，而非应用结果。因此，这篇论文是高度相关的前沿研究，**必须保留**。"
    },
    {
        "index": "#105",
        "title": "Mathematical exploration and discovery at scale",
        "link": "/arxiv/2511.02864",
        "arxiv_id": "2511.02864",
        "authors": "Bogdan Georgiev, Javier Gómez-Serrano, Terence Tao, Adam Zsolt Wagner",
        "summary": "AlphaEvolve is a generic evolutionary coding agent that combines the generative capabilities of LLMs with automated evaluation in an iterative evolutionary framework that proposes, tests, and refines algorithmic solutions to challenging scientific and practical problems. In this paper we showcase AlphaEvolve as a tool for autonomously discovering novel mathematical constructions and advancing our understanding of long-standing open problems. To demonstrate its breadth, we considered a list of 67 problems spanning mathematical analysis, combinatorics, geometry, and number theory. The system rediscovered the best known solutions in most of the cases and discovered improved solutions in several. In some instances, AlphaEvolve is also able to generalize results for a finite number of input values into a formula valid for all input values. Furthermore, we are able to combine this methodology with Deep Think and AlphaProof in a broader framework where the additional proof-assistants and reasoning systems provide automated proof generation and further mathematical insights. These results demonstrate that large language model-guided evolutionary search can autonomously discover mathematical constructions that complement human intuition, at times matching or even improving the best known results, highlighting the potential for significant new ways of interaction between mathematicians and AI systems. We present AlphaEvolve as a powerful new tool for mathematical discovery, capable of exploring vast search spaces to solve complex optimization problems at scale, often with significantly reduced requirements on preparation and computation time.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Classical Analysis and ODEs, Combinatorics, Metric Geometry",
        "date": "2025-11-03",
        "category": "cs.AI",
        "crawl_time": "2025-11-06T11:00:08.757455",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建了一个名为 \"AlphaEvolve\" 的 \"generic evolutionary coding agent\"（通用演化编码智能体）。它不是一个简单的应用，而是提出了一个全新的方法论和框架。这个框架的核心是一个 \"iterative evolutionary framework\"（迭代演化框架），能够自主地 \"proposes, tests, and refines algorithmic solutions\"（提出、测试和提炼算法解决方案）。这完全符合你筛选标准中关于“构建、改进或演化 LLM智能体”以及“自我演化”的定义。因此，应直接进入保留流程。 2.  **正面指标 (第二步):** 论文摘要中包含了大量与你研究焦点高度相关的关键词和概念： *   **核心范式:** 明确提到了 `LLM-based Agents` (\"evolutionary coding agent\") 和 `Self-Evolving` (\"iterative evolutionary framework\", \"LLM-guided evolutionary search\")。 *   **演化机制:** 完美体现了 `Self-Improvement` / `Self-Refine` / `Iterative Improvement`，其核心循环就是“提出-测试-提炼”。 3.  **排除标准 (第三步):** 论文内容不涉及安全、对齐、可解释性或视觉等多模态问题，因此没有触发任何排除标准。 4.  **特殊和模糊情况处理 (第四步):** *   **自我演化的应用:** 这是最关键的一点。虽然论文将 AlphaEvolve 应用于数学领域，但根据你的筛选规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域...也应该保留。” 这篇论文正是如此。它的核心贡献是 AlphaEvolve 这个**自我演化的智能体框架**，而数学发现是用来**验证和展示**该框架能力的应用场景。因此，它属于应保留的例外情况，而不是一个简单的“非演化型应用”。 **结论:** 该论文的本质是提出了一种新颖的、基于LLM的自我演化智能体框架。其核心贡献在于智能体的构建和演化机制本身，而非其在数学领域的应用结果。这与你的研究目标“LLM智能体及其演化”，特别是“自我演化”方向，高度契合。因此，应判定为符合要求。"
    },
    {
        "index": "#113",
        "title": "Digital Transformation Chatbot (DTchatbot): Integrating Large Language Model-based Chatbot in Acquiring Digital Transformation Needs",
        "link": "/arxiv/2511.02842",
        "arxiv_id": "2511.02842",
        "authors": "Jiawei Zheng, Gokcen Yilmaz, Ji Han, Saeema Ahmed-Kristensen",
        "summary": "Many organisations pursue digital transformation to enhance operational efficiency, reduce manual efforts, and optimise processes by automation and digital tools. To achieve this, a comprehensive understanding of their unique needs is required. However, traditional methods, such as expert interviews, while effective, face several challenges, including scheduling conflicts, resource constraints, inconsistency, etc. To tackle these issues, we investigate the use of a Large Language Model (LLM)-powered chatbot to acquire organisations' digital transformation needs. Specifically, the chatbot integrates workflow-based instruction with LLM's planning and reasoning capabilities, enabling it to function as a virtual expert and conduct interviews. We detail the chatbot's features and its implementation. Our preliminary evaluation indicates that the chatbot performs as designed, effectively following predefined workflows and supporting user interactions with areas for improvement. We conclude by discussing the implications of employing chatbots to elicit user information, emphasizing their potential and limitations.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-11-06T11:00:08.759793",
        "filter_reason": "这篇论文符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于“数字化转型”这一领域，而是提出并详细实现了一个名为DTchatbot的**智能体框架**。摘要中明确指出，该聊天机器人“集成了基于工作流的指令与LLM的规划和推理能力”，这描述的是一个构建智能体的方法论，而不仅仅是应用。它定义了智能体如何通过结合外部工作流和内部推理来执行复杂任务（进行专家访谈），这属于构建LLM智能体的范畴。因此，它不属于“非演化型应用”的排除项。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (明确提及)。 - **智能体能力**: `Planning` 和 `Reasoning` (明确提及“LLM's planning and reasoning capabilities”)。这直接对应了您研究焦点中的“单智能体”方向，特别是规划能力。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐（Safety, Alignment）、多模态（Vision）等排除标准。其焦点在于智能体的功能设计与实现。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美符合“保留”条件。它不是在研究如何提升LLM本身的基础数学或逻辑能力，而是在研究**智能体如何利用LLM的规划和推理能力**，结合外部工作流，来完成一个多步骤、有目标的复杂任务（作为虚拟专家进行访谈）。这与ReAct等Agentic框架的思想一脉相承。 **最终决策**: 综合以上分析，尽管这篇论文的应用背景是“数字化转型需求获取”，但其**核心贡献在于构建了一个具备规划和推理能力的LLM智能体**。它详细阐述了该智能体的架构（工作流+LLM推理）和实现，这完全符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标，特别是“单智能体”方向下的“规划”子方向。因此，应判定为 **True**。"
    },
    {
        "index": "#107",
        "title": "SELF-REDRAFT: Eliciting Intrinsic Exploration-Exploitation Balance in Test-Time Scaling for Code Generation",
        "link": "/arxiv/2511.02854",
        "arxiv_id": "2511.02854",
        "authors": "Yixiang Chen, Tianshi Zheng, Shijue Huang, Zhitao He, Yi R. Fung",
        "summary": "Test-time scaling without interpreter feedback is essential for real-world code generation scenarios where test cases are not readily available. While existing paradigms often rely on either greedy exploitation (i.e., iterative refinement) or stochastic exploration (i.e., relying on sample-based voting or reranking mechanisms), the balance between these two dimensions remains underexplored. To investigate the LLM's intrinsic ability to balance exploitation and exploration, we introduce SELF-REDRAFT, a framework built upon Self-Refine that encourages the model to propose new drafts for solutions that are fundamentally flawed. Our results show that SELF-REDRAFT consistently achieves better performance than Self-Refine when converged under the same maximum number of iterations. Still, we observe that significant room for improvement remains, largely due to two core aspects of current self-redraft capabilities: constrained capacity for generating instructive feedback and fragile discriminative judgment. We also find that balancing strategies vary notably across different LLMs, reflecting distinct, model-specific behaviors. Overall, our study establishes a baseline for intrinsic exploration-exploitation balancing in test-time scaling and identifies feedback and discrimination as key areas with potential for future advances.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-10-31",
        "category": "cs.AI",
        "crawl_time": "2025-11-06T11:00:08.758038",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献精准地命中了您设定的“自我演化”和“单智能体”方向。 以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用于代码生成领域，而是提出了一种名为 **`SELF-REDRAFT`** 的**新框架**。这个框架的核心是改进LLM在测试时的行为模式，即如何通过内在机制来平衡“探索”与“利用”，从而实现更好的自我迭代和优化。这完全符合“构建、改进或演化 LLM智能体”的核心目标。它不是在解决一个特定的代码问题，而是在研究智能体如何更好地“思考”和“自我完善”。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Self-Evolving` (自我演化) 是本文最核心的主题。`SELF-REDRAFT` 框架本身就是一种自我演化的机制。 - **智能体能力**: 论文明确基于 `Self-Refine` 框架进行构建，并深入探讨了 `Self-Correction` (自我修正) 和 `Iterative Improvement` (迭代改进) 的能力。它研究的是智能体如何通过自我反思（识别“根本性缺陷”）来生成新的解决方案草稿，这属于高级的自我反思能力。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。它的焦点是方法论和智能体行为机制，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美范例。虽然论文的应用领域是“代码生成”，但其**核心贡献是提出了一种新的“自我演化”机制 (`SELF-REDRAFT`)**。根据您的规则，“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 因此，这篇论文应该被保留。 - **推理/规划**: 论文研究的不是LLM基础的数学或逻辑推理能力，而是智能体在复杂任务（生成高质量代码）中如何进行多步、迭代的规划和决策过程。它关注的是智能体的“元认知”策略（如何平衡探索与利用），这完全符合“保留”关于智能体推理/规划框架的论文的要求。 **总结**: 这篇论文的核心贡献是构建了一个名为 `SELF-REDRAFT` 的新框架，旨在通过内在机制让LLM智能体在测试时能够更好地平衡探索与利用，从而实现更有效的自我迭代和优化。这直接对应了您研究课题中的 **“自我演化”** 方向，并涉及 **“单智能体”** 的自我反思与修正能力。它并非简单的应用型论文，而是对Agentic AI核心机制的深入探索和创新，因此是您需要筛选的前沿论文。"
    }
]