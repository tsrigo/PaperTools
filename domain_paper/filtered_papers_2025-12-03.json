[
    {
        "index": "#2",
        "title": "AsymPuzl: An Asymmetric Puzzle for multi-agent cooperation",
        "link": "/arxiv/2512.03466",
        "arxiv_id": "2512.03466",
        "authors": "Xavier Cadet, Edward Koh, Peter Chin",
        "summary": "Large Language Model (LLM) agents are increasingly studied in multi-turn, multi-agent scenarios, yet most existing setups emphasize open-ended role-play rather than controlled evaluation. We introduce AsymPuzl, a minimal but expressive two-agent puzzle environment designed to isolate communication under information asymmetry. Each agent observes complementary but incomplete views of a symbolic puzzle and must exchange messages to solve it cooperatively. Using a diverse set of current-generation and open-source LLMs, we show that (i) strong models such as GPT-5 and Claude-4.0 reliably converge across puzzle sizes on the solution by sharing complete information in two turns, (ii) weaker models often ignore partner messages or over-correct their hypotheses, and (iii) feedback design is non-trivial: simple self-feedback improves success rates, while detailed joint feedback can hurt performance. These findings show that even in simple cooperative tasks, LLM communication strategies diverge and depend on the granularity of feedback signals. AsymPuzl thus provides a testbed for probing the limits of multi-turn cooperation and opens avenues for studying coordination mechanisms.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.MA",
        "crawl_time": "2025-12-04T11:00:07.611302",
        "filter_reason": "这篇论文完全符合我的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非将LLM智能体作为工具去解决某个特定领域（如生物、金融）的问题，而是**构建了一个全新的、受控的评估环境（AsymPuzl）**，专门用于研究和剖析多智能体协作中的核心问题——信息不对称下的通信。这属于“构建、改进LLM智能体”的方法论贡献，具体来说是构建了一个用于研究多智能体系统的测试平台。因此，它通过了第一步的核心判断。 2.  **第二步：正面指标——高度匹配** 论文包含大量我的核心关注点： *   **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 *   **多智能体**: 论文明确研究了 `Collaboration`（协作）、`Communication`（通信），并探讨了 `Coordination Mechanisms`（协调机制）。 *   **自我演化**: 论文探讨了 `Self-Correction`（自我修正）的一种形式——`self-feedback`（自我反馈），并分析了不同反馈机制对智能体性能的影响，这与智能体通过反馈进行自我完善的理念密切相关。 这些正面指标表明，论文的研究内容与我的“多智能体”和“自我演化”方向高度契合。 3.  **第三步：排除标准——不涉及** 论文的研究焦点是智能体的协作机制和通信策略，完全不涉及安全、对齐、可解释性或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 论文研究的“推理”是智能体在多轮交互中如何通过通信解决协作任务的策略性推理，而非提升LLM本身的基础数学或逻辑能力，因此符合保留条件。 **最终决策**: 这篇论文的核心贡献是提出了一种新的多智能体研究范式和测试环境，旨在深入探究LLM智能体在协作中的通信、反馈和协调机制。这直接服务于我“构建、改进或演化LLM智能体”的核心目标，特别是在“多智能体”这一关键方向上。它不仅提供了一个新的研究工具，其关于反馈机制的发现也为“自我演化”方向提供了有价值的见解。因此，这篇论文是高质量且高度相关的前沿研究，必须保留。"
    },
    {
        "index": "#7",
        "title": "Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks",
        "link": "/arxiv/2512.03560",
        "arxiv_id": "2512.03560",
        "authors": "Gianni Molinari, Fabio Ciravegna",
        "summary": "Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-12-03",
        "category": "cs.MA",
        "crawl_time": "2025-12-04T11:00:07.612677",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一种名为 RP-ReAct 的新型**多智能体架构**。它并非简单地将现有智能体框架应用于企业领域，而是针对现有单智能体架构的“轨迹不稳定性”和“上下文窗口消耗”等根本性问题，提出了一种全新的解决方案。其本质是**构建和改进LLM智能体**的方法论，因此符合保留标准。 2.  **第二步：正面指标——高度相关** 论文包含了您核心关注点的多个关键范式和能力： *   **核心范式**: 明确提出了 `Multi-Agent Systems (MAS)` 方法，包含一个 `Reasoner Planner Agent (RPA)` 和一个或多个 `Proxy-Execution Agent (PEA)`。 *   **智能体能力**: RPA 负责 `Planning`（规划）和 `Self-Reflection`（通过持续分析执行结果实现自我反思），PEA 负责 `Tool Use / Tool Augmentation`（工具使用），并采用了 `ReAct` 范式。 *   **多智能体**: 论文的核心就是关于智能体间的协作与分工，即 RPA（规划者）与 PEA（执行者）之间的协作。 3.  **第三步：排除标准——未触及** 论文的研究焦点是智能体的架构和性能，主要贡献在于提升其可靠性和效率。摘要中完全没有提及 `Safety`、`Alignment`、`Interpretability` 或 `Vision` 等排除标准中的关键词。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文提出的规划机制（由RPA执行）是智能体框架的核心组成部分，用于解决复杂任务的多步执行问题，完全符合“保留”的条件。它不是关于提升LLM本身的基础推理能力，而是关于智能体如何利用LLM进行规划和执行。 *   **自我演化的应用**: 此规则不直接适用，因为论文的核心是“多智能体”而非“自我演化”。但其RPA的“持续分析执行结果”机制带有自我反思和迭代的意味，与您的关注点方向一致。 **最终决策**: 该论文的核心贡献在于提出了一种创新的**多智能体协作框架（RP-ReAct）**，通过解耦规划与执行，解决了现有LLM智能体在复杂任务中的关键瓶颈。这直接对应了您研究焦点中的“多智能体”方向，并深度涉及了“单智能体”的规划、工具使用和自我反思等核心能力。因此，这篇论文是您研究课题“LLM智能体及其演化”的典型前沿文献，应予以保留。"
    },
    {
        "index": "#4",
        "title": "A Gossip-Enhanced Communication Substrate for Agentic AI: Toward Decentralized Coordination in Large-Scale Multi-Agent Systems",
        "link": "/arxiv/2512.03285",
        "arxiv_id": "2512.03285",
        "authors": "Nafiul I. Khan, Mansura Habiba, Rafflesia Khan",
        "summary": "As agentic platforms scale, agents are moving beyond fixed roles and predefined toolchains, creating an urgent need for flexible and decentralized coordination. Current structured communication protocols such as direct agent-to-agent messaging or MCP-style tool calls offer reliability, but they struggle to support the emergent and swarm-like intelligence required in large adaptive systems. Distributed agents must learn continuously, share context fluidly, and coordinate without depending solely on central planners. This paper revisits gossip protocols as a complementary substrate for agentic communication. Gossip mechanisms, long valued in distributed systems for their decentralized and fault-tolerant properties, provide scalable and adaptive diffusion of knowledge and fill gaps that structured protocols alone cannot efficiently address. However, gossip also introduces challenges, including semantic relevance, temporal staleness, and limited guarantees on action consistency in rapidly changing environments. We examine how gossip can support context-rich state propagation, resilient coordination under uncertainty, and emergent global awareness. We also outline open problems around semantic filtering, trust, and knowledge decay. Rather than proposing a complete framework, this paper presents a research agenda for integrating gossip into multi-agent communication stacks and argues that gossip is essential for future agentic ecosystems that must remain robust, adaptive, and self-organizing as their scale and autonomy increase.",
        "subjects": "Multiagent Systems, Emerging Technologies",
        "date": "2025-12-02",
        "category": "cs.MA",
        "crawl_time": "2025-12-04T11:00:07.611839",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接聚焦于**多智能体**系统的构建与改进。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具应用到一个特定领域，而是深入探讨如何**改进LLM智能体系统本身**。其核心贡献是提出了一种新的通信机制——将“gossip协议”作为一种补充性的通信底层，用于解决大规模多智能体系统中的去中心化协调问题。这完全属于“构建、改进或演化LLM智能体”的范畴，特别是针对多智能体系统的通信和协调能力。 2.  **第二步：正面指标** - 论文包含了大量与你研究焦点高度相关的核心范式和能力关键词： - **核心范式**: `Agentic AI`, `Multi-Agent Systems (MAS)` 在标题和摘要中反复出现。 - **多智能体**: 论文的核心就是关于 `Communication`（通信）、`Decentralized Coordination`（去中心化协调）、`Collaboration`（协作），并探讨了 `emergent and swarm-like intelligence`（涌现和群体智能）以及 `self-organizing`（自组织）等高级特性。 - 这些指标强烈表明该论文与你的“多智能体”研究方向高度契合。 3.  **第三步：排除标准** - 论文的主要贡献**不是**关于安全、对齐、可解释性或多模态。它虽然提到了“trust”（信任）作为一个开放问题，但这并非论文的核心贡献点。因此，它成功避开了所有的排除标准。 4.  **第四步：处理特殊和模糊情况** - 论文虽然提出的是一个“研究议程”而非一个完整的、可运行的框架，但其核心是提出一种**新的方法论和底层机制**来改进多智能体系统。这完全符合“构建、改进或演化”的要求。它探讨的“adaptive”（适应性）和“self-organizing”（自组织）能力，也与“自我演化”的方向紧密相关，因为它描述了系统如何在没有中央控制的情况下动态适应和演化。 **最终决策**: 这篇论文的核心贡献在于为大规模多智能体系统提出了一种新的、去中心化的通信协调机制。它直接解决了多智能体系统在扩展性和自主性方面遇到的关键挑战，其研究内容（通信、协调、自组织）是你“多智能体”研究方向的子集。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#11",
        "title": "ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms",
        "link": "/arxiv/2512.03476",
        "arxiv_id": "2512.03476",
        "authors": "Juan Diego Toscano, Daniel T. Chen, George Em Karniadakis",
        "summary": "Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop\" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.",
        "subjects": "Machine Learning, Artificial Intelligence, Multiagent Systems, Numerical Analysis, Computational Physics",
        "date": "2025-12-03",
        "category": "cs.MA",
        "crawl_time": "2025-12-04T11:00:07.613796",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的筛选标准高度契合。以下是我的详细判断过程： **第一步：核心判断——保留** 这篇论文的本质是**构建一个新颖的、具有演化能力的LLM智能体框架**。摘要明确指出ATHENA是一个“agentic framework”和“Autonomous Lab”，其核心是“HENA loop”。这个框架并非简单地将现有智能体作为工具应用，而是提出了一套完整的、让智能体自主管理“端到端计算研究生命周期”的方法论。它通过分析历史经验来选择下一步的“行动”，生成代码并评估结果，这完全符合“构建、改进或演化LLM智能体”的核心目标。因此，它不属于“非演化型应用”的排除范畴。 **第二步：正面指标——高度匹配** 论文摘要中包含了大量您关注的核心范式和能力指标： *   **核心范式**: `Agentic Team` (标题), `Agentic framework` (摘要), `Evolutionary` (标题), `Autonomous Lab` (摘要)。这直接命中了`Agentic AI`, `Multi-Agent Systems`, 和 `Self-Evolving`。 *   **智能体能力**: `select structural 'actions'` 体现了 **Planning**；`translated into executable code` 体现了 **Tool Use**；`analyzes prior trials` 体现了 **Memory** 和 **Self-Reflection**。 *   **多智能体**: `Agentic Team` 和 `collaborative \"human-in-the-loop\" intervention` 暗示了多智能体协作或人机协同。 *   **演化机制**: `Hierarchical Evolutionary` (标题), `online learner`, `analyzes prior trials` 都明确指向了 **Self-Improvement** 和 **Iterative Improvement** 的演化机制。 **第三步：排除标准——未触发** 论文的主要贡献是关于智能体的方法论框架和性能，其目标是“加速科学发现”。摘要中完全没有提及`Safety`, `Alignment`, `Interpretability`等安全与对齐相关的内容，也未涉及`Vision`, `MLLMs`等多模态核心研究。因此，它没有触犯任何排除标准。 **第四步：处理特殊和模糊情况——符合保留规则** 1.  **推理/规划**: 论文中的HENA循环是一个典型的智能体规划和决策过程。它不是在提升LLM的基础数学能力，而是在构建一个能够自主进行多步科学研究和算法迭代的智能体框架。这完全符合“保留”关于智能体规划和多步推理的论文的要求。 2.  **自我演化的应用**: 这篇论文是“自我演化的应用”的一个完美范例。虽然它被应用在“Scientific Computing (SciC)”和“Scientific Machine Learning (SciML)”领域，但其**核心贡献是提出了一种新的“自我演化”机制（HENA loop）**。根据您的筛选规则，这种情况下应该保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是构建了一个名为ATHENA的、具有层级演化能力的自主智能体团队。该框架集成了规划、工具使用、记忆和自我反思等关键能力，并通过一个在线学习循环实现自我迭代和演化。它不仅是一个单智能体系统，还包含了团队协作的元素，并且其核心机制就是自我演化。因此，这篇论文与您关于“LLM智能体及其演化”的研究课题（特别是单智能体、多智能体和自我演化三个方向）高度相关，应当被保留。"
    },
    {
        "index": "#15",
        "title": "Optimizing Life Sciences Agents in Real-Time using Reinforcement Learning",
        "link": "/arxiv/2512.03065",
        "arxiv_id": "2512.03065",
        "authors": "Nihir Chadderwala",
        "summary": "Generative AI agents in life sciences face a critical challenge: determining the optimal approach for diverse queries ranging from simple factoid questions to complex mechanistic reasoning. Traditional methods rely on fixed rules or expensive labeled training data, neither of which adapts to changing conditions or user preferences. We present a novel framework that combines AWS Strands Agents with Thompson Sampling contextual bandits to enable AI agents to learn optimal decision-making strategies from user feedback alone. Our system optimizes three key dimensions: generation strategy selection (direct vs. chain-of-thought), tool selection (literature search, drug databases, etc.), and domain routing (pharmacology, molecular biology, clinical specialists). Through empirical evaluation on life science queries, we demonstrate 15-30\\% improvement in user satisfaction compared to random baselines, with clear learning patterns emerging after 20-30 queries. Our approach requires no ground truth labels, adapts continuously to user preferences, and provides a principled solution to the exploration-exploitation dilemma in agentic AI systems.",
        "subjects": "Machine Learning, Artificial Intelligence, Multiagent Systems",
        "date": "2025-11-26",
        "category": "cs.MA",
        "crawl_time": "2025-12-04T11:00:07.614848",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接命中了“自我演化”和“单智能体”两个核心方向。 1.  **第一步：核心判断 (保留)** 论文的核心不是简单地将LLM智能体应用于生命科学领域，而是提出了一种**新颖的框架**，用于**优化和改进LLM智能体本身**。它解决的是智能体在面对多样化任务时，如何动态学习和选择最优策略（生成策略、工具、领域）的核心问题。这属于构建和改进LLM智能体的方法论，因此应予以保留。它不是“非演化型应用”，因为它引入了学习和适应机制。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个核心关注点： *   **自我演化**: 这是论文最核心的贡献。它使用强化学习（Thompson Sampling contextual bandits）让智能体**从用户反馈中学习**，实现**持续适应**和**自我改进**。这完全符合“自我演化”的定义。 *   **单智能体能力**: 论文明确优化了智能体的关键能力，包括**规划**（选择生成策略，如直接生成 vs. CoT）、**工具使用**（选择文献搜索、药物数据库等工具）和决策（领域路由）。 *   **核心范式**: 论文的研究对象是“Generative AI agents”，并讨论了“agentic AI systems”中的“exploration-exploitation dilemma”，这些都是Agentic AI的核心议题。 3.  **第三步：排除标准 (未命中)** 论文的主要贡献不涉及安全、对齐、可解释性或多模态视觉。它的焦点是智能体的性能优化和自适应学习，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文讨论的规划是智能体层面的决策（选择用哪种推理方法、用哪个工具），而不是提升LLM底层的数学或逻辑推理能力。这符合保留条件。 *   **自我演化的应用**: 这篇论文是“自我演化的应用”的完美范例。虽然它应用在“生命科学”领域，但其**核心贡献是提出了一种通用的“自我演化”机制**（基于用户反馈的强化学习框架）。根据你的特殊规则，这种论文应该被保留。 **最终决策**: 该论文的核心贡献是提出了一种让LLM智能体通过实时反馈进行自我演化和优化的新框架。它直接解决了智能体在规划、工具使用和决策中的关键挑战，并引入了强大的自我改进机制。因此，这篇论文与你的研究课题“LLM智能体及其演化”高度相关，特别是与“自我演化”和“单智能体”方向紧密契合，应被筛选保留。"
    },
    {
        "index": "#1",
        "title": "SkillFactory: Self-Distillation For Learning Cognitive Behaviors",
        "link": "/arxiv/2512.04072",
        "arxiv_id": "2512.04072",
        "authors": "Zayne Sprague, Jack Lu, Manya Wadhwa, Sedrick Keh, Mengye Ren, Greg Durrett",
        "summary": "Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These \"silver\" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-04T11:00:07.919384",
        "filter_reason": "这篇论文完全符合您的研究范围。以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM作为工具应用，而是提出了一种名为 `SkillFactory` 的**新方法论**，用于**构建和改进LLM智能体的核心能力**。其核心贡献在于教会模型原本不具备的“认知技能”，如自我验证、回溯和重试。这些技能是智能体实现自主规划和自我反思的基础，因此论文的核心是关于智能体能力的构建，而非简单的应用。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **自我演化**: 论文的核心机制 `Self-Distillation`（自蒸馏）是一种典型的自我演化/自我完善形式。它利用模型自身生成的样本（尽管是“银色”的、不完美的）来训练和提升自身，这完全符合“通过经验进行自我完善”的定义。 - **智能体能力**: 论文明确提到了 `Self-Correction`（自我修正）和 `Self-Reflection`（自我反思）的具体表现形式，即“verification of their answers, backtracking, retrying”。这些都是智能体在复杂任务中自主决策和执行的关键能力。 - **自我完善**: 整个 `SkillFactory` 框架的目标就是实现模型的 `Self-Improvement`，使其在后续的RL阶段能更好地泛化和使用这些认知技能。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐（Safety, Alignment），也不涉及多模态与视觉。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它研究的不是提升LLM的基础数学或逻辑推理能力，而是**智能体如何进行规划和多步推理**。它提出的“认知技能”（验证、回溯、重试）正是高级推理框架（如ReAct, ToT）中的核心组件。论文关注的是推理的**过程和策略**，而非单点的答案正确性。 **最终决策**: 综合以上分析，该论文的核心贡献在于提出了一种创新的自我演化机制（自蒸馏），用于教会LLM智能体关键的认知技能（自我修正、反思）。这直接命中了您研究课题中的“单智能体”和“自我演化”两个核心方向。它不是应用型研究，而是关于智能体能力构建的基础性方法论，因此是您需要筛选的前沿论文。"
    },
    {
        "index": "#28",
        "title": "From Hypothesis to Premises: LLM-based Backward Logical Reasoning with Selective Symbolic Translation",
        "link": "/arxiv/2512.03360",
        "arxiv_id": "2512.03360",
        "authors": "Qingchuan Li, Mingyue Cheng, Zirui Liu, Daoyu Wang, Yuting Zeng, Tongxuan Liu",
        "summary": "Logical reasoning is a core challenge in natural language understanding and a fundamental capability of artificial intelligence, underpinning scientific discovery, mathematical theorem proving, and complex decision-making. Despite the remarkable progress of large language models (LLMs), most current approaches still rely on forward reasoning paradigms, generating step-by-step rationales from premises to conclusions. However, such methods often suffer from redundant inference paths, hallucinated steps, and semantic drift, resulting in inefficient and unreliable reasoning. In this paper, we propose a novel framework, Hypothesis-driven Backward Logical Reasoning (HBLR). The core idea is to integrate confidence-aware symbolic translation with hypothesis-driven backward reasoning. In the translation phase, only high-confidence spans are converted into logical form, such as First-Order Logic (FOL), while uncertain content remains in natural language. A translation reflection module further ensures semantic fidelity by evaluating symbolic outputs and reverting lossy ones back to text when necessary. In the reasoning phase, HBLR simulates human deductive thinking by assuming the conclusion is true and recursively verifying its premises. A reasoning reflection module further identifies and corrects flawed inference steps, enhancing logical coherence. Extensive experiments on five reasoning benchmarks demonstrate that HBLR consistently outperforms strong baselines in both accuracy and efficiency.",
        "subjects": "Computation and Language",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-04T11:00:07.983238",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出一个名为“HBLR”的新**框架**，而不仅仅是一个简单的提示技巧或微调方法。该框架旨在解决LLM在逻辑推理中的问题，其设计包含了多个结构化的处理阶段（翻译、推理）和反馈循环（反思）。这种结构化的、带有自我修正机制的自主执行系统，其本质是构建一个更强大的LLM智能体，而非仅仅提升LLM的基础能力。它不属于“非演化型应用”或“基础设施”的排除范畴。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **智能体能力**: - `Planning`: 论文提出的“从假设到前提的逆向推理”是一种高级的规划和推理策略，完全符合智能体规划的定义。 - `Tool Use / Tool Augmentation`: “选择性符号翻译”将部分内容转换为First-Order Logic (FOL)，这本质上是将符号逻辑作为一种外部工具来增强LLM的推理能力。 - `Self-Correction` / `Self-Reflection`: 论文明确提出了“翻译反思模块”和“推理反思模块”，用于评估和修正自身的行为（翻译和推理步骤）。这是典型的智能体自我反思与自我修正能力，也是自我演化的关键机制。 3.  **第三步：排除标准** - 论文的主要目标是提升逻辑推理的**准确性和效率**，而不是研究`Safety`、`Alignment`或`Interpretability`。虽然反思模块可能带来一定的可解释性，但这并非其核心贡献。论文也不涉及`Vision`或多模态内容。因此，它没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于**智能体如何进行规划和推理**的典型案例。它不是简单地提出一个新的CoT变体，而是构建了一个包含工具使用（符号翻译）和自我反思（反思模块）的完整框架。这完全符合“保留”的条件，即“关于智能体如何进行规划或在复杂任务中进行多步推理”。 **核心依据总结**: 该论文的核心贡献在于构建了一个名为HBLR的**LLM智能体框架**。这个框架通过整合**逆向推理规划**、**符号工具使用**和**双重自我反思机制**，显著提升了LLM在复杂逻辑任务中的表现。其方法论直接对应了您研究焦点中的“单智能体”和“自我演化”方向，特别是规划、工具使用和自我反思等子方向。因此，这篇论文是您研究课题“LLM智能体及其演化”的前沿相关文献。"
    },
    {
        "index": "#40",
        "title": "AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition",
        "link": "/arxiv/2512.03794",
        "arxiv_id": "2512.03794",
        "authors": "Zichuan Lin, Yicheng Liu, Yang Yang, Lvfang Tao, Deheng Ye",
        "summary": "Vision-Language Models (VLMs) have achieved remarkable success in visual question answering tasks, but their reliance on large numbers of visual tokens introduces significant computational overhead. While existing efficient VLM approaches reduce visual tokens through fixed-ratio compression, they operate passively and lack the ability to adapt to varying task requirements. This motivates a fundamental question: Can VLMs autonomously determine the minimum number of visual tokens required for each sample? Inspired by human active vision mechanisms, we introduce AdaptVision, an efficient VLM paradigm that enables adaptive visual token acquisition through a coarse-to-fine approach. Our model initially processes compressed visual tokens from low-resolution images and selectively acquires additional visual information by invoking a bounding box tool to crop key regions when necessary. We train AdaptVision using a reinforcement learning framework that carefully balances accuracy and efficiency. Central to our approach is Decoupled Turn Policy Optimization (DTPO), which decouples the learning objective into two components: (1) tool learning, which optimizes correct tool utilization, and (2) accuracy improvement, which refines the generated responses to improve answer correctness. Based on this formulation, we further decouple advantage estimation by computing separate advantages for tokens associated with each objective. This formulation enables more effective optimization for AdaptVision compared to vanilla GRPO. Comprehensive experiments across multiple VQA benchmarks demonstrate that AdaptVision achieves superior performance while consuming substantially fewer visual tokens than state-of-the-art efficient VLM methods.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-04T11:00:07.994551",
        "filter_reason": "这篇论文符合你的研究范围，应被保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建了一个名为 AdaptVision 的新框架，该框架使视觉语言模型（VLM）能够**自主地**、**自适应地**决定何时以及如何获取视觉信息。这并非简单地将LLM或智能体作为工具应用，而是提出了一种新的**智能体方法论**。其关键在于智能体能够根据任务需求，主动调用“边界框工具”来与环境（图像）进行交互，这完全符合“构建、改进LLM智能体”的核心目标。 2.  **正面指标 (第二步):** 论文包含了多个核心关注点。 *   **智能体能力:** 论文的核心是 `Tool Use / Tool Augmentation`。智能体通过调用工具来裁剪图像关键区域，这是典型的工具使用行为。 *   **自主决策:** 摘要中明确提到“autonomously determine the minimum number of visual tokens required”，这体现了智能体的自主规划与决策能力，虽然是一种反应式的规划，但本质上是智能体在多步推理中决定下一步行动。 *   **核心范式:** 整个 AdaptVision 框架是一个 `Agentic AI` 的实现范例。 3.  **排除标准 (第三步):** 尽管论文涉及视觉，但它并未被排除。 *   **多模态与视觉:** 论文的研究核心**不是**提出一个新的视觉模型或提升视觉理解能力本身，而是研究**智能体如何利用工具来高效地感知视觉环境**。这里的视觉和边界框工具是智能体与环境交互的媒介，研究的焦点在于智能体的决策机制（何时调用工具、调用在哪里），而不是视觉技术。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外条款。 *   **安全与对齐:** 论文未涉及安全、对齐等问题。 4.  **特殊和模糊情况 (第四步):** *   **推理/规划:** 论文符合“保留”条件。它不是在提升LLM的基础推理能力，而是在构建一个让智能体在复杂任务中进行多步决策（先看低分辨率图，再决定是否要看细节）的框架，这与 ReAct 等Agentic规划范式一脉相承。 **总结:** 论文的核心贡献在于提出了一种新颖的、基于工具使用的Agentic框架（AdaptVision），使智能体能够自适应地与环境交互。这直接命中了你研究范围中的“单智能体”方向，特别是“工具使用”和“规划”子方向。因此，这篇论文高度相关，应被保留。"
    },
    {
        "index": "#41",
        "title": "Thinking with Programming Vision: Towards a Unified View for Thinking with Images",
        "link": "/arxiv/2512.03746",
        "arxiv_id": "2512.03746",
        "authors": "Zirun Guo, Minjie Hong, Feng Zhang, Kai Jia, Tao Jin",
        "summary": "Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at https://github.com/ByteDance-BandAI/CodeVision.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-12-03",
        "category": "cs.CL",
        "crawl_time": "2025-12-04T11:00:07.994988",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出了一种名为 `CodeVision` 的新颖的“代码即工具”框架。这并非将现有智能体简单应用于某个领域，而是**构建和改进LLM智能体本身的方法论**。它解决了现有智能体工具集固定且有限的根本问题，提出了一种更灵活、可扩展的智能体架构。因此，它通过了第一步的核心判断，属于“保留”类别。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了多个您关注的核心正面指标： *   **智能体能力**: 明确提到了 `Tool Use / Tool Augmentation`（“code-as-tool framework”）、`Self-Correction`（“robust error recovery from runtime feedback”）和 `Planning`（“complex, multi-turn tool composition”, “efficient chained execution”）。这些都是单智能体研究的核心能力。 *   **核心范式**: 论文的工作本质上是 `Agentic AI` 和 `LLM-based Agents` 的研究，因为它专注于如何让LLM通过工具更有效地与环境（视觉信息）交互和推理。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性，因此未触发此项排除标准。 *   **多模态与视觉**: 这是本篇论文需要仔细辨析的关键点。虽然论文涉及 `MLLMs` 和 `Vision`，但其研究核心**并非视觉模型本身**，而是**如何让智能体使用工具来处理视觉信息**。视觉是智能体操作的“对象”和“环境”，而不是研究的“主体”。根据您的规则“除非它们被用作智能体感知环境的工具，而不是研究的核心”，这篇论文恰好符合这个例外情况。它的核心是智能体的工具使用框架，而不是视觉理解技术。 4.  **第四步：处理特殊和模糊情况 (符合保留条件)** *   **推理/规划**: 论文的研究重点在于智能体如何通过生成代码来规划和组合工具，以完成复杂的视觉任务。这完全符合“保留”的条件，即“关于智能体如何进行规划或在复杂任务中进行多步推理”。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个高级的Agentic推理框架。 5.  **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于提出了一种创新的、基于代码的LLM智能体工具使用框架，显著增强了智能体在规划、工具组合和自我纠错方面的能力。它精准地命中了您研究焦点中的“单智能体”方向，特别是“工具使用”和“规划”这两个子方向。尽管它以视觉任务为载体，但其本质是Agentic AI的架构创新，而非视觉技术的突破。因此，这篇论文是您研究课题下的高质量前沿文献，应被筛选入内。"
    },
    {
        "index": "#3",
        "title": "A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)",
        "link": "/arxiv/2512.03887",
        "arxiv_id": "2512.03887",
        "authors": "Saurav Prateek",
        "summary": "The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow. The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation. We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-04T11:00:08.775587",
        "filter_reason": "这篇论文符合研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是构建了一个名为Static-DRA（Static Deep Research Agent）的新型LLM智能体架构，并提出了一个可配置的、基于分层树的工作流来控制其研究过程。这完全符合“构建、改进LLM智能体”的核心目标。它不是简单地将现有智能体应用于研究任务，而是提出了一种新的智能体设计范式和控制机制，因此不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标 (高度相关)** 论文包含了多个核心关注点： *   **多智能体**: 论文明确提出了一个包含`Supervisor`、`Independent`和`Worker`的多智能体架构，用于实现任务的分解、协调与并行处理，这直接命中了`Multi-Agent Systems`和`Collaboration`等关键词。 *   **规划**: 其“可配置和分层树式静态工作流”本质上是一种结构化的任务规划方法，指导智能体如何进行多步、多跳的信息检索和子主题调查。这符合`Planning`的核心关注点。 *   **智能体能力**: 整个系统是为了完成复杂的深度研究任务而设计的，体现了高级的智能体能力，虽然摘要未明确提及`Tool Use`，但深度研究任务必然涉及信息检索等工具。 3.  **第三步：排除标准 (未触发)** 论文的研究焦点是智能体的架构、性能和可配置性，不涉及`Safety`、`Alignment`、`Interpretability`等安全与对齐问题，也未涉及`Vision`、`MLLMs`等多模态内容。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文提出的规划方法属于智能体层面的任务分解与执行框架，用于指导智能体在复杂任务中如何行动，这符合“保留”标准，而非仅仅提升LLM底层的数学或逻辑推理能力。 *   **自我演化**: 该论文的智能体是“静态”的，不涉及自我演化机制。但这并不影响其被保留，因为它在“单智能体”和“多智能体”两个核心方向上做出了明确的方法论贡献。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种新颖的、可配置的多智能体协作框架来解决复杂研究任务。它精准地契合了你研究课题中的“单智能体”和“多智能体”方向，提供了关于智能体规划和协作的新见解。因此，应判定为符合要求。"
    },
    {
        "index": "#1",
        "title": "Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol",
        "link": "/arxiv/2512.03955",
        "arxiv_id": "2512.03955",
        "authors": "Niklas Jobs, Luis Miguel Vieira da Silva, Jayanth Somashekaraiah, Maximilian Weigand, David Kube, Felix Gehlhoff",
        "summary": "Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.",
        "subjects": "Artificial Intelligence, Emerging Technologies",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-04T11:00:08.774776",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的核心贡献是构建了一个用于评估和比较LLM智能体规划与控制能力的**标准化基准**和**可执行环境**。虽然它没有提出一个全新的智能体架构，但它为“构建、改进或演化LLM智能体”这一核心目标提供了至关重要的**评估工具和方法论**。一个高质量的基准是推动一个领域（尤其是Agentic AI）进行系统性改进和演化的基础。它不属于“非演化型应用”，因为其目的不是解决某个特定领域（如工业自动化）的问题，而是为智能体研究本身服务。它也不属于“基础设施”，因为其焦点是智能体的能力评估，而非模型部署或硬件加速。 **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `LLM-based Agents` - **智能体能力**: `Planning` (标题和摘要的核心), `Tool Use / Tool Augmentation` (通过MCP实现) - **其他**: 论文提到了`Control`和`Execution`，这些都是智能体在环境中行动的关键环节。 - 这些正面指标强烈表明该论文与您的研究方向高度相关。 **第三步：排除标准** - 论文的主要贡献不涉及`Safety`、`Alignment`、`Interpretability`等安全与对齐议题。 - 论文也未涉及`Vision`、`MLLMs`等多模态内容。 - 因此，该论文未触发任何排除标准。 **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文完全符合“保留”条件。它不是在提升LLM的基础推理能力，而是在构建一个框架来**评估智能体如何进行规划和执行**。这直接服务于“单智能体”方向下的“规划”子方向的研究。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于为LLM智能体的“规划”和“工具使用”能力提供了一个标准化的基准和评估协议。这直接支持了您研究目标中的“构建、改进或演化LLM智能体”，尤其是在“单智能体”的“规划”与“工具使用”子方向上。通过提供定量比较的依据，该基准将极大地促进该领域内不同智能体方法的迭代和改进。因此，这篇论文是您研究课题中非常有价值的前沿文献，应当保留。"
    },
    {
        "index": "#5",
        "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design",
        "link": "/arxiv/2512.03762",
        "arxiv_id": "2512.03762",
        "authors": "Jiawei Xu, Fengfeng Wei, Weineng Chen",
        "summary": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-04T11:00:08.776546",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的三个研究方向高度契合。以下是根据您的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为RoCo的**新颖的多智能体协作框架**。它的核心贡献并非将LLM作为工具应用于组合优化领域，而是**构建了一个由四个专门化LLM智能体（探索者、利用者、评论家、整合者）组成的系统**，并设计了它们之间的交互、协作和演化机制。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了大量您的核心关注点： - **多智能体**: 标题和摘要中明确提到了 `Multi-Agent Role-Based System`、`collaboration`、`LLM-guided agents`。这直接命中了您的“多智能体”研究方向，特别是“智能体间的协作”。 - **自我演化**: 摘要中描述了“evolution step”、“feedback”、“reflection”、“refinement”和“elite mutations”等机制。这表明智能体系统通过迭代和反思进行自我完善，完全符合您的“自我演化”研究方向。 - **智能体能力**: 论文中的 `critic` 角色提供了 `Self-Reflection` 和 `Self-Correction` 的能力。整个多轮交互过程涉及复杂的 `Planning` 和决策。 3.  **第三步：排除标准** - 论文的主要贡献是关于智能体框架的设计和性能，而非安全、对齐或多模态。因此，它没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化机制应用于特定领域”的完美范例。虽然其应用场景是组合优化，但论文的核心是提出一种**新的“自我演化”协作范式**。根据您的规则，这种情况下应该保留，因为其方法论贡献远大于其应用价值。 **最终决策**: 这篇论文的核心贡献是构建了一个创新的、基于角色的多智能体协作框架，该框架通过结构化的交互、反思和迭代优化来实现自我演化。它直接推动了“多智能体”和“自我演化”两个前沿方向的发展，是您研究课题“LLM智能体及其演化”的理想筛选对象。因此，最终判断为 **True**。"
    },
    {
        "index": "#6",
        "title": "MemVerse: Multimodal Memory for Lifelong Learning Agents",
        "link": "/arxiv/2512.03627",
        "arxiv_id": "2512.03627",
        "authors": "Junming Liu, Yifei Sun, Weihua Cheng, Haodong Lei, Yirong Chen, Licheng Wen, Xuemeng Yang, Daocheng Fu, Pinlong Cai, Nianchen Deng, Yi Yu, Shuyue Hu, Botian Shi, Ding Wang",
        "summary": "Despite rapid progress in large-scale language and vision models, AI agents still suffer from a fundamental limitation: they cannot remember. Without reliable memory, agents catastrophically forget past experiences, struggle with long-horizon reasoning, and fail to operate coherently in multimodal or interactive environments. We introduce MemVerse, a model-agnostic, plug-and-play memory framework that bridges fast parametric recall with hierarchical retrieval-based memory, enabling scalable and adaptive multimodal intelligence. MemVerse maintains short-term memory for recent context while transforming raw multimodal experiences into structured long-term memories organized as hierarchical knowledge graphs. This design supports continual consolidation, adaptive forgetting, and bounded memory growth. To handle real-time demands, MemVerse introduces a periodic distillation mechanism that compresses essential knowledge from long-term memory into the parametric model, allowing fast, differentiable recall while preserving interpretability. Extensive experiments demonstrate that MemVerse significantly improves multimodal reasoning and continual learning efficiency, empowering agents to remember, adapt, and reason coherently across extended interactions.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-04T11:00:08.777098",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是构建了一个名为 **MemVerse** 的全新框架。这个框架并非将现有智能体应用于某个特定领域，而是直接解决了LLM智能体的一个根本性缺陷——**记忆**。它提出了一种“模型无关、即插即用”的记忆框架，旨在**构建和改进LLM智能体**本身的能力。这完全符合“保留”标准中关于“构建、改进LLM智能体的方法论或新框架”的定义。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个你的核心关注点： *   **智能体能力**: 论文的核心是 **`Memory`** (记忆)，并明确指出其目的是为了支持 **`long-horizon reasoning`** (长期推理) 和 **`continual learning`** (持续学习)。 *   **自我演化**: 论文提出的框架具备强烈的自我演化特征。关键词如 **`Lifelong Learning`** (终身学习)、**`continual consolidation`** (持续整合)、**`adaptive forgetting`** (自适应遗忘) 以及 **`periodic distillation mechanism`** (周期性提炼机制) 都指向智能体通过与环境的交互和经验积累，不断**自我完善和迭代**。这正是“自我演化”方向的核心。 3.  **第三步：排除标准 (不适用)** *   **安全与对齐**: 论文的主要贡献是记忆框架，而非安全、对齐或可解释性。 *   **多模态与视觉**: 虽然标题和摘要中提到了 **`Multimodal`** (多模态)，但这属于第四步中需要特殊处理的情况。在这里，多模态是智能体需要**记忆和处理的“环境体验”**，而不是论文研究的核心。论文的核心贡献是**如何记忆和处理这些体验的框架**，而非提出新的视觉或多模态模型本身。该框架是“model-agnostic”的，可以与任何多模态模型配合使用。因此，这不构成排除理由。 4.  **第四步：特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文通过增强记忆能力来支持智能体的“long-horizon reasoning”，这属于智能体框架层面的推理增强，而非LLM底层能力的提升，因此符合保留条件。 *   **自我演化的应用**: 这篇论文本身就是提出一种新的“自我演化”机制（通过记忆和知识提炼），因此即使它被应用于某个领域，也应保留。而本文是提出通用框架，相关性更强。 **总结**: 该论文的核心是提出一个创新的记忆框架 **MemVerse**，以赋予LLM智能体长期记忆和终身学习的能力。这直接命中了你研究范围中的 **“单智能体”** (记忆、规划) 和 **“自我演化”** (自我完善、迭代) 两个核心方向。它不是应用型研究，也不是基础设施或安全研究，其多模态特性是作为智能体感知环境的一部分，而非研究核心。因此，这篇论文是高度相关且应被保留的前沿研究。"
    },
    {
        "index": "#12",
        "title": "Multimodal Reinforcement Learning with Agentic Verifier for AI Agents",
        "link": "/arxiv/2512.03438",
        "arxiv_id": "2512.03438",
        "authors": "Reuben Tan, Baolin Peng, Zhengyuan Yang, Hao Cheng, Oier Mees, Theodore Zhao, Andrea Tupini, Isar Meijier, Qianhui Wu, Yuncong Yang, Lars Liden, Yu Gu, Sheng Zhang, Xiaodong Liu, Lijuan Wang, Marc Pollefeys, Yong Jae Lee, Jianfeng Gao",
        "summary": "Agentic reasoning models trained with multimodal reinforcement learning (MMRL) have become increasingly capable, yet they are almost universally optimized using sparse, outcome-based rewards computed based on the final answers. Richer rewards computed from the reasoning tokens can improve learning significantly by providing more fine-grained guidance. However, it is challenging to compute more informative rewards in MMRL beyond those based on outcomes since different samples may require different scoring functions and teacher models may provide noisy reward signals too. In this paper, we introduce the Argos (Agentic Reward for Grounded & Objective Scoring), a principled reward agent to train multimodal reasoning models for agentic tasks. For each sample, Argos selects from a pool of teacher-model derived and rule-based scoring functions to simultaneously evaluate: (i) final response accuracy, (ii) spatiotemporal localization of referred entities and actions, and (iii) the quality of the reasoning process. We find that by leveraging our agentic verifier across both SFT data curation and RL training, our model achieves state-of-the-art results across multiple agentic tasks such as spatial reasoning, visual hallucination as well as robotics and embodied AI benchmarks. Critically, we demonstrate that just relying on SFT post-training on highly curated reasoning data is insufficient, as agents invariably collapse to ungrounded solutions during RL without our online verification. We also show that our agentic verifier can help to reduce reward-hacking in MMRL. Finally, we also provide a theoretical justification for the effectiveness of Argos through the concept of pareto-optimality.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-04T11:00:08.785138",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为 \"Argos\" 的**奖励智能体**，这是一个用于训练和改进其他多模态智能体的新框架和方法论。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的本质不是将现有智能体作为工具去解决一个特定领域的问题，而是**提出了一种构建和改进LLM智能体的新方法**。Argos作为一个“奖励智能体”，其核心功能是通过提供更精细、更全面的奖励信号（包括评估最终答案、时空定位和推理过程质量）来训练其他智能体。这完全符合“构建、改进或演化LLM智能体的方法论或新框架”的保留标准。它不是非演化型应用，也不是非Agentic的推理，而是直接作用于智能体训练和演化的核心环节。 2.  **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **核心范式**: 论文明确围绕 `Agentic AI` 和 `AI Agents` 展开，提出了一个 `Agentic Verifier`。 *   **智能体能力**: Argos评估“推理过程的质量”，这与 `Self-Reflection`（自我反思）和 `Self-Correction`（自我修正）能力密切相关。通过强化学习（RL）进行训练，本身就体现了 `Iterative Improvement`（迭代改进）的思想。 *   **演化机制**: 整个论文的核心就是关于如何通过更好的奖励机制来驱动智能体的演化（训练过程）。防止智能体在RL中“坍塌到无根据的解决方案”和“减少奖励破解”，都是确保智能体能向更优、更可靠方向演化的关键机制。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 虽然论文提到了“减少奖励破解”和防止“无根据的解决方案”，这些与对齐和安全有关，但它们是**其训练方法带来的积极效果**，而非论文的**主要研究贡献**。论文的核心是Argos这个方法论本身，而不是提出一种新的对齐理论或安全协议。因此，不排除。 *   **多模态与视觉**: 论文标题和摘要都提到了“多模态”。根据筛选规则，如果多模态是作为智能体感知环境的工具，而不是研究的核心，就应该保留。在这篇论文中，多模态（特别是视觉）是智能体需要处理的输入信息，是其运行的环境的一部分。论文的核心贡献**不是一个新的视觉模型或多模态融合技术**，而是一种**训练多模态智能体的通用方法**。因此，不排除。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文明确研究“智能体推理模型”，并评估其“推理过程的质量”。这完全符合“保留”关于智能体如何进行规划和多步推理的研究，而不是“排除”仅提升LLM基础Token预测能力的研究。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种创新的、基于智能体的奖励机制（Argos），用于**训练和演化**其他多模态智能体。它直接解决了智能体训练中的一个关键挑战（稀疏奖励问题），并通过评估推理过程来促进智能体的自我完善。因此，这篇论文高度契合“LLM智能体及其演化”的研究课题，特别是“自我演化”和“单智能体能力提升”这两个方向。应予以保留。"
    },
    {
        "index": "#10",
        "title": "PARC: An Autonomous Self-Reflective Coding Agent for Robust Execution of Long-Horizon Tasks",
        "link": "/arxiv/2512.03549",
        "arxiv_id": "2512.03549",
        "authors": "Yuki Orimo, Iori Kurata, Hodaka Mori, Ryuhei Okuno, Ryohto Sawada, Daisuke Okanohara",
        "summary": "We introduce PARC, a coding agent for the autonomous and robust execution of long-horizon computational tasks. PARC is built on a hierarchical multi-agent architecture incorporating task planning, execution, and a mechanism that evaluates its own actions and their outcomes from an independent context and provides feedback, namely self-assessment and self-feedback. This design enables PARC to detect and correct high-level strategic errors and sustain progress without human intervention. We evaluate PARC across computational science and data science tasks. In materials science, it autonomously reproduces key results from studies on lithium-ion conduction and alloy segregation. In particular, it coordinates dozens of parallel simulation tasks, each requiring roughly 43 hours of computation, managing orchestration, monitoring, and error correction end-to-end. In Kaggle-based experiments, starting from minimal natural-language instructions, PARC conducts data analysis and implements search strategies, producing solutions competitive with human-engineered baselines. These results highlight the potential of integrating a hierarchical multi-agent system with self-assessment and self-feedback to enable AI systems capable of independent, large-scale scientific and analytical work.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-04T11:00:08.778878",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的筛选标准高度契合。以下是我的详细判断过程： 1.  **第一步：核心判断 (保留)** 论文的核心是构建一个名为PARC的新型LLM智能体框架。它并非简单地将现有智能体作为工具应用到特定领域，而是提出了一种全新的架构和方法论。该架构的核心是“分层多智能体系统”和“自我评估与自我反馈机制”，这直接对应了您研究焦点中的“多智能体”和“自我演化”方向。因此，根据第一步的核心判断标准，这篇论文应该被**保留**。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量您的核心关注点： *   **核心范式**: 明确提到了 `Multi-Agent Systems (MAS)` (`hierarchical multi-agent architecture`)。 *   **智能体能力**: 涵盖了 `Planning` (`task planning`)、`Self-Correction` (`detect and correct high-level strategic errors`) 和 `Self-Reflection` (`self-assessment and self-feedback`)。 *   **演化机制**: 其核心贡献之一就是 `Self-Improvement` 机制，通过独立的上下文评估自身行为并提供反馈，实现无需人工干预的持续修正和进步。 这些正面指标表明，论文的研究内容与您的三个核心方向（单智能体、多智能体、自我演化）均有深度交叉。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献不涉及安全、对齐、可解释性或水印等问题。同时，它也不以多模态或视觉为核心研究内容。因此，第三步的排除标准不适用。 4.  **第四步：处理特殊和模糊情况 (确认保留)** *   **推理/规划**: 论文明确研究了智能体如何进行“任务规划”以执行长期任务，这属于智能体框架内的规划能力，符合保留条件。 *   **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它在材料科学和数据科学等特定领域进行了评估，但其**核心贡献是提出了一种新的“自我演化”机制（self-assessment and self-feedback）和一种新的多智能体架构**。应用领域只是为了验证该框架的有效性和鲁棒性，而非研究本身的目的。因此，根据规则，应该**保留**。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个融合了多智能体协作、自主规划和自我反思/修正能力的LLM智能体框架（PARC）。它直接推动了LLM智能体在架构设计和演化机制上的前沿探索，与您“构建、改进或演化LLM智能体”的核心目标完全一致。因此，最终判断为 **True**。"
    },
    {
        "index": "#8",
        "title": "EnCompass: Enhancing Agent Programming with Search Over Program Execution Paths",
        "link": "/arxiv/2512.03571",
        "arxiv_id": "2512.03571",
        "authors": "Zhening Li, Armando Solar-Lezama, Yisong Yue, Stephan Zheng",
        "summary": "We introduce a new approach to agent programming, the development of LLM-based agents. Current approaches to agent programming often entangle two aspects of agent design: the core workflow logic and the inference-time strategy (e.g., tree search). We introduce \"probabilistic angelic nondeterminism\" (\"PAN\"), a programming model that disentangles these two concerns, allowing the programmer to describe the agent workflow and independently experiment with different inference-time strategies by simply changing a few inputs. We provide an implementation of PAN in Python as the EnCompass framework, which uses a Python decorator to compile agent workflow programs into a search space. We present three case studies that demonstrate how the framework lets the programmer quickly improve the reliability of an agent and easily switch between different inference-time strategies, all with little additional coding.",
        "subjects": "Artificial Intelligence, Machine Learning, Programming Languages",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-04T11:00:08.777985",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于**构建和改进LLM智能体的方法论**。以下是根据你的筛选标准进行的详细判断： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个特定领域的问题，而是直接针对“LLM智能体编程”这一核心过程提出了一种新的框架和编程模型。它的核心贡献是`EnCompass`框架和`PAN`编程模型，旨在**改进LLM智能体的构建方式**，使其工作流逻辑与推理策略解耦。这完全符合“构建、改进或演化LLM智能体”的核心目标。它不属于非演化型应用、非Agentic推理或基础设施的排除范畴。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **核心范式**: `LLM-based Agents` (摘要第一句)。 - **智能体能力**: 论文的核心是关于智能体的`Planning`和推理。它通过“搜索程序执行路径”和“推理时策略（例如，树搜索）”来增强智能体的能力，这与`ReAct`、`ToT`等范式在精神上是一致的，都是关于智能体如何进行多步决策和规划。 - **演化机制**: 论文提出的框架允许程序员“快速提高智能体的可靠性”和“轻松地在不同的推理时策略之间切换”，这本身就是一种对智能体行为的**迭代改进**，属于`Iterative Improvement`的范畴。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐，也没有涉及多模态与视觉。它的焦点纯粹在于智能体的编程范式和推理框架，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于“智能体如何进行规划或在复杂任务中进行多步推理”的典型范例。它提出了一种新的框架来管理和优化智能体的规划过程（通过搜索执行路径），而不是仅仅提升LLM本身的基础数学或逻辑能力。因此，根据规则，应该**保留**。 5.  **第五步：最终决策** - 综合以上分析，该论文的核心贡献是提出了一种创新的编程模型和框架，用于**构建和改进LLM智能体**，特别是在解耦工作流逻辑和推理策略方面做出了实质性贡献。它直接命中了你的研究焦点“单智能体”方向中的“规划”和“推理”子方向。因此，这篇论文与你的研究课题高度相关，应该被保留。"
    },
    {
        "index": "#35",
        "title": "Hierarchical Vision Language Action Model Using Success and Failure Demonstrations",
        "link": "/arxiv/2512.03913",
        "arxiv_id": "2512.03913",
        "authors": "Jeongeun Park, Jihwan Yoon, Byungwoo Jeon, Juhan Park, Jinwoo Shin, Namhoon Cho, Kyungjae Lee, Sangdoo Yun, Sungjoon Choi",
        "summary": "Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-12-03",
        "category": "cs.AI",
        "crawl_time": "2025-12-04T11:00:08.807224",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为VINE的新型分层视觉-语言-动作模型框架，其本质是构建和改进一个LLM智能体，因此符合您的研究范围。 1.  **第一步：核心判断 (保留)** 论文的核心并非简单地将现有智能体应用于机器人领域，而是提出了一种全新的智能体架构（VINE）来解决现有VLA模型鲁棒性不足的问题。其核心创新在于利用失败数据来改进智能体的规划和决策过程，这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个核心关注点： *   **Agentic AI**: VINE本身就是一个智能体模型，它将高层推理（System 2）与底层控制（System 1）分离，是典型的智能体架构。 *   **Planning**: 论文的核心贡献之一就是System 2的“feasibility-guided tree search”（可行性引导的树搜索）规划机制。这直接命中了“规划”这一关键能力。 *   **Self-Correction / Self-Reflection**: 智能体通过分析失败数据，在规划阶段就“prunes brittle branches”（剪掉脆弱的分支），这是一种在执行前的自我反思和纠错机制，旨在提高决策的鲁棒性。 *   **Iterative Improvement**: 整个框架的设计目标就是通过整合过去的失败经验，迭代地改进智能体的执行成功率，体现了自我完善的理念。 3.  **第三步：排除标准 (未触发)** *   **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性。 *   **多模态与视觉**: 这是本篇论文最需要辨析的一点。虽然论文标题和摘要中多次提及“Vision-Language-Action (VLA)”，但根据您的筛选规则“除非它们被用作智能体感知环境的工具，而不是研究的核心”，这篇论文应被保留。在这里，视觉是智能体感知物理环境（构建2D场景图）的**输入工具**，而研究的**核心贡献**是那个利用成功/失败数据进行高层规划的**智能体框架**，而非视觉模型本身。论文的创新点在于“如何思考”，而不是“如何看”。 4.  **第四步：特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文明确是关于智能体如何进行复杂任务的多步规划（System 2的树搜索），完全符合保留条件。 *   **自我演化的应用**: 论文虽然应用在机器人操控领域，但其核心是提出了一种新的“自我完善”机制（从失败中学习以改进规划）。这符合“例外”情况，即核心贡献是新的演化/完善机制，即使应用在特定领域也应保留。 **最终决策**: 综合来看，这篇论文提出了一种创新的分层智能体框架，其核心在于通过利用失败数据来增强智能体的规划和自我纠错能力，从而实现更鲁棒的执行。这完全契合您在“单智能体”方向上对“规划”和“自我反思/完善”的研究焦点。尽管涉及视觉，但视觉仅作为感知工具，而非研究核心。因此，这篇论文高度相关，应该被保留。"
    }
]