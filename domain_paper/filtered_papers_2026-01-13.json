[
    {
        "index": "#5",
        "title": "Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning",
        "link": "/arxiv/2601.07782",
        "arxiv_id": "2601.07782",
        "authors": "Wei Fang, James Glass",
        "summary": "LLM agents operating over massive, dynamic tool libraries rely on effective retrieval, yet standard single-shot dense retrievers struggle with complex requests. These failures primarily stem from the disconnect between abstract user goals and technical documentation, and the limited capacity of fixed-size embeddings to model combinatorial tool compositions. To address these challenges, we propose TOOLQP, a lightweight framework that models retrieval as iterative query planning. Instead of single-shot matching, TOOLQP decomposes instructions into sub-tasks and dynamically generates queries to interact with the retriever, effectively bridging the semantic gap by targeting the specific sub-tasks required for composition. We train TOOLQP using synthetic query trajectories followed by optimization via Reinforcement Learning with Verifiable Rewards (RLVR). Experiments demonstrate that TOOLQP achieves state-of-the-art performance, exhibiting superior zero-shot generalization, robustness across diverse retrievers, and significant improvements in downstream agentic execution.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.100627",
        "filter_reason": "该论文专注于LLM智能体的工具使用和规划能力。它提出了通过迭代查询规划和任务分解来改进工具检索的框架，直接属于单智能体（规划、工具使用）的研究范畴。"
    },
    {
        "index": "#9",
        "title": "Is Agentic RAG worth it? An experimental comparison of RAG approaches",
        "link": "/arxiv/2601.07711",
        "arxiv_id": "2601.07711",
        "authors": "Pietro Ferrazzi, Milica Cvjeticanin, Alessio Piraccini, Davide Giannuzzi",
        "summary": "Retrieval-Augmented Generation (RAG) systems are usually defined by the combination of a generator and a retrieval component that extracts textual context from a knowledge base to answer user queries. However, such basic implementations exhibit several limitations, including noisy or suboptimal retrieval, misuse of retrieval for out-of-scope queries, weak query-document matching, and variability or cost associated with the generator. These shortcomings have motivated the development of \"Enhanced\" RAG, where dedicated modules are introduced to address specific weaknesses in the workflow. More recently, the growing self-reflective capabilities of Large Language Models (LLMs) have enabled a new paradigm, which we refer to as \"Agentic\" RAG. In this approach, the LLM orchestrates the entire process-deciding which actions to perform, when to perform them, and whether to iterate-thereby reducing reliance on fixed, manually engineered modules. Despite the rapid adoption of both paradigms, it remains unclear which approach is preferable under which conditions. In this work, we conduct an extensive, empirically driven evaluation of Enhanced and Agentic RAG across multiple scenarios and dimensions. Our results provide practical insights into the trade-offs between the two paradigms, offering guidance on selecting the most effective RAG design for real-world applications, considering both costs and performance.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.108050",
        "filter_reason": "该论文明确研究“Agentic RAG”范式，其中LLM作为智能体负责编排整个流程（决定执行动作、时机及迭代），涉及规划、工具使用和自我反思等核心智能体能力，符合单智能体的研究范围。"
    },
    {
        "index": "#11",
        "title": "Exploring the Meta-level Reasoning of Large Language Models via a Tool-based Multi-hop Tabular Question Answering Task",
        "link": "/arxiv/2601.07696",
        "arxiv_id": "2601.07696",
        "authors": "Nick Ferguson, Alan Bundy, Kwabena Nuamah",
        "summary": "Recent advancements in Large Language Models (LLMs) are increasingly focused on \"reasoning\" ability, a concept with many overlapping definitions in the LLM discourse. We take a more structured approach, distinguishing meta-level reasoning (denoting the process of reasoning about intermediate steps required to solve a task) from object-level reasoning (which concerns the low-level execution of the aforementioned steps.) We design a novel question answering task, which is based around the values of geopolitical indicators for various countries over various years. Questions require breaking down into intermediate steps, retrieval of data, and mathematical operations over that data. The meta-level reasoning ability of LLMs is analysed by examining the selection of appropriate tools for answering questions. To bring greater depth to the analysis of LLMs beyond final answer accuracy, our task contains 'essential actions' against which we can compare the tool call output of LLMs to infer the strength of reasoning ability. We find that LLMs demonstrate good meta-level reasoning on our task, yet are flawed in some aspects of task understanding. We find that n-shot prompting has little effect on accuracy; error messages encountered do not often deteriorate performance; and provide additional evidence for the poor numeracy of LLMs. Finally, we discuss the generalisation and limitation of our findings to other task domains.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.108947",
        "filter_reason": "论文研究了LLM在基于工具的任务中的元级推理能力，重点分析了模型选择适当工具和分解任务步骤的能力，这属于单智能体范畴中的工具使用和规划能力。"
    },
    {
        "index": "#16",
        "title": "Proof of Time: A Benchmark for Evaluating Scientific Idea Judgments",
        "link": "/arxiv/2601.07606",
        "arxiv_id": "2601.07606",
        "authors": "Bingyang Ye, Shan Chen, Jingxuan Tu, Chen Liu, Zidi Xiong, Samuel Schmidgall, Danielle S. Bitterman",
        "summary": "Large language models are increasingly being used to assess and forecast research ideas, yet we lack scalable ways to evaluate the quality of models' judgments about these scientific ideas. Towards this goal, we introduce PoT, a semi-verifiable benchmarking framework that links scientific idea judgments to downstream signals that become observable later (e.g., citations and shifts in researchers' agendas). PoT freezes a pre-cutoff snapshot of evidence in an offline sandbox and asks models to forecast post-cutoff outcomes, enabling verifiable evaluation when ground truth arrives, scalable benchmarking without exhaustive expert annotation, and analysis of human-model misalignment against signals such as peer-review awards. In addition, PoT provides a controlled testbed for agent-based research judgments that evaluate scientific ideas, comparing tool-using agents to non-agent baselines under prompt ablations and budget scaling. Across 30,000+ instances spanning four benchmark domains, we find that, compared with non-agent baselines, higher interaction budgets generally improve agent performance, while the benefit of tool use is strongly task-dependent. By combining time-partitioned, future-verifiable targets with an offline sandbox for tool use, PoT supports scalable evaluation of agents on future-facing scientific idea judgment tasks.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.111610",
        "filter_reason": "论文明确提出了一个用于评估基于智能体的研究判断的基准，重点比较了使用工具的智能体与非智能体基线，涉及单智能体的工具使用能力。"
    },
    {
        "index": "#17",
        "title": "ES-Mem: Event Segmentation-Based Memory for Long-Term Dialogue Agents",
        "link": "/arxiv/2601.07582",
        "arxiv_id": "2601.07582",
        "authors": "Huhai Zou, Tianhao Sun, Chuanjiang He, Yu Tian, Zhenyang Li, Li Jin, Nayu Liu, Jiang Zhong, Kaiwen Wei",
        "summary": "Memory is critical for dialogue agents to maintain coherence and enable continuous adaptation in long-term interactions. While existing memory mechanisms offer basic storage and retrieval capabilities, they are hindered by two primary limitations: (1) rigid memory granularity often disrupts semantic integrity, resulting in fragmented and incoherent memory units; (2) prevalent flat retrieval paradigms rely solely on surface-level semantic similarity, neglecting the structural cues of discourse required to navigate and locate specific episodic contexts. To mitigate these limitations, drawing inspiration from Event Segmentation Theory, we propose ES-Mem, a framework incorporating two core components: (1) a dynamic event segmentation module that partitions long-term interactions into semantically coherent events with distinct boundaries; (2) a hierarchical memory architecture that constructs multi-layered memories and leverages boundary semantics to anchor specific episodic memory for precise context localization. Evaluations on two memory benchmarks demonstrate that ES-Mem yields consistent performance gains over baseline methods. Furthermore, the proposed event segmentation module exhibits robust applicability on dialogue segmentation datasets.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.112159",
        "filter_reason": "该论文专注于长期对话智能体的“记忆”机制，提出了基于事件分割的动态记忆架构。根据筛选条件，“记忆”属于单智能体研究的核心范畴，且该研究不涉及被排除的纯应用、纯推理或安全等领域。"
    },
    {
        "index": "#19",
        "title": "From RAG to Agentic RAG for Faithful Islamic Question Answering",
        "link": "/arxiv/2601.07528",
        "arxiv_id": "2601.07528",
        "authors": "Gagan Bhatia, Hamdy Mubarak, Mustafa Jarrar, George Mikros, Fadi Zaraket, Mahmoud Alhirthani, Mutaz Al-Khatib, Logan Cochrane, Kareem Darwish, Rashid Yahiaoui, Firoj Alam",
        "summary": "LLMs are increasingly used for Islamic question answering, where ungrounded responses may carry serious religious consequences. Yet standard MCQ/MRC-style evaluations do not capture key real-world failure modes, notably free-form hallucinations and whether models appropriately abstain when evidence is lacking. To shed a light on this aspect we introduce ISLAMICFAITHQA, a 3,810-item bilingual (Arabic/English) generative benchmark with atomic single-gold answers, which enables direct measurement of hallucination and abstention. We additionally developed an end-to-end grounded Islamic modelling suite consisting of (i) 25K Arabic text-grounded SFT reasoning pairs, (ii) 5K bilingual preference samples for reward-guided alignment, and (iii) a verse-level Qur'an retrieval corpus of $\\sim$6k atomic verses (ayat). Building on these resources, we develop an agentic Quran-grounding framework (agentic RAG) that uses structured tool calls for iterative evidence seeking and answer revision. Experiments across Arabic-centric and multilingual LLMs show that retrieval improves correctness and that agentic RAG yields the largest gains beyond standard RAG, achieving state-of-the-art performance and stronger Arabic-English robustness even with a small model (i.e., Qwen3 4B). We will make the experimental resources and datasets publicly available for the community.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.118366",
        "filter_reason": "论文提出了一个“智能体RAG”框架，该框架利用结构化工具调用进行迭代证据检索和答案修订。这符合单智能体研究范围中的“工具使用”和“自我反思/规划”特征。尽管应用场景是伊斯兰教问答，但其核心贡献在于智能体架构的设计与实现，而非单纯的应用。"
    },
    {
        "index": "#28",
        "title": "GROKE: Vision-Free Navigation Instruction Evaluation via Graph Reasoning on OpenStreetMap",
        "link": "/arxiv/2601.07375",
        "arxiv_id": "2601.07375",
        "authors": "Farzad Shami, Subhrasankha Dey, Nico Van de Weghe, Henrikki Tenkanen",
        "summary": "The evaluation of navigation instructions remains a persistent challenge in Vision-and-Language Navigation (VLN) research. Traditional reference-based metrics such as BLEU and ROUGE fail to capture the functional utility of spatial directives, specifically whether an instruction successfully guides a navigator to the intended destination. Although existing VLN agents could serve as evaluators, their reliance on high-fidelity visual simulators introduces licensing constraints and computational costs, and perception errors further confound linguistic quality assessment. This paper introduces GROKE(Graph-based Reasoning over OSM Knowledge for instruction Evaluation), a vision-free training-free hierarchical LLM-based framework for evaluating navigation instructions using OpenStreetMap data. Through systematic ablation studies, we demonstrate that structured JSON and textual formats for spatial information substantially outperform grid-based and visual graph representations. Our hierarchical architecture combines sub-instruction planning with topological graph navigation, reducing navigation error by 68.5% compared to heuristic and sampling baselines on the Map2Seq dataset. The agent's execution success, trajectory fidelity, and decision patterns serve as proxy metrics for functional navigability given OSM-visible landmarks and topology, establishing a scalable and interpretable evaluation paradigm without visual dependencies. Code and data are available at https://anonymous.4open.science/r/groke.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.128127",
        "filter_reason": "该论文提出了GROKE，一个基于LLM的框架，用于评估导航指令。它符合“单智能体”的研究范围，具体涉及“规划”（子指令规划）和“工具使用”（利用OpenStreetMap数据进行拓扑图导航）。论文明确指出是“Vision-Free”（无视觉），避开了多模态/视觉的排除项，且侧重于智能体的架构设计与执行能力，而非纯推理或特定垂直领域的纯应用。"
    },
    {
        "index": "#35",
        "title": "Controlled Self-Evolution for Algorithmic Code Optimization",
        "link": "/arxiv/2601.07348",
        "arxiv_id": "2601.07348",
        "authors": "Tu Hu, Ronghao Chen, Shuo Zhang, Jianghao Yin, Mou Xiao Feng, Jingping Liu, Shaolei Zhang, Wenqi Jiang, Yuqi Fang, Sen Hu, Yi Xu, Huacan Wang",
        "summary": "Self-evolution methods enhance code generation through iterative \"generate-verify-refine\" cycles, yet existing approaches suffer from low exploration efficiency, failing to discover solutions with superior complexity within limited budgets. This inefficiency stems from initialization bias trapping evolution in poor solution regions, uncontrolled stochastic operations lacking feedback guidance, and insufficient experience utilization across tasks.To address these bottlenecks, we propose Controlled Self-Evolution (CSE), which consists of three key components. Diversified Planning Initialization generates structurally distinct algorithmic strategies for broad solution space coverage. Genetic Evolution replaces stochastic operations with feedback-guided mechanisms, enabling targeted mutation and compositional crossover. Hierarchical Evolution Memory captures both successful and failed experiences at inter-task and intra-task levels.Experiments on EffiBench-X demonstrate that CSE consistently outperforms all baselines across various LLM backbones. Furthermore, CSE achieves higher efficiency from early generations and maintains continuous improvement throughout evolution. Our code is publicly available at https://github.com/QuantaAlpha/EvoControl.",
        "subjects": "Computation and Language, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.131690",
        "filter_reason": "论文提出了“受控自我演化”（CSE）框架，通过“生成-验证-优化”循环实现算法代码的自我完善，涵盖了规划（多样化规划初始化）、记忆（分层进化记忆）和自我演化（通过反馈引导的遗传进化）等LLM智能体的核心特征，符合研究范围。"
    },
    {
        "index": "#37",
        "title": "Beyond Literal Mapping: Benchmarking and Improving Non-Literal Translation Evaluation",
        "link": "/arxiv/2601.07338",
        "arxiv_id": "2601.07338",
        "authors": "Yanzhi Tian, Cunxiang Wang, Zeming Liu, Heyan Huang, Wenbo Yu, Dawei Song, Jie Tang, Yuhang Guo",
        "summary": "Large Language Models (LLMs) have significantly advanced Machine Translation (MT), applying them to linguistically complex domains-such as Social Network Services, literature etc. In these scenarios, translations often require handling non-literal expressions, leading to the inaccuracy of MT metrics. To systematically investigate the reliability of MT metrics, we first curate a meta-evaluation dataset focused on non-literal translations, namely MENT. MENT encompasses four non-literal translation domains and features source sentences paired with translations from diverse MT systems, with 7,530 human-annotated scores on translation quality. Experimental results reveal the inaccuracies of traditional MT metrics and the limitations of LLM-as-a-Judge, particularly the knowledge cutoff and score inconsistency problem. To mitigate these limitations, we propose RATE, a novel agentic translation evaluation framework, centered by a reflective Core Agent that dynamically invokes specialized sub-agents. Experimental results indicate the efficacy of RATE, achieving an improvement of at least 3.2 meta score compared with current metrics. Further experiments demonstrate the robustness of RATE to general-domain MT evaluation. Code and dataset are available at: https://github.com/BITHLP/RATE.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.132678",
        "filter_reason": "论文提出了RATE，一个基于智能体的翻译评估框架，其中包含具有自我反思能力的核心智能体和动态调用的子智能体，符合单智能体（自我反思、工具使用）及多智能体协作的研究范围。"
    },
    {
        "index": "#45",
        "title": "The Confidence Dichotomy: Analyzing and Mitigating Miscalibration in Tool-Use Agents",
        "link": "/arxiv/2601.07264",
        "arxiv_id": "2601.07264",
        "authors": "Weihao Xuan, Qingcheng Zeng, Heli Qi, Yunze Xiao, Junjue Wang, Naoto Yokoya",
        "summary": "Autonomous agents based on large language models (LLMs) are rapidly evolving to handle multi-turn tasks, but ensuring their trustworthiness remains a critical challenge. A fundamental pillar of this trustworthiness is calibration, which refers to an agent's ability to express confidence that reliably reflects its actual performance. While calibration is well-established for static models, its dynamics in tool-integrated agentic workflows remain underexplored. In this work, we systematically investigate verbalized calibration in tool-use agents, revealing a fundamental confidence dichotomy driven by tool type. Specifically, our pilot study identifies that evidence tools (e.g., web search) systematically induce severe overconfidence due to inherent noise in retrieved information, while verification tools (e.g., code interpreters) can ground reasoning through deterministic feedback and mitigate miscalibration. To robustly improve calibration across tool types, we propose a reinforcement learning (RL) fine-tuning framework that jointly optimizes task accuracy and calibration, supported by a holistic benchmark of reward designs. We demonstrate that our trained agents not only achieve superior calibration but also exhibit robust generalization from local training environments to noisy web settings and to distinct domains such as mathematical reasoning. Our results highlight the necessity of domain-specific calibration strategies for tool-use agents. More broadly, this work establishes a foundation for building self-aware agents that can reliably communicate uncertainty in high-stakes, real-world deployments.",
        "subjects": "Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.141869",
        "filter_reason": "该论文明确研究基于LLM的自主智能体，特别是聚焦于“工具使用智能体”。它探讨了智能体在工具集成工作流中的校准问题（即自我反思/自我意识），并提出了通过强化学习优化智能体性能和校准的方法。这符合“单智能体”中关于“工具使用”和“自我反思”的研究范围，不属于纯应用、纯推理或基础设施优化等排除类别。"
    },
    {
        "index": "#52",
        "title": "Measuring Iterative Temporal Reasoning with TimePuzzles",
        "link": "/arxiv/2601.07148",
        "arxiv_id": "2601.07148",
        "authors": "Zhengxiang Wang, Zeyu Dong",
        "summary": "We introduce TimePuzzles, a constraint-based date inference task for evaluating iterative temporal reasoning. Each puzzle combines factual temporal anchors with (cross-cultural) calendar relations, admits one or multiple valid solution dates, and is algorithmically generated for controlled, dynamic, and continual evaluation. Across 13 diverse LLMs, TimePuzzles well distinguishes their iterative temporal reasoning capabilities and remains challenging without tools: GPT-5 reaches only 49.3% accuracy and all other models stay below 31%, despite the dataset's simplicity. Web search consistently yields substantial gains and using code interpreter shows mixed effects, but all models perform much better when constraints are rewritten with explicit dates, revealing a gap in reliable tool use. Overall, TimePuzzles presents a simple, cost-effective diagnostic for tool-augmented iterative temporal reasoning.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.150907",
        "filter_reason": "论文提出了TimePuzzles基准，专门用于评估LLM在迭代时间推理中的工具使用能力（如Web搜索和代码解释器），并指出了可靠工具使用方面的差距，属于单智能体中的工具使用研究范畴。"
    },
    {
        "index": "#53",
        "title": "ReMIND: Orchestrating Modular Large Language Models for Controllable Serendipity A REM-Inspired System Design for Emergent Creative Ideation",
        "link": "/arxiv/2601.07121",
        "arxiv_id": "2601.07121",
        "authors": "Makoto Sato",
        "summary": "Large language models (LLMs) are used not only for problem solving but also for creative ideation; however, eliciting serendipitous insights that are both novel and internally coherent remains difficult. While stochastic sampling promotes novelty, it often degrades consistency. Here, we propose ReMIND, a REM-inspired modular framework for ideation. ReMIND consists of four stages: wake, which generates a stable low-temperature semantic baseline; dream, which performs high-temperature exploratory generation; judge, which applies coarse evaluation to filter incoherent outputs and extract candidate ideas; and re-wake, which re-articulates selected ideas into coherent final outputs. By instantiating each stage as an independent LLM, ReMIND enables functional separation between exploration and consolidation. Parameter sweeps show that ReMIND reliably induces semantic exploration while preserving downstream stability. Embedding-based analyses confirm substantial semantic displacement during the dream phase, whereas external evaluations reveal that high-quality ideas emerge sporadically rather than as extrema along any single metric. These results suggest that serendipitous ideation in LLMs is a rare-event process best approached through system level design that shapes the conditions under which valuable ideas can emerge and be stabilized. ReMIND provides a general framework for studying the computational basis of serendipity and illustrates how modular LLM orchestration can bridge exploration and stabilization.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.151333",
        "filter_reason": "论文提出的ReMIND框架通过编排多个独立的LLM模块（wake, dream, judge, re-wake）来执行创意构思任务。这种架构包含了工作流规划、自我评估（judge阶段）以及基于反馈的迭代完善（re-wake阶段），符合单智能体中关于规划、自我反思及模块化设计的定义。"
    },
    {
        "index": "#66",
        "title": "LLMs Can't Play Hangman: On the Necessity of a Private Working Memory for Language Agents",
        "link": "/arxiv/2601.06973",
        "arxiv_id": "2601.06973",
        "authors": "Davide Baldelli, Ali Parviz, Amal Zouaq, Sarath Chandar",
        "summary": "As LLMs move from text completion toward autonomous agents, they remain constrained by the standard chat interface, which lacks private working memory. This raises a fundamental question: can agents reliably perform interactive tasks that depend on hidden state? We define Private State Interactive Tasks (PSITs), which require agents to generate and maintain hidden information while producing consistent public responses. We show theoretically that any agent restricted to the public conversation history cannot simultaneously preserve secrecy and consistency in PSITs, yielding an impossibility theorem. To empirically validate this limitation, we introduce a self-consistency testing protocol that evaluates whether agents can maintain a hidden secret across forked dialogue branches. Standard chat-based LLMs and retrieval-based memory baselines fail this test regardless of scale, demonstrating that semantic retrieval does not enable true state maintenance. To address this, we propose a novel architecture incorporating an explicit private working memory; we demonstrate that this mechanism restores consistency, establishing private state as a necessary component for interactive language agents.",
        "subjects": "Computation and Language",
        "date": "2026-01-11",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.168497",
        "filter_reason": "该论文聚焦于语言智能体的架构设计，特别是针对“记忆”这一核心组件进行了深入研究。它提出了私有工作记忆的概念，以解决智能体在交互任务中维护隐藏状态的问题，属于单智能体研究中的记忆机制范畴。"
    },
    {
        "index": "#68",
        "title": "RealMem: Benchmarking LLMs in Real-World Memory-Driven Interaction",
        "link": "/arxiv/2601.06966",
        "arxiv_id": "2601.06966",
        "authors": "Haonan Bian, Zhiyuan Yao, Sen Hu, Zishan Xu, Shaolei Zhang, Yifu Guo, Ziliang Yang, Xueran Han, Huacan Wang, Ronghao Chen",
        "summary": "As Large Language Models (LLMs) evolve from static dialogue interfaces to autonomous general agents, effective memory is paramount to ensuring long-term consistency. However, existing benchmarks primarily focus on casual conversation or task-oriented dialogue, failing to capture **\"long-term project-oriented\"** interactions where agents must track evolving goals. To bridge this gap, we introduce **RealMem**, the first benchmark grounded in realistic project scenarios. RealMem comprises over 2,000 cross-session dialogues across eleven scenarios, utilizing natural user queries for evaluation. We propose a synthesis pipeline that integrates Project Foundation Construction, Multi-Agent Dialogue Generation, and Memory and Schedule Management to simulate the dynamic evolution of memory. Experiments reveal that current memory systems face significant challenges in managing the long-term project states and dynamic context dependencies inherent in real-world projects. Our code and datasets are available at [https://github.com/AvatarMemory/RealMemBench](https://github.com/AvatarMemory/RealMemBench).",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.169635",
        "filter_reason": "该论文提出了针对LLM智能体在长期项目导向交互中的记忆能力的基准测试（RealMem），明确涉及智能体的记忆机制（单智能体范畴）以及多智能体对话生成（多智能体范畴），符合LLM智能体的研究范围。"
    },
    {
        "index": "#71",
        "title": "TreePS-RAG: Tree-based Process Supervision for Reinforcement Learning in Agentic RAG",
        "link": "/arxiv/2601.06922",
        "arxiv_id": "2601.06922",
        "authors": "Tianhua Zhang, Kun Li, Junan Li, Yunxiang Li, Hongyin Luo, Xixin Wu, James Glass, Helen Meng",
        "summary": "Agentic retrieval-augmented generation (RAG) formulates question answering as a multi-step interaction between reasoning and information retrieval, and has recently been advanced by reinforcement learning (RL) with outcome-based supervision. While effective, relying solely on sparse final rewards limits step-wise credit assignment and provides weak guidance for intermediate reasoning and actions. Recent efforts explore process-level supervision, but typically depend on offline constructed training data, which risks distribution shift, or require costly intermediate annotations. We present TreePS-RAG, an online, tree-based RL framework for agentic RAG that enables step-wise credit assignment while retaining standard outcome-only rewards. Our key insight is to model agentic RAG reasoning as a rollout tree, where each reasoning step naturally maps to a node. This tree structure allows step utility to be estimated via Monte Carlo estimation over its descendant outcomes, yielding fine-grained process advantages without requiring intermediate labels. To make this paradigm practical, we introduce an efficient online tree construction strategy that preserves exploration diversity under a constrained computational budget. With a rollout cost comparable to strong baselines like Search-R1, experiments on seven multi-hop and general QA benchmarks across multiple model scales show that TreePS-RAG consistently and significantly outperforms both outcome-supervised and leading process-supervised RL methods.",
        "subjects": "Computation and Language",
        "date": "2026-01-11",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.171134",
        "filter_reason": "论文明确研究“Agentic RAG”，将问答视为推理与检索工具之间的多步交互过程。提出的TreePS-RAG框架利用强化学习和树结构优化智能体的决策（规划与工具使用），属于单智能体研究范畴。"
    },
    {
        "index": "#79",
        "title": "AgentHallu: Benchmarking Automated Hallucination Attribution of LLM-based Agents",
        "link": "/arxiv/2601.06818",
        "arxiv_id": "2601.06818",
        "authors": "Xuannan Liu, Xiao Yang, Zekun Li, Peipei Li, Ran He",
        "summary": "As LLM-based agents operate over sequential multi-step reasoning, hallucinations arising at intermediate steps risk propagating along the trajectory, thus degrading overall reliability. Unlike hallucination detection in single-turn responses, diagnosing hallucinations in multi-step workflows requires identifying which step causes the initial divergence. To fill this gap, we propose a new research task, automated hallucination attribution of LLM-based agents, aiming to identify the step responsible for the hallucination and explain why. To support this task, we introduce AgentHallu, a comprehensive benchmark with: (1) 693 high-quality trajectories spanning 7 agent frameworks and 5 domains, (2) a hallucination taxonomy organized into 5 categories (Planning, Retrieval, Reasoning, Human-Interaction, and Tool-Use) and 14 sub-categories, and (3) multi-level annotations curated by humans, covering binary labels, hallucination-responsible steps, and causal explanations. We evaluate 13 leading models, and results show the task is challenging even for top-tier models (like GPT-5, Gemini-2.5-Pro). The best-performing model achieves only 41.1\\% step localization accuracy, where tool-use hallucinations are the most challenging at just 11.6\\%. We believe AgentHallu will catalyze future research into developing robust, transparent, and reliable agentic systems.",
        "subjects": "Computation and Language",
        "date": "2026-01-11",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.180163",
        "filter_reason": "该论文专注于LLM智能体的评估和基准测试，特别是解决多步骤工作流中的幻觉问题。它直接涉及“单智能体”研究范围，通过分析“规划”和“工具使用”中的错误。虽然它涉及诊断（类似于可解释性），但其主要贡献是针对智能体可靠性的基准，而不是一般的安全/对齐或纯应用。"
    },
    {
        "index": "#92",
        "title": "IDRBench: Interactive Deep Research Benchmark",
        "link": "/arxiv/2601.06676",
        "arxiv_id": "2601.06676",
        "authors": "Yingchaojie Feng, Qiang Huang, Xiaoya Xie, Zhaorui Yang, Jun Yu, Wei Chen, Anthony K. H. Tung",
        "summary": "Deep research agents powered by Large Language Models (LLMs) can perform multi-step reasoning, web exploration, and long-form report generation. However, most existing systems operate in an autonomous manner, assuming fully specified user intent and evaluating only final outputs. In practice, research goals are often underspecified and evolve during exploration, making sustained interaction essential for robust alignment. Despite its importance, interaction remains largely invisible to existing deep research benchmarks, which neither model dynamic user feedback nor quantify its costs. We introduce IDRBench, the first benchmark for systematically evaluating interactive deep research. IDRBench combines a modular multi-agent research framework with on-demand interaction, a scalable reference-grounded user simulator, and an interaction-aware evaluation suite that jointly measures interaction benefits (quality and alignment) and costs (turns and tokens). Experiments across seven state-of-the-art LLMs show that interaction consistently improves research quality and robustness, often outweighing differences in model capacity, while revealing substantial trade-offs in interaction efficiency.",
        "subjects": "Computation and Language, Artificial Intelligence, Human-Computer Interaction",
        "date": "2026-01-10",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.191626",
        "filter_reason": "论文明确研究“深度研究智能体”，并提出了“模块化多智能体研究框架”。内容涉及Web探索（工具使用）、多步推理（规划）以及动态用户反馈交互（符合智能体与用户交互/反馈机制）。属于多智能体及单智能体工具使用的研究范畴，不属于纯应用或纯推理。"
    },
    {
        "index": "#99",
        "title": "MedEinst: Benchmarking the Einstellung Effect in Medical LLMs through Counterfactual Differential Diagnosis",
        "link": "/arxiv/2601.06636",
        "arxiv_id": "2601.06636",
        "authors": "Wenting Chen, Zhongrui Zhu, Guolin Huang, Wenxuan Wang",
        "summary": "Despite achieving high accuracy on medical benchmarks, LLMs exhibit the Einstellung Effect in clinical diagnosis--relying on statistical shortcuts rather than patient-specific evidence, causing misdiagnosis in atypical cases. Existing benchmarks fail to detect this critical failure mode. We introduce MedEinst, a counterfactual benchmark with 5,383 paired clinical cases across 49 diseases. Each pair contains a control case and a \"trap\" case with altered discriminative evidence that flips the diagnosis. We measure susceptibility via Bias Trap Rate--probability of misdiagnosing traps despite correctly diagnosing controls. Extensive Evaluation of 17 LLMs shows frontier models achieve high baseline accuracy but severe bias trap rates. Thus, we propose ECR-Agent, aligning LLM reasoning with Evidence-Based Medicine standard via two components: (1) Dynamic Causal Inference (DCI) performs structured reasoning through dual-pathway perception, dynamic causal graph reasoning across three levels (association, intervention, counterfactual), and evidence audit for final diagnosis; (2) Critic-Driven Graph and Memory Evolution (CGME) iteratively refines the system by storing validated reasoning paths in an exemplar base and consolidating disease-specific knowledge into evolving illness graphs. Source code is to be released.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.216039",
        "filter_reason": "论文提出了ECR-Agent，该智能体架构包含记忆（存储验证后的推理路径）和自我演化（Critic-Driven Graph and Memory Evolution）机制，符合单智能体和自我演化的研究范围，并非单纯的领域应用。"
    },
    {
        "index": "#122",
        "title": "Structured Episodic Event Memory",
        "link": "/arxiv/2601.06411",
        "arxiv_id": "2601.06411",
        "authors": "Zhengxuan Lu, Dongfang Li, Yukun Shi, Beilun Wang, Longyue Wang, Baotian Hu",
        "summary": "Current approaches to memory in Large Language Models (LLMs) predominantly rely on static Retrieval-Augmented Generation (RAG), which often results in scattered retrieval and fails to capture the structural dependencies required for complex reasoning. For autonomous agents, these passive and flat architectures lack the cognitive organization necessary to model the dynamic and associative nature of long-term interaction. To address this, we propose Structured Episodic Event Memory (SEEM), a hierarchical framework that synergizes a graph memory layer for relational facts with a dynamic episodic memory layer for narrative progression. Grounded in cognitive frame theory, SEEM transforms interaction streams into structured Episodic Event Frames (EEFs) anchored by precise provenance pointers. Furthermore, we introduce an agentic associative fusion and Reverse Provenance Expansion (RPE) mechanism to reconstruct coherent narrative contexts from fragmented evidence. Experimental results on the LoCoMo and LongMemEval benchmarks demonstrate that SEEM significantly outperforms baselines, enabling agents to maintain superior narrative coherence and logical consistency.",
        "subjects": "Computation and Language",
        "date": "2026-01-10",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.239013",
        "filter_reason": "论文提出了结构化情景事件记忆（SEEM）框架，旨在解决自主智能体在长期交互中的记忆组织问题，属于单智能体研究中的“记忆”范畴，且不涉及纯应用、纯推理或基础设施优化等排除领域。"
    },
    {
        "index": "#123",
        "title": "Value of Information: A Framework for Human-Agent Communication",
        "link": "/arxiv/2601.06407",
        "arxiv_id": "2601.06407",
        "authors": "Yijiang River Dong, Tiancheng Hu, Zheng Hui, Caiqi Zhang, Ivan Vulić, Andreea Bobu, Nigel Collier",
        "summary": "Large Language Model (LLM) agents deployed for real-world tasks face a fundamental dilemma: user requests are underspecified, yet agents must decide whether to act on incomplete information or interrupt users for clarification. Existing approaches either rely on brittle confidence thresholds that require task-specific tuning, or fail to account for the varying stakes of different decisions. We introduce a decision-theoretic framework that resolves this trade-off through the Value of Information (VoI), enabling agents to dynamically weigh the expected utility gain from asking questions against the cognitive cost imposed on users. Our inference-time method requires no hyperparameter tuning and adapts seamlessly across contexts-from casual games to medical diagnosis. Experiments across four diverse domains (20 Questions, medical diagnosis, flight booking, and e-commerce) show that VoI consistently matches or exceeds the best manually-tuned baselines, achieving up to 1.36 utility points higher in high-cost settings. This work provides a parameter-free framework for adaptive agent communication that explicitly balances task risk, query ambiguity, and user effort.",
        "subjects": "Computation and Language",
        "date": "2026-01-10",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.239531",
        "filter_reason": "该论文提出了一个基于信息价值的决策论框架，用于解决LLM智能体在行动与向用户提问之间的决策问题。这属于单智能体范畴中的决策与通信机制研究，核心贡献是智能体的方法论改进，而非纯应用。"
    },
    {
        "index": "#137",
        "title": "Amory: Building Coherent Narrative-Driven Agent Memory through Agentic Reasoning",
        "link": "/arxiv/2601.06282",
        "arxiv_id": "2601.06282",
        "authors": "Yue Zhou, Xiaobo Guo, Belhassen Bayar, Srinivasan H. Sengamedu",
        "summary": "Long-term conversational agents face a fundamental scalability challenge as interactions extend over time: repeatedly processing entire conversation histories becomes computationally prohibitive. Current approaches attempt to solve this through memory frameworks that predominantly fragment conversations into isolated embeddings or graph representations and retrieve relevant ones in a RAG style. While computationally efficient, these methods often treat memory formation minimally and fail to capture the subtlety and coherence of human memory. We introduce Amory, a working memory framework that actively constructs structured memory representations through enhancing agentic reasoning during offline time. Amory organizes conversational fragments into episodic narratives, consolidates memories with momentum, and semanticizes peripheral facts into semantic memory. At retrieval time, the system employs coherence-driven reasoning over narrative structures. Evaluated on the LOCOMO benchmark for long-term reasoning, Amory achieves considerable improvements over previous state-of-the-art, with performance comparable to full context reasoning while reducing response time by 50%. Analysis shows that momentum-aware consolidation significantly enhances response quality, while coherence-driven retrieval provides superior memory coverage compared to embedding-based approaches.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.256548",
        "filter_reason": "论文提出了 Amory，这是一个针对长期对话智能体的工作记忆框架。它专注于通过智能体推理构建结构化记忆表征（情景和语义记忆），这直接属于单智能体研究范围中的“记忆”类别。"
    },
    {
        "index": "#143",
        "title": "Operation Veja: Fixing Fundamental Concepts Missing from Modern Roleplaying Training Paradigms",
        "link": "/arxiv/2601.06039",
        "arxiv_id": "2601.06039",
        "authors": "Yueze Liu, Ajay Nagi Reddy Kumdam, Ronit Kanjilal, Hao Yang, Yichi Zhang",
        "summary": "Modern roleplaying models are increasingly sophisticated, yet they consistently struggle to capture the essence of believable, engaging characters. We argue this failure stems from training paradigms that overlook the dynamic interplay of a character's internal world. Current approaches, including Retrieval-Augmented Generation (RAG), fact-based priming, literature-based learning, and synthetic data generation, exhibit recurring limitations in modeling the deliberative, value-conflicted reasoning that defines human interaction. In this paper, we identify four core concepts essential for character authenticity: Values, Experiences, Judgments, and Abilities (VEJA). We propose the VEJA framework as a new paradigm for data curation that addresses these systemic limitations. To illustrate the qualitative ceiling enabled by our framework, we present a pilot study comparing a manually curated, VEJA-grounded dataset against a state-of-the-art synthetic baseline. Using an LLM-as-judge evaluation, our findings demonstrate a significant quality gap, suggesting that a shift toward conceptually grounded data curation, as embodied by VEJA, is necessary for creating roleplaying agents with genuine depth and narrative continuity. The full dataset is available at https://github.com/HyouinKyoumaIRL/Operation-Veja",
        "subjects": "Computation and Language",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.259510",
        "filter_reason": "该论文明确研究“角色扮演智能体”，提出的VEJA框架旨在通过优化数据来增强智能体的内部状态（价值观、经历、判断、能力）。这属于单智能体范畴，涉及智能体的记忆（经历）和自我反思/推理（判断），旨在提升智能体的行为一致性和深度，符合筛选条件。"
    },
    {
        "index": "#145",
        "title": "OS-Symphony: A Holistic Framework for Robust and Generalist Computer-Using Agent",
        "link": "/arxiv/2601.07779",
        "arxiv_id": "2601.07779",
        "authors": "Bowen Yang, Kaiming Jin, Zhenyu Wu, Zhaoyang Liu, Qiushi Sun, Zehao Li, JingJing Xie, Zhoumianze Liu, Fangzhi Xu, Kanzhi Cheng, Qingyun Li, Yian Wang, Yu Qiao, Zun Wang, Zichen Ding",
        "summary": "While Vision-Language Models (VLMs) have significantly advanced Computer-Using Agents (CUAs), current frameworks struggle with robustness in long-horizon workflows and generalization in novel domains. These limitations stem from a lack of granular control over historical visual context curation and the absence of visual-aware tutorial retrieval. To bridge these gaps, we introduce OS-Symphony, a holistic framework that comprises an Orchestrator coordinating two key innovations for robust automation: (1) a Reflection-Memory Agent that utilizes milestone-driven long-term memory to enable trajectory-level self-correction, effectively mitigating visual context loss in long-horizon tasks; (2) Versatile Tool Agents featuring a Multimodal Searcher that adopts a SeeAct paradigm to navigate a browser-based sandbox to synthesize live, visually aligned tutorials, thereby resolving fidelity issues in unseen scenarios. Experimental results demonstrate that OS-Symphony delivers substantial performance gains across varying model scales, establishing new state-of-the-art results on three online benchmarks, notably achieving 65.84% on OSWorld.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Human-Computer Interaction",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.265983",
        "filter_reason": "该论文提出了一个计算机使用智能体框架，核心研究内容包括单智能体的记忆、自我反思和工具使用，符合LLM智能体的研究范围。尽管涉及视觉模型，但重点在于智能体架构而非视觉模型本身。"
    },
    {
        "index": "#144",
        "title": "TeleMem: Building Long-Term and Multimodal Memory for Agentic AI",
        "link": "/arxiv/2601.06037",
        "arxiv_id": "2601.06037",
        "authors": "Chunliang Chen, Ming Guan, Xiao Lin, Jiaxu Li, Qiyi Wang, Xiangyu Chen, Jixiang Luo, Changzhi Sun, Dell Zhang, Xuelong Li",
        "summary": "Large language models (LLMs) excel at many NLP tasks but struggle to sustain long-term interactions due to limited attention over extended dialogue histories. Retrieval-augmented generation (RAG) mitigates this issue but lacks reliable mechanisms for updating or refining stored memories, leading to schema-driven hallucinations, inefficient write operations, and minimal support for multimodal reasoning.To address these challenges, we propose TeleMem, a unified long-term and multimodal memory system that maintains coherent user profiles through narrative dynamic extraction, ensuring that only dialogue-grounded information is preserved. TeleMem further introduces a structured writing pipeline that batches, retrieves, clusters, and consolidates memory entries, substantially improving storage efficiency, reducing token usage, and accelerating memory operations. Additionally, a multimodal memory module combined with ReAct-style reasoning equips the system with a closed-loop observe, think, and act process that enables accurate understanding of complex video content in long-term contexts. Experimental results show that TeleMem surpasses the state-of-the-art Mem0 baseline with 19% higher accuracy, 43% fewer tokens, and a 2.1x speedup on the ZH-4O long-term role-play gaming benchmark.",
        "subjects": "Computation and Language, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.260081",
        "filter_reason": "该论文提出了TeleMem，这是一个专门为Agentic AI设计的长程和多模态记忆系统。它直接属于“单智能体”研究范围中的“记忆”和“工具使用”（ReAct-style reasoning）范畴。虽然涉及多模态内容，但其核心贡献在于智能体的记忆机制与架构，而非单纯的多模态模型研究，因此符合筛选要求。"
    },
    {
        "index": "#148",
        "title": "Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning",
        "link": "/arxiv/2601.07641",
        "arxiv_id": "2601.07641",
        "authors": "Jiaxuan Lu, Ziyu Kong, Yemin Wang, Rong Fu, Haiyuan Wan, Cheng Yang, Wenjie Lou, Haoran Sun, Lilong Wang, Yankai Jiang, Xiaosong Wang, Xiao Sun, Dongzhan Zhou",
        "summary": "The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.",
        "subjects": "Artificial Intelligence, Computation and Language, Multiagent Systems",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.267575",
        "filter_reason": "论文明确研究LLM智能体，提出了“测试时工具演化”（TTE）范式，使智能体能够在推理过程中合成、验证和演化可执行工具。这属于单智能体的工具使用和自我演化范畴，且侧重于智能体机制本身的改进而非纯领域应用。"
    },
    {
        "index": "#154",
        "title": "Lost in the Noise: How Reasoning Models Fail with Contextual Distractors",
        "link": "/arxiv/2601.07226",
        "arxiv_id": "2601.07226",
        "authors": "Seongyun Lee, Yongrae Jo, Minju Seo, Moontae Lee, Minjoon Seo",
        "summary": "Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current sanitized benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. We find that prompting, context engineering, SFT, and outcome-reward only RL fail to ensure robustness; in contrast, our proposed Rationale-Aware Reward (RARE) significantly strengthens resilience by incentivizing the identification of helpful information within noise. Finally, we uncover an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrate via attention visualization that models disproportionately focus on distractor tokens, providing vital insights for building the next generation of robust, reasoning-capable agents.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.270711",
        "filter_reason": "论文明确研究了智能体AI系统和工作流，评估了工具使用和RAG任务，并分析了智能体在嘈杂环境下的鲁棒性，符合单智能体（工具使用）的研究范围。"
    },
    {
        "index": "#152",
        "title": "LRAS: Advanced Legal Reasoning with Agentic Search",
        "link": "/arxiv/2601.07296",
        "arxiv_id": "2601.07296",
        "authors": "Yujin Zhou, Chuxue Cao, Jinluan Yang, Lijun Wu, Conghui He, Sirui Han, Yike Guo",
        "summary": "While Large Reasoning Models (LRMs) have demonstrated exceptional logical capabilities in mathematical domains, their application to the legal field remains hindered by the strict requirements for procedural rigor and adherence to legal logic. Existing legal LLMs, which rely on \"closed-loop reasoning\" derived solely from internal parametric knowledge, frequently suffer from lack of self-awareness regarding their knowledge boundaries, leading to confident yet incorrect conclusions. To address this challenge, we present Legal Reasoning with Agentic Search (LRAS), the first framework designed to transition legal LLMs from static and parametric \"closed-loop thinking\" to dynamic and interactive \"Active Inquiry\". By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32\\%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. We will release our data and models for further exploration soon.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2026-01-12",
        "category": "cs.CL",
        "crawl_time": "2026-01-13T14:06:31.269735",
        "filter_reason": "该论文提出了LRAS框架，核心在于将法律大模型从静态的“闭环推理”转变为动态的“主动询问”，这涉及智能体的工具使用和交互能力。同时，论文引入了内省模仿学习和难度感知强化学习，分别对应智能体的自我反思和自我演化机制。尽管论文应用于法律领域，但其主要贡献在于提出了新的智能体搜索与演化框架，而非单纯的应用落地，因此符合LLM智能体的研究范围。"
    },
    {
        "index": "#8",
        "title": "Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents",
        "link": "/arxiv/2601.07577",
        "arxiv_id": "2601.07577",
        "authors": "Yunfan Li, Bingbing Xu, Xueyun Tian, Xiucheng Xu, Huawei Shen",
        "summary": "Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.576279",
        "filter_reason": "该论文专注于解决长视界LLM智能体的规划问题，提出了包含Supervisor、Planner和Executor的框架来优化任务分解与执行，属于单智能体研究中的“规划”范畴，符合筛选条件。"
    },
    {
        "index": "#7",
        "title": "DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning",
        "link": "/arxiv/2601.07611",
        "arxiv_id": "2601.07611",
        "authors": "Zhuoyang Zou, Abolfazl Ansari, Delvin Ce Zhang, Dongwon Lee, Wenpeng Yin",
        "summary": "Paper weakness identification using single-agent or multi-agent LLMs has attracted increasing attention, yet existing approaches exhibit key limitations. Many multi-agent systems simulate human roles at a surface level, missing the underlying criteria that lead experts to assess complementary intellectual aspects of a paper. Moreover, prior methods implicitly assume identified weaknesses are valid, ignoring reviewer bias, misunderstanding, and the critical role of author rebuttals in validating review quality. Finally, most systems output unranked weakness lists, rather than prioritizing the most consequential issues for users. In this work, we propose DIAGPaper, a novel multi-agent framework that addresses these challenges through three tightly integrated modules. The customizer module simulates human-defined review criteria and instantiates multiple reviewer agents with criterion-specific expertise. The rebuttal module introduces author agents that engage in structured debate with reviewer agents to validate and refine proposed weaknesses. The prioritizer module learns from large-scale human review practices to assess the severity of validated weaknesses and surfaces the top-K severest ones to users. Experiments on two benchmarks, AAAR and ReviewCritique, demonstrate that DIAGPaper substantially outperforms existing methods by producing more valid and more paper-specific weaknesses, while presenting them in a user-oriented, prioritized manner.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.575981",
        "filter_reason": "该论文提出了DIAGPaper，这是一个多智能体框架，包含评审智能体和作者智能体，通过结构化辩论（协作与通信）来识别和验证论文弱点，属于多智能体协作与通信的研究范围。"
    },
    {
        "index": "#10",
        "title": "JudgeFlow: Agentic Workflow Optimization via Block Judge",
        "link": "/arxiv/2601.07477",
        "arxiv_id": "2601.07477",
        "authors": "Zihan Ma, Zhikai Zhao, Chuanbo Hua, Federico Berto, Jinkyoo Park",
        "summary": "Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose {\\our{}}, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces -- particularly failed runs -- and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate {\\our{}} on mathematical reasoning and code generation benchmarks, where {\\our{}} achieves superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.576983",
        "filter_reason": "论文明确研究基于LLM的智能体工作流优化，提出了包含Judge模块和优化器的流水线，通过分析执行轨迹和反馈来修改工作流中的逻辑块，属于单智能体的自我反思与自我演化范畴。"
    },
    {
        "index": "#11",
        "title": "Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory",
        "link": "/arxiv/2601.07470",
        "arxiv_id": "2601.07470",
        "authors": "Sirui Liang, Pengfei Cao, Jian Zhao, Wenhao Teng, Xiangwen Liao, Jun Zhao, Kang Liu",
        "summary": "Large language model (LLM) agents increasingly rely on accumulated memory to solve long-horizon decision-making tasks. However, most existing approaches store memory in fixed representations and reuse it at a single or implicit level of abstraction, which limits generalization and often leads to negative transfer when distribution shift. This paper proposes the Meta-Cognitive Memory Abstraction method (MCMA), which treats memory abstraction as a learnable cognitive skill rather than a fixed design choice. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization, it determines how memories should be structured, abstracted, and reused. Memories are further organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.577332",
        "filter_reason": "该论文明确研究LLM智能体的记忆管理机制，提出了Meta-Cognitive Memory Abstraction (MCMA)方法来改进智能体的记忆结构、抽象和重用能力，属于单智能体研究中的“记忆”范畴。"
    },
    {
        "index": "#13",
        "title": "Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents",
        "link": "/arxiv/2601.07468",
        "arxiv_id": "2601.07468",
        "authors": "Miao Su, Yucan Guo, Zhongni Hou, Long Bai, Zixuan Li, Yufei Zhang, Guojun Yin, Wei Lin, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",
        "summary": "Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. However, existing methods fail to properly model the temporal dimension of memory in two aspects: 1) Temporal inaccuracy: memories are organized by dialogue time rather than their actual occurrence time; 2) Temporal fragmentation: existing methods focus on point-wise memory, losing durative information that captures persistent states and evolving patterns. To address these limitations, we propose Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. During memory construction, it first builds a semantic timeline rather than a dialogue one. Then, it consolidates temporally continuous and semantically related information into a durative memory. During memory utilization, it incorporates the query's temporal intent on the semantic timeline, enabling the retrieval of temporally appropriate durative memories and providing time-valid, duration-consistent context to support response generation. Experiments on LongMemEval and LoCoMo show that TSM consistently outperforms existing methods and achieves up to 12.2% absolute improvement in accuracy, demonstrating the effectiveness of the proposed method.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.577995",
        "filter_reason": "该论文明确研究LLM智能体的“记忆”机制，提出了时序语义记忆（TSM）框架以解决现有方法在时序建模上的不足，属于单智能体研究范围中的“记忆”方向，且不涉及被排除的纯应用、纯推理或安全等领域。"
    },
    {
        "index": "#19",
        "title": "Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure",
        "link": "/arxiv/2601.07342",
        "arxiv_id": "2601.07342",
        "authors": "Nicolas Tacheny",
        "summary": "Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis(RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model. In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. We define an investigation protocol that structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information. This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures, but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.581078",
        "filter_reason": "论文提出了一个LLM智能体框架，重点研究了智能体如何通过工具使用（Tool Use）和规划（Planning）来自主执行诊断任务。这符合单智能体中关于工具使用和规划的研究范围，且侧重于智能体架构与协议的设计，不属于排除的纯应用或基础设施优化（指AI系统部署）范畴。"
    },
    {
        "index": "#20",
        "title": "ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging",
        "link": "/arxiv/2601.07309",
        "arxiv_id": "2601.07309",
        "authors": "Zhuoka Feng, Kang Chen, Sihan Zhao, Kai Xiong, Yaoning Wang, Minshen Yu, Junjie Nian, Changyi Xiao, Yixin Cao, Yugang Jiang",
        "summary": "Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.581474",
        "filter_reason": "该论文提出了Agent-Role Merging (ARM)方法，专注于将多个专家模型合并为一个通用的LLM智能体，旨在提升智能体在不同交互环境中的泛化能力。这直接涉及LLM智能体的核心架构与能力提升，不属于排除的纯应用、纯推理、安全或基础设施优化范畴。"
    },
    {
        "index": "#28",
        "title": "Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration",
        "link": "/arxiv/2601.07224",
        "arxiv_id": "2601.07224",
        "authors": "Yang Zhao, Yangou Ouyang, Xiao Ding, Hepeng Wang, Bibo Cai, Kai Xiong, Jinglong Gao, Zhouhao Sun, Li Du, Bing Qin, Ting Liu",
        "summary": "While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. We propose PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the model's existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22$\\times$. Our findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.584161",
        "filter_reason": "论文明确研究LLM智能体的训练范式（SFT与RL的结合），提出了基于梯度浓度的数据分配框架以优化智能体的学习过程。论文在WebShop和ALFWorld等智能体基准上进行了验证，属于智能体的自我演化与训练优化范畴，不属于排除的纯应用、纯推理或基础设施优化类别。"
    },
    {
        "index": "#30",
        "title": "Active Context Compression: Autonomous Memory Management in LLM Agents",
        "link": "/arxiv/2601.07190",
        "arxiv_id": "2601.07190",
        "authors": "Nikhil Verma",
        "summary": "Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to \"Context Bloat.\" As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors. Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control. This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold). The Focus Agent autonomously decides when to consolidate key learnings into a persistent \"Knowledge\" block and actively withdraws (prunes) the raw interaction history. Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents). Focus performed 6.0 autonomous compressions per task on average, with token savings up to 57% on individual instances. We demonstrate that capable models can autonomously self-regulate their context when given appropriate tools and prompting, opening pathways for cost-aware agentic systems without sacrificing task performance.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.587948",
        "filter_reason": "该论文提出了Focus架构，专注于LLM智能体的自主记忆管理（将关键学习内容整合到持久知识块中），属于单智能体研究中的“记忆”和“自我反思”范畴。虽然涉及软件工程任务，但核心贡献在于智能体架构而非纯应用。"
    },
    {
        "index": "#35",
        "title": "Dr. Zero: Self-Evolving Search Agents without Training Data",
        "link": "/arxiv/2601.07055",
        "arxiv_id": "2601.07055",
        "authors": "Zhenrui Yue, Kartikeya Upasani, Xianjun Yang, Suyu Ge, Shaoliang Nie, Yuning Mao, Zhe Liu, Dong Wang",
        "summary": "As high-quality data becomes increasingly difficult to obtain, data-free self-evolution has emerged as a promising paradigm. This approach allows large language models (LLMs) to autonomously generate and solve complex problems, thereby improving their reasoning capabilities. However, multi-turn search agents struggle in data-free self-evolution due to the limited question diversity and the substantial compute required for multi-step reasoning and tool using. In this work, we introduce Dr. Zero, a framework enabling search agents to effectively self-evolve without any training data. In particular, we design a self-evolution feedback loop where a proposer generates diverse questions to train a solver initialized from the same base model. As the solver evolves, it incentivizes the proposer to produce increasingly difficult yet solvable tasks, thus establishing an automated curriculum to refine both agents. To enhance training efficiency, we also introduce hop-grouped relative policy optimization (HRPO). This method clusters structurally similar questions to construct group-level baselines, effectively minimizing the sampling overhead in evaluating each query's individual difficulty and solvability. Consequently, HRPO significantly reduces the compute requirements for solver training without compromising performance or stability. Extensive experiment results demonstrate that the data-free Dr. Zero matches or surpasses fully supervised search agents, proving that complex reasoning and search capabilities can emerge solely through self-evolution.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.590905",
        "filter_reason": "论文标题和摘要明确提出了“Self-Evolving Search Agents”（自我演化的搜索智能体），重点研究智能体如何在没有训练数据的情况下通过反馈循环进行自我完善，并涉及工具使用，完全符合研究范围中的“自我演化”和“单智能体（工具使用）”类别。"
    },
    {
        "index": "#41",
        "title": "ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration",
        "link": "/arxiv/2601.06860",
        "arxiv_id": "2601.06860",
        "authors": "Yifei Chen, Guanting Dong, Zhicheng Dou",
        "summary": "Large Language Models (LLMs) can extend their parameter knowledge limits by adopting the Tool-Integrated Reasoning (TIR) paradigm. However, existing LLM-based agent training framework often focuses on answers' accuracy, overlooking specific alignment for behavior patterns. Consequently, agent often exhibits ineffective actions during TIR tasks, such as redundant and insufficient tool calls. How to calibrate erroneous behavioral patterns when executing TIR tasks, thereby exploring effective trajectories, remains an open-ended problem. In this paper, we propose ET-Agent, a training framework for calibrating agent's tool-use behavior through two synergistic perspectives: Self-evolving Data Flywheel and Behavior Calibration Training. Specifically, we introduce a self-evolutionary data flywheel to generate enhanced data, used to fine-tune LLM to improve its exploration ability. Based on this, we implement an two-phases behavior-calibration training framework. It is designed to progressively calibrate erroneous behavioral patterns to optimal behaviors. Further in-depth experiments confirm the superiority of \\ourmodel{} across multiple dimensions, including correctness, efficiency, reasoning conciseness, and tool execution accuracy. Our ET-Agent framework provides practical insights for research in the TIR field. Codes can be found in https://github.com/asilverlight/ET-Agent",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.597409",
        "filter_reason": "该论文提出了ET-Agent框架，专注于LLM智能体的工具使用行为校准。它涉及单智能体的工具使用能力，并引入了自我演化数据飞轮机制，符合单智能体（工具使用）和自我演化的研究范围。"
    },
    {
        "index": "#47",
        "title": "No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning",
        "link": "/arxiv/2601.06794",
        "arxiv_id": "2601.06794",
        "authors": "Zhicong Li, Lingjie Jiang, Yulan Hu, Xingchen Zeng, Yixia Li, Xiangwen Zhang, Guanhua Chen, Zheng Pan, Xin Li, Yong Liu",
        "summary": "Critique-guided reinforcement learning (RL) has emerged as a powerful paradigm for training LLM agents by augmenting sparse outcome rewards with natural-language feedback. However, current methods often rely on static or offline critic models, which fail to adapt as the policy evolves. In on-policy RL, the agent's error patterns shift over time, causing stationary critics to become stale and providing feedback of diminishing utility. To address this, we introduce ECHO (Evolving Critic for Hindsight-Guided Optimization)}, a framework that jointly optimizes the policy and critic through a synchronized co-evolutionary loop. ECHO utilizes a cascaded rollout mechanism where the critic generates multiple diagnoses for an initial trajectory, followed by policy refinement to enable group-structured advantage estimation. We address the challenge of learning plateaus via a saturation-aware gain shaping objective, which rewards the critic for inducing incremental improvements in high-performing trajectories. By employing dual-track GRPO updates, ECHO ensures the critic's feedback stays synchronized with the evolving policy. Experimental results show that ECHO yields more stable training and higher long-horizon task success across open-world environments.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.600495",
        "filter_reason": "论文提出了ECHO框架，专注于训练LLM智能体，通过策略与评论家的协同演化（Co-evolution）机制解决反馈陈旧问题，属于自我演化和单智能体训练的研究范畴，符合筛选条件。"
    },
    {
        "index": "#48",
        "title": "From Text to Simulation: A Multi-Agent LLM Workflow for Automated Chemical Process Design",
        "link": "/arxiv/2601.06776",
        "arxiv_id": "2601.06776",
        "authors": "Xufei Tian, Wenli Du, Shaoyi Yang, Han Hu, Hui Xin, Shifeng Qu, Ke Ye",
        "summary": "Process simulation is a critical cornerstone of chemical engineering design. Current automated chemical design methodologies focus mainly on various representations of process flow diagrams. However, transforming these diagrams into executable simulation flowsheets remains a time-consuming and labor-intensive endeavor, requiring extensive manual parameter configuration within simulation software. In this work, we propose a novel multi-agent workflow that leverages the semantic understanding capabilities of large language models(LLMs) and enables iterative interactions with chemical process simulation software, achieving end-to-end automated simulation from textual process specifications to computationally validated software configurations for design enhancement. Our approach integrates four specialized agents responsible for task understanding, topology generation, parameter configuration, and evaluation analysis, respectively, coupled with Enhanced Monte Carlo Tree Search to accurately interpret semantics and robustly generate configurations. Evaluated on Simona, a large-scale process description dataset, our method achieves a 31.1% improvement in the simulation convergence rate compared to state-of-the-art baselines and reduces the design time by 89. 0% compared to the expert manual design. This work demonstrates the potential of AI-assisted chemical process design, which bridges the gap between conceptual design and practical implementation. Our workflow is applicable to diverse process-oriented industries, including pharmaceuticals, petrochemicals, food processing, and manufacturing, offering a generalizable solution for automated process design.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.601023",
        "filter_reason": "论文明确提出了一种新颖的多智能体LLM工作流，包含四个专门的智能体（任务理解、拓扑生成、参数配置、评估分析）进行协作，并利用增强蒙特卡洛树搜索与模拟软件进行交互（工具使用）。尽管应用于化工领域，但其核心贡献在于多智能体协作架构和工作流设计，符合多智能体和工具使用的研究范围。"
    },
    {
        "index": "#51",
        "title": "Agentic AI Empowered Intent-Based Networking for 6G",
        "link": "/arxiv/2601.06640",
        "arxiv_id": "2601.06640",
        "authors": "Genze Jiang, Kezhi Wang, Xiaomin Chen, Yizhou Huang",
        "summary": "The transition towards sixth-generation (6G) wireless networks necessitates autonomous orchestration mechanisms capable of translating high-level operational intents into executable network configurations. Existing approaches to Intent-Based Networking (IBN) rely upon either rule-based systems that struggle with linguistic variation or end-to-end neural models that lack interpretability and fail to enforce operational constraints. This paper presents a hierarchical multi-agent framework where Large Language Model (LLM) based agents autonomously decompose natural language intents, consult domain-specific specialists, and synthesise technically feasible network slice configurations through iterative reasoning-action (ReAct) cycles. The proposed architecture employs an orchestrator agent coordinating two specialist agents, i.e., Radio Access Network (RAN) and Core Network agents, via ReAct-style reasoning, grounded in structured network state representations. Experimental evaluation across diverse benchmark scenarios shows that the proposed system outperforms rule-based systems and direct LLM prompting, with architectural principles applicable to Open RAN (O-RAN) deployments. The results also demonstrate that whilst contemporary LLMs possess general telecommunications knowledge, network automation requires careful prompt engineering to encode context-dependent decision thresholds, advancing autonomous orchestration capabilities for next-generation wireless systems.",
        "subjects": "Artificial Intelligence, Networking and Internet Architecture",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.603209",
        "filter_reason": "论文提出了一个分层多智能体框架，包含编排器智能体和专家智能体（RAN和核心网络），它们通过ReAct循环进行协作和通信。这直接符合“多智能体：协作、通信”的研究范围。尽管应用于6G网络领域，但其核心贡献在于智能体的架构设计与交互机制，而非单纯的应用。"
    },
    {
        "index": "#54",
        "title": "DRAGON: LLM-Driven Decomposition and Reconstruction Agents for Large-Scale Combinatorial Optimization",
        "link": "/arxiv/2601.06502",
        "arxiv_id": "2601.06502",
        "authors": "Shengkai Chen, Zhiguang Cao, Jianan Zhou, Yaoxin Wu, Senthilnath Jayavelu, Zhuoyi Lin, Xiaoli Li, Shili Xiang",
        "summary": "Large Language Models (LLMs) have recently shown promise in addressing combinatorial optimization problems (COPs) through prompt-based strategies. However, their scalability and generalization remain limited, and their effectiveness diminishes as problem size increases, particularly in routing problems involving more than 30 nodes. We propose DRAGON, which stands for Decomposition and Reconstruction Agents Guided OptimizatioN, a novel framework that combines the strengths of metaheuristic design and LLM reasoning. Starting from an initial global solution, DRAGON autonomously identifies regions with high optimization potential and strategically decompose large-scale COPs into manageable subproblems. Each subproblem is then reformulated as a concise, localized optimization task and solved through targeted LLM prompting guided by accumulated experiences. Finally, the locally optimized solutions are systematically reintegrated into the original global context to yield a significantly improved overall outcome. By continuously interacting with the optimization environment and leveraging an adaptive experience memory, the agents iteratively learn from feedback, effectively coupling symbolic reasoning with heuristic search. Empirical results show that, unlike existing LLM-based solvers limited to small-scale instances, DRAGON consistently produces feasible solutions on TSPLIB, CVRPLIB, and Weibull-5k bin packing benchmarks, and achieves near-optimal results (0.16% gap) on knapsack problems with over 3M variables. This work shows the potential of feedback-driven language agents as a new paradigm for generalizable and interpretable large-scale optimization.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.604811",
        "filter_reason": "论文提出了名为 DRAGON 的框架，明确使用了“Agents”概念，涉及智能体与环境交互、利用自适应经验记忆以及通过反馈进行迭代学习，符合单智能体（记忆、自我反思）和自我演化的研究范围。尽管应用于组合优化问题，但其核心贡献在于智能体架构本身，而非单纯的应用。"
    },
    {
        "index": "#60",
        "title": "HiMem: Hierarchical Long-Term Memory for LLM Long-Horizon Agents",
        "link": "/arxiv/2601.06377",
        "arxiv_id": "2601.06377",
        "authors": "Ningning Zhang, Xingxing Yang, Zhizhong Tan, Weiping Deng, Wenyong Wang",
        "summary": "Although long-term memory systems have made substantial progress in recent years, they still exhibit clear limitations in adaptability, scalability, and self-evolution under continuous interaction settings. Inspired by cognitive theories, we propose HiMem, a hierarchical long-term memory framework for long-horizon dialogues, designed to support memory construction, retrieval, and dynamic updating during sustained interactions. HiMem constructs cognitively consistent Episode Memory via a Topic-Aware Event--Surprise Dual-Channel Segmentation strategy, and builds Note Memory that captures stable knowledge through a multi-stage information extraction pipeline. These two memory types are semantically linked to form a hierarchical structure that bridges concrete interaction events and abstract knowledge, enabling efficient retrieval without sacrificing information fidelity. HiMem supports both hybrid and best-effort retrieval strategies to balance accuracy and efficiency, and incorporates conflict-aware Memory Reconsolidation to revise and supplement stored knowledge based on retrieval feedback. This design enables continual memory self-evolution over long-term use. Experimental results on long-horizon dialogue benchmarks demonstrate that HiMem consistently outperforms representative baselines in accuracy, consistency, and long-term reasoning, while maintaining favorable efficiency. Overall, HiMem provides a principled and scalable design paradigm for building adaptive and self-evolving LLM-based conversational agents. The code is available at https://github.com/jojopdq/HiMem.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.607738",
        "filter_reason": "该论文提出了 HiMem 框架，专注于解决 LLM 智能体在长期交互中的“记忆”问题（包括记忆构建、检索和动态更新），并引入了冲突感知的记忆再巩固机制以实现“自我演化”。这完全符合单智能体（记忆）和自我演化的研究范围。"
    },
    {
        "index": "#65",
        "title": "ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation",
        "link": "/arxiv/2601.06328",
        "arxiv_id": "2601.06328",
        "authors": "Ziqiao Xi, Shuang Liang, Qi Liu, Jiaqing Zhang, Letian Peng, Fang Nan, Meshal Nayim, Tianhui Zhang, Rishika Mundada, Lianhui Qin, Biwei Huang, Kun Zhou",
        "summary": "Tool-using LLM agents still struggle in open-world settings with large tool pools, long-horizon objectives, wild constraints, and unreliable tool states. For scalable and realistic training and testing, we introduce an open-world tool-using environment, built on 5,571 format unified tools across 204 commonly used apps. It includes a task creation engine that synthesizes long-horizon, multi-tool workflows with wild constraints, and a state controller that injects interruptions and failures to stress-test robustness. On top of this environment, we develop a tool select-then-execute agent framework with a planner-actor decomposition to separate deliberate reasoning and self-correction from step-wise execution. Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents. Our code and data will be publicly released.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.610481",
        "filter_reason": "论文明确研究“Tool-using LLM agents”（使用工具的LLM智能体），提出了包含规划器-执行者分解的智能体框架，涉及规划、工具使用和自我修正，符合单智能体的研究范围。"
    },
    {
        "index": "#73",
        "title": "PsyAgent: Constructing Human-like Agents Based on Psychological Modeling and Contextual Interaction",
        "link": "/arxiv/2601.06158",
        "arxiv_id": "2601.06158",
        "authors": "Zibin Meng, Kani Chen",
        "summary": "Human-like agents require modeling how dispositions interact with social structure. We present PsyAgent, which couples a Big Five trait prior with Bourdieu's cognitive-social co-structure. PsyAgent comprises: (i) Individual Structure (IS), a machine-usable profile encoding traits and facets, cognitive style, values, cultural and educational capital, and salient life episodes; and (ii) Multi-Scenario Contexting (MSC), role-relationship-norm frames spanning eight arenas (work, family, friendship, strangers and civic life, solitude and self-regulation, romance, learning, and public expression). At inference, fixed structured prompts bind the active scenario to the agent profile, yielding behavior that is stable yet context-sensitive. We instantiate IS and MSC to synthesize supervision (role-play dialogues, decision probes, feedback trajectories) and then fine-tune a small LLM. The resulting model produces consistent, identifiable persona-aligned behaviors for specified Big Five configurations and matches or exceeds several larger untuned LLMs and other untuned baselines on our metrics: persona consistency, contextual appropriateness, style matching, trait identifiability, and long-horizon stability. Ablations show IS chiefly improves trait fidelity and stylistic stability, while MSC drives norm awareness and decision fit; both are necessary for cross-scenario performance. PsyAgent offers a precise, data-efficient architecture for personality-grounded agents.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.614123",
        "filter_reason": "该论文提出了PsyAgent框架，专注于构建具有心理建模和上下文交互能力的类人智能体。它涉及智能体的核心架构设计，包括个体结构（档案/记忆）和多场景上下文交互，旨在实现智能体行为的一致性和长期稳定性，属于LLM智能体的研究范畴。"
    },
    {
        "index": "#74",
        "title": "HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants",
        "link": "/arxiv/2601.06152",
        "arxiv_id": "2601.06152",
        "authors": "Hailong Li, Feifei Li, Wenhui Que, Xingyu Fan",
        "summary": "Large language models (LLMs) power many interactive systems such as chatbots, customer-service agents, and personal assistants. In knowledge-intensive scenarios requiring user-specific personalization, conventional retrieval-augmented generation (RAG) pipelines exhibit limited memory capacity and insufficient coordination between retrieval mechanisms and user-specific conversational history, leading to redundant clarification, irrelevant documents, and degraded user experience. Inspired by the hippocampus-neocortex memory mechanism, we propose HiMeS, an AI-assistant architecture that fuses short-term and long-term memory. Our contributions are fourfold: (1) A short-term memory extractor is trained end-to-end with reinforcement learning to compress recent dialogue and proactively pre-retrieve documents from the knowledge base, emulating the cooperative interaction between the hippocampus and prefrontal cortex. (2) A partitioned long-term memory network stores user-specific information and re-ranks retrieved documents, simulating distributed cortical storage and memory reactivation. (3) On a real-world industrial dataset, HiMeS significantly outperforms a cascaded RAG baseline on question-answering quality. (4) Ablation studies confirm the necessity of both memory modules and suggest a practical path toward more reliable, context-aware, user-customized LLM-based assistants.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-06",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.614428",
        "filter_reason": "该论文提出了HiMeS，一种受海马体启发的记忆系统，旨在解决LLM助手在个性化场景下的记忆问题。论文重点设计了短期和长期记忆模块及其交互机制，这直接属于“单智能体：记忆”的研究范围。"
    },
    {
        "index": "#75",
        "title": "NL2Dashboard: A Lightweight and Controllable Framework for Generating Dashboards with LLMs",
        "link": "/arxiv/2601.06126",
        "arxiv_id": "2601.06126",
        "authors": "Boshen Shi, Kexin Yang, Yuanbo Yang, Guanguang Chang, Ce Chi, Zhendong Wang, Xing Wang, Junlan Feng",
        "summary": "While Large Language Models (LLMs) have demonstrated remarkable proficiency in generating standalone charts, synthesizing comprehensive dashboards remains a formidable challenge. Existing end-to-end paradigms, which typically treat dashboard generation as a direct code generation task (e.g., raw HTML), suffer from two fundamental limitations: representation redundancy due to massive tokens spent on visual rendering, and low controllability caused by the entanglement of analytical reasoning and presentation. To address these challenges, we propose NL2Dashboard, a lightweight framework grounded in the principle of Analysis-Presentation Decoupling. We introduce a structured intermediate representation (IR) that encapsulates the dashboard's content, layout, and visual elements. Therefore, it confines the LLM's role to data analysis and intent translation, while offloading visual synthesis to a deterministic rendering engine. Building upon this framework, we develop a multi-agent system in which the IR-driven algorithm is instantiated as a suite of tools. Comprehensive experiments conducted with this system demonstrate that NL2Dashboard significantly outperforms state-of-the-art baselines across diverse domains, achieving superior visual quality, significantly higher token efficiency, and precise controllability in both generation and modification tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-04",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.614755",
        "filter_reason": "摘要明确提到开发了一个“multi-agent system”（多智能体系统），并将算法实例化为工具（tool use），这符合研究范围中关于多智能体协作及工具使用的定义。"
    },
    {
        "index": "#78",
        "title": "Dreaming Is Not a Bug: A Jung-Inspired Dream Layer for Multi-Agent LLM Companions",
        "link": "/arxiv/2601.06115",
        "arxiv_id": "2601.06115",
        "authors": "V. Cheung",
        "summary": "Inspired by a personal dream about knowledge-sharing barriers in an everyday hardware project, this paper proposes a Jung-inspired \"Dream Layer\" for LLM companions, reframing controlled offline hallucinations as a resource for learning and relationship-building rather than a mere reliability bug. Drawing on Jung's notion of the collective unconscious as a shared repository of archetypal forms, we introduce an Artificial Collective Unconscious (ACU): a shared dream pool where agents contribute de-identified, abstract Interaction Templates that are later re-instantiated as idiosyncratic Dream Narratives. The Dream Layer runs strictly offline: logic-enforcing modules are relaxed and sampling temperature is increased, yielding safe but deliberately bizarre narratives (e.g., travel sequences with mismatched currencies) that augment data for rare events and edge-case safety tests; to harness risk productively, we add a governance stack of strict abstraction, temporal delays, and ephemeral memory. Through behavioural simulations of everyday dialogue and long-horizon adaptation tasks, we show that the Dream Layer enables a critical decoupling: agents remain firm on safety constraints (e.g., security policies) while becoming flexible in narrative strategy (e.g., using shared archetypal metaphors to resolve deadlocks), conceptually reframing hallucination so that online, unmarked instances remain bugs, whereas bounded, marked, and delayed ones become a goldmine for synthetic scenarios and deepened companionship, echoing anti-overfitting dream mechanisms proposed in contemporary neuroscience.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.615658",
        "filter_reason": "该论文提出了一个“人工集体潜意识”（ACU）作为多智能体LLM伴侣的共享梦境池，涉及多智能体之间的协作与通信（共享交互模板）、记忆机制（共享梦境池）以及通过离线反馈（梦境）进行自我演化（长期适应任务），符合多智能体和自我演化的研究范围。"
    },
    {
        "index": "#80",
        "title": "ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions",
        "link": "/arxiv/2601.06112",
        "arxiv_id": "2601.06112",
        "authors": "Aayush Gupta",
        "summary": "Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production. We introduce \\textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $ε$, and (iii) fault tolerance under controlled tool/API failures at intensity $λ$. ReliabilityBench contributes a unified reliability surface $R(k,ε,λ)$, \\textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift). We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes. Perturbations alone reduce success from 96.9% at $ε=0$ to 88.1% at $ε=0.2$. Rate limiting is the most damaging fault in ablations. ReAct is more robust than Reflexion under combined stress, and Gemini 2.0 Flash achieves comparable reliability to GPT-4o at much lower cost. ReliabilityBench provides a systematic framework for assessing production readiness of LLM agents.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.616199",
        "filter_reason": "该论文提出了一个评估工具使用LLM智能体可靠性的基准测试，涉及ReAct和Reflexion等智能体架构，属于单智能体研究范畴（工具使用、自我反思）。虽然涉及生产环境压力测试，但核心是评估智能体本身的性能与鲁棒性，而非纯应用或基础设施优化。"
    },
    {
        "index": "#81",
        "title": "LLM-Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions",
        "link": "/arxiv/2601.06111",
        "arxiv_id": "2601.06111",
        "authors": "Aayush Gupta, Farahan Raza Sheikh",
        "summary": "Predicting how populations respond to policy interventions is a fundamental challenge in computational social science and public policy. Traditional approaches rely on aggregate statistical models that capture historical correlations but lack mechanistic interpretability and struggle with novel policy scenarios. We present a general framework for constructing Social Digital Twins - virtual population replicas where Large Language Models (LLMs) serve as cognitive engines for individual agents. Each agent, characterized by demographic and psychographic attributes, receives policy signals and outputs multi-dimensional behavioral probability vectors. A calibration layer maps aggregated agent responses to observable population-level metrics, enabling validation against real-world data and deployment for counterfactual policy analysis. We instantiate this framework in the domain of pandemic response, using COVID-19 as a case study with rich observational data. On a held-out test period, our calibrated digital twin achieves a 20.7% improvement in macro-averaged prediction error over gradient boosting baselines across six behavioral categories. Counterfactual experiments demonstrate monotonic and bounded responses to policy variations, establishing behavioral plausibility. The framework is domain-agnostic: the same architecture applies to transportation policy, economic interventions, environmental regulations, or any setting where policy affects population behavior. We discuss implications for policy simulation, limitations of the approach, and directions for extending LLM-based digital twins beyond pandemic response.",
        "subjects": "Artificial Intelligence, Computers and Society",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.616479",
        "filter_reason": "该论文提出了一个基于LLM的社会数字孪生框架，其中LLM作为个体智能体的认知引擎来模拟人口行为。这属于LLM智能体中的多智能体模拟范畴。尽管使用了疫情响应作为案例研究，但其核心贡献在于构建智能体框架的方法论，而非单纯的医疗领域应用。"
    },
    {
        "index": "#86",
        "title": "Automatic Question Generation for Intuitive Learning Utilizing Causal Graph Guided Chain of Thought Reasoning",
        "link": "/arxiv/2601.06098",
        "arxiv_id": "2601.06098",
        "authors": "Nicholas X. Wang, Neel V. Parpia, Aaryan D. Parikh, Aggelos K. Katsaggelos",
        "summary": "Intuitive learning is crucial for developing deep conceptual understanding, especially in STEM education, where students often struggle with abstract and interconnected concepts. Automatic question generation has become an effective strategy for personalized and adaptive learning. However, its effectiveness is hindered by hallucinations in large language models (LLMs), which may generate factually incorrect, ambiguous, or pedagogically inconsistent questions. To address this issue, we propose a novel framework that combines causal-graph-guided Chain-of-Thought (CoT) reasoning with a multi-agent LLM architecture. This approach ensures the generation of accurate, meaningful, and curriculum-aligned questions. Causal graphs provide an explicit representation of domain knowledge, while CoT reasoning facilitates a structured, step-by-step traversal of related concepts. Dedicated LLM agents are assigned specific tasks such as graph pathfinding, reasoning, validation, and output, all working within domain constraints. A dual validation mechanism-at both the conceptual and output stages-greatly reduces hallucinations. Experimental results demonstrate up to a 70% improvement in quality compared to reference methods and yielded highly favorable outcomes in subjective evaluations.",
        "subjects": "Artificial Intelligence",
        "date": "2026-01-02",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.618053",
        "filter_reason": "论文提出了一种结合因果图与CoT的多智能体LLM架构，通过专用智能体（寻路、推理、验证、输出）之间的协作来减少幻觉，符合“多智能体：协作”的研究范围。"
    },
    {
        "index": "#85",
        "title": "Dynamic Intelligence Ceilings: Measuring Long-Horizon Limits of Planning and Creativity in Artificial Systems",
        "link": "/arxiv/2601.06102",
        "arxiv_id": "2601.06102",
        "authors": "Truong Xuan Khanh, Truong Quynh Hoa",
        "summary": "Recent advances in artificial intelligence have produced systems capable of remarkable performance across a wide range of tasks. These gains, however, are increasingly accompanied by concerns regarding long-horizon developmental behavior, as many systems converge toward repetitive solution patterns rather than sustained growth. We argue that a central limitation of contemporary AI systems lies not in capability per se, but in the premature fixation of their performance frontier. To address this issue, we introduce the concept of a \\emph{Dynamic Intelligence Ceiling} (DIC), defined as the highest level of effective intelligence attainable by a system at a given time under its current resources, internal intent, and structural configuration. To make this notion empirically tractable, we propose a trajectory-centric evaluation framework that measures intelligence as a moving frontier rather than a static snapshot. We operationalize DIC using two estimators: the \\emph{Progressive Difficulty Ceiling} (PDC), which captures the maximal reliably solvable difficulty under constrained resources, and the \\emph{Ceiling Drift Rate} (CDR), which quantifies the temporal evolution of this frontier. These estimators are instantiated through a procedurally generated benchmark that jointly evaluates long-horizon planning and structural creativity within a single controlled environment. Our results reveal a qualitative distinction between systems that deepen exploitation within a fixed solution manifold and those that sustain frontier expansion over time. Importantly, our framework does not posit unbounded intelligence, but reframes limits as dynamic and trajectory-dependent rather than static and prematurely fixed. \\vspace{0.5em} \\noindent\\textbf{Keywords:} AI evaluation, planning and creativity, developmental intelligence, dynamic intelligence ceilings, complex adaptive systems",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2026-01-03",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.617764",
        "filter_reason": "论文关注长视界规划和结构创造力，这是单智能体LLM智能体的核心能力之一。论文提出的评估框架旨在测量智能体在复杂环境中的持续发展能力和规划极限，符合研究范围中的“单智能体：规划”及“自我演化”相关内容，且不属于纯推理、纯应用或基础设施优化等排除类别。"
    },
    {
        "index": "#107",
        "title": "Large Language Models for Physics Instrument Design",
        "link": "/arxiv/2601.07580",
        "arxiv_id": "2601.07580",
        "authors": "Sara Zoccheddu, Shah Rukh Qasim, Patrick Owen, Nicola Serra",
        "summary": "We study the use of large language models (LLMs) for physics instrument design and compare their performance to reinforcement learning (RL). Using only prompting, LLMs are given task constraints and summaries of prior high-scoring designs and propose complete detector configurations, which we evaluate with the same simulators and reward functions used in RL-based optimization. Although RL yields stronger final designs, we find that modern LLMs consistently generate valid, resource-aware, and physically meaningful configurations that draw on broad pretrained knowledge of detector design principles and particle--matter interactions, despite having no task-specific training. Based on this result, as a first step toward hybrid design workflows, we explore pairing the LLMs with a dedicated trust region optimizer, serving as a precursor to future pipelines in which LLMs propose and structure design hypotheses while RL performs reward-driven optimization. Based on these experiments, we argue that LLMs are well suited as meta-planners: they can design and orchestrate RL-based optimization studies, define search strategies, and coordinate multiple interacting components within a unified workflow. In doing so, they point toward automated, closed-loop instrument design in which much of the human effort required to structure and supervise optimization can be reduced.",
        "subjects": "Instrumentation and Detectors, Artificial Intelligence, Machine Learning, High Energy Physics - Experiment",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.625035",
        "filter_reason": "论文探讨了LLM作为“元规划者”的角色，涉及规划、编排和协调多个组件（如RL优化器）的能力，符合单智能体中关于“规划”和“工具使用/协调”的研究范围，尽管应用场景是物理仪器设计，但其核心贡献在于LLM在复杂工作流中的智能体能力。"
    },
    {
        "index": "#159",
        "title": "A Large-Scale Study on the Development and Issues of Multi-Agent AI Systems",
        "link": "/arxiv/2601.07136",
        "arxiv_id": "2601.07136",
        "authors": "Daniel Liu, Krishna Upadhyay, Vinaik Chhetri, A. B. Siddique, Umar Farooq",
        "summary": "The rapid emergence of multi-agent AI systems (MAS), including LangChain, CrewAI, and AutoGen, has shaped how large language model (LLM) applications are developed and orchestrated. However, little is known about how these systems evolve and are maintained in practice. This paper presents the first large-scale empirical study of open-source MAS, analyzing over 42K unique commits and over 4.7K resolved issues across eight leading systems. Our analysis identifies three distinct development profiles: sustained, steady, and burst-driven. These profiles reflect substantial variation in ecosystem maturity. Perfective commits constitute 40.8% of all changes, suggesting that feature enhancement is prioritized over corrective maintenance (27.4%) and adaptive updates (24.3%). Data about issues shows that the most frequent concerns involve bugs (22%), infrastructure (14%), and agent coordination challenges (10%). Issue reporting also increased sharply across all frameworks starting in 2023. Median resolution times range from under one day to about two weeks, with distributions skewed toward fast responses but a minority of issues requiring extended attention. These results highlight both the momentum and the fragility of the current ecosystem, emphasizing the need for improved testing infrastructure, documentation quality, and maintenance practices to ensure long-term reliability and sustainability.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.643816",
        "filter_reason": "该论文明确针对多智能体AI系统（MAS）进行大规模实证研究，分析了其开发、维护及演化过程。摘要中特别指出了“智能体协调挑战”是主要关注点之一，这直接符合筛选条件中“多智能体：协作、通信”的研究范围。虽然论文涉及基础设施问题，但其核心是对智能体系统本身的生态分析，而非单纯的基础设施优化或特定领域应用。"
    },
    {
        "index": "#160",
        "title": "Enhancing Cloud Network Resilience via a Robust LLM-Empowered Multi-Agent Reinforcement Learning Framework",
        "link": "/arxiv/2601.07122",
        "arxiv_id": "2601.07122",
        "authors": "Yixiao Peng, Hao Hu, Feiyang Li, Xinye Cao, Yingchang Jiang, Jipeng Tang, Guoshun Nan, Yuling Liu",
        "summary": "While virtualization and resource pooling empower cloud networks with structural flexibility and elastic scalability, they inevitably expand the attack surface and challenge cyber resilience. Reinforcement Learning (RL)-based defense strategies have been developed to optimize resource deployment and isolation policies under adversarial conditions, aiming to enhance system resilience by maintaining and restoring network availability. However, existing approaches lack robustness as they require retraining to adapt to dynamic changes in network structure, node scale, attack strategies, and attack intensity. Furthermore, the lack of Human-in-the-Loop (HITL) support limits interpretability and flexibility. To address these limitations, we propose CyberOps-Bots, a hierarchical multi-agent reinforcement learning framework empowered by Large Language Models (LLMs). Inspired by MITRE ATT&CK's Tactics-Techniques model, CyberOps-Bots features a two-layer architecture: (1) An upper-level LLM agent with four modules--ReAct planning, IPDRR-based perception, long-short term memory, and action/tool integration--performs global awareness, human intent recognition, and tactical planning; (2) Lower-level RL agents, developed via heterogeneous separated pre-training, execute atomic defense actions within localized network regions. This synergy preserves LLM adaptability and interpretability while ensuring reliable RL execution. Experiments on real cloud datasets show that, compared to state-of-the-art algorithms, CyberOps-Bots maintains network availability 68.5% higher and achieves a 34.7% jumpstart performance gain when shifting the scenarios without retraining. To our knowledge, this is the first study to establish a robust LLM-RL framework with HITL support for cloud defense. We will release our framework to the community, facilitating the advancement of robust and autonomous defense in cloud networks.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning",
        "date": "2026-01-12",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.644230",
        "filter_reason": "该论文提出了一个名为CyberOps-Bots的LLM赋能的多智能体强化学习框架，符合“多智能体”（LLM智能体与RL智能体协作）和“单智能体”（包含ReAct规划、记忆、工具使用模块）的研究范围。尽管应用场景为云网络防御，但论文核心贡献在于智能体的架构设计与机制，而非纯应用或AI安全/对齐研究。"
    },
    {
        "index": "#204",
        "title": "MemGovern: Enhancing Code Agents through Learning from Governed Human Experiences",
        "link": "/arxiv/2601.06789",
        "arxiv_id": "2601.06789",
        "authors": "Qihao Wang, Ziming Cheng, Shuo Zhang, Fan Liu, Rui Xu, Heng Lian, Kunyi Wang, Xiaoming Yu, Jianghao Yin, Sen Hu, Yue Hu, Shaolei Zhang, Yanbing Liu, Ronghao Chen, Huacan Wang",
        "summary": "While autonomous software engineering (SWE) agents are reshaping programming paradigms, they currently suffer from a \"closed-world\" limitation: they attempt to fix bugs from scratch or solely using local context, ignoring the immense historical human experience available on platforms like GitHub. Accessing this open-world experience is hindered by the unstructured and fragmented nature of real-world issue-tracking data. In this paper, we introduce MemGovern, a framework designed to govern and transform raw GitHub data into actionable experiential memory for agents. MemGovern employs experience governance to convert human experience into agent-friendly experience cards and introduces an agentic experience search strategy that enables logic-driven retrieval of human expertise. By producing 135K governed experience cards, MemGovern achieves a significant performance boost, improving resolution rates on the SWE-bench Verified by 4.65%. As a plug-in approach, MemGovern provides a solution for agent-friendly memory infrastructure.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-11",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.661284",
        "filter_reason": "该论文专注于增强代码智能体，核心贡献在于构建智能体的记忆机制，通过治理和检索人类历史经验来提升智能体性能，属于单智能体研究中的“记忆”范畴，符合筛选条件。"
    },
    {
        "index": "#244",
        "title": "ArenaRL: Scaling RL for Open-Ended Agents via Tournament-based Relative Ranking",
        "link": "/arxiv/2601.06487",
        "arxiv_id": "2601.06487",
        "authors": "Qiang Zhang, Boli Chen, Fanrui Zhang, Ruixue Ding, Shihang Wang, Qiuchen Wang, Yinfeng Huang, Haonan Zhang, Rongxiang Zhu, Pengyong Wang, Ailin Ren, Xin Li, Pengjun Xie, Jiawei Liu, Ning Guo, Jingren Zhou, Zheng-Jun Zha",
        "summary": "Reinforcement learning has substantially improved the performance of LLM agents on tasks with verifiable outcomes, but it still struggles on open-ended agent tasks with vast solution spaces (e.g., complex travel planning). Due to the absence of objective ground-truth for these tasks, current RL algorithms largely rely on reward models that assign scalar scores to individual responses. We contend that such pointwise scoring suffers from an inherent discrimination collapse: the reward model struggles to distinguish subtle advantages among different trajectories, resulting in scores within a group being compressed into a narrow range. Consequently, the effective reward signal becomes dominated by noise from the reward model, leading to optimization stagnation. To address this, we propose ArenaRL, a reinforcement learning paradigm that shifts from pointwise scalar scoring to intra-group relative ranking. ArenaRL introduces a process-aware pairwise evaluation mechanism, employing multi-level rubrics to assign fine-grained relative scores to trajectories. Additionally, we construct an intra-group adversarial arena and devise a tournament-based ranking scheme to obtain stable advantage signals. Empirical results confirm that the built seeded single-elimination scheme achieves nearly equivalent advantage estimation accuracy to full pairwise comparisons with O(N^2) complexity, while operating with only O(N) complexity, striking an optimal balance between efficiency and precision. Furthermore, to address the lack of full-cycle benchmarks for open-ended agents, we build Open-Travel and Open-DeepResearch, two high-quality benchmarks featuring a comprehensive pipeline covering SFT, RL training, and multi-dimensional evaluation. Extensive experiments show that ArenaRL substantially outperforms standard RL baselines, enabling LLM agents to generate more robust solutions for complex real-world tasks.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2026-01-10",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.675558",
        "filter_reason": "论文提出了ArenaRL框架，旨在通过强化学习（RL）和相对排序机制提升开放式LLM智能体（如复杂旅行规划）的性能。这属于单智能体（规划）和自我演化（通过反馈自我完善）的研究范畴，且核心贡献在于算法改进而非纯应用或基础设施优化。"
    },
    {
        "index": "#264",
        "title": "Beyond BeautifulSoup: Benchmarking LLM-Powered Web Scraping for Everyday Users",
        "link": "/arxiv/2601.06301",
        "arxiv_id": "2601.06301",
        "authors": "Arth Bhardwaj, Nirav Diwan, Gang Wang",
        "summary": "Web scraping has historically required technical expertise in HTML parsing, session management, and authentication circumvention, which limited large-scale data extraction to skilled developers. We argue that large language models (LLMs) have democratized web scraping, enabling low-skill users to execute sophisticated operations through simple natural language prompts. While extensive benchmarks evaluate these tools under optimal expert conditions, we show that without extensive manual effort, current LLM-based workflows allow novice users to scrape complex websites that would otherwise be inaccessible. We systematically benchmark what everyday users can do with off-the-shelf LLM tools across 35 sites spanning five security tiers, including authentication, anti-bot, and CAPTCHA controls. We devise and evaluate two distinct workflows: (a) LLM-assisted scripting, where users prompt LLMs to generate traditional scraping code but maintain manual execution control, and (b) end-to-end LLM agents, which autonomously navigate and extract data through integrated tool use. Our results demonstrate that end-to-end agents have made complex scraping accessible - requiring as little as a single prompt with minimal refinement (less than 5 changes) to complete workflows. We also highlight scenarios where LLM-assisted scripting may be simpler and faster for static sites. In light of these findings, we provide simple procedures for novices to use these workflows and gauge what adversaries could achieve using these.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Software Engineering",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.682404",
        "filter_reason": "论文明确研究并基准测试了“端到端 LLM 智能体”，重点在于它们通过集成的工具使用进行自主导航和数据提取的能力，这符合单智能体研究范围中的“工具使用”和“规划”特征。"
    },
    {
        "index": "#268",
        "title": "Automated QoR improvement in OpenROAD with coding agents",
        "link": "/arxiv/2601.06268",
        "arxiv_id": "2601.06268",
        "authors": "Amur Ghose, Junyeong Jang, Andrew B. Kahng, Jakang Lee",
        "summary": "EDA development and innovation has been constrained by scarcity of expert engineering resources. While leading LLMs have demonstrated excellent performance in coding and scientific reasoning tasks, their capacity to advance EDA technology itself has been largely untested. We present AuDoPEDA, an autonomous, repository-grounded coding system built atop OpenAI models and a Codex-class agent that reads OpenROAD, proposes research directions, expands them into implementation steps, and submits executable diffs. Our contributions include (i) a closed-loop LLM framework for EDA code changes; (ii) a task suite and evaluation protocol on OpenROAD for PPA-oriented improvements; and (iii) end-to-end demonstrations with minimal human oversight. Experiments in OpenROAD achieve routed wirelength reductions of up to 5.9%, and effective clock period reductions of up to 10.0%.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2026-01-09",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.683815",
        "filter_reason": "该论文提出了 \"AuDoPEDA\"，这是一个基于LLM的自主编码智能体系统。论文详细描述了智能体如何读取代码库（记忆/上下文）、提出研究方向（规划）、将其扩展为实施步骤并提交可执行的差异（工具使用与执行）。这完全符合单智能体在规划、工具使用和自主执行方面的研究范围，尽管应用于EDA领域，但其核心贡献在于智能体系统的构建而非单纯的应用。"
    },
    {
        "index": "#351",
        "title": "Autonomous QA Agent: A Retrieval-Augmented Framework for Reliable Selenium Script Generation",
        "link": "/arxiv/2601.06034",
        "arxiv_id": "2601.06034",
        "authors": "Dudekula Kasim Vali",
        "summary": "Software testing is critical in the software development lifecycle, yet translating requirements into executable test scripts remains manual and error-prone. While Large Language Models (LLMs) can generate code, they often hallucinate non-existent UI elements. We present the Autonomous QA Agent, a Retrieval-Augmented Generation (RAG) system that grounds Selenium script generation in project-specific documentation and HTML structure. By ingesting diverse formats (Markdown, PDF, HTML) into a vector database, our system retrieves relevant context before generation. Evaluation on 20 e-commerce test scenarios shows our RAG approach achieves 100% (20/20) syntax validity and 90% (18/20, 95% CI: [85%, 95%], p < 0.001) execution success, compared to 30% for standard LLM generation. While our evaluation is limited to a single domain, our method significantly reduces hallucinations by grounding generation in actual DOM structure, demonstrating RAG's potential for automated UI testing.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-11-28",
        "category": "cs.AI",
        "crawl_time": "2026-01-13T14:06:31.716837",
        "filter_reason": "论文提出了一个“Autonomous QA Agent”，利用检索增强生成（RAG，对应记忆机制）和Selenium脚本生成（对应工具使用）来自动化软件测试任务，符合单智能体的研究范围。"
    },
    {
        "index": "#5",
        "title": "DarwinTOD: LLM Driven Lifelong Self Evolution for Task Oriented Dialog Systems",
        "link": "/arxiv/2601.07248",
        "arxiv_id": "2601.07248",
        "authors": "Shuyu Zhang, Yujie Liu, Xinru Wang, Cheng Zhang, Yanmin Zhu, Bin Li",
        "summary": "Traditional task-oriented dialog systems are unable to evolve from ongoing interactions or adapt to new domains after deployment, that is a critical limitation in real-world dynamic environments. Continual learning approaches depend on episodic retraining with human curated data, failing to achieve autonomy lifelong improvement. While evolutionary computation and LLM driven self improvement offer promising mechanisms for dialog optimization, they lack a unified framework for holistic, iterative strategy refinement. To bridge this gap, we propose DarwinTOD, a lifelong self evolving dialog framework that systematically integrates these two paradigms, enabling continuous strategy optimization from a zero-shot base without task specific fine-tuning. DarwinTOD maintains an Evolvable Strategy Bank and operates through a dual-loop process: online multi-agent dialog execution with peer critique, and offline structured evolutionary operations that refine the strategy bank using accumulated feedback. This closed-loop design enables autonomous continuous improvement without human intervention. Extensive experiments show that DarwinTOD surpasses previous state-of-the-art methods and exhibits continuous performance gains throughout evolution. Our work provides a novel framework for building dialog systems with lifelong self evolution capabilities.",
        "subjects": "Multiagent Systems, Human-Computer Interaction",
        "date": "2026-01-12",
        "category": "cs.MA",
        "crawl_time": "2026-01-13T14:06:33.094825",
        "filter_reason": "论文提出了DarwinTOD框架，明确涉及“自我演化”（终身自我改进、进化计算）和“多智能体”（在线多智能体对话执行与同伴批判），符合研究范围中关于自我演化和多智能体协作的定义。"
    },
    {
        "index": "#6",
        "title": "Agents of Diffusion: Enhancing Diffusion Language Models with Multi-Agent Reinforcement Learning for Structured Data Generation (Extended Version)",
        "link": "/arxiv/2601.07152",
        "arxiv_id": "2601.07152",
        "authors": "Aja Khanal, Kaushik T. Ranade, Rishabh Agrawal, Kalyan S. Basu, Apurva Narayan",
        "summary": "Generating high-quality structured data such as JSON records, remains a fundamental challenge for large language models (LLMs), particularly when semantic richness must coexist with strict schema adherence. While autoregressive LLMs offer strong structural consistency, they often struggle with semantic variation and output diversity. In contrast, diffusion language models (DLMs) introduce powerful mechanisms for semantic richness and bidirectional decoding, yet lack the inductive biases needed for reliable structure preservation. We present Agents of Diffusion (AoD), a novel framework that unifies the generative flexibility of DLMs with the reasoning capabilities of autoregressive models through language-mediated reinforcement learning. AoD frames structured text generation as a multi-agent alignment process, where a prompt optimization agent collaborates with a judge agent to iteratively guide a DLM using natural language feedback. This approach enables controllable, schema-consistent generation without modifying model parameters or relying on handcrafted constraints. AoD advances the state of controllable generation by demonstrating that diffusion models, when supervised by cooperative agents, can achieve both high semantic novelty and structural fidelity. Across multiple structured data benchmarks, AoD consistently outperforms diffusion and autoregressive baselines, establishing a new path forward for structure-aware, diversity-enhanced text synthesis.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-12",
        "category": "cs.MA",
        "crawl_time": "2026-01-13T14:06:33.095086",
        "filter_reason": "论文提出了Agents of Diffusion (AoD)框架，明确将结构化文本生成构建为一个多智能体对齐过程，涉及提示优化智能体与评判智能体之间的协作与通信，符合多智能体协作的研究范围。"
    },
    {
        "index": "#9",
        "title": "Bi-Mem: Bidirectional Construction of Hierarchical Memory for Personalized LLMs via Inductive-Reflective Agents",
        "link": "/arxiv/2601.06490",
        "arxiv_id": "2601.06490",
        "authors": "Wenyu Mao, Haosong Tan, Shuchang Liu, Haoyang Liu, Yifan Xu, Huaxiang Ji, Xiang Wang",
        "summary": "Constructing memory from users' long-term conversations overcomes LLMs' contextual limitations and enables personalized interactions. Recent studies focus on hierarchical memory to model users' multi-granular behavioral patterns via clustering and aggregating historical conversations. However, conversational noise and memory hallucinations can be amplified during clustering, causing locally aggregated memories to misalign with the user's global persona. To mitigate this issue, we propose Bi-Mem, an agentic framework ensuring hierarchical memory fidelity through bidirectional construction. Specifically, we deploy an inductive agent to form the hierarchical memory: it extracts factual information from raw conversations to form fact-level memory, aggregates them into thematic scenes (i.e., local scene-level memory) using graph clustering, and infers users' profiles as global persona-level memory. Simultaneously, a reflective agent is designed to calibrate local scene-level memories using global constraints derived from the persona-level memory, thereby enforcing global-local alignment. For coherent memory recall, we propose an associative retrieval mechanism: beyond initial hierarchical search, a spreading activation process allows facts to evoke contextual scenes, while scene-level matches retrieve salient supporting factual information. Empirical evaluations demonstrate that Bi-Mem achieves significant improvements in question answering performance on long-term personalized conversational tasks.",
        "subjects": "Multiagent Systems",
        "date": "2026-01-10",
        "category": "cs.MA",
        "crawl_time": "2026-01-13T14:06:33.095844",
        "filter_reason": "该论文提出了一个包含归纳智能体和反思智能体的框架，专注于LLM智能体的记忆构建和自我反思机制，符合单智能体研究范围。"
    }
]