[
    {
        "index": "#4",
        "title": "Thought Communication in Multiagent Collaboration",
        "link": "/arxiv/2510.20733",
        "arxiv_id": "2510.20733",
        "authors": "Yujia Zheng, Zhuokai Zhao, Zijian Li, Yaqi Xie, Mingze Gao, Lizhu Zhang, Kun Zhang",
        "summary": "Natural language has long enabled human cooperation, but its lossy, ambiguous, and indirect nature limits the potential of collective intelligence. While machines are not subject to these constraints, most LLM-based multi-agent systems still rely solely on natural language, exchanging tokens or their embeddings. To go beyond language, we introduce a new paradigm, thought communication, which enables agents to interact directly mind-to-mind, akin to telepathy. To uncover these latent thoughts in a principled way, we formalize the process as a general latent variable model, where agent states are generated by an unknown function of underlying thoughts. We prove that, in a nonparametric setting without auxiliary information, both shared and private latent thoughts between any pair of agents can be identified. Moreover, the global structure of thought sharing, including which agents share which thoughts and how these relationships are structured, can also be recovered with theoretical guarantees. Guided by the established theory, we develop a framework that extracts latent thoughts from all agents prior to communication and assigns each agent the relevant thoughts, along with their sharing patterns. This paradigm naturally extends beyond LLMs to all modalities, as most observational data arise from hidden generative processes. Experiments on both synthetic and real-world benchmarks validate the theory and demonstrate the collaborative advantages of thought communication. We hope this work illuminates the potential of leveraging the hidden world, as many challenges remain unsolvable through surface-level observation alone, regardless of compute or data scale.",
        "subjects": "Machine Learning, Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-23",
        "category": "cs.MA",
        "crawl_time": "2025-10-24T11:00:03.599684",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的核心贡献是提出了一种名为“思想通信”（thought communication）的新范式，用于改进LLM多智能体系统。它不是将现有框架简单应用于某个领域，而是从根本上重新定义了智能体间的交互方式，提出了一种新的方法论和理论框架。这直接命中了您“构建、改进或演化LLM智能体”的核心目标，属于“多智能体 (Multi-Agent)”方向下的“通信”子方向。 **第二步：正面指标——高度相关** 论文包含了大量您关注的核心指标： - **核心范式**: 论文明确聚焦于 `Multi-Agent Systems (MAS)`，并提出了一个全新的交互范式。 - **多智能体**: 论文的核心就是解决智能体间的 `Communication` 问题，旨在提升 `Collaboration` 效果。摘要中提到的“共享和私有潜在思想”以及“思想共享的全局结构”直接对应了智能体社会中的信息共享模式。 - **智能体能力**: 虽然没有直接使用 `Planning` 或 `Tool Use` 等词汇，但“思想通信”本身可以被看作是一种增强智能体内部状态和协作能力的底层机制，它超越了传统的自然语言交互，是一种更高级的智能体能力。 **第三步：排除标准——不触发** 论文的主要贡献是关于提升多智能体协作的效率和范式，而非安全、对齐或可解释性。同时，论文虽然提到其框架可以扩展到所有模态，但其核心是LLM智能体之间的通信机制，而不是研究视觉或多模态模型本身。因此，不触及任何排除标准。 **第四步：处理特殊和模糊情况——不适用** 本文的情况非常清晰，属于多智能体协作的范畴，不涉及需要特殊处理的推理/规划或自我演化应用的模糊地带。 **第五步：最终决策** 综合以上分析，这篇论文的核心是提出一种创新的、理论驱动的多智能体通信框架，旨在突破自然语言的限制，实现更高效的“思想级”协作。这完全符合您在“多智能体 (Multi-Agent)”方向上，特别是“通信”和“协作”子方向的研究目标。因此，最终判断为 **True (保留)**。"
    },
    {
        "index": "#3",
        "title": "Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication",
        "link": "/arxiv/2510.19995",
        "arxiv_id": "2510.19995",
        "authors": "Yiming Lu, Xun Wang, Simin Ma, Shujian Liu, Sathish Reddy Indurthi, Song Wang, Haoyun Deng, Fei Liu, Kaiqiang Song",
        "summary": "Teamwork in workspace for complex tasks requires diverse communication strategies, but current multi-agent LLM systems lack systematic frameworks for task oriented communication. We introduce Communication to Completion (C2C), a scalable framework that addresses this gap through two key innovations: (1) the Alignment Factor (AF), a novel metric quantifying agent task alignment that directly impacts work efficiency, and (2) a Sequential Action Framework that integrates stepwise execution with intelligent communication decisions. C2C enables agents to make cost aware communication choices, dynamically improving task understanding through targeted interactions. We evaluated C2C on realistic coding workflows across three complexity tiers and team sizes from 5 to 17 agents, comparing against no communication and fixed steps baselines. The results show that C2C reduces the task completion time by about 40% with acceptable communication costs. The framework completes all tasks successfully in standard configurations and maintains effectiveness at scale. C2C establishes both a theoretical foundation for measuring communication effectiveness in multi-agent systems and a practical framework for complex collaborative tasks.",
        "subjects": "Multiagent Systems, Computation and Language",
        "date": "2025-10-22",
        "category": "cs.MA",
        "crawl_time": "2025-10-24T11:00:03.599371",
        "filter_reason": "这篇论文完全符合您的筛选要求，应被保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建和改进多智能体系统**。它没有简单地将一个现成的智能体框架应用到某个领域，而是提出了一个全新的、名为C2C的框架，专门用于解决多智能体LLM系统在面向任务的通信中缺乏系统性框架的痛点。其核心贡献是“Alignment Factor (AF)”这个新度量标准和“Sequential Action Framework”这个新框架，这完全属于构建和改进LLM智能体（特别是多智能体）的方法论范畴。 2.  **第二步：正面指标** - 论文高度匹配您的核心关注点。摘要中明确提到了 `Multi-Agent Systems (MAS)`、`Collaboration` 和 `Communication`。其核心创新点——让智能体做出“intelligent communication decisions”（智能通信决策）和“cost aware communication choices”（有成本意识的通信选择）——直接关联到智能体的规划和决策能力，是Agentic AI的关键特征。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。其研究焦点是提升多智能体协作的效率和任务完成速度，而非安全、对齐、可解释性或多模态视觉。 4.  **第四步：特殊和模糊情况** - 论文符合“推理/规划”的保留规则。它提出的“Sequential Action Framework”指导智能体在复杂的编程工作流中进行“stepwise execution”（逐步执行），这属于智能体在复杂任务中进行多步推理和规划的范畴，而不是单纯提升LLM的基础数学或逻辑能力。 **总结**：该论文的核心贡献在于提出了一种新颖的多智能体协作框架（C2C），旨在通过智能化的通信机制来提升团队完成复杂任务的效率。这直接命中了您研究课题中的“多智能体”方向，特别是“协作”与“通信”这两个子方向。因此，这是一篇与您研究范围高度相关的前沿论文。"
    },
    {
        "index": "#16",
        "title": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning",
        "link": "/arxiv/2510.20548",
        "arxiv_id": "2510.20548",
        "authors": "Jinchang Luo, Mingquan Cheng, Fan Wan, Ni Li, Xiaoling Xia, Shuangshuang Tian, Tingcheng Bian, Haiwei Wang, Haohuan Fu, Yan Tao",
        "summary": "Reinforcement learning has recently shown promise in improving retrieval-augmented generation (RAG). Despite these advances, its effectiveness in multi-hop question answering (QA) remains limited by two fundamental limitations: (i) global planning absence to structure multi-step reasoning, and (ii) unfaithful execution, which hinders effective query formulation and consistent use of retrieved evidence. We propose GlobalRAG, a reinforcement learning framework designed to enhance global reasoning in multi-hop QA. GlobalRAG decomposes questions into subgoals, coordinates retrieval with reasoning, and refines evidence iteratively. To guide this process, we introduce Planning Quality Reward and SubGoal Completion Reward, which encourage coherent planning and reliable subgoal execution. In addition, a progressive weight annealing strategy balances process-oriented and outcome-based objectives. Extensive experiments on both in-domain and out-of-domain benchmarks demonstrate that GlobalRAG significantly outperforms strong baselines while using only 8k training data (42% of the training data used by strong baselines), achieving average improvements of 14.2% in both EM and F1.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.097996",
        "filter_reason": "这篇论文完全符合您的研究范围，核心判断为“保留”。以下是根据您的筛选标准进行的详细分析： 1.  **第一步：核心判断** - **保留**: 这篇论文的本质不是简单地将RAG（检索增强生成）应用于多跳问答领域，而是提出了一种名为`GlobalRAG`的**新框架**。该框架的核心贡献在于解决现有方法在复杂任务中的两个根本性缺陷：**“全局规划的缺失”**和**“不忠实的执行”**。它通过强化学习来训练一个能够进行多步推理的系统，这个系统具备分解问题（规划）、协调工具（检索）和迭代优化（自我修正）的能力。这完全符合“构建、改进LLM智能体”的核心目标。它不是一个非演化型应用，而是一个关于如何让智能体在复杂任务中表现得更好的方法论。 2.  **第二步：正面指标** - 论文与您的核心关注点高度匹配： - **智能体能力**: 论文的核心是关于`Planning`（全局规划、分解为子目标）、`Tool Use`（协调检索与推理）和`Self-Refine`（迭代式地优化证据）。这些都是Agentic AI的关键能力。 - **核心范式**: `GlobalRAG`框架本身就是一个`LLM-based Agent`的实现，其设计思想与`ReAct`（Reason+Act）范式一脉相承，但更侧重于全局和结构化的规划。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。其主要贡献是关于提升智能体的推理框架和性能，而非安全、对齐或多模态等问题。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”情况的完美范例。它不是在研究如何提升LLM本身的基础逻辑或数学能力，而是在研究一个**智能体如何进行规划和多步推理**。它提出的“将问题分解为子目标”和“规划质量奖励”等机制，正是对智能体规划能力的直接构建和改进，完全符合您对“智能体如何在复杂任务中进行多步推理”的研究兴趣。 **最终决策**: 综合来看，这篇论文的核心贡献是`GlobalRAG`，一个通过强化学习来增强LLM智能体在复杂任务中全局规划和执行能力的新框架。它直接命中了您研究焦点中的“单智能体”方向，特别是“规划”和“工具使用”这两个子方向。因此，这篇论文与您的研究课题高度相关，应该被保留。"
    },
    {
        "index": "#15",
        "title": "Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for E-Commerce Search",
        "link": "/arxiv/2510.20567",
        "arxiv_id": "2510.20567",
        "authors": "Zhouwei Zhai, Mengxiang Chen, Haoyun Xia, Jin Li, Renquan Zhou, Min Yang",
        "summary": "The retrieval-ranking paradigm has long dominated e-commerce search, but its reliance on query-item matching fundamentally misaligns with multi-stage cognitive decision processes of platform users. This misalignment introduces critical limitations: semantic gaps in complex queries, high decision costs due to cross-platform information foraging, and the absence of professional shopping guidance. To address these issues, we propose a Multi-Agent Cognitive Decision Framework (MACDF), which shifts the paradigm from passive retrieval to proactive decision support. Extensive offline evaluations demonstrate MACDF's significant improvements in recommendation accuracy and user satisfaction, particularly for complex queries involving negation, multi-constraint, or reasoning demands. Online A/B testing on JD search platform confirms its practical efficacy. This work highlights the transformative potential of multi-agent cognitive systems in redefining e-commerce search.",
        "subjects": "Computation and Language",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.097432",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了一个全新的“多智能体认知决策框架（MACDF）”。它不是简单地将一个已有的智能体框架应用到电商领域，而是**构建了一个新的多智能体系统架构**来解决传统搜索范式的问题。论文的本质是关于如何设计和构建一个多智能体系统，这完全符合我“构建、改进或演化LLM智能体”的核心目标。它不属于“非演化型应用”，因为其创新点在于框架本身，而非应用结果。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 标题和摘要中明确提到了 `Multi-Agent Cognitive Decision Framework`，直接命中 `Multi-Agent Systems (MAS)` 和 `Agentic AI`。 - **智能体能力**: 摘要中提到的“多阶段认知决策过程”和“主动决策支持”强烈暗示了智能体的 `Planning`（规划）能力。而“跨平台信息搜寻”则明确指向了 `Tool Use`（工具使用）能力。 - **多智能体**: 作为一个“多智能体框架”，其内在必然涉及智能体间的 `Collaboration`（协作）来完成复杂的决策任务。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题。 - 论文也未将 `Vision` 或多模态作为研究核心，其焦点在于认知决策和搜索逻辑。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何进行规划和决策的典型例子。它提出的框架是为了模拟和辅助用户的“多阶段认知决策过程”，这属于智能体层面的规划和推理，而非提升LLM本身的基础数学或逻辑能力。因此，符合保留条件。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献在于**构建了一个新颖的多智能体框架（MACDF）**，以解决电商搜索中的复杂决策问题。它直接命中了我研究焦点中的“多智能体”方向，并涉及了“单智能体”方向中的规划和工具使用能力。虽然它没有明确涉及“自我演化”，但其在智能体构建和多智能体协作上的创新性贡献，使其完全符合我筛选前沿论文的核心目标。因此，最终判断为保留。"
    },
    {
        "index": "#20",
        "title": "Hierarchical Sequence Iteration for Heterogeneous Question Answering",
        "link": "/arxiv/2510.20505",
        "arxiv_id": "2510.20505",
        "authors": "Ruiyi Yang, Hao Xue, Imran Razzak, Hakim Hacid, Flora D. Salim",
        "summary": "Retrieval-augmented generation (RAG) remains brittle on multi-step questions and heterogeneous evidence sources, trading accuracy against latency and token/tool budgets. This paper introducesHierarchical Sequence (HSEQ) Iteration for Heterogeneous Question Answering, a unified framework that (i) linearize documents, tables, and knowledge graphs into a reversible hierarchical sequence with lightweight structural tags, and (ii) perform structure-aware iteration to collect just-enough evidence before answer synthesis. A Head Agent provides guidance that leads retrieval, while an Iteration Agent selects and expands HSeq via structure-respecting actions (e.g., parent/child hops, table row/column neighbors, KG relations); Finally the head agent composes canonicalized evidence to genearte the final answer, with an optional refinement loop to resolve detected contradictions. Experiments on HotpotQA (text), HybridQA/TAT-QA (table+text), and MetaQA (KG) show consistent EM/F1 gains over strong single-pass, multi-hop, and agentic RAG baselines with high efficiency. Besides, HSEQ exhibits three key advantages: (1) a format-agnostic unification that enables a single policy to operate across text, tables, and KGs without per-dataset specialization; (2) guided, budget-aware iteration that reduces unnecessary hops, tool calls, and tokens while preserving accuracy; and (3) evidence canonicalization for reliable QA, improving answers consistency and auditability.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.105068",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建和改进一个LLM智能体框架。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心是提出一个名为“HSEQ”的**统一框架**，用于解决复杂的多步、异构问答问题。这个框架并非简单地将LLM作为工具应用，而是设计了一个包含多个角色的智能体系统来协同完成任务。因此，它属于“构建、改进LLM智能体的方法论或新框架”，应予以保留。 2.  **第二步：正面指标——高度匹配** 论文包含了多个你关注的核心范式和能力： *   **核心范式**: 论文明确提出了一个基于LLM的智能体框架，并使用了`Agent`一词。 *   **智能体能力**: *   **规划**: `Head Agent`负责提供高层指导，引导整个检索和推理过程，这体现了智能体的规划能力。 *   **工具使用**: `Iteration Agent`执行“结构感知的动作”，如“父/子跳转、表格行/列邻居、KG关系”，这些动作本质上是智能体用来与异构数据环境（文本、表格、KG）交互的**工具**。 *   **自我反思/修正**: 论文提到了一个“可选的精炼循环来解决检测到的矛盾”，这是一种明确的**自我修正**机制。 *   **推理范式**: 整个“引导检索 -> 迭代选择和扩展证据 -> 合成答案”的流程，与`ReAct`（Reason+Act）的范式高度一致，是一种典型的Agentic推理框架。 3.  **第三步：排除标准——未命中** 论文的主要贡献是智能体框架的设计和效率，而非安全、对齐或可解释性。虽然提到了“auditability”（可审计性），但这只是框架带来的一个优点，并非研究的核心焦点。论文也不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 这篇论文是关于**智能体如何进行规划和推理**的典型案例。它不是在改进LLM本身的基础推理能力，而是在构建一个让LLM能够通过规划、行动和观察来解决复杂任务的智能体架构。因此，完全符合保留条件。 *   **自我演化的应用**: 虽然这篇论文不属于“自我演化”类别，但它完美地契合了“单智能体”的研究方向。 **最终决策**: 这篇论文的核心贡献是构建了一个新颖的LLM智能体框架（HSEQ），该框架通过`Head Agent`和`Iteration Agent`的分工协作，实现了在复杂任务中的**规划、工具使用和自我修正**。这完全符合你研究目标中的“单智能体”方向，特别是其子方向“规划”、“工具使用”和“自我反思”。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#42",
        "title": "DeepWideSearch: Benchmarking Depth and Width in Agentic Information Seeking",
        "link": "/arxiv/2510.20168",
        "arxiv_id": "2510.20168",
        "authors": "Tian Lan, Bin Zhu, Qianghuai Jia, Junyang Ren, Haijun Li, Longyue Wang, Zhao Xu, Weihua Luo, Kaifu Zhang",
        "summary": "Current search agents fundamentally lack the ability to simultaneously perform \\textit{deep} reasoning over multi-hop retrieval and \\textit{wide}-scale information collection-a critical deficiency for real-world applications like comprehensive market analysis and business development. To bridge this gap, we introduce DeepWideSearch, the first benchmark explicitly designed to evaluate agents to integrate depth and width in information seeking. In DeepWideSearch, agents must process a large volume of data, each requiring deep reasoning over multi-hop retrieval paths. Specifically, we propose two methods to converse established datasets, resulting in a curated collection of 220 questions spanning 15 diverse domains. Extensive experiments demonstrate that even state-of-the-art agents achieve only 2.39% average success rate on DeepWideSearch, highlighting the substantial challenge of integrating depth and width search in information-seeking tasks. Furthermore, our error analysis reveals four failure modes: lack of reflection, overreliance on internal knowledge, insufficient retrieval, and context overflow-exposing key limitations in current agent architectures. We publicly release DeepWideSearch to catalyze future research on more capable and robust information-seeking agents.",
        "subjects": "Computation and Language",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.126676",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** 这篇论文的核心贡献是构建了一个名为 `DeepWideSearch` 的**基准（Benchmark）**，用于评估和推动**LLM智能体**在信息寻求任务中整合“深度”和“广度”搜索的能力。论文的本质并非将智能体作为工具应用，而是**为智能体的能力评估和改进提供方法论和标准**。它直接聚焦于“LLM智能体”这一核心对象，旨在解决当前智能体架构中的一个关键缺陷。因此，它符合“保留”标准，不属于任何一种“排除”情况。 **第二步：正面指标——论文是否包含我的核心关注点？** 该论文高度契合您的核心关注点，包含多个正面指标： 1.  **核心范式**: 论文明确使用了 `Agentic Information Seeking`、`search agents` 等术语，直接定位在 `Agentic AI` 和 `LLM-based Agents` 的研究范式中。 2.  **智能体能力**: 论文的核心是评估智能体在复杂任务中的表现，这直接关联到 `Planning`（规划搜索路径）和 `Tool Use`（使用检索工具）。更重要的是，其错误分析明确指出了 `lack of reflection`（缺乏反思）是当前智能体的四大失败模式之一，这与您关注的 `Self-Reflection` 和 `Self-Correction` 能力紧密相关。 3.  **多智能体**: 虽然这篇论文不直接研究多智能体，但它为未来构建更强大的单智能体提供了评估基础，而强大的单智能体是多智能体系统研究的前提。 4.  **演化机制**: 论文通过揭示当前智能体的关键局限性（如缺乏反思、上下文溢出），为未来的研究指明了方向。这些局限性正是未来 `Self-Improvement` 和 `Iterative Improvement` 研究需要攻克的难题。构建一个能暴露问题的基准，是推动智能体“自我演化”研究的第一步。 **第三步：排除标准——是否为我的研究焦点之外？** 该论文不触及任何排除标准： *   **安全与对齐**: 论文焦点是智能体的能力评估，而非安全、对齐或可解释性。 *   **多模态与视觉**: 论文研究的是基于文本的信息寻求任务，不涉及视觉或多模态内容。 **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文明确研究智能体如何进行 `deep reasoning over multi-hop retrieval`（在多跳检索上进行深度推理），这完全符合“保留”条件，即“关于智能体如何进行规划或在复杂任务中进行多步推理”。它不是在提升LLM的基础推理能力，而是在评估一个完整的智能体在复杂任务中的推理表现。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是**构建了一个用于评估和推动LLM智能体能力演化的新基准**。它直接服务于您的研究目标“构建、改进或演化LLM智能体”。通过定义一个极具挑战性的任务并分析现有智能体的失败模式，该论文为未来开发具备更强规划、反思和工具使用能力的智能体铺平了道路。因此，这篇论文是您研究课题“LLM智能体及其演化”中一篇非常相关且有价值的前沿论文。"
    },
    {
        "index": "#49",
        "title": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering",
        "link": "/arxiv/2510.20036",
        "arxiv_id": "2510.20036",
        "authors": "Marianne Menglin Liu, Daniel Garcia, Fjona Parllaku, Vikas Upadhyay, Syed Fahad Allam Shah, Dan Roth",
        "summary": "Large language model (LLM) agents rely on external tools to solve complex tasks, but real-world toolsets often contain redundant tools with overlapping names and descriptions, introducing ambiguity and reducing selection accuracy. LLMs also face strict input context limits, preventing efficient consideration of large toolsets. To address these challenges, we propose ToolScope, which includes: (1) ToolScopeMerger with Auto-Correction to automatically audit and fix tool merges, reducing redundancy, and (2) ToolScopeRetriever to rank and select only the most relevant tools for each query, compressing toolsets to fit within context limits without sacrificing accuracy. Evaluations on three state-of-the-art LLMs and three open-source tool-use benchmarks show gains of 8.38% to 38.6% in tool selection accuracy, demonstrating ToolScope's effectiveness in enhancing LLM tool use.",
        "subjects": "Computation and Language, Software Engineering",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.135777",
        "filter_reason": "这篇论文的核心贡献是提出了一个名为 ToolScope 的框架，旨在提升 LLM 智能体的工具使用能力。这完全符合您研究目标中“构建、改进或演化 LLM 智能体”的范畴，特别是对“单智能体”方向下的“工具使用”能力的改进。 我的判断过程如下： 1.  **第一步：核心判断** - **保留**。该论文的本质是提出一种新的方法论（ToolScope框架）来解决LLM智能体在工具使用中遇到的具体挑战（工具冗余和上下文限制）。它不是将智能体作为工具应用到一个新领域，而是直接改进智能体本身的核心组件。因此，它符合“改进LLM智能体”的核心要求。 2.  **第二步：正面指标** - 论文标题和摘要中明确包含了多个核心关注点：`LLM Agent`、`Tool Use`。其提出的 `ToolScopeMerger with Auto-Correction` 也与 `Self-Correction` 的概念相关联。这些指标强烈表明该论文与您的研究方向高度契合。 3.  **第三步：排除标准** - 论文的研究焦点是提升工具选择的效率和准确性，不涉及 `Safety`、`Alignment`、`Interpretability` 或 `Vision` 等排除标准中的任何内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**：这篇论文虽然不直接研究智能体内部的规划或推理循环（如ReAct），但它解决了智能体在执行任务前的一个关键前置步骤——高效准确地选择工具。这属于对智能体能力的增强，而非对LLM基础推理能力的提升，因此符合保留条件。一个智能体能否在庞大的工具库中快速、准确地找到合适的工具，是其自主性和能力上限的关键体现。 **最终决策**：综合以上分析，ToolScope 论文通过提出新的方法论来增强LLM智能体的工具使用效率与准确性，是对Agentic AI核心能力的直接改进，与您的研究课题“LLM智能体及其演化”中的“单智能体”方向高度相关。因此，应予以保留。"
    },
    {
        "index": "#34",
        "title": "Teaching Language Models to Reason with Tools",
        "link": "/arxiv/2510.20342",
        "arxiv_id": "2510.20342",
        "authors": "Chengpeng Li, Zhengyang Tang, Ziniu Li, Mingfeng Xue, Keqin Bao, Tian Ding, Ruoyu Sun, Benyou Wang, Xiang Wang, Junyang Lin, Dayiheng Liu",
        "summary": "Large reasoning models (LRMs) like OpenAI-o1 have shown impressive capabilities in natural language reasoning. However, these models frequently demonstrate inefficiencies or inaccuracies when tackling complex mathematical operations. While integrating computational tools such as Code Interpreters (CIs) offers a promising solution, it introduces a critical challenge: a conflict between the model's internal, probabilistic reasoning and the external, deterministic knowledge provided by the CI, which often leads models to unproductive deliberation. To overcome this, we introduce CoRT (Code-Optimized Reasoning Training), a post-training framework designed to teach LRMs to effectively utilize CIs. We propose \\emph{Hint-Engineering}, a new data synthesis strategy that strategically injects diverse hints at optimal points within reasoning paths. This approach generates high-quality, code-integrated reasoning data specifically tailored to optimize LRM-CI interaction. Using this method, we have synthesized 30 high-quality samples to post-train models ranging from 1.5B to 32B parameters through supervised fine-tuning. CoRT further refines the multi-round interleaving of external CI usage and internal thinking by employing rejection sampling and reinforcement learning. Our experimental evaluations demonstrate CoRT's effectiveness, yielding absolute improvements of 4\\% and 8\\% on DeepSeek-R1-Distill-Qwen-32B and DeepSeek-R1-Distill-Qwen-1.5B, respectively, across five challenging mathematical reasoning datasets. Moreover, CoRT significantly enhances efficiency, reducing token usage by approximately 30\\% for the 32B model and 50\\% for the 1.5B model compared to pure natural language reasoning baselines. The models and code are available at: https://github.com/ChengpengLi1003/CoRT.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.117431",
        "filter_reason": "这篇论文完全符合您的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用，而是提出了一种名为CoRT的**后训练框架**，其核心目标是**教会LLM如何更有效地使用工具（代码解释器）**。这直接属于“构建、改进或演化LLM智能体”的范畴。它解决的是智能体在“工具使用”这一核心能力上的关键挑战（内部推理与外部工具知识的冲突），因此不是“非演化型应用”。 2.  **第二步：正面指标** - 论文高度符合您的核心关注点： - **核心范式**: 论文的研究对象是`LLM-based Agents`（或文中的LRMs），其方法论是构建一个改进智能体能力的框架。 - **智能体能力**: 论文的绝对核心是`Tool Use / Tool Augmentation`。同时，它通过优化“多轮交错使用外部CI和内部思考”，直接涉及了智能体的`Planning`和推理循环，这与`ReAct`范式高度一致。虽然未明确提及`Self-Reflection`，但其优化交互过程的目标，本质上是让模型学会更好地反思何时该依赖工具、何时该依赖自身，这是一种元认知能力的体现。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。其主要贡献是关于提升智能体的能力和效率，而非`Safety`、`Alignment`或`Vision`等多模态问题。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是“保留”的典型案例。它并非仅仅提升LLM的基础数学计算能力，而是**提出了一种新的Agentic框架（CoRT）**，来指导智能体如何在复杂任务中通过“思考-行动-观察”的循环进行多步推理。其核心是智能体与工具的交互机制，这正是Agentic AI研究的核心。 **最终决策**: 该论文的核心贡献是提出了一种新颖的训练框架（CoRT），用于显著提升LLM智能体的工具使用效率和效果。它直接解决了智能体在执行复杂任务时如何协调内部推理与外部工具的关键问题，完全符合您研究目标中的“单智能体”方向，特别是“工具使用”和“规划”子方向。因此，应判定为符合要求。"
    },
    {
        "index": "#41",
        "title": "Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding",
        "link": "/arxiv/2510.20176",
        "arxiv_id": "2510.20176",
        "authors": "Yuhang Zhou, Mingrui Zhang, Ke Li, Mingyi Wang, Qiao Liu, Qifei wang, Jiayi Liu, Fei Liu, Serena Li, Weiwi Li, Mingze Gao, Abhishek Kumar, Xiangjun Fan, Zhuokai Zhao, Lizhu Zhang",
        "summary": "Understanding and reasoning over tables is a critical capability for many real-world applications. Large language models (LLMs) have shown promise on this task, but current approaches remain limited. Fine-tuning based methods strengthen language reasoning; yet they are prone to arithmetic errors and hallucination. In contrast, tool-based methods enable precise table manipulation but rely on rigid schemas and lack semantic understanding. These complementary drawbacks highlight the need for approaches that integrate robust reasoning with reliable table processing. In this work, we propose Mixture-of-Minds, a multi-agent framework that decomposes table reasoning into three specialized roles: planning, coding, and answering. This design enables each agent to focus on a specific aspect of the task while leveraging code execution for precise table manipulation. Building on this workflow, we introduce a self-improvement training framework that employs Monte Carlo Tree Search (MCTS) rollouts to generate pseudo-gold trajectories and optimize agents with reinforcement learning (RL). Extensive experiments show that Mixture-of-Minds delivers substantial gains, reaching 62.13% on TableBench and surpassing OpenAI-o4-mini-high. These results demonstrate the promise of combining structured multi-agent workflows with RL to advance table understanding.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.126124",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接命中了你关注的三个核心方向。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质不是简单地将LLM或现有框架应用于表格理解领域，而是**提出了一种全新的多智能体框架（Mixture-of-Minds）和一种配套的自我改进训练机制**。其核心贡献在于方法论创新，即如何构建和优化一个能够协同工作的智能体系统来解决复杂任务。这完全符合“构建、改进或演化 LLM智能体”的核心目标，因此应予以保留。 **第二步：正面指标——高度相关** 论文包含了多个你关注的核心范式和能力指标： *   **多智能体:** 论文的核心是“Mixture-of-Minds”，一个明确提出的“multi-agent framework”，将任务分解为规划、编码、回答三个专门角色，这直接命中了“Multi-Agent Systems (MAS)”和“Collaboration”。 *   **单智能体能力:** 框架中的“planning”智能体直接对应了“Planning”能力；利用代码执行进行表格操作，是典型的“Tool Use / Tool Augmentation”。 *   **自我演化:** 论文明确提出了一个“self-improvement training framework”，使用MCTS和强化学习（RL）来迭代优化智能体。这精准地命中了“Self-Evolving”、“Self-Improvement”和“Iterative Improvement”等核心指标。 **第三步：排除标准——未触发** 论文的主要贡献是关于提升智能体系统的性能和框架设计，而非安全、对齐或多模态。虽然提到了“hallucination”作为现有方法的缺点，但其解决方案是构建新框架，而非以解决幻觉本身为核心贡献。因此，所有排除标准均不适用。 **第四步：处理特殊和模糊情况——完全符合** 1.  **推理/规划:** 论文中的规划是由一个专门的“planning”智能体完成的，是整个Agentic工作流的一部分，而非孤立地提升LLM的基础推理能力。这符合“保留”标准。 2.  **自我演化的应用:** 这篇论文是“自我演化的应用”这一例外情况的完美范例。虽然它应用在“表格理解”这一特定领域，但其核心贡献是**提出了一种新的“自我演化”机制**（基于MCTS和RL的自我改进训练框架）。根据你的规则，即使应用在特定领域，只要核心是新的演化机制，就应该保留。 **最终决策** 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的多智能体协作框架，并为其设计了一套基于强化学习的自我演化训练机制。它同时触及了你研究的三个核心方向：多智能体协作、单智能体的规划与工具使用能力，以及智能体的自我演化。因此，这篇论文与你的研究课题高度相关，是理想的前沿文献。"
    },
    {
        "index": "#70",
        "title": "Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems",
        "link": "/arxiv/2510.20728",
        "arxiv_id": "2510.20728",
        "authors": "Xi He, Sirui Lu, Bei Zeng",
        "summary": "We present a multi-agent, human-in-the-loop workflow that co-designs quantum codes with prescribed transversal diagonal gates. It builds on the Subset-Sum Linear Programming (SSLP) framework (arXiv:2504.20847), which partitions basis strings by modular residues and enforces $Z$-marginal Knill-Laflamme (KL) equalities via small LPs. The workflow is powered by GPT-5 and implemented within TeXRA (https://texra.ai)-a multi-agent research assistant platform that supports an iterative tool-use loop agent and a derivation-then-edit workflow reasoning agent. We work in a LaTeX-Python environment where agents reason, edit documents, execute code, and synchronize their work to Git/Overleaf. Within this workspace, three roles collaborate: a Synthesis Agent formulates the problem; a Search Agent sweeps/screens candidates and exactifies numerics into rationals; and an Audit Agent independently checks all KL equalities and the induced logical action. As a first step we focus on distance $d=2$ with nondegenerate residues. For code dimension $K\\in\\{2,3,4\\}$ and $n\\le6$ qubits, systematic sweeps yield certificate-backed tables cataloging attainable cyclic logical groups-all realized by new codes-e.g., for $K=3$ we obtain order $16$ at $n=6$. From verified instances, Synthesis Agent abstracts recurring structures into closed-form families and proves they satisfy the KL equalities for all parameters. It further demonstrates that SSLP accommodates residue degeneracy by exhibiting a new $((6,4,2))$ code implementing the transversal controlled-phase $diag(1,1,1,i)$. Overall, the workflow recasts diagonal-transversal feasibility as an analytical pipeline executed at scale, combining systematic enumeration with exact analytical reconstruction. It yields reproducible code constructions, supports targeted extensions to larger $K$ and higher distances, and leads toward data-driven classification.",
        "subjects": "Quantum Physics, Artificial Intelligence, Computation and Language, Mathematical Physics",
        "date": "2025-10-23",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.157169",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和应用一个多智能体系统来解决复杂的科学问题。 以下是详细的判断过程： 1.  **第一步：核心判断** - **保留 (Keep)**。这篇论文的本质不是将LLM作为一个简单的"
    },
    {
        "index": "#56",
        "title": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation",
        "link": "/arxiv/2510.19897",
        "arxiv_id": "2510.19897",
        "authors": "Jackson Hassell, Dan Zhang, Hannah Kim, Tom Mitchell, Estevam Hruschka",
        "summary": "We investigate how agents built on pretrained large language models can learn target classification functions from labeled examples without parameter updates. While conventional approaches like fine-tuning are often costly, inflexible, and opaque, we propose a memory-augmented framework that leverages both labeled data and LLM-generated critiques. Our framework uses episodic memory to store instance-level critiques-capturing specific past experiences-and semantic memory to distill these into reusable, task-level guidance. Across a diverse set of tasks, incorporating critiques yields up to a 24.8 percent accuracy improvement over retrieval-based (RAG-style) baselines that rely only on labels. Through extensive empirical evaluation, we uncover distinct behavioral differences between OpenAI and opensource models, particularly in how they handle fact-oriented versus preference-based data. To interpret how models respond to different representations of supervision encoded in memory, we introduce a novel metric, suggestibility. This helps explain observed behaviors and illuminates how model characteristics and memory strategies jointly shape learning dynamics. Our findings highlight the promise of memory-driven, reflective learning for building more adaptive and interpretable LLM agents.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.139254",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了您设定的多个关键方向。 1.  **核心判断 (第一步): 论文本质是构建和改进LLM智能体。** 该论文的核心不是将现有智能体应用到一个新领域，而是提出了一种全新的**方法论**——一个“记忆增强框架”。这个框架旨在解决LLM智能体如何**学习和适应**新任务的核心问题，而无需进行昂贵的模型微调。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **正面指标 (第二步): 高度匹配研究焦点。** *   **单智能体**: 论文的核心是关于智能体的**记忆**机制。它明确提出了使用**情景记忆**和**语义记忆**这两种高级记忆结构，这正是单智能体研究中的关键能力。 *   **自我演化/自我反思**: 论文的标题和摘要都强调了“反思方法”和“智能体适应”。其核心机制是利用LLM生成的**评析**来进行学习，这本质上是一种**自我反思**和**自我修正**的过程。通过这种机制，智能体能够从过往经验中学习，实现**迭代改进** 和**自我完善**，完全符合您对“自我演化”的定义。 *   **核心范式**: 论文聚焦于 **LLM-based Agents**，并探讨了其 **Adaptation** (适应) 和 **Reflective Learning** (反思性学习)。 3.  **排除标准 (第三步): 未触发排除项。** *   论文中提到的“interpretable”（可解释性）和引入的“suggestibility”（可暗示性）指标，其目的并非研究AI安全或对齐，而是作为分析工具，用以**解释和理解他们所提出的智能体框架是如何学习和响应的**。这是对所提框架的深入分析，而非论文的主要贡献，因此不应被排除。 *   论文不涉及多模态、视觉或基础设施等内容。 4.  **特殊情况处理 (第四步): 属于保留范畴。** *   该论文是“自我演化机制”的典型范例。它提出了一种具体的、新颖的演化方式（基于记忆和评析的反思性学习），并将其应用于分类任务。根据您的规则“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”，这篇论文应被明确保留。 **结论**: 该论文提出了一种通过结合情景记忆、语义记忆和自我反思机制来驱动LLM智能体适应和学习的新框架。其核心贡献在于**改进和演化智能体的学习与适应能力**，精准地落在您“单智能体”和“自我演化”的研究焦点上，是一篇高质量的相关论文。"
    },
    {
        "index": "#88",
        "title": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory",
        "link": "/arxiv/2510.19838",
        "arxiv_id": "2510.19838",
        "authors": "Shiqi He, Yue Cui, Xinyu Ma, Yaliang Li, Bolin Ding, Mosharaf Chowdhury",
        "summary": "Autonomous web agents powered by large language models (LLMs) show strong potential for performing goal-oriented tasks such as information retrieval, report generation, and online transactions. These agents mark a key step toward practical embodied reasoning in open web environments. However, existing approaches remain limited in reasoning depth and efficiency: vanilla linear methods fail at multi-step reasoning and lack effective backtracking, while other search strategies are coarse-grained and computationally costly. We introduce Branch-and-Browse, a fine-grained web agent framework that unifies structured reasoning-acting, contextual memory, and efficient execution. It (i) employs explicit subtask management with tree-structured exploration for controllable multi-branch reasoning, (ii) bootstraps exploration through efficient web state replay with background reasoning, and (iii) leverages a page action memory to share explored actions within and across sessions. On the WebArena benchmark, Branch-and-Browse achieves a task success rate of 35.8\\% and reduces execution time by up to 40.4\\% relative to state-of-the-art methods. These results demonstrate that Branch-and-Browse is a reliable and efficient framework for LLM-based web agents.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-10-18",
        "category": "cs.CL",
        "crawl_time": "2025-10-24T11:00:04.178237",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出一个名为 \"Branch-and-Browse\" 的**新框架**，用于构建和改进LLM智能体。它不是简单地将现有智能体作为工具应用，而是针对现有智能体在推理深度和效率上的局限性，提出了一套全新的方法论。因此，它通过了第一步的核心判断，属于应“保留”的论文。 2.  **第二步：正面指标 (高度匹配)** 论文包含了多个你关注的核心正面指标： *   **核心范式**: 论文明确提出了一个 \"LLM-based web agent framework\"，直接命中 `Agentic AI` 和 `LLM-based Agents`。 *   **智能体能力**: *   **规划**: 论文的核心创新之一是 \"tree-structured exploration for controllable multi-branch reasoning\"，这是一种全新的、更精细的智能体**规划**与推理机制，旨在解决多步推理和回溯问题。 *   **记忆**: 论文明确提出了 \"page action memory\" (页面动作记忆)，用于在会话内外共享探索过的动作，这是对智能体**记忆**能力的直接增强。 *   **推理-行动**: 论文强调 \"unifies structured reasoning-acting\"，这与 `ReAct` 等核心范式一脉相承。 3.  **第三步：排除标准 (未触发)** 论文的主要贡献是提升智能体的效率和推理能力，不涉及安全、对齐、可解释性或幻觉等主题。同时，其研究环境是网页，不涉及视觉或多模态模型作为核心研究对象。因此，未触发任何排除标准。 4.  **第四步：特殊情况处理 (清晰符合)** 论文属于典型的“智能体推理/规划”情况。它提出的“树结构化推理”是关于**智能体如何进行规划和决策**的框架，而不是提升LLM本身的基础数学或逻辑能力。这完全符合“保留”的条件。 **结论**: 该论文的核心是构建一个名为 \"Branch-and-Browse\" 的新框架，通过引入**树结构化规划**和**页面动作记忆**机制，显著改进了LLM智能体在复杂网页环境中的推理效率和执行能力。这完全契合你研究课题中“构建、改进LLM智能体”的核心目标，并且属于“单智能体”方向下的“规划”和“记忆”子方向。因此，这篇论文应被保留。"
    },
    {
        "index": "#3",
        "title": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs",
        "link": "/arxiv/2510.20691",
        "arxiv_id": "2510.20691",
        "authors": "Yanlin Song, Ben Liu, Víctor Gutiérrez-Basulto, Zhiwei Hu, Qianqian Xie, Min Peng, Sophia Ananiadou, Jeff Z. Pan",
        "summary": "Knowledge Graph Question Answering aims to answer natural language questions by reasoning over structured knowledge graphs. While large language models have advanced KGQA through their strong reasoning capabilities, existing methods continue to struggle to fully exploit both the rich knowledge encoded in KGs and the reasoning capabilities of LLMs, particularly in complex scenarios. They often assume complete KG coverage and lack mechanisms to judge when external information is needed, and their reasoning remains locally myopic, failing to maintain coherent multi-step planning, leading to reasoning failures even when relevant knowledge exists. We propose Graph-RFT, a novel two-stage reinforcement fine-tuning KGQA framework with a 'plan-KGsearch-and-Websearch-during-think' paradigm, that enables LLMs to perform autonomous planning and adaptive retrieval scheduling across KG and web sources under incomplete knowledge conditions. Graph-RFT introduces a chain-of-thought fine-tuning method with a customized plan-retrieval dataset activates structured reasoning and resolves the GRPO cold-start problem. It then introduces a novel plan-retrieval guided reinforcement learning process integrates explicit planning and retrieval actions with a multi-reward design, enabling coverage-aware retrieval scheduling. It employs a Cartesian-inspired planning module to decompose complex questions into ordered subquestions, and logical expression to guide tool invocation for globally consistent multi-step reasoning. This reasoning retrieval process is optimized with a multi-reward combining outcome and retrieval specific signals, enabling the model to learn when and how to combine KG and web retrieval effectively.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-24T11:00:05.113683",
        "filter_reason": "这篇论文符合研究范围，应予以保留。以下是基于筛选标准的详细判断过程： 1.  **第一步：核心判断——保留** 这篇论文的本质是提出一个名为 **Graph-RFT** 的新颖框架。其核心贡献并非简单地将LLM应用于知识图谱问答（KGQA）领域，而是构建了一个能够让LLM进行**自主规划**和**自适应检索调度**的智能体框架。论文明确提出了一个“plan-KGsearch-and-Websearch-during-think”的范式，这正是一个典型的Agentic框架。因此，它符合“构建、改进LLM智能体的方法论或新框架”的保留标准，而非仅仅是应用。 2.  **第二步：正面指标——高度匹配** 论文内容与我的核心关注点高度重合： *   **核心范式**: 论文构建了一个 `LLM-based Agent`。 *   **智能体能力**: *   `Planning`: 这是论文最核心的贡献之一。它提出了一个“受笛卡尔启发的规划模块”，能够将复杂问题分解为有序的子问题，这是智能体规划能力的关键体现。 *   `Tool Use / Tool Augmentation`: 论文明确提到使用“逻辑表达式来引导工具调用”，工具包括知识图谱（KG）检索和网络搜索。智能体能够自适应地调度这些工具。 *   `ReAct`: 论文的“plan-...-search-during-think”范式与ReAct（Reason+Act）模式高度一致，强调了在行动中进行思考和规划。 *   **演化机制**: 论文使用“强化学习”来优化整个推理和检索过程，并通过“多奖励设计”使模型学会何时以及如何有效结合不同工具。这是一种通过环境反馈进行迭代优化的机制，与“自我演化”方向相关。 3.  **第三步：排除标准——未触发** 论文的主要贡献是方法论和框架创新，而非安全、对齐或多模态。摘要中未提及任何关于`Safety`, `Alignment`, `Vision`等排除标准中的关键词。 4.  **第四步：处理特殊和模糊情况——符合保留条件** *   **推理/规划**: 这篇论文完美地诠释了“保留”情况。它不是在研究如何提升LLM本身的基础逻辑或数学推理能力，而是在研究**如何构建一个智能体框架来执行复杂的多步规划和推理**。其规划模块、工具调度机制和全局一致性追求，都是典型的智能体规划研究，而非单纯的LLM能力增强。 **最终决策**: 综合以上分析，该论文的核心贡献在于构建了一个具备高级**规划**和**工具使用**能力的LLM智能体框架（Graph-RFT）。它通过强化学习优化智能体的决策过程，使其能够在信息不完整的情况下自主行动。这完全符合我研究目标中的“单智能体”方向，特别是规划和工具使用这两个子方向。因此，这篇论文应被判定为符合要求。"
    },
    {
        "index": "#20",
        "title": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation",
        "link": "/arxiv/2510.20310",
        "arxiv_id": "2510.20310",
        "authors": "Mingliang Zhai, Hansheng Liang, Xiaomeng Fan, Zhi Gao, Chuanhao Li, Che Sun, Xu Bin, Yuwei Wu, Yunde Jia",
        "summary": "Embodied Question Answering (EQA) requires agents to explore 3D environments to obtain observations and answer questions related to the scene. Existing methods leverage VLMs to directly explore the environment and answer questions without explicit thinking or planning, which limits their reasoning ability and results in excessive or inefficient exploration as well as ineffective responses. In this paper, we introduce ToolEQA, an agent that integrates external tools with multi-step reasoning, where external tools can provide more useful information for completing the task, helping the model derive better exploration directions in the next step of reasoning and thus obtaining additional effective information. This enables ToolEQA to generate more accurate responses with a shorter exploration distance. To enhance the model's ability for tool-usage and multi-step reasoning, we further design a novel EQA data generation pipeline that automatically constructs large-scale EQA tasks with reasoning trajectories and corresponding answers. Based on the pipeline, we collect the EQA-RT dataset that contains about 18K tasks, divided into a training set EQA-RT-Train, and two test sets EQA-RT-Seen (scenes overlapping with the training set) and EQA-RT-Unseen (novel scenes). Experiments on EQA-RT-Seen and EQA-RT-Unseen show that ToolEQA improves the success rate by 9.2~20.2% over state-of-the-art baselines, while outperforming the zero-shot ToolEQA by 10% in success rate. In addition, ToolEQA also achieves state-of-the-art performance on the HM-EQA, OpenEQA, and EXPRESS-Bench datasets, demonstrating its generality. Our homepage see https://tooleqa.github.io.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-24T11:00:05.132835",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的本质是构建一个名为 `ToolEQA` 的新智能体框架。其核心贡献并非简单地将LLM应用于具身问答（EQA）领域，而是提出了一种**方法论**：通过“工具增强”和“多步推理”来改进智能体在复杂环境中的探索和决策能力。这完全符合“构建、改进LLM智能体”的核心目标。 **第二步：正面指标分析** - **核心范式**: 论文明确提出了一个基于LLM的智能体（`ToolEQA`），属于 `Agentic AI` 和 `LLM-based Agents` 范畴。 - **智能体能力**: 论文的核心亮点在于 `Tool Augmentation`（工具使用）和 `Multi-Step Reasoning`（多步推理）。这直接命中了我的研究焦点“单智能体”中的“工具使用”和“规划/推理”能力。其工作流程（推理 -> 使用工具 -> 获得信息 -> 下一步推理）与 `ReAct` 等经典智能体范式高度一致。 - **多智能体**: 不涉及。 - **演化机制**: 不直接涉及自我演化，但其迭代式的推理过程（`derive better exploration directions in the next step`）体现了智能体在任务执行过程中的动态调整和改进，这与智能体的自主性紧密相关。 **第三步：排除标准分析** - **安全与对齐**: 论文未涉及 `Safety`, `Alignment`, `Hallucination` 等主题，其目标是提升任务成功率，而非安全性或可解释性。 - **多模态与视觉**: 论文确实涉及了视觉（`VLMs`, `3D environments`），但根据我的核心规则，视觉在这里是作为智能体**感知环境的工具**，而不是研究的核心。论文的核心贡献是“如何利用工具进行推理”，而不是“如何改进视觉模型本身”。因此，这不构成排除理由。 **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是典型的“保留”案例。它不是在研究如何提升LLM的基础数学或逻辑能力，而是在研究一个**智能体框架**如何通过规划和多步推理来完成一个复杂的具身任务。这正是我所关注的“Agentic”层面的推理。 **第五步：最终决策** 综合以上分析，论文 `ToolEQA` 的核心贡献是提出了一种新的智能体框架，该框架通过整合工具使用和多步推理来显著提升智能体在具身问答任务中的表现。这完全符合我研究课题中“单智能体 (Agentic)”方向，特别是“规划”和“工具使用”这两个子方向。因此，这篇论文高度相关，应被保留。"
    },
    {
        "index": "#34",
        "title": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents",
        "link": "/arxiv/2510.19949",
        "arxiv_id": "2510.19949",
        "authors": "Mathieu Andreux, Märt Bakler, Yanael Barbier, Hamza Ben Chekroun, Emilien Biré, Antoine Bonnet, Riaz Bordie, Nathan Bout, Matthias Brunel, Aleix Cambray, Pierre-Louis Cedoz, Antoine Chassang, Gautier Cloix, Ethan Connelly, Alexandra Constantinou, Ramzi De Coster, Hubert de la Jonquiere, Aurélien Delfosse, Maxime Delpit, Alexis Deprez, Augustin Derupti, Mathieu Diaz, Shannon D'Souza, Julie Dujardin, Abai Edmund, Michael Eickenberg, Armand Fatalot, Wissem Felissi, Isaac Herring, Xavier Koegler, Erwan Le Jumeau de Kergaradec, Aurélien Lac, Maxime Langevin, Corentin Lauverjat, Antonio Loison, Avshalom Manevich, Axel Moyal, Axel Nguyen Kerbel, Marinela Parovic, Julien Revelle, Guillaume Richard, Mats Richter, Ronan Riochet, María Santos, Romain Savidan, Laurent Sifre, Maxime Theillard, Marc Thibault, Ivan Valentini, Tony Wu, Laura Yie, Kai Yuan, Jevgenij Zubovskij",
        "summary": "Building agents that generalize across web, desktop, and mobile environments remains an open challenge, as prior systems rely on environment-specific interfaces that limit cross-platform deployment. We introduce Surfer 2, a unified architecture operating purely from visual observations that achieves state-of-the-art performance across all three environments. Surfer 2 integrates hierarchical context management, decoupled planning and execution, and self-verification with adaptive recovery, enabling reliable operation over long task horizons. Our system achieves 97.1% accuracy on WebVoyager, 69.6% on WebArena, 60.1% on OSWorld, and 87.1% on AndroidWorld, outperforming all prior systems without task-specific fine-tuning. With multiple attempts, Surfer 2 exceeds human performance on all benchmarks. These results demonstrate that systematic orchestration amplifies foundation model capabilities and enables general-purpose computer control through visual interaction alone, while calling for a next-generation vision language model to achieve Pareto-optimal cost-efficiency.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-24T11:00:05.145302",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为“Surfer 2”的**全新计算机使用智能体架构**。它的核心贡献是**构建和改进LLM智能体**，而不是将现有智能体应用到一个特定领域。论文旨在解决智能体跨平台泛化的根本性挑战，属于Agentic AI领域的方法论创新。 2.  **第二步：正面指标** - 论文与您的核心关注点高度匹配，包含了多个关键指标： - **核心范式**: 论文明确是关于 `LLM-based Agents` 的研究。 - **智能体能力**: 论文的核心创新点直接对应了您关注的多个单智能体能力： - `Planning`: 论文明确提出了“解耦的规划和执行”。 - `Memory`: “分层上下文管理”是一种高级的记忆机制。 - `Self-Correction / Self-Reflection`: “自我验证与自适应恢复”是典型的自我反思和纠错能力。 - 这些能力的组合（规划、记忆、自我纠错）共同构成了一个更强大、更可靠的智能体框架，这正是您研究焦点“单智能体”方向的核心内容。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主要贡献不涉及安全、对齐、可解释性或幻觉问题。 - **多模态与视觉**: 这是一个关键点。虽然论文大量依赖视觉输入，但它完全符合特殊规则：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉是Surfer 2智能体感知计算机屏幕（环境）的手段，而论文的**核心贡献是智能体的架构（规划、记忆、自我验证机制）**，而不是改进视觉语言模型本身。因此，不应被排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确是关于智能体如何在复杂、长周期的任务中进行规划和执行的，这完全符合“保留”条件。它超越了基础的LLM推理，进入了智能体自主决策的范畴。 **总结**: Surfer 2的核心贡献在于提出了一种创新的、统一的智能体架构，通过系统性地整合规划、记忆和自我纠错等关键能力，显著提升了LLM智能体在复杂环境中的性能和泛化能力。这完全契合您“构建、改进或演化LLM智能体”的核心目标，特别是“单智能体”方向的研究。因此，这篇论文是高度相关的前沿研究，应被筛选出来。"
    },
    {
        "index": "#24",
        "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048",
        "link": "/arxiv/2510.20205",
        "arxiv_id": "2510.20205",
        "authors": "Maggie Bai, Ava Kim Cohen, Eleanor Koss, Charlie Lichtenbaum",
        "summary": "Optimizing artificial intelligence (AI) for dynamic environments remains a fundamental challenge in machine learning research. In this paper, we examine evolutionary training methods for optimizing AI to solve the game 2048, a 2D sliding puzzle. 2048, with its mix of strategic gameplay and stochastic elements, presents an ideal playground for studying decision-making, long-term planning, and dynamic adaptation. We implemented two distinct systems: a two-agent metaprompting system where a \"thinker\" large language model (LLM) agent refines gameplay strategies for an \"executor\" LLM agent, and a single-agent system based on refining a value function for a limited Monte Carlo Tree Search. We also experimented with rollback features to avoid performance degradation. Our results demonstrate the potential of evolutionary refinement techniques in improving AI performance in non-deterministic environments. The single-agent system achieved substantial improvements, with an average increase of 473.2 points per cycle, and with clear upward trends (correlation $\\rho$=0.607) across training cycles. The LLM's understanding of the game grew as well, shown in its development of increasingly advanced strategies. Conversely, the two-agent system did not garner much improvement, highlighting the inherent limits of meta-prompting.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-24T11:00:05.134620",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献直接聚焦于LLM智能体的构建与演化。我的判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心并非简单地应用LLM去玩2048游戏，而是**提出并比较了两种用于优化和演化AI智能体的方法论**。摘要明确指出，论文研究了“evolutionary training methods”（演化训练方法），并实现了两个系统：一个“two-agent metaprompting system”（双智能体元提示系统）和一个“single-agent system based on refining a value function”（基于精炼价值函数的单智能体系统）。这表明论文的本质是关于**如何构建和演化智能体**，而非将智能体作为工具解决特定领域问题。因此，它通过了第一步的核心判断。 2.  **第二步：正面指标 (高度匹配)** 论文包含了你关注的所有核心范式和能力： *   **多智能体:** 论文明确提出了一个“two-agent metaprompting system”，其中包含“thinker”和“executor”两个角色，这直接对应了多智能体系统的研究。 *   **自我演化:** 论文的标题和摘要反复强调“Evolutionarily Optimizing”、“evolutionary refinement techniques”和“training cycles”，这完全命中了“Self-Evolving”这一核心方向。论文展示了智能体在迭代过程中性能提升和策略发展，是自我演化的典型体现。 *   **单智能体:** 论文研究的另一个系统是“single-agent system”，并涉及“refining a value function”，这属于单智能体的能力优化范畴。 *   **智能体能力:** “thinker”智能体“refines gameplay strategies”体现了**自我反思/自我修正**；在2048游戏中取得高分需要**规划**和长期决策能力。 3.  **第三步：排除标准 (不适用)** 论文的主要贡献不涉及安全、对齐或多模态，因此不触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况 (适用例外规则)** 这篇论文是“自我演化的应用”这一特殊情况的完美范例。虽然它应用在2048这个特定游戏上，但其**核心贡献是提出并验证了一种“自我演化”的机制**（即通过迭代训练来精炼策略或价值函数）。根据你的规则，“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留”。这篇论文正是如此，它使用2048作为一个理想的“playground”（试验场）来研究其演化方法的有效性。 **结论:** 该论文的核心贡献在于构建和演化LLM智能体，同时覆盖了你关注的单智能体、多智能体和自我演化三个方向。它通过一个具体的游戏环境，深入探讨了智能体如何通过演化机制进行自我完善和迭代，这与你的研究目标“LLM智能体及其演化”高度契合。因此，应予以保留。"
    },
    {
        "index": "#22",
        "title": "Using Large Language Models for Abstraction of Planning Domains - Extended Version",
        "link": "/arxiv/2510.20258",
        "arxiv_id": "2510.20258",
        "authors": "Bita Banihashemi, Megh Patel, Yves Lespérance",
        "summary": "Generating an abstraction of a dynamic domain that aligns with a given purpose remains a significant challenge given that the choice of such an abstraction can impact an agent's ability to plan, reason, and provide explanations effectively. We model the agent's concrete behaviors in PDDL and investigate the use of in-context learning with large language models (LLMs) for the generation of abstract PDDL domains and problem instances, given an abstraction objective specified in natural language. The benchmark examples we use are new and have not been part of the data any LLMs have been trained on. We consider three categories of abstractions: abstraction of choice of alternative concrete actions, abstraction of sequences of concrete actions, and abstraction of action/predicate parameters, as well as combinations of these. The generated abstract PDDL domains and problem instances are then checked by symbolic validation tools as well as human experts. Our experiments show that GPT-4o can generally synthesize useful planning domain abstractions in simple settings, although it is better at abstracting over actions than over the associated fluents.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-24T11:00:05.133715",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** - **论文本质**: 这篇论文的核心贡献是提出一种**新的方法论**，即利用LLM为智能体生成抽象的规划领域。这并非将LLM或智能体框架简单地应用到一个外部领域（如医疗、金融），而是直接作用于智能体本身的核心能力——**规划**。 - **符合目标**: 论文的研究直接服务于“构建、改进或演化LLM智能体”这一核心目标。通过改进规划领域的抽象质量，它直接提升了智能体的规划效率和效果，属于对单智能体能力的**改进**。 2.  **第二步：正面指标 (高度匹配)** - **核心范式**: 论文内容紧密围绕 `LLM-based Agents`。 - **智能体能力**: 论文的焦点是 `Planning`。摘要中明确提到其研究目标是提升 \"agent's ability to plan, reason, and provide explanations effectively\"（智能体有效规划、推理和提供解释的能力）。这正是你研究焦点中“单智能体”方向的核心子方向。 3.  **第三步：排除标准 (未触发)** - 论文的主要贡献不涉及安全、对齐、可解释性（虽然提到了解释，但那是规划能力带来的结果，而非研究本身的主题）、水印或幻觉。 - 论文不涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况 (明确符合保留规则)** - **推理/规划**: 这篇论文是“关于智能体如何进行规划”的典型范例。它不是在提升LLM的基础数学或逻辑推理能力，而是在研究如何利用LLM来**辅助智能体完成一个更高级的规划任务**——即创建规划问题的抽象。这完全符合“保留”规则：“如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）”。 **总结**: 该论文的核心是提出一种增强LLM智能体**规划能力**的新方法。它通过利用LLM生成更优的规划领域抽象，直接解决了智能体在复杂任务中如何更有效规划这一根本性问题。这完全契合你研究课题中的“单智能体”方向，特别是“规划”这一子方向。因此，这篇论文是高度相关且应该被保留的前沿研究。"
    },
    {
        "index": "#66",
        "title": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection",
        "link": "/arxiv/2510.20653",
        "arxiv_id": "2510.20653",
        "authors": "Jack Butler, Nikita Kozodoi, Zainab Afolabi, Brian Tyacke, Gaiar Baimuratov",
        "summary": "As Large Language Models (LLMs) continue to evolve, practitioners face increasing options for enhancing inference-time performance without model retraining, including budget tuning and multi-step techniques like self-reflection. While these methods improve output quality, they create complex trade-offs among accuracy, cost, and latency that remain poorly understood across different domains. This paper systematically compares self-reflection and budget tuning across mathematical reasoning and translation tasks. We evaluate prominent LLMs, including Anthropic Claude, Amazon Nova, and Mistral families, along with other models under varying reflection depths and compute budgets to derive Pareto optimal performance frontiers. Our analysis reveals substantial domain dependent variation in self-reflection effectiveness, with performance gains up to 220\\% in mathematical reasoning. We further investigate how reflection round depth and feedback mechanism quality influence performance across model families. To validate our findings in a real-world setting, we deploy a self-reflection enhanced marketing content localisation system at Lounge by Zalando, where it shows market-dependent effectiveness, reinforcing the importance of domain specific evaluation when deploying these techniques. Our results provide actionable guidance for selecting optimal inference strategies given specific domains and resource constraints. We open source our self-reflection implementation for reproducibility at https://github.com/aws-samples/sample-genai-reflection-for-bedrock.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-10-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-24T11:00:05.177620",
        "filter_reason": "这篇论文的核心贡献在于对LLM智能体的一个关键能力——**自我反思**——进行了系统性的分析和评估，完全符合你的研究范围。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的本质不是将LLM或智能体框架作为工具去解决一个特定领域（如营销）的问题。它的核心是**“systematically compares self-reflection”**（系统性比较自我反思）和**“investigate how reflection round depth and feedback mechanism quality influence performance”**（研究反思轮次深度和反馈机制质量如何影响性能）。 - 这表明论文的核心贡献是**构建和改进LLM智能体的方法论**，具体来说是深入理解和优化“自我反思”这一Agentic能力。它不是非演化型应用，也不是非Agentic的基础推理研究。 2.  **第二步：正面指标——高度相关** - 论文明确包含了多个核心关注点：`Self-Reflection`（自我反思）、`Self-Correction`（自我纠正，是反思的结果）、`Iterative Improvement`（迭代改进，反思过程本身就是迭代的）。 - 这些关键词直接命中了你研究焦点中的“单智能体”和“自我演化”方向。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等排除领域。它的焦点是智能体的性能和效率。 4.  **第四步：处理特殊和模糊情况——符合保留规则** - **推理/规划**: 论文研究的`self-reflection`是一种典型的多步、自主的Agentic推理框架，不同于单纯提升LLM基础数学或逻辑能力的研究，因此符合保留条件。 - **自我演化的应用**: 论文中提到的营销内容本地化系统是一个应用案例。但根据你的核心规则，这篇论文的核心是提出并分析一种“自我反思”机制，而不是应用本身。因此，这属于“核心是提出一种新的‘自我演化’机制”的例外情况，应该保留。该应用案例是用来验证其核心发现的，而非论文的主要贡献。 **最终决策**: 这篇论文通过对“自我反思”这一核心Agentic能力的深度剖析，为如何构建、改进和评估LLM智能体提供了重要的实证依据和指导。其研究内容直接对齐了你的“单智能体”和“自我演化”研究方向，因此应被**保留**。"
    },
    {
        "index": "#128",
        "title": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents",
        "link": "/arxiv/2510.20211",
        "arxiv_id": "2510.20211",
        "authors": "Zhenning Yang, Hui Guan, Victor Nicolet, Brandon Paulsen, Joey Dodds, Daniel Kroening, Ang Chen",
        "summary": "Cloud infrastructure is managed through a mix of interfaces -- traditionally, cloud consoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the infrastructure in a \"source-of-truth\" configuration. They are capable of automatically carrying out modifications to the cloud -- deploying, updating, or destroying resources -- to bring the actual infrastructure into alignment with the IaC configuration. However, when IaC is used alongside consoles, CLIs, or SDKs, it loses visibility into external changes, causing infrastructure drift, where the configuration becomes outdated, and later IaC operations may undo valid updates or trigger errors. We present NSync, an automated system for IaC reconciliation that propagates out-of-band changes back into the IaC program. Our key insight is that infrastructure changes eventually all occur via cloud API invocations -- the lowest layer for cloud management operations. NSync gleans insights from API traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update the IaC configuration to capture the changes). It employs an agentic architecture that leverages LLMs to infer high-level intents from noisy API sequences, synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base of past reconciliations. We further introduce a novel evaluation pipeline for injecting realistic drifts into cloud infrastructure and assessing reconciliation performance. Experiments across five real-world Terraform projects and 372 drift scenarios show that NSync outperforms the baseline both in terms of accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\\times$ improvement).",
        "subjects": "Software Engineering, Artificial Intelligence, Machine Learning",
        "date": "2025-10-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-24T11:00:05.236243",
        "filter_reason": "这篇论文符合你的研究范围，其核心贡献与你的研究目标高度一致。以下是根据你的筛选标准进行的详细判断过程： **第一步：核心判断——这篇论文的本质是什么？** - **保留 (Keep)**。这篇论文的本质是**构建一个具有自我演化能力的LLM智能体（NSync）**来解决一个特定问题（云基础设施IaC对账）。论文的核心贡献不是解决云基础设施问题本身，而是提出了一种新的智能体架构和方法论。摘要明确指出：“It employs an agentic architecture that leverages LMs to infer high-level intents... synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base...”。这完全符合“构建、改进或演化LLM智能体”的核心目标。 - 它不属于“非演化型应用”，因为其核心是提出一个**新的自我演化机制**（self-evolving knowledge base），而不是简单地将现有框架（如ReAct）作为工具应用。 - 它不属于“非Agentic的推理”，因为其方法明确涉及智能体规划（从API序列推断意图）、工具使用（使用专门的工具合成IaC更新）和自我演化。 - 它不属于“基础设施”，因为其焦点是智能体的算法和架构，而非模型部署或硬件加速。 **第二步：正面指标——论文是否包含我的核心关注点？** 这篇论文包含了大量你的核心关注点，相关性极强： - **核心范式**: `Agentic AI`, `LLM-based Agents`, `Self-Evolving`。摘要直接使用了“agentic architecture”和“self-evolving knowledge base”。 - **智能体能力**: `Planning`（从API序列推断高层意图）、`Tool Use / Tool Augmentation`（使用专门的工具来合成IaC更新）、`Self-Correction`（对账过程本身就是一种纠正）。 - **演化机制**: `Self-Improvement`, `Iterative Improvement`。论文的核心亮点之一就是“continually improve through a self-evolving knowledge base of past reconciliations”，这直接命中了“自我演化”方向。 **第三步：排除标准——是否为我的研究焦点之外？** - **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性，因此不在此排除范围内。 - **多模态与视觉**: 论文不涉及视觉或多模态内容，因此不在此排除范围内。 **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这正是你筛选标准中提到的**例外情况**。论文虽然应用在“云基础设施”这一特定领域，但其核心贡献是提出了一种**新的“自我演化”机制**（通过不断学习过去的对账经验来改进知识库）。根据你的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 因此，这篇论文应该被保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种**集成了规划、工具使用和自我演化能力的LLM智能体架构（NSync）**。它不仅是一个智能体应用，更是一个在智能体方法论上有所创新的研究，特别是在“自我演化”方向上。虽然其应用场景是云基础设施，但这恰恰是验证其智能体框架有效性的一个实例，完全符合你筛选“构建、改进或演化LLM智能体”论文的核心目标。 因此，最终判断为 **True**。"
    },
    {
        "index": "#116",
        "title": "UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning",
        "link": "/arxiv/2510.20286",
        "arxiv_id": "2510.20286",
        "authors": "Liangyu Chen, Hanzhang Zhou, Chenglin Cai, Jianan Zhang, Panrong Tong, Quyu Kong, Xu Zhang, Chen Liu, Yuqi Liu, Wenxuan Wang, Yue Wang, Qin Jin, Steven Hoi",
        "summary": "GUI grounding, which maps natural-language instructions to actionable UI elements, is a core capability of GUI agents. Prior works largely treats instructions as a static proxy for user intent, overlooking the impact of instruction diversity and quality on grounding performance. Through a careful investigation of existing grounding datasets, we find a 23.3% flaw rate in their instructions and show that inference-time exploitation of instruction diversity yields up to a substantial 76% relative performance improvement. In this paper, we introduce the Instruction-as-Reasoning paradigm, treating instructions as dynamic analytical pathways that offer distinct perspectives and enabling the model to select the most effective pathway during reasoning. To achieve this, we propose a two-stage training framework: supervised fine-tuning (SFT) on synthesized, diverse instructions to instill multi-perspective reasoning, followed by reinforcement learning (RL) to optimize pathway selection and composition. Our resulting models, UI-Ins-7B and UI-Ins-32B, achieve state-of-the-art results on five challenging grounding benchmarks and exhibit emergent reasoning, selectively composing and synthesizing novel instruction pathways at inference. In particular, UI-Ins-32B attains the best grounding accuracy, scoring 87.3% on UI-I2E-Bench, 57.0% on ScreenSpot-Pro, and 84.9% on MMBench-GUI L2. Furthermore, our model demonstrates strong agentic potential, achieving a 74.1% success rate on AndroidWorld using UI-Ins-7B as the executor. Our in-depth analysis reveals additional insights such as how reasoning can be formulated to enhance rather than hinder grounding performance, and how our method mitigates policy collapse in the SFT+RL framework. All code and model checkpoints will be publicly released in https://github.com/alibaba/UI-Ins.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-24T11:00:05.225167",
        "filter_reason": "这篇论文的核心贡献是提出了一种名为“Instruction-as-Reasoning”的新范式，以及一个相应的两阶段训练框架（SFT+RL），用于增强GUI智能体的核心能力——GUI grounding。尽管其应用领域是GUI，但这篇论文完全符合你的研究范围，具体判断过程如下： 1.  **第一步：核心判断——保留** - **本质是构建/改进智能体框架**：这篇论文的本质并非简单地将LLM应用于GUI领域。它提出了一种全新的方法论，将“指令”从静态的用户意图代理，转变为动态的、可供选择的“推理路径”。这是一个关于**如何改进智能体推理过程**的根本性贡献，属于构建和改进LLM智能体的范畴。 - **不属于非演化型应用**：虽然论文在GUI grounding任务上进行了验证，但其核心贡献是通用的“多视角推理”范式和训练方法，而不是一个针对特定领域的应用解决方案。作者自己也强调其模型展现了“strong agentic potential”，并在智能体基准测试AndroidWorld上取得了成功，这表明其贡献超越了单一任务，具有智能体层面的普适性。 2.  **第二步：正面指标——高度相关** - **核心范式**：论文明确提出了一个新的智能体范式“Instruction-as-Reasoning”，这与你的关注点`Agentic AI`和`LLM-based Agents`高度契合。 - **智能体能力**：论文的核心是关于智能体如何进行`Reasoning`和`Planning`。它让模型在推理时“select the most effective pathway”（选择最有效的路径），这本质上是一种高级的规划和决策能力。其RL优化阶段也涉及`Self-Correction`或`Self-Refine`的机制，以优化路径选择。 - **框架**：其提出的两阶段训练框架（SFT+RL）是对现有智能体构建方法的改进，与`ReAct`等经典框架一样，都属于Agentic AI的方法论创新。 3.  **第三步：排除标准——不适用** - **安全与对齐**：论文的主要贡献不涉及安全、对齐或可解释性。 - **多模态与视觉**：虽然GUI grounding涉及视觉元素，但视觉在这里是智能体感知环境的**工具**。论文的核心贡献不是一个新的视觉模型或多模态融合技术，而是**如何利用这些感知信息进行更优的推理**。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”这一例外条款。 4.  **第四步：处理特殊和模糊情况——符合保留条件** - **推理/规划**：这是本论文最关键的一点。它完全符合“保留”条件：“论文是关于智能体如何进行规划或在复杂任务中进行多步推理”。它提出的“Instruction-as-Reasoning”正是一种新的多步推理框架，超越了简单的CoT，进入了动态路径选择的层面。 **最终决策**： 这篇论文的核心是提出了一种创新的智能体推理范式和训练方法，旨在提升智能体在复杂任务中的规划和决策能力。它直接命中了你研究焦点中的“单智能体”方向，特别是“规划”和“自我反思/修正”子方向。尽管其验证场景是GUI，但其方法论贡献是普适的、面向Agentic AI的。因此，这篇论文与你的研究目标高度相关，应该被保留。"
    },
    {
        "index": "#85",
        "title": "SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph",
        "link": "/arxiv/2510.20022",
        "arxiv_id": "2510.20022",
        "authors": "Jiazheng Li, Yawei Wang, David Yan, Yijun Tian, Zhichao Xu, Huan Song, Panpan Xu, Lin Lee Cheong",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities, enabling language agents to excel at single-turn tasks. However, their application to complex, multi-step, and long-horizon tasks remains challenging. While reinforcement learning (RL) offers a promising avenue for addressing these challenges, mainstream approaches typically rely solely on sparse, outcome-based rewards, a limitation that becomes especially problematic for group-based RL algorithms lacking critic models, such as Group Relative Policy Optimization (GRPO). In such methods, uniformly rewarding or penalizing all actions within a trajectory can lead to training instability and suboptimal policies, because beneficial and detrimental actions are often entangled across multi-step interactions. To address this challenge, we propose SALT, a novel and lightweight framework that provides a finer-grained advantage assignment, derived solely from outcome rewards. We achieve this by constructing a graph from trajectories of the same prompt, which allows us to quantify the quality of each step and assign advantages accordingly. Crucially, SALT is designed as a plug-and-play module that seamlessly integrates with existing group-based RL algorithms, requiring no modifications to the rollout procedure and introducing negligible computational overhead. Extensive experiments on the WebShop, ALFWorld, and AppWorld benchmarks with various model sizes demonstrate that SALT consistently improves performance. We also conduct a thorough analysis to validate the design choices behind SALT and offer actionable insights.",
        "subjects": "Machine Learning",
        "date": "2025-10-22",
        "category": "cs.LG",
        "crawl_time": "2025-10-24T11:00:05.170685",
        "filter_reason": "这篇论文完全符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体应用于某个特定领域，而是提出了一种名为SALT的**新框架**，其核心目标是**改进LLM智能体的训练过程**。它解决了长时程智能体在强化学习训练中因奖励稀疏而导致的训练不稳定问题。这直接属于“构建、改进或演化LLM智能体”的方法论研究，符合你的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **核心范式**: 论文明确研究 `LLM-based Agents`，特别是 `Long-horizon Agents`。 - **智能体能力**: 论文的核心是解决智能体在 `复杂、多步、长时程任务` 中的表现问题，这直接关联到 `Planning`（规划）能力。通过强化学习进行优化，也体现了 `Iterative Improvement`（迭代改进）。 - **演化机制**: 整个论文的框架是基于强化学习（RL）来优化智能体的策略，这是一种典型的通过环境反馈进行自我完善和迭代的 `Self-Evolving` 机制。 3.  **第三步：排除标准** - 论文未命中任何排除标准。其研究焦点是提升智能体的任务执行性能和训练效率，完全不涉及 `Safety`、`Alignment`、`Interpretability` 或 `Vision` 等主题。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于“智能体如何进行规划或在复杂任务中进行多步推理”的**典型范例**。它不是在改进LLM本身的基础推理能力（如数学计算），而是在改进智能体在长序列行动中学习如何规划的能力。因此，根据规则，应该**保留**。 - **自我演化的应用**: 虽然论文在WebShop、ALFWorld等基准上测试，但其核心贡献是SALT这个通用的训练框架，而不是针对某个特定领域的应用。因此，它完全符合你的研究焦点。 **最终决策**: 这篇论文的核心贡献是提出了一种新颖的、即插即用的框架（SALT），用于更有效地训练长时程LLM智能体。它通过改进强化学习中的优势分配机制，直接提升了智能体的规划和执行能力，属于对LLM智能体本身的**改进和演化**。因此，它与你的研究课题“LLM智能体及其演化”高度相关，应被保留。"
    }
]