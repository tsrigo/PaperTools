[
    {
        "index": "#9",
        "title": "MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation",
        "link": "/arxiv/2512.05671",
        "arxiv_id": "2512.05671",
        "authors": "Zhitao He, Haolin Yang, Zeyu Qin, Yi R Fung",
        "summary": "The significant gap between rising demands for clinical training and the scarcity of expert instruction poses a major challenge to medical education. With powerful capabilities in personalized guidance, Large Language Models (LLMs) offer a promising solution to bridge this gap. However, current research focuses mainly on one-on-one knowledge instruction, overlooking collaborative reasoning, a key skill for students developed in teamwork like ward rounds. To this end, we develop ClinEdu, a multi-agent pedagogical simulator with personality-driven patients and diverse student cohorts, enabling controlled testing of complex pedagogical processes and scalable generation of teaching data. Based on ClinEdu, we construct ClinTeach, a large Socratic teaching dialogue dataset that captures the complexities of group instruction. We then train MedTutor-R1, the first multimodal Socratic tutor designed for one-to-many instruction in clinical medical education. MedTutor-R1 is first instruction-tuned on our ClinTeach dataset and then optimized with reinforcement learning, using rewards derived from a three-axis rubric, covering structural fidelity, analytical quality, and clinical safety, to refine its adaptive Socratic strategies. For authentic in-situ assessment, we use simulation-based interactive evaluation that redeploys the tutor back into ClinEdu. Experimental results demonstrate that our MedTutor-R1 outperforms the base model by over 20% in average pedagogical score and is comparable to o3, while also exhibiting high adaptability in handling a varying number of students. This promising performance underscores the effectiveness of our pedagogical simulator, ClinEdu.",
        "subjects": "Computation and Language",
        "date": "2025-12-05",
        "category": "cs.CL",
        "crawl_time": "2025-12-08T11:00:04.185631",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进LLM智能体系统，而非简单的应用。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非“用LLM解决医学教育问题”，而是**构建了一个全新的多智能体教学模拟器（ClinEdu）和一个基于该模拟器的导师智能体（MedTutor-R1）**。这完全符合“构建LLM智能体”和“多智能体系统”的定义。论文的本质是提出一种新的Agentic框架和方法论，医学教育只是其验证和应用的场景。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度匹配** 论文包含了大量您关注的核心指标： *   **核心范式**: 明确提出了 `Multi-Agent Systems (MAS)`，即ClinEdu模拟器，其中包含“人格驱动的患者”和“多样化的学生群体”。 *   **多智能体**: 论文的核心是解决“协作推理”的缺失，其模拟器就是为了模拟多智能体间的 `Collaboration` 和 `Communication`。 *   **智能体能力**: MedTutor-R1作为一个导师智能体，其核心能力是执行“自适应的苏格拉底式策略”，这本质上是一种复杂的 `Planning` 和交互式推理能力。 *   **演化机制**: 论文使用强化学习对MedTutor-R1进行优化，以“改进其自适应的苏格拉底式策略”，这是一种 `Iterative Improvement` 和 `Self-Refine` 的体现，虽然不是完全自主的“自我演化”，但属于对智能体能力的改进和演化。 3.  **第三步：排除标准——不适用** *   **安全与对齐**: 论文中提到的“临床安全”是作为强化学习奖励函数的一个维度，用于优化智能体的教学策略。它不是论文的主要研究贡献，论文的核心是智能体的构建和教学方法，而非安全对齐技术本身。 *   **多模态与视觉**: 论文提到MedTutor-R1是“多模态的”，但这只是智能体的一个特性，并非研究的核心。研究的核心是其在多智能体环境中的教学策略和交互能力，而不是其多模态感知技术。 4.  **第四步：特殊和模糊情况——不适用** 论文清晰地聚焦于构建一个多智能体框架（ClinEdu）和一个在该框架中运行的智能体（MedTutor-R1），其规划（苏格拉底式策略）和交互（一对多教学）是典型的Agentic AI研究。 **最终决策**: 该论文的核心贡献是**构建了一个新颖的多智能体模拟器（ClinEdu）和一个导师智能体（MedTutor-R1）**，旨在解决多智能体协作和教学策略问题。这直接命中了您研究目标中的“多智能体”和“单智能体”方向。尽管其应用场景是医学教育，但论文的重点在于提出和验证一种新的Agentic AI方法论，因此完全符合筛选要求。"
    },
    {
        "index": "#16",
        "title": "Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment",
        "link": "/arxiv/2512.05464",
        "arxiv_id": "2512.05464",
        "authors": "Panatchakorn Anantaprayoon, Nataliia Babina, Jad Tarifi, Nima Asgharbeygi",
        "summary": "Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-05",
        "category": "cs.CL",
        "crawl_time": "2025-12-08T11:00:04.187474",
        "filter_reason": "这篇论文符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用，也不是提升LLM的基础推理能力。其核心贡献是提出了一种名为“Dynamic Alignment”的**自我改进框架**。这个框架使LLM能够通过自我评估和自我奖励的机制，**迭代地对齐自身**。这完全符合你研究范围中的“自我演化”方向，即智能体通过内部机制进行自我完善和迭代。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Self-Evolving` (自我演化) 是该论文的核心主题。 - **演化机制**: `Self-Improvement` (自我改进) 和 `Iterative Improvement` (迭代改进) 是论文提出框架的关键组成部分。 - **智能体能力**: 论文引入了 `Collective Agency (CA)` (集体智能体) 这一概念，旨在鼓励“集成的智能体能力”，这直接关联到你的“Agentic AI”研究焦点。 3.  **第三步：排除标准** - **安全与对齐**: 这是本案例中最需要仔细辨析的一点。虽然论文标题和摘要大量使用了“Alignment”（对齐）一词，但需要判断其**主要贡献**是否是关于对齐技术本身。 - 我的判断是：这篇论文的**主要贡献是“自我演化”的方法论**，而不是“对齐”的具体技术。论文将“对齐”作为自我演化过程的一个**目标或应用场景**，但其核心创新点在于那个可扩展的、自我迭代的框架（包括自动数据生成和自我奖励机制）。这与一篇主要贡献是提出新的对齐原则、安全微调方法或红队测试技术的论文有本质区别。因此，它不应被归入“安全与对齐”的排除类别。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文完美地符合“自我演化的应用”这一例外规则。论文的核心是提出一种**新的“自我演化”机制**（Dynamic Alignment框架），即使它被应用在“对齐”这个特定领域，也应该被保留。你的研究焦点是智能体如何演化，而这篇论文恰好提供了一个关于智能体如何自我演化其能力（在这里是对齐能力和集体智能体能力）的新颖框架。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个让LLM能够**自我迭代、自我改进**的框架，以实现更高级的“集体智能体”能力。这直接命中了你研究课题中的“自我演化”和“Agentic AI”两个核心方向。尽管它以“对齐”为切入点，但其本质是关于智能体演化机制的探索，而非对齐技术本身。因此，这篇论文高度相关，应该被保留。"
    },
    {
        "index": "#35",
        "title": "Active Video Perception: Iterative Evidence Seeking for Agentic Long Video Understanding",
        "link": "/arxiv/2512.05774",
        "arxiv_id": "2512.05774",
        "authors": "Ziyang Wang, Honglu Zhou, Shijie Wang, Junnan Li, Caiming Xiong, Silvio Savarese, Mohit Bansal, Michael S. Ryoo, Juan Carlos Niebles",
        "summary": "Long video understanding (LVU) is challenging because answering real-world queries often depends on sparse, temporally dispersed cues buried in hours of mostly redundant and irrelevant content. While agentic pipelines improve video reasoning capabilities, prevailing frameworks rely on a query-agnostic captioner to perceive video information, which wastes computation on irrelevant content and blurs fine-grained temporal and spatial information. Motivated by active perception theory, we argue that LVU agents should actively decide what, when, and where to observe, and continuously assess whether the current observation is sufficient to answer the query. We present Active Video Perception (AVP), an evidence-seeking framework that treats the video as an interactive environment and acquires compact, queryrelevant evidence directly from pixels. Concretely, AVP runs an iterative plan-observe-reflect process with MLLM agents. In each round, a planner proposes targeted video interactions, an observer executes them to extract time-stamped evidence, and a reflector evaluates the sufficiency of the evidence for the query, either halting with an answer or triggering further observation. Across five LVU benchmarks, AVP achieves highest performance with significant improvements. Notably, AVP outperforms the best agentic method by 5.7% in average accuracy while only requires 18.4% inference time and 12.4% input tokens.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-12-05",
        "category": "cs.CL",
        "crawl_time": "2025-12-08T11:00:04.192541",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **核心判断 (第一步):** - **保留**。这篇论文的本质不是将一个已有的智能体框架应用到视频领域，而是**提出了一种全新的智能体框架**。其核心贡献是构建了一个名为“Active Video Perception (AVP)”的框架，该框架定义了智能体如何主动地、迭代地与环境（视频）进行交互。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **正面指标 (第二步):** - 论文包含了您关注的所有核心范式和能力： - **核心范式**: `Agentic AI`, `LLM-based Agents`。摘要中明确提到“agentic pipelines”和“MLLM agents”。 - **智能体能力**: 论文的核心框架 `plan-observe-reflect` 直接对应了您关注的多个子方向： - `Planning`: “a planner proposes targeted video interactions”。 - `Tool Use / Tool Augmentation`: “an observer executes them to extract time-stamped evidence”，这里将视频环境作为可交互的工具。 - `Self-Reflection`: “a reflector evaluates the sufficiency of the evidence”，这是典型的自我反思与评估机制。 - **演化机制**: 整个 `plan-observe-reflect` 的迭代过程，直到证据足够才停止，这是一种**迭代改进** 的体现，属于自我演化的范畴。 3.  **排除标准 (第三步):** - **安全与对齐**: 论文不涉及安全、对齐等问题。 - **多模态与视觉**: 这是一个关键点。虽然论文处理的是视频，但它**并未被排除**。根据您的规则：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，视频（多模态）正是智能体感知和交互的**环境**，而研究的**核心**是智能体如何通过`plan-observe-reflect`框架来高效地与这个环境交互。因此，它符合例外情况，不应被排除。 4.  **特殊和模糊情况 (第四步):** - **推理/规划**: 论文明确是关于智能体如何进行规划的。它不是在提升LLM本身的基础推理能力，而是在构建一个让智能体能够进行复杂、多步、目标导向的规划与行动的框架。这完全符合“保留”的条件。 **最终决策 (第五步):** 综合分析，这篇论文的核心贡献是提出了一种创新的、包含规划、工具使用和自我反思的迭代式智能体框架（AVP），用于解决长视频理解这一复杂任务。它直接推动了“单智能体”方向的技术边界，特别是智能体的规划、工具使用和自我反思能力。因此，这篇论文与您的研究课题“LLM智能体及其演化”高度相关，应该被保留。"
    },
    {
        "index": "#36",
        "title": "GRASP: Graph Reasoning Agents for Systems Pharmacology with Human-in-the-Loop",
        "link": "/arxiv/2512.05502",
        "arxiv_id": "2512.05502",
        "authors": "Omid Bazgir, Vineeth Manthapuri, Ilia Rattsev, Mohammad Jafarnejad",
        "summary": "Quantitative Systems Pharmacology (QSP) modeling is essential for drug development but it requires significant time investment that limits the throughput of domain experts. We present \\textbf{GRASP} -- a multi-agent, graph-reasoning framework with a human-in-the-loop conversational interface -- that encodes QSP models as typed biological knowledge graphs and compiles them to executable MATLAB/SimBiology code while preserving units, mass balance, and physiological constraints. A two-phase workflow -- \\textsc{Understanding} (graph reconstruction of legacy code) and \\textsc{Action} (constraint-checked, language-driven modification) -- is orchestrated by a state machine with iterative validation. GRASP performs breadth-first parameter-alignment around new entities to surface dependent quantities and propose biologically plausible defaults, and it runs automatic execution/diagnostics until convergence. In head-to-head evaluations using LLM-as-judge, GRASP outperforms SME-guided CoT and ToT baselines across biological plausibility, mathematical correctness, structural fidelity, and code quality (\\(\\approx\\)9--10/10 vs.\\ 5--7/10). BFS alignment achieves F1 = 0.95 for dependency discovery, units, and range. These results demonstrate that graph-structured, agentic workflows can make QSP model development both accessible and rigorous, enabling domain experts to specify mechanisms in natural language without sacrificing biomedical fidelity.",
        "subjects": "Machine Learning",
        "date": "2025-12-05",
        "category": "cs.LG",
        "crawl_time": "2025-12-08T11:00:04.906364",
        "filter_reason": "这篇论文符合您的研究范围，应当保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为GRASP的**新颖的多智能体框架**。虽然它的应用领域是系统药理学（QSP），但其核心贡献并非解决QSP问题本身，而是**构建了一个能够完成该任务的、具有特定架构和工作流的智能体系统**。论文详细描述了该框架的“多智能体”特性、“图推理”机制、由状态机编排的两阶段工作流以及迭代验证过程。这完全符合“构建、改进LLM智能体”的核心目标，不属于“将已有框架作为工具应用到特定领域”的排除情况。 **第二步：正面指标** - 论文包含了大量您关注的核心指标： - **核心范式**: 明确提到了 `multi-agent` 框架和 `agentic workflows`。 - **智能体能力**: 论文描述了智能体的规划能力（由状态机编排的两阶段工作流：`Understanding` 和 `Action`）、工具使用能力（编译并执行MATLAB/SimBiology代码）、以及自我修正/迭代改进能力（`iterative validation` 和 `runs ... until convergence`）。 - **多智能体**: 标题和摘要都强调了其 `multi-agent` 的本质。 **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐，也没有涉及多模态与视觉。因此，不触犯任何排除标准。 **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的两阶段工作流和状态机编排机制，是典型的智能体在复杂任务中进行规划和多步推理的框架。这超越了单纯的LLM基础推理能力，属于Agentic AI的范畴，因此应该保留。 **第五步：最终决策** 综合以上分析，尽管这篇论文有一个非常具体的应用领域（系统药理学），但其**核心贡献在于方法论和框架本身**——即如何设计和构建一个能够理解、重构、修改和验证复杂领域模型的多智能体系统。它提出了一种新的Agentic工作流，并将其与现有的CoT、ToT等基线进行比较，证明了其框架的有效性。这完全符合您“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”这一核心目标，特别是与您的“多智能体”研究方向高度契合。因此，最终判断为保留。"
    },
    {
        "index": "#78",
        "title": "The Missing Layer of AGI: From Pattern Alchemy to Coordination Physics",
        "link": "/arxiv/2512.05765",
        "arxiv_id": "2512.05765",
        "authors": "Edward Y. Chang",
        "summary": "Influential critiques argue that Large Language Models (LLMs) are a dead end for AGI: \"mere pattern matchers\" structurally incapable of reasoning or planning. We argue this conclusion misidentifies the bottleneck: it confuses the ocean with the net. Pattern repositories are the necessary System-1 substrate; the missing component is a System-2 coordination layer that selects, constrains, and binds these patterns. We formalize this layer via UCCT, a theory of semantic anchoring that models reasoning as a phase transition governed by effective support (rho_d), representational mismatch (d_r), and an adaptive anchoring budget (gamma log k). Under this lens, ungrounded generation is simply an unbaited retrieval of the substrate's maximum likelihood prior, while \"reasoning\" emerges when anchors shift the posterior toward goal-directed constraints. We translate UCCT into architecture with MACI, a coordination stack that implements baiting (behavior-modulated debate), filtering (Socratic judging), and persistence (transactional memory). By reframing common objections as testable coordination failures, we argue that the path to AGI runs through LLMs, not around them.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-05",
        "category": "cs.LG",
        "crawl_time": "2025-12-08T11:00:04.946734",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于提出了一种构建和改进LLM智能体的新框架。 1.  **第一步核心判断 (保留)**: 论文的核心不是将LLM作为工具应用，也不是改进LLM的基础推理能力，而是提出了一个全新的架构层（System-2 coordination layer）来解决LLM在推理和规划上的根本性瓶颈。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。论文明确指出，LLM是“System-1 substrate”（系统1基础），而他们贡献的是缺失的“System-2 coordination layer”（系统2协调层），这正是构建高级智能体的关键。 2.  **第二步正面指标 (高度匹配)**: 论文包含了多个你的核心关注点。 *   **核心范式**: 论文本质上是关于 `Agentic AI` 和 `LLM-based Agents` 的。 *   **智能体能力**: 论文提出的MACI架构直接实现了多个核心能力： *   `Planning` / `Reasoning`: 整个框架的目标就是实现“推理”和“规划”，并将其定义为一种“相变”。 *   `Memory`: 明确提出了 `persistence (transactional memory)`，即持久化的事务性记忆。 *   `Self-Correction` / `Self-Reflection`: `filtering (Socratic judging)` 是一种自我纠正机制，而 `baiting (behavior-modulated debate)` 可以看作是一种内部或智能体间的辩论与反思过程。 3.  **第三步排除标准 (未触发)**: 论文的主要贡献是关于智能体的能力架构，而非安全、对齐或多模态。因此，没有触发任何排除标准。 4.  **第四步特殊与模糊情况 (清晰符合)**: *   **推理/规划**: 这篇论文是“保留”情况的完美范例。它不是在研究如何让LLM更好地做数学题，而是在构建一个让LLM能够进行复杂、多步、目标导向的“推理”和“规划”的**智能体框架**。这正是Agentic AI研究的核心。 **总结**: 该论文直面LLM作为智能体的核心缺陷（缺乏真正的推理规划能力），并提出了一个包含记忆、自我纠正和反思机制的全新架构（MACI）和理论（UCCT）。其核心贡献是方法论和框架层面的创新，旨在“构建”和“改进”LLM智能体，与你的研究课题“LLM智能体及其演化”高度契合，尤其是“单智能体”方向下的规划、记忆和自我反思等子方向。因此，应予以保留。"
    },
    {
        "index": "#9",
        "title": "Evolutionary System 2 Reasoning: An Empirical Proof",
        "link": "/arxiv/2512.05760",
        "arxiv_id": "2512.05760",
        "authors": "Zeyuan Ma, Wenqi Huang, Guo-Huan Song, Hongshu Guo, Sijie Ma, Zhiguang Cao, Yue-Jiao Gong",
        "summary": "Machine intelligence marks the ultimate dream of making machines' intelligence comparable to human beings. While recent progress in Large Language Models (LLMs) show substantial specific skills for a wide array of downstream tasks, they more or less fall shorts in general intelligence. Following correlation between intelligence and system 2 reasoning (slow thinking), in this paper, we aim to answering a worthwhile research question: could machine intelligence such as LLMs be evolved to acquire reasoning ability (not specific skill) just like our human beings? To this end, we propose evolutionary reasoning optimization (ERO) framework which performs survival of the fittest over a population of LLMs to search for individual with strong reasoning ability. Given a reasoning task, ERO first initializes multiple LLMs as a population, after which an evolutionary strategy evolves the population to maximize quantified reasoning score of the best individual. Based on experiments on representative testsuites, we claim two surprising empirical discoveries: i) the latest LLMs such as GPT-5 still show limited system 2 reasoning ability; ii) with simple evolution-loop of ERO, a relatively weak model (Qwen-7B) could be enhanced to emerge powerful reasoning ability. Our project can be accessed at https://github.com/MetaEvo/ERO for reproduction needs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-05",
        "category": "cs.AI",
        "crawl_time": "2025-12-08T11:00:04.966270",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献精准地命中了你的第三个研究方向：**自我演化**。 1.  **核心判断 (第一步):** 论文的核心是提出一个名为“演化推理优化（ERO）”的**新框架**。这个框架并非简单地将LLM作为工具应用，也不是单纯提升LLM的基础推理能力，而是设计了一个**演化机制**（“适者生存”、“演化策略”）来主动地、迭代地**改进和演化**LLM的推理能力。这完全符合“构建、改进或演化 LLM智能体”的核心目标，因此应**保留**。 2.  **正面指标 (第二步):** 论文包含了大量你的核心关注点： *   **核心范式:** `Self-Evolving` (自我演化) 和 `Evolutionary Algorithms` (演化算法) 是本文的绝对核心。 *   **演化机制:** 论文明确提出了 `Self-Improvement` (自我改进) 和 `Iterative Improvement` (迭代改进) 的机制，通过演化循环来增强模型能力。 3.  **排除标准 (第三步):** 论文内容不涉及安全对齐、多模态视觉等排除领域，因此没有触发任何排除标准。 4.  **特殊和模糊情况处理 (第四步):** *   **推理/规划:** 这是最关键的一点。虽然论文的目标是提升“推理能力”，但其实现方式并非提出一个新的CoT变体或微调数据集（这属于“非Agentic的推理”），而是构建了一个**更高层次的演化框架**。这个框架将LLM本身作为演化的对象，通过种群迭代来筛选和优化。这种“如何让智能体变得更强”的元框架，正是“自我演化”研究的精髓。因此，它应被归类为自我演化研究，而不是被排除的基础推理研究。 **结论:** 该论文的核心贡献是提出了一种让LLM通过演化机制进行自我完善和迭代的新方法（ERO框架），以涌现出更强的推理能力。这完全符合你关于“LLM智能体及其演化”的研究课题，特别是“自我演化”这一核心方向。因此，应判定为符合要求。"
    },
    {
        "index": "#14",
        "title": "CureAgent: A Training-Free Executor-Analyst Framework for Clinical Reasoning",
        "link": "/arxiv/2512.05576",
        "arxiv_id": "2512.05576",
        "authors": "Ting-Ting Xie, Yixin Zhang",
        "summary": "Current clinical agent built on small LLMs, such as TxAgent suffer from a \\textit{Context Utilization Failure}, where models successfully retrieve biomedical evidence due to supervised finetuning but fail to ground their diagnosis in that information. In this work, we propose the Executor-Analyst Framework, a modular architecture that decouples the syntactic precision of tool execution from the semantic robustness of clinical reasoning. By orchestrating specialized TxAgents (Executors) with long-context foundation models (Analysts), we mitigate the reasoning deficits observed in monolithic models. Beyond simple modularity, we demonstrate that a Stratified Ensemble strategy significantly outperforms global pooling by preserving evidentiary diversity, effectively addressing the information bottleneck. Furthermore, our stress tests reveal critical scaling insights: (1) a \\textit{Context-Performance Paradox}, where extending reasoning contexts beyond 12k tokens introduces noise that degrades accuracy; and (2) the \\textit{Curse of Dimensionality} in action spaces, where expanding toolsets necessitates hierarchical retrieval strategies. Crucially, our approach underscores the potential of training-free architectural engineering, achieving state-of-the-art performance on CURE-Bench without the need for expensive end-to-end finetuning. This provides a scalable, agile foundation for the next generation of trustworthy AI-driven therapeutics. Code has been released on https://github.com/June01/CureAgent.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-05",
        "category": "cs.AI",
        "crawl_time": "2025-12-08T11:00:04.968598",
        "filter_reason": "这篇论文符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一个名为“Executor-Analyst”的模块化智能体框架。这完全符合你筛选标准中“构建、改进LLM智能体的方法论或新框架”的要求。它不是简单地将一个已有的智能体框架应用到临床领域，而是针对现有智能体（如TxAgent）存在的“上下文利用失败”这一根本性缺陷，提出了一种全新的架构解决方案。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** 论文包含了你关注的核心指标： *   **智能体能力**: 明确提到了 `Tool Use`（工具执行，由Executor负责）和 `Reasoning`（临床推理，由Analyst负责）。其核心思想就是通过解耦这两者来提升智能体的整体能力。 *   **核心范式**: 论文本质上是在研究 `LLM-based Agents` 的架构设计，属于 `Agentic AI` 的核心范畴。 3.  **第三步：排除标准——未触发** 论文的主要目标是提升智能体的推理性能和架构的可扩展性，并未涉及安全、对齐、可解释性或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 这篇论文是关于智能体如何进行规划和推理的典型案例。它提出的“Executor-Anlasyt”框架是一种新的Agentic框架，旨在改进智能体在复杂任务（临床推理）中的多步推理能力，而不是仅仅提升LLM本身的基础数学或逻辑能力。因此，根据规则应予以保留。 *   **自我演化的应用**: 虽然论文标题中提到了“Training-Free”，但其核心是架构工程，而非自我演化机制。不过，这不影响其作为单智能体改进论文的价值。 **核心依据总结**: 这篇论文的本质是**对LLM智能体架构的创新性改进**。它通过提出一个新颖的“执行者-分析师”框架，解决了现有智能体在复杂推理任务中的一个关键瓶颈。尽管其验证场景是临床领域，但其贡献具有普适性，为构建更强大的LLM智能体提供了新的设计思路。这完全契合你研究课题中“单智能体”方向下的“规划”和“工具使用”子方向。"
    },
    {
        "index": "#18",
        "title": "ChipMind: Retrieval-Augmented Reasoning for Long-Context Circuit Design Specifications",
        "link": "/arxiv/2512.05371",
        "arxiv_id": "2512.05371",
        "authors": "Changwen Xing, SamZaak Wong, Xinlai Wan, Yanfeng Lu, Mengli Zhang, Zebin Ma, Lei Qi, Zhengxiong Li, Nan Guan, Zhe Jiang, Xi Wang, Jun Yang",
        "summary": "While Large Language Models (LLMs) demonstrate immense potential for automating integrated circuit (IC) development, their practical deployment is fundamentally limited by restricted context windows. Existing context-extension methods struggle to achieve effective semantic modeling and thorough multi-hop reasoning over extensive, intricate circuit specifications. To address this, we introduce ChipMind, a novel knowledge graph-augmented reasoning framework specifically designed for lengthy IC specifications. ChipMind first transforms circuit specifications into a domain-specific knowledge graph ChipKG through the Circuit Semantic-Aware Knowledge Graph Construction methodology. It then leverages the ChipKG-Augmented Reasoning mechanism, combining information-theoretic adaptive retrieval to dynamically trace logical dependencies with intent-aware semantic filtering to prune irrelevant noise, effectively balancing retrieval completeness and precision. Evaluated on an industrial-scale specification reasoning benchmark, ChipMind significantly outperforms state-of-the-art baselines, achieving an average improvement of 34.59% (up to 72.73%). Our framework bridges a critical gap between academic research and practical industrial deployment of LLM-aided Hardware Design (LAD).",
        "subjects": "Artificial Intelligence, Hardware Architecture",
        "date": "2025-12-05",
        "category": "cs.AI",
        "crawl_time": "2025-12-08T11:00:04.969739",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文的核心贡献是什么？** 论文的核心是提出了一个名为 \"ChipMind\" 的**知识图谱增强推理框架**。它不是一个简单的应用，而是一个新的方法论和系统架构。 - **是否符合保留标准？** 符合。该框架通过构建领域知识图谱（ChipKG）作为外部知识源，并设计了特定的检索和推理机制来辅助LLM完成任务。这本质上是在构建一个具备**工具使用**和**外部记忆**能力的LLM智能体。虽然它被应用于电路设计这一特定领域，但其核心贡献在于**构建和改进**这个智能体框架本身，而不是仅仅将LLM作为工具应用。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标** - 论文明确包含了多个我的核心关注点： - **智能体能力**: `Tool Use / Tool Augmentation` (使用知识图谱作为工具)、`Memory` (知识图谱作为结构化外部记忆)、`Reasoning` (整个框架的核心是增强推理能力)。 - **核心范式**: 论文提出的框架与 `Agentic AI` 和 `LLM-based Agents` 的范式高度契合。其“检索-推理”的循环机制与 `ReAct` 等经典智能体框架思想一致。 3.  **第三步：排除标准** - 论文的主要贡献不涉及 `Safety`、`Alignment`、`Interpretability` 等安全与对齐问题。 - 论文处理的是纯文本的电路设计规范，不涉及 `Vision` 或多模态内容。 - 因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何进行推理的典型案例。它不是在提升LLM底层的数学或逻辑能力，而是在构建一个外部框架（知识图谱+检索机制）来帮助LLM在复杂任务中进行多步、多跳的推理。这完全符合“保留”关于智能体推理/规划框架的规则。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于构建了一个具备工具使用和记忆能力的LLM智能体框架（ChipMind），以解决长上下文下的复杂推理问题。这直接命中了我的研究焦点之一——**单智能体**，特别是其**工具使用**和**记忆**子方向。尽管其应用场景是电路设计，但论文的创新点和价值在于其提出的通用智能体框架和方法论，而非应用本身。因此，这篇论文与我的研究目标高度相关，应予以保留。"
    },
    {
        "index": "#19",
        "title": "MCP-AI: Protocol-Driven Intelligence Framework for Autonomous Reasoning in Healthcare",
        "link": "/arxiv/2512.05365",
        "arxiv_id": "2512.05365",
        "authors": "Zag ElSayed, Craig Erickson, Ernest Pedapati",
        "summary": "Healthcare AI systems have historically faced challenges in merging contextual reasoning, long-term state management, and human-verifiable workflows into a cohesive framework. This paper introduces a completely innovative architecture and concept: combining the Model Context Protocol (MCP) with a specific clinical application, known as MCP-AI. This integration allows intelligent agents to reason over extended periods, collaborate securely, and adhere to authentic clinical logic, representing a significant shift away from traditional Clinical Decision Support Systems (CDSS) and prompt-based Large Language Models (LLMs). As healthcare systems become more complex, the need for autonomous, context-aware clinical reasoning frameworks has become urgent. We present MCP-AI, a novel architecture for explainable medical decision-making built upon the Model Context Protocol (MCP) a modular, executable specification for orchestrating generative and descriptive AI agents in real-time workflows. Each MCP file captures clinical objectives, patient context, reasoning state, and task logic, forming a reusable and auditable memory object. Unlike conventional CDSS or stateless prompt-based AI systems, MCP-AI supports adaptive, longitudinal, and collaborative reasoning across care settings. MCP-AI is validated through two use cases: (1) diagnostic modeling of Fragile X Syndrome with comorbid depression, and (2) remote coordination for Type 2 Diabetes and hypertension. In either scenario, the protocol facilitates physician-in-the-loop validation, streamlines clinical processes, and guarantees secure transitions of AI responsibilities between healthcare providers. The system connects with HL7/FHIR interfaces and adheres to regulatory standards, such as HIPAA and FDA SaMD guidelines. MCP-AI provides a scalable basis for interpretable, composable, and safety-oriented AI within upcoming clinical environments.",
        "subjects": "Artificial Intelligence, Quantitative Methods",
        "date": "2025-12-05",
        "category": "cs.AI",
        "crawl_time": "2025-12-08T11:00:04.970004",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为“MCP-AI”的**全新架构和框架**，其核心目标是实现智能体的“自主推理”。它不是简单地将一个已有的智能体框架应用到医疗领域，而是构建了一个新的、基于“模型上下文协议（MCP）”的智能体框架。该框架解决了智能体在复杂任务中的关键问题，如“上下文推理”和“长期状态管理”。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不属于“非演化型应用”，因为其贡献在于框架本身，而非应用。 2.  **第二步：正面指标** - 论文包含了大量我的核心关注点： - **核心范式**: 论文明确提出了一个用于编排AI智能体的框架，属于 `Agentic AI` 和 `LLM-based Agents` 范畴。 - **智能体能力**: 摘要中提到的“长期状态管理”直接对应 `Memory` 能力；“自主推理”和“长期推理”对应 `Planning` 能力。 - **多智能体**: 论文强调了智能体间的“协作”以及“在医疗提供者之间安全地交接AI职责”，这明确指向了 `Multi-Agent` 系统中的 `Collaboration` 和 `Communication`。 3.  **第三步：排除标准** - **安全与对齐**: 摘要中提到了“可解释的”和“安全导向的AI”。然而，这些是作为MCP-AI框架的**设计特性或目标**出现的，而不是论文的**核心研究贡献**。论文的核心是“如何构建一个能自主推理和协作的智能体框架”，而“可解释性”和“安全性”是该框架带来的结果或遵循的原则。因此，这不触发排除规则。 - **多模态与视觉**: 论文未涉及视觉或多模态内容，不在此排除范围内。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 该论文是关于智能体如何进行“自主推理”和“长期推理”的框架，这完全符合“保留”的条件。它不是在改进LLM本身的基础数学或逻辑能力，而是在构建一个让LLM能够进行复杂、多步、有状态推理的智能体系统。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于**构建了一个新颖的LLM智能体框架（MCP-AI）**，该框架重点解决了智能体的**记忆（长期状态管理）、规划（自主推理）和多智能体协作**等关键问题。尽管它以医疗领域为应用背景，但其本质是Agentic AI架构的创新，而非简单的领域应用。因此，它精准地契合了我关于“LLM智能体及其演化”的研究课题，特别是“单智能体”和“多智能体”方向。最终判断为 **True**。"
    },
    {
        "index": "#20",
        "title": "AI & Human Co-Improvement for Safer Co-Superintelligence",
        "link": "/arxiv/2512.05356",
        "arxiv_id": "2512.05356",
        "authors": "Jason Weston, Jakob Foerster",
        "summary": "Self-improvement is a goal currently exciting the field of AI, but is fraught with danger, and may take time to fully achieve. We advocate that a more achievable and better goal for humanity is to maximize co-improvement: collaboration between human researchers and AIs to achieve co-superintelligence. That is, specifically targeting improving AI systems' ability to work with human researchers to conduct AI research together, from ideation to experimentation, in order to both accelerate AI research and to generally endow both AIs and humans with safer superintelligence through their symbiosis. Focusing on including human research improvement in the loop will both get us there faster, and more safely.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-05",
        "category": "cs.AI",
        "crawl_time": "2025-12-08T11:00:04.970250",
        "filter_reason": "这篇论文符合筛选要求，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是提出一个名为“协同改进”的新框架。其本质是构建一种新型的LLM智能体，该智能体的核心能力是与人类研究人员进行深度协作，共同完成从构思到实验的复杂AI研究任务。 - **判断**: 这完全符合“构建、改进或演化LLM智能体”的核心目标。它不是简单地将现有智能体作为工具应用，而是提出了一种新的智能体形态和交互范式。因此，应**保留**。 2.  **第二步：正面指标** - 论文摘要中明确包含了多个核心关注点： - **多智能体**: 论文的核心是“AI & Human Co-Improvement”，这本质上是一个由人类智能体和AI智能体组成的混合多智能体系统，其核心机制是`Collaboration`（协作）。 - **自我演化**: 论文提出了“协同改进”和“自我改进”的概念，虽然它不是纯粹的AI自我演化，而是人机共生的演化路径，但这直接触及了“自我演化”的核心思想，即通过经验和反馈进行迭代完善。`Self-Improvement`是关键词。 - **智能体能力**: 论文描述的协作过程（“从构思到实验”）必然涉及智能体的`Planning`（规划）和`Tool Use`（工具使用，例如使用实验环境）能力。 3.  **第三步：排除标准** - **安全与对齐**: 这是本案例最需要辨析的一点。论文标题和摘要都提到了“更安全的协同超级智能”。然而，根据筛选标准，只有当论文的**主要贡献**是关于安全或对齐技术本身时，才需要排除。在这篇论文中，“安全”是所提出的“协同改进”框架所要达成的**目标或结果**，而不是其核心技术贡献。论文的核心是**如何构建这个协作系统**，而不是提出一种新的对齐算法或安全协议。因此，它没有触发排除标准。 - **多模态与视觉**: 论文摘要未提及相关内容，不适用此排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文描述的智能体需要与人类协作完成复杂的AI研究任务，这必然涉及多步的`Planning`（规划）和`Reasoning`（推理）。这符合“保留”的条件，因为它是在智能体框架下的复杂任务求解，而非单纯的LLM基础能力提升。 - **自我演化的应用**: 这篇论文提出的“协同改进”本身就是一种新的演化机制，即使它的应用领域是AI研究本身，根据规则也应保留。 5.  **第五步：最终决策** - 综合以上分析，这篇论文的核心贡献在于提出了一种构建和演化LLM智能体的新范式——人机协同改进的智能体。它直接关联到“多智能体”和“自我演化”两大研究方向。尽管它以“安全”为最终目标，但其技术贡献在于智能体的构建方法，而非安全技术本身。因此，这篇论文高度契合“LLM智能体及其演化”的研究课题，应被**保留**。"
    },
    {
        "index": "#116",
        "title": "AREA3D: Active Reconstruction Agent with Unified Feed-Forward 3D Perception and Vision-Language Guidance",
        "link": "/arxiv/2512.05131",
        "arxiv_id": "2512.05131",
        "authors": "Tianling Xu, Shengzhe Gan, Leslie Gu, Yuelei Li, Fangneng Zhan, Hanspeter Pfister",
        "summary": "Active 3D reconstruction enables an agent to autonomously select viewpoints to efficiently obtain accurate and complete scene geometry, rather than passively reconstructing scenes from pre-collected images. However, existing active reconstruction methods often rely on hand-crafted geometric heuristics, which can lead to redundant observations without substantially improving reconstruction quality. To address this limitation, we propose AREA3D, an active reconstruction agent that leverages feed-forward 3D reconstruction models and vision-language guidance. Our framework decouples view-uncertainty modeling from the underlying feed-forward reconstructor, enabling precise uncertainty estimation without expensive online optimization. In addition, an integrated vision-language model provides high-level semantic guidance, encouraging informative and diverse viewpoints beyond purely geometric cues. Extensive experiments on both scene-level and object-level benchmarks demonstrate that AREA3D achieves state-of-the-art reconstruction accuracy, particularly in the sparse-view regime. Code will be made available at: https://github.com/TianlingXu/AREA3D .",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Robotics",
        "date": "2025-11-28",
        "category": "cs.AI",
        "crawl_time": "2025-12-08T11:00:05.000295",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献是构建了一个名为 **AREA3D** 的 **\"Active Reconstruction Agent\"（主动重建智能体）**。它不是一个简单的应用，而是提出了一个新的智能体框架。该智能体的核心任务是“自主选择视点”，这本质上是一个规划和决策过程。因此，论文的本质是关于构建和改进一个LLM智能体（具体来说，是使用了Vision-Language Model的智能体），完全符合“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 论文明确提出了一个 **\"Agent\"** 框架。 - **智能体能力**: 智能体需要 **\"autonomously select viewpoints\"**（自主选择视点），这属于 **Planning**（规划）能力。同时，它利用 **\"vision-language model provides high-level semantic guidance\"**，这属于 **Tool Use / Tool Augmentation**（工具使用/增强），将VLM作为提供高级语义指导的工具。 3.  **第三步：排除标准** - **安全与对齐**: 论文不涉及安全、对齐或可解释性问题。 - **多模态与视觉**: 这是本案例的关键点。虽然论文大量涉及 **\"3D Perception\"** 和 **\"Vision-Language Guidance\"**，但它符合排除标准中的例外情况：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，3D重建模型和VLM是智能体用来感知环境（不确定性建模）和辅助决策（语义引导）的**工具**。论文的研究核心是**智能体本身的决策框架**（如何选择视点），而不是去改进底层的3D感知模型或VLM。因此，不应因此排除。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的核心是关于智能体如何在复杂任务（主动3D重建）中进行多步规划和决策（选择下一个最佳视点）。这完全符合“保留”的条件，即“关于智能体如何进行规划或在复杂任务中进行多步推理”。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种新的智能体框架（AREA3D），该框架具备自主规划和工具使用能力，以解决主动3D重建问题。尽管其应用领域和工具涉及视觉，但其研究焦点是智能体的架构和决策机制，而非视觉模型本身。这完全契合我研究课题中“单智能体”方向下的“规划”和“工具使用”子方向。因此，应判定为符合要求。"
    }
]