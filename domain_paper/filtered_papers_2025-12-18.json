[
    {
        "index": "#8",
        "title": "Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying",
        "link": "/arxiv/2512.15776",
        "arxiv_id": "2512.15776",
        "authors": "Shaun Baek, Sam Liu, Joseph Ukpong",
        "summary": "Large Language Models (LLMs) act as powerful reasoning engines but struggle with \"symbol grounding\" in embodied environments, particularly when information is asymmetrically distributed. We investigate the Privileged Information Bias (or \"Curse of Knowledge\"), where a knowledgeable \"Leader\" agent fails to guide a sensor-limited \"Follower\" due to a lack of Theory of Mind. To quantify this phenomenon, we propose a novel Asymmetric Assistive Reasoning framework within AI2-THOR. Our experiments reveal a significant \"Success Gap\": while the Leader successfully perceives the target in 35.0% of episodes, the collaborative team succeeds only 17.0% of the time, implying that nearly 50% of feasible plans fail solely due to communicative grounding errors. We demonstrate that a \"Pull-based\" protocol (active querying) is significantly more robust than standard \"Push-based\" instruction, with successful episodes featuring 2x the frequency of clarification requests. This research isolates the mechanism of active uncertainty reduction as a prerequisite for safe human-AI and robot-robot collaboration.",
        "subjects": "Artificial Intelligence, Multiagent Systems, Robotics",
        "date": "2025-12-13",
        "category": "cs.MA",
        "crawl_time": "2025-12-19T11:00:03.843486",
        "filter_reason": "这篇论文完全符合你的研究范围，核心贡献属于“多智能体”方向。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心并非将LLM或智能体框架作为工具去解决一个外部领域问题（如机器人控制），而是**研究并改进多智能体系统本身**。它提出了一个新颖的“非对称辅助推理框架”和一种“Pull-based”通信协议，旨在解决多智能体协作中的一个根本性问题——“特权信息偏差”。这直接对应了筛选标准中的“构建、改进或演化 LLM智能体”，特别是多智能体系统。 2.  **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **核心范式**: `LLM-based Agents`, `Multi-Agent Systems (MAS)`。论文明确研究了一个由“Leader”和“Follower”组成的多智能体系统。 *   **多智能体**: `Collaboration`, `Communication`。论文的核心贡献就是提出一种新的通信机制（主动查询/Pull-based protocol）来提升智能体间的协作效率。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 论文摘要中提到了“safe human-AI and robot-robot collaboration”，但这是作为其研究成果的一个潜在应用和意义，而非论文的主要贡献。论文的核心是**通信机制**，而不是安全或对齐算法本身。因此，这不构成排除理由。 *   **多模态与视觉**: 论文提到了“embodied agents”和“sensor-limited Follower”，这暗示了视觉等感知模块的存在。然而，这些感知能力是智能体与环境交互的工具，研究的核心并非改进视觉模型，而是**智能体如何处理和沟通由感知差异带来的信息不对称**。这完全符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”的例外情况。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文中的推理是发生在多智能体协作框架下的（Asymmetric Assistive Reasoning），而不是为了提升LLM本身的基础推理能力。因此，它属于应保留的Agentic框架研究。 **总结**: 该论文的核心贡献是提出了一种新的多智能体协作框架和通信协议，以解决信息不对称环境下的协作失败问题。这直接命中了你研究课题中的“多智能体”方向，特别是关于智能体间的“协作”与“通信”子方向。它不是一篇应用论文，而是一篇对Agentic AI基础机制进行深入探索和改进的前沿研究，因此应被保留。"
    },
    {
        "index": "#6",
        "title": "AMUSE: Audio-Visual Benchmark and Alignment Framework for Agentic Multi-Speaker Understanding",
        "link": "/arxiv/2512.16250",
        "arxiv_id": "2512.16250",
        "authors": "Sanjoy Chowdhury, Karren D. Yang, Xudong Liu, Fartash Faghri, Pavan Kumar Anasosalu Vasu, Oncel Tuzel, Dinesh Manocha, Chun-Liang Li, Raviteja Vemulapalli",
        "summary": "Recent multimodal large language models (MLLMs) such as GPT-4o and Qwen3-Omni show strong perception but struggle in multi-speaker, dialogue-centric settings that demand agentic reasoning tracking who speaks, maintaining roles, and grounding events across time. These scenarios are central to multimodal audio-video understanding, where models must jointly reason over audio and visual streams in applications such as conversational video assistants and meeting analytics. We introduce AMUSE, a benchmark designed around tasks that are inherently agentic, requiring models to decompose complex audio-visual interactions into planning, grounding, and reflection steps. It evaluates MLLMs across three modes zero-shot, guided, and agentic and six task families, including spatio-temporal speaker grounding and multimodal dialogue summarization. Across all modes, current models exhibit weak multi-speaker reasoning and inconsistent behavior under both non-agentic and agentic evaluation. Motivated by the inherently agentic nature of these tasks and recent advances in LLM agents, we propose RAFT, a data-efficient agentic alignment framework that integrates reward optimization with intrinsic multimodal self-evaluation as reward and selective parameter adaptation for data and parameter efficient updates. Using RAFT, we achieve up to 39.52\\% relative improvement in accuracy on our benchmark. Together, AMUSE and RAFT provide a practical platform for examining agentic reasoning in multimodal models and improving their capabilities.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-12-18",
        "category": "cs.MA",
        "crawl_time": "2025-12-19T11:00:03.842957",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献并非简单地将LLM应用于一个新领域，而是提出了两个关键组件： *   **AMUSE**: 一个专门为评估“智能体推理”能力而设计的基准。它明确要求模型将复杂的视听交互分解为**规划、定位和反思**步骤，这直接命中了你对单智能体能力（规划、自我反思）的研究焦点。 *   **RAFT**: 一个“智能体对齐框架”。这个框架通过奖励优化和内在的**多模态自我评估**来提升模型在AMUSE基准上的表现。这本质上是一个**改进LLM智能体**的方法论，其核心在于让智能体通过自我评估来完善自身，这与你的“自我演化”方向高度相关。 因此，论文的本质是构建和改进LLM智能体，应予以保留。 2.  **第二步：正面指标 (高度匹配)** 论文中包含了大量你的核心关注点： *   **核心范式**: `Agentic AI` (多次提及), `LLM-based Agents` (隐含在MLLMs的agentic reasoning中)。 *   **智能体能力**: `Planning`, `Self-Reflection`, `Self-Evaluation` (自我评估是自我反思/修正的一种形式)。 *   **演化机制**: `Self-Improvement` (RAFT框架的目标), `Iterative Improvement` (通过奖励优化实现)。 3.  **第三步：排除标准 (不适用)** *   **安全与对齐**: 论文中的 \"Alignment Framework\" 指的是让模型的行为与“智能体任务的要求”对齐，即提升其在规划、反思等任务上的表现，而非通常意义上的AI安全、伦理对齐。因此，这不属于排除范围。 *   **多模态与视觉**: 论文确实涉及多模态，但完全符合你的特殊规则。这里的音频和视觉是智能体感知和交互的**环境**，而不是研究的核心。论文的核心贡献是**如何让智能体在这种多模态环境中进行推理和自我完善**，而不是提出新的视觉或音频模型。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文明确聚焦于智能体如何在复杂任务中进行多步推理和规划，这正是你希望保留的类型，而非提升LLM基础数学或逻辑能力。 *   **自我演化的应用**: 虽然论文的应用场景是多说话人理解，但其核心贡献RAFT是一种新的“自我演化/改进”机制（通过自我评估作为奖励进行优化），因此即使应用在特定领域，也应保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一套用于评估和改进LLM智能体在复杂任务中规划、反思和自我完善能力的基准与框架。它直接触及了你研究课题中的“单智能体”和“自我演化”两个核心方向，因此应被**保留**。"
    },
    {
        "index": "#2",
        "title": "Ev-Trust: A Strategy Equilibrium Trust Mechanism for Evolutionary Games in LLM-Based Multi-Agent Services",
        "link": "/arxiv/2512.16167",
        "arxiv_id": "2512.16167",
        "authors": "Shiduo Yang, Jiye Wang, Jiayu Qin, Jianbin Li, Yu Wang, Yuanhe Zhao, Kenan Guo",
        "summary": "The rapid evolution of the Web toward an agent-centric paradigm, driven by large language models (LLMs), has enabled autonomous agents to reason, plan, and interact in complex decentralized environments. However, the openness and heterogeneity of LLM-based multi-agent systems also amplify the risks of deception, fraud, and misinformation, posing severe challenges to trust establishment and system robustness. To address this issue, we propose Ev-Trust, a strategy-equilibrium trust mechanism grounded in evolutionary game theory. This mechanism integrates direct trust, indirect trust, and expected revenue into a dynamic feedback structure that guides agents' behavioral evolution toward equilibria. Within a decentralized \"Request-Response-Payment-Evaluation\" service framework, Ev-Trust enables agents to adaptively adjust strategies, naturally excluding malicious participants while reinforcing high-quality collaboration. Furthermore, our theoretical derivation based on replicator dynamics equations proves the existence and stability of local evolutionary equilibria. Experimental results indicate that our approach effectively reflects agent trustworthiness in LLM-driven open service interaction scenarios, reduces malicious strategies, and increases collective revenue. We hope Ev-Trust can provide a new perspective on trust modeling for the agentic service web in group evolutionary game scenarios.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computer Science and Game Theory",
        "date": "2025-12-18",
        "category": "cs.MA",
        "crawl_time": "2025-12-19T11:00:03.841861",
        "filter_reason": "这篇论文完全符合你的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决某个特定领域（如金融、医疗）的问题。它的核心贡献是提出了一种名为 **`Ev-Trust`** 的**新机制**。这个机制基于演化博弈论，旨在**引导和塑造LLM多智能体系统中的行为演化**。这直接属于“构建、改进或演化LLM智能体”的范畴，特别是针对多智能体系统的演化机制。 2.  **第二步：正面指标** - 论文摘要中包含了大量与你研究焦点高度相关的核心范式和能力： - **核心范式**: `LLM-Based Multi-Agent Services`, `Evolutionary Games`。这直接命中了你的“多智能体”和“自我演化”两个核心方向。 - **多智能体**: 论文讨论了在去中心化环境中智能体的交互，并旨在`reinforcing high-quality collaboration`（强化高质量协作）。 - **演化机制**: 论文的核心是`Ev-Trust`机制，它通过`dynamic feedback structure`（动态反馈结构）来`guides agents' behavioral evolution toward equilibria`（引导智能体行为向均衡演化）。这完全符合“自我演化”的定义，即智能体通过环境反馈进行自我完善和迭代。摘要还明确提到了`replicator dynamics equations`（复制动态方程），这是演化博弈论的核心工具。 3.  **第三步：排除标准** - **安全与对齐**: 这是本论文最需要仔细甄别的一点。虽然论文标题和摘要中提到了`Trust`（信任）、`deception`（欺骗）、`fraud`（欺诈）和`malicious participants`（恶意参与者）等看似与“安全”相关的词汇，但其**主要贡献并非安全或对齐技术本身**。论文的核心是提出一个**博弈论框架**，通过经济和演化激励来**自然地筛选掉恶意行为者**，从而实现系统层面的稳健性。它的目标是研究智能体群体如何演化，而不是为单个智能体设计安全护栏或对齐方法。因此，它不属于“主要贡献是关于Safety, Security, Alignment”的排除范围。 - **多模态与视觉**: 论文未涉及相关内容。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文并非一个应用案例，而是提出了一种通用的“自我演化”机制。它恰好完美地体现了你所说的“例外情况”：即使它被应用在“服务网络”这个特定场景，但其核心是提出一种新的自我演化机制，因此必须保留。 **最终决策**: 综合以上分析，这篇论文的核心贡献是**提出了一种基于演化博弈论的信任机制，用以驱动LLM多智能体系统进行行为演化和策略调整**。这精准地命中了你研究课题中的“多智能体”和“自我演化”两个核心方向。它不是简单的应用，也不是关于安全对齐的研究，而是一个关于智能体系统如何演化的深刻方法论。因此，这篇论文高度相关，应该被**保留 (True)**。"
    },
    {
        "index": "#22",
        "title": "BRAID: Bounded Reasoning for Autonomous Inference and Decisions",
        "link": "/arxiv/2512.15959",
        "arxiv_id": "2512.15959",
        "authors": "Armağan Amcalar, Eyup Cinar",
        "summary": "Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the AdvancedIF, GSM-Hard, and the SCALE MultiChallenge benchmark datasets. BRAID introduces a bounded reasoning framework using Mermaid-based instruction graphs that enable models to reason struc turally rather than through unbounded natural-language token expansion. We show that structured machine-readable prompts substantially increase reasoning accuracy and cost efficiency for agents in production systems. The findings establish BRAID as an effective and scalable technique for optimizing inference efficiency in autonomous agent systems. All datasets and detailed result logs are available at https://benchmark.openserv.ai.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.CL",
        "crawl_time": "2025-12-19T11:00:04.278460",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心贡献是提出了 **BRAID (Bounded Reasoning for Autonomous Inference and Decisions)**，这是一个全新的“有界推理框架”。 - 它的本质不是将现有智能体应用到某个领域，而是**构建和改进LLM智能体的核心推理机制**。摘要明确指出，该技术旨在“优化自主智能体系统中的推理效率”，并“为生产系统中的智能体”提高准确性和成本效率。 - 这完全符合“核心贡献在于构建、改进LLM智能体”的保留标准，不属于“非演化型应用”、“非Agentic的推理”或“基础设施”等排除类别。 2.  **第二步：正面指标——高度相关** - 论文包含了多个核心关注点： - **核心范式**: `Agentic AI`, `LLM-based Agents` (摘要中明确提到 \"agents in production systems\" 和 \"autonomous agent systems\")。 - **智能体能力**: `Planning` (BRAID框架通过“指令图”实现结构化推理，这是一种高级的规划和多步推理能力)。 - 这些正面指标强烈表明该论文与你的研究焦点高度契合。 3.  **第三步：排除标准——不适用** - 论文的主要贡献是关于智能体的推理效率和框架，而非安全、对齐或多模态。因此，不触发任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留条件** - **推理/规划**: 这是本论文的关键。它完美地符合“保留”条件：“如果论文是关于智能体如何进行规划或在复杂任务中进行多步推理（如 ReAct、ToT 或新的Agentic框架）”。BRAID本身就是一个新的Agentic推理框架，它通过结构化的指令图来约束和引导智能体的推理过程，这与ReAct、ToT等在思想上一脉相承，但提出了新的实现方式（有界、结构化）。它不是在提升LLM的基础数学或逻辑能力，而是在为智能体提供一个更高效、更可控的“思考”框架。 5.  **第五步：最终决策** - 综合以上分析，论文《BRAID》的核心是提出一种新颖的、用于优化LLM智能体推理过程的结构化框架。它直接属于你的研究焦点中的**“单智能体”**方向，特别是**“规划”**和**“推理”**子方向。该论文为构建更高效、更强大的LLM智能体提供了新的方法论，因此完全符合你的筛选要求。"
    },
    {
        "index": "#30",
        "title": "Adaptation of Agentic AI",
        "link": "/arxiv/2512.16301",
        "arxiv_id": "2512.16301",
        "authors": "Pengcheng Jiang, Jiacheng Lin, Zhiyi Shi, Zifeng Wang, Luxi He, Yichen Wu, Ming Zhong, Peiyang Song, Qizheng Zhang, Heng Wang, Xueqiang Xu, Hanwen Xu, Pengrui Han, Dylan Zhang, Jiashuo Sun, Chaoqi Yang, Kun Qian, Tian Wang, Changran Hu, Manling Li, Quanzheng Li, Hao Peng, Sheng Wang, Jingbo Shang, Chao Zhang, Jiaxuan You, Liyuan Liu, Pan Lu, Yu Zhang, Heng Ji, Yejin Choi, Dawn Song, Jimeng Sun, Jiawei Han",
        "summary": "Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations. We further decompose these into tool-execution-signaled and agent-output-signaled forms of agent adaptation, as well as agent-agnostic and agent-supervised forms of tool adaptation. We demonstrate that this framework helps clarify the design space of adaptation strategies in agentic AI, makes their trade-offs explicit, and provides practical guidance for selecting or switching among strategies during system design. We then review the representative approaches in each category, analyze their strengths and limitations, and highlight key open challenges and future opportunities. Overall, this paper aims to offer a conceptual foundation and practical roadmap for researchers and practitioners seeking to build more capable, efficient, and reliable agentic AI systems.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-12-18",
        "category": "cs.CL",
        "crawl_time": "2025-12-19T11:00:04.340315",
        "filter_reason": "这篇论文完全符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将智能体作为工具去解决某个特定领域的问题，而是对“Agentic AI”的“Adaptation”（适应/演化）这一核心机制进行系统性梳理和框架构建。论文的核心贡献是提出了一个统一的框架，用于理解和设计智能体的适应策略，这直接关系到如何“改进或演化LLM智能体”，完全符合你的核心目标。 2.  **第二步：正面指标** - 论文标题和摘要中明确包含了你的核心关注点：`Agentic AI`。 - 摘要中提到了智能体的关键能力：`plan` (规划), `reason` (推理), `interact with external tools` (工具使用)。 - 论文的核心主题“Adaptation”与你的研究焦点“自我演化”高度相关，其子分类如“agent adaptations”和“tool adaptations”直接对应了智能体的改进和演化机制。这可以看作是对`Self-Improvement`和`Iterative Improvement`等概念的系统性归纳。 3.  **第三步：排除标准** - 论文的主要贡献不涉及`Safety`、`Alignment`、`Interpretability`等安全与对齐问题。 - 论文也未聚焦于`Vision`、`MLLMs`等多模态技术。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文明确将智能体的`planning`和`reasoning`作为其适应能力的基础，这属于智能体框架下的多步推理，符合保留条件。 - **自我演化的应用**: 这篇论文并非特定领域的应用，而是提出了一个通用的“适应”框架，其本身就是对“自我演化”机制的理论化和系统化，因此完全符合保留要求。 **最终决策**: 这篇论文的核心贡献在于为“LLM智能体的适应与演化”这一前沿领域提供了一个系统性的理论框架和设计路线图。它虽然不是提出一个全新的智能体模型，但它为你这样的研究者梳理了整个领域的设计空间、权衡取舍和未来方向。对于旨在“构建、改进或演化LLM智能体”的研究课题而言，这类高屋建瓴的综述和框架性论文是极具价值的导航性文献，能帮助你快速把握领域全貌，定位研究切入点。因此，它高度相关，必须保留。"
    },
    {
        "index": "#72",
        "title": "ReactorFold: Generative discovery of nuclear reactor cores via emergent physical reasoning",
        "link": "/arxiv/2512.15756",
        "arxiv_id": "2512.15756",
        "authors": "Yoonpyo Lee",
        "summary": "Designing nuclear reactor cores requires navigating large discrete design spaces governed by complex neutronic interactions. Traditional deterministic, metaheuristic, and machine-learning-assisted methods search within fixed, human-defined configuration spaces, limiting their ability to discover fundamentally new design topologies. Here we introduce ReactorFold, a generative framework that reformulates fuel-assembly design as a sequence modeling problem for language models. Using Monte Carlo data, parameter-efficient fine-tuning, and Direct Preference Optimization (DPO), the model learns the latent structure of a pressurized-water-reactor assembly and generates candidate layouts in a single forward pass. Notably, the DPO-aligned model exhibits emergent design-space expansion: despite being trained exclusively on configurations with a fixed number of gadolinium burnable absorber (Gd) rods, it autonomously adjusts Gd inventory to satisfy strict power-peaking constraints. The model also discovers high-performing asymmetric configurations that challenge conventional symmetric loading heuristics, accessing design regimes inaccessible to conventional search methods and demonstrating that language models can internalize causal physical relationships and transcend human-imposed design constraints.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-12",
        "category": "cs.LG",
        "crawl_time": "2025-12-19T11:00:05.036996",
        "filter_reason": "这篇论文符合筛选标准，应予以保留。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非简单地将LLM应用于核工程领域，而是提出了一种能够让LLM**超越其训练数据约束、自主演化其设计能力**的机制。论文的关键发现是“涌现的设计空间扩展”，即模型在训练后能够“自主调整Gd存量”以满足新的约束条件。这本质上是一种**自我完善和迭代**的过程，完全符合“自我演化”的定义。因此，它不属于“非演化型应用”的排除范畴。 2.  **正面指标 (第二步):** 论文的核心贡献与“自我演化”高度相关。 *   **自我演化机制:** 论文的核心是展示了一种通过Direct Preference Optimization (DPO)实现的**自我完善**机制。模型并非简单地复现训练数据中的模式，而是在对齐过程中演化出了新的、更优的设计策略（如调整Gd存量、发现非对称配置）。 *   **涌现能力:** “涌现的物理推理”和“涌现的设计空间扩展”是论文的核心亮点，这表明模型的能力在训练后发生了质变，是自我演化的典型表现。 3.  **排除标准 (第三步):** 论文虽然使用了DPO（一种对齐技术），但其目标是**对齐设计偏好**（满足功率峰值约束），而非AI安全、伦理或可解释性。因此，它不触发“安全与对齐”的排除规则。论文也不涉及多模态或视觉内容。 4.  **特殊和模糊情况 (第四步):** 这篇论文是“自我演化的应用”这一特殊情况的完美例证。 *   **规则应用:** 根据第四步的规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域（如‘用于化学实验的自我演化智能体’），也应该保留。” *   **论文分析:** ReactorFold的核心贡献正是提出并验证了一种**新的自我演化机制**（通过DPO对齐实现设计能力的涌现和扩展）。核反应堆设计仅仅是验证该机制的实验平台。研究的焦点在于模型**如何演化**，而不是演化出的反应堆设计本身。 **最终决策 (第五步):** 综合以上分析，尽管这篇论文没有涉及传统的智能体规划、工具使用或多智能体协作，但其核心贡献在于探索和实现了一种LLM的**自我演化**路径。它展示了LLM如何通过特定的训练和对齐策略，突破人类预设的框架，自主地提升其在复杂任务中的表现。这与研究课题中的“自我演化”方向高度契合，因此应被**保留**。"
    },
    {
        "index": "#122",
        "title": "Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM",
        "link": "/arxiv/2512.15784",
        "arxiv_id": "2512.15784",
        "authors": "Zibin Liu, Cheng Zhang, Xi Zhao, Yunfei Feng, Bingyu Bai, Dahu Feng, Erhu Feng, Yubin Xia, Haibo Chen",
        "summary": "Large Language Model (LLM) agents are increasingly deployed to automate complex workflows in mobile and desktop environments. However, current model-centric agent architectures struggle to self-evolve post-deployment: improving personalization, capability, and efficiency typically requires continuous model retraining/fine-tuning, which incurs prohibitive computational overheads and suffers from an inherent trade-off between model accuracy and inference efficiency. To enable iterative self-evolution without model retraining, we propose MOBIMEM, a memory-centric agent system. MOBIMEM first introduces three specialized memory primitives to decouple agent evolution from model weights: (1) Profile Memory uses a lightweight distance-graph (DisGraph) structure to align with user preferences, resolving the accuracy-latency trade-off in user profile retrieval; (2) Experience Memory employs multi-level templates to instantiate execution logic for new tasks, ensuring capability generalization; and (3) Action Memory records fine-grained interaction sequences, reducing the reliance on expensive model inference. Building upon this memory architecture, MOBIMEM further integrates a suite of OS-inspired services to orchestrate execution: a scheduler that coordinates parallel sub-task execution and memory operations; an agent record-and-replay (AgentRR) mechanism that enables safe and efficient action reuse; and a context-aware exception handling that ensures graceful recovery from user interruptions and runtime errors. Evaluation on AndroidWorld and top-50 apps shows that MOBIMEM achieves 83.1% profile alignment with 23.83 ms retrieval time (280x faster than GraphRAG baselines), improves task success rates by up to 50.3%, and reduces end-to-end latency by up to 9x on mobile devices.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-12-15",
        "category": "cs.LG",
        "crawl_time": "2025-12-19T11:00:05.184339",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了您设定的“自我演化”方向。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具应用，而是**提出了一种全新的、名为MOBIMEM的智能体系统架构**。其核心目标是解决现有智能体“无法在部署后自我演化”的关键问题。论文明确指出，其贡献在于“enable iterative self-evolution without model retraining”（在不重新训练模型的情况下实现迭代的自我演化）。这完全符合您筛选标准中“构建、改进或演化LLM智能体的方法论或新框架”的要求。 2.  **第二步：正面指标** - 论文包含了大量您关注的核心指标： - **核心范式**: `Self-Evolving` (标题和摘要中反复出现), `LLM-based Agents`。 - **智能体能力**: `Memory` (论文的核心，提出了三种专门的记忆原语), `Planning` (通过Experience Memory实现新任务的执行逻辑实例化，这属于规划范畴)。 - **演化机制**: `Self-Improvement` (通过记忆系统实现个性化、能力和效率的提升), `Iterative Improvement` (摘要中明确提出)。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全与对齐，也未将多模态或视觉作为研究核心。它是在移动和桌面环境中进行操作，但视觉/多模态并非其创新点，因此不触犯排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这是本案例的关键。论文虽然将MOBIMEM应用在了“AndroidWorld and top-50 apps”这一特定领域，但根据您的筛选规则：“如果论文的核心是提出一种新的‘自我演化’机制，即使它被应用在特定领域……也应该保留。” 这篇论文正是如此。它的核心价值在于MOBIMEM这个**自我演化机制本身**，而不是它在移动应用上的表现数据。应用场景仅是验证该机制有效性的试验场。 **最终决策**: 综合以上分析，这篇论文的核心贡献是构建了一个新颖的、以记忆为中心的智能体框架（MOBIMEM），旨在实现LLM智能体在部署后的自我演化和能力提升。这精准地契合了您研究课题中的“自我演化”方向。尽管它有具体的应用场景，但其根本创新在于智能体的演化机制，而非应用本身。因此，这篇论文应被**保留**。"
    },
    {
        "index": "#17",
        "title": "cuPilot: A Strategy-Coordinated Multi-agent Framework for CUDA Kernel Evolution",
        "link": "/arxiv/2512.16465",
        "arxiv_id": "2512.16465",
        "authors": "Jinwu Chen, Qidie Wu, Bin Li, Lin Ma, Xin Si, Yang Hu, Shouyi Yin, Jun Yang",
        "summary": "Optimizing CUDA kernels is a challenging and labor-intensive task, given the need for hardware-software co-design expertise and the proprietary nature of high-performance kernel libraries. While recent large language models (LLMs) combined with evolutionary algorithms show promise in automatic kernel optimization, existing approaches often fall short in performance due to their suboptimal agent designs and mismatched evolution representations. This work identifies these mismatches and proposes cuPilot, a strategy-coordinated multi-agent framework that introduces strategy as an intermediate semantic representation for kernel evolution. Key contributions include a strategy-coordinated evolution algorithm, roofline-guided prompting, and strategy-level population initialization. Experimental results show that the generated kernels by cuPilot achieve an average speed up of 3.09$\\times$ over PyTorch on a benchmark of 100 kernels. On the GEMM tasks, cuPilot showcases sophisticated optimizations and achieves high utilization of critical hardware units. The generated kernels are open-sourced at https://github.com/champloo2878/cuPilot-Kernels.git.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.229742",
        "filter_reason": "这篇论文完全符合你的研究范围，是一个典型的、高质量的“自我演化”与“多智能体”交叉领域的研究。 以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用到CUDA优化领域，而是**提出了一种全新的多智能体框架（cuPilot）和一种新的演化算法（策略协调的演化算法）**。其核心贡献在于方法论创新，即如何设计智能体以及如何让它们协同演化，从而更高效地完成任务。这完全符合“构建、改进或演化LLM智能体”的核心目标。它避开了“非演化型应用”的排除项，因为其核心是演化机制本身，而非应用结果。 2.  **第二步：正面指标** - 论文高度匹配你的核心关注点： - **核心范式**: 明确提到了 `Multi-Agent Systems (MAS)` 和 `Self-Evolving`（体现在标题的 \"Evolution\" 和摘要的 \"evolutionary algorithms\"）。 - **多智能体**: 标题和摘要都强调了 `Multi-agent Framework` 和 `Strategy-Coordinated`，这直接指向了智能体间的协作机制。 - **演化机制**: 论文的核心创新点之一是“策略协调的演化算法”，这属于 `Self-Improvement` 和 `Generational Evolution` 的范畴。 3.  **第三步：排除标准** - 论文不涉及任何排除标准。其焦点是算法和框架的性能，而非安全、对齐或多模态。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一特殊情况的完美范例。虽然它被应用在“CUDA内核优化”这个特定领域，但它的核心贡献是提出了一种**新的“自我演化”机制**（策略协调的演化算法、策略级种群初始化等）。根据你的规则，这种提出新机制并应用于特定领域的论文应该被保留。这篇论文的价值在于其提出的演化框架具有潜在的通用性，可以被借鉴到其他需要复杂搜索和优化的任务中。 **核心依据总结**: 该论文的核心贡献是**方法论层面的创新**，它构建了一个新颖的多智能体系统来解决一个复杂的演化问题。它研究的不是“如何用LLM写CUDA代码”，而是“如何设计一个多智能体框架，让智能体们通过协作和演化，高效地探索出最优的CUDA代码策略”。这直接命中了你研究课题中的“多智能体”和“自我演化”两个核心方向，是典型的Agentic AI研究。因此，这篇论文应该被保留。"
    },
    {
        "index": "#22",
        "title": "Synthelite: Chemist-aligned and feasibility-aware synthesis planning with LLMs",
        "link": "/arxiv/2512.16424",
        "arxiv_id": "2512.16424",
        "authors": "Nguyen Xuan-Vu, Daniel Armstrong, Milena Wehrbach, Andres M Bran, Zlatko Jončev, Philippe Schwaller",
        "summary": "Computer-aided synthesis planning (CASP) has long been envisioned as a complementary tool for synthetic chemists. However, existing frameworks often lack mechanisms to allow interaction with human experts, limiting their ability to integrate chemists' insights. In this work, we introduce Synthelite, a synthesis planning framework that uses large language models (LLMs) to directly propose retrosynthetic transformations. Synthelite can generate end-to-end synthesis routes by harnessing the intrinsic chemical knowledge and reasoning capabilities of LLMs, while allowing expert intervention through natural language prompts. Our experiments demonstrate that Synthelite can flexibly adapt its planning trajectory to diverse user-specified constraints, achieving up to 95\\% success rates in both strategy-constrained and starting-material-constrained synthesis tasks. Additionally, Synthelite exhibits the ability to account for chemical feasibility during route design. We envision Synthelite to be both a useful tool and a step toward a paradigm where LLMs are the central orchestrators of synthesis planning.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.231216",
        "filter_reason": "这篇论文符合我的研究范围，核心判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献是构建了一个名为 **Synthelite** 的新框架，而不是简单地将现有LLM或智能体框架作为工具应用于化学领域。该框架的核心功能是“合成规划”，并允许通过自然语言进行“专家干预”和“适应其规划轨迹”。这表明其本质是关于**构建一个具有规划能力的LLM智能体**，因此符合“保留”标准，避开了“非演化型应用”的排除规则。 2.  **正面指标 (第二步):** 论文明确包含了我的核心关注点。 *   **核心范式:** 论文提出了一个 `LLM-based Agent` 框架。 *   **智能体能力:** 论文的核心是 `Planning`（合成规划）。摘要中提到的“适应其规划轨迹”和“生成端到端合成路线”都体现了智能体在复杂任务中进行多步规划和决策的能力，这与ReAct等Agentic框架的范式高度一致。 3.  **排除标准 (第三步):** 论文的主要贡献不涉及安全、对齐或多模态视觉等领域，因此没有触发任何排除标准。 4.  **特殊情况处理 (第四步):** *   **推理/规划:** 这篇论文是“智能体如何进行规划或在复杂任务中进行多步推理”的典型范例。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个让LLM能够执行特定领域（化学合成）复杂规划任务的Agentic框架。因此，根据规则，应该保留。 **总结:** 尽管论文的应用领域是化学合成，但其核心贡献在于提出了一种新的、具有交互式和约束感知能力的**LLM智能体规划框架**。它研究了智能体如何利用LLM的知识进行多步规划、并根据外部反馈（人类专家的约束）调整策略，这完全属于我研究课题中“单智能体”方向下的“规划”子方向。因此，这篇论文是高度相关的前沿研究，应该被保留。"
    },
    {
        "index": "#28",
        "title": "OS-Oracle: A Comprehensive Framework for Cross-Platform GUI Critic Models",
        "link": "/arxiv/2512.16295",
        "arxiv_id": "2512.16295",
        "authors": "Zhenyu Wu, Jingjing Xie, Zehao Li, Bowen Yang, Qiushi Sun, Zhaoyang Liu, Zhoumianze Liu, Yu Qiao, Xiangyu Yue, Zun Wang, Zichen Ding",
        "summary": "With VLM-powered computer-using agents (CUAs) becoming increasingly capable at graphical user interface (GUI) navigation and manipulation, reliable step-level decision-making has emerged as a key bottleneck for real-world deployment. In long-horizon workflows, errors accumulate quickly and irreversible actions can cause unintended consequences, motivating critic models that assess each action before execution. While critic models offer a promising solution, their effectiveness is hindered by the lack of diverse, high-quality GUI feedback data and public critic benchmarks for step-level evaluation in computer use. To bridge these gaps, we introduce OS-Oracle that makes three core contributions: (1) a scalable data pipeline for synthesizing cross-platform GUI critic data; (2) a two-stage training paradigm combining supervised fine-tuning (SFT) and consistency-preserving group relative policy optimization (CP-GRPO); (3) OS-Critic Bench, a holistic benchmark for evaluating critic model performance across Mobile, Web, and Desktop platforms. Leveraging this framework, we curate a high-quality dataset containing 310k critic samples. The resulting critic model, OS-Oracle-7B, achieves state-of-the-art performance among open-source VLMs on OS-Critic Bench, and surpasses proprietary models on the mobile domain. Furthermore, when serving as a pre-critic, OS-Oracle-7B improves the performance of native GUI agents such as UI-TARS-1.5-7B in OSWorld and AndroidWorld environments. The code is open-sourced at https://github.com/numbmelon/OS-Oracle.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.233410",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为一个工具去解决某个特定领域（如生物、金融）的问题，而是聚焦于如何**改进LLM智能体本身**。其核心贡献是构建了一个名为“OS-Oracle”的框架，用于创建和训练“评判模型”。这个评判模型本身不是一个完整的智能体，但它是一个关键的**组件或机制**，用于增强其他智能体的能力。具体来说，它通过在智能体执行动作前进行评估和纠错，直接提升了智能体的可靠性和决策质量。这完全符合“改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **智能体能力**: 论文的核心是`Self-Correction`（自我纠正）和`Self-Reflection`（自我反思）机制。评判模型在每一步行动前对智能体的决策进行评估，这是一种显式的自我纠正和反思过程。 - **核心范式**: 研究背景是`Agentic AI`和`LLM-based Agents`（即文中的CUAs），旨在解决这些智能体在长任务中的关键瓶颈。 - **演化机制**: 虽然不是跨代的演化，但评判模型提供的迭代式改进（`Iterative Improvement`）是智能体在单次任务中实现性能提升的重要方式，属于自我演化的范畴。 3.  **第三步：排除标准** - **安全与对齐**: 论文的主要目标是提升智能体的任务成功率和可靠性，而不是研究`Safety`、`Alignment`或`Hallucination`等。虽然纠错能带来更安全的结果，但这不是论文的核心贡献和研究焦点。 - **多模态与视觉**: 论文确实涉及了`VLM`（视觉语言模型），因为智能体需要理解GUI界面。然而，根据您的规则，这里的视觉是作为智能体**感知环境的工具**。论文的核心贡献不是提出一个新的VLM架构或视觉理解算法，而是**如何将一个VLM训练成一个有效的“评判模型”**，并将其集成到智能体框架中以提升其决策能力。因此，这符合“除非它们被用作智能体感知环境的工具，而不是研究的核心”的例外情况。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的研究内容与智能体的规划和推理紧密相关。评判模型作用于智能体多步推理的每一步，确保其规划的合理性。这属于“关于智能体如何进行规划或在复杂任务中进行多步推理”的范畴，因此应该保留。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个用于智能体决策验证的框架。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一套完整的框架（数据、训练、评测）来构建一个能够**增强LLM智能体自我纠正和反思能力的“评判模型”**。这直接对应了您研究目标中的“改进LLM智能体”，特别是“单智能体”方向下的“自我反思”和“自我演化”方向下的“自我完善”。因此，这篇论文与您的研究课题高度相关，应该被筛选出来。"
    },
    {
        "index": "#30",
        "title": "Learning to Wait: Synchronizing Agents with the Physical World",
        "link": "/arxiv/2512.16262",
        "arxiv_id": "2512.16262",
        "authors": "Yifei She, Ping Zhang, He Liu, Yanmin Jia, Yang Jing, Zijun Liu, Peng Sun, Xiangbin Li, Xiaohe Hu",
        "summary": "Real-world agentic tasks, unlike synchronous Markov Decision Processes (MDPs), often involve non-blocking actions with variable latencies, creating a fundamental \\textit{Temporal Gap} between action initiation and completion. Existing environment-side solutions, such as blocking wrappers or frequent polling, either limit scalability or dilute the agent's context window with redundant observations. In this work, we propose an \\textbf{Agent-side Approach} that empowers Large Language Models (LLMs) to actively align their \\textit{Cognitive Timeline} with the physical world. By extending the Code-as-Action paradigm to the temporal domain, agents utilize semantic priors and In-Context Learning (ICL) to predict precise waiting durations (\\texttt{time.sleep(t)}), effectively synchronizing with asynchronous environment without exhaustive checking. Experiments in a simulated Kubernetes cluster demonstrate that agents can precisely calibrate their internal clocks to minimize both query overhead and execution latency, validating that temporal awareness is a learnable capability essential for autonomous evolution in open-ended environments.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.234084",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一种**“Agent-side Approach”**，旨在赋予LLM智能体一种新的能力——**时间感知**，使其能够与物理世界的异步操作同步。这并非将现有智能体框架简单应用于某个领域，而是**对智能体本身能力的构建和改进**。它解决了智能体在真实世界环境中面临的一个根本性问题（Temporal Gap），因此其本质是关于构建和改进LLM智能体的方法论，完全符合“保留”标准。 2.  **第二步：正面指标——高度匹配** 论文包含了多个核心关注点： *   **核心范式**: 论文明确聚焦于 `Agentic AI` 和 `LLM-based Agents`。 *   **智能体能力**: 论文的核心是关于智能体的**规划**能力。预测等待时间 (`time.sleep(t)`) 是智能体在异步环境中执行复杂任务规划的关键一环。同时，它扩展了 `Code-as-Action` 范式，属于 `Tool Use` 的范畴。 *   **演化机制**: 摘要最后明确指出，时间感知是智能体在开放环境中进行**“autonomous evolution”（自主演化）**的一项可学习的关键能力。这直接命中了您“自我演化”的研究焦点。 3.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性，也未以多模态或视觉为核心研究内容。因此，它没有被任何排除标准所排除。 4.  **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 这篇论文是关于智能体如何进行规划的典型范例。它研究的不是LLM基础的数学或逻辑推理，而是智能体在执行任务时如何处理环境的时间不确定性，这是一种高级的、与环境交互的规划能力，因此应**保留**。 *   **自我演化的应用**: 论文的核心是提出一种新的“时间感知”机制，并论证了这种机制对于“自主演化”至关重要。即使它在Kubernetes这个特定领域进行实验，其贡献也是普适性的智能体能力，因此完全符合保留条件。 **最终决策**: 这篇论文的核心贡献在于**构建和改进LLM智能体**，具体来说，是赋予智能体一种全新的、与物理世界同步的时间感知能力。该能力属于智能体的**规划**和**工具使用**范畴，并且被作者明确为智能体实现**自我演化**的关键一步。论文的研究内容与您“单智能体”和“自我演化”两个方向高度契合，是一篇高质量的前沿研究，应被筛选入内。"
    },
    {
        "index": "#34",
        "title": "PDE-Agent: A toolchain-augmented multi-agent framework for PDE solving",
        "link": "/arxiv/2512.16214",
        "arxiv_id": "2512.16214",
        "authors": "Jianming Liu, Ren Zhu, Jian Xu, Kun Ding, Xu-Yao Zhang, Gaofeng Meng, Cheng-Lin Liu",
        "summary": "Solving Partial Differential Equations (PDEs) is a cornerstone of engineering and scientific research. Traditional methods for PDE solving are cumbersome, relying on manual setup and domain expertise. While Physics-Informed Neural Network (PINNs) introduced end-to-end neural network-based solutions, and frameworks like DeepXDE further enhanced automation, these approaches still depend on expert knowledge and lack full autonomy. In this work, we frame PDE solving as tool invocation via LLM-driven agents and introduce PDE-Agent, the first toolchain-augmented multi-agent collaboration framework, inheriting the reasoning capacity of LLMs and the controllability of external tools and enabling automated PDE solving from natural language descriptions. PDE-Agent leverages the strengths of multi-agent and multi-tool collaboration through two key innovations: (1) A Prog-Act framework with graph memory for multi-agent collaboration, which enables effective dynamic planning and error correction via dual-loop mechanisms (localized fixes and global revisions). (2) A Resource-Pool integrated with a tool-parameter separation mechanism for multi-tool collaboration. This centralizes the management of runtime artifacts and resolves inter-tool dependency gaps in existing frameworks. To validate and evaluate this new paradigm for PDE solving , we develop PDE-Bench, a multi-type PDE Benchmark for agent-based tool collaborative solving, and propose multi-level metrics for assessing tool coordination. Evaluations verify that PDE-Agent exhibits superior applicability and performance in complex multi-step, cross-step dependent tasks. This new paradigm of toolchain-augmented multi-agent PDE solving will further advance future developments in automated scientific computing. Our source code and dataset will be made publicly available.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.235416",
        "filter_reason": "这篇论文完全符合您的研究范围，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是一篇应用论文。虽然它的应用领域是PDE求解，但其核心贡献是构建了一个名为“PDE-Agent”的**新型多智能体协作框架**。论文明确指出，它引入了“the first toolchain-augmented multi-agent collaboration framework”，并详细描述了其内部的“Prog-Act框架”和“Resource-Pool”等创新机制。这完全符合“核心贡献在于构建、改进LLM智能体”的要求。它不是简单地将一个已有的智能体框架拿来用，而是提出了新的方法论和架构。 2.  **第二步：正面指标** - 该论文包含了大量您关注的核心指标： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。 - **智能体能力**: 论文明确提到了 `Planning` (“dynamic planning”)、`Tool Use / Tool Augmentation` (“toolchain-augmented”, “multi-tool collaboration”)、`Memory` (“graph memory”) 和 `Self-Correction` (“error correction via dual-loop mechanisms”)。 - **多智能体**: `Collaboration` 是贯穿全文的主题。 3.  **第三步：排除标准** - 论文不涉及安全与对齐、多模态与视觉等排除领域。它的焦点完全集中在智能体的架构和协作机制上。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的“Prog-Act框架”正是关于智能体如何进行“动态规划”和“错误修正”的，这完全符合保留条件，因为它是在智能体框架的层面讨论规划，而非提升LLM本身的基础推理能力。 - **自我演化的应用**: 这篇论文虽然不是关于“自我演化”，但它完美地诠释了“核心是提出一种新机制，即使应用在特定领域也应保留”的原则。PDE求解在这里是验证其多智能体框架有效性的**实验平台**，而非研究的最终目的。论文的贡献在于这个框架本身，这个框架可以被迁移到其他需要复杂、多步骤、工具链协作的任务中。 **最终决策**：综合以上分析，这篇论文的核心贡献是构建了一个创新的、具备规划、记忆、工具使用和自我修正能力的多智能体框架。它直接推动了Agentic AI，特别是多智能体系统领域的发展。因此，它精准地符合您关于“LLM智能体及其演化”的研究课题，应被判定为 **True**。"
    },
    {
        "index": "#37",
        "title": "ToolForge: A Data Synthesis Pipeline for Multi-Hop Search without Real-World APIs",
        "link": "/arxiv/2512.16149",
        "arxiv_id": "2512.16149",
        "authors": "Hao Chen, Zhexin Hu, Jiajun Chai, Haocheng Yang, Hang He, Xiaohan Wang, Wei Lin, Luhang Wang, Guojun Yin, Zhuofeng zhao",
        "summary": "Training LLMs to invoke tools and leverage retrieved information necessitates high-quality, diverse data. However, existing pipelines for synthetic data generation often rely on tens of thousands of real API calls to enhance generalization, incurring prohibitive costs while lacking multi-hop reasoning and self-reflection. To address these limitations, we introduce ToolForge, an automated synthesis framework that achieves strong real-world tool-calling performance by constructing only a small number of virtual tools, eliminating the need for real API calls. ToolForge leverages a (question, golden context, answer) triple to synthesize large-scale tool-learning data specifically designed for multi-hop search scenarios, further enriching the generated data through multi-hop reasoning and self-reflection mechanisms. To ensure data fidelity, we employ a Multi-Layer Validation Framework that integrates both rule-based and model-based assessments. Empirical results show that a model with only 8B parameters, when trained on our synthesized data, outperforms GPT-4o on multiple benchmarks. Our code and dataset are publicly available at https://github.com/Buycar-arb/ToolForge .",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.236571",
        "filter_reason": "这篇论文完全符合您的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM或智能体作为工具去解决一个外部领域问题，而是提出了一种**构建和改进LLM智能体的新方法论**。其核心贡献是`ToolForge`，一个用于合成高质量训练数据的**框架**。这个框架的目的是为了让LLM更好地掌握**工具使用**这一核心智能体能力。因此，它直接命中了“构建、改进LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个您关注的核心范式和能力指标： - **智能体能力**: 论文的核心是`Tool Use / Tool Augmentation`（工具使用）。此外，摘要明确指出其生成的数据通过`multi-hop reasoning`（多跳推理）和`self-reflection mechanisms`（自我反思机制）进行了丰富。这三者都是您在“单智能体”方向下明确列出的关键子方向。 - **核心范式**: 整个`ToolForge`框架可以被视为一种`Agentic AI`的赋能技术，因为它专注于提升智能体的核心能力。 3.  **第三步：排除标准** - 论文的主要贡献不涉及`Safety`、`Alignment`、`Interpretability`等安全与对齐问题。 - 论文也未将`Vision`或多模态作为研究核心，其焦点完全在文本和工具调用上。 - 因此，该论文未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文讨论的`multi-hop reasoning`（多跳推理）是智能体在复杂任务中执行一系列步骤的能力，这与`ReAct`或`ToT`等Agentic框架中的规划/推理思想一致。它不是在提升LLM本身的基础数学或逻辑能力，而是在提升智能体在**工具使用场景下的规划和推理能力**。因此，这符合“保留”的条件。 **最终决策**: 这篇论文的核心贡献是`ToolForge`，一个旨在**提升LLM智能体工具使用、多跳推理和自我反思能力**的数据合成框架。它直接贡献于您研究课题中的“单智能体”方向，提出了一个新颖的、用于改进智能体核心能力的方法论。它不是应用型、安全型或基础设施型研究，因此完全符合您的筛选要求。"
    },
    {
        "index": "#27",
        "title": "Code-in-the-Loop Forensics: Agentic Tool Use for Image Forgery Detection",
        "link": "/arxiv/2512.16300",
        "arxiv_id": "2512.16300",
        "authors": "Fanrui Zhang, Qiang Zhang, Sizhuo Zhou, Jianwen Sun, Chuanhao Li, Jiaxin Ai, Yukang Feng, Yujie Zhang, Wenjie Li, Zizhen Li, Yifan Chang, Jiawei Liu, Kaipeng Zhang",
        "summary": "Existing image forgery detection (IFD) methods either exploit low-level, semantics-agnostic artifacts or rely on multimodal large language models (MLLMs) with high-level semantic knowledge. Although naturally complementary, these two information streams are highly heterogeneous in both paradigm and reasoning, making it difficult for existing methods to unify them or effectively model their cross-level interactions. To address this gap, we propose ForenAgent, a multi-round interactive IFD framework that enables MLLMs to autonomously generate, execute, and iteratively refine Python-based low-level tools around the detection objective, thereby achieving more flexible and interpretable forgery analysis. ForenAgent follows a two-stage training pipeline combining Cold Start and Reinforcement Fine-Tuning to enhance its tool interaction capability and reasoning adaptability progressively. Inspired by human reasoning, we design a dynamic reasoning loop comprising global perception, local focusing, iterative probing, and holistic adjudication, and instantiate it as both a data-sampling strategy and a task-aligned process reward. For systematic training and evaluation, we construct FABench, a heterogeneous, high-quality agent-forensics dataset comprising 100k images and approximately 200k agent-interaction question-answer pairs. Experiments show that ForenAgent exhibits emergent tool-use competence and reflective reasoning on challenging IFD tasks when assisted by low-level tools, charting a promising route toward general-purpose IFD. The code will be released after the review process is completed.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.233052",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于构建和改进一个具有自我演化能力的LLM智能体。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的本质不是简单地将LLM应用于图像伪造检测领域，而是提出了一种全新的智能体框架 **ForenAgent**。该框架的核心机制是让MLLM能够“**自主生成、执行和迭代优化**”基于Python的低级工具。这直接命中了你筛选标准中的“构建、改进或演化 LLM智能体”的核心目标。它不是非演化型应用，因为其核心创新点在于智能体的工作流和自我完善机制，而非应用本身。 **第二步：正面指标——高度匹配** 论文包含了大量你的核心关注点： *   **核心范式**: 论文明确提出了一个 `Agentic AI` 框架。 *   **智能体能力**: 核心贡献是 `Tool Use / Tool Augmentation`（自主生成和执行工具）。同时，`iteratively refine` 和 `reflective reasoning` 直接对应了 `Self-Refine` 和 `Self-Reflection`。其设计的 `dynamic reasoning loop`（动态推理循环）是智能体规划和推理能力的体现。 *   **演化机制**: `iteratively refine`（迭代优化）是 `Self-Improvement` 和 `Iterative Improvement` 的典型范例，属于自我演化的范畴。 **第三步：排除标准——未触发** *   **安全与对齐**: 论文虽然提到了“interpretable”（可解释性），但这是作为其智能体框架带来的一个优点，而非论文的主要研究贡献。论文的核心是构建智能体，而不是研究可解释性本身。 *   **多模态与视觉**: 论文确实使用了MLLMs来处理图像，但这完全符合你设定的例外情况——“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这里，视觉输入是智能体需要分析和处理的环境信息，而论文的核心是智能体如何通过生成和使用工具来分析这些信息，而不是研究MLLMs的视觉能力本身。 **第四步：处理特殊和模糊情况——符合保留规则** *   **推理/规划**: 论文提出的“动态推理循环”是典型的智能体规划和推理框架，而非单纯提升LLM的基础推理能力，因此应保留。 *   **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外情况的完美范例。它的核心贡献是提出了一种新的“自我演化”机制（即迭代优化工具），并将其应用在图像伪造检测这一特定领域。根据你的规则，这种情况应该保留。 **最终决策** 综合以上分析，这篇论文的核心是构建一个名为ForenAgent的单智能体系统，它具备先进的工具使用和自我迭代优化（自我演化）能力。尽管其应用场景是图像伪造检测，但其方法论和框架创新完全聚焦于Agentic AI的构建与演化，与你的研究课题高度契合。因此，最终判断为 **True**。"
    },
    {
        "index": "#43",
        "title": "Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning",
        "link": "/arxiv/2512.15943",
        "arxiv_id": "2512.15943",
        "authors": "Polaris Jhandi, Owais Kazi, Shreyas Subramanian, Neel Sendas",
        "summary": "As organizations scale adoption of generative AI, model cost optimization and operational efficiency have emerged as critical factors determining sustainability and accessibility. While Large Language Models (LLMs) demonstrate impressive capabilities across diverse tasks, their extensive computational requirements make them cost-prohibitive for routine enterprise use. This limitation motivates the exploration of Small Language Models (SLMs), which can deliver comparable performance in targeted applications while drastically reducing infrastructure overhead (Irugalbandara et al., 2023). In this work, we investigate the feasibility of replacing LLM-driven workflows with optimized SLMs. We trained a domain-adapted SLM to execute representative tasks traditionally handled by LLMs, such as document summarization, query answering, and structured data interpretation. As part of the experiment, we investigated the fine-tuning of facebook/opt-350m model (single epoch only) using the Hugging Face TRL (Transformer Reinforcement Learning), specifically the Supervised Fine-Tuning (SFT) trainer. The OPT-350M model was released by Meta AI in 2022 as part of the OPT (Open Pretrained Transformer) family of models. Similar studies demonstrate that even models at the 350M parameter scale can meaningfully contribute to instruction-tuning pipelines (Mekala et al., 2024). Experimental results demonstrated that our fine-tuned SLM achieves exceptional performance with a 77.55\\% pass rate on ToolBench evaluation, significantly outperforming all baseline models including ChatGPT-CoT (26.00\\%), ToolLLaMA-DFS (30.18\\%), and ToolLLaMA-CoT (16.27\\%). These findings emphasize that thoughtful design and targeted training of SLMs can significantly lower barriers to adoption, enabling cost-effective, large-scale integration of generative AI into production systems.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.238324",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非将LLM智能体作为工具应用到一个新领域，而是提出了一种**改进LLM智能体核心能力**的方法论。具体来说，它专注于提升智能体的“工具调用”能力，并通过使用小语言模型（SLM）进行有针对性的微调来实现这一目标。这直接属于“构建、改进或演化LLM智能体”的范畴，因此符合保留标准。它不是非演化型应用，也不是非Agentic的推理或基础设施研究。 2.  **第二步：正面指标——高度相关** 论文命中了多个核心正面指标： *   **核心范式**: 标题和摘要明确提到了 `Agentic Tool Calling`，直接指向 `Agentic AI` 和 `LLM-based Agents`。 *   **智能体能力**: 论文的核心是 `Tool Use / Tool Augmentation`。工具使用是智能体自主执行任务、与环境交互的关键能力，是我研究焦点中“单智能体”方向的核心子方向之一。论文在 `ToolBench` 这个专门评估工具使用能力的基准上进行测试，进一步证实了其相关性。 3.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等排除领域。其焦点是智能体的效率和性能，完全在我的研究范围内。 4.  **第四步：处理特殊和模糊情况——符合保留条件** 论文涉及“推理/规划”的特殊情况。工具调用是智能体进行多步推理和规划（如ReAct框架）中的关键一环。这篇论文并非在提升LLM的基础数学或逻辑能力，而是在**优化智能体在执行任务时的工具选择和调用这一推理行为**。因此，它符合“保留关于智能体如何进行规划或在复杂任务中进行多步推理”的规则。 **最终决策**: 综合以上分析，这篇论文的核心贡献在于提出了一种通过微调小语言模型来**高效地执行智能体工具调用任务**的方法，并证明了其在特定基准上可以超越大型模型。这直接对应了我研究目标中的“**改进LLM智能体**”，特别是“单智能体”方向下的“**工具使用**”能力。尽管论文的切入点是“效率”和“成本优化”，但其本质是**对智能体核心组件的构建与改进**，因此完全符合我的筛选要求。"
    },
    {
        "index": "#41",
        "title": "Conversational Time Series Foundation Models: Towards Explainable and Effective Forecasting",
        "link": "/arxiv/2512.16022",
        "arxiv_id": "2512.16022",
        "authors": "Defu Cao, Michael Gee, Jinbo Liu, Hengxuan Wang, Wei Yang, Rui Wang, Yan Liu",
        "summary": "The proliferation of time series foundation models has created a landscape where no single method achieves consistent superiority, framing the central challenge not as finding the best model, but as orchestrating an optimal ensemble with interpretability. While Large Language Models (LLMs) offer powerful reasoning capabilities, their direct application to time series forecasting has proven ineffective. We address this gap by repositioning the LLM as an intelligent judge that evaluates, explains, and strategically coordinates an ensemble of foundation models. To overcome the LLM's inherent lack of domain-specific knowledge on time series, we introduce an R1-style finetuning process, guided by SHAP-based faithfulness scores, which teaches the model to interpret ensemble weights as meaningful causal statements about temporal dynamics. The trained agent then engages in iterative, multi-turn conversations to perform forward-looking assessments, provide causally-grounded explanations for its weighting decisions, and adaptively refine the optimization strategy. Validated on the GIFT-Eval benchmark on 23 datasets across 97 settings, our approach significantly outperforms leading time series foundation models on both CRPS and MASE metrics, establishing new state-of-the-art results.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.237757",
        "filter_reason": "这篇论文符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM应用于时间序列预测，而是提出了一种**新的智能体框架**。其核心贡献在于将LLM重新定位为一个“智能法官”，这个法官能够评估、解释并策略性地协调一个由多个基础模型组成的集成系统。这本质上是在**构建一个具有特定功能的LLM智能体**，而不是将LLM作为黑盒工具直接应用。 2.  **第二步：正面指标** - 论文明确包含了多个核心关注点： - **Agentic AI / LLM-based Agents**: 摘要中直接使用了 \"intelligent judge\" 和 \"trained agent\" 来描述LLM的角色。 - **Self-Reflection / Self-Correction**: 智能体需要 \"explain its weighting decisions\"，这是一种自我反思和解释其行为的能力。 - **Self-Improvement / Iterative Improvement**: 摘要提到智能体会 \"adaptively refine the optimization strategy\"，这是一种基于反馈和对话进行自我完善和迭代优化的机制，完全符合“自我演化”的定义。 3.  **第三步：排除标准** - **安全与对齐**: 论文虽然提到了 \"Explainable\" (可解释性)，但这并非其**主要贡献**。论文的核心是提出一个能够**产生**解释的智能体架构，而不是提出一种新的可解释性（XAI）方法本身。可解释性是该智能体框架的一个关键特性和输出，用于支持其决策过程，因此不应因此被排除。 - **多模态与视觉**: 不涉及。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化的应用”的一个绝佳范例。虽然它应用在时间序列这个特定领域，但其核心贡献是提出了一种新的“自我演化”机制——即通过迭代对话和自适应优化来完善策略。根据你的筛选规则，这种情况应该**保留**。 - **推理/规划**: 论文中的智能体并非进行简单的数学或逻辑推理，而是在一个复杂任务（协调模型集成）中进行多步决策和规划，并根据结果进行调整。这完全符合保留标准。 **最终决策**: 综合以上分析，该论文的核心贡献在于**构建了一个能够自我反思、自我优化的LLM智能体**，用于协调和决策。它直接命中了你研究范围中的“单智能体”和“自我演化”两个核心方向。尽管它以时间序列预测为应用场景，但其创新点在于智能体架构本身，而非应用本身。因此，这篇论文高度相关，应被**保留 (True)**。"
    },
    {
        "index": "#38",
        "title": "WeMusic-Agent: Efficient Conversational Music Recommendation via Knowledge Internalization and Agentic Boundary Learning",
        "link": "/arxiv/2512.16108",
        "arxiv_id": "2512.16108",
        "authors": "Wendong Bi, Yirong Mao, Xianglong Liu, Kai Tian, Jian Zhang, Hanjie Wang, Wenhui Que",
        "summary": "Personalized music recommendation in conversational scenarios usually requires a deep understanding of user preferences and nuanced musical context, yet existing methods often struggle with balancing specialized domain knowledge and flexible tool integration. This paper proposes WeMusic-Agent, a training framework for efficient LLM-based conversational music recommendation. By integrating the knowledge internalization and agentic boundary learning, the framework aims to teach the model to intelligently decide when to leverage internalized knowledge and when to call specialized tools (e.g., music retrieval APIs, music recommendation systems). Under this framework, we present WeMusic-Agent-M1, an agentic model that internalizes extensive musical knowledge via continued pretraining on 50B music-related corpus while acquiring the ability to invoke external tools when necessary. Additionally, considering the lack of open-source benchmarks for conversational music recommendation, we also construct a benchmark for personalized music recommendations derived from real-world data in WeChat Listen. This benchmark enables comprehensive evaluation across multiple dimensions, including relevance, personalization, and diversity of the recommendations. Experiments on real-world data demonstrate that WeMusic-Agent achieves significant improvements over existing models.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.236886",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非简单地将LLM应用于音乐推荐领域，而是提出了一个名为 **WeMusic-Agent** 的**训练框架**。这个框架的核心是 **“知识内化”** 和 **“智能体边界学习”**，其目的是教会模型**智能地决定何时使用内部知识、何时调用外部工具**。这本质上是在构建和改进一个LLM智能体的决策机制，属于“构建、改进LLM智能体”的范畴，因此应**保留**。它不是“非演化型应用”，因为其创新点在于智能体的行为模式，而非应用本身。 2.  **正面指标 (第二步):** 论文明确包含了我的核心关注点。 *   **核心范式:** 论文标题和摘要中多次提及 `LLM-based Agent` 和 `Agentic`。 *   **智能体能力:** 论文的核心贡献 **“Agentic Boundary Learning”** 直接对应了 **`Tool Use / Tool Augmentation`**。智能体学习在“内部知识”和“外部工具调用”之间做决策，这是工具使用能力的关键一环，也是一种高级的规划和决策能力。 3.  **排除标准 (第三步):** 论文的主要贡献不涉及安全、对齐或多模态等排除领域。它专注于提升智能体在特定任务上的效率和决策能力，因此没有触发排除标准。 4.  **特殊和模糊情况 (第四步):** *   **推理/规划:** 论文中的“智能体边界学习”可以被视为一种轻量级的规划或决策过程。智能体不是在进行复杂的数学逻辑推理，而是在规划其行动路径（内部处理 vs. 外部调用），这符合“保留”关于智能体规划和多步推理的论文的要求。 **总结:** 尽管论文的应用场景是“音乐推荐”，但其**核心贡献是提出了一种新的、用于训练LLM智能体进行高效工具使用的框架**。它解决了智能体在“何时使用工具”这一关键问题上的决策能力，这完全属于我研究焦点中的 **“单智能体”** 方向，特别是 **“工具使用”** 子方向。因此，这篇论文是高度相关的前沿研究，应该被筛选出来。"
    },
    {
        "index": "#42",
        "title": "Subjective functions",
        "link": "/arxiv/2512.15948",
        "arxiv_id": "2512.15948",
        "authors": "Samuel J. Gershman",
        "summary": "Where do objective functions come from? How do we select what goals to pursue? Human intelligence is adept at synthesizing new objective functions on the fly. How does this work, and can we endow artificial systems with the same ability? This paper proposes an approach to answering these questions, starting with the concept of a subjective function, a higher-order objective function that is endogenous to the agent (i.e., defined with respect to the agent's features, rather than an external task). Expected prediction error is studied as a concrete example of a subjective function. This proposal has many connections to ideas in psychology, neuroscience, and machine learning.",
        "subjects": "Artificial Intelligence, Neurons and Cognition",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.238040",
        "filter_reason": "这篇论文符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的核心贡献并非将LLM或智能体作为工具去解决某个特定领域的问题，而是提出了一个名为“主观函数”的全新概念。这个概念旨在解决智能体如何自主生成目标这一根本性问题，即“目标函数从何而来”。这直接触及了智能体自主性的核心，属于构建和改进LLM智能体基础理论的范畴，而非简单的应用。 2.  **第二步：正面指标** - 论文的核心思想与你的多个核心关注点高度契合： - **自我演化**: 论文提出的“主观函数”是一种内生的、由智能体自身特征定义的目标函数。一个能够自主设定目标的智能体，是实现“自我完善和迭代”的先决条件。这直接关联到`Self-Evolving`、`Self-Improvement`和`Self-Reflection`等核心范式。 - **单智能体**: 论文探讨的是单个智能体如何进行高层次的认知活动——目标合成。这属于智能体内部机制的研究，与`Planning`（规划的前提是确定目标）和`Self-Reflection`（反思自身状态以确定新目标）等能力密切相关。 - **核心范式**: 论文的研究本质是`Agentic AI`，它试图赋予人工系统类似人类的高级认知能力，即自主定义追求的目标。 3.  **第三步：排除标准** - 论文的主要贡献不涉及`Safety`、`Alignment`、`Interpretability`等安全与对齐问题。 - 论文是理论性研究，不涉及`Vision`、`MLLMs`等多模态内容。 - 因此，论文未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文不是关于提升LLM在数学或逻辑上的基础推理能力，而是关于智能体在更高层次上“推理”自己应该追求什么目标。这完全符合“保留”的条件，因为它探讨的是智能体框架内的核心认知功能。 - **自我演化的应用**: 这篇论文本身就是对“自我演化”机制的一种理论探索，它提出的“主观函数”可以被看作是自我演化机制的基石。因此，它完全符合保留标准。 **最终决策**: 这篇论文的核心贡献是提出了一种让智能体能够内生地、自主地定义自身目标（主观函数）的理论框架。这直接命中了你研究课题中“自我演化”和“单智能体”的核心方向，因为它探讨了智能体实现真正自主和自我迭代的最根本前提：如何自己决定“做什么”。因此，这篇论文不仅符合，而且是高度相关的前沿研究，应该被**保留**。"
    },
    {
        "index": "#51",
        "title": "Prompt-to-Parts: Generative AI for Physical Assembly and Scalable Instructions",
        "link": "/arxiv/2512.15743",
        "arxiv_id": "2512.15743",
        "authors": "David Noever",
        "summary": "We present a framework for generating physically realizable assembly instructions from natural language descriptions. Unlike unconstrained text-to-3D approaches, our method operates within a discrete parts vocabulary, enforcing geometric validity, connection constraints, and buildability ordering. Using LDraw as a text-rich intermediate representation, we demonstrate that large language models can be guided with tools to produce valid step-by-step construction sequences and assembly instructions for brick-based prototypes of more than 3000 assembly parts. We introduce a Python library for programmatic model generation and evaluate buildable outputs on complex satellites, aircraft, and architectural domains. The approach aims for demonstrable scalability, modularity, and fidelity that bridges the gap between semantic design intent and manufacturable output. Physical prototyping follows from natural language specifications. The work proposes a novel elemental lingua franca as a key missing piece from the previous pixel-based diffusion methods or computer-aided design (CAD) models that fail to support complex assembly instructions or component exchange. Across four original designs, this novel \"bag of bricks\" method thus functions as a physical API: a constrained vocabulary connecting precisely oriented brick locations to a \"bag of words\" through which arbitrary functional requirements compile into material reality. Given such a consistent and repeatable AI representation opens new design options while guiding natural language implementations in manufacturing and engineering prototyping.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-10",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.240700",
        "filter_reason": "这篇论文符合我的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断——保留** 这篇论文的核心贡献并非简单地将LLM应用于物理装配领域，而是提出了一个**新颖的框架**。在这个框架中，LLM被用作一个智能体的核心“大脑”，通过**工具引导**来执行一个复杂的多步骤任务。具体来说，论文描述了如何让LLM使用LDraw（一个中间表示工具）和Python库，来生成符合物理约束的、分步的装配指令。这本质上是在**构建一个具备工具使用和规划能力的LLM智能体**，而不是一个非演化型的应用。因此，根据第一步的核心判断标准，应该保留。 **第二步：正面指标——高度相关** 论文包含了多个我核心关注点的正面指标： - **智能体能力**: 论文明确提到了“**Tool Use / Tool Augmentation**”（“large language models can be guided with tools”）和“**Planning**”（“produce valid step-by-step construction sequences and assembly instructions”）。这正是单智能体研究方向的核心能力。 - **核心范式**: 整个框架可以被视为一个“**LLM-based Agent**”，它接收自然语言指令，利用工具进行推理和规划，最终输出结构化的行动序列。 **第三步：排除标准——未命中** 论文的主要贡献不在于安全、对齐或多模态。虽然其最终输出可能用于物理世界，但论文的核心是生成指令的框架和方法，而不是研究视觉感知或模型安全性。因此，它没有触犯任何排除标准。 **第四步：处理特殊和模糊情况——符合保留条件** - **推理/规划**: 这篇论文是关于智能体如何进行规划的典型范例。它不是在提升LLM本身的基础数学或逻辑推理能力，而是在构建一个让LLM能够进行**复杂任务规划**（生成物理装配序列）的Agentic框架。这与ReAct等范式在精神上是一致的，即“推理+行动”。因此，它符合保留条件。 **第五步：最终决策** 综合以上分析，尽管论文的应用领域是物理装配，但其**核心贡献在于提出了一种构建LLM智能体的新方法论**。该方法论聚焦于如何让智能体通过使用工具来解决复杂的规划问题，完全符合我研究课题中“单智能体”方向下的“规划”和“工具使用”子方向。因此，这篇论文是高度相关且有价值的前沿研究，应被筛选出来。"
    },
    {
        "index": "#82",
        "title": "Hypernetworks That Evolve Themselves",
        "link": "/arxiv/2512.16406",
        "arxiv_id": "2512.16406",
        "authors": "Joachim Winther Pedersen, Erwan Plantec, Eleni Nisioti, Marcello Barylli, Milton Montero, Kathrin Korte, Sebastian Risi",
        "summary": "How can neural networks evolve themselves without relying on external optimizers? We propose Self-Referential Graph HyperNetworks, systems where the very machinery of variation and inheritance is embedded within the network. By uniting hypernetworks, stochastic parameter generation, and graph-based representations, Self-Referential GHNs mutate and evaluate themselves while adapting mutation rates as selectable traits. Through new reinforcement learning benchmarks with environmental shifts (CartPoleSwitch, LunarLander-Switch), Self-Referential GHNs show swift, reliable adaptation and emergent population dynamics. In the locomotion benchmark Ant-v5, they evolve coherent gaits, showing promising fine-tuning capabilities by autonomously decreasing variation in the population to concentrate around promising solutions. Our findings support the idea that evolvability itself can emerge from neural self-reference. Self-Referential GHNs reflect a step toward synthetic systems that more closely mirror biological evolution, offering tools for autonomous, open-ended learning agents.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.251287",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** - **核心贡献**: 这篇论文的核心贡献是提出了一种名为“自引用图超网络”的新框架，其本质是一种**让神经网络（智能体）自我演化的方法论**。它不依赖于外部优化器，而是将变异、评估和适应等演化机制内嵌于网络自身。 - **符合研究目标**: 这直接命中了你研究课题中的“**自我演化**”方向。论文的目标是创造能够“自主、开放式学习的智能体”，这与构建和演化LLM智能体的目标高度一致。它不是在应用一个已有的框架，而是在创造一种全新的演化范式。 2.  **第二步：正面指标——高度匹配** - 论文摘要中充满了你的核心关注点：`Self-Evolving`（自我演化）、`Evolutionary Algorithms`（演化算法，体现在变异、遗传、种群动态等概念中）、`Self-Improvement`（自我改进）、`Iterative Improvement`（迭代改进）。这些关键词表明论文与你的研究焦点紧密相关。 3.  **第三步：排除标准——未触发** - 论文的主要贡献是关于智能体的演化机制和能力，而非安全、对齐或多模态技术。因此，它没有触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况——适用例外规则** - **自我演化的应用**: 这篇论文是“自我演化的应用”这一例外规则的完美范例。论文虽然将自我演化机制应用在了强化学习的基准测试上（如CartPole, Ant-v5），但其**核心是提出一种全新的“自我演化”机制**。根据你的规则，即使应用在特定领域，只要核心是提出新的自我演化机制，就应该保留。 - **关于LLM的模糊性**: 虽然论文标题和摘要没有明确提及“LLM”，但它讨论的是“神经网络”和“超网络”的自我演化。超网络是一种可以生成其他网络权重的网络，这一概念完全可以应用于LLM。例如，一个超网络可以演化一个LLM智能体的策略网络或记忆模块。因此，这篇论文提出的方法论对于“LLM智能体的演化”具有直接的基础性和前瞻性价值。 5.  **第五步：最终决策** - 综合来看，这篇论文的核心贡献在于提出了一种创新的、内生的智能体自我演化框架。它直接解决了你研究课题中“自我演化”这一核心方向的关键问题：**智能体如何不依赖外部优化器而自主演化**。尽管其实验载体不是LLM，但其方法论对于构建和演化更高级的LLM智能体具有重要的启发和应用潜力。因此，这篇论文是高度相关且应该保留的前沿研究。"
    },
    {
        "index": "#120",
        "title": "A Multi-Agent Large Language Model Framework for Automated Qualitative Analysis",
        "link": "/arxiv/2512.16063",
        "arxiv_id": "2512.16063",
        "authors": "Qidi Xu, Nuzha Amjad, Grace Giles, Alexa Cumming, De'angelo Hermesky, Alexander Wen, Min Ji Kwak, Yejin Kim",
        "summary": "Understanding patients experiences is essential for advancing patient centered care, especially in chronic diseases that require ongoing communication. However, qualitative thematic analysis, the primary approach for exploring these experiences, remains labor intensive, subjective, and difficult to scale. In this study, we developed a multi agent large language model framework that automates qualitative thematic analysis through three agents (Instructor, Thematizer, CodebookGenerator), named Collaborative Theme Identification Agent (CoTI). We applied CoTI to 12 heart failure patient interviews to analyze their perceptions of medication intensity. CoTI identified key phrases, themes, and codebook that were more similar to those of the senior investigator than both junior investigators and baseline NLP models. We also implemented CoTI into a user-facing application to enable AI human interaction in qualitative analysis. However, collaboration between CoTI and junior investigators provided only marginal gains, suggesting they may overrely on CoTI and limit their independent critical thinking.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.265533",
        "filter_reason": "这篇论文符合筛选标准，应该被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是**构建一个新的多智能体LLM框架**。摘要明确指出，“we developed a multi agent large language model framework... named Collaborative Theme Identification Agent (CoTI)”，并详细描述了其由三个具有不同角色的智能体构成。这完全符合“核心贡献在于构建、改进LLM智能体”的要求。 - 它不属于“非演化型应用”的排除范畴。虽然论文将框架应用于“定性分析”这一特定领域，但其**核心贡献是框架本身的设计和实现**，而不是简单地将一个已有的智能体框架当作工具去解决领域问题。论文的重点在于提出CoTI这个方法论，而非定性分析的医学发现。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 和 `LLM-based Agents` 在标题和摘要中都被明确提及。 - **多智能体**: 论文的核心是智能体间的 `Collaboration`（协作），通过三个智能体分工完成复杂的定性分析任务，这隐含了智能体间的 `Communication`（通信）机制。 3.  **第三步：排除标准** - 论文的主要贡献不是关于安全、对齐或多模态。它专注于智能体的协作框架，因此不触及任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的多智能体协作流程可以被看作是一种结构化的规划和执行过程，符合“智能体如何进行规划或在复杂任务中进行多步推理”的保留标准。 - **自我演化的应用**: 虽然这篇论文不涉及自我演化，但它的情况与“自我演化的应用”的例外规则精神一致：**核心贡献是提出一种新的机制（多智能体协作框架），即使它被应用在特定领域，也应该保留。** **最终决策**: 综合以上分析，这篇论文的核心贡献是提出一个名为CoTI的多智能体LLM框架，用于自动化定性分析。这直接命中了研究课题中的“多智能体”方向。尽管其应用场景是医疗领域的定性分析，但论文的创新点在于智能体系统的构建方法本身，而非应用结果。因此，这篇论文与“LLM智能体及其演化”的研究范围高度相关，应予以保留。"
    },
    {
        "index": "#133",
        "title": "Scalable Agentic Reasoning for Designing Biologics Targeting Intrinsically Disordered Proteins",
        "link": "/arxiv/2512.15930",
        "arxiv_id": "2512.15930",
        "authors": "Matthew Sinclair, Moeen Meigooni, Archit Vasan, Ozan Gokdemir, Xinran Lian, Heng Ma, Yadu Babuji, Alexander Brace, Khalid Hossain, Carlo Siebenschuh, Thomas Brettin, Kyle Chard, Christopher Henry, Venkatram Vishwanath, Rick L. Stevens, Ian T. Foster, Arvind Ramanathan",
        "summary": "Intrinsically disordered proteins (IDPs) represent crucial therapeutic targets due to their significant role in disease -- approximately 80\\% of cancer-related proteins contain long disordered regions -- but their lack of stable secondary/tertiary structures makes them \"undruggable\". While recent computational advances, such as diffusion models, can design high-affinity IDP binders, translating these to practical drug discovery requires autonomous systems capable of reasoning across complex conformational ensembles and orchestrating diverse computational tools at scale.To address this challenge, we designed and implemented StructBioReasoner, a scalable multi-agent system for designing biologics that can be used to target IDPs. StructBioReasoner employs a novel tournament-based reasoning framework where specialized agents compete to generate and refine therapeutic hypotheses, naturally distributing computational load for efficient exploration of the vast design space. Agents integrate domain knowledge with access to literature synthesis, AI-structure prediction, molecular simulations, and stability analysis, coordinating their execution on HPC infrastructure via an extensible federated agentic middleware, Academy. We benchmark StructBioReasoner across Der f 21 and NMNAT-2 and demonstrate that over 50\\% of 787 designed and validated candidates for Der f 21 outperformed the human-designed reference binders from literature, in terms of improved binding free energy. For the more challenging NMNAT-2 protein, we identified three binding modes from 97,066 binders, including the well-studied NMNAT2:p53 interface. Thus, StructBioReasoner lays the groundwork for agentic reasoning systems for IDP therapeutic discovery on Exascale platforms.",
        "subjects": "Quantitative Methods, Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.269943",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进一个新颖的多智能体系统。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心本质是**构建一个新的LLM智能体框架**。摘要明确指出：“we designed and implemented **StructBioReasoner, a scalable multi-agent system**”（我们设计并实现了一个可扩展的多智能体系统StructBioReasoner）。 - 它提出了一个**新颖的“锦标赛式推理框架”**，让专业化的智能体相互竞争来生成和优化假设。这直接对应了您筛选标准中的“构建、改进或演化 LLM智能体的论文”。 - 尽管论文的应用领域是生物制药（一个特定领域），但论文的**核心贡献是方法论本身**，即这个多智能体系统如何工作、如何协调、如何推理，而不是它发现了什么具体的药物。这使其区别于“非演化型应用”，更符合第四步中“自我演化的应用”的例外情况精神——即核心贡献是新的智能体机制，即使它被应用在特定领域。 2.  **第二步：正面指标——高度匹配** - **核心范式**: 论文明确包含 `Multi-Agent Systems (MAS)` 和 `Agentic AI`（标题中的 \"Agentic Reasoning\"）。 - **智能体能力**: 论文详细描述了智能体的多种核心能力： - `Planning` & `Reasoning`: \"autonomous systems capable of reasoning across complex conformational ensembles and orchestrating diverse computational tools\"。 - `Tool Use / Tool Augmentation`: \"Agents integrate domain knowledge with access to literature synthesis, AI-structure prediction, molecular simulations, and stability analysis\"，这是典型的工具使用能力。 - **多智能体**: 论文的核心就是多智能体系统，包含了 `Collaboration` 和 `Competition`（\"specialized agents compete\"）。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不是关于安全、对齐、可解释性或幻觉。 - 论文虽然提到了扩散模型，但只是作为背景技术，其核心研究内容不涉及多模态或视觉。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文提出的“锦标赛式推理框架”是典型的智能体规划和推理机制，而不是提升LLM本身的基础数学或逻辑能力，因此符合保留条件。 - **自我演化的应用**: 如第一步所述，这篇论文是“提出一种新的智能体机制并应用在特定领域”的完美范例，其价值在于机制本身，因此应该保留。 **最终决策**: 这篇论文的核心贡献是**StructBioReasoner**，一个用于解决复杂科学问题的**新颖的多智能体推理框架**。它深入探讨了智能体如何通过竞争、协作和工具使用来完成大规模、多步骤的复杂任务。这完全契合您研究课题中的“多智能体”方向，并触及了“单智能体”的规划和工具使用能力。因此，这篇论文是您研究范围内的前沿高质量论文，应予以保留。"
    },
    {
        "index": "#141",
        "title": "CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory",
        "link": "/arxiv/2512.15813",
        "arxiv_id": "2512.15813",
        "authors": "Nishant Gaurav, Adit Akarsh, Tejas Ravishankar, Manoj Bajaj",
        "summary": "Current tool-using AI agents suffer from limited action space, context inefficiency, and probabilistic instability that makes them unsuitable for handling repetitive tasks which are otherwise reliably and efficiently tackled by agentic workflows built on platforms like n8n and Zapier. Earlier works like CodeAct, DynaSaur, Code Mode have tried to tackle the first two issues by using the whole Python language as its action space: The number of tools that the agent can call becomes infinite. Python code blocks can execute complex actions into a single step and print only relevant results which helps in keeping the context lean. However, the probabilistic instability issue still remains, as for the same task in the same environment, the agent can follow different trajectories due to the probabilistic nature of LLMs. Therefore, we need procedural memory for consistency and reliability. This paper proposes CodeMem, an architecture to implement procedural memory via code which can be used to build and run reusable agentic workflows with deterministic reliability.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-17",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.272728",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心贡献是提出了一种名为 `CodeMem` 的新架构，旨在构建和改进LLM智能体。它不是将现有智能体应用于某个特定领域，而是直接针对当前工具使用智能体存在的“概率不稳定性”这一根本性问题，提出了一种系统性的解决方案。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标 (高度匹配)** 论文命中了多个核心关注点： *   **核心范式**: 论文明确研究 `LLM-based Agents` 和 `Agentic AI`。 *   **智能体能力**: 论文的核心是解决智能体的 `Memory` 问题，具体提出了“程序性记忆”这一新概念。同时，它建立在 `Tool Use` 的研究之上（如引用CodeAct），并致力于构建可复用的“agentic workflows”，这与 `Planning` 能力密切相关。通过固化成功流程，它也实现了一种形式的 `Self-Correction`，解决了LLM的概率性不稳定性。 3.  **第三步：排除标准 (未触发)** 论文的研究焦点是智能体的架构和可靠性，不涉及安全、对齐、可解释性或视觉多模态等排除领域。 4.  **第四步：特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文关注的是如何构建可复用、可靠的“agentic workflows”，这属于智能体层面的规划和执行框架，而非提升LLM底层的数学或逻辑推理能力，因此符合保留条件。 *   **自我演化**: 虽然论文标题未直接使用“演化”，但其提出的“程序性记忆”机制，本质上是一种让智能体通过记录和重用成功的执行路径，从而实现自我完善和迭代的方式。它让智能体从一次性的、不稳定的执行，演变为可复现、可靠的自动化流程，这与“自我演化”的精神内核高度一致。 **总结**: 该论文的核心贡献在于为LLM智能体引入了一种创新的“程序性记忆”架构，以解决其在执行重复性任务时的可靠性问题。这直接推动了单智能体在**记忆**和**工具使用**方向的发展，并蕴含了**自我完善**的演化思想。因此，它是一篇与你研究课题高度相关的前沿论文，应予以保留。"
    },
    {
        "index": "#169",
        "title": "FedSight AI: Multi-Agent System Architecture for Federal Funds Target Rate Prediction",
        "link": "/arxiv/2512.15728",
        "arxiv_id": "2512.15728",
        "authors": "Yuhan Hou, Tianji Rao, Jeremy Tan, Adler Viton, Xiyue Zhang, David Ye, Abhishek Kodi, Sanjana Dulam, Aditya Paul, Yikai Feng",
        "summary": "The Federal Open Market Committee (FOMC) sets the federal funds rate, shaping monetary policy and the broader economy. We introduce \\emph{FedSight AI}, a multi-agent framework that uses large language models (LLMs) to simulate FOMC deliberations and predict policy outcomes. Member agents analyze structured indicators and unstructured inputs such as the Beige Book, debate options, and vote, replicating committee reasoning. A Chain-of-Draft (CoD) extension further improves efficiency and accuracy by enforcing concise multistage reasoning. Evaluated at 2023-2024 meetings, FedSight CoD achieved accuracy of 93.75\\% and stability of 93.33\\%, outperforming baselines including MiniFed and Ordinal Random Forest (RF), while offering transparent reasoning aligned with real FOMC communications.",
        "subjects": "General Finance, Artificial Intelligence",
        "date": "2025-12-05",
        "category": "cs.AI",
        "crawl_time": "2025-12-19T11:00:05.282618",
        "filter_reason": "这篇论文完全符合您的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非仅仅是“预测联邦基金利率”这一应用本身，而是提出了一个名为 **FedSight AI 的多智能体框架**。这个框架的设计、构建和改进是论文的精髓。它详细描述了如何使用LLM作为智能体，通过模拟FOMC成员的“分析、辩论、投票”过程来解决问题。这完全符合“构建、改进LLM智能体”的核心目标，因此它不是一个简单的“非演化型应用”，而是一个关于智能体系统架构的方法论研究。 2.  **第二步：正面指标——高度匹配** 论文摘要中包含了多个核心关注点的关键词： *   **核心范式**: 明确提出了 `Multi-Agent System Architecture`。 *   **多智能体**: 描述了智能体间的 `Collaboration`（协作）和 `Communication`（通信），具体表现为“debate options, and vote”（辩论选项和投票）。 *   **智能体能力/推理**: 提出了 `Chain-of-Draft (CoD)` 扩展，这是一种新的“多阶段推理”方法，旨在提升智能体的推理效率和准确性，这属于智能体规划和推理能力的改进。 3.  **第三步：排除标准——未触发** 论文的主要贡献不涉及安全、对齐、可解释性或视觉多模态等排除领域。虽然提到了“transparent reasoning”（透明的推理），但这是其多智能体框架设计带来的一个特性，而非研究本身的核心目标（研究目标是构建框架和提升预测性能）。 4.  **第四步：处理特殊和模糊情况——符合保留条件** 论文提出的 `Chain-of-Draft (CoD)` 方法，其目的是“enforcing concise multistage reasoning”（强制执行简洁的多阶段推理）。这完全符合“保留”条件，即它是关于**智能体如何进行规划和多步推理**的新框架，而不是单纯提升LLM底层Token预测能力的非Agentic方法。 **总结:** 该论文的核心是提出并验证了一个新颖的**多智能体系统架构**，并为其设计了一种新的**推理机制**。尽管其应用场景是金融预测，但其研究焦点和核心贡献在于**如何构建和改进这个LLM多智能体系统**，这与您的研究课题“LLM智能体及其演化”中的“多智能体”方向高度契合。因此，这篇论文应该被保留。"
    },
    {
        "index": "#32",
        "title": "Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning",
        "link": "/arxiv/2512.16917",
        "arxiv_id": "2512.16917",
        "authors": "Qihao Liu, Luoxin Ye, Wufei Ma, Yu-Cheng Chou, Alan Yuille",
        "summary": "Large language models (LLMs) with explicit reasoning capabilities excel at mathematical reasoning yet still commit process errors, such as incorrect calculations, brittle logic, and superficially plausible but invalid steps. In this paper, we introduce Generative Adversarial Reasoner, an on-policy joint training framework designed to enhance reasoning by co-evolving an LLM reasoner and an LLM-based discriminator through adversarial reinforcement learning. A compute-efficient review schedule partitions each reasoning chain into logically complete slices of comparable length, and the discriminator evaluates each slice's soundness with concise, structured justifications. Learning couples complementary signals: the LLM reasoner is rewarded for logically consistent steps that yield correct answers, while the discriminator earns rewards for correctly detecting errors or distinguishing traces in the reasoning process. This produces dense, well-calibrated, on-policy step-level rewards that supplement sparse exact-match signals, improving credit assignment, increasing sample efficiency, and enhancing overall reasoning quality of LLMs. Across various mathematical benchmarks, the method delivers consistent gains over strong baselines with standard RL post-training. Specifically, on AIME24, we improve DeepSeek-R1-Distill-Qwen-7B from 54.0 to 61.3 (+7.3) and DeepSeek-R1-Distill-Llama-8B from 43.7 to 53.7 (+10.0). The modular discriminator also enables flexible reward shaping for objectives such as teacher distillation, preference alignment, and mathematical proof-based reasoning.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-12-18",
        "category": "cs.CL",
        "crawl_time": "2025-12-22T11:00:06.330881",
        "filter_reason": "这篇论文完全符合您的研究范围。我的判断依据如下： 1.  **核心判断 (第一步):** - **保留**。这篇论文的本质不是将LLM作为工具应用，而是提出了一种全新的训练框架——**生成式对抗推理器**。其核心贡献在于方法论创新，即通过**对抗性强化学习共同演化**一个LLM推理器和一个LLM判别器。这直接命中了您研究目标中的“构建、改进或演化 LLM智能体”。 2.  **正面指标 (第二步):** - 论文包含了多个核心关注点： - **自我演化**: 摘要中明确使用了 **\"co-evolving\"** (共同演化) 一词，这是您研究焦点“自我演化”的直接体现。推理器和判别器在对抗过程中相互促进、共同迭代完善。 - **多智能体**: 该框架本质上是一个由**推理器**和**判别器**组成的双智能体系统。它们通过对抗性的交互和通信（判别器提供反馈）来共同完成任务，这符合“多智能体”的定义。 - **自我反思/修正**: 判别器的角色就是对推理器的推理链进行评估和纠错，这相当于为推理器提供了一个外部的、结构化的**自我反思** 和 **自我修正** 机制，是单智能体能力的关键部分。 3.  **排除标准 (第三步):** - 论文的主要贡献是提升推理能力的方法论，而非安全、对齐或多模态研究。因此，没有触发任何排除标准。 4.  **特殊和模糊情况 (第四步):** - **推理/规划**: 这篇论文虽然关注数学推理，但它并非简单地通过数据增强或微调来提升LLM的基础数学能力。相反，它构建了一个**智能体框架**，让推理过程变得可评估、可对抗、可演化。这完全符合“保留”关于智能体如何进行规划和多步推理的论文的标准。其核心是**过程**和**框架**，而非结果。 **核心依据总结**: 该论文的核心贡献是提出了一种名为“生成式对抗推理器”的**新框架**，该框架通过让两个基于LLM的智能体（推理器和判别器）**对抗性共同演化**，来提升推理能力。这精准地契合了您研究课题中的**“自我演化”**和**“多智能体”**两个核心方向，同时其判别器机制也涉及了单智能体的**“自我反思”**能力。因此，这是一篇高度相关的前沿论文，应当保留。"
    },
    {
        "index": "#4",
        "title": "AdaSearch: Balancing Parametric Knowledge and Search in Large Language Models via Reinforcement Learning",
        "link": "/arxiv/2512.16883",
        "arxiv_id": "2512.16883",
        "authors": "Tzu-Han Lin, Wei-Lin Chen, Chen-An Li, Hung-yi Lee, Yun-Nung Chen, Yu Meng",
        "summary": "Equipping large language models (LLMs) with search engines via reinforcement learning (RL) has emerged as an effective approach for building search agents. However, overreliance on search introduces unnecessary cost and risks exposure to noisy or malicious content, while relying solely on parametric knowledge risks hallucination. The central challenge is to develop agents that adaptively balance parametric knowledge with external search, invoking search only when necessary. Prior work mitigates search overuse by shaping rewards around the number of tool calls. However, these penalties require substantial reward engineering, provide ambiguous credit assignment, and can be exploited by agents that superficially reduce calls. Moreover, evaluating performance solely through call counts conflates necessary and unnecessary search, obscuring the measurement of true adaptive behavior. To address these limitations, we first quantify the self-knowledge awareness of existing search agents via an F1-based decision metric, revealing that methods such as Search-R1 often overlook readily available parametric knowledge. Motivated by these findings, we propose AdaSearch, a simple two-stage, outcome-driven RL framework that disentangles problem solving from the decision of whether to invoke search, and makes this decision process explicit and interpretable. This transparency is crucial for high-stakes domains such as finance and medical question answering, yet is largely neglected by prior approaches. Experiments across multiple model families and sizes demonstrate that AdaSearch substantially improves knowledge-boundary awareness, reduces unnecessary search calls, preserves strong task performance, and offers more transparent, interpretable decision behaviors.",
        "subjects": "Computation and Language",
        "date": "2025-12-18",
        "category": "cs.CL",
        "crawl_time": "2025-12-22T11:00:06.306022",
        "filter_reason": "这篇论文完全符合我的研究范围，应被保留。以下是我的详细判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 `AdaSearch` 的新框架，用于构建和改进LLM智能体。其核心贡献不是将现有智能体应用到某个领域，而是解决智能体内部的一个关键问题：如何自适应地决定何时使用内部知识（参数化知识），何时调用外部工具（搜索引擎）。这直接属于“构建、改进LLM智能体”的范畴。 2.  **第二步：正面指标** - 论文高度符合我的核心关注点： - **核心范式**: 论文明确提到了 `search agents`，属于 `LLM-based Agents`。 - **智能体能力**: 论文的核心是关于智能体的 `Tool Use / Tool Augmentation`（工具使用）。它研究的是智能体如何更智能地决定是否调用搜索工具，这是一种高级的规划和决策能力。此外，论文中提到的 `knowledge-boundary awareness`（知识边界感知）可以看作是 `Self-Reflection`（自我反思）的一种体现，即智能体需要了解自己知识的局限性。 3.  **第三步：排除标准** - 论文未触发任何排除标准。虽然提到了 `interpretable`（可解释性），但这只是其框架的一个优点和特性，并非论文的主要研究贡献。论文的核心目标是提升智能体的决策效率和能力，而不是研究可解释性本身。论文也未涉及安全、对齐或多模态等排除领域。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它研究的是智能体在解决问题时的多步决策过程（先判断是否需要搜索，再进行搜索或回答），这属于智能体的规划和推理范畴，而不是提升LLM本身的基础数学或逻辑能力。 **最终决策**: 这篇论文的核心贡献是提出了一种新的强化学习框架 `AdaSearch`，用于改进LLM智能体的工具使用决策机制。它使智能体能够更智能、更高效地平衡内部知识与外部搜索，这直接对应了我研究目标中的“单智能体”方向，特别是其“工具使用”和“自我反思”子方向。因此，这篇论文是高度相关且有价值的前沿研究，应被保留。"
    },
    {
        "index": "#7",
        "title": "Meta-RL Induces Exploration in Language Agents",
        "link": "/arxiv/2512.16848",
        "arxiv_id": "2512.16848",
        "authors": "Yulun Jiang, Liangze Jiang, Damien Teney, Michael Moor, Maria Brbic",
        "summary": "Reinforcement learning (RL) has enabled the training of large language model (LLM) agents to interact with the environment and to solve multi-turn long-horizon tasks. However, the RL-trained agents often struggle in tasks that require active exploration and fail to efficiently adapt from trial-and-error experiences. In this paper, we present LaMer, a general Meta-RL framework that enables LLM agents to actively explore and learn from the environment feedback at test time. LaMer consists of two key components: (i) a cross-episode training framework to encourage exploration and long-term rewards optimization; and (ii) in-context policy adaptation via reflection, allowing the agent to adapt their policy from task feedback signal without gradient update. Experiments across diverse environments show that LaMer significantly improves performance over RL baselines, with 11%, 14%, and 19% performance gains on Sokoban, MineSweeper and Webshop, respectively. Moreover, LaMer also demonstrates better generalization to more challenging or previously unseen tasks compared to the RL-trained agents. Overall, our results demonstrate that Meta-RL provides a principled approach to induce exploration in language agents, enabling more robust adaptation to novel environments through learned exploration strategies.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-18",
        "category": "cs.LG",
        "crawl_time": "2025-12-22T11:00:07.289025",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接聚焦于“LLM智能体及其演化”中的“自我演化”和“单智能体”方向。 **判断过程如下:** 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体作为工具去解决某个特定领域的问题，而是提出了一种名为 `LaMer` 的**新框架**。这个框架的核心目标是**改进LLM智能体本身的能力**，特别是它们在未知环境中主动探索和适应的能力。这完全符合“构建、改进或演化LLM智能体”的核心要求。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `LLM-based Agents` (标题和摘要中明确提及)。 - **自我演化**: 这是论文最核心的贡献。`Meta-RL` (元强化学习) 本身就是一种“学习如何学习”的范式，与自我演化高度相关。摘要中提到的 `learn from the environment feedback`、`adapt their policy`、`better generalization to...unseen tasks` 都是自我演化的典型特征。 - **智能体能力**: `Self-Reflection` (摘要中明确提到 `in-context policy adaptation via reflection`)，`Planning` (主动探索和解决长视野任务必然涉及规划)。 - 这些正面指标非常强烈，表明论文与您的研究焦点高度相关。 3.  **第三步：排除标准** - 论文的主要贡献并非关于安全、对齐、可解释性或多模态。它的焦点是智能体的性能和适应能力，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化应用”规则下的一个完美**保留**案例。虽然它在Sokoban、MineSweeper等具体环境中进行实验，但其**核心贡献是提出了一种通用的“自我演化”机制（Meta-RL框架）**，而不是仅仅应用智能体去解决扫雷问题。这个机制本身是可迁移的，是研究的主体。 - **推理/规划**: 论文关注的是智能体在复杂、多轮任务中如何通过**主动探索**来学习和适应，这属于智能体层面的规划和推理，而不是改进LLM底层的数学或逻辑推理能力。因此，符合保留条件。 **最终决策:** 这篇论文的核心贡献是提出了一种基于元强化学习（Meta-RL）的新框架 `LaMer`，旨在**提升LLM智能体的主动探索能力和在测试时的自适应能力**。其关键技术点，如跨回合训练和通过反思进行上下文策略调整，直接对应了您研究目标中的**“自我演化”**和**“单智能体”**（特别是自我反思与规划）方向。它不是简单的应用，而是对智能体核心能力的根本性改进，因此是您课题下非常前沿且高度相关的一篇论文。"
    }
]