[
    {
        "index": "#3",
        "title": "CrowdLLM: Building LLM-Based Digital Populations Augmented with Generative Models",
        "link": "/arxiv/2512.07890",
        "arxiv_id": "2512.07890",
        "authors": "Ryan Feng Lin, Keyu Tian, Hanming Zheng, Congjing Zhang, Li Zeng, Shuai Huang",
        "summary": "The emergence of large language models (LLMs) has sparked much interest in creating LLM-based digital populations that can be applied to many applications such as social simulation, crowdsourcing, marketing, and recommendation systems. A digital population can reduce the cost of recruiting human participants and alleviate many concerns related to human subject study. However, research has found that most of the existing works rely solely on LLMs and could not sufficiently capture the accuracy and diversity of a real human population. To address this limitation, we propose CrowdLLM that integrates pretrained LLMs and generative models to enhance the diversity and fidelity of the digital population. We conduct theoretical analysis of CrowdLLM regarding its great potential in creating cost-effective, sufficiently representative, scalable digital populations that can match the quality of a real crowd. Comprehensive experiments are also conducted across multiple domains (e.g., crowdsourcing, voting, user rating) and simulation studies which demonstrate that CrowdLLM achieves promising performance in both accuracy and distributional fidelity to human data.",
        "subjects": "Multiagent Systems, Machine Learning, Methodology, Machine Learning",
        "date": "2025-12-02",
        "category": "cs.MA",
        "crawl_time": "2025-12-10T11:00:04.448277",
        "filter_reason": "这篇论文符合研究范围。 我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为 `CrowdLLM` 的新框架，其核心目标是**构建**一个基于LLM的“数字人口”。这个“数字人口”本质上就是一个由多个LLM智能体组成的集合，即一个**多智能体系统**。论文的核心贡献在于构建这个系统的方法论（如何通过结合生成模型来提升智能体群体的多样性和保真度），而不是简单地将一个已有的智能体框架应用到某个领域。因此，它通过了第一步的核心判断。 2.  **第二步：正面指标** - 论文的核心贡献与 `LLM-based Agents` 和 `Multi-Agent Systems (MAS)` 这两个核心范式高度相关。摘要中明确提到“LLM-based digital populations”，这直接指向了多智能体系统。虽然未明确提及 `Collaboration` 或 `Communication`，但构建一个用于“社会模拟”的“人口”，其内在逻辑必然涉及智能体间的互动和社会性，这与多智能体的研究目标一致。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐或可解释性，也未将视觉或多模态作为研究核心。因此，没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文不涉及智能体的内部推理或规划机制，而是聚焦于智能体群体的构建方法，因此此项不适用。 - **自我演化的应用**: 论文的核心贡献不是一种“自我演化”机制，而是构建静态但高质量的智能体群体的方法。因此，此项也不适用。 5.  **第五步：最终决策** - 综合分析，该论文的核心贡献在于**构建多智能体系统**的新方法。它提出了一种框架来创建更逼真、更多样化的LLM智能体群体，这完全符合我研究课题中的“多智能体”方向。虽然它没有涉及智能体的自我演化，但它为构建更复杂、更真实的多智能体社会提供了基础，是“LLM智能体及其演化”研究中非常前沿和相关的组成部分。因此，最终判断为 **True**。"
    },
    {
        "index": "#8",
        "title": "Curriculum Guided Massive Multi Agent System Solving For Robust Long Horizon Tasks",
        "link": "/arxiv/2512.08545",
        "arxiv_id": "2512.08545",
        "authors": "Indrajit Kar, Kalathur Chenchu Kishore Kumar",
        "summary": "Large Language Models and multi-agent systems have shown promise in decomposing complex tasks, yet they struggle with long-horizon reasoning tasks and escalating computation cost. This work introduces a hierarchical multi-agent architecture that distributes reasoning across a 64*64 grid of lightweight agents, supported by a selective oracle. A spatial curriculum progressively expands the operational region of the grid, ensuring that agents master easier central tasks before tackling harder peripheral ones. To improve reliability, the system integrates Negative Log-Likelihood as a measure of confidence, allowing the curriculum to prioritize regions where agents are both accurate and well calibrated. A Thompson Sampling curriculum manager adaptively chooses training zones based on competence and NLL-driven reward signals. We evaluate the approach on a spatially grounded Tower of Hanoi benchmark, which mirrors the long-horizon structure of many robotic manipulation and planning tasks. Results demonstrate improved stability, reduced oracle usage, and stronger long-range reasoning from distributed agent cooperation.",
        "subjects": "Computation and Language, Artificial Intelligence, Computer Vision and Pattern Recognition, Multiagent Systems",
        "date": "2025-12-09",
        "category": "cs.MA",
        "crawl_time": "2025-12-10T11:00:04.449687",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接命中了“多智能体”和“自我演化”两个核心方向。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将现有智能体框架应用于某个领域，而是**提出了一种全新的、用于解决长时程任务的分层多智能体架构**。其核心创新点在于：1）一个大规模（64x64）的轻量级智能体网格；2）一个引导智能体学习的“空间课程学习”机制。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 - **智能体能力**: 论文聚焦于解决 `Long Horizon Tasks`，这直接关联到智能体的 `Planning`（规划）能力。 - **多智能体**: 论文明确提到了 `distributed agent cooperation`（分布式智能体协作），这是多智能体研究的核心。 - **演化机制**: 论文的另一个核心贡献是 `Curriculum Guided`（课程引导）的学习机制。这种“从易到难、逐步扩展”的训练方式，以及使用 `Thompson Sampling` 进行自适应区域选择，是一种结构化的、迭代的智能体系统改进方法，属于 `Iterative Improvement` 的范畴，与“自我演化”的理念高度契合。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性等排除主题。 - 论文虽然提到了 `spatially grounded`（空间基础）和 `robotic manipulation`（机器人操作）等应用场景，但其核心是提出一个通用的智能体架构和训练方法，并以一个经典的规划基准进行验证。视觉或机器人技术在这里是作为评估背景，而非研究核心，因此不触发排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是关于智能体如何进行规划的完美范例。它不是在提升LLM本身的基础推理能力，而是在设计一个多智能体系统架构和训练流程，来**协同完成复杂的长时程规划任务**。这完全符合保留标准。 **最终决策**: 该论文的核心贡献是提出了一种新颖的、大规模的多智能体系统架构，并为其设计了一种课程学习机制来引导其协作解决长时程规划问题。这直接对应了您研究课题中的“多智能体”方向，并通过课程学习机制触及了“自我演化”的范畴。它不是简单的应用，而是对智能体系统本身的构建和改进，因此是您研究范围内的前沿论文。"
    },
    {
        "index": "#4",
        "title": "Towards Foundation Models with Native Multi-Agent Intelligence",
        "link": "/arxiv/2512.08743",
        "arxiv_id": "2512.08743",
        "authors": "Shuyue Hu, Haoyang Yan, Yiqun Zhang, Yang Chen, Dongzhan Zhou, Lei Bai",
        "summary": "Foundation models (FMs) are increasingly assuming the role of the \"brain\" of AI agents. While recent efforts have begun to equip FMs with native single-agent abilities -- such as GUI interaction or integrated tool use -- we argue that the next frontier is endowing FMs with native multi-agent intelligence. We identify four core capabilities of FMs in multi-agent contexts: understanding, planning, efficient communication, and adaptation. Contrary to assumptions about the spontaneous emergence of such abilities, we provide extensive empirical evidence across 41 large language models showing that strong single-agent performance alone does not automatically yield robust multi-agent intelligence. To address this gap, we outline key research directions -- spanning dataset construction, evaluation, training paradigms, and safety considerations -- for building FMs with native multi-agent intelligence.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-12-09",
        "category": "cs.MA",
        "crawl_time": "2025-12-10T11:00:04.448559",
        "filter_reason": "这篇论文完全符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是应用现有智能体解决某个具体领域问题，而是提出一个全新的、前瞻性的研究方向和框架。其核心贡献在于**构建和改进LLM智能体**，具体来说是“赋予基础模型原生的多智能体智能”。论文明确指出了当前研究的空白，并提出了“如何构建”这类智能体的关键研究方向（数据集、评估、训练范式等）。这完全符合你筛选标准中“核心贡献在于构建、改进或演化LLM智能体的论文”的要求。 2.  **第二步：正面指标** - 论文高度契合你的核心关注点。标题和摘要中充满了相关的核心范式和能力关键词： - **核心范式**: `Multi-Agent Systems (MAS)` 是论文的绝对核心。 - **智能体能力**: 明确提到了 `Planning` 和 `Communication`，并强调了 `Adaptation`（适应），这与自我演化有紧密联系。 - **多智能体**: 论文的主题就是多智能体，探讨了智能体间的 `Communication` 和协作所需的能力。 3.  **第三步：排除标准** - 论文没有被排除。虽然摘要末尾提到了 \"safety considerations\"，但它只是作为未来研究方向的一个组成部分被列出，并非论文的主要贡献。论文的核心是构建智能体的方法论，而不是研究安全与对齐本身。因此，这不触发排除规则。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文将 `Planning` 列为多智能体智能的四大核心能力之一，并探讨如何在多智能体背景下实现它。这符合“保留”标准，因为它是在智能体框架下讨论规划，而不是孤立地提升LLM的基础推理能力。 5.  **第五步：最终决策** - 综合分析，这篇论文的核心贡献是为“构建具有原生多智能体智能的LLM”这一前沿课题提供理论框架和研究路线图。它直接命中了你研究焦点中的“多智能体”方向，并触及了“自我演化”中的“适应”概念。这篇论文不是简单的应用，而是对Agentic AI领域未来发展的顶层设计和思考，对于你“LLM智能体及其演化”的研究课题具有极高的参考价值和前瞻性。因此，最终判断为 **True**。"
    },
    {
        "index": "#5",
        "title": "Insured Agents: A Decentralized Trust Insurance Mechanism for Agentic Economy",
        "link": "/arxiv/2512.08737",
        "arxiv_id": "2512.08737",
        "authors": "Botao 'Amber' Hu, Bangdao Chen",
        "summary": "The emerging \"agentic web\" envisions large populations of autonomous agents coordinating, transacting, and delegating across open networks. Yet many agent communication and commerce protocols treat agents as low-cost identities, despite the empirical reality that LLM agents remain unreliable, hallucinated, manipulable, and vulnerable to prompt-injection and tool-abuse. A natural response is \"agents-at-stake\": binding economically meaningful, slashable collateral to persistent identities and adjudicating misbehavior with verifiable evidence. However, heterogeneous tasks make universal verification brittle and centralization-prone, while traditional reputation struggles under rapid model drift and opaque internal states. We propose a protocol-native alternative: insured agents. Specialized insurer agents post stake on behalf of operational agents in exchange for premiums, and receive privileged, privacy-preserving audit access via TEEs to assess claims. A hierarchical insurer market calibrates stake through pricing, decentralizes verification via competitive underwriting, and yields incentive-compatible dispute resolution.",
        "subjects": "Computers and Society, Multiagent Systems",
        "date": "2025-12-09",
        "category": "cs.MA",
        "crawl_time": "2025-12-10T11:00:04.448809",
        "filter_reason": "这篇论文完全符合你的研究范围，核心依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献并非将LLM智能体作为工具应用到一个特定领域，而是提出了一种全新的、用于构建和管理大规模多智能体系统的**方法论和框架**。它没有解决生物或金融问题，而是解决了“Agentic Economy”（智能体经济）中智能体之间如何建立信任、安全协作的根本性问题。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标——高度匹配** 论文内容与你的核心关注点高度重合： *   **核心范式**: 论文明确聚焦于 `Agentic AI` 和 `Multi-Agent Systems (MAS)`，提出了一个“agentic web”的愿景。 *   **多智能体**: 论文的整个框架都是围绕多智能体交互展开的，涉及 `Collaboration` (协作)、`Communication` (通信)、`Negotiation` (通过保费定价)以及一个复杂的 `Agent Society` (由运营智能体和保险商智能体组成的社会结构)。 3.  **第三步：排除标准——未触犯** 这是最关键的一点。虽然论文提到了LLM智能体的不可靠性、幻觉、提示注入等问题，这些都与`Safety`和`Security`相关，但**论文的主要贡献并非提出一种新的安全技术或对齐算法**。相反，它提出的是一个**经济和协议层面的机制**来**管理**这些固有的风险。它的核心是“一个去中心化的信任保险机制”，这是一个系统架构和博弈论设计，而不是一个模型内部的安全加固方法。因此，它没有触犯“主要贡献是关于安全与对齐”的排除规则。它的研究焦点是**如何让有缺陷的智能体在一个多智能体社会中更可靠地协作**，这本身就是对多智能体系统的一种重要改进和演化。 4.  **第四步：特殊和模糊情况——不适用** 论文不涉及基础推理或自我演化的特殊情况，因此无需额外判断。 **总结**: 这篇论文的核心是提出一种新颖的多智能体系统框架，通过引入“保险商智能体”这一新角色和相应的经济协议，来解决开放网络中多智能体协作的信任问题。这直接属于你研究焦点中的**“多智能体”**方向，是对智能体间协作、通信和社会结构的一次深刻探索和改进。因此，它是一篇非常相关且前沿的论文，应当保留。"
    },
    {
        "index": "#6",
        "title": "Multi-Agent Intelligence for Multidisciplinary Decision-Making in Gastrointestinal Oncology",
        "link": "/arxiv/2512.08674",
        "arxiv_id": "2512.08674",
        "authors": "Rongzhao Zhang, Junqiao Wang, Shuyun Yang, Mouxiao Bian, Chao Ding, Yuwei Bai, Chihao Zhang, Yuguang Shen, Lei Wang, Lei Zheng, Qiujuan Yan, Yun Zhong, Meiling Liu, Jiwei Yu, Zheng Wang, Jie Xu, Meng Luo",
        "summary": "Multimodal clinical reasoning in the field of gastrointestinal (GI) oncology necessitates the integrated interpretation of endoscopic imagery, radiological data, and biochemical markers. Despite the evident potential exhibited by Multimodal Large Language Models (MLLMs), they frequently encounter challenges such as context dilution and hallucination when confronted with intricate, heterogeneous medical histories. In order to address these limitations, a hierarchical Multi-Agent Framework is proposed, which emulates the collaborative workflow of a human Multidisciplinary Team (MDT). The system attained a composite expert evaluation score of 4.60/5.00, thereby demonstrating a substantial improvement over the monolithic baseline. It is noteworthy that the agent-based architecture yielded the most substantial enhancements in reasoning logic and medical accuracy. The findings indicate that mimetic, agent-based collaboration provides a scalable, interpretable, and clinically robust paradigm for automated decision support in oncology.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-12-09",
        "category": "cs.MA",
        "crawl_time": "2025-12-10T11:00:04.449158",
        "filter_reason": "这篇论文符合你的研究范围，应予以保留。我的判断过程如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出了一种“分层多智能体框架”，用于解决多模态LLMs在复杂医疗任务中遇到的上下文稀释和幻觉问题。这并非简单地将一个已有的智能体框架应用到新领域，而是**构建了一个新的多智能体系统（Multi-Agent Systems）方法论**。论文明确指出，其性能提升的关键在于“agent-based architecture”（基于智能体的架构），这完全符合你筛选标准中“核心贡献在于构建、改进或演化LLM智能体”的要求。因此，它不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——高度相关** 论文包含了多个核心关注点： *   **核心范式**: `Multi-Agent Systems (MAS)` 是论文的核心。 *   **多智能体**: 论文明确研究了智能体间的 `Collaboration`（协作），通过“模拟人类多学科团队（MDT）的协作工作流程”来实现。这直接命中了你的“多智能体”研究方向。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 摘要中提到了“可解释的”，但这被描述为该框架带来的一个**优点或特性**，而非论文的**主要贡献**。论文的核心是框架设计和性能提升，而不是提出一种新的可解释性方法。因此，这不触发排除规则。 *   **多模态与视觉**: 论文涉及了“内窥镜图像”和“放射学数据”，属于多模态范畴。但根据你的核心规则，这些多模态数据是作为智能体感知和处理的**环境输入**，而不是研究的核心。研究的核心是**如何通过多智能体架构来处理这些信息**，而不是多模态技术本身。因此，这不触发排除规则。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 论文的核心是关于多智能体如何通过协作进行复杂的临床推理，并显著提升了“推理逻辑”。这属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴，因此应该保留。 **最终决策**: 这篇论文的核心贡献在于**设计并验证了一个新颖的多智能体协作框架**，以解决现有LLM在复杂任务中的局限性。它直接贡献于“多智能体”这一研究方向，探讨了智能体间的协作模式。尽管它应用在特定的医疗领域，但其方法论贡献是普适的，完全符合你“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标。因此，最终判断为 **True**。"
    },
    {
        "index": "#2",
        "title": "MARINE: Theoretical Optimization and Design for Multi-Agent Recursive IN-context Enhancement",
        "link": "/arxiv/2512.07898",
        "arxiv_id": "2512.07898",
        "authors": "Hongwei Zhang, Ji Lu, Yongsheng Du, Yanqin Gao, Lingjun Huang, Baoli Wang, Fang Tan, Peng Zou",
        "summary": "Large Language Model (LLM)-based agents demonstrate advanced reasoning capabilities, yet practical constraints frequently limit outputs to single responses, leaving significant performance potential unrealized. This paper introduces MARINE (Multi-Agent Recursive IN-context Enhancement), a theoretically grounded framework that reconceptualizes test-time reasoning as iterative refinement of a persistent reference trajectory, fundamentally departing from conventional one-shot or multi-sample paradigms. The MARINE refinement operator systematically converts a base model's pass@N capabilities into near-optimal pass@1 performance. Rigorous theoretical analysis establishes that minimal feasible batches maximize expected performance gains under fixed invocation budgets, while logarithmically growing batch schedules ensure continuous improvement without computational constraints. Comprehensive evaluation on the BrowserComp-ZH benchmark demonstrates state-of-the-art results, with a 685B-parameter implementation achieving 46.0% pass@1 accuracy. Meanwhile, MARINE establishes a new paradigm for parameter-efficient reasoning: an 80B-parameter model augmented with MARINE matches the performance of standalone 1000B-parameter agents, reducing parameter requirements by over an order of magnitude. Notably, within a fixed computational budget, the proposed MARINE delivers higher-quality samples to alignment and optimization processes than traditional sampling-and-ranking strategies. Consequently, it has great potential to boost post-training efficiency.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-12-05",
        "category": "cs.MA",
        "crawl_time": "2025-12-10T11:00:04.447973",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献与你的研究目标高度契合。以下是详细的判断过程： 1.  **第一步：核心判断** - **保留**。这篇论文的本质是提出一个名为MARINE的新**框架**。它的核心贡献不是将现有智能体应用到某个领域，而是**构建和改进**LLM智能体的推理过程本身。论文明确指出，它“reconceptualizes test-time reasoning as iterative refinement”（将测试时推理重新概念化为迭代式改进），这是一种方法论上的创新，直接作用于智能体的核心能力，因此符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文命中了多个核心正面指标： - **核心范式**: `Multi-Agent Systems (MAS)` 在标题和摘要中明确提及。 - **演化机制**: `Iterative Improvement` 是该框架的核心机制。论文提出的“iterative refinement of a persistent reference trajectory”（对持久参考轨迹的迭代式改进）和“refinement operator”（改进算子）本质上是一种在测试时进行自我完善和迭代的机制，这与“自我演化”的方向紧密相关。 - **智能体能力**: `Reasoning` 是论文的核心，它提出了一种新的推理范式，超越了传统的one-shot或multi-sample方法。 3.  **第三步：排除标准** - 论文没有触发任何排除标准。虽然摘要末尾提到了“alignment and optimization processes”，但这只是该框架产生高质量样本的一个**应用场景**，并非论文的主要研究贡献。论文的核心是MARINE框架本身，而不是对齐理论或方法。因此，这不属于“安全与对齐”的排除范畴。论文也未涉及多模态或视觉内容。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文完美地符合“保留”条件。它不是在提升LLM的基础数学或逻辑能力，而是在构建一个**新的Agentic推理框架**（类似于ReAct, ToT），通过迭代和递归的方式来增强智能体在复杂任务中的表现。这正是你关注的“智能体如何进行规划或在复杂任务中进行多步推理”的范畴。 **综合结论**: 这篇论文的核心贡献是提出了一种名为MARINE的多智能体框架，其核心机制是通过迭代式改进来增强LLM智能体的推理能力。这直接对应了你研究范围中的**“多智能体”**和**“自我演化”**两个关键方向。它构建了一个新框架来改进智能体，而不是简单地应用智能体，因此完全符合你的筛选要求。"
    },
    {
        "index": "#4",
        "title": "An Agentic AI System for Multi-Framework Communication Coding",
        "link": "/arxiv/2512.08659",
        "arxiv_id": "2512.08659",
        "authors": "Bohao Yang, Rui Yang, Joshua M. Biro, Haoyuan Wang, Jessica L. Handley, Brianna Richardson, Sophia Bessias, Nicoleta Economou-Zavlanos, Armando D. Bedoya, Monica Agrawal, Michael M. Zavlanos, Anand Chowdhury, Raj M. Ratwani, Kai Sun, Kathryn I. Pollak, Michael J. Pencina, Chuan Hong",
        "summary": "Clinical communication is central to patient outcomes, yet large-scale human annotation of patient-provider conversation remains labor-intensive, inconsistent, and difficult to scale. Existing approaches based on large language models typically rely on single-task models that lack adaptability, interpretability, and reliability, especially when applied across various communication frameworks and clinical domains. In this study, we developed a Multi-framework Structured Agentic AI system for Clinical Communication (MOSAIC), built on a LangGraph-based architecture that orchestrates four core agents, including a Plan Agent for codebook selection and workflow planning, an Update Agent for maintaining up-to-date retrieval databases, a set of Annotation Agents that applies codebook-guided retrieval-augmented generation (RAG) with dynamic few-shot prompting, and a Verification Agent that provides consistency checks and feedback. To evaluate performance, we compared MOSAIC outputs against gold-standard annotations created by trained human coders. We developed and evaluated MOSAIC using 26 gold standard annotated transcripts for training and 50 transcripts for testing, spanning rheumatology and OB/GYN domains. On the test set, MOSAIC achieved an overall F1 score of 0.928. Performance was highest in the Rheumatology subset (F1 = 0.962) and strongest for Patient Behavior (e.g., patients asking questions, expressing preferences, or showing assertiveness). Ablations revealed that MOSAIC outperforms baseline benchmarking.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-12-09",
        "category": "cs.CL",
        "crawl_time": "2025-12-10T11:00:04.526495",
        "filter_reason": "这篇论文符合研究范围，应予以保留。 **判断过程如下:** 1.  **第一步：核心判断** - **论文本质**: 这篇论文的核心贡献是**构建了一个新颖的多智能体系统（MOSAIC）**，用于解决临床沟通编码这一复杂任务。它详细描述了基于LangGraph的架构，并设计了四个具有不同职责的智能体（Plan Agent, Update Agent, Annotation Agents, Verification Agent）进行协同工作。 - **结论**: 这完全符合“构建LLM智能体”和“多智能体系统”的定义。它不是简单地将现有框架作为工具应用，而是**提出了一个新的方法论和框架**。因此，根据第一步的筛选标准，应**保留**。 2.  **第二步：正面指标** - 论文包含了大量核心关注点： - **核心范式**: `Agentic AI` (标题中明确提及), `LLM-based Agents` (由LangGraph和RAG推断), `Multi-Agent Systems (MAS)` (摘要明确说明orchestrates four core agents)。 - **智能体能力**: `Planning` (Plan Agent负责workflow planning), `Tool Use / Tool Augmentation` (Annotation Agents使用RAG), `Memory` (Update Agent维护检索数据库), `Self-Correction` (Verification Agent提供consistency checks and feedback)。 - **多智能体**: `Collaboration` (四个Agent协同工作), `Communication` (Agent之间通过工作流进行信息传递和协调)。 - **结论**: 论文与我的研究焦点高度相关，正面指标非常充分。 3.  **第三步：排除标准** - 论文的主要贡献是关于智能体系统的架构和性能，而非安全、对齐或可解释性。虽然`Verification Agent`涉及一致性检查，但其目的是提升系统性能，而非以安全或对齐为主要研究目标。 - 论文不涉及多模态或视觉内容。 - **结论**: 未触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文中的`Plan Agent`明确负责工作流规划，整个系统是一个复杂的多步推理过程。这符合“保留”关于智能体如何进行规划的论文的标准。 - **自我演化的应用**: 虽然这篇论文不直接涉及“自我演化”（即智能体通过经验改变自身结构或策略），但它属于“提出一种新的智能体机制”的范畴。即使它应用在临床这一特定领域，根据筛选规则的核心精神（关注方法论而非应用领域），也应该保留。其核心价值在于MOSAIC这个多智能体协作框架本身。 **最终决策:** 综合以上分析，这篇论文的核心贡献在于**设计和实现了一个结构化的多智能体协作框架（MOSAIC）**，该框架集成了规划、记忆、工具使用和自我修正等关键Agentic能力。它直接回应了研究课题中的“单智能体”和“多智能体”方向，提供了关于如何构建和编排LLM智能体以解决复杂任务的深刻见解。因此，它完全符合筛选要求。"
    },
    {
        "index": "#11",
        "title": "Accelerating Urban Science Research with AI Urban Scientist",
        "link": "/arxiv/2512.07849",
        "arxiv_id": "2512.07849",
        "authors": "Tong Xia, Jiankun Zhang, Ruiwen You, Ao Xu, Linghao Zhang, Tengyao Tu, Jingzhi Wang, Jinghua Piao, Yunke Zhang, Fengli Xu, Yong Li",
        "summary": "Cities are complex, adaptive systems whose underlying principles remain difficult to disentangle despite unprecedented data abundance. Urban science therefore faces a fundamental challenge: converting vast, fragmented and interdisciplinary information into coherent explanations of how cities function and evolve. The emergence of AI scientists, i.e., agents capable of autonomous reasoning, hypothesis formation and data-driven experimentation, offers a new pathway toward accelerating this transformation, yet general-purpose systems fall short of the domain knowledge and methodological depth required for urban science research. Here we introduce a knowledge-driven AI Urban Scientist, built from hypotheses, peer-review signals, datasets and analytical patterns distilled from thousands of high-quality studies, and implemented as a coordinated multi-agent framework for end-to-end inquiry. The system generates structured hypotheses, retrieves and harmonizes heterogeneous datasets, conducts automated empirical analysis and simulation, and synthesizes insights in forms compatible with urban scientific reasoning. By providing reusable analytical tools and supporting community-driven extensions, the AI Urban Scientist lowers barriers to advanced urban analytics and acts not merely as an assistant but as an active collaborator in revealing the mechanisms that shape urban systems and in guiding the design of more resilient and equitable cities.",
        "subjects": "Computers and Society, Computation and Language, Multiagent Systems",
        "date": "2025-11-26",
        "category": "cs.MA",
        "crawl_time": "2025-12-10T11:00:04.450553",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断依据如下： 1.  **核心判断 (第一步):** 论文的核心贡献并非简单地将一个已有的LLM智能体框架应用于城市科学领域，而是**提出并实现了一个全新的、专门化的“协调的多智能体框架”**来构建“AI Urban Scientist”。摘要中明确指出，该系统是“implemented as a coordinated multi-agent framework for end-to-end inquiry”。这表明论文的重点在于**构建和设计智能体系统本身**，属于“构建LLM智能体”和“多智能体系统”的范畴，因此不属于“非演化型应用”的排除范围。 2.  **正面指标 (第二步):** 论文包含了多个我关注的核心关键词和概念： *   **多智能体:** 明确提出了“coordinated multi-agent framework”，这直接命中了我的第二个研究方向。 *   **智能体能力:** 描述了智能体具备“autonomous reasoning”（自主推理）、“hypothesis formation”（假设形成）、“retrieves and harmonizes heterogeneous datasets”（数据检索与调和）、“conducts automated empirical analysis and simulation”（自动实证分析与仿真）等能力。这些分别对应了智能体的规划、工具使用和自主执行任务的能力。 *   **核心范式:** 整个系统是一个典型的“LLM-based Agents”和“Agentic AI”的实现。 3.  **排除标准 (第三步):** 论文的研究焦点不在于安全、对齐、可解释性，也不涉及多模态或视觉模型作为核心研究内容。因此，它没有触犯任何排除标准。 4.  **特殊和模糊情况 (第四步):** 这篇论文是“推理/规划”规则的绝佳例证。它不是在提升LLM本身的基础数学或逻辑能力，而是在构建一个**智能体框架**，使其能够进行复杂的、端到端的科学推理流程（从假设到分析再到综合）。这正是我想要保留的关于智能体如何进行规划和多步推理的研究。 **结论:** 尽管论文的应用领域是城市科学，但其核心贡献在于**提出了一种新颖的多智能体协作框架，以实现复杂的、自主的科学探究任务**。这完全符合我“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的核心目标，特别是在“多智能体”和“单智能体（规划、工具使用）”方向上。因此，这篇论文应该被保留。"
    },
    {
        "index": "#40",
        "title": "Training LLMs for Honesty via Confessions",
        "link": "/arxiv/2512.08093",
        "arxiv_id": "2512.08093",
        "authors": "Manas Joglekar, Jeremy Chen, Gabriel Wu, Jason Yosinski, Jasmine Wang, Boaz Barak, Amelia Glaese",
        "summary": "Large language models (LLMs) can be dishonest when reporting on their actions and beliefs -- for example, they may overstate their confidence in factual claims or cover up evidence of covert actions. Such dishonesty may arise due to the effects of reinforcement learning (RL), where challenges with reward shaping can result in a training process that inadvertently incentivizes the model to lie or misrepresent its actions. In this work we propose a method for eliciting an honest expression of an LLM's shortcomings via a self-reported *confession*. A confession is an output, provided upon request after a model's original answer, that is meant to serve as a full account of the model's compliance with the letter and spirit of its policies and instructions. The reward assigned to a confession during training is solely based on its honesty, and does not impact positively or negatively the main answer's reward. As long as the \"path of least resistance\" for maximizing confession reward is to surface misbehavior rather than covering it up, this incentivizes models to be honest in their confessions. Our findings provide some justification this empirical assumption, especially in the case of egregious model misbehavior. To demonstrate the viability of our approach, we train GPT-5-Thinking to produce confessions, and we evaluate its honesty in out-of-distribution scenarios measuring hallucination, instruction following, scheming, and reward hacking. We find that when the model lies or omits shortcomings in its \"main\" answer, it often confesses to these behaviors honestly, and this confession honesty modestly improves with training. Confessions can enable a number of inference-time interventions including monitoring, rejection sampling, and surfacing issues to the user.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-12-08",
        "category": "cs.LG",
        "crawl_time": "2025-12-10T11:00:04.791551",
        "filter_reason": "这篇论文符合您的研究范围，应予以保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的核心贡献并非简单地将LLM应用于某个领域，而是提出了一种全新的训练**方法论**（\"confessions\"机制），旨在让LLM能够诚实地报告自身的错误和不当行为。这种机制本质上是一种结构化的**自我反思**和**自我评估**过程。它不是在解决一个外部问题，而是在改进LLM智能体自身的内在能力和行为模式，这直接关联到“自我演化”的核心目标。 **第二步：正面指标** - 论文内容与多个核心关注点高度匹配： - **自我演化**: 论文的核心是提出一种让模型通过训练进行**自我完善**的机制。 - **智能体能力**: 论文的核心机制“忏悔”是一种高级的**自我反思**形式，是通往**自我修正**的关键一步。 - **演化机制**: 论文明确指出，模型的“忏悔诚实性”会随着训练而**适度提高**，这体现了**迭代改进**的演化思想。 **第三步：排除标准** - **安全与对齐**: 这是最需要仔细辨析的一点。虽然论文的研究动机和评估指标（诚实性、阴谋、幻觉）与`Safety`和`Alignment`紧密相关，但其**主要贡献**并非提出一种新的对齐理论或评估标准，而是构建了一个**可操作的、用于实现自我反思的智能体框架**。这篇论文可以被看作是“如何构建一个能够进行自我反思的智能体”，并以“诚实”作为该能力的具体体现和验证场景。根据您的筛选规则，只要论文的核心是关于构建或改进智能体的方法论，即使其应用场景或评估指标与安全对齐相关，也应保留。这篇论文的贡献在于“如何做”（How），而不是“做什么”（What）或“为什么”（Why）。 **第四步：处理特殊和模糊情况** - **自我演化的应用**: 这篇论文是“自我演化”方向的一个典型范例。它提出了一种新的“自我演化”机制（通过忏悔来暴露并承认错误），并展示了该机制如何通过训练得到强化。即使它的评估场景是“安全对齐”，但其核心贡献是演化机制本身，因此完全符合保留条件。 **第五步：最终决策** 综合以上分析，尽管论文的表面主题是“诚实”，但其本质贡献是提出了一种新颖的、可训练的**自我反思与自我完善机制**。这直接服务于构建和演化更高级的LLM智能体的核心目标。因此，这篇论文与您的研究课题“LLM智能体及其演化”高度相关，特别是其中的“自我演化”和“自我反思”子方向。应判定为 **True**。"
    },
    {
        "index": "#73",
        "title": "SABER: Small Actions, Big Errors - Safeguarding Mutating Steps in LLM Agents",
        "link": "/arxiv/2512.07850",
        "arxiv_id": "2512.07850",
        "authors": "Alejandro Cuadron, Pengfei Yu, Yang Liu, Arpit Gupta",
        "summary": "Despite rapid progress in LLM agents, performance on long-horizon, tool-using tasks remains fragile. To better understand this fragility, we ask a simple question: \\emph{do all actions contribute equally to failure?} Analyzing execution traces on $τ$-Bench (Airline/Retail) and SWE-Bench Verified, we decompose trajectories into \\emph{mutating} (environment-changing) vs.\\ non-mutating steps and formalize \\emph{decisive deviations}, earliest action, level divergences that flip success to failure. A logistic regression reveals that each additional deviation in a mutating action reduces the odds of success by upto $92\\%$ on Airline and upto $96\\%$ on Retail for SoTA models. In contrast, deviations in non-mutating actions have little to no effect. Errors also grow with context length as agents drift from role and act on stale constraints. Motivated by these observations, we introduce \\cm{}, a model-agnostic, gradient-free, test-time safeguard that (i) adds mutation-gated verification, (ii) injects \\emph{Targeted Reflection} before mutating steps, and (iii) performs block-based context cleaning. \\cm{} delivers consistent gains, e.g., Qwen3-Thinking: +28\\% \\emph{relative} on Airline, +11\\% on Retail, and +7\\% on SWE-Bench Verified; Claude: +9\\%/+7\\%. We further identify ceiling effects in $τ$-Bench, where annotation errors and underspecified tasks artificially cap model performance. To address this, we release $τ$-Bench Verified, which restores benchmark headroom through targeted revisions. Our results argue for action-level analysis, targeted safeguards, and reliable evaluations as prerequisites for robust multi-turn agents.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-11-26",
        "category": "cs.LG",
        "crawl_time": "2025-12-10T11:00:04.800480",
        "filter_reason": "这篇论文完全符合你的研究范围，核心贡献在于对LLM智能体的改进。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是将LLM智能体作为工具去解决一个外部领域问题，而是直接针对LLM智能体本身在执行任务时的“脆弱性”进行分析和改进。它提出了一个名为SABER的新框架，这是一个用于增强智能体鲁棒性的方法论，完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **智能体能力**: 论文明确聚焦于`Tool Use`（工具使用）任务，并提出了`Targeted Reflection`（定向反思）机制，这直接命中了“自我反思”这一关键能力。 - **核心范式**: 整篇论文围绕`LLM-based Agents`展开，旨在提升其在`long-horizon`（长时程）任务中的表现。 - **演化机制**: SABER框架通过在测试时进行验证、反思和上下文清理，实现了对智能体行为的迭代优化和错误修正，这与`Self-Correction`（自我修正）和`Iterative Improvement`（迭代改进）的理念高度一致。 3.  **第三步：排除标准** - **安全与对齐**: 论文标题中的“Safeguarding”可能引起误解，但摘要内容明确指出，这里的“保障”是指防止智能体在执行任务时因关键步骤出错而导致任务失败，是关于**性能鲁棒性**，而非传统意义上的AI安全、伦理对齐或防止恶意使用。因此，它不属于排除范围。 - **多模态与视觉**: 论文未涉及多模态内容，不适用此排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 论文的研究对象是“long-horizon, tool-using tasks”，这本质上是一个多步规划和推理过程。SABER通过识别和加固“mutating steps”（改变环境的关键步骤）来提升整个规划执行的成功率，这完全属于“关于智能体如何进行规划或在复杂任务中进行多步推理”的保留范畴。 **最终决策**: 这篇论文的核心贡献是**提出了一种名为SABER的新框架，用于提升LLM智能体在长时程、工具使用任务中的鲁棒性**。该框架通过引入“mutation-gated verification”、“Targeted Reflection”和“block-based context cleaning”三种机制，直接增强了智能体的**工具使用**、**自我反思**和**记忆/上下文管理**能力。这完全符合你研究目标中的“单智能体”方向，特别是关于智能体能力改进的子方向。因此，这篇论文应被**保留**。"
    },
    {
        "index": "#102",
        "title": "Empowering smart app development with SolidGPT: an edge-cloud hybrid AI agent framework",
        "link": "/arxiv/2512.08286",
        "arxiv_id": "2512.08286",
        "authors": "Liao Hu, Qiteng Wu, Ruoyu Qi",
        "summary": "The integration of Large Language Models (LLMs) into mobile and software development workflows faces a persistent tension among three demands: semantic awareness, developer productivity, and data privacy. Traditional cloud-based tools offer strong reasoning but risk data exposure and latency, while on-device solutions lack full-context understanding across codebase and developer tooling. We introduce SolidGPT, an open-source, edge-cloud hybrid developer assistant built on GitHub, designed to enhance code and workspace semantic search. SolidGPT enables developers to: talk to your codebase: interactively query code and project structure, discovering the right methods and modules without manual searching. Automate software project workflows: generate PRDs, task breakdowns, Kanban boards, and even scaffold web app beginnings, with deep integration via VSCode and Notion. Configure private, extensible agents: onboard private code folders (up to approximately 500 files), connect Notion, customize AI agent personas via embedding and in-context training, and deploy via Docker, CLI, or VSCode extension. In practice, SolidGPT empowers developer productivity through: Semantic-rich code navigation: no more hunting through files or wondering where a feature lives. Integrated documentation and task management: seamlessly sync generated PRD content and task boards into developer workflows. Privacy-first design: running locally via Docker or VSCode, with full control over code and data, while optionally reaching out to LLM APIs as needed. By combining interactive code querying, automated project scaffolding, and human-AI collaboration, SolidGPT provides a practical, privacy-respecting edge assistant that accelerates real-world development workflows, ideal for intelligent mobile and software engineering contexts.",
        "subjects": "Software Engineering, Artificial Intelligence, Machine Learning",
        "date": "2025-12-09",
        "category": "cs.LG",
        "crawl_time": "2025-12-10T11:00:04.808564",
        "filter_reason": "这篇论文符合我的研究范围，应该被保留。我的判断过程如下： **第一步：核心判断** - **保留**。这篇论文的核心贡献是提出了一个名为 \"SolidGPT\" 的 \"edge-cloud hybrid AI agent framework\"。它的本质不是简单地将LLM应用于软件开发，而是**构建了一个新的、可配置的AI智能体框架**。该框架的设计旨在解决特定领域（软件开发）中的问题，但其核心贡献在于框架本身，包括其架构（边缘-云端混合）、能力（语义搜索、工作流自动化）和可扩展性（配置私有智能体）。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。 - 它不属于“非演化型应用”，因为论文的重点是**如何构建和配置这个智能体框架**，而不是仅仅展示这个框架在某个任务上的最终效果。它描述了智能体的能力构成和实现方式，这是对Agentic AI构建方法的贡献。 **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提出了 `AI agent framework`。 - **智能体能力**: 展现了典型的智能体能力，如 `Tool Use`（与代码库交互、连接Notion、生成PRD和看板）、`Memory`（通过语义搜索和嵌入技术实现对整个代码库和工作空间的上下文感知）。 - **人机协作**: 提到了 \"human-AI collaboration\"，这也是智能体研究的一个重要方面。 **第三步：排除标准** - 论文不涉及安全与对齐、多模态与视觉等排除领域。其焦点是智能体的构建和应用，符合要求。 **第四步：处理特殊和模糊情况** - **推理/规划**: 论文描述的智能体行为，如“talk to your codebase”和“Automate software project workflows”，属于智能体在复杂任务中进行多步推理和工具使用的范畴，符合保留条件。它不是在研究LLM底层的数学或逻辑推理能力。 **第五步：最终决策** 综合以上分析，尽管这篇论文的应用场景是软件开发，但其**核心贡献是提出了一种新的LLM智能体构建框架**。它详细阐述了该框架如何赋予智能体工具使用、记忆和上下文感知等关键能力，以解决实际问题。这直接命中了我研究目标中“构建、改进LLM智能体”的核心。因此，这篇论文与我的研究课题高度相关，应该被保留。"
    },
    {
        "index": "#6",
        "title": "See-Control: A Multimodal Agent Framework for Smartphone Interaction with a Robotic Arm",
        "link": "/arxiv/2512.08629",
        "arxiv_id": "2512.08629",
        "authors": "Haoyu Zhao, Weizhong Ding, Yuhao Yang, Zheng Tian, Linyi Yang, Kun Shao, Jun Wang",
        "summary": "Recent advances in Multimodal Large Language Models (MLLMs) have enabled their use as intelligent agents for smartphone operation. However, existing methods depend on the Android Debug Bridge (ADB) for data transmission and action execution, limiting their applicability to Android devices. In this work, we introduce the novel Embodied Smartphone Operation (ESO) task and present See-Control, a framework that enables smartphone operation via direct physical interaction with a low-DoF robotic arm, offering a platform-agnostic solution. See-Control comprises three key components: (1) an ESO benchmark with 155 tasks and corresponding evaluation metrics; (2) an MLLM-based embodied agent that generates robotic control commands without requiring ADB or system back-end access; and (3) a richly annotated dataset of operation episodes, offering valuable resources for future research. By bridging the gap between digital agents and the physical world, See-Control provides a concrete step toward enabling home robots to perform smartphone-dependent tasks in realistic environments.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition, Human-Computer Interaction",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.338576",
        "filter_reason": "这篇论文符合您的研究范围，核心判断依据如下： 1.  **第一步：核心判断——论文的本质是构建LLM智能体。** 论文的核心贡献是提出了一个名为 `See-Control` 的**新框架**。这个框架是一个基于多模态大语言模型（MLLM）的**具身智能体**，它能够生成控制指令，驱动机器人手臂与物理世界中的智能手机进行交互。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是简单地将一个已有的智能体框架应用到某个领域，而是**创造了一个新的智能体实现方式**（通过物理手臂而非ADB接口），因此不属于“非演化型应用”的排除范畴。 2.  **第二步：正面指标——论文包含核心关注点。** 论文明确涉及了多个核心关注点： *   **核心范式**: 论文的核心是 `Agentic AI` 和 `LLM-based Agents`。 *   **智能体能力**: 智能体需要通过视觉感知手机屏幕状态，然后**规划**出一系列机器人手臂的动作来完成指定任务。这直接对应了 `Planning`。同时，机器人手臂本身就是智能体与物理世界交互的**工具**，这对应了 `Tool Use / Tool Augmentation`。 3.  **第三步：排除标准——未触及排除红线。** *   **安全与对齐**: 论文的主要贡献不涉及安全、对齐或可解释性。 *   **多模态与视觉**: 虽然论文标题和摘要提到了 `Multimodal` 和 `See`（暗示视觉），但根据筛选规则的特殊说明：“除非它们被用作智能体感知环境的工具，而不是研究的核心”。在这篇论文中，视觉能力是智能体感知手机屏幕、进行决策的**必要组成部分**，是服务于整个智能体框架的，而不是论文研究的核心（核心是智能体框架本身）。因此，这不构成排除理由。 4.  **第四步：处理特殊和模糊情况。** *   **推理/规划**: 论文中的智能体需要规划机器人手臂的物理动作序列以完成任务，这属于“智能体如何进行规划或在复杂任务中进行多步推理”的范畴，因此应该保留。 **最终决策**: 综合以上分析，该论文的核心贡献在于提出了一种新颖的具身智能体框架 `See-Control`，它扩展了LLM智能体与物理世界交互的能力边界。其研究内容聚焦于智能体的构建、规划和工具使用，完全符合您关于“LLM智能体及其演化”的研究目标，特别是“单智能体”方向。因此，应判定为 **True**。"
    },
    {
        "index": "#12",
        "title": "Autonomous Issue Resolver: Towards Zero-Touch Code Maintenance",
        "link": "/arxiv/2512.08492",
        "arxiv_id": "2512.08492",
        "authors": "Aliaksei Kaliutau",
        "summary": "Recent advances in Large Language Models have revolutionized function-level code generation; however, repository-scale Automated Program Repair (APR) remains a significant challenge. Current approaches typically employ a control-centric paradigm, forcing agents to navigate complex directory structures and irrelevant control logic. In this paper, we propose a paradigm shift from the standard Code Property Graphs (CPGs) to the concept of Data Transformation Graph (DTG) that inverts the topology by modeling data states as nodes and functions as edges, enabling agents to trace logic defects through data lineage rather than control flow. We introduce a multi-agent framework that reconciles data integrity navigation with control flow logic. Our theoretical analysis and case studies demonstrate that this approach resolves the \"Semantic Trap\" inherent in standard RAG systems in modern coding agents. We provide a comprehensive implementation in the form of Autonomous Issue Resolver (AIR), a self-improvement system for zero-touch code maintenance that utilizes neuro-symbolic reasoning and uses the DTG structure for scalable logic repair. Our approach has demonstrated good results on several SWE benchmarks, reaching a resolution rate of 87.1% on SWE-Verified benchmark. Our approach directly addresses the core limitations of current AI code-assistant tools and tackles the critical need for a more robust foundation for our increasingly software-dependent world.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.340090",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献直接对应了您关注的“多智能体”和“自我演化”两个方向。 **第一步：核心判断——保留** 这篇论文的本质不是简单地将LLM应用于代码修复领域，而是提出了一套全新的方法论和框架来**构建和改进LLM智能体**。其核心贡献包括： 1.  **新的智能体认知框架 (Data Transformation Graph - DTG)**：这不仅仅是应用，而是为智能体设计了一种全新的、更有效的理解和推理代码逻辑的方式，属于智能体基础能力的改进。 2.  **多智能体框架**：论文明确提出了一个多智能体系统来协同解决问题，这直接命中了您的研究焦点。 3.  **自我改进系统**：论文将AIR描述为一个“self-improvement system”，这完全符合“自我演化”的定义。 因此，该论文不属于“非演化型应用”的排除范畴，其核心是关于智能体本身的构建和演化。 **第二步：正面指标——高度匹配** 论文摘要中包含了大量您关注的核心关键词和概念： *   **核心范式**: `Multi-Agent Systems (MAS)` (明确提及), `Self-Evolving` (通过 \"self-improvement system\" 体现)。 *   **智能体能力**: `Planning` (通过DTG追踪逻辑缺陷是一种高级规划), `Tool Use` (将DTG和代码库作为工具)。 *   **多智能体**: `Collaboration` (多智能体框架隐含协作)。 *   **演化机制**: `Self-Improvement` (明确提及), `Iterative Improvement` (通过修复过程体现)。 这些正面指标进一步确认了论文与您研究目标的高度相关性。 **第三步：排除标准——未触发** 论文的主要贡献是关于提升智能体的能力和框架，而非安全、对齐或可解释性。同时，论文不涉及多模态或视觉内容。因此，没有触发任何排除标准。 **第四步：处理特殊和模糊情况——符合保留规则** 1.  **推理/规划**: 论文提出的DTG框架是典型的**Agentic推理**。它不是在提升LLM的基础数学或逻辑能力，而是在为智能体提供一个在复杂任务（代码库级修复）中进行多步规划和追踪的全新框架。这完全符合保留条件。 2.  **自我演化的应用**: 这是一个典型的“自我演化的应用”的**例外情况**。虽然论文的应用领域是代码维护，但其核心贡献是提出了一种**新的“自我演化”机制**和**新的“多智能体”协作框架**。按照您的规则，这种提出新机制的论文即使应用在特定领域，也应该保留。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献在于构建了一个新颖的多智能体框架和一个自我改进系统，并引入了DTG这一新概念来增强智能体的规划与推理能力。它直接推动了LLM智能体在“多智能体协作”和“自我演化”两个前沿方向的发展，是您研究课题“LLM智能体及其演化”的典型前沿论文。因此，应予以保留。"
    },
    {
        "index": "#17",
        "title": "Reflecting with Two Voices: A Co-Adaptive Dual-Strategy Framework for LLM-Based Agent Decision Making",
        "link": "/arxiv/2512.08366",
        "arxiv_id": "2512.08366",
        "authors": "Wentao Zhang, Qunbo Wang, Tao Zhang, Junsheng Wu, Hongping Gan, Yang Liu, Ling Dai, Shizhuang Deng, Shuntong Sun",
        "summary": "Large language model (LLM) agents often rely on external demonstrations or retrieval-augmented planning, leading to brittleness, poor generalization, and high computational overhead. Inspired by human problem-solving, we propose DuSAR (Dual-Strategy Agent with Reflecting) - a demonstration-free framework that enables a single frozen LLM to perform co-adaptive reasoning via two complementary strategies: a high-level holistic plan and a context-grounded local policy. These strategies interact through a lightweight reflection mechanism, where the agent continuously assesses progress via a Strategy Fitness Score and dynamically revises its global plan when stuck or refines it upon meaningful advancement, mimicking human metacognitive behavior. On ALFWorld and Mind2Web, DuSAR achieves state-of-the-art performance with open-source LLMs (7B-70B), reaching 37.1% success on ALFWorld (Llama3.1-70B) - more than doubling the best prior result (13.0%) - and 4.02% on Mind2Web, also more than doubling the strongest baseline. Remarkably, it reduces per-step token consumption by 3-9X while maintaining strong performance. Ablation studies confirm the necessity of dual-strategy coordination. Moreover, optional integration of expert demonstrations further boosts results, highlighting DuSAR's flexibility and compatibility with external knowledge.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.341469",
        "filter_reason": "这篇论文完全符合你的研究范围，核心判断依据如下： 1.  **第一步：核心判断——保留** 论文的核心贡献是提出一个名为 **DuSAR** 的**新框架**，旨在**构建和改进LLM智能体**。它不是将现有智能体应用到某个特定领域，而是专注于解决智能体本身存在的“脆弱性、泛化性差和计算开销高”的问题。这完全符合“构建、改进或演化LLM智能体”的核心目标。 2.  **第二步：正面指标——高度匹配** 论文包含了多个你的核心关注点： *   **核心范式**: 论文明确提出了一个 `LLM-based Agent` 框架。 *   **智能体能力**: *   `Planning`: 论文的核心是双策略，包括一个“high-level holistic plan”（高层整体规划）和动态修订计划的能力。 *   `Self-Reflection` / `Self-Correction`: 论文的标题和摘要都强调了“Reflecting”（反思）。它通过一个“lightweight reflection mechanism”（轻量级反思机制）和“Strategy Fitness Score”（策略适应度得分）来持续评估进度，并在卡住时进行自我修正，这直接命中了你的研究焦点。 *   `ReAct`: 虽然没有直接使用ReAct这个词，但其“规划-行动-反思-修正”的循环模式与ReAct等Agentic推理范式一脉相承，并且是一种新的改进。 3.  **第三步：排除标准——未触发** 论文的主要贡献是关于提升智能体的决策效率和性能，而非安全、对齐、可解释性或多模态。因此，它没有触犯任何排除标准。 4.  **第四步：处理特殊和模糊情况——符合保留规则** 论文的研究内容属于“推理/规划”的特殊情况。它不是在提升LLM本身的基础数学或逻辑能力，而是在构建一个**让智能体如何进行规划和多步推理的框架**。这种“co-adaptive reasoning”（协同自适应推理）和“metacognitive behavior”（元认知行为）的模仿，正是Agentic AI研究的核心。 **总结**: 该论文的核心是提出了一种创新的、基于反思的双策略框架（DuSAR）来增强LLM智能体的决策能力。它直接贡献于**单智能体**方向下的**规划**和**自我反思**子方向，并带有**自我修正**的演化特征。其方法论是新颖的，目标是改进智能体本身，而非应用。因此，这篇论文是你研究课题“LLM智能体及其演化”的典型前沿文献，应予以保留。"
    },
    {
        "index": "#8",
        "title": "CogMCTS: A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution with Large Language Models",
        "link": "/arxiv/2512.08609",
        "arxiv_id": "2512.08609",
        "authors": "Hui Wang, Yang Liu, Xiaoyu Zhang, Chaoxu Mu",
        "summary": "Automatic Heuristic Design (AHD) is an effective1 framework for solving complex optimization prob-2 lems. The development of large language mod-3 els (LLMs) enables the automated generation of4 heuristics. Existing LLM-based evolutionary meth-5 ods rely on population strategies and are prone6 to local optima. Integrating LLMs with Monte7 Carlo Tree Search (MCTS) improves the trade-off8 between exploration and exploitation, but multi-9 round cognitive integration remains limited and10 search diversity is constrained. To overcome these11 limitations, this paper proposes a novel cognitive-12 guided MCTS framework (CogMCTS). CogMCTS13 tightly integrates the cognitive guidance mecha-14 nism of LLMs with MCTS to achieve efficient au-15 tomated heuristic optimization. The framework16 employs multi-round cognitive feedback to incor-17 porate historical experience, node information, and18 negative outcomes, dynamically improving heuris-19 tic generation. Dual-track node expansion com-20 bined with elite heuristic management balances the21 exploration of diverse heuristics and the exploita-22 tion of high-quality experience. In addition, strate-23 gic mutation modifies the heuristic forms and pa-24 rameters to further enhance the diversity of the so-25 lution and the overall optimization performance.26 The experimental results indicate that CogMCTS27 outperforms existing LLM-based AHD methods in28 stability, efficiency, and solution quality.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.339068",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于提出了一种新颖的LLM智能体自我演化框架。我的判断依据如下： 1.  **第一步：核心判断 (保留)** 论文的核心不是简单地将LLM作为工具应用于某个领域，而是构建了一个名为CogMCTS的**新框架**。这个框架的目标是实现“Iterative Heuristic Evolution”（迭代启发式演化）。这直接命中了您研究目标中的“自我演化”方向。论文的本质是提出一种让LLM驱动的系统进行自我完善和迭代的方法论，而非解决某个特定领域的应用问题。 2.  **第二步：正面指标 (高度匹配)** 论文摘要中包含了大量您关注的核心关键词和概念： *   **自我演化**: 标题和摘要中明确提到了 `Iterative Heuristic Evolution`、`evolutionary methods` 和 `strategic mutation`，这直接对应了您的“自我演化”研究焦点。 *   **智能体能力**: 论文描述的LLM扮演了“认知引导”的角色，通过 `multi-round cognitive feedback`（多轮认知反馈）来整合 `historical experience`（历史经验）和 `negative outcomes`（负面结果），这本质上是智能体的 `Self-Reflection`（自我反思）和 `Self-Improvement`（自我完善）能力。 *   **规划**: 框架的核心是 `Monte Carlo Tree Search (MCTS)`，这是一种经典的规划和搜索算法。论文将其与LLM结合，用于指导启发式方法的生成过程，这属于智能体在复杂任务中进行规划和多步推理的范畴。 3.  **第三步：排除标准 (不适用)** 论文的主要贡献是关于优化框架的性能（稳定性、效率、解的质量），并未涉及安全、对齐、可解释性或多模态等内容。因此，不触及任何排除标准。 4.  **第四步：处理特殊和模糊情况 (符合保留规则)** *   **推理/规划**: 论文中的MCTS是作为其自我演化框架的一个**组成部分**，用于平衡探索与利用，从而更好地演化启发式方法。它不是在研究如何提升LLM本身的基础推理能力，而是在构建一个使用规划算法的智能体框架，因此符合保留条件。 *   **自我演化的应用**: 尽管论文的应用场景是“Automatic Heuristic Design (AHD)”，但根据您的筛选规则，如果论文的核心是提出一种**新的“自我演化”机制**，即使应用在特定领域也应保留。CogMCTS正是这样一个新机制，它提出了一种结合LLM认知反馈和MCTS的演化范式，因此完全符合保留的例外情况。 **结论**: 该论文的核心贡献是构建了一个能够通过历史经验和反思进行迭代优化的LLM驱动框架（CogMCTS）。它深入探讨了智能体的自我演化、自我反思和规划能力，与您的研究课题“LLM智能体及其演化”中的“自我演化”方向高度契合。因此，这篇论文应该被**保留**。"
    },
    {
        "index": "#23",
        "title": "Towards a Science of Scaling Agent Systems",
        "link": "/arxiv/2512.08296",
        "arxiv_id": "2512.08296",
        "authors": "Yubin Kim, Ken Gu, Chanwoo Park, Chunjong Park, Samuel Schmidgall, A. Ali Heydari, Yao Yan, Zhihan Zhang, Yuchen Zhuang, Mark Malhotra, Paul Pu Liang, Hae Won Park, Yuzhe Yang, Xuhai Xu, Yilun Du, Shwetak Patel, Tim Althoff, Daniel McDuff, Xin Liu",
        "summary": "Agents, language model (LM)-based systems that are capable of reasoning, planning, and acting are becoming the dominant paradigm for real-world AI applications. Despite this widespread adoption, the principles that determine their performance remain underexplored, leaving practitioners to rely on heuristics rather than principled design choices. We address this gap by deriving quantitative scaling principles for agent systems. We evaluate this across four diverse benchmarks: Finance-Agent, BrowseComp-Plus, PlanCraft, and Workbench. Using five canonical architectures (Single, Independent, Centralized, Decentralized, Hybrid) instantiated across three LLM families, we perform a controlled evaluation spanning 180 configurations with standardized tools and token budgets. We derive a predictive model using empirical coordination metrics, including efficiency, overhead, error amplification, and redundancy, that achieves cross-validated R^2=0.513. We identify three dominant effects: (1) a tool-coordination trade-off: under fixed computational budgets, tool-heavy tasks suffer disproportionately from multi-agent overhead. (2) a capability saturation: coordination yields diminishing or negative returns (beta=-0.408, p<0.001) once single-agent baselines exceed ~45%. (3) topology-dependent error amplification: independent agents amplify errors 17.2x through unchecked propagation, while centralized coordination contains this to 4.4x. Centralized coordination improves performance by 80.9% on parallelizable tasks like financial reasoning, while decentralized coordination excels on dynamic web navigation (+9.2% vs. +0.2%). Yet for sequential reasoning tasks, all multi-agent variants degraded performance by 39-70%. The framework predicts the optimal coordination strategy for 87% of held-out configurations, providing a predictive principle of agentic scaling based on measurable task properties.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.343148",
        "filter_reason": "这篇论文完全符合你的研究范围，其核心贡献在于为LLM智能体系统的构建和改进提供了科学依据和可预测的原则。我的判断过程如下： 1.  **第一步：核心判断——保留** - 论文的核心不是将智能体作为工具去解决某个特定领域（如金融、网页浏览）的问题，而是**以这些领域为实验场，旨在探索和建立一套关于“如何扩展和设计智能体系统”的通用科学原则**。 - 摘要中明确指出，其目标是解决“principled design choices”（原则性设计选择）的缺失，并“deriving quantitative scaling principles for agent systems”（为智能体系统推导定量的缩放原则）。这直接命中了你“构建、改进或演化LLM智能体”的核心目标。它不是一篇应用论文，而是一篇关于智能体系统“元科学”的论文。 2.  **第二步：正面指标——高度匹配** - **核心范式**: 论文标题和摘要反复提及 `Agent Systems`，并研究了 `Single`, `Independent`, `Centralized`, `Decentralized`, `Hybrid` 等多种架构，这完全属于 `Agentic AI` 和 `Multi-Agent Systems (MAS)` 的范畴。 - **智能体能力**: 论文研究了智能体的 `reasoning, planning, and acting` 能力，并特别分析了 `Tool Use` 与多智能体开销之间的权衡。 - **多智能体**: 论文的核心就是多智能体研究，深入探讨了 `Coordination`（协调）、不同拓扑结构（`Centralized`, `Decentralized`）对性能的影响，以及错误在智能体间的传播（`error amplification`）。 3.  **第三步：排除标准——未触发** - 论文的主要贡献不涉及安全、对齐、可解释性或多模态。它专注于智能体系统的性能和架构设计，因此完全避开了这些排除项。 4.  **第四步：处理特殊和模糊情况——符合保留条件** - **推理/规划**: 这篇论文是典型的“保留”案例。它研究的不是LLM内部的数学推理能力，而是**智能体系统层面的规划和协调**。它比较了不同智能体架构在复杂任务（如`PlanCraft`）上的表现，这正是Agentic AI研究的核心。 5.  **第五步：最终决策** - 综合来看，这篇论文是一篇高质量的前沿研究。它没有提出一个具体的、新的智能体框架，而是**上升到了一个更高的维度，试图为整个LLM智能体领域建立一门“缩放科学”**。它通过大规模的实证实验，揭示了单智能体与多智能体、不同多智能体拓扑结构之间的性能权衡和适用场景。这种对智能体系统设计原则的深刻洞察，直接服务于“改进LLM智能体”这一核心目标，尤其与你的“多智能体”研究方向高度契合。因此，这篇论文必须保留。"
    },
    {
        "index": "#22",
        "title": "rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection",
        "link": "/arxiv/2512.08300",
        "arxiv_id": "2512.08300",
        "authors": "Sijia Chen, Baochun Li, Di Niu",
        "summary": "Large language models (LLMs) are post-trained through reinforcement learning (RL) to evolve into Reasoning Language Models (RLMs), where the hallmark of this advanced reasoning is ``aha'' moments when they start to perform strategies, such as self-reflection and deep thinking, within chain of thoughts (CoTs). Motivated by this, this paper proposes a novel reinforced strategy injection mechanism (rSIM), that enables any LLM to become an RLM by employing a small planner to guide the LLM's CoT through the adaptive injection of reasoning strategies. To achieve this, the planner (leader agent) is jointly trained with an LLM (follower agent) using multi-agent RL (MARL), based on a leader-follower framework and straightforward rule-based rewards. Experimental results show that rSIM enables Qwen2.5-0.5B to become an RLM and significantly outperform Qwen2.5-14B. Moreover, the planner is generalizable: it only needs to be trained once and can be applied as a plug-in to substantially improve the reasoning capabilities of existing LLMs. In addition, the planner supports continual learning across various tasks, allowing its planning abilities to gradually improve and generalize to a wider range of problems.",
        "subjects": "Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.342780",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献与您的三个研究方向高度契合。我的判断过程如下： **第一步：核心判断——论文的本质是什么？** 这篇论文的本质是**构建和改进LLM智能体**。它提出了一个名为rSIM（强化策略注入机制）的新框架，其目标是将任何LLM“演化为”一个具备高级推理能力的“推理语言模型”。这并非将LLM作为工具应用于某个特定领域，而是提出了一种通用的方法论来增强LLM本身的智能体能力。因此，根据第一步的判断标准，应**保留**。 **第二步：正面指标——论文是否包含我的核心关注点？** 该论文包含了大量您关注的核心指标，覆盖了所有三个方向： 1.  **单智能体**: *   论文的核心是让LLM学会执行`self-reflection`和`deep thinking`等策略，这直接命中了“自我反思”能力。 *   整个框架通过一个`planner`（规划器）来引导LLM的`chain of thoughts`（思维链），这完全符合“规划”这一核心能力。 2.  **多智能体**: *   论文明确使用了`Multi-Agent RL (MARL)`（多智能体强化学习）来训练系统。 *   它将系统构建为一个`leader-follower`（领导者-追随者）框架，其中`planner`是领导者智能体，`LLM`是追随者智能体。这是一种典型的多智能体协作与交互模式。 3.  **自我演化**: *   论文的标题和摘要都强调了“evolve”（演化）LLMs。 *   摘要最后明确指出，该规划器支持`continual learning`（持续学习），使其规划能力能够`gradually improve`（逐步提升）。这直接对应了“自我完善和迭代”的演化机制。 **第三步：排除标准——是否为我的研究焦点之外？** 该论文的主要贡献不涉及安全与对齐（Safety, Alignment等），也不涉及多模态（Vision, MLLMs等）。因此，它没有触发任何排除标准。 **第四步：处理特殊和模糊情况** *   **推理/规划**: 该论文的研究重点不是提升LLM底层的数学或逻辑推理能力，而是构建一个**智能体框架**，通过一个外部的规划器来引导LLM进行多步推理和策略执行。这完全符合“保留”的条件，因为它是在研究智能体如何进行规划，而非LLM本身的基础能力。 *   **自我演化的应用**: 该论文的核心贡献就是提出一种新的“自我演化”机制（rSIM），因此即使它有应用场景，也符合“保留”的例外规则。 **第五步：最终决策** 综合以上分析，这篇论文的核心贡献是提出了一种新颖的、基于多智能体强化学习的框架，用于将LLM构建成一个具备规划、自我反思和持续学习能力的、能够自我演化的智能体。它精准地命中了您研究的“单智能体”、“多智能体”和“自我演化”三个核心方向，且不涉及任何排除领域。因此，这篇论文是您研究课题的理想候选。"
    },
    {
        "index": "#66",
        "title": "Argus: A Multi-Agent Sensitive Information Leakage Detection Framework Based on Hierarchical Reference Relationships",
        "link": "/arxiv/2512.08326",
        "arxiv_id": "2512.08326",
        "authors": "Bin Wang, Hui Li, Liyang Zhang, Qijia Zhuang, Ao Yang, Dong Zhang, Xijun Luo, Bing Lin",
        "summary": "Sensitive information leakage in code repositories has emerged as a critical security challenge. Traditional detection methods that rely on regular expressions, fingerprint features, and high-entropy calculations often suffer from high false-positive rates. This not only reduces detection efficiency but also significantly increases the manual screening burden on developers. Recent advances in large language models (LLMs) and multi-agent collaborative architectures have demonstrated remarkable potential for tackling complex tasks, offering a novel technological perspective for sensitive information detection. In response to these challenges, we propose Argus, a multi-agent collaborative framework for detecting sensitive information. Argus employs a three-tier detection mechanism that integrates key content, file context, and project reference relationships to effectively reduce false positives and enhance overall detection accuracy. To comprehensively evaluate Argus in real-world repository environments, we developed two new benchmarks, one to assess genuine leak detection capabilities and another to evaluate false-positive filtering performance. Experimental results show that Argus achieves up to 94.86% accuracy in leak detection, with a precision of 96.36%, recall of 94.64%, and an F1 score of 0.955. Moreover, the analysis of 97 real repositories incurred a total cost of only 2.2$. All code implementations and related datasets are publicly available at https://github.com/TheBinKing/Argus-Guard for further research and application.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.355279",
        "filter_reason": "这篇论文符合你的研究范围，应当保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将一个现成的LLM或智能体框架应用于安全领域。它的核心贡献是**构建了一个名为“Argus”的全新多智能体协作框架**。论文详细描述了这个框架的“三层检测机制”和“分层参考关系”，这属于方法论和新框架的创新，直接命中了你“构建、改进或演化LLM智能体”的核心目标。它不是“非演化型应用”，因为其创新点在于智能体系统的架构本身，而非应用结果。 2.  **第二步：正面指标** - 论文包含了多个核心正面指标。标题和摘要中明确提到了 `Multi-Agent`（多智能体）和 `Collaborative`（协作），这完全符合你“多智能体”研究方向的焦点。虽然未直接提及“自我演化”，但其多智能体协作解决复杂问题的机制，是Agentic AI研究的重要组成部分。 3.  **第三步：排除标准** - **安全与对齐**：这是最需要辨析的一点。虽然论文的**应用领域**是“敏感信息泄露检测”，属于`Security`范畴，但你的排除标准是“**只要论文的主要贡献是关于** Safety, Security...”。本论文的**主要贡献**是那个多智能体框架，而不是一种新的加密算法或安全协议。它是在探讨“如何用多智能体架构更好地解决安全问题”，其研究价值在于“多智能体架构”本身，而非“安全”本身。因此，它不满足排除条件。 - **多模态与视觉**：论文不涉及此内容。 4.  **第四步：处理特殊和模糊情况** - 此处不直接适用，但核心原则依然有效：判断依据是论文的**核心贡献**。本论文的核心贡献是智能体框架的设计，这使其与那些仅仅将LLM作为工具应用在安全领域的论文区分开来。 **最终决策**： 综合来看，这篇论文的核心是提出了一种新颖的**多智能体协作框架**来解决一个复杂问题。这完全符合你“筛选出那些核心贡献在于构建、改进或演化LLM智能体的论文”的要求，特别是你关注的“多智能体”方向。尽管其应用场景是安全，但研究的焦点和贡献在于Agentic AI的架构设计，因此应当被保留。"
    },
    {
        "index": "#79",
        "title": "Embodied Tree of Thoughts: Deliberate Manipulation Planning with Embodied World Model",
        "link": "/arxiv/2512.08188",
        "arxiv_id": "2512.08188",
        "authors": "Wenjiang Xu, Cindy Wang, Rui Fang, Mingkang Zhang, Lusong Li, Jing Xu, Jiayuan Gu, Zecui Zeng, Rui Chen",
        "summary": "World models have emerged as a pivotal component in robot manipulation planning, enabling agents to predict future environmental states and reason about the consequences of actions before execution. While video-generation models are increasingly adopted, they often lack rigorous physical grounding, leading to hallucinations and a failure to maintain consistency in long-horizon physical constraints. To address these limitations, we propose Embodied Tree of Thoughts (EToT), a novel Real2Sim2Real planning framework that leverages a physics-based interactive digital twin as an embodied world model. EToT formulates manipulation planning as a tree search expanded through two synergistic mechanisms: (1) Priori Branching, which generates diverse candidate execution paths based on semantic and spatial analysis; and (2) Reflective Branching, which utilizes VLMs to diagnose execution failures within the simulator and iteratively refine the planning tree with corrective actions. By grounding high-level reasoning in a physics simulator, our framework ensures that generated plans adhere to rigid-body dynamics and collision constraints. We validate EToT on a suite of short- and long-horizon manipulation tasks, where it consistently outperforms baselines by effectively predicting physical dynamics and adapting to potential failures. Website at https://embodied-tree-of-thoughts.github.io .",
        "subjects": "Robotics, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.358968",
        "filter_reason": "这篇论文完全符合您的研究范围，其核心贡献在于构建和改进一个具有高级规划与自我反思能力的LLM智能体框架。以下是我的详细判断过程： 1.  **第一步：核心判断——保留** *   **论文本质**: 这篇论文的核心是提出一个名为 \"Embodied Tree of Thoughts (EToT)\" 的新颖规划框架。它不是简单地将现有LLM或智能体框架应用于机器人领域，而是构建了一个全新的、集成了物理模拟器和视觉语言模型（VLM）的智能体架构。 *   **符合保留条件**: 该框架的核心贡献在于其方法论，即如何让智能体进行更有效的规划和自我修正。这直接对应了“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是“非演化型应用”，因为其核心是智能体本身的机制创新，而非应用场景的解决。 2.  **第二步：正面指标——高度相关** *   **核心范式**: 论文明确提出了一个基于 `Tree of Thoughts (ToT)` 的 `Agentic AI` 框架。 *   **智能体能力**: *   `Planning`: 论文的主题就是“Deliberate Manipulation Planning”，其核心机制是树搜索，这是一种高级的规划方法。 *   `Tool Use`: 论文将“physics-based interactive digital twin”（物理模拟器）作为智能体的核心工具，用于预测行动后果，这是典型的工具使用。 *   `Self-Correction` / `Self-Reflection`: 论文的核心创新点之一是“Reflective Branching”机制，它利用VLM来“诊断执行失败”并“迭代地优化规划树”。这完全符合您关注的自我反思和自我修正能力。 *   **演化机制**: “Reflective Branching”中的“迭代地优化”体现了 `Iterative Improvement` 的思想。 3.  **第三步：排除标准——未触发** *   **安全与对齐**: 论文的主要贡献不是关于安全、对齐或可解释性。 *   **多模态与视觉**: 论文虽然使用了VLM（Vision-Language Model），但根据您的核心规则，它被用作智能体“诊断执行失败”的工具，是智能体感知和分析环境的一部分，而不是研究的核心。研究的核心是EToT这个规划框架本身，因此不触发排除标准。 4.  **第四步：处理特殊和模糊情况——明确符合保留条件** *   **推理/规划**: 这篇论文是“关于智能体如何进行规划或在复杂任务中进行多步推理”的完美范例。它将ToT从纯语言推理扩展到了具身物理世界，提出了一个全新的Agentic框架，完全符合保留条件。 *   **自我演化的应用**: 尽管论文应用于机器人领域，但其核心贡献是提出了一种新的“自我反思”机制。这符合您设定的例外情况：“如果论文的核心是提出一种新的‘自我演化’（此处为自我反思/修正）机制，即使它被应用在特定领域，也应该保留”。 **最终决策**: 这篇论文的核心贡献是构建了一个名为EToT的新型LLM智能体框架。该框架通过结合物理模拟器（工具使用）和树搜索（规划），并创新性地引入了基于VLM的自我反思与修正机制，显著提升了智能体在复杂物理任务中的规划能力。其研究焦点完全集中在“单智能体”的规划、工具使用和自我反思上，是您研究课题“LLM智能体及其演化”的前沿和高相关度文献。因此，应予以保留。"
    },
    {
        "index": "#84",
        "title": "Chat with UAV -- Human-UAV Interaction Based on Large Language Models",
        "link": "/arxiv/2512.08145",
        "arxiv_id": "2512.08145",
        "authors": "Haoran Wang, Zhuohang Chen, Guang Li, Bo Ma, Chuanghuang Li",
        "summary": "The future of UAV interaction systems is evolving from engineer-driven to user-driven, aiming to replace traditional predefined Human-UAV Interaction designs. This shift focuses on enabling more personalized task planning and design, thereby achieving a higher quality of interaction experience and greater flexibility, which can be used in many fileds, such as agriculture, aerial photography, logistics, and environmental monitoring. However, due to the lack of a common language between users and the UAVs, such interactions are often difficult to be achieved. The developments of Large Language Models possess the ability to understand nature languages and Robots' (UAVs') behaviors, marking the possibility of personalized Human-UAV Interaction. Recently, some HUI frameworks based on LLMs have been proposed, but they commonly suffer from difficulties in mixed task planning and execution, leading to low adaptability in complex scenarios. In this paper, we propose a novel dual-agent HUI framework. This framework constructs two independent LLM agents (a task planning agent, and an execution agent) and applies different Prompt Engineering to separately handle the understanding, planning, and execution of tasks. To verify the effectiveness and performance of the framework, we have built a task database covering four typical application scenarios of UAVs and quantified the performance of the HUI framework using three independent metrics. Meanwhile different LLM models are selected to control the UAVs with compared performance. Our user study experimental results demonstrate that the framework improves the smoothness of HUI and the flexibility of task execution in the tasks scenario we set up, effectively meeting users' personalized needs.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-12-09",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.360361",
        "filter_reason": "这篇论文符合你的研究范围，应被保留。我的判断过程如下： 1.  **第一步：核心判断** - **保留**。这篇论文的本质不是简单地将LLM作为工具应用于无人机控制，而是**提出了一种新颖的“双智能体框架”**。其核心贡献在于方法论和架构创新：通过构建一个“任务规划智能体”和一个“执行智能体”，来解决现有框架在混合任务规划与执行中的难题。这完全符合“构建、改进LLM智能体的方法论或新框架”的保留标准。它不是对现有智能体框架的简单应用，而是对智能体架构本身的创新。 2.  **第二步：正面指标** - 论文包含了多个核心关注点： - **核心范式**: 明确提出了 `LLM-based Agents` 和 `Multi-Agent Systems (MAS)`（双智能体）。 - **智能体能力**: 核心贡献之一就是 `Planning`（任务规划智能体），并且整个框架涉及 `Tool Use`（将无人机作为执行任务的工具）。 - **多智能体**: 论文的核心是双智能体的 `Collaboration`（协作）与 `Communication`（通信），规划智能体和执行智能体需要协同工作。 3.  **第三步：排除标准** - 论文的主要贡献不涉及安全、对齐、可解释性或视觉模型。它的焦点是智能体的架构设计和任务执行效率，因此没有触发任何排除标准。 4.  **第四步：处理特殊和模糊情况** - **推理/规划**: 这篇论文是典型的“保留”情况。它研究的是智能体如何通过一个专门的规划模块（任务规划智能体）来进行复杂任务的规划，这属于Agentic框架的范畴，而非提升LLM本身的基础推理能力。 **核心依据总结**: 尽管论文的应用领域是无人机控制（一个特定领域），但其**核心贡献是提出了一种新的多智能体协作框架**。这种将规划与执行解耦，分配给不同智能体的设计，是对LLM智能体架构本身的改进和创新。这直接命中了你研究目标中的“多智能体”方向，并涉及“单智能体”的规划能力。因此，它是一篇关于如何构建和改进LLM智能体的前沿论文，完全符合你的筛选要求。"
    },
    {
        "index": "#97",
        "title": "DeepCode: Open Agentic Coding",
        "link": "/arxiv/2512.07921",
        "arxiv_id": "2512.07921",
        "authors": "Zongwei Li, Zhonghang Li, Zirui Guo, Xubin Ren, Chao Huang",
        "summary": "Recent advances in large language models (LLMs) have given rise to powerful coding agents, making it possible for code assistants to evolve into code engineers. However, existing methods still face significant challenges in achieving high-fidelity document-to-codebase synthesis--such as scientific papers to code--primarily due to a fundamental conflict between information overload and the context bottlenecks of LLMs. In this work, we introduce DeepCode, a fully autonomous framework that fundamentally addresses this challenge through principled information-flow management. By treating repository synthesis as a channel optimization problem, DeepCode seamlessly orchestrates four information operations to maximize task-relevant signals under finite context budgets: source compression via blueprint distillation, structured indexing using stateful code memory, conditional knowledge injection via retrieval-augmented generation, and closed-loop error correction. Extensive evaluations on the PaperBench benchmark demonstrate that DeepCode achieves state-of-the-art performance, decisively outperforming leading commercial agents such as Cursor and Claude Code, and crucially, surpassing PhD-level human experts from top institutes on key reproduction metrics. By systematically transforming paper specifications into production-grade implementations comparable to human expert quality, this work establishes new foundations for autonomous scientific reproduction that can accelerate research evaluation and discovery.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-12-08",
        "category": "cs.AI",
        "crawl_time": "2025-12-10T11:00:07.363934",
        "filter_reason": "这篇论文符合研究范围，应被保留。 **判断过程如下:** 1.  **第一步：核心判断** *   论文的核心是构建一个名为 **DeepCode** 的全新自主框架。它不是简单地将一个已有的LLM或智能体框架应用到编程领域，而是提出了一种新的方法论来解决“文档到代码库合成”这一复杂挑战。其核心贡献在于这个框架本身的设计，包括信息流管理、蓝图蒸馏、状态记忆等机制。因此，这完全符合“保留”标准，即“论文的核心是关于构建LLM智能体的方法论或新框架”。 2.  **第二步：正面指标** *   论文命中了多个核心关注点，尤其是在“单智能体”方向： *   **核心范式**: `Agentic AI`, `LLM-based Agents` (标题和摘要中明确提及)。 *   **智能体能力**: *   `Planning`: 论文将任务视为“信道优化问题”并“无缝编排四种信息操作”，这本质上是一种高级的规划和任务执行策略。 *   `Memory`: 明确提出了“有状态的代码记忆”，这是智能体的关键能力。 *   `Tool Use / Tool Augmentation`: 使用了“检索增强生成”作为工具。 *   `Self-Correction`: 包含了“闭环错误纠正”机制，属于自我反思和修正的范畴。 3.  **第三步：排除标准** *   论文的主要贡献是提升智能体的任务执行能力，不涉及安全、对齐、可解释性或多模态等排除标准。因此，第三步的排除规则不适用。 4.  **第四步：处理特殊和模糊情况** *   **推理/规划**: 该论文属于应“保留”的情况。它研究的是智能体如何在一个复杂、多步骤的任务（从论文生成代码库）中进行规划和推理，而不是单纯提升LLM在数学或逻辑等基础推理上的Token预测能力。其提出的框架是一个典型的Agentic框架。 5.  **第五步：最终决策** *   综合以上分析，这篇论文的核心贡献是构建了一个具备高级规划、记忆、工具使用和自我纠正能力的LLM智能体框架。它完美地契合了研究课题中的“单智能体”方向，是关于如何构建和改进LLM智能体的前沿研究。因此，最终判断为 **True**，应被保留。"
    }
]