# PaperTools

English | [ä¸­æ–‡](README.md)

PaperTools is a comprehensive academic paper processing pipeline that provides automated paper crawling, intelligent filtering, summarization, and web generation capabilities.

## Features

- **Automated Crawling**: Crawl latest papers from arXiv and other academic platforms
- **AI-Powered Filtering**: Use large language models to intelligently filter papers by research domain
- **Automatic Summarization**: Generate high-quality Chinese summaries using jinja.ai for full paper content
- **ðŸ’¡ Inspiration Tracing**: Deep analysis of the innovation logic chain from challenges to insights to solutions
- **Web Generation**: Convert papers into interactive HTML pages with modern design and collapsible content
- **Local Deployment**: One-click local server startup for browsing and sharing
- **Multi-threaded Processing**: All components support parallel processing for improved performance
- **Interactive Features**: Support for paper bookmarking, read status tracking, and deletion with persistent storage

## Requirements

- Python 3.7+
- Network connection (for API calls and content retrieval)
- Recommended: 4GB+ RAM (for processing large volumes of papers)

## Installation

### Setup Environment

```bash
# 1. Copy configuration template
cp .env.example .env

# 2. Edit .env file and set your API key
# OPENAI_API_KEY=your_actual_api_key_here
# OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4
# MODEL=glm-4.5-flash

# 3. Check and install dependencies
python papertools.py check
```

### Quick Start

```bash
# Full mode: process 1000 papers (default)
python papertools.py run

# Quick mode: process 10 papers  
python papertools.py run --mode quick

# View results
python papertools.py serve

# Get help
python papertools.py --help
```

## Usage

### Main Commands

```bash
# Run paper processing pipeline
python papertools.py run [options]
  --mode {quick,full}     # Processing mode: quick(10 papers) or full(1000 papers, default)
  --date YYYY-MM-DD       # Process papers from specific date
  --categories cs.AI cs.CL # Specify paper categories
  --max-papers-total N    # Custom paper count

# Start web server
python papertools.py serve

# Clean cache files  
python papertools.py clean

# Check environment and dependencies
python papertools.py check
```

### Advanced: Individual Module Usage

For using individual modules:

```bash
# 1. Crawl papers
python src/core/crawl_arxiv.py --categories cs.AI cs.CV --max-papers 100

# 2. Filter papers
python src/core/select_.py --input-file arxiv_paper/papers.json

# 3. Generate summaries and inspiration tracing
python src/core/generate_summary.py --input-file domain_paper/filtered_papers.json

# 4. Generate unified web page
python src/core/generate_unified_index.py

# 5. Start server
python src/core/serve_webpages.py --port 8080
```

## Configuration

### Environment Variables

Configure in `.env` file:

```bash
# API Configuration
OPENAI_API_KEY=your_api_key_here
OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4
MODEL=glm-4.5-flash

# Optional: Jina API Token (for full paper content retrieval)
JINA_API_TOKEN=your_jina_token_here
```

### Examples

```bash
# Full processing (1000 papers, default)
python papertools.py run

# Quick test (10 papers)
python papertools.py run --mode quick

# Process specific categories
python papertools.py run --categories cs.AI cs.CL

# Process specific date
python papertools.py run --date 2025-09-24

# Custom paper count
python papertools.py run --max-papers-total 500
```

## Project Structure

```
PaperTools/
â”œâ”€â”€ papertools.py              # Main entry point
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ .env.example              # Environment variable template
â”œâ”€â”€ README.md                 # Chinese documentation
â”œâ”€â”€ README_EN.md              # English documentation
â”œâ”€â”€ src/                      # Source code directory
â”‚   â”œâ”€â”€ core/                 # Core functionality modules
â”‚   â”‚   â”œâ”€â”€ pipeline.py       # Main pipeline script
â”‚   â”‚   â”œâ”€â”€ crawl_arxiv.py    # Paper crawling
â”‚   â”‚   â”œâ”€â”€ select_.py        # Paper filtering
â”‚   â”‚   â”œâ”€â”€ generate_summary.py # Summary and inspiration tracing generation
â”‚   â”‚   â”œâ”€â”€ generate_unified_index.py # Unified web page generation
â”‚   â”‚   â””â”€â”€ serve_webpages.py # Local server
â”‚   â”œâ”€â”€ utils/                # Utilities and configuration
â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration file
â”‚   â”‚   â””â”€â”€ cache_manager.py  # Cache management
â”‚   â””â”€â”€ legacy/               # Legacy/experimental code
â”œâ”€â”€ arxiv_paper/              # Crawled raw papers
â”œâ”€â”€ domain_paper/             # Filtered papers
â”œâ”€â”€ summary/                  # Generated summaries
â””â”€â”€ webpages/                 # Generated web pages
```

## ðŸ’¡ New Features

**Inspiration Tracing**:
- Automatically analyze the innovation logic evolution of each paper
- Generate structured analysis: Challenges â†’ Key Insights â†’ Solution Evolution â†’ Innovation Summary
- Reuse already-fetched paper content, no additional API calls needed
- Support caching mechanism to avoid duplicate analysis

**Collapsible Interface**:
- **Filter Reason** and **Inspiration Tracing** collapsed by default to reduce page clutter
- **AI Summary** and **Original Abstract** expanded by default, highlighting core content
- Smooth fold/expand animation effects for enhanced user experience

## Use Cases

**AI Research**
- Track latest developments in LLM and reasoning technologies
- Research agent and multi-agent systems
- Understand reinforcement learning applications in AI
- Explore tool usage and evolutionary algorithms

**Academic Research**
- Quickly understand latest developments in specific fields
- Generate paper summaries for literature reviews
- **Deep Innovation Analysis**: Understand research breakthroughs through inspiration tracing logic
- Create elegant paper presentation pages
- Build personal research knowledge bases

**Teaching Support**
- Provide AI frontier paper comprehension assistance for students
- **Inspirational Learning**: Show complete thought processes from problem identification to solutions
- Create course-related paper resource libraries
- Make interactive learning materials with collapsible content organization
- Show research field development trajectories

**Team Collaboration**
- Share team-focused AI papers
- Unified paper management and display
- Facilitate team discussions and comments
- Track competitors and related work

## Troubleshooting

### Environment Check
```bash
# Check environment and dependencies
python papertools.py check
```

### Common Issues

**API Call Failures**
```bash
# Check API key configuration
cat .env
# Ensure OPENAI_API_KEY is properly set
```

**Missing Dependencies**
```bash
# Auto-install missing dependencies
python papertools.py check
# Or install manually
pip install -r requirements.txt
```

**Web Server Startup Failures**
```bash
# Generate web content first
python papertools.py run
# Then start server
python papertools.py serve
```

**Cache Issues**
```bash
# Clean all cache files
python papertools.py clean
```

### Debug Mode
```bash
# Test with few papers
python papertools.py run --max-papers-total 10

# Quick mode test
python papertools.py run --mode quick
```

## License

MIT License

## Contributing

We welcome contributions! Please feel free to submit Issues and Pull Requests to improve this project.

## Support

For questions or suggestions, please contact us through GitHub Issues.

---

If this project helps you, please give it a star!