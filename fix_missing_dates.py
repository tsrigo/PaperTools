#!/usr/bin/env python3
"""
è‡ªåŠ¨ä¿®å¤ç¼ºå¤±æ—¥æœŸçš„æ•°æ®
Auto-fix missing dates data up to today
"""

import os
import sys
import json
import subprocess
from datetime import datetime, timedelta
from pathlib import Path

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path(__file__).parent
DATA_DIR = PROJECT_ROOT / "webpages" / "data"
SUMMARY_DIR = PROJECT_ROOT / "summary"


def get_existing_dates():
    """è·å–å·²æœ‰æ•°æ®çš„æ—¥æœŸåˆ—è¡¨"""
    dates = set()

    # ä» webpages/data ç›®å½•è·å–
    if DATA_DIR.exists():
        for f in DATA_DIR.glob("20*.json"):
            date_str = f.stem  # 2026-01-08
            dates.add(date_str)

    return dates


def get_missing_dates(start_date_str: str = None):
    """è·å–ä»æœ€æ–°æ•°æ®æ—¥æœŸåˆ°ä»Šå¤©ä¹‹é—´ç¼ºå¤±çš„æ—¥æœŸ"""
    existing = get_existing_dates()

    if not existing:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å·²æœ‰æ•°æ®")
        return []

    # æ‰¾åˆ°æœ€æ–°çš„æ—¥æœŸ
    latest_date = max(existing)
    today = datetime.now().strftime("%Y-%m-%d")

    print(f"ğŸ“… å·²æœ‰æ•°æ®æœ€æ–°æ—¥æœŸ: {latest_date}")
    print(f"ğŸ“… ä»Šå¤©æ—¥æœŸ: {today}")

    # å¦‚æœæŒ‡å®šäº†èµ·å§‹æ—¥æœŸï¼Œä½¿ç”¨æŒ‡å®šçš„
    if start_date_str:
        start = datetime.strptime(start_date_str, "%Y-%m-%d")
    else:
        start = datetime.strptime(latest_date, "%Y-%m-%d") + timedelta(days=1)

    end = datetime.strptime(today, "%Y-%m-%d")

    # ç”Ÿæˆæ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰å·¥ä½œæ—¥ï¼ˆå‘¨ä¸€åˆ°å‘¨äº”ï¼ŒarXiv åªåœ¨å·¥ä½œæ—¥æ›´æ–°ï¼‰
    missing = []
    current = start
    while current <= end:
        date_str = current.strftime("%Y-%m-%d")
        weekday = current.weekday()

        # è·³è¿‡å‘¨æœ« (5=å‘¨å…­, 6=å‘¨æ—¥)
        if weekday < 5 and date_str not in existing:
            missing.append(date_str)

        current += timedelta(days=1)

    return missing


def check_date_data_exists(date_str: str) -> bool:
    """æ£€æŸ¥æŒ‡å®šæ—¥æœŸçš„æ•°æ®æ˜¯å¦å·²ç”Ÿæˆ"""
    # æ£€æŸ¥ summary ç›®å½•æ˜¯å¦æœ‰è¯¥æ—¥æœŸçš„æ–‡ä»¶
    summary_pattern = f"filtered_papers_{date_str}_with_summary2.json"
    summary_file = SUMMARY_DIR / summary_pattern
    return summary_file.exists()


def run_pipeline_for_date(date_str: str, max_retries: int = 2):
    """ä¸ºæŒ‡å®šæ—¥æœŸè¿è¡Œæµæ°´çº¿ï¼Œæ”¯æŒé‡è¯•"""
    print(f"\n{'='*50}")
    print(f"ğŸ”„ å¤„ç†æ—¥æœŸ: {date_str}")
    print(f"{'='*50}")

    for attempt in range(max_retries):
        if attempt > 0:
            print(f"\nâš ï¸  ç¬¬ {attempt + 1} æ¬¡é‡è¯•...")

        cmd = [
            sys.executable,
            "papertools.py",
            "run",
            "--mode", "full",
            "--date", date_str,
            "--skip-serve"
        ]

        result = subprocess.run(cmd, cwd=PROJECT_ROOT)

        # æ£€æŸ¥æ˜¯å¦çœŸæ­£ç”Ÿæˆäº†æ•°æ®æ–‡ä»¶
        if check_date_data_exists(date_str):
            print(f"âœ… {date_str} æ•°æ®ç”ŸæˆæˆåŠŸ")
            return True
        else:
            print(f"âš ï¸  {date_str} æ•°æ®æœªç”Ÿæˆï¼Œè¿”å›ç : {result.returncode}")

    print(f"âŒ {date_str} å¤„ç†å¤±è´¥ï¼ˆå·²é‡è¯• {max_retries} æ¬¡ï¼‰")
    return False


def regenerate_index():
    """é‡æ–°ç”Ÿæˆç»Ÿä¸€é¡µé¢"""
    print(f"\n{'='*50}")
    print("ğŸ”„ é‡æ–°ç”Ÿæˆç»Ÿä¸€é¡µé¢...")
    print(f"{'='*50}")

    cmd = [sys.executable, "src/core/generate_unified_index.py"]
    result = subprocess.run(cmd, cwd=PROJECT_ROOT)
    return result.returncode == 0


def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="è‡ªåŠ¨ä¿®å¤ç¼ºå¤±æ—¥æœŸçš„æ•°æ®"
    )
    parser.add_argument(
        "--start-date",
        help="æŒ‡å®šèµ·å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä»æœ€æ–°æ•°æ®çš„ä¸‹ä¸€å¤©å¼€å§‹"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="åªæ˜¾ç¤ºç¼ºå¤±çš„æ—¥æœŸï¼Œä¸å®é™…è¿è¡Œ"
    )
    parser.add_argument(
        "--regenerate-only",
        action="store_true",
        help="åªé‡æ–°ç”Ÿæˆç»Ÿä¸€é¡µé¢ï¼Œä¸çˆ¬å–æ–°æ•°æ®"
    )

    args = parser.parse_args()

    print("ğŸ” æ£€æŸ¥ç¼ºå¤±çš„æ—¥æœŸ...")

    if args.regenerate_only:
        regenerate_index()
        print("\nâœ… ç»Ÿä¸€é¡µé¢é‡æ–°ç”Ÿæˆå®Œæˆ")
        return

    missing = get_missing_dates(args.start_date)

    if not missing:
        print("âœ… æ²¡æœ‰ç¼ºå¤±çš„æ—¥æœŸï¼Œæ•°æ®å·²æ˜¯æœ€æ–°")
        return

    print(f"\nğŸ“‹ ç¼ºå¤±çš„æ—¥æœŸ ({len(missing)} å¤©):")
    for d in missing:
        print(f"   - {d}")

    if args.dry_run:
        print("\nğŸ’¡ ä½¿ç”¨ --dry-run æ¨¡å¼ï¼Œä¸å®é™…è¿è¡Œ")
        return

    # é€ä¸ªå¤„ç†ç¼ºå¤±çš„æ—¥æœŸ
    success_count = 0
    failed_dates = []

    for date_str in missing:
        try:
            if run_pipeline_for_date(date_str):
                success_count += 1
            else:
                failed_dates.append(date_str)
        except Exception as e:
            print(f"âŒ å¤„ç† {date_str} æ—¶å‡ºé”™: {e}")
            failed_dates.append(date_str)

    # é‡æ–°ç”Ÿæˆç»Ÿä¸€é¡µé¢
    regenerate_index()

    # æ€»ç»“
    print(f"\n{'='*50}")
    print("ğŸ“Š ä¿®å¤å®Œæˆæ€»ç»“")
    print(f"{'='*50}")
    print(f"âœ… æˆåŠŸ: {success_count} å¤©")
    if failed_dates:
        print(f"âŒ å¤±è´¥: {len(failed_dates)} å¤©")
        for d in failed_dates:
            print(f"   - {d}")

    print("\nğŸ’¡ æç¤º: è¿è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ç»“æœ")
    print("   python papertools.py serve")


if __name__ == "__main__":
    main()
