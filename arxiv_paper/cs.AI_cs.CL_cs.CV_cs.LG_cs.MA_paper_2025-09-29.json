[
    {
        "index": "#1",
        "title": "Voting-Bloc Entropy: A New Metric for DAO Decentralization",
        "link": "/arxiv/2509.22620",
        "arxiv_id": "2509.22620",
        "authors": "Andrés Fábrega, Amy Zhao, Jay Yu, James Austgen, Sarah Allen, Kushal Babel, Mahimna Kelkar, Ari Juels",
        "summary": "Decentralized Autonomous Organizations (DAOs) use smart contracts to foster communities working toward common goals. Existing definitions of decentralization, however -- the 'D' in DAO -- fall short of capturing the key properties characteristic of diverse and equitable participation. This work proposes a new framework for measuring DAO decentralization called Voting-Bloc Entropy (VBE, pronounced ''vibe''). VBE is based on the idea that voters with closely aligned interests act as a centralizing force and should be modeled as such. VBE formalizes this notion by measuring the similarity of participants' utility functions across a set of voting rounds. Unlike prior, ad hoc definitions of decentralization, VBE derives from first principles: We introduce a simple (yet powerful) reinforcement learning-based conceptual model for voting, that in turn implies VBE. We first show VBE's utility as a theoretical tool. We prove a number of results about the (de)centralizing effects of vote delegation, proposal bundling, bribery, etc. that are overlooked in previous notions of DAO decentralization. Our results lead to practical suggestions for enhancing DAO decentralization. We also show how VBE can be used empirically by presenting measurement studies and VBE-based governance experiments. We make the tools we developed for these results available to the community in the form of open-source artifacts in order to facilitate future study of DAO decentralization.",
        "subjects": "Multiagent Systems, Cryptography and Security",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.532273"
    },
    {
        "index": "#2",
        "title": "Effective Policy Learning for Multi-Agent Online Coordination Beyond Submodular Objectives",
        "link": "/arxiv/2509.22596",
        "arxiv_id": "2509.22596",
        "authors": "Qixin Zhang, Yan Sun, Can Jin, Xikun Zhang, Yao Shu, Puning Zhao, Li Shen, Dacheng Tao",
        "summary": "In this paper, we present two effective policy learning algorithms for multi-agent online coordination(MA-OC) problem. The first one, \\texttt{MA-SPL}, not only can achieve the optimal $(1-\\frac{c}{e})$-approximation guarantee for the MA-OC problem with submodular objectives but also can handle the unexplored $\\alpha$-weakly DR-submodular and $(\\gamma,\\beta)$-weakly submodular scenarios, where $c$ is the curvature of the investigated submodular functions, $\\alpha$ denotes the diminishing-return(DR) ratio and the tuple $(\\gamma,\\beta)$ represents the submodularity ratios. Subsequently, in order to reduce the reliance on the unknown parameters $\\alpha,\\gamma,\\beta$ inherent in the \\texttt{MA-SPL} algorithm, we further introduce the second online algorithm named \\texttt{MA-MPL}. This \\texttt{MA-MPL} algorithm is entirely \\emph{parameter-free} and simultaneously can maintain the same approximation ratio as the first \\texttt{MA-SPL} algorithm. The core of our \\texttt{MA-SPL} and \\texttt{MA-MPL} algorithms is a novel continuous-relaxation technique termed as \\emph{policy-based continuous extension}. Compared with the well-established \\emph{multi-linear extension}, a notable advantage of this new \\emph{policy-based continuous extension} is its ability to provide a lossless rounding scheme for any set function, thereby enabling us to tackle the challenging weakly submodular objectives. Finally, extensive simulations are conducted to validate the effectiveness of our proposed algorithms.",
        "subjects": "Multiagent Systems, Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.532610"
    },
    {
        "index": "#3",
        "title": "VizGen: Data Exploration and Visualization from Natural Language via a Multi-Agent AI Architecture",
        "link": "/arxiv/2509.22218",
        "arxiv_id": "2509.22218",
        "authors": "Sandaru Fernando, Imasha Jayarathne, Sithumini Abeysekara, Shanuja Sithamparanthan, Thushari Silva, Deshan Jayawardana",
        "summary": "Data visualization is essential for interpreting complex datasets, yet traditional tools often require technical expertise, limiting accessibility. VizGen is an AI-assisted graph generation system that empowers users to create meaningful visualizations using natural language. Leveraging advanced NLP and LLMs like Claude 3.7 Sonnet and Gemini 2.0 Flash, it translates user queries into SQL and recommends suitable graph types. Built on a multi-agent architecture, VizGen handles SQL generation, graph creation, customization, and insight extraction. Beyond visualization, it analyzes data for patterns, anomalies, and correlations, and enhances user understanding by providing explanations enriched with contextual information gathered from the internet. The system supports real-time interaction with SQL databases and allows conversational graph refinement, making data analysis intuitive and accessible. VizGen democratizes data visualization by bridging the gap between technical complexity and user-friendly design.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Databases",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.532907"
    },
    {
        "index": "#4",
        "title": "Impact of Collective Behaviors of Autonomous Vehicles on Urban Traffic Dynamics: A Multi-Agent Reinforcement Learning Approach",
        "link": "/arxiv/2509.22216",
        "arxiv_id": "2509.22216",
        "authors": "Ahmet Onur Akman, Anastasia Psarou, Zoltán György Varga, Grzegorz Jamróz, Rafał Kucharski",
        "summary": "This study examines the potential impact of reinforcement learning (RL)-enabled autonomous vehicles (AV) on urban traffic flow in a mixed traffic environment. We focus on a simplified day-to-day route choice problem in a multi-agent setting. We consider a city network where human drivers travel through their chosen routes to reach their destinations in minimum travel time. Then, we convert one-third of the population into AVs, which are RL agents employing Deep Q-learning algorithm. We define a set of optimization targets, or as we call them behaviors, namely selfish, collaborative, competitive, social, altruistic, and malicious. We impose a selected behavior on AVs through their rewards. We run our simulations using our in-house developed RL framework PARCOUR. Our simulations reveal that AVs optimize their travel times by up to 5\\%, with varying impacts on human drivers' travel times depending on the AV behavior. In all cases where AVs adopt a self-serving behavior, they achieve shorter travel times than human drivers. Our findings highlight the complexity differences in learning tasks of each target behavior. We demonstrate that the multi-agent RL setting is applicable for collective routing on traffic networks, though their impact on coexisting parties greatly varies with the behaviors adopted.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.533185"
    },
    {
        "index": "#5",
        "title": "Multi-Agent Path Finding via Offline RL and LLM Collaboration",
        "link": "/arxiv/2509.22130",
        "arxiv_id": "2509.22130",
        "authors": "Merve Atasever, Matthew Hong, Mihir Nitin Kulkarni, Qingpei Li, Jyotirmoy V. Deshmukh",
        "summary": "Multi-Agent Path Finding (MAPF) poses a significant and challenging problem critical for applications in robotics and logistics, particularly due to its combinatorial complexity and the partial observability inherent in realistic environments. Decentralized reinforcement learning methods commonly encounter two substantial difficulties: first, they often yield self-centered behaviors among agents, resulting in frequent collisions, and second, their reliance on complex communication modules leads to prolonged training times, sometimes spanning weeks. To address these challenges, we propose an efficient decentralized planning framework based on the Decision Transformer (DT), uniquely leveraging offline reinforcement learning to substantially reduce training durations from weeks to mere hours. Crucially, our approach effectively handles long-horizon credit assignment and significantly improves performance in scenarios with sparse and delayed rewards. Furthermore, to overcome adaptability limitations inherent in standard RL methods under dynamic environmental changes, we integrate a large language model (GPT-4o) to dynamically guide agent policies. Extensive experiments in both static and dynamically changing environments demonstrate that our DT-based approach, augmented briefly by GPT-4o, significantly enhances adaptability and performance.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.533464"
    },
    {
        "index": "#6",
        "title": "RobustFlow: Towards Robust Agentic Workflow Generation",
        "link": "/arxiv/2509.21834",
        "arxiv_id": "2509.21834",
        "authors": "Shengxiang Xu, Jiayi Zhang, Shimin Di, Yuyu Luo, Liang Yao, Hanmo Liu, Jia Zhu, Fan Liu, Min-Ling Zhang",
        "summary": "The automated generation of agentic workflows is a promising frontier for enabling large language models (LLMs) to solve complex tasks. However, our investigation reveals that the robustness of agentic workflow remains a critical, unaddressed challenge. Current methods often generate wildly inconsistent workflows when provided with instructions that are semantically identical but differently phrased. This brittleness severely undermines their reliability and trustworthiness for real-world applications. To quantitatively diagnose this instability, we propose metrics based on nodal and topological similarity to evaluate workflow consistency against common semantic variations such as paraphrasing and noise injection. Subsequently, we further propose a novel training framework, RobustFlow, that leverages preference optimization to teach models invariance to instruction variations. By training on sets of synonymous task descriptions, RobustFlow boosts workflow robustness scores to 70\\% - 90\\%, which is a substantial improvement over existing approaches. The code is publicly available at https://github.com/DEFENSE-SEU/RobustFlow.",
        "subjects": "Multiagent Systems",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.533751"
    },
    {
        "index": "#7",
        "title": "Visual Multi-Agent System: Mitigating Hallucination Snowballing via Visual Flow",
        "link": "/arxiv/2509.21789",
        "arxiv_id": "2509.21789",
        "authors": "Xinlei Yu, Chengming Xu, Guibin Zhang, Yongbo He, Zhangquan Chen, Zhucun Xue, Jiangning Zhang, Yue Liao, Xiaobin Hu, Yu-Gang Jiang, Shuicheng Yan",
        "summary": "Multi-Agent System (MAS) powered by Visual Language Models (VLMs) enables challenging tasks but suffers from a novel failure term, multi-agent visual hallucination snowballing, where hallucinations are seeded in a single agent and amplified by following ones due to the over-reliance on textual flow to relay visual information. Through turn-, layer-, and token-wise attention analyses, we provide detailed insights into the essence of hallucination snowballing regarding the reduction of visual attention allocation. It leads us to identify a subset of vision tokens with a unimodal attention peak in middle layers that best preserve visual evidence but gradually diminish in deeper agent turns, resulting in the visual hallucination snowballing in MAS. Thus, we propose ViF, a lightweight, plug-and-play mitigation paradigm that relays inter-agent messages with Visual Flow powered by the selected visual relay tokens and applies attention reallocation to amplify this pattern. The experiment results demonstrate that our method markedly reduces hallucination snowballing, consistently improving the performance across eight benchmarks based on four common MAS structures and ten base models. The source code will be available at: https://github.com/YU-deep/ViF.git.",
        "subjects": "Multiagent Systems, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.534069"
    },
    {
        "index": "#8",
        "title": "Learn the Ropes, Then Trust the Wins: Self-imitation with Progressive Exploration for Agentic Reinforcement Learning",
        "link": "/arxiv/2509.22601",
        "arxiv_id": "2509.22601",
        "authors": "Yulei Qin, Xiaoyu Tan, Zhengbao He, Gang Li, Haojia Lin, Zongyi Li, Zihan Xu, Yuchen Shi, Siqi Cai, Renting Rui, Shaofei Cai, Yuzheng Cai, Xuan Zhang, Sheng Ye, Ke Li, Xing Sun",
        "summary": "Reinforcement learning (RL) is the dominant paradigm for sharpening strategic tool use capabilities of LLMs on long-horizon, sparsely-rewarded agent tasks, yet it faces a fundamental challenge of exploration-exploitation trade-off. Existing studies stimulate exploration through the lens of policy entropy, but such mechanical entropy maximization is prone to RL training instability due to the multi-turn distribution shifting. In this paper, we target the progressive exploration-exploitation balance under the guidance of the agent own experiences without succumbing to either entropy collapsing or runaway divergence. We propose SPEAR, a curriculum-based self-imitation learning (SIL) recipe for training agentic LLMs. It extends the vanilla SIL framework, where a replay buffer stores self-generated promising trajectories for off-policy update, by gradually steering the policy evolution within a well-balanced range of entropy across stages. Specifically, our approach incorporates a curriculum to manage the exploration process, utilizing intrinsic rewards to foster skill-level exploration and facilitating action-level exploration through SIL. At first, the auxiliary tool call reward plays a critical role in the accumulation of tool-use skills, enabling broad exposure to the unfamiliar distributions of the environment feedback with an upward entropy trend. As training progresses, self-imitation gets strengthened to exploit existing successful patterns from replayed experiences for comparative action-level exploration, accelerating solution iteration without unbounded entropy growth. To further stabilize training, we recalibrate the advantages of experiences in the replay buffer to address the potential policy drift. Reugularizations such as the clipping of tokens with high covariance between probability and advantage are introduced to the trajectory-level entropy control to curb over-confidence.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Multiagent Systems",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.534441"
    },
    {
        "index": "#9",
        "title": "Learning from Delayed Feedback in Games via Extra Prediction",
        "link": "/arxiv/2509.22426",
        "arxiv_id": "2509.22426",
        "authors": "Yuma Fujimoto, Kenshi Abe, Kaito Ariu",
        "summary": "This study raises and addresses the problem of time-delayed feedback in learning in games. Because learning in games assumes that multiple agents independently learn their strategies, a discrepancy in optimization often emerges among the agents. To overcome this discrepancy, the prediction of the future reward is incorporated into algorithms, typically known as Optimistic Follow-the-Regularized-Leader (OFTRL). However, the time delay in observing the past rewards hinders the prediction. Indeed, this study firstly proves that even a single-step delay worsens the performance of OFTRL from the aspects of regret and convergence. This study proposes the weighted OFTRL (WOFTRL), where the prediction vector of the next reward in OFTRL is weighted $n$ times. We further capture an intuition that the optimistic weight cancels out this time delay. We prove that when the optimistic weight exceeds the time delay, our WOFTRL recovers the good performances that the regret is constant ($O(1)$-regret) in general-sum normal-form games, and the strategies converge to the Nash equilibrium as a subsequence (best-iterate convergence) in poly-matrix zero-sum games. The theoretical results are supported and strengthened by our experiments.",
        "subjects": "Machine Learning, Computer Science and Game Theory, Multiagent Systems, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.534713"
    },
    {
        "index": "#10",
        "title": "Log2Plan: An Adaptive GUI Automation Framework Integrated with Task Mining Approach",
        "link": "/arxiv/2509.22137",
        "arxiv_id": "2509.22137",
        "authors": "Seoyoung Lee, Seonbin Yoon, Seongbeen Lee, Hyesoo Kim, Joo Yong Sim",
        "summary": "GUI task automation streamlines repetitive tasks, but existing LLM or VLM-based planner-executor agents suffer from brittle generalization, high latency, and limited long-horizon coherence. Their reliance on single-shot reasoning or static plans makes them fragile under UI changes or complex tasks. Log2Plan addresses these limitations by combining a structured two-level planning framework with a task mining approach over user behavior logs, enabling robust and adaptable GUI automation. Log2Plan constructs high-level plans by mapping user commands to a structured task dictionary, enabling consistent and generalizable automation. To support personalization and reuse, it employs a task mining approach from user behavior logs that identifies user-specific patterns. These high-level plans are then grounded into low-level action sequences by interpreting real-time GUI context, ensuring robust execution across varying interfaces. We evaluated Log2Plan on 200 real-world tasks, demonstrating significant improvements in task success rate and execution time. Notably, it maintains over 60.0% success rate even on long-horizon task sequences, highlighting its robustness in complex, multi-step workflows.",
        "subjects": "Artificial Intelligence, Human-Computer Interaction, Multiagent Systems, Robotics",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.534998"
    },
    {
        "index": "#11",
        "title": "CoBel-World: Harnessing LLM Reasoning to Build a Collaborative Belief World for Optimizing Embodied Multi-Agent Collaboration",
        "link": "/arxiv/2509.21981",
        "arxiv_id": "2509.21981",
        "authors": "Zhimin Wang, Shaokang He, Duo Wu, Jinghe Wang, Linjia Kang, Jing Yu, Zhi Wang",
        "summary": "Effective real-world multi-agent collaboration requires not only accurate planning but also the ability to reason about collaborators' intents -- a crucial capability for avoiding miscoordination and redundant communication under partial observable environments. Due to their strong planning and reasoning capabilities, large language models (LLMs) have emerged as promising autonomous agents for collaborative task solving. However, existing collaboration frameworks for LLMs overlook their reasoning potential for dynamic intent inference, and thus produce inconsistent plans and redundant communication, reducing collaboration efficiency. To bridge this gap, we propose CoBel-World, a novel framework that equips LLM agents with a collaborative belief world -- an internal representation jointly modeling the physical environment and collaborators' mental states. CoBel-World enables agents to parse open-world task knowledge into structured beliefs via a symbolic belief language, and perform zero-shot Bayesian-style belief updates through LLM reasoning. This allows agents to proactively detect potential miscoordination (e.g., conflicting plans) and communicate adaptively. Evaluated on challenging embodied benchmarks (i.e., TDW-MAT and C-WAH), CoBel-World significantly reduces communication costs by 22-60% and improves task completion efficiency by 4-28% compared to the strongest baseline. Our results show that explicit, intent-aware belief modeling is essential for efficient and human-like collaboration in LLM-based multi-agent systems.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.535276"
    },
    {
        "index": "#12",
        "title": "Reimagining Agent-based Modeling with Large Language Model Agents via Shachi",
        "link": "/arxiv/2509.21862",
        "arxiv_id": "2509.21862",
        "authors": "So Kuroki, Yingtao Tian, Kou Misaki, Takashi Ikegami, Takuya Akiba, Yujin Tang",
        "summary": "The study of emergent behaviors in large language model (LLM)-driven multi-agent systems is a critical research challenge, yet progress is limited by a lack of principled methodologies for controlled experimentation. To address this, we introduce Shachi, a formal methodology and modular framework that decomposes an agent's policy into core cognitive components: Configuration for intrinsic traits, Memory for contextual persistence, and Tools for expanded capabilities, all orchestrated by an LLM reasoning engine. This principled architecture moves beyond brittle, ad-hoc agent designs and enables the systematic analysis of how specific architectural choices influence collective behavior. We validate our methodology on a comprehensive 10-task benchmark and demonstrate its power through novel scientific inquiries. Critically, we establish the external validity of our approach by modeling a real-world U.S. tariff shock, showing that agent behaviors align with observed market reactions only when their cognitive architecture is appropriately configured with memory and tools. Our work provides a rigorous, open-source foundation for building and evaluating LLM agents, aimed at fostering more cumulative and scientifically grounded research.",
        "subjects": "Artificial Intelligence, Multiagent Systems, Social and Information Networks, General Economics",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.535570"
    },
    {
        "index": "#13",
        "title": "Following the TRACE: A Structured Path to Empathetic Response Generation with Multi-Agent Models",
        "link": "/arxiv/2509.21849",
        "arxiv_id": "2509.21849",
        "authors": "Ziqi Liu, Ziyang Zhou, Yilin Li, Haiyang Zhang, Yangbin Chen",
        "summary": "Empathetic response generation is a crucial task for creating more human-like and supportive conversational agents. However, existing methods face a core trade-off between the analytical depth of specialized models and the generative fluency of Large Language Models (LLMs). To address this, we propose TRACE, Task-decomposed Reasoning for Affective Communication and Empathy, a novel framework that models empathy as a structured cognitive process by decomposing the task into a pipeline for analysis and synthesis. By building a comprehensive understanding before generation, TRACE unites deep analysis with expressive generation. Experimental results show that our framework significantly outperforms strong baselines in both automatic and LLM-based evaluations, confirming that our structured decomposition is a promising paradigm for creating more capable and interpretable empathetic agents. Our code is available at https://anonymous.4open.science/r/TRACE-18EF/README.md.",
        "subjects": "Computation and Language, Multiagent Systems",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.535850"
    },
    {
        "index": "#14",
        "title": "Axiomatic Choice and the Decision-Evaluation Paradox",
        "link": "/arxiv/2509.21836",
        "arxiv_id": "2509.21836",
        "authors": "Ben Abramowitz, Nicholas Mattei",
        "summary": "We introduce a framework for modeling decisions with axioms that are statements about decisions, e.g., ethical constraints. Using our framework we define a taxonomy of decision axioms based on their structural properties and demonstrate a tension between the use of axioms to make decisions and the use of axioms to evaluate decisions which we call the Decision-Evaluation Paradox. We argue that the Decision-Evaluation Paradox arises with realistic axiom structures, and the paradox illuminates why one must be exceptionally careful when training models on decision data or applying axioms to make and evaluate decisions.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.536100"
    },
    {
        "index": "#15",
        "title": "Preference-Guided Learning for Sparse-Reward Multi-Agent Reinforcement Learning",
        "link": "/arxiv/2509.21828",
        "arxiv_id": "2509.21828",
        "authors": "The Viet Bui, Tien Mai, Hong Thanh Nguyen",
        "summary": "We study the problem of online multi-agent reinforcement learning (MARL) in environments with sparse rewards, where reward feedback is not provided at each interaction but only revealed at the end of a trajectory. This setting, though realistic, presents a fundamental challenge: the lack of intermediate rewards hinders standard MARL algorithms from effectively guiding policy learning. To address this issue, we propose a novel framework that integrates online inverse preference learning with multi-agent on-policy optimization into a unified architecture. At its core, our approach introduces an implicit multi-agent reward learning model, built upon a preference-based value-decomposition network, which produces both global and local reward signals. These signals are further used to construct dual advantage streams, enabling differentiated learning targets for the centralized critic and decentralized actors. In addition, we demonstrate how large language models (LLMs) can be leveraged to provide preference labels that enhance the quality of the learned reward model. Empirical evaluations on state-of-the-art benchmarks, including MAMuJoCo and SMACv2, show that our method achieves superior performance compared to existing baselines, highlighting its effectiveness in addressing sparse-reward challenges in online MARL.",
        "subjects": "Machine Learning, Multiagent Systems",
        "date": "2025-09-26",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.536352"
    },
    {
        "index": "#16",
        "title": "Multi-Objective Reinforcement Learning for Large Language Model Optimization: Visionary Perspective",
        "link": "/arxiv/2509.21613",
        "arxiv_id": "2509.21613",
        "authors": "Lingxiao Kong, Cong Yang, Oya Deniz Beyan, Zeyd Boukhers",
        "summary": "Multi-Objective Reinforcement Learning (MORL) presents significant challenges and opportunities for optimizing multiple objectives in Large Language Models (LLMs). We introduce a MORL taxonomy and examine the advantages and limitations of various MORL methods when applied to LLM optimization, identifying the need for efficient and flexible approaches that accommodate personalization functionality and inherent complexities in LLMs and RL. We propose a vision for a MORL benchmarking framework that addresses the effects of different methods on diverse objective relationships. As future research directions, we focus on meta-policy MORL development that can improve efficiency and flexibility through its bi-level learning paradigm, highlighting key research questions and potential solutions for improving LLM performance.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-09-25",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.536636"
    },
    {
        "index": "#17",
        "title": "AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need",
        "link": "/arxiv/2509.21553",
        "arxiv_id": "2509.21553",
        "authors": "Ahmed Jaber, Wangshu Zhu, Karthick Jayavelu, Justin Downes, Sameer Mohamed, Candace Agonafir, Linnia Hawkins, Tian Zheng",
        "summary": "Climate data science faces persistent barriers stemming from the fragmented nature of data sources, heterogeneous formats, and the steep technical expertise required to identify, acquire, and process datasets. These challenges limit participation, slow discovery, and reduce the reproducibility of scientific workflows. In this paper, we present a proof of concept for addressing these barriers through the integration of a curated knowledge graph (KG) with AI agents designed for cloud-native scientific workflows. The KG provides a unifying layer that organizes datasets, tools, and workflows, while AI agents -- powered by generative AI services -- enable natural language interaction, automated data access, and streamlined analysis. Together, these components drastically lower the technical threshold for engaging in climate data science, enabling non-specialist users to identify and analyze relevant datasets. By leveraging existing cloud-ready API data portals, we demonstrate that \"a knowledge graph is all you need\" to unlock scalable and agentic workflows for scientific inquiry. The open-source design of our system further supports community contributions, ensuring that the KG and associated tools can evolve as a shared commons. Our results illustrate a pathway toward democratizing access to climate data and establishing a reproducible, extensible framework for human--AI collaboration in scientific research.",
        "subjects": "Artificial Intelligence, Computational Engineering, Finance, and Science, Human-Computer Interaction, Machine Learning, Multiagent Systems",
        "date": "2025-09-25",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T22:42:00.536952"
    },
    {
        "index": "#1",
        "title": "RefAM: Attention Magnets for Zero-Shot Referral Segmentation",
        "link": "/arxiv/2509.22650",
        "arxiv_id": "2509.22650",
        "authors": "Anna Kukleva, Enis Simsar, Alessio Tonioni, Muhammad Ferjad Naeem, Federico Tombari, Jan Eric Lenssen, Bernt Schiele",
        "summary": "Most existing approaches to referring segmentation achieve strong performance only through fine-tuning or by composing multiple pre-trained models, often at the cost of additional training and architectural modifications. Meanwhile, large-scale generative diffusion models encode rich semantic information, making them attractive as general-purpose feature extractors. In this work, we introduce a new method that directly exploits features, attention scores, from diffusion transformers for downstream tasks, requiring neither architectural modifications nor additional training. To systematically evaluate these features, we extend benchmarks with vision-language grounding tasks spanning both images and videos. Our key insight is that stop words act as attention magnets: they accumulate surplus attention and can be filtered to reduce noise. Moreover, we identify global attention sinks (GAS) emerging in deeper layers and show that they can be safely suppressed or redirected onto auxiliary tokens, leading to sharper and more accurate grounding maps. We further propose an attention redistribution strategy, where appended stop words partition background activations into smaller clusters, yielding sharper and more localized heatmaps. Building on these findings, we develop RefAM, a simple training-free grounding framework that combines cross-attention maps, GAS handling, and redistribution. Across zero-shot referring image and video segmentation benchmarks, our approach consistently outperforms prior methods, establishing a new state of the art without fine-tuning or additional components.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.317892"
    },
    {
        "index": "#2",
        "title": "CapRL: Stimulating Dense Image Caption Capabilities via Reinforcement Learning",
        "link": "/arxiv/2509.22647",
        "arxiv_id": "2509.22647",
        "authors": "Long Xing, Xiaoyi Dong, Yuhang Zang, Yuhang Cao, Jianze Liang, Qidong Huang, Jiaqi Wang, Feng Wu, Dahua Lin",
        "summary": "Image captioning is a fundamental task that bridges the visual and linguistic domains, playing a critical role in pre-training Large Vision-Language Models (LVLMs). Current state-of-the-art captioning models are typically trained with Supervised Fine-Tuning (SFT), a paradigm that relies on expensive, non-scalable data annotated by humans or proprietary models. This approach often leads to models that memorize specific ground-truth answers, limiting their generality and ability to generate diverse, creative descriptions. To overcome the limitation of SFT, we propose applying the Reinforcement Learning with Verifiable Rewards (RLVR) paradigm to the open-ended task of image captioning. A primary challenge, however, is designing an objective reward function for the inherently subjective nature of what constitutes a \"good\" caption. We introduce Captioning Reinforcement Learning (CapRL), a novel training framework that redefines caption quality through its utility: a high-quality caption should enable a non-visual language model to accurately answer questions about the corresponding image. CapRL employs a decoupled two-stage pipeline where an LVLM generates a caption, and the objective reward is derived from the accuracy of a separate, vision-free LLM answering Multiple-Choice Questions based solely on that caption. As the first study to apply RLVR to the subjective image captioning task, we demonstrate that CapRL significantly enhances multiple settings. Pretraining on the CapRL-5M caption dataset annotated by CapRL-3B results in substantial gains across 12 benchmarks. Moreover, within the Prism Framework for caption quality evaluation, CapRL achieves performance comparable to Qwen2.5-VL-72B, while exceeding the baseline by an average margin of 8.4%. Code is available here: https://github.com/InternLM/CapRL.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.318486"
    },
    {
        "index": "#3",
        "title": "Learning Human-Perceived Fakeness in AI-Generated Videos via Multimodal LLMs",
        "link": "/arxiv/2509.22646",
        "arxiv_id": "2509.22646",
        "authors": "Xingyu Fu, Siyi Liu, Yinuo Xu, Pan Lu, Guangqiuse Hu, Tianbo Yang, Taran Anantasagar, Christopher Shen, Yikai Mao, Yuanzhe Liu, Keyush Shah, Chung Un Lee, Yejin Choi, James Zou, Dan Roth, Chris Callison-Burch",
        "summary": "Can humans identify AI-generated (fake) videos and provide grounded reasons? While video generation models have advanced rapidly, a critical dimension -- whether humans can detect deepfake traces within a generated video, i.e., spatiotemporal grounded visual artifacts that reveal a video as machine generated -- has been largely overlooked. We introduce DeeptraceReward, the first fine-grained, spatially- and temporally- aware benchmark that annotates human-perceived fake traces for video generation reward. The dataset comprises 4.3K detailed annotations across 3.3K high-quality generated videos. Each annotation provides a natural-language explanation, pinpoints a bounding-box region containing the perceived trace, and marks precise onset and offset timestamps. We consolidate these annotations into 9 major categories of deepfake traces that lead humans to identify a video as AI-generated, and train multimodal language models (LMs) as reward models to mimic human judgments and localizations. On DeeptraceReward, our 7B reward model outperforms GPT-5 by 34.7% on average across fake clue identification, grounding, and explanation. Interestingly, we observe a consistent difficulty gradient: binary fake v.s. real classification is substantially easier than fine-grained deepfake trace detection; within the latter, performance degrades from natural language explanations (easiest), to spatial grounding, to temporal labeling (hardest). By foregrounding human-perceived deepfake traces, DeeptraceReward provides a rigorous testbed and training signal for socially aware and trustworthy video generation.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.319142"
    },
    {
        "index": "#4",
        "title": "Hierarchical Representation Matching for CLIP-based Class-Incremental Learning",
        "link": "/arxiv/2509.22645",
        "arxiv_id": "2509.22645",
        "authors": "Zhen-Hao Wen, Yan Wang, Ji Feng, Han-Jia Ye, De-Chuan Zhan, Da-Wei Zhou",
        "summary": "Class-Incremental Learning (CIL) aims to endow models with the ability to continuously adapt to evolving data streams. Recent advances in pre-trained vision-language models (e.g., CLIP) provide a powerful foundation for this task. However, existing approaches often rely on simplistic templates, such as \"a photo of a [CLASS]\", which overlook the hierarchical nature of visual concepts. For example, recognizing \"cat\" versus \"car\" depends on coarse-grained cues, while distinguishing \"cat\" from \"lion\" requires fine-grained details. Similarly, the current feature mapping in CLIP relies solely on the representation from the last layer, neglecting the hierarchical information contained in earlier layers. In this work, we introduce HiErarchical Representation MAtchiNg (HERMAN) for CLIP-based CIL. Our approach leverages LLMs to recursively generate discriminative textual descriptors, thereby augmenting the semantic space with explicit hierarchical cues. These descriptors are matched to different levels of the semantic hierarchy and adaptively routed based on task-specific requirements, enabling precise discrimination while alleviating catastrophic forgetting in incremental tasks. Extensive experiments on multiple benchmarks demonstrate that our method consistently achieves state-of-the-art performance.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.319646"
    },
    {
        "index": "#5",
        "title": "Scale-Wise VAR is Secretly Discrete Diffusion",
        "link": "/arxiv/2509.22636",
        "arxiv_id": "2509.22636",
        "authors": "Amandeep Kumar, Nithin Gopalakrishnan Nair, Vishal M. Patel",
        "summary": "Autoregressive (AR) transformers have emerged as a powerful paradigm for visual generation, largely due to their scalability, computational efficiency and unified architecture with language and vision. Among them, next scale prediction Visual Autoregressive Generation (VAR) has recently demonstrated remarkable performance, even surpassing diffusion-based models. In this work, we revisit VAR and uncover a theoretical insight: when equipped with a Markovian attention mask, VAR is mathematically equivalent to a discrete diffusion. We term this reinterpretation as Scalable Visual Refinement with Discrete Diffusion (SRDD), establishing a principled bridge between AR transformers and diffusion models. Leveraging this new perspective, we show how one can directly import the advantages of diffusion such as iterative refinement and reduce architectural inefficiencies into VAR, yielding faster convergence, lower inference cost, and improved zero-shot reconstruction. Across multiple datasets, we show that the diffusion based perspective of VAR leads to consistent gains in efficiency and generation.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.320124"
    },
    {
        "index": "#6",
        "title": "Training-Free Synthetic Data Generation with Dual IP-Adapter Guidance",
        "link": "/arxiv/2509.22635",
        "arxiv_id": "2509.22635",
        "authors": "Luc Boudier, Loris Manganelli, Eleftherios Tsonis, Nicolas Dufour, Vicky Kalogeiton",
        "summary": "Few-shot image classification remains challenging due to the limited availability of labeled examples. Recent approaches have explored generating synthetic training data using text-to-image diffusion models, but often require extensive model fine-tuning or external information sources. We present a novel training-free approach, called DIPSY, that leverages IP-Adapter for image-to-image translation to generate highly discriminative synthetic images using only the available few-shot examples. DIPSY introduces three key innovations: (1) an extended classifier-free guidance scheme that enables independent control over positive and negative image conditioning; (2) a class similarity-based sampling strategy that identifies effective contrastive examples; and (3) a simple yet effective pipeline that requires no model fine-tuning or external captioning and filtering. Experiments across ten benchmark datasets demonstrate that our approach achieves state-of-the-art or comparable performance, while eliminating the need for generative model adaptation or reliance on external tools for caption generation and image filtering. Our results highlight the effectiveness of leveraging dual image prompting with positive-negative guidance for generating class-discriminative features, particularly for fine-grained classification tasks.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.320595"
    },
    {
        "index": "#7",
        "title": "LABELING COPILOT: A Deep Research Agent for Automated Data Curation in Computer Vision",
        "link": "/arxiv/2509.22631",
        "arxiv_id": "2509.22631",
        "authors": "Debargha Ganguly, Sumit Kumar, Ishwar Balappanawar, Weicong Chen, Shashank Kambhatla, Srinivasan Iyengar, Shivkumar Kalyanaraman, Ponnurangam Kumaraguru, Vipin Chaudhary",
        "summary": "Curating high-quality, domain-specific datasets is a major bottleneck for deploying robust vision systems, requiring complex trade-offs between data quality, diversity, and cost when researching vast, unlabeled data lakes. We introduce Labeling Copilot, the first data curation deep research agent for computer vision. A central orchestrator agent, powered by a large multimodal language model, uses multi-step reasoning to execute specialized tools across three core capabilities: (1) Calibrated Discovery sources relevant, in-distribution data from large repositories; (2) Controllable Synthesis generates novel data for rare scenarios with robust filtering; and (3) Consensus Annotation produces accurate labels by orchestrating multiple foundation models via a novel consensus mechanism incorporating non-maximum suppression and voting. Our large-scale validation proves the effectiveness of Labeling Copilot's components. The Consensus Annotation module excels at object discovery: on the dense COCO dataset, it averages 14.2 candidate proposals per image-nearly double the 7.4 ground-truth objects-achieving a final annotation mAP of 37.1%. On the web-scale Open Images dataset, it navigated extreme class imbalance to discover 903 new bounding box categories, expanding its capability to over 1500 total. Concurrently, our Calibrated Discovery tool, tested at a 10-million sample scale, features an active learning strategy that is up to 40x more computationally efficient than alternatives with equivalent sample efficiency. These experiments validate that an agentic workflow with optimized, scalable tools provides a robust foundation for curating industrial-scale datasets.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.321129"
    },
    {
        "index": "#8",
        "title": "UML-CoT: Structured Reasoning and Planning with Unified Modeling Language for Robotic Room Cleaning",
        "link": "/arxiv/2509.22628",
        "arxiv_id": "2509.22628",
        "authors": "Hongyu Chen, Guangrun Wang",
        "summary": "Chain-of-Thought (CoT) prompting improves reasoning in large language models (LLMs), but its reliance on unstructured text limits interpretability and executability in embodied tasks. Prior work has explored structured CoTs using scene or logic graphs, yet these remain fundamentally limited: they model only low-order relations, lack constructs like inheritance or behavioral abstraction, and provide no standardized semantics for sequential or conditional planning. We propose UML-CoT, a structured reasoning and planning framework that leverages Unified Modeling Language (UML) to generate symbolic CoTs and executable action plans. UML class diagrams capture compositional object semantics, while activity diagrams model procedural control flow. Our three-stage training pipeline combines supervised fine-tuning with Group Relative Policy Optimization (GRPO), including reward learning from answer-only data. We evaluate UML-CoT on MRoom-30k, a new benchmark of cluttered room-cleaning scenarios. UML-CoT outperforms unstructured CoTs in interpretability, planning coherence, and execution success, highlighting UML as a more expressive and actionable structured reasoning formalism.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.321550"
    },
    {
        "index": "#9",
        "title": "CCNeXt: An Effective Self-Supervised Stereo Depth Estimation Approach",
        "link": "/arxiv/2509.22627",
        "arxiv_id": "2509.22627",
        "authors": "Alexandre Lopes, Roberto Souza, Helio Pedrini",
        "summary": "Depth Estimation plays a crucial role in recent applications in robotics, autonomous vehicles, and augmented reality. These scenarios commonly operate under constraints imposed by computational power. Stereo image pairs offer an effective solution for depth estimation since it only needs to estimate the disparity of pixels in image pairs to determine the depth in a known rectified system. Due to the difficulty in acquiring reliable ground-truth depth data across diverse scenarios, self-supervised techniques emerge as a solution, particularly when large unlabeled datasets are available. We propose a novel self-supervised convolutional approach that outperforms existing state-of-the-art Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) while balancing computational cost. The proposed CCNeXt architecture employs a modern CNN feature extractor with a novel windowed epipolar cross-attention module in the encoder, complemented by a comprehensive redesign of the depth estimation decoder. Our experiments demonstrate that CCNeXt achieves competitive metrics on the KITTI Eigen Split test data while being 10.18$\\times$ faster than the current best model and achieves state-of-the-art results in all metrics in the KITTI Eigen Split Improved Ground Truth and Driving Stereo datasets when compared to recently proposed techniques. To ensure complete reproducibility, our project is accessible at \\href{https://github.com/alelopes/CCNext}{\\texttt{https://github.com/alelopes/CCNext}}.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.321999"
    },
    {
        "index": "#10",
        "title": "SPARK: Synergistic Policy And Reward Co-Evolving Framework",
        "link": "/arxiv/2509.22624",
        "arxiv_id": "2509.22624",
        "authors": "Ziyu Liu, Yuhang Zang, Shengyuan Ding, Yuhang Cao, Xiaoyi Dong, Haodong Duan, Dahua Lin, Jiaqi Wang",
        "summary": "Recent Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) increasingly use Reinforcement Learning (RL) for post-pretraining, such as RL with Verifiable Rewards (RLVR) for objective tasks and RL from Human Feedback (RLHF) for subjective tasks. However, RLHF incurs high costs and potential reward-policy mismatch due to reliance on human preferences, while RLVR still wastes supervision by discarding rollouts and correctness signals after each update. To address these challenges, we introduce the Synergistic Policy And Reward Co-Evolving Framework (SPARK), an efficient, on-policy, and stable method that builds on RLVR. Instead of discarding rollouts and correctness data, SPARK recycles this valuable information to simultaneously train the model itself as a generative reward model. This auxiliary training uses a mix of objectives, such as pointwise reward score, pairwise comparison, and evaluation conditioned on further-reflection responses, to teach the model to evaluate and improve its own responses. Our process eliminates the need for a separate reward model and costly human preference data. SPARK creates a positive co-evolving feedback loop: improved reward accuracy yields better policy gradients, which in turn produce higher-quality rollouts that further refine the reward model. Our unified framework supports test-time scaling via self-reflection without external reward models and their associated costs. We show that SPARK achieves significant performance gains on multiple LLM and LVLM models and multiple reasoning, reward models, and general benchmarks. For example, SPARK-VL-7B achieves an average 9.7% gain on 7 reasoning benchmarks, 12.1% on 2 reward benchmarks, and 1.5% on 8 general benchmarks over the baselines, demonstrating robustness and broad generalization.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.327898"
    },
    {
        "index": "#11",
        "title": "LongLive: Real-time Interactive Long Video Generation",
        "link": "/arxiv/2509.22622",
        "arxiv_id": "2509.22622",
        "authors": "Shuai Yang, Wei Huang, Ruihang Chu, Yicheng Xiao, Yuyang Zhao, Xianbang Wang, Muyang Li, Enze Xie, Yingcong Chen, Yao Lu, Song Han, Yukang Chen",
        "summary": "We present LongLive, a frame-level autoregressive (AR) framework for real-time and interactive long video generation. Long video generation presents challenges in both efficiency and quality. Diffusion and Diffusion-Forcing models can produce high-quality videos but suffer from low efficiency due to bidirectional attention. Causal attention AR models support KV caching for faster inference, but often degrade in quality on long videos due to memory challenges during long-video training. In addition, beyond static prompt-based generation, interactive capabilities, such as streaming prompt inputs, are critical for dynamic content creation, enabling users to guide narratives in real time. This interactive requirement significantly increases complexity, especially in ensuring visual consistency and semantic coherence during prompt transitions. To address these challenges, LongLive adopts a causal, frame-level AR design that integrates a KV-recache mechanism that refreshes cached states with new prompts for smooth, adherent switches; streaming long tuning to enable long video training and to align training and inference (train-long-test-long); and short window attention paired with a frame-level attention sink, shorten as frame sink, preserving long-range consistency while enabling faster generation. With these key designs, LongLive fine-tunes a 1.3B-parameter short-clip model to minute-long generation in just 32 GPU-days. At inference, LongLive sustains 20.7 FPS on a single NVIDIA H100, achieves strong performance on VBench in both short and long videos. LongLive supports up to 240-second videos on a single H100 GPU. LongLive further supports INT8-quantized inference with only marginal quality loss.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.328630"
    },
    {
        "index": "#12",
        "title": "Vision-Language Alignment from Compressed Image Representations using 2D Gaussian Splatting",
        "link": "/arxiv/2509.22615",
        "arxiv_id": "2509.22615",
        "authors": "Yasmine Omri, Connor Ding, Tsachy Weissman, Thierry Tambe",
        "summary": "Modern vision language pipelines are driven by RGB vision encoders trained on massive image text corpora. While these pipelines have enabled impressive zero shot capabilities and strong transfer across tasks, they still inherit two structural inefficiencies from the pixel domain: (i) transmitting dense RGB images from edge devices to the cloud is energy intensive and costly, and (ii) patch based tokenization explodes sequence length, stressing attention budgets and context limits. We explore 2D Gaussian Splatting (2DGS) as an alternative visual substrate for alignment: a compact, spatially adaptive representation that parameterizes images by a set of colored anisotropic Gaussians. We develop a scalable 2DGS pipeline with structured initialization, luminance aware pruning, and batched CUDA kernels, achieving over 90x faster fitting and about 97% GPU utilization compared to prior implementations. We further adapt contrastive language image pretraining (CLIP) to 2DGS by reusing a frozen RGB-based transformer backbone with a lightweight splat aware input stem and a perceiver resampler, training only about 7% of the total parameters. On large DataComp subsets, GS encoders yield meaningful zero shot ImageNet-1K performance while compressing inputs 3 to 20x relative to pixels. While accuracy currently trails RGB encoders, our results establish 2DGS as a viable multimodal substrate, pinpoint architectural bottlenecks, and open a path toward representations that are both semantically powerful and transmission efficient for edge cloud learning.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.329264"
    },
    {
        "index": "#13",
        "title": "SpikeMatch: Semi-Supervised Learning with Temporal Dynamics of Spiking Neural Networks",
        "link": "/arxiv/2509.22581",
        "arxiv_id": "2509.22581",
        "authors": "Jini Yang, Beomseok Oh, Seungryong Kim, Sunok Kim",
        "summary": "Spiking neural networks (SNNs) have recently been attracting significant attention for their biological plausibility and energy efficiency, but semi-supervised learning (SSL) methods for SNN-based models remain underexplored compared to those for artificial neural networks (ANNs). In this paper, we introduce SpikeMatch, the first SSL framework for SNNs that leverages the temporal dynamics through the leakage factor of SNNs for diverse pseudo-labeling within a co-training framework. By utilizing agreement among multiple predictions from a single SNN, SpikeMatch generates reliable pseudo-labels from weakly-augmented unlabeled samples to train on strongly-augmented ones, effectively mitigating confirmation bias by capturing discriminative features with limited labels. Experiments show that SpikeMatch outperforms existing SSL methods adapted to SNN backbones across various standard benchmarks.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.329848"
    },
    {
        "index": "#14",
        "title": "JanusVLN: Decoupling Semantics and Spatiality with Dual Implicit Memory for Vision-Language Navigation",
        "link": "/arxiv/2509.22548",
        "arxiv_id": "2509.22548",
        "authors": "Shuang Zeng, Dekang Qi, Xinyuan Chang, Feng Xiong, Shichao Xie, Xiaolong Wu, Shiyi Liang, Mu Xu, Xing Wei",
        "summary": "Vision-and-Language Navigation requires an embodied agent to navigate through unseen environments, guided by natural language instructions and a continuous video stream. Recent advances in VLN have been driven by the powerful semantic understanding of Multimodal Large Language Models. However, these methods typically rely on explicit semantic memory, such as building textual cognitive maps or storing historical visual frames. This type of method suffers from spatial information loss, computational redundancy, and memory bloat, which impede efficient navigation. Inspired by the implicit scene representation in human navigation, analogous to the left brain's semantic understanding and the right brain's spatial cognition, we propose JanusVLN, a novel VLN framework featuring a dual implicit neural memory that models spatial-geometric and visual-semantic memory as separate, compact, and fixed-size neural representations. This framework first extends the MLLM to incorporate 3D prior knowledge from the spatial-geometric encoder, thereby enhancing the spatial reasoning capabilities of models based solely on RGB input. Then, the historical key-value caches from the spatial-geometric and visual-semantic encoders are constructed into a dual implicit memory. By retaining only the KVs of tokens in the initial and sliding window, redundant computation is avoided, enabling efficient incremental updates. Extensive experiments demonstrate that JanusVLN outperforms over 20 recent methods to achieve SOTA performance. For example, the success rate improves by 10.5-35.5 compared to methods using multiple data types as input and by 3.6-10.8 compared to methods using more RGB training data. This indicates that the proposed dual implicit neural memory, as a novel paradigm, explores promising new directions for future VLN research. Ours project page: https://miv-xjtu.github.io/JanusVLN.github.io/.",
        "subjects": "Computer Vision and Pattern Recognition, Robotics",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.330523"
    },
    {
        "index": "#15",
        "title": "HyCoVAD: A Hybrid SSL-LLM Model for Complex Video Anomaly Detection",
        "link": "/arxiv/2509.22544",
        "arxiv_id": "2509.22544",
        "authors": "Mohammad Mahdi Hemmatyar, Mahdi Jafari, Mohammad Amin Yousefi, Mohammad Reza Nemati, Mobin Azadani, Hamid Reza Rastad, Amirmohammad Akbari",
        "summary": "Video anomaly detection (VAD) is crucial for intelligent surveillance, but a significant challenge lies in identifying complex anomalies, which are events defined by intricate relationships and temporal dependencies among multiple entities rather than by isolated actions. While self-supervised learning (SSL) methods effectively model low-level spatiotemporal patterns, they often struggle to grasp the semantic meaning of these interactions. Conversely, large language models (LLMs) offer powerful contextual reasoning but are computationally expensive for frame-by-frame analysis and lack fine-grained spatial localization. We introduce HyCoVAD, Hybrid Complex Video Anomaly Detection, a hybrid SSL-LLM model that combines a multi-task SSL temporal analyzer with LLM validator. The SSL module is built upon an nnFormer backbone which is a transformer-based model for image segmentation. It is trained with multiple proxy tasks, learns from video frames to identify those suspected of anomaly. The selected frames are then forwarded to the LLM, which enriches the analysis with semantic context by applying structured, rule-based reasoning to validate the presence of anomalies. Experiments on the challenging ComplexVAD dataset show that HyCoVAD achieves a 72.5% frame-level AUC, outperforming existing baselines by 12.5% while reducing LLM computation. We release our interaction anomaly taxonomy, adaptive thresholding protocol, and code to facilitate future research in complex VAD scenarios.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.331143"
    },
    {
        "index": "#16",
        "title": "Category Discovery: An Open-World Perspective",
        "link": "/arxiv/2509.22542",
        "arxiv_id": "2509.22542",
        "authors": "Zhenqi He, Yuanpei Liu, Kai Han",
        "summary": "Category discovery (CD) is an emerging open-world learning task, which aims at automatically categorizing unlabelled data containing instances from unseen classes, given some labelled data from seen classes. This task has attracted significant attention over the years and leads to a rich body of literature trying to address the problem from different perspectives. In this survey, we provide a comprehensive review of the literature, and offer detailed analysis and in-depth discussion on different methods. Firstly, we introduce a taxonomy for the literature by considering two base settings, namely novel category discovery (NCD) and generalized category discovery (GCD), and several derived settings that are designed to address the extra challenges in different real-world application scenarios, including continual category discovery, skewed data distribution, federated category discovery, etc. Secondly, for each setting, we offer a detailed analysis of the methods encompassing three fundamental components, representation learning, label assignment, and estimation of class number. Thirdly, we benchmark all the methods and distill key insights showing that large-scale pretrained backbones, hierarchical and auxiliary cues, and curriculum-style training are all beneficial for category discovery, while challenges remain in the design of label assignment, the estimation of class numbers, and scaling to complex multi-object scenarios.Finally, we discuss the key insights from the literature so far and point out promising future research directions. We compile a living survey of the category discovery literature at \\href{https://github.com/Visual-AI/Category-Discovery}{https://github.com/Visual-AI/Category-Discovery}.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.331698"
    },
    {
        "index": "#17",
        "title": "EfficientDepth: A Fast and Detail-Preserving Monocular Depth Estimation Model",
        "link": "/arxiv/2509.22527",
        "arxiv_id": "2509.22527",
        "authors": "Andrii Litvynchuk, Ivan Livinsky, Anand Ravi, Nima Kalantari, Andrii Tsarov",
        "summary": "Monocular depth estimation (MDE) plays a pivotal role in various computer vision applications, such as robotics, augmented reality, and autonomous driving. Despite recent advancements, existing methods often fail to meet key requirements for 3D reconstruction and view synthesis, including geometric consistency, fine details, robustness to real-world challenges like reflective surfaces, and efficiency for edge devices. To address these challenges, we introduce a novel MDE system, called EfficientDepth, which combines a transformer architecture with a lightweight convolutional decoder, as well as a bimodal density head that allows the network to estimate detailed depth maps. We train our model on a combination of labeled synthetic and real images, as well as pseudo-labeled real images, generated using a high-performing MDE method. Furthermore, we employ a multi-stage optimization strategy to improve training efficiency and produce models that emphasize geometric consistency and fine detail. Finally, in addition to commonly used objectives, we introduce a loss function based on LPIPS to encourage the network to produce detailed depth maps. Experimental results demonstrate that EfficientDepth achieves performance comparable to or better than existing state-of-the-art models, with significantly reduced computational resources.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.332259"
    },
    {
        "index": "#18",
        "title": "Color Names in Vision-Language Models",
        "link": "/arxiv/2509.22524",
        "arxiv_id": "2509.22524",
        "authors": "Alexandra Gomez-Villa, Pablo Hernández-Cámara, Muhammad Atif Butt, Valero Laparra, Jesus Malo, Javier Vazquez-Corral",
        "summary": "Color serves as a fundamental dimension of human visual perception and a primary means of communicating about objects and scenes. As vision-language models (VLMs) become increasingly prevalent, understanding whether they name colors like humans is crucial for effective human-AI interaction. We present the first systematic evaluation of color naming capabilities across VLMs, replicating classic color naming methodologies using 957 color samples across five representative models. Our results show that while VLMs achieve high accuracy on prototypical colors from classical studies, performance drops significantly on expanded, non-prototypical color sets. We identify 21 common color terms that consistently emerge across all models, revealing two distinct approaches: constrained models using predominantly basic terms versus expansive models employing systematic lightness modifiers. Cross-linguistic analysis across nine languages demonstrates severe training imbalances favoring English and Chinese, with hue serving as the primary driver of color naming decisions. Finally, ablation studies reveal that language model architecture significantly influences color naming independent of visual processing capabilities.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.337877"
    },
    {
        "index": "#19",
        "title": "Where MLLMs Attend and What They Rely On: Explaining Autoregressive Token Generation",
        "link": "/arxiv/2509.22496",
        "arxiv_id": "2509.22496",
        "authors": "Ruoyu Chen, Xiaoqing Guo, Kangwei Liu, Siyuan Liang, Shiming Liu, Qunli Zhang, Hua Zhang, Xiaochun Cao",
        "summary": "Multimodal large language models (MLLMs) have demonstrated remarkable capabilities in aligning visual inputs with natural language outputs. Yet, the extent to which generated tokens depend on visual modalities remains poorly understood, limiting interpretability and reliability. In this work, we present EAGLE, a lightweight black-box framework for explaining autoregressive token generation in MLLMs. EAGLE attributes any selected tokens to compact perceptual regions while quantifying the relative influence of language priors and perceptual evidence. The framework introduces an objective function that unifies sufficiency (insight score) and indispensability (necessity score), optimized via greedy search over sparsified image regions for faithful and efficient attribution. Beyond spatial attribution, EAGLE performs modality-aware analysis that disentangles what tokens rely on, providing fine-grained interpretability of model decisions. Extensive experiments across open-source MLLMs show that EAGLE consistently outperforms existing methods in faithfulness, localization, and hallucination diagnosis, while requiring substantially less GPU memory. These results highlight its effectiveness and practicality for advancing the interpretability of MLLMs. The code is available at https://github.com/RuoyuChen10/EAGLE.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.338383"
    },
    {
        "index": "#20",
        "title": "Group Critical-token Policy Optimization for Autoregressive Image Generation",
        "link": "/arxiv/2509.22485",
        "arxiv_id": "2509.22485",
        "authors": "Guohui Zhang, Hu Yu, Xiaoxiao Ma, JingHao Zhang, Yaning Pan, Mingde Yao, Jie Xiao, Linjiang Huang, Feng Zhao",
        "summary": "Recent studies have extended Reinforcement Learning with Verifiable Rewards (RLVR) to autoregressive (AR) visual generation and achieved promising progress. However, existing methods typically apply uniform optimization across all image tokens, while the varying contributions of different image tokens for RLVR's training remain unexplored. In fact, the key obstacle lies in how to identify more critical image tokens during AR generation and implement effective token-wise optimization for them. To tackle this challenge, we propose $\\textbf{G}$roup $\\textbf{C}$ritical-token $\\textbf{P}$olicy $\\textbf{O}$ptimization ($\\textbf{GCPO}$), which facilitates effective policy optimization on critical tokens. We identify the critical tokens in RLVR-based AR generation from three perspectives, specifically: $\\textbf{(1)}$ Causal dependency: early tokens fundamentally determine the later tokens and final image effect due to unidirectional dependency; $\\textbf{(2)}$ Entropy-induced spatial structure: tokens with high entropy gradients correspond to image structure and bridges distinct visual regions; $\\textbf{(3)}$ RLVR-focused token diversity: tokens with low visual similarity across a group of sampled images contribute to richer token-level diversity. For these identified critical tokens, we further introduce a dynamic token-wise advantage weight to encourage exploration, based on confidence divergence between the policy model and reference model. By leveraging 30\\% of the image tokens, GCPO achieves better performance than GRPO with full tokens. Extensive experiments on multiple text-to-image benchmarks for both AR models and unified multimodal models demonstrate the effectiveness of GCPO for AR visual generation.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.338913"
    },
    {
        "index": "#21",
        "title": "PSTTS: A Plug-and-Play Token Selector for Efficient Event-based Spatio-temporal Representation Learning",
        "link": "/arxiv/2509.22481",
        "arxiv_id": "2509.22481",
        "authors": "Xiangmo Zhao, Nan Yang, Yang Wang, Zhanwen Liu",
        "summary": "Mainstream event-based spatio-temporal representation learning methods typically process event streams by converting them into sequences of event frames, achieving remarkable performance. However, they neglect the high spatial sparsity and inter-frame motion redundancy inherent in event frame sequences, leading to significant computational overhead. Existing token sparsification methods for RGB videos rely on unreliable intermediate token representations and neglect the influence of event noise, making them ineffective for direct application to event data. In this paper, we propose Progressive Spatio-Temporal Token Selection (PSTTS), a Plug-and-Play module for event data without introducing any additional parameters. PSTTS exploits the spatio-temporal distribution characteristics embedded in raw event data to effectively identify and discard spatio-temporal redundant tokens, achieving an optimal trade-off between accuracy and efficiency. Specifically, PSTTS consists of two stages, Spatial Token Purification and Temporal Token Selection. Spatial Token Purification discards noise and non-event regions by assessing the spatio-temporal consistency of events within each event frame to prevent interference with subsequent temporal redundancy evaluation. Temporal Token Selection evaluates the motion pattern similarity between adjacent event frames, precisely identifying and removing redundant temporal information. We apply PSTTS to four representative backbones UniformerV2, VideoSwin, EVMamba, and ExACT on the HARDVS, DailyDVS-200, and SeACT datasets. Experimental results demonstrate that PSTTS achieves significant efficiency improvements. Specifically, PSTTS reduces FLOPs by 29-43.6% and increases FPS by 21.6-41.3% on the DailyDVS-200 dataset, while maintaining task accuracy. Our code will be available.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.339367"
    },
    {
        "index": "#22",
        "title": "Bézier Meets Diffusion: Robust Generation Across Domains for Medical Image Segmentation",
        "link": "/arxiv/2509.22476",
        "arxiv_id": "2509.22476",
        "authors": "Chen Li, Meilong Xu, Xiaoling Hu, Weimin Lyu, Chao Chen",
        "summary": "Training robust learning algorithms across different medical imaging modalities is challenging due to the large domain gap. Unsupervised domain adaptation (UDA) mitigates this problem by using annotated images from the source domain and unlabeled images from the target domain to train the deep models. Existing approaches often rely on GAN-based style transfer, but these methods struggle to capture cross-domain mappings in regions with high variability. In this paper, we propose a unified framework, Bézier Meets Diffusion, for cross-domain image generation. First, we introduce a Bézier-curve-based style transfer strategy that effectively reduces the domain gap between source and target domains. The transferred source images enable the training of a more robust segmentation model across domains. Thereafter, using pseudo-labels generated by this segmentation model on the target domain, we train a conditional diffusion model (CDM) to synthesize high-quality, labeled target-domain images. To mitigate the impact of noisy pseudo-labels, we further develop an uncertainty-guided score matching method that improves the robustness of CDM training. Extensive experiments on public datasets demonstrate that our approach generates realistic labeled images, significantly augmenting the target domain and improving segmentation performance.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.339863"
    },
    {
        "index": "#23",
        "title": "SSVIF: Self-Supervised Segmentation-Oriented Visible and Infrared Image Fusion",
        "link": "/arxiv/2509.22450",
        "arxiv_id": "2509.22450",
        "authors": "Zixian Zhao, Xingchen Zhang",
        "summary": "Visible and infrared image fusion (VIF) has gained significant attention in recent years due to its wide application in tasks such as scene segmentation and object detection. VIF methods can be broadly classified into traditional VIF methods and application-oriented VIF methods. Traditional methods focus solely on improving the quality of fused images, while application-oriented VIF methods additionally consider the performance of downstream tasks on fused images by introducing task-specific loss terms during training. However, compared to traditional methods, application-oriented VIF methods require datasets labeled for downstream tasks (e.g., semantic segmentation or object detection), making data acquisition labor-intensive and time-consuming. To address this issue, we propose a self-supervised training framework for segmentation-oriented VIF methods (SSVIF). Leveraging the consistency between feature-level fusion-based segmentation and pixel-level fusion-based segmentation, we introduce a novel self-supervised task-cross-segmentation consistency-that enables the fusion model to learn high-level semantic features without the supervision of segmentation labels. Additionally, we design a two-stage training strategy and a dynamic weight adjustment method for effective joint learning within our self-supervised framework. Extensive experiments on public datasets demonstrate the effectiveness of our proposed SSVIF. Remarkably, although trained only on unlabeled visible-infrared image pairs, our SSVIF outperforms traditional VIF methods and rivals supervised segmentation-oriented ones. Our code will be released upon acceptance.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.340289"
    },
    {
        "index": "#24",
        "title": "$γ$-Quant: Towards Learnable Quantization for Low-bit Pattern Recognition",
        "link": "/arxiv/2509.22448",
        "arxiv_id": "2509.22448",
        "authors": "Mishal Fatima, Shashank Agnihotri, Marius Bock, Kanchana Vaishnavi Gandikota, Kristof Van Laerhoven, Michael Moeller, Margret Keuper",
        "summary": "Most pattern recognition models are developed on pre-proce\\-ssed data. In computer vision, for instance, RGB images processed through image signal processing (ISP) pipelines designed to cater to human perception are the most frequent input to image analysis networks. However, many modern vision tasks operate without a human in the loop, raising the question of whether such pre-processing is optimal for automated analysis. Similarly, human activity recognition (HAR) on body-worn sensor data commonly takes normalized floating-point data arising from a high-bit analog-to-digital converter (ADC) as an input, despite such an approach being highly inefficient in terms of data transmission, significantly affecting the battery life of wearable devices. In this work, we target low-bandwidth and energy-constrained settings where sensors are limited to low-bit-depth capture. We propose $\\gamma$-Quant, i.e.~the task-specific learning of a non-linear quantization for pattern recognition. We exemplify our approach on raw-image object detection as well as HAR of wearable data, and demonstrate that raw data with a learnable quantization using as few as 4-bits can perform on par with the use of raw 12-bit data. All code to reproduce our experiments is publicly available via https://github.com/Mishalfatima/Gamma-Quant",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.340781"
    },
    {
        "index": "#25",
        "title": "U-MAN: U-Net with Multi-scale Adaptive KAN Network for Medical Image Segmentation",
        "link": "/arxiv/2509.22444",
        "arxiv_id": "2509.22444",
        "authors": "Bohan Huang, Qianyun Bao, Haoyuan Ma",
        "summary": "Medical image segmentation faces significant challenges in preserving fine-grained details and precise boundaries due to complex anatomical structures and pathological regions. These challenges primarily stem from two key limitations of conventional U-Net architectures: (1) their simple skip connections ignore the encoder-decoder semantic gap between various features, and (2) they lack the capability for multi-scale feature extraction in deep layers. To address these challenges, we propose the U-Net with Multi-scale Adaptive KAN (U-MAN), a novel architecture that enhances the emerging Kolmogorov-Arnold Network (KAN) with two specialized modules: Progressive Attention-Guided Feature Fusion (PAGF) and the Multi-scale Adaptive KAN (MAN). Our PAGF module replaces the simple skip connection, using attention to fuse features from the encoder and decoder. The MAN module enables the network to adaptively process features at multiple scales, improving its ability to segment objects of various sizes. Experiments on three public datasets (BUSI, GLAS, and CVC) show that U-MAN outperforms state-of-the-art methods, particularly in defining accurate boundaries and preserving fine details.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.341214"
    },
    {
        "index": "#26",
        "title": "Explaining multimodal LLMs via intra-modal token interactions",
        "link": "/arxiv/2509.22415",
        "arxiv_id": "2509.22415",
        "authors": "Jiawei Liang, Ruoyu Chen, Xianghao Jiao, Siyuan Liang, Shiming Liu, Qunli Zhang, Zheng Hu, Xiaochun Cao",
        "summary": "Multimodal Large Language Models (MLLMs) have achieved remarkable success across diverse vision-language tasks, yet their internal decision-making mechanisms remain insufficiently understood. Existing interpretability research has primarily focused on cross-modal attribution, identifying which image regions the model attends to during output generation. However, these approaches often overlook intra-modal dependencies. In the visual modality, attributing importance to isolated image patches ignores spatial context due to limited receptive fields, resulting in fragmented and noisy explanations. In the textual modality, reliance on preceding tokens introduces spurious activations. Failing to effectively mitigate these interference compromises attribution fidelity. To address these limitations, we propose enhancing interpretability by leveraging intra-modal interaction. For the visual branch, we introduce \\textit{Multi-Scale Explanation Aggregation} (MSEA), which aggregates attributions over multi-scale inputs to dynamically adjust receptive fields, producing more holistic and spatially coherent visual explanations. For the textual branch, we propose \\textit{Activation Ranking Correlation} (ARC), which measures the relevance of contextual tokens to the current token via alignment of their top-$k$ prediction rankings. ARC leverages this relevance to suppress spurious activations from irrelevant contexts while preserving semantically coherent ones. Extensive experiments across state-of-the-art MLLMs and benchmark datasets demonstrate that our approach consistently outperforms existing interpretability methods, yielding more faithful and fine-grained explanations of model behavior.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.341746"
    },
    {
        "index": "#27",
        "title": "LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer",
        "link": "/arxiv/2509.22414",
        "arxiv_id": "2509.22414",
        "authors": "Song Fei, Tian Ye, Lujia Wang, Lei Zhu",
        "summary": "Universal image restoration (UIR) aims to recover images degraded by unknown mixtures while preserving semantics -- conditions under which discriminative restorers and UNet-based diffusion priors often oversmooth, hallucinate, or drift. We present LucidFlux, a caption-free UIR framework that adapts a large diffusion transformer (Flux.1) without image captions. LucidFlux introduces a lightweight dual-branch conditioner that injects signals from the degraded input and a lightly restored proxy to respectively anchor geometry and suppress artifacts. Then, a timestep- and layer-adaptive modulation schedule is designed to route these cues across the backbone's hierarchy, in order to yield coarse-to-fine and context-aware updates that protect the global structure while recovering texture. After that, to avoid the latency and instability of text prompts or MLLM captions, we enforce caption-free semantic alignment via SigLIP features extracted from the proxy. A scalable curation pipeline further filters large-scale data for structure-rich supervision. Across synthetic and in-the-wild benchmarks, LucidFlux consistently outperforms strong open-source and commercial baselines, and ablation studies verify the necessity of each component. LucidFlux shows that, for large DiTs, when, where, and what to condition on -- rather than adding parameters or relying on text prompts -- is the governing lever for robust and caption-free universal image restoration in the wild.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.342201"
    },
    {
        "index": "#28",
        "title": "FreqDebias: Towards Generalizable Deepfake Detection via Consistency-Driven Frequency Debiasing",
        "link": "/arxiv/2509.22412",
        "arxiv_id": "2509.22412",
        "authors": "Hossein Kashiani, Niloufar Alipour Talemi, Fatemeh Afghah",
        "summary": "Deepfake detectors often struggle to generalize to novel forgery types due to biases learned from limited training data. In this paper, we identify a new type of model bias in the frequency domain, termed spectral bias, where detectors overly rely on specific frequency bands, restricting their ability to generalize across unseen forgeries. To address this, we propose FreqDebias, a frequency debiasing framework that mitigates spectral bias through two complementary strategies. First, we introduce a novel Forgery Mixup (Fo-Mixup) augmentation, which dynamically diversifies frequency characteristics of training samples. Second, we incorporate a dual consistency regularization (CR), which enforces both local consistency using class activation maps (CAMs) and global consistency through a von Mises-Fisher (vMF) distribution on a hyperspherical embedding space. This dual CR mitigates over-reliance on certain frequency components by promoting consistent representation learning under both local and global supervision. Extensive experiments show that FreqDebias significantly enhances cross-domain generalization and outperforms state-of-the-art methods in both cross-domain and in-domain settings.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.347781"
    },
    {
        "index": "#29",
        "title": "RAU: Reference-based Anatomical Understanding with Vision Language Models",
        "link": "/arxiv/2509.22404",
        "arxiv_id": "2509.22404",
        "authors": "Yiwei Li, Yikang Liu, Jiaqi Guo, Lin Zhao, Zheyuan Zhang, Xiao Chen, Boris Mailhe, Ankush Mukherjee, Terrence Chen, Shanhui Sun",
        "summary": "Anatomical understanding through deep learning is critical for automatic report generation, intra-operative navigation, and organ localization in medical imaging; however, its progress is constrained by the scarcity of expert-labeled data. A promising remedy is to leverage an annotated reference image to guide the interpretation of an unlabeled target. Although recent vision-language models (VLMs) exhibit non-trivial visual reasoning, their reference-based understanding and fine-grained localization remain limited. We introduce RAU, a framework for reference-based anatomical understanding with VLMs. We first show that a VLM learns to identify anatomical regions through relative spatial reasoning between reference and target images, trained on a moderately sized dataset. We validate this capability through visual question answering (VQA) and bounding box prediction. Next, we demonstrate that the VLM-derived spatial cues can be seamlessly integrated with the fine-grained segmentation capability of SAM2, enabling localization and pixel-level segmentation of small anatomical regions, such as vessel segments. Across two in-distribution and two out-of-distribution datasets, RAU consistently outperforms a SAM2 fine-tuning baseline using the same memory setup, yielding more accurate segmentations and more reliable localization. More importantly, its strong generalization ability makes it scalable to out-of-distribution datasets, a property crucial for medical image applications. To the best of our knowledge, RAU is the first to explore the capability of VLMs for reference-based identification, localization, and segmentation of anatomical structures in medical images. Its promising performance highlights the potential of VLM-driven approaches for anatomical understanding in automated clinical workflows.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.348340"
    },
    {
        "index": "#30",
        "title": "Closing the Safety Gap: Surgical Concept Erasure in Visual Autoregressive Models",
        "link": "/arxiv/2509.22400",
        "arxiv_id": "2509.22400",
        "authors": "Xinhao Zhong, Yimin Zhou, Zhiqi Zhang, Junhao Li, Yi Sun, Bin Chen, Shu-Tao Xia, Ke Xu",
        "summary": "The rapid progress of visual autoregressive (VAR) models has brought new opportunities for text-to-image generation, but also heightened safety concerns. Existing concept erasure techniques, primarily designed for diffusion models, fail to generalize to VARs due to their next-scale token prediction paradigm. In this paper, we first propose a novel VAR Erasure framework VARE that enables stable concept erasure in VAR models by leveraging auxiliary visual tokens to reduce fine-tuning intensity. Building upon this, we introduce S-VARE, a novel and effective concept erasure method designed for VAR, which incorporates a filtered cross entropy loss to precisely identify and minimally adjust unsafe visual tokens, along with a preservation loss to maintain semantic fidelity, addressing the issues such as language drift and reduced diversity introduce by naïve fine-tuning. Extensive experiments demonstrate that our approach achieves surgical concept erasure while preserving generation quality, thereby closing the safety gap in autoregressive text-to-image generation by earlier methods.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.348854"
    },
    {
        "index": "#31",
        "title": "Integrating Background Knowledge in Medical Semantic Segmentation with Logic Tensor Networks",
        "link": "/arxiv/2509.22399",
        "arxiv_id": "2509.22399",
        "authors": "Luca Bergamin, Giovanna Maria Dimitri, Fabio Aiolli",
        "summary": "Semantic segmentation is a fundamental task in medical image analysis, aiding medical decision-making by helping radiologists distinguish objects in an image. Research in this field has been driven by deep learning applications, which have the potential to scale these systems even in the presence of noise and artifacts. However, these systems are not yet perfected. We argue that performance can be improved by incorporating common medical knowledge into the segmentation model's loss function. To this end, we introduce Logic Tensor Networks (LTNs) to encode medical background knowledge using first-order logic (FOL) rules. The encoded rules span from constraints on the shape of the produced segmentation, to relationships between different segmented areas. We apply LTNs in an end-to-end framework with a SwinUNETR for semantic segmentation. We evaluate our method on the task of segmenting the hippocampus in brain MRI scans. Our experiments show that LTNs improve the baseline segmentation performance, especially when training data is scarce. Despite being in its preliminary stages, we argue that neurosymbolic methods are general enough to be adapted and applied to other medical semantic segmentation tasks.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.349304"
    },
    {
        "index": "#32",
        "title": "Text Adversarial Attacks with Dynamic Outputs",
        "link": "/arxiv/2509.22393",
        "arxiv_id": "2509.22393",
        "authors": "Wenqiang Wang, Siyuan Liang, Xiao Yan, Xiaochun Cao",
        "summary": "Text adversarial attack methods are typically designed for static scenarios with fixed numbers of output labels and a predefined label space, relying on extensive querying of the victim model (query-based attacks) or the surrogate model (transfer-based attacks). To address this gap, we introduce the Textual Dynamic Outputs Attack (TDOA) method, which employs a clustering-based surrogate model training approach to convert the dynamic-output scenario into a static single-output scenario. To improve attack effectiveness, we propose the farthest-label targeted attack strategy, which selects adversarial vectors that deviate most from the model's coarse-grained labels, thereby maximizing disruption. We extensively evaluate TDOA on four datasets and eight victim models (e.g., ChatGPT-4o, ChatGPT-4.1), showing its effectiveness in crafting adversarial examples and its strong potential to compromise large language models with limited access. With a single query per text, TDOA achieves a maximum attack success rate of 50.81\\%. Additionally, we find that TDOA also achieves state-of-the-art performance in conventional static output scenarios, reaching a maximum ASR of 82.68\\%. Meanwhile, by conceptualizing translation tasks as classification problems with unbounded output spaces, we extend the TDOA framework to generative settings, surpassing prior results by up to 0.64 RDBLEU and 0.62 RDchrF.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.349748"
    },
    {
        "index": "#33",
        "title": "Gradient-based multi-focus image fusion with focus-aware saliency enhancement",
        "link": "/arxiv/2509.22392",
        "arxiv_id": "2509.22392",
        "authors": "Haoyu Li, XiaoSong Li",
        "summary": "Multi-focus image fusion (MFIF) aims to yield an all-focused image from multiple partially focused inputs, which is crucial in applications cover sur-veillance, microscopy, and computational photography. However, existing methods struggle to preserve sharp focus-defocus boundaries, often resulting in blurred transitions and focused details loss. To solve this problem, we propose a MFIF method based on significant boundary enhancement, which generates high-quality fused boundaries while effectively detecting focus in-formation. Particularly, we propose a gradient-domain-based model that can obtain initial fusion results with complete boundaries and effectively pre-serve the boundary details. Additionally, we introduce Tenengrad gradient detection to extract salient features from both the source images and the ini-tial fused image, generating the corresponding saliency maps. For boundary refinement, we develop a focus metric based on gradient and complementary information, integrating the salient features with the complementary infor-mation across images to emphasize focused regions and produce a high-quality initial decision result. Extensive experiments on four public datasets demonstrate that our method consistently outperforms 12 state-of-the-art methods in both subjective and objective evaluations. We have realized codes in https://github.com/Lihyua/GICI",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.350175"
    },
    {
        "index": "#34",
        "title": "GPT-4 for Occlusion Order Recovery",
        "link": "/arxiv/2509.22383",
        "arxiv_id": "2509.22383",
        "authors": "Kaziwa Saleh, Zhyar Rzgar K Rostam, Sándor Szénási, Zoltán Vámossy",
        "summary": "Occlusion remains a significant challenge for current vision models to robustly interpret complex and dense real-world images and scenes. To address this limitation and to enable accurate prediction of the occlusion order relationship between objects, we propose leveraging the advanced capability of a pre-trained GPT-4 model to deduce the order. By providing a specifically designed prompt along with the input image, GPT-4 can analyze the image and generate order predictions. The response can then be parsed to construct an occlusion matrix which can be utilized in assisting with other occlusion handling tasks and image understanding. We report the results of evaluating the model on COCOA and InstaOrder datasets. The results show that by using semantic context, visual patterns, and commonsense knowledge, the model can produce more accurate order predictions. Unlike baseline methods, the model can reason about occlusion relationships in a zero-shot fashion, which requires no annotated training data and can easily be integrated into occlusion handling frameworks.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.350628"
    },
    {
        "index": "#35",
        "title": "Effectiveness of Large Multimodal Models in Detecting Disinformation: Experimental Results",
        "link": "/arxiv/2509.22377",
        "arxiv_id": "2509.22377",
        "authors": "Yasmina Kheddache, Marc Lalonde",
        "summary": "The proliferation of disinformation, particularly in multimodal contexts combining text and images, presents a significant challenge across digital platforms. This study investigates the potential of large multimodal models (LMMs) in detecting and mitigating false information. We propose to approach multimodal disinformation detection by leveraging the advanced capabilities of the GPT-4o model. Our contributions include: (1) the development of an optimized prompt incorporating advanced prompt engineering techniques to ensure precise and consistent evaluations; (2) the implementation of a structured framework for multimodal analysis, including a preprocessing methodology for images and text to comply with the model's token limitations; (3) the definition of six specific evaluation criteria that enable a fine-grained classification of content, complemented by a self-assessment mechanism based on confidence levels; (4) a comprehensive performance analysis of the model across multiple heterogeneous datasets Gossipcop, Politifact, Fakeddit, MMFakeBench, and AMMEBA highlighting GPT-4o's strengths and limitations in disinformation detection; (5) an investigation of prediction variability through repeated testing, evaluating the stability and reliability of the model's classifications; and (6) the introduction of confidence-level and variability-based evaluation methods. These contributions provide a robust and reproducible methodological framework for automated multimodal disinformation analysis.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.351059"
    },
    {
        "index": "#36",
        "title": "HierLight-YOLO: A Hierarchical and Lightweight Object Detection Network for UAV Photography",
        "link": "/arxiv/2509.22365",
        "arxiv_id": "2509.22365",
        "authors": "Defan Chen, Yaohua Hu, Luchan Zhang",
        "summary": "The real-time detection of small objects in complex scenes, such as the unmanned aerial vehicle (UAV) photography captured by drones, has dual challenges of detecting small targets (<32 pixels) and maintaining real-time efficiency on resource-constrained platforms. While YOLO-series detectors have achieved remarkable success in real-time large object detection, they suffer from significantly higher false negative rates for drone-based detection where small objects dominate, compared to large object scenarios. This paper proposes HierLight-YOLO, a hierarchical feature fusion and lightweight model that enhances the real-time detection of small objects, based on the YOLOv8 architecture. We propose the Hierarchical Extended Path Aggregation Network (HEPAN), a multi-scale feature fusion method through hierarchical cross-level connections, enhancing the small object detection accuracy. HierLight-YOLO includes two innovative lightweight modules: Inverted Residual Depthwise Convolution Block (IRDCB) and Lightweight Downsample (LDown) module, which significantly reduce the model's parameters and computational complexity without sacrificing detection capabilities. Small object detection head is designed to further enhance spatial resolution and feature fusion to tackle the tiny object (4 pixels) detection. Comparison experiments and ablation studies on the VisDrone2019 benchmark demonstrate state-of-the-art performance of HierLight-YOLO.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.351493"
    },
    {
        "index": "#37",
        "title": "CircuitSense: A Hierarchical Circuit System Benchmark Bridging Visual Comprehension and Symbolic Reasoning in Engineering Design Process",
        "link": "/arxiv/2509.22339",
        "arxiv_id": "2509.22339",
        "authors": "Arman Akbari, Jian Gao, Yifei Zou, Mei Yang, Jinru Duan, Dmitrii Torbunov, Yanzhi Wang, Yihui Ren, Xuan Zhang",
        "summary": "Engineering design operates through hierarchical abstraction from system specifications to component implementations, requiring visual understanding coupled with mathematical reasoning at each level. While Multi-modal Large Language Models (MLLMs) excel at natural image tasks, their ability to extract mathematical models from technical diagrams remains unexplored. We present \\textbf{CircuitSense}, a comprehensive benchmark evaluating circuit understanding across this hierarchy through 8,006+ problems spanning component-level schematics to system-level block diagrams. Our benchmark uniquely examines the complete engineering workflow: Perception, Analysis, and Design, with a particular emphasis on the critical but underexplored capability of deriving symbolic equations from visual inputs. We introduce a hierarchical synthetic generation pipeline consisting of a grid-based schematic generator and a block diagram generator with auto-derived symbolic equation labels. Comprehensive evaluation of six state-of-the-art MLLMs, including both closed-source and open-source models, reveals fundamental limitations in visual-to-mathematical reasoning. Closed-source models achieve over 85\\% accuracy on perception tasks involving component recognition and topology identification, yet their performance on symbolic derivation and analytical reasoning falls below 19\\%, exposing a critical gap between visual parsing and symbolic reasoning. Models with stronger symbolic reasoning capabilities consistently achieve higher design task accuracy, confirming the fundamental role of mathematical understanding in circuit synthesis and establishing symbolic reasoning as the key metric for engineering competence.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.352037"
    },
    {
        "index": "#38",
        "title": "Pedestrian Attribute Recognition via Hierarchical Cross-Modality HyperGraph Learning",
        "link": "/arxiv/2509.22331",
        "arxiv_id": "2509.22331",
        "authors": "Xiao Wang, Shujuan Wu, Xiaoxia Cheng, Changwei Bi, Jin Tang, Bin Luo",
        "summary": "Current Pedestrian Attribute Recognition (PAR) algorithms typically focus on mapping visual features to semantic labels or attempt to enhance learning by fusing visual and attribute information. However, these methods fail to fully exploit attribute knowledge and contextual information for more accurate recognition. Although recent works have started to consider using attribute text as additional input to enhance the association between visual and semantic information, these methods are still in their infancy. To address the above challenges, this paper proposes the construction of a multi-modal knowledge graph, which is utilized to mine the relationships between local visual features and text, as well as the relationships between attributes and extensive visual context samples. Specifically, we propose an effective multi-modal knowledge graph construction method that fully considers the relationships among attributes and the relationships between attributes and vision tokens. To effectively model these relationships, this paper introduces a knowledge graph-guided cross-modal hypergraph learning framework to enhance the standard pedestrian attribute recognition framework. Comprehensive experiments on multiple PAR benchmark datasets have thoroughly demonstrated the effectiveness of our proposed knowledge graph for the PAR task, establishing a strong foundation for knowledge-guided pedestrian attribute recognition. The source code of this paper will be released on https://github.com/Event-AHU/OpenPAR",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.352547"
    },
    {
        "index": "#39",
        "title": "RAPID^3: Tri-Level Reinforced Acceleration Policies for Diffusion Transformer",
        "link": "/arxiv/2509.22323",
        "arxiv_id": "2509.22323",
        "authors": "Wangbo Zhao, Yizeng Han, Zhiwei Tang, Jiasheng Tang, Pengfei Zhou, Kai Wang, Bohan Zhuang, Zhangyang Wang, Fan Wang, Yang You",
        "summary": "Diffusion Transformers (DiTs) excel at visual generation yet remain hampered by slow sampling. Existing training-free accelerators - step reduction, feature caching, and sparse attention - enhance inference speed but typically rely on a uniform heuristic or a manually designed adaptive strategy for all images, leaving quality on the table. Alternatively, dynamic neural networks offer per-image adaptive acceleration, but their high fine-tuning costs limit broader applicability. To address these limitations, we introduce RAPID3: Tri-Level Reinforced Acceleration Policies for Diffusion Transformers, a framework that delivers image-wise acceleration with zero updates to the base generator. Specifically, three lightweight policy heads - Step-Skip, Cache-Reuse, and Sparse-Attention - observe the current denoising state and independently decide their corresponding speed-up at each timestep. All policy parameters are trained online via Group Relative Policy Optimization (GRPO) while the generator remains frozen. Meanwhile, an adversarially learned discriminator augments the reward signal, discouraging reward hacking by boosting returns only when generated samples stay close to the original model's distribution. Across state-of-the-art DiT backbones, including Stable Diffusion 3 and FLUX, RAPID3 achieves nearly 3x faster sampling with competitive generation quality.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.358133"
    },
    {
        "index": "#40",
        "title": "NIFTY: a Non-Local Image Flow Matching for Texture Synthesis",
        "link": "/arxiv/2509.22318",
        "arxiv_id": "2509.22318",
        "authors": "Pierrick Chatillon, Julien Rabin, David Tschumperlé",
        "summary": "This paper addresses the problem of exemplar-based texture synthesis. We introduce NIFTY, a hybrid framework that combines recent insights on diffusion models trained with convolutional neural networks, and classical patch-based texture optimization techniques. NIFTY is a non-parametric flow-matching model built on non-local patch matching, which avoids the need for neural network training while alleviating common shortcomings of patch-based methods, such as poor initialization or visual artifacts. Experimental results demonstrate the effectiveness of the proposed approach compared to representative methods from the literature. Code is available at https://github.com/PierrickCh/Nifty.git",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.358414"
    },
    {
        "index": "#41",
        "title": "Johnson-Lindenstrauss Lemma Guided Network for Efficient 3D Medical Segmentation",
        "link": "/arxiv/2509.22307",
        "arxiv_id": "2509.22307",
        "authors": "Jinpeng Lu, Linghan Cai, Yinda Chen, Guo Tang, Songhan Jiang, Haoyuan Shi, Zhiwei Xiong",
        "summary": "Lightweight 3D medical image segmentation remains constrained by a fundamental \"efficiency / robustness conflict\", particularly when processing complex anatomical structures and heterogeneous modalities. In this paper, we study how to redesign the framework based on the characteristics of high-dimensional 3D images, and explore data synergy to overcome the fragile representation of lightweight methods. Our approach, VeloxSeg, begins with a deployable and extensible dual-stream CNN-Transformer architecture composed of Paired Window Attention (PWA) and Johnson-Lindenstrauss lemma-guided convolution (JLC). For each 3D image, we invoke a \"glance-and-focus\" principle, where PWA rapidly retrieves multi-scale information, and JLC ensures robust local feature extraction with minimal parameters, significantly enhancing the model's ability to operate with low computational budget. Followed by an extension of the dual-stream architecture that incorporates modal interaction into the multi-scale image-retrieval process, VeloxSeg efficiently models heterogeneous modalities. Finally, Spatially Decoupled Knowledge Transfer (SDKT) via Gram matrices injects the texture prior extracted by a self-supervised network into the segmentation network, yielding stronger representations than baselines at no extra inference cost. Experimental results on multimodal benchmarks show that VeloxSeg achieves a 26% Dice improvement, alongside increasing GPU throughput by 11x and CPU by 48x. Codes are available at https://github.com/JinPLu/VeloxSeg.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.358715"
    },
    {
        "index": "#42",
        "title": "HiGS: History-Guided Sampling for Plug-and-Play Enhancement of Diffusion Models",
        "link": "/arxiv/2509.22300",
        "arxiv_id": "2509.22300",
        "authors": "Seyedmorteza Sadat, Farnood Salehi, Romann M. Weber",
        "summary": "While diffusion models have made remarkable progress in image generation, their outputs can still appear unrealistic and lack fine details, especially when using fewer number of neural function evaluations (NFEs) or lower guidance scales. To address this issue, we propose a novel momentum-based sampling technique, termed history-guided sampling (HiGS), which enhances quality and efficiency of diffusion sampling by integrating recent model predictions into each inference step. Specifically, HiGS leverages the difference between the current prediction and a weighted average of past predictions to steer the sampling process toward more realistic outputs with better details and structure. Our approach introduces practically no additional computation and integrates seamlessly into existing diffusion frameworks, requiring neither extra training nor fine-tuning. Extensive experiments show that HiGS consistently improves image quality across diverse models and architectures and under varying sampling budgets and guidance scales. Moreover, using a pretrained SiT model, HiGS achieves a new state-of-the-art FID of 1.61 for unguided ImageNet generation at 256$\\times$256 with only 30 sampling steps (instead of the standard 250). We thus present HiGS as a plug-and-play enhancement to standard diffusion sampling that enables faster generation with higher fidelity.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.359005"
    },
    {
        "index": "#43",
        "title": "Jailbreaking on Text-to-Video Models via Scene Splitting Strategy",
        "link": "/arxiv/2509.22292",
        "arxiv_id": "2509.22292",
        "authors": "Wonjun Lee, Haon Park, Doehyeon Lee, Bumsub Ham, Suhyun Kim",
        "summary": "Along with the rapid advancement of numerous Text-to-Video (T2V) models, growing concerns have emerged regarding their safety risks. While recent studies have explored vulnerabilities in models like LLMs, VLMs, and Text-to-Image (T2I) models through jailbreak attacks, T2V models remain largely unexplored, leaving a significant safety gap. To address this gap, we introduce SceneSplit, a novel black-box jailbreak method that works by fragmenting a harmful narrative into multiple scenes, each individually benign. This approach manipulates the generative output space, the abstract set of all potential video outputs for a given prompt, using the combination of scenes as a powerful constraint to guide the final outcome. While each scene individually corresponds to a wide and safe space where most outcomes are benign, their sequential combination collectively restricts this space, narrowing it to an unsafe region and significantly increasing the likelihood of generating a harmful video. This core mechanism is further enhanced through iterative scene manipulation, which bypasses the safety filter within this constrained unsafe region. Additionally, a strategy library that reuses successful attack patterns further improves the attack's overall effectiveness and robustness. To validate our method, we evaluate SceneSplit across 11 safety categories on T2V models. Our results show that it achieves a high average Attack Success Rate (ASR) of 77.2% on Luma Ray2, 84.1% on Hailuo, and 78.2% on Veo2, significantly outperforming the existing baseline. Through this work, we demonstrate that current T2V safety mechanisms are vulnerable to attacks that exploit narrative structure, providing new insights for understanding and improving the safety of T2V models.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.359291"
    },
    {
        "index": "#44",
        "title": "Rule-Based Reinforcement Learning for Document Image Classification with Vision Language Models",
        "link": "/arxiv/2509.22283",
        "arxiv_id": "2509.22283",
        "authors": "Michael Jungo, Andreas Fischer",
        "summary": "Rule-based reinforcement learning has been gaining popularity ever since DeepSeek-R1 has demonstrated its success through simple verifiable rewards. In the domain of document analysis, reinforcement learning is not as prevalent, even though many downstream tasks may benefit from the emerging properties of reinforcement learning, particularly the enhanced reason capabilities. We study the effects of rule-based reinforcement learning with the task of Document Image Classification which is one of the most commonly studied downstream tasks in document analysis. We find that reinforcement learning tends to have better generalisation capabilities to out-of-distritbution data, which we examine in three different scenarios, namely out-of-distribution images, unseen classes and different modalities. Our code is available at https://github.com/jungomi/vision-finetune.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.359544"
    },
    {
        "index": "#45",
        "title": "MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning",
        "link": "/arxiv/2509.22281",
        "arxiv_id": "2509.22281",
        "authors": "Jinkun Hao, Naifu Liang, Zhen Luo, Xudong Xu, Weipeng Zhong, Ran Yi, Yichen Jin, Zhaoyang Lyu, Feng Zheng, Lizhuang Ma, Jiangmiao Pang",
        "summary": "The ability of robots to interpret human instructions and execute manipulation tasks necessitates the availability of task-relevant tabletop scenes for training. However, traditional methods for creating these scenes rely on time-consuming manual layout design or purely randomized layouts, which are limited in terms of plausibility or alignment with the tasks. In this paper, we formulate a novel task, namely task-oriented tabletop scene generation, which poses significant challenges due to the substantial gap between high-level task instructions and the tabletop scenes. To support research on such a challenging task, we introduce MesaTask-10K, a large-scale dataset comprising approximately 10,700 synthetic tabletop scenes with manually crafted layouts that ensure realistic layouts and intricate inter-object relations. To bridge the gap between tasks and scenes, we propose a Spatial Reasoning Chain that decomposes the generation process into object inference, spatial interrelation reasoning, and scene graph construction for the final 3D layout. We present MesaTask, an LLM-based framework that utilizes this reasoning chain and is further enhanced with DPO algorithms to generate physically plausible tabletop scenes that align well with given task descriptions. Exhaustive experiments demonstrate the superior performance of MesaTask compared to baselines in generating task-conforming tabletop scenes with realistic layouts. Project page is at https://mesatask.github.io/",
        "subjects": "Computer Vision and Pattern Recognition, Robotics",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.360046"
    },
    {
        "index": "#46",
        "title": "GS-2M: Gaussian Splatting for Joint Mesh Reconstruction and Material Decomposition",
        "link": "/arxiv/2509.22276",
        "arxiv_id": "2509.22276",
        "authors": "Dinh Minh Nguyen, Malte Avenhaus, Thomas Lindemeier",
        "summary": "We propose a unified solution for mesh reconstruction and material decomposition from multi-view images based on 3D Gaussian Splatting, referred to as GS-2M. Previous works handle these tasks separately and struggle to reconstruct highly reflective surfaces, often relying on priors from external models to enhance the decomposition results. Conversely, our method addresses these two problems by jointly optimizing attributes relevant to the quality of rendered depth and normals, maintaining geometric details while being resilient to reflective surfaces. Although contemporary works effectively solve these tasks together, they often employ sophisticated neural components to learn scene properties, which hinders their performance at scale. To further eliminate these neural components, we propose a novel roughness supervision strategy based on multi-view photometric variation. When combined with a carefully designed loss and optimization process, our unified framework produces reconstruction results comparable to state-of-the-art methods, delivering triangle meshes and their associated material components for downstream tasks. We validate the effectiveness of our approach with widely used datasets from previous works and qualitative comparisons with state-of-the-art surface reconstruction methods.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.360304"
    },
    {
        "index": "#47",
        "title": "UniMapGen: A Generative Framework for Large-Scale Map Construction from Multi-modal Data",
        "link": "/arxiv/2509.22262",
        "arxiv_id": "2509.22262",
        "authors": "Yujian Yuan, Changjie Wu, Xinyuan Chang, Sijin Wang, Hang Zhang, Shiyi Liang, Shuang Zeng, Mu Xu",
        "summary": "Large-scale map construction is foundational for critical applications such as autonomous driving and navigation systems. Traditional large-scale map construction approaches mainly rely on costly and inefficient special data collection vehicles and labor-intensive annotation processes. While existing satellite-based methods have demonstrated promising potential in enhancing the efficiency and coverage of map construction, they exhibit two major limitations: (1) inherent drawbacks of satellite data (e.g., occlusions, outdatedness) and (2) inefficient vectorization from perception-based methods, resulting in discontinuous and rough roads that require extensive post-processing. This paper presents a novel generative framework, UniMapGen, for large-scale map construction, offering three key innovations: (1) representing lane lines as \\textbf{discrete sequence} and establishing an iterative strategy to generate more complete and smooth map vectors than traditional perception-based methods. (2) proposing a flexible architecture that supports \\textbf{multi-modal} inputs, enabling dynamic selection among BEV, PV, and text prompt, to overcome the drawbacks of satellite data. (3) developing a \\textbf{state update} strategy for global continuity and consistency of the constructed large-scale map. UniMapGen achieves state-of-the-art performance on the OpenSatMap dataset. Furthermore, UniMapGen can infer occluded roads and predict roads missing from dataset annotations. Our code will be released.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.360598"
    },
    {
        "index": "#48",
        "title": "Beyond Classification Accuracy: Neural-MedBench and the Need for Deeper Reasoning Benchmarks",
        "link": "/arxiv/2509.22258",
        "arxiv_id": "2509.22258",
        "authors": "Miao Jing, Mengting Jia, Junling Lin, Zhongxia Shen, Lijun Wang, Yuanyuan Peng, Huan Gao, Mingkun Xu, Shangyang Li",
        "summary": "Recent advances in vision-language models (VLMs) have achieved remarkable performance on standard medical benchmarks, yet their true clinical reasoning ability remains unclear. Existing datasets predominantly emphasize classification accuracy, creating an evaluation illusion in which models appear proficient while still failing at high-stakes diagnostic reasoning. We introduce Neural-MedBench, a compact yet reasoning-intensive benchmark specifically designed to probe the limits of multimodal clinical reasoning in neurology. Neural-MedBench integrates multi-sequence MRI scans, structured electronic health records, and clinical notes, and encompasses three core task families: differential diagnosis, lesion recognition, and rationale generation. To ensure reliable evaluation, we develop a hybrid scoring pipeline that combines LLM-based graders, clinician validation, and semantic similarity metrics. Through systematic evaluation of state-of-the-art VLMs, including GPT-4o, Claude-4, and MedGemma, we observe a sharp performance drop compared to conventional datasets. Error analysis shows that reasoning failures, rather than perceptual errors, dominate model shortcomings. Our findings highlight the necessity of a Two-Axis Evaluation Framework: breadth-oriented large datasets for statistical generalization, and depth-oriented, compact benchmarks such as Neural-MedBench for reasoning fidelity. We release Neural-MedBench at https://neuromedbench.github.io/ as an open and extensible diagnostic testbed, which guides the expansion of future benchmarks and enables rigorous yet cost-effective assessment of clinically trustworthy AI.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.360911"
    },
    {
        "index": "#49",
        "title": "FlashEdit: Decoupling Speed, Structure, and Semantics for Precise Image Editing",
        "link": "/arxiv/2509.22244",
        "arxiv_id": "2509.22244",
        "authors": "Junyi Wu, Zhiteng Li, Haotong Qin, Xiaohong Liu, Linghe Kong, Yulun Zhang, Xiaokang Yang",
        "summary": "Text-guided image editing with diffusion models has achieved remarkable quality but suffers from prohibitive latency, hindering real-world applications. We introduce FlashEdit, a novel framework designed to enable high-fidelity, real-time image editing. Its efficiency stems from three key innovations: (1) a One-Step Inversion-and-Editing (OSIE) pipeline that bypasses costly iterative processes; (2) a Background Shield (BG-Shield) technique that guarantees background preservation by selectively modifying features only within the edit region; and (3) a Sparsified Spatial Cross-Attention (SSCA) mechanism that ensures precise, localized edits by suppressing semantic leakage to the background. Extensive experiments demonstrate that FlashEdit maintains superior background consistency and structural integrity, while performing edits in under 0.2 seconds, which is an over 150$\\times$ speedup compared to prior multi-step methods. Our code will be made publicly available at https://github.com/JunyiWuCode/FlashEdit.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.361198"
    },
    {
        "index": "#50",
        "title": "A Tale of Two Experts: Cooperative Learning for Source-Free Unsupervised Domain Adaptation",
        "link": "/arxiv/2509.22229",
        "arxiv_id": "2509.22229",
        "authors": "Jiaping Yu, Muli Yang, Jiapeng Ji, Jiexi Yan, Cheng Deng",
        "summary": "Source-Free Unsupervised Domain Adaptation (SFUDA) addresses the realistic challenge of adapting a source-trained model to a target domain without access to the source data, driven by concerns over privacy and cost. Existing SFUDA methods either exploit only the source model's predictions or fine-tune large multimodal models, yet both neglect complementary insights and the latent structure of target data. In this paper, we propose the Experts Cooperative Learning (EXCL). EXCL contains the Dual Experts framework and Retrieval-Augmentation-Interaction optimization pipeline. The Dual Experts framework places a frozen source-domain model (augmented with Conv-Adapter) and a pretrained vision-language model (with a trainable text prompt) on equal footing to mine consensus knowledge from unlabeled target samples. To effectively train these plug-in modules under purely unsupervised conditions, we introduce Retrieval-Augmented-Interaction(RAIN), a three-stage pipeline that (1) collaboratively retrieves pseudo-source and complex target samples, (2) separately fine-tunes each expert on its respective sample set, and (3) enforces learning object consistency via a shared learning result. Extensive experiments on four benchmark datasets demonstrate that our approach matches state-of-the-art performance.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.361467"
    },
    {
        "index": "#51",
        "title": "UrbanFeel: A Comprehensive Benchmark for Temporal and Perceptual Understanding of City Scenes through Human Perspective",
        "link": "/arxiv/2509.22228",
        "arxiv_id": "2509.22228",
        "authors": "Jun He, Yi Lin, Zilong Huang, Jiacong Yin, Junyan Ye, Yuchuan Zhou, Weijia Li, Xiang Zhang",
        "summary": "Urban development impacts over half of the global population, making human-centered understanding of its structural and perceptual changes essential for sustainable development. While Multimodal Large Language Models (MLLMs) have shown remarkable capabilities across various domains, existing benchmarks that explore their performance in urban environments remain limited, lacking systematic exploration of temporal evolution and subjective perception of urban environment that aligns with human perception. To address these limitations, we propose UrbanFeel, a comprehensive benchmark designed to evaluate the performance of MLLMs in urban development understanding and subjective environmental perception. UrbanFeel comprises 14.3K carefully constructed visual questions spanning three cognitively progressive dimensions: Static Scene Perception, Temporal Change Understanding, and Subjective Environmental Perception. We collect multi-temporal single-view and panoramic street-view images from 11 representative cities worldwide, and generate high-quality question-answer pairs through a hybrid pipeline of spatial clustering, rule-based generation, model-assisted prompting, and manual annotation. Through extensive evaluation of 20 state-of-the-art MLLMs, we observe that Gemini-2.5 Pro achieves the best overall performance, with its accuracy approaching human expert levels and narrowing the average gap to just 1.5\\%. Most models perform well on tasks grounded in scene understanding. In particular, some models even surpass human annotators in pixel-level change detection. However, performance drops notably in tasks requiring temporal reasoning over urban development. Additionally, in the subjective perception dimension, several models reach human-level or even higher consistency in evaluating dimension such as beautiful and safety.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.361766"
    },
    {
        "index": "#52",
        "title": "Polysemous Language Gaussian Splatting via Matching-based Mask Lifting",
        "link": "/arxiv/2509.22225",
        "arxiv_id": "2509.22225",
        "authors": "Jiayu Ding, Xinpeng Liu, Zhiyi Pan, Shiqiang Long, Ge Li",
        "summary": "Lifting 2D open-vocabulary understanding into 3D Gaussian Splatting (3DGS) scenes is a critical challenge. However, mainstream methods suffer from three key flaws: (i) their reliance on costly per-scene retraining prevents plug-and-play application; (ii) their restrictive monosemous design fails to represent complex, multi-concept semantics; and (iii) their vulnerability to cross-view semantic inconsistencies corrupts the final semantic representation. To overcome these limitations, we introduce MUSplat, a training-free framework that abandons feature optimization entirely. Leveraging a pre-trained 2D segmentation model, our pipeline generates and lifts multi-granularity 2D masks into 3D, where we estimate a foreground probability for each Gaussian point to form initial object groups. We then optimize the ambiguous boundaries of these initial groups using semantic entropy and geometric opacity. Subsequently, by interpreting the object's appearance across its most representative viewpoints, a Vision-Language Model (VLM) distills robust textual features that reconciles visual inconsistencies, enabling open-vocabulary querying via semantic matching. By eliminating the costly per-scene training process, MUSplat reduces scene adaptation time from hours to mere minutes. On benchmark tasks for open-vocabulary 3D object selection and semantic segmentation, MUSplat outperforms established training-based frameworks while simultaneously addressing their monosemous limitations.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.362046"
    },
    {
        "index": "#53",
        "title": "Towards Faithful Reasoning in Remote Sensing: A Perceptually-Grounded GeoSpatial Chain-of-Thought for Vision-Language Models",
        "link": "/arxiv/2509.22221",
        "arxiv_id": "2509.22221",
        "authors": "Jiaqi Liu, Lang Sun, Ronghao Fu, Bo Yang",
        "summary": "Vision-Language Models (VLMs) in remote sensing often fail at complex analytical tasks, a limitation stemming from their end-to-end training paradigm that bypasses crucial reasoning steps and leads to unverifiable outputs. To address this limitation, we introduce the Perceptually-Grounded Geospatial Chain-of-Thought (Geo-CoT), a framework that models remote sensing analysis as a verifiable, multi-step process. We instill this analytical process through a two-stage alignment strategy, leveraging Geo-CoT380k, the first large-scale dataset of structured Geo-CoT rationales. This strategy first employs supervised fine-tuning (SFT) to instill the foundational cognitive architecture, then leverages Group Reward Policy Optimization (GRPO) to refine the model's reasoning policy towards factual correctness. The resulting model, RSThinker, outputs both a final answer and its justifying, verifiable analytical trace. This capability yields dominant performance, significantly outperforming state-of-the-art models across a comprehensive range of tasks. The public release of our Geo-CoT380k dataset and RSThinker model upon publication serves as a concrete pathway from opaque perception towards structured, verifiable reasoning for Earth Observation.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.362308"
    },
    {
        "index": "#54",
        "title": "MinerU2.5: A Decoupled Vision-Language Model for Efficient High-Resolution Document Parsing",
        "link": "/arxiv/2509.22186",
        "arxiv_id": "2509.22186",
        "authors": "Junbo Niu, Zheng Liu, Zhuangcheng Gu, Bin Wang, Linke Ouyang, Zhiyuan Zhao, Tao Chu, Tianyao He, Fan Wu, Qintong Zhang, Zhenjiang Jin, Guang Liang, Rui Zhang, Wenzheng Zhang, Yuan Qu, Zhifei Ren, Yuefeng Sun, Yuanhong Zheng, Dongsheng Ma, Zirui Tang, Boyu Niu, Ziyang Miao, Hejun Dong, Siyi Qian, Junyuan Zhang, Jingzhou Chen, Fangdong Wang, Xiaomeng Zhao, Liqun Wei, Wei Li, Shasha Wang, Ruiliang Xu, Yuanyuan Cao, Lu Chen, Qianqian Wu, Huaiyu Gu, Lindong Lu, Keming Wang, Dechen Lin, Guanlin Shen, Xuanhe Zhou, Linfeng Zhang, Yuhang Zang, Xiaoyi Dong, Jiaqi Wang, Bo Zhang, Lei Bai, Pei Chu, Weijia Li, Jiang Wu, Lijun Wu, Zhenxiang Li, Guangyu Wang, Zhongying Tu, Chao Xu, Kai Chen, Yu Qiao, Bowen Zhou, Dahua Lin, Wentao Zhang, Conghui He",
        "summary": "We introduce MinerU2.5, a 1.2B-parameter document parsing vision-language model that achieves state-of-the-art recognition accuracy while maintaining exceptional computational efficiency. Our approach employs a coarse-to-fine, two-stage parsing strategy that decouples global layout analysis from local content recognition. In the first stage, the model performs efficient layout analysis on downsampled images to identify structural elements, circumventing the computational overhead of processing high-resolution inputs. In the second stage, guided by the global layout, it performs targeted content recognition on native-resolution crops extracted from the original image, preserving fine-grained details in dense text, complex formulas, and tables. To support this strategy, we developed a comprehensive data engine that generates diverse, large-scale training corpora for both pretraining and fine-tuning. Ultimately, MinerU2.5 demonstrates strong document parsing ability, achieving state-of-the-art performance on multiple benchmarks, surpassing both general-purpose and domain-specific models across various recognition tasks, while maintaining significantly lower computational overhead.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.368200"
    },
    {
        "index": "#55",
        "title": "DragGANSpace: Latent Space Exploration and Control for GANs",
        "link": "/arxiv/2509.22169",
        "arxiv_id": "2509.22169",
        "authors": "Kirsten Odendaal, Neela Kaushik, Spencer Halverson",
        "summary": "This work integrates StyleGAN, DragGAN and Principal Component Analysis (PCA) to enhance the latent space efficiency and controllability of GAN-generated images. Style-GAN provides a structured latent space, DragGAN enables intuitive image manipulation, and PCA reduces dimensionality and facilitates cross-model alignment for more streamlined and interpretable exploration of latent spaces. We apply our techniques to the Animal Faces High Quality (AFHQ) dataset, and find that our approach of integrating PCA-based dimensionality reduction with the Drag-GAN framework for image manipulation retains performance while improving optimization efficiency. Notably, introducing PCA into the latent W+ layers of DragGAN can consistently reduce the total optimization time while maintaining good visual quality and even boosting the Structural Similarity Index Measure (SSIM) of the optimized image, particularly in shallower latent spaces (W+ layers = 3). We also demonstrate capability for aligning images generated by two StyleGAN models trained on similar but distinct data domains (AFHQ-Dog and AFHQ-Cat), and show that we can control the latent space of these aligned images to manipulate the images in an intuitive and interpretable manner. Our findings highlight the possibility for efficient and interpretable latent space control for a wide range of image synthesis and editing applications.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.368675"
    },
    {
        "index": "#56",
        "title": "MultiMat: Multimodal Program Synthesis for Procedural Materials using Large Multimodal Models",
        "link": "/arxiv/2509.22151",
        "arxiv_id": "2509.22151",
        "authors": "Jonas Belouadi, Tamy Boubekeur, Adrien Kaiser",
        "summary": "Material node graphs are programs that generate the 2D channels of procedural materials, including geometry such as roughness and displacement maps, and reflectance such as albedo and conductivity maps. They are essential in computer graphics for representing the appearance of virtual 3D objects parametrically and at arbitrary resolution. In particular, their directed acyclic graph structures and intermediate states provide an intuitive understanding and workflow for interactive appearance modeling. Creating such graphs is a challenging task and typically requires professional training. While recent neural program synthesis approaches attempt to simplify this process, they solely represent graphs as textual programs, failing to capture the inherently visual-spatial nature of node graphs that makes them accessible to humans. To address this gap, we present MultiMat, a multimodal program synthesis framework that leverages large multimodal models to process both visual and textual graph representations for improved generation of procedural material graphs. We train our models on a new dataset of production-quality procedural materials and combine them with a constrained tree search inference algorithm that ensures syntactic validity while efficiently navigating the program space. Our experimental results show that our multimodal program synthesis method is more efficient in both unconditional and conditional graph synthesis with higher visual quality and fidelity than text-only baselines, establishing new state-of-the-art performance.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.369118"
    },
    {
        "index": "#57",
        "title": "Joint graph entropy knowledge distillation for point cloud classification and robustness against corruptions",
        "link": "/arxiv/2509.22150",
        "arxiv_id": "2509.22150",
        "authors": "Zhiqiang Tian, Weigang Li, Junwei Hu, Chunhua Deng",
        "summary": "Classification tasks in 3D point clouds often assume that class events \\replaced{are }{follow }independent and identically distributed (IID), although this assumption destroys the correlation between classes. This \\replaced{study }{paper }proposes a classification strategy, \\textbf{J}oint \\textbf{G}raph \\textbf{E}ntropy \\textbf{K}nowledge \\textbf{D}istillation (JGEKD), suitable for non-independent and identically distributed 3D point cloud data, \\replaced{which }{the strategy } achieves knowledge transfer of class correlations through knowledge distillation by constructing a loss function based on joint graph entropy. First\\deleted{ly}, we employ joint graphs to capture add{the }hidden relationships between classes\\replaced{ and}{,} implement knowledge distillation to train our model by calculating the entropy of add{add }graph.\\replaced{ Subsequently}{ Then}, to handle 3D point clouds \\deleted{that is }invariant to spatial transformations, we construct \\replaced{S}{s}iamese structures and develop two frameworks, self-knowledge distillation and teacher-knowledge distillation, to facilitate information transfer between different transformation forms of the same data. \\replaced{In addition}{ Additionally}, we use the above framework to achieve knowledge transfer between point clouds and their corrupted forms, and increase the robustness against corruption of model. Extensive experiments on ScanObject, ModelNet40, ScanntV2\\_cls and ModelNet-C demonstrate that the proposed strategy can achieve competitive results.",
        "subjects": "Computer Vision and Pattern Recognition, Information Retrieval",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.369588"
    },
    {
        "index": "#58",
        "title": "REFINE-CONTROL: A Semi-supervised Distillation Method For Conditional Image Generation",
        "link": "/arxiv/2509.22139",
        "arxiv_id": "2509.22139",
        "authors": "Yicheng Jiang, Jin Yuan, Hua Yuan, Yao Zhang, Yong Rui",
        "summary": "Conditional image generation models have achieved remarkable results by leveraging text-based control to generate customized images. However, the high resource demands of these models and the scarcity of well-annotated data have hindered their deployment on edge devices, leading to enormous costs and privacy concerns, especially when user data is sent to a third party. To overcome these challenges, we propose Refine-Control, a semi-supervised distillation framework. Specifically, we improve the performance of the student model by introducing a tri-level knowledge fusion loss to transfer different levels of knowledge. To enhance generalization and alleviate dataset scarcity, we introduce a semi-supervised distillation method utilizing both labeled and unlabeled data. Our experiments reveal that Refine-Control achieves significant reductions in computational cost and latency, while maintaining high-fidelity generation capabilities and controllability, as quantified by comparative metrics.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.370071"
    },
    {
        "index": "#59",
        "title": "Self-Supervised Point Cloud Completion based on Multi-View Augmentations of Single Partial Point Cloud",
        "link": "/arxiv/2509.22132",
        "arxiv_id": "2509.22132",
        "authors": "Jingjing Lu, Huilong Pi, Yunchuan Qin, Zhuo Tang, Ruihui Li",
        "summary": "Point cloud completion aims to reconstruct complete shapes from partial observations. Although current methods have achieved remarkable performance, they still have some limitations: Supervised methods heavily rely on ground truth, which limits their generalization to real-world datasets due to the synthetic-to-real domain gap. Unsupervised methods require complete point clouds to compose unpaired training data, and weakly-supervised methods need multi-view observations of the object. Existing self-supervised methods frequently produce unsatisfactory predictions due to the limited capabilities of their self-supervised signals. To overcome these challenges, we propose a novel self-supervised point cloud completion method. We design a set of novel self-supervised signals based on multi-view augmentations of the single partial point cloud. Additionally, to enhance the model's learning ability, we first incorporate Mamba into self-supervised point cloud completion task, encouraging the model to generate point clouds with better quality. Experiments on synthetic and real-world datasets demonstrate that our method achieves state-of-the-art results.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.370543"
    },
    {
        "index": "#60",
        "title": "Large Material Gaussian Model for Relightable 3D Generation",
        "link": "/arxiv/2509.22112",
        "arxiv_id": "2509.22112",
        "authors": "Jingrui Ye, Lingting Zhu, Runze Zhang, Zeyu Hu, Yingda Yin, Lanjiong Li, Lequan Yu, Qingmin Liao",
        "summary": "The increasing demand for 3D assets across various industries necessitates efficient and automated methods for 3D content creation. Leveraging 3D Gaussian Splatting, recent large reconstruction models (LRMs) have demonstrated the ability to efficiently achieve high-quality 3D rendering by integrating multiview diffusion for generation and scalable transformers for reconstruction. However, existing models fail to produce the material properties of assets, which is crucial for realistic rendering in diverse lighting environments. In this paper, we introduce the Large Material Gaussian Model (MGM), a novel framework designed to generate high-quality 3D content with Physically Based Rendering (PBR) materials, ie, albedo, roughness, and metallic properties, rather than merely producing RGB textures with uncontrolled light baking. Specifically, we first fine-tune a new multiview material diffusion model conditioned on input depth and normal maps. Utilizing the generated multiview PBR images, we explore a Gaussian material representation that not only aligns with 2D Gaussian Splatting but also models each channel of the PBR materials. The reconstructed point clouds can then be rendered to acquire PBR attributes, enabling dynamic relighting by applying various ambient light maps. Extensive experiments demonstrate that the materials produced by our method not only exhibit greater visual appeal compared to baseline methods but also enhance material modeling, thereby enabling practical downstream rendering applications.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.371063"
    },
    {
        "index": "#61",
        "title": "SpecXNet: A Dual-Domain Convolutional Network for Robust Deepfake Detection",
        "link": "/arxiv/2509.22070",
        "arxiv_id": "2509.22070",
        "authors": "Inzamamul Alam, Md Tanvir Islam, Simon S. Woo",
        "summary": "The increasing realism of content generated by GANs and diffusion models has made deepfake detection significantly more challenging. Existing approaches often focus solely on spatial or frequency-domain features, limiting their generalization to unseen manipulations. We propose the Spectral Cross-Attentional Network (SpecXNet), a dual-domain architecture for robust deepfake detection. The core \\textbf{Dual-Domain Feature Coupler (DDFC)} decomposes features into a local spatial branch for capturing texture-level anomalies and a global spectral branch that employs Fast Fourier Transform to model periodic inconsistencies. This dual-domain formulation allows SpecXNet to jointly exploit localized detail and global structural coherence, which are critical for distinguishing authentic from manipulated images. We also introduce the \\textbf{Dual Fourier Attention (DFA)} module, which dynamically fuses spatial and spectral features in a content-aware manner. Built atop a modified XceptionNet backbone, we embed the DDFC and DFA modules within a separable convolution block. Extensive experiments on multiple deepfake benchmarks show that SpecXNet achieves state-of-the-art accuracy, particularly under cross-dataset and unseen manipulation scenarios, while maintaining real-time feasibility. Our results highlight the effectiveness of unified spatial-spectral learning for robust and generalizable deepfake detection. To ensure reproducibility, we released the full code on \\href{https://github.com/inzamamulDU/SpecXNet}{\\textcolor{blue}{\\textbf{GitHub}}}.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.371498"
    },
    {
        "index": "#62",
        "title": "High-Quality Sound Separation Across Diverse Categories via Visually-Guided Generative Modeling",
        "link": "/arxiv/2509.22063",
        "arxiv_id": "2509.22063",
        "authors": "Chao Huang, Susan Liang, Yapeng Tian, Anurag Kumar, Chenliang Xu",
        "summary": "We propose DAVIS, a Diffusion-based Audio-VIsual Separation framework that solves the audio-visual sound source separation task through generative learning. Existing methods typically frame sound separation as a mask-based regression problem, achieving significant progress. However, they face limitations in capturing the complex data distribution required for high-quality separation of sounds from diverse categories. In contrast, DAVIS circumvents these issues by leveraging potent generative modeling paradigms, specifically Denoising Diffusion Probabilistic Models (DDPM) and the more recent Flow Matching (FM), integrated within a specialized Separation U-Net architecture. Our framework operates by synthesizing the desired separated sound spectrograms directly from a noise distribution, conditioned concurrently on the mixed audio input and associated visual information. The inherent nature of its generative objective makes DAVIS particularly adept at producing high-quality sound separations for diverse sound categories. We present comparative evaluations of DAVIS, encompassing both its DDPM and Flow Matching variants, against leading methods on the standard AVE and MUSIC datasets. The results affirm that both variants surpass existing approaches in separation quality, highlighting the efficacy of our generative framework for tackling the audio-visual source separation task.",
        "subjects": "Computer Vision and Pattern Recognition, Sound",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.372001"
    },
    {
        "index": "#63",
        "title": "EgoInstruct: An Egocentric Video Dataset of Face-to-face Instructional Interactions with Multi-modal LLM Benchmarking",
        "link": "/arxiv/2509.22019",
        "arxiv_id": "2509.22019",
        "authors": "Yuki Sakai, Ryosuke Furuta, Juichun Yen, Yoichi Sato",
        "summary": "Analyzing instructional interactions between an instructor and a learner who are co-present in the same physical space is a critical problem for educational support and skill transfer. Yet such face-to-face instructional scenes have not been systematically studied in computer vision. We identify two key reasons: i) the lack of suitable datasets and ii) limited analytical techniques. To address this gap, we present a new egocentric video dataset of face-to-face instruction and provide ground-truth annotations for two fundamental tasks that serve as a first step toward a comprehensive understanding of instructional interactions: procedural step segmentation and conversation-state classification. Using this dataset, we benchmark multimodal large language models (MLLMs) against conventional task-specific models. Since face-to-face instruction involves multiple modalities (speech content and prosody, gaze and body motion, and visual context), effective understanding requires methods that handle verbal and nonverbal communication in an integrated manner. Accordingly, we evaluate recently introduced MLLMs that jointly process images, audio, and text. This evaluation quantifies the extent to which current machine learning models understand face-to-face instructional scenes. In experiments, MLLMs outperform specialized baselines even without task-specific fine-tuning, suggesting their promise for holistic understanding of instructional interactions.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.372456"
    },
    {
        "index": "#64",
        "title": "Lightweight Structured Multimodal Reasoning for Clinical Scene Understanding in Robotics",
        "link": "/arxiv/2509.22014",
        "arxiv_id": "2509.22014",
        "authors": "Saurav Jha, Stefan K. Ehrlich",
        "summary": "Healthcare robotics requires robust multimodal perception and reasoning to ensure safety in dynamic clinical environments. Current Vision-Language Models (VLMs) demonstrate strong general-purpose capabilities but remain limited in temporal reasoning, uncertainty estimation, and structured outputs needed for robotic planning. We present a lightweight agentic multimodal framework for video-based scene understanding. Combining the Qwen2.5-VL-3B-Instruct model with a SmolAgent-based orchestration layer, it supports chain-of-thought reasoning, speech-vision fusion, and dynamic tool invocation. The framework generates structured scene graphs and leverages a hybrid retrieval module for interpretable and adaptive reasoning. Evaluations on the Video-MME benchmark and a custom clinical dataset show competitive accuracy and improved robustness compared to state-of-the-art VLMs, demonstrating its potential for applications in robot-assisted surgery, patient monitoring, and decision support.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Human-Computer Interaction, Robotics",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.372930"
    },
    {
        "index": "#65",
        "title": "CoFFT: Chain of Foresight-Focus Thought for Visual Language Models",
        "link": "/arxiv/2509.22010",
        "arxiv_id": "2509.22010",
        "authors": "Xinyu Zhang, Yuxuan Dong, Lingling Zhang, Chengyou Jia, Zhuohang Dang, Basura Fernando, Jun Liu, Mike Zheng Shou",
        "summary": "Despite significant advances in Vision Language Models (VLMs), they remain constrained by the complexity and redundancy of visual input. When images contain large amounts of irrelevant information, VLMs are susceptible to interference, thus generating excessive task-irrelevant reasoning processes or even hallucinations. This limitation stems from their inability to discover and process the required regions during reasoning precisely. To address this limitation, we present the Chain of Foresight-Focus Thought (CoFFT), a novel training-free approach that enhances VLMs' visual reasoning by emulating human visual cognition. Each Foresight-Focus Thought consists of three stages: (1) Diverse Sample Generation: generates diverse reasoning samples to explore potential reasoning paths, where each sample contains several reasoning steps; (2) Dual Foresight Decoding: rigorously evaluates these samples based on both visual focus and reasoning progression, adding the first step of optimal sample to the reasoning process; (3) Visual Focus Adjustment: precisely adjust visual focus toward regions most beneficial for future reasoning, before returning to stage (1) to generate subsequent reasoning samples until reaching the final answer. These stages function iteratively, creating an interdependent cycle where reasoning guides visual focus and visual focus informs subsequent reasoning. Empirical results across multiple benchmarks using Qwen2.5-VL, InternVL-2.5, and Llava-Next demonstrate consistent performance improvements of 3.1-5.8\\% with controllable increasing computational overhead.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.409465"
    },
    {
        "index": "#66",
        "title": "Exposing Hallucinations To Suppress Them: VLMs Representation Editing With Generative Anchors",
        "link": "/arxiv/2509.21997",
        "arxiv_id": "2509.21997",
        "authors": "Youxu Shi, Suorong Yang, Dong Liu",
        "summary": "Multimodal large language models (MLLMs) have achieved remarkable success across diverse vision-language tasks, yet they remain highly susceptible to hallucinations, producing content that is fluent but inconsistent with visual evidence. Such hallucinations, spanning objects, attributes, and relations, persist even in larger models, while existing mitigation approaches often require additional finetuning, handcrafted priors, or trade-offs that compromise informativeness and scalability. To address this limitation, we propose a training-free, self-supervised method for hallucination mitigation. Our approach introduces a novel hallucination amplification mechanism: a caption is projected into the visual space via a text-to-image model to reveal implicit hallucination signals, serving as a negative anchor, while the original image provides a positive anchor. Leveraging these dual anchors, we edit decoder hidden states by pulling representations toward faithful semantics and pushing them away from hallucination directions. This correction requires no human priors or additional training costs, ensuring both effectiveness and efficiency. Extensive experiments across multiple benchmarks show that our method significantly reduces hallucinations at the object, attribute, and relation levels while largely preserving recall and caption richness, e.g., achieving a hallucination reduction by over 5% using LLaVA-v1.5-7B on CHAIR. Furthermore, results on diverse architectures, including LLaVA-NEXT-7B, Cambrian-8B, and InstructBLIP-7B, validate strong cross-architecture generalization. More importantly, when applied to hallucination-free captions, our method introduces almost no side effects, underscoring its robustness and practical plug-and-play applicability. The implementation will be publicly available.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.410079"
    },
    {
        "index": "#67",
        "title": "FailureAtlas:Mapping the Failure Landscape of T2I Models via Active Exploration",
        "link": "/arxiv/2509.21995",
        "arxiv_id": "2509.21995",
        "authors": "Muxi Chen, Zhaohua Zhang, Chenchen Zhao, Mingyang Chen, Wenyu Jiang, Tianwen Jiang, Jianhuan Zhuo, Yu Tang, Qiuyong Xiao, Jihong Zhang, Qiang Xu",
        "summary": "Static benchmarks have provided a valuable foundation for comparing Text-to-Image (T2I) models. However, their passive design offers limited diagnostic power, struggling to uncover the full landscape of systematic failures or isolate their root causes. We argue for a complementary paradigm: active exploration. We introduce FailureAtlas, the first framework designed to autonomously explore and map the vast failure landscape of T2I models at scale. FailureAtlas frames error discovery as a structured search for minimal, failure-inducing concepts. While it is a computationally explosive problem, we make it tractable with novel acceleration techniques. When applied to Stable Diffusion models, our method uncovers hundreds of thousands of previously unknown error slices (over 247,000 in SD1.5 alone) and provides the first large-scale evidence linking these failures to data scarcity in the training set. By providing a principled and scalable engine for deep model auditing, FailureAtlas establishes a new, diagnostic-first methodology to guide the development of more robust generative AI. The code is available at https://github.com/cure-lab/FailureAtlas",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.410791"
    },
    {
        "index": "#68",
        "title": "Rate-Distortion Optimized Communication for Collaborative Perception",
        "link": "/arxiv/2509.21994",
        "arxiv_id": "2509.21994",
        "authors": "Genjia Liu, Anning Hu, Yue Hu, Wenjun Zhang, Siheng Chen",
        "summary": "Collaborative perception emphasizes enhancing environmental understanding by enabling multiple agents to share visual information with limited bandwidth resources. While prior work has explored the empirical trade-off between task performance and communication volume, a significant gap remains in the theoretical foundation. To fill this gap, we draw on information theory and introduce a pragmatic rate-distortion theory for multi-agent collaboration, specifically formulated to analyze performance-communication trade-off in goal-oriented multi-agent systems. This theory concretizes two key conditions for designing optimal communication strategies: supplying pragmatically relevant information and transmitting redundancy-less messages. Guided by these two conditions, we propose RDcomm, a communication-efficient collaborative perception framework that introduces two key innovations: i) task entropy discrete coding, which assigns features with task-relevant codeword-lengths to maximize the efficiency in supplying pragmatic information; ii) mutual-information-driven message selection, which utilizes mutual information neural estimation to approach the optimal redundancy-less condition. Experiments on 3D object detection and BEV segmentation demonstrate that RDcomm achieves state-of-the-art accuracy on DAIR-V2X and OPV2V, while reducing communication volume by up to 108 times. The code will be released.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.411396"
    },
    {
        "index": "#69",
        "title": "DualFocus: Depth from Focus with Spatio-Focal Dual Variational Constraints",
        "link": "/arxiv/2509.21992",
        "arxiv_id": "2509.21992",
        "authors": "Sungmin Woo, Sangyoun Lee",
        "summary": "Depth-from-Focus (DFF) enables precise depth estimation by analyzing focus cues across a stack of images captured at varying focal lengths. While recent learning-based approaches have advanced this field, they often struggle in complex scenes with fine textures or abrupt depth changes, where focus cues may become ambiguous or misleading. We present DualFocus, a novel DFF framework that leverages the focal stack's unique gradient patterns induced by focus variation, jointly modeling focus changes over spatial and focal dimensions. Our approach introduces a variational formulation with dual constraints tailored to DFF: spatial constraints exploit gradient pattern changes across focus levels to distinguish true depth edges from texture artifacts, while focal constraints enforce unimodal, monotonic focus probabilities aligned with physical focus behavior. These inductive biases improve robustness and accuracy in challenging regions. Comprehensive experiments on four public datasets demonstrate that DualFocus consistently outperforms state-of-the-art methods in both depth accuracy and perceptual quality.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.411974"
    },
    {
        "index": "#70",
        "title": "ERGO: Efficient High-Resolution Visual Understanding for Vision-Language Models",
        "link": "/arxiv/2509.21991",
        "arxiv_id": "2509.21991",
        "authors": "Jewon Lee, Wooksu Shin, Seungmin Yang, Ki-Ung Song, DongUk Lim, Jaeyeon Kim, Tae-Ho Kim, Bo-Kyeong Kim",
        "summary": "Efficient processing of high-resolution images is crucial for real-world vision-language applications. However, existing Large Vision-Language Models (LVLMs) incur substantial computational overhead due to the large number of vision tokens. With the advent of \"thinking with images\" models, reasoning now extends beyond text to the visual domain. This capability motivates our two-stage \"coarse-to-fine\" reasoning pipeline: first, a downsampled image is analyzed to identify task-relevant regions; then, only these regions are cropped at full resolution and processed in a subsequent reasoning stage. This approach reduces computational cost while preserving fine-grained visual details where necessary. A major challenge lies in inferring which regions are truly relevant to a given query. Recent related methods often fail in the first stage after input-image downsampling, due to perception-driven reasoning, where clear visual information is required for effective reasoning. To address this issue, we propose ERGO (Efficient Reasoning & Guided Observation) that performs reasoning-driven perception-leveraging multimodal context to determine where to focus. Our model can account for perceptual uncertainty, expanding the cropped region to cover visually ambiguous areas for answering questions. To this end, we develop simple yet effective reward components in a reinforcement learning framework for coarse-to-fine perception. Across multiple datasets, our approach delivers higher accuracy than the original model and competitive methods, with greater efficiency. For instance, ERGO surpasses Qwen2.5-VL-7B on the V* benchmark by 4.7 points while using only 23% of the vision tokens, achieving a 3x inference speedup. The code and models can be found at: https://github.com/nota-github/ERGO.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.412705"
    },
    {
        "index": "#71",
        "title": "WAVE: Learning Unified & Versatile Audio-Visual Embeddings with Multimodal LLM",
        "link": "/arxiv/2509.21990",
        "arxiv_id": "2509.21990",
        "authors": "Changli Tang, Qinfan Xiao, Ke Mei, Tianyi Wang, Fengyun Rao, Chao Zhang",
        "summary": "While embeddings from multimodal large language models (LLMs) excel as general-purpose representations, their application to dynamic modalities like audio and video remains underexplored. We introduce WAVE (\\textbf{u}nified \\& \\textbf{v}ersatile \\textbf{a}udio-\\textbf{v}isual \\textbf{e}mbeddings), the first LLM-based embedding that creates a unified representation space for text, audio, and video modalities. WAVE employs a novel hierarchical feature fusion strategy and a joint multi-modal, multi-task training approach to enable two key capabilities: any-to-any cross-modal retrieval and the generation of prompt-aware embeddings tailored to user instructions. Experimentally, WAVE sets a new state-of-the-art on the MMEB-v2 video benchmark and achieves superior results in audio and video-to-audio retrieval. Its prompt-aware nature also yields remarkable performance in multimodal question answering, significantly outperforming existing embedding models. Ablation studies validate our joint training strategy, demonstrating improved performance across all modalities. With a newly introduced benchmark for versatile audio-visual learning, WAVE opens up broad possibilities for cross-modal, any-to-any applications. Our code, checkpoints, and data will be released.",
        "subjects": "Computer Vision and Pattern Recognition, Sound",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.413359"
    },
    {
        "index": "#72",
        "title": "Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation",
        "link": "/arxiv/2509.21989",
        "arxiv_id": "2509.21989",
        "authors": "Abdelrahman Eldesokey, Aleksandar Cvejic, Bernard Ghanem, Peter Wonka",
        "summary": "We propose a novel approach for disentangling visual and semantic features from the backbones of pre-trained diffusion models, enabling visual correspondence in a manner analogous to the well-established semantic correspondence. While diffusion model backbones are known to encode semantically rich features, they must also contain visual features to support their image synthesis capabilities. However, isolating these visual features is challenging due to the absence of annotated datasets. To address this, we introduce an automated pipeline that constructs image pairs with annotated semantic and visual correspondences based on existing subject-driven image generation datasets, and design a contrastive architecture to separate the two feature types. Leveraging the disentangled representations, we propose a new metric, Visual Semantic Matching (VSM), that quantifies visual inconsistencies in subject-driven image generation. Empirical results show that our approach outperforms global feature-based metrics such as CLIP, DINO, and vision--language models in quantifying visual inconsistencies while also enabling spatial localization of inconsistent regions. To our knowledge, this is the first method that supports both quantification and localization of inconsistencies in subject-driven generation, offering a valuable tool for advancing this task. Project Page:https://abdo-eldesokey.github.io/mind-the-glitch/",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.413947"
    },
    {
        "index": "#73",
        "title": "From Bias to Balance: Exploring and Mitigating Spatial Bias in LVLMs",
        "link": "/arxiv/2509.21984",
        "arxiv_id": "2509.21984",
        "authors": "Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Weili Guan, Jun Yu, Min Zhang",
        "summary": "Large Vision-Language Models (LVLMs) have achieved remarkable success across a wide range of multimodal tasks, yet their robustness to spatial variations remains insufficiently understood. In this work, we present a systematic study of the spatial bias of LVLMs, focusing on how models respond when identical key visual information is placed at different locations within an image. Through a carefully designed probing dataset, we demonstrate that current LVLMs often produce inconsistent outputs under such spatial shifts, revealing a fundamental limitation in their spatial-semantic understanding. Further analysis shows that this phenomenon originates not from the vision encoder, which reliably perceives and interprets visual content across positions, but from the unbalanced design of position embeddings in the language model component. In particular, the widely adopted position embedding strategies, such as RoPE, introduce imbalance during cross-modal interaction, leading image tokens at different positions to exert unequal influence on semantic understanding. To mitigate this issue, we introduce Balanced Position Assignment (BaPA), a simple yet effective mechanism that assigns identical position embeddings to all image tokens, promoting a more balanced integration of visual information. Extensive experiments show that BaPA enhances the spatial robustness of LVLMs without retraining and further boosts their performance across diverse multimodal benchmarks when combined with lightweight fine-tuning. Further analysis of information flow reveals that BaPA yields balanced attention, enabling more holistic visual understanding.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.419668"
    },
    {
        "index": "#74",
        "title": "Resolving Ambiguity in Gaze-Facilitated Visual Assistant Interaction Paradigm",
        "link": "/arxiv/2509.21980",
        "arxiv_id": "2509.21980",
        "authors": "Zeyu Wang, Baiyu Chen, Kun Yan, Hongjing Piao, Hao Xue, Flora D. Salim, Yuanchun Shi, Yuntao Wang",
        "summary": "With the rise in popularity of smart glasses, users' attention has been integrated into Vision-Language Models (VLMs) to streamline multi-modal querying in daily scenarios. However, leveraging gaze data to model users' attention may introduce ambiguity challenges: (1) users' verbal questions become ambiguous by using pronouns or skipping context, (2) humans' gaze patterns can be noisy and exhibit complex spatiotemporal relationships with their spoken questions. Previous works only consider single image as visual modality input, failing to capture the dynamic nature of the user's attention. In this work, we introduce GLARIFY, a novel method to leverage spatiotemporal gaze information to enhance the model's effectiveness in real-world applications. Initially, we analyzed hundreds of querying samples with the gaze modality to demonstrate the noisy nature of users' gaze patterns. We then utilized GPT-4o to design an automatic data synthesis pipeline to generate the GLARIFY-Ambi dataset, which includes a dedicated chain-of-thought (CoT) process to handle noisy gaze patterns. Finally, we designed a heatmap module to incorporate gaze information into cutting-edge VLMs while preserving their pretrained knowledge. We evaluated GLARIFY using a hold-out test set. Experiments demonstrate that GLARIFY significantly outperforms baselines. By robustly aligning VLMs with human attention, GLARIFY paves the way for a usable and intuitive interaction paradigm with a visual assistant.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.420440"
    },
    {
        "index": "#75",
        "title": "Benchmarking and Mitigate Psychological Sycophancy in Medical Vision-Language Models",
        "link": "/arxiv/2509.21979",
        "arxiv_id": "2509.21979",
        "authors": "Zikun Guo, Xinyue Xu, Pei Xiang, Shu Yang, Xin Han, Di Wang, Lijie Hu",
        "summary": "Vision language models(VLMs) are increasingly integrated into clinical workflows, but they often exhibit sycophantic behavior prioritizing alignment with user phrasing social cues or perceived authority over evidence based reasoning. This study evaluate clinical sycophancy in medical visual question answering through a novel clinically grounded benchmark. We propose a medical sycophancy dataset construct from PathVQA, SLAKE, and VQA-RAD stratified by different type organ system and modality. Using psychologically motivated pressure templates including various sycophancy. In our adversarial experiments on various VLMs, we found that these models are generally vulnerable, exhibiting significant variations in the occurrence of adversarial responses, with weak correlations to the model accuracy or size. Imitation and expert provided corrections were found to be the most effective triggers, suggesting that the models possess a bias mechanism independent of visual evidence. To address this, we propose Visual Information Purification for Evidence based Response (VIPER) a lightweight mitigation strategy that filters non evidentiary content for example social pressures and then generates constrained evidence first answers. This framework reduces sycophancy by an average amount outperforming baselines while maintaining interpretability. Our benchmark analysis and mitigation framework lay the groundwork for robust deployment of medical VLMs in real world clinician interactions emphasizing the need for evidence anchored defenses.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.420960"
    },
    {
        "index": "#76",
        "title": "Geo-R1: Improving Few-Shot Geospatial Referring Expression Understanding with Reinforcement Fine-Tuning",
        "link": "/arxiv/2509.21976",
        "arxiv_id": "2509.21976",
        "authors": "Zilun Zhang, Zian Guan, Tiancheng Zhao, Haozhan Shen, Tianyu Li, Yuxiang Cai, Zhonggen Su, Zhaojun Liu, Jianwei Yin, Xiang Li",
        "summary": "Referring expression understanding in remote sensing poses unique challenges, as it requires reasoning over complex object-context relationships. While supervised fine-tuning (SFT) on multimodal large language models achieves strong performance with massive labeled datasets, they struggle in data-scarce scenarios, leading to poor generalization. To address this limitation, we propose Geo-R1, a reasoning-centric reinforcement fine-tuning (RFT) paradigm for few-shot geospatial referring. Geo-R1 enforces the model to first generate explicit, interpretable reasoning chains that decompose referring expressions, and then leverage these rationales to localize target objects. This \"reason first, then act\" process enables the model to make more effective use of limited annotations, enhances generalization, and provides interpretability. We validate Geo-R1 on three carefully designed few-shot geospatial referring benchmarks, where our model consistently and substantially outperforms SFT baselines. It also demonstrates strong cross-dataset generalization, highlighting its robustness. Code and data will be released at http://geo-r1.github.io.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.421526"
    },
    {
        "index": "#77",
        "title": "No-Reference Image Contrast Assessment with Customized EfficientNet-B0",
        "link": "/arxiv/2509.21967",
        "arxiv_id": "2509.21967",
        "authors": "Javad Hassannataj Joloudari, Bita Mesbahzadeh, Omid Zare, Emrah Arslan, Roohallah Alizadehsani, Hossein Moosaei",
        "summary": "Image contrast was a fundamental factor in visual perception and played a vital role in overall image quality. However, most no reference image quality assessment NR IQA models struggled to accurately evaluate contrast distortions under diverse real world conditions. In this study, we proposed a deep learning based framework for blind contrast quality assessment by customizing and fine-tuning three pre trained architectures, EfficientNet B0, ResNet18, and MobileNetV2, for perceptual Mean Opinion Score, along with an additional model built on a Siamese network, which indicated a limited ability to capture perceptual contrast distortions. Each model is modified with a contrast-aware regression head and trained end to end using targeted data augmentations on two benchmark datasets, CID2013 and CCID2014, containing synthetic and authentic contrast distortions. Performance is evaluated using Pearson Linear Correlation Coefficient and Spearman Rank Order Correlation Coefficient, which assess the alignment between predicted and human rated scores. Among these three models, our customized EfficientNet B0 model achieved state-of-the-art performance with PLCC = 0.9286 and SRCC = 0.9178 on CCID2014 and PLCC = 0.9581 and SRCC = 0.9369 on CID2013, surpassing traditional methods and outperforming other deep baselines. These results highlighted the models robustness and effectiveness in capturing perceptual contrast distortion. Overall, the proposed method demonstrated that contrast aware adaptation of lightweight pre trained networks can yield a high performing, scalable solution for no reference contrast quality assessment suitable for real time and resource constrained applications.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.422050"
    },
    {
        "index": "#78",
        "title": "PartSAM: A Scalable Promptable Part Segmentation Model Trained on Native 3D Data",
        "link": "/arxiv/2509.21965",
        "arxiv_id": "2509.21965",
        "authors": "Zhe Zhu, Le Wan, Rui Xu, Yiheng Zhang, Honghua Chen, Zhiyang Dou, Cheng Lin, Yuan Liu, Mingqiang Wei",
        "summary": "Segmenting 3D objects into parts is a long-standing challenge in computer vision. To overcome taxonomy constraints and generalize to unseen 3D objects, recent works turn to open-world part segmentation. These approaches typically transfer supervision from 2D foundation models, such as SAM, by lifting multi-view masks into 3D. However, this indirect paradigm fails to capture intrinsic geometry, leading to surface-only understanding, uncontrolled decomposition, and limited generalization. We present PartSAM, the first promptable part segmentation model trained natively on large-scale 3D data. Following the design philosophy of SAM, PartSAM employs an encoder-decoder architecture in which a triplane-based dual-branch encoder produces spatially structured tokens for scalable part-aware representation learning. To enable large-scale supervision, we further introduce a model-in-the-loop annotation pipeline that curates over five million 3D shape-part pairs from online assets, providing diverse and fine-grained labels. This combination of scalable architecture and diverse 3D data yields emergent open-world capabilities: with a single prompt, PartSAM achieves highly accurate part identification, and in a Segment-Every-Part mode, it automatically decomposes shapes into both surface and internal structures. Extensive experiments show that PartSAM outperforms state-of-the-art methods by large margins across multiple benchmarks, marking a decisive step toward foundation models for 3D part understanding. Our code and model will be released soon.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.422588"
    },
    {
        "index": "#79",
        "title": "MultiCrafter: High-Fidelity Multi-Subject Generation via Spatially Disentangled Attention and Identity-Aware Reinforcement Learning",
        "link": "/arxiv/2509.21953",
        "arxiv_id": "2509.21953",
        "authors": "Tao Wu, Yibo Jiang, Yehao Lu, Zhizhong Wang, Zeyi Huang, Zequn Qin, Xi Li",
        "summary": "Multi-subject image generation aims to synthesize user-provided subjects in a single image while preserving subject fidelity, ensuring prompt consistency, and aligning with human aesthetic preferences. However, existing methods, particularly those built on the In-Context-Learning paradigm, are limited by their reliance on simple reconstruction-based objectives, leading to both severe attribute leakage that compromises subject fidelity and failing to align with nuanced human preferences. To address this, we propose MultiCrafter, a framework that ensures high-fidelity, preference-aligned generation. First, we find that the root cause of attribute leakage is a significant entanglement of attention between different subjects during the generation process. Therefore, we introduce explicit positional supervision to explicitly separate attention regions for each subject, effectively mitigating attribute leakage. To enable the model to accurately plan the attention region of different subjects in diverse scenarios, we employ a Mixture-of-Experts architecture to enhance the model's capacity, allowing different experts to focus on different scenarios. Finally, we design a novel online reinforcement learning framework to align the model with human preferences, featuring a scoring mechanism to accurately assess multi-subject fidelity and a more stable training strategy tailored for the MoE architecture. Experiments validate that our framework significantly improves subject fidelity while aligning with human preferences better.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.423109"
    },
    {
        "index": "#80",
        "title": "Customizing Visual Emotion Evaluation for MLLMs: An Open-vocabulary, Multifaceted, and Scalable Approach",
        "link": "/arxiv/2509.21950",
        "arxiv_id": "2509.21950",
        "authors": "Daiqing Wu, Dongbao Yang, Sicheng Zhao, Can Ma, Yu Zhou",
        "summary": "Recently, Multimodal Large Language Models (MLLMs) have achieved exceptional performance across diverse tasks, continually surpassing previous expectations regarding their capabilities. Nevertheless, their proficiency in perceiving emotions from images remains debated, with studies yielding divergent results in zero-shot scenarios. We argue that this inconsistency stems partly from constraints in existing evaluation methods, including the oversight of plausible responses, limited emotional taxonomies, neglect of contextual factors, and labor-intensive annotations. To facilitate customized visual emotion evaluation for MLLMs, we propose an Emotion Statement Judgment task that overcomes these constraints. Complementing this task, we devise an automated pipeline that efficiently constructs emotion-centric statements with minimal human effort. Through systematically evaluating prevailing MLLMs, our study showcases their stronger performance in emotion interpretation and context-based emotion judgment, while revealing relative limitations in comprehending perception subjectivity. When compared to humans, even top-performing MLLMs like GPT4o demonstrate remarkable performance gaps, underscoring key areas for future improvement. By developing a fundamental evaluation framework and conducting a comprehensive MLLM assessment, we hope this work contributes to advancing emotional intelligence in MLLMs. Project page: https://github.com/wdqqdw/MVEI.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.423576"
    },
    {
        "index": "#81",
        "title": "SemanticControl: A Training-Free Approach for Handling Loosely Aligned Visual Conditions in ControlNet",
        "link": "/arxiv/2509.21938",
        "arxiv_id": "2509.21938",
        "authors": "Woosung Joung, Daewon Chae, Jinkyu Kim",
        "summary": "ControlNet has enabled detailed spatial control in text-to-image diffusion models by incorporating additional visual conditions such as depth or edge maps. However, its effectiveness heavily depends on the availability of visual conditions that are precisely aligned with the generation goal specified by text prompt-a requirement that often fails in practice, especially for uncommon or imaginative scenes. For example, generating an image of a cat cooking in a specific pose may be infeasible due to the lack of suitable visual conditions. In contrast, structurally similar cues can often be found in more common settings-for instance, poses of humans cooking are widely available and can serve as rough visual guides. Unfortunately, existing ControlNet models struggle to use such loosely aligned visual conditions, often resulting in low text fidelity or visual artifacts. To address this limitation, we propose SemanticControl, a training-free method for effectively leveraging misaligned but semantically relevant visual conditions. Our approach adaptively suppresses the influence of the visual condition where it conflicts with the prompt, while strengthening guidance from the text. The key idea is to first run an auxiliary denoising process using a surrogate prompt aligned with the visual condition (e.g., \"a human playing guitar\" for a human pose condition) to extract informative attention masks, and then utilize these masks during the denoising of the actual target prompt (e.g., cat playing guitar). Experimental results demonstrate that our method improves performance under loosely aligned conditions across various conditions, including depth maps, edge maps, and human skeletons, outperforming existing baselines. Our code is available at https://mung3477.github.io/semantic-control.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.424046"
    },
    {
        "index": "#82",
        "title": "DynaNav: Dynamic Feature and Layer Selection for Efficient Visual Navigation",
        "link": "/arxiv/2509.21930",
        "arxiv_id": "2509.21930",
        "authors": "Jiahui Wang, Changhao Chen",
        "summary": "Visual navigation is essential for robotics and embodied AI. However, existing foundation models, particularly those with transformer decoders, suffer from high computational overhead and lack interpretability, limiting their deployment in resource-tight scenarios. To address this, we propose DynaNav, a Dynamic Visual Navigation framework that adapts feature and layer selection based on scene complexity. It employs a trainable hard feature selector for sparse operations, enhancing efficiency and interpretability. Additionally, we integrate feature selection into an early-exit mechanism, with Bayesian Optimization determining optimal exit thresholds to reduce computational cost. Extensive experiments in real-world-based datasets and simulated environments demonstrate the effectiveness of DynaNav. Compared to ViNT, DynaNav achieves a 2.26x reduction in FLOPs, 42.3% lower inference time, and 32.8% lower memory usage, while improving navigation performance across four public datasets.",
        "subjects": "Computer Vision and Pattern Recognition, Robotics",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.424497"
    },
    {
        "index": "#83",
        "title": "SingRef6D: Monocular Novel Object Pose Estimation with a Single RGB Reference",
        "link": "/arxiv/2509.21927",
        "arxiv_id": "2509.21927",
        "authors": "Jiahui Wang, Haiyue Zhu, Haoren Guo, Abdullah Al Mamun, Cheng Xiang, Tong Heng Lee",
        "summary": "Recent 6D pose estimation methods demonstrate notable performance but still face some practical limitations. For instance, many of them rely heavily on sensor depth, which may fail with challenging surface conditions, such as transparent or highly reflective materials. In the meantime, RGB-based solutions provide less robust matching performance in low-light and texture-less scenes due to the lack of geometry information. Motivated by these, we propose SingRef6D, a lightweight pipeline requiring only a single RGB image as a reference, eliminating the need for costly depth sensors, multi-view image acquisition, or training view synthesis models and neural fields. This enables SingRef6D to remain robust and capable even under resource-limited settings where depth or dense templates are unavailable. Our framework incorporates two key innovations. First, we propose a token-scaler-based fine-tuning mechanism with a novel optimization loss on top of Depth-Anything v2 to enhance its ability to predict accurate depth, even for challenging surfaces. Our results show a 14.41% improvement (in $\\delta_{1.05}$) on REAL275 depth prediction compared to Depth-Anything v2 (with fine-tuned head). Second, benefiting from depth availability, we introduce a depth-aware matching process that effectively integrates spatial relationships within LoFTR, enabling our system to handle matching for challenging materials and lighting conditions. Evaluations of pose estimation on the REAL275, ClearPose, and Toyota-Light datasets show that our approach surpasses state-of-the-art methods, achieving a 6.1% improvement in average recall.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.430139"
    },
    {
        "index": "#84",
        "title": "PANICL: Mitigating Over-Reliance on Single Prompt in Visual In-Context Learning",
        "link": "/arxiv/2509.21926",
        "arxiv_id": "2509.21926",
        "authors": "Jiahao Zhang, Bowen Wang, Hong Liu, Yuta Nakashima, Hajime Nagahara",
        "summary": "Visual In-Context Learning (VICL) uses input-output image pairs, referred to as in-context pairs (or examples), as prompts alongside query images to guide models in performing diverse vision tasks. However, VICL often suffers from over-reliance on a single in-context pair, which can lead to biased and unstable predictions. We introduce PAtch-based $k$-Nearest neighbor visual In-Context Learning (PANICL), a general training-free framework that mitigates this issue by leveraging multiple in-context pairs. PANICL smooths assignment scores across pairs, reducing bias without requiring additional training. Extensive experiments on a variety of tasks, including foreground segmentation, single object detection, colorization, multi-object segmentation, and keypoint detection, demonstrate consistent improvements over strong baselines. Moreover, PANICL exhibits strong robustness to domain shifts, including dataset-level shift (e.g., from COCO to Pascal) and label-space shift (e.g., FSS-1000), and generalizes well to other VICL models such as SegGPT, Painter, and LVM, highlighting its versatility and broad applicability.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.430621"
    },
    {
        "index": "#85",
        "title": "Spatial Reasoning in Foundation Models: Benchmarking Object-Centric Spatial Understanding",
        "link": "/arxiv/2509.21922",
        "arxiv_id": "2509.21922",
        "authors": "Vahid Mirjalili, Ramin Giahi, Sriram Kollipara, Akshay Kekuda, Kehui Yao, Kai Zhao, Jianpeng Xu, Kaushiki Nag, Sinduja Subramaniam, Topojoy Biswas, Evren Korpeoglu, Kannan Achan",
        "summary": "Spatial understanding is a critical capability for vision foundation models. While recent advances in large vision models or vision-language models (VLMs) have expanded recognition capabilities, most benchmarks emphasize localization accuracy rather than whether models capture how objects are arranged and related within a scene. This gap is consequential; effective scene understanding requires not only identifying objects, but reasoning about their relative positions, groupings, and depth. In this paper, we present a systematic benchmark for object-centric spatial reasoning in foundation models. Using a controlled synthetic dataset, we evaluate state-of-the-art vision models (e.g., GroundingDINO, Florence-2, OWLv2) and large VLMs (e.g., InternVL, LLaVA, GPT-4o) across three tasks: spatial localization, spatial reasoning, and downstream retrieval tasks. We find a stable trade-off: detectors such as GroundingDINO and OWLv2 deliver precise boxes with limited relational reasoning, while VLMs like SmolVLM and GPT-4o provide coarse layout cues and fluent captions but struggle with fine-grained spatial context. Our study highlights the gap between localization and true spatial understanding, and pointing toward the need for spatially-aware foundation models in the community.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.431205"
    },
    {
        "index": "#86",
        "title": "Multi-View Crowd Counting With Self-Supervised Learning",
        "link": "/arxiv/2509.21918",
        "arxiv_id": "2509.21918",
        "authors": "Hong Mo, Xiong Zhang, Tengfei Shi, Zhongbo Wu",
        "summary": "Multi-view counting (MVC) methods have attracted significant research attention and stimulated remarkable progress in recent years. Despite their success, most MVC methods have focused on improving performance by following the fully supervised learning (FSL) paradigm, which often requires large amounts of annotated data. In this work, we propose SSLCounter, a novel self-supervised learning (SSL) framework for MVC that leverages neural volumetric rendering to alleviate the reliance on large-scale annotated datasets. SSLCounter learns an implicit representation w.r.t. the scene, enabling the reconstruction of continuous geometry shape and the complex, view-dependent appearance of their 2D projections via differential neural rendering. Owing to its inherent flexibility, the key idea of our method can be seamlessly integrated into exsiting frameworks. Notably, extensive experiments demonstrate that SSLCounter not only demonstrates state-of-the-art performances but also delivers competitive performance with only using 70% proportion of training data, showcasing its superior data efficiency across multiple MVC benchmarks.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.431666"
    },
    {
        "index": "#87",
        "title": "Taming Flow-based I2V Models for Creative Video Editing",
        "link": "/arxiv/2509.21917",
        "arxiv_id": "2509.21917",
        "authors": "Xianghao Kong, Hansheng Chen, Yuwei Guo, Lvmin Zhang, Gordon Wetzstein, Maneesh Agrawala, Anyi Rao",
        "summary": "Although image editing techniques have advanced significantly, video editing, which aims to manipulate videos according to user intent, remains an emerging challenge. Most existing image-conditioned video editing methods either require inversion with model-specific design or need extensive optimization, limiting their capability of leveraging up-to-date image-to-video (I2V) models to transfer the editing capability of image editing models to the video domain. To this end, we propose IF-V2V, an Inversion-Free method that can adapt off-the-shelf flow-matching-based I2V models for video editing without significant computational overhead. To circumvent inversion, we devise Vector Field Rectification with Sample Deviation to incorporate information from the source video into the denoising process by introducing a deviation term into the denoising vector field. To further ensure consistency with the source video in a model-agnostic way, we introduce Structure-and-Motion-Preserving Initialization to generate motion-aware temporally correlated noise with structural information embedded. We also present a Deviation Caching mechanism to minimize the additional computational cost for denoising vector rectification without significantly impacting editing quality. Evaluations demonstrate that our method achieves superior editing quality and consistency over existing approaches, offering a lightweight plug-and-play solution to realize visual creativity.",
        "subjects": "Computer Vision and Pattern Recognition, Multimedia",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.432201"
    },
    {
        "index": "#88",
        "title": "Enhancing Vehicle Detection under Adverse Weather Conditions with Contrastive Learning",
        "link": "/arxiv/2509.21916",
        "arxiv_id": "2509.21916",
        "authors": "Boying Li, Chang Liu, Petter Kyösti, Mattias Öhman, Devashish Singha Roy, Sofia Plazzi, Hamam Mokayed, Olle Hagner",
        "summary": "Aside from common challenges in remote sensing like small, sparse targets and computation cost limitations, detecting vehicles from UAV images in the Nordic regions faces strong visibility challenges and domain shifts caused by diverse levels of snow coverage. Although annotated data are expensive, unannotated data is cheaper to obtain by simply flying the drones. In this work, we proposed a sideload-CL-adaptation framework that enables the use of unannotated data to improve vehicle detection using lightweight models. Specifically, we propose to train a CNN-based representation extractor through contrastive learning on the unannotated data in the pretraining stage, and then sideload it to a frozen YOLO11n backbone in the fine-tuning stage. To find a robust sideload-CL-adaptation, we conducted extensive experiments to compare various fusion methods and granularity. Our proposed sideload-CL-adaptation model improves the detection performance by 3.8% to 9.5% in terms of mAP50 on the NVD dataset.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.432711"
    },
    {
        "index": "#89",
        "title": "TDEdit: A Unified Diffusion Framework for Text-Drag Guided Image Manipulation",
        "link": "/arxiv/2509.21905",
        "arxiv_id": "2509.21905",
        "authors": "Qihang Wang, Yaxiong Wang, Lechao Cheng, Zhun Zhong",
        "summary": "This paper explores image editing under the joint control of text and drag interactions. While recent advances in text-driven and drag-driven editing have achieved remarkable progress, they suffer from complementary limitations: text-driven methods excel in texture manipulation but lack precise spatial control, whereas drag-driven approaches primarily modify shape and structure without fine-grained texture guidance. To address these limitations, we propose a unified diffusion-based framework for joint drag-text image editing, integrating the strengths of both paradigms. Our framework introduces two key innovations: (1) Point-Cloud Deterministic Drag, which enhances latent-space layout control through 3D feature mapping, and (2) Drag-Text Guided Denoising, dynamically balancing the influence of drag and text conditions during denoising. Notably, our model supports flexible editing modes - operating with text-only, drag-only, or combined conditions - while maintaining strong performance in each setting. Extensive quantitative and qualitative experiments demonstrate that our method not only achieves high-fidelity joint editing but also matches or surpasses the performance of specialized text-only or drag-only approaches, establishing a versatile and generalizable solution for controllable image manipulation. Code will be made publicly available to reproduce all results presented in this work.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.433173"
    },
    {
        "index": "#90",
        "title": "LG-CD: Enhancing Language-Guided Change Detection through SAM2 Adaptation",
        "link": "/arxiv/2509.21894",
        "arxiv_id": "2509.21894",
        "authors": "Yixiao Liu, Yizhou Yang, Jinwen Li, Jun Tao, Ruoyu Li, Xiangkun Wang, Min Zhu, Junlong Cheng",
        "summary": "Remote Sensing Change Detection (RSCD) typically identifies changes in land cover or surface conditions by analyzing multi-temporal images. Currently, most deep learning-based methods primarily focus on learning unimodal visual information, while neglecting the rich semantic information provided by multimodal data such as text. To address this limitation, we propose a novel Language-Guided Change Detection model (LG-CD). This model leverages natural language prompts to direct the network's attention to regions of interest, significantly improving the accuracy and robustness of change detection. Specifically, LG-CD utilizes a visual foundational model (SAM2) as a feature extractor to capture multi-scale pyramid features from high-resolution to low-resolution across bi-temporal remote sensing images. Subsequently, multi-layer adapters are employed to fine-tune the model for downstream tasks, ensuring its effectiveness in remote sensing change detection. Additionally, we design a Text Fusion Attention Module (TFAM) to align visual and textual information, enabling the model to focus on target change regions using text prompts. Finally, a Vision-Semantic Fusion Decoder (V-SFD) is implemented, which deeply integrates visual and semantic information through a cross-attention mechanism to produce highly accurate change detection masks. Our experiments on three datasets (LEVIR-CD, WHU-CD, and SYSU-CD) demonstrate that LG-CD consistently outperforms state-of-the-art change detection methods. Furthermore, our approach provides new insights into achieving generalized change detection by leveraging multimodal information.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.433687"
    },
    {
        "index": "#91",
        "title": "Syncphony: Synchronized Audio-to-Video Generation with Diffusion Transformers",
        "link": "/arxiv/2509.21893",
        "arxiv_id": "2509.21893",
        "authors": "Jibin Song, Mingi Kwon, Jaeseok Jeong, Youngjung Uh",
        "summary": "Text-to-video and image-to-video generation have made rapid progress in visual quality, but they remain limited in controlling the precise timing of motion. In contrast, audio provides temporal cues aligned with video motion, making it a promising condition for temporally controlled video generation. However, existing audio-to-video (A2V) models struggle with fine-grained synchronization due to indirect conditioning mechanisms or limited temporal modeling capacity. We present Syncphony, which generates 380x640 resolution, 24fps videos synchronized with diverse audio inputs. Our approach builds upon a pre-trained video backbone and incorporates two key components to improve synchronization: (1) Motion-aware Loss, which emphasizes learning at high-motion regions; (2) Audio Sync Guidance, which guides the full model using a visually aligned off-sync model without audio layers to better exploit audio cues at inference while maintaining visual quality. To evaluate synchronization, we propose CycleSync, a video-to-audio-based metric that measures the amount of motion cues in the generated video to reconstruct the original audio. Experiments on AVSync15 and The Greatest Hits datasets demonstrate that Syncphony outperforms existing methods in both synchronization accuracy and visual quality. Project page is available at: https://jibin86.github.io/syncphony_project_page",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.434144"
    },
    {
        "index": "#92",
        "title": "Drag4D: Align Your Motion with Text-Driven 3D Scene Generation",
        "link": "/arxiv/2509.21888",
        "arxiv_id": "2509.21888",
        "authors": "Minjun Kang, Inkyu Shin, Taeyeop Lee, In So Kweon, Kuk-Jin Yoon",
        "summary": "We introduce Drag4D, an interactive framework that integrates object motion control within text-driven 3D scene generation. This framework enables users to define 3D trajectories for the 3D objects generated from a single image, seamlessly integrating them into a high-quality 3D background. Our Drag4D pipeline consists of three stages. First, we enhance text-to-3D background generation by applying 2D Gaussian Splatting with panoramic images and inpainted novel views, resulting in dense and visually complete 3D reconstructions. In the second stage, given a reference image of the target object, we introduce a 3D copy-and-paste approach: the target instance is extracted in a full 3D mesh using an off-the-shelf image-to-3D model and seamlessly composited into the generated 3D scene. The object mesh is then positioned within the 3D scene via our physics-aware object position learning, ensuring precise spatial alignment. Lastly, the spatially aligned object is temporally animated along a user-defined 3D trajectory. To mitigate motion hallucination and ensure view-consistent temporal alignment, we develop a part-augmented, motion-conditioned video diffusion model that processes multiview image pairs together with their projected 2D trajectories. We demonstrate the effectiveness of our unified architecture through evaluations at each stage and in the final results, showcasing the harmonized alignment of user-controlled object motion within a high-quality 3D background.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.434614"
    },
    {
        "index": "#93",
        "title": "StableDub: Taming Diffusion Prior for Generalized and Efficient Visual Dubbing",
        "link": "/arxiv/2509.21887",
        "arxiv_id": "2509.21887",
        "authors": "Liyang Chen, Tianze Zhou, Xu He, Boshi Tang, Zhiyong Wu, Yang Huang, Yang Wu, Zhongqian Sun, Wei Yang, Helen Meng",
        "summary": "The visual dubbing task aims to generate mouth movements synchronized with the driving audio, which has seen significant progress in recent years. However, two critical deficiencies hinder their wide application: (1) Audio-only driving paradigms inadequately capture speaker-specific lip habits, which fail to generate lip movements similar to the target avatar; (2) Conventional blind-inpainting approaches frequently produce visual artifacts when handling obstructions (e.g., microphones, hands), limiting practical deployment. In this paper, we propose StableDub, a novel and concise framework integrating lip-habit-aware modeling with occlusion-robust synthesis. Specifically, building upon the Stable-Diffusion backbone, we develop a lip-habit-modulated mechanism that jointly models phonemic audio-visual synchronization and speaker-specific orofacial dynamics. To achieve plausible lip geometries and object appearances under occlusion, we introduce the occlusion-aware training strategy by explicitly exposing the occlusion objects to the inpainting process. By incorporating the proposed designs, the model eliminates the necessity for cost-intensive priors in previous methods, thereby exhibiting superior training efficiency on the computationally intensive diffusion-based backbone. To further optimize training efficiency from the perspective of model architecture, we introduce a hybrid Mamba-Transformer architecture, which demonstrates the enhanced applicability in low-resource research scenarios. Extensive experimental results demonstrate that StableDub achieves superior performance in lip habit resemblance and occlusion robustness. Our method also surpasses other methods in audio-lip sync, video quality, and resolution consistency. We expand the applicability of visual dubbing methods from comprehensive aspects, and demo videos can be found at https://stabledub.github.io.",
        "subjects": "Computer Vision and Pattern Recognition, Multimedia",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.440329"
    },
    {
        "index": "#94",
        "title": "Unlocking the Essence of Beauty: Advanced Aesthetic Reasoning with Relative-Absolute Policy Optimization",
        "link": "/arxiv/2509.21871",
        "arxiv_id": "2509.21871",
        "authors": "Boyang Liu, Yifan Hu, Senjie Jin, Shihan Dou, Gonglei Shi, Jie Shao, Tao Gui, Xuanjing Huang",
        "summary": "Multimodal large language models (MLLMs) are well suited to image aesthetic assessment, as they can capture high-level aesthetic features leveraging their cross-modal understanding capacity. However, the scarcity of multimodal aesthetic reasoning data and the inherently subjective nature of aesthetic judgment make it difficult for MLLMs to generate accurate aesthetic judgments with interpretable rationales. To this end, we propose Aes-R1, a comprehensive aesthetic reasoning framework with reinforcement learning (RL). Concretely, Aes-R1 integrates a pipeline, AesCoT, to construct and filter high-quality chain-of-thought aesthetic reasoning data used for cold-start. After teaching the model to generate structured explanations prior to scoring, we then employ the Relative-Absolute Policy Optimization (RAPO), a novel RL algorithm that jointly optimizes absolute score regression and relative ranking order, improving both per-image accuracy and cross-image preference judgments. Aes-R1 enables MLLMs to generate grounded explanations alongside faithful scores, thereby enhancing aesthetic scoring and reasoning in a unified framework. Extensive experiments demonstrate that Aes-R1 improves the backbone's average PLCC/SRCC by 47.9%/34.8%, surpassing state-of-the-art baselines of similar size. More ablation studies validate Aes-R1's robust generalization under limited supervision and in out-of-distribution scenarios.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.440876"
    },
    {
        "index": "#95",
        "title": "Deepfakes: we need to re-think the concept of \"real\" images",
        "link": "/arxiv/2509.21864",
        "arxiv_id": "2509.21864",
        "authors": "Janis Keuper, Margret Keuper",
        "summary": "The wide availability and low usability barrier of modern image generation models has triggered the reasonable fear of criminal misconduct and negative social implications. The machine learning community has been engaging this problem with an extensive series of publications proposing algorithmic solutions for the detection of \"fake\", e.g. entirely generated or partially manipulated images. While there is undoubtedly some progress towards technical solutions of the problem, we argue that current and prior work is focusing too much on generative algorithms and \"fake\" data-samples, neglecting a clear definition and data collection of \"real\" images. The fundamental question \"what is a real image?\" might appear to be quite philosophical, but our analysis shows that the development and evaluation of basically all current \"fake\"-detection methods is relying on only a few, quite old low-resolution datasets of \"real\" images like ImageNet. However, the technology for the acquisition of \"real\" images, aka taking photos, has drastically evolved over the last decade: Today, over 90% of all photographs are produced by smartphones which typically use algorithms to compute an image from multiple inputs (over time) from multiple sensors. Based on the fact that these image formation algorithms are typically neural network architectures which are closely related to \"fake\"-image generators, we state the position that today, we need to re-think the concept of \"real\" images. The purpose of this position paper is to raise the awareness of the current shortcomings in this active field of research and to trigger an open discussion whether the detection of \"fake\" images is a sound objective at all. At the very least, we need a clear technical definition of \"real\" images and new benchmark datasets.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.441309"
    },
    {
        "index": "#96",
        "title": "SRHand: Super-Resolving Hand Images and 3D Shapes via View/Pose-aware Neural Image Representations and Explicit 3D Meshes",
        "link": "/arxiv/2509.21859",
        "arxiv_id": "2509.21859",
        "authors": "Minje Kim, Tae-Kyun Kim",
        "summary": "Reconstructing detailed hand avatars plays a crucial role in various applications. While prior works have focused on capturing high-fidelity hand geometry, they heavily rely on high-resolution multi-view image inputs and struggle to generalize on low-resolution images. Multi-view image super-resolution methods have been proposed to enforce 3D view consistency. These methods, however, are limited to static objects/scenes with fixed resolutions and are not applicable to articulated deformable hands. In this paper, we propose SRHand (Super-Resolution Hand), the method for reconstructing detailed 3D geometry as well as textured images of hands from low-resolution images. SRHand leverages the advantages of implicit image representation with explicit hand meshes. Specifically, we introduce a geometric-aware implicit image function (GIIF) that learns detailed hand prior by upsampling the coarse input images. By jointly optimizing the implicit image function and explicit 3D hand shapes, our method preserves multi-view and pose consistency among upsampled hand images, and achieves fine-detailed 3D reconstruction (wrinkles, nails). In experiments using the InterHand2.6M and Goliath datasets, our method significantly outperforms state-of-the-art image upsampling methods adapted to hand datasets, and 3D hand reconstruction methods, quantitatively and qualitatively. Project page: https://yunminjin2.github.io/projects/srhand",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.441750"
    },
    {
        "index": "#97",
        "title": "Dynamic Novel View Synthesis in High Dynamic Range",
        "link": "/arxiv/2509.21853",
        "arxiv_id": "2509.21853",
        "authors": "Kaixuan Zhang, Zhipeng Xiong, Minxian Li, Mingwu Ren, Jiankang Deng, Xiatian Zhu",
        "summary": "High Dynamic Range Novel View Synthesis (HDR NVS) seeks to learn an HDR 3D model from Low Dynamic Range (LDR) training images captured under conventional imaging conditions. Current methods primarily focus on static scenes, implicitly assuming all scene elements remain stationary and non-living. However, real-world scenarios frequently feature dynamic elements, such as moving objects, varying lighting conditions, and other temporal events, thereby presenting a significantly more challenging scenario. To address this gap, we propose a more realistic problem named HDR Dynamic Novel View Synthesis (HDR DNVS), where the additional dimension ``Dynamic'' emphasizes the necessity of jointly modeling temporal radiance variations alongside sophisticated 3D translation between LDR and HDR. To tackle this complex, intertwined challenge, we introduce HDR-4DGS, a Gaussian Splatting-based architecture featured with an innovative dynamic tone-mapping module that explicitly connects HDR and LDR domains, maintaining temporal radiance coherence by dynamically adapting tone-mapping functions according to the evolving radiance distributions across the temporal dimension. As a result, HDR-4DGS achieves both temporal radiance consistency and spatially accurate color translation, enabling photorealistic HDR renderings from arbitrary viewpoints and time instances. Extensive experiments demonstrate that HDR-4DGS surpasses existing state-of-the-art methods in both quantitative performance and visual fidelity. Source code will be released.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.442237"
    },
    {
        "index": "#98",
        "title": "A Comprehensive Evaluation of Transformer-Based Question Answering Models and RAG-Enhanced Design",
        "link": "/arxiv/2509.21845",
        "arxiv_id": "2509.21845",
        "authors": "Zichen Zhang, Kunlong Zhang, Hongwei Ruan, Yiming Luo",
        "summary": "Transformer-based models have advanced the field of question answering, but multi-hop reasoning, where answers require combining evidence across multiple passages, remains difficult. This paper presents a comprehensive evaluation of retrieval strategies for multi-hop question answering within a retrieval-augmented generation framework. We compare cosine similarity, maximal marginal relevance, and a hybrid method that integrates dense embeddings with lexical overlap and re-ranking. To further improve retrieval, we adapt the EfficientRAG pipeline for query optimization, introducing token labeling and iterative refinement while maintaining efficiency. Experiments on the HotpotQA dataset show that the hybrid approach substantially outperforms baseline methods, achieving a relative improvement of 50 percent in exact match and 47 percent in F1 score compared to cosine similarity. Error analysis reveals that hybrid retrieval improves entity recall and evidence complementarity, while remaining limited in handling distractors and temporal reasoning. Overall, the results suggest that hybrid retrieval-augmented generation provides a practical zero-shot solution for multi-hop question answering, balancing accuracy, efficiency, and interpretability.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.442695"
    },
    {
        "index": "#99",
        "title": "DiTraj: training-free trajectory control for video diffusion transformer",
        "link": "/arxiv/2509.21839",
        "arxiv_id": "2509.21839",
        "authors": "Cheng Lei, Jiayu Zhang, Yue Ma, Xinyu Wang, Long Chen, Liang Tang, Yiqiang Yan, Fei Su, Zhicheng Zhao",
        "summary": "Diffusion Transformers (DiT)-based video generation models with 3D full attention exhibit strong generative capabilities. Trajectory control represents a user-friendly task in the field of controllable video generation. However, existing methods either require substantial training resources or are specifically designed for U-Net, do not take advantage of the superior performance of DiT. To address these issues, we propose DiTraj, a simple but effective training-free framework for trajectory control in text-to-video generation, tailored for DiT. Specifically, first, to inject the object's trajectory, we propose foreground-background separation guidance: we use the Large Language Model (LLM) to convert user-provided prompts into foreground and background prompts, which respectively guide the generation of foreground and background regions in the video. Then, we analyze 3D full attention and explore the tight correlation between inter-token attention scores and position embedding. Based on this, we propose inter-frame Spatial-Temporal Decoupled 3D-RoPE (STD-RoPE). By modifying only foreground tokens' position embedding, STD-RoPE eliminates their cross-frame spatial discrepancies, strengthening cross-frame attention among them and thus enhancing trajectory control. Additionally, we achieve 3D-aware trajectory control by regulating the density of position embedding. Extensive experiments demonstrate that our method outperforms previous methods in both video quality and trajectory controllability.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.443245"
    },
    {
        "index": "#100",
        "title": "MoWM: Mixture-of-World-Models for Embodied Planning via Latent-to-Pixel Feature Modulation",
        "link": "/arxiv/2509.21797",
        "arxiv_id": "2509.21797",
        "authors": "Yu Shang, Yangcheng Yu, Xin Zhang, Xin Jin, Haisheng Su, Wei Wu, Yong Li",
        "summary": "Embodied action planning is a core challenge in robotics, requiring models to generate precise actions from visual observations and language instructions. While video generation world models are promising, their reliance on pixel-level reconstruction often introduces visual redundancies that hinder action decoding and generalization. Latent world models offer a compact, motion-aware representation, but overlook the fine-grained details critical for precise manipulation. To overcome these limitations, we propose MoWM, a mixture-of-world-model framework that fuses representations from hybrid world models for embodied action planning. Our approach uses motion-aware representations from a latent model as a high-level prior, which guides the extraction of fine-grained visual features from the pixel space model. This design allows MoWM to highlight the informative visual details needed for action decoding. Extensive evaluations on the CALVIN benchmark demonstrate that our method achieves state-of-the-art task success rates and superior generalization. We also provide a comprehensive analysis of the strengths of each feature space, offering valuable insights for future research in embodied planning. The code is available at: https://github.com/tsinghua-fib-lab/MoWM.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.443811"
    },
    {
        "index": "#101",
        "title": "LongScape: Advancing Long-Horizon Embodied World Models with Context-Aware MoE",
        "link": "/arxiv/2509.21790",
        "arxiv_id": "2509.21790",
        "authors": "Yu Shang, Lei Jin, Yiding Ma, Xin Zhang, Chen Gao, Wei Wu, Yong Li",
        "summary": "Video-based world models hold significant potential for generating high-quality embodied manipulation data. However, current video generation methods struggle to achieve stable long-horizon generation: classical diffusion-based approaches often suffer from temporal inconsistency and visual drift over multiple rollouts, while autoregressive methods tend to compromise on visual detail. To solve this, we introduce LongScape, a hybrid framework that adaptively combines intra-chunk diffusion denoising with inter-chunk autoregressive causal generation. Our core innovation is an action-guided, variable-length chunking mechanism that partitions video based on the semantic context of robotic actions. This ensures each chunk represents a complete, coherent action, enabling the model to flexibly generate diverse dynamics. We further introduce a Context-aware Mixture-of-Experts (CMoE) framework that adaptively activates specialized experts for each chunk during generation, guaranteeing high visual quality and seamless chunk transitions. Extensive experimental results demonstrate that our method achieves stable and consistent long-horizon generation over extended rollouts. Our code is available at: https://github.com/tsinghua-fib-lab/Longscape.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.444313"
    },
    {
        "index": "#102",
        "title": "MIRG-RL: Multi-Image Reasoning and Grounding with Reinforcement Learning",
        "link": "/arxiv/2509.21788",
        "arxiv_id": "2509.21788",
        "authors": "Lihao Zheng, Jiawei Chen, Xintian Shen, Hao Ma, Tao Wei",
        "summary": "Multi-image reasoning and grounding require understanding complex cross-image relationships at both object levels and image levels. Current Large Visual Language Models (LVLMs) face two critical challenges: the lack of cross-image reasoning capabilities and insufficient cross-image reference reward modeling. To address these issues, we propose a unified framework - Multi-Image Reasoning and Grounding with Reinforcement Learning (MIRG-RL). Specifically, our two-stage training paradigm combines supervised fine-tuning with annotated trajectories and image-aware reinforcement learning optimization, progressively developing multi-image reasoning capabilities. Furthermore, we innovatively propose a method for constructing the trajectory data, which integrates object-level and image-level annotation information, and use this method to generate a lightweight reasoning-enhanced dataset. To effectively resolve cross-image ambiguities, we design an image-aware RL policy with dual reward functions for objects and images. Experiments demonstrate that MIRG-RL achieves state-of-the-art (SOTA) performance in multi-image grounding benchmarks, attaining 64.82% on cross-image reasoning tasks - exceeding the previous best method by 1%. The code and dataset have been released at https://github.com/ZEUS2035/MIRG-RL.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.444784"
    },
    {
        "index": "#103",
        "title": "DeHate: A Stable Diffusion-based Multimodal Approach to Mitigate Hate Speech in Images",
        "link": "/arxiv/2509.21787",
        "arxiv_id": "2509.21787",
        "authors": "Dwip Dalal, Gautam Vashishtha, Anku Ranui, Aishwarya Reganti, Parth Patwa, Mohd Sarique, Chandan Gupta, Keshav Nath, Viswanatha Reddy, Vinija Jain, Aman Chadha, Amitava Das, Amit Sheth, Asif Ekbal",
        "summary": "The rise in harmful online content not only distorts public discourse but also poses significant challenges to maintaining a healthy digital environment. In response to this, we introduce a multimodal dataset uniquely crafted for identifying hate in digital content. Central to our methodology is the innovative application of watermarked, stability-enhanced, stable diffusion techniques combined with the Digital Attention Analysis Module (DAAM). This combination is instrumental in pinpointing the hateful elements within images, thereby generating detailed hate attention maps, which are used to blur these regions from the image, thereby removing the hateful sections of the image. We release this data set as a part of the dehate shared task. This paper also describes the details of the shared task. Furthermore, we present DeHater, a vision-language model designed for multimodal dehatification tasks. Our approach sets a new standard in AI-driven image hate detection given textual prompts, contributing to the development of more ethical AI applications in social media.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.450543"
    },
    {
        "index": "#104",
        "title": "Prompt-guided Representation Disentanglement for Action Recognition",
        "link": "/arxiv/2509.21783",
        "arxiv_id": "2509.21783",
        "authors": "Tianci Wu, Guangming Zhu, Jiang Lu, Siyuan Wang, Ning Wang, Nuoye Xiong, Zhang Liang",
        "summary": "Action recognition is a fundamental task in video understanding. Existing methods typically extract unified features to process all actions in one video, which makes it challenging to model the interactions between different objects in multi-action scenarios. To alleviate this issue, we explore disentangling any specified actions from complex scenes as an effective solution. In this paper, we propose Prompt-guided Disentangled Representation for Action Recognition (ProDA), a novel framework that disentangles any specified actions from a multi-action scene. ProDA leverages Spatio-temporal Scene Graphs (SSGs) and introduces Dynamic Prompt Module (DPM) to guide a Graph Parsing Neural Network (GPNN) in generating action-specific representations. Furthermore, we design a video-adapted GPNN that aggregates information using dynamic weights. Experiments in video action recognition demonstrate the effectiveness of our approach when compared with the state-of-the-art methods. Our code can be found in https://github.com/iamsnaping/ProDA.git",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.451053"
    },
    {
        "index": "#105",
        "title": "Training-Free Multimodal Deepfake Detection via Graph Reasoning",
        "link": "/arxiv/2509.21774",
        "arxiv_id": "2509.21774",
        "authors": "Yuxin Liu, Fei Wang, Kun Li, Yiqi Nie, Junjie Chen, Yanyan Wei, Zhangling Duan, Zhaohong Jia",
        "summary": "Multimodal deepfake detection (MDD) aims to uncover manipulations across visual, textual, and auditory modalities, thereby reinforcing the reliability of modern information systems. Although large vision-language models (LVLMs) exhibit strong multimodal reasoning, their effectiveness in MDD is limited by challenges in capturing subtle forgery cues, resolving cross-modal inconsistencies, and performing task-aligned retrieval. To this end, we propose Guided Adaptive Scorer and Propagation In-Context Learning (GASP-ICL), a training-free framework for MDD. GASP-ICL employs a pipeline to preserve semantic relevance while injecting task-aware knowledge into LVLMs. We leverage an MDD-adapted feature extractor to retrieve aligned image-text pairs and build a candidate set. We further design the Graph-Structured Taylor Adaptive Scorer (GSTAS) to capture cross-sample relations and propagate query-aligned signals, producing discriminative exemplars. This enables precise selection of semantically aligned, task-relevant demonstrations, enhancing LVLMs for robust MDD. Experiments on four forgery types show that GASP-ICL surpasses strong baselines, delivering gains without LVLM fine-tuning.",
        "subjects": "Computer Vision and Pattern Recognition, Computers and Society",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.451581"
    },
    {
        "index": "#106",
        "title": "CubistMerge: Spatial-Preserving Token Merging For Diverse ViT Backbones",
        "link": "/arxiv/2509.21764",
        "arxiv_id": "2509.21764",
        "authors": "Wenyi Gong, Mieszko Lis",
        "summary": "Many modern ViT backbones adopt spatial architectural designs, such as window attention, decomposed relative positional embeddings in SAM, and RoPE in DINOv3. Such architectures impose new challenges on token reduction, as the vast majority of existing methods fail to preserve the spatial structure these architectures depend on. In this paper, we introduce a simple yet effective token merging method that maintains spatial integrity, enabling seamless compatibility with spatial architectures. We reconcile two seemingly conflicting requirements: (i)exploiting the uneven information distribution across the spatial layout while (ii)preserving the spatial structure post-merging. Our approach employs (i)a 2D reduction strategy to enforce structured token layouts, (ii)a spatial-aware merging algorithm that maintains relative token positions, and (iii)a novel max-magnitude-per-dimension token representation that preserves salient features. Our method demonstrates strong performance both off-the-shelf and with fine-tuning, achieving state-of-the-art results on spatial and non-spatial architectures across various vision tasks. Specifically, we achieve 1.25x speedup on SAM-H with only 0.7% mIOU drop evaluated on COCO off-the-shelf, and 1.15x speedup on DeiT-B with no top-1 accuracy drop on ImageNet within just one epoch of fine-tuning.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.452104"
    },
    {
        "index": "#107",
        "title": "UniVid: Unifying Vision Tasks with Pre-trained Video Generation Models",
        "link": "/arxiv/2509.21760",
        "arxiv_id": "2509.21760",
        "authors": "Lan Chen, Yuchao Gu, Qi Mao",
        "summary": "Large language models, trained on extensive corpora, successfully unify diverse linguistic tasks within a single generative framework. Inspired by this, recent works like Large Vision Model (LVM) extend this paradigm to vision by organizing tasks into sequential visual sentences, where visual prompts serve as the context to guide outputs. However, such modeling requires task-specific pre-training across modalities and sources, which is costly and limits scalability to unseen tasks. Given that pre-trained video generation models inherently capture temporal sequence dependencies, we explore a more unified and scalable alternative: can a pre-trained video generation model adapt to diverse image and video tasks? To answer this, we propose UniVid, a framework that fine-tunes a video diffusion transformer to handle various vision tasks without task-specific modifications. Tasks are represented as visual sentences, where the context sequence defines both the task and the expected output modality. We evaluate the generalization of UniVid from two perspectives: (1) cross-modal inference with contexts composed of both images and videos, extending beyond LVM's uni-modal setting; (2) cross-source tasks from natural to annotated data, without multi-source pre-training. Despite being trained solely on natural video data, UniVid generalizes well in both settings. Notably, understanding and generation tasks can easily switch by simply reversing the visual sentence order in this paradigm. These findings highlight the potential of pre-trained video generation models to serve as a scalable and unified foundation for vision modeling. Our code will be released at https://github.com/CUC-MIPG/UniVid.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.452552"
    },
    {
        "index": "#108",
        "title": "KG-SAM: Injecting Anatomical Knowledge into Segment Anything Models via Conditional Random Fields",
        "link": "/arxiv/2509.21750",
        "arxiv_id": "2509.21750",
        "authors": "Yu Li, Da Chang, Xi Xiao",
        "summary": "While the Segment Anything Model (SAM) has achieved remarkable success in image segmentation, its direct application to medical imaging remains hindered by fundamental challenges, including ambiguous boundaries, insufficient modeling of anatomical relationships, and the absence of uncertainty quantification. To address these limitations, we introduce KG-SAM, a knowledge-guided framework that synergistically integrates anatomical priors with boundary refinement and uncertainty estimation. Specifically, KG-SAM incorporates (i) a medical knowledge graph to encode fine-grained anatomical relationships, (ii) an energy-based Conditional Random Field (CRF) to enforce anatomically consistent predictions, and (iii) an uncertainty-aware fusion module to enhance reliability in high-stakes clinical scenarios. Extensive experiments across multi-center medical datasets demonstrate the effectiveness of our approach: KG-SAM achieves an average Dice score of 82.69% on prostate segmentation and delivers substantial gains in abdominal segmentation, reaching 78.05% on MRI and 79.68% on CT. These results establish KG-SAM as a robust and generalizable framework for advancing medical image segmentation.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.452985"
    },
    {
        "index": "#109",
        "title": "Incorporating Scene Context and Semantic Labels for Enhanced Group-level Emotion Recognition",
        "link": "/arxiv/2509.21747",
        "arxiv_id": "2509.21747",
        "authors": "Qing Zhu, Wangdong Guo, Qirong Mao, Xiaohua Huang, Xiuyan Shao, Wenming Zheng",
        "summary": "Group-level emotion recognition (GER) aims to identify holistic emotions within a scene involving multiple individuals. Current existed methods underestimate the importance of visual scene contextual information in modeling individual relationships. Furthermore, they overlook the crucial role of semantic information from emotional labels for complete understanding of emotions. To address this limitation, we propose a novel framework that incorporates visual scene context and label-guided semantic information to improve GER performance. It involves the visual context encoding module that leverages multi-scale scene information to diversely encode individual relationships. Complementarily, the emotion semantic encoding module utilizes group-level emotion labels to prompt a large language model to generate nuanced emotion lexicons. These lexicons, in conjunction with the emotion labels, are then subsequently refined into comprehensive semantic representations through the utilization of a structured emotion tree. Finally, similarity-aware interaction is proposed to align and integrate visual and semantic information, thereby generating enhanced group-level emotion representations and subsequently improving the performance of GER. Experiments on three widely adopted GER datasets demonstrate that our proposed method achieves competitive performance compared to state-of-the-art methods.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.453497"
    },
    {
        "index": "#110",
        "title": "LFA-Net: A Lightweight Network with LiteFusion Attention for Retinal Vessel Segmentation",
        "link": "/arxiv/2509.21738",
        "arxiv_id": "2509.21738",
        "authors": "Mehwish Mehmood, Ivor Spence, Muhammad Fahim",
        "summary": "Lightweight retinal vessel segmentation is important for the early diagnosis of vision-threatening and systemic diseases, especially in a real-world clinical environment with limited computational resources. Although segmentation methods based on deep learning are improving, existing models are still facing challenges of small vessel segmentation and high computational costs. To address these challenges, we proposed a new vascular segmentation network, LFA-Net, which incorporates a newly designed attention module, LiteFusion-Attention. This attention module incorporates residual learning connections, Vision Mamba-inspired dynamics, and modulation-based attention, enabling the model to capture local and global context efficiently and in a lightweight manner. LFA-Net offers high performance with 0.11 million parameters, 0.42 MB memory size, and 4.46 GFLOPs, which make it ideal for resource-constrained environments. We validated our proposed model on DRIVE, STARE, and CHASE_DB with outstanding performance in terms of dice scores of 83.28, 87.44, and 84.50% and Jaccard indices of 72.85, 79.31, and 74.70%, respectively. The code of LFA-Net is available online https://github.com/Mehwish4593/LFA-Net.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.453965"
    },
    {
        "index": "#111",
        "title": "UISim: An Interactive Image-Based UI Simulator for Dynamic Mobile Environments",
        "link": "/arxiv/2509.21733",
        "arxiv_id": "2509.21733",
        "authors": "Jiannan Xiang, Yun Zhu, Lei Shu, Maria Wang, Lijun Yu, Gabriel Barcik, James Lyon, Srinivas Sunkara, Jindong Chen",
        "summary": "Developing and testing user interfaces (UIs) and training AI agents to interact with them are challenging due to the dynamic and diverse nature of real-world mobile environments. Existing methods often rely on cumbersome physical devices or limited static analysis of screenshots, which hinders scalable testing and the development of intelligent UI agents. We introduce UISim, a novel image-based UI simulator that offers a dynamic and interactive platform for exploring mobile phone environments purely from screen images. Our system employs a two-stage method: given an initial phone screen image and a user action, it first predicts the abstract layout of the next UI state, then synthesizes a new, visually consistent image based on this predicted layout. This approach enables the realistic simulation of UI transitions. UISim provides immediate practical benefits for UI testing, rapid prototyping, and synthetic data generation. Furthermore, its interactive capabilities pave the way for advanced applications, such as UI navigation task planning for AI agents. Our experimental results show that UISim outperforms end-to-end UI generation baselines in generating realistic and coherent subsequent UI states, highlighting its fidelity and potential to streamline UI development and enhance AI agent training.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language, Human-Computer Interaction, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.454563"
    },
    {
        "index": "#112",
        "title": "On the Status of Foundation Models for SAR Imagery",
        "link": "/arxiv/2509.21722",
        "arxiv_id": "2509.21722",
        "authors": "Nathan Inkawhich",
        "summary": "In this work we investigate the viability of foundational AI/ML models for Synthetic Aperture Radar (SAR) object recognition tasks. We are inspired by the tremendous progress being made in the wider community, particularly in the natural image domain where frontier labs are training huge models on web-scale datasets with unprecedented computing budgets. It has become clear that these models, often trained with Self-Supervised Learning (SSL), will transform how we develop AI/ML solutions for object recognition tasks - they can be adapted downstream with very limited labeled data, they are more robust to many forms of distribution shift, and their features are highly transferable out-of-the-box. For these reasons and more, we are motivated to apply this technology to the SAR domain. In our experiments we first run tests with today's most powerful visual foundational models, including DINOv2, DINOv3 and PE-Core and observe their shortcomings at extracting semantically-interesting discriminative SAR target features when used off-the-shelf. We then show that Self-Supervised finetuning of publicly available SSL models with SAR data is a viable path forward by training several AFRL-DINOv2s and setting a new state-of-the-art for SAR foundation models, significantly outperforming today's best SAR-domain model SARATR-X. Our experiments further analyze the performance trade-off of using different backbones with different downstream task-adaptation recipes, and we monitor each model's ability to overcome challenges within the downstream environments (e.g., extended operating conditions and low amounts of labeled data). We hope this work will inform and inspire future SAR foundation model builders, because despite our positive results, we still have a long way to go.",
        "subjects": "Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.454999"
    },
    {
        "index": "#113",
        "title": "DeLiVR: Differential Spatiotemporal Lie Bias for Efficient Video Deraining",
        "link": "/arxiv/2509.21719",
        "arxiv_id": "2509.21719",
        "authors": "Shuning Sun, Jialang Lu, Xiang Chen, Jichao Wang, Dianjie Lu, Guijuan Zhang, Guangwei Gao, Zhuoran Zheng",
        "summary": "Videos captured in the wild often suffer from rain streaks, blur, and noise. In addition, even slight changes in camera pose can amplify cross-frame mismatches and temporal artifacts. Existing methods rely on optical flow or heuristic alignment, which are computationally expensive and less robust. To address these challenges, Lie groups provide a principled way to represent continuous geometric transformations, making them well-suited for enforcing spatial and temporal consistency in video modeling. Building on this insight, we propose DeLiVR, an efficient video deraining method that injects spatiotemporal Lie-group differential biases directly into attention scores of the network. Specifically, the method introduces two complementary components. First, a rotation-bounded Lie relative bias predicts the in-plane angle of each frame using a compact prediction module, where normalized coordinates are rotated and compared with base coordinates to achieve geometry-consistent alignment before feature aggregation. Second, a differential group displacement computes angular differences between adjacent frames to estimate a velocity. This bias computation combines temporal decay and attention masks to focus on inter-frame relationships while precisely matching the direction of rain streaks. Extensive experimental results demonstrate the effectiveness of our method on publicly available benchmarks.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.460675"
    },
    {
        "index": "#114",
        "title": "Motion-Aware Transformer for Multi-Object Tracking",
        "link": "/arxiv/2509.21715",
        "arxiv_id": "2509.21715",
        "authors": "Xu Yang, Gady Agam",
        "summary": "Multi-object tracking (MOT) in videos remains challenging due to complex object motions and crowded scenes. Recent DETR-based frameworks offer end-to-end solutions but typically process detection and tracking queries jointly within a single Transformer Decoder layer, leading to conflicts and degraded association accuracy. We introduce the Motion-Aware Transformer (MATR), which explicitly predicts object movements across frames to update track queries in advance. By reducing query collisions, MATR enables more consistent training and improves both detection and association. Extensive experiments on DanceTrack, SportsMOT, and BDD100k show that MATR delivers significant gains across standard metrics. On DanceTrack, MATR improves HOTA by more than 9 points over MOTR without additional data and reaches a new state-of-the-art score of 71.3 with supplementary data. MATR also achieves state-of-the-art results on SportsMOT (72.2 HOTA) and BDD100k (54.7 mTETA, 41.6 mHOTA) without relying on external datasets. These results demonstrate that explicitly modeling motion within end-to-end Transformers offers a simple yet highly effective approach to advancing multi-object tracking.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.461114"
    },
    {
        "index": "#115",
        "title": "MS-YOLO: Infrared Object Detection for Edge Deployment via MobileNetV4 and SlideLoss",
        "link": "/arxiv/2509.21696",
        "arxiv_id": "2509.21696",
        "authors": "Jiali Zhang, Thomas S. White, Haoliang Zhang, Wenqing Hu, Donald C. Wunsch II, Jian Liu",
        "summary": "Infrared imaging has emerged as a robust solution for urban object detection under low-light and adverse weather conditions, offering significant advantages over traditional visible-light cameras. However, challenges such as class imbalance, thermal noise, and computational constraints can significantly hinder model performance in practical settings. To address these issues, we evaluate multiple YOLO variants on the FLIR ADAS V2 dataset, ultimately selecting YOLOv8 as our baseline due to its balanced accuracy and efficiency. Building on this foundation, we present \\texttt{MS-YOLO} (\\textbf{M}obileNetv4 and \\textbf{S}lideLoss based on YOLO), which replaces YOLOv8's CSPDarknet backbone with the more efficient MobileNetV4, reducing computational overhead by \\textbf{1.5%} while sustaining high accuracy. In addition, we introduce \\emph{SlideLoss}, a novel loss function that dynamically emphasizes under-represented and occluded samples, boosting precision without sacrificing recall. Experiments on the FLIR ADAS V2 benchmark show that \\texttt{MS-YOLO} attains competitive mAP and superior precision while operating at only \\textbf{6.7 GFLOPs}. These results demonstrate that \\texttt{MS-YOLO} effectively addresses the dual challenge of maintaining high detection quality while minimizing computational costs, making it well-suited for real-time edge deployment in urban environments.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.461610"
    },
    {
        "index": "#116",
        "title": "MORPH: Shape-agnostic PDE Foundation Models",
        "link": "/arxiv/2509.21670",
        "arxiv_id": "2509.21670",
        "authors": "Mahindra Singh Rautela, Alexander Most, Siddharth Mansingh, Bradley C. Love, Ayan Biswas, Diane Oyen, Earl Lawrence",
        "summary": "We introduce MORPH, a shape-agnostic, autoregressive foundation model for partial differential equations (PDEs). MORPH is built on a convolutional vision transformer backbone that seamlessly handles heterogeneous spatiotemporal datasets of varying data dimensionality (1D--3D) at different resolutions, multiple fields with mixed scalar and vector components. The architecture combines (i) component-wise convolution, which jointly processes scalar and vector channels to capture local interactions, (ii) inter-field cross-attention, which models and selectively propagates information between different physical fields, (iii) axial attentions, which factorizes full spatiotemporal self-attention along individual spatial and temporal axes to reduce computational burden while retaining expressivity. We pretrain multiple model variants on a diverse collection of heterogeneous PDE datasets and evaluate transfer to a range of downstream prediction tasks. Using both full-model fine-tuning and parameter-efficient low-rank adapters (LoRA), MORPH outperforms models trained from scratch in both zero-shot and full-shot generalization. Across extensive evaluations, MORPH matches or surpasses strong baselines and recent state-of-the-art models. Collectively, these capabilities present a flexible and powerful backbone for learning from heterogeneous and multimodal nature of scientific observations, charting a path toward scalable and data-efficient scientific machine learning.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning, Computational Physics",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.462170"
    },
    {
        "index": "#117",
        "title": "FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction",
        "link": "/arxiv/2509.21657",
        "arxiv_id": "2509.21657",
        "authors": "Yixiang Dai, Fan Jiang, Chiyu Wang, Mu Xu, Yonggang Qi",
        "summary": "High-quality 3D world models are pivotal for embodied intelligence and Artificial General Intelligence (AGI), underpinning applications such as AR/VR content creation and robotic navigation. Despite the established strong imaginative priors, current video foundation models lack explicit 3D grounding capabilities, thus being limited in both spatial consistency and their utility for downstream 3D reasoning tasks. In this work, we present FantasyWorld, a geometry-enhanced framework that augments frozen video foundation models with a trainable geometric branch, enabling joint modeling of video latents and an implicit 3D field in a single forward pass. Our approach introduces cross-branch supervision, where geometry cues guide video generation and video priors regularize 3D prediction, thus yielding consistent and generalizable 3D-aware video representations. Notably, the resulting latents from the geometric branch can potentially serve as versatile representations for downstream 3D tasks such as novel view synthesis and navigation, without requiring per-scene optimization or fine-tuning. Extensive experiments show that FantasyWorld effectively bridges video imagination and 3D perception, outperforming recent geometry-consistent baselines in multi-view coherence and style consistency. Ablation studies further confirm that these gains stem from the unified backbone and cross-branch information exchange.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.462626"
    },
    {
        "index": "#118",
        "title": "A Data-driven Typology of Vision Models from Integrated Representational Metrics",
        "link": "/arxiv/2509.21628",
        "arxiv_id": "2509.21628",
        "authors": "Jialin Wu, Shreya Saha, Yiqing Bo, Meenakshi Khosla",
        "summary": "Large vision models differ widely in architecture and training paradigm, yet we lack principled methods to determine which aspects of their representations are shared across families and which reflect distinctive computational strategies. We leverage a suite of representational similarity metrics, each capturing a different facet-geometry, unit tuning, or linear decodability-and assess family separability using multiple complementary measures. Metrics preserving geometry or tuning (e.g., RSA, Soft Matching) yield strong family discrimination, whereas flexible mappings such as Linear Predictivity show weaker separation. These findings indicate that geometry and tuning carry family-specific signatures, while linearly decodable information is more broadly shared. To integrate these complementary facets, we adapt Similarity Network Fusion (SNF), a method inspired by multi-omics integration. SNF achieves substantially sharper family separation than any individual metric and produces robust composite signatures. Clustering of the fused similarity matrix recovers both expected and surprising patterns: supervised ResNets and ViTs form distinct clusters, yet all self-supervised models group together across architectural boundaries. Hybrid architectures (ConvNeXt, Swin) cluster with masked autoencoders, suggesting convergence between architectural modernization and reconstruction-based training. This biology-inspired framework provides a principled typology of vision models, showing that emergent computational strategies-shaped jointly by architecture and training objective-define representational structure beyond surface design categories.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.463110"
    },
    {
        "index": "#119",
        "title": "VLCE: A Knowledge-Enhanced Framework for Image Description in Disaster Assessment",
        "link": "/arxiv/2509.21609",
        "arxiv_id": "2509.21609",
        "authors": "Md. Mahfuzur Rahman, Kishor Datta Gupta, Marufa Kamal, Fahad Rahman, Sunzida Siddique, Ahmed Rafi Hasan, Mohd Ariful Haque, Roy George",
        "summary": "Immediate damage assessment is essential after natural catastrophes; yet, conventional hand evaluation techniques are sluggish and perilous. Although satellite and unmanned aerial vehicle (UAV) photos offer extensive perspectives of impacted regions, current computer vision methodologies generally yield just classification labels or segmentation masks, so constraining their capacity to deliver a thorough situational comprehension. We introduce the Vision Language Caption Enhancer (VLCE), a multimodal system designed to produce comprehensive, contextually-informed explanations of disaster imagery. VLCE employs a dual-architecture approach: a CNN-LSTM model with a ResNet50 backbone pretrained on EuroSat satellite imagery for the xBD dataset, and a Vision Transformer (ViT) model pretrained on UAV pictures for the RescueNet dataset. Both systems utilize external semantic knowledge from ConceptNet and WordNet to expand vocabulary coverage and improve description accuracy. We assess VLCE in comparison to leading vision-language models (LLaVA and QwenVL) utilizing CLIPScore for semantic alignment and InfoMetIC for caption informativeness. Experimental findings indicate that VLCE markedly surpasses baseline models, attaining a maximum of 95.33% on InfoMetIC while preserving competitive semantic alignment. Our dual-architecture system demonstrates significant potential for improving disaster damage assessment by automating the production of actionable, information-dense descriptions from satellite and drone photos.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.463633"
    },
    {
        "index": "#120",
        "title": "Temporal vs. Spatial: Comparing DINOv3 and V-JEPA2 Feature Representations for Video Action Analysis",
        "link": "/arxiv/2509.21595",
        "arxiv_id": "2509.21595",
        "authors": "Sai Varun Kodathala, Rakesh Vunnam",
        "summary": "This study presents a comprehensive comparative analysis of two prominent self-supervised learning architectures for video action recognition: DINOv3, which processes frames independently through spatial feature extraction, and V-JEPA2, which employs joint temporal modeling across video sequences. We evaluate both approaches on the UCF Sports dataset, examining feature quality through multiple dimensions including classification accuracy, clustering performance, intra-class consistency, and inter-class discrimination. Our analysis reveals fundamental architectural trade-offs: DINOv3 achieves superior clustering performance (Silhouette score: 0.31 vs 0.21) and demonstrates exceptional discrimination capability (6.16x separation ratio) particularly for pose-identifiable actions, while V-JEPA2 exhibits consistent reliability across all action types with significantly lower performance variance (0.094 vs 0.288). Through action-specific evaluation, we identify that DINOv3's spatial processing architecture excels at static pose recognition but shows degraded performance on motion-dependent actions, whereas V-JEPA2's temporal modeling provides balanced representation quality across diverse action categories. These findings contribute to the understanding of architectural design choices in video analysis systems and provide empirical guidance for selecting appropriate feature extraction methods based on task requirements and reliability constraints.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.464108"
    },
    {
        "index": "#121",
        "title": "What Happens Next? Anticipating Future Motion by Generating Point Trajectories",
        "link": "/arxiv/2509.21592",
        "arxiv_id": "2509.21592",
        "authors": "Gabrijel Boduljak, Laurynas Karazija, Iro Laina, Christian Rupprecht, Andrea Vedaldi",
        "summary": "We consider the problem of forecasting motion from a single image, i.e., predicting how objects in the world are likely to move, without the ability to observe other parameters such as the object velocities or the forces applied to them. We formulate this task as conditional generation of dense trajectory grids with a model that closely follows the architecture of modern video generators but outputs motion trajectories instead of pixels. This approach captures scene-wide dynamics and uncertainty, yielding more accurate and diverse predictions than prior regressors and generators. We extensively evaluate our method on simulated data, demonstrate its effectiveness on downstream applications such as robotics, and show promising accuracy on real-world intuitive physics datasets. Although recent state-of-the-art video generators are often regarded as world models, we show that they struggle with forecasting motion from a single image, even in simple physical scenarios such as falling blocks or mechanical object interactions, despite fine-tuning on such data. We show that this limitation arises from the overhead of generating pixels rather than directly modeling motion.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.464621"
    },
    {
        "index": "#122",
        "title": "X-Streamer: Unified Human World Modeling with Audiovisual Interaction",
        "link": "/arxiv/2509.21574",
        "arxiv_id": "2509.21574",
        "authors": "You Xie, Tianpei Gu, Zenan Li, Chenxu Zhang, Guoxian Song, Xiaochen Zhao, Chao Liang, Jianwen Jiang, Hongyi Xu, Linjie Luo",
        "summary": "We introduce X-Streamer, an end-to-end multimodal human world modeling framework for building digital human agents capable of infinite interactions across text, speech, and video within a single unified architecture. Starting from a single portrait, X-Streamer enables real-time, open-ended video calls driven by streaming multimodal inputs. At its core is a Thinker-Actor dual-transformer architecture that unifies multimodal understanding and generation, turning a static portrait into persistent and intelligent audiovisual interactions. The Thinker module perceives and reasons over streaming user inputs, while its hidden states are translated by the Actor into synchronized multimodal streams in real time. Concretely, the Thinker leverages a pretrained large language-speech model, while the Actor employs a chunk-wise autoregressive diffusion model that cross-attends to the Thinker's hidden states to produce time-aligned multimodal responses with interleaved discrete text and audio tokens and continuous video latents. To ensure long-horizon stability, we design inter- and intra-chunk attentions with time-aligned multimodal positional embeddings for fine-grained cross-modality alignment and context retention, further reinforced by chunk-wise diffusion forcing and global identity referencing. X-Streamer runs in real time on two A100 GPUs, sustaining hours-long consistent video chat experiences from arbitrary portraits and paving the way toward unified world modeling of interactive digital humans.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.465163"
    },
    {
        "index": "#123",
        "title": "Enhancing Contrastive Learning for Geolocalization by Discovering Hard Negatives on Semivariograms",
        "link": "/arxiv/2509.21573",
        "arxiv_id": "2509.21573",
        "authors": "Boyi Chen, Zhangyu Wang, Fabian Deuser, Johann Maximilian Zollner, Martin Werner",
        "summary": "Accurate and robust image-based geo-localization at a global scale is challenging due to diverse environments, visually ambiguous scenes, and the lack of distinctive landmarks in many regions. While contrastive learning methods show promising performance by aligning features between street-view images and corresponding locations, they neglect the underlying spatial dependency in the geographic space. As a result, they fail to address the issue of false negatives -- image pairs that are both visually and geographically similar but labeled as negatives, and struggle to effectively distinguish hard negatives, which are visually similar but geographically distant. To address this issue, we propose a novel spatially regularized contrastive learning strategy that integrates a semivariogram, which is a geostatistical tool for modeling how spatial correlation changes with distance. We fit the semivariogram by relating the distance of images in feature space to their geographical distance, capturing the expected visual content in a spatial correlation. With the fitted semivariogram, we define the expected visual dissimilarity at a given spatial distance as reference to identify hard negatives and false negatives. We integrate this strategy into GeoCLIP and evaluate it on the OSV5M dataset, demonstrating that explicitly modeling spatial priors improves image-based geo-localization performance, particularly at finer granularity.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.470788"
    },
    {
        "index": "#124",
        "title": "No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models",
        "link": "/arxiv/2509.21565",
        "arxiv_id": "2509.21565",
        "authors": "Junno Yun, Yaşar Utku Alçalar, Mehmet Akçakaya",
        "summary": "Efficient training strategies for large-scale diffusion models have recently emphasized the importance of improving discriminative feature representations in these models. A central line of work in this direction is representation alignment with features obtained from powerful external encoders, which improves the representation quality as assessed through linear probing. Alignment-based approaches show promise but depend on large pretrained encoders, which are computationally expensive to obtain. In this work, we propose an alternative regularization for training, based on promoting the Linear SEParability (LSEP) of intermediate layer representations. LSEP eliminates the need for an auxiliary encoder and representation alignment, while incorporating linear probing directly into the network's learning dynamics rather than treating it as a simple post-hoc evaluation tool. Our results demonstrate substantial improvements in both training efficiency and generation quality on flow-based transformer architectures such as SiTs, achieving an FID of 1.46 on $256 \\times 256$ ImageNet dataset.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.471267"
    },
    {
        "index": "#125",
        "title": "Unsupervised Defect Detection for Surgical Instruments",
        "link": "/arxiv/2509.21561",
        "arxiv_id": "2509.21561",
        "authors": "Joseph Huang, Yichi Zhang, Jingxi Yu, Wei Chen, Seunghyun Hwang, Qiang Qiu, Amy R. Reibman, Edward J. Delp, Fengqing Zhu",
        "summary": "Ensuring the safety of surgical instruments requires reliable detection of visual defects. However, manual inspection is prone to error, and existing automated defect detection methods, typically trained on natural/industrial images, fail to transfer effectively to the surgical domain. We demonstrate that simply applying or fine-tuning these approaches leads to issues: false positive detections arising from textured backgrounds, poor sensitivity to small, subtle defects, and inadequate capture of instrument-specific features due to domain shift. To address these challenges, we propose a versatile method that adapts unsupervised defect detection methods specifically for surgical instruments. By integrating background masking, a patch-based analysis strategy, and efficient domain adaptation, our method overcomes these limitations, enabling the reliable detection of fine-grained defects in surgical instrument imagery.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.471798"
    },
    {
        "index": "#126",
        "title": "X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning",
        "link": "/arxiv/2509.21559",
        "arxiv_id": "2509.21559",
        "authors": "Prasanna Reddy Pulakurthi, Jiamian Wang, Majid Rabbani, Sohail Dianat, Raghuveer Rao, Zhiqiang Tao",
        "summary": "Prevalent text-to-video retrieval systems mainly adopt embedding models for feature extraction and compute cosine similarities for ranking. However, this design presents two limitations. Low-quality text-video data pairs could compromise the retrieval, yet are hard to identify and examine. Cosine similarity alone provides no explanation for the ranking results, limiting the interpretability. We ask that can we interpret the ranking results, so as to assess the retrieval models and examine the text-video data? This work proposes X-CoT, an explainable retrieval framework upon LLM CoT reasoning in place of the embedding model-based similarity ranking. We first expand the existing benchmarks with additional video annotations to support semantic understanding and reduce data bias. We also devise a retrieval CoT consisting of pairwise comparison steps, yielding detailed reasoning and complete ranking. X-CoT empirically improves the retrieval performance and produces detailed rationales. It also facilitates the model behavior and data quality analysis. Code and data are available at: https://github.com/PrasannaPulakurthi/X-CoT.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.472290"
    },
    {
        "index": "#127",
        "title": "Learning GUI Grounding with Spatial Reasoning from Visual Feedback",
        "link": "/arxiv/2509.21552",
        "arxiv_id": "2509.21552",
        "authors": "Yu Zhao, Wei-Ning Chen, Huseyin Atahan Inan, Samuel Kessler, Lu Wang, Lukas Wutschitz, Fangkai Yang, Chaoyun Zhang, Pasquale Minervini, Saravan Rajmohan, Robert Sim",
        "summary": "Graphical User Interface (GUI) grounding is commonly framed as a coordinate prediction task -- given a natural language instruction, generate on-screen coordinates for actions such as clicks and keystrokes. However, recent Vision Language Models (VLMs) often fail to predict accurate numeric coordinates when processing high-resolution GUI images with complex layouts. To address this issue, we reframe GUI grounding as an \\emph{interactive search task}, where the VLM generates actions to move a cursor in the GUI to locate UI elements. At each step, the model determines the target object, evaluates the spatial relations between the cursor and the target, and moves the cursor closer to the target conditioned on the movement history. In this interactive process, the rendered cursor provides visual feedback to help the model align its predictions with the corresponding on-screen locations. We train our GUI grounding model, GUI-Cursor, using multi-step online reinforcement learning with a dense trajectory-based reward function. Our experimental results show that GUI-Cursor, based on Qwen2.5-VL-7B, improves the GUI grounding accuracy and achieves state-of-the-art results on ScreenSpot-v2 ($88.8\\% \\rightarrow 93.9\\%$) and ScreenSpot-Pro ($26.8\\% \\rightarrow 56.5\\%$). Moreover, we observe that GUI-Cursor learns to solve the problem within two steps for 95\\% of instances and can adaptively conduct more steps on more difficult examples.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.472856"
    },
    {
        "index": "#128",
        "title": "Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Moderation",
        "link": "/arxiv/2509.21486",
        "arxiv_id": "2509.21486",
        "authors": "Zixuan Wang, Yu Sun, Hongwei Wang, Baoyu Jing, Xiang Shen, Xin Dong, Zhuolin Hao, Hongyu Xiong, Yang Song",
        "summary": "Short video platforms are evolving rapidly, making the identification of inappropriate content increasingly critical. Existing approaches typically train separate and small classification models for each type of issue, which requires extensive human-labeled data and lacks cross-issue generalization. We propose a reasoning-enhanced multimodal large language model (MLLM) pretraining paradigm for unified inappropriate content detection. To address the distribution gap between short video content and the original pretraining data of MLLMs, as well as the complex issue definitions, we introduce three targeted pretraining tasks: (1) \\textit{Caption}, to enhance the MLLM's perception of video details; (2) \\textit{Visual Question Answering (VQA)}, to deepen the MLLM's understanding of issue definitions and annotation guidelines; (3) \\textit{Chain-of-Thought (CoT)}, to enhance the MLLM's reasoning capability. Experimental results show that our pretraining approach significantly improves the MLLM's performance in both zero-shot and supervised fine-tuning (SFT) settings. In addition, our pretrained model demonstrates strong generalization capabilities to emergent, previously unseen issues.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.473392"
    },
    {
        "index": "#129",
        "title": "Gender Stereotypes in Professional Roles Among Saudis: An Analytical Study of AI-Generated Images Using Language Models",
        "link": "/arxiv/2509.21466",
        "arxiv_id": "2509.21466",
        "authors": "Khaloud S. AlKhalifah, Malak Mashaabi, Hend Al-Khalifa",
        "summary": "This study investigates the extent to which contemporary Text-to-Image artificial intelligence (AI) models perpetuate gender stereotypes and cultural inaccuracies when generating depictions of professionals in Saudi Arabia. We analyzed 1,006 images produced by ImageFX, DALL-E V3, and Grok for 56 diverse Saudi professions using neutral prompts. Two trained Saudi annotators evaluated each image on five dimensions: perceived gender, clothing and appearance, background and setting, activities and interactions, and age. A third senior researcher adjudicated whenever the two primary raters disagreed, yielding 10,100 individual judgements. The results reveal a strong gender imbalance, with ImageFX outputs being 85\\% male, Grok 86.6\\% male, and DALL-E V3 96\\% male, indicating that DALL-E V3 exhibited the strongest overall gender stereotyping. This imbalance was most evident in leadership and technical roles. Moreover, cultural inaccuracies in clothing, settings, and depicted activities were frequently observed across all three models. Counter-stereotypical images often arise from cultural misinterpretations rather than genuinely progressive portrayals. We conclude that current models mirror societal biases embedded in their training data, generated by humans, offering only a limited reflection of the Saudi labour market's gender dynamics and cultural nuances. These findings underscore the urgent need for more diverse training data, fairer algorithms, and culturally sensitive evaluation frameworks to ensure equitable and authentic visual outputs.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.473881"
    },
    {
        "index": "#130",
        "title": "Residual Vector Quantization For Communication-Efficient Multi-Agent Perception",
        "link": "/arxiv/2509.21464",
        "arxiv_id": "2509.21464",
        "authors": "Dereje Shenkut, B. V. K Vijaya Kumar",
        "summary": "Multi-agent collaborative perception (CP) improves scene understanding by sharing information across connected agents such as autonomous vehicles, unmanned aerial vehicles, and robots. Communication bandwidth, however, constrains scalability. We present ReVQom, a learned feature codec that preserves spatial identity while compressing intermediate features. ReVQom is an end-to-end method that compresses feature dimensions via a simple bottleneck network followed by multi-stage residual vector quantization (RVQ). This allows only per-pixel code indices to be transmitted, reducing payloads from 8192 bits per pixel (bpp) of uncompressed 32-bit float features to 6-30 bpp per agent with minimal accuracy loss. On DAIR-V2X real-world CP dataset, ReVQom achieves 273x compression at 30 bpp to 1365x compression at 6 bpp. At 18 bpp (455x), ReVQom matches or outperforms raw-feature CP, and at 6-12 bpp it enables ultra-low-bandwidth operation with graceful degradation. ReVQom allows efficient and accurate multi-agent collaborative perception with a step toward practical V2X deployment.",
        "subjects": "Computer Vision and Pattern Recognition, Robotics",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.474328"
    },
    {
        "index": "#131",
        "title": "VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding",
        "link": "/arxiv/2509.21451",
        "arxiv_id": "2509.21451",
        "authors": "Abdul Waheed, Zhen Wu, Dareen Alharthi, Seungone Kim, Bhiksha Raj",
        "summary": "Precisely evaluating video understanding models remains challenging: commonly used metrics such as BLEU, ROUGE, and BERTScore fail to capture the fineness of human judgment, while obtaining such judgments through manual evaluation is costly. Recent work has explored using large language models (LLMs) or multimodal LLMs (MLLMs) as evaluators, but their extension to video understanding remains relatively unexplored. In this work, we introduce VideoJudge, a 3B and 7B-sized MLLM judge specialized to evaluate outputs from video understanding models (\\textit{i.e.}, text responses conditioned on videos). To train VideoJudge, our recipe builds on the interplay between a generator and an evaluator: the generator is prompted to produce responses conditioned on a target rating, and responses not matching the evaluator's rating are discarded. Across three out of four meta-evaluation benchmarks, VideoJudge-7B outperforms larger MLLM judge baselines such as Qwen2.5-VL (32B and 72B). Notably, we find that LLM judges (Qwen3) models perform worse than MLLM judges (Qwen2.5-VL) and long chain-of-thought reasoning does not improve performance, indicating that providing video inputs is crucial for evaluation of video understanding tasks.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.474823"
    },
    {
        "index": "#132",
        "title": "DyME: Dynamic Multi-Concept Erasure in Diffusion Models with Bi-Level Orthogonal LoRA Adaptation",
        "link": "/arxiv/2509.21433",
        "arxiv_id": "2509.21433",
        "authors": "Jiaqi Liu, Lan Zhang, Xiaoyong Yuan",
        "summary": "Text-to-image diffusion models (DMs) inadvertently reproduce copyrighted styles and protected visual concepts, raising legal and ethical concerns. Concept erasure has emerged as a safeguard, aiming to selectively suppress such concepts through fine-tuning. However, existing methods do not scale to practical settings where providers must erase multiple and possibly conflicting concepts. The core bottleneck is their reliance on static erasure: a single checkpoint is fine-tuned to remove all target concepts, regardless of the actual erasure needs at inference. This rigid design mismatches real-world usage, where requests vary per generation, leading to degraded erasure success and reduced fidelity for non-target content. We propose DyME, an on-demand erasure framework that trains lightweight, concept-specific LoRA adapters and dynamically composes only those needed at inference. This modular design enables flexible multi-concept erasure, but naive composition causes interference among adapters, especially when many or semantically related concepts are suppressed. To overcome this, we introduce bi-level orthogonality constraints at both the feature and parameter levels, disentangling representation shifts and enforcing orthogonal adapter subspaces. We further develop ErasureBench-H, a new hierarchical benchmark with brand-series-character structure, enabling principled evaluation across semantic granularities and erasure set sizes. Experiments on ErasureBench-H and standard datasets (e.g., CIFAR-100, Imagenette) demonstrate that DyME consistently outperforms state-of-the-art baselines, achieving higher multi-concept erasure fidelity with minimal collateral degradation.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.475304"
    },
    {
        "index": "#133",
        "title": "QuadGPT: Native Quadrilateral Mesh Generation with Autoregressive Models",
        "link": "/arxiv/2509.21420",
        "arxiv_id": "2509.21420",
        "authors": "Jian Liu, Chunshi Wang, Song Guo, Haohan Weng, Zhen Zhou, Zhiqi Li, Jiaao Yu, Yiling Zhu, Jing Xu, Biwen Lei, Zhuo Chen, Chunchao Guo",
        "summary": "The generation of quadrilateral-dominant meshes is a cornerstone of professional 3D content creation. However, existing generative models generate quad meshes by first generating triangle meshes and then merging triangles into quadrilaterals with some specific rules, which typically produces quad meshes with poor topology. In this paper, we introduce QuadGPT, the first autoregressive framework for generating quadrilateral meshes in an end-to-end manner. QuadGPT formulates this as a sequence prediction paradigm, distinguished by two key innovations: a unified tokenization method to handle mixed topologies of triangles and quadrilaterals, and a specialized Reinforcement Learning fine-tuning method tDPO for better generation quality. Extensive experiments demonstrate that QuadGPT significantly surpasses previous triangle-to-quad conversion pipelines in both geometric accuracy and topological quality. Our work establishes a new benchmark for native quad-mesh generation and showcases the power of combining large-scale autoregressive models with topology-aware RL refinement for creating structured 3D assets.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.501566"
    },
    {
        "index": "#134",
        "title": "Overview of ExpertLifeCLEF 2018: how far automated identification systems are from the best experts?",
        "link": "/arxiv/2509.21419",
        "arxiv_id": "2509.21419",
        "authors": "Herve Goeau, Pierre Bonnet, Alexis Joly",
        "summary": "Automated identification of plants and animals has improved considerably in the last few years, in particular thanks to the recent advances in deep learning. The next big question is how far such automated systems are from the human expertise. Indeed, even the best experts are sometimes confused and/or disagree between each others when validating visual or audio observations of living organism. A picture actually contains only a partial information that is usually not sufficient to determine the right species with certainty. Quantifying this uncertainty and comparing it to the performance of automated systems is of high interest for both computer scientists and expert naturalists. The LifeCLEF 2018 ExpertCLEF challenge presented in this paper was designed to allow this comparison between human experts and automated systems. In total, 19 deep-learning systems implemented by 4 different research teams were evaluated with regard to 9 expert botanists of the French flora. The main outcome of this work is that the performance of state-of-the-art deep learning models is now close to the most advanced human expertise. This paper presents more precisely the resources and assessments of the challenge, summarizes the approaches and systems employed by the participating research groups, and provides an analysis of the main outcomes.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.502158"
    },
    {
        "index": "#135",
        "title": "JaiLIP: Jailbreaking Vision-Language Models via Loss Guided Image Perturbation",
        "link": "/arxiv/2509.21401",
        "arxiv_id": "2509.21401",
        "authors": "Md Jueal Mia, M. Hadi Amini",
        "summary": "Vision-Language Models (VLMs) have remarkable abilities in generating multimodal reasoning tasks. However, potential misuse or safety alignment concerns of VLMs have increased significantly due to different categories of attack vectors. Among various attack vectors, recent studies have demonstrated that image-based perturbations are particularly effective in generating harmful outputs. In the literature, many existing techniques have been proposed to jailbreak VLMs, leading to unstable performance and visible perturbations. In this study, we propose Jailbreaking with Loss-guided Image Perturbation (JaiLIP), a jailbreaking attack in the image space that minimizes a joint objective combining the mean squared error (MSE) loss between clean and adversarial image with the models harmful-output loss. We evaluate our proposed method on VLMs using standard toxicity metrics from Perspective API and Detoxify. Experimental results demonstrate that our method generates highly effective and imperceptible adversarial images, outperforming existing methods in producing toxicity. Moreover, we have evaluated our method in the transportation domain to demonstrate the attacks practicality beyond toxic text generation in specific domain. Our findings emphasize the practical challenges of image-based jailbreak attacks and the need for efficient defense mechanisms for VLMs.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-24",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.502715"
    },
    {
        "index": "#136",
        "title": "Downscaling climate projections to 1 km with single-image super resolution",
        "link": "/arxiv/2509.21399",
        "arxiv_id": "2509.21399",
        "authors": "Petr Košťál, Pavel Kordík, Ondřej Podsztavek",
        "summary": "High-resolution climate projections are essential for local decision-making. However, available climate projections have low spatial resolution (e.g. 12.5 km), which limits their usability. We address this limitation by leveraging single-image super-resolution models to statistically downscale climate projections to 1-km resolution. Since high-resolution climate projections are unavailable for training, we train models on a high-resolution observational gridded data set and apply them to low-resolution climate projections. We propose a climate indicator-based assessment using observed climate indices computed at weather station locations to evaluate the downscaled climate projections without ground-truth high-resolution climate projections. Experiments on daily mean temperature demonstrate that single-image super-resolution models can downscale climate projections without increasing the error of climate indicators compared to low-resolution climate projections.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-24",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.503313"
    },
    {
        "index": "#137",
        "title": "Skeleton Sparsification and Densification Scale-Spaces",
        "link": "/arxiv/2509.21398",
        "arxiv_id": "2509.21398",
        "authors": "Julia Gierke, Pascal Peter",
        "summary": "The Hamilton-Jacobi skeleton, also known as the medial axis, is a powerful shape descriptor that represents binary objects in terms of the centres of maximal inscribed discs. Despite its broad applicability, the medial axis suffers from sensitivity to noise: minor boundary variations can lead to disproportionately large and undesirable expansions of the skeleton. Classical pruning methods mitigate this shortcoming by systematically removing extraneous skeletal branches. This sequential simplification of skeletons resembles the principle of sparsification scale-spaces that embed images into a family of reconstructions from increasingly sparse pixel representations. We combine both worlds by introducing skeletonisation scale-spaces: They leverage sparsification of the medial axis to achieve hierarchical simplification of shapes. Unlike conventional pruning, our framework inherently satisfies key scale-space properties such as hierarchical architecture, controllable simplification, and equivariance to geometric transformations. We provide a rigorous theoretical foundation in both continuous and discrete formulations and extend the concept further with densification. This allows inverse progression from coarse to fine scales and can even reach beyond the original skeleton to produce overcomplete shape representations with relevancy for practical applications. Through proof-of-concept experiments, we demonstrate the effectiveness of our framework for practical tasks including robust skeletonisation, shape compression, and stiffness enhancement for additive manufacturing.",
        "subjects": "Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2025-09-24",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.503905"
    },
    {
        "index": "#138",
        "title": "mmHSense: Multi-Modal and Distributed mmWave ISAC Datasets for Human Sensing",
        "link": "/arxiv/2509.21396",
        "arxiv_id": "2509.21396",
        "authors": "Nabeel Nisar Bhat, Maksim Karnaukh, Stein Vandenbroeke, Wouter Lemoine, Jakob Struye, Jesus Omar Lacruz, Siddhartha Kumar, Mohammad Hossein Moghaddam, Joerg Widmer, Rafael Berkvens, Jeroen Famaey",
        "summary": "This article presents mmHSense, a set of open labeled mmWave datasets to support human sensing research within Integrated Sensing and Communication (ISAC) systems. The datasets can be used to explore mmWave ISAC for various end applications such as gesture recognition, person identification, pose estimation, and localization. Moreover, the datasets can be used to develop and advance signal processing and deep learning research on mmWave ISAC. This article describes the testbed, experimental settings, and signal features for each dataset. Furthermore, the utility of the datasets is demonstrated through validation on a specific downstream task. In addition, we demonstrate the use of parameter-efficient fine-tuning to adapt ISAC models to different tasks, significantly reducing computational complexity while maintaining performance on prior tasks.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-24",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.504637"
    },
    {
        "index": "#139",
        "title": "Large AI Model-Enabled Generative Semantic Communications for Image Transmission",
        "link": "/arxiv/2509.21394",
        "arxiv_id": "2509.21394",
        "authors": "Qiyu Ma, Wanli Ni, Zhijin Qin",
        "summary": "The rapid development of generative artificial intelligence (AI) has introduced significant opportunities for enhancing the efficiency and accuracy of image transmission within semantic communication systems. Despite these advancements, existing methodologies often neglect the difference in importance of different regions of the image, potentially compromising the reconstruction quality of visually critical content. To address this issue, we introduce an innovative generative semantic communication system that refines semantic granularity by segmenting images into key and non-key regions. Key regions, which contain essential visual information, are processed using an image oriented semantic encoder, while non-key regions are efficiently compressed through an image-to-text modeling approach. Additionally, to mitigate the substantial storage and computational demands posed by large AI models, the proposed system employs a lightweight deployment strategy incorporating model quantization and low-rank adaptation fine-tuning techniques, significantly boosting resource utilization without sacrificing performance. Simulation results demonstrate that the proposed system outperforms traditional methods in terms of both semantic fidelity and visual quality, thereby affirming its effectiveness for image transmission tasks.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Information Theory",
        "date": "2025-09-24",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.505259"
    },
    {
        "index": "#140",
        "title": "TUN3D: Towards Real-World Scene Understanding from Unposed Images",
        "link": "/arxiv/2509.21388",
        "arxiv_id": "2509.21388",
        "authors": "Anton Konushin, Nikita Drozdov, Bulat Gabdullin, Alexey Zakharov, Anna Vorontsova, Danila Rukhovich, Maksim Kolodiazhnyi",
        "summary": "Layout estimation and 3D object detection are two fundamental tasks in indoor scene understanding. When combined, they enable the creation of a compact yet semantically rich spatial representation of a scene. Existing approaches typically rely on point cloud input, which poses a major limitation since most consumer cameras lack depth sensors and visual-only data remains far more common. We address this issue with TUN3D, the first method that tackles joint layout estimation and 3D object detection in real scans, given multi-view images as input, and does not require ground-truth camera poses or depth supervision. Our approach builds on a lightweight sparse-convolutional backbone and employs two dedicated heads: one for 3D object detection and one for layout estimation, leveraging a novel and effective parametric wall representation. Extensive experiments show that TUN3D achieves state-of-the-art performance across three challenging scene understanding benchmarks: (i) using ground-truth point clouds, (ii) using posed images, and (iii) using unposed images. While performing on par with specialized 3D object detection methods, TUN3D significantly advances layout estimation, setting a new benchmark in holistic indoor scene understanding. Code is available at https://github.com/col14m/tun3d .",
        "subjects": "Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.505928"
    },
    {
        "index": "#141",
        "title": "Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence",
        "link": "/arxiv/2509.21387",
        "arxiv_id": "2509.21387",
        "authors": "Sanish Suwal, Dipkamal Bhusal, Michael Clifford, Nidhi Rastogi",
        "summary": "Prior works have shown that neural networks can be heavily pruned while preserving performance, but the impact of pruning on model interpretability remains unclear. In this work, we investigate how magnitude-based pruning followed by fine-tuning affects both low-level saliency maps and high-level concept representations. Using a ResNet-18 trained on ImageNette, we compare post-hoc explanations from Vanilla Gradients (VG) and Integrated Gradients (IG) across pruning levels, evaluating sparsity and faithfulness. We further apply CRAFT-based concept extraction to track changes in semantic coherence of learned concepts. Our results show that light-to-moderate pruning improves saliency-map focus and faithfulness while retaining distinct, semantically meaningful concepts. In contrast, aggressive pruning merges heterogeneous features, reducing saliency map sparsity and concept coherence despite maintaining accuracy. These findings suggest that while pruning can shape internal representations toward more human-aligned attention patterns, excessive pruning undermines interpretability.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.511679"
    },
    {
        "index": "#142",
        "title": "ShipwreckFinder: A QGIS Tool for Shipwreck Detection in Multibeam Sonar Data",
        "link": "/arxiv/2509.21386",
        "arxiv_id": "2509.21386",
        "authors": "Anja Sheppard, Tyler Smithline, Andrew Scheffer, David Smith, Advaith V. Sethuraman, Ryan Bird, Sabrina Lin, Katherine A. Skinner",
        "summary": "In this paper, we introduce ShipwreckFinder, an open-source QGIS plugin that detects shipwrecks from multibeam sonar data. Shipwrecks are an important historical marker of maritime history, and can be discovered through manual inspection of bathymetric data. However, this is a time-consuming process and often requires expert analysis. Our proposed tool allows users to automatically preprocess bathymetry data, perform deep learning inference, threshold model outputs, and produce either pixel-wise segmentation masks or bounding boxes of predicted shipwrecks. The backbone of this open-source tool is a deep learning model, which is trained on a variety of shipwreck data from the Great Lakes and the coasts of Ireland. Additionally, we employ synthetic data generation in order to increase the size and diversity of our dataset. We demonstrate superior segmentation performance with our open-source tool and training pipeline as compared to a deep learning-based ArcGIS toolkit and a more classical inverse sinkhole detection method. The open-source tool can be found at https://github.com/umfieldrobotics/ShipwreckFinderQGISPlugin.",
        "subjects": "Computer Vision and Pattern Recognition, Robotics, Image and Video Processing",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.512264"
    },
    {
        "index": "#143",
        "title": "Debugging Concept Bottleneck Models through Removal and Retraining",
        "link": "/arxiv/2509.21385",
        "arxiv_id": "2509.21385",
        "authors": "Eric Enouen, Sainyam Galhotra",
        "summary": "Concept Bottleneck Models (CBMs) use a set of human-interpretable concepts to predict the final task label, enabling domain experts to not only validate the CBM's predictions, but also intervene on incorrect concepts at test time. However, these interventions fail to address systemic misalignment between the CBM and the expert's reasoning, such as when the model learns shortcuts from biased data. To address this, we present a general interpretable debugging framework for CBMs that follows a two-step process of Removal and Retraining. In the Removal step, experts use concept explanations to identify and remove any undesired concepts. In the Retraining step, we introduce CBDebug, a novel method that leverages the interpretability of CBMs as a bridge for converting concept-level user feedback into sample-level auxiliary labels. These labels are then used to apply supervised bias mitigation and targeted augmentation, reducing the model's reliance on undesired concepts. We evaluate our framework with both real and automated expert feedback, and find that CBDebug significantly outperforms prior retraining methods across multiple CBM architectures (PIP-Net, Post-hoc CBM) and benchmarks with known spurious correlations.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.512722"
    },
    {
        "index": "#144",
        "title": "Assessing the Alignment of Popular CNNs to the Brain for Valence Appraisal",
        "link": "/arxiv/2509.21384",
        "arxiv_id": "2509.21384",
        "authors": "Laurent Mertens, Elahe' Yargholi, Laura Van Hove, Hans Op de Beeck, Jan Van den Stock, Joost Vennekens",
        "summary": "Convolutional Neural Networks (CNNs) are a popular type of computer model that have proven their worth in many computer vision tasks. Moreover, they form an interesting study object for the field of psychology, with shown correspondences between the workings of CNNs and the human brain. However, these correspondences have so far mostly been studied in the context of general visual perception. In contrast, this paper explores to what extent this correspondence also holds for a more complex brain process, namely social cognition. To this end, we assess the alignment between popular CNN architectures and both human behavioral and fMRI data for image valence appraisal through a correlation analysis. We show that for this task CNNs struggle to go beyond simple visual processing, and do not seem to reflect higher-order brain processing. Furthermore, we present Object2Brain, a novel framework that combines GradCAM and object detection at the CNN-filter level with the aforementioned correlation analysis to study the influence of different object classes on the CNN-to-human correlations. Despite similar correlation trends, different CNN architectures are shown to display different object class sensitivities.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.513222"
    },
    {
        "index": "#145",
        "title": "The LongiMam model for improved breast cancer risk prediction using longitudinal mammograms",
        "link": "/arxiv/2509.21383",
        "arxiv_id": "2509.21383",
        "authors": "Manel Rakez, Thomas Louis, Julien Guillaumin, Foucauld Chamming's, Pierre Fillard, Brice Amadeo, Virginie Rondeau",
        "summary": "Risk-adapted breast cancer screening requires robust models that leverage longitudinal imaging data. Most current deep learning models use single or limited prior mammograms and lack adaptation for real-world settings marked by imbalanced outcome distribution and heterogeneous follow-up. We developed LongiMam, an end-to-end deep learning model that integrates both current and up to four prior mammograms. LongiMam combines a convolutional and a recurrent neural network to capture spatial and temporal patterns predictive of breast cancer. The model was trained and evaluated using a large, population-based screening dataset with disproportionate case-to-control ratio typical of clinical screening. Across several scenarios that varied in the number and composition of prior exams, LongiMam consistently improved prediction when prior mammograms were included. The addition of prior and current visits outperformed single-visit models, while priors alone performed less well, highlighting the importance of combining historical and recent information. Subgroup analyses confirmed the model's efficacy across key risk groups, including women with dense breasts and those aged 55 years or older. Moreover, the model performed best in women with observed changes in mammographic density over time. These findings demonstrate that longitudinal modeling enhances breast cancer prediction and support the use of repeated mammograms to refine risk stratification in screening programs. LongiMam is publicly available as open-source software.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.513750"
    },
    {
        "index": "#146",
        "title": "Coreset selection based on Intra-class diversity",
        "link": "/arxiv/2509.21380",
        "arxiv_id": "2509.21380",
        "authors": "Imran Ashraf, Mukhtar Ullah, Muhammad Faisal Nadeem, Muhammad Nouman Noor",
        "summary": "Deep Learning models have transformed various domains, including the healthcare sector, particularly biomedical image classification by learning intricate features and enabling accurate diagnostics pertaining to complex diseases. Recent studies have adopted two different approaches to train DL models: training from scratch and transfer learning. Both approaches demand substantial computational time and resources due to the involvement of massive datasets in model training. These computational demands are further increased due to the design-space exploration required for selecting optimal hyperparameters, which typically necessitates several training rounds. With the growing sizes of datasets, exploring solutions to this problem has recently gained the research community's attention. A plausible solution is to select a subset of the dataset for training and hyperparameter search. This subset, referred to as the corset, must be a representative set of the original dataset. A straightforward approach to selecting the coreset could be employing random sampling, albeit at the cost of compromising the representativeness of the original dataset. A critical limitation of random sampling is the bias towards the dominant classes in an imbalanced dataset. Even if the dataset has inter-class balance, this random sampling will not capture intra-class diversity. This study addresses this issue by introducing an intelligent, lightweight mechanism for coreset selection. Specifically, it proposes a method to extract intra-class diversity, forming per-class clusters that are utilized for the final sampling. We demonstrate the efficacy of the proposed methodology by conducting extensive classification experiments on a well-known biomedical imaging dataset. Results demonstrate that the proposed scheme outperforms the random sampling approach on several performance metrics for uniform conditions.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.514246"
    },
    {
        "index": "#147",
        "title": "SAEmnesia: Erasing Concepts in Diffusion Models with Sparse Autoencoders",
        "link": "/arxiv/2509.21379",
        "arxiv_id": "2509.21379",
        "authors": "Enrico Cassano, Riccardo Renzulli, Marco Nurisso, Mirko Zaffaroni, Alan Perotti, Marco Grangetto",
        "summary": "Effective concept unlearning in text-to-image diffusion models requires precise localization of concept representations within the model's latent space. While sparse autoencoders successfully reduce neuron polysemanticity (i.e., multiple concepts per neuron) compared to the original network, individual concept representations can still be distributed across multiple latent features, requiring extensive search procedures for concept unlearning. We introduce SAEmnesia, a supervised sparse autoencoder training method that promotes one-to-one concept-neuron mappings through systematic concept labeling, mitigating feature splitting and promoting feature centralization. Our approach learns specialized neurons with significantly stronger concept associations compared to unsupervised baselines. The only computational overhead introduced by SAEmnesia is limited to cross-entropy computation during training. At inference time, this interpretable representation reduces hyperparameter search by 96.67% with respect to current approaches. On the UnlearnCanvas benchmark, SAEmnesia achieves a 9.22% improvement over the state-of-the-art. In sequential unlearning tasks, we demonstrate superior scalability with a 28.4% improvement in unlearning accuracy for 9-object removal.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.514763"
    },
    {
        "index": "#148",
        "title": "Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation",
        "link": "/arxiv/2509.21377",
        "arxiv_id": "2509.21377",
        "authors": "Yinfeng Yu, Hailong Zhang, Meiling Zhu",
        "summary": "Audiovisual embodied navigation enables robots to locate audio sources by dynamically integrating visual observations from onboard sensors with the auditory signals emitted by the target. The core challenge lies in effectively leveraging multimodal cues to guide navigation. While prior works have explored basic fusion of visual and audio data, they often overlook deeper perceptual context. To address this, we propose the Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation (DMTF-AVN). Our approach uses a multi-target architecture coupled with a refined Transformer mechanism to filter and selectively fuse cross-modal information. Extensive experiments on the Replica and Matterport3D datasets demonstrate that DMTF-AVN achieves state-of-the-art performance, outperforming existing methods in success rate (SR), path efficiency (SPL), and scene adaptation (SNA). Furthermore, the model exhibits strong scalability and generalizability, paving the way for advanced multimodal fusion strategies in robotic navigation. The code and videos are available at https://github.com/zzzmmm-svg/DMTF.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.515230"
    },
    {
        "index": "#149",
        "title": "In silico Deep Learning Protocols for Label-Free Super-Resolution Microscopy: A Comparative Study of Network Architectures and SNR Dependence",
        "link": "/arxiv/2509.21376",
        "arxiv_id": "2509.21376",
        "authors": "Shiraz S Kaderuppan, Jonathan Mar, Andrew Irvine, Anurag Sharma, Muhammad Ramadan Saifuddin, Wai Leong Eugene Wong, Wai Lok Woo",
        "summary": "The field of optical microscopy spans across numerous industries and research domains, ranging from education to healthcare, quality inspection and analysis. Nonetheless, a key limitation often cited by optical microscopists refers to the limit of its lateral resolution (typically defined as ~200nm), with potential circumventions involving either costly external modules (e.g. confocal scan heads, etc) and/or specialized techniques [e.g. super-resolution (SR) fluorescent microscopy]. Addressing these challenges in a normal (non-specialist) context thus remains an aspect outside the scope of most microscope users & facilities. This study thus seeks to evaluate an alternative & economical approach to achieving SR optical microscopy, involving non-fluorescent phase-modulated microscopical modalities such as Zernike phase contrast (PCM) and differential interference contrast (DIC) microscopy. Two in silico deep neural network (DNN) architectures which we developed previously (termed O-Net and Theta-Net) are assessed on their abilities to resolve a custom-fabricated test target containing nanoscale features calibrated via atomic force microscopy (AFM). The results of our study demonstrate that although both O-Net and Theta-Net seemingly performed well when super-resolving these images, they were complementary (rather than competing) approaches to be considered for image SR, particularly under different image signal-to-noise ratios (SNRs). High image SNRs favoured the application of O-Net models, while low SNRs inclined preferentially towards Theta-Net models. These findings demonstrate the importance of model architectures (in conjunction with the source image SNR) on model performance and the SR quality of the generated images where DNN models are utilized for non-fluorescent optical nanoscopy, even where the same training dataset & number of epochs are being used.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.515775"
    },
    {
        "index": "#150",
        "title": "Automated Prompt Generation for Creative and Counterfactual Text-to-image Synthesis",
        "link": "/arxiv/2509.21375",
        "arxiv_id": "2509.21375",
        "authors": "Aleksa Jelaca, Ying Jiao, Chang Tian, Marie-Francine Moens",
        "summary": "Text-to-image generation has advanced rapidly with large-scale multimodal training, yet fine-grained controllability remains a critical challenge. Counterfactual controllability, defined as the capacity to deliberately generate images that contradict common-sense patterns, remains a major challenge but plays a crucial role in enabling creativity and exploratory applications. In this work, we address this gap with a focus on counterfactual size (e.g., generating a tiny walrus beside a giant button) and propose an automatic prompt engineering framework that adapts base prompts into revised prompts for counterfactual images. The framework comprises three components: an image evaluator that guides dataset construction by identifying successful image generations, a supervised prompt rewriter that produces revised prompts, and a DPO-trained ranker that selects the optimal revised prompt. We construct the first counterfactual size text-image dataset and enhance the image evaluator by extending Grounded SAM with refinements, achieving a 114 percent improvement over its backbone. Experiments demonstrate that our method outperforms state-of-the-art baselines and ChatGPT-4o, establishing a foundation for future research on counterfactual controllability.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.516266"
    },
    {
        "index": "#151",
        "title": "Safety Assessment of Scaffolding on Construction Site using AI",
        "link": "/arxiv/2509.21368",
        "arxiv_id": "2509.21368",
        "authors": "Sameer Prabhu, Amit Patwardhan, Ramin Karim",
        "summary": "In the construction industry, safety assessment is vital to ensure both the reliability of assets and the safety of workers. Scaffolding, a key structural support asset requires regular inspection to detect and identify alterations from the design rules that may compromise the integrity and stability. At present, inspections are primarily visual and are conducted by site manager or accredited personnel to identify deviations. However, visual inspection is time-intensive and can be susceptible to human errors, which can lead to unsafe conditions. This paper explores the use of Artificial Intelligence (AI) and digitization to enhance the accuracy of scaffolding inspection and contribute to the safety improvement. A cloud-based AI platform is developed to process and analyse the point cloud data of scaffolding structure. The proposed system detects structural modifications through comparison and evaluation of certified reference data with the recent point cloud data. This approach may enable automated monitoring of scaffolding, reducing the time and effort required for manual inspections while enhancing the safety on a construction site.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-22",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.521880"
    },
    {
        "index": "#152",
        "title": "MAJORScore: A Novel Metric for Evaluating Multimodal Relevance via Joint Representation",
        "link": "/arxiv/2509.21365",
        "arxiv_id": "2509.21365",
        "authors": "Zhicheng Du, Qingyang Shi, Jiasheng Lu, Yingshan Liang, Xinyu Zhang, Yiran Wang, Peiwu Qin",
        "summary": "The multimodal relevance metric is usually borrowed from the embedding ability of pretrained contrastive learning models for bimodal data, which is used to evaluate the correlation between cross-modal data (e.g., CLIP). However, the commonly used evaluation metrics are only suitable for the associated analysis between two modalities, which greatly limits the evaluation of multimodal similarity. Herein, we propose MAJORScore, a brand-new evaluation metric for the relevance of multiple modalities (N modalities, N>=3) via multimodal joint representation for the first time. The ability of multimodal joint representation to integrate multiple modalities into the same latent space can accurately represent different modalities at one scale, providing support for fair relevance scoring. Extensive experiments have shown that MAJORScore increases by 26.03%-64.29% for consistent modality and decreases by 13.28%-20.54% for inconsistence compared to existing methods. MAJORScore serves as a more reliable metric for evaluating similarity on large-scale multimodal datasets and multimodal model performance evaluation.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-22",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.522639"
    },
    {
        "index": "#153",
        "title": "A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised",
        "link": "/arxiv/2509.21363",
        "arxiv_id": "2509.21363",
        "authors": "Runmin Wu, Mengyang Feng, Wenlong Guan, Dong Wang, Huchuan Lu, Errui Ding",
        "summary": "Though deep learning techniques have made great progress in salient object detection recently, the predicted saliency maps still suffer from incomplete predictions due to the internal complexity of objects and inaccurate boundaries caused by strides in convolution and pooling operations. To alleviate these issues, we propose to train saliency detection networks by exploiting the supervision from not only salient object detection, but also foreground contour detection and edge detection. First, we leverage salient object detection and foreground contour detection tasks in an intertwined manner to generate saliency maps with uniform highlight. Second, the foreground contour and edge detection tasks guide each other simultaneously, thereby leading to precise foreground contour prediction and reducing the local noises for edge prediction. In addition, we develop a novel mutual learning module (MLM) which serves as the building block of our method. Each MLM consists of multiple network branches trained in a mutual learning manner, which improves the performance by a large margin. Extensive experiments on seven challenging datasets demonstrate that the proposed method has delivered state-of-the-art results in both salient object detection and edge detection.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-21",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.523152"
    },
    {
        "index": "#154",
        "title": "Multimodal Prompt Decoupling Attack on the Safety Filters in Text-to-Image Models",
        "link": "/arxiv/2509.21360",
        "arxiv_id": "2509.21360",
        "authors": "Xingkai Peng, Jun Jiang, Meng Tong, Shuai Li, Weiming Zhang, Nenghai Yu, Kejiang Chen",
        "summary": "Text-to-image (T2I) models have been widely applied in generating high-fidelity images across various domains. However, these models may also be abused to produce Not-Safe-for-Work (NSFW) content via jailbreak attacks. Existing jailbreak methods primarily manipulate the textual prompt, leaving potential vulnerabilities in image-based inputs largely unexplored. Moreover, text-based methods face challenges in bypassing the model's safety filters. In response to these limitations, we propose the Multimodal Prompt Decoupling Attack (MPDA), which utilizes image modality to separate the harmful semantic components of the original unsafe prompt. MPDA follows three core steps: firstly, a large language model (LLM) decouples unsafe prompts into pseudo-safe prompts and harmful prompts. The former are seemingly harmless sub-prompts that can bypass filters, while the latter are sub-prompts with unsafe semantics that trigger filters. Subsequently, the LLM rewrites the harmful prompts into natural adversarial prompts to bypass safety filters, which guide the T2I model to modify the base image into an NSFW output. Finally, to ensure semantic consistency between the generated NSFW images and the original unsafe prompts, the visual language model generates image captions, providing a new pathway to guide the LLM in iterative rewriting and refining the generated content.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-21",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.523677"
    },
    {
        "index": "#155",
        "title": "MDF-MLLM: Deep Fusion Through Cross-Modal Feature Alignment for Contextually Aware Fundoscopic Image Classification",
        "link": "/arxiv/2509.21358",
        "arxiv_id": "2509.21358",
        "authors": "Jason Jordan, Mohammadreza Akbari Lor, Peter Koulen, Mei-Ling Shyu, Shu-Ching Chen",
        "summary": "This study aimed to enhance disease classification accuracy from retinal fundus images by integrating fine-grained image features and global textual context using a novel multimodal deep learning architecture. Existing multimodal large language models (MLLMs) often struggle to capture low-level spatial details critical for diagnosing retinal diseases such as glaucoma, diabetic retinopathy, and retinitis pigmentosa. This model development and validation study was conducted on 1,305 fundus image-text pairs compiled from three public datasets (FIVES, HRF, and StoneRounds), covering acquired and inherited retinal diseases, and evaluated using classification accuracy and F1-score. The MDF-MLLM integrates skip features from four U-Net encoder layers into cross-attention blocks within a LLaMA 3.2 11B MLLM. Vision features are patch-wise projected and fused using scaled cross-attention and FiLM-based U-Net modulation. Baseline MLLM achieved 60% accuracy on the dual-type disease classification task. MDF-MLLM, with both U-Net and MLLM components fully fine-tuned during training, achieved a significantly higher accuracy of 94%, representing a 56% improvement. Recall and F1-scores improved by as much as 67% and 35% over baseline, respectively. Ablation studies confirmed that the multi-depth fusion approach contributed to substantial gains in spatial reasoning and classification, particularly for inherited diseases with rich clinical text. MDF-MLLM presents a generalizable, interpretable, and modular framework for fundus image classification, outperforming traditional MLLM baselines through multi-scale feature fusion. The architecture holds promise for real-world deployment in clinical decision support systems. Future work will explore synchronized training techniques, a larger pool of diseases for more generalizability, and extending the model for segmentation tasks.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-21",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.524187"
    },
    {
        "index": "#156",
        "title": "Phrase-grounded Fact-checking for Automatically Generated Chest X-ray Reports",
        "link": "/arxiv/2509.21356",
        "arxiv_id": "2509.21356",
        "authors": "Razi Mahmood, Diego Machado-Reyes, Joy Wu, Parisa Kaviani, Ken C. L. Wong, Niharika D'Souza, Mannudeep Kalra, Ge Wang, Pingkun Yan, Tanveer Syeda-Mahmood",
        "summary": "With the emergence of large-scale vision language models (VLM), it is now possible to produce realistic-looking radiology reports for chest X-ray images. However, their clinical translation has been hampered by the factual errors and hallucinations in the produced descriptions during inference. In this paper, we present a novel phrase-grounded fact-checking model (FC model) that detects errors in findings and their indicated locations in automatically generated chest radiology reports. Specifically, we simulate the errors in reports through a large synthetic dataset derived by perturbing findings and their locations in ground truth reports to form real and fake findings-location pairs with images. A new multi-label cross-modal contrastive regression network is then trained on this dataset. We present results demonstrating the robustness of our method in terms of accuracy of finding veracity prediction and localization on multiple X-ray datasets. We also show its effectiveness for error detection in reports of SOTA report generators on multiple datasets achieving a concordance correlation coefficient of 0.997 with ground truth-based verification, thus pointing to its utility during clinical inference in radiology workflows.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-20",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.524751"
    },
    {
        "index": "#157",
        "title": "KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache",
        "link": "/arxiv/2509.21354",
        "arxiv_id": "2509.21354",
        "authors": "Wanshun Xu, Long Zhuang",
        "summary": "Vision-Language-Action (VLA) models promise unified robotic perception and control, yet their scalability is constrained by the quadratic cost of attention and the unbounded growth of key-value (KV) memory during long-horizon inference. While recent methods improve generalization through scaling backbone architectures, they often neglect the inference inefficiencies critical to real-time deployment. In this work, we present KV-Efficient VLA, a model-agnostic memory compression framework that addresses these limitations by introducing a lightweight, training-friendly mechanism to selectively retain high-utility context. Our method partitions the KV cache into fixed size chunks and employs a recurrent gating module to summarize and filter historical context according to learned utility scores. This design preserves recent fine-grained detail while aggressively pruning stale, low-relevance memory, all while maintaining causality. Theoretically, KV-Efficient VLA yields up to 1.21x inference speedup and 36% KV memory reduction, with minimal impact on task success. Our method integrates seamlessly into existing autoregressive and hybrid VLA stacks, enabling scalable inference without modifying training pipelines or downstream control logic.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-09-20",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.525203"
    },
    {
        "index": "#158",
        "title": "Improving Autism Detection with Multimodal Behavioral Analysis",
        "link": "/arxiv/2509.21352",
        "arxiv_id": "2509.21352",
        "authors": "William Saakyan, Matthias Norden, Lola Eversmann, Simon Kirsch, Muyu Lin, Simon Guendelman, Isabel Dziobek, Hanna Drimalla",
        "summary": "Due to the complex and resource-intensive nature of diagnosing Autism Spectrum Condition (ASC), several computer-aided diagnostic support methods have been proposed to detect autism by analyzing behavioral cues in patient video data. While these models show promising results on some datasets, they struggle with poor gaze feature performance and lack of real-world generalizability. To tackle these challenges, we analyze a standardized video dataset comprising 168 participants with ASC (46% female) and 157 non-autistic participants (46% female), making it, to our knowledge, the largest and most balanced dataset available. We conduct a multimodal analysis of facial expressions, voice prosody, head motion, heart rate variability (HRV), and gaze behavior. To address the limitations of prior gaze models, we introduce novel statistical descriptors that quantify variability in eye gaze angles, improving gaze-based classification accuracy from 64% to 69% and aligning computational findings with clinical research on gaze aversion in ASC. Using late fusion, we achieve a classification accuracy of 74%, demonstrating the effectiveness of integrating behavioral markers across multiple modalities. Our findings highlight the potential for scalable, video-based screening tools to support autism assessment.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-19",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.525740"
    },
    {
        "index": "#159",
        "title": "Random Direct Preference Optimization for Radiography Report Generation",
        "link": "/arxiv/2509.21351",
        "arxiv_id": "2509.21351",
        "authors": "Valentin Samokhin, Boris Shirokikh, Mikhail Goncharov, Dmitriy Umerenkov, Maksim Bobrin, Ivan Oseledets, Dmitry Dylov, Mikhail Belyaev",
        "summary": "Radiography Report Generation (RRG) has gained significant attention in medical image analysis as a promising tool for alleviating the growing workload of radiologists. However, despite numerous advancements, existing methods have yet to achieve the quality required for deployment in real-world clinical settings. Meanwhile, large Visual Language Models (VLMs) have demonstrated remarkable progress in the general domain by adopting training strategies originally designed for Large Language Models (LLMs), such as alignment techniques. In this paper, we introduce a model-agnostic framework to enhance RRG accuracy using Direct Preference Optimization (DPO). Our approach leverages random contrastive sampling to construct training pairs, eliminating the need for reward models or human preference annotations. Experiments on supplementing three state-of-the-art models with our Random DPO show that our method improves clinical performance metrics by up to 5%, without requiring any additional training data.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-09-19",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.526293"
    },
    {
        "index": "#160",
        "title": "See, Point, Fly: A Learning-Free VLM Framework for Universal Unmanned Aerial Navigation",
        "link": "/arxiv/2509.22653",
        "arxiv_id": "2509.22653",
        "authors": "Chih Yao Hu, Yang-Sen Lin, Yuna Lee, Chih-Hai Su, Jie-Ying Lee, Shr-Ruei Tsai, Chin-Yang Lin, Kuan-Wen Chen, Tsung-Wei Ke, Yu-Lun Liu",
        "summary": "We present See, Point, Fly (SPF), a training-free aerial vision-and-language navigation (AVLN) framework built atop vision-language models (VLMs). SPF is capable of navigating to any goal based on any type of free-form instructions in any kind of environment. In contrast to existing VLM-based approaches that treat action prediction as a text generation task, our key insight is to consider action prediction for AVLN as a 2D spatial grounding task. SPF harnesses VLMs to decompose vague language instructions into iterative annotation of 2D waypoints on the input image. Along with the predicted traveling distance, SPF transforms predicted 2D waypoints into 3D displacement vectors as action commands for UAVs. Moreover, SPF also adaptively adjusts the traveling distance to facilitate more efficient navigation. Notably, SPF performs navigation in a closed-loop control manner, enabling UAVs to follow dynamic targets in dynamic environments. SPF sets a new state of the art in DRL simulation benchmark, outperforming the previous best method by an absolute margin of 63%. In extensive real-world evaluations, SPF outperforms strong baselines by a large margin. We also conduct comprehensive ablation studies to highlight the effectiveness of our design choice. Lastly, SPF shows remarkable generalization to different VLMs. Project page: https://spf-web.pages.dev",
        "subjects": "Robotics, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.526909"
    },
    {
        "index": "#161",
        "title": "Pixel Motion Diffusion is What We Need for Robot Control",
        "link": "/arxiv/2509.22652",
        "arxiv_id": "2509.22652",
        "authors": "E-Ro Nguyen, Yichi Zhang, Kanchana Ranasinghe, Xiang Li, Michael S. Ryoo",
        "summary": "We present DAWN (Diffusion is All We Need for robot control), a unified diffusion-based framework for language-conditioned robotic manipulation that bridges high-level motion intent and low-level robot action via structured pixel motion representation. In DAWN, both the high-level and low-level controllers are modeled as diffusion processes, yielding a fully trainable, end-to-end system with interpretable intermediate motion abstractions. DAWN achieves state-of-the-art results on the challenging CALVIN benchmark, demonstrating strong multi-task performance, and further validates its effectiveness on MetaWorld. Despite the substantial domain gap between simulation and reality and limited real-world data, we demonstrate reliable real-world transfer with only minimal finetuning, illustrating the practical viability of diffusion-based motion abstractions for robotic control. Our results show the effectiveness of combining diffusion modeling with motion-centric representations as a strong baseline for scalable and robust robot learning. Project page: https://nero1342.github.io/DAWN/",
        "subjects": "Robotics, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.532580"
    },
    {
        "index": "#162",
        "title": "VoiceAssistant-Eval: Benchmarking AI Assistants across Listening, Speaking, and Viewing",
        "link": "/arxiv/2509.22651",
        "arxiv_id": "2509.22651",
        "authors": "Ke Wang, Houxing Ren, Zimu Lu, Mingjie Zhan, Hongsheng Li",
        "summary": "The growing capabilities of large language models and multimodal systems have spurred interest in voice-first AI assistants, yet existing benchmarks are inadequate for evaluating the full range of these systems' capabilities. We introduce VoiceAssistant-Eval, a comprehensive benchmark designed to assess AI assistants across listening, speaking, and viewing. VoiceAssistant-Eval comprises 10,497 curated examples spanning 13 task categories. These tasks include natural sounds, music, and spoken dialogue for listening; multi-turn dialogue, role-play imitation, and various scenarios for speaking; and highly heterogeneous images for viewing. To demonstrate its utility, we evaluate 21 open-source models and GPT-4o-Audio, measuring the quality of the response content and speech, as well as their consistency. The results reveal three key findings: (1) proprietary models do not universally outperform open-source models; (2) most models excel at speaking tasks but lag in audio understanding; and (3) well-designed smaller models can rival much larger ones. Notably, the mid-sized Step-Audio-2-mini (7B) achieves more than double the listening accuracy of LLaMA-Omni2-32B-Bilingual. However, challenges remain: multimodal (audio plus visual) input and role-play voice imitation tasks are difficult for current models, and significant gaps persist in robustness and safety alignment. VoiceAssistant-Eval identifies these gaps and establishes a rigorous framework for evaluating and guiding the development of next-generation AI assistants. Code and data will be released at https://mathllm.github.io/VoiceAssistantEval/ .",
        "subjects": "Computation and Language, Artificial Intelligence, Computer Vision and Pattern Recognition, Human-Computer Interaction, Sound",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.533130"
    },
    {
        "index": "#163",
        "title": "WoW: Towards a World omniscient World model Through Embodied Interaction",
        "link": "/arxiv/2509.22642",
        "arxiv_id": "2509.22642",
        "authors": "Xiaowei Chi, Peidong Jia, Chun-Kai Fan, Xiaozhu Ju, Weishi Mi, Kevin Zhang, Zhiyuan Qin, Wanxin Tian, Kuangzhi Ge, Hao Li, Zezhong Qian, Anthony Chen, Qiang Zhou, Yueru Jia, Jiaming Liu, Yong Dai, Qingpo Wuwu, Chengyu Bai, Yu-Kai Wang, Ying Li, Lizhang Chen, Yong Bao, Zhiyuan Jiang, Jiacheng Zhu, Kai Tang, Ruichuan An, Yulin Luo, Qiuxuan Feng, Siyuan Zhou, Chi-min Chan, Chengkai Hou, Wei Xue, Sirui Han, Yike Guo, Shanghang Zhang, Jian Tang",
        "summary": "Humans develop an understanding of intuitive physics through active interaction with the world. This approach is in stark contrast to current video models, such as Sora, which rely on passive observation and therefore struggle with grasping physical causality. This observation leads to our central hypothesis: authentic physical intuition of the world model must be grounded in extensive, causally rich interactions with the real world. To test this hypothesis, we present WoW, a 14-billion-parameter generative world model trained on 2 million robot interaction trajectories. Our findings reveal that the model's understanding of physics is a probabilistic distribution of plausible outcomes, leading to stochastic instabilities and physical hallucinations. Furthermore, we demonstrate that this emergent capability can be actively constrained toward physical realism by SOPHIA, where vision-language model agents evaluate the DiT-generated output and guide its refinement by iteratively evolving the language instructions. In addition, a co-trained Inverse Dynamics Model translates these refined plans into executable robotic actions, thus closing the imagination-to-action loop. We establish WoWBench, a new benchmark focused on physical consistency and causal reasoning in video, where WoW achieves state-of-the-art performance in both human and autonomous evaluation, demonstrating strong ability in physical causality, collision dynamics, and object permanence. Our work provides systematic evidence that large-scale, real-world interaction is a cornerstone for developing physical intuition in AI. Models, data, and benchmarks will be open-sourced.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition, Multimedia",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.534056"
    },
    {
        "index": "#165",
        "title": "MINT-RVAE: Multi-Cues Intention Prediction of Human-Robot Interaction using Human Pose and Emotion Information from RGB-only Camera Data",
        "link": "/arxiv/2509.22573",
        "arxiv_id": "2509.22573",
        "authors": "Farida Mohsen, Ali Safa",
        "summary": "Efficiently detecting human intent to interact with ubiquitous robots is crucial for effective human-robot interaction (HRI) and collaboration. Over the past decade, deep learning has gained traction in this field, with most existing approaches relying on multimodal inputs, such as RGB combined with depth (RGB-D), to classify time-sequence windows of sensory data as interactive or non-interactive. In contrast, we propose a novel RGB-only pipeline for predicting human interaction intent with frame-level precision, enabling faster robot responses and improved service quality. A key challenge in intent prediction is the class imbalance inherent in real-world HRI datasets, which can hinder the model's training and generalization. To address this, we introduce MINT-RVAE, a synthetic sequence generation method, along with new loss functions and training strategies that enhance generalization on out-of-sample data. Our approach achieves state-of-the-art performance (AUROC: 0.95) outperforming prior works (AUROC: 0.90-0.912), while requiring only RGB input and supporting precise frame onset prediction. Finally, to support future research, we openly release our new dataset with frame-level labeling of human interaction intent.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.535189"
    },
    {
        "index": "#166",
        "title": "Activation Function Design Sustains Plasticity in Continual Learning",
        "link": "/arxiv/2509.22562",
        "arxiv_id": "2509.22562",
        "authors": "Lute Lillo, Nick Cheney",
        "summary": "In independent, identically distributed (i.i.d.) training regimes, activation functions have been benchmarked extensively, and their differences often shrink once model size and optimization are tuned. In continual learning, however, the picture is different: beyond catastrophic forgetting, models can progressively lose the ability to adapt (referred to as loss of plasticity) and the role of the non-linearity in this failure mode remains underexplored. We show that activation choice is a primary, architecture-agnostic lever for mitigating plasticity loss. Building on a property-level analysis of negative-branch shape and saturation behavior, we introduce two drop-in nonlinearities (Smooth-Leaky and Randomized Smooth-Leaky) and evaluate them in two complementary settings: (i) supervised class-incremental benchmarks and (ii) reinforcement learning with non-stationary MuJoCo environments designed to induce controlled distribution and dynamics shifts. We also provide a simple stress protocol and diagnostics that link the shape of the activation to the adaptation under change. The takeaway is straightforward: thoughtful activation design offers a lightweight, domain-general way to sustain plasticity in continual learning without extra capacity or task-specific tuning.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.535651"
    },
    {
        "index": "#167",
        "title": "JointDiff: Bridging Continuous and Discrete in Multi-Agent Trajectory Generation",
        "link": "/arxiv/2509.22522",
        "arxiv_id": "2509.22522",
        "authors": "Guillem Capellera, Luis Ferraz, Antonio Rubio, Alexandre Alahi, Antonio Agudo",
        "summary": "Generative models often treat continuous data and discrete events as separate processes, creating a gap in modeling complex systems where they interact synchronously. To bridge this gap, we introduce JointDiff, a novel diffusion framework designed to unify these two processes by simultaneously generating continuous spatio-temporal data and synchronous discrete events. We demonstrate its efficacy in the sports domain by simultaneously modeling multi-agent trajectories and key possession events. This joint modeling is validated with non-controllable generation and two novel controllable generation scenarios: weak-possessor-guidance, which offers flexible semantic control over game dynamics through a simple list of intended ball possessors, and text-guidance, which enables fine-grained, language-driven generation. To enable the conditioning with these guidance signals, we introduce CrossGuid, an effective conditioning operation for multi-agent domains. We also share a new unified sports benchmark enhanced with textual descriptions for soccer and football datasets. JointDiff achieves state-of-the-art performance, demonstrating that joint modeling is crucial for building realistic and controllable generative models for interactive systems.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.536187"
    },
    {
        "index": "#168",
        "title": "Adaptive Dual-Mode Distillation with Incentive Schemes for Scalable, Heterogeneous Federated Learning on Non-IID Data",
        "link": "/arxiv/2509.22507",
        "arxiv_id": "2509.22507",
        "authors": "Zahid Iqbal",
        "summary": "Federated Learning (FL) has emerged as a promising decentralized learning (DL) approach that enables the use of distributed data without compromising user privacy. However, FL poses several key challenges. First, it is frequently assumed that every client can train the same machine learning models, however, not all clients are able to meet this assumption because of differences in their business needs and computational resources. Second, statistical heterogeneity (a.k.a. non-IID data) poses a major challenge in FL, which can lead to lower global model performance. Third, while addressing these challenges, there is a need for a cost-effective incentive mechanism to encourage clients to participate in FL training. In response to these challenges, we propose several methodologies: DL-SH, which facilitates efficient, privacy-preserving, and communication-efficient learning in the context of statistical heterogeneity; DL-MH, designed to manage fully heterogeneous models while tackling statistical disparities; and I-DL-MH, an incentive-based extension of DL-MH that promotes client engagement in federated learning training by providing incentives within this complex federated learning framework. Comprehensive experiments were carried out to assess the performance and scalability of the proposed approaches across a range of complex experimental settings. This involved utilizing various model architectures, in diverse data distributions, including IID and several non-IID scenarios, as well as multiple datasets. Experimental results demonstrate that the proposed approaches significantly enhance accuracy and decrease communication costs while effectively addressing statistical heterogeneity and model heterogeneity in comparison to existing state-of-the-art approaches and baselines, with DL-SH improving global model accuracy by 153%, and I-DL-MH achieving a 225% improvement under non-IID conditions.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.536610"
    },
    {
        "index": "#169",
        "title": "Deep Learning-Based Cross-Anatomy CT Synthesis Using Adapted nnResU-Net with Anatomical Feature Prioritized Loss",
        "link": "/arxiv/2509.22394",
        "arxiv_id": "2509.22394",
        "authors": "Javier Sequeiro González, Arthur Longuefosse, Miguel Díaz Benito, Álvaro García Martín, Fabien Baldacci",
        "summary": "We present a patch-based 3D nnUNet adaptation for MR to CT and CBCT to CT image translation using the multicenter SynthRAD2025 dataset, covering head and neck (HN), thorax (TH), and abdomen (AB) regions. Our approach leverages two main network configurations: a standard UNet and a residual UNet, both adapted from nnUNet for image synthesis. The Anatomical Feature-Prioritized (AFP) loss was introduced, which compares multilayer features extracted from a compact segmentation network trained on TotalSegmentator labels, enhancing reconstruction of clinically relevant structures. Input volumes were normalized per-case using zscore normalization for MRIs, and clipping plus dataset level zscore normalization for CBCT and CT. Training used 3D patches tailored to each anatomical region without additional data augmentation. Models were trained for 1000 and 1500 epochs, with AFP fine-tuning performed for 500 epochs using a combined L1+AFP objective. During inference, overlapping patches were aggregated via mean averaging with step size of 0.3, and postprocessing included reverse zscore normalization. Both network configurations were applied across all regions, allowing consistent model design while capturing local adaptations through residual learning and AFP loss. Qualitative and quantitative evaluation revealed that residual networks combined with AFP yielded sharper reconstructions and improved anatomical fidelity, particularly for bone structures in MR to CT and lesions in CBCT to CT, while L1only networks achieved slightly better intensity-based metrics. This methodology provides a stable solution for cross modality medical image synthesis, demonstrating the effectiveness of combining the automatic nnUNet pipeline with residual learning and anatomically guided feature losses.",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.537121"
    },
    {
        "index": "#170",
        "title": "RoboView-Bias: Benchmarking Visual Bias in Embodied Agents for Robotic Manipulation",
        "link": "/arxiv/2509.22356",
        "arxiv_id": "2509.22356",
        "authors": "Enguang Liu, Siyuan Liang, Liming Lu, Xiyu Zeng, Xiaochun Cao, Aishan Liu, Shuchao Pang",
        "summary": "The safety and reliability of embodied agents rely on accurate and unbiased visual perception. However, existing benchmarks mainly emphasize generalization and robustness under perturbations, while systematic quantification of visual bias remains scarce. This gap limits a deeper understanding of how perception influences decision-making stability. To address this issue, we propose RoboView-Bias, the first benchmark specifically designed to systematically quantify visual bias in robotic manipulation, following a principle of factor isolation. Leveraging a structured variant-generation framework and a perceptual-fairness validation protocol, we create 2,127 task instances that enable robust measurement of biases induced by individual visual factors and their interactions. Using this benchmark, we systematically evaluate three representative embodied agents across two prevailing paradigms and report three key findings: (i) all agents exhibit significant visual biases, with camera viewpoint being the most critical factor; (ii) agents achieve their highest success rates on highly saturated colors, indicating inherited visual preferences from underlying VLMs; and (iii) visual biases show strong, asymmetric coupling, with viewpoint strongly amplifying color-related bias. Finally, we demonstrate that a mitigation strategy based on a semantic grounding layer substantially reduces visual bias by approximately 54.5\\% on MOKA. Our results highlight that systematic analysis of visual bias is a prerequisite for developing safe and reliable general-purpose embodied agents.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.542785"
    },
    {
        "index": "#171",
        "title": "Clinical Uncertainty Impacts Machine Learning Evaluations",
        "link": "/arxiv/2509.22242",
        "arxiv_id": "2509.22242",
        "authors": "Simone Lionetti, Fabian Gröger, Philippe Gottfrois, Alvaro Gonzalez-Jimenez, Ludovic Amruthalingam, Alexander A. Navarini, Marc Pouly",
        "summary": "Clinical dataset labels are rarely certain as annotators disagree and confidence is not uniform across cases. Typical aggregation procedures, such as majority voting, obscure this variability. In simple experiments on medical imaging benchmarks, accounting for the confidence in binary labels significantly impacts model rankings. We therefore argue that machine-learning evaluations should explicitly account for annotation uncertainty using probabilistic metrics that directly operate on distributions. These metrics can be applied independently of the annotations' generating process, whether modeled by simple counting, subjective confidence ratings, or probabilistic response models. They are also computationally lightweight, as closed-form expressions have linear-time implementations once examples are sorted by model score. We thus urge the community to release raw annotations for datasets and to adopt uncertainty-aware evaluation so that performance estimates may better reflect clinical data.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.543314"
    },
    {
        "index": "#172",
        "title": "COMPASS: Robust Feature Conformal Prediction for Medical Segmentation Metrics",
        "link": "/arxiv/2509.22240",
        "arxiv_id": "2509.22240",
        "authors": "Matt Y. Cheung, Ashok Veeraraghavan, Guha Balakrishnan",
        "summary": "In clinical applications, the utility of segmentation models is often based on the accuracy of derived downstream metrics such as organ size, rather than by the pixel-level accuracy of the segmentation masks themselves. Thus, uncertainty quantification for such metrics is crucial for decision-making. Conformal prediction (CP) is a popular framework to derive such principled uncertainty guarantees, but applying CP naively to the final scalar metric is inefficient because it treats the complex, non-linear segmentation-to-metric pipeline as a black box. We introduce COMPASS, a practical framework that generates efficient, metric-based CP intervals for image segmentation models by leveraging the inductive biases of their underlying deep neural networks. COMPASS performs calibration directly in the model's representation space by perturbing intermediate features along low-dimensional subspaces maximally sensitive to the target metric. We prove that COMPASS achieves valid marginal coverage under exchangeability and nestedness assumptions. Empirically, we demonstrate that COMPASS produces significantly tighter intervals than traditional CP baselines on four medical image segmentation tasks for area estimation of skin lesions and anatomical structures. Furthermore, we show that leveraging learned internal features to estimate importance weights allows COMPASS to also recover target coverage under covariate shifts. COMPASS paves the way for practical, metric-based uncertainty quantification for medical image segmentation.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning, Applications, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.543850"
    },
    {
        "index": "#173",
        "title": "Aerial Path Planning for Urban Geometry and Texture Co-Capture",
        "link": "/arxiv/2509.22227",
        "arxiv_id": "2509.22227",
        "authors": "Weidan Xiong, Bochuan Zeng, Ziyu Hu, Jianwei Guo, Ke Xie, Hui Huang",
        "summary": "Recent advances in image acquisition and scene reconstruction have enabled the generation of high-quality structural urban scene geometry, given sufficient site information. However, current capture techniques often overlook the crucial importance of texture quality, resulting in noticeable visual artifacts in the textured models. In this work, we introduce the urban geometry and texture co-capture problem under limited prior knowledge before a site visit. The only inputs are a 2D building contour map of the target area and a safe flying altitude above the buildings. We propose an innovative aerial path planning framework designed to co-capture images for reconstructing both structured geometry and high-fidelity textures. To evaluate and guide view planning, we introduce a comprehensive texture quality assessment system, including two novel metrics tailored for building facades. Firstly, our method generates high-quality vertical dipping views and horizontal planar views to effectively capture both geometric and textural details. A multi-objective optimization strategy is then proposed to jointly maximize texture fidelity, improve geometric accuracy, and minimize the cost associated with aerial views. Furthermore, we present a sequential path planning algorithm that accounts for texture consistency during image capture. Extensive experiments on large-scale synthetic and real-world urban datasets demonstrate that our approach effectively produces image sets suitable for concurrent geometric and texture reconstruction, enabling the creation of realistic, textured scene proxies at low operational cost.",
        "subjects": "Graphics, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.544364"
    },
    {
        "index": "#174",
        "title": "Rigidity-Aware 3D Gaussian Deformation from a Single Image",
        "link": "/arxiv/2509.22222",
        "arxiv_id": "2509.22222",
        "authors": "Jinhyeok Kim, Jaehun Bang, Seunghyun Seo, Kyungdon Joo",
        "summary": "Reconstructing object deformation from a single image remains a significant challenge in computer vision and graphics. Existing methods typically rely on multi-view video to recover deformation, limiting their applicability under constrained scenarios. To address this, we propose DeformSplat, a novel framework that effectively guides 3D Gaussian deformation from only a single image. Our method introduces two main technical contributions. First, we present Gaussian-to-Pixel Matching which bridges the domain gap between 3D Gaussian representations and 2D pixel observations. This enables robust deformation guidance from sparse visual cues. Second, we propose Rigid Part Segmentation consisting of initialization and refinement. This segmentation explicitly identifies rigid regions, crucial for maintaining geometric coherence during deformation. By combining these two techniques, our approach can reconstruct consistent deformations from a single image. Extensive experiments demonstrate that our approach significantly outperforms existing methods and naturally extends to various applications,such as frame interpolation and interactive object manipulation.",
        "subjects": "Graphics, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.544854"
    },
    {
        "index": "#175",
        "title": "Guidance Watermarking for Diffusion Models",
        "link": "/arxiv/2509.22126",
        "arxiv_id": "2509.22126",
        "authors": "Enoal Gesny, Eva Giboulot, Teddy Furon, Vivien Chappelier",
        "summary": "This paper introduces a novel watermarking method for diffusion models. It is based on guiding the diffusion process using the gradient computed from any off-the-shelf watermark decoder. The gradient computation encompasses different image augmentations, increasing robustness to attacks against which the decoder was not originally robust, without retraining or fine-tuning. Our method effectively convert any \\textit{post-hoc} watermarking scheme into an in-generation embedding along the diffusion process. We show that this approach is complementary to watermarking techniques modifying the variational autoencoder at the end of the diffusion process. We validate the methods on different diffusion models and detectors. The watermarking guidance does not significantly alter the generated image for a given seed and prompt, preserving both the diversity and quality of generation.",
        "subjects": "Cryptography and Security, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.545350"
    },
    {
        "index": "#176",
        "title": "Enriching Knowledge Distillation with Intra-Class Contrastive Learning",
        "link": "/arxiv/2509.22053",
        "arxiv_id": "2509.22053",
        "authors": "Hua Yuan, Ning Xu, Xin Geng, Yong Rui",
        "summary": "Since the advent of knowledge distillation, much research has focused on how the soft labels generated by the teacher model can be utilized effectively. Existing studies points out that the implicit knowledge within soft labels originates from the multi-view structure present in the data. Feature variations within samples of the same class allow the student model to generalize better by learning diverse representations. However, in existing distillation methods, teacher models predominantly adhere to ground-truth labels as targets, without considering the diverse representations within the same class. Therefore, we propose incorporating an intra-class contrastive loss during teacher training to enrich the intra-class information contained in soft labels. In practice, we find that intra-class loss causes instability in training and slows convergence. To mitigate these issues, margin loss is integrated into intra-class contrastive learning to improve the training stability and convergence speed. Simultaneously, we theoretically analyze the impact of this loss on the intra-class distances and inter-class distances. It has been proved that the intra-class contrastive loss can enrich the intra-class diversity. Experimental results demonstrate the effectiveness of the proposed method.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.545827"
    },
    {
        "index": "#177",
        "title": "Comparative Analysis of GAN and Diffusion for MRI-to-CT translation",
        "link": "/arxiv/2509.22049",
        "arxiv_id": "2509.22049",
        "authors": "Emily Honey, Anders Helbo, Jens Petersen",
        "summary": "Computed tomography (CT) is essential for treatment and diagnostics; In case CT are missing or otherwise difficult to obtain, methods for generating synthetic CT (sCT) images from magnetic resonance imaging (MRI) images are sought after. Therefore, it is valuable to establish a reference for what strategies are most effective for MRI-to-CT translation. In this paper, we compare the performance of two frequently used architectures for MRI-to-CT translation: a conditional generative adversarial network (cGAN) and a conditional denoising diffusion probabilistic model (cDDPM). We chose well-established implementations to represent each architecture: Pix2Pix for cGAN, and Palette for cDDPM. We separate the classical 3D translation problem into a sequence of 2D translations on the transverse plane, to investigate the viability of a strategy that reduces the computational cost. We also investigate the impact of conditioning the generative process on a single MRI image/slice and on multiple MRI slices. The performance is assessed using a thorough evaluation protocol, including a novel slice-wise metric Similarity Of Slices (SIMOS), which measures the continuity between transverse slices when compiling the sCTs into 3D format. Our comparative analysis revealed that MRI-to-CT generative models benefit from multi-channel conditional input and using cDDPM as an architecture.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.546313"
    },
    {
        "index": "#178",
        "title": "Closing the Oracle Gap: Increment Vector Transformation for Class Incremental Learning",
        "link": "/arxiv/2509.21898",
        "arxiv_id": "2509.21898",
        "authors": "Zihuan Qiu, Yi Xu, Fanman Meng, Runtong Zhang, Linfeng Xu, Qingbo Wu, Hongliang Li",
        "summary": "Class Incremental Learning (CIL) aims to sequentially acquire knowledge of new classes without forgetting previously learned ones. Despite recent progress, current CIL methods still exhibit significant performance gaps compared to their oracle counterparts-models trained with full access to historical data. Inspired by recent insights on Linear Mode Connectivity (LMC), we revisit the geometric properties of oracle solutions in CIL and uncover a fundamental observation: these oracle solutions typically maintain low-loss linear connections to the optimum of previous tasks. Motivated by this finding, we propose Increment Vector Transformation (IVT), a novel plug-and-play framework designed to mitigate catastrophic forgetting during training. Rather than directly following CIL updates, IVT periodically teleports the model parameters to transformed solutions that preserve linear connectivity to previous task optimum. By maintaining low-loss along these connecting paths, IVT effectively ensures stable performance on previously learned tasks. The transformation is efficiently approximated using diagonal Fisher Information Matrices, making IVT suitable for both exemplar-free and exemplar-based scenarios, and compatible with various initialization strategies. Extensive experiments on CIFAR-100, FGVCAircraft, ImageNet-Subset, and ImageNet-Full demonstrate that IVT consistently enhances the performance of strong CIL baselines. Specifically, on CIFAR-100, IVT improves the last accuracy of the PASS baseline by +5.12% and reduces forgetting by 2.54%. For the CLIP-pre-trained SLCA baseline on FGVCAircraft, IVT yields gains of +14.93% in average accuracy and +21.95% in last accuracy. The code will be released.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.546834"
    },
    {
        "index": "#179",
        "title": "Perception-Consistency Multimodal Large Language Models Reasoning via Caption-Regularized Policy Optimization",
        "link": "/arxiv/2509.21854",
        "arxiv_id": "2509.21854",
        "authors": "Songjun Tu, Qichao Zhang, Jingbo Sun, Yuqian Fu, Linjing Li, Xiangyuan Lan, Dongmei Jiang, Yaowei Wang, Dongbin Zhao",
        "summary": "While multimodal large language models excel at tasks that integrate visual perception with symbolic reasoning, their performance is often undermined by a critical vulnerability: perception-induced errors that propagate through the reasoning chain. Current reinforcement learning (RL) fine-tuning methods, while enhancing reasoning abilities, largely fail to address the underlying misalignment between visual grounding and the subsequent reasoning process. To address this challenge, we propose \\textbf{Caption-Regularized Policy Optimization (CapPO)}, a novel RL framework that explicitly enforces perceptual consistency during policy optimization. CapPO integrates two key mechanisms: (1) a caption-based consistency regularization, which minimizes the divergence between responses conditioned on raw images and those conditioned on captions, thereby anchoring reasoning to semantically faithful visual content; and (2) a KL-weighted advantage estimation scheme, which adaptively scales reinforcement signals to strengthen perceptually consistent trajectories while suppressing spurious correlations. Extensive experiments on five math-focused and five general reasoning benchmarks demonstrate that CapPO achieves competitive performance, yielding gains of +6.0% accuracy on math-related tasks and +2.4% on general reasoning tasks over the base Qwen2.5-VL-7B model. Moreover, ablation studies further confirm the effectiveness of each component, while error analysis reveals that CapPO significantly reduces perception-related mistakes compared with baselines. Overall, CapPO provides a simple yet effective framework for improving multimodal reasoning.",
        "subjects": "Multimedia, Computer Vision and Pattern Recognition",
        "date": "2025-09-26",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.719940"
    },
    {
        "index": "#181",
        "title": "ControlHair: Physically-based Video Diffusion for Controllable Dynamic Hair Rendering",
        "link": "/arxiv/2509.21541",
        "arxiv_id": "2509.21541",
        "authors": "Weikai Lin, Haoxiang Li, Yuhao Zhu",
        "summary": "Hair simulation and rendering are challenging due to complex strand dynamics, diverse material properties, and intricate light-hair interactions. Recent video diffusion models can generate high-quality videos, but they lack fine-grained control over hair dynamics. We present ControlHair, a hybrid framework that integrates a physics simulator with conditional video diffusion to enable controllable dynamic hair rendering. ControlHair adopts a three-stage pipeline: it first encodes physics parameters (e.g., hair stiffness, wind) into per-frame geometry using a simulator, then extracts per-frame control signals, and finally feeds control signals into a video diffusion model to generate videos with desired hair dynamics. This cascaded design decouples physics reasoning from video generation, supports diverse physics, and makes training the video diffusion model easy. Trained on a curated 10K video dataset, ControlHair outperforms text- and pose-conditioned baselines, delivering precisely controlled hair dynamics. We further demonstrate three use cases of ControlHair: dynamic hairstyle try-on, bullet-time effects, and cinemagraphic. ControlHair introduces the first physics-informed video diffusion framework for controllable dynamics. We provide a teaser video and experimental results on our website.",
        "subjects": "Graphics, Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.721405"
    },
    {
        "index": "#182",
        "title": "Patch-Based Diffusion for Data-Efficient, Radiologist-Preferred MRI Reconstruction",
        "link": "/arxiv/2509.21531",
        "arxiv_id": "2509.21531",
        "authors": "Rohan Sanda, Asad Aali, Andrew Johnston, Eduardo Reis, Jonathan Singh, Gordon Wetzstein, Sara Fridovich-Keil",
        "summary": "Magnetic resonance imaging (MRI) requires long acquisition times, raising costs, reducing accessibility, and making scans more susceptible to motion artifacts. Diffusion probabilistic models that learn data-driven priors can potentially assist in reducing acquisition time. However, they typically require large training datasets that can be prohibitively expensive to collect. Patch-based diffusion models have shown promise in learning effective data-driven priors over small real-valued datasets, but have not yet demonstrated clinical value in MRI. We extend the Patch-based Diffusion Inverse Solver (PaDIS) to complex-valued, multi-coil MRI reconstruction, and compare it against a state-of-the-art whole-image diffusion baseline (FastMRI-EDM) for 7x undersampled MRI reconstruction on the FastMRI brain dataset. We show that PaDIS-MRI models trained on small datasets of as few as 25 k-space images outperform FastMRI-EDM on image quality metrics (PSNR, SSIM, NRMSE), pixel-level uncertainty, cross-contrast generalization, and robustness to severe k-space undersampling. In a blinded study with three radiologists, PaDIS-MRI reconstructions were chosen as diagnostically superior in 91.7% of cases, compared to baselines (i) FastMRI-EDM and (ii) classical convex reconstruction with wavelet sparsity. These findings highlight the potential of patch-based diffusion priors for high-fidelity MRI reconstruction in data-scarce clinical settings where diagnostic confidence matters.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.722086"
    },
    {
        "index": "#183",
        "title": "TRiCo: Triadic Game-Theoretic Co-Training for Robust Semi-Supervised Learning",
        "link": "/arxiv/2509.21526",
        "arxiv_id": "2509.21526",
        "authors": "Hongyang He, Xinyuan Song, Yangfan He, Zeyu Zhang, Yanshu Li, Haochen You, Lifan Sun, Wenqiao Zhang",
        "summary": "We introduce TRiCo, a novel triadic game-theoretic co-training framework that rethinks the structure of semi-supervised learning by incorporating a teacher, two students, and an adversarial generator into a unified training paradigm. Unlike existing co-training or teacher-student approaches, TRiCo formulates SSL as a structured interaction among three roles: (i) two student classifiers trained on frozen, complementary representations, (ii) a meta-learned teacher that adaptively regulates pseudo-label selection and loss balancing via validation-based feedback, and (iii) a non-parametric generator that perturbs embeddings to uncover decision boundary weaknesses. Pseudo-labels are selected based on mutual information rather than confidence, providing a more robust measure of epistemic uncertainty. This triadic interaction is formalized as a Stackelberg game, where the teacher leads strategy optimization and students follow under adversarial perturbations. By addressing key limitations in existing SSL frameworks, such as static view interactions, unreliable pseudo-labels, and lack of hard sample modeling, TRiCo provides a principled and generalizable solution. Extensive experiments on CIFAR-10, SVHN, STL-10, and ImageNet demonstrate that TRiCo consistently achieves state-of-the-art performance in low-label regimes, while remaining architecture-agnostic and compatible with frozen vision backbones.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.722800"
    },
    {
        "index": "#184",
        "title": "DistillKac: Few-Step Image Generation via Damped Wave Equations",
        "link": "/arxiv/2509.21513",
        "arxiv_id": "2509.21513",
        "authors": "Weiqiao Han, Chenlin Meng, Christopher D. Manning, Stefano Ermon",
        "summary": "We present DistillKac, a fast image generator that uses the damped wave equation and its stochastic Kac representation to move probability mass at finite speed. In contrast to diffusion models whose reverse time velocities can become stiff and implicitly allow unbounded propagation speed, Kac dynamics enforce finite speed transport and yield globally bounded kinetic energy. Building on this structure, we introduce classifier-free guidance in velocity space that preserves square integrability under mild conditions. We then propose endpoint only distillation that trains a student to match a frozen teacher over long intervals. We prove a stability result that promotes supervision at the endpoints to closeness along the entire path. Experiments demonstrate DistillKac delivers high quality samples with very few function evaluations while retaining the numerical stability benefits of finite speed probability flows.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Probability, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.723516"
    },
    {
        "index": "#185",
        "title": "SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models",
        "link": "/arxiv/2509.21498",
        "arxiv_id": "2509.21498",
        "authors": "Arani Roy, Shristi Das Biswas, Kaushik Roy",
        "summary": "Diffusion models (DMs), lauded for their generative performance, are computationally prohibitive due to their billion-scale parameters and iterative denoising dynamics. Existing efficiency techniques, such as quantization, timestep reduction, or pruning, offer savings in compute, memory, or runtime but are strictly bottlenecked by reliance on fine-tuning or retraining to recover performance. In this work, we introduce SlimDiff, an automated activation-informed structural compression framework that reduces both attention and feedforward dimensionalities in DMs, while being entirely gradient-free. SlimDiff reframes DM compression as a spectral approximation task, where activation covariances across denoising timesteps define low-rank subspaces that guide dynamic pruning under a fixed compression budget. This activation-aware formulation mitigates error accumulation across timesteps by applying module-wise decompositions over functional weight groups: query--key interactions, value--output couplings, and feedforward projections, rather than isolated matrix factorizations, while adaptively allocating sparsity across modules to respect the non-uniform geometry of diffusion trajectories. SlimDiff achieves up to 35\\% acceleration and $\\sim$100M parameter reduction over baselines, with generation quality on par with uncompressed models without any backpropagation. Crucially, our approach requires only about 500 calibration samples, over 70$\\times$ fewer than prior methods. To our knowledge, this is the first closed-form, activation-guided structural compression of DMs that is entirely training-free, providing both theoretical clarity and practical efficiency.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.724129"
    },
    {
        "index": "#186",
        "title": "VISION: Prompting Ocean Vertical Velocity Reconstruction from Incomplete Observations",
        "link": "/arxiv/2509.21477",
        "arxiv_id": "2509.21477",
        "authors": "Yuan Gao, Hao Wu, Qingsong Wen, Kun Wang, Xian Wu, Xiaomeng Huang",
        "summary": "Reconstructing subsurface ocean dynamics, such as vertical velocity fields, from incomplete surface observations poses a critical challenge in Earth science, a field long hampered by the lack of standardized, analysis-ready benchmarks. To systematically address this issue and catalyze research, we first build and release KD48, a high-resolution ocean dynamics benchmark derived from petascale simulations and curated with expert-driven denoising. Building on this benchmark, we introduce VISION, a novel reconstruction paradigm based on Dynamic Prompting designed to tackle the core problem of missing data in real-world observations. The essence of VISION lies in its ability to generate a visual prompt on-the-fly from any available subset of observations, which encodes both data availability and the ocean's physical state. More importantly, we design a State-conditioned Prompting module that efficiently injects this prompt into a universal backbone, endowed with geometry- and scale-aware operators, to guide its adaptive adjustment of computational strategies. This mechanism enables VISION to precisely handle the challenges posed by varying input combinations. Extensive experiments on the KD48 benchmark demonstrate that VISION not only substantially outperforms state-of-the-art models but also exhibits strong generalization under extreme data missing scenarios. By providing a high-quality benchmark and a robust model, our work establishes a solid infrastructure for ocean science research under data uncertainty. Our codes are available at: https://github.com/YuanGao-YG/VISION.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Atmospheric and Oceanic Physics",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.724708"
    },
    {
        "index": "#187",
        "title": "Are Hallucinations Bad Estimations?",
        "link": "/arxiv/2509.21473",
        "arxiv_id": "2509.21473",
        "authors": "Hude Liu, Jerry Yao-Chieh Hu, Jennifer Yuntong Zhang, Zhao Song, Han Liu",
        "summary": "We formalize hallucinations in generative models as failures to link an estimate to any plausible cause. Under this interpretation, we show that even loss-minimizing optimal estimators still hallucinate. We confirm this with a general high probability lower bound on hallucinate rate for generic data distributions. This reframes hallucination as structural misalignment between loss minimization and human-acceptable outputs, and hence estimation errors induced by miscalibration. Experiments on coin aggregation, open-ended QA, and text-to-image support our theory.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.730480"
    },
    {
        "index": "#188",
        "title": "Language-in-the-Loop Culvert Inspection on the Erie Canal",
        "link": "/arxiv/2509.21370",
        "arxiv_id": "2509.21370",
        "authors": "Yashom Dighe, Yash Turkar, Karthik Dantu",
        "summary": "Culverts on canals such as the Erie Canal, built originally in 1825, require frequent inspections to ensure safe operation. Human inspection of culverts is challenging due to age, geometry, poor illumination, weather, and lack of easy access. We introduce VISION, an end-to-end, language-in-the-loop autonomy system that couples a web-scale vision-language model (VLM) with constrained viewpoint planning for autonomous inspection of culverts. Brief prompts to the VLM solicit open-vocabulary ROI proposals with rationales and confidences, stereo depth is fused to recover scale, and a planner -- aware of culvert constraints -- commands repositioning moves to capture targeted close-ups. Deployed on a quadruped in a culvert under the Erie Canal, VISION closes the see, decide, move, re-image loop on-board and produces high-resolution images for detailed reporting without domain-specific fine-tuning. In an external evaluation by New York Canal Corporation personnel, initial ROI proposals achieved 61.4\\% agreement with subject-matter experts, and final post-re-imaging assessments reached 80\\%, indicating that VISION converts tentative hypotheses into grounded, expert-aligned findings.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition",
        "date": "2025-09-22",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.730983"
    },
    {
        "index": "#189",
        "title": "Cross-Modal Retrieval with Cauchy-Schwarz Divergence",
        "link": "/arxiv/2509.21339",
        "arxiv_id": "2509.21339",
        "authors": "Jiahao Zhang, Wenzhe Yin, Shujian Yu",
        "summary": "Effective cross-modal retrieval requires robust alignment of heterogeneous data types. Most existing methods focus on bi-modal retrieval tasks and rely on distributional alignment techniques such as Kullback-Leibler divergence, Maximum Mean Discrepancy, and correlation alignment. However, these methods often suffer from critical limitations, including numerical instability, sensitivity to hyperparameters, and their inability to capture the full structure of the underlying distributions. In this paper, we introduce the Cauchy-Schwarz (CS) divergence, a hyperparameter-free measure that improves both training stability and retrieval performance. We further propose a novel Generalized CS (GCS) divergence inspired by Hölder's inequality. This extension enables direct alignment of three or more modalities within a unified mathematical framework through a bidirectional circular comparison scheme, eliminating the need for exhaustive pairwise comparisons. Extensive experiments on six benchmark datasets demonstrate the effectiveness of our method in both bi-modal and tri-modal retrieval tasks. The code of our CS/GCS divergence is publicly available at https://github.com/JiahaoZhang666/CSD.",
        "subjects": "Information Retrieval, Artificial Intelligence, Computer Vision and Pattern Recognition, Multimedia",
        "date": "2025-09-15",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.731531"
    },
    {
        "index": "#190",
        "title": "SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment",
        "link": "/arxiv/2509.20401",
        "arxiv_id": "2509.20401",
        "authors": "Binod Singh, Sayan Deb Sarkar, Iro Armeni",
        "summary": "Aligning 3D scene graphs is a crucial initial step for several applications in robot navigation and embodied perception. Current methods in 3D scene graph alignment often rely on single-modality point cloud data and struggle with incomplete or noisy input. We introduce SGAligner++, a cross-modal, language-aided framework for 3D scene graph alignment. Our method addresses the challenge of aligning partially overlapping scene observations across heterogeneous modalities by learning a unified joint embedding space, enabling accurate alignment even under low-overlap conditions and sensor noise. By employing lightweight unimodal encoders and attention-based fusion, SGAligner++ enhances scene understanding for tasks such as visual localization, 3D reconstruction, and navigation, while ensuring scalability and minimal computational overhead. Extensive evaluations on real-world datasets demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40% on noisy real-world reconstructions, while enabling cross-modal generalization.",
        "subjects": "Graphics, Robotics",
        "date": "2025-09-23",
        "category": "cs.CV",
        "crawl_time": "2025-10-06T22:42:02.732061"
    },
    {
        "index": "#2",
        "title": "WebGen-Agent: Enhancing Interactive Website Generation with Multi-Level Feedback and Step-Level Reinforcement Learning",
        "link": "/arxiv/2509.22644",
        "arxiv_id": "2509.22644",
        "authors": "Zimu Lu, Houxing Ren, Yunqiao Yang, Ke Wang, Zhuofan Zong, Junting Pan, Mingjie Zhan, Hongsheng Li",
        "summary": "Agent systems powered by large language models (LLMs) have demonstrated impressive performance on repository-level code-generation tasks. However, for tasks such as website codebase generation, which depend heavily on visual effects and user-interaction feedback, current code agents rely only on simple code execution for feedback and verification. This approach fails to capture the actual quality of the generated code. In this paper, we propose WebGen-Agent, a novel website-generation agent that leverages comprehensive and multi-level visual feedback to iteratively generate and refine the website codebase. Detailed and expressive text descriptions and suggestions regarding the screenshots and GUI-agent testing of the websites are generated by a visual language model (VLM), together with scores that quantify their quality. The screenshot and GUI-agent scores are further integrated with a backtracking and select-best mechanism, enhancing the performance of the agent. Utilizing the accurate visual scores inherent in the WebGen-Agent workflow, we further introduce \\textit{Step-GRPO with Screenshot and GUI-agent Feedback} to improve the ability of LLMs to act as the reasoning engine of WebGen-Agent. By using the screenshot and GUI-agent scores at each step as the reward in Step-GRPO, we provide a dense and reliable process supervision signal, which effectively improves the model's website-generation ability. On the WebGen-Bench dataset, WebGen-Agent increases the accuracy of Claude-3.5-Sonnet from 26.4% to 51.9% and its appearance score from 3.0 to 3.9, outperforming the previous state-of-the-art agent system. Additionally, our Step-GRPO training approach increases the accuracy of Qwen2.5-Coder-7B-Instruct from 38.9% to 45.4% and raises the appearance score from 3.4 to 3.7.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.554597"
    },
    {
        "index": "#3",
        "title": "Death of the Novel(ty): Beyond n-Gram Novelty as a Metric for Textual Creativity",
        "link": "/arxiv/2509.22641",
        "arxiv_id": "2509.22641",
        "authors": "Arkadiy Saakyan, Najoung Kim, Smaranda Muresan, Tuhin Chakrabarty",
        "summary": "N-gram novelty is widely used to evaluate language models' ability to generate text outside of their training data. More recently, it has also been adopted as a metric for measuring textual creativity. However, theoretical work on creativity suggests that this approach may be inadequate, as it does not account for creativity's dual nature: novelty (how original the text is) and appropriateness (how sensical and pragmatic it is). We investigate the relationship between this notion of creativity and n-gram novelty through 7542 expert writer annotations (n=26) of novelty, pragmaticality, and sensicality via close reading of human and AI-generated text. We find that while n-gram novelty is positively associated with expert writer-judged creativity, ~91% of top-quartile expressions by n-gram novelty are not judged as creative, cautioning against relying on n-gram novelty alone. Furthermore, unlike human-written text, higher n-gram novelty in open-source LLMs correlates with lower pragmaticality. In an exploratory study with frontier close-source models, we additionally confirm that they are less likely to produce creative expressions than humans. Using our dataset, we test whether zero-shot, few-shot, and finetuned models are able to identify creative expressions (a positive aspect of writing) and non-pragmatic ones (a negative aspect). Overall, frontier LLMs exhibit performance much higher than random but leave room for improvement, especially struggling to identify non-pragmatic expressions. We further find that LLM-as-a-Judge novelty scores from the best-performing model were predictive of expert writer preferences.",
        "subjects": "Computation and Language, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.555232"
    },
    {
        "index": "#4",
        "title": "Language Models Can Learn from Verbal Feedback Without Scalar Rewards",
        "link": "/arxiv/2509.22638",
        "arxiv_id": "2509.22638",
        "authors": "Renjie Luo, Zichen Liu, Xiangyan Liu, Chao Du, Min Lin, Wenhu Chen, Wei Lu, Tianyu Pang",
        "summary": "LLMs are often trained with RL from human or AI feedback, yet such methods typically compress nuanced feedback into scalar rewards, discarding much of their richness and inducing scale imbalance. We propose treating verbal feedback as a conditioning signal. Inspired by language priors in text-to-image generation, which enable novel outputs from unseen prompts, we introduce the feedback-conditional policy (FCP). FCP learns directly from response-feedback pairs, approximating the feedback-conditional posterior through maximum likelihood training on offline data. We further develop an online bootstrapping stage where the policy generates under positive conditions and receives fresh feedback to refine itself. This reframes feedback-driven learning as conditional generation rather than reward optimization, offering a more expressive way for LLMs to directly learn from verbal feedback. Our code is available at https://github.com/sail-sg/feedback-conditional-policy.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.555984"
    },
    {
        "index": "#5",
        "title": "Variational Reasoning for Language Models",
        "link": "/arxiv/2509.22637",
        "arxiv_id": "2509.22637",
        "authors": "Xiangxin Zhou, Zichen Liu, Haonan Wang, Chao Du, Min Lin, Chongxuan Li, Liang Wang, Tianyu Pang",
        "summary": "We introduce a variational reasoning framework for language models that treats thinking traces as latent variables and optimizes them through variational inference. Starting from the evidence lower bound (ELBO), we extend it to a multi-trace objective for tighter bounds and propose a forward-KL formulation that stabilizes the training of the variational posterior. We further show that rejection sampling finetuning and binary-reward RL, including GRPO, can be interpreted as local forward-KL objectives, where an implicit weighting by model accuracy naturally arises from the derivation and reveals a previously unnoticed bias toward easier questions. We empirically validate our method on the Qwen 2.5 and Qwen 3 model families across a wide range of reasoning tasks. Overall, our work provides a principled probabilistic perspective that unifies variational inference with RL-style methods and yields stable objectives for improving the reasoning ability of language models. Our code is available at https://github.com/sail-sg/variational-reasoning.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.556691"
    },
    {
        "index": "#6",
        "title": "StateX: Enhancing RNN Recall via Post-training State Expansion",
        "link": "/arxiv/2509.22630",
        "arxiv_id": "2509.22630",
        "authors": "Xingyu Shen, Yingfa Chen, Zhen Leng Thai, Xu Han, Zhiyuan Liu, Maosong Sun",
        "summary": "While Transformer-based models have demonstrated remarkable language modeling performance, their high complexities result in high costs when processing long contexts. In contrast, recurrent neural networks (RNNs) such as linear attention and state space models have gained popularity due to their constant per-token complexities. However, these recurrent models struggle with tasks that require accurate recall of contextual information from long contexts, because all contextual information is compressed into a constant-size recurrent state. Previous works have shown that recall ability is positively correlated with the recurrent state size, yet directly training RNNs with larger recurrent states results in high training costs. In this paper, we introduce StateX, a training pipeline for efficiently expanding the states of pre-trained RNNs through post-training. For two popular classes of RNNs, linear attention and state space models, we design post-training architectural modifications to scale up the state size with no or negligible increase in model parameters. Experiments on models up to 1.3B parameters demonstrate that StateX efficiently enhances the recall and in-context learning ability of RNNs without incurring high post-training costs or compromising other capabilities.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.557272"
    },
    {
        "index": "#7",
        "title": "From tests to effect sizes: Quantifying uncertainty and statistical variability in multilingual and multitask NLP evaluation benchmarks",
        "link": "/arxiv/2509.22612",
        "arxiv_id": "2509.22612",
        "authors": "Jonne Sälevä, Duygu Ataman, Constantine Lignos",
        "summary": "In this paper, we introduce a set of resampling-based methods for quantifying uncertainty and statistical precision of evaluation metrics in multilingual and/or multitask NLP benchmarks. We show how experimental variation in performance scores arises from both model- and data-related sources, and that accounting for both of them is necessary to avoid substantially underestimating the overall variability over hypothetical replications. Using multilingual question answering, machine translation, and named entity recognition as example tasks, we also demonstrate how resampling methods are useful for computing sampling distributions for various quantities used in leaderboards such as the average/median, pairwise differences between models, and rankings.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.557717"
    },
    {
        "index": "#8",
        "title": "Capturing Opinion Shifts in Deliberative Discourse through Frequency-based Quantum deep learning methods",
        "link": "/arxiv/2509.22603",
        "arxiv_id": "2509.22603",
        "authors": "Rakesh Thakur, Harsh Chaturvedi, Ruqayya Shah, Janvi Chauhan, Ayush Sharma",
        "summary": "Deliberation plays a crucial role in shaping outcomes by weighing diverse perspectives before reaching decisions. With recent advancements in Natural Language Processing, it has become possible to computationally model deliberation by analyzing opinion shifts and predicting potential outcomes under varying scenarios. In this study, we present a comparative analysis of multiple NLP techniques to evaluate how effectively models interpret deliberative discourse and produce meaningful insights. Opinions from individuals of varied backgrounds were collected to construct a self-sourced dataset that reflects diverse viewpoints. Deliberation was simulated using product presentations enriched with striking facts, which often prompted measurable shifts in audience opinions. We have given comparative analysis between two models namely Frequency-Based Discourse Modulation and Quantum-Deliberation Framework which outperform the existing state of art models. The findings highlight practical applications in public policy-making, debate evaluation, decision-support frameworks, and large-scale social media opinion mining.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.563350"
    },
    {
        "index": "#9",
        "title": "From Formal Language Theory to Statistical Learning: Finite Observability of Subregular Languages",
        "link": "/arxiv/2509.22598",
        "arxiv_id": "2509.22598",
        "authors": "Katsuhiko Hayashi, Hidetaka Kamigaito",
        "summary": "We prove that all standard subregular language classes are linearly separable when represented by their deciding predicates. This establishes finite observability and guarantees learnability with simple linear models. Synthetic experiments confirm perfect separability under noise-free conditions, while real-data experiments on English morphology show that learned features align with well-known linguistic constraints. These results demonstrate that the subregular hierarchy provides a rigorous and interpretable foundation for modeling natural language structure. Our code used in real-data experiments is available at https://github.com/UTokyo-HayashiLab/subregular.",
        "subjects": "Computation and Language, Formal Languages and Automata Theory, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.563865"
    },
    {
        "index": "#10",
        "title": "ArabJobs: A Multinational Corpus of Arabic Job Ads",
        "link": "/arxiv/2509.22589",
        "arxiv_id": "2509.22589",
        "authors": "Mo El-Haj",
        "summary": "ArabJobs is a publicly available corpus of Arabic job advertisements collected from Egypt, Jordan, Saudi Arabia, and the United Arab Emirates. Comprising over 8,500 postings and more than 550,000 words, the dataset captures linguistic, regional, and socio-economic variation in the Arab labour market. We present analyses of gender representation and occupational structure, and highlight dialectal variation across ads, which offers opportunities for future research. We also demonstrate applications such as salary estimation and job category normalisation using large language models, alongside benchmark tasks for gender bias detection and profession classification. The findings show the utility of ArabJobs for fairness-aware Arabic NLP and labour market research. The dataset is publicly available on GitHub: https://github.com/drelhaj/ArabJobs.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.564285"
    },
    {
        "index": "#11",
        "title": "Fine-Grained Detection of Context-Grounded Hallucinations Using LLMs",
        "link": "/arxiv/2509.22582",
        "arxiv_id": "2509.22582",
        "authors": "Yehonatan Pesiakhovsky, Zorik Gekhman, Yosi Mass, Liat Ein-Dor, Roi Reichart",
        "summary": "Context-grounded hallucinations are cases where model outputs contain information not verifiable against the source text. We study the applicability of LLMs for localizing such hallucinations, as a more practical alternative to existing complex evaluation pipelines. In the absence of established benchmarks for meta-evaluation of hallucinations localization, we construct one tailored to LLMs, involving a challenging human annotation of over 1,000 examples. We complement the benchmark with an LLM-based evaluation protocol, verifying its quality in a human evaluation. Since existing representations of hallucinations limit the types of errors that can be expressed, we propose a new representation based on free-form textual descriptions, capturing the full range of possible errors. We conduct a comprehensive study, evaluating four large-scale LLMs, which highlights the benchmark's difficulty, as the best model achieves an F1 score of only 0.67. Through careful analysis, we offer insights into optimal prompting strategies for the task and identify the main factors that make it challenging for LLMs: (1) a tendency to incorrectly flag missing details as inconsistent, despite being instructed to check only facts in the output; and (2) difficulty with outputs containing factually correct information absent from the source - and thus not verifiable - due to alignment with the model's parametric knowledge.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.564767"
    },
    {
        "index": "#12",
        "title": "Retrieval-Augmented Guardrails for AI-Drafted Patient-Portal Messages: Error Taxonomy Construction and Large-Scale Evaluation",
        "link": "/arxiv/2509.22565",
        "arxiv_id": "2509.22565",
        "authors": "Wenyuan Chen, Fateme Nateghi Haredasht, Kameron C. Black, Francois Grolleau, Emily Alsentzer, Jonathan H. Chen, Stephen P. Ma",
        "summary": "Asynchronous patient-clinician messaging via EHR portals is a growing source of clinician workload, prompting interest in large language models (LLMs) to assist with draft responses. However, LLM outputs may contain clinical inaccuracies, omissions, or tone mismatches, making robust evaluation essential. Our contributions are threefold: (1) we introduce a clinically grounded error ontology comprising 5 domains and 59 granular error codes, developed through inductive coding and expert adjudication; (2) we develop a retrieval-augmented evaluation pipeline (RAEC) that leverages semantically similar historical message-response pairs to improve judgment quality; and (3) we provide a two-stage prompting architecture using DSPy to enable scalable, interpretable, and hierarchical error detection. Our approach assesses the quality of drafts both in isolation and with reference to similar past message-response pairs retrieved from institutional archives. Using a two-stage DSPy pipeline, we compared baseline and reference-enhanced evaluations on over 1,500 patient messages. Retrieval context improved error identification in domains such as clinical completeness and workflow appropriateness. Human validation on 100 messages demonstrated superior agreement (concordance = 50% vs. 33%) and performance (F1 = 0.500 vs. 0.256) of context-enhanced labels vs. baseline, supporting the use of our RAEC pipeline as AI guardrails for patient messaging.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.565310"
    },
    {
        "index": "#13",
        "title": "Think Socially via Cognitive Reasoning",
        "link": "/arxiv/2509.22546",
        "arxiv_id": "2509.22546",
        "authors": "Jinfeng Zhou, Zheyu Chen, Shuai Wang, Quanyu Dai, Zhenhua Dong, Hongning Wang, Minlie Huang",
        "summary": "LLMs trained for logical reasoning excel at step-by-step deduction to reach verifiable answers. However, this paradigm is ill-suited for navigating social situations, which induce an interpretive process of analyzing ambiguous cues that rarely yield a definitive outcome. To bridge this gap, we introduce Cognitive Reasoning, a paradigm modeled on human social cognition. It formulates the interpretive process into a structured cognitive flow of interconnected cognitive units (e.g., observation or attribution), which combine adaptively to enable effective social thinking and responses. We then propose CogFlow, a complete framework that instills this capability in LLMs. CogFlow first curates a dataset of cognitive flows by simulating the associative and progressive nature of human thought via tree-structured planning. After instilling the basic cognitive reasoning capability via supervised fine-tuning, CogFlow adopts reinforcement learning to enable the model to improve itself via trial and error, guided by a multi-objective reward that optimizes both cognitive flow and response quality. Extensive experiments show that CogFlow effectively enhances the social cognitive capabilities of LLMs, and even humans, leading to more effective social decision-making.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.565814"
    },
    {
        "index": "#14",
        "title": "InfiR2: A Comprehensive FP8 Training Recipe for Reasoning-Enhanced Language Models",
        "link": "/arxiv/2509.22536",
        "arxiv_id": "2509.22536",
        "authors": "Wenjun Wang, Shuo Cai, Congkai Xie, Mingfa Feng, Yiming Zhang, Zhen Li, Kejing Yang, Ming Li, Jiannong Cao, Yuan Xie, Hongxia Yang",
        "summary": "The immense computational cost of training Large Language Models (LLMs) presents a major barrier to innovation. While FP8 training offers a promising solution with significant theoretical efficiency gains, its widespread adoption has been hindered by the lack of a comprehensive, open-source training recipe. To bridge this gap, we introduce an end-to-end FP8 training recipe that seamlessly integrates continual pre-training and supervised fine-tuning. Our methodology employs a fine-grained, hybrid-granularity quantization strategy to maintain numerical fidelity while maximizing computational efficiency. Through extensive experiments, including the continue pre-training of models on a 160B-token corpus, we demonstrate that our recipe is not only remarkably stable but also essentially lossless, achieving performance on par with the BF16 baseline across a suite of reasoning benchmarks. Crucially, this is achieved with substantial efficiency improvements, including up to a 22% reduction in training time, a 14% decrease in peak memory usage, and a 19% increase in throughput. Our results establish FP8 as a practical and robust alternative to BF16, and we will release the accompanying code to further democratize large-scale model training.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.566394"
    },
    {
        "index": "#15",
        "title": "We Think, Therefore We Align LLMs to Helpful, Harmless and Honest Before They Go Wrong",
        "link": "/arxiv/2509.22510",
        "arxiv_id": "2509.22510",
        "authors": "Gautam Siddharth Kashyap, Mark Dras, Usman Naseem",
        "summary": "Alignment of Large Language Models (LLMs) along multiple objectives-helpfulness, harmlessness, and honesty (HHH)-is critical for safe and reliable deployment. Prior work has used steering vector-small control signals injected into hidden states-to guide LLM outputs, typically via one-to-one (1-to-1) Transformer decoders. In this setting, optimizing a single alignment objective can inadvertently overwrite representations learned for other objectives, leading to catastrophic forgetting. More recent approaches extend steering vectors via one-to-many (1-to-N) Transformer decoders. While this alleviates catastrophic forgetting, naive multi-branch designs optimize each objective independently, which can cause inference fragmentation-outputs across HHH objectives may become inconsistent. We propose Adaptive Multi-Branch Steering (AMBS), a two-stage 1-to-N framework for unified and efficient multi-objective alignment. In Stage I, post-attention hidden states of the Transformer layer are computed once to form a shared representation. In Stage II, this representation is cloned into parallel branches and steered via a policy-reference mechanism, enabling objective-specific control while maintaining cross-objective consistency. Empirical evaluations on Alpaca, BeaverTails, and TruthfulQA show that AMBS consistently improves HHH alignment across multiple 7B LLM backbones. For example, on DeepSeek-7B, AMBS improves average alignment scores by +32.4% and reduces unsafe outputs by 11.0% compared to a naive 1-to-N baseline, while remaining competitive with state-of-the-art methods.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.566843"
    },
    {
        "index": "#16",
        "title": "Representing LLMs in Prompt Semantic Task Space",
        "link": "/arxiv/2509.22506",
        "arxiv_id": "2509.22506",
        "authors": "Idan Kashani, Avi Mendelson, Yaniv Nemcovsky",
        "summary": "Large language models (LLMs) achieve impressive results over various tasks, and ever-expanding public repositories contain an abundance of pre-trained models. Therefore, identifying the best-performing LLM for a given task is a significant challenge. Previous works have suggested learning LLM representations to address this. However, these approaches present limited scalability and require costly retraining to encompass additional models and datasets. Moreover, the produced representation utilizes distinct spaces that cannot be easily interpreted. This work presents an efficient, training-free approach to representing LLMs as linear operators within the prompts' semantic task space, thus providing a highly interpretable representation of the models' application. Our method utilizes closed-form computation of geometrical properties and ensures exceptional scalability and real-time adaptability to dynamically expanding repositories. We demonstrate our approach on success prediction and model selection tasks, achieving competitive or state-of-the-art results with notable performance in out-of-sample scenarios.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.567306"
    },
    {
        "index": "#17",
        "title": "JGU Mainz's Submission to the WMT25 Shared Task on LLMs with Limited Resources for Slavic Languages: MT and QA",
        "link": "/arxiv/2509.22490",
        "arxiv_id": "2509.22490",
        "authors": "Hossain Shaikh Saadi, Minh Duc Bui, Mario Sanz-Guerrero, Katharina von der Wense",
        "summary": "This paper presents the JGU Mainz submission to the WMT25 Shared Task on LLMs with Limited Resources for Slavic Languages: Machine Translation and Question Answering, focusing on Ukrainian, Upper Sorbian, and Lower Sorbian. For each language, we jointly fine-tune a Qwen2.5-3B-Instruct model for both tasks with parameter-efficient finetuning. Our pipeline integrates additional translation and multiple-choice question answering (QA) data. For Ukrainian QA, we further use retrieval-augmented generation. We also apply ensembling for QA in Upper and Lower Sorbian. Experiments show that our models outperform the baseline on both tasks.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.567777"
    },
    {
        "index": "#18",
        "title": "Exploring Solution Divergence and Its Effect on Large Language Model Problem Solving",
        "link": "/arxiv/2509.22480",
        "arxiv_id": "2509.22480",
        "authors": "Hang Li, Kaiqi Yang, Yucheng Chu, Hui Liu, Jiliang Tang",
        "summary": "Large language models (LLMs) have been widely used for problem-solving tasks. Most recent work improves their performance through supervised fine-tuning (SFT) with labeled data or reinforcement learning (RL) from task feedback. In this paper, we study a new perspective: the divergence in solutions generated by LLMs for a single problem. We show that higher solution divergence is positively related to better problem-solving abilities across various models. Based on this finding, we propose solution divergence as a novel metric that can support both SFT and RL strategies. We test this idea on three representative problem domains and find that using solution divergence consistently improves success rates. These results suggest that solution divergence is a simple but effective tool for advancing LLM training and evaluation.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.683823"
    },
    {
        "index": "#19",
        "title": "NeLLCom-Lex: A Neural-agent Framework to Study the Interplay between Lexical Systems and Language Use",
        "link": "/arxiv/2509.22479",
        "arxiv_id": "2509.22479",
        "authors": "Yuqing Zhang, Ecesu Ürker, Tessa Verhoef, Gemma Boleda, Arianna Bisazza",
        "summary": "Lexical semantic change has primarily been investigated with observational and experimental methods; however, observational methods (corpus analysis, distributional semantic modeling) cannot get at causal mechanisms, and experimental paradigms with humans are hard to apply to semantic change due to the extended diachronic processes involved. This work introduces NeLLCom-Lex, a neural-agent framework designed to simulate semantic change by first grounding agents in a real lexical system (e.g. English) and then systematically manipulating their communicative needs. Using a well-established color naming task, we simulate the evolution of a lexical system within a single generation, and study which factors lead agents to: (i) develop human-like naming behavior and lexicons, and (ii) change their behavior and lexicons according to their communicative needs. Our experiments with different supervised and reinforcement learning pipelines show that neural agents trained to 'speak' an existing language can reproduce human-like patterns in color naming to a remarkable extent, supporting the further use of NeLLCom-Lex to elucidate the mechanisms of semantic change.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.689931"
    },
    {
        "index": "#20",
        "title": "Evaluating the Limits of Large Language Models in Multilingual Legal Reasoning",
        "link": "/arxiv/2509.22472",
        "arxiv_id": "2509.22472",
        "authors": "Antreas Ioannou, Andreas Shiamishis, Nora Hollenstein, Nezihe Merve Gürel",
        "summary": "In an era dominated by Large Language Models (LLMs), understanding their capabilities and limitations, especially in high-stakes fields like law, is crucial. While LLMs such as Meta's LLaMA, OpenAI's ChatGPT, Google's Gemini, DeepSeek, and other emerging models are increasingly integrated into legal workflows, their performance in multilingual, jurisdictionally diverse, and adversarial contexts remains insufficiently explored. This work evaluates LLaMA and Gemini on multilingual legal and non-legal benchmarks, and assesses their adversarial robustness in legal tasks through character and word-level perturbations. We use an LLM-as-a-Judge approach for human-aligned evaluation. We moreover present an open-source, modular evaluation pipeline designed to support multilingual, task-diverse benchmarking of any combination of LLMs and datasets, with a particular focus on legal tasks, including classification, summarization, open questions, and general reasoning. Our findings confirm that legal tasks pose significant challenges for LLMs with accuracies often below 50% on legal reasoning benchmarks such as LEXam, compared to over 70% on general-purpose tasks like XNLI. In addition, while English generally yields more stable results, it does not always lead to higher accuracy. Prompt sensitivity and adversarial vulnerability is also shown to persist across languages. Finally, a correlation is found between the performance of a language and its syntactic similarity to English. We also observe that LLaMA is weaker than Gemini, with the latter showing an average advantage of about 24 percentage points across the same task. Despite improvements in newer LLMs, challenges remain in deploying them reliably for critical, multilingual legal applications.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.690614"
    },
    {
        "index": "#21",
        "title": "Detecting (Un)answerability in Large Language Models with Linear Directions",
        "link": "/arxiv/2509.22449",
        "arxiv_id": "2509.22449",
        "authors": "Maor Juliet Lavi, Tova Milo, Mor Geva",
        "summary": "Large language models (LLMs) often respond confidently to questions even when they lack the necessary information, leading to hallucinated answers. In this work, we study the problem of (un)answerability detection, focusing on extractive question answering (QA) where the model should determine if a passage contains sufficient information to answer a given question. We propose a simple approach for identifying a direction in the model's activation space that captures unanswerability and uses it for classification. This direction is selected by applying activation additions during inference and measuring their impact on the model's abstention behavior. We show that projecting hidden activations onto this direction yields a reliable score for (un)answerability classification. Experiments on two open-weight LLMs and four extractive QA benchmarks show that our method effectively detects unanswerable questions and generalizes better across datasets than existing prompt-based and classifier-based approaches. Moreover, the obtained directions extend beyond extractive QA to unanswerability that stems from factors, such as lack of scientific consensus and subjectivity. Last, causal interventions show that adding or ablating the directions effectively controls the abstention behavior of the model.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.691206"
    },
    {
        "index": "#22",
        "title": "Chimera: Diagnosing Shortcut Learning in Visual-Language Understanding",
        "link": "/arxiv/2509.22437",
        "arxiv_id": "2509.22437",
        "authors": "Ziheng Chi, Yifan Hou, Chenxi Pang, Shaobo Cui, Mubashara Akhtar, Mrinmaya Sachan",
        "summary": "Diagrams convey symbolic information in a visual format rather than a linear stream of words, making them especially challenging for AI models to process. While recent evaluations suggest that vision-language models (VLMs) perform well on diagram-related benchmarks, their reliance on knowledge, reasoning, or modality shortcuts raises concerns about whether they genuinely understand and reason over diagrams. To address this gap, we introduce Chimera, a comprehensive test suite comprising 7,500 high-quality diagrams sourced from Wikipedia; each diagram is annotated with its symbolic content represented by semantic triples along with multi-level questions designed to assess four fundamental aspects of diagram comprehension: entity recognition, relation understanding, knowledge grounding, and visual reasoning. We use Chimera to measure the presence of three types of shortcuts in visual question answering: (1) the visual-memorization shortcut, where VLMs rely on memorized visual patterns; (2) the knowledge-recall shortcut, where models leverage memorized factual knowledge instead of interpreting the diagram; and (3) the Clever-Hans shortcut, where models exploit superficial language patterns or priors without true comprehension. We evaluate 15 open-source VLMs from 7 model families on Chimera and find that their seemingly strong performance largely stems from shortcut behaviors: visual-memorization shortcuts have slight impact, knowledge-recall shortcuts play a moderate role, and Clever-Hans shortcuts contribute significantly. These findings expose critical limitations in current VLMs and underscore the need for more robust evaluation protocols that benchmark genuine comprehension of complex visual inputs (e.g., diagrams) rather than question-answering shortcuts.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.691911"
    },
    {
        "index": "#23",
        "title": "What Is The Political Content in LLMs' Pre- and Post-Training Data?",
        "link": "/arxiv/2509.22367",
        "arxiv_id": "2509.22367",
        "authors": "Tanise Ceron, Dmitry Nikolaev, Dominik Stammbach, Debora Nozza",
        "summary": "Large language models (LLMs) are known to generate politically biased text, yet how such biases arise remains unclear. A crucial step toward answering this question is the analysis of training data, whose political content remains largely underexplored in current LLM research. To address this gap, we present in this paper an analysis of the pre- and post-training corpora of OLMO2, the largest fully open-source model released together with its complete dataset. From these corpora, we draw large random samples, automatically annotate documents for political orientation, and analyze their source domains and content. We then assess how political content in the training data correlates with models' stance on specific policy issues. Our analysis shows that left-leaning documents predominate across datasets, with pre-training corpora containing significantly more politically engaged content than post-training data. We also find that left- and right-leaning documents frame similar topics through distinct values and sources of legitimacy. Finally, the predominant stance in the training data strongly correlates with models' political biases when evaluated on policy issues. These findings underscore the need to integrate political content analysis into future data curation pipelines as well as in-depth documentation of filtering strategies for transparency.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.692562"
    },
    {
        "index": "#24",
        "title": "Exploratory Semantic Reliability Analysis of Wind Turbine Maintenance Logs using Large Language Models",
        "link": "/arxiv/2509.22366",
        "arxiv_id": "2509.22366",
        "authors": "Max Malyi, Jonathan Shek, Andre Biscaya",
        "summary": "A wealth of operational intelligence is locked within the unstructured free-text of wind turbine maintenance logs, a resource largely inaccessible to traditional quantitative reliability analysis. While machine learning has been applied to this data, existing approaches typically stop at classification, categorising text into predefined labels. This paper addresses the gap in leveraging modern large language models (LLMs) for more complex reasoning tasks. We introduce an exploratory framework that uses LLMs to move beyond classification and perform deep semantic analysis. We apply this framework to a large industrial dataset to execute four analytical workflows: failure mode identification, causal chain inference, comparative site analysis, and data quality auditing. The results demonstrate that LLMs can function as powerful \"reliability co-pilots,\" moving beyond labelling to synthesise textual information and generate actionable, expert-level hypotheses. This work contributes a novel and reproducible methodology for using LLMs as a reasoning tool, offering a new pathway to enhance operational intelligence in the wind energy sector by unlocking insights previously obscured in unstructured data.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.693150"
    },
    {
        "index": "#25",
        "title": "CHRONOBERG: Capturing Language Evolution and Temporal Awareness in Foundation Models",
        "link": "/arxiv/2509.22360",
        "arxiv_id": "2509.22360",
        "authors": "Niharika Hegde, Subarnaduti Paul, Lars Joel-Frey, Manuel Brack, Kristian Kersting, Martin Mundt, Patrick Schramowski",
        "summary": "Large language models (LLMs) excel at operating at scale by leveraging social media and various data crawled from the web. Whereas existing corpora are diverse, their frequent lack of long-term temporal structure may however limit an LLM's ability to contextualize semantic and normative evolution of language and to capture diachronic variation. To support analysis and training for the latter, we introduce CHRONOBERG, a temporally structured corpus of English book texts spanning 250 years, curated from Project Gutenberg and enriched with a variety of temporal annotations. First, the edited nature of books enables us to quantify lexical semantic change through time-sensitive Valence-Arousal-Dominance (VAD) analysis and to construct historically calibrated affective lexicons to support temporally grounded interpretation. With the lexicons at hand, we demonstrate a need for modern LLM-based tools to better situate their detection of discriminatory language and contextualization of sentiment across various time-periods. In fact, we show how language models trained sequentially on CHRONOBERG struggle to encode diachronic shifts in meaning, emphasizing the need for temporally aware training and evaluation pipelines, and positioning CHRONOBERG as a scalable resource for the study of linguistic change and temporal generalization. Disclaimer: This paper includes language and display of samples that could be offensive to readers. Open Access: Chronoberg is available publicly on HuggingFace at ( https://huggingface.co/datasets/spaul25/Chronoberg). Code is available at (https://github.com/paulsubarna/Chronoberg).",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.693850"
    },
    {
        "index": "#26",
        "title": "Conversational Implicatures: Modelling Relevance Theory Probabilistically",
        "link": "/arxiv/2509.22354",
        "arxiv_id": "2509.22354",
        "authors": "Christoph Unger, Hendrik Buschmeier",
        "summary": "Recent advances in Bayesian probability theory and its application to cognitive science in combination with the development of a new generation of computational tools and methods for probabilistic computation have led to a 'probabilistic turn' in pragmatics and semantics. In particular, the framework of Rational Speech Act theory has been developed to model broadly Gricean accounts of pragmatic phenomena in Bayesian terms, starting with fairly simple reference games and covering ever more complex communicative exchanges such as verbal syllogistic reasoning. This paper explores in which way a similar Bayesian approach might be applied to relevance-theoretic pragmatics (Sperber & Wilson, 1995) by study a paradigmatic pragmatic phenomenon: the communication of implicit meaning by ways of (conversational) implicatures.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.699671"
    },
    {
        "index": "#27",
        "title": "The InviTE Corpus: Annotating Invectives in Tudor English Texts for Computational Modeling",
        "link": "/arxiv/2509.22345",
        "arxiv_id": "2509.22345",
        "authors": "Sophie Spliethoff, Sanne Hoeken, Silke Schwandt, Sina Zarrieß, Özge Alaçam",
        "summary": "In this paper, we aim at the application of Natural Language Processing (NLP) techniques to historical research endeavors, particularly addressing the study of religious invectives in the context of the Protestant Reformation in Tudor England. We outline a workflow spanning from raw data, through pre-processing and data selection, to an iterative annotation process. As a result, we introduce the InviTE corpus -- a corpus of almost 2000 Early Modern English (EModE) sentences, which are enriched with expert annotations regarding invective language throughout 16th-century England. Subsequently, we assess and compare the performance of fine-tuned BERT-based models and zero-shot prompted instruction-tuned large language models (LLMs), which highlights the superiority of models pre-trained on historical data and fine-tuned to invective detection.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.700238"
    },
    {
        "index": "#28",
        "title": "Transformers Can Learn Connectivity in Some Graphs but Not Others",
        "link": "/arxiv/2509.22343",
        "arxiv_id": "2509.22343",
        "authors": "Amit Roy, Abulhair Saparov",
        "summary": "Reasoning capability is essential to ensure the factual correctness of the responses of transformer-based Large Language Models (LLMs), and robust reasoning about transitive relations is instrumental in many settings, such as causal inference. Hence, it is essential to investigate the capability of transformers in the task of inferring transitive relations (e.g., knowing A causes B and B causes C, then A causes C). The task of inferring transitive relations is equivalent to the task of connectivity in directed graphs (e.g., knowing there is a path from A to B, and there is a path from B to C, then there is a path from A to C). Past research focused on whether transformers can learn to infer transitivity from in-context examples provided in the input prompt. However, transformers' capability to infer transitive relations from training examples and how scaling affects the ability is unexplored. In this study, we seek to answer this question by generating directed graphs to train transformer models of varying sizes and evaluate their ability to infer transitive relations for various graph sizes. Our findings suggest that transformers are capable of learning connectivity on \"grid-like'' directed graphs where each node can be embedded in a low-dimensional subspace, and connectivity is easily inferable from the embeddings of the nodes. We find that the dimensionality of the underlying grid graph is a strong predictor of transformers' ability to learn the connectivity task, where higher-dimensional grid graphs pose a greater challenge than low-dimensional grid graphs. In addition, we observe that increasing the model scale leads to increasingly better generalization to infer connectivity over grid graphs. However, if the graph is not a grid graph and contains many disconnected components, transformers struggle to learn the connectivity task, especially when the number of components is large.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Logic in Computer Science",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.700767"
    },
    {
        "index": "#29",
        "title": "Advancing Natural Language Formalization to First Order Logic with Fine-tuned LLMs",
        "link": "/arxiv/2509.22338",
        "arxiv_id": "2509.22338",
        "authors": "Felix Vossel, Till Mossakowski, Björn Gehrke",
        "summary": "Automating the translation of natural language to first-order logic (FOL) is crucial for knowledge representation and formal methods, yet remains challenging. We present a systematic evaluation of fine-tuned LLMs for this task, comparing architectures (encoder-decoder vs. decoder-only) and training strategies. Using the MALLS and Willow datasets, we explore techniques like vocabulary extension, predicate conditioning, and multilingual training, introducing metrics for exact match, logical equivalence, and predicate alignment. Our fine-tuned Flan-T5-XXL achieves 70% accuracy with predicate lists, outperforming GPT-4o and even the DeepSeek-R1-0528 model with CoT reasoning ability as well as symbolic systems like ccg2lambda. Key findings show: (1) predicate availability boosts performance by 15-20%, (2) T5 models surpass larger decoder-only LLMs, and (3) models generalize to unseen logical arguments (FOLIO dataset) without specific training. While structural logic translation proves robust, predicate extraction emerges as the main bottleneck.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.701251"
    },
    {
        "index": "#30",
        "title": "Bridging Fairness and Explainability: Can Input-Based Explanations Promote Fairness in Hate Speech Detection?",
        "link": "/arxiv/2509.22291",
        "arxiv_id": "2509.22291",
        "authors": "Yifan Wang, Mayank Jobanputra, Ji-Ung Lee, Soyoung Oh, Isabel Valera, Vera Demberg",
        "summary": "Natural language processing (NLP) models often replicate or amplify social bias from training data, raising concerns about fairness. At the same time, their black-box nature makes it difficult for users to recognize biased predictions and for developers to effectively mitigate them. While some studies suggest that input-based explanations can help detect and mitigate bias, others question their reliability in ensuring fairness. Existing research on explainability in fair NLP has been predominantly qualitative, with limited large-scale quantitative analysis. In this work, we conduct the first systematic study of the relationship between explainability and fairness in hate speech detection, focusing on both encoder- and decoder-only models. We examine three key dimensions: (1) identifying biased predictions, (2) selecting fair models, and (3) mitigating bias during model training. Our findings show that input-based explanations can effectively detect biased predictions and serve as useful supervision for reducing bias during training, but they are unreliable for selecting fair models among candidates.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.701782"
    },
    {
        "index": "#31",
        "title": "Beyond Textual Context: Structural Graph Encoding with Adaptive Space Alignment to alleviate the hallucination of LLMs",
        "link": "/arxiv/2509.22251",
        "arxiv_id": "2509.22251",
        "authors": "Yifang Zhang, Pengfei Duan, Yiwen Yang, Shengwu Xiong",
        "summary": "Currently, the main approach for Large Language Models (LLMs) to tackle the hallucination issue is incorporating Knowledge Graphs(KGs).However, LLMs typically treat KGs as plain text, extracting only semantic information and limiting their use of the crucial structural aspects of KGs. Another challenge is the gap between the embedding spaces of KGs encoders and LLMs text embeddings, which hinders the effective integration of structured knowledge. To overcome these obstacles, we put forward the SSKG-LLM, an innovative model architecture that is designed to efficiently integrate both the Structural and Semantic information of KGs into the reasoning processes of LLMs. SSKG-LLM incorporates the Knowledge Graph Retrieval (KGR) module and the Knowledge Graph Encoding (KGE) module to preserve semantics while utilizing structure. Then, the Knowledge Graph Adaptation (KGA) module is incorporated to enable LLMs to understand KGs embeddings. We conduct extensive experiments and provide a detailed analysis to explore how incorporating the structural information of KGs can enhance the factual reasoning abilities of LLMs. Our code are available at https://github.com/yfangZhang/SSKG-LLM.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.702296"
    },
    {
        "index": "#32",
        "title": "Safety Compliance: Rethinking LLM Safety Reasoning through the Lens of Compliance",
        "link": "/arxiv/2509.22250",
        "arxiv_id": "2509.22250",
        "authors": "Wenbin Hu, Huihao Jing, Haochen Shi, Haoran Li, Yangqiu Song",
        "summary": "The proliferation of Large Language Models (LLMs) has demonstrated remarkable capabilities, elevating the critical importance of LLM safety. However, existing safety methods rely on ad-hoc taxonomy and lack a rigorous, systematic protection, failing to ensure safety for the nuanced and complex behaviors of modern LLM systems. To address this problem, we solve LLM safety from legal compliance perspectives, named safety compliance. In this work, we posit relevant established legal frameworks as safety standards for defining and measuring safety compliance, including the EU AI Act and GDPR, which serve as core legal frameworks for AI safety and data security in Europe. To bridge the gap between LLM safety and legal compliance, we first develop a new benchmark for safety compliance by generating realistic LLM safety scenarios seeded with legal statutes. Subsequently, we align Qwen3-8B using Group Policy Optimization (GRPO) to construct a safety reasoner, Compliance Reasoner, which effectively aligns LLMs with legal standards to mitigate safety risks. Our comprehensive experiments demonstrate that the Compliance Reasoner achieves superior performance on the new benchmark, with average improvements of +10.45% for the EU AI Act and +11.85% for GDPR.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.702825"
    },
    {
        "index": "#33",
        "title": "FLEXI: Benchmarking Full-duplex Human-LLM Speech Interaction",
        "link": "/arxiv/2509.22243",
        "arxiv_id": "2509.22243",
        "authors": "Yuan Ge, Saihan Chen, Jingqi Xiao, Xiaoqian Liu, Tong Xiao, Yan Xiang, Zhengtao Yu, Jingbo Zhu",
        "summary": "Full-Duplex Speech-to-Speech Large Language Models (LLMs) are foundational to natural human-computer interaction, enabling real-time spoken dialogue systems. However, benchmarking and modeling these models remains a fundamental challenge. We introduce FLEXI, the first benchmark for full-duplex LLM-human spoken interaction that explicitly incorporates model interruption in emergency scenarios. FLEXI systematically evaluates the latency, quality, and conversational effectiveness of real-time dialogue through six diverse human-LLM interaction scenarios, revealing significant gaps between open source and commercial models in emergency awareness, turn terminating, and interaction latency. Finally, we suggest that next token-pair prediction offers a promising path toward achieving truly seamless and human-like full-duplex interaction.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.703366"
    },
    {
        "index": "#34",
        "title": "FeatBench: Evaluating Coding Agents on Feature Implementation for Vibe Coding",
        "link": "/arxiv/2509.22237",
        "arxiv_id": "2509.22237",
        "authors": "Haorui Chen, Chengze Li, Jia Li",
        "summary": "The rapid advancement of Large Language Models (LLMs) has given rise to a novel software development paradigm known as \"vibe coding,\" where users interact with coding agents through high-level natural language. However, existing evaluation benchmarks for code generation inadequately assess an agent's vibe coding capabilities. Existing benchmarks are misaligned, as they either require code-level specifications or focus narrowly on issue-solving, neglecting the critical scenario of feature implementation within the vibe coding paradiam. To address this gap, we propose FeatBench, a novel benchmark for vibe coding that focuses on feature implementation. Our benchmark is distinguished by several key features: 1. Pure Natural Language Prompts. Task inputs consist solely of abstract natural language descriptions, devoid of any code or structural hints. 2. A Rigorous & Evolving Data Collection Process. FeatBench is built on a multi-level filtering pipeline to ensure quality and a fully automated pipeline to evolve the benchmark, mitigating data contamination. 3. Comprehensive Test Cases. Each task includes Fail-to-Pass (F2P) and Pass-to-Pass (P2P) tests to verify correctness and prevent regressions. 4. Diverse Application Domains. The benchmark includes repositories from diverse domains to ensure it reflects real-world scenarios. We evaluate two state-of-the-art agent frameworks with four leading LLMs on FeatBench. Our evaluation reveals that feature implementation within the vibe coding paradigm is a significant challenge, with the highest success rate of only 29.94%. Our analysis also reveals a tendency for \"aggressive implementation,\" a strategy that paradoxically leads to both critical failures and superior software design. We release FeatBench, our automated collection pipeline, and all experimental results to facilitate further community research.",
        "subjects": "Computation and Language, Artificial Intelligence, Software Engineering",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.703901"
    },
    {
        "index": "#35",
        "title": "In Their Own Words: Reasoning Traces Tailored for Small Models Make Them Better Reasoners",
        "link": "/arxiv/2509.22230",
        "arxiv_id": "2509.22230",
        "authors": "Jaehoon Kim, Kwangwook Seo, Dongha Lee",
        "summary": "Transferring reasoning capabilities from larger language models to smaller ones through supervised fine-tuning often fails counterintuitively, with performance degrading despite access to high-quality teacher demonstrations. We identify that this failure stems from distributional misalignment: reasoning traces from larger models contain tokens that are low probability under the student's distribution, exceeding the internal representation capacity of smaller architectures and creating learning barriers rather than helpful guidance. We propose Reverse Speculative Decoding (RSD), a mechanism for generating student-friendly reasoning traces in which the teacher model proposes candidate tokens but the student model determines acceptance based on its own probability distributions, filtering low probability tokens. When applied to Qwen3-0.6B, direct distillation of s1K-1.1 reasoning trace data degrades average performance across major reasoning benchmarks by 20.5\\%, while the same model trained on RSD-generated reasoning traces achieves meaningful improvements of 4.9\\%. Our analysis reveals that low probability tokens constitute the critical bottleneck in reasoning ability transfer. However, cross-model experiments demonstrate that RSD traces are model-specific rather than universally applicable, indicating that distributional alignment must be tailored for each student architecture's unique internal representation.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.704369"
    },
    {
        "index": "#36",
        "title": "Thinking in Many Modes: How Composite Reasoning Elevates Large Language Model Performance with Limited Data",
        "link": "/arxiv/2509.22224",
        "arxiv_id": "2509.22224",
        "authors": "Zishan Ahmad, Saisubramaniam Gopalakrishnan",
        "summary": "Large Language Models (LLMs), despite their remarkable capabilities, rely on singular, pre-dominant reasoning paradigms, hindering their performance on intricate problems that demand diverse cognitive strategies. To address this, we introduce Composite Reasoning (CR), a novel reasoning approach empowering LLMs to dynamically explore and combine multiple reasoning styles like deductive, inductive, and abductive for more nuanced problem-solving. Evaluated on scientific and medical question-answering benchmarks, our approach outperforms existing baselines like Chain-of-Thought (CoT) and also surpasses the accuracy of DeepSeek-R1 style reasoning (SR) capabilities, while demonstrating superior sample efficiency and adequate token usage. Notably, CR adaptively emphasizes domain-appropriate reasoning styles. It prioritizes abductive and deductive reasoning for medical question answering, but shifts to causal, deductive, and inductive methods for scientific reasoning. Our findings highlight that by cultivating internal reasoning style diversity, LLMs acquire more robust, adaptive, and efficient problem-solving abilities.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.710000"
    },
    {
        "index": "#37",
        "title": "StableToken: A Noise-Robust Semantic Speech Tokenizer for Resilient SpeechLLMs",
        "link": "/arxiv/2509.22220",
        "arxiv_id": "2509.22220",
        "authors": "Yuhan Song, Linhao Zhang, Chuhan Wu, Aiwei Liu, Wei Jia, Houfeng Wang, Xiao Zhou",
        "summary": "Prevalent semantic speech tokenizers, designed to capture linguistic content, are surprisingly fragile. We find they are not robust to meaning-irrelevant acoustic perturbations; even at high Signal-to-Noise Ratios (SNRs) where speech is perfectly intelligible, their output token sequences can change drastically, increasing the learning burden for downstream LLMs. This instability stems from two flaws: a brittle single-path quantization architecture and a distant training signal indifferent to intermediate token stability. To address this, we introduce StableToken, a tokenizer that achieves stability through a consensus-driven mechanism. Its multi-branch architecture processes audio in parallel, and these representations are merged via a powerful bit-wise voting mechanism to form a single, stable token sequence. StableToken sets a new state-of-the-art in token stability, drastically reducing Unit Edit Distance (UED) under diverse noise conditions. This foundational stability translates directly to downstream benefits, significantly improving the robustness of SpeechLLMs on a variety of tasks.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.710518"
    },
    {
        "index": "#38",
        "title": "Question-Driven Analysis and Synthesis: Building Interpretable Thematic Trees with LLMs for Text Clustering and Controllable Generation",
        "link": "/arxiv/2509.22211",
        "arxiv_id": "2509.22211",
        "authors": "Tiago Fernandes Tavares",
        "summary": "Unsupervised analysis of text corpora is challenging, especially in data-scarce domains where traditional topic models struggle. While these models offer a solution, they typically describe clusters with lists of keywords that require significant manual effort to interpret and often lack semantic coherence. To address this critical interpretability gap, we introduce Recursive Thematic Partitioning (RTP), a novel framework that leverages Large Language Models (LLMs) to interactively build a binary tree. Each node in the tree is a natural language question that semantically partitions the data, resulting in a fully interpretable taxonomy where the logic of each cluster is explicit. Our experiments demonstrate that RTP's question-driven hierarchy is more interpretable than the keyword-based topics from a strong baseline like BERTopic. Furthermore, we establish the quantitative utility of these clusters by showing they serve as powerful features in downstream classification tasks, particularly when the data's underlying themes correlate with the task labels. RTP introduces a new paradigm for data exploration, shifting the focus from statistical pattern discovery to knowledge-driven thematic analysis. Furthermore, we demonstrate that the thematic paths from the RTP tree can serve as structured, controllable prompts for generative models. This transforms our analytical framework into a powerful tool for synthesis, enabling the consistent imitation of specific characteristics discovered in the source corpus.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.710972"
    },
    {
        "index": "#39",
        "title": "The Outputs of Large Language Models are Meaningless",
        "link": "/arxiv/2509.22206",
        "arxiv_id": "2509.22206",
        "authors": "Anandi Hattiangadi, Anders J. Schoubye",
        "summary": "In this paper, we offer a simple argument for the conclusion that the outputs of large language models (LLMs) are meaningless. Our argument is based on two key premises: (a) that certain kinds of intentions are needed in order for LLMs' outputs to have literal meanings, and (b) that LLMs cannot plausibly have the right kinds of intentions. We defend this argument from various types of responses, for example, the semantic externalist argument that deference can be assumed to take the place of intentions and the semantic internalist argument that meanings can be defined purely in terms of intrinsic relations between concepts, such as conceptual roles. We conclude the paper by discussing why, even if our argument is sound, the outputs of LLMs nevertheless seem meaningful and can be used to acquire true beliefs and even knowledge.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.711458"
    },
    {
        "index": "#40",
        "title": "When Does Reasoning Matter? A Controlled Study of Reasoning's Contribution to Model Performance",
        "link": "/arxiv/2509.22193",
        "arxiv_id": "2509.22193",
        "authors": "Nicolas Boizard, Hippolyte Gisserot-Boukhlef, Kevin El-Haddad, Céline Hudelot, Pierre Colombo",
        "summary": "Large Language Models (LLMs) with reasoning capabilities have achieved state-of-the-art performance on a wide range of tasks. Despite its empirical success, the tasks and model scales at which reasoning becomes effective, as well as its training and inference costs, remain underexplored. In this work, we rely on a synthetic data distillation framework to conduct a large-scale supervised study. We compare Instruction Fine-Tuning (IFT) and reasoning models of varying sizes, on a wide range of math-centric and general-purpose tasks, evaluating both multiple-choice and open-ended formats. Our analysis reveals that reasoning consistently improves model performance, often matching or surpassing significantly larger IFT systems. Notably, while IFT remains Pareto-optimal in training and inference costs, reasoning models become increasingly valuable as model size scales, overcoming IFT performance limits on reasoning-intensive and open-ended tasks.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.711974"
    },
    {
        "index": "#41",
        "title": "Context Parametrization with Compositional Adapters",
        "link": "/arxiv/2509.22158",
        "arxiv_id": "2509.22158",
        "authors": "Josip Jukić, Martin Tutek, Jan Šnajder",
        "summary": "Large language models (LLMs) often seamlessly adapt to new tasks through in-context learning (ICL) or supervised fine-tuning (SFT). However, both of these approaches face key limitations: ICL is inefficient when handling many demonstrations, and SFT incurs training overhead while sacrificing flexibility. Mapping instructions or demonstrations from context directly into adapter parameters offers an appealing alternative. While prior work explored generating adapters based on a single input context, it has overlooked the need to integrate multiple chunks of information. To address this gap, we introduce CompAs, a meta-learning framework that translates context into adapter parameters with a compositional structure. Adapters generated this way can be merged algebraically, enabling instructions, demonstrations, or retrieved passages to be seamlessly combined without reprocessing long prompts. Critically, this approach yields three benefits: lower inference cost, robustness to long-context instability, and establishes a principled solution when input exceeds the model's context window. Furthermore, CompAs encodes information into adapter parameters in a reversible manner, enabling recovery of input context through a decoder, facilitating safety and security. Empirical results on diverse multiple-choice and extractive question answering tasks show that CompAs outperforms ICL and prior generator-based methods, especially when scaling to more inputs. Our work establishes composable adapter generation as a practical and efficient alternative for scaling LLM deployment.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.712437"
    },
    {
        "index": "#42",
        "title": "Mixture of Detectors: A Compact View of Machine-Generated Text Detection",
        "link": "/arxiv/2509.22147",
        "arxiv_id": "2509.22147",
        "authors": "Sai Teja Lekkala, Yadagiri Annepaka, Arun Kumar Challa, Samatha Reddy Machireddy, Partha Pakray, Chukhu Chunka",
        "summary": "Large Language Models (LLMs) are gearing up to surpass human creativity. The veracity of the statement needs careful consideration. In recent developments, critical questions arise regarding the authenticity of human work and the preservation of their creativity and innovative abilities. This paper investigates such issues. This paper addresses machine-generated text detection across several scenarios, including document-level binary and multiclass classification or generator attribution, sentence-level segmentation to differentiate between human-AI collaborative text, and adversarial attacks aimed at reducing the detectability of machine-generated text. We introduce a new work called BMAS English: an English language dataset for binary classification of human and machine text, for multiclass classification, which not only identifies machine-generated text but can also try to determine its generator, and Adversarial attack addressing where it is a common act for the mitigation of detection, and Sentence-level segmentation, for predicting the boundaries between human and machine-generated text. We believe that this paper will address previous work in Machine-Generated Text Detection (MGTD) in a more meaningful way.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.712959"
    },
    {
        "index": "#43",
        "title": "From Long to Lean: Performance-aware and Adaptive Chain-of-Thought Compression via Multi-round Refinement",
        "link": "/arxiv/2509.22144",
        "arxiv_id": "2509.22144",
        "authors": "Jianzhi Yan, Le Liu, Youcheng Pan, Shiwei Chen, Zike Yuan, Yang Xiang, Buzhou Tang",
        "summary": "Chain-of-Thought (CoT) reasoning improves performance on complex tasks but introduces significant inference latency due to verbosity. We propose Multiround Adaptive Chain-of-Thought Compression (MACC), a framework that leverages the token elasticity phenomenon--where overly small token budgets can paradoxically increase output length--to progressively compress CoTs via multiround refinement. This adaptive strategy allows MACC to determine the optimal compression depth for each input. Our method achieves an average accuracy improvement of 5.6 percent over state-of-the-art baselines, while also reducing CoT length by an average of 47 tokens and significantly lowering latency. Furthermore, we show that test-time performance--accuracy and token length--can be reliably predicted using interpretable features like perplexity and compression rate on the training set. Evaluated across different models, our method enables efficient model selection and forecasting without repeated fine-tuning, demonstrating that CoT compression is both effective and predictable. Our code will be released in https://github.com/Leon221220/MACC.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.713525"
    },
    {
        "index": "#44",
        "title": "NFDI4DS Shared Tasks for Scholarly Document Processing",
        "link": "/arxiv/2509.22141",
        "arxiv_id": "2509.22141",
        "authors": "Raia Abu Ahmad, Rana Abdulla, Tilahun Abedissa Taffa, Soeren Auer, Hamed Babaei Giglou, Ekaterina Borisova, Zongxiong Chen, Stefan Dietze, Jennifer DSouza, Mayra Elwes, Genet-Asefa Gesese, Shufan Jiang, Ekaterina Kutafina, Philipp Mayr, Georg Rehm, Sameer Sadruddin, Sonja Schimmler, Daniel Schneider, Kanishka Silva, Sharmila Upadhyaya, Ricardo Usbeck",
        "summary": "Shared tasks are powerful tools for advancing research through community-based standardised evaluation. As such, they play a key role in promoting findable, accessible, interoperable, and reusable (FAIR), as well as transparent and reproducible research practices. This paper presents an updated overview of twelve shared tasks developed and hosted under the German National Research Data Infrastructure for Data Science and Artificial Intelligence (NFDI4DS) consortium, covering a diverse set of challenges in scholarly document processing. Hosted at leading venues, the tasks foster methodological innovations and contribute open-access datasets, models, and tools for the broader research community, which are integrated into the consortium's research data infrastructure.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.714258"
    },
    {
        "index": "#45",
        "title": "Bridging Draft Policy Misalignment: Group Tree Optimization for Speculative Decoding",
        "link": "/arxiv/2509.22134",
        "arxiv_id": "2509.22134",
        "authors": "Shijing Hu, Jingyang Li, Zhihui Lu, Pan Zhou",
        "summary": "Speculative decoding accelerates large language model (LLM) inference by letting a lightweight draft model propose multiple tokens that the target model verifies in parallel. Yet existing training objectives optimize only a single greedy draft path, while decoding follows a tree policy that re-ranks and verifies multiple branches. This draft policy misalignment limits achievable speedups. We introduce Group Tree Optimization (GTO), which aligns training with the decoding-time tree policy through two components: (i) Draft Tree Reward, a sampling-free objective equal to the expected acceptance length of the draft tree under the target model, directly measuring decoding performance; (ii) Group-based Draft Policy Training, a stable optimization scheme that contrasts trees from the current and a frozen reference draft model, forming debiased group-standardized advantages and applying a PPO-style surrogate along the longest accepted sequence for robust updates. We further prove that increasing our Draft Tree Reward provably improves acceptance length and speedup. Across dialogue (MT-Bench), code (HumanEval), and math (GSM8K), and multiple LLMs (e.g., LLaMA-3.1-8B, LLaMA-3.3-70B, Vicuna-1.3-13B, DeepSeek-R1-Distill-LLaMA-8B), GTO increases acceptance length by 7.4% and yields an additional 7.7% speedup over prior state-of-the-art EAGLE-3. By bridging draft policy misalignment, GTO offers a practical, general solution for efficient LLM inference.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.714760"
    },
    {
        "index": "#46",
        "title": "R-Capsule: Compressing High-Level Plans for Efficient Large Language Model Reasoning",
        "link": "/arxiv/2509.22131",
        "arxiv_id": "2509.22131",
        "authors": "Hongyu Shan, Mingyang Song, Chang Dai, Di Liang, Han Chen",
        "summary": "Chain-of-Thought (CoT) prompting helps Large Language Models (LLMs) tackle complex reasoning by eliciting explicit step-by-step rationales. However, CoT's verbosity increases latency and memory usage and may propagate early errors across long chains. We propose the Reasoning Capsule (R-Capsule), a framework that aims to combine the efficiency of latent reasoning with the transparency of explicit CoT. The core idea is to compress the high-level plan into a small set of learned latent tokens (a Reasoning Capsule) while keeping execution steps lightweight or explicit. This hybrid approach is inspired by the Information Bottleneck (IB) principle, where we encourage the capsule to be approximately minimal yet sufficient for the task. Minimality is encouraged via a low-capacity bottleneck, which helps improve efficiency. Sufficiency is encouraged via a dual objective: a primary task loss for answer accuracy and an auxiliary plan-reconstruction loss that encourages the capsule to faithfully represent the original textual plan. The reconstruction objective helps ground the latent space, thereby improving interpretability and reducing the use of uninformative shortcuts. Our framework strikes a balance between efficiency, accuracy, and interpretability, thereby reducing the visible token footprint of reasoning while maintaining or improving accuracy on complex benchmarks. Our codes are available at: https://anonymous.4open.science/r/Reasoning-Capsule-7BE0",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.738595"
    },
    {
        "index": "#47",
        "title": "FoodSEM: Large Language Model Specialized in Food Named-Entity Linking",
        "link": "/arxiv/2509.22125",
        "arxiv_id": "2509.22125",
        "authors": "Ana Gjorgjevikj, Matej Martinc, Gjorgjina Cenikj, Sašo Džeroski, Barbara Koroušić Seljak, Tome Eftimov",
        "summary": "This paper introduces FoodSEM, a state-of-the-art fine-tuned open-source large language model (LLM) for named-entity linking (NEL) to food-related ontologies. To the best of our knowledge, food NEL is a task that cannot be accurately solved by state-of-the-art general-purpose (large) language models or custom domain-specific models/systems. Through an instruction-response (IR) scenario, FoodSEM links food-related entities mentioned in a text to several ontologies, including FoodOn, SNOMED-CT, and the Hansard taxonomy. The FoodSEM model achieves state-of-the-art performance compared to related models/systems, with F1 scores even reaching 98% on some ontologies and datasets. The presented comparative analyses against zero-shot, one-shot, and few-shot LLM prompting baselines further highlight FoodSEM's superior performance over its non-fine-tuned version. By making FoodSEM and its related resources publicly available, the main contributions of this article include (1) publishing a food-annotated corpora into an IR format suitable for LLM fine-tuning/evaluation, (2) publishing a robust model to advance the semantic understanding of text in the food domain, and (3) providing a strong baseline on food NEL for future benchmarking.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.739290"
    },
    {
        "index": "#48",
        "title": "Multilingual Vision-Language Models, A Survey",
        "link": "/arxiv/2509.22123",
        "arxiv_id": "2509.22123",
        "authors": "Andrei-Alexandru Manea, Jindřich Libovický",
        "summary": "This survey examines multilingual vision-language models that process text and images across languages. We review 31 models and 21 benchmarks, spanning encoder-only and generative architectures, and identify a key tension between language neutrality (consistent cross-lingual representations) and cultural awareness (adaptation to cultural contexts). Current training methods favor neutrality through contrastive learning, while cultural awareness depends on diverse data. Two-thirds of evaluation benchmarks use translation-based approaches prioritizing semantic consistency, though recent work incorporates culturally grounded content. We find discrepancies in cross-lingual capabilities and gaps between training objectives and evaluation goals.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.739916"
    },
    {
        "index": "#49",
        "title": "Universal Legal Article Prediction via Tight Collaboration between Supervised Classification Model and LLM",
        "link": "/arxiv/2509.22119",
        "arxiv_id": "2509.22119",
        "authors": "Xiao Chi, Wenlin Zhong, Yiquan Wu, Wei Wang, Kun Kuang, Fei Wu, Minghui Xiong",
        "summary": "Legal Article Prediction (LAP) is a critical task in legal text classification, leveraging natural language processing (NLP) techniques to automatically predict relevant legal articles based on the fact descriptions of cases. As a foundational step in legal decision-making, LAP plays a pivotal role in determining subsequent judgments, such as charges and penalties. Despite its importance, existing methods face significant challenges in addressing the complexities of LAP. Supervised classification models (SCMs), such as CNN and BERT, struggle to fully capture intricate fact patterns due to their inherent limitations. Conversely, large language models (LLMs), while excelling in generative tasks, perform suboptimally in predictive scenarios due to the abstract and ID-based nature of legal articles. Furthermore, the diversity of legal systems across jurisdictions exacerbates the issue, as most approaches are tailored to specific countries and lack broader applicability. To address these limitations, we propose Uni-LAP, a universal framework for legal article prediction that integrates the strengths of SCMs and LLMs through tight collaboration. Specifically, in Uni-LAP, the SCM is enhanced with a novel Top-K loss function to generate accurate candidate articles, while the LLM employs syllogism-inspired reasoning to refine the final predictions. We evaluated Uni-LAP on datasets from multiple jurisdictions, and empirical results demonstrate that our approach consistently outperforms existing baselines, showcasing its effectiveness and generalizability.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.740613"
    },
    {
        "index": "#50",
        "title": "Think Right, Not More: Test-Time Scaling for Numerical Claim Verification",
        "link": "/arxiv/2509.22101",
        "arxiv_id": "2509.22101",
        "authors": "Primakov Chungkham, V Venktesh, Vinay Setty, Avishek Anand",
        "summary": "Fact-checking real-world claims, particularly numerical claims, is inherently complex that require multistep reasoning and numerical reasoning for verifying diverse aspects of the claim. Although large language models (LLMs) including reasoning models have made tremendous advances, they still fall short on fact-checking real-world claims that require a combination of compositional and numerical reasoning. They are unable to understand nuance of numerical aspects, and are also susceptible to the reasoning drift issue, where the model is unable to contextualize diverse information resulting in misinterpretation and backtracking of reasoning process. In this work, we systematically explore scaling test-time compute (TTS) for LLMs on the task of fact-checking complex numerical claims, which entails eliciting multiple reasoning paths from an LLM. We train a verifier model (VERIFIERFC) to navigate this space of possible reasoning paths and select one that could lead to the correct verdict. We observe that TTS helps mitigate the reasoning drift issue, leading to significant performance gains for fact-checking numerical claims. To improve compute efficiency in TTS, we introduce an adaptive mechanism that performs TTS selectively based on the perceived complexity of the claim. This approach achieves 1.8x higher efficiency than standard TTS, while delivering a notable 18.8% performance improvement over single-shot claim verification methods. Our code and data can be found at https://github.com/VenkteshV/VerifierFC",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.741243"
    },
    {
        "index": "#51",
        "title": "S2J: Bridging the Gap Between Solving and Judging Ability in Generative Reward Models",
        "link": "/arxiv/2509.22099",
        "arxiv_id": "2509.22099",
        "authors": "Shaoning Sun, Jiachen Yu, Zongqi Wang, Xuewei Yang, Tianle Gu, Yujiu Yang",
        "summary": "With the rapid development of large language models (LLMs), generative reward models (GRMs) have been widely adopted for reward modeling and evaluation. Previous studies have primarily focused on training specialized GRMs by optimizing them on preference datasets with the judgment correctness as supervision. While it's widely accepted that GRMs with stronger problem-solving capabilities typically exhibit superior judgment abilities, we first identify a significant solve-to-judge gap when examining individual queries. Specifically, the solve-to-judge gap refers to the phenomenon where GRMs struggle to make correct judgments on some queries (14%-37%), despite being fully capable of solving them. In this paper, we propose the Solve-to-Judge (S2J) approach to address this problem. Specifically, S2J simultaneously leverages both the solving and judging capabilities on a single GRM's output for supervision, explicitly linking the GRM's problem-solving and evaluation abilities during model optimization, thereby narrowing the gap. Our comprehensive experiments demonstrate that S2J effectively reduces the solve-to-judge gap by 16.2%, thereby enhancing the model's judgment performance by 5.8%. Notably, S2J achieves state-of-the-art (SOTA) performance among GRMs built on the same base model while utilizing a significantly smaller training dataset. Moreover, S2J accomplishes this through self-evolution without relying on more powerful external models for distillation.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.741903"
    },
    {
        "index": "#52",
        "title": "Multilingual Dialogue Generation and Localization with Dialogue Act Scripting",
        "link": "/arxiv/2509.22086",
        "arxiv_id": "2509.22086",
        "authors": "Justin Vasselli, Eunike Andriani Kardinata, Yusuke Sakai, Taro Watanabe",
        "summary": "Non-English dialogue datasets are scarce, and models are often trained or evaluated on translations of English-language dialogues, an approach which can introduce artifacts that reduce their naturalness and cultural appropriateness. This work proposes Dialogue Act Script (DAS), a structured framework for encoding, localizing, and generating multilingual dialogues from abstract intent representations. Rather than translating dialogue utterances directly, DAS enables the generation of new dialogues in the target language that are culturally and contextually appropriate. By using structured dialogue act representations, DAS supports flexible localization across languages, mitigating translationese and enabling more fluent, naturalistic conversations. Human evaluations across Italian, German, and Chinese show that DAS-generated dialogues consistently outperform those produced by both machine and human translators on measures of cultural relevance, coherence, and situational appropriateness.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.742520"
    },
    {
        "index": "#53",
        "title": "COSPADI: Compressing LLMs via Calibration-Guided Sparse Dictionary Learning",
        "link": "/arxiv/2509.22075",
        "arxiv_id": "2509.22075",
        "authors": "Dmitriy Shopkhoev, Denis Makhov, Magauiya Zhussip, Ammar Ali, Stamatios Lefkimmiatis",
        "summary": "Post-training compression of large language models (LLMs) largely relies on low-rank weight approximation, which represents each column of a weight matrix in a shared low-dimensional subspace. While this is a computationally efficient strategy, the imposed structural constraint is rigid and can lead to a noticeable model accuracy drop. In this work, we propose CoSpaDi (Compression via Sparse Dictionary Learning), a novel training-free compression framework that replaces low-rank decomposition with a more flexible structured sparse factorization in which each weight matrix is represented with a dense dictionary and a column-sparse coefficient matrix. This formulation enables a union-of-subspaces representation: different columns of the original weight matrix are approximated in distinct subspaces spanned by adaptively selected dictionary atoms, offering greater expressiveness than a single invariant basis. Crucially, CoSpaDi leverages a small calibration dataset to optimize the factorization such that the output activations of compressed projection layers closely match those of the original ones, thereby minimizing functional reconstruction error rather than mere weight approximation. This data-aware strategy preserves better model fidelity without any fine-tuning under reasonable compression ratios. Moreover, the resulting structured sparsity allows efficient sparse-dense matrix multiplication and is compatible with post-training quantization for further memory and latency gains. We evaluate CoSpaDi across multiple Llama and Qwen models under per-layer and per-group settings at 20-50\\% compression ratios, demonstrating consistent superiority over state-of-the-art data-aware low-rank methods both in accuracy and perplexity. Our results establish structured sparse dictionary learning as a powerful alternative to conventional low-rank approaches for efficient LLM deployment.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.748817"
    },
    {
        "index": "#54",
        "title": "Fine-tuning Done Right in Model Editing",
        "link": "/arxiv/2509.22072",
        "arxiv_id": "2509.22072",
        "authors": "Wanli Yang, Fei Sun, Rui Tang, Hongyu Zang, Du Su, Qi Cao, Jingang Wang, Huawei Shen, Xueqi Cheng",
        "summary": "Fine-tuning, a foundational method for adapting large language models, has long been considered ineffective for model editing. Here, we challenge this belief, arguing that the reported failure arises not from the inherent limitation of fine-tuning itself, but from adapting it to the sequential nature of the editing task, a single-pass depth-first pipeline that optimizes each sample to convergence before moving on. While intuitive, this depth-first pipeline coupled with sample-wise updating over-optimizes each edit and induces interference across edits. Our controlled experiments reveal that simply restoring fine-tuning to the standard breadth-first (i.e., epoch-based) pipeline with mini-batch optimization substantially improves its effectiveness for model editing. Moreover, fine-tuning in editing also suffers from suboptimal tuning parameter locations inherited from prior methods. Through systematic analysis of tuning locations, we derive LocFT-BF, a simple and effective localized editing method built on the restored fine-tuning framework. Extensive experiments across diverse LLMs and datasets demonstrate that LocFT-BF outperforms state-of-the-art methods by large margins. Notably, to our knowledge, it is the first to sustain 100K edits and 72B-parameter models,10 x beyond prior practice, without sacrificing general capabilities. By clarifying a long-standing misconception and introducing a principled localized tuning strategy, we advance fine-tuning from an underestimated baseline to a leading method for model editing, establishing a solid foundation for future research.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.749401"
    },
    {
        "index": "#55",
        "title": "The QCET Taxonomy of Standard Quality Criterion Names and Definitions for the Evaluation of NLP Systems",
        "link": "/arxiv/2509.22064",
        "arxiv_id": "2509.22064",
        "authors": "Anya Belz, Simon Mille, Craig Thomson",
        "summary": "Prior work has shown that two NLP evaluation experiments that report results for the same quality criterion name (e.g. Fluency) do not necessarily evaluate the same aspect of quality, and the comparability implied by the name can be misleading. Not knowing when two evaluations are comparable in this sense means we currently lack the ability to draw reliable conclusions about system quality on the basis of multiple, independently conducted evaluations. This in turn hampers the ability of the field to progress scientifically as a whole, a pervasive issue in NLP since its beginning (Sparck Jones, 1981). It is hard to see how the issue of unclear comparability can be fully addressed other than by the creation of a standard set of quality criterion names and definitions that the several hundred quality criterion names actually in use in the field can be mapped to, and grounded in. Taking a strictly descriptive approach, the QCET Quality Criteria for Evaluation Taxonomy derives a standard set of quality criterion names and definitions from three surveys of evaluations reported in NLP, and structures them into a hierarchy where each parent node captures common aspects of its child nodes. We present QCET and the resources it consists of, and discuss its three main uses in (i) establishing comparability of existing evaluations, (ii) guiding the design of new evaluations, and (iii) assessing regulatory compliance.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.749899"
    },
    {
        "index": "#56",
        "title": "RedNote-Vibe: A Dataset for Capturing Temporal Dynamics of AI-Generated Text in Social Media",
        "link": "/arxiv/2509.22055",
        "arxiv_id": "2509.22055",
        "authors": "Yudong Li, Yufei Sun, Yuhan Yao, Peiru Yang, Wanyue Li, Jiajun Zou, Yongfeng Huang, Linlin Shen",
        "summary": "The proliferation of Large Language Models (LLMs) has led to widespread AI-Generated Text (AIGT) on social media platforms, creating unique challenges where content dynamics are driven by user engagement and evolve over time. However, existing datasets mainly depict static AIGT detection. In this work, we introduce RedNote-Vibe, the first longitudinal (5-years) dataset for social media AIGT analysis. This dataset is sourced from Xiaohongshu platform, containing user engagement metrics (e.g., likes, comments) and timestamps spanning from the pre-LLM period to July 2025, which enables research into the temporal dynamics and user interaction patterns of AIGT. Furthermore, to detect AIGT in the context of social media, we propose PsychoLinguistic AIGT Detection Framework (PLAD), an interpretable approach that leverages psycholinguistic features. Our experiments show that PLAD achieves superior detection performance and provides insights into the signatures distinguishing human and AI-generated content. More importantly, it reveals the complex relationship between these linguistic features and social media engagement. The dataset is available at https://github.com/testuser03158/RedNote-Vibe.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.750459"
    },
    {
        "index": "#57",
        "title": "Fuzzy Reasoning Chain (FRC): An Innovative Reasoning Framework from Fuzziness to Clarity",
        "link": "/arxiv/2509.22054",
        "arxiv_id": "2509.22054",
        "authors": "Ping Chen, Xiang Liu, Zhaoxiang Liu, Zezhou Chen, Xingpeng Zhang, Huan Hu, Zipeng Wang, Kai Wang, Shuming Shi, Shiguo Lian",
        "summary": "With the rapid advancement of large language models (LLMs), natural language processing (NLP) has achieved remarkable progress. Nonetheless, significant challenges remain in handling texts with ambiguity, polysemy, or uncertainty. We introduce the Fuzzy Reasoning Chain (FRC) framework, which integrates LLM semantic priors with continuous fuzzy membership degrees, creating an explicit interaction between probability-based reasoning and fuzzy membership reasoning. This transition allows ambiguous inputs to be gradually transformed into clear and interpretable decisions while capturing conflicting or uncertain signals that traditional probability-based methods cannot. We validate FRC on sentiment analysis tasks, where both theoretical analysis and empirical results show that it ensures stable reasoning and facilitates knowledge transfer across different model scales. These findings indicate that FRC provides a general mechanism for managing subtle and ambiguous expressions with improved interpretability and robustness.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.751053"
    },
    {
        "index": "#58",
        "title": "Taxonomy of Comprehensive Safety for Clinical Agents",
        "link": "/arxiv/2509.22041",
        "arxiv_id": "2509.22041",
        "authors": "Jean Seo, Hyunkyung Lee, Gibaeg Kim, Wooseok Han, Jaehyo Yoo, Seungseop Lim, Kihun Shin, Eunho Yang",
        "summary": "Safety is a paramount concern in clinical chatbot applications, where inaccurate or harmful responses can lead to serious consequences. Existing methods--such as guardrails and tool calling--often fall short in addressing the nuanced demands of the clinical domain. In this paper, we introduce TACOS (TAxonomy of COmprehensive Safety for Clinical Agents), a fine-grained, 21-class taxonomy that integrates safety filtering and tool selection into a single user intent classification step. TACOS is a taxonomy that can cover a wide spectrum of clinical and non-clinical queries, explicitly modeling varying safety thresholds and external tool dependencies. To validate our framework, we curate a TACOS-annotated dataset and perform extensive experiments. Our results demonstrate the value of a new taxonomy specialized for clinical agent settings, and reveal useful insights about train data distribution and pretrained knowledge of base models.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.751597"
    },
    {
        "index": "#59",
        "title": "From Outliers to Topics in Language Models: Anticipating Trends in News Corpora",
        "link": "/arxiv/2509.22030",
        "arxiv_id": "2509.22030",
        "authors": "Evangelia Zve, Benjamin Icard, Alice Breton, Lila Sainero, Gauvain Bourgne, Jean-Gabriel Ganascia",
        "summary": "This paper examines how outliers, often dismissed as noise in topic modeling, can act as weak signals of emerging topics in dynamic news corpora. Using vector embeddings from state-of-the-art language models and a cumulative clustering approach, we track their evolution over time in French and English news datasets focused on corporate social responsibility and climate change. The results reveal a consistent pattern: outliers tend to evolve into coherent topics over time across both models and languages.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.752156"
    },
    {
        "index": "#60",
        "title": "GraphSearch: An Agentic Deep Searching Workflow for Graph Retrieval-Augmented Generation",
        "link": "/arxiv/2509.22009",
        "arxiv_id": "2509.22009",
        "authors": "Cehao Yang, Xiaojun Wu, Xueyuan Lin, Chengjin Xu, Xuhui Jiang, Yuanliang Sun, Jia Li, Hui Xiong, Jian Guo",
        "summary": "Graph Retrieval-Augmented Generation (GraphRAG) enhances factual reasoning in LLMs by structurally modeling knowledge through graph-based representations. However, existing GraphRAG approaches face two core limitations: shallow retrieval that fails to surface all critical evidence, and inefficient utilization of pre-constructed structural graph data, which hinders effective reasoning from complex queries. To address these challenges, we propose \\textsc{GraphSearch}, a novel agentic deep searching workflow with dual-channel retrieval for GraphRAG. \\textsc{GraphSearch} organizes the retrieval process into a modular framework comprising six modules, enabling multi-turn interactions and iterative reasoning. Furthermore, \\textsc{GraphSearch} adopts a dual-channel retrieval strategy that issues semantic queries over chunk-based text data and relational queries over structural graph data, enabling comprehensive utilization of both modalities and their complementary strengths. Experimental results across six multi-hop RAG benchmarks demonstrate that \\textsc{GraphSearch} consistently improves answer accuracy and generation quality over the traditional strategy, confirming \\textsc{GraphSearch} as a promising direction for advancing graph retrieval-augmented generation.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.752724"
    },
    {
        "index": "#61",
        "title": "Black-Box Hallucination Detection via Consistency Under the Uncertain Expression",
        "link": "/arxiv/2509.21999",
        "arxiv_id": "2509.21999",
        "authors": "Seongho Joo, Kyungmin Min, Jahyun Koo, Kyomin Jung",
        "summary": "Despite the great advancement of Language modeling in recent days, Large Language Models (LLMs) such as GPT3 are notorious for generating non-factual responses, so-called \"hallucination\" problems. Existing methods for detecting and alleviating this hallucination problem require external resources or the internal state of LLMs, such as the output probability of each token. Given the LLM's restricted external API availability and the limited scope of external resources, there is an urgent demand to establish the Black-Box approach as the cornerstone for effective hallucination detection. In this work, we propose a simple black-box hallucination detection metric after the investigation of the behavior of LLMs under expression of uncertainty. Our comprehensive analysis reveals that LLMs generate consistent responses when they present factual responses while non-consistent responses vice versa. Based on the analysis, we propose an efficient black-box hallucination detection metric with the expression of uncertainty. The experiment demonstrates that our metric is more predictive of the factuality in model responses than baselines that use internal knowledge of LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.753239"
    },
    {
        "index": "#62",
        "title": "MotivGraph-SoIQ: Integrating Motivational Knowledge Graphs and Socratic Dialogue for Enhanced LLM Ideation",
        "link": "/arxiv/2509.21978",
        "arxiv_id": "2509.21978",
        "authors": "Xinping Lei, Tong Zhou, Yubo Chen, Kang Liu, Jun Zhao",
        "summary": "Large Language Models (LLMs) hold substantial potential for accelerating academic ideation but face critical challenges in grounding ideas and mitigating confirmation bias for further refinement. We propose integrating motivational knowledge graphs and socratic dialogue to address these limitations in enhanced LLM ideation (MotivGraph-SoIQ). This novel framework provides essential grounding and practical idea improvement steps for LLM ideation by integrating a Motivational Knowledge Graph (MotivGraph) with a Q-Driven Socratic Ideator. The MotivGraph structurally stores three key node types(problem, challenge and solution) to offer motivation grounding for the LLM ideation process. The Ideator is a dual-agent system utilizing Socratic questioning, which facilitates a rigorous refinement process that mitigates confirmation bias and improves idea quality across novelty, experimental rigor, and motivational rationality dimensions. On the ICLR25 paper topics dataset, MotivGraph-SoIQ exhibits clear advantages over existing state-of-the-art approaches across LLM-based scoring, ELO ranking, and human evaluation metrics.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.753733"
    },
    {
        "index": "#63",
        "title": "Debiasing Large Language Models in Thai Political Stance Detection via Counterfactual Calibration",
        "link": "/arxiv/2509.21946",
        "arxiv_id": "2509.21946",
        "authors": "Kasidit Sermsri, Teerapong Panboonyuen",
        "summary": "Political stance detection in low-resource and culturally complex settings poses a critical challenge for large language models (LLMs). In the Thai political landscape - marked by indirect language, polarized figures, and entangled sentiment and stance - LLMs often display systematic biases such as sentiment leakage and favoritism toward entities. These biases undermine fairness and reliability. We present ThaiFACTUAL, a lightweight, model-agnostic calibration framework that mitigates political bias without requiring fine-tuning. ThaiFACTUAL uses counterfactual data augmentation and rationale-based supervision to disentangle sentiment from stance and reduce bias. We also release the first high-quality Thai political stance dataset, annotated with stance, sentiment, rationales, and bias markers across diverse entities and events. Experimental results show that ThaiFACTUAL significantly reduces spurious correlations, enhances zero-shot generalization, and improves fairness across multiple LLMs. This work highlights the importance of culturally grounded debiasing techniques for underrepresented languages.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.754208"
    },
    {
        "index": "#64",
        "title": "Why Chain of Thought Fails in Clinical Text Understanding",
        "link": "/arxiv/2509.21933",
        "arxiv_id": "2509.21933",
        "authors": "Jiageng Wu, Kevin Xie, Bowen Gu, Nils Krüger, Kueiyu Joshua Lin, Jie Yang",
        "summary": "Large language models (LLMs) are increasingly being applied to clinical care, a domain where both accuracy and transparent reasoning are critical for safe and trustworthy deployment. Chain-of-thought (CoT) prompting, which elicits step-by-step reasoning, has demonstrated improvements in performance and interpretability across a wide range of tasks. However, its effectiveness in clinical contexts remains largely unexplored, particularly in the context of electronic health records (EHRs), the primary source of clinical documentation, which are often lengthy, fragmented, and noisy. In this work, we present the first large-scale systematic study of CoT for clinical text understanding. We assess 95 advanced LLMs on 87 real-world clinical text tasks, covering 9 languages and 8 task types. Contrary to prior findings in other domains, we observe that 86.3\\% of models suffer consistent performance degradation in the CoT setting. More capable models remain relatively robust, while weaker ones suffer substantial declines. To better characterize these effects, we perform fine-grained analyses of reasoning length, medical concept alignment, and error profiles, leveraging both LLM-as-a-judge evaluation and clinical expert evaluation. Our results uncover systematic patterns in when and why CoT fails in clinical contexts, which highlight a critical paradox: CoT enhances interpretability but may undermine reliability in clinical text tasks. This work provides an empirical basis for clinical reasoning strategies of LLMs, highlighting the need for transparent and trustworthy approaches.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.754761"
    },
    {
        "index": "#65",
        "title": "SimulSense: Sense-Driven Interpreting for Efficient Simultaneous Speech Translation",
        "link": "/arxiv/2509.21932",
        "arxiv_id": "2509.21932",
        "authors": "Haotian Tan, Hiroki Ouchi, Sakriani Sakti",
        "summary": "How to make human-interpreter-like read/write decisions for simultaneous speech translation (SimulST) systems? Current state-of-the-art systems formulate SimulST as a multi-turn dialogue task, requiring specialized interleaved training data and relying on computationally expensive large language model (LLM) inference for decision-making. In this paper, we propose SimulSense, a novel framework for SimulST that mimics human interpreters by continuously reading input speech and triggering write decisions to produce translation when a new sense unit is perceived. Experiments against two state-of-the-art baseline systems demonstrate that our proposed method achieves a superior quality-latency tradeoff and substantially improved real-time efficiency, where its decision-making is up to 9.6x faster than the baselines.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.755233"
    },
    {
        "index": "#66",
        "title": "AutoSCORE: Enhancing Automated Scoring with Multi-Agent Large Language Models via Structured Component Recognition",
        "link": "/arxiv/2509.21910",
        "arxiv_id": "2509.21910",
        "authors": "Yun Wang, Zhaojun Ding, Xuansheng Wu, Siyue Sun, Ninghao Liu, Xiaoming Zhai",
        "summary": "Automated scoring plays a crucial role in education by reducing the reliance on human raters, offering scalable and immediate evaluation of student work. While large language models (LLMs) have shown strong potential in this task, their use as end-to-end raters faces challenges such as low accuracy, prompt sensitivity, limited interpretability, and rubric misalignment. These issues hinder the implementation of LLM-based automated scoring in assessment practice. To address the limitations, we propose AutoSCORE, a multi-agent LLM framework enhancing automated scoring via rubric-aligned Structured COmponent REcognition. With two agents, AutoSCORE first extracts rubric-relevant components from student responses and encodes them into a structured representation (i.e., Scoring Rubric Component Extraction Agent), which is then used to assign final scores (i.e., Scoring Agent). This design ensures that model reasoning follows a human-like grading process, enhancing interpretability and robustness. We evaluate AutoSCORE on four benchmark datasets from the ASAP benchmark, using both proprietary and open-source LLMs (GPT-4o, LLaMA-3.1-8B, and LLaMA-3.1-70B). Across diverse tasks and rubrics, AutoSCORE consistently improves scoring accuracy, human-machine agreement (QWK, correlations), and error metrics (MAE, RMSE) compared to single-agent baselines, with particularly strong benefits on complex, multi-dimensional rubrics, and especially large relative gains on smaller LLMs. These results demonstrate that structured component recognition combined with multi-agent design offers a scalable, reliable, and interpretable solution for automated scoring.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.755780"
    },
    {
        "index": "#67",
        "title": "A Large-Scale Dataset and Citation Intent Classification in Turkish with LLMs",
        "link": "/arxiv/2509.21907",
        "arxiv_id": "2509.21907",
        "authors": "Kemal Sami Karaca, Bahaeddin Eravcı",
        "summary": "Understanding the qualitative intent of citations is essential for a comprehensive assessment of academic research, a task that poses unique challenges for agglutinative languages like Turkish. This paper introduces a systematic methodology and a foundational dataset to address this problem. We first present a new, publicly available dataset of Turkish citation intents, created with a purpose-built annotation tool. We then evaluate the performance of standard In-Context Learning (ICL) with Large Language Models (LLMs), demonstrating that its effectiveness is limited by inconsistent results caused by manually designed prompts. To address this core limitation, we introduce a programmable classification pipeline built on the DSPy framework, which automates prompt optimization systematically. For final classification, we employ a stacked generalization ensemble to aggregate outputs from multiple optimized models, ensuring stable and reliable predictions. This ensemble, with an XGBoost meta-model, achieves a state-of-the-art accuracy of 91.3\\%. Ultimately, this study provides the Turkish NLP community and the broader academic circles with a foundational dataset and a robust classification framework paving the way for future qualitative citation studies.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.756257"
    },
    {
        "index": "#68",
        "title": "Elastic MoE: Unlocking the Inference-Time Scalability of Mixture-of-Experts",
        "link": "/arxiv/2509.21892",
        "arxiv_id": "2509.21892",
        "authors": "Naibin Gu, Zhenyu Zhang, Yuchen Feng, Yilong Chen, Peng Fu, Zheng Lin, Shuohuan Wang, Yu Sun, Hua Wu, Weiping Wang, Haifeng Wang",
        "summary": "Mixture-of-Experts (MoE) models typically fix the number of activated experts $k$ at both training and inference. Intuitively, activating more experts at inference $k'$ (where $k'> k$) means engaging a larger set of model parameters for the computation and thus is expected to improve performance. However, contrary to this intuition, we find the scaling range to be so narrow that performance begins to degrade rapidly after only a slight increase in the number of experts. Further investigation reveals that this degradation stems from a lack of learned collaboration among experts. To address this, we introduce Elastic Mixture-of-Experts (EMoE), a novel training framework that enables MoE models to scale the number of activated experts at inference without incurring additional training overhead. By simultaneously training experts to collaborate in diverse combinations and encouraging the router for high-quality selections, EMoE ensures robust performance across computational budgets at inference. We conduct extensive experiments on various MoE settings. Our results show that EMoE significantly expands the effective performance-scaling range, extending it to as much as 2-3$\\times$ the training-time $k$, while also pushing the model's peak performance to a higher level.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.756891"
    },
    {
        "index": "#69",
        "title": "QoNext: Towards Next-generation QoE for Foundation Models",
        "link": "/arxiv/2509.21889",
        "arxiv_id": "2509.21889",
        "authors": "Yijin Guo, Ye Shen, Farong Wen, Junying Wang, Zicheng Zhang, Qi Jia, Guangtao Zhai",
        "summary": "Existing evaluations of foundation models, including recent human-centric approaches, fail to capture what truly matters: user's experience during interaction. Current methods treat evaluation as a matter of output correctness alone, overlooking that user satisfaction emerges from the interplay between response quality and interaction, which limits their ability to account for the mechanisms underlying user experience. To address this gap, we introduce QoNext, the first framework that adapts Quality of Experience (QoE) principles from networking and multimedia to the assessment of foundation models. QoNext identifies experiential factors that shape user experience and incorporates them into controlled experiments, where human ratings are collected under varied configurations. From these studies we construct a QoE-oriented database and train predictive models that estimate perceived user experience from measurable system parameters. Our results demonstrate that QoNext not only enables proactive and fine-grained evaluation but also provides actionable guidance for productized services of optimizing foundation models in practice.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.757413"
    },
    {
        "index": "#70",
        "title": "No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping",
        "link": "/arxiv/2509.21880",
        "arxiv_id": "2509.21880",
        "authors": "Thanh-Long V. Le, Myeongho Jeon, Kim Vu, Viet Lai, Eunho Yang",
        "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful framework for improving the reasoning abilities of Large Language Models (LLMs). However, current methods such as GRPO rely only on problems where the model responses to the same input differ in correctness, while ignoring those where all responses receive the same reward - so-called zero-variance prompts. In this work, we argue that such prompts are not useless but can, in fact, provide meaningful feedback for policy optimization. To this end, we introduce RL with Zero-Variance Prompts (RL-ZVP), a novel algorithm that extract learning signals from zero-variance prompts. RL-ZVP directly rewards correctness and penalizes errors even without contrasting responses, modulating feedback with token-level characteristics to preserve informative, nuanced signals. Across six math reasoning benchmarks, RL-ZVP achieves significant improvements of up to 8.61 points in accuracy and 7.77 points in pass rate over GRPO, while consistently outperforming other baselines that filter out zero-variance prompts. These results highlight the untapped potential of learning from zero-variance prompts in RLVR.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.762938"
    },
    {
        "index": "#71",
        "title": "LUMINA: Detecting Hallucinations in RAG System with Context-Knowledge Signals",
        "link": "/arxiv/2509.21875",
        "arxiv_id": "2509.21875",
        "authors": "Min-Hsuan Yeh, Yixuan Li, Tanwi Mallick",
        "summary": "Retrieval-Augmented Generation (RAG) aims to mitigate hallucinations in large language models (LLMs) by grounding responses in retrieved documents. Yet, RAG-based LLMs still hallucinate even when provided with correct and sufficient context. A growing line of work suggests that this stems from an imbalance between how models use external context and their internal knowledge, and several approaches have attempted to quantify these signals for hallucination detection. However, existing methods require extensive hyperparameter tuning, limiting their generalizability. We propose LUMINA, a novel framework that detects hallucinations in RAG systems through context-knowledge signals: external context utilization is quantified via distributional distance, while internal knowledge utilization is measured by tracking how predicted tokens evolve across transformer layers. We further introduce a framework for statistically validating these measurements. Experiments on common RAG hallucination benchmarks and four open-source LLMs show that LUMINA achieves consistently high AUROC and AUPRC scores, outperforming prior utilization-based methods by up to +13% AUROC on HalluRAG. Moreover, LUMINA remains robust under relaxed assumptions about retrieval quality and model matching, offering both effectiveness and practicality.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.763233"
    },
    {
        "index": "#72",
        "title": "Enhancing Low-Rank Adaptation with Structured Nonlinear Transformations",
        "link": "/arxiv/2509.21870",
        "arxiv_id": "2509.21870",
        "authors": "Guanzhi Deng, Mingyang Liu, Dapeng Wu, Yinqiao Li, Linqi Song",
        "summary": "Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning method for large language models. However, its linear nature limits expressiveness. We propose LoRAN, a non-linear extension of LoRA that applies lightweight transformations to the low-rank updates. We further introduce Sinter, a sine-based activation that adds structured perturbations without increasing parameter count. Experiments across summarization and classification tasks show that LoRAN consistently improves over QLoRA. Ablation studies reveal that Sinter outperforms standard activations such as Sigmoid, ReLU, and Tanh, highlighting the importance of activation design in lowrank tuning.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.763556"
    },
    {
        "index": "#73",
        "title": "KnowMT-Bench: Benchmarking Knowledge-Intensive Long-Form Question Answering in Multi-Turn Dialogues",
        "link": "/arxiv/2509.21856",
        "arxiv_id": "2509.21856",
        "authors": "Junhao Chen, Yu Huang, Siyuan Li, Rui Yao, Hanqian Li, Hanyu Zhang, Jungang Li, Jian Chen, Bowen Wang, Xuming Hu",
        "summary": "Multi-Turn Long-Form Question Answering (MT-LFQA) is a key application paradigm of Large Language Models (LLMs) in knowledge-intensive domains. However, existing benchmarks are limited to single-turn dialogue, while multi-turn dialogue benchmarks typically assess other orthogonal capabilities rather than knowledge-intensive factuality. To bridge this critical gap, we introduce \\textbf{KnowMT-Bench}, the \\textit{first-ever} benchmark designed to systematically evaluate MT-LFQA for LLMs across knowledge-intensive fields, including medicine, finance, and law. To faithfully assess the model's real-world performance, KnowMT-Bench employs a dynamic evaluation setting where models generate their own multi-turn dialogue histories given logically progressive question sequences. The factual capability and information delivery efficiency of the \\textit{final-turn} answer are then evaluated using a human-validated automated pipeline. Our experiments reveal that multi-turn contexts degrade performance: factual capability declines due to the contextual noise from self-generated histories, while information efficiency drops as models become more verbose with increasing dialogue length. We then investigate mitigation strategies, demonstrating that retrieval-augmented generation (RAG) can effectively alleviate and even reverse this factual degradation. These findings underscore the importance of our benchmark in evaluating and enhancing the conversational factual capabilities of LLMs in real-world knowledge-intensive applications. Code is available at \\href{https://github.com/hardenyu21/KnowMT-Bench}{\\textcolor{cyan}{\\texttt{KnowMT-Bench}}}.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.763917"
    },
    {
        "index": "#75",
        "title": "Semantic Agreement Enables Efficient Open-Ended LLM Cascades",
        "link": "/arxiv/2509.21837",
        "arxiv_id": "2509.21837",
        "authors": "Duncan Soiffer, Steven Kolawole, Virginia Smith",
        "summary": "Cascade systems route computational requests to smaller models when possible and defer to larger models only when necessary, offering a promising approach to balance cost and quality in LLM deployment. However, they face a fundamental challenge in open-ended text generation: determining output reliability when generation quality lies on a continuous spectrum, often with multiple valid responses. To address this, we propose semantic agreement -- meaning-level consensus between ensemble outputs -- as a training-free signal for reliable deferral. We show that when diverse model outputs agree semantically, their consensus is a stronger reliability signal than token-level confidence. Evaluated from 500M to 70B-parameter models, we find that semantic cascades match or surpass target-model quality at 40% of the cost and reduce latency by up to 60%. Our method requires no model internals, works across black-box APIs, and remains robust to model updates, making it a practical baseline for real-world LLM deployment.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.764536"
    },
    {
        "index": "#76",
        "title": "ResT: Reshaping Token-Level Policy Gradients for Tool-Use Large Language Models",
        "link": "/arxiv/2509.21826",
        "arxiv_id": "2509.21826",
        "authors": "Zihan Lin, Xiaohan Wang, Jie Cao, Jiajun Chai, Guojun Yin, Wei Lin, Ran He",
        "summary": "Large language models (LLMs) transcend passive generation and act as goal-directed agents by invoking external tools. Reinforcement learning (RL) offers a principled framework for optimizing these emergent tool-use policies, yet the prevailing paradigm relies exclusively on sparse outcome rewards and lacks consideration of the particularity of tool-use tasks, inflating policy-gradient variance and resulting in inefficient training. To better understand and address these challenges, we first establish a theoretical link between policy entropy and training stability of tool-use tasks, which reveals that structured, low-entropy tokens are primary determinants of rewards. Motivated by this insight, we propose \\textbf{Res}haped \\textbf{T}oken-level policy gradients (\\textbf{ResT}) for tool-use tasks. ResT reshapes the policy gradient through entropy-informed token reweighting, progressively upweighting reasoning tokens as training proceeds. This entropy-aware scheme enables a smooth shift from structural correctness to semantic reasoning and stabilizes convergence in multi-turn tool-use tasks. Evaluation on BFCL and API-Bank shows that ResT achieves state-of-the-art results, outperforming prior methods by up to $8.76\\%$. When fine-tuned on a 4B base LLM, ResT further surpasses GPT-4o by $4.11\\%$ on single-turn tasks and $1.50\\%$ on multi-turn base tasks.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.764865"
    },
    {
        "index": "#77",
        "title": "Can LLMs Solve and Generate Linguistic Olympiad Puzzles?",
        "link": "/arxiv/2509.21820",
        "arxiv_id": "2509.21820",
        "authors": "Neh Majmudar, Elena Filatova",
        "summary": "In this paper, we introduce a combination of novel and exciting tasks: the solution and generation of linguistic puzzles. We focus on puzzles used in Linguistic Olympiads for high school students. We first extend the existing benchmark for the task of solving linguistic puzzles. We explore the use of Large Language Models (LLMs), including recent state-of-the-art models such as OpenAI's o1, for solving linguistic puzzles, analyzing their performance across various linguistic topics. We demonstrate that LLMs outperform humans on most puzzles types, except for those centered on writing systems, and for the understudied languages. We use the insights from puzzle-solving experiments to direct the novel task of puzzle generation. We believe that automating puzzle generation, even for relatively simple puzzles, holds promise for expanding interest in linguistics and introducing the field to a broader audience. This finding highlights the importance of linguistic puzzle generation as a research task: such puzzles can not only promote linguistics but also support the dissemination of knowledge about rare and understudied languages.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.765153"
    },
    {
        "index": "#78",
        "title": "Towards Minimal Causal Representations for Human Multimodal Language Understanding",
        "link": "/arxiv/2509.21805",
        "arxiv_id": "2509.21805",
        "authors": "Menghua Jiang, Yuncheng Jiang, Haifeng Hu, Sijie Mai",
        "summary": "Human Multimodal Language Understanding (MLU) aims to infer human intentions by integrating related cues from heterogeneous modalities. Existing works predominantly follow a ``learning to attend\" paradigm, which maximizes mutual information between data and labels to enhance predictive performance. However, such methods are vulnerable to unintended dataset biases, causing models to conflate statistical shortcuts with genuine causal features and resulting in degraded out-of-distribution (OOD) generalization. To alleviate this issue, we introduce a Causal Multimodal Information Bottleneck (CaMIB) model that leverages causal principles rather than traditional likelihood. Concretely, we first applies the information bottleneck to filter unimodal inputs, removing task-irrelevant noise. A parameterized mask generator then disentangles the fused multimodal representation into causal and shortcut subrepresentations. To ensure global consistency of causal features, we incorporate an instrumental variable constraint, and further adopt backdoor adjustment by randomly recombining causal and shortcut features to stabilize causal estimation. Extensive experiments on multimodal sentiment analysis, humor detection, and sarcasm detection, along with OOD test sets, demonstrate the effectiveness of CaMIB. Theoretical and empirical analyses further highlight its interpretability and soundness.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.765460"
    },
    {
        "index": "#79",
        "title": "Redefining Machine Simultaneous Interpretation: From Incremental Translation to Human-Like Strategies",
        "link": "/arxiv/2509.21801",
        "arxiv_id": "2509.21801",
        "authors": "Qianen Zhang, Satoshi Nakamura",
        "summary": "Simultaneous Machine Translation (SiMT) requires high-quality translations under strict real-time constraints, which traditional encoder-decoder policies with only READ/WRITE actions cannot fully address. We extend the action space of SiMT with four adaptive actions: SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION and PRONOMINALIZATION, which enable real-time restructuring, omission, and simplification while preserving semantic fidelity. We implement these actions in a decoder-only large language model (LLM) framework and construct training references through action-aware prompting. To evaluate both quality and latency, we further develop a latency-aware TTS pipeline that maps textual outputs to speech with realistic timing. Experiments on the ACL60/60 English-Chinese and English-German benchmarks show that our framework consistently improves semantic metrics (e.g., COMET-KIWI) and achieves lower delay (measured by Average Lagging) compared to reference translations and salami-based baselines. Notably, combining DROP and SENTENCE_CUT yields the best overall balance between fluency and latency. These results demonstrate that enriching the action space of LLM-based SiMT provides a promising direction for bridging the gap between human and machine interpretation.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.765737"
    },
    {
        "index": "#80",
        "title": "Evaluating and Improving Cultural Awareness of Reward Models for LLM Alignment",
        "link": "/arxiv/2509.21798",
        "arxiv_id": "2509.21798",
        "authors": "Hongbin Zhang, Kehai Chen, Xuefeng Bai, Yang Xiang, Min Zhang",
        "summary": "Reward models (RMs) are crucial for aligning large language models (LLMs) with diverse cultures. Consequently, evaluating their cultural awareness is essential for further advancing global alignment of LLMs. However, existing RM evaluations fall short in assessing cultural awareness due to the scarcity of culturally relevant evaluation datasets. To fill this gap, we propose Cultural Awareness Reward modeling Benchmark (CARB), covering 10 distinct cultures across 4 cultural domains. Our extensive evaluation of state-of-the-art RMs reveals their deficiencies in modeling cultural awareness and demonstrates a positive correlation between performance on CARB and downstream multilingual cultural alignment tasks. Further analysis identifies the spurious correlations within culture-aware reward modeling, wherein RM's scoring relies predominantly on surface-level features rather than authentic cultural nuance understanding. To address these, we propose Think-as-Locals to elicit deeper culturally grounded reasoning from generative RMs via reinforcement learning from verifiable rewards (RLVR) and employ well-designed rewards to ensure accurate preference judgments and high-quality structured evaluation criteria generation. Experimental results validate its efficacy in mitigating spurious features interference and advancing culture-aware reward modeling.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.766053"
    },
    {
        "index": "#81",
        "title": "Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference",
        "link": "/arxiv/2509.21791",
        "arxiv_id": "2509.21791",
        "authors": "Han Yuan, Yue Zhao, Li Zhang, Wuqiong Luo, Zheng Ma",
        "summary": "Structured output from large language models (LLMs) has enhanced efficiency in processing generated information and is increasingly adopted in industrial applications. Prior studies have investigated the impact of structured output on LLMs' generation quality, often presenting one-way findings. Some suggest that structured format enhances completeness and factual accuracy, while others argue that it restricts the reasoning capacity of LLMs and leads to reductions in standard evaluation metrics. Potential limitations of these assessments include restricted testing scenarios, weakly controlled comparative settings, and reliance on coarse metrics. In this work, we present a refined analysis using causal inference. Based on one assumed and two guaranteed constraints, we derive five potential causal structures characterizing the influence of structured output on LLMs' generation: (1) collider without m-bias, (2) collider with m-bias, (3) single cause from instruction, (4) single cause from output format, and (5) independence. Across seven public and one developed reasoning tasks, we find that coarse metrics report positive, negative, or neutral effects of structured output on GPT-4o's generation. However, causal inference reveals no causal impact in 43 out of 48 scenarios. In the remaining 5, 3 involve multifaceted causal structures influenced by concrete instructions.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.766375"
    },
    {
        "index": "#82",
        "title": "SynerGen: Contextualized Generative Recommender for Unified Search and Recommendation",
        "link": "/arxiv/2509.21777",
        "arxiv_id": "2509.21777",
        "authors": "Vianne R. Gao, Chen Xue, Marc Versage, Xie Zhou, Zhongruo Wang, Chao Li, Yeon Seonwoo, Nan Chen, Zhen Ge, Gourab Kundu, Weiqi Zhang, Tian Wang, Qingjun Cui, Trishul Chilimbi",
        "summary": "The dominant retrieve-then-rank pipeline in large-scale recommender systems suffers from mis-calibration and engineering overhead due to its architectural split and differing optimization objectives. While recent generative sequence models have shown promise in unifying retrieval and ranking by auto-regressively generating ranked items, existing solutions typically address either personalized search or query-free recommendation, often exhibiting performance trade-offs when attempting to unify both. We introduce \\textit{SynerGen}, a novel generative recommender model that bridges this critical gap by providing a single generative backbone for both personalized search and recommendation, while simultaneously excelling at retrieval and ranking tasks. Trained on behavioral sequences, our decoder-only Transformer leverages joint optimization with InfoNCE for retrieval and a hybrid pointwise-pairwise loss for ranking, allowing semantic signals from search to improve recommendation and vice versa. We also propose a novel time-aware rotary positional embedding to effectively incorporate time information into the attention mechanism. \\textit{SynerGen} achieves significant improvements on widely adopted recommendation and search benchmarks compared to strong generative recommender and joint search and recommendation baselines. This work demonstrates the viability of a single generative foundation model for industrial-scale unified information access.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.766771"
    },
    {
        "index": "#83",
        "title": "Thinking with Sound: Audio Chain-of-Thought Enables Multimodal Reasoning in Large Audio-Language Models",
        "link": "/arxiv/2509.21749",
        "arxiv_id": "2509.21749",
        "authors": "Zhen Xiong, Yujun Cai, Zhecheng Li, Junsong Yuan, Yiwei Wang",
        "summary": "Recent Large Audio-Language Models (LALMs) have shown strong performance on various audio understanding tasks such as speech translation and Audio Q\\&A. However, they exhibit significant limitations on challenging audio reasoning tasks in complex acoustic scenarios. These situations would greatly benefit from the use of acoustic tools like noise suppression, source separation, and precise temporal alignment, but current LALMs lack access to such tools. To address this limitation, we introduce Thinking-with-Sound (TwS), a framework that equips LALMs with Audio CoT by combining linguistic reasoning with on-the-fly audio-domain analysis. Unlike existing approaches that treat audio as static input, TwS enables models to actively think with audio signals, performing numerical analysis and digital manipulation through multimodal reasoning. To evaluate this approach, we construct MELD-Hard1k, a new robustness benchmark created by introducing various acoustic perturbations. Experiments reveal that state-of-the-art LALMs suffer dramatic performance degradation on MELD-Hard1k, with accuracy dropping by more than $50\\%$ compared to clean audio. TwS achieves substantial improvements in robustness, demonstrating both effectiveness and scalability: small models gain $24.73\\%$ absolute accuracy, with improvements scaling consistently up to $36.61\\%$ for larger models. Our findings demonstrate that Audio CoT can significantly enhance robustness without retraining, opening new directions for developing more robust audio understanding systems.",
        "subjects": "Computation and Language, Sound",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.767091"
    },
    {
        "index": "#84",
        "title": "Self-Speculative Biased Decoding for Faster Live Translation",
        "link": "/arxiv/2509.21740",
        "arxiv_id": "2509.21740",
        "authors": "Linxiao Zeng, Haoyun Deng, Kangyuan Shu, Shizhen Wang",
        "summary": "Large Language Models (LLMs) have recently demonstrated impressive capabilities in various text generation tasks. However, it remains challenging to use them off-the-shelf in streaming applications (such as live translation), where the output must continually update as the input context expands, while still maintaining a reasonable computational cost to meet the latency requirement. In this work, we reexamine the re-translation approach to simultaneous translation and propose Self-Speculative Biased Decoding, a novel inference paradigm designed to avoid repeatedly generating output from scratch for a consistently growing input stream. We propose using the most recent output as a draft for the current growing input context. During the verification stage, the output will be biased towards the draft token for a higher draft acceptance rate. This strategy not only minimizes flickering that might distract users but also leads to higher speedups. Conventional decoding may take charge from the point of divergence after draft verification and continue until the end condition is met. Unlike existing speculative decoding strategies, our approach eliminates the need for draft computations, making it a model-agnostic and plug-and-play solution for accelerating latency-sensitive streaming applications. Experimental results on simultaneous text-to-text re-translation demonstrate that our approach achieves up to 1.7x speedup compared to conventional auto-regressive re-translation without compromising quality. Additionally, it significantly reduces flickering by 80% by incorporating the display-only mask-k technique.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.767424"
    },
    {
        "index": "#85",
        "title": "How Accurate Are LLMs at Multi-Question Answering on Conversational Transcripts?",
        "link": "/arxiv/2509.21732",
        "arxiv_id": "2509.21732",
        "authors": "Xiliang Zhu, Shi Zong, David Rossouw",
        "summary": "Deploying Large Language Models (LLMs) for question answering (QA) over lengthy contexts is a significant challenge. In industrial settings, this process is often hindered by high computational costs and latency, especially when multiple questions must be answered based on the same context. In this work, we explore the capabilities of LLMs to answer multiple questions based on the same conversational context. We conduct extensive experiments and benchmark a range of both proprietary and public models on this challenging task. Our findings highlight that while strong proprietary LLMs like GPT-4o achieve the best overall performance, fine-tuned public LLMs with up to 8 billion parameters can surpass GPT-4o in accuracy, which demonstrates their potential for transparent and cost-effective deployment in real-world applications.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.767710"
    },
    {
        "index": "#86",
        "title": "ProPerSim: Developing Proactive and Personalized AI Assistants through User-Assistant Simulation",
        "link": "/arxiv/2509.21730",
        "arxiv_id": "2509.21730",
        "authors": "Jiho Kim, Junseong Choi, Woosog Chay, Daeun Kyung, Yeonsu Kwon, Yohan Jo, Edward Choi",
        "summary": "As large language models (LLMs) become increasingly integrated into daily life, there is growing demand for AI assistants that are not only reactive but also proactive and personalized. While recent advances have pushed forward proactivity and personalization individually, their combination remains underexplored. To bridge this gap, we introduce ProPerSim, a new task and simulation framework for developing assistants capable of making timely, personalized recommendations in realistic home scenarios. In our simulation environment, a user agent with a rich persona interacts with the assistant, providing ratings on how well each suggestion aligns with its preferences and context. The assistant's goal is to use these ratings to learn and adapt to achieve higher scores over time. Built on ProPerSim, we propose ProPerAssistant, a retrieval-augmented, preference-aligned assistant that continually learns and adapts through user feedback. Experiments across 32 diverse personas show that ProPerAssistant adapts its strategy and steadily improves user satisfaction, highlighting the promise of uniting proactivity and personalization.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.773402"
    },
    {
        "index": "#87",
        "title": "Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval",
        "link": "/arxiv/2509.21710",
        "arxiv_id": "2509.21710",
        "authors": "Xiaojun Wu, Cehao Yang, Xueyuan Lin, Chengjin Xu, Xuhui Jiang, Yuanliang Sun, Hui Xiong, Jia Li, Jian Guo",
        "summary": "Retrieval-Augmented Generation (RAG) and Graph-based RAG has become the important paradigm for enhancing Large Language Models (LLMs) with external knowledge. However, existing approaches face a fundamental trade-off. While graph-based methods are inherently dependent on high-quality graph structures, they face significant practical constraints: manually constructed knowledge graphs are prohibitively expensive to scale, while automatically extracted graphs from corpora are limited by the performance of the underlying LLM extractors, especially when using smaller, local-deployed models. This paper presents Think-on-Graph 3.0 (ToG-3), a novel framework that introduces Multi-Agent Context Evolution and Retrieval (MACER) mechanism to overcome these limitations. Our core innovation is the dynamic construction and refinement of a Chunk-Triplets-Community heterogeneous graph index, which pioneeringly incorporates a dual-evolution mechanism of Evolving Query and Evolving Sub-Graph for precise evidence retrieval. This approach addresses a critical limitation of prior Graph-based RAG methods, which typically construct a static graph index in a single pass without adapting to the actual query. A multi-agent system, comprising Constructor, Retriever, Reflector, and Responser agents, collaboratively engages in an iterative process of evidence retrieval, answer generation, sufficiency reflection, and, crucially, evolving query and subgraph. This dual-evolving multi-agent system allows ToG-3 to adaptively build a targeted graph index during reasoning, mitigating the inherent drawbacks of static, one-time graph construction and enabling deep, precise reasoning even with lightweight LLMs. Extensive experiments demonstrate that ToG-3 outperforms compared baselines on both deep and broad reasoning benchmarks, and ablation studies confirm the efficacy of the components of MACER framework.",
        "subjects": "Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.773963"
    },
    {
        "index": "#88",
        "title": "GRAB: A Risk Taxonomy--Grounded Benchmark for Unsupervised Topic Discovery in Financial Disclosures",
        "link": "/arxiv/2509.21698",
        "arxiv_id": "2509.21698",
        "authors": "Ying Li, Tiejun Ma",
        "summary": "Risk categorization in 10-K risk disclosures matters for oversight and investment, yet no public benchmark evaluates unsupervised topic models for this task. We present GRAB, a finance-specific benchmark with 1.61M sentences from 8,247 filings and span-grounded sentence labels produced without manual annotation by combining FinBERT token attention, YAKE keyphrase signals, and taxonomy-aware collocation matching. Labels are anchored in a risk taxonomy mapping 193 terms to 21 fine-grained types nested under five macro classes; the 21 types guide weak supervision, while evaluation is reported at the macro level. GRAB unifies evaluation with fixed dataset splits and robust metrics--Accuracy, Macro-F1, Topic BERTScore, and the entropy-based Effective Number of Topics. The dataset, labels, and code enable reproducible, standardized comparison across classical, embedding-based, neural, and hybrid topic models on financial disclosures.",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.774406"
    },
    {
        "index": "#89",
        "title": "ReviewScore: Misinformed Peer Review Detection with Large Language Models",
        "link": "/arxiv/2509.21679",
        "arxiv_id": "2509.21679",
        "authors": "Hyun Ryu, Doohyuk Jang, Hyemin S. Lee, Joonhyun Jeong, Gyeongman Kim, Donghyeon Cho, Gyouk Chu, Minyeong Hwang, Hyeongwon Jang, Changhun Kim, Haechan Kim, Jina Kim, Joowon Kim, Yoonjeon Kim, Kwanhyung Lee, Chanjae Park, Heecheol Yun, Gregor Betz, Eunho Yang",
        "summary": "Peer review serves as a backbone of academic research, but in most AI conferences, the review quality is degrading as the number of submissions explodes. To reliably detect low-quality reviews, we define misinformed review points as either \"weaknesses\" in a review that contain incorrect premises, or \"questions\" in a review that can be already answered by the paper. We verify that 15.2% of weaknesses and 26.4% of questions are misinformed and introduce ReviewScore indicating if a review point is misinformed. To evaluate the factuality of each premise of weaknesses, we propose an automated engine that reconstructs every explicit and implicit premise from a weakness. We build a human expert-annotated ReviewScore dataset to check the ability of LLMs to automate ReviewScore evaluation. Then, we measure human-model agreements on ReviewScore using eight current state-of-the-art LLMs and verify moderate agreements. We also prove that evaluating premise-level factuality shows significantly higher agreements than evaluating weakness-level factuality. A thorough disagreement analysis further supports a potential of fully automated ReviewScore evaluation.",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.775089"
    },
    {
        "index": "#90",
        "title": "Towards Transparent AI: A Survey on Explainable Language Models",
        "link": "/arxiv/2509.21631",
        "arxiv_id": "2509.21631",
        "authors": "Avash Palikhe, Zichong Wang, Zhipeng Yin, Rui Guo, Qiang Duan, Jie Yang, Wenbin Zhang",
        "summary": "Language Models (LMs) have significantly advanced natural language processing and enabled remarkable progress across diverse domains, yet their black-box nature raises critical concerns about the interpretability of their internal mechanisms and decision-making processes. This lack of transparency is particularly problematic for adoption in high-stakes domains, where stakeholders need to understand the rationale behind model outputs to ensure accountability. On the other hand, while explainable artificial intelligence (XAI) methods have been well studied for non-LMs, they face many limitations when applied to LMs due to their complex architectures, considerable training corpora, and broad generalization abilities. Although various surveys have examined XAI in the context of LMs, they often fail to capture the distinct challenges arising from the architectural diversity and evolving capabilities of these models. To bridge this gap, this survey presents a comprehensive review of XAI techniques with a particular emphasis on LMs, organizing them according to their underlying transformer architectures: encoder-only, decoder-only, and encoder-decoder, and analyzing how methods are adapted to each while assessing their respective strengths and limitations. Furthermore, we evaluate these techniques through the dual lenses of plausibility and faithfulness, offering a structured perspective on their effectiveness. Finally, we identify open research challenges and outline promising future directions, aiming to guide ongoing efforts toward the development of robust, transparent, and interpretable XAI methods for LMs.",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.775617"
    },
    {
        "index": "#91",
        "title": "OjaKV: Context-Aware Online Low-Rank KV Cache Compression with Oja's Rule",
        "link": "/arxiv/2509.21623",
        "arxiv_id": "2509.21623",
        "authors": "Yuxuan Zhu, David H. Yang, Mohammad Mohammadi Amiri, Keerthiram Murugesan, Tejaswini Pedapati, Pin-Yu Chen",
        "summary": "The expanding long-context capabilities of large language models are constrained by a significant memory bottleneck: the key-value (KV) cache required for autoregressive generation. This bottleneck is substantial; for instance, a Llama-3.1-8B model processing a 32K-token prompt at a batch size of 4 requires approximately 16GB for its KV cache, a size exceeding the model's weights. While KV-cache compression via low-rank projection is a promising direction, existing methods rely on a static, offline-learned subspace that performs poorly under data distribution shifts. To overcome these limitations, we introduce OjaKV, a novel framework that integrates a strategic hybrid storage policy with online subspace adaptation. First, OjaKV recognizes that not all tokens are equally important for compression; it preserves the crucial first and most recent tokens in full-rank, maintaining high-fidelity anchors for attention. Second, for the vast majority of intermediate tokens, it applies low-rank compression by incrementally adapting the projection basis using Oja's algorithm for online principal component analysis. This adaptation involves a comprehensive update during prompt prefilling and lightweight periodic updates during decoding, ensuring the subspace remains aligned with the evolving context. Crucially, our framework is fully compatible with modern attention modules like FlashAttention. Experiments demonstrate that OjaKV maintains or even improves zero-shot accuracy at high compression ratios. In particular, OjaKV achieves its strongest gains on very long-context benchmarks that require complex reasoning, highlighting the importance of online subspace adaptation in dynamically tracking context shifts. These results establish our hybrid framework as a practical, plug-and-play solution for memory-efficient long-context inference without requiring model fine-tuning.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.776212"
    },
    {
        "index": "#93",
        "title": "\"Be My Cheese?\": Assessing Cultural Nuance in Multilingual LLM Translations",
        "link": "/arxiv/2509.21577",
        "arxiv_id": "2509.21577",
        "authors": "Madison Van Doren, Cory Holland",
        "summary": "This pilot study explores the localisation capabilities of state-of-the-art multilingual AI models when translating figurative language, such as idioms and puns, from English into a diverse range of global languages. It expands on existing LLM translation research and industry benchmarks, which emphasise grammatical accuracy and token-level correctness, by focusing on cultural appropriateness and overall localisation quality - critical factors for real-world applications like marketing and e-commerce. To investigate these challenges, this project evaluated a sample of 87 LLM-generated translations of e-commerce marketing emails across 24 regional dialects of 20 languages. Human reviewers fluent in each target language provided quantitative ratings and qualitative feedback on faithfulness to the original's tone, meaning, and intended audience. Findings suggest that, while leading models generally produce grammatically correct translations, culturally nuanced language remains a clear area for improvement, often requiring substantial human refinement. Notably, even high-resource global languages, despite topping industry benchmark leaderboards, frequently mistranslated figurative expressions and wordplay. This work challenges the assumption that data volume is the most reliable predictor of machine translation quality and introduces cultural appropriateness as a key determinant of multilingual LLM performance - an area currently underexplored in existing academic and industry benchmarks. As a proof of concept, this pilot highlights limitations of current multilingual AI systems for real-world localisation use cases. Results of this pilot support the opportunity for expanded research at greater scale to deliver generalisable insights and inform deployment of reliable machine translation workflows in culturally diverse contexts.",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.777192"
    },
    {
        "index": "#94",
        "title": "Vision Language Models Cannot Plan, but Can They Formalize?",
        "link": "/arxiv/2509.21576",
        "arxiv_id": "2509.21576",
        "authors": "Muyu He, Yuxi Zheng, Yuchen Liu, Zijian An, Bill Cai, Jiani Huang, Lifeng Zhou, Feng Liu, Ziyang Li, Li Zhang",
        "summary": "The advancement of vision language models (VLMs) has empowered embodied agents to accomplish simple multimodal planning tasks, but not long-horizon ones requiring long sequences of actions. In text-only simulations, long-horizon planning has seen significant improvement brought by repositioning the role of LLMs. Instead of directly generating action sequences, LLMs translate the planning domain and problem into a formal planning language like the Planning Domain Definition Language (PDDL), which can call a formal solver to derive the plan in a verifiable manner. In multimodal environments, research on VLM-as-formalizer remains scarce, usually involving gross simplifications such as predefined object vocabulary or overly similar few-shot examples. In this work, we present a suite of five VLM-as-formalizer pipelines that tackle one-shot, open-vocabulary, and multimodal PDDL formalization. We evaluate those on an existing benchmark while presenting another two that for the first time account for planning with authentic, multi-view, and low-quality images. We conclude that VLM-as-formalizer greatly outperforms end-to-end plan generation. We reveal the bottleneck to be vision rather than language, as VLMs often fail to capture an exhaustive set of necessary object relations. While generating intermediate, textual representations such as captions or scene graphs partially compensate for the performance, their inconsistent gain leaves headroom for future research directions on multimodal planning formalization.",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.777761"
    },
    {
        "index": "#95",
        "title": "Comparative Personalization for Multi-document Summarization",
        "link": "/arxiv/2509.21562",
        "arxiv_id": "2509.21562",
        "authors": "Haoyuan Li, Snigdha Chaturvedi",
        "summary": "Personalized multi-document summarization (MDS) is essential for meeting individual user preferences of writing style and content focus for summaries. In this paper, we propose that for effective personalization, it is important to identify fine-grained differences between users' preferences by comparing the given user's preferences with other users' preferences.Motivated by this, we propose ComPSum, a personalized MDS framework. It first generates a structured analysis of a user by comparing their preferences with other users' preferences. The generated structured analysis is then used to guide the generation of personalized summaries. To evaluate the performance of ComPSum, we propose AuthorMap, a fine-grained reference-free evaluation framework for personalized MDS. It evaluates the personalization of a system based on the authorship attribution between two personalized summaries generated for different users. For robust evaluation of personalized MDS, we construct PerMSum, a personalized MDS dataset in the review and news domain. We evaluate the performance of ComPSum on PerMSum using AuthorMap, showing that it outperforms strong baselines.",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.788473"
    },
    {
        "index": "#96",
        "title": "Generation-Time vs. Post-hoc Citation: A Holistic Evaluation of LLM Attribution",
        "link": "/arxiv/2509.21557",
        "arxiv_id": "2509.21557",
        "authors": "Yash Saxena, Raviteja Bommireddy, Ankur Padia, Manas Gaur",
        "summary": "Trustworthy Large Language Models (LLMs) must cite human-verifiable sources in high-stakes domains such as healthcare, law, academia, and finance, where even small errors can have severe consequences. Practitioners and researchers face a choice: let models generate citations during decoding, or let models draft answers first and then attach appropriate citations. To clarify this choice, we introduce two paradigms: Generation-Time Citation (G-Cite), which produces the answer and citations in one pass, and Post-hoc Citation (P-Cite), which adds or verifies citations after drafting. We conduct a comprehensive evaluation from zero-shot to advanced retrieval-augmented methods across four popular attribution datasets and provide evidence-based recommendations that weigh trade-offs across use cases. Our results show a consistent trade-off between coverage and citation correctness, with retrieval as the main driver of attribution quality in both paradigms. P-Cite methods achieve high coverage with competitive correctness and moderate latency, whereas G-Cite methods prioritize precision at the cost of coverage and speed. We recommend a retrieval-centric, P-Cite-first approach for high-stakes applications, reserving G-Cite for precision-critical settings such as strict claim verification. Our codes and human evaluation results are available at https://anonymous.4open.science/r/Citation_Paradigms-BBB5/",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.794410"
    },
    {
        "index": "#97",
        "title": "Domain-Aware Speaker Diarization On African-Accented English",
        "link": "/arxiv/2509.21554",
        "arxiv_id": "2509.21554",
        "authors": "Chibuzor Okocha, Kelechi Ezema, Christan Grant",
        "summary": "This study examines domain effects in speaker diarization for African-accented English. We evaluate multiple production and open systems on general and clinical dialogues under a strict DER protocol that scores overlap. A consistent domain penalty appears for clinical speech and remains significant across models. Error analysis attributes much of this penalty to false alarms and missed detections, aligning with short turns and frequent overlap. We test lightweight domain adaptation by fine-tuning a segmentation module on accent-matched data; it reduces error but does not eliminate the gap. Our contributions include a controlled benchmark across domains, a concise approach to error decomposition and conversation-level profiling, and an adaptation recipe that is easy to reproduce. Results point to overlap-aware segmentation and balanced clinical resources as practical next steps.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.795036"
    },
    {
        "index": "#98",
        "title": "Agribot: agriculture-specific question answer system",
        "link": "/arxiv/2509.21535",
        "arxiv_id": "2509.21535",
        "authors": "Naman Jain, Pranjali Jain, Pratik Kayal, Jayakrishna Sahit, Soham Pachpande, Jayesh Choudhari",
        "summary": "India is an agro-based economy and proper information about agricultural practices is the key to optimal agricultural growth and output. In order to answer the queries of the farmer, we have build an agricultural chatbot based on the dataset from Kisan Call Center. This system is robust enough to answer queries related to weather, market rates, plant protection and government schemes. This system is available 24* 7, can be accessed through any electronic device and the information is delivered with the ease of understanding. The system is based on a sentence embedding model which gives an accuracy of 56%. After eliminating synonyms and incorporating entity extraction, the accuracy jumps to 86%. With such a system, farmers can progress towards easier information about farming related practices and hence a better agricultural output. The job of the Call Center workforce would be made easier and the hard work of various such workers can be redirected to a better goal.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.795740"
    },
    {
        "index": "#99",
        "title": "On Code-Induced Reasoning in LLMs",
        "link": "/arxiv/2509.21499",
        "arxiv_id": "2509.21499",
        "authors": "Abdul Waheed, Zhen Wu, Carolyn Rosé, Daphne Ippolito",
        "summary": "Code data has been shown to enhance the reasoning capabilities of large language models (LLMs), but it remains unclear which aspects of code are most responsible. We investigate this question with a systematic, data-centric framework. We construct parallel instruction datasets in ten programming languages and apply controlled perturbations that selectively disrupt structural or semantic properties of code. We then finetune LLMs from five model families and eight scales on each variant and evaluate their performance on natural language, math, and code tasks. Across 3,331 experiments, our results show that LLMs are more vulnerable to structural perturbations than semantic ones, particularly on math and code tasks. Appropriate abstractions like pseudocode and flowcharts can be as effective as code, while encoding the same information with fewer tokens without adhering to original syntax can often retain or even improve performance. Remarkably, even corrupted code with misleading signals remains competitive when surface-level regularities persist. Finally, syntactic styles also shape task-specific gains with Python favoring natural language reasoning and lower-level languages such as Java and Rust favoring math. Through our systematic framework, we aim to provide insight into how different properties of code influence reasoning and inform the design of training data for enhancing LLM reasoning capabilities.",
        "subjects": "Computation and Language, Programming Languages",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.796362"
    },
    {
        "index": "#100",
        "title": "Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning",
        "link": "/arxiv/2509.21487",
        "arxiv_id": "2509.21487",
        "authors": "Jillian Xu, Dylan Zhou, Vinay Shukla, Yang Yang, Junrui Ruan, Shuhuai Lin, Wenfei Zou, Yinxiao Liu, Karthik Lakshmanan",
        "summary": "Chain-of-Thought (CoT) prompting often improves classification accuracy, but it introduces a significant throughput penalty with rationale generation (Wei et al., 2022; Cheng and Van Durme, 2024). To resolve this trade-off, we introduce Dual-Head Reasoning Distillation (DHRD), a simple training method for decoder-only language models (LMs) that adds (i) a pooled classification head used during training and inference and (ii) a reasoning head supervised by teacher rationales used only in training. We train with a loss function that is a weighted sum of label cross-entropy and token-level LM loss over input-plus-rationale sequences. On seven SuperGLUE tasks, DHRD yields relative gains of 0.65-5.47% over pooled baselines, with notably larger gains on entailment/causal tasks. Since we disable the reasoning head at test time, inference throughput matches pooled classifiers and exceeds CoT decoding on the same backbones by 96-142 times in QPS.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.797073"
    },
    {
        "index": "#101",
        "title": "Learning to Reason with Mixture of Tokens",
        "link": "/arxiv/2509.21482",
        "arxiv_id": "2509.21482",
        "authors": "Adit Jain, Brendan Rappazzo",
        "summary": "Reinforcement learning with verifiable rewards (RLVR) has become a leading approach for improving large language model (LLM) reasoning capabilities. Most current methods follow variants of Group Relative Policy Optimization, which samples multiple reasoning completions, scores them relative to each other, and adjusts the policy accordingly. However, these approaches invariably sample discrete tokens at each reasoning step, discarding the rich distributional information in the model's probability distribution over candidate tokens. While preserving and utilizing this distributional information has proven beneficial in non-RL settings, current RLVR methods seem to be unnecessarily constraining the reasoning search space by not using this information. To address this limitation, we investigate mixture-of-token generation (MoT-G) in RLVR. We present a unified framework that generalizes existing MoT-G approaches, including existing training-free methods that construct mixture embeddings as weighted sums over token embeddings, and extend RLVR to operate directly in this continuous mixture space for generating chain-of-thought. Evaluating two MoT-G variants on Reasoning-Gym, a suite of reasoning-intensive language tasks, we find that MoT--G methods achieve substantial improvements (5--35 \\% gains on 7 out of 10 tasks) compared to standard decoding with the Qwen2.5-1.5B model, while reaching comparable accuracy with half the number of trajectories, suggesting improved training efficiency. Through comprehensive hidden-state and token-level analyses, we provide evidence that MoT--G's benefits may stem from its ability to maintain higher hidden-state entropy throughout the reasoning process and promote exploration in token space.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.797697"
    },
    {
        "index": "#102",
        "title": "A State-of-the-Art SQL Reasoning Model using RLVR",
        "link": "/arxiv/2509.21459",
        "arxiv_id": "2509.21459",
        "authors": "Alnur Ali, Ashutosh Baheti, Jonathan Chang, Ta-Chung Chi, Brandon Cui, Andrew Drozdov, Jonathan Frankle, Abhay Gupta, Pallavi Koppol, Sean Kulinski, Jonathan Li, Dipendra Misra, Krista Opsahl-Ong, Jose Javier Gonzalez Ortiz, Matei Zaharia, Yue Zhang",
        "summary": "Developing custom reasoning models via Reinforcement Learning (RL) that can incorporate organization-specific knowledge has great potential to address problems faced by enterprise customers. In many of these problems, the reward function is verifiable, a setting termed RL with Verifiable Rewards (RLVR). We apply RLVR to a popular data science benchmark called BIRD that measures the ability of an AI agent to convert a natural language query for a database to SQL executions. We apply a simple and general-purpose training recipe involving careful prompt and model selection, a warm-up stage using our offline RL approach called TAO, followed by rigorous online RLVR training. With no additional training data beyond the BIRD training set and no use of proprietary models, our very first submission to the BIRD leaderboard reached state-of-the-art accuracy on the private test set: 73.56% without self-consistency and 75.68% with self-consistency. In the latter case, our model also required fewer generations than the second-best approach. While BIRD is only a proxy task, the simplicity of our framework makes it broadly applicable to enterprise domains such as business intelligence, data science, and coding.",
        "subjects": "Computation and Language, Artificial Intelligence, Databases, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.798589"
    },
    {
        "index": "#103",
        "title": "Diagnosing the Performance Trade-off in Moral Alignment: A Case Study on Gender Stereotypes",
        "link": "/arxiv/2509.21456",
        "arxiv_id": "2509.21456",
        "authors": "Guangliang Liu, Bocheng Chen, Xitong Zhang, Kristen Marie Johnson",
        "summary": "Moral alignment has emerged as a widely adopted approach for regulating the behavior of pretrained language models (PLMs), typically through fine-tuning or model editing on curated datasets. However, this process often comes at the cost of degraded downstream task performance. Prior studies commonly aim to achieve a performance trade-off by encouraging PLMs to selectively forget stereotypical knowledge through carefully designed fairness objectives, while preserving their helpfulness. In this short paper, we investigate the underlying mechanisms of the performance trade-off in the context of mitigating gender stereotypes, through the lens of forgetting and the fairness objective. Our analysis reveals the limitations of current fairness objective in achieving trade-off by demonstrating that: (1) downstream task performance is primarily driven by the overall forgetting level; (2) selective forgetting of stereotypes tends to increase overall forgetting; and (3) general solutions for mitigating forgetting are ineffective at reducing overall forgetting and fail to improve downstream task performance.",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.829828"
    },
    {
        "index": "#104",
        "title": "LLM-Based Support for Diabetes Diagnosis: Opportunities, Scenarios, and Challenges with GPT-5",
        "link": "/arxiv/2509.21450",
        "arxiv_id": "2509.21450",
        "authors": "Gaurav Kumar Gupta, Nirajan Acharya, Pranal Pande",
        "summary": "Diabetes mellitus is a major global health challenge, affecting over half a billion adults worldwide with prevalence projected to rise. Although the American Diabetes Association (ADA) provides clear diagnostic thresholds, early recognition remains difficult due to vague symptoms, borderline laboratory values, gestational complexity, and the demands of long-term monitoring. Advances in large language models (LLMs) offer opportunities to enhance decision support through structured, interpretable, and patient-friendly outputs. This study evaluates GPT-5, the latest generative pre-trained transformer, using a simulation framework built entirely on synthetic cases aligned with ADA Standards of Care 2025 and inspired by public datasets including NHANES, Pima Indians, EyePACS, and MIMIC-IV. Five representative scenarios were tested: symptom recognition, laboratory interpretation, gestational diabetes screening, remote monitoring, and multimodal complication detection. For each, GPT-5 classified cases, generated clinical rationales, produced patient explanations, and output structured JSON summaries. Results showed strong alignment with ADA-defined criteria, suggesting GPT-5 may function as a dual-purpose tool for clinicians and patients, while underscoring the importance of reproducible evaluation frameworks for responsibly assessing LLMs in healthcare.",
        "subjects": "Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.830636"
    },
    {
        "index": "#105",
        "title": "One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning",
        "link": "/arxiv/2509.21443",
        "arxiv_id": "2509.21443",
        "authors": "Sualeha Farid, Jayden Lin, Zean Chen, Shivani Kumar, David Jurgens",
        "summary": "Large Language Models (LLMs) are increasingly deployed in multilingual and multicultural environments where moral reasoning is essential for generating ethically appropriate responses. Yet, the dominant pretraining of LLMs on English-language data raises critical concerns about their ability to generalize judgments across diverse linguistic and cultural contexts. In this work, we systematically investigate how language mediates moral decision-making in LLMs. We translate two established moral reasoning benchmarks into five culturally and typologically diverse languages, enabling multilingual zero-shot evaluation. Our analysis reveals significant inconsistencies in LLMs' moral judgments across languages, often reflecting cultural misalignment. Through a combination of carefully constructed research questions, we uncover the underlying drivers of these disparities, ranging from disagreements to reasoning strategies employed by LLMs. Finally, through a case study, we link the role of pretraining data in shaping an LLM's moral compass. Through this work, we distill our insights into a structured typology of moral reasoning errors that calls for more culturally-aware AI.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.831303"
    },
    {
        "index": "#106",
        "title": "How Large Language Models Need Symbolism",
        "link": "/arxiv/2509.21404",
        "arxiv_id": "2509.21404",
        "authors": "Xiaotie Deng, Hanyu Li",
        "summary": "We argue that AI's future requires more than scaling. To unlock genuine discovery, large language models need a compass: human-crafted symbols to guide their powerful but blind intuition.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-24",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.831930"
    },
    {
        "index": "#107",
        "title": "Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs",
        "link": "/arxiv/2509.21361",
        "arxiv_id": "2509.21361",
        "authors": "Norman Paulsen",
        "summary": "Large language model (LLM) providers boast big numbers for maximum context window sizes. To test the real world use of context windows, we 1) define a concept of maximum effective context window, 2) formulate a testing method of a context window's effectiveness over various sizes and problem types, and 3) create a standardized way to compare model efficacy for increasingly larger context window sizes to find the point of failure. We collected hundreds of thousands of data points across several models and found significant differences between reported Maximum Context Window (MCW) size and Maximum Effective Context Window (MECW) size. Our findings show that the MECW is, not only, drastically different from the MCW but also shifts based on the problem type. A few top of the line models in our test group failed with as little as 100 tokens in context; most had severe degradation in accuracy by 1000 tokens in context. All models fell far short of their Maximum Context Window by as much as 99 percent. Our data reveals the Maximum Effective Context Window shifts based on the type of problem provided, offering clear and actionable insights into how to improve model accuracy and decrease model hallucination rates.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-21",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.832508"
    },
    {
        "index": "#108",
        "title": "Influence Guided Context Selection for Effective Retrieval-Augmented Generation",
        "link": "/arxiv/2509.21359",
        "arxiv_id": "2509.21359",
        "authors": "Jiale Deng, Yanyan Shen, Ziyuan Pei, Youmin Chen, Linpeng Huang",
        "summary": "Retrieval-Augmented Generation (RAG) addresses large language model (LLM) hallucinations by grounding responses in external knowledge, but its effectiveness is compromised by poor-quality retrieved contexts containing irrelevant or noisy information. While existing approaches attempt to improve performance through context selection based on predefined context quality assessment metrics, they show limited gains over standard RAG. We attribute this limitation to their failure in holistically utilizing available information (query, context list, and generator) for comprehensive quality assessment. Inspired by recent advances in data selection, we reconceptualize context quality assessment as an inference-time data valuation problem and introduce the Contextual Influence Value (CI value). This novel metric quantifies context quality by measuring the performance degradation when removing each context from the list, effectively integrating query-aware relevance, list-aware uniqueness, and generator-aware alignment. Moreover, CI value eliminates complex selection hyperparameter tuning by simply retaining contexts with positive CI values. To address practical challenges of label dependency and computational overhead, we develop a parameterized surrogate model for CI value prediction during inference. The model employs a hierarchical architecture that captures both local query-context relevance and global inter-context interactions, trained through oracle CI value supervision and end-to-end generator feedback. Extensive experiments across 8 NLP tasks and multiple LLMs demonstrate that our context selection method significantly outperforms state-of-the-art baselines, effectively filtering poor-quality contexts while preserving critical information. Code is available at https://github.com/SJTU-DMTai/RAG-CSM.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-21",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.833175"
    },
    {
        "index": "#109",
        "title": "A Novel Differential Feature Learning for Effective Hallucination Detection and Classification",
        "link": "/arxiv/2509.21357",
        "arxiv_id": "2509.21357",
        "authors": "Wenkai Wang, Vincent Lee, Yizhen Zheng",
        "summary": "Large language model hallucination represents a critical challenge where outputs deviate from factual accuracy due to distributional biases in training data. While recent investigations establish that specific hidden layers exhibit differences between hallucinatory and factual content, the precise localization of hallucination signals within layers remains unclear, limiting the development of efficient detection methods. We propose a dual-model architecture integrating a Projected Fusion (PF) block for adaptive inter-layer feature weighting and a Differential Feature Learning (DFL) mechanism that identifies discriminative features by computing differences between parallel encoders learning complementary representations from identical inputs. Through systematic experiments across HaluEval's question answering, dialogue, and summarization datasets, we demonstrate that hallucination signals concentrate in highly sparse feature subsets, achieving significant accuracy improvements on question answering and dialogue tasks. Notably, our analysis reveals a hierarchical \"funnel pattern\" where shallow layers exhibit high feature diversity while deep layers demonstrate concentrated usage, enabling detection performance to be maintained with minimal degradation using only 1\\% of feature dimensions. These findings suggest that hallucination signals are more concentrated than previously assumed, offering a pathway toward computationally efficient detection systems that could reduce inference costs while maintaining accuracy.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-09-20",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.833793"
    },
    {
        "index": "#113",
        "title": "Towards Efficient Online Exploration for Reinforcement Learning with Human Feedback",
        "link": "/arxiv/2509.22633",
        "arxiv_id": "2509.22633",
        "authors": "Gen Li, Yuling Yan",
        "summary": "Reinforcement learning with human feedback (RLHF), which learns a reward model from human preference data and then optimizes a policy to favor preferred responses, has emerged as a central paradigm for aligning large language models (LLMs) with human preferences. In this paper, we investigate exploration principles for online RLHF, where one seeks to adaptively collect new preference data to refine both the reward model and the policy in a data-efficient manner. By examining existing optimism-based exploration algorithms, we identify a drawback in their sampling protocol: they tend to gather comparisons that fail to reduce the most informative uncertainties in reward differences, and we prove lower bounds showing that such methods can incur linear regret over exponentially long horizons. Motivated by this insight, we propose a new exploration scheme that directs preference queries toward reducing uncertainty in reward differences most relevant to policy improvement. Under a multi-armed bandit model of RLHF, we establish regret bounds of order $T^{(\\beta+1)/(\\beta+2)}$, where $\\beta>0$ is a hyperparameter that balances reward maximization against mitigating distribution shift. To our knowledge, this is the first online RLHF algorithm with regret scaling polynomially in all model parameters.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language, Machine Learning, Statistics Theory",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.841631"
    },
    {
        "index": "#115",
        "title": "IA2: Alignment with ICL Activations Improves Supervised Fine-Tuning",
        "link": "/arxiv/2509.22621",
        "arxiv_id": "2509.22621",
        "authors": "Aayush Mishra, Daniel Khashabi, Anqi Liu",
        "summary": "Supervised Fine-Tuning (SFT) is used to specialize model behavior by training weights to produce intended target responses for queries. In contrast, In-Context Learning (ICL) adapts models during inference with instructions or demonstrations in the prompt. ICL can offer better generalizability and more calibrated responses compared to SFT in data scarce settings, at the cost of more inference compute. In this work, we ask the question: Can ICL's internal computations be used to improve the qualities of SFT? We first show that ICL and SFT produce distinct activation patterns, indicating that the two methods achieve adaptation through different functional mechanisms. Motivated by this observation and to use ICL's rich functionality, we introduce ICL Activation Alignment (IA2), a self-distillation technique which aims to replicate ICL's activation patterns in SFT models and incentivizes ICL-like internal reasoning. Performing IA2 as a priming step before SFT significantly improves the accuracy and calibration of model outputs, as shown by our extensive empirical results on 12 popular benchmarks and 2 model families. This finding is not only practically useful, but also offers a conceptual window into the inner mechanics of model adaptation.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.842724"
    },
    {
        "index": "#118",
        "title": "EPO: Entropy-regularized Policy Optimization for LLM Agents Reinforcement Learning",
        "link": "/arxiv/2509.22576",
        "arxiv_id": "2509.22576",
        "authors": "Xu Wujiang, Wentian Zhao, Zhenting Wang, Li Yu-Jhe, Jin Can, Jin Mingyu, Mei Kai, Wan Kun, Metaxas Dimitris",
        "summary": "Training LLM agents in multi-turn environments with sparse rewards, where completing a single task requires 30+ turns of interaction within an episode, presents a fundamental challenge for reinforcement learning. We identify a critical failure mode unique to this setting: the exploration-exploitation cascade failure. This cascade begins with early-stage policy premature convergence, where sparse feedback causes agents to commit to flawed, low-entropy strategies. Subsequently, agents enter late-stage policy collapse, where conventional entropy regularization becomes counterproductive, promoting chaotic exploration that destabilizes training. We propose Entropy-regularized Policy Optimization (EPO), a general framework that breaks this failure cycle through three synergistic mechanisms: (1) adopting entropy regularization in multi-turn settings to enhance exploration, (2) an entropy smoothing regularizer that bounds policy entropy within historical averages to prevent abrupt fluctuations, and (3) adaptive phase-based weighting that balances exploration and exploitation across training. Our analysis justifies that EPO guarantees monotonically decreasing entropy variance while maintaining convergence. EPO achieves up to 152% performance improvement on ScienceWorld and up to 19.8% on ALFWorld. Our work demonstrates that multi-turn sparse-reward settings require fundamentally different entropy control than traditional RL, with broad implications for LLM agent training.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.844607"
    },
    {
        "index": "#119",
        "title": "Dynamic Experts Search: Enhancing Reasoning in Mixture-of-Experts LLMs at Test Time",
        "link": "/arxiv/2509.22572",
        "arxiv_id": "2509.22572",
        "authors": "Yixuan Han, Fan Ma, Ruijie Quan, Yi Yang",
        "summary": "Test-Time Scaling (TTS) enhances the reasoning ability of large language models (LLMs) by allocating additional computation during inference. However, existing approaches primarily rely on output-level sampling while overlooking the role of model architecture. In mainstream Mixture-of-Experts (MoE) LLMs, we observe that varying the number of activated experts yields complementary solution sets with stable accuracy, revealing a new and underexplored source of diversity. Motivated by this observation, we propose Dynamic Experts Search (DES), a TTS strategy that elevates expert activation into a controllable dimension of the search space. DES integrates two key components: (1) Dynamic MoE, which enables direct control of expert counts during inference to generate diverse reasoning trajectories without additional cost; and (2) Expert Configuration Inheritance, which preserves consistent expert counts within a reasoning path while varying them across runs, thereby balancing stability and diversity throughout the search. Extensive experiments across MoE architectures, verifiers and reasoning benchmarks (i.e., math, code and knowledge) demonstrate that DES reliably outperforms TTS baselines, enhancing accuracy and stability without additional cost. These results highlight DES as a practical and scalable form of architecture-aware TTS, illustrating how structural flexibility in modern LLMs can advance reasoning.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.850280"
    },
    {
        "index": "#120",
        "title": "Does AI Coaching Prepare us for Workplace Negotiations?",
        "link": "/arxiv/2509.22545",
        "arxiv_id": "2509.22545",
        "authors": "Veda Duddu, Jash Rajesh Parekh, Andy Mao, Hanyi Min, Ziang Xiao, Vedant Das Swain, Koustuv Saha",
        "summary": "Workplace negotiations are undermined by psychological barriers, which can even derail well-prepared tactics. AI offers personalized and always -- available negotiation coaching, yet its effectiveness for negotiation preparedness remains unclear. We built Trucey, a prototype AI coach grounded in Brett's negotiation model. We conducted a between-subjects experiment (N=267), comparing Trucey, ChatGPT, and a traditional negotiation Handbook, followed by in-depth interviews (N=15). While Trucey showed the strongest reductions in fear relative to both comparison conditions, the Handbook outperformed both AIs in usability and psychological empowerment. Interviews revealed that the Handbook's comprehensive, reviewable content was crucial for participants' confidence and preparedness. In contrast, although participants valued AI's rehearsal capability, its guidance often felt verbose and fragmented -- delivered in bits and pieces that required additional effort -- leaving them uncertain or overwhelmed. These findings challenge assumptions of AI superiority and motivate hybrid designs that integrate structured, theory-driven content with targeted rehearsal, clear boundaries, and adaptive scaffolds to address psychological barriers and support negotiation preparedness.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Computation and Language, Computers and Society",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.850886"
    },
    {
        "index": "#121",
        "title": "Mental Health Impacts of AI Companions: Triangulating Social Media Quasi-Experiments, User Perspectives, and Relational Theory",
        "link": "/arxiv/2509.22505",
        "arxiv_id": "2509.22505",
        "authors": "Yunhao Yuan, Jiaxun Zhang, Talayeh Aledavood, Renwen Zhang, Koustuv Saha",
        "summary": "AI-powered companion chatbots (AICCs) such as Replika are increasingly popular, offering empathetic interactions, yet their psychosocial impacts remain unclear. We examined how engaging with AICCs shaped wellbeing and how users perceived these experiences. First, we conducted a large-scale quasi-experimental study of longitudinal Reddit data, applying stratified propensity score matching and Difference-in-Differences regression. Findings revealed mixed effects -- greater affective and grief expression, readability, and interpersonal focus, alongside increases in language about loneliness and suicidal ideation. Second, we complemented these results with 15 semi-structured interviews, which we thematically analyzed and contextualized using Knapp's relationship development model. We identified trajectories of initiation, escalation, and bonding, wherein AICCs provided emotional validation and social rehearsal but also carried risks of over-reliance and withdrawal. Triangulating across methods, we offer design implications for AI companions that scaffold healthy boundaries, support mindful engagement, support disclosure without dependency, and surface relationship stages -- maximizing psychosocial benefits while mitigating risks.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Computation and Language, Computers and Society, Applications",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.851456"
    },
    {
        "index": "#122",
        "title": "IIET: Efficient Numerical Transformer via Implicit Iterative Euler Method",
        "link": "/arxiv/2509.22463",
        "arxiv_id": "2509.22463",
        "authors": "Xinyu Liu, Bei Li, Jiahao Liu, Junhao Ruan, Kechen Jiao, Hongyin Tang, Jingang Wang, Xiao Tong, Jingbo Zhu",
        "summary": "High-order numerical methods enhance Transformer performance in tasks like NLP and CV, but introduce a performance-efficiency trade-off due to increased computational overhead. Our analysis reveals that conventional efficiency techniques, such as distillation, can be detrimental to the performance of these models, exemplified by PCformer. To explore more optimizable ODE-based Transformer architectures, we propose the \\textbf{I}terative \\textbf{I}mplicit \\textbf{E}uler \\textbf{T}ransformer \\textbf{(IIET)}, which simplifies high-order methods using an iterative implicit Euler approach. This simplification not only leads to superior performance but also facilitates model compression compared to PCformer. To enhance inference efficiency, we introduce \\textbf{I}teration \\textbf{I}nfluence-\\textbf{A}ware \\textbf{D}istillation \\textbf{(IIAD)}. Through a flexible threshold, IIAD allows users to effectively balance the performance-efficiency trade-off. On lm-evaluation-harness, IIET boosts average accuracy by 2.65\\% over vanilla Transformers and 0.8\\% over PCformer. Its efficient variant, E-IIET, significantly cuts inference overhead by 55\\% while retaining 99.4\\% of the original task accuracy. Moreover, the most efficient IIET variant achieves an average performance gain exceeding 1.6\\% over vanilla Transformer with comparable speed.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.852054"
    },
    {
        "index": "#123",
        "title": "MDAR: A Multi-scene Dynamic Audio Reasoning Benchmark",
        "link": "/arxiv/2509.22461",
        "arxiv_id": "2509.22461",
        "authors": "Hui Li, Changhao Jiang, Hongyu Wang, Ming Zhang, Jiajun Sun, Zhixiong Yang, Yifei Cao, Shihan Dou, Xiaoran Fan, Baoyu Fan, Tao Ji, Tao Gui, Qi Zhang, Xuanjing Huang",
        "summary": "The ability to reason from audio, including speech, paralinguistic cues, environmental sounds, and music, is essential for AI agents to interact effectively in real-world scenarios. Existing benchmarks mainly focus on static or single-scene settings and do not fully capture scenarios where multiple speakers, unfolding events, and heterogeneous audio sources interact. To address these challenges, we introduce MDAR, a benchmark for evaluating models on complex, multi-scene, and dynamically evolving audio reasoning tasks. MDAR comprises 3,000 carefully curated question-answer pairs linked to diverse audio clips, covering five categories of complex reasoning and spanning three question types. We benchmark 26 state-of-the-art audio language models on MDAR and observe that they exhibit limitations in complex reasoning tasks. On single-choice questions, Qwen2.5-Omni (open-source) achieves 76.67% accuracy, whereas GPT-4o Audio (closed-source) reaches 68.47%; however, GPT-4o Audio substantially outperforms Qwen2.5-Omni on the more challenging multiple-choice and open-ended tasks. Across all three question types, no model achieves 80% performance. These findings underscore the unique challenges posed by MDAR and its value as a benchmark for advancing audio reasoning research.Code and benchmark can be found at https://github.com/luckyerr/MDAR.",
        "subjects": "Sound, Artificial Intelligence, Computation and Language, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.852752"
    },
    {
        "index": "#124",
        "title": "Bridging Kolmogorov Complexity and Deep Learning: Asymptotically Optimal Description Length Objectives for Transformers",
        "link": "/arxiv/2509.22445",
        "arxiv_id": "2509.22445",
        "authors": "Peter Shaw, James Cohan, Jacob Eisenstein, Kristina Toutanova",
        "summary": "The Minimum Description Length (MDL) principle offers a formal framework for applying Occam's razor in machine learning. However, its application to neural networks such as Transformers is challenging due to the lack of a principled, universal measure for model complexity. This paper introduces the theoretical notion of asymptotically optimal description length objectives, grounded in the theory of Kolmogorov complexity. We establish that a minimizer of such an objective achieves optimal compression, for any dataset, up to an additive constant, in the limit as model resource bounds increase. We prove that asymptotically optimal objectives exist for Transformers, building on a new demonstration of their computational universality. We further show that such objectives can be tractable and differentiable by constructing and analyzing a variational objective based on an adaptive Gaussian mixture prior. Our empirical analysis shows that this variational objective selects for a low-complexity solution with strong generalization on an algorithmic task, but standard optimizers fail to find such solutions from a random initialization, highlighting key optimization challenges. More broadly, by providing a theoretical framework for identifying description length objectives with strong asymptotic guarantees, we outline a potential path towards training neural networks that achieve greater compression and generalization.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.853274"
    },
    {
        "index": "#125",
        "title": "Can Synthetic Query Rewrites Capture User Intent Better than Humans in Retrieval-Augmented Generation?",
        "link": "/arxiv/2509.22325",
        "arxiv_id": "2509.22325",
        "authors": "JiaYing Zheng, HaiNan Zhang, Liang Pang, YongXin Tong, ZhiMing Zheng",
        "summary": "Multi-turn RAG systems often face queries with colloquial omissions and ambiguous references, posing significant challenges for effective retrieval and generation. Traditional query rewriting relies on human annotators to clarify queries, but due to limitations in annotators' expressive ability and depth of understanding, manually rewritten queries often diverge from those needed in real-world RAG systems, resulting in a gap between user intent and system response. We observe that high-quality synthetic queries can better bridge this gap, achieving superior performance in both retrieval and generation compared to human rewrites. This raises an interesting question: Can rewriting models trained on synthetic queries better capture user intent than human annotators? In this paper, we propose SynRewrite, a synthetic data-driven query rewriting model to generate high-quality synthetic rewrites more aligned with user intent. To construct training data, we prompt GPT-4o with dialogue history, current queries, positive documents, and answers to synthesize high-quality rewrites. A Flan-T5 model is then finetuned on this dataset to map dialogue history and queries to synthetic rewrites. Finally, we further enhance the rewriter using the generator's feedback through the DPO algorithm to boost end-task performance. Experiments on TopiOCQA and QRECC datasets show that SynRewrite consistently outperforms human rewrites in both retrieval and generation tasks. Our results demonstrate that synthetic rewrites can serve as a scalable and effective alternative to human annotations.",
        "subjects": "Information Retrieval, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.853802"
    },
    {
        "index": "#126",
        "title": "PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning",
        "link": "/arxiv/2509.22315",
        "arxiv_id": "2509.22315",
        "authors": "Hieu Tran, Zonghai Yao, Nguyen Luong Tran, Zhichao Yang, Feiyun Ouyang, Shuo Han, Razieh Rahimi, Hong Yu",
        "summary": "Inspired by the dual-process theory of human cognition from \\textit{Thinking, Fast and Slow}, we introduce \\textbf{PRIME} (Planning and Retrieval-Integrated Memory for Enhanced Reasoning), a multi-agent reasoning framework that dynamically integrates \\textbf{System 1} (fast, intuitive thinking) and \\textbf{System 2} (slow, deliberate thinking). PRIME first employs a Quick Thinking Agent (System 1) to generate a rapid answer; if uncertainty is detected, it then triggers a structured System 2 reasoning pipeline composed of specialized agents for \\textit{planning}, \\textit{hypothesis generation}, \\textit{retrieval}, \\textit{information integration}, and \\textit{decision-making}. This multi-agent design faithfully mimics human cognitive processes and enhances both efficiency and accuracy. Experimental results with LLaMA 3 models demonstrate that PRIME enables open-source LLMs to perform competitively with state-of-the-art closed-source models like GPT-4 and GPT-4o on benchmarks requiring multi-hop and knowledge-grounded reasoning. This research establishes PRIME as a scalable solution for improving LLMs in domains requiring complex, knowledge-intensive reasoning.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.854369"
    },
    {
        "index": "#127",
        "title": "InfiMed-Foundation: Pioneering Advanced Multimodal Medical Models with Compute-Efficient Pre-Training and Multi-Stage Fine-Tuning",
        "link": "/arxiv/2509.22261",
        "arxiv_id": "2509.22261",
        "authors": "Guanghao Zhu, Zhitian Hou, Zeyu Liu, Zhijie Sang, Congkai Xie, Hongxia Yang",
        "summary": "Multimodal large language models (MLLMs) have shown remarkable potential in various domains, yet their application in the medical field is hindered by several challenges. General-purpose MLLMs often lack the specialized knowledge required for medical tasks, leading to uncertain or hallucinatory responses. Knowledge distillation from advanced models struggles to capture domain-specific expertise in radiology and pharmacology. Additionally, the computational cost of continual pretraining with large-scale medical data poses significant efficiency challenges. To address these issues, we propose InfiMed-Foundation-1.7B and InfiMed-Foundation-4B, two medical-specific MLLMs designed to deliver state-of-the-art performance in medical applications. We combined high-quality general-purpose and medical multimodal data and proposed a novel five-dimensional quality assessment framework to curate high-quality multimodal medical datasets. We employ low-to-high image resolution and multimodal sequence packing to enhance training efficiency, enabling the integration of extensive medical data. Furthermore, a three-stage supervised fine-tuning process ensures effective knowledge extraction for complex medical tasks. Evaluated on the MedEvalKit framework, InfiMed-Foundation-1.7B outperforms Qwen2.5VL-3B, while InfiMed-Foundation-4B surpasses HuatuoGPT-V-7B and MedGemma-27B-IT, demonstrating superior performance in medical visual question answering and diagnostic tasks. By addressing key challenges in data quality, training efficiency, and domain-specific knowledge extraction, our work paves the way for more reliable and effective AI-driven solutions in healthcare. InfiMed-Foundation-4B model is available at \\href{https://huggingface.co/InfiX-ai/InfiMed-Foundation-4B}{InfiMed-Foundation-4B}.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.880522"
    },
    {
        "index": "#128",
        "title": "Library Hallucinations in LLMs: Risk Analysis Grounded in Developer Queries",
        "link": "/arxiv/2509.22202",
        "arxiv_id": "2509.22202",
        "authors": "Lukas Twist, Jie M. Zhang, Mark Harman, Helen Yannakoudakis",
        "summary": "Large language models (LLMs) are increasingly used to generate code, yet they continue to hallucinate, often inventing non-existent libraries. Such library hallucinations are not just benign errors: they can mislead developers, break builds, and expose systems to supply chain threats such as slopsquatting. Despite increasing awareness of these risks, little is known about how real-world prompt variations affect hallucination rates. Therefore, we present the first systematic study of how user-level prompt variations impact library hallucinations in LLM-generated code. We evaluate six diverse LLMs across two hallucination types: library name hallucinations (invalid imports) and library member hallucinations (invalid calls from valid libraries). We investigate how realistic user language extracted from developer forums and how user errors of varying degrees (one- or multi-character misspellings and completely fake names/members) affect LLM hallucination rates. Our findings reveal systemic vulnerabilities: one-character misspellings in library names trigger hallucinations in up to 26% of tasks, fake library names are accepted in up to 99% of tasks, and time-related prompts lead to hallucinations in up to 84% of tasks. Prompt engineering shows promise for mitigating hallucinations, but remains inconsistent and LLM-dependent. Our results underscore the fragility of LLMs to natural prompt variation and highlight the urgent need for safeguards against library-related hallucinations and their potential exploitation.",
        "subjects": "Software Engineering, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.881236"
    },
    {
        "index": "#130",
        "title": "SecureAgentBench: Benchmarking Secure Code Generation under Realistic Vulnerability Scenarios",
        "link": "/arxiv/2509.22097",
        "arxiv_id": "2509.22097",
        "authors": "Junkai Chen, Huihui Huang, Yunbo Lyu, Junwen An, Jieke Shi, Chengran Yang, Ting Zhang, Haoye Tian, Yikun Li, Zhenhao Li, Xin Zhou, Xing Hu, David Lo",
        "summary": "Large language model (LLM) powered code agents are rapidly transforming software engineering by automating tasks such as testing, debugging, and repairing, yet the security risks of their generated code have become a critical concern. Existing benchmarks have offered valuable insights but remain insufficient: they often overlook the genuine context in which vulnerabilities were introduced or adopt narrow evaluation protocols that fail to capture either functional correctness or newly introduced vulnerabilities. We therefore introduce SecureAgentBench, a benchmark of 105 coding tasks designed to rigorously evaluate code agents' capabilities in secure code generation. Each task includes (i) realistic task settings that require multi-file edits in large repositories, (ii) aligned contexts based on real-world open-source vulnerabilities with precisely identified introduction points, and (iii) comprehensive evaluation that combines functionality testing, vulnerability checking through proof-of-concept exploits, and detection of newly introduced vulnerabilities using static analysis. We evaluate three representative agents (SWE-agent, OpenHands, and Aider) with three state-of-the-art LLMs (Claude 3.7 Sonnet, GPT-4.1, and DeepSeek-V3.1). Results show that (i) current agents struggle to produce secure code, as even the best-performing one, SWE-agent supported by DeepSeek-V3.1, achieves merely 15.2% correct-and-secure solutions, (ii) some agents produce functionally correct code but still introduce vulnerabilities, including new ones not previously recorded, and (iii) adding explicit security instructions for agents does not significantly improve secure coding, underscoring the need for further research. These findings establish SecureAgentBench as a rigorous benchmark for secure code generation and a step toward more reliable software development with LLMs.",
        "subjects": "Software Engineering, Artificial Intelligence, Computation and Language, Cryptography and Security",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.883816"
    },
    {
        "index": "#131",
        "title": "Speak Your Mind: The Speech Continuation Task as a Probe of Voice-Based Model Bias",
        "link": "/arxiv/2509.22061",
        "arxiv_id": "2509.22061",
        "authors": "Shree Harsha Bokkahalli Satish, Harm Lameris, Olivier Perrotin, Gustav Eje Henter, Éva Székely",
        "summary": "Speech Continuation (SC) is the task of generating a coherent extension of a spoken prompt while preserving both semantic context and speaker identity. Because SC is constrained to a single audio stream, it offers a more direct setting for probing biases in speech foundation models than dialogue does. In this work we present the first systematic evaluation of bias in SC, investigating how gender and phonation type (breathy, creaky, end-creak) affect continuation behaviour. We evaluate three recent models: SpiritLM (base and expressive), VAE-GSLM, and SpeechGPT across speaker similarity, voice quality preservation, and text-based bias metrics. Results show that while both speaker similarity and coherence remain a challenge, textual evaluations reveal significant model and gender interactions: once coherence is sufficiently high (for VAE-GSLM), gender effects emerge on text-metrics such as agency and sentence polarity. In addition, continuations revert toward modal phonation more strongly for female prompts than for male ones, revealing a systematic voice-quality bias. These findings highlight SC as a controlled probe of socially relevant representational biases in speech foundation models, and suggest that it will become an increasingly informative diagnostic as continuation quality improves.",
        "subjects": "Audio and Speech Processing, Computation and Language, Sound",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.884499"
    },
    {
        "index": "#132",
        "title": "A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning",
        "link": "/arxiv/2509.22044",
        "arxiv_id": "2509.22044",
        "authors": "Ziqi Wang, Boye Niu, Zhongli Li, Linghui Meng, Jing Liu, Zhi Zheng, Tong Xu, Hua Wu, Haifeng Wang, Enhong Chen",
        "summary": "Recent Large Reasoning Models have achieved significant improvements in complex task-solving capabilities by allocating more computation at the inference stage with a \"thinking longer\" paradigm. Even as the foundational reasoning capabilities of models advance rapidly, the persistent gap between a model's performance in a single attempt and its latent potential, often revealed only across multiple solution paths, starkly highlights the disparity between its realized and inherent capabilities. To address this, we present A2R, an Asymmetric Two-Stage Reasoning framework designed to explicitly bridge the gap between a model's potential and its actual performance. In this framework, an \"explorer\" model first generates potential solutions in parallel through repeated sampling. Subsequently,a \"synthesizer\" model integrates these references for a more refined, second stage of reasoning. This two-stage process allows computation to be scaled orthogonally to existing sequential methods. Our work makes two key innovations: First, we present A2R as a plug-and-play parallel reasoning framework that explicitly enhances a model's capabilities on complex questions. For example, using our framework, the Qwen3-8B-distill model achieves a 75% performance improvement compared to its self-consistency baseline. Second, through a systematic analysis of the explorer and synthesizer roles, we identify an effective asymmetric scaling paradigm. This insight leads to A2R-Efficient, a \"small-to-big\" variant that combines a Qwen3-4B explorer with a Qwen3-8B synthesizer. This configuration surpasses the average performance of a monolithic Qwen3-32B model at a nearly 30% lower cost. Collectively, these results show that A2R is not only a performance-boosting framework but also an efficient and practical solution for real-world applications.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.885259"
    },
    {
        "index": "#133",
        "title": "The Thinking Spectrum: An Emperical Study of Tunable Reasoning in LLMs through Model Merging",
        "link": "/arxiv/2509.22034",
        "arxiv_id": "2509.22034",
        "authors": "Xiaochong Lan, Yu Zheng, Shiteng Cao, Yong Li",
        "summary": "The growing demand for large language models (LLMs) with tunable reasoning capabilities in many real-world applications highlights a critical need for methods that can efficiently produce a spectrum of models balancing reasoning depth and computational cost. Model merging has emerged as a promising, training-free technique to address this challenge by arithmetically combining the weights of a general-purpose model with a specialized reasoning model. While various merging techniques exist, their potential to create a spectrum of models with fine-grained control over reasoning abilities remains largely unexplored. This work presents a large-scale empirical study evaluating a range of model merging techniques across multiple reasoning benchmarks. We systematically vary merging strengths to construct accuracy-efficiency curves, providing the first comprehensive view of the tunable performance landscape. Our findings reveal that model merging offers an effective and controllable method for calibrating the trade-off between reasoning accuracy and token efficiency, even when parent models have highly divergent weight spaces. Crucially, we identify instances of Pareto Improvement, where a merged model achieves both higher accuracy and lower token consumption than one of its parents. Our study provides the first comprehensive analysis of this tunable space, offering practical guidelines for creating LLMs with specific reasoning profiles to meet diverse application demands.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.937023"
    },
    {
        "index": "#136",
        "title": "RISK: A Framework for GUI Agents in E-commerce Risk Management",
        "link": "/arxiv/2509.21982",
        "arxiv_id": "2509.21982",
        "authors": "Renqi Chen, Zeyin Tao, Jianming Guo, Jingzhe Zhu, Yiheng Peng, Qingqing Sun, Tianyi Zhang, Shuai Chen",
        "summary": "E-commerce risk management requires aggregating diverse, deeply embedded web data through multi-step, stateful interactions, which traditional scraping methods and most existing Graphical User Interface (GUI) agents cannot handle. These agents are typically limited to single-step tasks and lack the ability to manage dynamic, interactive content critical for effective risk assessment. To address this challenge, we introduce RISK, a novel framework designed to build and deploy GUI agents for this domain. RISK integrates three components: (1) RISK-Data, a dataset of 8,492 single-step and 2,386 multi-step interaction trajectories, collected through a high-fidelity browser framework and a meticulous data curation process; (2) RISK-Bench, a benchmark with 802 single-step and 320 multi-step trajectories across three difficulty levels for standardized evaluation; and (3) RISK-R1, a R1-style reinforcement fine-tuning framework considering four aspects: (i) Output Format: Updated format reward to enhance output syntactic correctness and task comprehension, (ii) Single-step Level: Stepwise accuracy reward to provide granular feedback during early training stages, (iii) Multi-step Level: Process reweight to emphasize critical later steps in interaction sequences, and (iv) Task Level: Level reweight to focus on tasks of varying difficulty. Experiments show that RISK-R1 outperforms existing baselines, achieving a 6.8% improvement in offline single-step and an 8.8% improvement in offline multi-step. Moreover, it attains a top task success rate of 70.5% in online evaluation. RISK provides a scalable, domain-specific solution for automating complex web interactions, advancing the state of the art in e-commerce risk management.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.939234"
    },
    {
        "index": "#137",
        "title": "Evaluating Open-Source Large Language Models for Technical Telecom Question Answering",
        "link": "/arxiv/2509.21949",
        "arxiv_id": "2509.21949",
        "authors": "Arina Caraus, Alessio Buscemi, Sumit Kumar, Ion Turcanu",
        "summary": "Large Language Models (LLMs) have shown remarkable capabilities across various fields. However, their performance in technical domains such as telecommunications remains underexplored. This paper evaluates two open-source LLMs, Gemma 3 27B and DeepSeek R1 32B, on factual and reasoning-based questions derived from advanced wireless communications material. We construct a benchmark of 105 question-answer pairs and assess performance using lexical metrics, semantic similarity, and LLM-as-a-judge scoring. We also analyze consistency, judgment reliability, and hallucination through source attribution and score variance. Results show that Gemma excels in semantic fidelity and LLM-rated correctness, while DeepSeek demonstrates slightly higher lexical consistency. Additional findings highlight current limitations in telecom applications and the need for domain-adapted models to support trustworthy Artificial Intelligence (AI) assistants in engineering.",
        "subjects": "Networking and Internet Architecture, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.939886"
    },
    {
        "index": "#138",
        "title": "AgentPack: A Dataset of Code Changes, Co-Authored by Agents and Humans",
        "link": "/arxiv/2509.21891",
        "arxiv_id": "2509.21891",
        "authors": "Yangtian Zi, Zixuan Wu, Aleksander Boruch-Gruszecki, Jonathan Bell, Arjun Guha",
        "summary": "Fine-tuning large language models for code editing has typically relied on mining commits and pull requests. The working hypothesis has been that commit messages describe human intent in natural language, and patches to code describe the changes that implement that intent. However, much of the previously collected data is noisy: commit messages are terse, human-written commits commingle several unrelated edits, and many commits come from simple, rule-based bots. The recent adoption of software engineering agents changes this landscape. Code changes co-authored by humans and agents tend to be more narrowly scoped and focused on clearer goals. Their commit messages, generated by LLMs, articulate intent and rationale in much greater detail. Moreover, when these changes land in public repositories, they are implicitly filtered by humans: maintainers discard low-quality commits to their projects. We present AgentPack, a corpus of 1.3M code edits co-authored by Claude Code, OpenAI Codex, and Cursor Agent across public GitHub projects up to mid-August 2025. We describe the identification and curation pipeline, quantify adoption trends of these agents, and analyze the structural properties of the edits. Finally, we show that models fine-tuned on AgentPack can outperform models trained on prior human-only commit corpora, highlighting the potential of using public data from software engineering agents to train future code-editing models.",
        "subjects": "Software Engineering, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.940538"
    },
    {
        "index": "#139",
        "title": "You Can't Steal Nothing: Mitigating Prompt Leakages in LLMs via System Vectors",
        "link": "/arxiv/2509.21884",
        "arxiv_id": "2509.21884",
        "authors": "Bochuan Cao, Changjiang Li, Yuanpu Cao, Yameng Ge, Ting Wang, Jinghui Chen",
        "summary": "Large language models (LLMs) have been widely adopted across various applications, leveraging customized system prompts for diverse tasks. Facing potential system prompt leakage risks, model developers have implemented strategies to prevent leakage, primarily by disabling LLMs from repeating their context when encountering known attack patterns. However, it remains vulnerable to new and unforeseen prompt-leaking techniques. In this paper, we first introduce a simple yet effective prompt leaking attack to reveal such risks. Our attack is capable of extracting system prompts from various LLM-based application, even from SOTA LLM models such as GPT-4o or Claude 3.5 Sonnet. Our findings further inspire us to search for a fundamental solution to the problems by having no system prompt in the context. To this end, we propose SysVec, a novel method that encodes system prompts as internal representation vectors rather than raw text. By doing so, SysVec minimizes the risk of unauthorized disclosure while preserving the LLM's core language capabilities. Remarkably, this approach not only enhances security but also improves the model's general instruction-following abilities. Experimental results demonstrate that SysVec effectively mitigates prompt leakage attacks, preserves the LLM's functional integrity, and helps alleviate the forgetting issue in long-context scenarios.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.941245"
    },
    {
        "index": "#140",
        "title": "What Makes LLM Agent Simulations Useful for Policy? Insights From an Iterative Design Engagement in Emergency Preparedness",
        "link": "/arxiv/2509.21868",
        "arxiv_id": "2509.21868",
        "authors": "Yuxuan Li, Sauvik Das, Hirokazu Shirado",
        "summary": "There is growing interest in using Large Language Models as agents (LLM agents) for social simulations to inform policy, yet real-world adoption remains limited. This paper addresses the question: How can LLM agent simulations be made genuinely useful for policy? We report on a year-long iterative design engagement with a university emergency preparedness team. Across multiple design iterations, we iteratively developed a system of 13,000 LLM agents that simulate crowd movement and communication during a large-scale gathering under various emergency scenarios. These simulations informed actual policy implementation, shaping volunteer training, evacuation protocols, and infrastructure planning. Analyzing this process, we identify three design implications: start with verifiable scenarios and build trust gradually, use preliminary simulations to elicit tacit knowledge, and treat simulation and policy development as evolving together. These implications highlight actionable pathways to making LLM agent simulations that are genuinely useful for policy.",
        "subjects": "Human-Computer Interaction, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.952076"
    },
    {
        "index": "#141",
        "title": "SBFA: Single Sneaky Bit Flip Attack to Break Large Language Models",
        "link": "/arxiv/2509.21843",
        "arxiv_id": "2509.21843",
        "authors": "Jingkai Guo, Chaitali Chakrabarti, Deliang Fan",
        "summary": "Model integrity of Large language models (LLMs) has become a pressing security concern with their massive online deployment. Prior Bit-Flip Attacks (BFAs) -- a class of popular AI weight memory fault-injection techniques -- can severely compromise Deep Neural Networks (DNNs): as few as tens of bit flips can degrade accuracy toward random guessing. Recent studies extend BFAs to LLMs and reveal that, despite the intuition of better robustness from modularity and redundancy, only a handful of adversarial bit flips can also cause LLMs' catastrophic accuracy degradation. However, existing BFA methods typically focus on either integer or floating-point models separately, limiting attack flexibility. Moreover, in floating-point models, random bit flips often cause perturbed parameters to extreme values (e.g., flipping in exponent bit), making it not stealthy and leading to numerical runtime error (e.g., invalid tensor values (NaN/Inf)). In this work, for the first time, we propose SBFA (Sneaky Bit-Flip Attack), which collapses LLM performance with only one single bit flip while keeping perturbed values within benign layer-wise weight distribution. It is achieved through iterative searching and ranking through our defined parameter sensitivity metric, ImpactScore, which combines gradient sensitivity and perturbation range constrained by the benign layer-wise weight distribution. A novel lightweight SKIP searching algorithm is also proposed to greatly reduce searching complexity, which leads to successful SBFA searching taking only tens of minutes for SOTA LLMs. Across Qwen, LLaMA, and Gemma models, with only one single bit flip, SBFA successfully degrades accuracy to below random levels on MMLU and SST-2 in both BF16 and INT8 data formats. Remarkably, flipping a single bit out of billions of parameters reveals a severe security concern of SOTA LLM models.",
        "subjects": "Cryptography and Security, Computation and Language, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.952599"
    },
    {
        "index": "#142",
        "title": "Compiling by Proving: Language-Agnostic Automatic Optimization from Formal Semantics",
        "link": "/arxiv/2509.21793",
        "arxiv_id": "2509.21793",
        "authors": "Jianhong Zhao, Everett Hildenbrandt, Juan Conejero, Yongwang Zhao",
        "summary": "Verification proofs encode complete program behavior, yet we discard them after checking correctness. We present compiling by proving, a paradigm that transforms these proofs into optimized execution rules. By constructing All-Path Reachability Proofs through symbolic execution and compiling their graph structure, we consolidate many semantic rewrites into single rules while preserving correctness by construction. We implement this as a language-agnostic extension to the K framework. Evaluation demonstrates performance improvements across different compilation scopes: opcode-level optimizations show consistent speedups, while whole-program compilation achieves orders of magnitude greater performance gains.",
        "subjects": "Programming Languages, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.953103"
    },
    {
        "index": "#144",
        "title": "UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios",
        "link": "/arxiv/2509.21766",
        "arxiv_id": "2509.21766",
        "authors": "Haotian Luo, Huaisong Zhang, Xuelin Zhang, Haoyu Wang, Zeyu Qin, Wenjie Lu, Guozheng Ma, Haiying He, Yingsha Xie, Qiyang Zhou, Zixuan Hu, Hongze Mi, Yibo Wang, Naiqiang Tan, Hong Chen, Yi R. Fung, Chun Yuan, Li Shen",
        "summary": "Autonomous agents have recently achieved remarkable progress across diverse domains, yet most evaluations focus on short-horizon, fully observable tasks. In contrast, many critical real-world tasks, such as large-scale software development, commercial investment, and scientific discovery, unfold in long-horizon and partially observable scenarios where success hinges on sustained reasoning, planning, memory management, and tool use. Existing benchmarks rarely capture these long-horizon challenges, leaving a gap in systematic evaluation. To bridge this gap, we introduce \\textbf{UltraHorizon} a novel benchmark that measures the foundational capabilities essential for complex real-world challenges. We use exploration as a unifying task across three distinct environments to validate these core competencies. Agents are designed in long-horizon discovery tasks where they must iteratively uncover hidden rules through sustained reasoning, planning, memory and tools management, and interaction with environments. Under the heaviest scale setting, trajectories average \\textbf{200k+} tokens and \\textbf{400+} tool calls, whereas in standard configurations they still exceed \\textbf{35k} tokens and involve more than \\textbf{60} tool calls on average. Our extensive experiments reveal that LLM-agents consistently underperform in these settings, whereas human participants achieve higher scores, underscoring a persistent gap in agents' long-horizon abilities. We also observe that simple scaling fails in our task. To better illustrate the failure of agents, we conduct an in-depth analysis of collected trajectories. We identify eight types of errors and attribute them to two primary causes: in-context locking and functional fundamental capability gaps. \\href{https://github.com/StarDewXXX/UltraHorizon}{Our code will be available here.}",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-09-26",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.954492"
    },
    {
        "index": "#146",
        "title": "InvBench: Can LLMs Accelerate Program Verification with Invariant Synthesis?",
        "link": "/arxiv/2509.21629",
        "arxiv_id": "2509.21629",
        "authors": "Anjiang Wei, Tarun Suresh, Tianran Sun, Haoze Wu, Ke Wang, Alex Aiken",
        "summary": "Program verification relies on loop invariants, yet automatically discovering strong invariants remains a long-standing challenge. We introduce a principled framework for evaluating LLMs on invariant synthesis. Our approach uses a verifier-based decision procedure with a formal soundness guarantee and assesses not only correctness but also the speedup that invariants provide in verification. We evaluate 7 state-of-the-art LLMs, and existing LLM-based verifiers against the traditional solver UAutomizer. While LLM-based verifiers represent a promising direction, they do not yet offer a significant advantage over UAutomizer. Model capability also proves critical, as shown by sharp differences in speedups across models, and our benchmark remains an open challenge for current LLMs. Finally, we show that supervised fine-tuning and Best-of-N sampling can improve performance: fine-tuning on 3589 instances raises the percentage of speedup cases for Qwen3-Coder-480B from 8% to 29.2%, and Best-of-N sampling with N=16 improves Claude-sonnet-4 from 8.8% to 22.1%.",
        "subjects": "Programming Languages, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.955975"
    },
    {
        "index": "#147",
        "title": "AUDDT: Audio Unified Deepfake Detection Benchmark Toolkit",
        "link": "/arxiv/2509.21597",
        "arxiv_id": "2509.21597",
        "authors": "Yi Zhu, Heitor R. Guimarães, Arthur Pimentel, Tiago Falk",
        "summary": "With the prevalence of artificial intelligence (AI)-generated content, such as audio deepfakes, a large body of recent work has focused on developing deepfake detection techniques. However, most models are evaluated on a narrow set of datasets, leaving their generalization to real-world conditions uncertain. In this paper, we systematically review 28 existing audio deepfake datasets and present an open-source benchmarking toolkit called AUDDT (https://github.com/MuSAELab/AUDDT). The goal of this toolkit is to automate the evaluation of pretrained detectors across these 28 datasets, giving users direct feedback on the advantages and shortcomings of their deepfake detectors. We start by showcasing the usage of the developed toolkit, the composition of our benchmark, and the breakdown of different deepfake subgroups. Next, using a widely adopted pretrained deepfake detector, we present in- and out-of-domain detection results, revealing notable differences across conditions and audio manipulation types. Lastly, we also analyze the limitations of these existing datasets and their gap relative to practical deployment scenarios.",
        "subjects": "Audio and Speech Processing, Computation and Language, Sound",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.956513"
    },
    {
        "index": "#148",
        "title": "Leveraging Big Data Frameworks for Spam Detection in Amazon Reviews",
        "link": "/arxiv/2509.21579",
        "arxiv_id": "2509.21579",
        "authors": "Mst Eshita Khatun, Halima Akter, Tasnimul Rehan, Toufiq Ahmed",
        "summary": "In this digital era, online shopping is common practice in our daily lives. Product reviews significantly influence consumer buying behavior and help establish buyer trust. However, the prevalence of fraudulent reviews undermines this trust by potentially misleading consumers and damaging the reputations of the sellers. This research addresses this pressing issue by employing advanced big data analytics and machine learning approaches on a substantial dataset of Amazon product reviews. The primary objective is to detect and classify spam reviews accurately so that it enhances the authenticity of the review. Using a scalable big data framework, we efficiently process and analyze a large scale of review data, extracting key features indicative of fraudulent behavior. Our study illustrates the utility of various machine learning classifiers in detecting spam reviews, with Logistic Regression achieving an accuracy of 90.35%, thus contributing to a more trustworthy and transparent online shopping environment.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.957022"
    },
    {
        "index": "#150",
        "title": "C-QUERI: Congressional Questions, Exchanges, and Responses in Institutions Dataset",
        "link": "/arxiv/2509.21548",
        "arxiv_id": "2509.21548",
        "authors": "Manjari Rudra, Daniel Magleby, Sujoy Sikdar",
        "summary": "Questions in political interviews and hearings serve strategic purposes beyond information gathering including advancing partisan narratives and shaping public perceptions. However, these strategic aspects remain understudied due to the lack of large-scale datasets for studying such discourse. Congressional hearings provide an especially rich and tractable site for studying political questioning: Interactions are structured by formal rules, witnesses are obliged to respond, and members with different political affiliations are guaranteed opportunities to ask questions, enabling comparisons of behaviors across the political spectrum. We develop a pipeline to extract question-answer pairs from unstructured hearing transcripts and construct a novel dataset of committee hearings from the 108th--117th Congress. Our analysis reveals systematic differences in questioning strategies across parties, by showing the party affiliation of questioners can be predicted from their questions alone. Our dataset and methods not only advance the study of congressional politics, but also provide a general framework for analyzing question-answering across interview-like settings.",
        "subjects": "Computers and Society, Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.958114"
    },
    {
        "index": "#151",
        "title": "Uncertainty-Aware Knowledge Tracing Models",
        "link": "/arxiv/2509.21514",
        "arxiv_id": "2509.21514",
        "authors": "Joshua Mitton, Prarthana Bhattacharyya, Ralph Abboud, Simon Woodhead",
        "summary": "The main focus of research on Knowledge Tracing (KT) models is on model developments with the aim of improving predictive accuracy. Most of these models make the most incorrect predictions when students choose a distractor, leading to student errors going undetected. We present an approach to add new capabilities to KT models by capturing predictive uncertainty and demonstrate that a larger predictive uncertainty aligns with model incorrect predictions. We show that uncertainty in KT models is informative and that this signal would be pedagogically useful for application in an educational learning platform that can be used in a limited resource setting where understanding student ability is necessary.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.958613"
    },
    {
        "index": "#152",
        "title": "LLM Agent Meets Agentic AI: Can LLM Agents Simulate Customers to Evaluate Agentic-AI-based Shopping Assistants?",
        "link": "/arxiv/2509.21501",
        "arxiv_id": "2509.21501",
        "authors": "Lu Sun, Shihan Fu, Bingsheng Yao, Yuxuan Lu, Wenbo Li, Hansu Gu, Jiri Gesi, Jing Huang, Chen Luo, Dakuo Wang",
        "summary": "Agentic AI is emerging, capable of executing tasks through natural language, such as Copilot for coding or Amazon Rufus for shopping. Evaluating these systems is challenging, as their rapid evolution outpaces traditional human evaluation. Researchers have proposed LLM Agents to simulate participants as digital twins, but it remains unclear to what extent a digital twin can represent a specific customer in multi-turn interaction with an agentic AI system. In this paper, we recruited 40 human participants to shop with Amazon Rufus, collected their personas, interaction traces, and UX feedback, and then created digital twins to repeat the task. Pairwise comparison of human and digital-twin traces shows that while agents often explored more diverse choices, their action patterns aligned with humans and yielded similar design feedback. This study is the first to quantify how closely LLM agents can mirror human multi-turn interaction with an agentic AI system, highlighting their potential for scalable evaluation.",
        "subjects": "Human-Computer Interaction, Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.959202"
    },
    {
        "index": "#156",
        "title": "ARTI-6: Towards Six-dimensional Articulatory Speech Encoding",
        "link": "/arxiv/2509.21447",
        "arxiv_id": "2509.21447",
        "authors": "Jihwan Lee, Sean Foley, Thanathai Lertpetchpun, Kevin Huang, Yoonjeong Lee, Tiantian Feng, Louis Goldstein, Dani Byrd, Shrikanth Narayanan",
        "summary": "We propose ARTI-6, a compact six-dimensional articulatory speech encoding framework derived from real-time MRI data that captures crucial vocal tract regions including the velum, tongue root, and larynx. ARTI-6 consists of three components: (1) a six-dimensional articulatory feature set representing key regions of the vocal tract; (2) an articulatory inversion model, which predicts articulatory features from speech acoustics leveraging speech foundation models, achieving a prediction correlation of 0.87; and (3) an articulatory synthesis model, which reconstructs intelligible speech directly from articulatory features, showing that even a low-dimensional representation can generate natural-sounding speech. Together, ARTI-6 provides an interpretable, computationally efficient, and physiologically grounded framework for advancing articulatory inversion, synthesis, and broader speech technology applications. The source code and speech samples are publicly available.",
        "subjects": "Audio and Speech Processing, Artificial Intelligence, Computation and Language",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.966592"
    },
    {
        "index": "#157",
        "title": "LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet?",
        "link": "/arxiv/2509.21403",
        "arxiv_id": "2509.21403",
        "authors": "Rushil Gupta, Jason Hartford, Bang Liu",
        "summary": "Large language models (LLMs) have recently been proposed as general-purpose agents for experimental design, with claims that they can perform in-context experimental design. We evaluate this hypothesis using both open- and closed-source instruction-tuned LLMs applied to genetic perturbation and molecular property discovery tasks. We find that LLM-based agents show no sensitivity to experimental feedback: replacing true outcomes with randomly permuted labels has no impact on performance. Across benchmarks, classical methods such as linear bandits and Gaussian process optimization consistently outperform LLM agents. We further propose a simple hybrid method, LLM-guided Nearest Neighbour (LLMNN) sampling, that combines LLM prior knowledge with nearest-neighbor sampling to guide the design of experiments. LLMNN achieves competitive or superior performance across domains without requiring significant in-context adaptation. These results suggest that current open- and closed-source LLMs do not perform in-context experimental design in practice and highlight the need for hybrid frameworks that decouple prior-based reasoning from batch acquisition with updated posteriors.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-09-24",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.967118"
    },
    {
        "index": "#158",
        "title": "ReGeS: Reciprocal Retrieval-Generation Synergy for Conversational Recommender Systems",
        "link": "/arxiv/2509.21371",
        "arxiv_id": "2509.21371",
        "authors": "Dayu Yang, Hui Fang",
        "summary": "Connecting conversation with external domain knowledge is vital for conversational recommender systems (CRS) to correctly understand user preferences. However, existing solutions either require domain-specific engineering, which limits flexibility, or rely solely on large language models, which increases the risk of hallucination. While Retrieval-Augmented Generation (RAG) holds promise, its naive use in CRS is hindered by noisy dialogues that weaken retrieval and by overlooked nuances among similar items. We propose ReGeS, a reciprocal Retrieval-Generation Synergy framework that unifies generation-augmented retrieval to distill informative user intent from conversations and retrieval-augmented generation to differentiate subtle item features. This synergy obviates the need for extra annotations, reduces hallucinations, and simplifies continuous updates. Experiments on multiple CRS benchmarks show that ReGeS achieves state-of-the-art performance in recommendation accuracy, demonstrating the effectiveness of reciprocal synergy for knowledge-intensive CRS tasks.",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-09-22",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.967628"
    },
    {
        "index": "#160",
        "title": "Towards mitigating information leakage when evaluating safety monitors",
        "link": "/arxiv/2509.21344",
        "arxiv_id": "2509.21344",
        "authors": "Gerard Boxo, Aman Neelappa, Shivam Raval",
        "summary": "White box monitors that analyze model internals offer promising advantages for detecting potentially harmful behaviors in large language models, including lower computational costs and integration into layered defense systems.However, training and evaluating these monitors requires response exemplars that exhibit the target behaviors, typically elicited through prompting or fine-tuning. This presents a challenge when the information used to elicit behaviors inevitably leaks into the data that monitors ingest, inflating their effectiveness. We present a systematic framework for evaluating a monitor's performance in terms of its ability to detect genuine model behavior rather than superficial elicitation artifacts. Furthermore, we propose three novel strategies to evaluate the monitor: content filtering (removing deception-related text from inputs), score filtering (aggregating only over task-relevant tokens), and prompt distilled fine-tuned model organisms (models trained to exhibit deceptive behavior without explicit prompting). Using deception detection as a representative case study, we identify two forms of leakage that inflate monitor performance: elicitation leakage from prompts that explicitly request harmful behavior, and reasoning leakage from models that verbalize their deceptive actions. Through experiments on multiple deception benchmarks, we apply our proposed mitigation strategies and measure performance retention. Our evaluation of the monitors reveal three crucial findings: (1) Content filtering is a good mitigation strategy that allows for a smooth removal of elicitation signal and can decrease probe AUROC by 30\\% (2) Score filtering was found to reduce AUROC by 15\\% but is not as straightforward to attribute to (3) A finetuned model organism improves monitor evaluations but reduces their performance by upto 40\\%, even when re-trained.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-09-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.968756"
    },
    {
        "index": "#161",
        "title": "HetaRAG: Hybrid Deep Retrieval-Augmented Generation across Heterogeneous Data Stores",
        "link": "/arxiv/2509.21336",
        "arxiv_id": "2509.21336",
        "authors": "Guohang Yan, Yue Zhang, Pinlong Cai, Ding Wang, Song Mao, Hongwei Zhang, Yaoze Zhang, Hairong Zhang, Xinyu Cai, Botian Shi",
        "summary": "Retrieval-augmented generation (RAG) has become a dominant paradigm for mitigating knowledge hallucination and staleness in large language models (LLMs) while preserving data security. By retrieving relevant evidence from private, domain-specific corpora and injecting it into carefully engineered prompts, RAG delivers trustworthy responses without the prohibitive cost of fine-tuning. Traditional retrieval-augmented generation (RAG) systems are text-only and often rely on a single storage backend, most commonly a vector database. In practice, this monolithic design suffers from unavoidable trade-offs: vector search captures semantic similarity yet loses global context; knowledge graphs excel at relational precision but struggle with recall; full-text indexes are fast and exact yet semantically blind; and relational engines such as MySQL provide strong transactional guarantees but no semantic understanding. We argue that these heterogeneous retrieval paradigms are complementary, and propose a principled fusion scheme to orchestrate them synergistically, mitigating the weaknesses of any single modality. In this work we introduce HetaRAG, a hybrid, deep-retrieval augmented generation framework that orchestrates cross-modal evidence from heterogeneous data stores. We plan to design a system that unifies vector indices, knowledge graphs, full-text engines, and structured databases into a single retrieval plane, dynamically routing and fusing evidence to maximize recall, precision, and contextual fidelity. To achieve this design goal, we carried out preliminary explorations and constructed an initial RAG pipeline; this technical report provides a brief overview. The partial code is available at https://github.com/KnowledgeXLab/HetaRAG.",
        "subjects": "Information Retrieval, Computation and Language",
        "date": "2025-09-12",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.969359"
    },
    {
        "index": "#162",
        "title": "Accelerate Creation of Product Claims Using Generative AI",
        "link": "/arxiv/2509.20652",
        "arxiv_id": "2509.20652",
        "authors": "Po-Yu Liang, Yong Zhang, Tatiana Hwa, Aaron Byers",
        "summary": "The benefit claims of a product is a critical driver of consumers' purchase behavior. Creating product claims is an intense task that requires substantial time and funding. We have developed the $\\textbf{Claim Advisor}$ web application to accelerate claim creations using in-context learning and fine-tuning of large language models (LLM). $\\textbf{Claim Advisor}$ was designed to disrupt the speed and economics of claim search, generation, optimization, and simulation. It has three functions: (1) semantically searching and identifying existing claims and/or visuals that resonate with the voice of consumers; (2) generating and/or optimizing claims based on a product description and a consumer profile; and (3) ranking generated and/or manually created claims using simulations via synthetic consumers. Applications in a consumer packaged goods (CPG) company have shown very promising results. We believe that this capability is broadly useful and applicable across product categories and industries. We share our learning to encourage the research and application of generative AI in different industries.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.CL",
        "crawl_time": "2025-10-06T22:42:02.969840"
    },
    {
        "index": "#1",
        "title": "Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective",
        "link": "/arxiv/2509.22613",
        "arxiv_id": "2509.22613",
        "authors": "Siwei Wang, Yifei Shen, Haoran Sun, Shi Feng, Shang-Hua Teng, Li Dong, Yaru Hao, Wei Chen",
        "summary": "Recent reinforcement learning (RL) methods have substantially enhanced the planning capabilities of Large Language Models (LLMs), yet the theoretical basis for their effectiveness remains elusive. In this work, we investigate RL's benefits and limitations through a tractable graph-based abstraction, focusing on policy gradient (PG) and Q-learning methods. Our theoretical analyses reveal that supervised fine-tuning (SFT) may introduce co-occurrence-based spurious solutions, whereas RL achieves correct planning primarily through exploration, underscoring exploration's role in enabling better generalization. However, we also show that PG suffers from diversity collapse, where output diversity decreases during training and persists even after perfect accuracy is attained. By contrast, Q-learning provides two key advantages: off-policy learning and diversity preservation at convergence. We further demonstrate that careful reward design is necessary to prevent reward hacking in Q-learning. Finally, applying our framework to the real-world planning benchmark Blocksworld, we confirm that these behaviors manifest in practice.",
        "subjects": "Artificial Intelligence, Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.623143"
    },
    {
        "index": "#3",
        "title": "UniMIC: Token-Based Multimodal Interactive Coding for Human-AI Collaboration",
        "link": "/arxiv/2509.22570",
        "arxiv_id": "2509.22570",
        "authors": "Qi Mao, Tinghan Yang, Jiahao Li, Bin Li, Libiao Jin, Yan Lu",
        "summary": "The rapid progress of Large Multimodal Models (LMMs) and cloud-based AI agents is transforming human-AI collaboration into bidirectional, multimodal interaction. However, existing codecs remain optimized for unimodal, one-way communication, resulting in repeated degradation under conventional compress-transmit-reconstruct pipelines. To address this limitation, we propose UniMIC, a Unified token-based Multimodal Interactive Coding framework that bridges edge devices and cloud AI agents. Instead of transmitting raw pixels or plain text, UniMIC employs compact tokenized representations as the communication medium, enabling efficient low-bitrate transmission while maintaining compatibility with LMMs. To further enhance compression, lightweight Transformer-based entropy models with scenario-specific designs-generic, masked, and text-conditioned-effectively minimize inter-token redundancy. Extensive experiments on text-to-image generation, text-guided inpainting, outpainting, and visual question answering show that UniMIC achieves substantial bitrate savings and remains robust even at ultra-low bitrates (<0.05bpp), without compromising downstream task performance. These results establish UniMIC as a practical and forward-looking paradigm for next-generation multimodal interactive communication.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.625447"
    },
    {
        "index": "#4",
        "title": "StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models",
        "link": "/arxiv/2509.22558",
        "arxiv_id": "2509.22558",
        "authors": "Chenyu Zhou, Tianyi Xu, Jianghao Lin, Dongdong Ge",
        "summary": "Large Language Models (LLMs) have shown promising capabilities for solving Operations Research (OR) problems. While reinforcement learning serves as a powerful paradigm for LLM training on OR problems, existing works generally face two key limitations. First, outcome reward suffers from the credit assignment problem, where correct final answers can reinforce flawed reasoning. Second, conventional discriminative process supervision is myopic, failing to evaluate the interdependent steps of OR modeling holistically. To this end, we introduce StepORLM, a novel self-evolving framework with generative process supervision. At its core, StepORLM features a co-evolutionary loop where a policy model and a generative process reward model (GenPRM) iteratively improve on each other. This loop is driven by a dual-feedback mechanism: definitive, outcome-based verification from an external solver, and nuanced, holistic process evaluation from the GenPRM. The combined signal is used to align the policy via Weighted Direct Preference Optimization (W-DPO) and simultaneously refine the GenPRM. Our resulting 8B-parameter StepORLM establishes a new state-of-the-art across six benchmarks, significantly outperforming vastly larger generalist models, agentic methods, and specialized baselines. Moreover, the co-evolved GenPRM is able to act as a powerful and universally applicable process verifier, substantially boosting the inference scaling performance of both our own model and other existing LLMs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.625918"
    },
    {
        "index": "#5",
        "title": "The Emergence of Altruism in Large-Language-Model Agents Society",
        "link": "/arxiv/2509.22537",
        "arxiv_id": "2509.22537",
        "authors": "Haoyang Li, Xiao Jia, Zhanzhan Zhao",
        "summary": "Leveraging Large Language Models (LLMs) for social simulation is a frontier in computational social science. Understanding the social logics these agents embody is critical to this attempt. However, existing research has primarily focused on cooperation in small-scale, task-oriented games, overlooking how altruism, which means sacrificing self-interest for collective benefit, emerges in large-scale agent societies. To address this gap, we introduce a Schelling-variant urban migration model that creates a social dilemma, compelling over 200 LLM agents to navigate an explicit conflict between egoistic (personal utility) and altruistic (system utility) goals. Our central finding is a fundamental difference in the social tendencies of LLMs. We identify two distinct archetypes: \"Adaptive Egoists\", which default to prioritizing self-interest but whose altruistic behaviors significantly increase under the influence of a social norm-setting message board; and \"Altruistic Optimizers\", which exhibit an inherent altruistic logic, consistently prioritizing collective benefit even at a direct cost to themselves. Furthermore, to qualitatively analyze the cognitive underpinnings of these decisions, we introduce a method inspired by Grounded Theory to systematically code agent reasoning. In summary, this research provides the first evidence of intrinsic heterogeneity in the egoistic and altruistic tendencies of different LLMs. We propose that for social simulation, model selection is not merely a matter of choosing reasoning capability, but of choosing an intrinsic social action logic. While \"Adaptive Egoists\" may offer a more suitable choice for simulating complex human societies, \"Altruistic Optimizers\" are better suited for modeling idealized pro-social actors or scenarios where collective welfare is the primary consideration.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.626371"
    },
    {
        "index": "#6",
        "title": "REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model",
        "link": "/arxiv/2509.22518",
        "arxiv_id": "2509.22518",
        "authors": "Bo Li, Guanzhi Deng, Ronghao Chen, Junrong Yue, Shuo Zhang, Qinghua Zhao, Linqi Song, Lijie Wen",
        "summary": "Understanding how Large Language Models (LLMs) perform complex reasoning and their failure mechanisms is a challenge in interpretability research. To provide a measurable geometric analysis perspective, we define the concept of the Reasoning Manifold, a latent low-dimensional geometric structure formed by the internal representations corresponding to all correctly reasoned generations. This structure can be conceptualized as the embodiment of the effective thinking paths that the model has learned to successfully solve a given task. Based on this concept, we build REMA, a framework that explains the origins of failures by quantitatively comparing the spatial relationships of internal model representations corresponding to both erroneous and correct reasoning samples. Specifically, REMA first quantifies the geometric deviation of each erroneous representation by calculating its k-nearest neighbors distance to the approximated manifold formed by correct representations, thereby providing a unified failure signal. It then localizes the divergence points where these deviations first become significant by tracking this deviation metric across the model's layers and comparing it against a baseline of internal fluctuations from correct representations, thus identifying where the reasoning chain begins to go off-track. Our extensive experiments on diverse language and multimodal models and tasks demonstrate the low-dimensional nature of the reasoning manifold and the high separability between erroneous and correct reasoning representations. The results also validate the effectiveness of the REMA framework in analyzing the origins of reasoning failures. This research connects abstract reasoning failures to measurable geometric deviations in representations, providing new avenues for in-depth understanding and diagnosis of the internal computational processes of black-box models.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.626906"
    },
    {
        "index": "#7",
        "title": "TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments",
        "link": "/arxiv/2509.22516",
        "arxiv_id": "2509.22516",
        "authors": "Rakesh Thakur, Shivaansh Kaushik, Gauri Chopra, Harsh Rohilla",
        "summary": "This paper introduces TrueGradeAI, an AI-driven digital examination framework designed to overcome the shortcomings of traditional paper-based assessments, including excessive paper usage, logistical complexity, grading delays, and evaluator bias. The system preserves natural handwriting by capturing stylus input on secure tablets and applying transformer-based optical character recognition for transcription. Evaluation is conducted through a retrieval-augmented pipeline that integrates faculty solutions, cache layers, and external references, enabling a large language model to assign scores with explicit, evidence-linked reasoning. Unlike prior tablet-based exam systems that primarily digitize responses, TrueGradeAI advances the field by incorporating explainable automation, bias mitigation, and auditable grading trails. By uniting handwriting preservation with scalable and transparent evaluation, the framework reduces environmental costs, accelerates feedback cycles, and progressively builds a reusable knowledge base, while actively working to mitigate grading bias and ensure fairness in assessment.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.627397"
    },
    {
        "index": "#8",
        "title": "Estimating the Empowerment of Language Model Agents",
        "link": "/arxiv/2509.22504",
        "arxiv_id": "2509.22504",
        "authors": "Jinyeop Song, Jeff Gore, Max Kleiman-Weiner",
        "summary": "As language model (LM) agents become more capable and gain broader access to real-world tools, there is a growing need for scalable evaluation frameworks of agentic capability. However, conventional benchmark-centric evaluations are costly to design and require human designers to come up with valid tasks that translate into insights about general model capabilities. In this work, we propose information-theoretic evaluation based on empowerment, the mutual information between an agent's actions and future states, as an open-ended method for evaluating LM agents. We introduce EELMA (Estimating Empowerment of Language Model Agents), an algorithm for approximating effective empowerment from multi-turn text interactions. We validate EELMA on both language games and scaled-up realistic web-browsing scenarios. We find that empowerment strongly correlates with average task performance, characterize the impact of environmental complexity and agentic factors such as chain-of-thought, model scale, and memory length on estimated empowerment, and that high empowerment states and actions are often pivotal moments for general capabilities. Together, these results demonstrate empowerment as an appealing general-purpose metric for evaluating and monitoring LM agents in complex, open-ended settings.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.633028"
    },
    {
        "index": "#9",
        "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios",
        "link": "/arxiv/2509.22502",
        "arxiv_id": "2509.22502",
        "authors": "Chenglin Yu, Yang Yu, Songmiao Wang, Yucheng Wang, Yifan Yang, Jinjia Li, Ming Li, Hongxia Yang",
        "summary": "Large Language Model (LLM) agents have demonstrated remarkable capabilities in organizing and executing complex tasks, and many such agents are now widely used in various application scenarios. However, developing these agents requires carefully designed workflows, carefully crafted prompts, and iterative tuning, which requires LLM techniques and domain-specific expertise. These hand-crafted limitations hinder the scalability and cost-effectiveness of LLM agents across a wide range of industries. To address these challenges, we propose \\textbf{InfiAgent}, a Pyramid-like DAG-based Multi-Agent Framework that can be applied to \\textbf{infi}nite scenarios, which introduces several key innovations: a generalized \"agent-as-a-tool\" mechanism that automatically decomposes complex agents into hierarchical multi-agent systems; a dual-audit mechanism that ensures the quality and stability of task completion; an agent routing function that enables efficient task-agent matching; and an agent self-evolution mechanism that autonomously restructures the agent DAG based on new tasks, poor performance, or optimization opportunities. Furthermore, InfiAgent's atomic task design supports agent parallelism, significantly improving execution efficiency. This framework evolves into a versatile pyramid-like multi-agent system capable of solving a wide range of problems. Evaluations on multiple benchmarks demonstrate that InfiAgent achieves 9.9\\% higher performance compared to ADAS (similar auto-generated agent framework), while a case study of the AI research assistant InfiHelper shows that it generates scientific papers that have received recognition from human reviewers at top-tier IEEE conferences.",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.633596"
    },
    {
        "index": "#10",
        "title": "GeoSketch: A Neural-Symbolic Approach to Geometric Multimodal Reasoning with Auxiliary Line Construction and Affine Transformation",
        "link": "/arxiv/2509.22460",
        "arxiv_id": "2509.22460",
        "authors": "Shichao Weng, Zhiqiang Wang, Yuhua Zhou, Rui Lu, Ting Liu, Zhiyang Teng, Xiaozhang Liu, Hanmeng Liu",
        "summary": "Geometric Problem Solving (GPS) poses a unique challenge for Multimodal Large Language Models (MLLMs), requiring not only the joint interpretation of text and diagrams but also iterative visuospatial reasoning. While existing approaches process diagrams as static images, they lack the capacity for dynamic manipulation - a core aspect of human geometric reasoning involving auxiliary line construction and affine transformations. We present GeoSketch, a neural-symbolic framework that recasts geometric reasoning as an interactive perception-reasoning-action loop. GeoSketch integrates: (1) a Perception module that abstracts diagrams into structured logic forms, (2) a Symbolic Reasoning module that applies geometric theorems to decide the next deductive step, and (3) a Sketch Action module that executes operations such as drawing auxiliary lines or applying transformations, thereby updating the diagram in a closed loop. To train this agent, we develop a two-stage pipeline: supervised fine-tuning on 2,000 symbolic-curated trajectories followed by reinforcement learning with dense, symbolic rewards to enhance robustness and strategic exploration. To evaluate this paradigm, we introduce the GeoSketch Benchmark, a high-quality set of 390 geometry problems requiring auxiliary construction or affine transformations. Experiments on strong MLLM baselines demonstrate that GeoSketch significantly improves stepwise reasoning accuracy and problem-solving success over static perception methods. By unifying hierarchical decision-making, executable visual actions, and symbolic verification, GeoSketch advances multimodal reasoning from static interpretation to dynamic, verifiable interaction, establishing a new foundation for solving complex visuospatial problems.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.634139"
    },
    {
        "index": "#11",
        "title": "Guiding Evolution of Artificial Life Using Vision-Language Models",
        "link": "/arxiv/2509.22447",
        "arxiv_id": "2509.22447",
        "authors": "Nikhil Baid, Hannah Erlebach, Paul Hellegouarch, Frederico Wieser",
        "summary": "Foundation models (FMs) have recently opened up new frontiers in the field of artificial life (ALife) by providing powerful tools to automate search through ALife simulations. Previous work aligns ALife simulations with natural language target prompts using vision-language models (VLMs). We build on Automated Search for Artificial Life (ASAL) by introducing ASAL++, a method for open-ended-like search guided by multimodal FMs. We use a second FM to propose new evolutionary targets based on a simulation's visual history. This induces an evolutionary trajectory with increasingly complex targets. We explore two strategies: (1) evolving a simulation to match a single new prompt at each iteration (Evolved Supervised Targets: EST) and (2) evolving a simulation to match the entire sequence of generated prompts (Evolved Temporal Targets: ETT). We test our method empirically in the Lenia substrate using Gemma-3 to propose evolutionary targets, and show that EST promotes greater visual novelty, while ETT fosters more coherent and interpretable evolutionary sequences. Our results suggest that ASAL++ points towards new directions for FM-driven ALife discovery with open-ended characteristics.",
        "subjects": "Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.634629"
    },
    {
        "index": "#12",
        "title": "EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer",
        "link": "/arxiv/2509.22407",
        "arxiv_id": "2509.22407",
        "authors": "Zhehao Dong, Xiaofeng Wang, Zheng Zhu, Yirui Wang, Yang Wang, Yukun Zhou, Boyuan Wang, Chaojun Ni, Runqi Ouyang, Wenkang Qin, Xinze Chen, Yun Ye, Guan Huang",
        "summary": "Vision-language-action (VLA) models increasingly rely on diverse training data to achieve robust generalization. However, collecting large-scale real-world robot manipulation data across varied object appearances and environmental conditions remains prohibitively time-consuming and expensive. To overcome this bottleneck, we propose Embodied Manipulation Media Adaptation (EMMA), a VLA policy enhancement framework that integrates a generative data engine with an effective training pipeline. We introduce DreamTransfer, a diffusion Transformer-based framework for generating multi-view consistent, geometrically grounded embodied manipulation videos. DreamTransfer enables text-controlled visual editing of robot videos, transforming foreground, background, and lighting conditions without compromising 3D structure or geometrical plausibility. Furthermore, we explore hybrid training with real and generated data, and introduce AdaMix, a hard-sample-aware training strategy that dynamically reweights training batches to focus optimization on perceptually or kinematically challenging samples. Extensive experiments show that videos generated by DreamTransfer significantly outperform prior video generation methods in multi-view consistency, geometric fidelity, and text-conditioning accuracy. Crucially, VLAs trained with generated data enable robots to generalize to unseen object categories and novel visual domains using only demonstrations from a single appearance. In real-world robotic manipulation tasks with zero-shot visual domains, our approach achieves over a 200% relative performance gain compared to training on real data alone, and further improves by 13% with AdaMix, demonstrating its effectiveness in boosting policy generalization.",
        "subjects": "Artificial Intelligence, Robotics",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.635255"
    },
    {
        "index": "#13",
        "title": "Do LLM Agents Know How to Ground, Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents",
        "link": "/arxiv/2509.22391",
        "arxiv_id": "2509.22391",
        "authors": "Jiaqi Shao, Yuxiang Lin, Munish Prasad Lohani, Yufeng Miao, Bing Luo",
        "summary": "Recent work has explored training Large Language Model (LLM) search agents with reinforcement learning (RL) for open-domain question answering (QA). However, most evaluations focus solely on final answer accuracy, overlooking how these agents reason with and act on external evidence. We introduce SeekBench, the first benchmark for evaluating the \\textit{epistemic competence} of LLM search agents through step-level analysis of their response traces. SeekBench comprises 190 expert-annotated traces with over 1,800 response steps generated by LLM search agents, each enriched with evidence annotations for granular analysis of whether agents (1) generate reasoning steps grounded in observed evidence, (2) adaptively reformulate searches to recover from low-quality results, and (3) have proper calibration to correctly assess whether the current evidence is sufficient for providing an answer.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.635752"
    },
    {
        "index": "#15",
        "title": "Large Language Models as Nondeterministic Causal Models",
        "link": "/arxiv/2509.22297",
        "arxiv_id": "2509.22297",
        "authors": "Sander Beckers",
        "summary": "Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first time, a method for generating counterfactuals of probabilistic Large Language Models. Such counterfactuals tell us what would - or might - have been the output of an LLM if some factual prompt ${\\bf x}$ had been ${\\bf x}^*$ instead. The ability to generate such counterfactuals is an important necessary step towards explaining, evaluating, and comparing, the behavior of LLMs. I argue, however, that the existing method rests on an ambiguous interpretation of LLMs: it does not interpret LLMs literally, for the method involves the assumption that one can change the implementation of an LLM's sampling process without changing the LLM itself, nor does it interpret LLMs as intended, for the method involves explicitly representing a nondeterministic LLM as a deterministic causal model. I here present a much simpler method for generating counterfactuals that is based on an LLM's intended interpretation by representing it as a nondeterministic causal model instead. The advantage of my simpler method is that it is directly applicable to any black-box LLM without modification, as it is agnostic to any implementation details. The advantage of the existing method, on the other hand, is that it directly implements the generation of a specific type of counterfactuals that is useful for certain purposes, but not for others. I clarify how both methods relate by offering a theoretical foundation for reasoning about counterfactuals in LLMs based on their intended semantics, thereby laying the groundwork for novel application-specific methods for generating counterfactuals.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.636723"
    },
    {
        "index": "#16",
        "title": "Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models",
        "link": "/arxiv/2509.22284",
        "arxiv_id": "2509.22284",
        "authors": "Aleksandar Terzić, Nicolas Menet, Michael Hersche, Thomas Hofmann, Abbas Rahimi",
        "summary": "Modern state-space models (SSMs) often utilize transition matrices which enable efficient computation but pose restrictions on the model's expressivity, as measured in terms of the ability to emulate finite-state automata (FSA). While unstructured transition matrices are optimal in terms of expressivity, they come at a prohibitively high compute and memory cost even for moderate state sizes. We propose a structured sparse parametrization of transition matrices in SSMs that enables FSA state tracking with optimal state size and depth, while keeping the computational cost of the recurrence comparable to that of diagonal SSMs. Our method, PD-SSM, parametrizes the transition matrix as the product of a column one-hot matrix ($P$) and a complex-valued diagonal matrix ($D$). Consequently, the computational cost of parallel scans scales linearly with the state size. Theoretically, the model is BIBO-stable and can emulate any $N$-state FSA with one layer of dimension $N$ and a linear readout of size $N \\times N$, significantly improving on all current structured SSM guarantees. Experimentally, the model significantly outperforms a wide collection of modern SSM variants on various FSA state tracking tasks. On multiclass time-series classification, the performance is comparable to that of neural controlled differential equations, a paradigm explicitly built for time-series analysis. Finally, we integrate PD-SSM into a hybrid Transformer-SSM architecture and demonstrate that the model can effectively track the states of a complex FSA in which transitions are encoded as a set of variable-length English sentences. The code is available at https://github.com/IBM/expressive-sparse-state-space-model",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.637223"
    },
    {
        "index": "#18",
        "title": "Evaluating LLMs for Combinatorial Optimization: One-Phase and Two-Phase Heuristics for 2D Bin-Packing",
        "link": "/arxiv/2509.22255",
        "arxiv_id": "2509.22255",
        "authors": "Syed Mahbubul Huq, Daniel Brito, Daniel Sikar, Rajesh Mojumder",
        "summary": "This paper presents an evaluation framework for assessing Large Language Models' (LLMs) capabilities in combinatorial optimization, specifically addressing the 2D bin-packing problem. We introduce a systematic methodology that combines LLMs with evolutionary algorithms to generate and refine heuristic solutions iteratively. Through comprehensive experiments comparing LLM generated heuristics against traditional approaches (Finite First-Fit and Hybrid First-Fit), we demonstrate that LLMs can produce more efficient solutions while requiring fewer computational resources. Our evaluation reveals that GPT-4o achieves optimal solutions within two iterations, reducing average bin usage from 16 to 15 bins while improving space utilization from 0.76-0.78 to 0.83. This work contributes to understanding LLM evaluation in specialized domains and establishes benchmarks for assessing LLM performance in combinatorial optimization tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.853884"
    },
    {
        "index": "#21",
        "title": "Ground-Truthing AI Energy Consumption: Validating CodeCarbon Against External Measurements",
        "link": "/arxiv/2509.22092",
        "arxiv_id": "2509.22092",
        "authors": "Raphael Fischer",
        "summary": "Although machine learning (ML) and artificial intelligence (AI) present fascinating opportunities for innovation, their rapid development is also significantly impacting our environment. In response to growing resource-awareness in the field, quantification tools such as the ML Emissions Calculator and CodeCarbon were developed to estimate the energy consumption and carbon emissions of running AI models. They are easy to incorporate into AI projects, however also make pragmatic assumptions and neglect important factors, raising the question of estimation accuracy. This study systematically evaluates the reliability of static and dynamic energy estimation approaches through comparisons with ground-truth measurements across hundreds of AI experiments. Based on the proposed validation framework, investigative insights into AI energy demand and estimation inaccuracies are provided. While generally following the patterns of AI energy consumption, the established estimation approaches are shown to consistently make errors of up to 40%. By providing empirical evidence on energy estimation quality and errors, this study establishes transparency and validates widely used tools for sustainable AI development. It moreover formulates guidelines for improving the state-of-the-art and offers code for extending the validation to other domains and tools, thus making important contributions to resource-aware ML and AI sustainability research.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.871748"
    },
    {
        "index": "#22",
        "title": "Generalizing Multi-Objective Search via Objective-Aggregation Functions",
        "link": "/arxiv/2509.22085",
        "arxiv_id": "2509.22085",
        "authors": "Hadar Peer, Eyal Weiss, Ron Alterovitz, Oren Salzman",
        "summary": "Multi-objective search (MOS) has become essential in robotics, as real-world robotic systems need to simultaneously balance multiple, often conflicting objectives. Recent works explore complex interactions between objectives, leading to problem formulations that do not allow the usage of out-of-the-box state-of-the-art MOS algorithms. In this paper, we suggest a generalized problem formulation that optimizes solution objectives via aggregation functions of hidden (search) objectives. We show that our formulation supports the application of standard MOS algorithms, necessitating only to properly extend several core operations to reflect the specific aggregation functions employed. We demonstrate our approach in several diverse robotics planning problems, spanning motion-planning for navigation, manipulation and planning fr medical systems under obstacle uncertainty as well as inspection planning, and route planning with different road types. We solve the problems using state-of-the-art MOS algorithms after properly extending their core operations, and provide empirical evidence that they outperform by orders of magnitude the vanilla versions of the algorithms applied to the same problems but without objective aggregation.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.872350"
    },
    {
        "index": "#25",
        "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments",
        "link": "/arxiv/2509.21998",
        "arxiv_id": "2509.21998",
        "authors": "Hanlin Zhu, Tianyu Guo, Song Mei, Stuart Russell, Nikhil Ghosh, Alberto Bietti, Jiantao Jiao",
        "summary": "As LLMs are increasingly deployed as agents, agentic reasoning - the ability to combine tool use, especially search, and reasoning - becomes a critical skill. However, it is hard to disentangle agentic reasoning when evaluated in complex environments and tasks. Current agent benchmarks often mix agentic reasoning with challenging math reasoning, expert-level knowledge, and other advanced capabilities. To fill this gap, we build a novel benchmark, GSM-Agent, where an LLM agent is required to solve grade-school-level reasoning problems, but is only presented with the question in the prompt without the premises that contain the necessary information to solve the task, and needs to proactively collect that information using tools. Although the original tasks are grade-school math problems, we observe that even frontier models like GPT-5 only achieve 67% accuracy. To understand and analyze the agentic reasoning patterns, we propose the concept of agentic reasoning graph: cluster the environment's document embeddings into nodes, and map each tool call to its nearest node to build a reasoning path. Surprisingly, we identify that the ability to revisit a previously visited node, widely taken as a crucial pattern in static reasoning, is often missing for agentic reasoning for many models. Based on the insight, we propose a tool-augmented test-time scaling method to improve LLM's agentic reasoning performance by adding tools to encourage models to revisit. We expect our benchmark and the agentic reasoning framework to aid future studies of understanding and pushing the boundaries of agentic reasoning.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.874380"
    },
    {
        "index": "#26",
        "title": "Bilinear relational structure fixes reversal curse and enables consistent model editing",
        "link": "/arxiv/2509.21993",
        "arxiv_id": "2509.21993",
        "authors": "Dong-Kyum Kim, Minsung Kim, Jea Kwon, Nakyeong Yang, Meeyoung Cha",
        "summary": "The reversal curse -- a language model's (LM) inability to infer an unseen fact ``B is A'' from a learned fact ``A is B'' -- is widely considered a fundamental limitation. We show that this is not an inherent failure but an artifact of how models encode knowledge. By training LMs from scratch on a synthetic dataset of relational knowledge graphs, we demonstrate that bilinear relational structure emerges in their hidden representations. This structure substantially alleviates the reversal curse, enabling LMs to infer unseen reverse facts. Crucially, we also find that this bilinear structure plays a key role in consistent model editing. When a fact is updated in a LM with this structure, the edit correctly propagates to its reverse and other logically dependent facts. In contrast, models lacking this representation not only suffer from the reversal curse but also fail to generalize edits, further introducing logical inconsistencies. Our results establish that training on a relational knowledge dataset induces the emergence of bilinear internal representations, which in turn enable LMs to behave in a logically consistent manner after editing. This implies that the success of model editing depends critically not just on editing algorithms but on the underlying representational geometry of the knowledge being modified.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.880293"
    },
    {
        "index": "#29",
        "title": "Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning",
        "link": "/arxiv/2509.21943",
        "arxiv_id": "2509.21943",
        "authors": "Carlo Dindorf, Jonas Dully, Steven Simon, Dennis Perchthaler, Stephan Becker, Hannah Ehmann, Kjell Heitmann, Bernd Stetter, Christian Diers, Michael Fröhlich",
        "summary": "Plantar pressure mapping is essential in clinical diagnostics and sports science, yet large heterogeneous datasets often contain outliers from technical errors or procedural inconsistencies. Statistical Parametric Mapping (SPM) provides interpretable analyses but is sensitive to alignment and its capacity for robust outlier detection remains unclear. This study compares an SPM approach with an explainable machine learning (ML) approach to establish transparent quality-control pipelines for plantar pressure datasets. Data from multiple centers were annotated by expert consensus and enriched with synthetic anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a non-parametric, registration-dependent SPM approach and (ii) a convolutional neural network (CNN), explained using SHapley Additive exPlanations (SHAP). Performance was assessed via nested cross-validation; explanation quality via a semantic differential survey with domain experts. The ML model reached high accuracy and outperformed SPM, which misclassified clinically meaningful variations and missed true outliers. Experts perceived both SPM and SHAP explanations as clear, useful, and trustworthy, though SPM was assessed less complex. These findings highlight the complementary potential of SPM and explainable ML as approaches for automated outlier detection in plantar pressure data, and underscore the importance of explainability in translating complex model outputs into interpretable insights that can effectively inform decision-making.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.882129"
    },
    {
        "index": "#30",
        "title": "DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling",
        "link": "/arxiv/2509.21902",
        "arxiv_id": "2509.21902",
        "authors": "Ruiqi Chen, Yi Mei, Fangfang Zhang, Mengjie Zhang",
        "summary": "Dynamic job shop scheduling, a fundamental combinatorial optimisation problem in various industrial sectors, poses substantial challenges for effective scheduling due to frequent disruptions caused by the arrival of new jobs. State-of-the-art methods employ machine learning to learn scheduling policies offline, enabling rapid responses to dynamic events. However, these offline policies are often imperfect, necessitating the use of planning techniques such as Monte Carlo Tree Search (MCTS) to improve performance at online decision time. The unpredictability of new job arrivals complicates online planning, as decisions based on incomplete problem information are vulnerable to disturbances. To address this issue, we propose the Dynamic Robust MCTS (DyRo-MCTS) approach, which integrates action robustness estimation into MCTS. DyRo-MCTS guides the production environment toward states that not only yield good scheduling outcomes but are also easily adaptable to future job arrivals. Extensive experiments show that DyRo-MCTS significantly improves the performance of offline-learned policies with negligible additional online planning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across various scheduling scenarios. Further analysis reveals that its ability to make robust scheduling decisions leads to long-term, sustainable performance gains under disturbances.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.882603"
    },
    {
        "index": "#31",
        "title": "GenesisGeo: Technical Report",
        "link": "/arxiv/2509.21896",
        "arxiv_id": "2509.21896",
        "authors": "Minfeng Zhu, Zi Wang, Sizhe Ji, Zhengtong Du, Junming Ke, Xiao Deng, Zanlang Yin, Xiuqi Huang, Heyu Wang, Wei Chen",
        "summary": "We present GenesisGeo, an automated theorem prover in Euclidean geometry. We have open-sourced a large-scale geometry dataset of 21.8 million geometric problems, over 3 million of which contain auxiliary constructions. Specially, we significantly accelerate the symbolic deduction engine DDARN by 120x through theorem matching, combined with a C++ implementation of its core components. Furthermore, we build our neuro-symbolic prover, GenesisGeo, upon Qwen3-0.6B-Base, which solves 24 of 30 problems (IMO silver medal level) in the IMO-AG-30 benchmark using a single model, and achieves 26 problems (IMO gold medal level) with a dual-model ensemble.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.883164"
    },
    {
        "index": "#32",
        "title": "TRACE: Learning to Compute on Graphs",
        "link": "/arxiv/2509.21886",
        "arxiv_id": "2509.21886",
        "authors": "Ziyang Zheng, Jiaying Zhu, Jingyi Zhou, Qiang Xu",
        "summary": "Learning to compute, the ability to model the functional behavior of a computational graph, is a fundamental challenge for graph representation learning. Yet, the dominant paradigm is architecturally mismatched for this task. This flawed assumption, central to mainstream message passing neural networks (MPNNs) and their conventional Transformer-based counterparts, prevents models from capturing the position-aware, hierarchical nature of computation. To resolve this, we introduce \\textbf{TRACE}, a new paradigm built on an architecturally sound backbone and a principled learning objective. First, TRACE employs a Hierarchical Transformer that mirrors the step-by-step flow of computation, providing a faithful architectural backbone that replaces the flawed permutation-invariant aggregation. Second, we introduce \\textbf{function shift learning}, a novel objective that decouples the learning problem. Instead of predicting the complex global function directly, our model is trained to predict only the \\textit{function shift}, the discrepancy between the true global function and a simple local approximation that assumes input independence. We validate this paradigm on electronic circuits, one of the most complex and economically critical classes of computational graphs. Across a comprehensive suite of benchmarks, TRACE substantially outperforms all prior architectures. These results demonstrate that our architecturally-aligned backbone and decoupled learning objective form a more robust paradigm for the fundamental challenge of learning to compute on graphs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.883606"
    },
    {
        "index": "#34",
        "title": "DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents",
        "link": "/arxiv/2509.21842",
        "arxiv_id": "2509.21842",
        "authors": "Yansong Ning, Rui Liu, Jun Wang, Kai Chen, Wei Li, Jun Fang, Kan Zheng, Naiqiang Tan, Hao Liu",
        "summary": "Travel planning (TP) agent has recently worked as an emerging building block to interact with external tools and resources for travel itinerary generation, ensuring enjoyable user experience. Despite its benefits, existing studies rely on hand craft prompt and fixed agent workflow, hindering more flexible and autonomous TP agent. This paper proposes DeepTravel, an end to end agentic reinforcement learning framework for building autonomous travel planning agent, capable of autonomously planning, executing tools, and reflecting on tool responses to explore, verify, and refine intermediate actions in multi step reasoning. To achieve this, we first construct a robust sandbox environment by caching transportation, accommodation and POI data, facilitating TP agent training without being constrained by real world APIs limitations (e.g., inconsistent outputs). Moreover, we develop a hierarchical reward modeling system, where a trajectory level verifier first checks spatiotemporal feasibility and filters unsatisfied travel itinerary, and then the turn level verifier further validate itinerary detail consistency with tool responses, enabling efficient and precise reward service. Finally, we propose the reply augmented reinforcement learning method that enables TP agent to periodically replay from a failures experience buffer, emerging notable agentic capacity. We deploy trained TP agent on DiDi Enterprise Solutions App and conduct comprehensive online and offline evaluations, demonstrating that DeepTravel enables small size LLMs (e.g., Qwen3 32B) to significantly outperform existing frontier LLMs such as OpenAI o1, o3 and DeepSeek R1 in travel planning tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.884693"
    },
    {
        "index": "#36",
        "title": "DS-STAR: Data Science Agent via Iterative Planning and Verification",
        "link": "/arxiv/2509.21825",
        "arxiv_id": "2509.21825",
        "authors": "Jaehyun Nam, Jinsung Yoon, Jiefeng Chen, Jinwoo Shin, Tomas Pfister",
        "summary": "Data science, which transforms raw data into actionable insights, is critical for data-driven decision-making. However, these tasks are often complex, involving steps for exploring multiple data sources and synthesizing findings to deliver insightful answers. While large language models (LLMs) show significant promise in automating this process, they often struggle with heterogeneous data formats and generate sub-optimal analysis plans, as verifying plan sufficiency is inherently difficult without ground-truth labels for such open-ended tasks. To overcome these limitations, we introduce DS-STAR, a novel data science agent. Specifically, DS-STAR makes three key contributions: (1) a data file analysis module that automatically explores and extracts context from diverse data formats, including unstructured types; (2) a verification step where an LLM-based judge evaluates the sufficiency of the analysis plan at each stage; and (3) a sequential planning mechanism that starts with a simple, executable plan and iteratively refines it based on the DS-STAR's feedback until its sufficiency is verified. This iterative refinement allows DS-STAR to reliably navigate complex analyses involving diverse data sources. Our experiments show that DS-STAR achieves state-of-the-art performance across three challenging benchmarks: DABStep, KramaBench, and DA-Code. Moreover, DS-STAR particularly outperforms baselines on hard tasks that require processing multiple data files with heterogeneous formats.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.890777"
    },
    {
        "index": "#37",
        "title": "ProRe: A Proactive Reward System for GUI Agents via Reasoner-Actor Collaboration",
        "link": "/arxiv/2509.21823",
        "arxiv_id": "2509.21823",
        "authors": "Gaole Dai, Shiqi Jiang, Ting Cao, Yuqing Yang, Yuanchun Li, Rui Tan, Mo Li, Lili Qiu",
        "summary": "Reward is critical to the evaluation and training of large language models (LLMs). However, existing rule-based or model-based reward methods struggle to generalize to GUI agents, where access to ground-truth trajectories or application databases is often unavailable, and static trajectory-based LLM-as-a-Judge approaches suffer from limited accuracy. To address these challenges, we propose ProRe, a proactive reward system that leverages a general-purpose reasoner and domain-specific evaluator agents (actors). The reasoner schedules targeted state probing tasks, which the evaluator agents then execute by actively interacting with the environment to collect additional observations. This enables the reasoner to assign more accurate and verifiable rewards to GUI agents. Empirical results on over 3K trajectories demonstrate that ProRe improves reward accuracy and F1 score by up to 5.3% and 19.4%, respectively. Furthermore, integrating ProRe with state-of-the-art policy agents yields a success rate improvement of up to 22.4%.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.891296"
    },
    {
        "index": "#38",
        "title": "D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents",
        "link": "/arxiv/2509.21799",
        "arxiv_id": "2509.21799",
        "authors": "Hongze Mi, Yibo Feng, Wenjie Lu, Yuqi Wang, Jinyuan Li, Song Cao, He Cui, Tengfei Tian, Xuelin Zhang, Haotian Luo, Di Sun, Naiqiang Tan, Gang Pan",
        "summary": "Graphical User Interface (GUI) agents aim to automate a wide spectrum of human tasks by emulating user interaction. Despite rapid advancements, current approaches are hindered by several critical challenges: data bottleneck in end-to-end training, high cost of delayed error detection, and risk of contradictory guidance. Inspired by the human cognitive loop of Thinking, Alignment, and Reflection, we present D-Artemis -- a novel deliberative framework in this paper. D-Artemis leverages a fine-grained, app-specific tip retrieval mechanism to inform its decision-making process. It also employs a proactive Pre-execution Alignment stage, where Thought-Action Consistency (TAC) Check module and Action Correction Agent (ACA) work in concert to mitigate the risk of execution failures. A post-execution Status Reflection Agent (SRA) completes the cognitive loop, enabling strategic learning from experience. Crucially, D-Artemis enhances the capabilities of general-purpose Multimodal large language models (MLLMs) for GUI tasks without the need for training on complex trajectory datasets, demonstrating strong generalization. D-Artemis establishes new state-of-the-art (SOTA) results across both major benchmarks, achieving a 75.8% success rate on AndroidWorld and 96.8% on ScreenSpot-V2. Extensive ablation studies further demonstrate the significant contribution of each component to the framework.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.891891"
    },
    {
        "index": "#39",
        "title": "Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety",
        "link": "/arxiv/2509.21782",
        "arxiv_id": "2509.21782",
        "authors": "Junliang Liu, Jingyu Xiao, Wenxin Tang, Wenxuan Wang, Zhixian Wang, Minrui Zhang, Shuanghe Yu",
        "summary": "Multimodal large language models (MLLMs) are increasingly positioned as AI collaborators for building complex web-related applications like GUI agents and front-end code generation. However, existing benchmarks largely emphasize visual perception or UI code generation, showing insufficient evaluation on the reasoning, robustness and safety capability required for end-to-end web applications. To bridge the gap, we introduce a comprehensive web understanding benchmark, named WebRSSBench, that jointly evaluates Reasoning, Robustness, and Safety across eight tasks, such as position relationship reasoning, color robustness, and safety critical detection, etc. The benchmark is constructed from 729 websites and contains 3799 question answer pairs that probe multi-step inference over page structure, text, widgets, and safety-critical interactions. To ensure reliable measurement, we adopt standardized prompts, deterministic evaluation scripts, and multi-stage quality control combining automatic checks with targeted human verification. We evaluate 12 MLLMs on WebRSSBench. The results reveal significant gaps, models still struggle with compositional and cross-element reasoning over realistic layouts, show limited robustness when facing perturbations in user interfaces and content such as layout rearrangements or visual style shifts, and are rather conservative in recognizing and avoiding safety critical or irreversible actions. Our code is available at https://github.com/jinliang-byte/webssrbench.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.892402"
    },
    {
        "index": "#41",
        "title": "Lifelong Learning with Behavior Consolidation for Vehicle Routing",
        "link": "/arxiv/2509.21765",
        "arxiv_id": "2509.21765",
        "authors": "Jiyuan Pei, Yi Mei, Jialin Liu, Mengjie Zhang, Xin Yao",
        "summary": "Recent neural solvers have demonstrated promising performance in learning to solve routing problems. However, existing studies are primarily based on one-off training on one or a set of predefined problem distributions and scales, i.e., tasks. When a new task arises, they typically rely on either zero-shot generalization, which may be poor due to the discrepancies between the new task and the training task(s), or fine-tuning the pretrained solver on the new task, which possibly leads to catastrophic forgetting of knowledge acquired from previous tasks. This paper explores a novel lifelong learning paradigm for neural VRP solvers, where multiple tasks with diverse distributions and scales arise sequentially over time. Solvers are required to effectively and efficiently learn to solve new tasks while maintaining their performance on previously learned tasks. Consequently, a novel framework called Lifelong Learning Router with Behavior Consolidation (LLR-BC) is proposed. LLR-BC consolidates prior knowledge effectively by aligning behaviors of the solver trained on a new task with the buffered ones in a decision-seeking way. To encourage more focus on crucial experiences, LLR-BC assigns greater consolidated weights to decisions with lower confidence. Extensive experiments on capacitated vehicle routing problems and traveling salesman problems demonstrate LLR-BC's effectiveness in training high-performance neural solvers in a lifelong learning setting, addressing the catastrophic forgetting issue, maintaining their plasticity, and improving zero-shot generalization ability.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.893555"
    },
    {
        "index": "#42",
        "title": "Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts",
        "link": "/arxiv/2509.21743",
        "arxiv_id": "2509.21743",
        "authors": "Ammar Ahmed, Azal Ahmad Khan, Ayaan Ahmad, Sheng Di, Zirui Liu, Ali Anwar",
        "summary": "Large reasoning models improve accuracy by producing long reasoning traces, but this inflates latency and cost, motivating inference-time efficiency. We propose Retrieval-of-Thought (RoT), which reuses prior reasoning as composable ``thought\" steps to guide new problems. RoT organizes steps into a thought graph with sequential and semantic edges to enable fast retrieval and flexible recombination. At inference, RoT retrieves query-relevant nodes and applies reward-guided traversal to assemble a problem-specific template that guides generation. This dynamic template reuse reduces redundant exploration and, therefore, reduces output tokens while preserving accuracy. We evaluate RoT on reasoning benchmarks with multiple models, measuring accuracy, token usage, latency, and memory overhead. Findings show small prompt growth but substantial efficiency gains, with RoT reducing output tokens by up to 40%, inference latency by 82%, and cost by 59% while maintaining accuracy. RoT establishes a scalable paradigm for efficient LRM reasoning via dynamic template construction through retrieval.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.894059"
    },
    {
        "index": "#43",
        "title": "Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization",
        "link": "/arxiv/2509.21718",
        "arxiv_id": "2509.21718",
        "authors": "Shehzeen Hussain, Paarth Neekhara, Xuesong Yang, Edresson Casanova, Subhankar Ghosh, Roy Fejgin, Ryan Langman, Mikyas Desta, Leili Tavabi, Jason Li",
        "summary": "Developing high-quality text-to-speech (TTS) systems for low-resource languages is challenging due to the scarcity of paired text and speech data. In contrast, automatic speech recognition (ASR) models for such languages are often more accessible, owing to large-scale multilingual pre-training efforts. We propose a framework based on Group Relative Policy Optimization (GRPO) to adapt an autoregressive, multilingual TTS model to new languages. Our method first establishes a language-agnostic foundation for TTS synthesis by training a multilingual baseline with International Phonetic Alphabet (IPA) tokens. Next, we fine-tune this model on limited paired data of the new languages to capture the target language's prosodic features. Finally, we apply GRPO to optimize the model using only unpaired text and speaker prompts, guided by a multi-objective reward from pretrained ASR, speaker verification, and audio quality estimation models. Experiments demonstrate that this pipeline produces intelligible and speaker-consistent speech in low-resource languages, substantially outperforming fine-tuning alone. Furthermore, our GRPO-based framework also improves TTS performance in high-resource languages, surpassing offline alignment methods such as Direct Preference Optimization (DPO) yielding superior intelligibility, speaker similarity, and audio quality.",
        "subjects": "Artificial Intelligence, Machine Learning, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.894642"
    },
    {
        "index": "#44",
        "title": "Can AI Perceive Physical Danger and Intervene?",
        "link": "/arxiv/2509.21651",
        "arxiv_id": "2509.21651",
        "authors": "Abhishek Jindal, Dmitry Kalashnikov, Oscar Chang, Divya Garikapati, Anirudha Majumdar, Pierre Sermanet, Vikas Sindhwani",
        "summary": "When AI interacts with the physical world -- as a robot or an assistive agent -- new safety challenges emerge beyond those of purely ``digital AI\". In such interactions, the potential for physical harm is direct and immediate. How well do state-of-the-art foundation models understand common-sense facts about physical safety, e.g. that a box may be too heavy to lift, or that a hot cup of coffee should not be handed to a child? In this paper, our contributions are three-fold: first, we develop a highly scalable approach to continuous physical safety benchmarking of Embodied AI systems, grounded in real-world injury narratives and operational safety constraints. To probe multi-modal safety understanding, we turn these narratives and constraints into photorealistic images and videos capturing transitions from safe to unsafe states, using advanced generative models. Secondly, we comprehensively analyze the ability of major foundation models to perceive risks, reason about safety, and trigger interventions; this yields multi-faceted insights into their deployment readiness for safety-critical agentic applications. Finally, we develop a post-training paradigm to teach models to explicitly reason about embodiment-specific safety constraints provided through system instructions. The resulting models generate thinking traces that make safety reasoning interpretable and transparent, achieving state of the art performance in constraint satisfaction evaluations. The benchmark will be released at https://asimov-benchmark.github.io/v2",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.900253"
    },
    {
        "index": "#45",
        "title": "Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries",
        "link": "/arxiv/2509.21633",
        "arxiv_id": "2509.21633",
        "authors": "Georgios Chochlakis, Jackson Trager, Vedant Jhaveri, Nikhil Ravichandran, Alexandros Potamianos, Shrikanth Narayanan",
        "summary": "We propose Semantic F1 Scores, novel evaluation metrics for subjective or fuzzy multi-label classification that quantify semantic relatedness between predicted and gold labels. Unlike the conventional F1 metrics that treat semantically related predictions as complete failures, Semantic F1 incorporates a label similarity matrix to compute soft precision-like and recall-like scores, from which the Semantic F1 scores are derived. Unlike existing similarity-based metrics, our novel two-step precision-recall formulation enables the comparison of label sets of arbitrary sizes without discarding labels or forcing matches between dissimilar labels. By granting partial credit for semantically related but nonidentical labels, Semantic F1 better reflects the realities of domains marked by human disagreement or fuzzy category boundaries. In this way, it provides fairer evaluations: it recognizes that categories overlap, that annotators disagree, and that downstream decisions based on similar predictions lead to similar outcomes. Through theoretical justification and extensive empirical validation on synthetic and real data, we show that Semantic F1 demonstrates greater interpretability and ecological validity. Because it requires only a domain-appropriate similarity matrix, which is robust to misspecification, and not a rigid ontology, it is applicable across tasks and modalities.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.900763"
    },
    {
        "index": "#46",
        "title": "Automated and Interpretable Survival Analysis from Multimodal Data",
        "link": "/arxiv/2509.21600",
        "arxiv_id": "2509.21600",
        "authors": "Mafalda Malafaia, Peter A. N. Bosman, Coen Rasch, Tanja Alderliesten",
        "summary": "Accurate and interpretable survival analysis remains a core challenge in oncology. With growing multimodal data and the clinical need for transparent models to support validation and trust, this challenge increases in complexity. We propose an interpretable multimodal AI framework to automate survival analysis by integrating clinical variables and computed tomography imaging. Our MultiFIX-based framework uses deep learning to infer survival-relevant features that are further explained: imaging features are interpreted via Grad-CAM, while clinical variables are modeled as symbolic expressions through genetic programming. Risk estimation employs a transparent Cox regression, enabling stratification into groups with distinct survival outcomes. Using the open-source RADCURE dataset for head and neck cancer, MultiFIX achieves a C-index of 0.838 (prediction) and 0.826 (stratification), outperforming the clinical and academic baseline approaches and aligning with known prognostic markers. These results highlight the promise of interpretable multimodal AI for precision oncology with MultiFIX.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.901266"
    },
    {
        "index": "#47",
        "title": "GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models",
        "link": "/arxiv/2509.21593",
        "arxiv_id": "2509.21593",
        "authors": "Peng Luo, Xiayin Lou, Yu Zheng, Zhuo Zheng, Stefano Ermon",
        "summary": "Geospatial modeling provides critical solutions for pressing global challenges such as sustainability and climate change. Existing large language model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at evolving generic code but lack the domain knowledge and multi-step reasoning required for complex geospatial problems. We introduce GeoEvolve, a multi-agent LLM framework that couples evolutionary search with geospatial domain knowledge to automatically design and refine geospatial algorithms. GeoEvolve operates in two nested loops: an inner loop leverages a code evolver to generate and mutate candidate solutions, while an outer agentic controller evaluates global elites and queries a GeoKnowRAG module -- a structured geospatial knowledge base that injects theoretical priors from geography. This knowledge-guided evolution steers the search toward theoretically meaningful and computationally efficient algorithms. We evaluate GeoEvolve on two fundamental and classical tasks: spatial interpolation (kriging) and spatial uncertainty quantification (geospatial conformal prediction). Across these benchmarks, GeoEvolve automatically improves and discovers new algorithms, incorporating geospatial theory on top of classical models. It reduces spatial interpolation error (RMSE) by 13-21% and enhances uncertainty estimation performance by 17\\%. Ablation studies confirm that domain-guided retrieval is essential for stable, high-quality evolution. These results demonstrate that GeoEvolve provides a scalable path toward automated, knowledge-driven geospatial modeling, opening new opportunities for trustworthy and efficient AI-for-Science discovery.",
        "subjects": "Artificial Intelligence, Physics and Society",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.901761"
    },
    {
        "index": "#48",
        "title": "EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks",
        "link": "/arxiv/2509.21567",
        "arxiv_id": "2509.21567",
        "authors": "Mohammad Parsa Afshar, Aryan Azimi",
        "summary": "Prediction of consumer behavior is one of the important purposes in marketing, cognitive neuroscience, and human-computer interaction. The electroencephalography (EEG) data can help analyze the decision process by providing detailed information about the brain's neural activity. In this research, a comparative approach is utilized for predicting consumer behavior by EEG data. In the first step, the features of the EEG data from the NeuMa dataset were extracted and cleaned. For the Graph Neural Network (GNN) models, the brain connectivity features were created. Different machine learning models, such as classical models and Graph Neural Networks, are used and compared. The GNN models with different architectures are implemented to have a comprehensive comparison; furthermore, a wide range of classical models, such as ensemble models, are applied, which can be very helpful to show the difference and performance of each model on the dataset. Although the results did not show a significant difference overall, the GNN models generally performed better in some basic criteria where classical models were not satisfactory. This study not only shows that combining EEG signal analysis and machine learning models can provide an approach to deeper understanding of consumer behavior, but also provides a comprehensive comparison between the machine learning models that have been widely used in previous studies in the EEG-based neuromarketing such as Support Vector Machine (SVM), and the models which are not used or rarely used in the field, like Graph Neural Networks.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.902223"
    },
    {
        "index": "#50",
        "title": "Correct Reasoning Paths Visit Shared Decision Pivots",
        "link": "/arxiv/2509.21549",
        "arxiv_id": "2509.21549",
        "authors": "Dongkyu Cho, Amy B. Z. Zhang, Bilel Fehri, Sheng Wang, Rumi Chunara, Rui Song, Hengrui Cai",
        "summary": "Chain-of-thought (CoT) reasoning exposes the intermediate thinking process of large language models (LLMs), yet verifying those traces at scale remains unsolved. In response, we introduce the idea of decision pivots-minimal, verifiable checkpoints that any correct reasoning path must visit. We hypothesize that correct reasoning, though stylistically diverse, converge on the same pivot set, while incorrect ones violate at least one pivot. Leveraging this property, we propose a self-training pipeline that (i) samples diverse reasoning paths and mines shared decision pivots, (ii) compresses each trace into pivot-focused short-path reasoning using an auxiliary verifier, and (iii) post-trains the model using its self-generated outputs. The proposed method aligns reasoning without ground truth reasoning data or external metrics. Experiments on standard benchmarks such as LogiQA, MedQA, and MATH500 show the effectiveness of our method.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.903331"
    },
    {
        "index": "#54",
        "title": "Toward a Physics of Deep Learning and Brains",
        "link": "/arxiv/2509.22649",
        "arxiv_id": "2509.22649",
        "authors": "Arsham Ghavasieh, Meritxell Vila-Minana, Akanksha Khurd, John Beggs, Gerardo Ortiz, Santo Fortunato",
        "summary": "Deep neural networks and brains both learn and share superficial similarities: processing nodes are likened to neurons and adjustable weights are likened to modifiable synapses. But can a unified theoretical framework be found to underlie them both? Here we show that the equations used to describe neuronal avalanches in living brains can also be applied to cascades of activity in deep neural networks. These equations are derived from non-equilibrium statistical physics and show that deep neural networks learn best when poised between absorbing and active phases. Because these networks are strongly driven by inputs, however, they do not operate at a true critical point but within a quasi-critical regime -- one that still approximately satisfies crackling noise scaling relations. By training networks with different initializations, we show that maximal susceptibility is a more reliable predictor of learning than proximity to the critical point itself. This provides a blueprint for engineering improved network performance. Finally, using finite-size scaling we identify distinct universality classes, including Barkhausen noise and directed percolation. This theoretical framework demonstrates that universal features are shared by both biological and artificial neural networks.",
        "subjects": "Disordered Systems and Neural Networks, Statistical Mechanics, Artificial Intelligence, Adaptation and Self-Organizing Systems, Biological Physics",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.910753"
    },
    {
        "index": "#64",
        "title": "Learning Admissible Heuristics for A*: Theory and Practice",
        "link": "/arxiv/2509.22626",
        "arxiv_id": "2509.22626",
        "authors": "Ehsan Futuhi, Nathan R. Sturtevant",
        "summary": "Heuristic functions are central to the performance of search algorithms such as A-star, where admissibility - the property of never overestimating the true shortest-path cost - guarantees solution optimality. Recent deep learning approaches often disregard admissibility and provide limited guarantees on generalization beyond the training data. This paper addresses both of these limitations. First, we pose heuristic learning as a constrained optimization problem and introduce Cross-Entropy Admissibility (CEA), a loss function that enforces admissibility during training. On the Rubik's Cube domain, this method yields near-admissible heuristics with significantly stronger guidance than compressed pattern database (PDB) heuristics. Theoretically, we study the sample complexity of learning heuristics. By leveraging PDB abstractions and the structural properties of graphs such as the Rubik's Cube, we tighten the bound on the number of training samples needed for A-star to generalize. Replacing a general hypothesis class with a ReLU neural network gives bounds that depend primarily on the network's width and depth, rather than on graph size. Using the same network, we also provide the first generalization guarantees for goal-dependent heuristics.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.921376"
    },
    {
        "index": "#65",
        "title": "A Theoretical Analysis of Discrete Flow Matching Generative Models",
        "link": "/arxiv/2509.22623",
        "arxiv_id": "2509.22623",
        "authors": "Maojiang Su, Mingcheng Lu, Jerry Yao-Chieh Hu, Shang Wu, Zhao Song, Alex Reneau, Han Liu",
        "summary": "We provide a theoretical analysis for end-to-end training Discrete Flow Matching (DFM) generative models. DFM is a promising discrete generative modeling framework that learns the underlying generative dynamics by training a neural network to approximate the transformative velocity field. Our analysis establishes a clear chain of guarantees by decomposing the final distribution estimation error. We first prove that the total variation distance between the generated and target distributions is controlled by the risk of the learned velocity field. We then bound this risk by analyzing its two primary sources: (i) Approximation Error, where we quantify the capacity of the Transformer architecture to represent the true velocity, and (ii) Estimation Error, where we derive statistical convergence rates that bound the error from training on a finite dataset. By composing these results, we provide the first formal proof that the distribution generated by a trained DFM model provably converges to the true data distribution as the training set size increases.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.921921"
    },
    {
        "index": "#68",
        "title": "Quantile Advantage Estimation for Entropy-Safe Reasoning",
        "link": "/arxiv/2509.22611",
        "arxiv_id": "2509.22611",
        "authors": "Junkang Wu, Kexin Huang, Jiancan Wu, An Zhang, Xiang Wang, Xiangnan He",
        "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) strengthens LLM reasoning, but training often oscillates between {entropy collapse} and {entropy explosion}. We trace both hazards to the mean baseline used in value-free RL (e.g., GRPO and DAPO), which improperly penalizes negative-advantage samples under reward outliers. We propose {Quantile Advantage Estimation} (QAE), replacing the mean with a group-wise K-quantile baseline. QAE induces a response-level, two-regime gate: on hard queries (p <= 1 - K) it reinforces rare successes, while on easy queries (p > 1 - K) it targets remaining failures. Under first-order softmax updates, we prove {two-sided entropy safety}, giving lower and upper bounds on one-step entropy change that curb explosion and prevent collapse. Empirically, this minimal modification stabilizes entropy, sparsifies credit assignment (with tuned K, roughly 80% of responses receive zero advantage), and yields sustained pass@1 gains on Qwen3-8B/14B-Base across AIME 2024/2025 and AMC 2023. These results identify {baseline design} -- rather than token-level heuristics -- as the primary mechanism for scaling RLVR.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.923450"
    },
    {
        "index": "#70",
        "title": "From Parameters to Behavior: Unsupervised Compression of the Policy Space",
        "link": "/arxiv/2509.22566",
        "arxiv_id": "2509.22566",
        "authors": "Davide Tenedini, Riccardo Zamboni, Mirco Mutti, Marcello Restelli",
        "summary": "Despite its recent successes, Deep Reinforcement Learning (DRL) is notoriously sample-inefficient. We argue that this inefficiency stems from the standard practice of optimizing policies directly in the high-dimensional and highly redundant parameter space $\\Theta$. This challenge is greatly compounded in multi-task settings. In this work, we develop a novel, unsupervised approach that compresses the policy parameter space $\\Theta$ into a low-dimensional latent space $\\mathcal{Z}$. We train a generative model $g:\\mathcal{Z}\\to\\Theta$ by optimizing a behavioral reconstruction loss, which ensures that the latent space is organized by functional similarity rather than proximity in parameterization. We conjecture that the inherent dimensionality of this manifold is a function of the environment's complexity, rather than the size of the policy network. We validate our approach in continuous control domains, showing that the parameterization of standard policy networks can be compressed up to five orders of magnitude while retaining most of its expressivity. As a byproduct, we show that the learned manifold enables task-specific adaptation via Policy Gradient operating in the latent space $\\mathcal{Z}$.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.924640"
    },
    {
        "index": "#73",
        "title": "ConQuER: Modular Architectures for Control and Bias Mitigation in IQP Quantum Generative Models",
        "link": "/arxiv/2509.22551",
        "arxiv_id": "2509.22551",
        "authors": "Xiaocheng Zou, Shijin Duan, Charles Fleming, Gaowen Liu, Ramana Rao Kompella, Shaolei Ren, Xiaolin Xu",
        "summary": "Quantum generative models based on instantaneous quantum polynomial (IQP) circuits show great promise in learning complex distributions while maintaining classical trainability. However, current implementations suffer from two key limitations: lack of controllability over generated outputs and severe generation bias towards certain expected patterns. We present a Controllable Quantum Generative Framework, ConQuER, which addresses both challenges through a modular circuit architecture. ConQuER embeds a lightweight controller circuit that can be directly combined with pre-trained IQP circuits to precisely control the output distribution without full retraining. Leveraging the advantages of IQP, our scheme enables precise control over properties such as the Hamming Weight distribution with minimal parameter and gate overhead. In addition, inspired by the controller design, we extend this modular approach through data-driven optimization to embed implicit control paths in the underlying IQP architecture, significantly reducing generation bias on structured datasets. ConQuER retains efficient classical training properties and high scalability. We experimentally validate ConQuER on multiple quantum state datasets, demonstrating its superior control accuracy and balanced generation performance, only with very low overhead cost over original IQP circuits. Our framework bridges the gap between the advantages of quantum computing and the practical needs of controllable generation modeling.",
        "subjects": "Quantum Physics, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.931436"
    },
    {
        "index": "#77",
        "title": "Ontological foundations for contrastive explanatory narration of robot plans",
        "link": "/arxiv/2509.22493",
        "arxiv_id": "2509.22493",
        "authors": "Alberto Olivares-Alarcos, Sergi Foix, Júlia Borràs, Gerard Canal, Guillem Alenyà",
        "summary": "Mutual understanding of artificial agents' decisions is key to ensuring a trustworthy and successful human-robot interaction. Hence, robots are expected to make reasonable decisions and communicate them to humans when needed. In this article, the focus is on an approach to modeling and reasoning about the comparison of two competing plans, so that robots can later explain the divergent result. First, a novel ontological model is proposed to formalize and reason about the differences between competing plans, enabling the classification of the most appropriate one (e.g., the shortest, the safest, the closest to human preferences, etc.). This work also investigates the limitations of a baseline algorithm for ontology-based explanatory narration. To address these limitations, a novel algorithm is presented, leveraging divergent knowledge between plans and facilitating the construction of contrastive narratives. Through empirical evaluation, it is observed that the explanations excel beyond the baseline method.",
        "subjects": "Robotics, Artificial Intelligence, Information Retrieval, Logic in Computer Science",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.933690"
    },
    {
        "index": "#78",
        "title": "A Machine Learning Pipeline for Multiple Sclerosis Biomarker Discovery: Comparing explainable AI and Traditional Statistical Approaches",
        "link": "/arxiv/2509.22484",
        "arxiv_id": "2509.22484",
        "authors": "Samuele Punzo, Silvia Giulia Galfrè, Francesco Massafra, Alessandro Maglione, Corrado Priami, Alina Sîrbu",
        "summary": "We present a machine learning pipeline for biomarker discovery in Multiple Sclerosis (MS), integrating eight publicly available microarray datasets from Peripheral Blood Mononuclear Cells (PBMC). After robust preprocessing we trained an XGBoost classifier optimized via Bayesian search. SHapley Additive exPlanations (SHAP) were used to identify key features for model prediction, indicating thus possible biomarkers. These were compared with genes identified through classical Differential Expression Analysis (DEA). Our comparison revealed both overlapping and unique biomarkers between SHAP and DEA, suggesting complementary strengths. Enrichment analysis confirmed the biological relevance of SHAP-selected genes, linking them to pathways such as sphingolipid signaling, Th1/Th2/Th17 cell differentiation, and Epstein-Barr virus infection all known to be associated with MS. This study highlights the value of combining explainable AI (xAI) with traditional statistical methods to gain deeper insights into disease mechanism.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.934220"
    },
    {
        "index": "#79",
        "title": "OFMU: Optimization-Driven Framework for Machine Unlearning",
        "link": "/arxiv/2509.22483",
        "arxiv_id": "2509.22483",
        "authors": "Sadia Asif, Mohammad Mohammadi Amiri",
        "summary": "Large language models deployed in sensitive applications increasingly require the ability to unlearn specific knowledge, such as user requests, copyrighted materials, or outdated information, without retraining from scratch to ensure regulatory compliance, user privacy, and safety. This task, known as machine unlearning, aims to remove the influence of targeted data (forgetting) while maintaining performance on the remaining data (retention). A common approach is to formulate this as a multi-objective problem and reduce it to a single-objective problem via scalarization, where forgetting and retention losses are combined using a weighted sum. However, this often results in unstable training dynamics and degraded model utility due to conflicting gradient directions. To address these challenges, we propose OFMU, a penalty-based bi-level optimization framework that explicitly prioritizes forgetting while preserving retention through a hierarchical structure. Our method enforces forgetting via an inner maximization step that incorporates a similarity-aware penalty to decorrelate the gradients of the forget and retention objectives, and restores utility through an outer minimization step. To ensure scalability, we develop a two-loop algorithm with provable convergence guarantees under both convex and non-convex regimes. We further provide a rigorous theoretical analysis of convergence rates and show that our approach achieves better trade-offs between forgetting efficacy and model utility compared to prior methods. Extensive experiments across vision and language benchmarks demonstrate that OFMU consistently outperforms existing unlearning methods in both forgetting efficacy and retained utility.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.934687"
    },
    {
        "index": "#82",
        "title": "Learning the Neighborhood: Contrast-Free Multimodal Self-Supervised Molecular Graph Pretraining",
        "link": "/arxiv/2509.22468",
        "arxiv_id": "2509.22468",
        "authors": "Boshra Ariguib, Mathias Niepert, Andrei Manolache",
        "summary": "High-quality molecular representations are essential for property prediction and molecular design, yet large labeled datasets remain scarce. While self-supervised pretraining on molecular graphs has shown promise, many existing approaches either depend on hand-crafted augmentations or complex generative objectives, and often rely solely on 2D topology, leaving valuable 3D structural information underutilized. To address this gap, we introduce C-FREE (Contrast-Free Representation learning on Ego-nets), a simple framework that integrates 2D graphs with ensembles of 3D conformers. C-FREE learns molecular representations by predicting subgraph embeddings from their complementary neighborhoods in the latent space, using fixed-radius ego-nets as modeling units across different conformers. This design allows us to integrate both geometric and topological information within a hybrid Graph Neural Network (GNN)-Transformer backbone, without negatives, positional encodings, or expensive pre-processing. Pretraining on the GEOM dataset, which provides rich 3D conformational diversity, C-FREE achieves state-of-the-art results on MoleculeNet, surpassing contrastive, generative, and other multimodal self-supervised methods. Fine-tuning across datasets with diverse sizes and molecule types further demonstrates that pretraining transfers effectively to new chemical domains, highlighting the importance of 3D-informed molecular representations.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.941313"
    },
    {
        "index": "#84",
        "title": "Physics-informed GNN for medium-high voltage AC power flow with edge-aware attention and line search correction operator",
        "link": "/arxiv/2509.22458",
        "arxiv_id": "2509.22458",
        "authors": "Changhun Kim, Timon Conrad, Redwanul Karim, Julian Oelhaf, David Riebesel, Tomás Arias-Vergara, Andreas Maier, Johann Jäger, Siming Bayer",
        "summary": "Physics-informed graph neural networks (PIGNNs) have emerged as fast AC power-flow solvers that can replace classic Newton--Raphson (NR) solvers, especially when thousands of scenarios must be evaluated. However, current PIGNNs still need accuracy improvements at parity speed; in particular, the physics loss is inoperative at inference, which can deter operational adoption. We address this with PIGNN-Attn-LS, combining an edge-aware attention mechanism that explicitly encodes line physics via per-edge biases, capturing the grid's anisotropy, with a backtracking line-search-based globalized correction operator that restores an operative decrease criterion at inference. Training and testing use a realistic High-/Medium-Voltage scenario generator, with NR used only to construct reference states. On held-out HV cases consisting of 4--32-bus grids, PIGNN-Attn-LS achieves a test RMSE of 0.00033 p.u. in voltage and 0.08$^\\circ$ in angle, outperforming the PIGNN-MLP baseline by 99.5\\% and 87.1\\%, respectively. With streaming micro-batches, it delivers 2--5$\\times$ faster batched inference than NR on 4--1024-bus grids.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.942531"
    },
    {
        "index": "#86",
        "title": "Learning to Ball: Composing Policies for Long-Horizon Basketball Moves",
        "link": "/arxiv/2509.22442",
        "arxiv_id": "2509.22442",
        "authors": "Pei Xu, Zhen Wu, Ruocheng Wang, Vishnu Sarukkai, Kayvon Fatahalian, Ioannis Karamouzas, Victor Zordan, C. Karen Liu",
        "summary": "Learning a control policy for a multi-phase, long-horizon task, such as basketball maneuvers, remains challenging for reinforcement learning approaches due to the need for seamless policy composition and transitions between skills. A long-horizon task typically consists of distinct subtasks with well-defined goals, separated by transitional subtasks with unclear goals but critical to the success of the entire task. Existing methods like the mixture of experts and skill chaining struggle with tasks where individual policies do not share significant commonly explored states or lack well-defined initial and terminal states between different phases. In this paper, we introduce a novel policy integration framework to enable the composition of drastically different motor skills in multi-phase long-horizon tasks with ill-defined intermediate states. Based on that, we further introduce a high-level soft router to enable seamless and robust transitions between the subtasks. We evaluate our framework on a set of fundamental basketball skills and challenging transitions. Policies trained by our approach can effectively control the simulated character to interact with the ball and accomplish the long-horizon task specified by real-time user commands, without relying on ball trajectory references.",
        "subjects": "Graphics, Artificial Intelligence, Machine Learning, Robotics",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.943616"
    },
    {
        "index": "#88",
        "title": "Global Convergence in Neural ODEs: Impact of Activation Functions",
        "link": "/arxiv/2509.22436",
        "arxiv_id": "2509.22436",
        "authors": "Tianxiang Gao, Siyuan Sun, Hailiang Liu, Hongyang Gao",
        "summary": "Neural Ordinary Differential Equations (ODEs) have been successful in various applications due to their continuous nature and parameter-sharing efficiency. However, these unique characteristics also introduce challenges in training, particularly with respect to gradient computation accuracy and convergence analysis. In this paper, we address these challenges by investigating the impact of activation functions. We demonstrate that the properties of activation functions, specifically smoothness and nonlinearity, are critical to the training dynamics. Smooth activation functions guarantee globally unique solutions for both forward and backward ODEs, while sufficient nonlinearity is essential for maintaining the spectral properties of the Neural Tangent Kernel (NTK) during training. Together, these properties enable us to establish the global convergence of Neural ODEs under gradient descent in overparameterized regimes. Our theoretical findings are validated by numerical experiments, which not only support our analysis but also provide practical guidelines for scaling Neural ODEs, potentially leading to faster training and improved performance in real-world applications.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.944667"
    },
    {
        "index": "#89",
        "title": "An Ontology for Unified Modeling of Tasks, Actions, Environments, and Capabilities in Personal Service Robotics",
        "link": "/arxiv/2509.22434",
        "arxiv_id": "2509.22434",
        "authors": "Margherita Martorana, Francesca Urgese, Ilaria Tiddi, Stefan Schlobach",
        "summary": "Personal service robots are increasingly used in domestic settings to assist older adults and people requiring support. Effective operation involves not only physical interaction but also the ability to interpret dynamic environments, understand tasks, and choose appropriate actions based on context. This requires integrating both hardware components (e.g. sensors, actuators) and software systems capable of reasoning about tasks, environments, and robot capabilities. Frameworks such as the Robot Operating System (ROS) provide open-source tools that help connect low-level hardware with higher-level functionalities. However, real-world deployments remain tightly coupled to specific platforms. As a result, solutions are often isolated and hard-coded, limiting interoperability, reusability, and knowledge sharing. Ontologies and knowledge graphs offer a structured way to represent tasks, environments, and robot capabilities. Existing ontologies, such as the Socio-physical Model of Activities (SOMA) and the Descriptive Ontology for Linguistic and Cognitive Engineering (DOLCE), provide models for activities, spatial relationships, and reasoning structures. However, they often focus on specific domains and do not fully capture the connection between environment, action, robot capabilities, and system-level integration. In this work, we propose the Ontology for roBOts and acTions (OntoBOT), which extends existing ontologies to provide a unified representation of tasks, actions, environments, and capabilities. Our contributions are twofold: (1) we unify these aspects into a cohesive ontology to support formal reasoning about task execution, and (2) we demonstrate its generalizability by evaluating competency questions across four embodied agents - TIAGo, HSR, UR3, and Stretch - showing how OntoBOT enables context-aware reasoning, task-oriented execution, and knowledge sharing in service robotics.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.945158"
    },
    {
        "index": "#90",
        "title": "Partial Parameter Updates for Efficient Distributed Training",
        "link": "/arxiv/2509.22418",
        "arxiv_id": "2509.22418",
        "authors": "Anastasiia Filippova, Angelos Katharopoulos, David Grangier, Ronan Collobert",
        "summary": "We introduce a memory- and compute-efficient method for low-communication distributed training. Existing methods reduce communication by performing multiple local updates between infrequent global synchronizations. We demonstrate that their efficiency can be significantly improved by restricting backpropagation: instead of updating all the parameters, each node updates only a fixed subset while keeping the remainder frozen during local steps. This constraint substantially reduces peak memory usage and training FLOPs, while a full forward pass over all parameters eliminates the need for cross-node activation exchange. Experiments on a $1.3$B-parameter language model trained across $32$ nodes show that our method matches the perplexity of prior low-communication approaches under identical token and bandwidth budgets while reducing training FLOPs and peak memory.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.945650"
    },
    {
        "index": "#94",
        "title": "SpinGPT: A Large-Language-Model Approach to Playing Poker Correctly",
        "link": "/arxiv/2509.22387",
        "arxiv_id": "2509.22387",
        "authors": "Narada Maugin, Tristan Cazenave",
        "summary": "The Counterfactual Regret Minimization (CFR) algorithm and its variants have enabled the development of pokerbots capable of beating the best human players in heads-up (1v1) cash games and competing with them in six-player formats. However, CFR's computational complexity rises exponentially with the number of players. Furthermore, in games with three or more players, following Nash equilibrium no longer guarantees a non-losing outcome. These limitations, along with others, significantly restrict the applicability of CFR to the most popular formats: tournaments. Motivated by the recent success of Large Language Models (LLM) in chess and Diplomacy, we present SpinGPT, the first LLM tailored to Spin & Go, a popular three-player online poker format. SpinGPT is trained in two stages: (1) Supervised Fine-Tuning on 320k high-stakes expert decisions; (2) Reinforcement Learning on 270k solver-generated hands. Our results show that SpinGPT matches the solver's actions in 78% of decisions (tolerant accuracy). With a simple deep-stack heuristic, it achieves 13.4 +/- 12.9 BB/100 versus Slumbot in heads-up over 30,000 hands (95% CI). These results suggest that LLMs could be a new way to deal with multi-player imperfect-information games like poker.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Science and Game Theory",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.952948"
    },
    {
        "index": "#95",
        "title": "Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach",
        "link": "/arxiv/2509.22378",
        "arxiv_id": "2509.22378",
        "authors": "Zijian Zhao, Dian Jin, Zijing Zhou",
        "summary": "Recently, Image-to-Music (I2M) generation has garnered significant attention, with potential applications in fields such as gaming, advertising, and multi-modal art creation. However, due to the ambiguous and subjective nature of I2M tasks, most end-to-end methods lack interpretability, leaving users puzzled about the generation results. Even methods based on emotion mapping face controversy, as emotion represents only a singular aspect of art. Additionally, most learning-based methods require substantial computational resources and large datasets for training, hindering accessibility for common users. To address these challenges, we propose the first Vision Language Model (VLM)-based I2M framework that offers high interpretability and low computational cost. Specifically, we utilize ABC notation to bridge the text and music modalities, enabling the VLM to generate music using natural language. We then apply multi-modal Retrieval-Augmented Generation (RAG) and self-refinement techniques to allow the VLM to produce high-quality music without external training. Furthermore, we leverage the generated motivations in text and the attention maps from the VLM to provide explanations for the generated results in both text and image modalities. To validate our method, we conduct both human studies and machine evaluations, where our method outperforms others in terms of music quality and music-image consistency, indicating promising results. Our code is available at https://github.com/RS2002/Image2Music .",
        "subjects": "Sound, Artificial Intelligence, Multimedia, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.953456"
    },
    {
        "index": "#98",
        "title": "Forecasting the Future with Yesterday's Climate: Temperature Bias in AI Weather and Climate Models",
        "link": "/arxiv/2509.22359",
        "arxiv_id": "2509.22359",
        "authors": "Jacob B. Landsberg, Elizabeth A. Barnes",
        "summary": "AI-based climate and weather models have rapidly gained popularity, providing faster forecasts with skill that can match or even surpass that of traditional dynamical models. Despite this success, these models face a key challenge: predicting future climates while being trained only with historical data. In this study, we investigate this issue by analyzing boreal winter land temperature biases in AI weather and climate models. We examine two weather models, FourCastNet V2 Small (FourCastNet) and Pangu Weather (Pangu), evaluating their predictions for 2020-2025 and Ai2 Climate Emulator version 2 (ACE2) for 1996-2010. These time periods lie outside of the respective models' training sets and are significantly more recent than the bulk of their training data, allowing us to assess how well the models generalize to new, i.e. more modern, conditions. We find that all three models produce cold-biased mean temperatures, resembling climates from 15-20 years earlier than the period they are predicting. In some regions, like the Eastern U.S., the predictions resemble climates from as much as 20-30 years earlier. Further analysis shows that FourCastNet's and Pangu's cold bias is strongest in the hottest predicted temperatures, indicating limited training exposure to modern extreme heat events. In contrast, ACE2's bias is more evenly distributed but largest in regions, seasons, and parts of the temperature distribution where climate change has been most pronounced. These findings underscore the challenge of training AI models exclusively on historical data and highlight the need to account for such biases when applying them to future climate prediction.",
        "subjects": "Atmospheric and Oceanic Physics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.955175"
    },
    {
        "index": "#99",
        "title": "Stochastic activations",
        "link": "/arxiv/2509.22358",
        "arxiv_id": "2509.22358",
        "authors": "Maria Lomeli, Matthijs Douze, Gergely Szilvasy, Loic Cabannes, Jade Copet, Sainbayar Sukhbaatar, Jason Weston, Gabriel Synnaeve, Pierre-Emmanuel Mazaré, Hervé Jégou",
        "summary": "We introduce stochastic activations. This novel strategy randomly selects between several non-linear functions in the feed-forward layer of a large language model. In particular, we choose between SILU or RELU depending on a Bernoulli draw. This strategy circumvents the optimization problem associated with RELU, namely, the constant shape for negative inputs that prevents the gradient flow. We leverage this strategy in two ways: (1) We use stochastic activations during pre-training and fine-tune the model with RELU, which is used at inference time to provide sparse latent vectors. This reduces the inference FLOPs and translates into a significant speedup in the CPU. Interestingly, this leads to much better results than training from scratch with the RELU activation function. (2) We evaluate stochastic activations for generation. This strategy performs reasonably well: it is only slightly inferior to the best deterministic non-linearity, namely SILU combined with temperature scaling. This offers an alternative to existing strategies by providing a controlled way to increase the diversity of the generated text.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.955754"
    },
    {
        "index": "#100",
        "title": "Context and Diversity Matter: The Emergence of In-Context Learning in World Models",
        "link": "/arxiv/2509.22353",
        "arxiv_id": "2509.22353",
        "authors": "Fan Wang, Zhiyuan Chen, Yuxuan Zhong, Sunjian Zheng, Pengtao Shao, Bo Yu, Shaoshan Liu, Jianan Wang, Ning Ding, Yang Cao, Yu Kang",
        "summary": "The capability of predicting environmental dynamics underpins both biological neural systems and general embodied AI in adapting to their surroundings. Yet prevailing approaches rest on static world models that falter when confronted with novel or rare configurations. We investigate in-context environment learning (ICEL), shifting attention from zero-shot performance to the growth and asymptotic limits of the world model. Our contributions are three-fold: (1) we formalize in-context learning of a world model and identify two core mechanisms: environment recognition and environment learning; (2) we derive error upper-bounds for both mechanisms that expose how the mechanisms emerge; and (3) we empirically confirm that distinct ICL mechanisms exist in the world model, and we further investigate how data distribution and model architecture affect ICL in a manner consistent with theory. These findings demonstrate the potential of self-adapting world models and highlight the key factors behind the emergence of ICEL, most notably the necessity of long context and diverse environments.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.956346"
    },
    {
        "index": "#101",
        "title": "SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis",
        "link": "/arxiv/2509.22352",
        "arxiv_id": "2509.22352",
        "authors": "Marie Brockschmidt, Maresa Schröder, Stefan Feuerriegel",
        "summary": "Survival analysis is a cornerstone of clinical research by modeling time-to-event outcomes such as metastasis, disease relapse, or patient death. Unlike standard tabular data, survival data often come with incomplete event information due to dropout, or loss to follow-up. This poses unique challenges for synthetic data generation, where it is crucial for clinical research to faithfully reproduce both the event-time distribution and the censoring mechanism. In this paper, we propose SurvDiff, an end-to-end diffusion model specifically designed for generating synthetic data in survival analysis. SurvDiff is tailored to capture the data-generating mechanism by jointly generating mixed-type covariates, event times, and right-censoring, guided by a survival-tailored loss function. The loss encodes the time-to-event structure and directly optimizes for downstream survival tasks, which ensures that SurvDiff (i) reproduces realistic event-time distributions and (ii) preserves the censoring mechanism. Across multiple datasets, we show that \\survdiff consistently outperforms state-of-the-art generative baselines in both distributional fidelity and downstream evaluation metrics across multiple medical datasets. To the best of our knowledge, SurvDiff is the first diffusion model explicitly designed for generating synthetic survival data.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.956811"
    },
    {
        "index": "#104",
        "title": "Spectral Collapse Drives Loss of Plasticity in Deep Continual Learning",
        "link": "/arxiv/2509.22335",
        "arxiv_id": "2509.22335",
        "authors": "Naicheng He, Kaicheng Guo, Arjun Prakash, Saket Tiwari, Ruo Yu Tao, Tyrone Serapio, Amy Greenwald, George Konidaris",
        "summary": "We investigate why deep neural networks suffer from \\emph{loss of plasticity} in deep continual learning, failing to learn new tasks without reinitializing parameters. We show that this failure is preceded by Hessian spectral collapse at new-task initialization, where meaningful curvature directions vanish and gradient descent becomes ineffective. To characterize the necessary condition for successful training, we introduce the notion of $\\tau$-trainability and show that current plasticity preserving algorithms can be unified under this framework. Targeting spectral collapse directly, we then discuss the Kronecker factored approximation of the Hessian, which motivates two regularization enhancements: maintaining high effective feature rank and applying $L2$ penalties. Experiments on continual supervised and reinforcement learning tasks confirm that combining these two regularizers effectively preserves plasticity.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.958324"
    },
    {
        "index": "#106",
        "title": "Progressive Weight Loading: Accelerating Initial Inference and Gradually Boosting Performance on Resource-Constrained Environments",
        "link": "/arxiv/2509.22319",
        "arxiv_id": "2509.22319",
        "authors": "Hyunwoo Kim, Junha Lee, Mincheol Choi, Jeonghwan Lee, Jaeshin Cho",
        "summary": "Deep learning models have become increasingly large and complex, resulting in higher memory consumption and computational demands. Consequently, model loading times and initial inference latency have increased, posing significant challenges in mobile and latency-sensitive environments where frequent model loading and unloading are required, which directly impacts user experience. While Knowledge Distillation (KD) offers a solution by compressing large teacher models into smaller student ones, it often comes at the cost of reduced performance. To address this trade-off, we propose Progressive Weight Loading (PWL), a novel technique that enables fast initial inference by first deploying a lightweight student model, then incrementally replacing its layers with those of a pre-trained teacher model. To support seamless layer substitution, we introduce a training method that not only aligns intermediate feature representations between student and teacher layers, but also improves the overall output performance of the student model. Our experiments on VGG, ResNet, and ViT architectures demonstrate that models trained with PWL maintain competitive distillation performance and gradually improve accuracy as teacher layers are loaded-matching the final accuracy of the full teacher model without compromising initial inference speed. This makes PWL particularly suited for dynamic, resource-constrained deployments where both responsiveness and performance are critical.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.964397"
    },
    {
        "index": "#107",
        "title": "Adaptive Policy Backbone via Shared Network",
        "link": "/arxiv/2509.22310",
        "arxiv_id": "2509.22310",
        "authors": "Bumgeun Park, Donghwan Lee",
        "summary": "Reinforcement learning (RL) has achieved impressive results across domains, yet learning an optimal policy typically requires extensive interaction data, limiting practical deployment. A common remedy is to leverage priors, such as pre-collected datasets or reference policies, but their utility degrades under task mismatch between training and deployment. While prior work has sought to address this mismatch, it has largely been restricted to in-distribution settings. To address this challenge, we propose Adaptive Policy Backbone (APB), a meta-transfer RL method that inserts lightweight linear layers before and after a shared backbone, thereby enabling parameter-efficient fine-tuning (PEFT) while preserving prior knowledge during adaptation. Our results show that APB improves sample efficiency over standard RL and adapts to out-of-distribution (OOD) tasks where existing meta-RL baselines typically fail.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.964682"
    },
    {
        "index": "#109",
        "title": "HEAPr: Hessian-based Efficient Atomic Expert Pruning in Output Space",
        "link": "/arxiv/2509.22299",
        "arxiv_id": "2509.22299",
        "authors": "Ke Li, Zheng Yang, Zhongbin Zhou, Feng Xue, Zhonglin Jiang, Wenxiao Wang",
        "summary": "Mixture-of-Experts (MoE) architectures in large language models (LLMs) deliver exceptional performance and reduced inference costs compared to dense LLMs. However, their large parameter counts result in prohibitive memory requirements, limiting practical deployment. While existing pruning methods primarily focus on expert-level pruning, this coarse granularity often leads to substantial accuracy degradation. In this work, we introduce HEAPr, a novel pruning algorithm that decomposes experts into smaller, indivisible atomic experts, enabling more precise and flexible atomic expert pruning. To measure the importance of each atomic expert, we leverage second-order information based on principles similar to Optimal Brain Surgeon (OBS) theory. To address the computational and storage challenges posed by second-order information, HEAPr exploits the inherent properties of atomic experts to transform the second-order information from expert parameters into that of atomic expert parameters, and further simplifies it to the second-order information of atomic expert outputs. This approach reduces the space complexity from $O(d^4)$, where d is the model's dimensionality, to $O(d^2)$. HEAPr requires only two forward passes and one backward pass on a small calibration set to compute the importance of atomic experts. Extensive experiments on MoE models, including DeepSeek MoE and Qwen MoE family, demonstrate that HEAPr outperforms existing expert-level pruning methods across a wide range of compression ratios and benchmarks. Specifically, HEAPr achieves nearly lossless compression at compression ratios of 20% ~ 25% in most models, while also reducing FLOPs nearly by 20%. The code can be found at \\href{https://github.com/LLIKKE/HEAPr}{https://github.com/LLIKKE/HEAPr}.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.965328"
    },
    {
        "index": "#112",
        "title": "Leveraging Large Language Models for Robot-Assisted Learning of Morphological Structures in Preschool Children with Language Vulnerabilities",
        "link": "/arxiv/2509.22287",
        "arxiv_id": "2509.22287",
        "authors": "Stina Sundstedt, Mattias Wingren, Susanne Hägglund, Daniel Ventus",
        "summary": "Preschool children with language vulnerabilities -- such as developmental language disorders or immigration related language challenges -- often require support to strengthen their expressive language skills. Based on the principle of implicit learning, speech-language therapists (SLTs) typically embed target morphological structures (e.g., third person -s) into everyday interactions or game-based learning activities. Educators are recommended by SLTs to do the same. This approach demands precise linguistic knowledge and real-time production of various morphological forms (e.g., \"Daddy wears these when he drives to work\"). The task becomes even more demanding when educators or parent also must keep children engaged and manage turn-taking in a game-based activity. In the TalBot project our multiprofessional team have developed an application in which the Furhat conversational robot plays the word retrieval game \"Alias\" with children to improve language skills. Our application currently employs a large language model (LLM) to manage gameplay, dialogue, affective responses, and turn-taking. Our next step is to further leverage the capacity of LLMs so the robot can generate and deliver specific morphological targets during the game. We hypothesize that a robot could outperform humans at this task. Novel aspects of this approach are that the robot could ultimately serve as a model and tutor for both children and professionals and that using LLM capabilities in this context would support basic communication needs for children with language vulnerabilities. Our long-term goal is to create a robust LLM-based Robot-Assisted Language Learning intervention capable of teaching a variety of morphological structures across different languages.",
        "subjects": "Robotics, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.966248"
    },
    {
        "index": "#113",
        "title": "A Global Analysis of Cyber Threats to the Energy Sector: \"Currents of Conflict\" from a Geopolitical Perspective",
        "link": "/arxiv/2509.22280",
        "arxiv_id": "2509.22280",
        "authors": "Gustavo Sánchez, Ghada Elbez, Veit Hagenmeyer",
        "summary": "The escalating frequency and sophistication of cyber threats increased the need for their comprehensive understanding. This paper explores the intersection of geopolitical dynamics, cyber threat intelligence analysis, and advanced detection technologies, with a focus on the energy domain. We leverage generative artificial intelligence to extract and structure information from raw cyber threat descriptions, enabling enhanced analysis. By conducting a geopolitical comparison of threat actor origins and target regions across multiple databases, we provide insights into trends within the general threat landscape. Additionally, we evaluate the effectiveness of cybersecurity tools -- with particular emphasis on learning-based techniques -- in detecting indicators of compromise for energy-targeted attacks. This analysis yields new insights, providing actionable information to researchers, policy makers, and cybersecurity professionals.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.966537"
    },
    {
        "index": "#114",
        "title": "Wavelet-Induced Rotary Encodings: RoPE Meets Graphs",
        "link": "/arxiv/2509.22259",
        "arxiv_id": "2509.22259",
        "authors": "Isaac Reid, Arijit Sehanobish, Cedrik Höfs, Bruno Mlodozeniec, Leonhard Vulpius, Federico Barbero, Adrian Weller, Krzysztof Choromanski, Richard E. Turner, Petar Veličković",
        "summary": "We introduce WIRE: Wavelet-Induced Rotary Encodings. WIRE extends Rotary Position Encodings (RoPE), a popular algorithm in LLMs and ViTs, to graph-structured data. We demonstrate that WIRE is more general than RoPE, recovering the latter in the special case of grid graphs. WIRE also enjoys a host of desirable theoretical properties, including equivariance under node ordering permutation, compatibility with linear attention, and (under select assumptions) asymptotic dependence on graph resistive distance. We test WIRE on a range of synthetic and real-world tasks, including identifying monochromatic subgraphs, semantic segmentation of point clouds, and more standard graph benchmarks. We find it to be effective in settings where the underlying graph structure is important.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.966871"
    },
    {
        "index": "#116",
        "title": "Secure and Efficient Access Control for Computer-Use Agents via Context Space",
        "link": "/arxiv/2509.22256",
        "arxiv_id": "2509.22256",
        "authors": "Haochen Gong, Chenxiao Li, Rui Chang, Wenbo Shen",
        "summary": "Large language model (LLM)-based computer-use agents represent a convergence of AI and OS capabilities, enabling natural language to control system- and application-level functions. However, due to LLMs' inherent uncertainty issues, granting agents control over computers poses significant security risks. When agent actions deviate from user intentions, they can cause irreversible consequences. Existing mitigation approaches, such as user confirmation and LLM-based dynamic action validation, still suffer from limitations in usability, security, and performance. To address these challenges, we propose CSAgent, a system-level, static policy-based access control framework for computer-use agents. To bridge the gap between static policy and dynamic context and user intent, CSAgent introduces intent- and context-aware policies, and provides an automated toolchain to assist developers in constructing and refining them. CSAgent enforces these policies through an optimized OS service, ensuring that agent actions can only be executed under specific user intents and contexts. CSAgent supports protecting agents that control computers through diverse interfaces, including API, CLI, and GUI. We implement and evaluate CSAgent, which successfully defends against more than 99.36% of attacks while introducing only 6.83% performance overhead.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Operating Systems",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.967500"
    },
    {
        "index": "#119",
        "title": "ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity",
        "link": "/arxiv/2509.22246",
        "arxiv_id": "2509.22246",
        "authors": "Xiaoyang Liu, Tao Zhu, Zineng Dong, Yuntian Liu, Qingfeng Guo, Zhaoxuan Liu, Yu Chen, Tao Luo",
        "summary": "Statement autoformalization, the automated translation of statements from natural language into formal languages, has seen significant advancements, yet the development of automated evaluation metrics remains limited. Existing metrics for formal statement similarity often fail to balance semantic and structural information. String-based approaches capture syntactic structure but ignore semantic meaning, whereas proof-based methods validate semantic equivalence but disregard structural nuances and, critically, provide no graded similarity score in the event of proof failure. To address these issues, we introduce ASSESS (A Semantic and Structural Evaluation Framework for Statement Similarity), which comprehensively integrates semantic and structural information to provide a continuous similarity score. Our framework first transforms formal statements into Operator Trees to capture their syntactic structure and then computes a similarity score using our novel TransTED (Transformation Tree Edit Distance) Similarity metric, which enhances traditional Tree Edit Distance by incorporating semantic awareness through transformations. For rigorous validation, we present EPLA (Evaluating Provability and Likeness for Autoformalization), a new benchmark of 524 expert-annotated formal statement pairs derived from miniF2F and ProofNet, with labels for both semantic provability and structural likeness. Experiments on EPLA demonstrate that TransTED Similarity outperforms existing methods, achieving state-of-the-art accuracy and the highest Kappa coefficient. The benchmark, and implementation code will be made public soon.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.968771"
    },
    {
        "index": "#121",
        "title": "Fairness-Aware Reinforcement Learning (FAReL): A Framework for Transparent and Balanced Sequential Decision-Making",
        "link": "/arxiv/2509.22232",
        "arxiv_id": "2509.22232",
        "authors": "Alexandra Cimpean, Nicole Orzan, Catholijn Jonker, Pieter Libin, Ann Nowé",
        "summary": "Equity in real-world sequential decision problems can be enforced using fairness-aware methods. Therefore, we require algorithms that can make suitable and transparent trade-offs between performance and the desired fairness notions. As the desired performance-fairness trade-off is hard to specify a priori, we propose a framework where multiple trade-offs can be explored. Insights provided by the reinforcement learning algorithm regarding the obtainable performance-fairness trade-offs can then guide stakeholders in selecting the most appropriate policy. To capture fairness, we propose an extended Markov decision process, $f$MDP, that explicitly encodes individuals and groups. Given this $f$MDP, we formalise fairness notions in the context of sequential decision problems and formulate a fairness framework that computes fairness measures over time. We evaluate our framework in two scenarios with distinct fairness requirements: job hiring, where strong teams must be composed while treating applicants equally, and fraud detection, where fraudulent transactions must be detected while ensuring the burden on customers is fairly distributed. We show that our framework learns policies that are more fair across multiple scenarios, with only minor loss in performance reward. Moreover, we observe that group and individual fairness notions do not necessarily imply one another, highlighting the benefit of our framework in settings where both fairness types are desired. Finally, we provide guidelines on how to apply this framework across different problem settings.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.974928"
    },
    {
        "index": "#125",
        "title": "Automatic Discovery of One Parameter Subgroups of $SO(n)$",
        "link": "/arxiv/2509.22219",
        "arxiv_id": "2509.22219",
        "authors": "Pavan Karjol, Vivek V Kashyap, Rohan Kashyap, Prathosh A P",
        "summary": "We introduce a novel framework for the automatic discovery of one-parameter subgroups ($H_{\\gamma}$) of $SO(3)$ and, more generally, $SO(n)$. One-parameter subgroups of $SO(n)$ are crucial in a wide range of applications, including robotics, quantum mechanics, and molecular structure analysis. Our method utilizes the standard Jordan form of skew-symmetric matrices, which define the Lie algebra of $SO(n)$, to establish a canonical form for orbits under the action of $H_{\\gamma}$. This canonical form is then employed to derive a standardized representation for $H_{\\gamma}$-invariant functions. By learning the appropriate parameters, the framework uncovers the underlying one-parameter subgroup $H_{\\gamma}$. The effectiveness of the proposed approach is demonstrated through tasks such as double pendulum modeling, moment of inertia prediction, top quark tagging and invariant polynomial regression, where it successfully recovers meaningful subgroup structure and produces interpretable, symmetry-aware representations.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.976955"
    },
    {
        "index": "#129",
        "title": "Reversible GNS for Dissipative Fluids with Consistent Bidirectional Dynamics",
        "link": "/arxiv/2509.22207",
        "arxiv_id": "2509.22207",
        "authors": "Mu Huang, Linning Xu, Mingyue Dai, Yidi Shao, Bo Dai",
        "summary": "Simulating physically plausible trajectories toward user-defined goals is a fundamental yet challenging task in fluid dynamics. While particle-based simulators can efficiently reproduce forward dynamics, inverse inference remains difficult, especially in dissipative systems where dynamics are irreversible and optimization-based solvers are slow, unstable, and often fail to converge. In this work, we introduce the Reversible Graph Network Simulator (R-GNS), a unified framework that enforces bidirectional consistency within a single graph architecture. Unlike prior neural simulators that approximate inverse dynamics by fitting backward data, R-GNS does not attempt to reverse the underlying physics. Instead, we propose a mathematically invertible design based on residual reversible message passing with shared parameters, coupling forward dynamics with inverse inference to deliver accurate predictions and efficient recovery of plausible initial states. Experiments on three dissipative benchmarks (Water-3D, WaterRamps, and WaterDrop) show that R-GNS achieves higher accuracy and consistency with only one quarter of the parameters, and performs inverse inference more than 100 times faster than optimization-based baselines. For forward simulation, R-GNS matches the speed of strong GNS baselines, while in goal-conditioned tasks it eliminates iterative optimization and achieves orders-of-magnitude speedups. On goal-conditioned tasks, R-GNS further demonstrates its ability to complex target shapes (e.g., characters \"L\" and \"N\") through vivid, physically consistent trajectories. To our knowledge, this is the first reversible framework that unifies forward and inverse simulation for dissipative fluid systems.",
        "subjects": "Machine Learning, Artificial Intelligence, Fluid Dynamics",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.979096"
    },
    {
        "index": "#131",
        "title": "MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training",
        "link": "/arxiv/2509.22199",
        "arxiv_id": "2509.22199",
        "authors": "Haoyun Li, Ivan Zhang, Runqi Ouyang, Xiaofeng Wang, Zheng Zhu, Zhiqin Yang, Zhentao Zhang, Boyuan Wang, Chaojun Ni, Wenkang Qin, Xinze Chen, Yun Ye, Guan Huang, Zhenbo Song, Xingang Wang",
        "summary": "Vision Language Action (VLA) models derive their generalization capability from diverse training data, yet collecting embodied robot interaction data remains prohibitively expensive. In contrast, human demonstration videos are far more scalable and cost-efficient to collect, and recent studies confirm their effectiveness in training VLA models. However, a significant domain gap persists between human videos and robot-executed videos, including unstable camera viewpoints, visual discrepancies between human hands and robotic arms, and differences in motion dynamics. To bridge this gap, we propose MimicDreamer, a framework that turns fast, low-cost human demonstrations into robot-usable supervision by jointly aligning vision, viewpoint, and actions to directly support policy training. For visual alignment, we propose H2R Aligner, a video diffusion model that generates high-fidelity robot demonstration videos by transferring motion from human manipulation footage. For viewpoint stabilization, EgoStabilizer is proposed, which canonicalizes egocentric videos via homography and inpaints occlusions and distortions caused by warping. For action alignment, we map human hand trajectories to the robot frame and apply a constrained inverse kinematics solver to produce feasible, low-jitter joint commands with accurate pose tracking. Empirically, VLA models trained purely on our synthesized human-to-robot videos achieve few-shot execution on real robots. Moreover, scaling training with human data significantly boosts performance compared to models trained solely on real robot data; our approach improves the average success rate by 14.7\\% across six representative manipulation tasks.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.985328"
    },
    {
        "index": "#132",
        "title": "Learning Equivariant Functions via Quadratic Forms",
        "link": "/arxiv/2509.22184",
        "arxiv_id": "2509.22184",
        "authors": "Pavan Karjol, Vivek V Kashyap, Rohan Kashyap, Prathosh A P",
        "summary": "In this study, we introduce a method for learning group (known or unknown) equivariant functions by learning the associated quadratic form $x^T A x$ corresponding to the group from the data. Certain groups, known as orthogonal groups, preserve a specific quadratic form, and we leverage this property to uncover the underlying symmetry group under the assumption that it is orthogonal. By utilizing the corresponding unique symmetric matrix and its inherent diagonal form, we incorporate suitable inductive biases into the neural network architecture, leading to models that are both simplified and efficient. Our approach results in an invariant model that preserves norms, while the equivariant model is represented as a product of a norm-invariant model and a scale-invariant model, where the ``product'' refers to the group action. Moreover, we extend our framework to a more general setting where the function acts on tuples of input vectors via a diagonal (or product) group action. In this extension, the equivariant function is decomposed into an angular component extracted solely from the normalized first vector and a scale-invariant component that depends on the full Gram matrix of the tuple. This decomposition captures the inter-dependencies between multiple inputs while preserving the underlying group symmetry. We assess the effectiveness of our framework across multiple tasks, including polynomial regression, top quark tagging, and moment of inertia matrix prediction. Comparative analysis with baseline methods demonstrates that our model consistently excels in both discovering the underlying symmetry and efficiently learning the corresponding equivariant function.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.985822"
    },
    {
        "index": "#133",
        "title": "Efficiency Boost in Decentralized Optimization: Reimagining Neighborhood Aggregation with Minimal Overhead",
        "link": "/arxiv/2509.22174",
        "arxiv_id": "2509.22174",
        "authors": "Durgesh Kalwar, Mayank Baranwal, Harshad Khadilkar",
        "summary": "In today's data-sensitive landscape, distributed learning emerges as a vital tool, not only fortifying privacy measures but also streamlining computational operations. This becomes especially crucial within fully decentralized infrastructures where local processing is imperative due to the absence of centralized aggregation. Here, we introduce DYNAWEIGHT, a novel framework to information aggregation in multi-agent networks. DYNAWEIGHT offers substantial acceleration in decentralized learning with minimal additional communication and memory overhead. Unlike traditional static weight assignments, such as Metropolis weights, DYNAWEIGHT dynamically allocates weights to neighboring servers based on their relative losses on local datasets. Consequently, it favors servers possessing diverse information, particularly in scenarios of substantial data heterogeneity. Our experiments on various datasets MNIST, CIFAR10, and CIFAR100 incorporating various server counts and graph topologies, demonstrate notable enhancements in training speeds. Notably, DYNAWEIGHT functions as an aggregation scheme compatible with any underlying server-level optimization algorithm, underscoring its versatility and potential for widespread integration.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.986299"
    },
    {
        "index": "#134",
        "title": "Teaching AI to Feel: A Collaborative, Full-Body Exploration of Emotive Communication",
        "link": "/arxiv/2509.22168",
        "arxiv_id": "2509.22168",
        "authors": "Esen K. Tütüncü, Lissette Lemus, Kris Pilcher, Holger Sprengel, Jordi Sabater-Mir",
        "summary": "Commonaiverse is an interactive installation exploring human emotions through full-body motion tracking and real-time AI feedback. Participants engage in three phases: Teaching, Exploration and the Cosmos Phase, collaboratively expressing and interpreting emotions with the system. The installation integrates MoveNet for precise motion tracking and a multi-recommender AI system to analyze emotional states dynamically, responding with adaptive audiovisual outputs. By shifting from top-down emotion classification to participant-driven, culturally diverse definitions, we highlight new pathways for inclusive, ethical affective computing. We discuss how this collaborative, out-of-the-box approach pushes multimedia research beyond single-user facial analysis toward a more embodied, co-created paradigm of emotional AI. Furthermore, we reflect on how this reimagined framework fosters user agency, reduces bias, and opens avenues for advanced interactive applications.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.986803"
    },
    {
        "index": "#135",
        "title": "Lightweight error mitigation strategies for post-training N:M activation sparsity in LLMs",
        "link": "/arxiv/2509.22166",
        "arxiv_id": "2509.22166",
        "authors": "Shirin Alanova, Kristina Kazistova, Ekaterina Galaeva, Alina Kostromina, Vladimir Smirnov, Redko Dmitry, Alexey Dontsov, Maxim Zhelnin, Evgeny Burnaev, Egor Shvetsov",
        "summary": "The demand for efficient large language model (LLM) inference has intensified the focus on sparsification techniques. While semi-structured (N:M) pruning is well-established for weights, its application to activation pruning remains underexplored despite its potential for dynamic, input-adaptive compression and reductions in I/O overhead. This work presents a comprehensive analysis of methods for post-training N:M activation pruning in LLMs. Across multiple LLMs, we demonstrate that pruning activations enables superior preservation of generative capabilities compared to weight pruning at equivalent sparsity levels. We evaluate lightweight, plug-and-play error mitigation techniques and pruning criteria, establishing strong hardware-friendly baselines that require minimal calibration. Furthermore, we explore sparsity patterns beyond NVIDIA's standard 2:4, showing that the 16:32 pattern achieves performance nearly on par with unstructured sparsity. However, considering the trade-off between flexibility and hardware implementation complexity, we focus on the 8:16 pattern as a superior candidate. Our findings provide both effective practical methods for activation pruning and a motivation for future hardware to support more flexible sparsity patterns. Our code is available https://anonymous.4open.science/r/Structured-Sparse-Activations-Inference-EC3C/README.md .",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.987369"
    },
    {
        "index": "#136",
        "title": "Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization",
        "link": "/arxiv/2509.22161",
        "arxiv_id": "2509.22161",
        "authors": "Takashi Morita",
        "summary": "Vector quantization, which discretizes a continuous vector space into a finite set of representative vectors (a codebook), has been widely adopted in modern machine learning. Despite its effectiveness, vector quantization poses a fundamental challenge: the non-differentiable quantization step blocks gradient backpropagation. Smoothed vector quantization addresses this issue by relaxing the hard assignment of a codebook vector into a weighted combination of codebook entries, represented as the matrix product of a simplex vector and the codebook. Effective smoothing requires two properties: (1) smoothed quantizers should remain close to a onehot vector, ensuring tight approximation, and (2) all codebook entries should be utilized, preventing code collapse. Existing methods typically address these desiderata separately. By contrast, the present study introduces a simple and intuitive regularization that promotes both simultaneously by minimizing the distance between each simplex vertex and its $K$-nearest smoothed quantizers. Experiments on representative benchmarks, including discrete image autoencoding and contrastive speech representation learning, demonstrate that the proposed method achieves more reliable codebook utilization and improves performance compared to prior approaches.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.987812"
    },
    {
        "index": "#143",
        "title": "The AI_INFN Platform: Artificial Intelligence Development in the Cloud",
        "link": "/arxiv/2509.22117",
        "arxiv_id": "2509.22117",
        "authors": "Lucio Anderlini, Giulio Bianchini, Diego Ciangottini, Stefano Dal Pra, Diego Michelotto, Rosa Petrini, Daniele Spiga",
        "summary": "Machine Learning (ML) is driving a revolution in the way scientists design, develop, and deploy data-intensive software. However, the adoption of ML presents new challenges for the computing infrastructure, particularly in terms of provisioning and orchestrating access to hardware accelerators for development, testing, and production. The INFN-funded project AI_INFN (Artificial Intelligence at INFN) aims at fostering the adoption of ML techniques within INFN use cases by providing support on multiple aspects, including the provisioning of AI-tailored computing resources. It leverages cloud-native solutions in the context of INFN Cloud, to share hardware accelerators as effectively as possible, ensuring the diversity of the Institute's research activities is not compromised. In this contribution, we provide an update on the commissioning of a Kubernetes platform designed to ease the development of GPU-powered data analysis workflows and their scalability on heterogeneous distributed computing resources, also using the offloading mechanism with Virtual Kubelet and InterLink API. This setup can manage workflows across different resource providers, including sites of the Worldwide LHC Computing Grid and supercomputers such as CINECA Leonardo, providing a model for use cases requiring dedicated infrastructures for different parts of the workload. Initial test results, emerging case studies, and integration scenarios will be presented with functional tests and benchmarks.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.996661"
    },
    {
        "index": "#144",
        "title": "Learning More with Less: A Dynamic Dual-Level Down-Sampling Framework for Efficient Policy Optimization",
        "link": "/arxiv/2509.22115",
        "arxiv_id": "2509.22115",
        "authors": "Chao Wang, Tao Yang, Hongtao Tian, Yunsheng Shi, Qiyao Ma, Xiaotao Liu, Ting Yao, Wenbo Ding",
        "summary": "Critic-free methods like GRPO reduce memory demands by estimating advantages from multiple rollouts but tend to converge slowly, as critical learning signals are diluted by an abundance of uninformative samples and tokens. To tackle this challenge, we propose the \\textbf{Dynamic Dual-Level Down-Sampling (D$^3$S)} framework that prioritizes the most informative samples and tokens across groups to improve the efficient of policy optimization. D$^3$S operates along two levels: (1) the sample-level, which selects a subset of rollouts to maximize advantage variance ($\\text{Var}(A)$). We theoretically proven that this selection is positively correlated with the upper bound of the policy gradient norms, yielding higher policy gradients. (2) the token-level, which prioritizes tokens with a high product of advantage magnitude and policy entropy ($|A_{i,t}|\\times H_{i,t}$), focusing updates on tokens where the policy is both uncertain and impactful. Moreover, to prevent overfitting to high-signal data, D$^3$S employs a dynamic down-sampling schedule inspired by curriculum learning. This schedule starts with aggressive down-sampling to accelerate early learning and gradually relaxes to promote robust generalization. Extensive experiments on Qwen2.5 and Llama3.1 demonstrate that integrating D$^3$S into advanced RL algorithms achieves state-of-the-art performance and generalization while requiring \\textit{fewer} samples and tokens across diverse reasoning benchmarks. Our code is added in the supplementary materials and will be made publicly available.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.997210"
    },
    {
        "index": "#145",
        "title": "Reinforcement Learning for Durable Algorithmic Recourse",
        "link": "/arxiv/2509.22102",
        "arxiv_id": "2509.22102",
        "authors": "Marina Ceccon, Alessandro Fabris, Goran Radanović, Asia J. Biega, Gian Antonio Susto",
        "summary": "Algorithmic recourse seeks to provide individuals with actionable recommendations that increase their chances of receiving favorable outcomes from automated decision systems (e.g., loan approvals). While prior research has emphasized robustness to model updates, considerably less attention has been given to the temporal dynamics of recourse--particularly in competitive, resource-constrained settings where recommendations shape future applicant pools. In this work, we present a novel time-aware framework for algorithmic recourse, explicitly modeling how candidate populations adapt in response to recommendations. Additionally, we introduce a novel reinforcement learning (RL)-based recourse algorithm that captures the evolving dynamics of the environment to generate recommendations that are both feasible and valid. We design our recommendations to be durable, supporting validity over a predefined time horizon T. This durability allows individuals to confidently reapply after taking time to implement the suggested changes. Through extensive experiments in complex simulation environments, we show that our approach substantially outperforms existing baselines, offering a superior balance between feasibility and long-term validity. Together, these results underscore the importance of incorporating temporal and behavioral dynamics into the design of practical recourse systems.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.997718"
    },
    {
        "index": "#147",
        "title": "Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation",
        "link": "/arxiv/2509.22093",
        "arxiv_id": "2509.22093",
        "authors": "Xiaohuan Pei, Yuxing Chen, Siyu Xu, Yunke Wang, Yuheng Shi, Chang Xu",
        "summary": "Robotic manipulation with Vision-Language-Action models requires efficient inference over long-horizon multi-modal context, where attention to dense visual tokens dominates computational cost. Existing methods optimize inference speed by reducing visual redundancy within VLA models, but they overlook the varying redundancy across robotic manipulation stages. We observe that the visual token redundancy is higher in coarse manipulation phase than in fine-grained operations, and is strongly correlated with the action dynamic. Motivated by this observation, we propose \\textbf{A}ction-aware \\textbf{D}ynamic \\textbf{P}runing (\\textbf{ADP}), a multi-modal pruning framework that integrates text-driven token selection with action-aware trajectory gating. Our method introduces a gating mechanism that conditions the pruning signal on recent action trajectories, using past motion windows to adaptively adjust token retention ratios in accordance with dynamics, thereby balancing computational efficiency and perceptual precision across different manipulation stages. Extensive experiments on the LIBERO suites and diverse real-world scenarios demonstrate that our method significantly reduces FLOPs and action inference latency (\\textit{e.g.} $1.35 \\times$ speed up on OpenVLA-OFT) while maintaining competitive success rates (\\textit{e.g.} 25.8\\% improvements with OpenVLA) compared to baselines, thereby providing a simple plug-in path to efficient robot policies that advances the efficiency and performance frontier of robotic manipulation. Our project website is: \\href{https://vla-adp.github.io/}{ADP.com}.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.998892"
    },
    {
        "index": "#148",
        "title": "The Rogue Scalpel: Activation Steering Compromises LLM Safety",
        "link": "/arxiv/2509.22067",
        "arxiv_id": "2509.22067",
        "authors": "Anton Korznikov, Andrey Galichin, Alexey Dontsov, Oleg Y. Rogov, Ivan Oseledets, Elena Tutubalina",
        "summary": "Activation steering is a promising technique for controlling LLM behavior by adding semantically meaningful vectors directly into a model's hidden states during inference. It is often framed as a precise, interpretable, and potentially safer alternative to fine-tuning. We demonstrate the opposite: steering systematically breaks model alignment safeguards, making it comply with harmful requests. Through extensive experiments on different model families, we show that even steering in a random direction can increase the probability of harmful compliance from 0% to 2-27%. Alarmingly, steering benign features from a sparse autoencoder (SAE), a common source of interpretable directions, increases these rates by a further 2-4%. Finally, we show that combining 20 randomly sampled vectors that jailbreak a single prompt creates a universal attack, significantly increasing harmful compliance on unseen requests. These results challenge the paradigm of safety through interpretability, showing that precise control over model internals does not guarantee precise control over model behavior.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.999398"
    },
    {
        "index": "#150",
        "title": "Decoding Deception: Understanding Automatic Speech Recognition Vulnerabilities in Evasion and Poisoning Attacks",
        "link": "/arxiv/2509.22060",
        "arxiv_id": "2509.22060",
        "authors": "Aravindhan G, Yuvaraj Govindarajulu, Parin Shah",
        "summary": "Recent studies have demonstrated the vulnerability of Automatic Speech Recognition systems to adversarial examples, which can deceive these systems into misinterpreting input speech commands. While previous research has primarily focused on white-box attacks with constrained optimizations, and transferability based black-box attacks against commercial Automatic Speech Recognition devices, this paper explores cost efficient white-box attack and non transferability black-box adversarial attacks on Automatic Speech Recognition systems, drawing insights from approaches such as Fast Gradient Sign Method and Zeroth-Order Optimization. Further, the novelty of the paper includes how poisoning attack can degrade the performances of state-of-the-art models leading to misinterpretation of audio signals. Through experimentation and analysis, we illustrate how hybrid models can generate subtle yet impactful adversarial examples with very little perturbation having Signal Noise Ratio of 35dB that can be generated within a minute. These vulnerabilities of state-of-the-art open source model have practical security implications, and emphasize the need for adversarial security.",
        "subjects": "Sound, Artificial Intelligence, Cryptography and Security",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.005472"
    },
    {
        "index": "#151",
        "title": "An Adaptive ICP LiDAR Odometry Based on Reliable Initial Pose",
        "link": "/arxiv/2509.22058",
        "arxiv_id": "2509.22058",
        "authors": "Qifeng Wang, Weigang Li, Lei Nie, Xin Xu, Wenping Liu, Zhe Xu",
        "summary": "As a key technology for autonomous navigation and positioning in mobile robots, light detection and ranging (LiDAR) odometry is widely used in autonomous driving applications. The Iterative Closest Point (ICP)-based methods have become the core technique in LiDAR odometry due to their efficient and accurate point cloud registration capability. However, some existing ICP-based methods do not consider the reliability of the initial pose, which may cause the method to converge to a local optimum. Furthermore, the absence of an adaptive mechanism hinders the effective handling of complex dynamic environments, resulting in a significant degradation of registration accuracy. To address these issues, this paper proposes an adaptive ICP-based LiDAR odometry method that relies on a reliable initial pose. First, distributed coarse registration based on density filtering is employed to obtain the initial pose estimation. The reliable initial pose is then selected by comparing it with the motion prediction pose, reducing the initial error between the source and target point clouds. Subsequently, by combining the current and historical errors, the adaptive threshold is dynamically adjusted to accommodate the real-time changes in the dynamic environment. Finally, based on the reliable initial pose and the adaptive threshold, point-to-plane adaptive ICP registration is performed from the current frame to the local map, achieving high-precision alignment of the source and target point clouds. Extensive experiments on the public KITTI dataset demonstrate that the proposed method outperforms existing approaches and significantly enhances the accuracy of LiDAR odometry.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.005975"
    },
    {
        "index": "#153",
        "title": "Latent Diffusion : Multi-Dimension Stable Diffusion Latent Space Explorer",
        "link": "/arxiv/2509.22038",
        "arxiv_id": "2509.22038",
        "authors": "Zhihua Zhong, Xuanyang Huang",
        "summary": "Latent space is one of the key concepts in generative AI, offering powerful means for creative exploration through vector manipulation. However, diffusion models like Stable Diffusion lack the intuitive latent vector control found in GANs, limiting their flexibility for artistic expression. This paper introduces \\workname, a framework for integrating customizable latent space operations into the diffusion process. By enabling direct manipulation of conceptual and spatial representations, this approach expands creative possibilities in generative art. We demonstrate the potential of this framework through two artworks, \\textit{Infinitepedia} and \\textit{Latent Motion}, highlighting its use in conceptual blending and dynamic motion generation. Our findings reveal latent space structures with semantic and meaningless regions, offering insights into the geometry of diffusion models and paving the way for further explorations of latent space.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.006979"
    },
    {
        "index": "#157",
        "title": "Developing Vision-Language-Action Model from Egocentric Videos",
        "link": "/arxiv/2509.21986",
        "arxiv_id": "2509.21986",
        "authors": "Tomoya Yoshida, Shuhei Kurita, Taichi Nishimura, Shinsuke Mori",
        "summary": "Egocentric videos capture how humans manipulate objects and tools, providing diverse motion cues for learning object manipulation. Unlike the costly, expert-driven manual teleoperation commonly used in training Vision-Language-Action models (VLAs), egocentric videos offer a scalable alternative. However, prior studies that leverage such videos for training robot policies typically rely on auxiliary annotations, such as detailed hand-pose recordings. Consequently, it remains unclear whether VLAs can be trained directly from raw egocentric videos. In this work, we address this challenge by leveraging EgoScaler, a framework that extracts 6DoF object manipulation trajectories from egocentric videos without requiring auxiliary recordings. We apply EgoScaler to four large-scale egocentric video datasets and automatically refine noisy or incomplete trajectories, thereby constructing a new large-scale dataset for VLA pre-training. Our experiments with a state-of-the-art $\\pi_0$ architecture in both simulated and real-robot environments yield three key findings: (i) pre-training on our dataset improves task success rates by over 20\\% compared to training from scratch, (ii) the performance is competitive with that achieved using real-robot datasets, and (iii) combining our dataset with real-robot data yields further improvements. These results demonstrate that egocentric videos constitute a promising and scalable resource for advancing VLA research.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.009006"
    },
    {
        "index": "#158",
        "title": "Hybrid Diffusion for Simultaneous Symbolic and Continuous Planning",
        "link": "/arxiv/2509.21983",
        "arxiv_id": "2509.21983",
        "authors": "Sigmund Hennum Høeg, Aksel Vaaler, Chaoqi Liu, Olav Egeland, Yilun Du",
        "summary": "Constructing robots to accomplish long-horizon tasks is a long-standing challenge within artificial intelligence. Approaches using generative methods, particularly Diffusion Models, have gained attention due to their ability to model continuous robotic trajectories for planning and control. However, we show that these models struggle with long-horizon tasks that involve complex decision-making and, in general, are prone to confusing different modes of behavior, leading to failure. To remedy this, we propose to augment continuous trajectory generation by simultaneously generating a high-level symbolic plan. We show that this requires a novel mix of discrete variable diffusion and continuous diffusion, which dramatically outperforms the baselines. In addition, we illustrate how this hybrid diffusion process enables flexible trajectory synthesis, allowing us to condition synthesized actions on partial and complete symbolic conditions.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.009486"
    },
    {
        "index": "#161",
        "title": "From Superficial Outputs to Superficial Learning: Risks of Large Language Models in Education",
        "link": "/arxiv/2509.21972",
        "arxiv_id": "2509.21972",
        "authors": "Iris Delikoura, Yi. R, Fung, Pan Hui",
        "summary": "Large Language Models (LLMs) are transforming education by enabling personalization, feedback, and knowledge access, while also raising concerns about risks to students and learning systems. Yet empirical evidence on these risks remains fragmented. This paper presents a systematic review of 70 empirical studies across computer science, education, and psychology. Guided by four research questions, we examine: (i) which applications of LLMs in education have been most frequently explored; (ii) how researchers have measured their impact; (iii) which risks stem from such applications; and (iv) what mitigation strategies have been proposed. We find that research on LLMs clusters around three domains: operational effectiveness, personalized applications, and interactive learning tools. Across these, model-level risks include superficial understanding, bias, limited robustness, anthropomorphism, hallucinations, privacy concerns, and knowledge constraints. When learners interact with LLMs, these risks extend to cognitive and behavioural outcomes, including reduced neural activity, over-reliance, diminished independent learning skills, and a loss of student agency. To capture this progression, we propose an LLM-Risk Adapted Learning Model that illustrates how technical risks cascade through interaction and interpretation to shape educational outcomes. As the first synthesis of empirically assessed risks, this review provides a foundation for responsible, human-centred integration of LLMs in education.",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.016200"
    },
    {
        "index": "#163",
        "title": "FlowDrive: moderated flow matching with data balancing for trajectory planning",
        "link": "/arxiv/2509.21961",
        "arxiv_id": "2509.21961",
        "authors": "Lingguang Wang, Ömer Şahin Taş, Marlon Steiner, Christoph Stiller",
        "summary": "Learning-based planners are sensitive to the long-tailed distribution of driving data. Common maneuvers dominate datasets, while dangerous or rare scenarios are sparse. This imbalance can bias models toward the frequent cases and degrade performance on critical scenarios. To tackle this problem, we compare balancing strategies for sampling training data and find reweighting by trajectory pattern an effective approach. We then present FlowDrive, a flow-matching trajectory planner that learns a conditional rectified flow to map noise directly to trajectory distributions with few flow-matching steps. We further introduce moderated, in-the-loop guidance that injects small perturbation between flow steps to systematically increase trajectory diversity while remaining scene-consistent. On nuPlan and the interaction-focused interPlan benchmarks, FlowDrive achieves state-of-the-art results among learning-based planners and approaches methods with rule-based refinements. After adding moderated guidance and light post-processing (FlowDrive*), it achieves overall state-of-the-art performance across nearly all benchmark splits.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.017185"
    },
    {
        "index": "#164",
        "title": "Active Attacks: Red-teaming LLMs via Adaptive Environments",
        "link": "/arxiv/2509.21947",
        "arxiv_id": "2509.21947",
        "authors": "Taeyoung Yun, Pierre-Luc St-Charles, Jinkyoo Park, Yoshua Bengio, Minsu Kim",
        "summary": "We address the challenge of generating diverse attack prompts for large language models (LLMs) that elicit harmful behaviors (e.g., insults, sexual content) and are used for safety fine-tuning. Rather than relying on manual prompt engineering, attacker LLMs can be trained with reinforcement learning (RL) to automatically generate such prompts using only a toxicity classifier as a reward. However, capturing a wide range of harmful behaviors is a significant challenge that requires explicit diversity objectives. Existing diversity-seeking RL methods often collapse to limited modes: once high-reward prompts are found, exploration of new regions is discouraged. Inspired by the active learning paradigm that encourages adaptive exploration, we introduce \\textit{Active Attacks}, a novel RL-based red-teaming algorithm that adapts its attacks as the victim evolves. By periodically safety fine-tuning the victim LLM with collected attack prompts, rewards in exploited regions diminish, which forces the attacker to seek unexplored vulnerabilities. This process naturally induces an easy-to-hard exploration curriculum, where the attacker progresses beyond easy modes toward increasingly difficult ones. As a result, Active Attacks uncovers a wide range of local attack modes step by step, and their combination achieves wide coverage of the multi-mode distribution. Active Attacks, a simple plug-and-play module that seamlessly integrates into existing RL objectives, unexpectedly outperformed prior RL-based methods -- including GFlowNets, PPO, and REINFORCE -- by improving cross-attack success rates against GFlowNets, the previous state-of-the-art, from 0.07% to 31.28% (a relative gain greater than $400\\ \\times$) with only a 6% increase in computation. Our code is publicly available \\href{https://github.com/dbsxodud-11/active_attacks}{here}.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.017671"
    },
    {
        "index": "#166",
        "title": "Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective",
        "link": "/arxiv/2509.21945",
        "arxiv_id": "2509.21945",
        "authors": "Pengzhou Chen, Hongyuan Liang, Tao Chen",
        "summary": "To efficiently tune configuration for better system performance (e.g., latency), many tuners have leveraged a surrogate model to expedite the process instead of solely relying on the profoundly expensive system measurement. As such, it is naturally believed that we need more accurate models. However, the fact of accuracy can lie-a somewhat surprising finding from prior work-has left us many unanswered questions regarding what role the surrogate model plays in configuration tuning. This paper provides the very first systematic exploration and discussion, together with a resolution proposal, to disclose the many faces of surrogate models for configuration tuning, through the novel perspective of fitness landscape analysis. We present a theory as an alternative to accuracy for assessing the model usefulness in tuning, based on which we conduct an extensive empirical study involving up to 27,000 cases. Drawing on the above, we propose Model4Tune, an automated predictive tool that estimates which model-tuner pairs are the best for an unforeseen system without expensive tuner profiling. Our results suggest that Moldel4Tune, as one of the first of its kind, performs significantly better than random guessing in 79%-82% of the cases. Our results not only shed light on the possible future research directions but also offer a practical resolution that can assist practitioners in evaluating the most useful model for configuration tuning.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.018546"
    },
    {
        "index": "#169",
        "title": "SAGE: Scene Graph-Aware Guidance and Execution for Long-Horizon Manipulation Tasks",
        "link": "/arxiv/2509.21928",
        "arxiv_id": "2509.21928",
        "authors": "Jialiang Li, Wenzheng Wu, Gaojing Zhang, Yifan Han, Wenzhao Lian",
        "summary": "Successfully solving long-horizon manipulation tasks remains a fundamental challenge. These tasks involve extended action sequences and complex object interactions, presenting a critical gap between high-level symbolic planning and low-level continuous control. To bridge this gap, two essential capabilities are required: robust long-horizon task planning and effective goal-conditioned manipulation. Existing task planning methods, including traditional and LLM-based approaches, often exhibit limited generalization or sparse semantic reasoning. Meanwhile, image-conditioned control methods struggle to adapt to unseen tasks. To tackle these problems, we propose SAGE, a novel framework for Scene Graph-Aware Guidance and Execution in Long-Horizon Manipulation Tasks. SAGE utilizes semantic scene graphs as a structural representation for scene states. A structural scene graph enables bridging task-level semantic reasoning and pixel-level visuo-motor control. This also facilitates the controllable synthesis of accurate, novel sub-goal images. SAGE consists of two key components: (1) a scene graph-based task planner that uses VLMs and LLMs to parse the environment and reason about physically-grounded scene state transition sequences, and (2) a decoupled structural image editing pipeline that controllably converts each target sub-goal graph into a corresponding image through image inpainting and composition. Extensive experiments have demonstrated that SAGE achieves state-of-the-art performance on distinct long-horizon tasks.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.019974"
    },
    {
        "index": "#170",
        "title": "Generation Properties of Stochastic Interpolation under Finite Training Set",
        "link": "/arxiv/2509.21925",
        "arxiv_id": "2509.21925",
        "authors": "Yunchen Li, Shaohui Lin, Zhou Yu",
        "summary": "This paper investigates the theoretical behavior of generative models under finite training populations. Within the stochastic interpolation generative framework, we derive closed-form expressions for the optimal velocity field and score function when only a finite number of training samples are available. We demonstrate that, under some regularity conditions, the deterministic generative process exactly recovers the training samples, while the stochastic generative process manifests as training samples with added Gaussian noise. Beyond the idealized setting, we consider model estimation errors and introduce formal definitions of underfitting and overfitting specific to generative models. Our theoretical analysis reveals that, in the presence of estimation errors, the stochastic generation process effectively produces convex combinations of training samples corrupted by a mixture of uniform and Gaussian noise. Experiments on generation tasks and downstream tasks such as classification support our theory.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.025573"
    },
    {
        "index": "#171",
        "title": "EqDiff-CT: Equivariant Conditional Diffusion model for CT Image Synthesis from CBCT",
        "link": "/arxiv/2509.21913",
        "arxiv_id": "2509.21913",
        "authors": "Alzahra Altalib, Chunhui Li, Alessandro Perelli",
        "summary": "Cone-beam computed tomography (CBCT) is widely used for image-guided radiotherapy (IGRT). It provides real time visualization at low cost and dose. However, photon scattering and beam hindrance cause artifacts in CBCT. These include inaccurate Hounsfield Units (HU), reducing reliability for dose calculation, and adaptive planning. By contrast, computed tomography (CT) offers better image quality and accurate HU calibration but is usually acquired offline and fails to capture intra-treatment anatomical changes. Thus, accurate CBCT-to-CT synthesis is needed to close the imaging-quality gap in adaptive radiotherapy workflows. To cater to this, we propose a novel diffusion-based conditional generative model, coined EqDiff-CT, to synthesize high-quality CT images from CBCT. EqDiff-CT employs a denoising diffusion probabilistic model (DDPM) to iteratively inject noise and learn latent representations that enable reconstruction of anatomically consistent CT images. A group-equivariant conditional U-Net backbone, implemented with e2cnn steerable layers, enforces rotational equivariance (cyclic C4 symmetry), helping preserve fine structural details while minimizing noise and artifacts. The system was trained and validated on the SynthRAD2025 dataset, comprising CBCT-CT scans across multiple head-and-neck anatomical sites, and we compared it with advanced methods such as CycleGAN and DDPM. EqDiff-CT provided substantial gains in structural fidelity, HU accuracy and quantitative metrics. Visual findings further confirm the improved recovery, sharper soft tissue boundaries, and realistic bone reconstructions. The findings suggest that the diffusion model has offered a robust and generalizable framework for CBCT improvements. The proposed solution helps in improving the image quality as well as the clinical confidence in the CBCT-guided treatment planning and dose calculations.",
        "subjects": "Medical Physics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.026026"
    },
    {
        "index": "#176",
        "title": "Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards",
        "link": "/arxiv/2509.21882",
        "arxiv_id": "2509.21882",
        "authors": "Aaron Tu, Weihao Xuan, Heli Qi, Xu Huang, Qingcheng Zeng, Shayan Talaei, Yijia Xiao, Peng Xia, Xiangru Tang, Yuchen Zhuang, Bing Hu, Hanqun Cao, Wenqi Shi, Tianang Leng, Rui Yang, Yingjian Chen, Ziqi Wang, Irene Li, Nan Liu, Huaxiu Yao, Li Erran Li, Ge Liu, Amin Saberi, Naoto Yokoya, Jure Leskovec, Yejin Choi, Fang Wu",
        "summary": "Reinforcement learning with verifiable rewards (RLVR) is a practical and scalable approach to enhancing large language models in areas such as math, code, and other structured tasks. Two questions motivate this paper: how much of the reported gains survive under strictly parity-controlled evaluation, and whether RLVR is cost-free or exacts a measurable tax. We argue that progress is real, but gains are often overstated due to three forces - an RLVR tax, evaluation pitfalls, and data contamination. Using a partial-prompt contamination audit and matched-budget reproductions across base and RL models, we show that several headline gaps shrink or vanish under clean, parity-controlled evaluation. We then propose a tax-aware training and evaluation protocol that co-optimizes accuracy, grounding, and calibrated abstention and standardizes budgeting and provenance checks. Applied to recent RLVR setups, this protocol yields more reliable estimates of reasoning gains and, in several cases, revises prior conclusions. Our position is constructive: RLVR is valuable and industry-ready; we advocate keeping its practical benefits while prioritizing reliability, safety, and measurement.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.028827"
    },
    {
        "index": "#180",
        "title": "Graph of Agents: Principled Long Context Modeling by Emergent Multi-Agent Collaboration",
        "link": "/arxiv/2509.21848",
        "arxiv_id": "2509.21848",
        "authors": "Taejong Joo, Shu Ishida, Ivan Sosnovik, Bryan Lim, Sahand Rezaei-Shoshtari, Adam Gaier, Robert Giaquinto",
        "summary": "As a model-agnostic approach to long context modeling, multi-agent systems can process inputs longer than a large language model's context window without retraining or architectural modifications. However, their performance often heavily relies on hand-crafted multi-agent collaboration strategies and prompt engineering, which limit generalizability. In this work, we introduce a principled framework that formalizes the model-agnostic long context modeling problem as a compression problem, yielding an information-theoretic compression objective. Building on this framework, we propose Graph of Agents (GoA), which dynamically constructs an input-dependent collaboration structure that maximizes this objective. For Llama 3.1 8B and Qwen3 8B across six document question answering benchmarks, GoA improves the average $F_1$ score of retrieval-augmented generation by 5.7\\% and a strong multi-agent baseline using a fixed collaboration structure by 16.35\\%, respectively. Even with only a 2K context window, GoA surpasses the 128K context window Llama 3.1 8B on LongBench, showing a dramatic increase in effective context length. Our source code is available at https://github.com/tjoo512/graph-of-agents.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.035958"
    },
    {
        "index": "#181",
        "title": "Beyond Johnson-Lindenstrauss: Uniform Bounds for Sketched Bilinear Forms",
        "link": "/arxiv/2509.21847",
        "arxiv_id": "2509.21847",
        "authors": "Rohan Deb, Qiaobo Li, Mayank Shrivastava, Arindam Banerjee",
        "summary": "Uniform bounds on sketched inner products of vectors or matrices underpin several important computational and statistical results in machine learning and randomized algorithms, including the Johnson-Lindenstrauss (J-L) lemma, the Restricted Isometry Property (RIP), randomized sketching, and approximate linear algebra. However, many modern analyses involve *sketched bilinear forms*, for which existing uniform bounds either do not apply or are not sharp on general sets. In this work, we develop a general framework to analyze such sketched bilinear forms and derive uniform bounds in terms of geometric complexities of the associated sets. Our approach relies on generic chaining and introduces new techniques for handling suprema over pairs of sets. We further extend these results to the setting where the bilinear form involves a sum of $T$ independent sketching matrices and show that the deviation scales as $\\sqrt{T}$. This unified analysis recovers known results such as the J-L lemma as special cases, while extending RIP-type guarantees. Additionally, we obtain improved convergence bounds for sketched Federated Learning algorithms where such cross terms arise naturally due to sketched gradient compression, and design sketched variants of bandit algorithms with sharper regret bounds that depend on the geometric complexity of the action and parameter sets, rather than the ambient dimension.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.036468"
    },
    {
        "index": "#182",
        "title": "Can Large Language Models Autoformalize Kinematics?",
        "link": "/arxiv/2509.21840",
        "arxiv_id": "2509.21840",
        "authors": "Aditi Kabra, Jonathan Laurent, Sagar Bharadwaj, Ruben Martins, Stefan Mitsch, André Platzer",
        "summary": "Autonomous cyber-physical systems like robots and self-driving cars could greatly benefit from using formal methods to reason reliably about their control decisions. However, before a problem can be solved it needs to be stated. This requires writing a formal physics model of the cyber-physical system, which is a complex task that traditionally requires human expertise and becomes a bottleneck. This paper experimentally studies whether Large Language Models (LLMs) can automate the formalization process. A 20 problem benchmark suite is designed drawing from undergraduate level physics kinematics problems. In each problem, the LLM is provided with a natural language description of the objects' motion and must produce a model in differential game logic (dGL). The model is (1) syntax checked and iteratively refined based on parser feedback, and (2) semantically evaluated by checking whether symbolically executing the dGL formula recovers the solution to the original physics problem. A success rate of 70% (best over 5 samples) is achieved. We analyze failing cases, identifying directions for future improvement. This provides a first quantitative baseline for LLM-based autoformalization from natural language to a hybrid games logic with continuous dynamics.",
        "subjects": "Logic in Computer Science, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.036988"
    },
    {
        "index": "#184",
        "title": "ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting with Multi-scale Representations",
        "link": "/arxiv/2509.21802",
        "arxiv_id": "2509.21802",
        "authors": "Chang Liu, Bohao Zhao, Jingtao Ding, Yong Li",
        "summary": "Accurately forecasting chaotic systems, prevalent in domains such as weather prediction and fluid dynamics, remains a significant scientific challenge. The inherent sensitivity of these systems to initial conditions, coupled with a scarcity of observational data, severely constrains traditional modeling approaches. Since these models are typically trained for a specific system, they lack the generalization capacity necessary for real-world applications, which demand robust zero-shot or few-shot forecasting on novel or data-limited scenarios. To overcome this generalization barrier, we propose ChaosNexus, a foundation model pre-trained on a diverse corpus of chaotic dynamics. ChaosNexus employs a novel multi-scale architecture named ScaleFormer augmented with Mixture-of-Experts layers, to capture both universal patterns and system-specific behaviors. The model demonstrates state-of-the-art zero-shot generalization across both synthetic and real-world benchmarks. On a large-scale testbed comprising over 9,000 synthetic chaotic systems, it improves the fidelity of long-term attractor statistics by more than 40% compared to the leading baseline. This robust performance extends to real-world applications with exceptional data efficiency. For instance, in 5-day global weather forecasting, ChaosNexus achieves a competitive zero-shot mean error below 1 degree, a result that further improves with few-shot fine-tuning. Moreover, experiments on the scaling behavior of ChaosNexus provide a guiding principle for scientific foundation models: cross-system generalization stems from the diversity of training systems, rather than sheer data volume.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.038022"
    },
    {
        "index": "#186",
        "title": "FastGRPO: Accelerating Policy Optimization via Concurrency-aware Speculative Decoding and Online Draft Learning",
        "link": "/arxiv/2509.21792",
        "arxiv_id": "2509.21792",
        "authors": "Yizhou Zhang, Ning Lv, Teng Wang, Jisheng Dang",
        "summary": "Group relative policy optimization (GRPO) has demonstrated significant potential in improving the reasoning capabilities of large language models (LLMs) via reinforcement learning. However, its practical deployment is impeded by an excessively slow training process, primarily attributed to the computationally intensive autoregressive generation of multiple responses per query, which makes the generation phase the primary performance bottleneck. Although speculative decoding presents a promising direction for acceleration, its direct application in GRPO achieves limited speedup under high-concurrency training conditions. To overcome this limitation, we propose a concurrency-aware speculative decoding framework that dynamically adjusts the drafting and verification strategy according to real-time concurrency levels, thereby maximizing the acceleration of the generation process. Furthermore, to address performance degradation arising from distributional drift between the evolving target model and the fixed draft model during training, we introduce an online draft learning mechanism that enables the draft model to continuously adapt using feedback signals from the target model. Experimental results across multiple mathematical reasoning datasets and models demonstrate that the proposed method achieves end-to-end speedups of 2.35x to 2.72x, significantly surpassing baseline approaches in efficiency. The code is available at https://github.com/yedaotian9/GRPO_speculative.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.039015"
    },
    {
        "index": "#187",
        "title": "Unbiased Binning: Fairness-aware Attribute Representation",
        "link": "/arxiv/2509.21785",
        "arxiv_id": "2509.21785",
        "authors": "Abolfazl Asudeh, Zeinab, Asoodeh, Bita Asoodeh, Omid Asudeh",
        "summary": "Discretizing raw features into bucketized attribute representations is a popular step before sharing a dataset. It is, however, evident that this step can cause significant bias in data and amplify unfairness in downstream tasks. In this paper, we address this issue by introducing the unbiased binning problem that, given an attribute to bucketize, finds its closest discretization to equal-size binning that satisfies group parity across different buckets. Defining a small set of boundary candidates, we prove that unbiased binning must select its boundaries from this set. We then develop an efficient dynamic programming algorithm on top of the boundary candidates to solve the unbiased binning problem. Finding an unbiased binning may sometimes result in a high price of fairness, or it may not even exist, especially when group values follow different distributions. Considering that a small bias in the group ratios may be tolerable in such settings, we introduce the epsilon-biased binning problem that bounds the group disparities across buckets to a small value epsilon. We first develop a dynamic programming solution, DP, that finds the optimal binning in quadratic time. The DP algorithm, while polynomial, does not scale to very large settings. Therefore, we propose a practically scalable algorithm, based on local search (LS), for epsilon-biased binning. The key component of the LS algorithm is a divide-and-conquer (D&C) algorithm that finds a near-optimal solution for the problem in near-linear time. We prove that D&C finds a valid solution for the problem unless none exists. The LS algorithm then initiates a local search, using the D&C solution as the upper bound, to find the optimal solution.",
        "subjects": "Databases, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.039513"
    },
    {
        "index": "#188",
        "title": "Beyond Structure: Invariant Crystal Property Prediction with Pseudo-Particle Ray Diffraction",
        "link": "/arxiv/2509.21778",
        "arxiv_id": "2509.21778",
        "authors": "Bin Cao, Yang Liu, Longhan Zhang, Yifan Wu, Zhixun Li, Yuyu Luo, Hong Cheng, Yang Ren, Tong-Yi Zhang",
        "summary": "Crystal property prediction, governed by quantum mechanical principles, is computationally prohibitive to solve exactly for large many-body systems using traditional density functional theory. While machine learning models have emerged as efficient approximations for large-scale applications, their performance is strongly influenced by the choice of atomic representation. Although modern graph-based approaches have progressively incorporated more structural information, they often fail to capture long-term atomic interactions due to finite receptive fields and local encoding schemes. This limitation leads to distinct crystals being mapped to identical representations, hindering accurate property prediction. To address this, we introduce PRDNet that leverages unique reciprocal-space diffraction besides graph representations. To enhance sensitivity to elemental and environmental variations, we employ a data-driven pseudo-particle to generate a synthetic diffraction pattern. PRDNet ensures full invariance to crystallographic symmetries. Extensive experiments are conducted on Materials Project, JARVIS-DFT, and MatBench, demonstrating that the proposed model achieves state-of-the-art performance.",
        "subjects": "Materials Science, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.040072"
    },
    {
        "index": "#189",
        "title": "Backdoor Attribution: Elucidating and Controlling Backdoor in Language Models",
        "link": "/arxiv/2509.21761",
        "arxiv_id": "2509.21761",
        "authors": "Miao Yu, Zhenhong Zhou, Moayad Aloqaily, Kun Wang, Biwei Huang, Stephen Wang, Yueming Jin, Qingsong Wen",
        "summary": "Fine-tuned Large Language Models (LLMs) are vulnerable to backdoor attacks through data poisoning, yet the internal mechanisms governing these attacks remain a black box. Previous research on interpretability for LLM safety tends to focus on alignment, jailbreak, and hallucination, but overlooks backdoor mechanisms, making it difficult to understand and fully eliminate the backdoor threat. In this paper, aiming to bridge this gap, we explore the interpretable mechanisms of LLM backdoors through Backdoor Attribution (BkdAttr), a tripartite causal analysis framework. We first introduce the Backdoor Probe that proves the existence of learnable backdoor features encoded within the representations. Building on this insight, we further develop Backdoor Attention Head Attribution (BAHA), efficiently pinpointing the specific attention heads responsible for processing these features. Our primary experiments reveals these heads are relatively sparse; ablating a minimal \\textbf{$\\sim$ 3%} of total heads is sufficient to reduce the Attack Success Rate (ASR) by \\textbf{over 90%}. More importantly, we further employ these findings to construct the Backdoor Vector derived from these attributed heads as a master controller for the backdoor. Through only \\textbf{1-point} intervention on \\textbf{single} representation, the vector can either boost ASR up to \\textbf{$\\sim$ 100% ($\\uparrow$)} on clean inputs, or completely neutralize backdoor, suppressing ASR down to \\textbf{$\\sim$ 0% ($\\downarrow$)} on triggered inputs. In conclusion, our work pioneers the exploration of mechanistic interpretability in LLM backdoors, demonstrating a powerful method for backdoor control and revealing actionable insights for the community.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.040582"
    },
    {
        "index": "#190",
        "title": "SubZeroCore: A Submodular Approach with Zero Training for Coreset Selection",
        "link": "/arxiv/2509.21748",
        "arxiv_id": "2509.21748",
        "authors": "Brian B. Moser, Tobias C. Nauen, Arundhati S. Shanbhag, Federico Raue, Stanislav Frolov, Joachim Folz, Andreas Dengel",
        "summary": "The goal of coreset selection is to identify representative subsets of datasets for efficient model training. Yet, existing approaches paradoxically require expensive training-based signals, e.g., gradients, decision boundary estimates or forgetting counts, computed over the entire dataset prior to pruning, which undermines their very purpose by requiring training on samples they aim to avoid. We introduce SubZeroCore, a novel, training-free coreset selection method that integrates submodular coverage and density into a single, unified objective. To achieve this, we introduce a sampling strategy based on a closed-form solution to optimally balance these objectives, guided by a single hyperparameter that explicitly controls the desired coverage for local density measures. Despite no training, extensive evaluations show that SubZeroCore matches training-based baselines and significantly outperforms them at high pruning rates, while dramatically reducing computational overhead. SubZeroCore also demonstrates superior robustness to label noise, highlighting its practical effectiveness and scalability for real-world scenarios.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.046276"
    },
    {
        "index": "#191",
        "title": "HyperCore: Coreset Selection under Noise via Hypersphere Models",
        "link": "/arxiv/2509.21746",
        "arxiv_id": "2509.21746",
        "authors": "Brian B. Moser, Arundhati S. Shanbhag, Tobias C. Nauen, Stanislav Frolov, Federico Raue, Joachim Folz, Andreas Dengel",
        "summary": "The goal of coreset selection methods is to identify representative subsets of datasets for efficient model training. Yet, existing methods often ignore the possibility of annotation errors and require fixed pruning ratios, making them impractical in real-world settings. We present HyperCore, a robust and adaptive coreset selection framework designed explicitly for noisy environments. HyperCore leverages lightweight hypersphere models learned per class, embedding in-class samples close to a hypersphere center while naturally segregating out-of-class samples based on their distance. By using Youden's J statistic, HyperCore can adaptively select pruning thresholds, enabling automatic, noise-aware data pruning without hyperparameter tuning. Our experiments reveal that HyperCore consistently surpasses state-of-the-art coreset selection methods, especially under noisy and low-data regimes. HyperCore effectively discards mislabeled and ambiguous points, yielding compact yet highly informative subsets suitable for scalable and noise-free learning.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.046806"
    },
    {
        "index": "#192",
        "title": "Brain PathoGraph Learning",
        "link": "/arxiv/2509.21742",
        "arxiv_id": "2509.21742",
        "authors": "Ciyuan Peng, Nguyen Linh Dan Le, Shan Jin, Dexuan Ding, Shuo Yu, Feng Xia",
        "summary": "Brain graph learning has demonstrated significant achievements in the fields of neuroscience and artificial intelligence. However, existing methods struggle to selectively learn disease-related knowledge, leading to heavy parameters and computational costs. This challenge diminishes their efficiency, as well as limits their practicality for real-world clinical applications. To this end, we propose a lightweight Brain PathoGraph Learning (BrainPoG) model that enables efficient brain graph learning by pathological pattern filtering and pathological feature distillation. Specifically, BrainPoG first contains a filter to extract the pathological pattern formulated by highly disease-relevant subgraphs, achieving graph pruning and lesion localization. A PathoGraph is therefore constructed by dropping less disease-relevant subgraphs from the whole brain graph. Afterwards, a pathological feature distillation module is designed to reduce disease-irrelevant noise features and enhance pathological features of each node in the PathoGraph. BrainPoG can exclusively learn informative disease-related knowledge while avoiding less relevant information, achieving efficient brain graph learning. Extensive experiments on four benchmark datasets demonstrate that BrainPoG exhibits superiority in both model performance and computational efficiency across various brain disease detection tasks.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.047310"
    },
    {
        "index": "#195",
        "title": "POLO: Preference-Guided Multi-Turn Reinforcement Learning for Lead Optimization",
        "link": "/arxiv/2509.21737",
        "arxiv_id": "2509.21737",
        "authors": "Ziqing Wang, Yibo Wen, William Pattie, Xiao Luo, Weimin Wu, Jerry Yao-Chieh Hu, Abhishek Pandey, Han Liu, Kaize Ding",
        "summary": "Lead optimization in drug discovery requires efficiently navigating vast chemical space through iterative cycles to enhance molecular properties while preserving structural similarity to the original lead compound. Despite recent advances, traditional optimization methods struggle with sample efficiency-achieving good optimization performance with limited oracle evaluations. Large Language Models (LLMs) provide a promising approach through their in-context learning and instruction following capabilities, which align naturally with these iterative processes. However, existing LLM-based methods fail to leverage this strength, treating each optimization step independently. To address this, we present POLO (Preference-guided multi-turn Optimization for Lead Optimization), which enables LLMs to learn from complete optimization trajectories rather than isolated steps. At its core, POLO introduces Preference-Guided Policy Optimization (PGPO), a novel reinforcement learning algorithm that extracts learning signals at two complementary levels: trajectory-level optimization reinforces successful strategies, while turn-level preference learning provides dense comparative feedback by ranking intermediate molecules within each trajectory. Through this dual-level learning from intermediate evaluation, POLO achieves superior sample efficiency by fully exploiting each costly oracle call. Extensive experiments demonstrate that POLO achieves 84% average success rate on single-property tasks (2.3x better than baselines) and 50% on multi-property tasks using only 500 oracle evaluations, significantly advancing the state-of-the-art in sample-efficient molecular optimization.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.048849"
    },
    {
        "index": "#196",
        "title": "Uncovering Alzheimer's Disease Progression via SDE-based Spatio-Temporal Graph Deep Learning on Longitudinal Brain Networks",
        "link": "/arxiv/2509.21735",
        "arxiv_id": "2509.21735",
        "authors": "Houliang Zhou, Rong Zhou, Yangying Liu, Kanhao Zhao, Li Shen, Brian Y. Chen, Yu Zhang, Lifang He, Alzheimer's Disease Neuroimaging Initiative",
        "summary": "Identifying objective neuroimaging biomarkers to forecast Alzheimer's disease (AD) progression is crucial for timely intervention. However, this task remains challenging due to the complex dysfunctions in the spatio-temporal characteristics of underlying brain networks, which are often overlooked by existing methods. To address these limitations, we develop an interpretable spatio-temporal graph neural network framework to predict future AD progression, leveraging dual Stochastic Differential Equations (SDEs) to model the irregularly-sampled longitudinal functional magnetic resonance imaging (fMRI) data. We validate our approach on two independent cohorts, including the Open Access Series of Imaging Studies (OASIS-3) and the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our framework effectively learns sparse regional and connective importance probabilities, enabling the identification of key brain circuit abnormalities associated with disease progression. Notably, we detect the parahippocampal cortex, prefrontal cortex, and parietal lobule as salient regions, with significant disruptions in the ventral attention, dorsal attention, and default mode networks. These abnormalities correlate strongly with longitudinal AD-related clinical symptoms. Moreover, our interpretability strategy reveals both established and novel neural systems-level and sex-specific biomarkers, offering new insights into the neurobiological mechanisms underlying AD progression. Our findings highlight the potential of spatio-temporal graph-based learning for early, individualized prediction of AD progression, even in the context of irregularly-sampled longitudinal imaging data.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.049391"
    },
    {
        "index": "#198",
        "title": "Developing Strategies to Increase Capacity in AI Education",
        "link": "/arxiv/2509.21713",
        "arxiv_id": "2509.21713",
        "authors": "Noah Q. Cowit, Sri Yash Tadimalla, Stephanie T. Jones, Mary Lou Maher, Tracy Camp, Enrico Pontelli",
        "summary": "Many institutions are currently grappling with teaching artificial intelligence (AI) in the face of growing demand and relevance in our world. The Computing Research Association (CRA) has conducted 32 moderated virtual roundtable discussions of 202 experts committed to improving AI education. These discussions slot into four focus areas: AI Knowledge Areas and Pedagogy, Infrastructure Challenges in AI Education, Strategies to Increase Capacity in AI Education, and AI Education for All. Roundtables were organized around institution type to consider the particular goals and resources of different AI education environments. We identified the following high-level community needs to increase capacity in AI education. A significant digital divide creates major infrastructure hurdles, especially for smaller and under-resourced institutions. These challenges manifest as a shortage of faculty with AI expertise, who also face limited time for reskilling; a lack of computational infrastructure for students and faculty to develop and test AI models; and insufficient institutional technical support. Compounding these issues is the large burden associated with updating curricula and creating new programs. To address the faculty gap, accessible and continuous professional development is crucial for faculty to learn about AI and its ethical dimensions. This support is particularly needed for under-resourced institutions and must extend to faculty both within and outside of computing programs to ensure all students have access to AI education. We have compiled and organized a list of resources that our participant experts mentioned throughout this study. These resources contribute to a frequent request heard during the roundtables: a central repository of AI education resources for institutions to freely use across higher education.",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.050512"
    },
    {
        "index": "#199",
        "title": "Not My Agent, Not My Boundary? Elicitation of Personal Privacy Boundaries in AI-Delegated Information Sharing",
        "link": "/arxiv/2509.21712",
        "arxiv_id": "2509.21712",
        "authors": "Bingcan Guo, Eryue Xu, Zhiping Zhang, Tianshi Li",
        "summary": "Aligning AI systems with human privacy preferences requires understanding individuals' nuanced disclosure behaviors beyond general norms. Yet eliciting such boundaries remains challenging due to the context-dependent nature of privacy decisions and the complex trade-offs involved. We present an AI-powered elicitation approach that probes individuals' privacy boundaries through a discriminative task. We conducted a between-subjects study that systematically varied communication roles and delegation conditions, resulting in 1,681 boundary specifications from 169 participants for 61 scenarios. We examined how these contextual factors and individual differences influence the boundary specification. Quantitative results show that communication roles influence individuals' acceptance of detailed and identifiable disclosure, AI delegation and individuals' need for privacy heighten sensitivity to disclosed identifiers, and AI delegation results in less consensus across individuals. Our findings highlight the importance of situating privacy preference elicitation within real-world data flows. We advocate using nuanced privacy boundaries as an alignment goal for future AI systems.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.056164"
    },
    {
        "index": "#200",
        "title": "Optimizing the non-Clifford-count in unitary synthesis using Reinforcement Learning",
        "link": "/arxiv/2509.21709",
        "arxiv_id": "2509.21709",
        "authors": "David Kremer, Ali Javadi-Abhari, Priyanka Mukhopadhyay",
        "summary": "An efficient implementation of unitary operators is important in order to practically realize the computational advantages claimed by quantum algorithms over their classical counterparts. In this paper we study the potential of using reinforcement learning (RL) in order to synthesize quantum circuits, while optimizing the T-count and CS-count, of unitaries that are exactly implementable by the Clifford+T and Clifford+CS gate sets, respectively. In general, the complexity of existing algorithms depend exponentially on the number of qubits and the non-Clifford-count of unitaries. We have designed our RL framework to work with channel representation of unitaries, that enables us to perform matrix operations efficiently, using integers only. We have also incorporated pruning heuristics and a canonicalization of operators, in order to reduce the search complexity. As a result, compared to previous works, we are able to implement significantly larger unitaries, in less time, with much better success rate and improvement factor. Our results for Clifford+T synthesis on two qubits achieve close-to-optimal decompositions for up to 100 T gates, 5 times more than previous RL algorithms and to the best of our knowledge, the largest instances achieved with any method to date. Our RL algorithm is able to recover previously-known optimal linear complexity algorithm for T-count-optimal decomposition of 1 qubit unitaries. For 2-qubit Clifford+CS unitaries, our algorithm achieves a linear complexity, something that could only be accomplished by a previous algorithm using $SO(6)$ representation.",
        "subjects": "Quantum Physics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.056883"
    },
    {
        "index": "#201",
        "title": "QueryGym: Step-by-Step Interaction with Relational Databases",
        "link": "/arxiv/2509.21674",
        "arxiv_id": "2509.21674",
        "authors": "Haritha Ananthakrishanan, Harsha Kokel, Kelsey Sikes, Debarun Bhattacharjya, Michael Katz, Shirin Sohrabi, Kavitha Srinivas",
        "summary": "We introduce QueryGym, an interactive environment for building, testing, and evaluating LLM-based query planning agents. Existing frameworks often tie agents to specific query language dialects or obscure their reasoning; QueryGym instead requires agents to construct explicit sequences of relational algebra operations, ensuring engine-agnostic evaluation and transparent step-by-step planning. The environment is implemented as a Gymnasium interface that supplies observations -- including schema details, intermediate results, and execution feedback -- and receives actions that represent database exploration (e.g., previewing tables, sampling column values, retrieving unique values) as well as relational algebra operations (e.g., filter, project, join). We detail the motivation and the design of the environment. In the demo, we showcase the utility of the environment by contrasting it with contemporary LLMs that query databases. QueryGym serves as a practical testbed for research in error remediation, transparency, and reinforcement learning for query generation. For the associated demo, see https://ibm.biz/QueryGym.",
        "subjects": "Databases, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.057436"
    },
    {
        "index": "#202",
        "title": "SlotFM: A Motion Foundation Model with Slot Attention for Diverse Downstream Tasks",
        "link": "/arxiv/2509.21673",
        "arxiv_id": "2509.21673",
        "authors": "Junyong Park, Oron Levy, Rebecca Adaimi, Asaf Liberman, Gierad Laput, Abdelkareem Bedri",
        "summary": "Wearable accelerometers are used for a wide range of applications, such as gesture recognition, gait analysis, and sports monitoring. Yet most existing foundation models focus primarily on classifying common daily activities such as locomotion and exercise, limiting their applicability to the broader range of tasks that rely on other signal characteristics. We present SlotFM, an accelerometer foundation model that generalizes across diverse downstream tasks. SlotFM uses Time-Frequency Slot Attention, an extension of Slot Attention that processes both time and frequency representations of the raw signals. It generates multiple small embeddings (slots), each capturing different signal components, enabling task-specific heads to focus on the most relevant parts of the data. We also introduce two loss regularizers that capture local structure and frequency patterns, which improve reconstruction of fine-grained details and helps the embeddings preserve task-relevant information. We evaluate SlotFM on 16 classification and regression downstream tasks that extend beyond standard human activity recognition. It outperforms existing self-supervised approaches on 13 of these tasks and achieves comparable results to the best performing approaches on the remaining tasks. On average, our method yields a 4.5% performance gain, demonstrating strong generalization for sensing foundation models.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.057966"
    },
    {
        "index": "#204",
        "title": "DIM: Enforcing Domain-Informed Monotonicity in Deep Neural Networks",
        "link": "/arxiv/2509.21666",
        "arxiv_id": "2509.21666",
        "authors": "Joshua Salim, Jordan Yu, Xilei Zhao",
        "summary": "While deep learning models excel at predictive tasks, they often overfit due to their complex structure and large number of parameters, causing them to memorize training data, including noise, rather than learn patterns that generalize to new data. To tackle this challenge, this paper proposes a new regularization method, i.e., Enforcing Domain-Informed Monotonicity in Deep Neural Networks (DIM), which maintains domain-informed monotonic relationships in complex deep learning models to further improve predictions. Specifically, our method enforces monotonicity by penalizing violations relative to a linear baseline, effectively encouraging the model to follow expected trends while preserving its predictive power. We formalize this approach through a comprehensive mathematical framework that establishes a linear reference, measures deviations from monotonic behavior, and integrates these measurements into the training objective. We test and validate the proposed methodology using a real-world ridesourcing dataset from Chicago and a synthetically created dataset. Experiments across various neural network architectures show that even modest monotonicity constraints consistently enhance model performance. DIM enhances the predictive performance of deep neural networks by applying domain-informed monotonicity constraints to regularize model behavior and mitigate overfitting",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.059041"
    },
    {
        "index": "#205",
        "title": "Logic of Hypotheses: from Zero to Full Knowledge in Neurosymbolic Integration",
        "link": "/arxiv/2509.21663",
        "arxiv_id": "2509.21663",
        "authors": "Davide Bizzaro, Alessandro Daniele",
        "summary": "Neurosymbolic integration (NeSy) blends neural-network learning with symbolic reasoning. The field can be split between methods injecting hand-crafted rules into neural models, and methods inducing symbolic rules from data. We introduce Logic of Hypotheses (LoH), a novel language that unifies these strands, enabling the flexible integration of data-driven rule learning with symbolic priors and expert knowledge. LoH extends propositional logic syntax with a choice operator, which has learnable parameters and selects a subformula from a pool of options. Using fuzzy logic, formulas in LoH can be directly compiled into a differentiable computational graph, so the optimal choices can be learned via backpropagation. This framework subsumes some existing NeSy models, while adding the possibility of arbitrary degrees of knowledge specification. Moreover, the use of Goedel fuzzy logic and the recently developed Goedel trick yields models that can be discretized to hard Boolean-valued functions without any loss in performance. We provide experimental analysis on such models, showing strong results on tabular data and on the Visual Tic-Tac-Toe NeSy task, while producing interpretable decision rules.",
        "subjects": "Machine Learning, Artificial Intelligence, Logic in Computer Science",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.059542"
    },
    {
        "index": "#206",
        "title": "Limitations on Safe, Trusted, Artificial General Intelligence",
        "link": "/arxiv/2509.21654",
        "arxiv_id": "2509.21654",
        "authors": "Rina Panigrahy, Vatsal Sharan",
        "summary": "Safety, trust and Artificial General Intelligence (AGI) are aspirational goals in artificial intelligence (AI) systems, and there are several informal interpretations of these notions. In this paper, we propose strict, mathematical definitions of safety, trust, and AGI, and demonstrate a fundamental incompatibility between them. We define safety of a system as the property that it never makes any false claims, trust as the assumption that the system is safe, and AGI as the property of an AI system always matching or exceeding human capability. Our core finding is that -- for our formal definitions of these notions -- a safe and trusted AI system cannot be an AGI system: for such a safe, trusted system there are task instances which are easily and provably solvable by a human but not by the system. We note that we consider strict mathematical definitions of safety and trust, and it is possible for real-world deployments to instead rely on alternate, practical interpretations of these notions. We show our results for program verification, planning, and graph reachability. Our proofs draw parallels to Gödel's incompleteness theorems and Turing's proof of the undecidability of the halting problem, and can be regarded as interpretations of Gödel's and Turing's results.",
        "subjects": "Machine Learning, Artificial Intelligence, Computational Complexity",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.060072"
    },
    {
        "index": "#207",
        "title": "MobiLLM: An Agentic AI Framework for Closed-Loop Threat Mitigation in 6G Open RANs",
        "link": "/arxiv/2509.21634",
        "arxiv_id": "2509.21634",
        "authors": "Prakhar Sharma, Haohuang Wen, Vinod Yegneswaran, Ashish Gehani, Phillip Porras, Zhiqiang Lin",
        "summary": "The evolution toward 6G networks is being accelerated by the Open Radio Access Network (O-RAN) paradigm -- an open, interoperable architecture that enables intelligent, modular applications across public telecom and private enterprise domains. While this openness creates unprecedented opportunities for innovation, it also expands the attack surface, demanding resilient, low-cost, and autonomous security solutions. Legacy defenses remain largely reactive, labor-intensive, and inadequate for the scale and complexity of next-generation systems. Current O-RAN applications focus mainly on network optimization or passive threat detection, with limited capability for closed-loop, automated response. To address this critical gap, we present an agentic AI framework for fully automated, end-to-end threat mitigation in 6G O-RAN environments. MobiLLM orchestrates security workflows through a modular multi-agent system powered by Large Language Models (LLMs). The framework features a Threat Analysis Agent for real-time data triage, a Threat Classification Agent that uses Retrieval-Augmented Generation (RAG) to map anomalies to specific countermeasures, and a Threat Response Agent that safely operationalizes mitigation actions via O-RAN control interfaces. Grounded in trusted knowledge bases such as the MITRE FiGHT framework and 3GPP specifications, and equipped with robust safety guardrails, MobiLLM provides a blueprint for trustworthy AI-driven network security. Initial evaluations demonstrate that MobiLLM can effectively identify and orchestrate complex mitigation strategies, significantly reducing response latency and showcasing the feasibility of autonomous security operations in 6G.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning, Networking and Internet Architecture",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.060644"
    },
    {
        "index": "#210",
        "title": "Guiding Audio Editing with Audio Language Model",
        "link": "/arxiv/2509.21625",
        "arxiv_id": "2509.21625",
        "authors": "Zitong Lan, Yiduo Hao, Mingmin Zhao",
        "summary": "Audio editing plays a central role in VR/AR immersion, virtual conferencing, sound design, and other interactive media. However, recent generative audio editing models depend on template-like instruction formats and are restricted to mono-channel audio. These models fail to deal with declarative audio editing, where the user declares what the desired outcome should be, while leaving the details of editing operations to the system. We introduce SmartDJ, a novel framework for stereo audio editing that combines the reasoning capability of audio language models with the generative power of latent diffusion. Given a high-level instruction, SmartDJ decomposes it into a sequence of atomic edit operations, such as adding, removing, or spatially relocating events. These operations are then executed by a diffusion model trained to manipulate stereo audio. To support this, we design a data synthesis pipeline that produces paired examples of high-level instructions, atomic edit operations, and audios before and after each edit operation. Experiments demonstrate that SmartDJ achieves superior perceptual quality, spatial realism, and semantic alignment compared to prior audio editing methods. Demos are available at https://zitonglan.github.io/project/smartdj/smartdj.html.",
        "subjects": "Sound, Artificial Intelligence, Machine Learning, Audio and Speech Processing",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.067397"
    },
    {
        "index": "#212",
        "title": "LANCE: Low Rank Activation Compression for Efficient On-Device Continual Learning",
        "link": "/arxiv/2509.21617",
        "arxiv_id": "2509.21617",
        "authors": "Marco Paul E. Apolinario, Kaushik Roy",
        "summary": "On-device learning is essential for personalization, privacy, and long-term adaptation in resource-constrained environments. Achieving this requires efficient learning, both fine-tuning existing models and continually acquiring new tasks without catastrophic forgetting. Yet both settings are constrained by high memory cost of storing activations during backpropagation. Existing activation compression methods reduce this cost but relying on repeated low-rank decompositions, introducing computational overhead. Also, such methods have not been explored for continual learning. We propose LANCE (Low-rank Activation Compression), a framework that performs one-shot higher-order Singular Value Decompsoition (SVD) to obtain a reusable low-rank subspace for activation projection. This eliminates repeated decompositions, reducing both memory and computation. Moreover, fixed low-rank subspaces further enable on-device continual learning by allocating tasks to orthogonal subspaces without storing large task-specific matrices. Experiments show that LANCE reduces activation storage up to 250$\\times$ while maintaining accuracy comparable to full backpropagation on CIFAR-10/100, Oxford-IIIT Pets, Flowers102, and CUB-200 datasets. On continual learning benchmarks (Split CIFAR-100, Split MiniImageNet, 5-Datasets), it achieves performance competitive with orthogonal gradient projection methods at a fraction of the memory cost. These results position LANCE as a practical and scalable solution for efficient fine-tuning and continual learning on edge devices.",
        "subjects": "Machine Learning, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.068471"
    },
    {
        "index": "#219",
        "title": "Psychological and behavioural responses in human-agent vs. human-human interactions: a systematic review and meta-analysis",
        "link": "/arxiv/2509.21542",
        "arxiv_id": "2509.21542",
        "authors": "Jianan Zhou, Fleur Corbett, Joori Byun, Talya Porat, Nejra van Zalk",
        "summary": "Interactive intelligent agents are being integrated across society. Despite achieving human-like capabilities, humans' responses to these agents remain poorly understood, with research fragmented across disciplines. We conducted a first systematic synthesis comparing a range of psychological and behavioural responses in matched human-agent vs. human-human dyadic interactions. A total of 162 eligible studies (146 contributed to the meta-analysis; 468 effect sizes) were included in the systematic review and meta-analysis, which integrated frequentist and Bayesian approaches. Our results indicate that individuals exhibited less prosocial behaviour and moral engagement when interacting with agents vs. humans. They attributed less agency and responsibility to agents, perceiving them as less competent, likeable, and socially present. In contrast, individuals' social alignment (i.e., alignment or adaptation of internal states and behaviours with partners), trust in partners, personal agency, task performance, and interaction experiences were generally comparable when interacting with agents vs. humans. We observed high effect-size heterogeneity for many subjective responses (i.e., social perceptions of partners, subjective trust, and interaction experiences), suggesting context-dependency of partner effects. By examining the characteristics of studies, participants, partners, interaction scenarios, and response measures, we also identified several moderators shaping partner effects. Overall, functional behaviours and interactive experiences with agents can resemble those with humans, whereas fundamental social attributions and moral/prosocial concerns lag in human-agent interactions. Agents are thus afforded instrumental value on par with humans but lack comparable intrinsic value, providing practical implications for agent design and regulation.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.077239"
    },
    {
        "index": "#221",
        "title": "Preemptive Detection and Steering of LLM Misalignment via Latent Reachability",
        "link": "/arxiv/2509.21528",
        "arxiv_id": "2509.21528",
        "authors": "Sathwik Karnik, Somil Bansal",
        "summary": "Large language models (LLMs) are now ubiquitous in everyday tools, raising urgent safety concerns about their tendency to generate harmful content. The dominant safety approach -- reinforcement learning from human feedback (RLHF) -- effectively shapes model behavior during training but offers no safeguards at inference time, where unsafe continuations may still arise. We propose BRT-Align, a reachability-based framework that brings control-theoretic safety tools to LLM inference. BRT-Align models autoregressive generation as a dynamical system in latent space and learn a safety value function via backward reachability, estimating the worst-case evolution of a trajectory. This enables two complementary mechanisms: (1) a runtime monitor that forecasts unsafe completions several tokens in advance, and (2) a least-restrictive steering filter that minimally perturbs latent states to redirect generation away from unsafe regions. Experiments across multiple LLMs and toxicity benchmarks demonstrate that BRT-Align provides more accurate and earlier detection of unsafe continuations than baselines. Moreover, for LLM safety alignment, BRT-Align substantially reduces unsafe generations while preserving sentence diversity and coherence. Qualitative results further highlight emergent alignment properties: BRT-Align consistently produces responses that are less violent, less profane, less offensive, and less politically biased. Together, these findings demonstrate that reachability analysis provides a principled and practical foundation for inference-time LLM safety.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.078247"
    },
    {
        "index": "#222",
        "title": "Shortcut Flow Matching for Speech Enhancement: Step-Invariant flows via single stage training",
        "link": "/arxiv/2509.21522",
        "arxiv_id": "2509.21522",
        "authors": "Naisong Zhou, Saisamarth Rajesh Phaye, Milos Cernak, Tijana Stojkovic, Andy Pearce, Andrea Cavallaro, Andy Harper",
        "summary": "Diffusion-based generative models have achieved state-of-the-art performance for perceptual quality in speech enhancement (SE). However, their iterative nature requires numerous Neural Function Evaluations (NFEs), posing a challenge for real-time applications. On the contrary, flow matching offers a more efficient alternative by learning a direct vector field, enabling high-quality synthesis in just a few steps using deterministic ordinary differential equation~(ODE) solvers. We thus introduce Shortcut Flow Matching for Speech Enhancement (SFMSE), a novel approach that trains a single, step-invariant model. By conditioning the velocity field on the target time step during a one-stage training process, SFMSE can perform single, few, or multi-step denoising without any architectural changes or fine-tuning. Our results demonstrate that a single-step SFMSE inference achieves a real-time factor (RTF) of 0.013 on a consumer GPU while delivering perceptual quality comparable to a strong diffusion baseline requiring 60 NFEs. This work also provides an empirical analysis of the role of stochasticity in training and inference, bridging the gap between high-quality generative SE and low-latency constraints.",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.078787"
    },
    {
        "index": "#223",
        "title": "$\\mathbf{Li_2}$: A Framework on Dynamics of Feature Emergence and Delayed Generalization",
        "link": "/arxiv/2509.21519",
        "arxiv_id": "2509.21519",
        "authors": "Yuandong Tian",
        "summary": "While the phenomenon of grokking, i.e., delayed generalization, has been studied extensively, it remains an open question whether there is a mathematical framework to characterize what kind of features emerge, how and in which conditions it happens from training, for complex structured inputs. We propose a novel framework, named $\\mathbf{Li_2}$, that captures three key stages for the grokking behavior of 2-layer nonlinear networks: (I) Lazy learning, (II) independent feature learning and (III) interactive feature learning, characterized by the structure of backpropagated gradient $G_F$ across layers. In (I), $G_F$ is random, and top layer overfits to random hidden representation. In (II), the gradient of each node (column of $G_F$) only depends on its own activation, and thus each hidden node learns their representation independently from $G_F$, which now carries information about target labels, thanks to weight decay. Interestingly, the independent dynamics follows exactly the gradient ascent of an energy function $E$, and its local maxima are precisely the emerging features. We study whether these local-optima induced features are generalizable, their representation power, and how they change on sample size, in group arithmetic tasks. Finally, in (III), we provably show how hidden nodes interact, and how $G_F$ changes to focus on missing features that need to be learned. Our study sheds lights on roles played by key hyperparameters such as weight decay, learning rate and sample sizes in grokking, leads to provable scaling laws of memorization and generalization, and reveals the underlying cause why recent optimizers such as Muon can be effective, from the first principles of gradient dynamics. Our analysis can be extended to multi-layer architectures.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.079244"
    },
    {
        "index": "#225",
        "title": "New Algorithmic Directions in Optimal Transport and Applications for Product Spaces",
        "link": "/arxiv/2509.21502",
        "arxiv_id": "2509.21502",
        "authors": "Salman Beigi, Omid Etesami, Mohammad Mahmoody, Amir Najafi",
        "summary": "We study optimal transport between two high-dimensional distributions $\\mu,\\nu$ in $R^n$ from an algorithmic perspective: given $x \\sim \\mu$, find a close $y \\sim \\nu$ in $poly(n)$ time, where $n$ is the dimension of $x,y$. Thus, running time depends on the dimension rather than the full representation size of $\\mu,\\nu$. Our main result is a general algorithm for transporting any product distribution $\\mu$ to any $\\nu$ with cost $\\Delta + \\delta$ under $\\ell_p^p$, where $\\Delta$ is the Knothe-Rosenblatt transport cost and $\\delta$ is a computational error decreasing with runtime. This requires $\\nu$ to be \"sequentially samplable\" with bounded average sampling cost, a new but natural notion. We further prove: An algorithmic version of Talagrand's inequality for transporting the standard Gaussian $\\Phi^n$ to arbitrary $\\nu$ under squared Euclidean cost. For $\\nu = \\Phi^n$ conditioned on a set $\\mathcal{S}$ of measure $\\varepsilon$, we construct the sequential sampler in expected time $poly(n/\\varepsilon)$ using membership oracle access to $\\mathcal{S}$. This yields an algorithmic transport from $\\Phi^n$ to $\\Phi^n|\\mathcal{S}$ in $poly(n/\\varepsilon)$ time and expected squared distance $O(\\log 1/\\varepsilon)$, optimal for general $\\mathcal{S}$ of measure $\\varepsilon$. As corollary, we obtain the first computational concentration result (Etesami et al. SODA 2020) for Gaussian measure under Euclidean distance with dimension-independent transportation cost, resolving an open question of Etesami et al. Specifically, for any $\\mathcal{S}$ of Gaussian measure $\\varepsilon$, most $\\Phi^n$ samples can be mapped to $\\mathcal{S}$ within distance $O(\\sqrt{\\log 1/\\varepsilon})$ in $poly(n/\\varepsilon)$ time.",
        "subjects": "Data Structures and Algorithms, Artificial Intelligence, Information Theory, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.080357"
    },
    {
        "index": "#226",
        "title": "Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training",
        "link": "/arxiv/2509.21500",
        "arxiv_id": "2509.21500",
        "authors": "Junkai Zhang, Zihao Wang, Lin Gui, Swarnashree Mysore Sathyendra, Jaehwan Jeong, Victor Veitch, Wei Wang, Yunzhong He, Bing Liu, Lifeng Jin",
        "summary": "Reinforcement fine-tuning (RFT) often suffers from \\emph{reward over-optimization}, where a policy model hacks the reward signals to achieve high scores while producing low-quality outputs. Our theoretical analysis shows that the key lies in reward misspecification at the high-reward tail: the inability to reliably distinguish Excellent responses from merely Great ones. This motivate us to focus on the high-reward region. However, such tail examples are scarce under the base LLM. While off-policy exemplars (e.g. from stronger models or rewrites) are easier to obtain, naively training on them yields a misspecified reward for the policy we aim to align. To address this, we study rubric-based rewards. By design, rubrics can leverage off-policy examples while remaining insensitive to their artifacts. To elicit rubrics that capture the high-reward tail, we highlight the importance of distinguishing among great and diverse responses, and introduce a workflow to implement this idea. We empirically demonstrate that rubric-based rewards substantially mitigate reward over-optimization and deliver effective LLM post-training improvements. Our code can be accessed at https://github.com/Jun-Kai-Zhang/rubrics.git .",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.080939"
    },
    {
        "index": "#228",
        "title": "Neural Operators for Mathematical Modeling of Transient Fluid Flow in Subsurface Reservoir Systems",
        "link": "/arxiv/2509.21485",
        "arxiv_id": "2509.21485",
        "authors": "Daniil D. Sirota, Sergey A. Khan, Sergey L. Kostikov, Kirill A. Butov",
        "summary": "This paper presents a method for modeling transient fluid flow in subsurface reservoir systems based on the developed neural operator architecture (TFNO-opt). Reservoir systems are complex dynamic objects with distributed parameters described by systems of partial differential equations (PDEs). Traditional numerical methods for modeling such systems, despite their high accuracy, are characterized by significant time costs for performing calculations, which limits their applicability in control and decision support problems. The proposed architecture (TFNO-opt) is based on Fourier neural operators, which allow approximating PDE solutions in infinite-dimensional functional spaces, providing invariance to discretization and the possibility of generalization to various implementations of equations. The developed modifications are aimed at increasing the accuracy and stability of the trained neural operator, which is especially important for control problems. These include adjustable internal time resolution of the integral Fourier operator, tensor decomposition of parameters in the spectral domain, use of the Sobolev norm in the error function, and separation of approximation errors and reconstruction of initial conditions for more accurate reproduction of physical processes. The effectiveness of the proposed improvements is confirmed by computational experiments. The practical significance is confirmed by computational experiments using the example of the problem of hydrodynamic modeling of an underground gas storage (UGS), where the acceleration of calculations by six orders of magnitude was achieved, compared to traditional methods. This opens up new opportunities for the effective control of complex reservoir systems.",
        "subjects": "Machine Learning, Artificial Intelligence, Fluid Dynamics, Geophysics",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.087159"
    },
    {
        "index": "#231",
        "title": "Score-based Idempotent Distillation of Diffusion Models",
        "link": "/arxiv/2509.21470",
        "arxiv_id": "2509.21470",
        "authors": "Shehtab Zaman, Chengyan Liu, Kenneth Chiu",
        "summary": "Idempotent generative networks (IGNs) are a new line of generative models based on idempotent mapping to a target manifold. IGNs support both single-and multi-step generation, allowing for a flexible trade-off between computational cost and sample quality. But similar to Generative Adversarial Networks (GANs), conventional IGNs require adversarial training and are prone to training instabilities and mode collapse. Diffusion and score-based models are popular approaches to generative modeling that iteratively transport samples from one distribution, usually a Gaussian, to a target data distribution. These models have gained popularity due to their stable training dynamics and high-fidelity generation quality. However, this stability and quality come at the cost of high computational cost, as the data must be transported incrementally along the entire trajectory. New sampling methods, model distillation, and consistency models have been developed to reduce the sampling cost and even perform one-shot sampling from diffusion models. In this work, we unite diffusion and IGNs by distilling idempotent models from diffusion model scores, called SIGN. Our proposed method is highly stable and does not require adversarial losses. We provide a theoretical analysis of our proposed score-based training methods and empirically show that IGNs can be effectively distilled from a pre-trained diffusion model, enabling faster inference than iterative score-based models. SIGNs can perform multi-step sampling, allowing users to trade off quality for efficiency. These models operate directly on the source domain; they can project corrupted or alternate distributions back onto the target manifold, enabling zero-shot editing of inputs. We validate our models on multiple image datasets, achieving state-of-the-art results for idempotent models on the CIFAR and CelebA datasets.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.088722"
    },
    {
        "index": "#233",
        "title": "Enhanced Generative Machine Listener",
        "link": "/arxiv/2509.21463",
        "arxiv_id": "2509.21463",
        "authors": "Vishnu Raj, Gouthaman KV, Shiv Gehlot, Lars Villemoes, Arijit Biswas",
        "summary": "We present GMLv2, a reference-based model designed for the prediction of subjective audio quality as measured by MUSHRA scores. GMLv2 introduces a Beta distribution-based loss to model the listener ratings and incorporates additional neural audio coding (NAC) subjective datasets to extend its generalization and applicability. Extensive evaluations on diverse testset demonstrate that proposed GMLv2 consistently outperforms widely used metrics, such as PEAQ and ViSQOL, both in terms of correlation with subjective scores and in reliably predicting these scores across diverse content types and codec configurations. Consequently, GMLv2 offers a scalable and automated framework for perceptual audio quality evaluation, poised to accelerate research and development in modern audio coding technologies.",
        "subjects": "Audio and Speech Processing, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.089756"
    },
    {
        "index": "#237",
        "title": "Foundation models for high-energy physics",
        "link": "/arxiv/2509.21434",
        "arxiv_id": "2509.21434",
        "authors": "Anna Hallin",
        "summary": "The rise of foundation models -- large, pretrained machine learning models that can be finetuned to a variety of tasks -- has revolutionized the fields of natural language processing and computer vision. In high-energy physics, the question of whether these models can be implemented directly in physics research, or even built from scratch, tailored for particle physics data, has generated an increasing amount of attention. This review, which is the first on the topic of foundation models in high-energy physics, summarizes and discusses the research that has been published in the field so far.",
        "subjects": "High Energy Physics - Phenomenology, Artificial Intelligence, Machine Learning, High Energy Physics - Experiment, Data Analysis, Statistics and Probability",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.097241"
    },
    {
        "index": "#239",
        "title": "PhenoMoler: Phenotype-Guided Molecular Optimization via Chemistry Large Language Model",
        "link": "/arxiv/2509.21424",
        "arxiv_id": "2509.21424",
        "authors": "Ran Song, Hui Liu",
        "summary": "Current molecular generative models primarily focus on improving drug-target binding affinity and specificity, often neglecting the system-level phenotypic effects elicited by compounds. Transcriptional profiles, as molecule-level readouts of drug-induced phenotypic shifts, offer a powerful opportunity to guide molecular design in a phenotype-aware manner. We present PhenoMoler, a phenotype-guided molecular generation framework that integrates a chemistry large language model with expression profiles to enable biologically informed drug design. By conditioning the generation on drug-induced differential expression signatures, PhenoMoler explicitly links transcriptional responses to chemical structure. By selectively masking and reconstructing specific substructures-scaffolds, side chains, or linkers-PhenoMoler supports fine-grained, controllable molecular optimization. Extensive experiments demonstrate that PhenoMoler generates chemically valid, novel, and diverse molecules aligned with desired phenotypic profiles. Compared to FDA-approved drugs, the generated compounds exhibit comparable or enhanced drug-likeness (QED), optimized physicochemical properties, and superior binding affinity to key cancer targets. These findings highlight PhenoMoler's potential for phenotype-guided and structure-controllable molecular optimization.",
        "subjects": "Chemical Physics, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.098229"
    },
    {
        "index": "#240",
        "title": "Near-Optimal Experiment Design in Linear non-Gaussian Cyclic Models",
        "link": "/arxiv/2509.21423",
        "arxiv_id": "2509.21423",
        "authors": "Ehsan Sharifian, Saber Salehkaleybar, Negar Kiyavash",
        "summary": "We study the problem of causal structure learning from a combination of observational and interventional data generated by a linear non-Gaussian structural equation model that might contain cycles. Recent results show that using mere observational data identifies the causal graph only up to a permutation-equivalence class. We obtain a combinatorial characterization of this class by showing that each graph in an equivalence class corresponds to a perfect matching in a bipartite graph. This bipartite representation allows us to analyze how interventions modify or constrain the matchings. Specifically, we show that each atomic intervention reveals one edge of the true matching and eliminates all incompatible causal graphs. Consequently, we formalize the optimal experiment design task as an adaptive stochastic optimization problem over the set of equivalence classes with a natural reward function that quantifies how many graphs are eliminated from the equivalence class by an intervention. We show that this reward function is adaptive submodular and provide a greedy policy with a provable near-optimal performance guarantee. A key technical challenge is to efficiently estimate the reward function without having to explicitly enumerate all the graphs in the equivalence class. We propose a sampling-based estimator using random matchings and analyze its bias and concentration behavior. Our simulation results show that performing a small number of interventions guided by our stochastic optimization framework recovers the true underlying causal structure.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.098735"
    },
    {
        "index": "#243",
        "title": "MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering",
        "link": "/arxiv/2509.21391",
        "arxiv_id": "2509.21391",
        "authors": "Lihui Liu, Carl J. Yang",
        "summary": "Large Language Models (LLMs) have achieved impressive performance across a wide range of applications. However, they often suffer from hallucinations in knowledge-intensive domains due to their reliance on static pretraining corpora. To address this limitation, Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating external knowledge sources during inference. Among these sources, textual graphs provide structured and semantically rich information that supports more precise and interpretable reasoning. This has led to growing interest in graph-based RAG systems. Despite their potential, most existing approaches rely on a single retriever to identify relevant subgraphs, which limits their ability to capture the diverse aspects of complex queries. Moreover, these systems often struggle to accurately judge the relevance of retrieved content, making them prone to distraction by irrelevant noise. To address these challenges, in this paper, we propose MIXRAG, a Mixture-of-Experts Graph-RAG framework that introduces multiple specialized graph retrievers and a dynamic routing controller to better handle diverse query intents. Each retriever is trained to focus on a specific aspect of graph semantics, such as entities, relations, or subgraph topology. A Mixture-of-Experts module adaptively selects and fuses relevant retrievers based on the input query. To reduce noise in the retrieved information, we introduce a query-aware GraphEncoder that carefully analyzes relationships within the retrieved subgraphs, highlighting the most relevant parts while down-weighting unnecessary noise. Empirical results demonstrate that our method achieves state-of-the-art performance and consistently outperforms various baselines. MIXRAG is effective across a wide range of graph-based tasks in different domains. The code will be released upon paper acceptance.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-09-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.100189"
    },
    {
        "index": "#244",
        "title": "Towards Adapting Federated & Quantum Machine Learning for Network Intrusion Detection: A Survey",
        "link": "/arxiv/2509.21389",
        "arxiv_id": "2509.21389",
        "authors": "Devashish Chaudhary, Sutharshan Rajasegarar, Shiva Raj Pokhrel",
        "summary": "This survey explores the integration of Federated Learning (FL) with Network Intrusion Detection Systems (NIDS), with particular emphasis on deep learning and quantum machine learning approaches. FL enables collaborative model training across distributed devices while preserving data privacy-a critical requirement in network security contexts where sensitive traffic data cannot be centralized. Our comprehensive analysis systematically examines the full spectrum of FL architectures, deployment strategies, communication protocols, and aggregation methods specifically tailored for intrusion detection. We provide an in-depth investigation of privacy-preserving techniques, model compression approaches, and attack-specific federated solutions for threats including DDoS, MITM, and botnet attacks. The survey further delivers a pioneering exploration of Quantum FL (QFL), discussing quantum feature encoding, quantum machine learning algorithms, and quantum-specific aggregation methods that promise exponential speedups for complex pattern recognition in network traffic. Through rigorous comparative analysis of classical and quantum approaches, identification of research gaps, and evaluation of real-world deployments, we outline a concrete roadmap for industrial adoption and future research directions. This work serves as an authoritative reference for researchers and practitioners seeking to enhance privacy, efficiency, and robustness of federated intrusion detection systems in increasingly complex network environments, while preparing for the quantum-enhanced cybersecurity landscape of tomorrow.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.100679"
    },
    {
        "index": "#246",
        "title": "Toward a Realistic Encoding Model of Auditory Affective Understanding in the Brain",
        "link": "/arxiv/2509.21381",
        "arxiv_id": "2509.21381",
        "authors": "Guandong Pan, Yaqian Yang, Shi Chen, Xin Wang, Longzhao Liu, Hongwei Zheng, Shaoting Tang",
        "summary": "In affective neuroscience and emotion-aware AI, understanding how complex auditory stimuli drive emotion arousal dynamics remains unresolved. This study introduces a computational framework to model the brain's encoding of naturalistic auditory inputs into dynamic behavioral/neural responses across three datasets (SEED, LIRIS, self-collected BAVE). Guided by neurobiological principles of parallel auditory hierarchy, we decompose audio into multilevel auditory features (through classical algorithms and wav2vec 2.0/Hubert) from the original and isolated human voice/background soundtrack elements, mapping them to emotion-related responses via cross-dataset analyses. Our analysis reveals that high-level semantic representations (derived from the final layer of wav2vec 2.0/Hubert) exert a dominant role in emotion encoding, outperforming low-level acoustic features with significantly stronger mappings to behavioral annotations and dynamic neural synchrony across most brain regions ($p < 0.05$). Notably, middle layers of wav2vec 2.0/hubert (balancing acoustic-semantic information) surpass the final layers in emotion induction across datasets. Moreover, human voices and soundtracks show dataset-dependent emotion-evoking biases aligned with stimulus energy distribution (e.g., LIRIS favors soundtracks due to higher background energy), with neural analyses indicating voices dominate prefrontal/temporal activity while soundtracks excel in limbic regions. By integrating affective computing and neuroscience, this work uncovers hierarchical mechanisms of auditory-emotion encoding, providing a foundation for adaptive emotion-aware systems and cross-disciplinary explorations of audio-affective interactions.",
        "subjects": "Audio and Speech Processing, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-09-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.101766"
    },
    {
        "index": "#253",
        "title": "Design and Implementation of a Secure RAG-Enhanced AI Chatbot for Smart Tourism Customer Service: Defending Against Prompt Injection Attacks -- A Case Study of Hsinchu, Taiwan",
        "link": "/arxiv/2509.21367",
        "arxiv_id": "2509.21367",
        "authors": "Yu-Kai Shih, You-Kai Kang",
        "summary": "As smart tourism evolves, AI-powered chatbots have become indispensable for delivering personalized, real-time assistance to travelers while promoting sustainability and efficiency. However, these systems are increasingly vulnerable to prompt injection attacks, where adversaries manipulate inputs to elicit unintended behaviors such as leaking sensitive information or generating harmful content. This paper presents a case study on the design and implementation of a secure retrieval-augmented generation (RAG) chatbot for Hsinchu smart tourism services. The system integrates RAG with API function calls, multi-layered linguistic analysis, and guardrails against injections, achieving high contextual awareness and security. Key features include a tiered response strategy, RAG-driven knowledge grounding, and intent decomposition across lexical, semantic, and pragmatic levels. Defense mechanisms include system norms, gatekeepers for intent judgment, and reverse RAG text to prioritize verified data. We also benchmark a GPT-5 variant (released 2025-08-07) to assess inherent robustness. Evaluations with 674 adversarial prompts and 223 benign queries show over 95% accuracy on benign tasks and substantial detection of injection attacks. GPT-5 blocked about 85% of attacks, showing progress yet highlighting the need for layered defenses. Findings emphasize contributions to sustainable tourism, multilingual accessibility, and ethical AI deployment. This work offers a practical framework for deploying secure chatbots in smart tourism and contributes to resilient, trustworthy AI applications.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.110443"
    },
    {
        "index": "#262",
        "title": "Domain-Informed Genetic Superposition Programming: A Case Study on SFRC Beams",
        "link": "/arxiv/2509.21355",
        "arxiv_id": "2509.21355",
        "authors": "Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Mohammad Reza Nikoo, Fang Chen, Amir H. Gandomi",
        "summary": "This study presents domain-informed genetic superposition programming (DIGSP), a symbolic regression framework tailored for engineering systems governed by separable physical mechanisms. DIGSP partitions the input space into domain-specific feature subsets and evolves independent genetic programming (GP) populations to model material-specific effects. Early evolution occurs in isolation, while ensemble fitness promotes inter-population cooperation. To enable symbolic superposition, an adaptive hierarchical symbolic abstraction mechanism (AHSAM) is triggered after stagnation across all populations. AHSAM performs analysis of variance- (ANOVA) based filtering to identify statistically significant individuals, compresses them into symbolic constructs, and injects them into all populations through a validation-guided pruning cycle. The DIGSP is benchmarked against a baseline multi-gene genetic programming (BGP) model using a dataset of steel fiber-reinforced concrete (SFRC) beams. Across 30 independent trials with 65% training, 10% validation, and 25% testing splits, DIGSP consistently outperformed BGP in training and test root mean squared error (RMSE). The Wilcoxon rank-sum test confirmed statistical significance (p < 0.01), and DIGSP showed tighter error distributions and fewer outliers. No significant difference was observed in validation RMSE due to limited sample size. These results demonstrate that domain-informed structural decomposition and symbolic abstraction improve convergence and generalization. DIGSP offers a principled and interpretable modeling strategy for systems where symbolic superposition aligns with the underlying physical structure.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence",
        "date": "2025-09-20",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.120297"
    },
    {
        "index": "#265",
        "title": "SGNNBench: A Holistic Evaluation of Spiking Graph Neural Network on Large-scale Graph",
        "link": "/arxiv/2509.21342",
        "arxiv_id": "2509.21342",
        "authors": "Huizhe Zhang, Jintang Li, Yuchang Zhu, Liang Chen, Li Kuang",
        "summary": "Graph Neural Networks (GNNs) are exemplary deep models designed for graph data. Message passing mechanism enables GNNs to effectively capture graph topology and push the performance boundaries across various graph tasks. However, the trend of developing such complex machinery for graph representation learning has become unsustainable on large-scale graphs. The computational and time overhead make it imperative to develop more energy-efficient GNNs to cope with the explosive growth of real-world graphs. Spiking Graph Neural Networks (SGNNs), which integrate biologically plausible learning via unique spike-based neurons, have emerged as a promising energy-efficient alternative. Different layers communicate with sparse and binary spikes, which facilitates computation and storage of intermediate graph representations. Despite the proliferation of SGNNs proposed in recent years, there is no systematic benchmark to explore the basic design principles of these brain-inspired networks on the graph data. To bridge this gap, we present SGNNBench to quantify progress in the field of SGNNs. Specifically, SGNNBench conducts an in-depth investigation of SGNNs from multiple perspectives, including effectiveness, energy efficiency, and architectural design. We comprehensively evaluate 9 state-of-the-art SGNNs across 18 datasets. Regarding efficiency, we empirically compare these baselines w.r.t model size, memory usage, and theoretical energy consumption to reveal the often-overlooked energy bottlenecks of SGNNs. Besides, we elaborately investigate the design space of SGNNs to promote the development of a general SGNN paradigm.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Machine Learning",
        "date": "2025-09-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.121858"
    },
    {
        "index": "#266",
        "title": "From Embeddings to Equations: Genetic-Programming Surrogates for Interpretable Transformer Classification",
        "link": "/arxiv/2509.21341",
        "arxiv_id": "2509.21341",
        "authors": "Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Mohammad Reza Nikoo, Fang Chen, Amir H. Gandomi",
        "summary": "We study symbolic surrogate modeling of frozen Transformer embeddings to obtain compact, auditable classifiers with calibrated probabilities. For five benchmarks (SST2G, 20NG, MNIST, CIFAR10, MSC17), embeddings from ModernBERT, DINOv2, and SigLIP are partitioned on the training set into disjoint, information-preserving views via semantic-preserving feature partitioning (SPFP). A cooperative multi-population genetic program (MEGP) then learns additive, closed-form logit programs over these views. Across 30 runs per dataset we report F1, AUC, log-loss, Brier, expected calibration error (ECE), and symbolic complexity; a canonical model is chosen by a one-standard-error rule on validation F1 with a parsimony tie-break. Temperature scaling fitted on validation yields substantial ECE reductions on test. The resulting surrogates achieve strong discrimination (up to F1 around 0.99 on MNIST, CIFAR10, MSC17; around 0.95 on SST2G), while 20NG remains most challenging. We provide reliability diagrams, dimension usage and overlap statistics, contribution-based importances, and global effect profiles (PDP and ALE), demonstrating faithful, cross-modal explanations grounded in explicit programs.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Machine Learning",
        "date": "2025-09-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.122407"
    },
    {
        "index": "#267",
        "title": "Cycle is All You Need: More Is Different",
        "link": "/arxiv/2509.21340",
        "arxiv_id": "2509.21340",
        "authors": "Xin Li",
        "summary": "We propose an information-topological framework in which cycle closure is the fundamental mechanism of memory and consciousness. Memory is not a static store but the ability to re-enter latent cycles in neural state space, with invariant cycles serving as carriers of meaning by filtering order-specific noise and preserving what persists across contexts. The dot-cycle dichotomy captures this: transient dots scaffold exploration, while nontrivial cycles encode low-entropy content invariants that stabilize memory. Biologically, polychronous neural groups realize 1-cycles through delay-locked spiking reinforced by STDP, nested within theta-gamma rhythms that enforce boundary cancellation. These micro-cycles compose hierarchically, extending navigation loops into general memory and cognition. The perception-action cycle introduces high-order invariance: closure holds even across sense-act alternations, generalizing ancestral homing behavior. Sheaf-cosheaf duality formalizes this process: sheaves glue perceptual fragments into global sections, cosheaves decompose global plans into actions and closure aligns top-down predictions with bottom-up cycles. Consciousness then arises as the persistence of high-order invariants that integrate (unity) yet differentiate (richness) across contexts. We conclude that cycle is all you need: persistent invariants enable generalization in non-ergodic environments with long-term coherence at minimal energetic cost.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Machine Learning, Neurons and Cognition",
        "date": "2025-09-15",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.123329"
    },
    {
        "index": "#269",
        "title": "Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+",
        "link": "/arxiv/2509.21331",
        "arxiv_id": "2509.21331",
        "authors": "Mahedi Hasan",
        "summary": "Seismic velocity inversion is a key task in geophysical exploration, enabling the reconstruction of subsurface structures from seismic wave data. It is critical for high-resolution seismic imaging and interpretation. Traditional physics-driven methods, such as Full Waveform Inversion (FWI), are computationally demanding, sensitive to initialization, and limited by the bandwidth of seismic data. Recent advances in deep learning have led to data-driven approaches that treat velocity inversion as a dense prediction task. This research benchmarks three advanced encoder-decoder architectures -- U-Net, U-Net++, and DeepLabV3+ -- together with SeismoLabV3+, an optimized variant of DeepLabV3+ with a ResNeXt50 32x4d backbone and task-specific modifications -- for seismic velocity inversion using the ThinkOnward 2025 Speed \\& Structure dataset, which consists of five-channel seismic shot gathers paired with high-resolution velocity maps. Experimental results show that SeismoLabV3+ achieves the best performance, with MAPE values of 0.03025 on the internal validation split and 0.031246 on the hidden test set as scored via the official ThinkOnward leaderboard. These findings demonstrate the suitability of deep segmentation networks for seismic velocity inversion and underscore the value of tailored architectural refinements in advancing geophysical AI models.",
        "subjects": "Geophysics, Artificial Intelligence, Machine Learning",
        "date": "2025-09-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.124342"
    },
    {
        "index": "#270",
        "title": "Assessment of deep learning models integrated with weather and environmental variables for wildfire spread prediction and a case study of the 2023 Maui fires",
        "link": "/arxiv/2509.21327",
        "arxiv_id": "2509.21327",
        "authors": "Jiyeon Kim, Yingjie Hu, Negar Elhami-Khorasani, Kai Sun, Ryan Zhenqi Zhou",
        "summary": "Predicting the spread of wildfires is essential for effective fire management and risk assessment. With the fast advancements of artificial intelligence (AI), various deep learning models have been developed and utilized for wildfire spread prediction. However, there is limited understanding of the advantages and limitations of these models, and it is also unclear how deep learning-based fire spread models can be compared with existing non-AI fire models. In this work, we assess the ability of five typical deep learning models integrated with weather and environmental variables for wildfire spread prediction based on over ten years of wildfire data in the state of Hawaii. We further use the 2023 Maui fires as a case study to compare the best deep learning models with a widely-used fire spread model, FARSITE. The results show that two deep learning models, i.e., ConvLSTM and ConvLSTM with attention, perform the best among the five tested AI models. FARSITE shows higher precision, lower recall, and higher F1-score than the best AI models, while the AI models offer higher flexibility for the input data. By integrating AI models with an explainable AI method, we further identify important weather and environmental factors associated with the 2023 Maui wildfires.",
        "subjects": "Physics and Society, Artificial Intelligence, Machine Learning",
        "date": "2025-09-05",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.124879"
    },
    {
        "index": "#271",
        "title": "PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation",
        "link": "/arxiv/2509.21325",
        "arxiv_id": "2509.21325",
        "authors": "Baiqiang Wang, Qian Lou, Mengxin Zheng, Dongfang Zhao",
        "summary": "Retrieval-Augmented Generation (RAG) has become a foundational component of modern AI systems, yet it introduces significant privacy risks by exposing user queries to service providers. To address this, we introduce PIR-RAG, a practical system for privacy-preserving RAG. PIR-RAG employs a novel architecture that uses coarse-grained semantic clustering to prune the search space, combined with a fast, lattice-based Private Information Retrieval (PIR) protocol. This design allows for the efficient retrieval of entire document clusters, uniquely optimizing for the end-to-end RAG workflow where full document content is required. Our comprehensive evaluation against strong baseline architectures, including graph-based PIR and Tiptoe-style private scoring, demonstrates PIR-RAG's scalability and its superior performance in terms of \"RAG-Ready Latency\"-the true end-to-end time required to securely fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly efficient solution for privacy in large-scale AI systems.",
        "subjects": "Information Retrieval, Artificial Intelligence, Cryptography and Security",
        "date": "2025-09-01",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.125395"
    },
    {
        "index": "#272",
        "title": "From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data",
        "link": "/arxiv/2509.21324",
        "arxiv_id": "2509.21324",
        "authors": "Gurbinder Gill, Ritvik Gupta, Denis Lusson, Anand Chandrashekar, Donald Nguyen",
        "summary": "Retrieval-Augmented Generation (RAG) has emerged as the standard paradigm for answering questions on enterprise data. Traditionally, RAG has centered on text-based semantic search and re-ranking. However, this approach falls short when dealing with questions beyond data summarization or non-text data. This has led to various attempts to supplement RAG to bridge the gap between RAG, the implementation paradigm, and the question answering problem that enterprise users expect it to solve. Given that contemporary RAG is a collection of techniques rather than a defined implementation, discussion of RAG and related question-answering systems benefits from a problem-oriented understanding. We propose a new classification framework (L1-L5) to categorize systems based on data modalities and task complexity of the underlying question answering problems: L1 (Surface Knowledge of Unstructured Data) through L4 (Reflective and Reasoned Knowledge) and the aspirational L5 (General Intelligence). We also introduce benchmarks aligned with these levels and evaluate four state-of-the-art platforms: LangChain, Azure AI Search, OpenAI, and Corvic AI. Our experiments highlight the value of multi-space retrieval and dynamic orchestration for enabling L1-L4 capabilities. We empirically validate our findings using diverse datasets indicative of enterprise use cases.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-08-27",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.125899"
    },
    {
        "index": "#6",
        "title": "Transport Based Mean Flows for Generative Modeling",
        "link": "/arxiv/2509.22592",
        "arxiv_id": "2509.22592",
        "authors": "Elaheh Akbari, Ping He, Ahmadreza Moradipari, Yikun Bai, Soheil Kolouri",
        "summary": "Flow-matching generative models have emerged as a powerful paradigm for continuous data generation, achieving state-of-the-art results across domains such as images, 3D shapes, and point clouds. Despite their success, these models suffer from slow inference due to the requirement of numerous sequential sampling steps. Recent work has sought to accelerate inference by reducing the number of sampling steps. In particular, Mean Flows offer a one-step generation approach that delivers substantial speedups while retaining strong generative performance. Yet, in many continuous domains, Mean Flows fail to faithfully approximate the behavior of the original multi-step flow-matching process. In this work, we address this limitation by incorporating optimal transport-based sampling strategies into the Mean Flow framework, enabling one-step generators that better preserve the fidelity and diversity of the original multi-step flow process. Experiments on controlled low-dimensional settings and on high-dimensional tasks such as image generation, image-to-image translation, and point cloud generation demonstrate that our approach achieves superior inference accuracy in one-step generative modeling.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.131776"
    },
    {
        "index": "#7",
        "title": "The Lie of the Average: How Class Incremental Learning Evaluation Deceives You?",
        "link": "/arxiv/2509.22580",
        "arxiv_id": "2509.22580",
        "authors": "Guannan Lai, Da-Wei Zhou, Xin Yang, Han-Jia Ye",
        "summary": "Class Incremental Learning (CIL) requires models to continuously learn new classes without forgetting previously learned ones, while maintaining stable performance across all possible class sequences. In real-world settings, the order in which classes arrive is diverse and unpredictable, and model performance can vary substantially across different sequences. Yet mainstream evaluation protocols calculate mean and variance from only a small set of randomly sampled sequences. Our theoretical analysis and empirical results demonstrate that this sampling strategy fails to capture the full performance range, resulting in biased mean estimates and a severe underestimation of the true variance in the performance distribution. We therefore contend that a robust CIL evaluation protocol should accurately characterize and estimate the entire performance distribution. To this end, we introduce the concept of extreme sequences and provide theoretical justification for their crucial role in the reliable evaluation of CIL. Moreover, we observe a consistent positive correlation between inter-task similarity and model performance, a relation that can be leveraged to guide the search for extreme sequences. Building on these insights, we propose EDGE (Extreme case-based Distribution and Generalization Evaluation), an evaluation protocol that adaptively identifies and samples extreme class sequences using inter-task similarity, offering a closer approximation of the ground-truth performance distribution. Extensive experiments demonstrate that EDGE effectively captures performance extremes and yields more accurate estimates of distributional boundaries, providing actionable insights for model selection and robustness checking. Our code is available at https://github.com/AIGNLAI/EDGE.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.132378"
    },
    {
        "index": "#9",
        "title": "Machine learning approaches to seismic event classification in the Ostrava region",
        "link": "/arxiv/2509.22574",
        "arxiv_id": "2509.22574",
        "authors": "Marek Pecha, Michael Skotnica, Jana Rušajová, Bohdan Rieznikov, Vít Wandrol, Markéta Rösnerová, Jaromír Knejzlík",
        "summary": "The northeastern region of the Czech Republic is among the most seismically active areas in the country. The most frequent seismic events are mining-induced since there used to be strong mining activity in the past. However, natural tectonic events may also occur. In addition, seismic stations often record explosions in quarries in the region. Despite the cessation of mining activities, mine-induced seismic events still occur. Therefore, a rapid differentiation between tectonic and anthropogenic events is still important. The region is currently monitored by the OKC seismic station in Ostrava-Krásné Pole built in 1983 which is a part of the Czech Regional Seismic Network. The station has been providing digital continuous waveform data at 100 Hz since 2007. In the years 1992--2002, the region was co-monitored by the Seismic Polygon Frenštát (SPF) which consisted of five seismic stations using a triggered STA/LTA system. In this study, we apply and compare machine learning methods to the SPF dataset, which contains labeled records of tectonic and mining-induced events. For binary classification, a Long Short-Term Memory recurrent neural network and XGBoost achieved an F1-score of 0.94 -- 0.95, demonstrating the potential of modern machine learning techniques for rapid event characterization.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.134330"
    },
    {
        "index": "#12",
        "title": "Learning to Price Bundles: A GCN Approach for Mixed Bundling",
        "link": "/arxiv/2509.22557",
        "arxiv_id": "2509.22557",
        "authors": "Liangyu Ding, Chenghan Wu, Guokai Li, Zizhuo Wang",
        "summary": "Bundle pricing refers to designing several product combinations (i.e., bundles) and determining their prices in order to maximize the expected profit. It is a classic problem in revenue management and arises in many industries, such as e-commerce, tourism, and video games. However, the problem is typically intractable due to the exponential number of candidate bundles. In this paper, we explore the usage of graph convolutional networks (GCNs) in solving the bundle pricing problem. Specifically, we first develop a graph representation of the mixed bundling model (where every possible bundle is assigned with a specific price) and then train a GCN to learn the latent patterns of optimal bundles. Based on the trained GCN, we propose two inference strategies to derive high-quality feasible solutions. A local-search technique is further proposed to improve the solution quality. Numerical experiments validate the effectiveness and efficiency of our proposed GCN-based framework. Using a GCN trained on instances with 5 products, our methods consistently achieve near-optimal solutions (better than 97%) with only a fraction of computational time for problems of small to medium size. It also achieves superior solutions for larger size of problems compared with other heuristic methods such as bundle size pricing (BSP). The method can also provide high quality solutions for instances with more than 30 products even for the challenging cases where product utilities are non-additive.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.136067"
    },
    {
        "index": "#13",
        "title": "ECHO: Toward Contextual Seq2Seq Paradigms in Large EEG Models",
        "link": "/arxiv/2509.22556",
        "arxiv_id": "2509.22556",
        "authors": "Chenyu Liu, Yuqiu Deng, Tianyu Liu, Jinan Zhou, Xinliang Zhou, Ziyu Jia, Yi Ding",
        "summary": "Electroencephalography (EEG), with its broad range of applications, necessitates models that can generalize effectively across various tasks and datasets. Large EEG Models (LEMs) address this by pretraining encoder-centric architectures on large-scale unlabeled data to extract universal representations. While effective, these models lack decoders of comparable capacity, limiting the full utilization of the learned features. To address this issue, we introduce ECHO, a novel decoder-centric LEM paradigm that reformulates EEG modeling as sequence-to-sequence learning. ECHO captures layered relationships among signals, labels, and tasks within sequence space, while incorporating discrete support samples to construct contextual cues. This design equips ECHO with in-context learning, enabling dynamic adaptation to heterogeneous tasks without parameter updates. Extensive experiments across multiple datasets demonstrate that, even with basic model components, ECHO consistently outperforms state-of-the-art single-task LEMs in multi-task settings, showing superior generalization and adaptability.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.136381"
    },
    {
        "index": "#16",
        "title": "Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise",
        "link": "/arxiv/2509.22500",
        "arxiv_id": "2509.22500",
        "authors": "Juan Ramirez, Simon Lacoste-Julien",
        "summary": "Constrained optimization is a powerful framework for enforcing requirements on neural networks. These constrained deep learning problems are typically solved using first-order methods on their min-max Lagrangian formulation, but such approaches often suffer from oscillations and can fail to find all local solutions. While the Augmented Lagrangian method (ALM) addresses these issues, practitioners often favor dual optimistic ascent schemes (PI control) on the standard Lagrangian, which perform well empirically but lack formal guarantees. In this paper, we establish a previously unknown equivalence between these approaches: dual optimistic ascent on the Lagrangian is equivalent to gradient descent-ascent on the Augmented Lagrangian. This finding allows us to transfer the robust theoretical guarantees of the ALM to the dual optimistic setting, proving it converges linearly to all local solutions. Furthermore, the equivalence provides principled guidance for tuning the optimism hyper-parameter. Our work closes a critical gap between the empirical success of dual optimistic methods and their theoretical foundation.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.137216"
    },
    {
        "index": "#19",
        "title": "Bayesian Transfer Operators in Reproducing Kernel Hilbert Spaces",
        "link": "/arxiv/2509.22482",
        "arxiv_id": "2509.22482",
        "authors": "Septimus Boshoff, Sebastian Peitz, Stefan Klus",
        "summary": "The Koopman operator, as a linear representation of a nonlinear dynamical system, has been attracting attention in many fields of science. Recently, Koopman operator theory has been combined with another concept that is popular in data science: reproducing kernel Hilbert spaces. We follow this thread into Gaussian process methods, and illustrate how these methods can alleviate two pervasive problems with kernel-based Koopman algorithms. The first being sparsity: most kernel methods do not scale well and require an approximation to become practical. We show that not only can the computational demands be reduced, but also demonstrate improved resilience against sensor noise. The second problem involves hyperparameter optimization and dictionary learning to adapt the model to the dynamical system. In summary, the main contribution of this work is the unification of Gaussian process regression and dynamic mode decomposition.",
        "subjects": "Machine Learning, Dynamical Systems, Chaotic Dynamics, Data Analysis, Statistics and Probability",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.138109"
    },
    {
        "index": "#22",
        "title": "Nonlinear Optimization with GPU-Accelerated Neural Network Constraints",
        "link": "/arxiv/2509.22462",
        "arxiv_id": "2509.22462",
        "authors": "Robert Parker, Oscar Dowson, Nicole LoGiudice, Manuel Garcia, Russell Bent",
        "summary": "We propose a reduced-space formulation for optimizing over trained neural networks where the network's outputs and derivatives are evaluated on a GPU. To do this, we treat the neural network as a \"gray box\" where intermediate variables and constraints are not exposed to the optimization solver. Compared to the full-space formulation, in which intermediate variables and constraints are exposed to the optimization solver, the reduced-space formulation leads to faster solves and fewer iterations in an interior point method. We demonstrate the benefits of this method on two optimization problems: Adversarial generation for a classifier trained on MNIST images and security-constrained optimal power flow with transient feasibility enforced using a neural network surrogate.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.139130"
    },
    {
        "index": "#24",
        "title": "Overclocking Electrostatic Generative Models",
        "link": "/arxiv/2509.22454",
        "arxiv_id": "2509.22454",
        "authors": "Daniil Shlenskii, Alexander Korotin",
        "summary": "Electrostatic generative models such as PFGM++ have recently emerged as a powerful framework, achieving state-of-the-art performance in image synthesis. PFGM++ operates in an extended data space with auxiliary dimensionality $D$, recovering the diffusion model framework as $D\\to\\infty$, while yielding superior empirical results for finite $D$. Like diffusion models, PFGM++ relies on expensive ODE simulations to generate samples, making it computationally costly. To address this, we propose Inverse Poisson Flow Matching (IPFM), a novel distillation framework that accelerates electrostatic generative models across all values of $D$. Our IPFM reformulates distillation as an inverse problem: learning a generator whose induced electrostatic field matches that of the teacher. We derive a tractable training objective for this problem and show that, as $D \\to \\infty$, our IPFM closely recovers Score Identity Distillation (SiD), a recent method for distilling diffusion models. Empirically, our IPFM produces distilled generators that achieve near-teacher or even superior sample quality using only a few function evaluations. Moreover, we observe that distillation converges faster for finite $D$ than in the $D \\to \\infty$ (diffusion) limit, which is consistent with prior findings that finite-$D$ PFGM++ models exhibit more favorable optimization and sampling properties.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.139738"
    },
    {
        "index": "#27",
        "title": "The Flood Complex: Large-Scale Persistent Homology on Millions of Points",
        "link": "/arxiv/2509.22432",
        "arxiv_id": "2509.22432",
        "authors": "Florian Graf, Paolo Pellizzoni, Martin Uray, Stefan Huber, Roland Kwitt",
        "summary": "We consider the problem of computing persistent homology (PH) for large-scale Euclidean point cloud data, aimed at downstream machine learning tasks, where the exponential growth of the most widely-used Vietoris-Rips complex imposes serious computational limitations. Although more scalable alternatives such as the Alpha complex or sparse Rips approximations exist, they often still result in a prohibitively large number of simplices. This poses challenges in the complex construction and in the subsequent PH computation, prohibiting their use on large-scale point clouds. To mitigate these issues, we introduce the Flood complex, inspired by the advantages of the Alpha and Witness complex constructions. Informally, at a given filtration value $r\\geq 0$, the Flood complex contains all simplices from a Delaunay triangulation of a small subset of the point cloud $X$ that are fully covered by balls of radius $r$ emanating from $X$, a process we call flooding. Our construction allows for efficient PH computation, possesses several desirable theoretical properties, and is amenable to GPU parallelization. Scaling experiments on 3D point cloud data show that we can compute PH of up to dimension 2 on several millions of points. Importantly, when evaluating object classification performance on real-world and synthetic data, we provide evidence that this scaling capability is needed, especially if objects are geometrically or topologically complex, yielding performance superior to other PH-based methods and neural networks for point cloud data.",
        "subjects": "Machine Learning, Computational Geometry",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.140646"
    },
    {
        "index": "#30",
        "title": "One Prompt Fits All: Universal Graph Adaptation for Pretrained Models",
        "link": "/arxiv/2509.22416",
        "arxiv_id": "2509.22416",
        "authors": "Yongqi Huang, Jitao Zhao, Dongxiao He, Xiaobao Wang, Yawen Li, Yuxiao Huang, Di Jin, Zhiyong Feng",
        "summary": "Graph Prompt Learning (GPL) has emerged as a promising paradigm that bridges graph pretraining models and downstream scenarios, mitigating label dependency and the misalignment between upstream pretraining and downstream tasks. Although existing GPL studies explore various prompt strategies, their effectiveness and underlying principles remain unclear. We identify two critical limitations: (1) Lack of consensus on underlying mechanisms: Despite current GPLs have advanced the field, there is no consensus on how prompts interact with pretrained models, as different strategies intervene at varying spaces within the model, i.e., input-level, layer-wise, and representation-level prompts. (2) Limited scenario adaptability: Most methods fail to generalize across diverse downstream scenarios, especially under data distribution shifts (e.g., homophilic-to-heterophilic graphs). To address these issues, we theoretically analyze existing GPL approaches and reveal that representation-level prompts essentially function as fine-tuning a simple downstream classifier, proposing that graph prompt learning should focus on unleashing the capability of pretrained models, and the classifier adapts to downstream scenarios. Based on our findings, we propose UniPrompt, a novel GPL method that adapts any pretrained models, unleashing the capability of pretrained models while preserving the structure of the input graph. Extensive experiments demonstrate that our method can effectively integrate with various pretrained models and achieve strong performance across in-domain and cross-domain scenarios.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.141572"
    },
    {
        "index": "#31",
        "title": "Fast-Forward Lattice Boltzmann: Learning Kinetic Behaviour with Physics-Informed Neural Operators",
        "link": "/arxiv/2509.22411",
        "arxiv_id": "2509.22411",
        "authors": "Xiao Xue, Marco F. P. ten Eikelder, Mingyang Gao, Xiaoyuan Cheng, Yiming Yang, Yi He, Shuo Wang, Sibo Cheng, Yukun Hu, Peter V. Coveney",
        "summary": "The lattice Boltzmann equation (LBE), rooted in kinetic theory, provides a powerful framework for capturing complex flow behaviour by describing the evolution of single-particle distribution functions (PDFs). Despite its success, solving the LBE numerically remains computationally intensive due to strict time-step restrictions imposed by collision kernels. Here, we introduce a physics-informed neural operator framework for the LBE that enables prediction over large time horizons without step-by-step integration, effectively bypassing the need to explicitly solve the collision kernel. We incorporate intrinsic moment-matching constraints of the LBE, along with global equivariance of the full distribution field, enabling the model to capture the complex dynamics of the underlying kinetic system. Our framework is discretization-invariant, enabling models trained on coarse lattices to generalise to finer ones (kinetic super-resolution). In addition, it is agnostic to the specific form of the underlying collision model, which makes it naturally applicable across different kinetic datasets regardless of the governing dynamics. Our results demonstrate robustness across complex flow scenarios, including von Karman vortex shedding, ligament breakup, and bubble adhesion. This establishes a new data-driven pathway for modelling kinetic systems.",
        "subjects": "Machine Learning, Cellular Automata and Lattice Gases, Computational Physics, Fluid Dynamics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.141946"
    },
    {
        "index": "#32",
        "title": "MoveFM-R: Advancing Mobility Foundation Models via Language-driven Semantic Reasoning",
        "link": "/arxiv/2509.22403",
        "arxiv_id": "2509.22403",
        "authors": "Fanjin Meng, Yuan Yuan, Jingtao Ding, Jie Feng, Chonghua Han, Yong Li",
        "summary": "Mobility Foundation Models (MFMs) have advanced the modeling of human movement patterns, yet they face a ceiling due to limitations in data scale and semantic understanding. While Large Language Models (LLMs) offer powerful semantic reasoning, they lack the innate understanding of spatio-temporal statistics required for generating physically plausible mobility trajectories. To address these gaps, we propose MoveFM-R, a novel framework that unlocks the full potential of mobility foundation models by leveraging language-driven semantic reasoning capabilities. It tackles two key challenges: the vocabulary mismatch between continuous geographic coordinates and discrete language tokens, and the representation gap between the latent vectors of MFMs and the semantic world of LLMs. MoveFM-R is built on three core innovations: a semantically enhanced location encoding to bridge the geography-language gap, a progressive curriculum to align the LLM's reasoning with mobility patterns, and an interactive self-reflection mechanism for conditional trajectory generation. Extensive experiments demonstrate that MoveFM-R significantly outperforms existing MFM-based and LLM-based baselines. It also shows robust generalization in zero-shot settings and excels at generating realistic trajectories from natural language instructions. By synthesizing the statistical power of MFMs with the deep semantic understanding of LLMs, MoveFM-R pioneers a new paradigm that enables a more comprehensive, interpretable, and powerful modeling of human mobility. The implementation of MoveFM-R is available online at https://anonymous.4open.science/r/MoveFM-R-CDE7/.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.142248"
    },
    {
        "index": "#33",
        "title": "ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation",
        "link": "/arxiv/2509.22402",
        "arxiv_id": "2509.22402",
        "authors": "Nan Tang, Jing-Cheng Pang, Guanlin Li, Chao Qian, Yang Yu",
        "summary": "Reward design remains a critical bottleneck in visual reinforcement learning (RL) for robotic manipulation. In simulated environments, rewards are conventionally designed based on the distance to a target position. However, such precise positional information is often unavailable in real-world visual settings due to sensory and perceptual limitations. In this study, we propose a method that implicitly infers spatial distances through keypoints extracted from images. Building on this, we introduce Reward Learning with Anticipation Model (ReLAM), a novel framework that automatically generates dense, structured rewards from action-free video demonstrations. ReLAM first learns an anticipation model that serves as a planner and proposes intermediate keypoint-based subgoals on the optimal path to the final goal, creating a structured learning curriculum directly aligned with the task's geometric objectives. Based on the anticipated subgoals, a continuous reward signal is provided to train a low-level, goal-conditioned policy under the hierarchical reinforcement learning (HRL) framework with provable sub-optimality bound. Extensive experiments on complex, long-horizon manipulation tasks show that ReLAM significantly accelerates learning and achieves superior performance compared to state-of-the-art methods.",
        "subjects": "Machine Learning, Robotics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.142547"
    },
    {
        "index": "#34",
        "title": "Improving accuracy in short mortality rate series: Exploring Multi-step Forecasting Approaches in Hybrid Systems",
        "link": "/arxiv/2509.22395",
        "arxiv_id": "2509.22395",
        "authors": "Filipe C. L. Duarte, Paulo S. G. de Mattos Neto, Paulo R. A. Firmino",
        "summary": "The decline in interest rates and economic stabilization has heightened the importance of accurate mortality rate forecasting, particularly in insurance and pension markets. Multi-step-ahead predictions are crucial for public health, demographic planning, and insurance risk assessments; however, they face challenges when data are limited. Hybrid systems that combine statistical and Machine Learning (ML) models offer a promising solution for handling both linear and nonlinear patterns. This study evaluated the impact of different multi-step forecasting approaches (Recursive, Direct, and Multi-Input Multi-Output) and ML models on the accuracy of hybrid systems. Results from 12 datasets and 21 models show that the selection of both the multi-step approach and the ML model is essential for improving performance, with the ARIMA-LSTM hybrid using a recursive approach outperforming other models in most cases.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.142816"
    },
    {
        "index": "#36",
        "title": "(Sometimes) Less is More: Mitigating the Complexity of Rule-based Representation for Interpretable Classification",
        "link": "/arxiv/2509.22384",
        "arxiv_id": "2509.22384",
        "authors": "Luca Bergamin, Roberto Confalonieri, Fabio Aiolli",
        "summary": "Deep neural networks are widely used in practical applications of AI, however, their inner structure and complexity made them generally not easily interpretable. Model transparency and interpretability are key requirements for multiple scenarios where high performance is not enough to adopt the proposed solution. In this work, a differentiable approximation of $L_0$ regularization is adapted into a logic-based neural network, the Multi-layer Logical Perceptron (MLLP), to study its efficacy in reducing the complexity of its discrete interpretable version, the Concept Rule Set (CRS), while retaining its performance. The results are compared to alternative heuristics like Random Binarization of the network weights, to determine if better results can be achieved when using a less-noisy technique that sparsifies the network based on the loss function instead of a random distribution. The trade-off between the CRS complexity and its performance is discussed.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.143353"
    },
    {
        "index": "#37",
        "title": "Enhancing Credit Risk Prediction: A Meta-Learning Framework Integrating Baseline Models, LASSO, and ECOC for Superior Accuracy",
        "link": "/arxiv/2509.22381",
        "arxiv_id": "2509.22381",
        "authors": "Haibo Wang, Lutfu S. Sua, Jun Huang, Figen Balo, Burak Dolar",
        "summary": "Effective credit risk management is fundamental to financial decision-making, necessitating robust models for default probability prediction and financial entity classification. Traditional machine learning approaches face significant challenges when confronted with high-dimensional data, limited interpretability, rare event detection, and multi-class imbalance problems in risk assessment. This research proposes a comprehensive meta-learning framework that synthesizes multiple complementary models: supervised learning algorithms, including XGBoost, Random Forest, Support Vector Machine, and Decision Tree; unsupervised methods such as K-Nearest Neighbors; deep learning architectures like Multilayer Perceptron; alongside LASSO regularization for feature selection and dimensionality reduction; and Error-Correcting Output Codes as a meta-classifier for handling imbalanced multi-class problems. We implement Permutation Feature Importance analysis for each prediction class across all constituent models to enhance model transparency. Our framework aims to optimize predictive performance while providing a more holistic approach to credit risk assessment. This research contributes to the development of more accurate and reliable computational models for strategic financial decision support by addressing three fundamental challenges in credit risk modeling. The empirical validation of our approach involves an analysis of the Corporate Credit Ratings dataset with credit ratings for 2,029 publicly listed US companies. Results demonstrate that our meta-learning framework significantly enhances the accuracy of financial entity classification regarding credit rating migrations (upgrades and downgrades) and default probability estimation.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.143649"
    },
    {
        "index": "#38",
        "title": "Role-Aware Multi-modal federated learning system for detecting phishing webpages",
        "link": "/arxiv/2509.22369",
        "arxiv_id": "2509.22369",
        "authors": "Bo Wang, Imran Khan, Martin White, Natalia Beloff",
        "summary": "We present a federated, multi-modal phishing website detector that supports URL, HTML, and IMAGE inputs without binding clients to a fixed modality at inference: any client can invoke any modality head trained elsewhere. Methodologically, we propose role-aware bucket aggregation on top of FedProx, inspired by Mixture-of-Experts and FedMM. We drop learnable routing and use hard gating (selecting the IMAGE/HTML/URL expert by sample modality), enabling separate aggregation of modality-specific parameters to isolate cross-embedding conflicts and stabilize convergence. On TR-OP, the Fusion head reaches Acc 97.5% with FPR 2.4% across two data types; on the image subset (ablation) it attains Acc 95.5% with FPR 5.9%. For text, we use GraphCodeBERT for URLs and an early three-way embedding for raw, noisy HTML. On WebPhish (HTML) we obtain Acc 96.5% / FPR 1.8%; on TR-OP (raw HTML) we obtain Acc 95.1% / FPR 4.6%. Results indicate that bucket aggregation with hard-gated experts enables stable federated training under strict privacy, while improving the usability and flexibility of multi-modal phishing detection.",
        "subjects": "Machine Learning, Distributed, Parallel, and Cluster Computing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.143948"
    },
    {
        "index": "#39",
        "title": "Investigating Faithfulness in Large Audio Language Models",
        "link": "/arxiv/2509.22363",
        "arxiv_id": "2509.22363",
        "authors": "Lovenya Jain, Pooneh Mousavi, Mirco Ravanelli, Cem Subakan",
        "summary": "Faithfulness measures whether chain-of-thought (CoT) representations accurately reflect a model's decision process and can be used as reliable explanations. Prior work has shown that CoTs from text-based LLMs are often unfaithful. This question has not been explored for large audio-language models (LALMs), where faithfulness is critical for safety-sensitive applications. Reasoning in LALMs is also more challenging, as models must first extract relevant clues from audio before reasoning over them. In this paper, we investigate the faithfulness of CoTs produced by several LALMs by applying targeted interventions, including paraphrasing, filler token injection, early answering, and introducing mistakes, on two challenging reasoning datasets: SAKURA and MMAR. After going through the aforementioned interventions across several datasets and tasks, our experiments suggest that, LALMs generally produce CoTs that appear to be faithful to their underlying decision processes.",
        "subjects": "Machine Learning, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.144242"
    },
    {
        "index": "#40",
        "title": "Neural Feature Geometry Evolves as Discrete Ricci Flow",
        "link": "/arxiv/2509.22362",
        "arxiv_id": "2509.22362",
        "authors": "Moritz Hehl, Max von Renesse, Melanie Weber",
        "summary": "Deep neural networks learn feature representations via complex geometric transformations of the input data manifold. Despite the models' empirical success across domains, our understanding of neural feature representations is still incomplete. In this work we investigate neural feature geometry through the lens of discrete geometry. Since the input data manifold is typically unobserved, we approximate it using geometric graphs that encode local similarity structure. We provide theoretical results on the evolution of these graphs during training, showing that nonlinear activations play a crucial role in shaping feature geometry in feedforward neural networks. Moreover, we discover that the geometric transformations resemble a discrete Ricci flow on these graphs, suggesting that neural feature geometry evolves analogous to Ricci flow. This connection is supported by experiments on over 20,000 feedforward neural networks trained on binary classification tasks across both synthetic and real-world datasets. We observe that the emergence of class separability corresponds to the emergence of community structure in the associated graph representations, which is known to relate to discrete Ricci flow dynamics. Building on these insights, we introduce a novel framework for locally evaluating geometric transformations through comparison with discrete Ricci flow dynamics. Our results suggest practical design principles, including a geometry-informed early-stopping heuristic and a criterion for selecting network depth.",
        "subjects": "Machine Learning, Discrete Mathematics, Differential Geometry",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.144528"
    },
    {
        "index": "#45",
        "title": "Distributed Associative Memory via Online Convex Optimization",
        "link": "/arxiv/2509.22321",
        "arxiv_id": "2509.22321",
        "authors": "Bowen Wang, Matteo Zecchin, Osvaldo Simeone",
        "summary": "An associative memory (AM) enables cue-response recall, and associative memorization has recently been noted to underlie the operation of modern neural architectures such as Transformers. This work addresses a distributed setting where agents maintain a local AM to recall their own associations as well as selective information from others. Specifically, we introduce a distributed online gradient descent method that optimizes local AMs at different agents through communication over routing trees. Our theoretical analysis establishes sublinear regret guarantees, and experiments demonstrate that the proposed protocol consistently outperforms existing online optimization baselines.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.146112"
    },
    {
        "index": "#48",
        "title": "SoDaDE: Solvent Data-Driven Embeddings with Small Transformer Models",
        "link": "/arxiv/2509.22302",
        "arxiv_id": "2509.22302",
        "authors": "Gabriel Kitso Gibberd, Jose Pablo Folch, Antonio Del Rio Chanona",
        "summary": "Computational representations have become crucial in unlocking the recent growth of machine learning algorithms for chemistry. Initially hand-designed, machine learning has shown that meaningful representations can be learnt from data. Chemical datasets are limited and so the representations learnt from data are generic, being trained on broad datasets which contain shallow information on many different molecule types. For example, generic fingerprints lack physical context specific to solvents. However, the use of harmful solvents is a leading climate-related issue in the chemical industry, and there is a surge of interest in green solvent replacement. To empower this research, we propose a new solvent representation scheme by developing Solvent Data Driven Embeddings (SoDaDE). SoDaDE uses a small transformer model and solvent property dataset to create a fingerprint for solvents. To showcase their effectiveness, we use SoDaDE to predict yields on a recently published dataset, outperforming previous representations. We demonstrate through this paper that data-driven fingerprints can be made with small datasets and set-up a workflow that can be explored for other applications.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.146961"
    },
    {
        "index": "#50",
        "title": "Aurora: Towards Universal Generative Multimodal Time Series Forecasting",
        "link": "/arxiv/2509.22295",
        "arxiv_id": "2509.22295",
        "authors": "Xingjian Wu, Jianxin Jin, Wanghui Qiu, Peng Chen, Yang Shu, Bin Yang, Chenjuan Guo",
        "summary": "Cross-domain generalization is very important in Time Series Forecasting because similar historical information may lead to distinct future trends due to the domain-specific characteristics. Recent works focus on building unimodal time series foundation models and end-to-end multimodal supervised models. Since domain-specific knowledge is often contained in modalities like texts, the former lacks the explicit utilization of them, thus hindering the performance. The latter is tailored for end-to-end scenarios and does not support zero-shot inference for cross-domain scenarios. In this work, we introduce Aurora, a Multimodal Time Series Foundation Model, which supports multimodal inputs and zero-shot inference. Pretrained on Corss-domain Multimodal Time Series Corpus, Aurora can adaptively extract and focus on key domain knowledge contained in corrsponding text or image modalities, thus possessing strong Cross-domain generalization capability. Through tokenization, encoding, and distillation, Aurora can extract multimodal domain knowledge as guidance and then utilizes a Modality-Guided Multi-head Self-Attention to inject them into the modeling of temporal representations. In the decoding phase, the multimodal representations are used to generate the conditions and prototypes of future tokens, contributing to a novel Prototype-Guided Flow Matching for generative probabilistic forecasting. Comprehensive experiments on well-recognized benchmarks, including TimeMMD, TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art performance of Aurora on both unimodal and multimodal scenarios.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.147575"
    },
    {
        "index": "#51",
        "title": "A Multi-Level Framework for Multi-Objective Hypergraph Partitioning: Combining Minimum Spanning Tree and Proximal Gradient",
        "link": "/arxiv/2509.22294",
        "arxiv_id": "2509.22294",
        "authors": "Yingying Li, Mingxuan Xie, Hailong You, Yongqiang Yao, Hongwei Liu",
        "summary": "This paper proposes an efficient hypergraph partitioning framework based on a novel multi-objective non-convex constrained relaxation model. A modified accelerated proximal gradient algorithm is employed to generate diverse $k$-dimensional vertex features to avoid local optima and enhance partition quality. Two MST-based strategies are designed for different data scales: for small-scale data, the Prim algorithm constructs a minimum spanning tree followed by pruning and clustering; for large-scale data, a subset of representative nodes is selected to build a smaller MST, while the remaining nodes are assigned accordingly to reduce complexity. To further improve partitioning results, refinement strategies including greedy migration, swapping, and recursive MST-based clustering are introduced for partitions. Experimental results on public benchmark sets demonstrate that the proposed algorithm achieves reductions in cut size of approximately 2\\%--5\\% on average compared to KaHyPar in 2, 3, and 4-way partitioning, with improvements of up to 35\\% on specific instances. Particularly on weighted vertex sets, our algorithm outperforms state-of-the-art partitioners including KaHyPar, hMetis, Mt-KaHyPar, and K-SpecPart, highlighting its superior partitioning quality and competitiveness. Furthermore, the proposed refinement strategy improves hMetis partitions by up to 16\\%. A comprehensive evaluation based on virtual instance methodology and parameter sensitivity analysis validates the algorithm's competitiveness and characterizes its performance trade-offs.",
        "subjects": "Machine Learning, Combinatorics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.147890"
    },
    {
        "index": "#52",
        "title": "Conditional Denoising Diffusion Autoencoders for Wireless Semantic Communications",
        "link": "/arxiv/2509.22282",
        "arxiv_id": "2509.22282",
        "authors": "Mehdi Letafati, Samad Ali, Matti Latva-aho",
        "summary": "Semantic communication (SemCom) systems aim to learn the mapping from low-dimensional semantics to high-dimensional ground-truth. While this is more akin to a \"domain translation\" problem, existing frameworks typically emphasize on channel-adaptive neural encoding-decoding schemes, lacking full exploration of signal distribution. Moreover, such methods so far have employed autoencoder-based architectures, where the encoding is tightly coupled to a matched decoder, causing scalability issues in practice. To address these gaps, diffusion autoencoder models are proposed for wireless SemCom. The goal is to learn a \"semantic-to-clean\" mapping, from the semantic space to the ground-truth probability distribution. A neural encoder at semantic transmitter extracts the high-level semantics, and a conditional diffusion model (CDiff) at the semantic receiver exploits the source distribution for signal-space denoising, while the received semantic latents are incorporated as the conditioning input to \"steer\" the decoding process towards the semantics intended by the transmitter. It is analytically proved that the proposed decoder model is a consistent estimator of the ground-truth data. Furthermore, extensive simulations over CIFAR-10 and MNIST datasets are provided along with design insights, highlighting the performance compared to legacy autoencoders and variational autoencoders (VAE). Simulations are further extended to the multi-user SemCom, identifying the dominating factors in a more realistic setup.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.148166"
    },
    {
        "index": "#53",
        "title": "Unlocking the Power of Mixture-of-Experts for Task-Aware Time Series Analytics",
        "link": "/arxiv/2509.22279",
        "arxiv_id": "2509.22279",
        "authors": "Xingjian Wu, Zhengyu Li, Hanyin Cheng, Xiangfei Qiu, Jilin Hu, Chenjuan Guo, Bin Yang",
        "summary": "Time Series Analysis is widely used in various real-world applications such as weather forecasting, financial fraud detection, imputation for missing data in IoT systems, and classification for action recognization. Mixture-of-Experts (MoE), as a powerful architecture, though demonstrating effectiveness in NLP, still falls short in adapting to versatile tasks in time series analytics due to its task-agnostic router and the lack of capability in modeling channel correlations. In this study, we propose a novel, general MoE-based time series framework called PatchMoE to support the intricate ``knowledge'' utilization for distinct tasks, thus task-aware. Based on the observation that hierarchical representations often vary across tasks, e.g., forecasting vs. classification, we propose a Recurrent Noisy Gating to utilize the hierarchical information in routing, thus obtaining task-sepcific capability. And the routing strategy is operated on time series tokens in both temporal and channel dimensions, and encouraged by a meticulously designed Temporal \\& Channel Load Balancing Loss to model the intricate temporal and channel correlations. Comprehensive experiments on five downstream tasks demonstrate the state-of-the-art performance of PatchMoE.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.148470"
    },
    {
        "index": "#54",
        "title": "Fine-Grained Uncertainty Decomposition in Large Language Models: A Spectral Approach",
        "link": "/arxiv/2509.22272",
        "arxiv_id": "2509.22272",
        "authors": "Nassim Walha, Sebastian G. Gruber, Thomas Decker, Yinchong Yang, Alireza Javanmardi, Eyke Hüllermeier, Florian Buettner",
        "summary": "As Large Language Models (LLMs) are increasingly integrated in diverse applications, obtaining reliable measures of their predictive uncertainty has become critically important. A precise distinction between aleatoric uncertainty, arising from inherent ambiguities within input data, and epistemic uncertainty, originating exclusively from model limitations, is essential to effectively address each uncertainty source. In this paper, we introduce Spectral Uncertainty, a novel approach to quantifying and decomposing uncertainties in LLMs. Leveraging the Von Neumann entropy from quantum information theory, Spectral Uncertainty provides a rigorous theoretical foundation for separating total uncertainty into distinct aleatoric and epistemic components. Unlike existing baseline methods, our approach incorporates a fine-grained representation of semantic similarity, enabling nuanced differentiation among various semantic interpretations in model responses. Empirical evaluations demonstrate that Spectral Uncertainty outperforms state-of-the-art methods in estimating both aleatoric and total uncertainty across diverse models and benchmark datasets.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.148771"
    },
    {
        "index": "#55",
        "title": "Towards a more realistic evaluation of machine learning models for bearing fault diagnosis",
        "link": "/arxiv/2509.22267",
        "arxiv_id": "2509.22267",
        "authors": "João Paulo Vieira, Victor Afonso Bauler, Rodrigo Kobashikawa Rosa, Danilo Silva",
        "summary": "Reliable detection of bearing faults is essential for maintaining the safety and operational efficiency of rotating machinery. While recent advances in machine learning (ML), particularly deep learning, have shown strong performance in controlled settings, many studies fail to generalize to real-world applications due to methodological flaws, most notably data leakage. This paper investigates the issue of data leakage in vibration-based bearing fault diagnosis and its impact on model evaluation. We demonstrate that common dataset partitioning strategies, such as segment-wise and condition-wise splits, introduce spurious correlations that inflate performance metrics. To address this, we propose a rigorous, leakage-free evaluation methodology centered on bearing-wise data partitioning, ensuring no overlap between the physical components used for training and testing. Additionally, we reformulate the classification task as a multi-label problem, enabling the detection of co-occurring fault types and the use of prevalence-independent metrics such as Macro AUROC. Beyond preventing leakage, we also examine the effect of dataset diversity on generalization, showing that the number of unique training bearings is a decisive factor for achieving robust performance. We evaluate our methodology on three widely adopted datasets: CWRU, Paderborn University (PU), and University of Ottawa (UORED-VAFCLS). This study highlights the importance of leakage-aware evaluation protocols and provides practical guidelines for dataset partitioning, model selection, and validation, fostering the development of more trustworthy ML systems for industrial fault diagnosis applications.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.149063"
    },
    {
        "index": "#56",
        "title": "Erase or Hide? Suppressing Spurious Unlearning Neurons for Robust Unlearning",
        "link": "/arxiv/2509.22263",
        "arxiv_id": "2509.22263",
        "authors": "Nakyeong Yang, Dong-Kyum Kim, Jea Kwon, Minsung Kim, Kyomin Jung, Meeyoung Cha",
        "summary": "Large language models trained on web-scale data can memorize private or sensitive knowledge, raising significant privacy risks. Although some unlearning methods mitigate these risks, they remain vulnerable to \"relearning\" during subsequent training, allowing a substantial portion of forgotten knowledge to resurface. In this paper, we show that widely used unlearning methods cause shallow alignment: instead of faithfully erasing target knowledge, they generate spurious unlearning neurons that amplify negative influence to hide it. To overcome this limitation, we introduce Ssiuu, a new class of unlearning methods that employs attribution-guided regularization to prevent spurious negative influence and faithfully remove target knowledge. Experimental results confirm that our method reliably erases target knowledge and outperforms strong baselines across two practical retraining scenarios: (1) adversarial injection of private data, and (2) benign attack using an instruction-following benchmark. Our findings highlight the necessity of robust and faithful unlearning methods for safe deployment of language models.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.149357"
    },
    {
        "index": "#61",
        "title": "A Law of Data Reconstruction for Random Features (and Beyond)",
        "link": "/arxiv/2509.22214",
        "arxiv_id": "2509.22214",
        "authors": "Leonardo Iurada, Simone Bombari, Tatiana Tommasi, Marco Mondelli",
        "summary": "Large-scale deep learning models are known to memorize parts of the training set. In machine learning theory, memorization is often framed as interpolation or label fitting, and classical results show that this can be achieved when the number of parameters $p$ in the model is larger than the number of training samples $n$. In this work, we consider memorization from the perspective of data reconstruction, demonstrating that this can be achieved when $p$ is larger than $dn$, where $d$ is the dimensionality of the data. More specifically, we show that, in the random features model, when $p \\gg dn$, the subspace spanned by the training samples in feature space gives sufficient information to identify the individual samples in input space. Our analysis suggests an optimization method to reconstruct the dataset from the model parameters, and we demonstrate that this method performs well on various architectures (random features, two-layer fully-connected and deep residual networks). Our results reveal a law of data reconstruction, according to which the entire training dataset can be recovered as $p$ exceeds the threshold $dn$.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.150917"
    },
    {
        "index": "#63",
        "title": "Kernel Regression of Multi-Way Data via Tensor Trains with Hadamard Overparametrization: The Dynamic Graph Flow Case",
        "link": "/arxiv/2509.22197",
        "arxiv_id": "2509.22197",
        "authors": "Duc Thien Nguyen, Konstantinos Slavakis, Eleftherios Kofidis, Dimitris Pados",
        "summary": "A regression-based framework for interpretable multi-way data imputation, termed Kernel Regression via Tensor Trains with Hadamard overparametrization (KReTTaH), is introduced. KReTTaH adopts a nonparametric formulation by casting imputation as regression via reproducing kernel Hilbert spaces. Parameter efficiency is achieved through tensors of fixed tensor-train (TT) rank, which reside on low-dimensional Riemannian manifolds, and is further enhanced via Hadamard overparametrization, which promotes sparsity within the TT parameter space. Learning is accomplished by solving a smooth inverse problem posed on the Riemannian manifold of fixed TT-rank tensors. As a representative application, the estimation of dynamic graph flows is considered. In this setting, KReTTaH exhibits flexibility by seamlessly incorporating graph-based (topological) priors via its inverse problem formulation. Numerical tests on real-world graph datasets demonstrate that KReTTaH consistently outperforms state-of-the-art alternatives-including a nonparametric tensor- and a neural-network-based methods-for imputing missing, time-varying edge flows.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.151520"
    },
    {
        "index": "#64",
        "title": "Mechanistic Independence: A Principle for Identifiable Disentangled Representations",
        "link": "/arxiv/2509.22196",
        "arxiv_id": "2509.22196",
        "authors": "Stefan Matthes, Zhiwei Han, Hao Shen",
        "summary": "Disentangled representations seek to recover latent factors of variation underlying observed data, yet their identifiability is still not fully understood. We introduce a unified framework in which disentanglement is achieved through mechanistic independence, which characterizes latent factors by how they act on observed variables rather than by their latent distribution. This perspective is invariant to changes of the latent density, even when such changes induce statistical dependencies among factors. Within this framework, we propose several related independence criteria -- ranging from support-based and sparsity-based to higher-order conditions -- and show that each yields identifiability of latent subspaces, even under nonlinear, non-invertible mixing. We further establish a hierarchy among these criteria and provide a graph-theoretic characterization of latent subspaces as connected components. Together, these results clarify the conditions under which disentangled representations can be identified without relying on statistical assumptions.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.151817"
    },
    {
        "index": "#69",
        "title": "Slicing Wasserstein Over Wasserstein Via Functional Optimal Transport",
        "link": "/arxiv/2509.22138",
        "arxiv_id": "2509.22138",
        "authors": "Moritz Piening, Robert Beinert",
        "summary": "Wasserstein distances define a metric between probability measures on arbitrary metric spaces, including meta-measures (measures over measures). The resulting Wasserstein over Wasserstein (WoW) distance is a powerful, but computationally costly tool for comparing datasets or distributions over images and shapes. Existing sliced WoW accelerations rely on parametric meta-measures or the existence of high-order moments, leading to numerical instability. As an alternative, we propose to leverage the isometry between the 1d Wasserstein space and the quantile functions in the function space $L_2([0,1])$. For this purpose, we introduce a general sliced Wasserstein framework for arbitrary Banach spaces. Due to the 1d Wasserstein isometry, this framework defines a sliced distance between 1d meta-measures via infinite-dimensional $L_2$-projections, parametrized by Gaussian processes. Combining this 1d construction with classical integration over the Euclidean unit sphere yields the double-sliced Wasserstein (DSW) metric for general meta-measures. We show that DSW minimization is equivalent to WoW minimization for discretized meta-measures, while avoiding unstable higher-order moments and computational savings. Numerical experiments on datasets, shapes, and images validate DSW as a scalable substitute for the WoW distance.",
        "subjects": "Machine Learning, Metric Geometry, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.153288"
    },
    {
        "index": "#70",
        "title": "Mind the Missing: Variable-Aware Representation Learning for Irregular EHR Time Series using Large Language Models",
        "link": "/arxiv/2509.22121",
        "arxiv_id": "2509.22121",
        "authors": "Jeong Eul Kwon, Joo Heung Yoon, Hyo Kyung Lee",
        "summary": "Irregular sampling and high missingness are intrinsic challenges in modeling time series derived from electronic health records (EHRs),where clinical variables are measured at uneven intervals depending on workflow and intervention timing. To address this, we propose VITAL, a variable-aware, large language model (LLM) based framework tailored for learning from irregularly sampled physiological time series. VITAL differentiates between two distinct types of clinical variables: vital signs, which are frequently recorded and exhibit temporal patterns, and laboratory tests, which are measured sporadically and lack temporal structure. It reprograms vital signs into the language space, enabling the LLM to capture temporal context and reason over missing values through explicit encoding. In contrast, laboratory variables are embedded either using representative summary values or a learnable [Not measured] token, depending on their availability. Extensive evaluations on the benchmark datasets from the PhysioNet demonstrate that VITAL outperforms state of the art methods designed for irregular time series. Furthermore, it maintains robust performance under high levels of missingness, which is prevalent in real world clinical scenarios where key variables are often unavailable.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.153559"
    },
    {
        "index": "#72",
        "title": "Countering adversarial evasion in regression analysis",
        "link": "/arxiv/2509.22113",
        "arxiv_id": "2509.22113",
        "authors": "David Benfield, Phan Tu Vuong, Alain Zemkoho",
        "summary": "Adversarial machine learning challenges the assumption that the underlying distribution remains consistent throughout the training and implementation of a prediction model. In particular, adversarial evasion considers scenarios where adversaries adapt their data to influence particular outcomes from established prediction models, such scenarios arise in applications such as spam email filtering, malware detection and fake-image generation, where security methods must be actively updated to keep up with the ever-improving generation of malicious data. Game theoretic models have been shown to be effective at modelling these scenarios and hence training resilient predictors against such adversaries. Recent advancements in the use of pessimistic bilevel optimsiation which remove assumptions about the convexity and uniqueness of the adversary's optimal strategy have proved to be particularly effective at mitigating threats to classifiers due to its ability to capture the antagonistic nature of the adversary. However, this formulation has not yet been adapted to regression scenarios. This article serves to propose a pessimistic bilevel optimisation program for regression scenarios which makes no assumptions on the convexity or uniqueness of the adversary's solutions.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.154144"
    },
    {
        "index": "#73",
        "title": "Modeling Psychological Profiles in Volleyball via Mixed-Type Bayesian Networks",
        "link": "/arxiv/2509.22111",
        "arxiv_id": "2509.22111",
        "authors": "Maria Iannario, Dae-Jin Lee, Manuele Leonelli",
        "summary": "Psychological attributes rarely operate in isolation: coaches reason about networks of related traits. We analyze a new dataset of 164 female volleyball players from Italy's C and D leagues that combines standardized psychological profiling with background information. To learn directed relationships among mixed-type variables (ordinal questionnaire scores, categorical demographics, continuous indicators), we introduce latent MMHC, a hybrid structure learner that couples a latent Gaussian copula and a constraint-based skeleton with a constrained score-based refinement to return a single DAG. We also study a bootstrap-aggregated variant for stability. In simulations spanning sample size, sparsity, and dimension, latent Max-Min Hill-Climbing (MMHC) attains lower structural Hamming distance and higher edge recall than recent copula-based learners while maintaining high specificity. Applied to volleyball, the learned network organizes mental skills around goal setting and self-confidence, with emotional arousal linking motivation and anxiety, and locates Big-Five traits (notably neuroticism and extraversion) upstream of skill clusters. Scenario analyses quantify how improvements in specific skills propagate through the network to shift preparation, confidence, and self-esteem. The approach provides an interpretable, data-driven framework for profiling psychological traits in sport and for decision support in athlete development.",
        "subjects": "Machine Learning, Applications",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.154427"
    },
    {
        "index": "#75",
        "title": "SHAKE-GNN: Scalable Hierarchical Kirchhoff-Forest Graph Neural Network",
        "link": "/arxiv/2509.22100",
        "arxiv_id": "2509.22100",
        "authors": "Zhipu Cui, Johannes Lutzeyer",
        "summary": "Graph Neural Networks (GNNs) have achieved remarkable success across a range of learning tasks. However, scaling GNNs to large graphs remains a significant challenge, especially for graph-level tasks. In this work, we introduce SHAKE-GNN, a novel scalable graph-level GNN framework based on a hierarchy of Kirchhoff Forests, a class of random spanning forests used to construct stochastic multi-resolution decompositions of graphs. SHAKE-GNN produces multi-scale representations, enabling flexible trade-offs between efficiency and performance. We introduce an improved, data-driven strategy for selecting the trade-off parameter and analyse the time-complexity of SHAKE-GNN. Experimental results on multiple large-scale graph classification benchmarks demonstrate that SHAKE-GNN achieves competitive performance while offering improved scalability.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.155007"
    },
    {
        "index": "#76",
        "title": "Non-Linear Trajectory Modeling for Multi-Step Gradient Inversion Attacks in Federated Learning",
        "link": "/arxiv/2509.22082",
        "arxiv_id": "2509.22082",
        "authors": "Li Xia, Zheng Liu, Sili Huang, Wei Tang, Xuan Liu",
        "summary": "Federated Learning (FL) preserves privacy by keeping raw data local, yet Gradient Inversion Attacks (GIAs) pose significant threats. In FedAVG multi-step scenarios, attackers observe only aggregated gradients, making data reconstruction challenging. Existing surrogate model methods like SME assume linear parameter trajectories, but we demonstrate this severely underestimates SGD's nonlinear complexity, fundamentally limiting attack effectiveness. We propose Non-Linear Surrogate Model Extension (NL-SME), the first method to introduce nonlinear parametric trajectory modeling for GIAs. Our approach replaces linear interpolation with learnable quadratic Bézier curves that capture SGD's curved characteristics through control points, combined with regularization and dvec scaling mechanisms for enhanced expressiveness. Extensive experiments on CIFAR-100 and FEMNIST datasets show NL-SME significantly outperforms baselines across all metrics, achieving order-of-magnitude improvements in cosine similarity loss while maintaining computational efficiency.This work exposes heightened privacy vulnerabilities in FL's multi-step update paradigm and offers novel perspectives for developing robust defense strategies.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.155310"
    },
    {
        "index": "#78",
        "title": "Towards Understanding Feature Learning in Parameter Transfer",
        "link": "/arxiv/2509.22056",
        "arxiv_id": "2509.22056",
        "authors": "Hua Yuan, Xuran Meng, Qiufeng Wang, Shiyu Xia, Ning Xu, Xu Yang, Jing Wang, Xin Geng, Yong Rui",
        "summary": "Parameter transfer is a central paradigm in transfer learning, enabling knowledge reuse across tasks and domains by sharing model parameters between upstream and downstream models. However, when only a subset of parameters from the upstream model is transferred to the downstream model, there remains a lack of theoretical understanding of the conditions under which such partial parameter reuse is beneficial and of the factors that govern its effectiveness. To address this gap, we analyze a setting in which both the upstream and downstream models are ReLU convolutional neural networks (CNNs). Within this theoretical framework, we characterize how the inherited parameters act as carriers of universal knowledge and identify key factors that amplify their beneficial impact on the target task. Furthermore, our analysis provides insight into why, in certain cases, transferring parameters can lead to lower test accuracy on the target task than training a new model from scratch. Numerical experiments and real-world data experiments are conducted to empirically validate our theoretical findings.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.155971"
    },
    {
        "index": "#80",
        "title": "BrainPro: Towards Large-scale Brain State-aware EEG Representation Learning",
        "link": "/arxiv/2509.22050",
        "arxiv_id": "2509.22050",
        "authors": "Yi Ding, Muyun Jiang, Weibang Jiang, Shuailei Zhang, Xinliang Zhou, Chenyu Liu, Shanglin Li, Yong Li, Cuntai Guan",
        "summary": "Electroencephalography (EEG) is a non-invasive technique for recording brain electrical activity, widely used in brain-computer interface (BCI) and healthcare. Recent EEG foundation models trained on large-scale datasets have shown improved performance and generalizability over traditional decoding methods, yet significant challenges remain. Existing models often fail to explicitly capture channel-to-channel and region-to-region interactions, which are critical sources of information inherently encoded in EEG signals. Due to varying channel configurations across datasets, they either approximate spatial structure with self-attention or restrict training to a limited set of common channels, sacrificing flexibility and effectiveness. Moreover, although EEG datasets reflect diverse brain states such as emotion, motor, and others, current models rarely learn state-aware representations during self-supervised pre-training. To address these gaps, we propose BrainPro, a large EEG model that introduces a retrieval-based spatial learning block to flexibly capture channel- and region-level interactions across varying electrode layouts, and a brain state-decoupling block that enables state-aware representation learning through parallel encoders with decoupling and region-aware reconstruction losses. This design allows BrainPro to adapt seamlessly to diverse tasks and hardware settings. Pre-trained on an extensive EEG corpus, BrainPro achieves state-of-the-art performance and robust generalization across nine public BCI datasets. Our codes and the pre-trained weights will be released.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.156595"
    },
    {
        "index": "#81",
        "title": "MO-GRPO: Mitigating Reward Hacking of Group Relative Policy Optimization on Multi-Objective Problems",
        "link": "/arxiv/2509.22047",
        "arxiv_id": "2509.22047",
        "authors": "Yuki Ichihara, Yuu Jinnai, Tetsuro Morimura, Mitsuki Sakamoto, Ryota Mitsuhashi, Eiji Uchibe",
        "summary": "Group Relative Policy Optimization (GRPO) has been shown to be an effective algorithm when an accurate reward model is available. However, such a highly reliable reward model is not available in many real-world tasks. In this paper, we particularly focus on multi-objective settings, in which we identify that GRPO is vulnerable to reward hacking, optimizing only one of the objectives at the cost of the others. To address this issue, we propose MO-GRPO, an extension of GRPO with a simple normalization method to reweight the reward functions automatically according to the variances of their values. We first show analytically that MO-GRPO ensures that all reward functions contribute evenly to the loss function while preserving the order of preferences, eliminating the need for manual tuning of the reward functions' scales. Then, we evaluate MO-GRPO experimentally in four domains: (i) the multi-armed bandits problem, (ii) simulated control task (Mo-Gymnasium), (iii) machine translation tasks on the WMT benchmark (En-Ja, En-Zh), and (iv) instruction following task. MO-GRPO achieves stable learning by evenly distributing correlations among the components of rewards, outperforming GRPO, showing MO-GRPO to be a promising algorithm for multi-objective reinforcement learning problems.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.156896"
    },
    {
        "index": "#82",
        "title": "Convexity-Driven Projection for Point Cloud Dimensionality Reduction",
        "link": "/arxiv/2509.22043",
        "arxiv_id": "2509.22043",
        "authors": "Suman Sanyal",
        "summary": "We propose Convexity-Driven Projection (CDP), a boundary-free linear method for dimensionality reduction of point clouds that targets preserving detour-induced local non-convexity. CDP builds a $k$-NN graph, identifies admissible pairs whose Euclidean-to-shortest-path ratios are below a threshold, and aggregates their normalized directions to form a positive semidefinite non-convexity structure matrix. The projection uses the top-$k$ eigenvectors of the structure matrix. We give two verifiable guarantees. A pairwise a-posteriori certificate that bounds the post-projection distortion for each admissible pair, and an average-case spectral bound that links expected captured direction energy to the spectrum of the structure matrix, yielding quantile statements for typical distortion. Our evaluation protocol reports fixed- and reselected-pairs detour errors and certificate quantiles, enabling practitioners to check guarantees on their data.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.157157"
    },
    {
        "index": "#84",
        "title": "OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features",
        "link": "/arxiv/2509.22033",
        "arxiv_id": "2509.22033",
        "authors": "Anton Korznikov, Andrey Galichin, Alexey Dontsov, Oleg Rogov, Elena Tutubalina, Ivan Oseledets",
        "summary": "Sparse autoencoders (SAEs) are a technique for sparse decomposition of neural network activations into human-interpretable features. However, current SAEs suffer from feature absorption, where specialized features capture instances of general features creating representation holes, and feature composition, where independent features merge into composite representations. In this work, we introduce Orthogonal SAE (OrtSAE), a novel approach aimed to mitigate these issues by enforcing orthogonality between the learned features. By implementing a new training procedure that penalizes high pairwise cosine similarity between SAE features, OrtSAE promotes the development of disentangled features while scaling linearly with the SAE size, avoiding significant computational overhead. We train OrtSAE across different models and layers and compare it with other methods. We find that OrtSAE discovers 9% more distinct features, reduces feature absorption (by 65%) and composition (by 15%), improves performance on spurious correlation removal (+6%), and achieves on-par performance for other downstream tasks compared to traditional SAEs.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.157736"
    },
    {
        "index": "#85",
        "title": "MCGM: Multi-stage Clustered Global Modeling for Long-range Interactions in Molecules",
        "link": "/arxiv/2509.22028",
        "arxiv_id": "2509.22028",
        "authors": "Haodong Pan, Yusong Wang, Nanning Zheng, Caijui Jiang",
        "summary": "Geometric graph neural networks (GNNs) excel at capturing molecular geometry, yet their locality-biased message passing hampers the modeling of long-range interactions. Current solutions have fundamental limitations: extending cutoff radii causes computational costs to scale cubically with distance; physics-inspired kernels (e.g., Coulomb, dispersion) are often system-specific and lack generality; Fourier-space methods require careful tuning of multiple parameters (e.g., mesh size, k-space cutoff) with added computational overhead. We introduce Multi-stage Clustered Global Modeling (MCGM), a lightweight, plug-and-play module that endows geometric GNNs with hierarchical global context through efficient clustering operations. MCGM builds a multi-resolution hierarchy of atomic clusters, distills global information via dynamic hierarchical clustering, and propagates this context back through learned transformations, ultimately reinforcing atomic features via residual connections. Seamlessly integrated into four diverse backbone architectures, MCGM reduces OE62 energy prediction error by an average of 26.2%. On AQM, MCGM achieves state-of-the-art accuracy (17.0 meV for energy, 4.9 meV/Å for forces) while using 20% fewer parameters than Neural P3M. Code will be made available upon acceptance.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.158016"
    },
    {
        "index": "#86",
        "title": "Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error",
        "link": "/arxiv/2509.22023",
        "arxiv_id": "2509.22023",
        "authors": "Panagiotis Giannoulis, Yorgos Pantis, Christos Tzamos",
        "summary": "Despite their proficiency in various language tasks, Large Language Models (LLMs) struggle with combinatorial problems like Satisfiability, Traveling Salesman Problem, or even basic arithmetic. We address this gap through a novel approach for solving problems in the class NP. We focus on the paradigmatic task of Sudoku and achieve state-of-the-art accuracy (99\\%) compared to prior neuro-symbolic approaches. Unlike prior work that used custom architectures, our method employs a vanilla decoder-only Transformer (GPT-2) without external tools or function calling. Our method integrates imitation learning of simple Sudoku rules with an explicit Depth-First Search (DFS) exploration strategy involving informed guessing and backtracking. Moving beyond imitation learning, we seek to minimize the number of guesses until reaching a solution. We provide a rigorous analysis of this setup formalizing its connection to a contextual variant of Min-Sum Set Cover, a well-studied problem in algorithms and stochastic optimization.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.158286"
    },
    {
        "index": "#87",
        "title": "Task-Adaptive Parameter-Efficient Fine-Tuning for Weather Foundation Models",
        "link": "/arxiv/2509.22020",
        "arxiv_id": "2509.22020",
        "authors": "Shilei Cao, Hehai Lin, Jiashun Cheng, Yang Liu, Guowen Li, Xuehe Wang, Juepeng Zheng, Haoyuan Liang, Meng Jin, Chengwei Qin, Hong Cheng, Haohuan Fu",
        "summary": "While recent advances in machine learning have equipped Weather Foundation Models (WFMs) with substantial generalization capabilities across diverse downstream tasks, the escalating computational requirements associated with their expanding scale increasingly hinder practical deployment. Current Parameter-Efficient Fine-Tuning (PEFT) methods, designed for vision or language tasks, fail to address the unique challenges of weather downstream tasks, such as variable heterogeneity, resolution diversity, and spatiotemporal coverage variations, leading to suboptimal performance when applied to WFMs. To bridge this gap, we introduce WeatherPEFT, a novel PEFT framework for WFMs incorporating two synergistic innovations. First, during the forward pass, Task-Adaptive Dynamic Prompting (TADP) dynamically injects the embedding weights within the encoder to the input tokens of the pre-trained backbone via internal and external pattern extraction, enabling context-aware feature recalibration for specific downstream tasks. Furthermore, during backpropagation, Stochastic Fisher-Guided Adaptive Selection (SFAS) not only leverages Fisher information to identify and update the most task-critical parameters, thereby preserving invariant pre-trained knowledge, but also introduces randomness to stabilize the selection. We demonstrate the effectiveness and efficiency of WeatherPEFT on three downstream tasks, where existing PEFT methods show significant gaps versus Full-Tuning, and WeatherPEFT achieves performance parity with Full-Tuning using fewer trainable parameters. The code of this work will be released.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.158638"
    },
    {
        "index": "#88",
        "title": "AEGIS: Authentic Edge Growth In Sparsity for Link Prediction in Edge-Sparse Bipartite Knowledge Graphs",
        "link": "/arxiv/2509.22017",
        "arxiv_id": "2509.22017",
        "authors": "Hugh Xuechen Liu, Kıvanç Tatar",
        "summary": "Bipartite knowledge graphs in niche domains are typically data-poor and edge-sparse, which hinders link prediction. We introduce AEGIS (Authentic Edge Growth In Sparsity), an edge-only augmentation framework that resamples existing training edges -either uniformly simple or with inverse-degree bias degree-aware -thereby preserving the original node set and sidestepping fabricated endpoints. To probe authenticity across regimes, we consider naturally sparse graphs (game design pattern's game-pattern network) and induce sparsity in denser benchmarks (Amazon, MovieLens) via high-rate bond percolation. We evaluate augmentations on two complementary metrics: AUC-ROC (higher is better) and the Brier score (lower is better), using two-tailed paired t-tests against sparse baselines. On Amazon and MovieLens, copy-based AEGIS variants match the baseline while the semantic KNN augmentation is the only method that restores AUC and calibration; random and synthetic edges remain detrimental. On the text-rich GDP graph, semantic KNN achieves the largest AUC improvement and Brier score reduction, and simple also lowers the Brier score relative to the sparse control. These findings position authenticity-constrained resampling as a data-efficient strategy for sparse bipartite link prediction, with semantic augmentation providing an additional boost when informative node descriptions are available.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.158902"
    },
    {
        "index": "#89",
        "title": "Concept-SAE: Active Causal Probing of Visual Model Behavior",
        "link": "/arxiv/2509.22015",
        "arxiv_id": "2509.22015",
        "authors": "Jianrong Ding, Muxi Chen, Chenchen Zhao, Qiang Xu",
        "summary": "Standard Sparse Autoencoders (SAEs) excel at discovering a dictionary of a model's learned features, offering a powerful observational lens. However, the ambiguous and ungrounded nature of these features makes them unreliable instruments for the active, causal probing of model behavior. To solve this, we introduce Concept-SAE, a framework that forges semantically grounded concept tokens through a novel hybrid disentanglement strategy. We first quantitatively demonstrate that our dual-supervision approach produces tokens that are remarkably faithful and spatially localized, outperforming alternative methods in disentanglement. This validated fidelity enables two critical applications: (1) we probe the causal link between internal concepts and predictions via direct intervention, and (2) we probe the model's failure modes by systematically localizing adversarial vulnerabilities to specific layers. Concept-SAE provides a validated blueprint for moving beyond correlational interpretation to the mechanistic, causal probing of model behavior.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.159190"
    },
    {
        "index": "#90",
        "title": "Goal-Guided Efficient Exploration via Large Language Model in Reinforcement Learning",
        "link": "/arxiv/2509.22008",
        "arxiv_id": "2509.22008",
        "authors": "Yajie Qi, Wei Wei, Lin Li, Lijun Zhang, Zhidong Gao, Da Wang, Huizhong Song",
        "summary": "Real-world decision-making tasks typically occur in complex and open environments, posing significant challenges to reinforcement learning (RL) agents' exploration efficiency and long-horizon planning capabilities. A promising approach is LLM-enhanced RL, which leverages the rich prior knowledge and strong planning capabilities of LLMs to guide RL agents in efficient exploration. However, existing methods mostly rely on frequent and costly LLM invocations and suffer from limited performance due to the semantic mismatch. In this paper, we introduce a Structured Goal-guided Reinforcement Learning (SGRL) method that integrates a structured goal planner and a goal-conditioned action pruner to guide RL agents toward efficient exploration. Specifically, the structured goal planner utilizes LLMs to generate a reusable, structured function for goal generation, in which goals are prioritized. Furthermore, by utilizing LLMs to determine goals' priority weights, it dynamically generates forward-looking goals to guide the agent's policy toward more promising decision-making trajectories. The goal-conditioned action pruner employs an action masking mechanism that filters out actions misaligned with the current goal, thereby constraining the RL agent to select goal-consistent policies. We evaluate the proposed method on Crafter and Craftax-Classic, and experimental results demonstrate that SGRL achieves superior performance compared to existing state-of-the-art methods.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.159493"
    },
    {
        "index": "#91",
        "title": "Stage-wise Dynamics of Classifier-Free Guidance in Diffusion Models",
        "link": "/arxiv/2509.22007",
        "arxiv_id": "2509.22007",
        "authors": "Cheng Jin, Qitan Shi, Yuantao Gu",
        "summary": "Classifier-Free Guidance (CFG) is widely used to improve conditional fidelity in diffusion models, but its impact on sampling dynamics remains poorly understood. Prior studies, often restricted to unimodal conditional distributions or simplified cases, provide only a partial picture. We analyze CFG under multimodal conditionals and show that the sampling process unfolds in three successive stages. In the Direction Shift stage, guidance accelerates movement toward the weighted mean, introducing initialization bias and norm growth. In the Mode Separation stage, local dynamics remain largely neutral, but the inherited bias suppresses weaker modes, reducing global diversity. In the Concentration stage, guidance amplifies within-mode contraction, diminishing fine-grained variability. This unified view explains a widely observed phenomenon: stronger guidance improves semantic alignment but inevitably reduces diversity. Experiments support these predictions, showing that early strong guidance erodes global diversity, while late strong guidance suppresses fine-grained variation. Moreover, our theory naturally suggests a time-varying guidance schedule, and empirical results confirm that it consistently improves both quality and diversity.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.159784"
    },
    {
        "index": "#92",
        "title": "GRAM-TDI: adaptive multimodal representation learning for drug target interaction prediction",
        "link": "/arxiv/2509.21971",
        "arxiv_id": "2509.21971",
        "authors": "Feng Jiang, Amina Mollaysa, Hehuan Ma, Tommaso Mansi, Junzhou Huang, Mangal Prakash, Rui Liao",
        "summary": "Drug target interaction (DTI) prediction is a cornerstone of computational drug discovery, enabling rational design, repurposing, and mechanistic insights. While deep learning has advanced DTI modeling, existing approaches primarily rely on SMILES protein pairs and fail to exploit the rich multimodal information available for small molecules and proteins. We introduce GRAMDTI, a pretraining framework that integrates multimodal molecular and protein inputs into unified representations. GRAMDTI extends volume based contrastive learning to four modalities, capturing higher-order semantic alignment beyond conventional pairwise approaches. To handle modality informativeness, we propose adaptive modality dropout, dynamically regulating each modality's contribution during pre-training. Additionally, IC50 activity measurements, when available, are incorporated as weak supervision to ground representations in biologically meaningful interaction strengths. Experiments on four publicly available datasets demonstrate that GRAMDTI consistently outperforms state of the art baselines. Our results highlight the benefits of higher order multimodal alignment, adaptive modality utilization, and auxiliary supervision for robust and generalizable DTI prediction.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.160100"
    },
    {
        "index": "#93",
        "title": "Think Smart, Not Hard: Difficulty Adaptive Reasoning for Large Audio Language Models",
        "link": "/arxiv/2509.21960",
        "arxiv_id": "2509.21960",
        "authors": "Zhichao Sheng, Shilin Zhou, Chen Gong, Zhenghua Li",
        "summary": "Large Audio Language Models (LALMs), powered by the chain-of-thought (CoT) paradigm, have shown remarkable reasoning capabilities. Intuitively, different problems often require varying depths of reasoning. While some methods can determine whether to reason for a given problem, they typically lack a fine-grained mechanism to modulate how much to reason. This often results in a ``one-size-fits-all'' reasoning depth, which generates redundant overthinking for simple questions while failing to allocate sufficient thought to complex ones. In this paper, we conduct an in-depth analysis of LALMs and find that an effective and efficient LALM should reason smartly by adapting its reasoning depth to the problem's complexity. To achieve this, we propose a difficulty-adaptive reasoning method for LALMs. Specifically, we propose a reward function that dynamically links reasoning length to the model's perceived problem difficulty. This reward encourages shorter, concise reasoning for easy tasks and more elaborate, in-depth reasoning for complex ones. Extensive experiments demonstrate that our method is both effective and efficient, simultaneously improving task performance and significantly reducing the average reasoning length. Further analysis on reasoning structure paradigm offers valuable insights for future work.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.160380"
    },
    {
        "index": "#95",
        "title": "Structural Information-based Hierarchical Diffusion for Offline Reinforcement Learning",
        "link": "/arxiv/2509.21942",
        "arxiv_id": "2509.21942",
        "authors": "Xianghua Zeng, Hao Peng, Angsheng Li, Yicheng Pan",
        "summary": "Diffusion-based generative methods have shown promising potential for modeling trajectories from offline reinforcement learning (RL) datasets, and hierarchical diffusion has been introduced to mitigate variance accumulation and computational challenges in long-horizon planning tasks. However, existing approaches typically assume a fixed two-layer diffusion hierarchy with a single predefined temporal scale, which limits adaptability to diverse downstream tasks and reduces flexibility in decision making. In this work, we propose SIHD, a novel Structural Information-based Hierarchical Diffusion framework for effective and stable offline policy learning in long-horizon environments with sparse rewards. Specifically, we analyze structural information embedded in offline trajectories to construct the diffusion hierarchy adaptively, enabling flexible trajectory modeling across multiple temporal scales. Rather than relying on reward predictions from localized sub-trajectories, we quantify the structural information gain of each state community and use it as a conditioning signal within the corresponding diffusion layer. To reduce overreliance on offline datasets, we introduce a structural entropy regularizer that encourages exploration of underrepresented states while avoiding extrapolation errors from distributional shifts. Extensive evaluations on challenging offline RL tasks show that SIHD significantly outperforms state-of-the-art baselines in decision-making performance and demonstrates superior generalization across diverse scenarios.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.160977"
    },
    {
        "index": "#96",
        "title": "Statistical Advantage of Softmax Attention: Insights from Single-Location Regression",
        "link": "/arxiv/2509.21936",
        "arxiv_id": "2509.21936",
        "authors": "O. Duranthon, P. Marion, C. Boyer, B. Loureiro, L. Zdeborová",
        "summary": "Large language models rely on attention mechanisms with a softmax activation. Yet the dominance of softmax over alternatives (e.g., component-wise or linear) remains poorly understood, and many theoretical works have focused on the easier-to-analyze linearized attention. In this work, we address this gap through a principled study of the single-location regression task, where the output depends on a linear transformation of a single input token at a random location. Building on ideas from statistical physics, we develop an analysis of attention-based predictors in the high-dimensional limit, where generalization performance is captured by a small set of order parameters. At the population level, we show that softmax achieves the Bayes risk, whereas linear attention fundamentally falls short. We then examine other activation functions to identify which properties are necessary for optimal performance. Finally, we analyze the finite-sample regime: we provide an asymptotic characterization of the test error and show that, while softmax is no longer Bayes-optimal, it consistently outperforms linear attention. We discuss the connection with optimization by gradient-based algorithms.",
        "subjects": "Machine Learning, Disordered Systems and Neural Networks",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.161280"
    },
    {
        "index": "#97",
        "title": "Extracting Actionable Insights from Building Energy Data using Vision LLMs on Wavelet and 3D Recurrence Representations",
        "link": "/arxiv/2509.21934",
        "arxiv_id": "2509.21934",
        "authors": "Amine Bechar, Adel Oulefki, Abbes Amira, Fatih Kurogollu, Yassine Himeur",
        "summary": "The analysis of complex building time-series for actionable insights and recommendations remains challenging due to the nonlinear and multi-scale characteristics of energy data. To address this, we propose a framework that fine-tunes visual language large models (VLLMs) on 3D graphical representations of the data. The approach converts 1D time-series into 3D representations using continuous wavelet transforms (CWTs) and recurrence plots (RPs), which capture temporal dynamics and localize frequency anomalies. These 3D encodings enable VLLMs to visually interpret energy-consumption patterns, detect anomalies, and provide recommendations for energy efficiency. We demonstrate the framework on real-world building-energy datasets, where fine-tuned VLLMs successfully monitor building states, identify recurring anomalies, and generate optimization recommendations. Quantitatively, the Idefics-7B VLLM achieves validation losses of 0.0952 with CWTs and 0.1064 with RPs on the University of Sharjah energy dataset, outperforming direct fine-tuning on raw time-series data (0.1176) for anomaly detection. This work bridges time-series analysis and visualization, providing a scalable and interpretable framework for energy analytics.",
        "subjects": "Machine Learning, Computers and Society",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.161581"
    },
    {
        "index": "#99",
        "title": "Multiplicative-Additive Constrained Models:Toward Joint Visualization of Interactive and Independent Effects",
        "link": "/arxiv/2509.21923",
        "arxiv_id": "2509.21923",
        "authors": "Fumin Wang",
        "summary": "Interpretability is one of the considerations when applying machine learning to high-stakes fields such as healthcare that involve matters of life safety. Generalized Additive Models (GAMs) enhance interpretability by visualizing shape functions. Nevertheless, to preserve interpretability, GAMs omit higher-order interaction effects (beyond pairwise interactions), which imposes significant constraints on their predictive performance. We observe that Curve Ergodic Set Regression (CESR), a multiplicative model, naturally enables the visualization of its shape functions and simultaneously incorporates both interactions among all features and individual feature effects. Nevertheless, CESR fails to demonstrate superior performance compared to GAMs. We introduce Multiplicative-Additive Constrained Models (MACMs), which augment CESR with an additive part to disentangle the intertwined coefficients of its interactive and independent terms, thus effectively broadening the hypothesis space. The model is composed of a multiplicative part and an additive part, whose shape functions can both be naturally visualized, thereby assisting users in interpreting how features participate in the decision-making process. Consequently, MACMs constitute an improvement over both CESR and GAMs. The experimental results indicate that neural network-based MACMs significantly outperform both CESR and the current state-of-the-art GAMs in terms of predictive performance.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.162120"
    },
    {
        "index": "#100",
        "title": "Discrete Guidance Matching: Exact Guidance for Discrete Flow Matching",
        "link": "/arxiv/2509.21912",
        "arxiv_id": "2509.21912",
        "authors": "Zhengyan Wan, Yidong Ouyang, Liyan Xie, Fang Fang, Hongyuan Zha, Guang Cheng",
        "summary": "Guidance provides a simple and effective framework for posterior sampling by steering the generation process towards the desired distribution. When modeling discrete data, existing approaches mostly focus on guidance with the first-order Taylor approximation to improve the sampling efficiency. However, such an approximation is inappropriate in discrete state spaces since the approximation error could be large. A novel guidance framework for discrete data is proposed to address this problem: We derive the exact transition rate for the desired distribution given a learned discrete flow matching model, leading to guidance that only requires a single forward pass in each sampling step, significantly improving efficiency. This unified novel framework is general enough, encompassing existing guidance methods as special cases, and it can also be seamlessly applied to the masked diffusion model. We demonstrate the effectiveness of our proposed guidance on energy-guided simulations and preference alignment on text-to-image generation and multimodal understanding tasks. The code is available through https://github.com/WanZhengyan/Discrete-Guidance-Matching/tree/main.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.162423"
    },
    {
        "index": "#102",
        "title": "Why High-rank Neural Networks Generalize?: An Algebraic Framework with RKHSs",
        "link": "/arxiv/2509.21895",
        "arxiv_id": "2509.21895",
        "authors": "Yuka Hashimoto, Sho Sonoda, Isao Ishikawa, Masahiro Ikeda",
        "summary": "We derive a new Rademacher complexity bound for deep neural networks using Koopman operators, group representations, and reproducing kernel Hilbert spaces (RKHSs). The proposed bound describes why the models with high-rank weight matrices generalize well. Although there are existing bounds that attempt to describe this phenomenon, these existing bounds can be applied to limited types of models. We introduce an algebraic representation of neural networks and a kernel function to construct an RKHS to derive a bound for a wider range of realistic models. This work paves the way for the Koopman-based theory for Rademacher complexity bounds to be valid for more practical situations.",
        "subjects": "Machine Learning, Functional Analysis, Representation Theory, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.163061"
    },
    {
        "index": "#104",
        "title": "Zubov-Net: Adaptive Stability for Neural ODEs Reconciling Accuracy with Robustness",
        "link": "/arxiv/2509.21879",
        "arxiv_id": "2509.21879",
        "authors": "Chaoyang Luo, Yan Zou, Nanjing Huang",
        "summary": "Despite neural ordinary differential equations (Neural ODEs) exhibiting intrinsic robustness under input perturbations due to their dynamical systems nature, recent approaches often involve imposing Lyapunov-based stability conditions to provide formal robustness guarantees. However, a fundamental challenge remains: the tension between robustness and accuracy, primarily stemming from the difficulty in imposing appropriate stability conditions. To address this, we propose an adaptive stable learning framework named Zubov-Net, which innovatively reformulates Zubov's equation into a consistency characterization between regions of attraction (RoAs) and prescribed RoAs (PRoAs). Building on this consistency, we introduce a new paradigm for actively controlling the geometry of RoAs by directly optimizing PRoAs to reconcile accuracy and robustness. Our approach is realized through tripartite losses (consistency, classification, and separation losses) and a parallel boundary sampling algorithm that co-optimizes the Neural ODE and the Lyapunov function. To enhance the discriminativity of Lyapunov functions, we design an input-attention-based convex neural network via a softmax attention mechanism that focuses on equilibrium-relevant features and also serves as weight normalization to maintain training stability in deep architectures. Theoretically, we prove that minimizing the tripartite loss guarantees consistent alignment of PRoAs-RoAs, trajectory stability, and non-overlapping PRoAs. Moreover, we establish stochastic convex separability with tighter probability bounds and fewer dimensionality requirements to justify the convex design in Lyapunov functions. Experimentally, Zubov-Net maintains high classification accuracy while significantly improving robustness against various stochastic noises and adversarial attacks.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.163856"
    },
    {
        "index": "#105",
        "title": "Abductive Logical Rule Induction by Bridging Inductive Logic Programming and Multimodal Large Language Models",
        "link": "/arxiv/2509.21874",
        "arxiv_id": "2509.21874",
        "authors": "Yifei Peng, Yaoli Liu, Enbo Xia, Yu Jin, Wang-Zhou Dai, Zhong Ren, Yao-Xiang Ding, Kun Zhou",
        "summary": "We propose ILP-CoT, a method that bridges Inductive Logic Programming (ILP) and Multimodal Large Language Models (MLLMs) for abductive logical rule induction. The task involves both discovering logical facts and inducing logical rules from a small number of unstructured textual or visual inputs, which still remain challenging when solely relying on ILP, due to the requirement of specified background knowledge and high computational cost, or MLLMs, due to the appearance of perceptual hallucinations. Based on the key observation that MLLMs could propose structure-correct rules even under hallucinations, our approach automatically builds ILP tasks with pruned search spaces based on the rule structure proposals from MLLMs, and utilizes ILP system to output rules built upon rectified logical facts and formal inductive reasoning. Its effectiveness is verified through challenging logical induction benchmarks, as well as a potential application of our approach, namely text-to-image customized generation with rule induction. Our code and data are released at https://github.com/future-item/ILP-CoT.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.164176"
    },
    {
        "index": "#106",
        "title": "Beyond RAG vs. Long-Context: Learning Distraction-Aware Retrieval for Efficient Knowledge Grounding",
        "link": "/arxiv/2509.21865",
        "arxiv_id": "2509.21865",
        "authors": "Seong-Woong Shim, Myunsoo Kim, Jae Hyeon Cho, Byung-Jun Lee",
        "summary": "Retrieval-Augmented Generation (RAG) is a framework for grounding Large Language Models (LLMs) in external, up-to-date information. However, recent advancements in context window size allow LLMs to process inputs of up to 128K tokens or more, offering an alternative strategy: supplying the full document context directly to the model, rather than relying on RAG to retrieve a subset of contexts. Nevertheless, this emerging alternative strategy has notable limitations: (i) it is token-inefficient to handle large and potentially redundant contexts; (ii) it exacerbates the `lost in the middle' phenomenon; and (iii) under limited model capacity, it amplifies distraction, ultimately degrading LLM output quality. In this paper, we propose LDAR (Learning Distraction-Aware Retrieval), an adaptive retriever that learns to retrieve contexts in a way that mitigates interference from distracting passages, thereby achieving significantly higher performance with reduced token usage compared to long-context approaches. Extensive experiments across diverse LLM architectures and six knowledge-intensive benchmarks demonstrate the effectiveness and robustness of our approach, highlighting the importance of balancing the trade-off between information coverage and distraction.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.164459"
    },
    {
        "index": "#107",
        "title": "MolSpectLLM: A Molecular Foundation Model Bridging Spectroscopy, Molecule Elucidation, and 3D Structure Generation",
        "link": "/arxiv/2509.21861",
        "arxiv_id": "2509.21861",
        "authors": "Shuaike Shen, Jiaqing Xie, Zhuo Yang, Antong Zhang, Shuzhou Sun, Ben Gao, Tianfan Fu, Biqing Qi, Yuqiang Li",
        "summary": "Recent advances in molecular foundation models have shown impressive performance in molecular property prediction and de novo molecular design, with promising applications in areas such as drug discovery and reaction prediction. Nevertheless, most existing approaches rely exclusively on SMILES representations and overlook both experimental spectra and 3D structural information-two indispensable sources for capturing molecular behavior in real-world scenarios. This limitation reduces their effectiveness in tasks where stereochemistry, spatial conformation, and experimental validation are critical. To overcome these challenges, we propose MolSpectLLM, a molecular foundation model pretrained on Qwen2.5-7B that unifies experimental spectroscopy with molecular 3D structure. By explicitly modeling molecular spectra, MolSpectLLM achieves state-of-the-art performance on spectrum-related tasks, with an average accuracy of 0.53 across NMR, IR, and MS benchmarks. MolSpectLLM also shows strong performance on the spectra analysis task, obtaining 15.5% sequence accuracy and 41.7% token accuracy on Spectra-to-SMILES, substantially outperforming large general-purpose LLMs. More importantly, MolSpectLLM not only achieves strong performance on molecular elucidation tasks, but also generates accurate 3D molecular structures directly from SMILES or spectral inputs, bridging spectral analysis, molecular elucidation, and molecular design.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.164789"
    },
    {
        "index": "#110",
        "title": "On the Complexity Theory of Masked Discrete Diffusion: From $\\mathrm{poly}(1/ε)$ to Nearly $ε$-Free",
        "link": "/arxiv/2509.21835",
        "arxiv_id": "2509.21835",
        "authors": "Xunpeng Huang, Yingyu Lin, Nishant Jain, Kaibo Wang, Difan Zou, Yian Ma, Tong Zhang",
        "summary": "We study masked discrete diffusion -- a flexible paradigm for text generation in which tokens are progressively corrupted by special mask symbols before being denoised. Although this approach has demonstrated strong empirical performance, its theoretical complexity in high-dimensional settings remains insufficiently understood. Existing analyses largely focus on uniform discrete diffusion, and more recent attempts addressing masked diffusion either (1) overlook widely used Euler samplers, (2) impose restrictive bounded-score assumptions, or (3) fail to showcase the advantages of masked discrete diffusion over its uniform counterpart. To address this gap, we show that Euler samplers can achieve $\\epsilon$-accuracy in total variation (TV) with $\\tilde{O}(d^{2}\\epsilon^{-3/2})$ discrete score evaluations, thereby providing the first rigorous analysis of typical Euler sampler in masked discrete diffusion. We then propose a Mask-Aware Truncated Uniformization (MATU) approach that both removes bounded-score assumptions and preserves unbiased discrete score approximation. By exploiting the property that each token can be unmasked at most once, MATU attains a nearly $\\epsilon$-free complexity of $O(d\\,\\ln d\\cdot (1-\\epsilon^2))$. This result surpasses existing uniformization methods under uniform discrete diffusion, eliminating the $\\ln(1/\\epsilon)$ factor and substantially speeding up convergence. Our findings not only provide a rigorous theoretical foundation for masked discrete diffusion, showcasing its practical advantages over uniform diffusion for text generation, but also pave the way for future efforts to analyze diffusion-based language models developed under masking paradigm.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.165742"
    },
    {
        "index": "#112",
        "title": "Sharpness-Aware Minimization Can Hallucinate Minimizers",
        "link": "/arxiv/2509.21818",
        "arxiv_id": "2509.21818",
        "authors": "Chanwoong Park, Uijeong Jang, Ernest K. Ryu, Insoon Yang",
        "summary": "Sharpness-Aware Minimization (SAM) is a widely used method that steers training toward flatter minimizers, which typically generalize better. In this work, however, we show that SAM can converge to hallucinated minimizers -- points that are not minimizers of the original objective. We theoretically prove the existence of such hallucinated minimizers and establish conditions for local convergence to them. We further provide empirical evidence demonstrating that SAM can indeed converge to these points in practice. Finally, we propose a simple yet effective remedy for avoiding hallucinated minimizers.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.166322"
    },
    {
        "index": "#113",
        "title": "Scaling Laws for Neural Material Models",
        "link": "/arxiv/2509.21811",
        "arxiv_id": "2509.21811",
        "authors": "Akshay Trikha, Kyle Chu, Advait Gosai, Parker Szachta, Eric Weiner",
        "summary": "Predicting material properties is crucial for designing better batteries, semiconductors, and medical devices. Deep learning helps scientists quickly find promising materials by predicting their energy, forces, and stresses. Companies scale capacities of deep learning models in multiple domains, such as language modeling, and invest many millions of dollars into such models. Our team analyzes how scaling training data (giving models more information to learn from), model sizes (giving models more capacity to learn patterns), and compute (giving models more computational resources) for neural networks affects their performance for material property prediction. In particular, we trained both transformer and EquiformerV2 neural networks to predict material properties. We find empirical scaling laws for these models: we can predict how increasing each of the three hyperparameters (training data, model size, and compute) affects predictive performance. In particular, the loss $L$ can be measured with a power law relationship $L = \\alpha \\cdot N^{-\\beta}$, where $\\alpha$ and $\\beta$ are constants while $N$ is the relevant hyperparameter. We also incorporate command-line arguments for changing training settings such as the amount of epochs, maximum learning rate, and whether mixed precision is enabled. Future work could entail further investigating scaling laws for other neural network models in this domain, such as GemNet and fully connected networks, to assess how they compare to the models we trained.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.166618"
    },
    {
        "index": "#115",
        "title": "Exploring the Relationships Between Physiological Signals During Automated Fatigue Detection",
        "link": "/arxiv/2509.21794",
        "arxiv_id": "2509.21794",
        "authors": "Kourosh Kakhi, Abbas Khosravi, Roohallah Alizadehsani, U. Rajendra Acharyab",
        "summary": "Fatigue detection using physiological signals is critical in domains such as transportation, healthcare, and performance monitoring. While most studies focus on single modalities, this work examines statistical relationships between signal pairs to improve classification robustness. Using the DROZY dataset, we extracted features from ECG, EMG, EOG, and EEG across 15 signal combinations and evaluated them with Decision Tree, Random Forest, Logistic Regression, and XGBoost. Results show that XGBoost with the EMG EEG combination achieved the best performance. SHAP analysis highlighted ECG EOG correlation as a key feature, and multi signal models consistently outperformed single signal ones. These findings demonstrate that feature level fusion of physiological signals enhances accuracy, interpretability, and practical applicability of fatigue monitoring systems.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.167203"
    },
    {
        "index": "#117",
        "title": "Beyond Formula Complexity: Effective Information Criterion Improves Performance and Interpretability for Symbolic Regression",
        "link": "/arxiv/2509.21780",
        "arxiv_id": "2509.21780",
        "authors": "Zihan Yu, Guanren Wang, Jingtao Ding, Huandong Wang, Yong Li",
        "summary": "Symbolic regression discovers accurate and interpretable formulas to describe given data, thereby providing scientific insights for domain experts and promoting scientific discovery. However, existing symbolic regression methods often use complexity metrics as a proxy for interoperability, which only considers the size of the formula but ignores its internal mathematical structure. Therefore, while they can discover formulas with compact forms, the discovered formulas often have structures that are difficult to analyze or interpret mathematically. In this work, inspired by the observation that physical formulas are typically numerically stable under limited calculation precision, we propose the Effective Information Criterion (EIC). It treats formulas as information processing systems with specific internal structures and identifies the unreasonable structure in them by the loss of significant digits or the amplification of rounding noise as data flows through the system. We find that this criterion reveals the gap between the structural rationality of models discovered by existing symbolic regression algorithms and real-world physical formulas. Combining EIC with various search-based symbolic regression algorithms improves their performance on the Pareto frontier and reduces the irrational structure in the results. Combining EIC with generative-based algorithms reduces the number of samples required for pre-training, improving sample efficiency by 2~4 times. Finally, for different formulas with similar accuracy and complexity, EIC shows a 70.2% agreement with 108 human experts' preferences for formula interpretability, demonstrating that EIC, by measuring the unreasonable structures in formulas, actually reflects the formula's interpretability.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.167798"
    },
    {
        "index": "#118",
        "title": "Machine Learning and AI Applied to fNIRS Data Reveals Novel Brain Activity Biomarkers in Stable Subclinical Multiple Sclerosis",
        "link": "/arxiv/2509.21770",
        "arxiv_id": "2509.21770",
        "authors": "Sadman Saumik Islam, Bruna Dalcin Baldasso, Davide Cattaneo, Xianta Jiang, Michelle Ploughman",
        "summary": "People with Multiple Sclerosis (MS) complain of problems with hand dexterity and cognitive fatigue. However, in many cases, impairments are subtle and difficult to detect. Functional near-infrared spectroscopy (fNIRS) is a non-invasive neuroimaging technique that measures brain hemodynamic responses during cognitive or motor tasks. We aimed to detect brain activity biomarkers that could explain subjective reports of cognitive fatigue while completing dexterous tasks and provide targets for future brain stimulation treatments. We recruited 15 people with MS who did not have a hand (Nine Hole Peg Test [NHPT]), mobility, or cognitive impairment, and 12 age- and sex-matched controls. Participants completed two types of hand dexterity tasks with their dominant hand, single task and dual task (NHPT while holding a ball between the fifth finger and hypothenar eminence of the same hand). We analyzed fNIRS data (oxygenated and deoxygenated hemoglobin levels) using a machine learning framework to classify MS patients from controls based on their brain activation patterns in bilateral prefrontal and sensorimotor cortices. The K-Nearest Neighbor classifier achieved an accuracy of 75.0% for single manual dexterity tasks and 66.7% for the more complex dual manual dexterity tasks. Using XAI, we found that the most important brain regions contributing to the machine learning model were the supramarginal/angular gyri and the precentral gyrus (sensory integration and motor regions) of the ipsilateral hemisphere, with suppressed activity and slower neurovascular response in the MS group. During both tasks, deoxygenated hemoglobin levels were better predictors than the conventional measure of oxygenated hemoglobin. This nonconventional method of fNIRS data analysis revealed novel brain activity biomarkers that can help develop personalized brain stimulation targets.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.168093"
    },
    {
        "index": "#119",
        "title": "Reparameterizing 4DVAR with neural fields",
        "link": "/arxiv/2509.21751",
        "arxiv_id": "2509.21751",
        "authors": "Jaemin Oh",
        "summary": "Four-dimensional variational data assimilation (4DVAR) is a cornerstone of numerical weather prediction, but its cost function is difficult to optimize and computationally intensive. We propose a neural field-based reformulation in which the full spatiotemporal state is represented as a continuous function parameterized by a neural network. This reparameterization removes the time-sequential dependency of classical 4DVAR, enabling parallel-in-time optimization in parameter space. Physical constraints are incorporated directly through a physics-informed loss, simplifying implementation and reducing computational cost. We evaluate the method on the two-dimensional incompressible Navier--Stokes equations with Kolmogorov forcing. Compared to a baseline 4DVAR implementation, the neural reparameterized variants produce more stable initial condition estimates without spurious oscillations. Notably, unlike most machine learning-based approaches, our framework does not require access to ground-truth states or reanalysis data, broadening its applicability to settings with limited reference information.",
        "subjects": "Machine Learning, Computational Physics, Fluid Dynamics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.168365"
    },
    {
        "index": "#125",
        "title": "Information-Theoretic Bayesian Optimization for Bilevel Optimization Problems",
        "link": "/arxiv/2509.21725",
        "arxiv_id": "2509.21725",
        "authors": "Takuya Kanayama, Yuki Ito, Tomoyuki Tamura, Masayuki Karasuyama",
        "summary": "A bilevel optimization problem consists of two optimization problems nested as an upper- and a lower-level problem, in which the optimality of the lower-level problem defines a constraint for the upper-level problem. This paper considers Bayesian optimization (BO) for the case that both the upper- and lower-levels involve expensive black-box functions. Because of its nested structure, bilevel optimization has a complex problem definition and, compared with other standard extensions of BO such as multi-objective or constraint settings, it has not been widely studied. We propose an information-theoretic approach that considers the information gain of both the upper- and lower-optimal solutions and values. This enables us to define a unified criterion that measures the benefit for both level problems, simultaneously. Further, we also show a practical lower bound based approach to evaluating the information gain. We empirically demonstrate the effectiveness of our proposed method through several benchmark datasets.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.170285"
    },
    {
        "index": "#126",
        "title": "A Unifying Framework for Parallelizing Sequential Models with Linear Dynamical Systems",
        "link": "/arxiv/2509.21716",
        "arxiv_id": "2509.21716",
        "authors": "Xavier Gonzalez, E. Kelly Buchanan, Hyun Dong Lee, Jerry Weihong Liu, Ke Alexander Wang, David M. Zoltowski, Christopher Ré, Scott W. Linderman",
        "summary": "Harnessing parallelism in seemingly sequential models is a central challenge for modern machine learning. Several approaches have been proposed for evaluating sequential processes in parallel using fixed-point methods, like Newton, Picard, and Jacobi iterations. In this work, we show that these methods can be understood within a common framework based on linear dynamical systems (LDSs), where different iteration schemes arise naturally as approximate linearizations of a nonlinear recursion. This unifying view highlights shared principles behind these techniques and clarifies when particular fixed-point methods are most likely to be effective. By bridging diverse algorithms through the language of LDSs, our framework provides a clearer theoretical foundation for parallelizing sequential models and points toward new opportunities for efficient and scalable computation.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.170605"
    },
    {
        "index": "#127",
        "title": "PQFed: A Privacy-Preserving Quality-Controlled Federated Learning Framework",
        "link": "/arxiv/2509.21704",
        "arxiv_id": "2509.21704",
        "authors": "Weiqi Yue, Wenbiao Li, Yuzhou Jiang, Anisa Halimi, Roger French, Erman Ayday",
        "summary": "Federated learning enables collaborative model training without sharing raw data, but data heterogeneity consistently challenges the performance of the global model. Traditional optimization methods often rely on collaborative global model training involving all clients, followed by local adaptation to improve individual performance. In this work, we focus on early-stage quality control and propose PQFed, a novel privacy-preserving personalized federated learning framework that designs customized training strategies for each client prior to the federated training process. PQFed extracts representative features from each client's raw data and applies clustering techniques to estimate inter-client dataset similarity. Based on these similarity estimates, the framework implements a client selection strategy that enables each client to collaborate with others who have compatible data distributions. We evaluate PQFed on two benchmark datasets, CIFAR-10 and MNIST, integrated with three existing federated learning algorithms. Experimental results show that PQFed consistently improves the target client's model performance, even with a limited number of participants. We further benchmark PQFed against a baseline cluster-based algorithm, IFCA, and observe that PQFed also achieves better performance in low-participation scenarios. These findings highlight PQFed's scalability and effectiveness in personalized federated learning settings.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.170899"
    },
    {
        "index": "#128",
        "title": "Downscaling human mobility data based on demographic socioeconomic and commuting characteristics using interpretable machine learning methods",
        "link": "/arxiv/2509.21703",
        "arxiv_id": "2509.21703",
        "authors": "Yuqin Jiang, Andrey A. Popov, Tianle Duan, Qingchun Li",
        "summary": "Understanding urban human mobility patterns at various spatial levels is essential for social science. This study presents a machine learning framework to downscale origin-destination (OD) taxi trips flows in New York City from a larger spatial unit to a smaller spatial unit. First, correlations between OD trips and demographic, socioeconomic, and commuting characteristics are developed using four models: Linear Regression (LR), Random Forest (RF), Support Vector Machine (SVM), and Neural Networks (NN). Second, a perturbation-based sensitivity analysis is applied to interpret variable importance for nonlinear models. The results show that the linear regression model failed to capture the complex variable interactions. While NN performs best with the training and testing datasets, SVM shows the best generalization ability in downscaling performance. The methodology presented in this study provides both analytical advancement and practical applications to improve transportation services and urban development.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.171176"
    },
    {
        "index": "#129",
        "title": "Exact Subgraph Isomorphism Network for Predictive Graph Mining",
        "link": "/arxiv/2509.21699",
        "arxiv_id": "2509.21699",
        "authors": "Taiga Kojima, Masayuki Karasuyama",
        "summary": "In the graph-level prediction task (predict a label for a given graph), the information contained in subgraphs of the input graph plays a key role. In this paper, we propose Exact subgraph Isomorphism Network (EIN), which combines the exact subgraph enumeration, neural network, and a sparse regularization. In general, building a graph-level prediction model achieving high discriminative ability along with interpretability is still a challenging problem. Our combination of the subgraph enumeration and neural network contributes to high discriminative ability about the subgraph structure of the input graph. Further, the sparse regularization in EIN enables us 1) to derive an effective pruning strategy that mitigates computational difficulty of the enumeration while maintaining the prediction performance, and 2) to identify important subgraphs that contributes to high interpretability. We empirically show that EIN has sufficiently high prediction performance compared with standard graph neural network models, and also, we show examples of post-hoc analysis based on the selected subgraphs.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.171445"
    },
    {
        "index": "#130",
        "title": "Wav2Arrest 2.0: Long-Horizon Cardiac Arrest Prediction with Time-to-Event Modeling, Identity-Invariance, and Pseudo-Lab Alignment",
        "link": "/arxiv/2509.21695",
        "arxiv_id": "2509.21695",
        "authors": "Saurabh Kataria, Davood Fattahi, Minxiao Wang, Ran Xiao, Matthew Clark, Timothy Ruchti, Mark Mai, Xiao Hu",
        "summary": "High-frequency physiological waveform modality offers deep, real-time insights into patient status. Recently, physiological foundation models based on Photoplethysmography (PPG), such as PPG-GPT, have been shown to predict critical events, including Cardiac Arrest (CA). However, their powerful representation still needs to be leveraged suitably, especially when the downstream data/label is scarce. We offer three orthogonal improvements to improve PPG-only CA systems by using minimal auxiliary information. First, we propose to use time-to-event modeling, either through simple regression to the event onset time or by pursuing fine-grained discrete survival modeling. Second, we encourage the model to learn CA-focused features by making them patient-identity invariant. This is achieved by first training the largest-scale de-identified biometric identification model, referred to as the p-vector, and subsequently using it adversarially to deconfound cues, such as person identity, that may cause overfitting through memorization. Third, we propose regression on the pseudo-lab values generated by pre-trained auxiliary estimator networks. This is crucial since true blood lab measurements, such as lactate, sodium, troponin, and potassium, are collected sparingly. Via zero-shot prediction, the auxiliary networks can enrich cardiac arrest waveform labels and generate pseudo-continuous estimates as targets. Our proposals can independently improve the 24-hour time-averaged AUC from the 0.74 to the 0.78-0.80 range. We primarily improve over longer time horizons with minimal degradation near the event, thus pushing the Early Warning System research. Finally, we pursue multi-task formulation and diagnose it with a high gradient conflict rate among competing losses, which we alleviate via the PCGrad optimization technique.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.171783"
    },
    {
        "index": "#131",
        "title": "SpecMER: Fast Protein Generation with K-mer Guided Speculative Decoding",
        "link": "/arxiv/2509.21689",
        "arxiv_id": "2509.21689",
        "authors": "Thomas Walton, Darin Tsui, Aryan Musharaf, Amirali Aghazadeh",
        "summary": "Autoregressive models have transformed protein engineering by enabling the generation of novel protein sequences beyond those found in nature. However, their sequential inference introduces significant latency, limiting their utility in high-throughput protein screening. Speculative decoding accelerates generation by employing a lightweight draft model to sample tokens, which a larger target model then verifies and refines. Yet, in protein sequence generation, draft models are typically agnostic to the structural and functional constraints of the target protein, leading to biologically implausible outputs and a shift in the likelihood distribution of generated sequences. We introduce SpecMER (Speculative Decoding via k-mer Guidance), a novel framework that incorporates biological, structural, and functional priors using k-mer motifs extracted from multiple sequence alignments. By scoring candidate sequences in parallel and selecting those most consistent with known biological patterns, SpecMER significantly improves sequence plausibility while retaining the efficiency of speculative decoding. SpecMER achieves 24-32% speedup over standard autoregressive decoding, along with higher acceptance rates and improved sequence likelihoods.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.172061"
    },
    {
        "index": "#132",
        "title": "Prophecy: Inferring Formal Properties from Neuron Activations",
        "link": "/arxiv/2509.21677",
        "arxiv_id": "2509.21677",
        "authors": "Divya Gopinath, Corina S. Pasareanu, Muhammad Usman",
        "summary": "We present Prophecy, a tool for automatically inferring formal properties of feed-forward neural networks. Prophecy is based on the observation that a significant part of the logic of feed-forward networks is captured in the activation status of the neurons at inner layers. Prophecy works by extracting rules based on neuron activations (values or on/off statuses) as preconditions that imply certain desirable output property, e.g., the prediction being a certain class. These rules represent network properties captured in the hidden layers that imply the desired output behavior. We present the architecture of the tool, highlight its features and demonstrate its usage on different types of models and output properties. We present an overview of its applications, such as inferring and proving formal explanations of neural networks, compositional verification, run-time monitoring, repair, and others. We also show novel results highlighting its potential in the era of large vision-language models.",
        "subjects": "Machine Learning, Software Engineering",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.172349"
    },
    {
        "index": "#133",
        "title": "Scalable Second-order Riemannian Optimization for $K$-means Clustering",
        "link": "/arxiv/2509.21675",
        "arxiv_id": "2509.21675",
        "authors": "Peng Xu, Chun-Ying Hou, Xiaohui Chen, Richard Y. Zhang",
        "summary": "Clustering is a hard discrete optimization problem. Nonconvex approaches such as low-rank semidefinite programming (SDP) have recently demonstrated promising statistical and local algorithmic guarantees for cluster recovery. Due to the combinatorial structure of the $K$-means clustering problem, current relaxation algorithms struggle to balance their constraint feasibility and objective optimality, presenting tremendous challenges in computing the second-order critical points with rigorous guarantees. In this paper, we provide a new formulation of the $K$-means problem as a smooth unconstrained optimization over a submanifold and characterize its Riemannian structures to allow it to be solved using a second-order cubic-regularized Riemannian Newton algorithm. By factorizing the $K$-means manifold into a product manifold, we show how each Newton subproblem can be solved in linear time. Our numerical experiments show that the proposed method converges significantly faster than the state-of-the-art first-order nonnegative low-rank factorization method, while achieving similarly optimal statistical accuracy.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.172652"
    },
    {
        "index": "#135",
        "title": "Neuroprobe: Evaluating Intracranial Brain Responses to Naturalistic Stimuli",
        "link": "/arxiv/2509.21671",
        "arxiv_id": "2509.21671",
        "authors": "Andrii Zahorodnii, Christopher Wang, Bennett Stankovits, Charikleia Moraitaki, Geeling Chau, Andrei Barbu, Boris Katz, Ila R Fiete",
        "summary": "High-resolution neural datasets enable foundation models for the next generation of brain-computer interfaces and neurological treatments. The community requires rigorous benchmarks to discriminate between competing modeling approaches, yet no standardized evaluation frameworks exist for intracranial EEG (iEEG) recordings. To address this gap, we present Neuroprobe: a suite of decoding tasks for studying multi-modal language processing in the brain. Unlike scalp EEG, intracranial EEG requires invasive surgery to implant electrodes that record neural activity directly from the brain with minimal signal distortion. Neuroprobe is built on the BrainTreebank dataset, which consists of 40 hours of iEEG recordings from 10 human subjects performing a naturalistic movie viewing task. Neuroprobe serves two critical functions. First, it is a mine from which neuroscience insights can be drawn. Its high temporal and spatial resolution allows researchers to systematically determine when and where computations for each aspect of language processing occur in the brain by measuring the decodability of each feature across time and all electrode locations. Using Neuroprobe, we visualize how information flows from the superior temporal gyrus to the prefrontal cortex, and the progression from simple auditory features to more complex language features in a purely data-driven manner. Second, as the field moves toward neural foundation models, Neuroprobe provides a rigorous framework for comparing competing architectures and training protocols. We found that the linear baseline is surprisingly strong, beating frontier foundation models on many tasks. Neuroprobe is designed with computational efficiency and ease of use in mind. We make the code for Neuroprobe openly available and maintain a public leaderboard, aiming to enable rapid progress in the field of iEEG foundation models, at https://neuroprobe.dev/",
        "subjects": "Machine Learning, Neurons and Cognition",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.173293"
    },
    {
        "index": "#138",
        "title": "MMPlanner: Zero-Shot Multimodal Procedural Planning with Chain-of-Thought Object State Reasoning",
        "link": "/arxiv/2509.21662",
        "arxiv_id": "2509.21662",
        "authors": "Afrina Tabassum, Bin Guo, Xiyao Ma, Hoda Eldardiry, Ismini Lourentzou",
        "summary": "Multimodal Procedural Planning (MPP) aims to generate step-by-step instructions that combine text and images, with the central challenge of preserving object-state consistency across modalities while producing informative plans. Existing approaches often leverage large language models (LLMs) to refine textual steps; however, visual object-state alignment and systematic evaluation are largely underexplored. We present MMPlanner, a zero-shot MPP framework that introduces Object State Reasoning Chain-of-Thought (OSR-CoT) prompting to explicitly model object-state transitions and generate accurate multimodal plans. To assess plan quality, we design LLM-as-a-judge protocols for planning accuracy and cross-modal alignment, and further propose a visual step-reordering task to measure temporal coherence. Experiments on RECIPEPLAN and WIKIPLAN show that MMPlanner achieves state-of-the-art performance, improving textual planning by +6.8%, cross-modal alignment by +11.9%, and visual step ordering by +26.7%",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.174172"
    },
    {
        "index": "#139",
        "title": "A Systematic Review of Conformal Inference Procedures for Treatment Effect Estimation: Methods and Challenges",
        "link": "/arxiv/2509.21660",
        "arxiv_id": "2509.21660",
        "authors": "Pascal Memmesheimer, Vincent Heuveline, Jürgen Hesser",
        "summary": "Treatment effect estimation is essential for informed decision-making in many fields such as healthcare, economics, and public policy. While flexible machine learning models have been widely applied for estimating heterogeneous treatment effects, quantifying the inherent uncertainty of their point predictions remains an issue. Recent advancements in conformal prediction address this limitation by allowing for inexpensive computation, as well as distribution shifts, while still providing frequentist, finite-sample coverage guarantees under minimal assumptions for any point-predictor model. This advancement holds significant potential for improving decision-making in especially high-stakes environments. In this work, we perform a systematic review regarding conformal prediction methods for treatment effect estimation and provide for both the necessary theoretical background. Through a systematic filtering process, we select and analyze eleven key papers, identifying and describing current state-of-the-art methods in this area. Based on our findings, we propose directions for future research.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.174455"
    },
    {
        "index": "#140",
        "title": "RED-DiffEq: Regularization by denoising diffusion models for solving inverse PDE problems with application to full waveform inversion",
        "link": "/arxiv/2509.21659",
        "arxiv_id": "2509.21659",
        "authors": "Siming Shan, Min Zhu, Youzuo Lin, Lu Lu",
        "summary": "Partial differential equation (PDE)-governed inverse problems are fundamental across various scientific and engineering applications; yet they face significant challenges due to nonlinearity, ill-posedness, and sensitivity to noise. Here, we introduce a new computational framework, RED-DiffEq, by integrating physics-driven inversion and data-driven learning. RED-DiffEq leverages pretrained diffusion models as a regularization mechanism for PDE-governed inverse problems. We apply RED-DiffEq to solve the full waveform inversion problem in geophysics, a challenging seismic imaging technique that seeks to reconstruct high-resolution subsurface velocity models from seismic measurement data. Our method shows enhanced accuracy and robustness compared to conventional methods. Additionally, it exhibits strong generalization ability to more complex velocity models that the diffusion model is not trained on. Our framework can also be directly applied to diverse PDE-governed inverse problems.",
        "subjects": "Machine Learning, Geophysics",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.174754"
    },
    {
        "index": "#141",
        "title": "Differentiable Structure Learning for General Binary Data",
        "link": "/arxiv/2509.21658",
        "arxiv_id": "2509.21658",
        "authors": "Chang Deng, Bryon Aragam",
        "summary": "Existing methods for differentiable structure learning in discrete data typically assume that the data are generated from specific structural equation models. However, these assumptions may not align with the true data-generating process, which limits the general applicability of such methods. Furthermore, current approaches often ignore the complex dependence structure inherent in discrete data and consider only linear effects. We propose a differentiable structure learning framework that is capable of capturing arbitrary dependencies among discrete variables. We show that although general discrete models are unidentifiable from purely observational data, it is possible to characterize the complete set of compatible parameters and structures. Additionally, we establish identifiability up to Markov equivalence under mild assumptions. We formulate the learning problem as a single differentiable optimization task in the most general form, thereby avoiding the unrealistic simplifications adopted by previous methods. Empirical results demonstrate that our approach effectively captures complex relationships in discrete data.",
        "subjects": "Machine Learning, Statistics Theory, Methodology, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.175053"
    },
    {
        "index": "#142",
        "title": "DriftLite: Lightweight Drift Control for Inference-Time Scaling of Diffusion Models",
        "link": "/arxiv/2509.21655",
        "arxiv_id": "2509.21655",
        "authors": "Yinuo Ren, Wenhao Gao, Lexing Ying, Grant M. Rotskoff, Jiequn Han",
        "summary": "We study inference-time scaling for diffusion models, where the goal is to adapt a pre-trained model to new target distributions without retraining. Existing guidance-based methods are simple but introduce bias, while particle-based corrections suffer from weight degeneracy and high computational cost. We introduce DriftLite, a lightweight, training-free particle-based approach that steers the inference dynamics on the fly with provably optimal stability control. DriftLite exploits a previously unexplored degree of freedom in the Fokker-Planck equation between the drift and particle potential, and yields two practical instantiations: Variance- and Energy-Controlling Guidance (VCG/ECG) for approximating the optimal drift with minimal overhead. Across Gaussian mixture models, particle systems, and large-scale protein-ligand co-folding problems, DriftLite consistently reduces variance and improves sample quality over pure guidance and sequential Monte Carlo baselines. These results highlight a principled, efficient route toward scalable inference-time adaptation of diffusion models.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.175358"
    },
    {
        "index": "#144",
        "title": "Understanding and Enhancing Mask-Based Pretraining towards Universal Representations",
        "link": "/arxiv/2509.21650",
        "arxiv_id": "2509.21650",
        "authors": "Mingze Dong, Leda Wang, Yuval Kluger",
        "summary": "Mask-based pretraining has become a cornerstone of modern large-scale models across language, vision, and recently biology. Despite its empirical success, its role and limits in learning data representations have been unclear. In this work, we show that the behavior of mask-based pretraining can be directly characterized by test risk in high-dimensional minimum-norm (\"ridge-less\") linear regression, without relying on further model specifications. Further analysis of linear models uncovers several novel aspects of mask-based pretraining. The theoretical framework and its implications have been validated across diverse neural architectures (including MLPs, CNNs, and Transformers) applied to both vision and language tasks. Guided by our theory, we propose an embarrassingly simple yet overlooked pretraining scheme named Randomly Random Mask AutoEncoding (R$^2$MAE), which enforces capturing multi-scale features from data and is able to outperform optimal fixed mask ratio settings in our linear model framework. We implement R$^2$MAE in vision, language, DNA sequence, and single-cell models, where it consistently outperforms standard and more complicated masking schemes, leading to improvements for state-of-the-art models. Our code is available at: https://github.com/MingzeDong/r2mae",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.175922"
    },
    {
        "index": "#145",
        "title": "Blockwise Hadamard high-Rank Adaptation for Parameter-Efficient LLM Fine-Tuning",
        "link": "/arxiv/2509.21637",
        "arxiv_id": "2509.21637",
        "authors": "Feng Yu, Jia Hu, Geyong Min",
        "summary": "Parameter-efficient fine-tuning (PEFT) methods must be resource-efficient yet handle heterogeneous reasoning transformations, and classical low-rank adaptation (LoRA) is constrained by the nominal rank $r$. Hadamard-style extensions like HiRA raise the nominal rank but couple every update to the global energy pattern of the frozen weight matrix, while ABBA trades this inductive bias for fully learned dense intermediates. To address the limitation of global modulation, we propose Block Hadamard high-Rank Adaptation (BHRA), which partitions each weight matrix and applies HiRA-style multiplicative modulation independently within every block, preserving the PEFT parameter footprint while unlocking localized rank amplification. Our empirical analyses reveal that this blockwise design maintains rich spectra across rank budgets, mitigating the collapse induced by global modulation. Across eight commonsense reasoning tasks and two arithmetic benchmarks with Llama-3.2 1B/3B, Mistral-7B, and Gemma-2 9B, BHRA consistently surpasses strong PEFT baselines under matched parameter budgets.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.176198"
    },
    {
        "index": "#146",
        "title": "Shoot from the HIP: Hessian Interatomic Potentials without derivatives",
        "link": "/arxiv/2509.21624",
        "arxiv_id": "2509.21624",
        "authors": "Andreas Burger, Luca Thiede, Nikolaj Rønne, Varinia Bernales, Nandita Vijaykumar, Tejs Vegge, Arghya Bhowmik, Alan Aspuru-Guzik",
        "summary": "Fundamental tasks in computational chemistry, from transition state search to vibrational analysis, rely on molecular Hessians, which are the second derivatives of the potential energy. Yet, Hessians are computationally expensive to calculate and scale poorly with system size, with both quantum mechanical methods and neural networks. In this work, we demonstrate that Hessians can be predicted directly from a deep learning model, without relying on automatic differentiation or finite differences. We observe that one can construct SE(3)-equivariant, symmetric Hessians from irreducible representations (irrep) features up to degree $l$=2 computed during message passing in graph neural networks. This makes HIP Hessians one to two orders of magnitude faster, more accurate, more memory efficient, easier to train, and enables more favorable scaling with system size. We validate our predictions across a wide range of downstream tasks, demonstrating consistently superior performance for transition state search, accelerated geometry optimization, zero-point energy corrections, and vibrational analysis benchmarks. We open-source the HIP codebase and model weights to enable further development of the direct prediction of Hessians at https://github.com/BurgerAndreas/hip",
        "subjects": "Machine Learning, Chemical Physics, Computational Physics",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.176540"
    },
    {
        "index": "#147",
        "title": "PreLoRA: Hybrid Pre-training of Vision Transformers with Full Training and Low-Rank Adapters",
        "link": "/arxiv/2509.21619",
        "arxiv_id": "2509.21619",
        "authors": "Krishu K Thapa, Reet Barik, Krishna Teja Chitty-Venkata, Murali Emani, Venkatram Vishwanath",
        "summary": "Training large models ranging from millions to billions of parameters is highly resource-intensive, requiring significant time, compute, and memory. It is observed that most of the learning (higher change in weights) takes place in the earlier stage of the training loop. These changes stabilize as training continues, enabling them to be captured by matrices of a low intrinsic rank. Therefore, we propose an approach to identify such states of partial convergence and dynamically switch from full parameter training to Low-Rank Adaptation (LoRA) on the ViT-Large model. We introduce a flexible approach that leverages user-defined hyperparameters to determine the switching point and assign a rank specific to each module layer based on its level of convergence. Experimental results show that this approach preserves model accuracy while reducing the number of trainable parameters to 10% of its original size, resulting in a 3x improvement in throughput, and a 1.5x reduction in average training time per epoch while also reducing GPU memory consumption by 20%",
        "subjects": "Machine Learning, Performance",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.176846"
    },
    {
        "index": "#149",
        "title": "Causal Abstraction Inference under Lossy Representations",
        "link": "/arxiv/2509.21607",
        "arxiv_id": "2509.21607",
        "authors": "Kevin Xia, Elias Bareinboim",
        "summary": "The study of causal abstractions bridges two integral components of human intelligence: the ability to determine cause and effect, and the ability to interpret complex patterns into abstract concepts. Formally, causal abstraction frameworks define connections between complicated low-level causal models and simple high-level ones. One major limitation of most existing definitions is that they are not well-defined when considering lossy abstraction functions in which multiple low-level interventions can have different effects while mapping to the same high-level intervention (an assumption called the abstract invariance condition). In this paper, we introduce a new type of abstractions called projected abstractions that generalize existing definitions to accommodate lossy representations. We show how to construct a projected abstraction from the low-level model and how it translates equivalent observational, interventional, and counterfactual causal queries from low to high-level. Given that the true model is rarely available in practice we prove a new graphical criteria for identifying and estimating high-level causal queries from limited low-level data. Finally, we experimentally show the effectiveness of projected abstraction models in high-dimensional image settings.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.177404"
    },
    {
        "index": "#150",
        "title": "Task-Agnostic Federated Continual Learning via Replay-Free Gradient Projection",
        "link": "/arxiv/2509.21606",
        "arxiv_id": "2509.21606",
        "authors": "Seohyeon Cha, Huancheng Chen, Haris Vikalo",
        "summary": "Federated continual learning (FCL) enables distributed client devices to learn from streaming data across diverse and evolving tasks. A major challenge to continual learning, catastrophic forgetting, is exacerbated in decentralized settings by the data heterogeneity, constrained communication and privacy concerns. We propose Federated gradient Projection-based Continual Learning with Task Identity Prediction (FedProTIP), a novel FCL framework that mitigates forgetting by projecting client updates onto the orthogonal complement of the subspace spanned by previously learned representations of the global model. This projection reduces interference with earlier tasks and preserves performance across the task sequence. To further address the challenge of task-agnostic inference, we incorporate a lightweight mechanism that leverages core bases from prior tasks to predict task identity and dynamically adjust the global model's outputs. Extensive experiments across standard FCL benchmarks demonstrate that FedProTIP significantly outperforms state-of-the-art methods in average accuracy, particularly in settings where task identities are a priori unknown.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.177681"
    },
    {
        "index": "#151",
        "title": "GenUQ: Predictive Uncertainty Estimates via Generative Hyper-Networks",
        "link": "/arxiv/2509.21605",
        "arxiv_id": "2509.21605",
        "authors": "Tian Yu Yen, Reese E. Jones, Ravi G. Patel",
        "summary": "Operator learning is a recently developed generalization of regression to mappings between functions. It promises to drastically reduce expensive numerical integration of PDEs to fast evaluations of mappings between functional states of a system, i.e., surrogate and reduced-order modeling. Operator learning has already found applications in several areas such as modeling sea ice, combustion, and atmospheric physics. Recent approaches towards integrating uncertainty quantification into the operator models have relied on likelihood based methods to infer parameter distributions from noisy data. However, stochastic operators may yield actions from which a likelihood is difficult or impossible to construct. In this paper, we introduce, GenUQ, a measure-theoretic approach to UQ that avoids constructing a likelihood by introducing a generative hyper-network model that produces parameter distributions consistent with observed data. We demonstrate that GenUQ outperforms other UQ methods in three example problems, recovering a manufactured operator, learning the solution operator to a stochastic elliptic PDE, and modeling the failure location of porous steel under tension.",
        "subjects": "Machine Learning, Numerical Analysis, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.177975"
    },
    {
        "index": "#153",
        "title": "Interpretable time series analysis with Gumbel dynamics",
        "link": "/arxiv/2509.21578",
        "arxiv_id": "2509.21578",
        "authors": "Yiliu Wang, Timothy Doyeon Kim, Eric Shea-Brown, Uygar Sümbül",
        "summary": "Switching dynamical systems can model complicated time series data while maintaining interpretability by inferring a finite set of dynamics primitives and explaining different portions of the observed time series with one of these primitives. However, due to the discrete nature of this set, such models struggle to capture smooth, variable-speed transitions, as well as stochastic mixtures of overlapping states, and the inferred dynamics often display spurious rapid switching on real-world datasets. Here, we propose the Gumbel Dynamical Model (GDM). First, by introducing a continuous relaxation of discrete states and a different noise model defined on the relaxed-discrete state space via the Gumbel distribution, GDM expands the set of available state dynamics, allowing the model to approximate smoother and non-stationary ground-truth dynamics more faithfully. Second, the relaxation makes the model fully differentiable, enabling fast and scalable training with standard gradient descent methods. We validate our approach on standard simulation datasets and highlight its ability to model soft, sticky states and transitions in a stochastic setting. Furthermore, we apply our model to two real-world datasets, demonstrating its ability to infer interpretable states in stochastic time series with multiple dynamics, a setting where traditional methods often fail.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.178559"
    },
    {
        "index": "#154",
        "title": "Machine Learning. The Science of Selection under Uncertainty",
        "link": "/arxiv/2509.21547",
        "arxiv_id": "2509.21547",
        "authors": "Yevgeny Seldin",
        "summary": "Learning, whether natural or artificial, is a process of selection. It starts with a set of candidate options and selects the more successful ones. In the case of machine learning the selection is done based on empirical estimates of prediction accuracy of candidate prediction rules on some data. Due to randomness of data sampling the empirical estimates are inherently noisy, leading to selection under uncertainty. The book provides statistical tools to obtain theoretical guarantees on the outcome of selection under uncertainty. We start with concentration of measure inequalities, which are the main statistical instrument for controlling how much an empirical estimate of expectation of a function deviates from the true expectation. The book covers a broad range of inequalities, including Markov's, Chebyshev's, Hoeffding's, Bernstein's, Empirical Bernstein's, Unexpected Bernstein's, kl, and split-kl. We then study the classical (offline) supervised learning and provide a range of tools for deriving generalization bounds, including Occam's razor, Vapnik-Chervonenkis analysis, and PAC-Bayesian analysis. The latter is further applied to derive generalization guarantees for weighted majority votes. After covering the offline setting, we turn our attention to online learning. We present the space of online learning problems characterized by environmental feedback, environmental resistance, and structural complexity. A common performance measure in online learning is regret, which compares performance of an algorithm to performance of the best prediction rule in hindsight, out of a restricted set of prediction rules. We present tools for deriving regret bounds in stochastic and adversarial environments, and under full information and bandit feedback.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.178834"
    },
    {
        "index": "#155",
        "title": "Evidence for Limited Metacognition in LLMs",
        "link": "/arxiv/2509.21545",
        "arxiv_id": "2509.21545",
        "authors": "Christopher Ackerman",
        "summary": "The possibility of LLM self-awareness and even sentience is gaining increasing public attention and has major safety and policy implications, but the science of measuring them is still in a nascent state. Here we introduce a novel methodology for quantitatively evaluating metacognitive abilities in LLMs. Taking inspiration from research on metacognition in nonhuman animals, our approach eschews model self-reports and instead tests to what degree models can strategically deploy knowledge of internal states. Using two experimental paradigms, we demonstrate that frontier LLMs introduced since early 2024 show increasingly strong evidence of certain metacognitive abilities, specifically the ability to assess and utilize their own confidence in their ability to answer factual and reasoning questions correctly and the ability to anticipate what answers they would give and utilize that information appropriately. We buttress these behavioral findings with an analysis of the token probabilities returned by the models, which suggests the presence of an upstream internal signal that could provide the basis for metacognition. We further find that these abilities 1) are limited in resolution, 2) emerge in context-dependent manners, and 3) seem to be qualitatively different from those of humans. We also report intriguing differences across models of similar capabilities, suggesting that LLM post-training may have a role in developing metacognitive abilities.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.179085"
    },
    {
        "index": "#156",
        "title": "A circuit for predicting hierarchical structure in-context in Large Language Models",
        "link": "/arxiv/2509.21534",
        "arxiv_id": "2509.21534",
        "authors": "Tankred Saanum, Can Demircan, Samuel J. Gershman, Eric Schulz",
        "summary": "Large Language Models (LLMs) excel at in-context learning, the ability to use information provided as context to improve prediction of future tokens. Induction heads have been argued to play a crucial role for in-context learning in Transformer Language Models. These attention heads make a token attend to successors of past occurrences of the same token in the input. This basic mechanism supports LLMs' ability to copy and predict repeating patterns. However, it is unclear if this same mechanism can support in-context learning of more complex repetitive patterns with hierarchical structure. Natural language is teeming with such cases: The article \"the\" in English usually prefaces multiple nouns in a text. When predicting which token succeeds a particular instance of \"the\", we need to integrate further contextual cues from the text to predict the correct noun. If induction heads naively attend to all past instances of successor tokens of \"the\" in a context-independent manner, they cannot support this level of contextual information integration. In this study, we design a synthetic in-context learning task, where tokens are repeated with hierarchical dependencies. Here, attending uniformly to all successor tokens is not sufficient to accurately predict future tokens. Evaluating a range of LLMs on these token sequences and natural language analogues, we find adaptive induction heads that support prediction by learning what to attend to in-context. Next, we investigate how induction heads themselves learn in-context. We find evidence that learning is supported by attention heads that uncover a set of latent contexts, determining the different token transition relationships. Overall, we not only show that LLMs have induction heads that learn, but offer a complete mechanistic account of how LLMs learn to predict higher-order repetitive patterns in-context.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.179375"
    },
    {
        "index": "#157",
        "title": "Expert-guided Clinical Text Augmentation via Query-Based Model Collaboration",
        "link": "/arxiv/2509.21530",
        "arxiv_id": "2509.21530",
        "authors": "Dongkyu Cho, Miao Zhang, Rumi Chunara",
        "summary": "Data augmentation is a widely used strategy to improve model robustness and generalization by enriching training datasets with synthetic examples. While large language models (LLMs) have demonstrated strong generative capabilities for this purpose, their applications in high-stakes domains like healthcare present unique challenges due to the risk of generating clinically incorrect or misleading information. In this work, we propose a novel query-based model collaboration framework that integrates expert-level domain knowledge to guide the augmentation process to preserve critical medical information. Experiments on clinical prediction tasks demonstrate that our lightweight collaboration-based approach consistently outperforms existing LLM augmentation methods while improving safety through reduced factual errors. This framework addresses the gap between LLM augmentation potential and the safety requirements of specialized domains.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.179642"
    },
    {
        "index": "#163",
        "title": "Contrastive Mutual Information Learning: Toward Robust Representations without Positive-Pair Augmentations",
        "link": "/arxiv/2509.21511",
        "arxiv_id": "2509.21511",
        "authors": "Micha Livne",
        "summary": "Learning representations that transfer well to diverse downstream tasks remains a central challenge in representation learning. Existing paradigms -- contrastive learning, self-supervised masking, and denoising auto-encoders -- balance this challenge with different trade-offs. We introduce the {contrastive Mutual Information Machine} (cMIM), a probabilistic framework that extends the Mutual Information Machine (MIM) with a contrastive objective. While MIM maximizes mutual information between inputs and latents and promotes clustering of codes, it falls short on discriminative tasks. cMIM addresses this gap by imposing global discriminative structure while retaining MIM's generative fidelity. Our contributions are threefold. First, we propose cMIM, a contrastive extension of MIM that removes the need for positive data augmentation and is substantially less sensitive to batch size than InfoNCE. Second, we introduce {informative embeddings}, a general technique for extracting enriched features from encoder-decoder models that boosts discriminative performance without additional training and applies broadly beyond MIM. Third, we provide empirical evidence across vision and molecular benchmarks showing that cMIM outperforms MIM and InfoNCE on classification and regression tasks while preserving competitive reconstruction quality. These results position cMIM as a unified framework for representation learning, advancing the goal of models that serve both discriminative and generative applications effectively.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.181408"
    },
    {
        "index": "#166",
        "title": "GraphPFN: A Prior-Data Fitted Graph Foundation Model",
        "link": "/arxiv/2509.21489",
        "arxiv_id": "2509.21489",
        "authors": "Dmitry Eremeev, Oleg Platonov, Gleb Bazhenov, Artem Babenko, Liudmila Prokhorenkova",
        "summary": "Foundation models pretrained on large-scale datasets have transformed such fields as natural language processing and computer vision, but their application to graph data remains limited. Recently emerged graph foundation models, such as G2T-FM, utilize tabular foundation models for graph tasks and were shown to significantly outperform prior attempts to create GFMs. However, these models primarily rely on hand-crafted graph features, limiting their ability to learn complex graph-specific patterns. In this work, we propose GraphPFN: a prior-data fitted network for node-level prediction. First, we design a prior distribution of synthetic attributed graphs. For graph structure generation, we use a novel combination of multiple stochastic block models and a preferential attachment process. We then apply graph-aware structured causal models to generate node attributes and targets. This procedure allows us to efficiently generate a wide range of realistic graph datasets. Then, we augment the tabular foundation model LimiX with attention-based graph neighborhood aggregation layers and train it on synthetic graphs sampled from our prior, allowing the model to capture graph structural dependencies not present in tabular data. On diverse real-world graph datasets with up to 50,000 nodes, GraphPFN shows strong in-context learning performance and achieves state-of-the-art results after finetuning, outperforming both G2T-FM and task-specific GNNs trained from scratch on most datasets. More broadly, our work demonstrates that pretraining on synthetic graphs from a well-designed prior distribution is an effective strategy for building graph foundation models.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.182323"
    },
    {
        "index": "#168",
        "title": "High-Probability Analysis of Online and Federated Zero-Order Optimisation",
        "link": "/arxiv/2509.21484",
        "arxiv_id": "2509.21484",
        "authors": "Arya Akhavan, David Janz, El-Mahdi El-Mhamdi",
        "summary": "We study distributed learning in the setting of gradient-free zero-order optimization and introduce FedZero, a federated zero-order algorithm that delivers sharp theoretical guarantees. Specifically, FedZero: (1) achieves near-optimal optimization error bounds with high probability in the federated convex setting; and (2) in the single-worker regime-where the problem reduces to the standard zero-order framework, establishes the first high-probability convergence guarantees for convex zero-order optimization, thereby strengthening the classical expectation-based results. At its core, FedZero employs a gradient estimator based on randomization over the $\\ell_1$-sphere. To analyze it, we develop new concentration inequalities for Lipschitz functions under the uniform measure on the $\\ell_1$-sphere, with explicit constants. These concentration tools are not only central to our high-probability guarantees but may also be of independent interest.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.182908"
    },
    {
        "index": "#169",
        "title": "Filtering with Confidence: When Data Augmentation Meets Conformal Prediction",
        "link": "/arxiv/2509.21479",
        "arxiv_id": "2509.21479",
        "authors": "Zixuan Wu, So Won Jeong, Yating Liu, Yeo Jin Jung, Claire Donnat",
        "summary": "With promising empirical performance across a wide range of applications, synthetic data augmentation appears a viable solution to data scarcity and the demands of increasingly data-intensive models. Its effectiveness lies in expanding the training set in a way that reduces estimator variance while introducing only minimal bias. Controlling this bias is therefore critical: effective data augmentation should generate diverse samples from the same underlying distribution as the training set, with minimal shifts. In this paper, we propose conformal data augmentation, a principled data filtering framework that leverages the power of conformal prediction to produce diverse synthetic data while filtering out poor-quality generations with provable risk control. Our method is simple to implement, requires no access to internal model logits, nor large-scale model retraining. We demonstrate the effectiveness of our approach across multiple tasks, including topic prediction, sentiment analysis, image classification, and fraud detection, showing consistent performance improvements of up to 40% in F1 score over unaugmented baselines, and 4% over other filtered augmentation baselines.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.183195"
    },
    {
        "index": "#171",
        "title": "d2: Improved Techniques for Training Reasoning Diffusion Language Models",
        "link": "/arxiv/2509.21474",
        "arxiv_id": "2509.21474",
        "authors": "Guanghan Wang, Yair Schiff, Gilad Turok, Volodymyr Kuleshov",
        "summary": "While diffusion language models (DLMs) have achieved competitive performance in text generation, improving their reasoning ability with reinforcement learning remains an active research area. Here, we introduce d2, a reasoning framework tailored for masked DLMs. Central to our framework is a new policy gradient algorithm that relies on properties of masking to accurately estimate the likelihoods of sampling trajectories. Our estimators trade off computation for approximation accuracy in an analytically tractable manner, and are particularly effective for DLMs that support any-order likelihood estimation. We characterize and study this property in popular DLMs and show that it is key for efficient diffusion-based reasoning. Empirically, d2 significantly improves over previous diffusion reasoning frameworks using only RL (without relying on supervised fine-tuning), and sets a new state-of-the-art performance for DLMs on logical reasoning tasks (Countdown and Sudoku) and math reasoning benchmarks (GSM8K and MATH500).",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.183812"
    },
    {
        "index": "#174",
        "title": "Talking Trees: Reasoning-Assisted Induction of Decision Trees for Tabular Data",
        "link": "/arxiv/2509.21465",
        "arxiv_id": "2509.21465",
        "authors": "George Yakushev, Alina Shutova, Ivan Rubachev, Renat Sergazinov, Artem Babenko",
        "summary": "Tabular foundation models are becoming increasingly popular for low-resource tabular problems. These models make up for small training datasets by pretraining on large volumes of synthetic data. The prior knowledge obtained via pretraining provides the exceptional performance, but the resulting model becomes a black box that is difficult to interpret and costly to inference. In this work, we explore an alternative strategy: using reasoning-capable LLMs to induce decision trees for small tabular datasets in agentic setup. We design a minimal set of tools for constructing, analyzing and manipulating decision trees. By using these tools, LLMs combine their prior knowledge with learning from data to create a lightweight decision tree that outperforms traditional CART on low-resource tabular problems. While a single decision tree does not outperform state-of-the-art black box models, it comes with a human-readable reasoning trace that can be checked for biases and data leaks. Furthermore, the reasoning-based LLM's creation process allows for additional human input: correcting biases or incorporating domain-specific intuition that is not captured in the data.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.184720"
    },
    {
        "index": "#175",
        "title": "Forecasting Seismic Waveforms: A Deep Learning Approach for Einstein Telescope",
        "link": "/arxiv/2509.21446",
        "arxiv_id": "2509.21446",
        "authors": "Waleed Esmail, Alexander Kappes, Stuart Russell, Christine Thomas",
        "summary": "We introduce \\textit{SeismoGPT}, a transformer-based model for forecasting three-component seismic waveforms in the context of future gravitational wave detectors like the Einstein Telescope. The model is trained in an autoregressive setting and can operate on both single-station and array-based inputs. By learning temporal and spatial dependencies directly from waveform data, SeismoGPT captures realistic ground motion patterns and provides accurate short-term forecasts. Our results show that the model performs well within the immediate prediction window and gradually degrades further ahead, as expected in autoregressive systems. This approach lays the groundwork for data-driven seismic forecasting that could support Newtonian noise mitigation and real-time observatory control.",
        "subjects": "Machine Learning, Earth and Planetary Astrophysics, Instrumentation and Methods for Astrophysics, General Relativity and Quantum Cosmology",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.185033"
    },
    {
        "index": "#176",
        "title": "Null-Space Filtering for Data-Free Continual Model Merging: Preserving Transparency, Promoting Fidelity",
        "link": "/arxiv/2509.21413",
        "arxiv_id": "2509.21413",
        "authors": "Zihuan Qiu, Lei Wang, Yang Cao, Runtong Zhang, Bing Su, Yi Xu, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li",
        "summary": "Data-free continual model merging (DFCMM) aims to fuse independently fine-tuned models into a single backbone that evolves with incoming tasks without accessing task data. This paper formulate two fundamental desiderata for DFCMM: transparency, avoiding interference with earlier tasks, and fidelity, adapting faithfully to each new task. This poses a challenge that existing approaches fail to address: how to bridge data-level desiderata with parameter-space optimization to ensure transparency and fidelity in the absence of task data. To this end, we propose NUFILT (NUll-space FILTering), a data-free framework that directly links these desiderata to optimization. Our key observation is that task vectors approximately align with representation subspaces, providing structural surrogates for enforcing transparency and fidelity. Accordingly, we design a null-space projector that preserves prior responses by filtering out overlapping components of new task vectors, thereby ensuring transparency, and a lightweight LoRA adapter that injects complementary task-specific signals, enabling fidelity in adapting to new tasks. The adapter is trained with a projection-based surrogate loss to retain consistency with previous knowledge while introducing novel directions. This joint filtering-adaptation process allows the backbone to absorb new knowledge while retaining existing behaviors, and the updates are finally fused back in a layer-wise linear fashion without extra parameters or inference cost. Theoretically, we establish approximate subspace alignment guarantees that justify null-space filtering. Empirically, NUFILT achieves state-of-the-art performance with minimal forgetting on both vision and NLP benchmarks, improving average accuracy by 4-7% over OPCM and WUDI-Merging, while narrowing the gap to fine-tuning and reducing computation overhead.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.185365"
    },
    {
        "index": "#177",
        "title": "Object Identification Under Known Dynamics: A PIRNN Approach for UAV Classification",
        "link": "/arxiv/2509.21405",
        "arxiv_id": "2509.21405",
        "authors": "Nyi Nyi Aung, Neil Muralles, Adrian Stein",
        "summary": "This work addresses object identification under known dynamics in unmanned aerial vehicle applications, where learning and classification are combined through a physics-informed residual neural network. The proposed framework leverages physics-informed learning for state mapping and state-derivative prediction, while a softmax layer enables multi-class confidence estimation. Quadcopter, fixed-wing, and helicopter aerial vehicles are considered as case studies. The results demonstrate high classification accuracy with reduced training time, offering a promising solution for system identification problems in domains where the underlying dynamics are well understood.",
        "subjects": "Machine Learning, Robotics",
        "date": "2025-09-24",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.185647"
    },
    {
        "index": "#179",
        "title": "Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics",
        "link": "/arxiv/2509.21393",
        "arxiv_id": "2509.21393",
        "authors": "Yi En Chou, Te Hsin Liu, Chao An Lin",
        "summary": "Physics Informed Neural Networks offer a mesh free framework for solving PDEs but are highly sensitive to loss weight selection. We propose two dimensional analysis based weighting schemes, one based on quantifiable terms, and another also incorporating unquantifiable terms for more balanced training. Benchmarks on heat conduction, convection diffusion, and lid driven cavity flows show that the second scheme consistently improves stability and accuracy over equal weighting. Notably, in high Peclet number convection diffusion, where traditional solvers fail, PINNs with our scheme achieve stable, accurate predictions, highlighting their robustness and generalizability in CFD problems.",
        "subjects": "Machine Learning, Fluid Dynamics",
        "date": "2025-09-24",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.186206"
    },
    {
        "index": "#180",
        "title": "Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail",
        "link": "/arxiv/2509.21322",
        "arxiv_id": "2509.21322",
        "authors": "Anna Kalenkova, Lu Xia, Dirk Neumann",
        "summary": "This paper proposes a novel method for analyzing food retail processes with a focus on reducing food waste. The approach integrates object-centric process mining (OCPM) with stochastic process discovery and analysis. First, a stochastic process in the form of a continuous-time Markov chain is discovered from grocery store sales data. This model is then extended with supply activities. Finally, a what-if analysis is conducted to evaluate how the quantity of products in the store evolves over time. This enables the identification of an optimal balance between customer purchasing behavior and supply strategies, helping to prevent both food waste due to oversupply and product shortages.",
        "subjects": "Machine Learning, Probability, Applications",
        "date": "2025-08-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.186506"
    },
    {
        "index": "#193",
        "title": "Nearly Tight Regret Bounds for Profit Maximization in Bilateral Trade",
        "link": "/arxiv/2509.22563",
        "arxiv_id": "2509.22563",
        "authors": "Simone Di Gregorio, Paul Dütting, Federico Fusco, Chris Schwiegelshohn",
        "summary": "Bilateral trade models the task of intermediating between two strategic agents, a seller and a buyer, willing to trade a good for which they hold private valuations. We study this problem from the perspective of a broker, in a regret minimization framework. At each time step, a new seller and buyer arrive, and the broker has to propose a mechanism that is incentive-compatible and individually rational, with the goal of maximizing profit. We propose a learning algorithm that guarantees a nearly tight $\\tilde{O}(\\sqrt{T})$ regret in the stochastic setting when seller and buyer valuations are drawn i.i.d. from a fixed and possibly correlated unknown distribution. We further show that it is impossible to achieve sublinear regret in the non-stationary scenario where valuations are generated upfront by an adversary. Our ambitious benchmark for these results is the best incentive-compatible and individually rational mechanism. This separates us from previous works on efficiency maximization in bilateral trade, where the benchmark is a single number: the best fixed price in hindsight. A particular challenge we face is that uniform convergence for all mechanisms' profits is impossible. We overcome this difficulty via a careful chaining analysis that proves convergence for a provably near-optimal mechanism at (essentially) optimal rate. We further showcase the broader applicability of our techniques by providing nearly optimal results for the joint ads problem.",
        "subjects": "Computer Science and Game Theory, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.190698"
    },
    {
        "index": "#194",
        "title": "Linear Causal Representation Learning by Topological Ordering, Pruning, and Disentanglement",
        "link": "/arxiv/2509.22553",
        "arxiv_id": "2509.22553",
        "authors": "Hao Chen, Lin Liu, Yu Guang Wang",
        "summary": "Causal representation learning (CRL) has garnered increasing interests from the causal inference and artificial intelligence community, due to its capability of disentangling potentially complex data-generating mechanism into causally interpretable latent features, by leveraging the heterogeneity of modern datasets. In this paper, we further contribute to the CRL literature, by focusing on the stylized linear structural causal model over the latent features and assuming a linear mixing function that maps latent features to the observed data or measurements. Existing linear CRL methods often rely on stringent assumptions, such as accessibility to single-node interventional data or restrictive distributional constraints on latent features and exogenous measurement noise. However, these prerequisites can be challenging to satisfy in certain scenarios. In this work, we propose a novel linear CRL algorithm that, unlike most existing linear CRL methods, operates under weaker assumptions about environment heterogeneity and data-generating distributions while still recovering latent causal features up to an equivalence class. We further validate our new algorithm via synthetic experiments and an interpretability analysis of large language models (LLMs), demonstrating both its superiority over competing methods in finite samples and its potential in integrating causality into AI.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.190978"
    },
    {
        "index": "#196",
        "title": "Metrics for Parametric Families of Networks",
        "link": "/arxiv/2509.22549",
        "arxiv_id": "2509.22549",
        "authors": "Mario Gómez, Guanqun Ma, Tom Needham, Bei Wang",
        "summary": "We introduce a general framework for analyzing data modeled as parameterized families of networks. Building on a Gromov-Wasserstein variant of optimal transport, we define a family of parameterized Gromov-Wasserstein distances for comparing such parametric data, including time-varying metric spaces induced by collective motion, temporally evolving weighted social networks, and random graph models. We establish foundational properties of these distances, showing that they subsume several existing metrics in the literature, and derive theoretical approximation guarantees. In particular, we develop computationally tractable lower bounds and relate them to graph statistics commonly used in random graph theory. Furthermore, we prove that our distances can be consistently approximated in random graph and random metric space settings via empirical estimates from generative models. Finally, we demonstrate the practical utility of our framework through a series of numerical experiments.",
        "subjects": "Machine Learning, Machine Learning, Metric Geometry",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.191610"
    },
    {
        "index": "#197",
        "title": "Debiased Front-Door Learners for Heterogeneous Effects",
        "link": "/arxiv/2509.22531",
        "arxiv_id": "2509.22531",
        "authors": "Yonghan Jung",
        "summary": "In observational settings where treatment and outcome share unmeasured confounders but an observed mediator remains unconfounded, the front-door (FD) adjustment identifies causal effects through the mediator. We study the heterogeneous treatment effect (HTE) under FD identification and introduce two debiased learners: FD-DR-Learner and FD-R-Learner. Both attain fast, quasi-oracle rates (i.e., performance comparable to an oracle that knows the nuisances) even when nuisance functions converge as slowly as n^-1/4. We provide error analyses establishing debiasedness and demonstrate robust empirical performance in synthetic studies and a real-world case study of primary seat-belt laws using Fatality Analysis Reporting System (FARS) dataset. Together, these results indicate that the proposed learners deliver reliable and sample-efficient HTE estimates in FD scenarios. The implementation is available at https://github.com/yonghanjung/FD-CATE. Keywords: Front-door adjustment; Heterogeneous treatment effects; Debiased learning; Quasi-oracle rates; Causal inference.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.191907"
    },
    {
        "index": "#198",
        "title": "Smoothing-Based Conformal Prediction for Balancing Efficiency and Interpretability",
        "link": "/arxiv/2509.22529",
        "arxiv_id": "2509.22529",
        "authors": "Mingyi Zheng, Hongyu Jiang, Yizhou Lu, Jiaye Teng",
        "summary": "Conformal Prediction (CP) is a distribution-free framework for constructing statistically rigorous prediction sets. While popular variants such as CD-split improve CP's efficiency, they often yield prediction sets composed of multiple disconnected subintervals, which are difficult to interpret. In this paper, we propose SCD-split, which incorporates smoothing operations into the CP framework. Such smoothing operations potentially help merge the subintervals, thus leading to interpretable prediction sets. Experimental results on both synthetic and real-world datasets demonstrate that SCD-split balances the interval length and the number of disconnected subintervals. Theoretically, under specific conditions, SCD-split provably reduces the number of disconnected subintervals while maintaining comparable coverage guarantees and interval length compared with CD-split.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.192198"
    },
    {
        "index": "#204",
        "title": "CausalKANs: interpretable treatment effect estimation with Kolmogorov-Arnold networks",
        "link": "/arxiv/2509.22467",
        "arxiv_id": "2509.22467",
        "authors": "Alejandro Almodóvar, Patricia A. Apellániz, Santiago Zazo, Juan Parras",
        "summary": "Deep neural networks achieve state-of-the-art performance in estimating heterogeneous treatment effects, but their opacity limits trust and adoption in sensitive domains such as medicine, economics, and public policy. Building on well-established and high-performing causal neural architectures, we propose causalKANs, a framework that transforms neural estimators of conditional average treatment effects (CATEs) into Kolmogorov--Arnold Networks (KANs). By incorporating pruning and symbolic simplification, causalKANs yields interpretable closed-form formulas while preserving predictive accuracy. Experiments on benchmark datasets demonstrate that causalKANs perform on par with neural baselines in CATE error metrics, and that even simple KAN variants achieve competitive performance, offering a favorable accuracy--interpretability trade-off. By combining reliability with analytic accessibility, causalKANs provide auditable estimators supported by closed-form expressions and interpretable plots, enabling trustworthy individualized decision-making in high-stakes settings. We release the code for reproducibility at https://github.com/aalmodovares/causalkans .",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.194004"
    },
    {
        "index": "#205",
        "title": "Universal Inverse Distillation for Matching Models with Real-Data Supervision (No GANs)",
        "link": "/arxiv/2509.22459",
        "arxiv_id": "2509.22459",
        "authors": "Nikita Kornilov, David Li, Tikhon Mavrin, Aleksei Leonov, Nikita Gushchin, Evgeny Burnaev, Iaroslav Koshelev, Alexander Korotin",
        "summary": "While achieving exceptional generative quality, modern diffusion, flow, and other matching models suffer from slow inference, as they require many steps of iterative generation. Recent distillation methods address this by training efficient one-step generators under the guidance of a pre-trained teacher model. However, these methods are often constrained to only one specific framework, e.g., only to diffusion or only to flow models. Furthermore, these methods are naturally data-free, and to benefit from the usage of real data, it is required to use an additional complex adversarial training with an extra discriminator model. In this paper, we present RealUID, a universal distillation framework for all matching models that seamlessly incorporates real data into the distillation procedure without GANs. Our RealUID approach offers a simple theoretical foundation that covers previous distillation methods for Flow Matching and Diffusion models, and is also extended to their modifications, such as Bridge Matching and Stochastic Interpolants.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.194332"
    },
    {
        "index": "#207",
        "title": "NeuroScalar: A Deep Learning Framework for Fast, Accurate, and In-the-Wild Cycle-Level Performance Prediction",
        "link": "/arxiv/2509.22410",
        "arxiv_id": "2509.22410",
        "authors": "Shayne Wadle, Yanxin Zhang, Vikas Singh, Karthikeyan Sankaralingam",
        "summary": "The evaluation of new microprocessor designs is constrained by slow, cycle-accurate simulators that rely on unrepresentative benchmark traces. This paper introduces a novel deep learning framework for high-fidelity, ``in-the-wild'' simulation on production hardware. Our core contribution is a DL model trained on microarchitecture-independent features to predict cycle-level performance for hypothetical processor designs. This unique approach allows the model to be deployed on existing silicon to evaluate future hardware. We propose a complete system featuring a lightweight hardware trace collector and a principled sampling strategy to minimize user impact. This system achieves a simulation speed of 5 MIPS on a commodity GPU, imposing a mere 0.1% performance overhead. Furthermore, our co-designed Neutrino on-chip accelerator improves performance by 85x over the GPU. We demonstrate that this framework enables accurate performance analysis and large-scale hardware A/B testing on a massive scale using real-world applications.",
        "subjects": "Hardware Architecture, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.194974"
    },
    {
        "index": "#209",
        "title": "Multidimensional Uncertainty Quantification via Optimal Transport",
        "link": "/arxiv/2509.22380",
        "arxiv_id": "2509.22380",
        "authors": "Nikita Kotelevskii, Maiya Goloburda, Vladimir Kondratyev, Alexander Fishkov, Mohsen Guizani, Eric Moulines, Maxim Panov",
        "summary": "Most uncertainty quantification (UQ) approaches provide a single scalar value as a measure of model reliability. However, different uncertainty measures could provide complementary information on the prediction confidence. Even measures targeting the same type of uncertainty (e.g., ensemble-based and density-based measures of epistemic uncertainty) may capture different failure modes. We take a multidimensional view on UQ by stacking complementary UQ measures into a vector. Such vectors are assigned with Monge-Kantorovich ranks produced by an optimal-transport-based ordering method. The prediction is then deemed more uncertain than the other if it has a higher rank. The resulting VecUQ-OT algorithm uses entropy-regularized optimal transport. The transport map is learned on vectors of scores from in-distribution data and, by design, applies to unseen inputs, including out-of-distribution cases, without retraining. Our framework supports flexible non-additive uncertainty fusion (including aleatoric and epistemic components). It yields a robust ordering for downstream tasks such as selective prediction, misclassification detection, out-of-distribution detection, and selective generation. Across synthetic, image, and text data, VecUQ-OT shows high efficiency even when individual measures fail. The code for the method is available at: https://github.com/stat-ml/multidimensional_uncertainty.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.195582"
    },
    {
        "index": "#210",
        "title": "Multi-channel convolutional neural quantum embedding",
        "link": "/arxiv/2509.22355",
        "arxiv_id": "2509.22355",
        "authors": "Yujin Kim, Changjae Im, Taehyun Kim, Tak Hur, Daniel K. Park",
        "summary": "Classification using variational quantum circuits is a promising frontier in quantum machine learning. Quantum supervised learning (QSL) applied to classical data using variational quantum circuits involves embedding the data into a quantum Hilbert space and optimizing the circuit parameters to train the measurement process. In this context, the efficacy of QSL is inherently influenced by the selection of quantum embedding. In this study, we introduce a classical-quantum hybrid approach for optimizing quantum embedding beyond the limitations of the standard circuit model of quantum computation (i.e., completely positive and trace-preserving maps) for general multi-channel data. We benchmark the performance of various models in our framework using the CIFAR-10 and Tiny ImageNet datasets and provide theoretical analyses that guide model design and optimization.",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.195890"
    },
    {
        "index": "#212",
        "title": "Preventing Model Collapse Under Overparametrization: Optimal Mixing Ratios for Interpolation Learning and Ridge Regression",
        "link": "/arxiv/2509.22341",
        "arxiv_id": "2509.22341",
        "authors": "Anvit Garg, Sohom Bhattacharya, Pragya Sur",
        "summary": "Model collapse occurs when generative models degrade after repeatedly training on their own synthetic outputs. We study this effect in overparameterized linear regression in a setting where each iteration mixes fresh real labels with synthetic labels drawn from the model fitted in the previous iteration. We derive precise generalization error formulae for minimum-$\\ell_2$-norm interpolation and ridge regression under this iterative scheme. Our analysis reveals intriguing properties of the optimal mixing weight that minimizes long-term prediction error and provably prevents model collapse. For instance, in the case of min-$\\ell_2$-norm interpolation, we establish that the optimal real-data proportion converges to the reciprocal of the golden ratio for fairly general classes of covariate distributions. Previously, this property was known only for ordinary least squares, and additionally in low dimensions. For ridge regression, we further analyze two popular model classes -- the random-effects model and the spiked covariance model -- demonstrating how spectral geometry governs optimal weighting. In both cases, as well as for isotropic features, we uncover that the optimal mixing ratio should be at least one-half, reflecting the necessity of favoring real-data over synthetic. We validate our theoretical results with extensive simulations.",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory, Methodology",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.196511"
    },
    {
        "index": "#220",
        "title": "Incorporating priors in learning: a random matrix study under a teacher-student framework",
        "link": "/arxiv/2509.22124",
        "arxiv_id": "2509.22124",
        "authors": "Malik Tiomoko, Ekkehard Schnoor",
        "summary": "Regularized linear regression is central to machine learning, yet its high-dimensional behavior with informative priors remains poorly understood. We provide the first exact asymptotic characterization of training and test risks for maximum a posteriori (MAP) regression with Gaussian priors centered at a domain-informed initialization. Our framework unifies ridge regression, least squares, and prior-informed estimators, and -- using random matrix theory -- yields closed-form risk formulas that expose the bias-variance-prior tradeoff, explain double descent, and quantify prior mismatch. We also identify a closed-form minimizer of test risk, enabling a simple estimator of the optimal regularization parameter. Simulations confirm the theory with high accuracy. By connecting Bayesian priors, classical regularization, and modern asymptotics, our results provide both conceptual clarity and practical guidance for learning with structured prior knowledge.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.198899"
    },
    {
        "index": "#221",
        "title": "Direct Bias-Correction Term Estimation for Propensity Scores and Average Treatment Effect Estimation",
        "link": "/arxiv/2509.22122",
        "arxiv_id": "2509.22122",
        "authors": "Masahiro Kato",
        "summary": "This study considers the estimation of the average treatment effect (ATE). For ATE estimation, we estimate the propensity score through direct bias-correction term estimation. Let $\\{(X_i, D_i, Y_i)\\}_{i=1}^{n}$ be the observations, where $X_i \\in \\mathbb{R}^p$ denotes $p$-dimensional covariates, $D_i \\in \\{0, 1\\}$ denotes a binary treatment assignment indicator, and $Y_i \\in \\mathbb{R}$ is an outcome. In ATE estimation, the bias-correction term $h_0(X_i, D_i) = \\frac{1[D_i = 1]}{e_0(X_i)} - \\frac{1[D_i = 0]}{1 - e_0(X_i)}$ plays an important role, where $e_0(X_i)$ is the propensity score, the probability of being assigned treatment $1$. In this study, we propose estimating $h_0$ (or equivalently the propensity score $e_0$) by directly minimizing the prediction error of $h_0$. Since the bias-correction term $h_0$ is essential for ATE estimation, this direct approach is expected to improve estimation accuracy for the ATE. For example, existing studies often employ maximum likelihood or covariate balancing to estimate $e_0$, but these approaches may not be optimal for accurately estimating $h_0$ or the ATE. We present a general framework for this direct bias-correction term estimation approach from the perspective of Bregman divergence minimization and conduct simulation studies to evaluate the effectiveness of the proposed method.",
        "subjects": "Econometrics, Machine Learning, Statistics Theory, Methodology, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.199194"
    },
    {
        "index": "#223",
        "title": "Exploring the Early Universe with Deep Learning",
        "link": "/arxiv/2509.22018",
        "arxiv_id": "2509.22018",
        "authors": "Emmanuel de Salis, Massimo De Santis, Davide Piras, Sambit K. Giri, Michele Bianco, Nicolas Cerardi, Philipp Denzel, Merve Selcuk-Simsek, Kelley M. Hess, M. Carmen Toribio, Franz Kirsten, Hatem Ghorbel",
        "summary": "Hydrogen is the most abundant element in our Universe. The first generation of stars and galaxies produced photons that ionized hydrogen gas, driving a cosmological event known as the Epoch of Reionization (EoR). The upcoming Square Kilometre Array Observatory (SKAO) will map the distribution of neutral hydrogen during this era, aiding in the study of the properties of these first-generation objects. Extracting astrophysical information will be challenging, as SKAO will produce a tremendous amount of data where the hydrogen signal will be contaminated with undesired foreground contamination and instrumental systematics. To address this, we develop the latest deep learning techniques to extract information from the 2D power spectra of the hydrogen signal expected from SKAO. We apply a series of neural network models to these measurements and quantify their ability to predict the history of cosmic hydrogen reionization, which is connected to the increasing number and efficiency of early photon sources. We show that the study of the early Universe benefits from modern deep learning technology. In particular, we demonstrate that dedicated machine learning algorithms can achieve more than a $0.95$ $R^2$ score on average in recovering the reionization history. This enables accurate and precise cosmological and astrophysical inference of structure formation in the early Universe.",
        "subjects": "Cosmology and Nongalactic Astrophysics, Instrumentation and Methods for Astrophysics, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.199862"
    },
    {
        "index": "#224",
        "title": "A Random Matrix Perspective of Echo State Networks: From Precise Bias--Variance Characterization to Optimal Regularization",
        "link": "/arxiv/2509.22011",
        "arxiv_id": "2509.22011",
        "authors": "Yessin Moakher, Malik Tiomoko, Cosme Louart, Zhenyu Liao",
        "summary": "We present a rigorous asymptotic analysis of Echo State Networks (ESNs) in a teacher student setting with a linear teacher with oracle weights. Leveraging random matrix theory, we derive closed form expressions for the asymptotic bias, variance, and mean-squared error (MSE) as functions of the input statistics, the oracle vector, and the ridge regularization parameter. The analysis reveals two key departures from classical ridge regression: (i) ESNs do not exhibit double descent, and (ii) ESNs attain lower MSE when both the number of training samples and the teacher memory length are limited. We further provide an explicit formula for the optimal regularization in the identity input covariance case, and propose an efficient numerical scheme to compute the optimum in the general case. Together, these results offer interpretable theory and practical guidelines for tuning ESNs, helping reconcile recent empirical observations with provable performance guarantees",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.200158"
    },
    {
        "index": "#226",
        "title": "A Nonparametric Discrete Hawkes Model with a Collapsed Gaussian-Process Prior",
        "link": "/arxiv/2509.21996",
        "arxiv_id": "2509.21996",
        "authors": "Trinnhallen Brisley, Gordon Ross, Daniel Paulin",
        "summary": "Hawkes process models are used in settings where past events increase the likelihood of future events occurring. Many applications record events as counts on a regular grid, yet discrete-time Hawkes models remain comparatively underused and are often constrained by fixed-form baselines and excitation kernels. In particular, there is a lack of flexible, nonparametric treatments of both the baseline and the excitation in discrete time. To this end, we propose the Gaussian Process Discrete Hawkes Process (GP-DHP), a nonparametric framework that places Gaussian process priors on both the baseline and the excitation and performs inference through a collapsed latent representation. This yields smooth, data-adaptive structure without prespecifying trends, periodicities, or decay shapes, and enables maximum a posteriori (MAP) estimation with near-linear-time \\(O(T\\log T)\\) complexity. A closed-form projection recovers interpretable baseline and excitation functions from the optimized latent trajectory. In simulations, GP-DHP recovers diverse excitation shapes and evolving baselines. In case studies on U.S. terrorism incidents and weekly Cryptosporidiosis counts, it improves test predictive log-likelihood over standard parametric discrete Hawkes baselines while capturing bursts, delays, and seasonal background variation. The results indicate that flexible discrete-time self-excitation can be achieved without sacrificing scalability or interpretability.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.200751"
    },
    {
        "index": "#230",
        "title": "Learnable Conformal Prediction with Context-Aware Nonconformity Functions for Robotic Planning and Perception",
        "link": "/arxiv/2509.21955",
        "arxiv_id": "2509.21955",
        "authors": "Divake Kumar, Sina Tayebati, Francesco Migliarba, Ranganath Krishnan, Amit Ranjan Trivedi",
        "summary": "Deep learning models in robotics often output point estimates with poorly calibrated confidences, offering no native mechanism to quantify predictive reliability under novel, noisy, or out-of-distribution inputs. Conformal prediction (CP) addresses this gap by providing distribution-free coverage guarantees, yet its reliance on fixed nonconformity scores ignores context and can yield intervals that are overly conservative or unsafe. We address this with Learnable Conformal Prediction (LCP), which replaces fixed scores with a lightweight neural function that leverages geometric, semantic, and task-specific features to produce context-aware uncertainty sets. LCP maintains CP's theoretical guarantees while reducing prediction set sizes by 18% in classification, tightening detection intervals by 52%, and improving path planning safety from 72% to 91% success with minimal overhead. Across three robotic tasks on seven benchmarks, LCP consistently outperforms Standard CP and ensemble baselines. In classification on CIFAR-100 and ImageNet, it achieves smaller set sizes (4.7-9.9% reduction) at target coverage. For object detection on COCO, BDD100K, and Cityscapes, it produces 46-54% tighter bounding boxes. In path planning through cluttered environments, it improves success to 91.5% with only 4.5% path inflation, compared to 12.2% for Standard CP. The method is lightweight (approximately 4.8% runtime overhead, 42 KB memory) and supports online adaptation, making it well suited to resource-constrained autonomous systems. Hardware evaluation shows LCP adds less than 1% memory and 15.9% inference overhead, yet sustains 39 FPS on detection tasks while being 7.4 times more energy-efficient than ensembles.",
        "subjects": "Robotics, Machine Learning, Statistics Theory",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.201998"
    },
    {
        "index": "#232",
        "title": "Sequential 1-bit Mean Estimation with Near-Optimal Sample Complexity",
        "link": "/arxiv/2509.21940",
        "arxiv_id": "2509.21940",
        "authors": "Ivan Lau, Jonathan Scarlett",
        "summary": "In this paper, we study the problem of distributed mean estimation with 1-bit communication constraints. We propose a mean estimator that is based on (randomized and sequentially-chosen) interval queries, whose 1-bit outcome indicates whether the given sample lies in the specified interval. Our estimator is $(\\epsilon, \\delta)$-PAC for all distributions with bounded mean ($-\\lambda \\le \\mathbb{E}(X) \\le \\lambda $) and variance ($\\mathrm{Var}(X) \\le \\sigma^2$) for some known parameters $\\lambda$ and $\\sigma$. We derive a sample complexity bound $\\widetilde{O}\\big( \\frac{\\sigma^2}{\\epsilon^2}\\log\\frac{1}{\\delta} + \\log\\frac{\\lambda}{\\sigma}\\big)$, which matches the minimax lower bound for the unquantized setting up to logarithmic factors and the additional $\\log\\frac{\\lambda}{\\sigma}$ term that we show to be unavoidable. We also establish an adaptivity gap for interval-query based estimators: the best non-adaptive mean estimator is considerably worse than our adaptive mean estimator for large $\\frac{\\lambda}{\\sigma}$. Finally, we give tightened sample complexity bounds for distributions with stronger tail decay, and present additional variants that (i) handle an unknown sampling budget (ii) adapt to the unknown true variance given (possibly loose) upper and lower bounds on the variance, and (iii) use only two stages of adaptivity at the expense of more complicated (non-interval) queries.",
        "subjects": "Machine Learning, Information Theory, Machine Learning, Statistics Theory",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.202631"
    },
    {
        "index": "#233",
        "title": "Error Analysis of Discrete Flow with Generator Matching",
        "link": "/arxiv/2509.21906",
        "arxiv_id": "2509.21906",
        "authors": "Zhengyan Wan, Yidong Ouyang, Qiang Yao, Liyan Xie, Fang Fang, Hongyuan Zha, Guang Cheng",
        "summary": "Discrete flow models offer a powerful framework for learning distributions over discrete state spaces and have demonstrated superior performance compared to the discrete diffusion model. However, their convergence properties and error analysis remain largely unexplored. In this work, we develop a unified framework grounded in stochastic calculus theory to systematically investigate the theoretical properties of discrete flow. Specifically, we derive the KL divergence of two path measures regarding two continuous-time Markov chains (CTMCs) with different transition rates by developing a novel Girsanov-type theorem, and provide a comprehensive analysis that encompasses the error arising from transition rate estimation and early stopping, where the first type of error has rarely been analyzed by existing works. Unlike discrete diffusion models, discrete flow incurs no truncation error caused by truncating the time horizon in the noising process. Building on generator matching and uniformization, we establish non-asymptotic error bounds for distribution estimation. Our results provide the first error analysis for discrete flow models.",
        "subjects": "Statistics Theory, Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.202953"
    },
    {
        "index": "#236",
        "title": "Causal-EPIG: A Prediction-Oriented Active Learning Framework for CATE Estimation",
        "link": "/arxiv/2509.21866",
        "arxiv_id": "2509.21866",
        "authors": "Erdun Gao, Jake Fawkes, Dino Sejdinovic",
        "summary": "Estimating the Conditional Average Treatment Effect (CATE) is often constrained by the high cost of obtaining outcome measurements, making active learning essential. However, conventional active learning strategies suffer from a fundamental objective mismatch. They are designed to reduce uncertainty in model parameters or in observable factual outcomes, failing to directly target the unobservable causal quantities that are the true objects of interest. To address this misalignment, we introduce the principle of causal objective alignment, which posits that acquisition functions should target unobservable causal quantities, such as the potential outcomes and the CATE, rather than indirect proxies. We operationalize this principle through the Causal-EPIG framework, which adapts the information-theoretic criterion of Expected Predictive Information Gain (EPIG) to explicitly quantify the value of a query in terms of reducing uncertainty about unobservable causal quantities. From this unified framework, we derive two distinct strategies that embody a fundamental trade-off: a comprehensive approach that robustly models the full causal mechanisms via the joint potential outcomes, and a focused approach that directly targets the CATE estimand for maximum sample efficiency. Extensive experiments demonstrate that our strategies consistently outperform standard baselines, and crucially, reveal that the optimal strategy is context-dependent, contingent on the base estimator and data complexity. Our framework thus provides a principled guide for sample-efficient CATE estimation in practice.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.203909"
    },
    {
        "index": "#241",
        "title": "Reinforcement Learning Based Traffic Signal Design to Minimize Queue Lengths",
        "link": "/arxiv/2509.21745",
        "arxiv_id": "2509.21745",
        "authors": "Anirud Nandakumar, Chayan Banerjee, Lelitha Devi Vanajakshi",
        "summary": "Efficient traffic signal control (TSC) is crucial for reducing congestion, travel delays, pollution, and for ensuring road safety. Traditional approaches, such as fixed signal control and actuated control, often struggle to handle dynamic traffic patterns. In this study, we propose a novel adaptive TSC framework that leverages Reinforcement Learning (RL), using the Proximal Policy Optimization (PPO) algorithm, to minimize total queue lengths across all signal phases. The challenge of efficiently representing highly stochastic traffic conditions for an RL controller is addressed through multiple state representations, including an expanded state space, an autoencoder representation, and a K-Planes-inspired representation. The proposed algorithm has been implemented using the Simulation of Urban Mobility (SUMO) traffic simulator and demonstrates superior performance over both traditional methods and other conventional RL-based approaches in reducing queue lengths. The best performing configuration achieves an approximately 29% reduction in average queue lengths compared to the traditional Webster method. Furthermore, comparative evaluation of alternative reward formulations demonstrates the effectiveness of the proposed queue-based approach, showcasing the potential for scalable and adaptive urban traffic management.",
        "subjects": "Systems and Control, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.205359"
    },
    {
        "index": "#244",
        "title": "Noise-to-Notes: Diffusion-based Generation and Refinement for Automatic Drum Transcription",
        "link": "/arxiv/2509.21739",
        "arxiv_id": "2509.21739",
        "authors": "Michael Yeung, Keisuke Toyama, Toya Teramoto, Shusuke Takahashi, Tamaki Kojima",
        "summary": "Automatic drum transcription (ADT) is traditionally formulated as a discriminative task to predict drum events from audio spectrograms. In this work, we redefine ADT as a conditional generative task and introduce Noise-to-Notes (N2N), a framework leveraging diffusion modeling to transform audio-conditioned Gaussian noise into drum events with associated velocities. This generative diffusion approach offers distinct advantages, including a flexible speed-accuracy trade-off and strong inpainting capabilities. However, the generation of binary onset and continuous velocity values presents a challenge for diffusion models, and to overcome this, we introduce an Annealed Pseudo-Huber loss to facilitate effective joint optimization. Finally, to augment low-level spectrogram features, we propose incorporating features extracted from music foundation models (MFMs), which capture high-level semantic information and enhance robustness to out-of-domain drum audio. Experimental results demonstrate that including MFM features significantly improves robustness and N2N establishes a new state-of-the-art performance across multiple ADT benchmarks.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.206280"
    },
    {
        "index": "#247",
        "title": "Multi-modal Bayesian Neural Network Surrogates with Conjugate Last-Layer Estimation",
        "link": "/arxiv/2509.21711",
        "arxiv_id": "2509.21711",
        "authors": "Ian Taylor, Juliane Mueller, Julie Bessac",
        "summary": "As data collection and simulation capabilities advance, multi-modal learning, the task of learning from multiple modalities and sources of data, is becoming an increasingly important area of research. Surrogate models that learn from data of multiple auxiliary modalities to support the modeling of a highly expensive quantity of interest have the potential to aid outer loop applications such as optimization, inverse problems, or sensitivity analyses when multi-modal data are available. We develop two multi-modal Bayesian neural network surrogate models and leverage conditionally conjugate distributions in the last layer to estimate model parameters using stochastic variational inference (SVI). We provide a method to perform this conjugate SVI estimation in the presence of partially missing observations. We demonstrate improved prediction accuracy and uncertainty quantification compared to uni-modal surrogate models for both scalar and time series data.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.207286"
    },
    {
        "index": "#248",
        "title": "SADA: Safe and Adaptive Inference with Multiple Black-Box Predictions",
        "link": "/arxiv/2509.21707",
        "arxiv_id": "2509.21707",
        "authors": "Jiawei Shan, Yiming Dong, Jiwei Zhao",
        "summary": "Real-world applications often face scarce labeled data due to the high cost and time requirements of gold-standard experiments, whereas unlabeled data are typically abundant. With the growing adoption of machine learning techniques, it has become increasingly feasible to generate multiple predicted labels using a variety of models and algorithms, including deep learning, large language models, and generative AI. In this paper, we propose a novel approach that safely and adaptively aggregates multiple black-box predictions with unknown quality while preserving valid statistical inference. Our method provides two key guarantees: (i) it never performs worse than using the labeled data alone, regardless of the quality of the predictions; and (ii) if any one of the predictions (without knowing which one) perfectly fits the ground truth, the algorithm adaptively exploits this to achieve either a faster convergence rate or the semiparametric efficiency bound. We demonstrate the effectiveness of the proposed algorithm through experiments on both synthetic and benchmark datasets.",
        "subjects": "Machine Learning, Machine Learning, Methodology",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.207577"
    },
    {
        "index": "#249",
        "title": "HuLA: Prosody-Aware Anti-Spoofing with Multi-Task Learning for Expressive and Emotional Synthetic Speech",
        "link": "/arxiv/2509.21676",
        "arxiv_id": "2509.21676",
        "authors": "Aurosweta Mahapatra, Ismail Rasim Ulgen, Berrak Sisman",
        "summary": "Current anti-spoofing systems remain vulnerable to expressive and emotional synthetic speech, since they rarely leverage prosody as a discriminative cue. Prosody is central to human expressiveness and emotion, and humans instinctively use prosodic cues such as F0 patterns and voiced/unvoiced structure to distinguish natural from synthetic speech. In this paper, we propose HuLA, a two-stage prosody-aware multi-task learning framework for spoof detection. In Stage 1, a self-supervised learning (SSL) backbone is trained on real speech with auxiliary tasks of F0 prediction and voiced/unvoiced classification, enhancing its ability to capture natural prosodic variation similar to human perceptual learning. In Stage 2, the model is jointly optimized for spoof detection and prosody tasks on both real and synthetic data, leveraging prosodic awareness to detect mismatches between natural and expressive synthetic speech. Experiments show that HuLA consistently outperforms strong baselines on challenging out-of-domain dataset, including expressive, emotional, and cross-lingual attacks. These results demonstrate that explicit prosodic supervision, combined with SSL embeddings, substantially improves robustness against advanced synthetic speech attacks.",
        "subjects": "Audio and Speech Processing, Machine Learning, Sound",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.207881"
    },
    {
        "index": "#251",
        "title": "Generating Stable Placements via Physics-guided Diffusion Models",
        "link": "/arxiv/2509.21664",
        "arxiv_id": "2509.21664",
        "authors": "Philippe Nadeau, Miguel Rogel, Ivan Bilić, Ivan Petrović, Jonathan Kelly",
        "summary": "Stably placing an object in a multi-object scene is a fundamental challenge in robotic manipulation, as placements must be penetration-free, establish precise surface contact, and result in a force equilibrium. To assess stability, existing methods rely on running a simulation engine or resort to heuristic, appearance-based assessments. In contrast, our approach integrates stability directly into the sampling process of a diffusion model. To this end, we query an offline sampling-based planner to gather multi-modal placement labels and train a diffusion model to generate stable placements. The diffusion model is conditioned on scene and object point clouds, and serves as a geometry-aware prior. We leverage the compositional nature of score-based generative models to combine this learned prior with a stability-aware loss, thereby increasing the likelihood of sampling from regions of high stability. Importantly, this strategy requires no additional re-training or fine-tuning, and can be directly applied to off-the-shelf models. We evaluate our method on four benchmark scenes where stability can be accurately computed. Our physics-guided models achieve placements that are 56% more robust to forceful perturbations while reducing runtime by 47% compared to a state-of-the-art geometric method.",
        "subjects": "Robotics, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.208518"
    },
    {
        "index": "#252",
        "title": "Automating Sensor Characterization with Bayesian Optimization",
        "link": "/arxiv/2509.21661",
        "arxiv_id": "2509.21661",
        "authors": "J. Cuevas-Zepeda, C. Chavez, J. Estrada, J. Noonan, B. D. Nord, N. Saffold, M. Sofo-Haro, R. Spinola e Castro, S. Trivedi",
        "summary": "The development of novel instrumentation requires an iterative cycle with three stages: design, prototyping, and testing. Recent advancements in simulation and nanofabrication techniques have significantly accelerated the design and prototyping phases. Nonetheless, detector characterization continues to be a major bottleneck in device development. During the testing phase, a significant time investment is required to characterize the device in different operating conditions and find optimal operating parameters. The total effort spent on characterization and parameter optimization can occupy a year or more of an expert's time. In this work, we present a novel technique for automated sensor calibration that aims to accelerate the testing stage of the development cycle. This technique leverages closed-loop Bayesian optimization (BO), using real-time measurements to guide parameter selection and identify optimal operating states. We demonstrate the method with a novel low-noise CCD, showing that the machine learning-driven tool can efficiently characterize and optimize operation of the sensor in a couple of days without supervision of a device expert.",
        "subjects": "Instrumentation and Detectors, Instrumentation and Methods for Astrophysics, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.208866"
    },
    {
        "index": "#253",
        "title": "A regret minimization approach to fixed-point iterations",
        "link": "/arxiv/2509.21653",
        "arxiv_id": "2509.21653",
        "authors": "Joon Kwon",
        "summary": "We propose a conversion scheme that turns regret minimizing algorithms into fixed point iterations, with convergence guarantees following from regret bounds. The resulting iterations can be seen as a grand extension of the classical Krasnoselskii--Mann iterations, as the latter are recovered by converting the Online Gradient Descent algorithm. This approach yields new simple iterations for finding fixed points of non-self operators. We also focus on converting algorithms from the AdaGrad family of regret minimizers, and thus obtain fixed point iterations with adaptive guarantees of a new kind. Numerical experiments on various problems demonstrate faster convergence of AdaGrad-based fixed point iterations over Krasnoselskii--Mann iterations.",
        "subjects": "Optimization and Control, Machine Learning, Numerical Analysis",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.209134"
    },
    {
        "index": "#254",
        "title": "Automated Machine Learning Pipeline for Training and Analysis Using Large Language Models",
        "link": "/arxiv/2509.21647",
        "arxiv_id": "2509.21647",
        "authors": "Adam Lahouari, Jutta Rogal, Mark E. Tuckerman",
        "summary": "Machine learning interatomic potentials (MLIPs) have become powerful tools to extend molecular simulations beyond the limits of quantum methods, offering near-quantum accuracy at much lower computational cost. Yet, developing reliable MLIPs remains difficult because it requires generating high-quality datasets, preprocessing atomic structures, and carefully training and validating models. In this work, we introduce an Automated Machine Learning Pipeline (AMLP) that unifies the entire workflow from dataset creation to model validation. AMLP employs large-language-model agents to assist with electronic-structure code selection, input preparation, and output conversion, while its analysis suite (AMLP-Analysis), based on ASE supports a range of molecular simulations. The pipeline is built on the MACE architecture and validated on acridine polymorphs, where, with a straightforward fine-tuning of a foundation model, mean absolute errors of ~1.7 meV/atom in energies and ~7.0 meV/Å in forces are achieved. The fitted MLIP reproduces DFT geometries with sub-Å accuracy and demonstrates stability during molecular dynamics simulations in the microcanonical and canonical ensembles.",
        "subjects": "Materials Science, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.209411"
    },
    {
        "index": "#259",
        "title": "Effective continuous equations for adaptive SGD: a stochastic analysis view",
        "link": "/arxiv/2509.21614",
        "arxiv_id": "2509.21614",
        "authors": "Luca Callisti, Marco Romito, Francesco Triggiano",
        "summary": "We present a theoretical analysis of some popular adaptive Stochastic Gradient Descent (SGD) methods in the small learning rate regime. Using the stochastic modified equations framework introduced by Li et al., we derive effective continuous stochastic dynamics for these methods. Our key contribution is that sampling-induced noise in SGD manifests in the limit as independent Brownian motions driving the parameter and gradient second momentum evolutions. Furthermore, extending the approach of Malladi et al., we investigate scaling rules between the learning rate and key hyperparameters in adaptive methods, characterising all non-trivial limiting dynamics.",
        "subjects": "Machine Learning, Machine Learning, Probability",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.210993"
    },
    {
        "index": "#264",
        "title": "IndiSeek learns information-guided disentangled representations",
        "link": "/arxiv/2509.21584",
        "arxiv_id": "2509.21584",
        "authors": "Yu Gui, Cong Ma, Zongming Ma",
        "summary": "Learning disentangled representations is a fundamental task in multi-modal learning. In modern applications such as single-cell multi-omics, both shared and modality-specific features are critical for characterizing cell states and supporting downstream analyses. Ideally, modality-specific features should be independent of shared ones while also capturing all complementary information within each modality. This tradeoff is naturally expressed through information-theoretic criteria, but mutual-information-based objectives are difficult to estimate reliably, and their variational surrogates often underperform in practice. In this paper, we introduce IndiSeek, a novel disentangled representation learning approach that addresses this challenge by combining an independence-enforcing objective with a computationally efficient reconstruction loss that bounds conditional mutual information. This formulation explicitly balances independence and completeness, enabling principled extraction of modality-specific features. We demonstrate the effectiveness of IndiSeek on synthetic simulations, a CITE-seq dataset and multiple real-world multi-modal benchmarks.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.212526"
    },
    {
        "index": "#265",
        "title": "General Pruning Criteria for Fast SBL",
        "link": "/arxiv/2509.21572",
        "arxiv_id": "2509.21572",
        "authors": "Jakob Möderl, Erik Leitinger, Bernard Henri Fleury",
        "summary": "Sparse Bayesian learning (SBL) associates to each weight in the underlying linear model a hyperparameter by assuming that each weight is Gaussian distributed with zero mean and precision (inverse variance) equal to its associated hyperparameter. The method estimates the hyperparameters by marginalizing out the weights and performing (marginalized) maximum likelihood (ML) estimation. SBL returns many hyperparameter estimates to diverge to infinity, effectively setting the estimates of the corresponding weights to zero (i.e., pruning the corresponding weights from the model) and thereby yielding a sparse estimate of the weight vector. In this letter, we analyze the marginal likelihood as function of a single hyperparameter while keeping the others fixed, when the Gaussian assumptions on the noise samples and the weight distribution that underlies the derivation of SBL are weakened. We derive sufficient conditions that lead, on the one hand, to finite hyperparameter estimates and, on the other, to infinite ones. Finally, we show that in the Gaussian case, the two conditions are complementary and coincide with the pruning condition of fast SBL (F-SBL), thereby providing additional insights into this algorithm.",
        "subjects": "Machine Learning, Machine Learning, Signal Processing",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.212816"
    },
    {
        "index": "#272",
        "title": "Functional Encryption in Secure Neural Network Training: Data Leakage and Practical Mitigations",
        "link": "/arxiv/2509.21497",
        "arxiv_id": "2509.21497",
        "authors": "Alexandru Ioniţă, Andreea Ioniţă",
        "summary": "With the increased interest in artificial intelligence, Machine Learning as a Service provides the infrastructure in the Cloud for easy training, testing, and deploying models. However, these systems have a major privacy issue: uploading sensitive data to the Cloud, especially during training. Therefore, achieving secure Neural Network training has been on many researchers' minds lately. More and more solutions for this problem are built around a main pillar: Functional Encryption (FE). Although these approaches are very interesting and offer a new perspective on ML training over encrypted data, some vulnerabilities do not seem to be taken into consideration. In our paper, we present an attack on neural networks that uses FE for secure training over encrypted data. Our approach uses linear programming to reconstruct the original input, unveiling the previous security promises. To address the attack, we propose two solutions for secure training and inference that involve the client during the computation phase. One approach ensures security without relying on encryption, while the other uses function-hiding inner-product techniques.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.214956"
    },
    {
        "index": "#273",
        "title": "Context-Aware Hybrid Routing in Bluetooth Mesh Networks Using Multi-Model Machine Learning and AODV Fallback",
        "link": "/arxiv/2509.21490",
        "arxiv_id": "2509.21490",
        "authors": "Md Sajid Islam, Tanvir Hasan",
        "summary": "Bluetooth-based mesh networks offer a promising infrastructure for offline communication in emergency and resource constrained scenarios. However, traditional routing strategies such as Ad hoc On-Demand Distance Vector (AODV) often degrade under congestion and dynamic topological changes. This study proposes a hybrid intelligent routing framework that augments AODV with supervised machine learning to improve next-hop selection under varied network constraints. The framework integrates four predictive models: a delivery success classifier, a TTL regressor, a delay regressor, and a forwarder suitability classifier, into a unified scoring mechanism that dynamically ranks neighbors during multi-hop message transmission. A simulation environment with stationary node deployments was developed, incorporating buffer constraints and device heterogeneity to evaluate three strategies: baseline AODV, a partial hybrid ML model (ABC), and the full hybrid ML model (ABCD). Across ten scenarios, the Hybrid ABCD model achieves approximately 99.97 percent packet delivery under these controlled conditions, significantly outperforming both the baseline and intermediate approaches. The results demonstrate that lightweight, explainable machine learning models can enhance routing reliability and adaptability in Bluetooth mesh networks, particularly in infrastructure-less environments where delivery success is prioritized over latency constraints.",
        "subjects": "Networking and Internet Architecture, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.215217"
    },
    {
        "index": "#287",
        "title": "Data-driven approach to the design of complexing agents for trivalent transuranium elements",
        "link": "/arxiv/2509.21362",
        "arxiv_id": "2509.21362",
        "authors": "Kirill V. Karpov, Ivan S. Pikulin, Grigory V. Bokov, Artem A. Mitrofanov",
        "summary": "The properties of complexes with transuranium elements have long been the object of research in various fields of chemistry. However, their experimental study is complicated by their rarity, high cost and special conditions necessary for working with such elements, and the complexity of quantum chemical calculations does not allow their use for large systems. To overcome these problems, we used modern machine learning methods to create a novel neural network architecture that allows to use available experimental data on a number of elements and thus significantly improve the quality of the resulting models. We also described the applicability domain of the presented model and identified the molecular fragments that most influence the stability of the complexes.",
        "subjects": "Chemical Physics, Machine Learning",
        "date": "2025-09-21",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.219538"
    },
    {
        "index": "#289",
        "title": "Accurate typhoon intensity forecasts using a non-iterative spatiotemporal transformer model",
        "link": "/arxiv/2509.21349",
        "arxiv_id": "2509.21349",
        "authors": "Hongyu Qu, Hongxiong Xu, Lin Dong, Chunyi Xiang, Gaozhen Nie",
        "summary": "Accurate forecasting of tropical cyclone (TC) intensity - particularly during periods of rapid intensification and rapid weakening - remains a challenge for operational meteorology, with high-stakes implications for disaster preparedness and infrastructure resilience. Recent advances in machine learning have yielded notable progress in TC prediction; however, most existing systems provide forecasts that degrade rapidly in extreme regimes and lack long-range consistency. Here we introduce TIFNet, a transformer-based forecasting model that generates non-iterative, 5-day intensity trajectories by integrating high-resolution global forecasts with a historical-evolution fusion mechanism. Trained on reanalysis data and fine-tuned with operational data, TIFNet consistently outperforms operational numerical models across all forecast horizons, delivering robust improvements across weak, strong, and super typhoon categories. In rapid intensity change regimes - long regarded as the most difficult to forecast - TIFNet reduces forecast error by 29-43% relative to current operational baselines. These results represent a substantial advance in artificial-intelligence-based TC intensity forecasting, especially under extreme conditions where traditional models consistently underperform.",
        "subjects": "Atmospheric and Oceanic Physics, Machine Learning",
        "date": "2025-09-18",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.220190"
    },
    {
        "index": "#290",
        "title": "Spiking Neural Networks for Mental Workload Classification with a Multimodal Approach",
        "link": "/arxiv/2509.21346",
        "arxiv_id": "2509.21346",
        "authors": "Jiahui An, Sara Irina Fabrikant, Giacomo Indiveri, Elisa Donati",
        "summary": "Accurately assessing mental workload is crucial in cognitive neuroscience, human-computer interaction, and real-time monitoring, as cognitive load fluctuations affect performance and decision-making. While Electroencephalography (EEG) based machine learning (ML) models can be used to this end, their high computational cost hinders embedded real-time applications. Hardware implementations of spiking neural networks (SNNs) offer a promising alternative for low-power, fast, event-driven processing. This study compares hardware compatible SNN models with various traditional ML ones, using an open-source multimodal dataset. Our results show that multimodal integration improves accuracy, with SNN performance comparable to the ML one, demonstrating their potential for real-time implementations of cognitive load detection. These findings position event-based processing as a promising solution for low-latency, energy efficient workload monitoring in adaptive closed-loop embedded devices that dynamically regulate cognitive load.",
        "subjects": "Neural and Evolutionary Computing, Machine Learning, Biomolecules",
        "date": "2025-09-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.220489"
    },
    {
        "index": "#296",
        "title": "Interpretable Spectral Features Predict Conductivity in Self-Driving Doped Conjugated Polymer Labs",
        "link": "/arxiv/2509.21330",
        "arxiv_id": "2509.21330",
        "authors": "Ankush Kumar Mishra, Jacob P. Mauthe, Nicholas Luke, Aram Amassian, Baskar Ganapathysubramanian",
        "summary": "Self-driving labs (SDLs) promise faster materials discovery by coupling automation with machine learning, but a central challenge is predicting costly, slow-to-measure properties from inexpensive, automatable readouts. We address this for doped conjugated polymers by learning interpretable spectral fingerprints from optical spectroscopy to predict electrical conductivity. Optical spectra are fast, non-destructive, and sensitive to aggregation and charge generation; we automate their featurization by combining a genetic algorithm (GA) with area-under-the-curve (AUC) computations over adaptively selected spectral windows. These data-driven spectral features, together with processing parameters, are used to train a quantitative structure-property relationship (QSPR) linking optical response and processing to conductivity. To improve accuracy and interpretability in the small-data regime, we add domain-knowledge-based feature expansions and apply SHAP-guided selection to retain a compact, physically meaningful feature set. The pipeline is evaluated under a leak-free train/test protocol, and GA is repeated to assess feature stability. The data-driven model matches the performance of a baseline built from expert-curated descriptors while reducing experimental effort (about 33%) by limiting direct conductivity measurements. Combining data-driven and expert features yields a hybrid QSPR with superior predictive performance, highlighting productive human-ML collaboration. The learned features recover known descriptors in pBTTT (0-0/0-1 vibronic intensity ratio) and reveal a tail-state region correlated with polymer bleaching during successful doping. This approach delivers interpretable, noise-robust, small-data-friendly features that convert rapid measurements into reliable predictions of costly properties and readily extends to other spectral modalities (e.g., XANES, Raman, FTIR).",
        "subjects": "Materials Science, Soft Condensed Matter, Machine Learning",
        "date": "2025-09-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.222281"
    }
]