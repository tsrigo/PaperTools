[
    {
        "index": "#6",
        "title": "Transport Based Mean Flows for Generative Modeling",
        "link": "/arxiv/2509.22592",
        "arxiv_id": "2509.22592",
        "authors": "Elaheh Akbari, Ping He, Ahmadreza Moradipari, Yikun Bai, Soheil Kolouri",
        "summary": "Flow-matching generative models have emerged as a powerful paradigm for continuous data generation, achieving state-of-the-art results across domains such as images, 3D shapes, and point clouds. Despite their success, these models suffer from slow inference due to the requirement of numerous sequential sampling steps. Recent work has sought to accelerate inference by reducing the number of sampling steps. In particular, Mean Flows offer a one-step generation approach that delivers substantial speedups while retaining strong generative performance. Yet, in many continuous domains, Mean Flows fail to faithfully approximate the behavior of the original multi-step flow-matching process. In this work, we address this limitation by incorporating optimal transport-based sampling strategies into the Mean Flow framework, enabling one-step generators that better preserve the fidelity and diversity of the original multi-step flow process. Experiments on controlled low-dimensional settings and on high-dimensional tasks such as image generation, image-to-image translation, and point cloud generation demonstrate that our approach achieves superior inference accuracy in one-step generative modeling.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.131776"
    },
    {
        "index": "#7",
        "title": "The Lie of the Average: How Class Incremental Learning Evaluation Deceives You?",
        "link": "/arxiv/2509.22580",
        "arxiv_id": "2509.22580",
        "authors": "Guannan Lai, Da-Wei Zhou, Xin Yang, Han-Jia Ye",
        "summary": "Class Incremental Learning (CIL) requires models to continuously learn new classes without forgetting previously learned ones, while maintaining stable performance across all possible class sequences. In real-world settings, the order in which classes arrive is diverse and unpredictable, and model performance can vary substantially across different sequences. Yet mainstream evaluation protocols calculate mean and variance from only a small set of randomly sampled sequences. Our theoretical analysis and empirical results demonstrate that this sampling strategy fails to capture the full performance range, resulting in biased mean estimates and a severe underestimation of the true variance in the performance distribution. We therefore contend that a robust CIL evaluation protocol should accurately characterize and estimate the entire performance distribution. To this end, we introduce the concept of extreme sequences and provide theoretical justification for their crucial role in the reliable evaluation of CIL. Moreover, we observe a consistent positive correlation between inter-task similarity and model performance, a relation that can be leveraged to guide the search for extreme sequences. Building on these insights, we propose EDGE (Extreme case-based Distribution and Generalization Evaluation), an evaluation protocol that adaptively identifies and samples extreme class sequences using inter-task similarity, offering a closer approximation of the ground-truth performance distribution. Extensive experiments demonstrate that EDGE effectively captures performance extremes and yields more accurate estimates of distributional boundaries, providing actionable insights for model selection and robustness checking. Our code is available at https://github.com/AIGNLAI/EDGE.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.132378"
    },
    {
        "index": "#9",
        "title": "Machine learning approaches to seismic event classification in the Ostrava region",
        "link": "/arxiv/2509.22574",
        "arxiv_id": "2509.22574",
        "authors": "Marek Pecha, Michael Skotnica, Jana Rušajová, Bohdan Rieznikov, Vít Wandrol, Markéta Rösnerová, Jaromír Knejzlík",
        "summary": "The northeastern region of the Czech Republic is among the most seismically active areas in the country. The most frequent seismic events are mining-induced since there used to be strong mining activity in the past. However, natural tectonic events may also occur. In addition, seismic stations often record explosions in quarries in the region. Despite the cessation of mining activities, mine-induced seismic events still occur. Therefore, a rapid differentiation between tectonic and anthropogenic events is still important. The region is currently monitored by the OKC seismic station in Ostrava-Krásné Pole built in 1983 which is a part of the Czech Regional Seismic Network. The station has been providing digital continuous waveform data at 100 Hz since 2007. In the years 1992--2002, the region was co-monitored by the Seismic Polygon Frenštát (SPF) which consisted of five seismic stations using a triggered STA/LTA system. In this study, we apply and compare machine learning methods to the SPF dataset, which contains labeled records of tectonic and mining-induced events. For binary classification, a Long Short-Term Memory recurrent neural network and XGBoost achieved an F1-score of 0.94 -- 0.95, demonstrating the potential of modern machine learning techniques for rapid event characterization.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.134330"
    },
    {
        "index": "#12",
        "title": "Learning to Price Bundles: A GCN Approach for Mixed Bundling",
        "link": "/arxiv/2509.22557",
        "arxiv_id": "2509.22557",
        "authors": "Liangyu Ding, Chenghan Wu, Guokai Li, Zizhuo Wang",
        "summary": "Bundle pricing refers to designing several product combinations (i.e., bundles) and determining their prices in order to maximize the expected profit. It is a classic problem in revenue management and arises in many industries, such as e-commerce, tourism, and video games. However, the problem is typically intractable due to the exponential number of candidate bundles. In this paper, we explore the usage of graph convolutional networks (GCNs) in solving the bundle pricing problem. Specifically, we first develop a graph representation of the mixed bundling model (where every possible bundle is assigned with a specific price) and then train a GCN to learn the latent patterns of optimal bundles. Based on the trained GCN, we propose two inference strategies to derive high-quality feasible solutions. A local-search technique is further proposed to improve the solution quality. Numerical experiments validate the effectiveness and efficiency of our proposed GCN-based framework. Using a GCN trained on instances with 5 products, our methods consistently achieve near-optimal solutions (better than 97%) with only a fraction of computational time for problems of small to medium size. It also achieves superior solutions for larger size of problems compared with other heuristic methods such as bundle size pricing (BSP). The method can also provide high quality solutions for instances with more than 30 products even for the challenging cases where product utilities are non-additive.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.136067"
    },
    {
        "index": "#13",
        "title": "ECHO: Toward Contextual Seq2Seq Paradigms in Large EEG Models",
        "link": "/arxiv/2509.22556",
        "arxiv_id": "2509.22556",
        "authors": "Chenyu Liu, Yuqiu Deng, Tianyu Liu, Jinan Zhou, Xinliang Zhou, Ziyu Jia, Yi Ding",
        "summary": "Electroencephalography (EEG), with its broad range of applications, necessitates models that can generalize effectively across various tasks and datasets. Large EEG Models (LEMs) address this by pretraining encoder-centric architectures on large-scale unlabeled data to extract universal representations. While effective, these models lack decoders of comparable capacity, limiting the full utilization of the learned features. To address this issue, we introduce ECHO, a novel decoder-centric LEM paradigm that reformulates EEG modeling as sequence-to-sequence learning. ECHO captures layered relationships among signals, labels, and tasks within sequence space, while incorporating discrete support samples to construct contextual cues. This design equips ECHO with in-context learning, enabling dynamic adaptation to heterogeneous tasks without parameter updates. Extensive experiments across multiple datasets demonstrate that, even with basic model components, ECHO consistently outperforms state-of-the-art single-task LEMs in multi-task settings, showing superior generalization and adaptability.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.136381"
    },
    {
        "index": "#16",
        "title": "Dual Optimistic Ascent (PI Control) is the Augmented Lagrangian Method in Disguise",
        "link": "/arxiv/2509.22500",
        "arxiv_id": "2509.22500",
        "authors": "Juan Ramirez, Simon Lacoste-Julien",
        "summary": "Constrained optimization is a powerful framework for enforcing requirements on neural networks. These constrained deep learning problems are typically solved using first-order methods on their min-max Lagrangian formulation, but such approaches often suffer from oscillations and can fail to find all local solutions. While the Augmented Lagrangian method (ALM) addresses these issues, practitioners often favor dual optimistic ascent schemes (PI control) on the standard Lagrangian, which perform well empirically but lack formal guarantees. In this paper, we establish a previously unknown equivalence between these approaches: dual optimistic ascent on the Lagrangian is equivalent to gradient descent-ascent on the Augmented Lagrangian. This finding allows us to transfer the robust theoretical guarantees of the ALM to the dual optimistic setting, proving it converges linearly to all local solutions. Furthermore, the equivalence provides principled guidance for tuning the optimism hyper-parameter. Our work closes a critical gap between the empirical success of dual optimistic methods and their theoretical foundation.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.137216"
    },
    {
        "index": "#19",
        "title": "Bayesian Transfer Operators in Reproducing Kernel Hilbert Spaces",
        "link": "/arxiv/2509.22482",
        "arxiv_id": "2509.22482",
        "authors": "Septimus Boshoff, Sebastian Peitz, Stefan Klus",
        "summary": "The Koopman operator, as a linear representation of a nonlinear dynamical system, has been attracting attention in many fields of science. Recently, Koopman operator theory has been combined with another concept that is popular in data science: reproducing kernel Hilbert spaces. We follow this thread into Gaussian process methods, and illustrate how these methods can alleviate two pervasive problems with kernel-based Koopman algorithms. The first being sparsity: most kernel methods do not scale well and require an approximation to become practical. We show that not only can the computational demands be reduced, but also demonstrate improved resilience against sensor noise. The second problem involves hyperparameter optimization and dictionary learning to adapt the model to the dynamical system. In summary, the main contribution of this work is the unification of Gaussian process regression and dynamic mode decomposition.",
        "subjects": "Machine Learning, Dynamical Systems, Chaotic Dynamics, Data Analysis, Statistics and Probability",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.138109"
    },
    {
        "index": "#22",
        "title": "Nonlinear Optimization with GPU-Accelerated Neural Network Constraints",
        "link": "/arxiv/2509.22462",
        "arxiv_id": "2509.22462",
        "authors": "Robert Parker, Oscar Dowson, Nicole LoGiudice, Manuel Garcia, Russell Bent",
        "summary": "We propose a reduced-space formulation for optimizing over trained neural networks where the network's outputs and derivatives are evaluated on a GPU. To do this, we treat the neural network as a \"gray box\" where intermediate variables and constraints are not exposed to the optimization solver. Compared to the full-space formulation, in which intermediate variables and constraints are exposed to the optimization solver, the reduced-space formulation leads to faster solves and fewer iterations in an interior point method. We demonstrate the benefits of this method on two optimization problems: Adversarial generation for a classifier trained on MNIST images and security-constrained optimal power flow with transient feasibility enforced using a neural network surrogate.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.139130"
    },
    {
        "index": "#24",
        "title": "Overclocking Electrostatic Generative Models",
        "link": "/arxiv/2509.22454",
        "arxiv_id": "2509.22454",
        "authors": "Daniil Shlenskii, Alexander Korotin",
        "summary": "Electrostatic generative models such as PFGM++ have recently emerged as a powerful framework, achieving state-of-the-art performance in image synthesis. PFGM++ operates in an extended data space with auxiliary dimensionality $D$, recovering the diffusion model framework as $D\\to\\infty$, while yielding superior empirical results for finite $D$. Like diffusion models, PFGM++ relies on expensive ODE simulations to generate samples, making it computationally costly. To address this, we propose Inverse Poisson Flow Matching (IPFM), a novel distillation framework that accelerates electrostatic generative models across all values of $D$. Our IPFM reformulates distillation as an inverse problem: learning a generator whose induced electrostatic field matches that of the teacher. We derive a tractable training objective for this problem and show that, as $D \\to \\infty$, our IPFM closely recovers Score Identity Distillation (SiD), a recent method for distilling diffusion models. Empirically, our IPFM produces distilled generators that achieve near-teacher or even superior sample quality using only a few function evaluations. Moreover, we observe that distillation converges faster for finite $D$ than in the $D \\to \\infty$ (diffusion) limit, which is consistent with prior findings that finite-$D$ PFGM++ models exhibit more favorable optimization and sampling properties.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.139738"
    },
    {
        "index": "#27",
        "title": "The Flood Complex: Large-Scale Persistent Homology on Millions of Points",
        "link": "/arxiv/2509.22432",
        "arxiv_id": "2509.22432",
        "authors": "Florian Graf, Paolo Pellizzoni, Martin Uray, Stefan Huber, Roland Kwitt",
        "summary": "We consider the problem of computing persistent homology (PH) for large-scale Euclidean point cloud data, aimed at downstream machine learning tasks, where the exponential growth of the most widely-used Vietoris-Rips complex imposes serious computational limitations. Although more scalable alternatives such as the Alpha complex or sparse Rips approximations exist, they often still result in a prohibitively large number of simplices. This poses challenges in the complex construction and in the subsequent PH computation, prohibiting their use on large-scale point clouds. To mitigate these issues, we introduce the Flood complex, inspired by the advantages of the Alpha and Witness complex constructions. Informally, at a given filtration value $r\\geq 0$, the Flood complex contains all simplices from a Delaunay triangulation of a small subset of the point cloud $X$ that are fully covered by balls of radius $r$ emanating from $X$, a process we call flooding. Our construction allows for efficient PH computation, possesses several desirable theoretical properties, and is amenable to GPU parallelization. Scaling experiments on 3D point cloud data show that we can compute PH of up to dimension 2 on several millions of points. Importantly, when evaluating object classification performance on real-world and synthetic data, we provide evidence that this scaling capability is needed, especially if objects are geometrically or topologically complex, yielding performance superior to other PH-based methods and neural networks for point cloud data.",
        "subjects": "Machine Learning, Computational Geometry",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.140646"
    },
    {
        "index": "#30",
        "title": "One Prompt Fits All: Universal Graph Adaptation for Pretrained Models",
        "link": "/arxiv/2509.22416",
        "arxiv_id": "2509.22416",
        "authors": "Yongqi Huang, Jitao Zhao, Dongxiao He, Xiaobao Wang, Yawen Li, Yuxiao Huang, Di Jin, Zhiyong Feng",
        "summary": "Graph Prompt Learning (GPL) has emerged as a promising paradigm that bridges graph pretraining models and downstream scenarios, mitigating label dependency and the misalignment between upstream pretraining and downstream tasks. Although existing GPL studies explore various prompt strategies, their effectiveness and underlying principles remain unclear. We identify two critical limitations: (1) Lack of consensus on underlying mechanisms: Despite current GPLs have advanced the field, there is no consensus on how prompts interact with pretrained models, as different strategies intervene at varying spaces within the model, i.e., input-level, layer-wise, and representation-level prompts. (2) Limited scenario adaptability: Most methods fail to generalize across diverse downstream scenarios, especially under data distribution shifts (e.g., homophilic-to-heterophilic graphs). To address these issues, we theoretically analyze existing GPL approaches and reveal that representation-level prompts essentially function as fine-tuning a simple downstream classifier, proposing that graph prompt learning should focus on unleashing the capability of pretrained models, and the classifier adapts to downstream scenarios. Based on our findings, we propose UniPrompt, a novel GPL method that adapts any pretrained models, unleashing the capability of pretrained models while preserving the structure of the input graph. Extensive experiments demonstrate that our method can effectively integrate with various pretrained models and achieve strong performance across in-domain and cross-domain scenarios.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.141572"
    },
    {
        "index": "#31",
        "title": "Fast-Forward Lattice Boltzmann: Learning Kinetic Behaviour with Physics-Informed Neural Operators",
        "link": "/arxiv/2509.22411",
        "arxiv_id": "2509.22411",
        "authors": "Xiao Xue, Marco F. P. ten Eikelder, Mingyang Gao, Xiaoyuan Cheng, Yiming Yang, Yi He, Shuo Wang, Sibo Cheng, Yukun Hu, Peter V. Coveney",
        "summary": "The lattice Boltzmann equation (LBE), rooted in kinetic theory, provides a powerful framework for capturing complex flow behaviour by describing the evolution of single-particle distribution functions (PDFs). Despite its success, solving the LBE numerically remains computationally intensive due to strict time-step restrictions imposed by collision kernels. Here, we introduce a physics-informed neural operator framework for the LBE that enables prediction over large time horizons without step-by-step integration, effectively bypassing the need to explicitly solve the collision kernel. We incorporate intrinsic moment-matching constraints of the LBE, along with global equivariance of the full distribution field, enabling the model to capture the complex dynamics of the underlying kinetic system. Our framework is discretization-invariant, enabling models trained on coarse lattices to generalise to finer ones (kinetic super-resolution). In addition, it is agnostic to the specific form of the underlying collision model, which makes it naturally applicable across different kinetic datasets regardless of the governing dynamics. Our results demonstrate robustness across complex flow scenarios, including von Karman vortex shedding, ligament breakup, and bubble adhesion. This establishes a new data-driven pathway for modelling kinetic systems.",
        "subjects": "Machine Learning, Cellular Automata and Lattice Gases, Computational Physics, Fluid Dynamics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.141946"
    },
    {
        "index": "#32",
        "title": "MoveFM-R: Advancing Mobility Foundation Models via Language-driven Semantic Reasoning",
        "link": "/arxiv/2509.22403",
        "arxiv_id": "2509.22403",
        "authors": "Fanjin Meng, Yuan Yuan, Jingtao Ding, Jie Feng, Chonghua Han, Yong Li",
        "summary": "Mobility Foundation Models (MFMs) have advanced the modeling of human movement patterns, yet they face a ceiling due to limitations in data scale and semantic understanding. While Large Language Models (LLMs) offer powerful semantic reasoning, they lack the innate understanding of spatio-temporal statistics required for generating physically plausible mobility trajectories. To address these gaps, we propose MoveFM-R, a novel framework that unlocks the full potential of mobility foundation models by leveraging language-driven semantic reasoning capabilities. It tackles two key challenges: the vocabulary mismatch between continuous geographic coordinates and discrete language tokens, and the representation gap between the latent vectors of MFMs and the semantic world of LLMs. MoveFM-R is built on three core innovations: a semantically enhanced location encoding to bridge the geography-language gap, a progressive curriculum to align the LLM's reasoning with mobility patterns, and an interactive self-reflection mechanism for conditional trajectory generation. Extensive experiments demonstrate that MoveFM-R significantly outperforms existing MFM-based and LLM-based baselines. It also shows robust generalization in zero-shot settings and excels at generating realistic trajectories from natural language instructions. By synthesizing the statistical power of MFMs with the deep semantic understanding of LLMs, MoveFM-R pioneers a new paradigm that enables a more comprehensive, interpretable, and powerful modeling of human mobility. The implementation of MoveFM-R is available online at https://anonymous.4open.science/r/MoveFM-R-CDE7/.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.142248"
    },
    {
        "index": "#33",
        "title": "ReLAM: Learning Anticipation Model for Rewarding Visual Robotic Manipulation",
        "link": "/arxiv/2509.22402",
        "arxiv_id": "2509.22402",
        "authors": "Nan Tang, Jing-Cheng Pang, Guanlin Li, Chao Qian, Yang Yu",
        "summary": "Reward design remains a critical bottleneck in visual reinforcement learning (RL) for robotic manipulation. In simulated environments, rewards are conventionally designed based on the distance to a target position. However, such precise positional information is often unavailable in real-world visual settings due to sensory and perceptual limitations. In this study, we propose a method that implicitly infers spatial distances through keypoints extracted from images. Building on this, we introduce Reward Learning with Anticipation Model (ReLAM), a novel framework that automatically generates dense, structured rewards from action-free video demonstrations. ReLAM first learns an anticipation model that serves as a planner and proposes intermediate keypoint-based subgoals on the optimal path to the final goal, creating a structured learning curriculum directly aligned with the task's geometric objectives. Based on the anticipated subgoals, a continuous reward signal is provided to train a low-level, goal-conditioned policy under the hierarchical reinforcement learning (HRL) framework with provable sub-optimality bound. Extensive experiments on complex, long-horizon manipulation tasks show that ReLAM significantly accelerates learning and achieves superior performance compared to state-of-the-art methods.",
        "subjects": "Machine Learning, Robotics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.142547"
    },
    {
        "index": "#34",
        "title": "Improving accuracy in short mortality rate series: Exploring Multi-step Forecasting Approaches in Hybrid Systems",
        "link": "/arxiv/2509.22395",
        "arxiv_id": "2509.22395",
        "authors": "Filipe C. L. Duarte, Paulo S. G. de Mattos Neto, Paulo R. A. Firmino",
        "summary": "The decline in interest rates and economic stabilization has heightened the importance of accurate mortality rate forecasting, particularly in insurance and pension markets. Multi-step-ahead predictions are crucial for public health, demographic planning, and insurance risk assessments; however, they face challenges when data are limited. Hybrid systems that combine statistical and Machine Learning (ML) models offer a promising solution for handling both linear and nonlinear patterns. This study evaluated the impact of different multi-step forecasting approaches (Recursive, Direct, and Multi-Input Multi-Output) and ML models on the accuracy of hybrid systems. Results from 12 datasets and 21 models show that the selection of both the multi-step approach and the ML model is essential for improving performance, with the ARIMA-LSTM hybrid using a recursive approach outperforming other models in most cases.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.142816"
    },
    {
        "index": "#36",
        "title": "(Sometimes) Less is More: Mitigating the Complexity of Rule-based Representation for Interpretable Classification",
        "link": "/arxiv/2509.22384",
        "arxiv_id": "2509.22384",
        "authors": "Luca Bergamin, Roberto Confalonieri, Fabio Aiolli",
        "summary": "Deep neural networks are widely used in practical applications of AI, however, their inner structure and complexity made them generally not easily interpretable. Model transparency and interpretability are key requirements for multiple scenarios where high performance is not enough to adopt the proposed solution. In this work, a differentiable approximation of $L_0$ regularization is adapted into a logic-based neural network, the Multi-layer Logical Perceptron (MLLP), to study its efficacy in reducing the complexity of its discrete interpretable version, the Concept Rule Set (CRS), while retaining its performance. The results are compared to alternative heuristics like Random Binarization of the network weights, to determine if better results can be achieved when using a less-noisy technique that sparsifies the network based on the loss function instead of a random distribution. The trade-off between the CRS complexity and its performance is discussed.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.143353"
    },
    {
        "index": "#37",
        "title": "Enhancing Credit Risk Prediction: A Meta-Learning Framework Integrating Baseline Models, LASSO, and ECOC for Superior Accuracy",
        "link": "/arxiv/2509.22381",
        "arxiv_id": "2509.22381",
        "authors": "Haibo Wang, Lutfu S. Sua, Jun Huang, Figen Balo, Burak Dolar",
        "summary": "Effective credit risk management is fundamental to financial decision-making, necessitating robust models for default probability prediction and financial entity classification. Traditional machine learning approaches face significant challenges when confronted with high-dimensional data, limited interpretability, rare event detection, and multi-class imbalance problems in risk assessment. This research proposes a comprehensive meta-learning framework that synthesizes multiple complementary models: supervised learning algorithms, including XGBoost, Random Forest, Support Vector Machine, and Decision Tree; unsupervised methods such as K-Nearest Neighbors; deep learning architectures like Multilayer Perceptron; alongside LASSO regularization for feature selection and dimensionality reduction; and Error-Correcting Output Codes as a meta-classifier for handling imbalanced multi-class problems. We implement Permutation Feature Importance analysis for each prediction class across all constituent models to enhance model transparency. Our framework aims to optimize predictive performance while providing a more holistic approach to credit risk assessment. This research contributes to the development of more accurate and reliable computational models for strategic financial decision support by addressing three fundamental challenges in credit risk modeling. The empirical validation of our approach involves an analysis of the Corporate Credit Ratings dataset with credit ratings for 2,029 publicly listed US companies. Results demonstrate that our meta-learning framework significantly enhances the accuracy of financial entity classification regarding credit rating migrations (upgrades and downgrades) and default probability estimation.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.143649"
    },
    {
        "index": "#38",
        "title": "Role-Aware Multi-modal federated learning system for detecting phishing webpages",
        "link": "/arxiv/2509.22369",
        "arxiv_id": "2509.22369",
        "authors": "Bo Wang, Imran Khan, Martin White, Natalia Beloff",
        "summary": "We present a federated, multi-modal phishing website detector that supports URL, HTML, and IMAGE inputs without binding clients to a fixed modality at inference: any client can invoke any modality head trained elsewhere. Methodologically, we propose role-aware bucket aggregation on top of FedProx, inspired by Mixture-of-Experts and FedMM. We drop learnable routing and use hard gating (selecting the IMAGE/HTML/URL expert by sample modality), enabling separate aggregation of modality-specific parameters to isolate cross-embedding conflicts and stabilize convergence. On TR-OP, the Fusion head reaches Acc 97.5% with FPR 2.4% across two data types; on the image subset (ablation) it attains Acc 95.5% with FPR 5.9%. For text, we use GraphCodeBERT for URLs and an early three-way embedding for raw, noisy HTML. On WebPhish (HTML) we obtain Acc 96.5% / FPR 1.8%; on TR-OP (raw HTML) we obtain Acc 95.1% / FPR 4.6%. Results indicate that bucket aggregation with hard-gated experts enables stable federated training under strict privacy, while improving the usability and flexibility of multi-modal phishing detection.",
        "subjects": "Machine Learning, Distributed, Parallel, and Cluster Computing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.143948"
    },
    {
        "index": "#39",
        "title": "Investigating Faithfulness in Large Audio Language Models",
        "link": "/arxiv/2509.22363",
        "arxiv_id": "2509.22363",
        "authors": "Lovenya Jain, Pooneh Mousavi, Mirco Ravanelli, Cem Subakan",
        "summary": "Faithfulness measures whether chain-of-thought (CoT) representations accurately reflect a model's decision process and can be used as reliable explanations. Prior work has shown that CoTs from text-based LLMs are often unfaithful. This question has not been explored for large audio-language models (LALMs), where faithfulness is critical for safety-sensitive applications. Reasoning in LALMs is also more challenging, as models must first extract relevant clues from audio before reasoning over them. In this paper, we investigate the faithfulness of CoTs produced by several LALMs by applying targeted interventions, including paraphrasing, filler token injection, early answering, and introducing mistakes, on two challenging reasoning datasets: SAKURA and MMAR. After going through the aforementioned interventions across several datasets and tasks, our experiments suggest that, LALMs generally produce CoTs that appear to be faithful to their underlying decision processes.",
        "subjects": "Machine Learning, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.144242"
    },
    {
        "index": "#40",
        "title": "Neural Feature Geometry Evolves as Discrete Ricci Flow",
        "link": "/arxiv/2509.22362",
        "arxiv_id": "2509.22362",
        "authors": "Moritz Hehl, Max von Renesse, Melanie Weber",
        "summary": "Deep neural networks learn feature representations via complex geometric transformations of the input data manifold. Despite the models' empirical success across domains, our understanding of neural feature representations is still incomplete. In this work we investigate neural feature geometry through the lens of discrete geometry. Since the input data manifold is typically unobserved, we approximate it using geometric graphs that encode local similarity structure. We provide theoretical results on the evolution of these graphs during training, showing that nonlinear activations play a crucial role in shaping feature geometry in feedforward neural networks. Moreover, we discover that the geometric transformations resemble a discrete Ricci flow on these graphs, suggesting that neural feature geometry evolves analogous to Ricci flow. This connection is supported by experiments on over 20,000 feedforward neural networks trained on binary classification tasks across both synthetic and real-world datasets. We observe that the emergence of class separability corresponds to the emergence of community structure in the associated graph representations, which is known to relate to discrete Ricci flow dynamics. Building on these insights, we introduce a novel framework for locally evaluating geometric transformations through comparison with discrete Ricci flow dynamics. Our results suggest practical design principles, including a geometry-informed early-stopping heuristic and a criterion for selecting network depth.",
        "subjects": "Machine Learning, Discrete Mathematics, Differential Geometry",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.144528"
    },
    {
        "index": "#45",
        "title": "Distributed Associative Memory via Online Convex Optimization",
        "link": "/arxiv/2509.22321",
        "arxiv_id": "2509.22321",
        "authors": "Bowen Wang, Matteo Zecchin, Osvaldo Simeone",
        "summary": "An associative memory (AM) enables cue-response recall, and associative memorization has recently been noted to underlie the operation of modern neural architectures such as Transformers. This work addresses a distributed setting where agents maintain a local AM to recall their own associations as well as selective information from others. Specifically, we introduce a distributed online gradient descent method that optimizes local AMs at different agents through communication over routing trees. Our theoretical analysis establishes sublinear regret guarantees, and experiments demonstrate that the proposed protocol consistently outperforms existing online optimization baselines.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.146112"
    },
    {
        "index": "#48",
        "title": "SoDaDE: Solvent Data-Driven Embeddings with Small Transformer Models",
        "link": "/arxiv/2509.22302",
        "arxiv_id": "2509.22302",
        "authors": "Gabriel Kitso Gibberd, Jose Pablo Folch, Antonio Del Rio Chanona",
        "summary": "Computational representations have become crucial in unlocking the recent growth of machine learning algorithms for chemistry. Initially hand-designed, machine learning has shown that meaningful representations can be learnt from data. Chemical datasets are limited and so the representations learnt from data are generic, being trained on broad datasets which contain shallow information on many different molecule types. For example, generic fingerprints lack physical context specific to solvents. However, the use of harmful solvents is a leading climate-related issue in the chemical industry, and there is a surge of interest in green solvent replacement. To empower this research, we propose a new solvent representation scheme by developing Solvent Data Driven Embeddings (SoDaDE). SoDaDE uses a small transformer model and solvent property dataset to create a fingerprint for solvents. To showcase their effectiveness, we use SoDaDE to predict yields on a recently published dataset, outperforming previous representations. We demonstrate through this paper that data-driven fingerprints can be made with small datasets and set-up a workflow that can be explored for other applications.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.146961"
    },
    {
        "index": "#50",
        "title": "Aurora: Towards Universal Generative Multimodal Time Series Forecasting",
        "link": "/arxiv/2509.22295",
        "arxiv_id": "2509.22295",
        "authors": "Xingjian Wu, Jianxin Jin, Wanghui Qiu, Peng Chen, Yang Shu, Bin Yang, Chenjuan Guo",
        "summary": "Cross-domain generalization is very important in Time Series Forecasting because similar historical information may lead to distinct future trends due to the domain-specific characteristics. Recent works focus on building unimodal time series foundation models and end-to-end multimodal supervised models. Since domain-specific knowledge is often contained in modalities like texts, the former lacks the explicit utilization of them, thus hindering the performance. The latter is tailored for end-to-end scenarios and does not support zero-shot inference for cross-domain scenarios. In this work, we introduce Aurora, a Multimodal Time Series Foundation Model, which supports multimodal inputs and zero-shot inference. Pretrained on Corss-domain Multimodal Time Series Corpus, Aurora can adaptively extract and focus on key domain knowledge contained in corrsponding text or image modalities, thus possessing strong Cross-domain generalization capability. Through tokenization, encoding, and distillation, Aurora can extract multimodal domain knowledge as guidance and then utilizes a Modality-Guided Multi-head Self-Attention to inject them into the modeling of temporal representations. In the decoding phase, the multimodal representations are used to generate the conditions and prototypes of future tokens, contributing to a novel Prototype-Guided Flow Matching for generative probabilistic forecasting. Comprehensive experiments on well-recognized benchmarks, including TimeMMD, TSFM-Bench and ProbTS, demonstrate the consistent state-of-the-art performance of Aurora on both unimodal and multimodal scenarios.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.147575"
    },
    {
        "index": "#51",
        "title": "A Multi-Level Framework for Multi-Objective Hypergraph Partitioning: Combining Minimum Spanning Tree and Proximal Gradient",
        "link": "/arxiv/2509.22294",
        "arxiv_id": "2509.22294",
        "authors": "Yingying Li, Mingxuan Xie, Hailong You, Yongqiang Yao, Hongwei Liu",
        "summary": "This paper proposes an efficient hypergraph partitioning framework based on a novel multi-objective non-convex constrained relaxation model. A modified accelerated proximal gradient algorithm is employed to generate diverse $k$-dimensional vertex features to avoid local optima and enhance partition quality. Two MST-based strategies are designed for different data scales: for small-scale data, the Prim algorithm constructs a minimum spanning tree followed by pruning and clustering; for large-scale data, a subset of representative nodes is selected to build a smaller MST, while the remaining nodes are assigned accordingly to reduce complexity. To further improve partitioning results, refinement strategies including greedy migration, swapping, and recursive MST-based clustering are introduced for partitions. Experimental results on public benchmark sets demonstrate that the proposed algorithm achieves reductions in cut size of approximately 2\\%--5\\% on average compared to KaHyPar in 2, 3, and 4-way partitioning, with improvements of up to 35\\% on specific instances. Particularly on weighted vertex sets, our algorithm outperforms state-of-the-art partitioners including KaHyPar, hMetis, Mt-KaHyPar, and K-SpecPart, highlighting its superior partitioning quality and competitiveness. Furthermore, the proposed refinement strategy improves hMetis partitions by up to 16\\%. A comprehensive evaluation based on virtual instance methodology and parameter sensitivity analysis validates the algorithm's competitiveness and characterizes its performance trade-offs.",
        "subjects": "Machine Learning, Combinatorics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.147890"
    },
    {
        "index": "#52",
        "title": "Conditional Denoising Diffusion Autoencoders for Wireless Semantic Communications",
        "link": "/arxiv/2509.22282",
        "arxiv_id": "2509.22282",
        "authors": "Mehdi Letafati, Samad Ali, Matti Latva-aho",
        "summary": "Semantic communication (SemCom) systems aim to learn the mapping from low-dimensional semantics to high-dimensional ground-truth. While this is more akin to a \"domain translation\" problem, existing frameworks typically emphasize on channel-adaptive neural encoding-decoding schemes, lacking full exploration of signal distribution. Moreover, such methods so far have employed autoencoder-based architectures, where the encoding is tightly coupled to a matched decoder, causing scalability issues in practice. To address these gaps, diffusion autoencoder models are proposed for wireless SemCom. The goal is to learn a \"semantic-to-clean\" mapping, from the semantic space to the ground-truth probability distribution. A neural encoder at semantic transmitter extracts the high-level semantics, and a conditional diffusion model (CDiff) at the semantic receiver exploits the source distribution for signal-space denoising, while the received semantic latents are incorporated as the conditioning input to \"steer\" the decoding process towards the semantics intended by the transmitter. It is analytically proved that the proposed decoder model is a consistent estimator of the ground-truth data. Furthermore, extensive simulations over CIFAR-10 and MNIST datasets are provided along with design insights, highlighting the performance compared to legacy autoencoders and variational autoencoders (VAE). Simulations are further extended to the multi-user SemCom, identifying the dominating factors in a more realistic setup.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.148166"
    },
    {
        "index": "#53",
        "title": "Unlocking the Power of Mixture-of-Experts for Task-Aware Time Series Analytics",
        "link": "/arxiv/2509.22279",
        "arxiv_id": "2509.22279",
        "authors": "Xingjian Wu, Zhengyu Li, Hanyin Cheng, Xiangfei Qiu, Jilin Hu, Chenjuan Guo, Bin Yang",
        "summary": "Time Series Analysis is widely used in various real-world applications such as weather forecasting, financial fraud detection, imputation for missing data in IoT systems, and classification for action recognization. Mixture-of-Experts (MoE), as a powerful architecture, though demonstrating effectiveness in NLP, still falls short in adapting to versatile tasks in time series analytics due to its task-agnostic router and the lack of capability in modeling channel correlations. In this study, we propose a novel, general MoE-based time series framework called PatchMoE to support the intricate ``knowledge'' utilization for distinct tasks, thus task-aware. Based on the observation that hierarchical representations often vary across tasks, e.g., forecasting vs. classification, we propose a Recurrent Noisy Gating to utilize the hierarchical information in routing, thus obtaining task-sepcific capability. And the routing strategy is operated on time series tokens in both temporal and channel dimensions, and encouraged by a meticulously designed Temporal \\& Channel Load Balancing Loss to model the intricate temporal and channel correlations. Comprehensive experiments on five downstream tasks demonstrate the state-of-the-art performance of PatchMoE.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.148470"
    },
    {
        "index": "#54",
        "title": "Fine-Grained Uncertainty Decomposition in Large Language Models: A Spectral Approach",
        "link": "/arxiv/2509.22272",
        "arxiv_id": "2509.22272",
        "authors": "Nassim Walha, Sebastian G. Gruber, Thomas Decker, Yinchong Yang, Alireza Javanmardi, Eyke Hüllermeier, Florian Buettner",
        "summary": "As Large Language Models (LLMs) are increasingly integrated in diverse applications, obtaining reliable measures of their predictive uncertainty has become critically important. A precise distinction between aleatoric uncertainty, arising from inherent ambiguities within input data, and epistemic uncertainty, originating exclusively from model limitations, is essential to effectively address each uncertainty source. In this paper, we introduce Spectral Uncertainty, a novel approach to quantifying and decomposing uncertainties in LLMs. Leveraging the Von Neumann entropy from quantum information theory, Spectral Uncertainty provides a rigorous theoretical foundation for separating total uncertainty into distinct aleatoric and epistemic components. Unlike existing baseline methods, our approach incorporates a fine-grained representation of semantic similarity, enabling nuanced differentiation among various semantic interpretations in model responses. Empirical evaluations demonstrate that Spectral Uncertainty outperforms state-of-the-art methods in estimating both aleatoric and total uncertainty across diverse models and benchmark datasets.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.148771"
    },
    {
        "index": "#55",
        "title": "Towards a more realistic evaluation of machine learning models for bearing fault diagnosis",
        "link": "/arxiv/2509.22267",
        "arxiv_id": "2509.22267",
        "authors": "João Paulo Vieira, Victor Afonso Bauler, Rodrigo Kobashikawa Rosa, Danilo Silva",
        "summary": "Reliable detection of bearing faults is essential for maintaining the safety and operational efficiency of rotating machinery. While recent advances in machine learning (ML), particularly deep learning, have shown strong performance in controlled settings, many studies fail to generalize to real-world applications due to methodological flaws, most notably data leakage. This paper investigates the issue of data leakage in vibration-based bearing fault diagnosis and its impact on model evaluation. We demonstrate that common dataset partitioning strategies, such as segment-wise and condition-wise splits, introduce spurious correlations that inflate performance metrics. To address this, we propose a rigorous, leakage-free evaluation methodology centered on bearing-wise data partitioning, ensuring no overlap between the physical components used for training and testing. Additionally, we reformulate the classification task as a multi-label problem, enabling the detection of co-occurring fault types and the use of prevalence-independent metrics such as Macro AUROC. Beyond preventing leakage, we also examine the effect of dataset diversity on generalization, showing that the number of unique training bearings is a decisive factor for achieving robust performance. We evaluate our methodology on three widely adopted datasets: CWRU, Paderborn University (PU), and University of Ottawa (UORED-VAFCLS). This study highlights the importance of leakage-aware evaluation protocols and provides practical guidelines for dataset partitioning, model selection, and validation, fostering the development of more trustworthy ML systems for industrial fault diagnosis applications.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.149063"
    },
    {
        "index": "#56",
        "title": "Erase or Hide? Suppressing Spurious Unlearning Neurons for Robust Unlearning",
        "link": "/arxiv/2509.22263",
        "arxiv_id": "2509.22263",
        "authors": "Nakyeong Yang, Dong-Kyum Kim, Jea Kwon, Minsung Kim, Kyomin Jung, Meeyoung Cha",
        "summary": "Large language models trained on web-scale data can memorize private or sensitive knowledge, raising significant privacy risks. Although some unlearning methods mitigate these risks, they remain vulnerable to \"relearning\" during subsequent training, allowing a substantial portion of forgotten knowledge to resurface. In this paper, we show that widely used unlearning methods cause shallow alignment: instead of faithfully erasing target knowledge, they generate spurious unlearning neurons that amplify negative influence to hide it. To overcome this limitation, we introduce Ssiuu, a new class of unlearning methods that employs attribution-guided regularization to prevent spurious negative influence and faithfully remove target knowledge. Experimental results confirm that our method reliably erases target knowledge and outperforms strong baselines across two practical retraining scenarios: (1) adversarial injection of private data, and (2) benign attack using an instruction-following benchmark. Our findings highlight the necessity of robust and faithful unlearning methods for safe deployment of language models.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.149357"
    },
    {
        "index": "#61",
        "title": "A Law of Data Reconstruction for Random Features (and Beyond)",
        "link": "/arxiv/2509.22214",
        "arxiv_id": "2509.22214",
        "authors": "Leonardo Iurada, Simone Bombari, Tatiana Tommasi, Marco Mondelli",
        "summary": "Large-scale deep learning models are known to memorize parts of the training set. In machine learning theory, memorization is often framed as interpolation or label fitting, and classical results show that this can be achieved when the number of parameters $p$ in the model is larger than the number of training samples $n$. In this work, we consider memorization from the perspective of data reconstruction, demonstrating that this can be achieved when $p$ is larger than $dn$, where $d$ is the dimensionality of the data. More specifically, we show that, in the random features model, when $p \\gg dn$, the subspace spanned by the training samples in feature space gives sufficient information to identify the individual samples in input space. Our analysis suggests an optimization method to reconstruct the dataset from the model parameters, and we demonstrate that this method performs well on various architectures (random features, two-layer fully-connected and deep residual networks). Our results reveal a law of data reconstruction, according to which the entire training dataset can be recovered as $p$ exceeds the threshold $dn$.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.150917"
    },
    {
        "index": "#63",
        "title": "Kernel Regression of Multi-Way Data via Tensor Trains with Hadamard Overparametrization: The Dynamic Graph Flow Case",
        "link": "/arxiv/2509.22197",
        "arxiv_id": "2509.22197",
        "authors": "Duc Thien Nguyen, Konstantinos Slavakis, Eleftherios Kofidis, Dimitris Pados",
        "summary": "A regression-based framework for interpretable multi-way data imputation, termed Kernel Regression via Tensor Trains with Hadamard overparametrization (KReTTaH), is introduced. KReTTaH adopts a nonparametric formulation by casting imputation as regression via reproducing kernel Hilbert spaces. Parameter efficiency is achieved through tensors of fixed tensor-train (TT) rank, which reside on low-dimensional Riemannian manifolds, and is further enhanced via Hadamard overparametrization, which promotes sparsity within the TT parameter space. Learning is accomplished by solving a smooth inverse problem posed on the Riemannian manifold of fixed TT-rank tensors. As a representative application, the estimation of dynamic graph flows is considered. In this setting, KReTTaH exhibits flexibility by seamlessly incorporating graph-based (topological) priors via its inverse problem formulation. Numerical tests on real-world graph datasets demonstrate that KReTTaH consistently outperforms state-of-the-art alternatives-including a nonparametric tensor- and a neural-network-based methods-for imputing missing, time-varying edge flows.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.151520"
    },
    {
        "index": "#64",
        "title": "Mechanistic Independence: A Principle for Identifiable Disentangled Representations",
        "link": "/arxiv/2509.22196",
        "arxiv_id": "2509.22196",
        "authors": "Stefan Matthes, Zhiwei Han, Hao Shen",
        "summary": "Disentangled representations seek to recover latent factors of variation underlying observed data, yet their identifiability is still not fully understood. We introduce a unified framework in which disentanglement is achieved through mechanistic independence, which characterizes latent factors by how they act on observed variables rather than by their latent distribution. This perspective is invariant to changes of the latent density, even when such changes induce statistical dependencies among factors. Within this framework, we propose several related independence criteria -- ranging from support-based and sparsity-based to higher-order conditions -- and show that each yields identifiability of latent subspaces, even under nonlinear, non-invertible mixing. We further establish a hierarchy among these criteria and provide a graph-theoretic characterization of latent subspaces as connected components. Together, these results clarify the conditions under which disentangled representations can be identified without relying on statistical assumptions.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.151817"
    },
    {
        "index": "#69",
        "title": "Slicing Wasserstein Over Wasserstein Via Functional Optimal Transport",
        "link": "/arxiv/2509.22138",
        "arxiv_id": "2509.22138",
        "authors": "Moritz Piening, Robert Beinert",
        "summary": "Wasserstein distances define a metric between probability measures on arbitrary metric spaces, including meta-measures (measures over measures). The resulting Wasserstein over Wasserstein (WoW) distance is a powerful, but computationally costly tool for comparing datasets or distributions over images and shapes. Existing sliced WoW accelerations rely on parametric meta-measures or the existence of high-order moments, leading to numerical instability. As an alternative, we propose to leverage the isometry between the 1d Wasserstein space and the quantile functions in the function space $L_2([0,1])$. For this purpose, we introduce a general sliced Wasserstein framework for arbitrary Banach spaces. Due to the 1d Wasserstein isometry, this framework defines a sliced distance between 1d meta-measures via infinite-dimensional $L_2$-projections, parametrized by Gaussian processes. Combining this 1d construction with classical integration over the Euclidean unit sphere yields the double-sliced Wasserstein (DSW) metric for general meta-measures. We show that DSW minimization is equivalent to WoW minimization for discretized meta-measures, while avoiding unstable higher-order moments and computational savings. Numerical experiments on datasets, shapes, and images validate DSW as a scalable substitute for the WoW distance.",
        "subjects": "Machine Learning, Metric Geometry, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.153288"
    },
    {
        "index": "#70",
        "title": "Mind the Missing: Variable-Aware Representation Learning for Irregular EHR Time Series using Large Language Models",
        "link": "/arxiv/2509.22121",
        "arxiv_id": "2509.22121",
        "authors": "Jeong Eul Kwon, Joo Heung Yoon, Hyo Kyung Lee",
        "summary": "Irregular sampling and high missingness are intrinsic challenges in modeling time series derived from electronic health records (EHRs),where clinical variables are measured at uneven intervals depending on workflow and intervention timing. To address this, we propose VITAL, a variable-aware, large language model (LLM) based framework tailored for learning from irregularly sampled physiological time series. VITAL differentiates between two distinct types of clinical variables: vital signs, which are frequently recorded and exhibit temporal patterns, and laboratory tests, which are measured sporadically and lack temporal structure. It reprograms vital signs into the language space, enabling the LLM to capture temporal context and reason over missing values through explicit encoding. In contrast, laboratory variables are embedded either using representative summary values or a learnable [Not measured] token, depending on their availability. Extensive evaluations on the benchmark datasets from the PhysioNet demonstrate that VITAL outperforms state of the art methods designed for irregular time series. Furthermore, it maintains robust performance under high levels of missingness, which is prevalent in real world clinical scenarios where key variables are often unavailable.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.153559"
    },
    {
        "index": "#72",
        "title": "Countering adversarial evasion in regression analysis",
        "link": "/arxiv/2509.22113",
        "arxiv_id": "2509.22113",
        "authors": "David Benfield, Phan Tu Vuong, Alain Zemkoho",
        "summary": "Adversarial machine learning challenges the assumption that the underlying distribution remains consistent throughout the training and implementation of a prediction model. In particular, adversarial evasion considers scenarios where adversaries adapt their data to influence particular outcomes from established prediction models, such scenarios arise in applications such as spam email filtering, malware detection and fake-image generation, where security methods must be actively updated to keep up with the ever-improving generation of malicious data. Game theoretic models have been shown to be effective at modelling these scenarios and hence training resilient predictors against such adversaries. Recent advancements in the use of pessimistic bilevel optimsiation which remove assumptions about the convexity and uniqueness of the adversary's optimal strategy have proved to be particularly effective at mitigating threats to classifiers due to its ability to capture the antagonistic nature of the adversary. However, this formulation has not yet been adapted to regression scenarios. This article serves to propose a pessimistic bilevel optimisation program for regression scenarios which makes no assumptions on the convexity or uniqueness of the adversary's solutions.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.154144"
    },
    {
        "index": "#73",
        "title": "Modeling Psychological Profiles in Volleyball via Mixed-Type Bayesian Networks",
        "link": "/arxiv/2509.22111",
        "arxiv_id": "2509.22111",
        "authors": "Maria Iannario, Dae-Jin Lee, Manuele Leonelli",
        "summary": "Psychological attributes rarely operate in isolation: coaches reason about networks of related traits. We analyze a new dataset of 164 female volleyball players from Italy's C and D leagues that combines standardized psychological profiling with background information. To learn directed relationships among mixed-type variables (ordinal questionnaire scores, categorical demographics, continuous indicators), we introduce latent MMHC, a hybrid structure learner that couples a latent Gaussian copula and a constraint-based skeleton with a constrained score-based refinement to return a single DAG. We also study a bootstrap-aggregated variant for stability. In simulations spanning sample size, sparsity, and dimension, latent Max-Min Hill-Climbing (MMHC) attains lower structural Hamming distance and higher edge recall than recent copula-based learners while maintaining high specificity. Applied to volleyball, the learned network organizes mental skills around goal setting and self-confidence, with emotional arousal linking motivation and anxiety, and locates Big-Five traits (notably neuroticism and extraversion) upstream of skill clusters. Scenario analyses quantify how improvements in specific skills propagate through the network to shift preparation, confidence, and self-esteem. The approach provides an interpretable, data-driven framework for profiling psychological traits in sport and for decision support in athlete development.",
        "subjects": "Machine Learning, Applications",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.154427"
    },
    {
        "index": "#75",
        "title": "SHAKE-GNN: Scalable Hierarchical Kirchhoff-Forest Graph Neural Network",
        "link": "/arxiv/2509.22100",
        "arxiv_id": "2509.22100",
        "authors": "Zhipu Cui, Johannes Lutzeyer",
        "summary": "Graph Neural Networks (GNNs) have achieved remarkable success across a range of learning tasks. However, scaling GNNs to large graphs remains a significant challenge, especially for graph-level tasks. In this work, we introduce SHAKE-GNN, a novel scalable graph-level GNN framework based on a hierarchy of Kirchhoff Forests, a class of random spanning forests used to construct stochastic multi-resolution decompositions of graphs. SHAKE-GNN produces multi-scale representations, enabling flexible trade-offs between efficiency and performance. We introduce an improved, data-driven strategy for selecting the trade-off parameter and analyse the time-complexity of SHAKE-GNN. Experimental results on multiple large-scale graph classification benchmarks demonstrate that SHAKE-GNN achieves competitive performance while offering improved scalability.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.155007"
    },
    {
        "index": "#76",
        "title": "Non-Linear Trajectory Modeling for Multi-Step Gradient Inversion Attacks in Federated Learning",
        "link": "/arxiv/2509.22082",
        "arxiv_id": "2509.22082",
        "authors": "Li Xia, Zheng Liu, Sili Huang, Wei Tang, Xuan Liu",
        "summary": "Federated Learning (FL) preserves privacy by keeping raw data local, yet Gradient Inversion Attacks (GIAs) pose significant threats. In FedAVG multi-step scenarios, attackers observe only aggregated gradients, making data reconstruction challenging. Existing surrogate model methods like SME assume linear parameter trajectories, but we demonstrate this severely underestimates SGD's nonlinear complexity, fundamentally limiting attack effectiveness. We propose Non-Linear Surrogate Model Extension (NL-SME), the first method to introduce nonlinear parametric trajectory modeling for GIAs. Our approach replaces linear interpolation with learnable quadratic Bézier curves that capture SGD's curved characteristics through control points, combined with regularization and dvec scaling mechanisms for enhanced expressiveness. Extensive experiments on CIFAR-100 and FEMNIST datasets show NL-SME significantly outperforms baselines across all metrics, achieving order-of-magnitude improvements in cosine similarity loss while maintaining computational efficiency.This work exposes heightened privacy vulnerabilities in FL's multi-step update paradigm and offers novel perspectives for developing robust defense strategies.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.155310"
    },
    {
        "index": "#78",
        "title": "Towards Understanding Feature Learning in Parameter Transfer",
        "link": "/arxiv/2509.22056",
        "arxiv_id": "2509.22056",
        "authors": "Hua Yuan, Xuran Meng, Qiufeng Wang, Shiyu Xia, Ning Xu, Xu Yang, Jing Wang, Xin Geng, Yong Rui",
        "summary": "Parameter transfer is a central paradigm in transfer learning, enabling knowledge reuse across tasks and domains by sharing model parameters between upstream and downstream models. However, when only a subset of parameters from the upstream model is transferred to the downstream model, there remains a lack of theoretical understanding of the conditions under which such partial parameter reuse is beneficial and of the factors that govern its effectiveness. To address this gap, we analyze a setting in which both the upstream and downstream models are ReLU convolutional neural networks (CNNs). Within this theoretical framework, we characterize how the inherited parameters act as carriers of universal knowledge and identify key factors that amplify their beneficial impact on the target task. Furthermore, our analysis provides insight into why, in certain cases, transferring parameters can lead to lower test accuracy on the target task than training a new model from scratch. Numerical experiments and real-world data experiments are conducted to empirically validate our theoretical findings.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.155971"
    },
    {
        "index": "#80",
        "title": "BrainPro: Towards Large-scale Brain State-aware EEG Representation Learning",
        "link": "/arxiv/2509.22050",
        "arxiv_id": "2509.22050",
        "authors": "Yi Ding, Muyun Jiang, Weibang Jiang, Shuailei Zhang, Xinliang Zhou, Chenyu Liu, Shanglin Li, Yong Li, Cuntai Guan",
        "summary": "Electroencephalography (EEG) is a non-invasive technique for recording brain electrical activity, widely used in brain-computer interface (BCI) and healthcare. Recent EEG foundation models trained on large-scale datasets have shown improved performance and generalizability over traditional decoding methods, yet significant challenges remain. Existing models often fail to explicitly capture channel-to-channel and region-to-region interactions, which are critical sources of information inherently encoded in EEG signals. Due to varying channel configurations across datasets, they either approximate spatial structure with self-attention or restrict training to a limited set of common channels, sacrificing flexibility and effectiveness. Moreover, although EEG datasets reflect diverse brain states such as emotion, motor, and others, current models rarely learn state-aware representations during self-supervised pre-training. To address these gaps, we propose BrainPro, a large EEG model that introduces a retrieval-based spatial learning block to flexibly capture channel- and region-level interactions across varying electrode layouts, and a brain state-decoupling block that enables state-aware representation learning through parallel encoders with decoupling and region-aware reconstruction losses. This design allows BrainPro to adapt seamlessly to diverse tasks and hardware settings. Pre-trained on an extensive EEG corpus, BrainPro achieves state-of-the-art performance and robust generalization across nine public BCI datasets. Our codes and the pre-trained weights will be released.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.156595"
    },
    {
        "index": "#81",
        "title": "MO-GRPO: Mitigating Reward Hacking of Group Relative Policy Optimization on Multi-Objective Problems",
        "link": "/arxiv/2509.22047",
        "arxiv_id": "2509.22047",
        "authors": "Yuki Ichihara, Yuu Jinnai, Tetsuro Morimura, Mitsuki Sakamoto, Ryota Mitsuhashi, Eiji Uchibe",
        "summary": "Group Relative Policy Optimization (GRPO) has been shown to be an effective algorithm when an accurate reward model is available. However, such a highly reliable reward model is not available in many real-world tasks. In this paper, we particularly focus on multi-objective settings, in which we identify that GRPO is vulnerable to reward hacking, optimizing only one of the objectives at the cost of the others. To address this issue, we propose MO-GRPO, an extension of GRPO with a simple normalization method to reweight the reward functions automatically according to the variances of their values. We first show analytically that MO-GRPO ensures that all reward functions contribute evenly to the loss function while preserving the order of preferences, eliminating the need for manual tuning of the reward functions' scales. Then, we evaluate MO-GRPO experimentally in four domains: (i) the multi-armed bandits problem, (ii) simulated control task (Mo-Gymnasium), (iii) machine translation tasks on the WMT benchmark (En-Ja, En-Zh), and (iv) instruction following task. MO-GRPO achieves stable learning by evenly distributing correlations among the components of rewards, outperforming GRPO, showing MO-GRPO to be a promising algorithm for multi-objective reinforcement learning problems.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.156896"
    },
    {
        "index": "#82",
        "title": "Convexity-Driven Projection for Point Cloud Dimensionality Reduction",
        "link": "/arxiv/2509.22043",
        "arxiv_id": "2509.22043",
        "authors": "Suman Sanyal",
        "summary": "We propose Convexity-Driven Projection (CDP), a boundary-free linear method for dimensionality reduction of point clouds that targets preserving detour-induced local non-convexity. CDP builds a $k$-NN graph, identifies admissible pairs whose Euclidean-to-shortest-path ratios are below a threshold, and aggregates their normalized directions to form a positive semidefinite non-convexity structure matrix. The projection uses the top-$k$ eigenvectors of the structure matrix. We give two verifiable guarantees. A pairwise a-posteriori certificate that bounds the post-projection distortion for each admissible pair, and an average-case spectral bound that links expected captured direction energy to the spectrum of the structure matrix, yielding quantile statements for typical distortion. Our evaluation protocol reports fixed- and reselected-pairs detour errors and certificate quantiles, enabling practitioners to check guarantees on their data.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.157157"
    },
    {
        "index": "#84",
        "title": "OrtSAE: Orthogonal Sparse Autoencoders Uncover Atomic Features",
        "link": "/arxiv/2509.22033",
        "arxiv_id": "2509.22033",
        "authors": "Anton Korznikov, Andrey Galichin, Alexey Dontsov, Oleg Rogov, Elena Tutubalina, Ivan Oseledets",
        "summary": "Sparse autoencoders (SAEs) are a technique for sparse decomposition of neural network activations into human-interpretable features. However, current SAEs suffer from feature absorption, where specialized features capture instances of general features creating representation holes, and feature composition, where independent features merge into composite representations. In this work, we introduce Orthogonal SAE (OrtSAE), a novel approach aimed to mitigate these issues by enforcing orthogonality between the learned features. By implementing a new training procedure that penalizes high pairwise cosine similarity between SAE features, OrtSAE promotes the development of disentangled features while scaling linearly with the SAE size, avoiding significant computational overhead. We train OrtSAE across different models and layers and compare it with other methods. We find that OrtSAE discovers 9% more distinct features, reduces feature absorption (by 65%) and composition (by 15%), improves performance on spurious correlation removal (+6%), and achieves on-par performance for other downstream tasks compared to traditional SAEs.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.157736"
    },
    {
        "index": "#85",
        "title": "MCGM: Multi-stage Clustered Global Modeling for Long-range Interactions in Molecules",
        "link": "/arxiv/2509.22028",
        "arxiv_id": "2509.22028",
        "authors": "Haodong Pan, Yusong Wang, Nanning Zheng, Caijui Jiang",
        "summary": "Geometric graph neural networks (GNNs) excel at capturing molecular geometry, yet their locality-biased message passing hampers the modeling of long-range interactions. Current solutions have fundamental limitations: extending cutoff radii causes computational costs to scale cubically with distance; physics-inspired kernels (e.g., Coulomb, dispersion) are often system-specific and lack generality; Fourier-space methods require careful tuning of multiple parameters (e.g., mesh size, k-space cutoff) with added computational overhead. We introduce Multi-stage Clustered Global Modeling (MCGM), a lightweight, plug-and-play module that endows geometric GNNs with hierarchical global context through efficient clustering operations. MCGM builds a multi-resolution hierarchy of atomic clusters, distills global information via dynamic hierarchical clustering, and propagates this context back through learned transformations, ultimately reinforcing atomic features via residual connections. Seamlessly integrated into four diverse backbone architectures, MCGM reduces OE62 energy prediction error by an average of 26.2%. On AQM, MCGM achieves state-of-the-art accuracy (17.0 meV for energy, 4.9 meV/Å for forces) while using 20% fewer parameters than Neural P3M. Code will be made available upon acceptance.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.158016"
    },
    {
        "index": "#86",
        "title": "Teaching Transformers to Solve Combinatorial Problems through Efficient Trial & Error",
        "link": "/arxiv/2509.22023",
        "arxiv_id": "2509.22023",
        "authors": "Panagiotis Giannoulis, Yorgos Pantis, Christos Tzamos",
        "summary": "Despite their proficiency in various language tasks, Large Language Models (LLMs) struggle with combinatorial problems like Satisfiability, Traveling Salesman Problem, or even basic arithmetic. We address this gap through a novel approach for solving problems in the class NP. We focus on the paradigmatic task of Sudoku and achieve state-of-the-art accuracy (99\\%) compared to prior neuro-symbolic approaches. Unlike prior work that used custom architectures, our method employs a vanilla decoder-only Transformer (GPT-2) without external tools or function calling. Our method integrates imitation learning of simple Sudoku rules with an explicit Depth-First Search (DFS) exploration strategy involving informed guessing and backtracking. Moving beyond imitation learning, we seek to minimize the number of guesses until reaching a solution. We provide a rigorous analysis of this setup formalizing its connection to a contextual variant of Min-Sum Set Cover, a well-studied problem in algorithms and stochastic optimization.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.158286"
    },
    {
        "index": "#87",
        "title": "Task-Adaptive Parameter-Efficient Fine-Tuning for Weather Foundation Models",
        "link": "/arxiv/2509.22020",
        "arxiv_id": "2509.22020",
        "authors": "Shilei Cao, Hehai Lin, Jiashun Cheng, Yang Liu, Guowen Li, Xuehe Wang, Juepeng Zheng, Haoyuan Liang, Meng Jin, Chengwei Qin, Hong Cheng, Haohuan Fu",
        "summary": "While recent advances in machine learning have equipped Weather Foundation Models (WFMs) with substantial generalization capabilities across diverse downstream tasks, the escalating computational requirements associated with their expanding scale increasingly hinder practical deployment. Current Parameter-Efficient Fine-Tuning (PEFT) methods, designed for vision or language tasks, fail to address the unique challenges of weather downstream tasks, such as variable heterogeneity, resolution diversity, and spatiotemporal coverage variations, leading to suboptimal performance when applied to WFMs. To bridge this gap, we introduce WeatherPEFT, a novel PEFT framework for WFMs incorporating two synergistic innovations. First, during the forward pass, Task-Adaptive Dynamic Prompting (TADP) dynamically injects the embedding weights within the encoder to the input tokens of the pre-trained backbone via internal and external pattern extraction, enabling context-aware feature recalibration for specific downstream tasks. Furthermore, during backpropagation, Stochastic Fisher-Guided Adaptive Selection (SFAS) not only leverages Fisher information to identify and update the most task-critical parameters, thereby preserving invariant pre-trained knowledge, but also introduces randomness to stabilize the selection. We demonstrate the effectiveness and efficiency of WeatherPEFT on three downstream tasks, where existing PEFT methods show significant gaps versus Full-Tuning, and WeatherPEFT achieves performance parity with Full-Tuning using fewer trainable parameters. The code of this work will be released.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.158638"
    },
    {
        "index": "#88",
        "title": "AEGIS: Authentic Edge Growth In Sparsity for Link Prediction in Edge-Sparse Bipartite Knowledge Graphs",
        "link": "/arxiv/2509.22017",
        "arxiv_id": "2509.22017",
        "authors": "Hugh Xuechen Liu, Kıvanç Tatar",
        "summary": "Bipartite knowledge graphs in niche domains are typically data-poor and edge-sparse, which hinders link prediction. We introduce AEGIS (Authentic Edge Growth In Sparsity), an edge-only augmentation framework that resamples existing training edges -either uniformly simple or with inverse-degree bias degree-aware -thereby preserving the original node set and sidestepping fabricated endpoints. To probe authenticity across regimes, we consider naturally sparse graphs (game design pattern's game-pattern network) and induce sparsity in denser benchmarks (Amazon, MovieLens) via high-rate bond percolation. We evaluate augmentations on two complementary metrics: AUC-ROC (higher is better) and the Brier score (lower is better), using two-tailed paired t-tests against sparse baselines. On Amazon and MovieLens, copy-based AEGIS variants match the baseline while the semantic KNN augmentation is the only method that restores AUC and calibration; random and synthetic edges remain detrimental. On the text-rich GDP graph, semantic KNN achieves the largest AUC improvement and Brier score reduction, and simple also lowers the Brier score relative to the sparse control. These findings position authenticity-constrained resampling as a data-efficient strategy for sparse bipartite link prediction, with semantic augmentation providing an additional boost when informative node descriptions are available.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.158902"
    },
    {
        "index": "#89",
        "title": "Concept-SAE: Active Causal Probing of Visual Model Behavior",
        "link": "/arxiv/2509.22015",
        "arxiv_id": "2509.22015",
        "authors": "Jianrong Ding, Muxi Chen, Chenchen Zhao, Qiang Xu",
        "summary": "Standard Sparse Autoencoders (SAEs) excel at discovering a dictionary of a model's learned features, offering a powerful observational lens. However, the ambiguous and ungrounded nature of these features makes them unreliable instruments for the active, causal probing of model behavior. To solve this, we introduce Concept-SAE, a framework that forges semantically grounded concept tokens through a novel hybrid disentanglement strategy. We first quantitatively demonstrate that our dual-supervision approach produces tokens that are remarkably faithful and spatially localized, outperforming alternative methods in disentanglement. This validated fidelity enables two critical applications: (1) we probe the causal link between internal concepts and predictions via direct intervention, and (2) we probe the model's failure modes by systematically localizing adversarial vulnerabilities to specific layers. Concept-SAE provides a validated blueprint for moving beyond correlational interpretation to the mechanistic, causal probing of model behavior.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.159190"
    },
    {
        "index": "#90",
        "title": "Goal-Guided Efficient Exploration via Large Language Model in Reinforcement Learning",
        "link": "/arxiv/2509.22008",
        "arxiv_id": "2509.22008",
        "authors": "Yajie Qi, Wei Wei, Lin Li, Lijun Zhang, Zhidong Gao, Da Wang, Huizhong Song",
        "summary": "Real-world decision-making tasks typically occur in complex and open environments, posing significant challenges to reinforcement learning (RL) agents' exploration efficiency and long-horizon planning capabilities. A promising approach is LLM-enhanced RL, which leverages the rich prior knowledge and strong planning capabilities of LLMs to guide RL agents in efficient exploration. However, existing methods mostly rely on frequent and costly LLM invocations and suffer from limited performance due to the semantic mismatch. In this paper, we introduce a Structured Goal-guided Reinforcement Learning (SGRL) method that integrates a structured goal planner and a goal-conditioned action pruner to guide RL agents toward efficient exploration. Specifically, the structured goal planner utilizes LLMs to generate a reusable, structured function for goal generation, in which goals are prioritized. Furthermore, by utilizing LLMs to determine goals' priority weights, it dynamically generates forward-looking goals to guide the agent's policy toward more promising decision-making trajectories. The goal-conditioned action pruner employs an action masking mechanism that filters out actions misaligned with the current goal, thereby constraining the RL agent to select goal-consistent policies. We evaluate the proposed method on Crafter and Craftax-Classic, and experimental results demonstrate that SGRL achieves superior performance compared to existing state-of-the-art methods.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.159493"
    },
    {
        "index": "#91",
        "title": "Stage-wise Dynamics of Classifier-Free Guidance in Diffusion Models",
        "link": "/arxiv/2509.22007",
        "arxiv_id": "2509.22007",
        "authors": "Cheng Jin, Qitan Shi, Yuantao Gu",
        "summary": "Classifier-Free Guidance (CFG) is widely used to improve conditional fidelity in diffusion models, but its impact on sampling dynamics remains poorly understood. Prior studies, often restricted to unimodal conditional distributions or simplified cases, provide only a partial picture. We analyze CFG under multimodal conditionals and show that the sampling process unfolds in three successive stages. In the Direction Shift stage, guidance accelerates movement toward the weighted mean, introducing initialization bias and norm growth. In the Mode Separation stage, local dynamics remain largely neutral, but the inherited bias suppresses weaker modes, reducing global diversity. In the Concentration stage, guidance amplifies within-mode contraction, diminishing fine-grained variability. This unified view explains a widely observed phenomenon: stronger guidance improves semantic alignment but inevitably reduces diversity. Experiments support these predictions, showing that early strong guidance erodes global diversity, while late strong guidance suppresses fine-grained variation. Moreover, our theory naturally suggests a time-varying guidance schedule, and empirical results confirm that it consistently improves both quality and diversity.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.159784"
    },
    {
        "index": "#92",
        "title": "GRAM-TDI: adaptive multimodal representation learning for drug target interaction prediction",
        "link": "/arxiv/2509.21971",
        "arxiv_id": "2509.21971",
        "authors": "Feng Jiang, Amina Mollaysa, Hehuan Ma, Tommaso Mansi, Junzhou Huang, Mangal Prakash, Rui Liao",
        "summary": "Drug target interaction (DTI) prediction is a cornerstone of computational drug discovery, enabling rational design, repurposing, and mechanistic insights. While deep learning has advanced DTI modeling, existing approaches primarily rely on SMILES protein pairs and fail to exploit the rich multimodal information available for small molecules and proteins. We introduce GRAMDTI, a pretraining framework that integrates multimodal molecular and protein inputs into unified representations. GRAMDTI extends volume based contrastive learning to four modalities, capturing higher-order semantic alignment beyond conventional pairwise approaches. To handle modality informativeness, we propose adaptive modality dropout, dynamically regulating each modality's contribution during pre-training. Additionally, IC50 activity measurements, when available, are incorporated as weak supervision to ground representations in biologically meaningful interaction strengths. Experiments on four publicly available datasets demonstrate that GRAMDTI consistently outperforms state of the art baselines. Our results highlight the benefits of higher order multimodal alignment, adaptive modality utilization, and auxiliary supervision for robust and generalizable DTI prediction.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.160100"
    },
    {
        "index": "#93",
        "title": "Think Smart, Not Hard: Difficulty Adaptive Reasoning for Large Audio Language Models",
        "link": "/arxiv/2509.21960",
        "arxiv_id": "2509.21960",
        "authors": "Zhichao Sheng, Shilin Zhou, Chen Gong, Zhenghua Li",
        "summary": "Large Audio Language Models (LALMs), powered by the chain-of-thought (CoT) paradigm, have shown remarkable reasoning capabilities. Intuitively, different problems often require varying depths of reasoning. While some methods can determine whether to reason for a given problem, they typically lack a fine-grained mechanism to modulate how much to reason. This often results in a ``one-size-fits-all'' reasoning depth, which generates redundant overthinking for simple questions while failing to allocate sufficient thought to complex ones. In this paper, we conduct an in-depth analysis of LALMs and find that an effective and efficient LALM should reason smartly by adapting its reasoning depth to the problem's complexity. To achieve this, we propose a difficulty-adaptive reasoning method for LALMs. Specifically, we propose a reward function that dynamically links reasoning length to the model's perceived problem difficulty. This reward encourages shorter, concise reasoning for easy tasks and more elaborate, in-depth reasoning for complex ones. Extensive experiments demonstrate that our method is both effective and efficient, simultaneously improving task performance and significantly reducing the average reasoning length. Further analysis on reasoning structure paradigm offers valuable insights for future work.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.160380"
    },
    {
        "index": "#95",
        "title": "Structural Information-based Hierarchical Diffusion for Offline Reinforcement Learning",
        "link": "/arxiv/2509.21942",
        "arxiv_id": "2509.21942",
        "authors": "Xianghua Zeng, Hao Peng, Angsheng Li, Yicheng Pan",
        "summary": "Diffusion-based generative methods have shown promising potential for modeling trajectories from offline reinforcement learning (RL) datasets, and hierarchical diffusion has been introduced to mitigate variance accumulation and computational challenges in long-horizon planning tasks. However, existing approaches typically assume a fixed two-layer diffusion hierarchy with a single predefined temporal scale, which limits adaptability to diverse downstream tasks and reduces flexibility in decision making. In this work, we propose SIHD, a novel Structural Information-based Hierarchical Diffusion framework for effective and stable offline policy learning in long-horizon environments with sparse rewards. Specifically, we analyze structural information embedded in offline trajectories to construct the diffusion hierarchy adaptively, enabling flexible trajectory modeling across multiple temporal scales. Rather than relying on reward predictions from localized sub-trajectories, we quantify the structural information gain of each state community and use it as a conditioning signal within the corresponding diffusion layer. To reduce overreliance on offline datasets, we introduce a structural entropy regularizer that encourages exploration of underrepresented states while avoiding extrapolation errors from distributional shifts. Extensive evaluations on challenging offline RL tasks show that SIHD significantly outperforms state-of-the-art baselines in decision-making performance and demonstrates superior generalization across diverse scenarios.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.160977"
    },
    {
        "index": "#96",
        "title": "Statistical Advantage of Softmax Attention: Insights from Single-Location Regression",
        "link": "/arxiv/2509.21936",
        "arxiv_id": "2509.21936",
        "authors": "O. Duranthon, P. Marion, C. Boyer, B. Loureiro, L. Zdeborová",
        "summary": "Large language models rely on attention mechanisms with a softmax activation. Yet the dominance of softmax over alternatives (e.g., component-wise or linear) remains poorly understood, and many theoretical works have focused on the easier-to-analyze linearized attention. In this work, we address this gap through a principled study of the single-location regression task, where the output depends on a linear transformation of a single input token at a random location. Building on ideas from statistical physics, we develop an analysis of attention-based predictors in the high-dimensional limit, where generalization performance is captured by a small set of order parameters. At the population level, we show that softmax achieves the Bayes risk, whereas linear attention fundamentally falls short. We then examine other activation functions to identify which properties are necessary for optimal performance. Finally, we analyze the finite-sample regime: we provide an asymptotic characterization of the test error and show that, while softmax is no longer Bayes-optimal, it consistently outperforms linear attention. We discuss the connection with optimization by gradient-based algorithms.",
        "subjects": "Machine Learning, Disordered Systems and Neural Networks",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.161280"
    },
    {
        "index": "#97",
        "title": "Extracting Actionable Insights from Building Energy Data using Vision LLMs on Wavelet and 3D Recurrence Representations",
        "link": "/arxiv/2509.21934",
        "arxiv_id": "2509.21934",
        "authors": "Amine Bechar, Adel Oulefki, Abbes Amira, Fatih Kurogollu, Yassine Himeur",
        "summary": "The analysis of complex building time-series for actionable insights and recommendations remains challenging due to the nonlinear and multi-scale characteristics of energy data. To address this, we propose a framework that fine-tunes visual language large models (VLLMs) on 3D graphical representations of the data. The approach converts 1D time-series into 3D representations using continuous wavelet transforms (CWTs) and recurrence plots (RPs), which capture temporal dynamics and localize frequency anomalies. These 3D encodings enable VLLMs to visually interpret energy-consumption patterns, detect anomalies, and provide recommendations for energy efficiency. We demonstrate the framework on real-world building-energy datasets, where fine-tuned VLLMs successfully monitor building states, identify recurring anomalies, and generate optimization recommendations. Quantitatively, the Idefics-7B VLLM achieves validation losses of 0.0952 with CWTs and 0.1064 with RPs on the University of Sharjah energy dataset, outperforming direct fine-tuning on raw time-series data (0.1176) for anomaly detection. This work bridges time-series analysis and visualization, providing a scalable and interpretable framework for energy analytics.",
        "subjects": "Machine Learning, Computers and Society",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.161581"
    },
    {
        "index": "#99",
        "title": "Multiplicative-Additive Constrained Models:Toward Joint Visualization of Interactive and Independent Effects",
        "link": "/arxiv/2509.21923",
        "arxiv_id": "2509.21923",
        "authors": "Fumin Wang",
        "summary": "Interpretability is one of the considerations when applying machine learning to high-stakes fields such as healthcare that involve matters of life safety. Generalized Additive Models (GAMs) enhance interpretability by visualizing shape functions. Nevertheless, to preserve interpretability, GAMs omit higher-order interaction effects (beyond pairwise interactions), which imposes significant constraints on their predictive performance. We observe that Curve Ergodic Set Regression (CESR), a multiplicative model, naturally enables the visualization of its shape functions and simultaneously incorporates both interactions among all features and individual feature effects. Nevertheless, CESR fails to demonstrate superior performance compared to GAMs. We introduce Multiplicative-Additive Constrained Models (MACMs), which augment CESR with an additive part to disentangle the intertwined coefficients of its interactive and independent terms, thus effectively broadening the hypothesis space. The model is composed of a multiplicative part and an additive part, whose shape functions can both be naturally visualized, thereby assisting users in interpreting how features participate in the decision-making process. Consequently, MACMs constitute an improvement over both CESR and GAMs. The experimental results indicate that neural network-based MACMs significantly outperform both CESR and the current state-of-the-art GAMs in terms of predictive performance.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.162120"
    },
    {
        "index": "#100",
        "title": "Discrete Guidance Matching: Exact Guidance for Discrete Flow Matching",
        "link": "/arxiv/2509.21912",
        "arxiv_id": "2509.21912",
        "authors": "Zhengyan Wan, Yidong Ouyang, Liyan Xie, Fang Fang, Hongyuan Zha, Guang Cheng",
        "summary": "Guidance provides a simple and effective framework for posterior sampling by steering the generation process towards the desired distribution. When modeling discrete data, existing approaches mostly focus on guidance with the first-order Taylor approximation to improve the sampling efficiency. However, such an approximation is inappropriate in discrete state spaces since the approximation error could be large. A novel guidance framework for discrete data is proposed to address this problem: We derive the exact transition rate for the desired distribution given a learned discrete flow matching model, leading to guidance that only requires a single forward pass in each sampling step, significantly improving efficiency. This unified novel framework is general enough, encompassing existing guidance methods as special cases, and it can also be seamlessly applied to the masked diffusion model. We demonstrate the effectiveness of our proposed guidance on energy-guided simulations and preference alignment on text-to-image generation and multimodal understanding tasks. The code is available through https://github.com/WanZhengyan/Discrete-Guidance-Matching/tree/main.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.162423"
    },
    {
        "index": "#102",
        "title": "Why High-rank Neural Networks Generalize?: An Algebraic Framework with RKHSs",
        "link": "/arxiv/2509.21895",
        "arxiv_id": "2509.21895",
        "authors": "Yuka Hashimoto, Sho Sonoda, Isao Ishikawa, Masahiro Ikeda",
        "summary": "We derive a new Rademacher complexity bound for deep neural networks using Koopman operators, group representations, and reproducing kernel Hilbert spaces (RKHSs). The proposed bound describes why the models with high-rank weight matrices generalize well. Although there are existing bounds that attempt to describe this phenomenon, these existing bounds can be applied to limited types of models. We introduce an algebraic representation of neural networks and a kernel function to construct an RKHS to derive a bound for a wider range of realistic models. This work paves the way for the Koopman-based theory for Rademacher complexity bounds to be valid for more practical situations.",
        "subjects": "Machine Learning, Functional Analysis, Representation Theory, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.163061"
    },
    {
        "index": "#104",
        "title": "Zubov-Net: Adaptive Stability for Neural ODEs Reconciling Accuracy with Robustness",
        "link": "/arxiv/2509.21879",
        "arxiv_id": "2509.21879",
        "authors": "Chaoyang Luo, Yan Zou, Nanjing Huang",
        "summary": "Despite neural ordinary differential equations (Neural ODEs) exhibiting intrinsic robustness under input perturbations due to their dynamical systems nature, recent approaches often involve imposing Lyapunov-based stability conditions to provide formal robustness guarantees. However, a fundamental challenge remains: the tension between robustness and accuracy, primarily stemming from the difficulty in imposing appropriate stability conditions. To address this, we propose an adaptive stable learning framework named Zubov-Net, which innovatively reformulates Zubov's equation into a consistency characterization between regions of attraction (RoAs) and prescribed RoAs (PRoAs). Building on this consistency, we introduce a new paradigm for actively controlling the geometry of RoAs by directly optimizing PRoAs to reconcile accuracy and robustness. Our approach is realized through tripartite losses (consistency, classification, and separation losses) and a parallel boundary sampling algorithm that co-optimizes the Neural ODE and the Lyapunov function. To enhance the discriminativity of Lyapunov functions, we design an input-attention-based convex neural network via a softmax attention mechanism that focuses on equilibrium-relevant features and also serves as weight normalization to maintain training stability in deep architectures. Theoretically, we prove that minimizing the tripartite loss guarantees consistent alignment of PRoAs-RoAs, trajectory stability, and non-overlapping PRoAs. Moreover, we establish stochastic convex separability with tighter probability bounds and fewer dimensionality requirements to justify the convex design in Lyapunov functions. Experimentally, Zubov-Net maintains high classification accuracy while significantly improving robustness against various stochastic noises and adversarial attacks.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.163856"
    },
    {
        "index": "#105",
        "title": "Abductive Logical Rule Induction by Bridging Inductive Logic Programming and Multimodal Large Language Models",
        "link": "/arxiv/2509.21874",
        "arxiv_id": "2509.21874",
        "authors": "Yifei Peng, Yaoli Liu, Enbo Xia, Yu Jin, Wang-Zhou Dai, Zhong Ren, Yao-Xiang Ding, Kun Zhou",
        "summary": "We propose ILP-CoT, a method that bridges Inductive Logic Programming (ILP) and Multimodal Large Language Models (MLLMs) for abductive logical rule induction. The task involves both discovering logical facts and inducing logical rules from a small number of unstructured textual or visual inputs, which still remain challenging when solely relying on ILP, due to the requirement of specified background knowledge and high computational cost, or MLLMs, due to the appearance of perceptual hallucinations. Based on the key observation that MLLMs could propose structure-correct rules even under hallucinations, our approach automatically builds ILP tasks with pruned search spaces based on the rule structure proposals from MLLMs, and utilizes ILP system to output rules built upon rectified logical facts and formal inductive reasoning. Its effectiveness is verified through challenging logical induction benchmarks, as well as a potential application of our approach, namely text-to-image customized generation with rule induction. Our code and data are released at https://github.com/future-item/ILP-CoT.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.164176"
    },
    {
        "index": "#106",
        "title": "Beyond RAG vs. Long-Context: Learning Distraction-Aware Retrieval for Efficient Knowledge Grounding",
        "link": "/arxiv/2509.21865",
        "arxiv_id": "2509.21865",
        "authors": "Seong-Woong Shim, Myunsoo Kim, Jae Hyeon Cho, Byung-Jun Lee",
        "summary": "Retrieval-Augmented Generation (RAG) is a framework for grounding Large Language Models (LLMs) in external, up-to-date information. However, recent advancements in context window size allow LLMs to process inputs of up to 128K tokens or more, offering an alternative strategy: supplying the full document context directly to the model, rather than relying on RAG to retrieve a subset of contexts. Nevertheless, this emerging alternative strategy has notable limitations: (i) it is token-inefficient to handle large and potentially redundant contexts; (ii) it exacerbates the `lost in the middle' phenomenon; and (iii) under limited model capacity, it amplifies distraction, ultimately degrading LLM output quality. In this paper, we propose LDAR (Learning Distraction-Aware Retrieval), an adaptive retriever that learns to retrieve contexts in a way that mitigates interference from distracting passages, thereby achieving significantly higher performance with reduced token usage compared to long-context approaches. Extensive experiments across diverse LLM architectures and six knowledge-intensive benchmarks demonstrate the effectiveness and robustness of our approach, highlighting the importance of balancing the trade-off between information coverage and distraction.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.164459"
    },
    {
        "index": "#107",
        "title": "MolSpectLLM: A Molecular Foundation Model Bridging Spectroscopy, Molecule Elucidation, and 3D Structure Generation",
        "link": "/arxiv/2509.21861",
        "arxiv_id": "2509.21861",
        "authors": "Shuaike Shen, Jiaqing Xie, Zhuo Yang, Antong Zhang, Shuzhou Sun, Ben Gao, Tianfan Fu, Biqing Qi, Yuqiang Li",
        "summary": "Recent advances in molecular foundation models have shown impressive performance in molecular property prediction and de novo molecular design, with promising applications in areas such as drug discovery and reaction prediction. Nevertheless, most existing approaches rely exclusively on SMILES representations and overlook both experimental spectra and 3D structural information-two indispensable sources for capturing molecular behavior in real-world scenarios. This limitation reduces their effectiveness in tasks where stereochemistry, spatial conformation, and experimental validation are critical. To overcome these challenges, we propose MolSpectLLM, a molecular foundation model pretrained on Qwen2.5-7B that unifies experimental spectroscopy with molecular 3D structure. By explicitly modeling molecular spectra, MolSpectLLM achieves state-of-the-art performance on spectrum-related tasks, with an average accuracy of 0.53 across NMR, IR, and MS benchmarks. MolSpectLLM also shows strong performance on the spectra analysis task, obtaining 15.5% sequence accuracy and 41.7% token accuracy on Spectra-to-SMILES, substantially outperforming large general-purpose LLMs. More importantly, MolSpectLLM not only achieves strong performance on molecular elucidation tasks, but also generates accurate 3D molecular structures directly from SMILES or spectral inputs, bridging spectral analysis, molecular elucidation, and molecular design.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.164789"
    },
    {
        "index": "#110",
        "title": "On the Complexity Theory of Masked Discrete Diffusion: From $\\mathrm{poly}(1/ε)$ to Nearly $ε$-Free",
        "link": "/arxiv/2509.21835",
        "arxiv_id": "2509.21835",
        "authors": "Xunpeng Huang, Yingyu Lin, Nishant Jain, Kaibo Wang, Difan Zou, Yian Ma, Tong Zhang",
        "summary": "We study masked discrete diffusion -- a flexible paradigm for text generation in which tokens are progressively corrupted by special mask symbols before being denoised. Although this approach has demonstrated strong empirical performance, its theoretical complexity in high-dimensional settings remains insufficiently understood. Existing analyses largely focus on uniform discrete diffusion, and more recent attempts addressing masked diffusion either (1) overlook widely used Euler samplers, (2) impose restrictive bounded-score assumptions, or (3) fail to showcase the advantages of masked discrete diffusion over its uniform counterpart. To address this gap, we show that Euler samplers can achieve $\\epsilon$-accuracy in total variation (TV) with $\\tilde{O}(d^{2}\\epsilon^{-3/2})$ discrete score evaluations, thereby providing the first rigorous analysis of typical Euler sampler in masked discrete diffusion. We then propose a Mask-Aware Truncated Uniformization (MATU) approach that both removes bounded-score assumptions and preserves unbiased discrete score approximation. By exploiting the property that each token can be unmasked at most once, MATU attains a nearly $\\epsilon$-free complexity of $O(d\\,\\ln d\\cdot (1-\\epsilon^2))$. This result surpasses existing uniformization methods under uniform discrete diffusion, eliminating the $\\ln(1/\\epsilon)$ factor and substantially speeding up convergence. Our findings not only provide a rigorous theoretical foundation for masked discrete diffusion, showcasing its practical advantages over uniform diffusion for text generation, but also pave the way for future efforts to analyze diffusion-based language models developed under masking paradigm.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.165742"
    },
    {
        "index": "#112",
        "title": "Sharpness-Aware Minimization Can Hallucinate Minimizers",
        "link": "/arxiv/2509.21818",
        "arxiv_id": "2509.21818",
        "authors": "Chanwoong Park, Uijeong Jang, Ernest K. Ryu, Insoon Yang",
        "summary": "Sharpness-Aware Minimization (SAM) is a widely used method that steers training toward flatter minimizers, which typically generalize better. In this work, however, we show that SAM can converge to hallucinated minimizers -- points that are not minimizers of the original objective. We theoretically prove the existence of such hallucinated minimizers and establish conditions for local convergence to them. We further provide empirical evidence demonstrating that SAM can indeed converge to these points in practice. Finally, we propose a simple yet effective remedy for avoiding hallucinated minimizers.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.166322"
    },
    {
        "index": "#113",
        "title": "Scaling Laws for Neural Material Models",
        "link": "/arxiv/2509.21811",
        "arxiv_id": "2509.21811",
        "authors": "Akshay Trikha, Kyle Chu, Advait Gosai, Parker Szachta, Eric Weiner",
        "summary": "Predicting material properties is crucial for designing better batteries, semiconductors, and medical devices. Deep learning helps scientists quickly find promising materials by predicting their energy, forces, and stresses. Companies scale capacities of deep learning models in multiple domains, such as language modeling, and invest many millions of dollars into such models. Our team analyzes how scaling training data (giving models more information to learn from), model sizes (giving models more capacity to learn patterns), and compute (giving models more computational resources) for neural networks affects their performance for material property prediction. In particular, we trained both transformer and EquiformerV2 neural networks to predict material properties. We find empirical scaling laws for these models: we can predict how increasing each of the three hyperparameters (training data, model size, and compute) affects predictive performance. In particular, the loss $L$ can be measured with a power law relationship $L = \\alpha \\cdot N^{-\\beta}$, where $\\alpha$ and $\\beta$ are constants while $N$ is the relevant hyperparameter. We also incorporate command-line arguments for changing training settings such as the amount of epochs, maximum learning rate, and whether mixed precision is enabled. Future work could entail further investigating scaling laws for other neural network models in this domain, such as GemNet and fully connected networks, to assess how they compare to the models we trained.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.166618"
    },
    {
        "index": "#115",
        "title": "Exploring the Relationships Between Physiological Signals During Automated Fatigue Detection",
        "link": "/arxiv/2509.21794",
        "arxiv_id": "2509.21794",
        "authors": "Kourosh Kakhi, Abbas Khosravi, Roohallah Alizadehsani, U. Rajendra Acharyab",
        "summary": "Fatigue detection using physiological signals is critical in domains such as transportation, healthcare, and performance monitoring. While most studies focus on single modalities, this work examines statistical relationships between signal pairs to improve classification robustness. Using the DROZY dataset, we extracted features from ECG, EMG, EOG, and EEG across 15 signal combinations and evaluated them with Decision Tree, Random Forest, Logistic Regression, and XGBoost. Results show that XGBoost with the EMG EEG combination achieved the best performance. SHAP analysis highlighted ECG EOG correlation as a key feature, and multi signal models consistently outperformed single signal ones. These findings demonstrate that feature level fusion of physiological signals enhances accuracy, interpretability, and practical applicability of fatigue monitoring systems.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.167203"
    },
    {
        "index": "#117",
        "title": "Beyond Formula Complexity: Effective Information Criterion Improves Performance and Interpretability for Symbolic Regression",
        "link": "/arxiv/2509.21780",
        "arxiv_id": "2509.21780",
        "authors": "Zihan Yu, Guanren Wang, Jingtao Ding, Huandong Wang, Yong Li",
        "summary": "Symbolic regression discovers accurate and interpretable formulas to describe given data, thereby providing scientific insights for domain experts and promoting scientific discovery. However, existing symbolic regression methods often use complexity metrics as a proxy for interoperability, which only considers the size of the formula but ignores its internal mathematical structure. Therefore, while they can discover formulas with compact forms, the discovered formulas often have structures that are difficult to analyze or interpret mathematically. In this work, inspired by the observation that physical formulas are typically numerically stable under limited calculation precision, we propose the Effective Information Criterion (EIC). It treats formulas as information processing systems with specific internal structures and identifies the unreasonable structure in them by the loss of significant digits or the amplification of rounding noise as data flows through the system. We find that this criterion reveals the gap between the structural rationality of models discovered by existing symbolic regression algorithms and real-world physical formulas. Combining EIC with various search-based symbolic regression algorithms improves their performance on the Pareto frontier and reduces the irrational structure in the results. Combining EIC with generative-based algorithms reduces the number of samples required for pre-training, improving sample efficiency by 2~4 times. Finally, for different formulas with similar accuracy and complexity, EIC shows a 70.2% agreement with 108 human experts' preferences for formula interpretability, demonstrating that EIC, by measuring the unreasonable structures in formulas, actually reflects the formula's interpretability.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.167798"
    },
    {
        "index": "#118",
        "title": "Machine Learning and AI Applied to fNIRS Data Reveals Novel Brain Activity Biomarkers in Stable Subclinical Multiple Sclerosis",
        "link": "/arxiv/2509.21770",
        "arxiv_id": "2509.21770",
        "authors": "Sadman Saumik Islam, Bruna Dalcin Baldasso, Davide Cattaneo, Xianta Jiang, Michelle Ploughman",
        "summary": "People with Multiple Sclerosis (MS) complain of problems with hand dexterity and cognitive fatigue. However, in many cases, impairments are subtle and difficult to detect. Functional near-infrared spectroscopy (fNIRS) is a non-invasive neuroimaging technique that measures brain hemodynamic responses during cognitive or motor tasks. We aimed to detect brain activity biomarkers that could explain subjective reports of cognitive fatigue while completing dexterous tasks and provide targets for future brain stimulation treatments. We recruited 15 people with MS who did not have a hand (Nine Hole Peg Test [NHPT]), mobility, or cognitive impairment, and 12 age- and sex-matched controls. Participants completed two types of hand dexterity tasks with their dominant hand, single task and dual task (NHPT while holding a ball between the fifth finger and hypothenar eminence of the same hand). We analyzed fNIRS data (oxygenated and deoxygenated hemoglobin levels) using a machine learning framework to classify MS patients from controls based on their brain activation patterns in bilateral prefrontal and sensorimotor cortices. The K-Nearest Neighbor classifier achieved an accuracy of 75.0% for single manual dexterity tasks and 66.7% for the more complex dual manual dexterity tasks. Using XAI, we found that the most important brain regions contributing to the machine learning model were the supramarginal/angular gyri and the precentral gyrus (sensory integration and motor regions) of the ipsilateral hemisphere, with suppressed activity and slower neurovascular response in the MS group. During both tasks, deoxygenated hemoglobin levels were better predictors than the conventional measure of oxygenated hemoglobin. This nonconventional method of fNIRS data analysis revealed novel brain activity biomarkers that can help develop personalized brain stimulation targets.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.168093"
    },
    {
        "index": "#119",
        "title": "Reparameterizing 4DVAR with neural fields",
        "link": "/arxiv/2509.21751",
        "arxiv_id": "2509.21751",
        "authors": "Jaemin Oh",
        "summary": "Four-dimensional variational data assimilation (4DVAR) is a cornerstone of numerical weather prediction, but its cost function is difficult to optimize and computationally intensive. We propose a neural field-based reformulation in which the full spatiotemporal state is represented as a continuous function parameterized by a neural network. This reparameterization removes the time-sequential dependency of classical 4DVAR, enabling parallel-in-time optimization in parameter space. Physical constraints are incorporated directly through a physics-informed loss, simplifying implementation and reducing computational cost. We evaluate the method on the two-dimensional incompressible Navier--Stokes equations with Kolmogorov forcing. Compared to a baseline 4DVAR implementation, the neural reparameterized variants produce more stable initial condition estimates without spurious oscillations. Notably, unlike most machine learning-based approaches, our framework does not require access to ground-truth states or reanalysis data, broadening its applicability to settings with limited reference information.",
        "subjects": "Machine Learning, Computational Physics, Fluid Dynamics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.168365"
    },
    {
        "index": "#125",
        "title": "Information-Theoretic Bayesian Optimization for Bilevel Optimization Problems",
        "link": "/arxiv/2509.21725",
        "arxiv_id": "2509.21725",
        "authors": "Takuya Kanayama, Yuki Ito, Tomoyuki Tamura, Masayuki Karasuyama",
        "summary": "A bilevel optimization problem consists of two optimization problems nested as an upper- and a lower-level problem, in which the optimality of the lower-level problem defines a constraint for the upper-level problem. This paper considers Bayesian optimization (BO) for the case that both the upper- and lower-levels involve expensive black-box functions. Because of its nested structure, bilevel optimization has a complex problem definition and, compared with other standard extensions of BO such as multi-objective or constraint settings, it has not been widely studied. We propose an information-theoretic approach that considers the information gain of both the upper- and lower-optimal solutions and values. This enables us to define a unified criterion that measures the benefit for both level problems, simultaneously. Further, we also show a practical lower bound based approach to evaluating the information gain. We empirically demonstrate the effectiveness of our proposed method through several benchmark datasets.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.170285"
    },
    {
        "index": "#126",
        "title": "A Unifying Framework for Parallelizing Sequential Models with Linear Dynamical Systems",
        "link": "/arxiv/2509.21716",
        "arxiv_id": "2509.21716",
        "authors": "Xavier Gonzalez, E. Kelly Buchanan, Hyun Dong Lee, Jerry Weihong Liu, Ke Alexander Wang, David M. Zoltowski, Christopher Ré, Scott W. Linderman",
        "summary": "Harnessing parallelism in seemingly sequential models is a central challenge for modern machine learning. Several approaches have been proposed for evaluating sequential processes in parallel using fixed-point methods, like Newton, Picard, and Jacobi iterations. In this work, we show that these methods can be understood within a common framework based on linear dynamical systems (LDSs), where different iteration schemes arise naturally as approximate linearizations of a nonlinear recursion. This unifying view highlights shared principles behind these techniques and clarifies when particular fixed-point methods are most likely to be effective. By bridging diverse algorithms through the language of LDSs, our framework provides a clearer theoretical foundation for parallelizing sequential models and points toward new opportunities for efficient and scalable computation.",
        "subjects": "Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.170605"
    },
    {
        "index": "#127",
        "title": "PQFed: A Privacy-Preserving Quality-Controlled Federated Learning Framework",
        "link": "/arxiv/2509.21704",
        "arxiv_id": "2509.21704",
        "authors": "Weiqi Yue, Wenbiao Li, Yuzhou Jiang, Anisa Halimi, Roger French, Erman Ayday",
        "summary": "Federated learning enables collaborative model training without sharing raw data, but data heterogeneity consistently challenges the performance of the global model. Traditional optimization methods often rely on collaborative global model training involving all clients, followed by local adaptation to improve individual performance. In this work, we focus on early-stage quality control and propose PQFed, a novel privacy-preserving personalized federated learning framework that designs customized training strategies for each client prior to the federated training process. PQFed extracts representative features from each client's raw data and applies clustering techniques to estimate inter-client dataset similarity. Based on these similarity estimates, the framework implements a client selection strategy that enables each client to collaborate with others who have compatible data distributions. We evaluate PQFed on two benchmark datasets, CIFAR-10 and MNIST, integrated with three existing federated learning algorithms. Experimental results show that PQFed consistently improves the target client's model performance, even with a limited number of participants. We further benchmark PQFed against a baseline cluster-based algorithm, IFCA, and observe that PQFed also achieves better performance in low-participation scenarios. These findings highlight PQFed's scalability and effectiveness in personalized federated learning settings.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.170899"
    },
    {
        "index": "#128",
        "title": "Downscaling human mobility data based on demographic socioeconomic and commuting characteristics using interpretable machine learning methods",
        "link": "/arxiv/2509.21703",
        "arxiv_id": "2509.21703",
        "authors": "Yuqin Jiang, Andrey A. Popov, Tianle Duan, Qingchun Li",
        "summary": "Understanding urban human mobility patterns at various spatial levels is essential for social science. This study presents a machine learning framework to downscale origin-destination (OD) taxi trips flows in New York City from a larger spatial unit to a smaller spatial unit. First, correlations between OD trips and demographic, socioeconomic, and commuting characteristics are developed using four models: Linear Regression (LR), Random Forest (RF), Support Vector Machine (SVM), and Neural Networks (NN). Second, a perturbation-based sensitivity analysis is applied to interpret variable importance for nonlinear models. The results show that the linear regression model failed to capture the complex variable interactions. While NN performs best with the training and testing datasets, SVM shows the best generalization ability in downscaling performance. The methodology presented in this study provides both analytical advancement and practical applications to improve transportation services and urban development.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.171176"
    },
    {
        "index": "#129",
        "title": "Exact Subgraph Isomorphism Network for Predictive Graph Mining",
        "link": "/arxiv/2509.21699",
        "arxiv_id": "2509.21699",
        "authors": "Taiga Kojima, Masayuki Karasuyama",
        "summary": "In the graph-level prediction task (predict a label for a given graph), the information contained in subgraphs of the input graph plays a key role. In this paper, we propose Exact subgraph Isomorphism Network (EIN), which combines the exact subgraph enumeration, neural network, and a sparse regularization. In general, building a graph-level prediction model achieving high discriminative ability along with interpretability is still a challenging problem. Our combination of the subgraph enumeration and neural network contributes to high discriminative ability about the subgraph structure of the input graph. Further, the sparse regularization in EIN enables us 1) to derive an effective pruning strategy that mitigates computational difficulty of the enumeration while maintaining the prediction performance, and 2) to identify important subgraphs that contributes to high interpretability. We empirically show that EIN has sufficiently high prediction performance compared with standard graph neural network models, and also, we show examples of post-hoc analysis based on the selected subgraphs.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.171445"
    },
    {
        "index": "#130",
        "title": "Wav2Arrest 2.0: Long-Horizon Cardiac Arrest Prediction with Time-to-Event Modeling, Identity-Invariance, and Pseudo-Lab Alignment",
        "link": "/arxiv/2509.21695",
        "arxiv_id": "2509.21695",
        "authors": "Saurabh Kataria, Davood Fattahi, Minxiao Wang, Ran Xiao, Matthew Clark, Timothy Ruchti, Mark Mai, Xiao Hu",
        "summary": "High-frequency physiological waveform modality offers deep, real-time insights into patient status. Recently, physiological foundation models based on Photoplethysmography (PPG), such as PPG-GPT, have been shown to predict critical events, including Cardiac Arrest (CA). However, their powerful representation still needs to be leveraged suitably, especially when the downstream data/label is scarce. We offer three orthogonal improvements to improve PPG-only CA systems by using minimal auxiliary information. First, we propose to use time-to-event modeling, either through simple regression to the event onset time or by pursuing fine-grained discrete survival modeling. Second, we encourage the model to learn CA-focused features by making them patient-identity invariant. This is achieved by first training the largest-scale de-identified biometric identification model, referred to as the p-vector, and subsequently using it adversarially to deconfound cues, such as person identity, that may cause overfitting through memorization. Third, we propose regression on the pseudo-lab values generated by pre-trained auxiliary estimator networks. This is crucial since true blood lab measurements, such as lactate, sodium, troponin, and potassium, are collected sparingly. Via zero-shot prediction, the auxiliary networks can enrich cardiac arrest waveform labels and generate pseudo-continuous estimates as targets. Our proposals can independently improve the 24-hour time-averaged AUC from the 0.74 to the 0.78-0.80 range. We primarily improve over longer time horizons with minimal degradation near the event, thus pushing the Early Warning System research. Finally, we pursue multi-task formulation and diagnose it with a high gradient conflict rate among competing losses, which we alleviate via the PCGrad optimization technique.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.171783"
    },
    {
        "index": "#131",
        "title": "SpecMER: Fast Protein Generation with K-mer Guided Speculative Decoding",
        "link": "/arxiv/2509.21689",
        "arxiv_id": "2509.21689",
        "authors": "Thomas Walton, Darin Tsui, Aryan Musharaf, Amirali Aghazadeh",
        "summary": "Autoregressive models have transformed protein engineering by enabling the generation of novel protein sequences beyond those found in nature. However, their sequential inference introduces significant latency, limiting their utility in high-throughput protein screening. Speculative decoding accelerates generation by employing a lightweight draft model to sample tokens, which a larger target model then verifies and refines. Yet, in protein sequence generation, draft models are typically agnostic to the structural and functional constraints of the target protein, leading to biologically implausible outputs and a shift in the likelihood distribution of generated sequences. We introduce SpecMER (Speculative Decoding via k-mer Guidance), a novel framework that incorporates biological, structural, and functional priors using k-mer motifs extracted from multiple sequence alignments. By scoring candidate sequences in parallel and selecting those most consistent with known biological patterns, SpecMER significantly improves sequence plausibility while retaining the efficiency of speculative decoding. SpecMER achieves 24-32% speedup over standard autoregressive decoding, along with higher acceptance rates and improved sequence likelihoods.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.172061"
    },
    {
        "index": "#132",
        "title": "Prophecy: Inferring Formal Properties from Neuron Activations",
        "link": "/arxiv/2509.21677",
        "arxiv_id": "2509.21677",
        "authors": "Divya Gopinath, Corina S. Pasareanu, Muhammad Usman",
        "summary": "We present Prophecy, a tool for automatically inferring formal properties of feed-forward neural networks. Prophecy is based on the observation that a significant part of the logic of feed-forward networks is captured in the activation status of the neurons at inner layers. Prophecy works by extracting rules based on neuron activations (values or on/off statuses) as preconditions that imply certain desirable output property, e.g., the prediction being a certain class. These rules represent network properties captured in the hidden layers that imply the desired output behavior. We present the architecture of the tool, highlight its features and demonstrate its usage on different types of models and output properties. We present an overview of its applications, such as inferring and proving formal explanations of neural networks, compositional verification, run-time monitoring, repair, and others. We also show novel results highlighting its potential in the era of large vision-language models.",
        "subjects": "Machine Learning, Software Engineering",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.172349"
    },
    {
        "index": "#133",
        "title": "Scalable Second-order Riemannian Optimization for $K$-means Clustering",
        "link": "/arxiv/2509.21675",
        "arxiv_id": "2509.21675",
        "authors": "Peng Xu, Chun-Ying Hou, Xiaohui Chen, Richard Y. Zhang",
        "summary": "Clustering is a hard discrete optimization problem. Nonconvex approaches such as low-rank semidefinite programming (SDP) have recently demonstrated promising statistical and local algorithmic guarantees for cluster recovery. Due to the combinatorial structure of the $K$-means clustering problem, current relaxation algorithms struggle to balance their constraint feasibility and objective optimality, presenting tremendous challenges in computing the second-order critical points with rigorous guarantees. In this paper, we provide a new formulation of the $K$-means problem as a smooth unconstrained optimization over a submanifold and characterize its Riemannian structures to allow it to be solved using a second-order cubic-regularized Riemannian Newton algorithm. By factorizing the $K$-means manifold into a product manifold, we show how each Newton subproblem can be solved in linear time. Our numerical experiments show that the proposed method converges significantly faster than the state-of-the-art first-order nonnegative low-rank factorization method, while achieving similarly optimal statistical accuracy.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.172652"
    },
    {
        "index": "#135",
        "title": "Neuroprobe: Evaluating Intracranial Brain Responses to Naturalistic Stimuli",
        "link": "/arxiv/2509.21671",
        "arxiv_id": "2509.21671",
        "authors": "Andrii Zahorodnii, Christopher Wang, Bennett Stankovits, Charikleia Moraitaki, Geeling Chau, Andrei Barbu, Boris Katz, Ila R Fiete",
        "summary": "High-resolution neural datasets enable foundation models for the next generation of brain-computer interfaces and neurological treatments. The community requires rigorous benchmarks to discriminate between competing modeling approaches, yet no standardized evaluation frameworks exist for intracranial EEG (iEEG) recordings. To address this gap, we present Neuroprobe: a suite of decoding tasks for studying multi-modal language processing in the brain. Unlike scalp EEG, intracranial EEG requires invasive surgery to implant electrodes that record neural activity directly from the brain with minimal signal distortion. Neuroprobe is built on the BrainTreebank dataset, which consists of 40 hours of iEEG recordings from 10 human subjects performing a naturalistic movie viewing task. Neuroprobe serves two critical functions. First, it is a mine from which neuroscience insights can be drawn. Its high temporal and spatial resolution allows researchers to systematically determine when and where computations for each aspect of language processing occur in the brain by measuring the decodability of each feature across time and all electrode locations. Using Neuroprobe, we visualize how information flows from the superior temporal gyrus to the prefrontal cortex, and the progression from simple auditory features to more complex language features in a purely data-driven manner. Second, as the field moves toward neural foundation models, Neuroprobe provides a rigorous framework for comparing competing architectures and training protocols. We found that the linear baseline is surprisingly strong, beating frontier foundation models on many tasks. Neuroprobe is designed with computational efficiency and ease of use in mind. We make the code for Neuroprobe openly available and maintain a public leaderboard, aiming to enable rapid progress in the field of iEEG foundation models, at https://neuroprobe.dev/",
        "subjects": "Machine Learning, Neurons and Cognition",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.173293"
    },
    {
        "index": "#138",
        "title": "MMPlanner: Zero-Shot Multimodal Procedural Planning with Chain-of-Thought Object State Reasoning",
        "link": "/arxiv/2509.21662",
        "arxiv_id": "2509.21662",
        "authors": "Afrina Tabassum, Bin Guo, Xiyao Ma, Hoda Eldardiry, Ismini Lourentzou",
        "summary": "Multimodal Procedural Planning (MPP) aims to generate step-by-step instructions that combine text and images, with the central challenge of preserving object-state consistency across modalities while producing informative plans. Existing approaches often leverage large language models (LLMs) to refine textual steps; however, visual object-state alignment and systematic evaluation are largely underexplored. We present MMPlanner, a zero-shot MPP framework that introduces Object State Reasoning Chain-of-Thought (OSR-CoT) prompting to explicitly model object-state transitions and generate accurate multimodal plans. To assess plan quality, we design LLM-as-a-judge protocols for planning accuracy and cross-modal alignment, and further propose a visual step-reordering task to measure temporal coherence. Experiments on RECIPEPLAN and WIKIPLAN show that MMPlanner achieves state-of-the-art performance, improving textual planning by +6.8%, cross-modal alignment by +11.9%, and visual step ordering by +26.7%",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.174172"
    },
    {
        "index": "#139",
        "title": "A Systematic Review of Conformal Inference Procedures for Treatment Effect Estimation: Methods and Challenges",
        "link": "/arxiv/2509.21660",
        "arxiv_id": "2509.21660",
        "authors": "Pascal Memmesheimer, Vincent Heuveline, Jürgen Hesser",
        "summary": "Treatment effect estimation is essential for informed decision-making in many fields such as healthcare, economics, and public policy. While flexible machine learning models have been widely applied for estimating heterogeneous treatment effects, quantifying the inherent uncertainty of their point predictions remains an issue. Recent advancements in conformal prediction address this limitation by allowing for inexpensive computation, as well as distribution shifts, while still providing frequentist, finite-sample coverage guarantees under minimal assumptions for any point-predictor model. This advancement holds significant potential for improving decision-making in especially high-stakes environments. In this work, we perform a systematic review regarding conformal prediction methods for treatment effect estimation and provide for both the necessary theoretical background. Through a systematic filtering process, we select and analyze eleven key papers, identifying and describing current state-of-the-art methods in this area. Based on our findings, we propose directions for future research.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.174455"
    },
    {
        "index": "#140",
        "title": "RED-DiffEq: Regularization by denoising diffusion models for solving inverse PDE problems with application to full waveform inversion",
        "link": "/arxiv/2509.21659",
        "arxiv_id": "2509.21659",
        "authors": "Siming Shan, Min Zhu, Youzuo Lin, Lu Lu",
        "summary": "Partial differential equation (PDE)-governed inverse problems are fundamental across various scientific and engineering applications; yet they face significant challenges due to nonlinearity, ill-posedness, and sensitivity to noise. Here, we introduce a new computational framework, RED-DiffEq, by integrating physics-driven inversion and data-driven learning. RED-DiffEq leverages pretrained diffusion models as a regularization mechanism for PDE-governed inverse problems. We apply RED-DiffEq to solve the full waveform inversion problem in geophysics, a challenging seismic imaging technique that seeks to reconstruct high-resolution subsurface velocity models from seismic measurement data. Our method shows enhanced accuracy and robustness compared to conventional methods. Additionally, it exhibits strong generalization ability to more complex velocity models that the diffusion model is not trained on. Our framework can also be directly applied to diverse PDE-governed inverse problems.",
        "subjects": "Machine Learning, Geophysics",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.174754"
    },
    {
        "index": "#141",
        "title": "Differentiable Structure Learning for General Binary Data",
        "link": "/arxiv/2509.21658",
        "arxiv_id": "2509.21658",
        "authors": "Chang Deng, Bryon Aragam",
        "summary": "Existing methods for differentiable structure learning in discrete data typically assume that the data are generated from specific structural equation models. However, these assumptions may not align with the true data-generating process, which limits the general applicability of such methods. Furthermore, current approaches often ignore the complex dependence structure inherent in discrete data and consider only linear effects. We propose a differentiable structure learning framework that is capable of capturing arbitrary dependencies among discrete variables. We show that although general discrete models are unidentifiable from purely observational data, it is possible to characterize the complete set of compatible parameters and structures. Additionally, we establish identifiability up to Markov equivalence under mild assumptions. We formulate the learning problem as a single differentiable optimization task in the most general form, thereby avoiding the unrealistic simplifications adopted by previous methods. Empirical results demonstrate that our approach effectively captures complex relationships in discrete data.",
        "subjects": "Machine Learning, Statistics Theory, Methodology, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.175053"
    },
    {
        "index": "#142",
        "title": "DriftLite: Lightweight Drift Control for Inference-Time Scaling of Diffusion Models",
        "link": "/arxiv/2509.21655",
        "arxiv_id": "2509.21655",
        "authors": "Yinuo Ren, Wenhao Gao, Lexing Ying, Grant M. Rotskoff, Jiequn Han",
        "summary": "We study inference-time scaling for diffusion models, where the goal is to adapt a pre-trained model to new target distributions without retraining. Existing guidance-based methods are simple but introduce bias, while particle-based corrections suffer from weight degeneracy and high computational cost. We introduce DriftLite, a lightweight, training-free particle-based approach that steers the inference dynamics on the fly with provably optimal stability control. DriftLite exploits a previously unexplored degree of freedom in the Fokker-Planck equation between the drift and particle potential, and yields two practical instantiations: Variance- and Energy-Controlling Guidance (VCG/ECG) for approximating the optimal drift with minimal overhead. Across Gaussian mixture models, particle systems, and large-scale protein-ligand co-folding problems, DriftLite consistently reduces variance and improves sample quality over pure guidance and sequential Monte Carlo baselines. These results highlight a principled, efficient route toward scalable inference-time adaptation of diffusion models.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.175358"
    },
    {
        "index": "#144",
        "title": "Understanding and Enhancing Mask-Based Pretraining towards Universal Representations",
        "link": "/arxiv/2509.21650",
        "arxiv_id": "2509.21650",
        "authors": "Mingze Dong, Leda Wang, Yuval Kluger",
        "summary": "Mask-based pretraining has become a cornerstone of modern large-scale models across language, vision, and recently biology. Despite its empirical success, its role and limits in learning data representations have been unclear. In this work, we show that the behavior of mask-based pretraining can be directly characterized by test risk in high-dimensional minimum-norm (\"ridge-less\") linear regression, without relying on further model specifications. Further analysis of linear models uncovers several novel aspects of mask-based pretraining. The theoretical framework and its implications have been validated across diverse neural architectures (including MLPs, CNNs, and Transformers) applied to both vision and language tasks. Guided by our theory, we propose an embarrassingly simple yet overlooked pretraining scheme named Randomly Random Mask AutoEncoding (R$^2$MAE), which enforces capturing multi-scale features from data and is able to outperform optimal fixed mask ratio settings in our linear model framework. We implement R$^2$MAE in vision, language, DNA sequence, and single-cell models, where it consistently outperforms standard and more complicated masking schemes, leading to improvements for state-of-the-art models. Our code is available at: https://github.com/MingzeDong/r2mae",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.175922"
    },
    {
        "index": "#145",
        "title": "Blockwise Hadamard high-Rank Adaptation for Parameter-Efficient LLM Fine-Tuning",
        "link": "/arxiv/2509.21637",
        "arxiv_id": "2509.21637",
        "authors": "Feng Yu, Jia Hu, Geyong Min",
        "summary": "Parameter-efficient fine-tuning (PEFT) methods must be resource-efficient yet handle heterogeneous reasoning transformations, and classical low-rank adaptation (LoRA) is constrained by the nominal rank $r$. Hadamard-style extensions like HiRA raise the nominal rank but couple every update to the global energy pattern of the frozen weight matrix, while ABBA trades this inductive bias for fully learned dense intermediates. To address the limitation of global modulation, we propose Block Hadamard high-Rank Adaptation (BHRA), which partitions each weight matrix and applies HiRA-style multiplicative modulation independently within every block, preserving the PEFT parameter footprint while unlocking localized rank amplification. Our empirical analyses reveal that this blockwise design maintains rich spectra across rank budgets, mitigating the collapse induced by global modulation. Across eight commonsense reasoning tasks and two arithmetic benchmarks with Llama-3.2 1B/3B, Mistral-7B, and Gemma-2 9B, BHRA consistently surpasses strong PEFT baselines under matched parameter budgets.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.176198"
    },
    {
        "index": "#146",
        "title": "Shoot from the HIP: Hessian Interatomic Potentials without derivatives",
        "link": "/arxiv/2509.21624",
        "arxiv_id": "2509.21624",
        "authors": "Andreas Burger, Luca Thiede, Nikolaj Rønne, Varinia Bernales, Nandita Vijaykumar, Tejs Vegge, Arghya Bhowmik, Alan Aspuru-Guzik",
        "summary": "Fundamental tasks in computational chemistry, from transition state search to vibrational analysis, rely on molecular Hessians, which are the second derivatives of the potential energy. Yet, Hessians are computationally expensive to calculate and scale poorly with system size, with both quantum mechanical methods and neural networks. In this work, we demonstrate that Hessians can be predicted directly from a deep learning model, without relying on automatic differentiation or finite differences. We observe that one can construct SE(3)-equivariant, symmetric Hessians from irreducible representations (irrep) features up to degree $l$=2 computed during message passing in graph neural networks. This makes HIP Hessians one to two orders of magnitude faster, more accurate, more memory efficient, easier to train, and enables more favorable scaling with system size. We validate our predictions across a wide range of downstream tasks, demonstrating consistently superior performance for transition state search, accelerated geometry optimization, zero-point energy corrections, and vibrational analysis benchmarks. We open-source the HIP codebase and model weights to enable further development of the direct prediction of Hessians at https://github.com/BurgerAndreas/hip",
        "subjects": "Machine Learning, Chemical Physics, Computational Physics",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.176540"
    },
    {
        "index": "#147",
        "title": "PreLoRA: Hybrid Pre-training of Vision Transformers with Full Training and Low-Rank Adapters",
        "link": "/arxiv/2509.21619",
        "arxiv_id": "2509.21619",
        "authors": "Krishu K Thapa, Reet Barik, Krishna Teja Chitty-Venkata, Murali Emani, Venkatram Vishwanath",
        "summary": "Training large models ranging from millions to billions of parameters is highly resource-intensive, requiring significant time, compute, and memory. It is observed that most of the learning (higher change in weights) takes place in the earlier stage of the training loop. These changes stabilize as training continues, enabling them to be captured by matrices of a low intrinsic rank. Therefore, we propose an approach to identify such states of partial convergence and dynamically switch from full parameter training to Low-Rank Adaptation (LoRA) on the ViT-Large model. We introduce a flexible approach that leverages user-defined hyperparameters to determine the switching point and assign a rank specific to each module layer based on its level of convergence. Experimental results show that this approach preserves model accuracy while reducing the number of trainable parameters to 10% of its original size, resulting in a 3x improvement in throughput, and a 1.5x reduction in average training time per epoch while also reducing GPU memory consumption by 20%",
        "subjects": "Machine Learning, Performance",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.176846"
    },
    {
        "index": "#149",
        "title": "Causal Abstraction Inference under Lossy Representations",
        "link": "/arxiv/2509.21607",
        "arxiv_id": "2509.21607",
        "authors": "Kevin Xia, Elias Bareinboim",
        "summary": "The study of causal abstractions bridges two integral components of human intelligence: the ability to determine cause and effect, and the ability to interpret complex patterns into abstract concepts. Formally, causal abstraction frameworks define connections between complicated low-level causal models and simple high-level ones. One major limitation of most existing definitions is that they are not well-defined when considering lossy abstraction functions in which multiple low-level interventions can have different effects while mapping to the same high-level intervention (an assumption called the abstract invariance condition). In this paper, we introduce a new type of abstractions called projected abstractions that generalize existing definitions to accommodate lossy representations. We show how to construct a projected abstraction from the low-level model and how it translates equivalent observational, interventional, and counterfactual causal queries from low to high-level. Given that the true model is rarely available in practice we prove a new graphical criteria for identifying and estimating high-level causal queries from limited low-level data. Finally, we experimentally show the effectiveness of projected abstraction models in high-dimensional image settings.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.177404"
    },
    {
        "index": "#150",
        "title": "Task-Agnostic Federated Continual Learning via Replay-Free Gradient Projection",
        "link": "/arxiv/2509.21606",
        "arxiv_id": "2509.21606",
        "authors": "Seohyeon Cha, Huancheng Chen, Haris Vikalo",
        "summary": "Federated continual learning (FCL) enables distributed client devices to learn from streaming data across diverse and evolving tasks. A major challenge to continual learning, catastrophic forgetting, is exacerbated in decentralized settings by the data heterogeneity, constrained communication and privacy concerns. We propose Federated gradient Projection-based Continual Learning with Task Identity Prediction (FedProTIP), a novel FCL framework that mitigates forgetting by projecting client updates onto the orthogonal complement of the subspace spanned by previously learned representations of the global model. This projection reduces interference with earlier tasks and preserves performance across the task sequence. To further address the challenge of task-agnostic inference, we incorporate a lightweight mechanism that leverages core bases from prior tasks to predict task identity and dynamically adjust the global model's outputs. Extensive experiments across standard FCL benchmarks demonstrate that FedProTIP significantly outperforms state-of-the-art methods in average accuracy, particularly in settings where task identities are a priori unknown.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.177681"
    },
    {
        "index": "#151",
        "title": "GenUQ: Predictive Uncertainty Estimates via Generative Hyper-Networks",
        "link": "/arxiv/2509.21605",
        "arxiv_id": "2509.21605",
        "authors": "Tian Yu Yen, Reese E. Jones, Ravi G. Patel",
        "summary": "Operator learning is a recently developed generalization of regression to mappings between functions. It promises to drastically reduce expensive numerical integration of PDEs to fast evaluations of mappings between functional states of a system, i.e., surrogate and reduced-order modeling. Operator learning has already found applications in several areas such as modeling sea ice, combustion, and atmospheric physics. Recent approaches towards integrating uncertainty quantification into the operator models have relied on likelihood based methods to infer parameter distributions from noisy data. However, stochastic operators may yield actions from which a likelihood is difficult or impossible to construct. In this paper, we introduce, GenUQ, a measure-theoretic approach to UQ that avoids constructing a likelihood by introducing a generative hyper-network model that produces parameter distributions consistent with observed data. We demonstrate that GenUQ outperforms other UQ methods in three example problems, recovering a manufactured operator, learning the solution operator to a stochastic elliptic PDE, and modeling the failure location of porous steel under tension.",
        "subjects": "Machine Learning, Numerical Analysis, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.177975"
    },
    {
        "index": "#153",
        "title": "Interpretable time series analysis with Gumbel dynamics",
        "link": "/arxiv/2509.21578",
        "arxiv_id": "2509.21578",
        "authors": "Yiliu Wang, Timothy Doyeon Kim, Eric Shea-Brown, Uygar Sümbül",
        "summary": "Switching dynamical systems can model complicated time series data while maintaining interpretability by inferring a finite set of dynamics primitives and explaining different portions of the observed time series with one of these primitives. However, due to the discrete nature of this set, such models struggle to capture smooth, variable-speed transitions, as well as stochastic mixtures of overlapping states, and the inferred dynamics often display spurious rapid switching on real-world datasets. Here, we propose the Gumbel Dynamical Model (GDM). First, by introducing a continuous relaxation of discrete states and a different noise model defined on the relaxed-discrete state space via the Gumbel distribution, GDM expands the set of available state dynamics, allowing the model to approximate smoother and non-stationary ground-truth dynamics more faithfully. Second, the relaxation makes the model fully differentiable, enabling fast and scalable training with standard gradient descent methods. We validate our approach on standard simulation datasets and highlight its ability to model soft, sticky states and transitions in a stochastic setting. Furthermore, we apply our model to two real-world datasets, demonstrating its ability to infer interpretable states in stochastic time series with multiple dynamics, a setting where traditional methods often fail.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.178559"
    },
    {
        "index": "#154",
        "title": "Machine Learning. The Science of Selection under Uncertainty",
        "link": "/arxiv/2509.21547",
        "arxiv_id": "2509.21547",
        "authors": "Yevgeny Seldin",
        "summary": "Learning, whether natural or artificial, is a process of selection. It starts with a set of candidate options and selects the more successful ones. In the case of machine learning the selection is done based on empirical estimates of prediction accuracy of candidate prediction rules on some data. Due to randomness of data sampling the empirical estimates are inherently noisy, leading to selection under uncertainty. The book provides statistical tools to obtain theoretical guarantees on the outcome of selection under uncertainty. We start with concentration of measure inequalities, which are the main statistical instrument for controlling how much an empirical estimate of expectation of a function deviates from the true expectation. The book covers a broad range of inequalities, including Markov's, Chebyshev's, Hoeffding's, Bernstein's, Empirical Bernstein's, Unexpected Bernstein's, kl, and split-kl. We then study the classical (offline) supervised learning and provide a range of tools for deriving generalization bounds, including Occam's razor, Vapnik-Chervonenkis analysis, and PAC-Bayesian analysis. The latter is further applied to derive generalization guarantees for weighted majority votes. After covering the offline setting, we turn our attention to online learning. We present the space of online learning problems characterized by environmental feedback, environmental resistance, and structural complexity. A common performance measure in online learning is regret, which compares performance of an algorithm to performance of the best prediction rule in hindsight, out of a restricted set of prediction rules. We present tools for deriving regret bounds in stochastic and adversarial environments, and under full information and bandit feedback.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.178834"
    },
    {
        "index": "#155",
        "title": "Evidence for Limited Metacognition in LLMs",
        "link": "/arxiv/2509.21545",
        "arxiv_id": "2509.21545",
        "authors": "Christopher Ackerman",
        "summary": "The possibility of LLM self-awareness and even sentience is gaining increasing public attention and has major safety and policy implications, but the science of measuring them is still in a nascent state. Here we introduce a novel methodology for quantitatively evaluating metacognitive abilities in LLMs. Taking inspiration from research on metacognition in nonhuman animals, our approach eschews model self-reports and instead tests to what degree models can strategically deploy knowledge of internal states. Using two experimental paradigms, we demonstrate that frontier LLMs introduced since early 2024 show increasingly strong evidence of certain metacognitive abilities, specifically the ability to assess and utilize their own confidence in their ability to answer factual and reasoning questions correctly and the ability to anticipate what answers they would give and utilize that information appropriately. We buttress these behavioral findings with an analysis of the token probabilities returned by the models, which suggests the presence of an upstream internal signal that could provide the basis for metacognition. We further find that these abilities 1) are limited in resolution, 2) emerge in context-dependent manners, and 3) seem to be qualitatively different from those of humans. We also report intriguing differences across models of similar capabilities, suggesting that LLM post-training may have a role in developing metacognitive abilities.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.179085"
    },
    {
        "index": "#156",
        "title": "A circuit for predicting hierarchical structure in-context in Large Language Models",
        "link": "/arxiv/2509.21534",
        "arxiv_id": "2509.21534",
        "authors": "Tankred Saanum, Can Demircan, Samuel J. Gershman, Eric Schulz",
        "summary": "Large Language Models (LLMs) excel at in-context learning, the ability to use information provided as context to improve prediction of future tokens. Induction heads have been argued to play a crucial role for in-context learning in Transformer Language Models. These attention heads make a token attend to successors of past occurrences of the same token in the input. This basic mechanism supports LLMs' ability to copy and predict repeating patterns. However, it is unclear if this same mechanism can support in-context learning of more complex repetitive patterns with hierarchical structure. Natural language is teeming with such cases: The article \"the\" in English usually prefaces multiple nouns in a text. When predicting which token succeeds a particular instance of \"the\", we need to integrate further contextual cues from the text to predict the correct noun. If induction heads naively attend to all past instances of successor tokens of \"the\" in a context-independent manner, they cannot support this level of contextual information integration. In this study, we design a synthetic in-context learning task, where tokens are repeated with hierarchical dependencies. Here, attending uniformly to all successor tokens is not sufficient to accurately predict future tokens. Evaluating a range of LLMs on these token sequences and natural language analogues, we find adaptive induction heads that support prediction by learning what to attend to in-context. Next, we investigate how induction heads themselves learn in-context. We find evidence that learning is supported by attention heads that uncover a set of latent contexts, determining the different token transition relationships. Overall, we not only show that LLMs have induction heads that learn, but offer a complete mechanistic account of how LLMs learn to predict higher-order repetitive patterns in-context.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.179375"
    },
    {
        "index": "#157",
        "title": "Expert-guided Clinical Text Augmentation via Query-Based Model Collaboration",
        "link": "/arxiv/2509.21530",
        "arxiv_id": "2509.21530",
        "authors": "Dongkyu Cho, Miao Zhang, Rumi Chunara",
        "summary": "Data augmentation is a widely used strategy to improve model robustness and generalization by enriching training datasets with synthetic examples. While large language models (LLMs) have demonstrated strong generative capabilities for this purpose, their applications in high-stakes domains like healthcare present unique challenges due to the risk of generating clinically incorrect or misleading information. In this work, we propose a novel query-based model collaboration framework that integrates expert-level domain knowledge to guide the augmentation process to preserve critical medical information. Experiments on clinical prediction tasks demonstrate that our lightweight collaboration-based approach consistently outperforms existing LLM augmentation methods while improving safety through reduced factual errors. This framework addresses the gap between LLM augmentation potential and the safety requirements of specialized domains.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.179642"
    },
    {
        "index": "#163",
        "title": "Contrastive Mutual Information Learning: Toward Robust Representations without Positive-Pair Augmentations",
        "link": "/arxiv/2509.21511",
        "arxiv_id": "2509.21511",
        "authors": "Micha Livne",
        "summary": "Learning representations that transfer well to diverse downstream tasks remains a central challenge in representation learning. Existing paradigms -- contrastive learning, self-supervised masking, and denoising auto-encoders -- balance this challenge with different trade-offs. We introduce the {contrastive Mutual Information Machine} (cMIM), a probabilistic framework that extends the Mutual Information Machine (MIM) with a contrastive objective. While MIM maximizes mutual information between inputs and latents and promotes clustering of codes, it falls short on discriminative tasks. cMIM addresses this gap by imposing global discriminative structure while retaining MIM's generative fidelity. Our contributions are threefold. First, we propose cMIM, a contrastive extension of MIM that removes the need for positive data augmentation and is substantially less sensitive to batch size than InfoNCE. Second, we introduce {informative embeddings}, a general technique for extracting enriched features from encoder-decoder models that boosts discriminative performance without additional training and applies broadly beyond MIM. Third, we provide empirical evidence across vision and molecular benchmarks showing that cMIM outperforms MIM and InfoNCE on classification and regression tasks while preserving competitive reconstruction quality. These results position cMIM as a unified framework for representation learning, advancing the goal of models that serve both discriminative and generative applications effectively.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.181408"
    },
    {
        "index": "#166",
        "title": "GraphPFN: A Prior-Data Fitted Graph Foundation Model",
        "link": "/arxiv/2509.21489",
        "arxiv_id": "2509.21489",
        "authors": "Dmitry Eremeev, Oleg Platonov, Gleb Bazhenov, Artem Babenko, Liudmila Prokhorenkova",
        "summary": "Foundation models pretrained on large-scale datasets have transformed such fields as natural language processing and computer vision, but their application to graph data remains limited. Recently emerged graph foundation models, such as G2T-FM, utilize tabular foundation models for graph tasks and were shown to significantly outperform prior attempts to create GFMs. However, these models primarily rely on hand-crafted graph features, limiting their ability to learn complex graph-specific patterns. In this work, we propose GraphPFN: a prior-data fitted network for node-level prediction. First, we design a prior distribution of synthetic attributed graphs. For graph structure generation, we use a novel combination of multiple stochastic block models and a preferential attachment process. We then apply graph-aware structured causal models to generate node attributes and targets. This procedure allows us to efficiently generate a wide range of realistic graph datasets. Then, we augment the tabular foundation model LimiX with attention-based graph neighborhood aggregation layers and train it on synthetic graphs sampled from our prior, allowing the model to capture graph structural dependencies not present in tabular data. On diverse real-world graph datasets with up to 50,000 nodes, GraphPFN shows strong in-context learning performance and achieves state-of-the-art results after finetuning, outperforming both G2T-FM and task-specific GNNs trained from scratch on most datasets. More broadly, our work demonstrates that pretraining on synthetic graphs from a well-designed prior distribution is an effective strategy for building graph foundation models.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.182323"
    },
    {
        "index": "#168",
        "title": "High-Probability Analysis of Online and Federated Zero-Order Optimisation",
        "link": "/arxiv/2509.21484",
        "arxiv_id": "2509.21484",
        "authors": "Arya Akhavan, David Janz, El-Mahdi El-Mhamdi",
        "summary": "We study distributed learning in the setting of gradient-free zero-order optimization and introduce FedZero, a federated zero-order algorithm that delivers sharp theoretical guarantees. Specifically, FedZero: (1) achieves near-optimal optimization error bounds with high probability in the federated convex setting; and (2) in the single-worker regime-where the problem reduces to the standard zero-order framework, establishes the first high-probability convergence guarantees for convex zero-order optimization, thereby strengthening the classical expectation-based results. At its core, FedZero employs a gradient estimator based on randomization over the $\\ell_1$-sphere. To analyze it, we develop new concentration inequalities for Lipschitz functions under the uniform measure on the $\\ell_1$-sphere, with explicit constants. These concentration tools are not only central to our high-probability guarantees but may also be of independent interest.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.182908"
    },
    {
        "index": "#169",
        "title": "Filtering with Confidence: When Data Augmentation Meets Conformal Prediction",
        "link": "/arxiv/2509.21479",
        "arxiv_id": "2509.21479",
        "authors": "Zixuan Wu, So Won Jeong, Yating Liu, Yeo Jin Jung, Claire Donnat",
        "summary": "With promising empirical performance across a wide range of applications, synthetic data augmentation appears a viable solution to data scarcity and the demands of increasingly data-intensive models. Its effectiveness lies in expanding the training set in a way that reduces estimator variance while introducing only minimal bias. Controlling this bias is therefore critical: effective data augmentation should generate diverse samples from the same underlying distribution as the training set, with minimal shifts. In this paper, we propose conformal data augmentation, a principled data filtering framework that leverages the power of conformal prediction to produce diverse synthetic data while filtering out poor-quality generations with provable risk control. Our method is simple to implement, requires no access to internal model logits, nor large-scale model retraining. We demonstrate the effectiveness of our approach across multiple tasks, including topic prediction, sentiment analysis, image classification, and fraud detection, showing consistent performance improvements of up to 40% in F1 score over unaugmented baselines, and 4% over other filtered augmentation baselines.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.183195"
    },
    {
        "index": "#171",
        "title": "d2: Improved Techniques for Training Reasoning Diffusion Language Models",
        "link": "/arxiv/2509.21474",
        "arxiv_id": "2509.21474",
        "authors": "Guanghan Wang, Yair Schiff, Gilad Turok, Volodymyr Kuleshov",
        "summary": "While diffusion language models (DLMs) have achieved competitive performance in text generation, improving their reasoning ability with reinforcement learning remains an active research area. Here, we introduce d2, a reasoning framework tailored for masked DLMs. Central to our framework is a new policy gradient algorithm that relies on properties of masking to accurately estimate the likelihoods of sampling trajectories. Our estimators trade off computation for approximation accuracy in an analytically tractable manner, and are particularly effective for DLMs that support any-order likelihood estimation. We characterize and study this property in popular DLMs and show that it is key for efficient diffusion-based reasoning. Empirically, d2 significantly improves over previous diffusion reasoning frameworks using only RL (without relying on supervised fine-tuning), and sets a new state-of-the-art performance for DLMs on logical reasoning tasks (Countdown and Sudoku) and math reasoning benchmarks (GSM8K and MATH500).",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.183812"
    },
    {
        "index": "#174",
        "title": "Talking Trees: Reasoning-Assisted Induction of Decision Trees for Tabular Data",
        "link": "/arxiv/2509.21465",
        "arxiv_id": "2509.21465",
        "authors": "George Yakushev, Alina Shutova, Ivan Rubachev, Renat Sergazinov, Artem Babenko",
        "summary": "Tabular foundation models are becoming increasingly popular for low-resource tabular problems. These models make up for small training datasets by pretraining on large volumes of synthetic data. The prior knowledge obtained via pretraining provides the exceptional performance, but the resulting model becomes a black box that is difficult to interpret and costly to inference. In this work, we explore an alternative strategy: using reasoning-capable LLMs to induce decision trees for small tabular datasets in agentic setup. We design a minimal set of tools for constructing, analyzing and manipulating decision trees. By using these tools, LLMs combine their prior knowledge with learning from data to create a lightweight decision tree that outperforms traditional CART on low-resource tabular problems. While a single decision tree does not outperform state-of-the-art black box models, it comes with a human-readable reasoning trace that can be checked for biases and data leaks. Furthermore, the reasoning-based LLM's creation process allows for additional human input: correcting biases or incorporating domain-specific intuition that is not captured in the data.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.184720"
    },
    {
        "index": "#175",
        "title": "Forecasting Seismic Waveforms: A Deep Learning Approach for Einstein Telescope",
        "link": "/arxiv/2509.21446",
        "arxiv_id": "2509.21446",
        "authors": "Waleed Esmail, Alexander Kappes, Stuart Russell, Christine Thomas",
        "summary": "We introduce \\textit{SeismoGPT}, a transformer-based model for forecasting three-component seismic waveforms in the context of future gravitational wave detectors like the Einstein Telescope. The model is trained in an autoregressive setting and can operate on both single-station and array-based inputs. By learning temporal and spatial dependencies directly from waveform data, SeismoGPT captures realistic ground motion patterns and provides accurate short-term forecasts. Our results show that the model performs well within the immediate prediction window and gradually degrades further ahead, as expected in autoregressive systems. This approach lays the groundwork for data-driven seismic forecasting that could support Newtonian noise mitigation and real-time observatory control.",
        "subjects": "Machine Learning, Earth and Planetary Astrophysics, Instrumentation and Methods for Astrophysics, General Relativity and Quantum Cosmology",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.185033"
    },
    {
        "index": "#176",
        "title": "Null-Space Filtering for Data-Free Continual Model Merging: Preserving Transparency, Promoting Fidelity",
        "link": "/arxiv/2509.21413",
        "arxiv_id": "2509.21413",
        "authors": "Zihuan Qiu, Lei Wang, Yang Cao, Runtong Zhang, Bing Su, Yi Xu, Fanman Meng, Linfeng Xu, Qingbo Wu, Hongliang Li",
        "summary": "Data-free continual model merging (DFCMM) aims to fuse independently fine-tuned models into a single backbone that evolves with incoming tasks without accessing task data. This paper formulate two fundamental desiderata for DFCMM: transparency, avoiding interference with earlier tasks, and fidelity, adapting faithfully to each new task. This poses a challenge that existing approaches fail to address: how to bridge data-level desiderata with parameter-space optimization to ensure transparency and fidelity in the absence of task data. To this end, we propose NUFILT (NUll-space FILTering), a data-free framework that directly links these desiderata to optimization. Our key observation is that task vectors approximately align with representation subspaces, providing structural surrogates for enforcing transparency and fidelity. Accordingly, we design a null-space projector that preserves prior responses by filtering out overlapping components of new task vectors, thereby ensuring transparency, and a lightweight LoRA adapter that injects complementary task-specific signals, enabling fidelity in adapting to new tasks. The adapter is trained with a projection-based surrogate loss to retain consistency with previous knowledge while introducing novel directions. This joint filtering-adaptation process allows the backbone to absorb new knowledge while retaining existing behaviors, and the updates are finally fused back in a layer-wise linear fashion without extra parameters or inference cost. Theoretically, we establish approximate subspace alignment guarantees that justify null-space filtering. Empirically, NUFILT achieves state-of-the-art performance with minimal forgetting on both vision and NLP benchmarks, improving average accuracy by 4-7% over OPCM and WUDI-Merging, while narrowing the gap to fine-tuning and reducing computation overhead.",
        "subjects": "Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.185365"
    },
    {
        "index": "#177",
        "title": "Object Identification Under Known Dynamics: A PIRNN Approach for UAV Classification",
        "link": "/arxiv/2509.21405",
        "arxiv_id": "2509.21405",
        "authors": "Nyi Nyi Aung, Neil Muralles, Adrian Stein",
        "summary": "This work addresses object identification under known dynamics in unmanned aerial vehicle applications, where learning and classification are combined through a physics-informed residual neural network. The proposed framework leverages physics-informed learning for state mapping and state-derivative prediction, while a softmax layer enables multi-class confidence estimation. Quadcopter, fixed-wing, and helicopter aerial vehicles are considered as case studies. The results demonstrate high classification accuracy with reduced training time, offering a promising solution for system identification problems in domains where the underlying dynamics are well understood.",
        "subjects": "Machine Learning, Robotics",
        "date": "2025-09-24",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.185647"
    },
    {
        "index": "#179",
        "title": "Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics",
        "link": "/arxiv/2509.21393",
        "arxiv_id": "2509.21393",
        "authors": "Yi En Chou, Te Hsin Liu, Chao An Lin",
        "summary": "Physics Informed Neural Networks offer a mesh free framework for solving PDEs but are highly sensitive to loss weight selection. We propose two dimensional analysis based weighting schemes, one based on quantifiable terms, and another also incorporating unquantifiable terms for more balanced training. Benchmarks on heat conduction, convection diffusion, and lid driven cavity flows show that the second scheme consistently improves stability and accuracy over equal weighting. Notably, in high Peclet number convection diffusion, where traditional solvers fail, PINNs with our scheme achieve stable, accurate predictions, highlighting their robustness and generalizability in CFD problems.",
        "subjects": "Machine Learning, Fluid Dynamics",
        "date": "2025-09-24",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.186206"
    },
    {
        "index": "#180",
        "title": "Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail",
        "link": "/arxiv/2509.21322",
        "arxiv_id": "2509.21322",
        "authors": "Anna Kalenkova, Lu Xia, Dirk Neumann",
        "summary": "This paper proposes a novel method for analyzing food retail processes with a focus on reducing food waste. The approach integrates object-centric process mining (OCPM) with stochastic process discovery and analysis. First, a stochastic process in the form of a continuous-time Markov chain is discovered from grocery store sales data. This model is then extended with supply activities. Finally, a what-if analysis is conducted to evaluate how the quantity of products in the store evolves over time. This enables the identification of an optimal balance between customer purchasing behavior and supply strategies, helping to prevent both food waste due to oversupply and product shortages.",
        "subjects": "Machine Learning, Probability, Applications",
        "date": "2025-08-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.186506"
    },
    {
        "index": "#193",
        "title": "Nearly Tight Regret Bounds for Profit Maximization in Bilateral Trade",
        "link": "/arxiv/2509.22563",
        "arxiv_id": "2509.22563",
        "authors": "Simone Di Gregorio, Paul Dütting, Federico Fusco, Chris Schwiegelshohn",
        "summary": "Bilateral trade models the task of intermediating between two strategic agents, a seller and a buyer, willing to trade a good for which they hold private valuations. We study this problem from the perspective of a broker, in a regret minimization framework. At each time step, a new seller and buyer arrive, and the broker has to propose a mechanism that is incentive-compatible and individually rational, with the goal of maximizing profit. We propose a learning algorithm that guarantees a nearly tight $\\tilde{O}(\\sqrt{T})$ regret in the stochastic setting when seller and buyer valuations are drawn i.i.d. from a fixed and possibly correlated unknown distribution. We further show that it is impossible to achieve sublinear regret in the non-stationary scenario where valuations are generated upfront by an adversary. Our ambitious benchmark for these results is the best incentive-compatible and individually rational mechanism. This separates us from previous works on efficiency maximization in bilateral trade, where the benchmark is a single number: the best fixed price in hindsight. A particular challenge we face is that uniform convergence for all mechanisms' profits is impossible. We overcome this difficulty via a careful chaining analysis that proves convergence for a provably near-optimal mechanism at (essentially) optimal rate. We further showcase the broader applicability of our techniques by providing nearly optimal results for the joint ads problem.",
        "subjects": "Computer Science and Game Theory, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.190698"
    },
    {
        "index": "#194",
        "title": "Linear Causal Representation Learning by Topological Ordering, Pruning, and Disentanglement",
        "link": "/arxiv/2509.22553",
        "arxiv_id": "2509.22553",
        "authors": "Hao Chen, Lin Liu, Yu Guang Wang",
        "summary": "Causal representation learning (CRL) has garnered increasing interests from the causal inference and artificial intelligence community, due to its capability of disentangling potentially complex data-generating mechanism into causally interpretable latent features, by leveraging the heterogeneity of modern datasets. In this paper, we further contribute to the CRL literature, by focusing on the stylized linear structural causal model over the latent features and assuming a linear mixing function that maps latent features to the observed data or measurements. Existing linear CRL methods often rely on stringent assumptions, such as accessibility to single-node interventional data or restrictive distributional constraints on latent features and exogenous measurement noise. However, these prerequisites can be challenging to satisfy in certain scenarios. In this work, we propose a novel linear CRL algorithm that, unlike most existing linear CRL methods, operates under weaker assumptions about environment heterogeneity and data-generating distributions while still recovering latent causal features up to an equivalence class. We further validate our new algorithm via synthetic experiments and an interpretability analysis of large language models (LLMs), demonstrating both its superiority over competing methods in finite samples and its potential in integrating causality into AI.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.190978"
    },
    {
        "index": "#196",
        "title": "Metrics for Parametric Families of Networks",
        "link": "/arxiv/2509.22549",
        "arxiv_id": "2509.22549",
        "authors": "Mario Gómez, Guanqun Ma, Tom Needham, Bei Wang",
        "summary": "We introduce a general framework for analyzing data modeled as parameterized families of networks. Building on a Gromov-Wasserstein variant of optimal transport, we define a family of parameterized Gromov-Wasserstein distances for comparing such parametric data, including time-varying metric spaces induced by collective motion, temporally evolving weighted social networks, and random graph models. We establish foundational properties of these distances, showing that they subsume several existing metrics in the literature, and derive theoretical approximation guarantees. In particular, we develop computationally tractable lower bounds and relate them to graph statistics commonly used in random graph theory. Furthermore, we prove that our distances can be consistently approximated in random graph and random metric space settings via empirical estimates from generative models. Finally, we demonstrate the practical utility of our framework through a series of numerical experiments.",
        "subjects": "Machine Learning, Machine Learning, Metric Geometry",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.191610"
    },
    {
        "index": "#197",
        "title": "Debiased Front-Door Learners for Heterogeneous Effects",
        "link": "/arxiv/2509.22531",
        "arxiv_id": "2509.22531",
        "authors": "Yonghan Jung",
        "summary": "In observational settings where treatment and outcome share unmeasured confounders but an observed mediator remains unconfounded, the front-door (FD) adjustment identifies causal effects through the mediator. We study the heterogeneous treatment effect (HTE) under FD identification and introduce two debiased learners: FD-DR-Learner and FD-R-Learner. Both attain fast, quasi-oracle rates (i.e., performance comparable to an oracle that knows the nuisances) even when nuisance functions converge as slowly as n^-1/4. We provide error analyses establishing debiasedness and demonstrate robust empirical performance in synthetic studies and a real-world case study of primary seat-belt laws using Fatality Analysis Reporting System (FARS) dataset. Together, these results indicate that the proposed learners deliver reliable and sample-efficient HTE estimates in FD scenarios. The implementation is available at https://github.com/yonghanjung/FD-CATE. Keywords: Front-door adjustment; Heterogeneous treatment effects; Debiased learning; Quasi-oracle rates; Causal inference.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.191907"
    },
    {
        "index": "#198",
        "title": "Smoothing-Based Conformal Prediction for Balancing Efficiency and Interpretability",
        "link": "/arxiv/2509.22529",
        "arxiv_id": "2509.22529",
        "authors": "Mingyi Zheng, Hongyu Jiang, Yizhou Lu, Jiaye Teng",
        "summary": "Conformal Prediction (CP) is a distribution-free framework for constructing statistically rigorous prediction sets. While popular variants such as CD-split improve CP's efficiency, they often yield prediction sets composed of multiple disconnected subintervals, which are difficult to interpret. In this paper, we propose SCD-split, which incorporates smoothing operations into the CP framework. Such smoothing operations potentially help merge the subintervals, thus leading to interpretable prediction sets. Experimental results on both synthetic and real-world datasets demonstrate that SCD-split balances the interval length and the number of disconnected subintervals. Theoretically, under specific conditions, SCD-split provably reduces the number of disconnected subintervals while maintaining comparable coverage guarantees and interval length compared with CD-split.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.192198"
    },
    {
        "index": "#204",
        "title": "CausalKANs: interpretable treatment effect estimation with Kolmogorov-Arnold networks",
        "link": "/arxiv/2509.22467",
        "arxiv_id": "2509.22467",
        "authors": "Alejandro Almodóvar, Patricia A. Apellániz, Santiago Zazo, Juan Parras",
        "summary": "Deep neural networks achieve state-of-the-art performance in estimating heterogeneous treatment effects, but their opacity limits trust and adoption in sensitive domains such as medicine, economics, and public policy. Building on well-established and high-performing causal neural architectures, we propose causalKANs, a framework that transforms neural estimators of conditional average treatment effects (CATEs) into Kolmogorov--Arnold Networks (KANs). By incorporating pruning and symbolic simplification, causalKANs yields interpretable closed-form formulas while preserving predictive accuracy. Experiments on benchmark datasets demonstrate that causalKANs perform on par with neural baselines in CATE error metrics, and that even simple KAN variants achieve competitive performance, offering a favorable accuracy--interpretability trade-off. By combining reliability with analytic accessibility, causalKANs provide auditable estimators supported by closed-form expressions and interpretable plots, enabling trustworthy individualized decision-making in high-stakes settings. We release the code for reproducibility at https://github.com/aalmodovares/causalkans .",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.194004"
    },
    {
        "index": "#205",
        "title": "Universal Inverse Distillation for Matching Models with Real-Data Supervision (No GANs)",
        "link": "/arxiv/2509.22459",
        "arxiv_id": "2509.22459",
        "authors": "Nikita Kornilov, David Li, Tikhon Mavrin, Aleksei Leonov, Nikita Gushchin, Evgeny Burnaev, Iaroslav Koshelev, Alexander Korotin",
        "summary": "While achieving exceptional generative quality, modern diffusion, flow, and other matching models suffer from slow inference, as they require many steps of iterative generation. Recent distillation methods address this by training efficient one-step generators under the guidance of a pre-trained teacher model. However, these methods are often constrained to only one specific framework, e.g., only to diffusion or only to flow models. Furthermore, these methods are naturally data-free, and to benefit from the usage of real data, it is required to use an additional complex adversarial training with an extra discriminator model. In this paper, we present RealUID, a universal distillation framework for all matching models that seamlessly incorporates real data into the distillation procedure without GANs. Our RealUID approach offers a simple theoretical foundation that covers previous distillation methods for Flow Matching and Diffusion models, and is also extended to their modifications, such as Bridge Matching and Stochastic Interpolants.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.194332"
    },
    {
        "index": "#207",
        "title": "NeuroScalar: A Deep Learning Framework for Fast, Accurate, and In-the-Wild Cycle-Level Performance Prediction",
        "link": "/arxiv/2509.22410",
        "arxiv_id": "2509.22410",
        "authors": "Shayne Wadle, Yanxin Zhang, Vikas Singh, Karthikeyan Sankaralingam",
        "summary": "The evaluation of new microprocessor designs is constrained by slow, cycle-accurate simulators that rely on unrepresentative benchmark traces. This paper introduces a novel deep learning framework for high-fidelity, ``in-the-wild'' simulation on production hardware. Our core contribution is a DL model trained on microarchitecture-independent features to predict cycle-level performance for hypothetical processor designs. This unique approach allows the model to be deployed on existing silicon to evaluate future hardware. We propose a complete system featuring a lightweight hardware trace collector and a principled sampling strategy to minimize user impact. This system achieves a simulation speed of 5 MIPS on a commodity GPU, imposing a mere 0.1% performance overhead. Furthermore, our co-designed Neutrino on-chip accelerator improves performance by 85x over the GPU. We demonstrate that this framework enables accurate performance analysis and large-scale hardware A/B testing on a massive scale using real-world applications.",
        "subjects": "Hardware Architecture, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.194974"
    },
    {
        "index": "#209",
        "title": "Multidimensional Uncertainty Quantification via Optimal Transport",
        "link": "/arxiv/2509.22380",
        "arxiv_id": "2509.22380",
        "authors": "Nikita Kotelevskii, Maiya Goloburda, Vladimir Kondratyev, Alexander Fishkov, Mohsen Guizani, Eric Moulines, Maxim Panov",
        "summary": "Most uncertainty quantification (UQ) approaches provide a single scalar value as a measure of model reliability. However, different uncertainty measures could provide complementary information on the prediction confidence. Even measures targeting the same type of uncertainty (e.g., ensemble-based and density-based measures of epistemic uncertainty) may capture different failure modes. We take a multidimensional view on UQ by stacking complementary UQ measures into a vector. Such vectors are assigned with Monge-Kantorovich ranks produced by an optimal-transport-based ordering method. The prediction is then deemed more uncertain than the other if it has a higher rank. The resulting VecUQ-OT algorithm uses entropy-regularized optimal transport. The transport map is learned on vectors of scores from in-distribution data and, by design, applies to unseen inputs, including out-of-distribution cases, without retraining. Our framework supports flexible non-additive uncertainty fusion (including aleatoric and epistemic components). It yields a robust ordering for downstream tasks such as selective prediction, misclassification detection, out-of-distribution detection, and selective generation. Across synthetic, image, and text data, VecUQ-OT shows high efficiency even when individual measures fail. The code for the method is available at: https://github.com/stat-ml/multidimensional_uncertainty.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.195582"
    },
    {
        "index": "#210",
        "title": "Multi-channel convolutional neural quantum embedding",
        "link": "/arxiv/2509.22355",
        "arxiv_id": "2509.22355",
        "authors": "Yujin Kim, Changjae Im, Taehyun Kim, Tak Hur, Daniel K. Park",
        "summary": "Classification using variational quantum circuits is a promising frontier in quantum machine learning. Quantum supervised learning (QSL) applied to classical data using variational quantum circuits involves embedding the data into a quantum Hilbert space and optimizing the circuit parameters to train the measurement process. In this context, the efficacy of QSL is inherently influenced by the selection of quantum embedding. In this study, we introduce a classical-quantum hybrid approach for optimizing quantum embedding beyond the limitations of the standard circuit model of quantum computation (i.e., completely positive and trace-preserving maps) for general multi-channel data. We benchmark the performance of various models in our framework using the CIFAR-10 and Tiny ImageNet datasets and provide theoretical analyses that guide model design and optimization.",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.195890"
    },
    {
        "index": "#212",
        "title": "Preventing Model Collapse Under Overparametrization: Optimal Mixing Ratios for Interpolation Learning and Ridge Regression",
        "link": "/arxiv/2509.22341",
        "arxiv_id": "2509.22341",
        "authors": "Anvit Garg, Sohom Bhattacharya, Pragya Sur",
        "summary": "Model collapse occurs when generative models degrade after repeatedly training on their own synthetic outputs. We study this effect in overparameterized linear regression in a setting where each iteration mixes fresh real labels with synthetic labels drawn from the model fitted in the previous iteration. We derive precise generalization error formulae for minimum-$\\ell_2$-norm interpolation and ridge regression under this iterative scheme. Our analysis reveals intriguing properties of the optimal mixing weight that minimizes long-term prediction error and provably prevents model collapse. For instance, in the case of min-$\\ell_2$-norm interpolation, we establish that the optimal real-data proportion converges to the reciprocal of the golden ratio for fairly general classes of covariate distributions. Previously, this property was known only for ordinary least squares, and additionally in low dimensions. For ridge regression, we further analyze two popular model classes -- the random-effects model and the spiked covariance model -- demonstrating how spectral geometry governs optimal weighting. In both cases, as well as for isotropic features, we uncover that the optimal mixing ratio should be at least one-half, reflecting the necessity of favoring real-data over synthetic. We validate our theoretical results with extensive simulations.",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory, Methodology",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.196511"
    },
    {
        "index": "#220",
        "title": "Incorporating priors in learning: a random matrix study under a teacher-student framework",
        "link": "/arxiv/2509.22124",
        "arxiv_id": "2509.22124",
        "authors": "Malik Tiomoko, Ekkehard Schnoor",
        "summary": "Regularized linear regression is central to machine learning, yet its high-dimensional behavior with informative priors remains poorly understood. We provide the first exact asymptotic characterization of training and test risks for maximum a posteriori (MAP) regression with Gaussian priors centered at a domain-informed initialization. Our framework unifies ridge regression, least squares, and prior-informed estimators, and -- using random matrix theory -- yields closed-form risk formulas that expose the bias-variance-prior tradeoff, explain double descent, and quantify prior mismatch. We also identify a closed-form minimizer of test risk, enabling a simple estimator of the optimal regularization parameter. Simulations confirm the theory with high accuracy. By connecting Bayesian priors, classical regularization, and modern asymptotics, our results provide both conceptual clarity and practical guidance for learning with structured prior knowledge.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.198899"
    },
    {
        "index": "#221",
        "title": "Direct Bias-Correction Term Estimation for Propensity Scores and Average Treatment Effect Estimation",
        "link": "/arxiv/2509.22122",
        "arxiv_id": "2509.22122",
        "authors": "Masahiro Kato",
        "summary": "This study considers the estimation of the average treatment effect (ATE). For ATE estimation, we estimate the propensity score through direct bias-correction term estimation. Let $\\{(X_i, D_i, Y_i)\\}_{i=1}^{n}$ be the observations, where $X_i \\in \\mathbb{R}^p$ denotes $p$-dimensional covariates, $D_i \\in \\{0, 1\\}$ denotes a binary treatment assignment indicator, and $Y_i \\in \\mathbb{R}$ is an outcome. In ATE estimation, the bias-correction term $h_0(X_i, D_i) = \\frac{1[D_i = 1]}{e_0(X_i)} - \\frac{1[D_i = 0]}{1 - e_0(X_i)}$ plays an important role, where $e_0(X_i)$ is the propensity score, the probability of being assigned treatment $1$. In this study, we propose estimating $h_0$ (or equivalently the propensity score $e_0$) by directly minimizing the prediction error of $h_0$. Since the bias-correction term $h_0$ is essential for ATE estimation, this direct approach is expected to improve estimation accuracy for the ATE. For example, existing studies often employ maximum likelihood or covariate balancing to estimate $e_0$, but these approaches may not be optimal for accurately estimating $h_0$ or the ATE. We present a general framework for this direct bias-correction term estimation approach from the perspective of Bregman divergence minimization and conduct simulation studies to evaluate the effectiveness of the proposed method.",
        "subjects": "Econometrics, Machine Learning, Statistics Theory, Methodology, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.199194"
    },
    {
        "index": "#223",
        "title": "Exploring the Early Universe with Deep Learning",
        "link": "/arxiv/2509.22018",
        "arxiv_id": "2509.22018",
        "authors": "Emmanuel de Salis, Massimo De Santis, Davide Piras, Sambit K. Giri, Michele Bianco, Nicolas Cerardi, Philipp Denzel, Merve Selcuk-Simsek, Kelley M. Hess, M. Carmen Toribio, Franz Kirsten, Hatem Ghorbel",
        "summary": "Hydrogen is the most abundant element in our Universe. The first generation of stars and galaxies produced photons that ionized hydrogen gas, driving a cosmological event known as the Epoch of Reionization (EoR). The upcoming Square Kilometre Array Observatory (SKAO) will map the distribution of neutral hydrogen during this era, aiding in the study of the properties of these first-generation objects. Extracting astrophysical information will be challenging, as SKAO will produce a tremendous amount of data where the hydrogen signal will be contaminated with undesired foreground contamination and instrumental systematics. To address this, we develop the latest deep learning techniques to extract information from the 2D power spectra of the hydrogen signal expected from SKAO. We apply a series of neural network models to these measurements and quantify their ability to predict the history of cosmic hydrogen reionization, which is connected to the increasing number and efficiency of early photon sources. We show that the study of the early Universe benefits from modern deep learning technology. In particular, we demonstrate that dedicated machine learning algorithms can achieve more than a $0.95$ $R^2$ score on average in recovering the reionization history. This enables accurate and precise cosmological and astrophysical inference of structure formation in the early Universe.",
        "subjects": "Cosmology and Nongalactic Astrophysics, Instrumentation and Methods for Astrophysics, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.199862"
    },
    {
        "index": "#224",
        "title": "A Random Matrix Perspective of Echo State Networks: From Precise Bias--Variance Characterization to Optimal Regularization",
        "link": "/arxiv/2509.22011",
        "arxiv_id": "2509.22011",
        "authors": "Yessin Moakher, Malik Tiomoko, Cosme Louart, Zhenyu Liao",
        "summary": "We present a rigorous asymptotic analysis of Echo State Networks (ESNs) in a teacher student setting with a linear teacher with oracle weights. Leveraging random matrix theory, we derive closed form expressions for the asymptotic bias, variance, and mean-squared error (MSE) as functions of the input statistics, the oracle vector, and the ridge regularization parameter. The analysis reveals two key departures from classical ridge regression: (i) ESNs do not exhibit double descent, and (ii) ESNs attain lower MSE when both the number of training samples and the teacher memory length are limited. We further provide an explicit formula for the optimal regularization in the identity input covariance case, and propose an efficient numerical scheme to compute the optimum in the general case. Together, these results offer interpretable theory and practical guidelines for tuning ESNs, helping reconcile recent empirical observations with provable performance guarantees",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.200158"
    },
    {
        "index": "#226",
        "title": "A Nonparametric Discrete Hawkes Model with a Collapsed Gaussian-Process Prior",
        "link": "/arxiv/2509.21996",
        "arxiv_id": "2509.21996",
        "authors": "Trinnhallen Brisley, Gordon Ross, Daniel Paulin",
        "summary": "Hawkes process models are used in settings where past events increase the likelihood of future events occurring. Many applications record events as counts on a regular grid, yet discrete-time Hawkes models remain comparatively underused and are often constrained by fixed-form baselines and excitation kernels. In particular, there is a lack of flexible, nonparametric treatments of both the baseline and the excitation in discrete time. To this end, we propose the Gaussian Process Discrete Hawkes Process (GP-DHP), a nonparametric framework that places Gaussian process priors on both the baseline and the excitation and performs inference through a collapsed latent representation. This yields smooth, data-adaptive structure without prespecifying trends, periodicities, or decay shapes, and enables maximum a posteriori (MAP) estimation with near-linear-time \\(O(T\\log T)\\) complexity. A closed-form projection recovers interpretable baseline and excitation functions from the optimized latent trajectory. In simulations, GP-DHP recovers diverse excitation shapes and evolving baselines. In case studies on U.S. terrorism incidents and weekly Cryptosporidiosis counts, it improves test predictive log-likelihood over standard parametric discrete Hawkes baselines while capturing bursts, delays, and seasonal background variation. The results indicate that flexible discrete-time self-excitation can be achieved without sacrificing scalability or interpretability.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.200751"
    },
    {
        "index": "#230",
        "title": "Learnable Conformal Prediction with Context-Aware Nonconformity Functions for Robotic Planning and Perception",
        "link": "/arxiv/2509.21955",
        "arxiv_id": "2509.21955",
        "authors": "Divake Kumar, Sina Tayebati, Francesco Migliarba, Ranganath Krishnan, Amit Ranjan Trivedi",
        "summary": "Deep learning models in robotics often output point estimates with poorly calibrated confidences, offering no native mechanism to quantify predictive reliability under novel, noisy, or out-of-distribution inputs. Conformal prediction (CP) addresses this gap by providing distribution-free coverage guarantees, yet its reliance on fixed nonconformity scores ignores context and can yield intervals that are overly conservative or unsafe. We address this with Learnable Conformal Prediction (LCP), which replaces fixed scores with a lightweight neural function that leverages geometric, semantic, and task-specific features to produce context-aware uncertainty sets. LCP maintains CP's theoretical guarantees while reducing prediction set sizes by 18% in classification, tightening detection intervals by 52%, and improving path planning safety from 72% to 91% success with minimal overhead. Across three robotic tasks on seven benchmarks, LCP consistently outperforms Standard CP and ensemble baselines. In classification on CIFAR-100 and ImageNet, it achieves smaller set sizes (4.7-9.9% reduction) at target coverage. For object detection on COCO, BDD100K, and Cityscapes, it produces 46-54% tighter bounding boxes. In path planning through cluttered environments, it improves success to 91.5% with only 4.5% path inflation, compared to 12.2% for Standard CP. The method is lightweight (approximately 4.8% runtime overhead, 42 KB memory) and supports online adaptation, making it well suited to resource-constrained autonomous systems. Hardware evaluation shows LCP adds less than 1% memory and 15.9% inference overhead, yet sustains 39 FPS on detection tasks while being 7.4 times more energy-efficient than ensembles.",
        "subjects": "Robotics, Machine Learning, Statistics Theory",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.201998"
    },
    {
        "index": "#232",
        "title": "Sequential 1-bit Mean Estimation with Near-Optimal Sample Complexity",
        "link": "/arxiv/2509.21940",
        "arxiv_id": "2509.21940",
        "authors": "Ivan Lau, Jonathan Scarlett",
        "summary": "In this paper, we study the problem of distributed mean estimation with 1-bit communication constraints. We propose a mean estimator that is based on (randomized and sequentially-chosen) interval queries, whose 1-bit outcome indicates whether the given sample lies in the specified interval. Our estimator is $(\\epsilon, \\delta)$-PAC for all distributions with bounded mean ($-\\lambda \\le \\mathbb{E}(X) \\le \\lambda $) and variance ($\\mathrm{Var}(X) \\le \\sigma^2$) for some known parameters $\\lambda$ and $\\sigma$. We derive a sample complexity bound $\\widetilde{O}\\big( \\frac{\\sigma^2}{\\epsilon^2}\\log\\frac{1}{\\delta} + \\log\\frac{\\lambda}{\\sigma}\\big)$, which matches the minimax lower bound for the unquantized setting up to logarithmic factors and the additional $\\log\\frac{\\lambda}{\\sigma}$ term that we show to be unavoidable. We also establish an adaptivity gap for interval-query based estimators: the best non-adaptive mean estimator is considerably worse than our adaptive mean estimator for large $\\frac{\\lambda}{\\sigma}$. Finally, we give tightened sample complexity bounds for distributions with stronger tail decay, and present additional variants that (i) handle an unknown sampling budget (ii) adapt to the unknown true variance given (possibly loose) upper and lower bounds on the variance, and (iii) use only two stages of adaptivity at the expense of more complicated (non-interval) queries.",
        "subjects": "Machine Learning, Information Theory, Machine Learning, Statistics Theory",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.202631"
    },
    {
        "index": "#233",
        "title": "Error Analysis of Discrete Flow with Generator Matching",
        "link": "/arxiv/2509.21906",
        "arxiv_id": "2509.21906",
        "authors": "Zhengyan Wan, Yidong Ouyang, Qiang Yao, Liyan Xie, Fang Fang, Hongyuan Zha, Guang Cheng",
        "summary": "Discrete flow models offer a powerful framework for learning distributions over discrete state spaces and have demonstrated superior performance compared to the discrete diffusion model. However, their convergence properties and error analysis remain largely unexplored. In this work, we develop a unified framework grounded in stochastic calculus theory to systematically investigate the theoretical properties of discrete flow. Specifically, we derive the KL divergence of two path measures regarding two continuous-time Markov chains (CTMCs) with different transition rates by developing a novel Girsanov-type theorem, and provide a comprehensive analysis that encompasses the error arising from transition rate estimation and early stopping, where the first type of error has rarely been analyzed by existing works. Unlike discrete diffusion models, discrete flow incurs no truncation error caused by truncating the time horizon in the noising process. Building on generator matching and uniformization, we establish non-asymptotic error bounds for distribution estimation. Our results provide the first error analysis for discrete flow models.",
        "subjects": "Statistics Theory, Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.202953"
    },
    {
        "index": "#236",
        "title": "Causal-EPIG: A Prediction-Oriented Active Learning Framework for CATE Estimation",
        "link": "/arxiv/2509.21866",
        "arxiv_id": "2509.21866",
        "authors": "Erdun Gao, Jake Fawkes, Dino Sejdinovic",
        "summary": "Estimating the Conditional Average Treatment Effect (CATE) is often constrained by the high cost of obtaining outcome measurements, making active learning essential. However, conventional active learning strategies suffer from a fundamental objective mismatch. They are designed to reduce uncertainty in model parameters or in observable factual outcomes, failing to directly target the unobservable causal quantities that are the true objects of interest. To address this misalignment, we introduce the principle of causal objective alignment, which posits that acquisition functions should target unobservable causal quantities, such as the potential outcomes and the CATE, rather than indirect proxies. We operationalize this principle through the Causal-EPIG framework, which adapts the information-theoretic criterion of Expected Predictive Information Gain (EPIG) to explicitly quantify the value of a query in terms of reducing uncertainty about unobservable causal quantities. From this unified framework, we derive two distinct strategies that embody a fundamental trade-off: a comprehensive approach that robustly models the full causal mechanisms via the joint potential outcomes, and a focused approach that directly targets the CATE estimand for maximum sample efficiency. Extensive experiments demonstrate that our strategies consistently outperform standard baselines, and crucially, reveal that the optimal strategy is context-dependent, contingent on the base estimator and data complexity. Our framework thus provides a principled guide for sample-efficient CATE estimation in practice.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.203909"
    },
    {
        "index": "#241",
        "title": "Reinforcement Learning Based Traffic Signal Design to Minimize Queue Lengths",
        "link": "/arxiv/2509.21745",
        "arxiv_id": "2509.21745",
        "authors": "Anirud Nandakumar, Chayan Banerjee, Lelitha Devi Vanajakshi",
        "summary": "Efficient traffic signal control (TSC) is crucial for reducing congestion, travel delays, pollution, and for ensuring road safety. Traditional approaches, such as fixed signal control and actuated control, often struggle to handle dynamic traffic patterns. In this study, we propose a novel adaptive TSC framework that leverages Reinforcement Learning (RL), using the Proximal Policy Optimization (PPO) algorithm, to minimize total queue lengths across all signal phases. The challenge of efficiently representing highly stochastic traffic conditions for an RL controller is addressed through multiple state representations, including an expanded state space, an autoencoder representation, and a K-Planes-inspired representation. The proposed algorithm has been implemented using the Simulation of Urban Mobility (SUMO) traffic simulator and demonstrates superior performance over both traditional methods and other conventional RL-based approaches in reducing queue lengths. The best performing configuration achieves an approximately 29% reduction in average queue lengths compared to the traditional Webster method. Furthermore, comparative evaluation of alternative reward formulations demonstrates the effectiveness of the proposed queue-based approach, showcasing the potential for scalable and adaptive urban traffic management.",
        "subjects": "Systems and Control, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.205359"
    },
    {
        "index": "#244",
        "title": "Noise-to-Notes: Diffusion-based Generation and Refinement for Automatic Drum Transcription",
        "link": "/arxiv/2509.21739",
        "arxiv_id": "2509.21739",
        "authors": "Michael Yeung, Keisuke Toyama, Toya Teramoto, Shusuke Takahashi, Tamaki Kojima",
        "summary": "Automatic drum transcription (ADT) is traditionally formulated as a discriminative task to predict drum events from audio spectrograms. In this work, we redefine ADT as a conditional generative task and introduce Noise-to-Notes (N2N), a framework leveraging diffusion modeling to transform audio-conditioned Gaussian noise into drum events with associated velocities. This generative diffusion approach offers distinct advantages, including a flexible speed-accuracy trade-off and strong inpainting capabilities. However, the generation of binary onset and continuous velocity values presents a challenge for diffusion models, and to overcome this, we introduce an Annealed Pseudo-Huber loss to facilitate effective joint optimization. Finally, to augment low-level spectrogram features, we propose incorporating features extracted from music foundation models (MFMs), which capture high-level semantic information and enhance robustness to out-of-domain drum audio. Experimental results demonstrate that including MFM features significantly improves robustness and N2N establishes a new state-of-the-art performance across multiple ADT benchmarks.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.206280"
    },
    {
        "index": "#247",
        "title": "Multi-modal Bayesian Neural Network Surrogates with Conjugate Last-Layer Estimation",
        "link": "/arxiv/2509.21711",
        "arxiv_id": "2509.21711",
        "authors": "Ian Taylor, Juliane Mueller, Julie Bessac",
        "summary": "As data collection and simulation capabilities advance, multi-modal learning, the task of learning from multiple modalities and sources of data, is becoming an increasingly important area of research. Surrogate models that learn from data of multiple auxiliary modalities to support the modeling of a highly expensive quantity of interest have the potential to aid outer loop applications such as optimization, inverse problems, or sensitivity analyses when multi-modal data are available. We develop two multi-modal Bayesian neural network surrogate models and leverage conditionally conjugate distributions in the last layer to estimate model parameters using stochastic variational inference (SVI). We provide a method to perform this conjugate SVI estimation in the presence of partially missing observations. We demonstrate improved prediction accuracy and uncertainty quantification compared to uni-modal surrogate models for both scalar and time series data.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.207286"
    },
    {
        "index": "#248",
        "title": "SADA: Safe and Adaptive Inference with Multiple Black-Box Predictions",
        "link": "/arxiv/2509.21707",
        "arxiv_id": "2509.21707",
        "authors": "Jiawei Shan, Yiming Dong, Jiwei Zhao",
        "summary": "Real-world applications often face scarce labeled data due to the high cost and time requirements of gold-standard experiments, whereas unlabeled data are typically abundant. With the growing adoption of machine learning techniques, it has become increasingly feasible to generate multiple predicted labels using a variety of models and algorithms, including deep learning, large language models, and generative AI. In this paper, we propose a novel approach that safely and adaptively aggregates multiple black-box predictions with unknown quality while preserving valid statistical inference. Our method provides two key guarantees: (i) it never performs worse than using the labeled data alone, regardless of the quality of the predictions; and (ii) if any one of the predictions (without knowing which one) perfectly fits the ground truth, the algorithm adaptively exploits this to achieve either a faster convergence rate or the semiparametric efficiency bound. We demonstrate the effectiveness of the proposed algorithm through experiments on both synthetic and benchmark datasets.",
        "subjects": "Machine Learning, Machine Learning, Methodology",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.207577"
    },
    {
        "index": "#249",
        "title": "HuLA: Prosody-Aware Anti-Spoofing with Multi-Task Learning for Expressive and Emotional Synthetic Speech",
        "link": "/arxiv/2509.21676",
        "arxiv_id": "2509.21676",
        "authors": "Aurosweta Mahapatra, Ismail Rasim Ulgen, Berrak Sisman",
        "summary": "Current anti-spoofing systems remain vulnerable to expressive and emotional synthetic speech, since they rarely leverage prosody as a discriminative cue. Prosody is central to human expressiveness and emotion, and humans instinctively use prosodic cues such as F0 patterns and voiced/unvoiced structure to distinguish natural from synthetic speech. In this paper, we propose HuLA, a two-stage prosody-aware multi-task learning framework for spoof detection. In Stage 1, a self-supervised learning (SSL) backbone is trained on real speech with auxiliary tasks of F0 prediction and voiced/unvoiced classification, enhancing its ability to capture natural prosodic variation similar to human perceptual learning. In Stage 2, the model is jointly optimized for spoof detection and prosody tasks on both real and synthetic data, leveraging prosodic awareness to detect mismatches between natural and expressive synthetic speech. Experiments show that HuLA consistently outperforms strong baselines on challenging out-of-domain dataset, including expressive, emotional, and cross-lingual attacks. These results demonstrate that explicit prosodic supervision, combined with SSL embeddings, substantially improves robustness against advanced synthetic speech attacks.",
        "subjects": "Audio and Speech Processing, Machine Learning, Sound",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.207881"
    },
    {
        "index": "#251",
        "title": "Generating Stable Placements via Physics-guided Diffusion Models",
        "link": "/arxiv/2509.21664",
        "arxiv_id": "2509.21664",
        "authors": "Philippe Nadeau, Miguel Rogel, Ivan Bilić, Ivan Petrović, Jonathan Kelly",
        "summary": "Stably placing an object in a multi-object scene is a fundamental challenge in robotic manipulation, as placements must be penetration-free, establish precise surface contact, and result in a force equilibrium. To assess stability, existing methods rely on running a simulation engine or resort to heuristic, appearance-based assessments. In contrast, our approach integrates stability directly into the sampling process of a diffusion model. To this end, we query an offline sampling-based planner to gather multi-modal placement labels and train a diffusion model to generate stable placements. The diffusion model is conditioned on scene and object point clouds, and serves as a geometry-aware prior. We leverage the compositional nature of score-based generative models to combine this learned prior with a stability-aware loss, thereby increasing the likelihood of sampling from regions of high stability. Importantly, this strategy requires no additional re-training or fine-tuning, and can be directly applied to off-the-shelf models. We evaluate our method on four benchmark scenes where stability can be accurately computed. Our physics-guided models achieve placements that are 56% more robust to forceful perturbations while reducing runtime by 47% compared to a state-of-the-art geometric method.",
        "subjects": "Robotics, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.208518"
    },
    {
        "index": "#252",
        "title": "Automating Sensor Characterization with Bayesian Optimization",
        "link": "/arxiv/2509.21661",
        "arxiv_id": "2509.21661",
        "authors": "J. Cuevas-Zepeda, C. Chavez, J. Estrada, J. Noonan, B. D. Nord, N. Saffold, M. Sofo-Haro, R. Spinola e Castro, S. Trivedi",
        "summary": "The development of novel instrumentation requires an iterative cycle with three stages: design, prototyping, and testing. Recent advancements in simulation and nanofabrication techniques have significantly accelerated the design and prototyping phases. Nonetheless, detector characterization continues to be a major bottleneck in device development. During the testing phase, a significant time investment is required to characterize the device in different operating conditions and find optimal operating parameters. The total effort spent on characterization and parameter optimization can occupy a year or more of an expert's time. In this work, we present a novel technique for automated sensor calibration that aims to accelerate the testing stage of the development cycle. This technique leverages closed-loop Bayesian optimization (BO), using real-time measurements to guide parameter selection and identify optimal operating states. We demonstrate the method with a novel low-noise CCD, showing that the machine learning-driven tool can efficiently characterize and optimize operation of the sensor in a couple of days without supervision of a device expert.",
        "subjects": "Instrumentation and Detectors, Instrumentation and Methods for Astrophysics, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.208866"
    },
    {
        "index": "#253",
        "title": "A regret minimization approach to fixed-point iterations",
        "link": "/arxiv/2509.21653",
        "arxiv_id": "2509.21653",
        "authors": "Joon Kwon",
        "summary": "We propose a conversion scheme that turns regret minimizing algorithms into fixed point iterations, with convergence guarantees following from regret bounds. The resulting iterations can be seen as a grand extension of the classical Krasnoselskii--Mann iterations, as the latter are recovered by converting the Online Gradient Descent algorithm. This approach yields new simple iterations for finding fixed points of non-self operators. We also focus on converting algorithms from the AdaGrad family of regret minimizers, and thus obtain fixed point iterations with adaptive guarantees of a new kind. Numerical experiments on various problems demonstrate faster convergence of AdaGrad-based fixed point iterations over Krasnoselskii--Mann iterations.",
        "subjects": "Optimization and Control, Machine Learning, Numerical Analysis",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.209134"
    },
    {
        "index": "#254",
        "title": "Automated Machine Learning Pipeline for Training and Analysis Using Large Language Models",
        "link": "/arxiv/2509.21647",
        "arxiv_id": "2509.21647",
        "authors": "Adam Lahouari, Jutta Rogal, Mark E. Tuckerman",
        "summary": "Machine learning interatomic potentials (MLIPs) have become powerful tools to extend molecular simulations beyond the limits of quantum methods, offering near-quantum accuracy at much lower computational cost. Yet, developing reliable MLIPs remains difficult because it requires generating high-quality datasets, preprocessing atomic structures, and carefully training and validating models. In this work, we introduce an Automated Machine Learning Pipeline (AMLP) that unifies the entire workflow from dataset creation to model validation. AMLP employs large-language-model agents to assist with electronic-structure code selection, input preparation, and output conversion, while its analysis suite (AMLP-Analysis), based on ASE supports a range of molecular simulations. The pipeline is built on the MACE architecture and validated on acridine polymorphs, where, with a straightforward fine-tuning of a foundation model, mean absolute errors of ~1.7 meV/atom in energies and ~7.0 meV/Å in forces are achieved. The fitted MLIP reproduces DFT geometries with sub-Å accuracy and demonstrates stability during molecular dynamics simulations in the microcanonical and canonical ensembles.",
        "subjects": "Materials Science, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.209411"
    },
    {
        "index": "#259",
        "title": "Effective continuous equations for adaptive SGD: a stochastic analysis view",
        "link": "/arxiv/2509.21614",
        "arxiv_id": "2509.21614",
        "authors": "Luca Callisti, Marco Romito, Francesco Triggiano",
        "summary": "We present a theoretical analysis of some popular adaptive Stochastic Gradient Descent (SGD) methods in the small learning rate regime. Using the stochastic modified equations framework introduced by Li et al., we derive effective continuous stochastic dynamics for these methods. Our key contribution is that sampling-induced noise in SGD manifests in the limit as independent Brownian motions driving the parameter and gradient second momentum evolutions. Furthermore, extending the approach of Malladi et al., we investigate scaling rules between the learning rate and key hyperparameters in adaptive methods, characterising all non-trivial limiting dynamics.",
        "subjects": "Machine Learning, Machine Learning, Probability",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.210993"
    },
    {
        "index": "#264",
        "title": "IndiSeek learns information-guided disentangled representations",
        "link": "/arxiv/2509.21584",
        "arxiv_id": "2509.21584",
        "authors": "Yu Gui, Cong Ma, Zongming Ma",
        "summary": "Learning disentangled representations is a fundamental task in multi-modal learning. In modern applications such as single-cell multi-omics, both shared and modality-specific features are critical for characterizing cell states and supporting downstream analyses. Ideally, modality-specific features should be independent of shared ones while also capturing all complementary information within each modality. This tradeoff is naturally expressed through information-theoretic criteria, but mutual-information-based objectives are difficult to estimate reliably, and their variational surrogates often underperform in practice. In this paper, we introduce IndiSeek, a novel disentangled representation learning approach that addresses this challenge by combining an independence-enforcing objective with a computationally efficient reconstruction loss that bounds conditional mutual information. This formulation explicitly balances independence and completeness, enabling principled extraction of modality-specific features. We demonstrate the effectiveness of IndiSeek on synthetic simulations, a CITE-seq dataset and multiple real-world multi-modal benchmarks.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.212526"
    },
    {
        "index": "#265",
        "title": "General Pruning Criteria for Fast SBL",
        "link": "/arxiv/2509.21572",
        "arxiv_id": "2509.21572",
        "authors": "Jakob Möderl, Erik Leitinger, Bernard Henri Fleury",
        "summary": "Sparse Bayesian learning (SBL) associates to each weight in the underlying linear model a hyperparameter by assuming that each weight is Gaussian distributed with zero mean and precision (inverse variance) equal to its associated hyperparameter. The method estimates the hyperparameters by marginalizing out the weights and performing (marginalized) maximum likelihood (ML) estimation. SBL returns many hyperparameter estimates to diverge to infinity, effectively setting the estimates of the corresponding weights to zero (i.e., pruning the corresponding weights from the model) and thereby yielding a sparse estimate of the weight vector. In this letter, we analyze the marginal likelihood as function of a single hyperparameter while keeping the others fixed, when the Gaussian assumptions on the noise samples and the weight distribution that underlies the derivation of SBL are weakened. We derive sufficient conditions that lead, on the one hand, to finite hyperparameter estimates and, on the other, to infinite ones. Finally, we show that in the Gaussian case, the two conditions are complementary and coincide with the pruning condition of fast SBL (F-SBL), thereby providing additional insights into this algorithm.",
        "subjects": "Machine Learning, Machine Learning, Signal Processing",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.212816"
    },
    {
        "index": "#272",
        "title": "Functional Encryption in Secure Neural Network Training: Data Leakage and Practical Mitigations",
        "link": "/arxiv/2509.21497",
        "arxiv_id": "2509.21497",
        "authors": "Alexandru Ioniţă, Andreea Ioniţă",
        "summary": "With the increased interest in artificial intelligence, Machine Learning as a Service provides the infrastructure in the Cloud for easy training, testing, and deploying models. However, these systems have a major privacy issue: uploading sensitive data to the Cloud, especially during training. Therefore, achieving secure Neural Network training has been on many researchers' minds lately. More and more solutions for this problem are built around a main pillar: Functional Encryption (FE). Although these approaches are very interesting and offer a new perspective on ML training over encrypted data, some vulnerabilities do not seem to be taken into consideration. In our paper, we present an attack on neural networks that uses FE for secure training over encrypted data. Our approach uses linear programming to reconstruct the original input, unveiling the previous security promises. To address the attack, we propose two solutions for secure training and inference that involve the client during the computation phase. One approach ensures security without relying on encryption, while the other uses function-hiding inner-product techniques.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.214956"
    },
    {
        "index": "#273",
        "title": "Context-Aware Hybrid Routing in Bluetooth Mesh Networks Using Multi-Model Machine Learning and AODV Fallback",
        "link": "/arxiv/2509.21490",
        "arxiv_id": "2509.21490",
        "authors": "Md Sajid Islam, Tanvir Hasan",
        "summary": "Bluetooth-based mesh networks offer a promising infrastructure for offline communication in emergency and resource constrained scenarios. However, traditional routing strategies such as Ad hoc On-Demand Distance Vector (AODV) often degrade under congestion and dynamic topological changes. This study proposes a hybrid intelligent routing framework that augments AODV with supervised machine learning to improve next-hop selection under varied network constraints. The framework integrates four predictive models: a delivery success classifier, a TTL regressor, a delay regressor, and a forwarder suitability classifier, into a unified scoring mechanism that dynamically ranks neighbors during multi-hop message transmission. A simulation environment with stationary node deployments was developed, incorporating buffer constraints and device heterogeneity to evaluate three strategies: baseline AODV, a partial hybrid ML model (ABC), and the full hybrid ML model (ABCD). Across ten scenarios, the Hybrid ABCD model achieves approximately 99.97 percent packet delivery under these controlled conditions, significantly outperforming both the baseline and intermediate approaches. The results demonstrate that lightweight, explainable machine learning models can enhance routing reliability and adaptability in Bluetooth mesh networks, particularly in infrastructure-less environments where delivery success is prioritized over latency constraints.",
        "subjects": "Networking and Internet Architecture, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.215217"
    },
    {
        "index": "#287",
        "title": "Data-driven approach to the design of complexing agents for trivalent transuranium elements",
        "link": "/arxiv/2509.21362",
        "arxiv_id": "2509.21362",
        "authors": "Kirill V. Karpov, Ivan S. Pikulin, Grigory V. Bokov, Artem A. Mitrofanov",
        "summary": "The properties of complexes with transuranium elements have long been the object of research in various fields of chemistry. However, their experimental study is complicated by their rarity, high cost and special conditions necessary for working with such elements, and the complexity of quantum chemical calculations does not allow their use for large systems. To overcome these problems, we used modern machine learning methods to create a novel neural network architecture that allows to use available experimental data on a number of elements and thus significantly improve the quality of the resulting models. We also described the applicability domain of the presented model and identified the molecular fragments that most influence the stability of the complexes.",
        "subjects": "Chemical Physics, Machine Learning",
        "date": "2025-09-21",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.219538"
    },
    {
        "index": "#289",
        "title": "Accurate typhoon intensity forecasts using a non-iterative spatiotemporal transformer model",
        "link": "/arxiv/2509.21349",
        "arxiv_id": "2509.21349",
        "authors": "Hongyu Qu, Hongxiong Xu, Lin Dong, Chunyi Xiang, Gaozhen Nie",
        "summary": "Accurate forecasting of tropical cyclone (TC) intensity - particularly during periods of rapid intensification and rapid weakening - remains a challenge for operational meteorology, with high-stakes implications for disaster preparedness and infrastructure resilience. Recent advances in machine learning have yielded notable progress in TC prediction; however, most existing systems provide forecasts that degrade rapidly in extreme regimes and lack long-range consistency. Here we introduce TIFNet, a transformer-based forecasting model that generates non-iterative, 5-day intensity trajectories by integrating high-resolution global forecasts with a historical-evolution fusion mechanism. Trained on reanalysis data and fine-tuned with operational data, TIFNet consistently outperforms operational numerical models across all forecast horizons, delivering robust improvements across weak, strong, and super typhoon categories. In rapid intensity change regimes - long regarded as the most difficult to forecast - TIFNet reduces forecast error by 29-43% relative to current operational baselines. These results represent a substantial advance in artificial-intelligence-based TC intensity forecasting, especially under extreme conditions where traditional models consistently underperform.",
        "subjects": "Atmospheric and Oceanic Physics, Machine Learning",
        "date": "2025-09-18",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.220190"
    },
    {
        "index": "#290",
        "title": "Spiking Neural Networks for Mental Workload Classification with a Multimodal Approach",
        "link": "/arxiv/2509.21346",
        "arxiv_id": "2509.21346",
        "authors": "Jiahui An, Sara Irina Fabrikant, Giacomo Indiveri, Elisa Donati",
        "summary": "Accurately assessing mental workload is crucial in cognitive neuroscience, human-computer interaction, and real-time monitoring, as cognitive load fluctuations affect performance and decision-making. While Electroencephalography (EEG) based machine learning (ML) models can be used to this end, their high computational cost hinders embedded real-time applications. Hardware implementations of spiking neural networks (SNNs) offer a promising alternative for low-power, fast, event-driven processing. This study compares hardware compatible SNN models with various traditional ML ones, using an open-source multimodal dataset. Our results show that multimodal integration improves accuracy, with SNN performance comparable to the ML one, demonstrating their potential for real-time implementations of cognitive load detection. These findings position event-based processing as a promising solution for low-latency, energy efficient workload monitoring in adaptive closed-loop embedded devices that dynamically regulate cognitive load.",
        "subjects": "Neural and Evolutionary Computing, Machine Learning, Biomolecules",
        "date": "2025-09-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.220489"
    },
    {
        "index": "#296",
        "title": "Interpretable Spectral Features Predict Conductivity in Self-Driving Doped Conjugated Polymer Labs",
        "link": "/arxiv/2509.21330",
        "arxiv_id": "2509.21330",
        "authors": "Ankush Kumar Mishra, Jacob P. Mauthe, Nicholas Luke, Aram Amassian, Baskar Ganapathysubramanian",
        "summary": "Self-driving labs (SDLs) promise faster materials discovery by coupling automation with machine learning, but a central challenge is predicting costly, slow-to-measure properties from inexpensive, automatable readouts. We address this for doped conjugated polymers by learning interpretable spectral fingerprints from optical spectroscopy to predict electrical conductivity. Optical spectra are fast, non-destructive, and sensitive to aggregation and charge generation; we automate their featurization by combining a genetic algorithm (GA) with area-under-the-curve (AUC) computations over adaptively selected spectral windows. These data-driven spectral features, together with processing parameters, are used to train a quantitative structure-property relationship (QSPR) linking optical response and processing to conductivity. To improve accuracy and interpretability in the small-data regime, we add domain-knowledge-based feature expansions and apply SHAP-guided selection to retain a compact, physically meaningful feature set. The pipeline is evaluated under a leak-free train/test protocol, and GA is repeated to assess feature stability. The data-driven model matches the performance of a baseline built from expert-curated descriptors while reducing experimental effort (about 33%) by limiting direct conductivity measurements. Combining data-driven and expert features yields a hybrid QSPR with superior predictive performance, highlighting productive human-ML collaboration. The learned features recover known descriptors in pBTTT (0-0/0-1 vibronic intensity ratio) and reveal a tail-state region correlated with polymer bleaching during successful doping. This approach delivers interpretable, noise-robust, small-data-friendly features that convert rapid measurements into reliable predictions of costly properties and readily extends to other spectral modalities (e.g., XANES, Raman, FTIR).",
        "subjects": "Materials Science, Soft Condensed Matter, Machine Learning",
        "date": "2025-09-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-06T22:42:04.222281"
    }
]