[
    {
        "index": "#1",
        "title": "Benefits and Pitfalls of Reinforcement Learning for Language Model Planning: A Theoretical Perspective",
        "link": "/arxiv/2509.22613",
        "arxiv_id": "2509.22613",
        "authors": "Siwei Wang, Yifei Shen, Haoran Sun, Shi Feng, Shang-Hua Teng, Li Dong, Yaru Hao, Wei Chen",
        "summary": "Recent reinforcement learning (RL) methods have substantially enhanced the planning capabilities of Large Language Models (LLMs), yet the theoretical basis for their effectiveness remains elusive. In this work, we investigate RL's benefits and limitations through a tractable graph-based abstraction, focusing on policy gradient (PG) and Q-learning methods. Our theoretical analyses reveal that supervised fine-tuning (SFT) may introduce co-occurrence-based spurious solutions, whereas RL achieves correct planning primarily through exploration, underscoring exploration's role in enabling better generalization. However, we also show that PG suffers from diversity collapse, where output diversity decreases during training and persists even after perfect accuracy is attained. By contrast, Q-learning provides two key advantages: off-policy learning and diversity preservation at convergence. We further demonstrate that careful reward design is necessary to prevent reward hacking in Q-learning. Finally, applying our framework to the real-world planning benchmark Blocksworld, we confirm that these behaviors manifest in practice.",
        "subjects": "Artificial Intelligence, Machine Learning, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.623143"
    },
    {
        "index": "#3",
        "title": "UniMIC: Token-Based Multimodal Interactive Coding for Human-AI Collaboration",
        "link": "/arxiv/2509.22570",
        "arxiv_id": "2509.22570",
        "authors": "Qi Mao, Tinghan Yang, Jiahao Li, Bin Li, Libiao Jin, Yan Lu",
        "summary": "The rapid progress of Large Multimodal Models (LMMs) and cloud-based AI agents is transforming human-AI collaboration into bidirectional, multimodal interaction. However, existing codecs remain optimized for unimodal, one-way communication, resulting in repeated degradation under conventional compress-transmit-reconstruct pipelines. To address this limitation, we propose UniMIC, a Unified token-based Multimodal Interactive Coding framework that bridges edge devices and cloud AI agents. Instead of transmitting raw pixels or plain text, UniMIC employs compact tokenized representations as the communication medium, enabling efficient low-bitrate transmission while maintaining compatibility with LMMs. To further enhance compression, lightweight Transformer-based entropy models with scenario-specific designs-generic, masked, and text-conditioned-effectively minimize inter-token redundancy. Extensive experiments on text-to-image generation, text-guided inpainting, outpainting, and visual question answering show that UniMIC achieves substantial bitrate savings and remains robust even at ultra-low bitrates (<0.05bpp), without compromising downstream task performance. These results establish UniMIC as a practical and forward-looking paradigm for next-generation multimodal interactive communication.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.625447"
    },
    {
        "index": "#4",
        "title": "StepORLM: A Self-Evolving Framework With Generative Process Supervision For Operations Research Language Models",
        "link": "/arxiv/2509.22558",
        "arxiv_id": "2509.22558",
        "authors": "Chenyu Zhou, Tianyi Xu, Jianghao Lin, Dongdong Ge",
        "summary": "Large Language Models (LLMs) have shown promising capabilities for solving Operations Research (OR) problems. While reinforcement learning serves as a powerful paradigm for LLM training on OR problems, existing works generally face two key limitations. First, outcome reward suffers from the credit assignment problem, where correct final answers can reinforce flawed reasoning. Second, conventional discriminative process supervision is myopic, failing to evaluate the interdependent steps of OR modeling holistically. To this end, we introduce StepORLM, a novel self-evolving framework with generative process supervision. At its core, StepORLM features a co-evolutionary loop where a policy model and a generative process reward model (GenPRM) iteratively improve on each other. This loop is driven by a dual-feedback mechanism: definitive, outcome-based verification from an external solver, and nuanced, holistic process evaluation from the GenPRM. The combined signal is used to align the policy via Weighted Direct Preference Optimization (W-DPO) and simultaneously refine the GenPRM. Our resulting 8B-parameter StepORLM establishes a new state-of-the-art across six benchmarks, significantly outperforming vastly larger generalist models, agentic methods, and specialized baselines. Moreover, the co-evolved GenPRM is able to act as a powerful and universally applicable process verifier, substantially boosting the inference scaling performance of both our own model and other existing LLMs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.625918"
    },
    {
        "index": "#5",
        "title": "The Emergence of Altruism in Large-Language-Model Agents Society",
        "link": "/arxiv/2509.22537",
        "arxiv_id": "2509.22537",
        "authors": "Haoyang Li, Xiao Jia, Zhanzhan Zhao",
        "summary": "Leveraging Large Language Models (LLMs) for social simulation is a frontier in computational social science. Understanding the social logics these agents embody is critical to this attempt. However, existing research has primarily focused on cooperation in small-scale, task-oriented games, overlooking how altruism, which means sacrificing self-interest for collective benefit, emerges in large-scale agent societies. To address this gap, we introduce a Schelling-variant urban migration model that creates a social dilemma, compelling over 200 LLM agents to navigate an explicit conflict between egoistic (personal utility) and altruistic (system utility) goals. Our central finding is a fundamental difference in the social tendencies of LLMs. We identify two distinct archetypes: \"Adaptive Egoists\", which default to prioritizing self-interest but whose altruistic behaviors significantly increase under the influence of a social norm-setting message board; and \"Altruistic Optimizers\", which exhibit an inherent altruistic logic, consistently prioritizing collective benefit even at a direct cost to themselves. Furthermore, to qualitatively analyze the cognitive underpinnings of these decisions, we introduce a method inspired by Grounded Theory to systematically code agent reasoning. In summary, this research provides the first evidence of intrinsic heterogeneity in the egoistic and altruistic tendencies of different LLMs. We propose that for social simulation, model selection is not merely a matter of choosing reasoning capability, but of choosing an intrinsic social action logic. While \"Adaptive Egoists\" may offer a more suitable choice for simulating complex human societies, \"Altruistic Optimizers\" are better suited for modeling idealized pro-social actors or scenarios where collective welfare is the primary consideration.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.626371"
    },
    {
        "index": "#6",
        "title": "REMA: A Unified Reasoning Manifold Framework for Interpreting Large Language Model",
        "link": "/arxiv/2509.22518",
        "arxiv_id": "2509.22518",
        "authors": "Bo Li, Guanzhi Deng, Ronghao Chen, Junrong Yue, Shuo Zhang, Qinghua Zhao, Linqi Song, Lijie Wen",
        "summary": "Understanding how Large Language Models (LLMs) perform complex reasoning and their failure mechanisms is a challenge in interpretability research. To provide a measurable geometric analysis perspective, we define the concept of the Reasoning Manifold, a latent low-dimensional geometric structure formed by the internal representations corresponding to all correctly reasoned generations. This structure can be conceptualized as the embodiment of the effective thinking paths that the model has learned to successfully solve a given task. Based on this concept, we build REMA, a framework that explains the origins of failures by quantitatively comparing the spatial relationships of internal model representations corresponding to both erroneous and correct reasoning samples. Specifically, REMA first quantifies the geometric deviation of each erroneous representation by calculating its k-nearest neighbors distance to the approximated manifold formed by correct representations, thereby providing a unified failure signal. It then localizes the divergence points where these deviations first become significant by tracking this deviation metric across the model's layers and comparing it against a baseline of internal fluctuations from correct representations, thus identifying where the reasoning chain begins to go off-track. Our extensive experiments on diverse language and multimodal models and tasks demonstrate the low-dimensional nature of the reasoning manifold and the high separability between erroneous and correct reasoning representations. The results also validate the effectiveness of the REMA framework in analyzing the origins of reasoning failures. This research connects abstract reasoning failures to measurable geometric deviations in representations, providing new avenues for in-depth understanding and diagnosis of the internal computational processes of black-box models.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.626906"
    },
    {
        "index": "#7",
        "title": "TrueGradeAI: Retrieval-Augmented and Bias-Resistant AI for Transparent and Explainable Digital Assessments",
        "link": "/arxiv/2509.22516",
        "arxiv_id": "2509.22516",
        "authors": "Rakesh Thakur, Shivaansh Kaushik, Gauri Chopra, Harsh Rohilla",
        "summary": "This paper introduces TrueGradeAI, an AI-driven digital examination framework designed to overcome the shortcomings of traditional paper-based assessments, including excessive paper usage, logistical complexity, grading delays, and evaluator bias. The system preserves natural handwriting by capturing stylus input on secure tablets and applying transformer-based optical character recognition for transcription. Evaluation is conducted through a retrieval-augmented pipeline that integrates faculty solutions, cache layers, and external references, enabling a large language model to assign scores with explicit, evidence-linked reasoning. Unlike prior tablet-based exam systems that primarily digitize responses, TrueGradeAI advances the field by incorporating explainable automation, bias mitigation, and auditable grading trails. By uniting handwriting preservation with scalable and transparent evaluation, the framework reduces environmental costs, accelerates feedback cycles, and progressively builds a reusable knowledge base, while actively working to mitigate grading bias and ensure fairness in assessment.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.627397"
    },
    {
        "index": "#8",
        "title": "Estimating the Empowerment of Language Model Agents",
        "link": "/arxiv/2509.22504",
        "arxiv_id": "2509.22504",
        "authors": "Jinyeop Song, Jeff Gore, Max Kleiman-Weiner",
        "summary": "As language model (LM) agents become more capable and gain broader access to real-world tools, there is a growing need for scalable evaluation frameworks of agentic capability. However, conventional benchmark-centric evaluations are costly to design and require human designers to come up with valid tasks that translate into insights about general model capabilities. In this work, we propose information-theoretic evaluation based on empowerment, the mutual information between an agent's actions and future states, as an open-ended method for evaluating LM agents. We introduce EELMA (Estimating Empowerment of Language Model Agents), an algorithm for approximating effective empowerment from multi-turn text interactions. We validate EELMA on both language games and scaled-up realistic web-browsing scenarios. We find that empowerment strongly correlates with average task performance, characterize the impact of environmental complexity and agentic factors such as chain-of-thought, model scale, and memory length on estimated empowerment, and that high empowerment states and actions are often pivotal moments for general capabilities. Together, these results demonstrate empowerment as an appealing general-purpose metric for evaluating and monitoring LM agents in complex, open-ended settings.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.633028"
    },
    {
        "index": "#9",
        "title": "InfiAgent: Self-Evolving Pyramid Agent Framework for Infinite Scenarios",
        "link": "/arxiv/2509.22502",
        "arxiv_id": "2509.22502",
        "authors": "Chenglin Yu, Yang Yu, Songmiao Wang, Yucheng Wang, Yifan Yang, Jinjia Li, Ming Li, Hongxia Yang",
        "summary": "Large Language Model (LLM) agents have demonstrated remarkable capabilities in organizing and executing complex tasks, and many such agents are now widely used in various application scenarios. However, developing these agents requires carefully designed workflows, carefully crafted prompts, and iterative tuning, which requires LLM techniques and domain-specific expertise. These hand-crafted limitations hinder the scalability and cost-effectiveness of LLM agents across a wide range of industries. To address these challenges, we propose \\textbf{InfiAgent}, a Pyramid-like DAG-based Multi-Agent Framework that can be applied to \\textbf{infi}nite scenarios, which introduces several key innovations: a generalized \"agent-as-a-tool\" mechanism that automatically decomposes complex agents into hierarchical multi-agent systems; a dual-audit mechanism that ensures the quality and stability of task completion; an agent routing function that enables efficient task-agent matching; and an agent self-evolution mechanism that autonomously restructures the agent DAG based on new tasks, poor performance, or optimization opportunities. Furthermore, InfiAgent's atomic task design supports agent parallelism, significantly improving execution efficiency. This framework evolves into a versatile pyramid-like multi-agent system capable of solving a wide range of problems. Evaluations on multiple benchmarks demonstrate that InfiAgent achieves 9.9\\% higher performance compared to ADAS (similar auto-generated agent framework), while a case study of the AI research assistant InfiHelper shows that it generates scientific papers that have received recognition from human reviewers at top-tier IEEE conferences.",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.633596"
    },
    {
        "index": "#10",
        "title": "GeoSketch: A Neural-Symbolic Approach to Geometric Multimodal Reasoning with Auxiliary Line Construction and Affine Transformation",
        "link": "/arxiv/2509.22460",
        "arxiv_id": "2509.22460",
        "authors": "Shichao Weng, Zhiqiang Wang, Yuhua Zhou, Rui Lu, Ting Liu, Zhiyang Teng, Xiaozhang Liu, Hanmeng Liu",
        "summary": "Geometric Problem Solving (GPS) poses a unique challenge for Multimodal Large Language Models (MLLMs), requiring not only the joint interpretation of text and diagrams but also iterative visuospatial reasoning. While existing approaches process diagrams as static images, they lack the capacity for dynamic manipulation - a core aspect of human geometric reasoning involving auxiliary line construction and affine transformations. We present GeoSketch, a neural-symbolic framework that recasts geometric reasoning as an interactive perception-reasoning-action loop. GeoSketch integrates: (1) a Perception module that abstracts diagrams into structured logic forms, (2) a Symbolic Reasoning module that applies geometric theorems to decide the next deductive step, and (3) a Sketch Action module that executes operations such as drawing auxiliary lines or applying transformations, thereby updating the diagram in a closed loop. To train this agent, we develop a two-stage pipeline: supervised fine-tuning on 2,000 symbolic-curated trajectories followed by reinforcement learning with dense, symbolic rewards to enhance robustness and strategic exploration. To evaluate this paradigm, we introduce the GeoSketch Benchmark, a high-quality set of 390 geometry problems requiring auxiliary construction or affine transformations. Experiments on strong MLLM baselines demonstrate that GeoSketch significantly improves stepwise reasoning accuracy and problem-solving success over static perception methods. By unifying hierarchical decision-making, executable visual actions, and symbolic verification, GeoSketch advances multimodal reasoning from static interpretation to dynamic, verifiable interaction, establishing a new foundation for solving complex visuospatial problems.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.634139"
    },
    {
        "index": "#11",
        "title": "Guiding Evolution of Artificial Life Using Vision-Language Models",
        "link": "/arxiv/2509.22447",
        "arxiv_id": "2509.22447",
        "authors": "Nikhil Baid, Hannah Erlebach, Paul Hellegouarch, Frederico Wieser",
        "summary": "Foundation models (FMs) have recently opened up new frontiers in the field of artificial life (ALife) by providing powerful tools to automate search through ALife simulations. Previous work aligns ALife simulations with natural language target prompts using vision-language models (VLMs). We build on Automated Search for Artificial Life (ASAL) by introducing ASAL++, a method for open-ended-like search guided by multimodal FMs. We use a second FM to propose new evolutionary targets based on a simulation's visual history. This induces an evolutionary trajectory with increasingly complex targets. We explore two strategies: (1) evolving a simulation to match a single new prompt at each iteration (Evolved Supervised Targets: EST) and (2) evolving a simulation to match the entire sequence of generated prompts (Evolved Temporal Targets: ETT). We test our method empirically in the Lenia substrate using Gemma-3 to propose evolutionary targets, and show that EST promotes greater visual novelty, while ETT fosters more coherent and interpretable evolutionary sequences. Our results suggest that ASAL++ points towards new directions for FM-driven ALife discovery with open-ended characteristics.",
        "subjects": "Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.634629"
    },
    {
        "index": "#12",
        "title": "EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer",
        "link": "/arxiv/2509.22407",
        "arxiv_id": "2509.22407",
        "authors": "Zhehao Dong, Xiaofeng Wang, Zheng Zhu, Yirui Wang, Yang Wang, Yukun Zhou, Boyuan Wang, Chaojun Ni, Runqi Ouyang, Wenkang Qin, Xinze Chen, Yun Ye, Guan Huang",
        "summary": "Vision-language-action (VLA) models increasingly rely on diverse training data to achieve robust generalization. However, collecting large-scale real-world robot manipulation data across varied object appearances and environmental conditions remains prohibitively time-consuming and expensive. To overcome this bottleneck, we propose Embodied Manipulation Media Adaptation (EMMA), a VLA policy enhancement framework that integrates a generative data engine with an effective training pipeline. We introduce DreamTransfer, a diffusion Transformer-based framework for generating multi-view consistent, geometrically grounded embodied manipulation videos. DreamTransfer enables text-controlled visual editing of robot videos, transforming foreground, background, and lighting conditions without compromising 3D structure or geometrical plausibility. Furthermore, we explore hybrid training with real and generated data, and introduce AdaMix, a hard-sample-aware training strategy that dynamically reweights training batches to focus optimization on perceptually or kinematically challenging samples. Extensive experiments show that videos generated by DreamTransfer significantly outperform prior video generation methods in multi-view consistency, geometric fidelity, and text-conditioning accuracy. Crucially, VLAs trained with generated data enable robots to generalize to unseen object categories and novel visual domains using only demonstrations from a single appearance. In real-world robotic manipulation tasks with zero-shot visual domains, our approach achieves over a 200% relative performance gain compared to training on real data alone, and further improves by 13% with AdaMix, demonstrating its effectiveness in boosting policy generalization.",
        "subjects": "Artificial Intelligence, Robotics",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.635255"
    },
    {
        "index": "#13",
        "title": "Do LLM Agents Know How to Ground, Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents",
        "link": "/arxiv/2509.22391",
        "arxiv_id": "2509.22391",
        "authors": "Jiaqi Shao, Yuxiang Lin, Munish Prasad Lohani, Yufeng Miao, Bing Luo",
        "summary": "Recent work has explored training Large Language Model (LLM) search agents with reinforcement learning (RL) for open-domain question answering (QA). However, most evaluations focus solely on final answer accuracy, overlooking how these agents reason with and act on external evidence. We introduce SeekBench, the first benchmark for evaluating the \\textit{epistemic competence} of LLM search agents through step-level analysis of their response traces. SeekBench comprises 190 expert-annotated traces with over 1,800 response steps generated by LLM search agents, each enriched with evidence annotations for granular analysis of whether agents (1) generate reasoning steps grounded in observed evidence, (2) adaptively reformulate searches to recover from low-quality results, and (3) have proper calibration to correctly assess whether the current evidence is sufficient for providing an answer.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.635752"
    },
    {
        "index": "#15",
        "title": "Large Language Models as Nondeterministic Causal Models",
        "link": "/arxiv/2509.22297",
        "arxiv_id": "2509.22297",
        "authors": "Sander Beckers",
        "summary": "Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first time, a method for generating counterfactuals of probabilistic Large Language Models. Such counterfactuals tell us what would - or might - have been the output of an LLM if some factual prompt ${\\bf x}$ had been ${\\bf x}^*$ instead. The ability to generate such counterfactuals is an important necessary step towards explaining, evaluating, and comparing, the behavior of LLMs. I argue, however, that the existing method rests on an ambiguous interpretation of LLMs: it does not interpret LLMs literally, for the method involves the assumption that one can change the implementation of an LLM's sampling process without changing the LLM itself, nor does it interpret LLMs as intended, for the method involves explicitly representing a nondeterministic LLM as a deterministic causal model. I here present a much simpler method for generating counterfactuals that is based on an LLM's intended interpretation by representing it as a nondeterministic causal model instead. The advantage of my simpler method is that it is directly applicable to any black-box LLM without modification, as it is agnostic to any implementation details. The advantage of the existing method, on the other hand, is that it directly implements the generation of a specific type of counterfactuals that is useful for certain purposes, but not for others. I clarify how both methods relate by offering a theoretical foundation for reasoning about counterfactuals in LLMs based on their intended semantics, thereby laying the groundwork for novel application-specific methods for generating counterfactuals.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.636723"
    },
    {
        "index": "#16",
        "title": "Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models",
        "link": "/arxiv/2509.22284",
        "arxiv_id": "2509.22284",
        "authors": "Aleksandar Terzić, Nicolas Menet, Michael Hersche, Thomas Hofmann, Abbas Rahimi",
        "summary": "Modern state-space models (SSMs) often utilize transition matrices which enable efficient computation but pose restrictions on the model's expressivity, as measured in terms of the ability to emulate finite-state automata (FSA). While unstructured transition matrices are optimal in terms of expressivity, they come at a prohibitively high compute and memory cost even for moderate state sizes. We propose a structured sparse parametrization of transition matrices in SSMs that enables FSA state tracking with optimal state size and depth, while keeping the computational cost of the recurrence comparable to that of diagonal SSMs. Our method, PD-SSM, parametrizes the transition matrix as the product of a column one-hot matrix ($P$) and a complex-valued diagonal matrix ($D$). Consequently, the computational cost of parallel scans scales linearly with the state size. Theoretically, the model is BIBO-stable and can emulate any $N$-state FSA with one layer of dimension $N$ and a linear readout of size $N \\times N$, significantly improving on all current structured SSM guarantees. Experimentally, the model significantly outperforms a wide collection of modern SSM variants on various FSA state tracking tasks. On multiclass time-series classification, the performance is comparable to that of neural controlled differential equations, a paradigm explicitly built for time-series analysis. Finally, we integrate PD-SSM into a hybrid Transformer-SSM architecture and demonstrate that the model can effectively track the states of a complex FSA in which transitions are encoded as a set of variable-length English sentences. The code is available at https://github.com/IBM/expressive-sparse-state-space-model",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.637223"
    },
    {
        "index": "#18",
        "title": "Evaluating LLMs for Combinatorial Optimization: One-Phase and Two-Phase Heuristics for 2D Bin-Packing",
        "link": "/arxiv/2509.22255",
        "arxiv_id": "2509.22255",
        "authors": "Syed Mahbubul Huq, Daniel Brito, Daniel Sikar, Rajesh Mojumder",
        "summary": "This paper presents an evaluation framework for assessing Large Language Models' (LLMs) capabilities in combinatorial optimization, specifically addressing the 2D bin-packing problem. We introduce a systematic methodology that combines LLMs with evolutionary algorithms to generate and refine heuristic solutions iteratively. Through comprehensive experiments comparing LLM generated heuristics against traditional approaches (Finite First-Fit and Hybrid First-Fit), we demonstrate that LLMs can produce more efficient solutions while requiring fewer computational resources. Our evaluation reveals that GPT-4o achieves optimal solutions within two iterations, reducing average bin usage from 16 to 15 bins while improving space utilization from 0.76-0.78 to 0.83. This work contributes to understanding LLM evaluation in specialized domains and establishes benchmarks for assessing LLM performance in combinatorial optimization tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.853884"
    },
    {
        "index": "#21",
        "title": "Ground-Truthing AI Energy Consumption: Validating CodeCarbon Against External Measurements",
        "link": "/arxiv/2509.22092",
        "arxiv_id": "2509.22092",
        "authors": "Raphael Fischer",
        "summary": "Although machine learning (ML) and artificial intelligence (AI) present fascinating opportunities for innovation, their rapid development is also significantly impacting our environment. In response to growing resource-awareness in the field, quantification tools such as the ML Emissions Calculator and CodeCarbon were developed to estimate the energy consumption and carbon emissions of running AI models. They are easy to incorporate into AI projects, however also make pragmatic assumptions and neglect important factors, raising the question of estimation accuracy. This study systematically evaluates the reliability of static and dynamic energy estimation approaches through comparisons with ground-truth measurements across hundreds of AI experiments. Based on the proposed validation framework, investigative insights into AI energy demand and estimation inaccuracies are provided. While generally following the patterns of AI energy consumption, the established estimation approaches are shown to consistently make errors of up to 40%. By providing empirical evidence on energy estimation quality and errors, this study establishes transparency and validates widely used tools for sustainable AI development. It moreover formulates guidelines for improving the state-of-the-art and offers code for extending the validation to other domains and tools, thus making important contributions to resource-aware ML and AI sustainability research.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.871748"
    },
    {
        "index": "#22",
        "title": "Generalizing Multi-Objective Search via Objective-Aggregation Functions",
        "link": "/arxiv/2509.22085",
        "arxiv_id": "2509.22085",
        "authors": "Hadar Peer, Eyal Weiss, Ron Alterovitz, Oren Salzman",
        "summary": "Multi-objective search (MOS) has become essential in robotics, as real-world robotic systems need to simultaneously balance multiple, often conflicting objectives. Recent works explore complex interactions between objectives, leading to problem formulations that do not allow the usage of out-of-the-box state-of-the-art MOS algorithms. In this paper, we suggest a generalized problem formulation that optimizes solution objectives via aggregation functions of hidden (search) objectives. We show that our formulation supports the application of standard MOS algorithms, necessitating only to properly extend several core operations to reflect the specific aggregation functions employed. We demonstrate our approach in several diverse robotics planning problems, spanning motion-planning for navigation, manipulation and planning fr medical systems under obstacle uncertainty as well as inspection planning, and route planning with different road types. We solve the problems using state-of-the-art MOS algorithms after properly extending their core operations, and provide empirical evidence that they outperform by orders of magnitude the vanilla versions of the algorithms applied to the same problems but without objective aggregation.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.872350"
    },
    {
        "index": "#25",
        "title": "GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments",
        "link": "/arxiv/2509.21998",
        "arxiv_id": "2509.21998",
        "authors": "Hanlin Zhu, Tianyu Guo, Song Mei, Stuart Russell, Nikhil Ghosh, Alberto Bietti, Jiantao Jiao",
        "summary": "As LLMs are increasingly deployed as agents, agentic reasoning - the ability to combine tool use, especially search, and reasoning - becomes a critical skill. However, it is hard to disentangle agentic reasoning when evaluated in complex environments and tasks. Current agent benchmarks often mix agentic reasoning with challenging math reasoning, expert-level knowledge, and other advanced capabilities. To fill this gap, we build a novel benchmark, GSM-Agent, where an LLM agent is required to solve grade-school-level reasoning problems, but is only presented with the question in the prompt without the premises that contain the necessary information to solve the task, and needs to proactively collect that information using tools. Although the original tasks are grade-school math problems, we observe that even frontier models like GPT-5 only achieve 67% accuracy. To understand and analyze the agentic reasoning patterns, we propose the concept of agentic reasoning graph: cluster the environment's document embeddings into nodes, and map each tool call to its nearest node to build a reasoning path. Surprisingly, we identify that the ability to revisit a previously visited node, widely taken as a crucial pattern in static reasoning, is often missing for agentic reasoning for many models. Based on the insight, we propose a tool-augmented test-time scaling method to improve LLM's agentic reasoning performance by adding tools to encourage models to revisit. We expect our benchmark and the agentic reasoning framework to aid future studies of understanding and pushing the boundaries of agentic reasoning.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.874380"
    },
    {
        "index": "#26",
        "title": "Bilinear relational structure fixes reversal curse and enables consistent model editing",
        "link": "/arxiv/2509.21993",
        "arxiv_id": "2509.21993",
        "authors": "Dong-Kyum Kim, Minsung Kim, Jea Kwon, Nakyeong Yang, Meeyoung Cha",
        "summary": "The reversal curse -- a language model's (LM) inability to infer an unseen fact ``B is A'' from a learned fact ``A is B'' -- is widely considered a fundamental limitation. We show that this is not an inherent failure but an artifact of how models encode knowledge. By training LMs from scratch on a synthetic dataset of relational knowledge graphs, we demonstrate that bilinear relational structure emerges in their hidden representations. This structure substantially alleviates the reversal curse, enabling LMs to infer unseen reverse facts. Crucially, we also find that this bilinear structure plays a key role in consistent model editing. When a fact is updated in a LM with this structure, the edit correctly propagates to its reverse and other logically dependent facts. In contrast, models lacking this representation not only suffer from the reversal curse but also fail to generalize edits, further introducing logical inconsistencies. Our results establish that training on a relational knowledge dataset induces the emergence of bilinear internal representations, which in turn enable LMs to behave in a logically consistent manner after editing. This implies that the success of model editing depends critically not just on editing algorithms but on the underlying representational geometry of the knowledge being modified.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.880293"
    },
    {
        "index": "#29",
        "title": "Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning",
        "link": "/arxiv/2509.21943",
        "arxiv_id": "2509.21943",
        "authors": "Carlo Dindorf, Jonas Dully, Steven Simon, Dennis Perchthaler, Stephan Becker, Hannah Ehmann, Kjell Heitmann, Bernd Stetter, Christian Diers, Michael Fröhlich",
        "summary": "Plantar pressure mapping is essential in clinical diagnostics and sports science, yet large heterogeneous datasets often contain outliers from technical errors or procedural inconsistencies. Statistical Parametric Mapping (SPM) provides interpretable analyses but is sensitive to alignment and its capacity for robust outlier detection remains unclear. This study compares an SPM approach with an explainable machine learning (ML) approach to establish transparent quality-control pipelines for plantar pressure datasets. Data from multiple centers were annotated by expert consensus and enriched with synthetic anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a non-parametric, registration-dependent SPM approach and (ii) a convolutional neural network (CNN), explained using SHapley Additive exPlanations (SHAP). Performance was assessed via nested cross-validation; explanation quality via a semantic differential survey with domain experts. The ML model reached high accuracy and outperformed SPM, which misclassified clinically meaningful variations and missed true outliers. Experts perceived both SPM and SHAP explanations as clear, useful, and trustworthy, though SPM was assessed less complex. These findings highlight the complementary potential of SPM and explainable ML as approaches for automated outlier detection in plantar pressure data, and underscore the importance of explainability in translating complex model outputs into interpretable insights that can effectively inform decision-making.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.882129"
    },
    {
        "index": "#30",
        "title": "DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling",
        "link": "/arxiv/2509.21902",
        "arxiv_id": "2509.21902",
        "authors": "Ruiqi Chen, Yi Mei, Fangfang Zhang, Mengjie Zhang",
        "summary": "Dynamic job shop scheduling, a fundamental combinatorial optimisation problem in various industrial sectors, poses substantial challenges for effective scheduling due to frequent disruptions caused by the arrival of new jobs. State-of-the-art methods employ machine learning to learn scheduling policies offline, enabling rapid responses to dynamic events. However, these offline policies are often imperfect, necessitating the use of planning techniques such as Monte Carlo Tree Search (MCTS) to improve performance at online decision time. The unpredictability of new job arrivals complicates online planning, as decisions based on incomplete problem information are vulnerable to disturbances. To address this issue, we propose the Dynamic Robust MCTS (DyRo-MCTS) approach, which integrates action robustness estimation into MCTS. DyRo-MCTS guides the production environment toward states that not only yield good scheduling outcomes but are also easily adaptable to future job arrivals. Extensive experiments show that DyRo-MCTS significantly improves the performance of offline-learned policies with negligible additional online planning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across various scheduling scenarios. Further analysis reveals that its ability to make robust scheduling decisions leads to long-term, sustainable performance gains under disturbances.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.882603"
    },
    {
        "index": "#31",
        "title": "GenesisGeo: Technical Report",
        "link": "/arxiv/2509.21896",
        "arxiv_id": "2509.21896",
        "authors": "Minfeng Zhu, Zi Wang, Sizhe Ji, Zhengtong Du, Junming Ke, Xiao Deng, Zanlang Yin, Xiuqi Huang, Heyu Wang, Wei Chen",
        "summary": "We present GenesisGeo, an automated theorem prover in Euclidean geometry. We have open-sourced a large-scale geometry dataset of 21.8 million geometric problems, over 3 million of which contain auxiliary constructions. Specially, we significantly accelerate the symbolic deduction engine DDARN by 120x through theorem matching, combined with a C++ implementation of its core components. Furthermore, we build our neuro-symbolic prover, GenesisGeo, upon Qwen3-0.6B-Base, which solves 24 of 30 problems (IMO silver medal level) in the IMO-AG-30 benchmark using a single model, and achieves 26 problems (IMO gold medal level) with a dual-model ensemble.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.883164"
    },
    {
        "index": "#32",
        "title": "TRACE: Learning to Compute on Graphs",
        "link": "/arxiv/2509.21886",
        "arxiv_id": "2509.21886",
        "authors": "Ziyang Zheng, Jiaying Zhu, Jingyi Zhou, Qiang Xu",
        "summary": "Learning to compute, the ability to model the functional behavior of a computational graph, is a fundamental challenge for graph representation learning. Yet, the dominant paradigm is architecturally mismatched for this task. This flawed assumption, central to mainstream message passing neural networks (MPNNs) and their conventional Transformer-based counterparts, prevents models from capturing the position-aware, hierarchical nature of computation. To resolve this, we introduce \\textbf{TRACE}, a new paradigm built on an architecturally sound backbone and a principled learning objective. First, TRACE employs a Hierarchical Transformer that mirrors the step-by-step flow of computation, providing a faithful architectural backbone that replaces the flawed permutation-invariant aggregation. Second, we introduce \\textbf{function shift learning}, a novel objective that decouples the learning problem. Instead of predicting the complex global function directly, our model is trained to predict only the \\textit{function shift}, the discrepancy between the true global function and a simple local approximation that assumes input independence. We validate this paradigm on electronic circuits, one of the most complex and economically critical classes of computational graphs. Across a comprehensive suite of benchmarks, TRACE substantially outperforms all prior architectures. These results demonstrate that our architecturally-aligned backbone and decoupled learning objective form a more robust paradigm for the fundamental challenge of learning to compute on graphs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.883606"
    },
    {
        "index": "#34",
        "title": "DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents",
        "link": "/arxiv/2509.21842",
        "arxiv_id": "2509.21842",
        "authors": "Yansong Ning, Rui Liu, Jun Wang, Kai Chen, Wei Li, Jun Fang, Kan Zheng, Naiqiang Tan, Hao Liu",
        "summary": "Travel planning (TP) agent has recently worked as an emerging building block to interact with external tools and resources for travel itinerary generation, ensuring enjoyable user experience. Despite its benefits, existing studies rely on hand craft prompt and fixed agent workflow, hindering more flexible and autonomous TP agent. This paper proposes DeepTravel, an end to end agentic reinforcement learning framework for building autonomous travel planning agent, capable of autonomously planning, executing tools, and reflecting on tool responses to explore, verify, and refine intermediate actions in multi step reasoning. To achieve this, we first construct a robust sandbox environment by caching transportation, accommodation and POI data, facilitating TP agent training without being constrained by real world APIs limitations (e.g., inconsistent outputs). Moreover, we develop a hierarchical reward modeling system, where a trajectory level verifier first checks spatiotemporal feasibility and filters unsatisfied travel itinerary, and then the turn level verifier further validate itinerary detail consistency with tool responses, enabling efficient and precise reward service. Finally, we propose the reply augmented reinforcement learning method that enables TP agent to periodically replay from a failures experience buffer, emerging notable agentic capacity. We deploy trained TP agent on DiDi Enterprise Solutions App and conduct comprehensive online and offline evaluations, demonstrating that DeepTravel enables small size LLMs (e.g., Qwen3 32B) to significantly outperform existing frontier LLMs such as OpenAI o1, o3 and DeepSeek R1 in travel planning tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.884693"
    },
    {
        "index": "#36",
        "title": "DS-STAR: Data Science Agent via Iterative Planning and Verification",
        "link": "/arxiv/2509.21825",
        "arxiv_id": "2509.21825",
        "authors": "Jaehyun Nam, Jinsung Yoon, Jiefeng Chen, Jinwoo Shin, Tomas Pfister",
        "summary": "Data science, which transforms raw data into actionable insights, is critical for data-driven decision-making. However, these tasks are often complex, involving steps for exploring multiple data sources and synthesizing findings to deliver insightful answers. While large language models (LLMs) show significant promise in automating this process, they often struggle with heterogeneous data formats and generate sub-optimal analysis plans, as verifying plan sufficiency is inherently difficult without ground-truth labels for such open-ended tasks. To overcome these limitations, we introduce DS-STAR, a novel data science agent. Specifically, DS-STAR makes three key contributions: (1) a data file analysis module that automatically explores and extracts context from diverse data formats, including unstructured types; (2) a verification step where an LLM-based judge evaluates the sufficiency of the analysis plan at each stage; and (3) a sequential planning mechanism that starts with a simple, executable plan and iteratively refines it based on the DS-STAR's feedback until its sufficiency is verified. This iterative refinement allows DS-STAR to reliably navigate complex analyses involving diverse data sources. Our experiments show that DS-STAR achieves state-of-the-art performance across three challenging benchmarks: DABStep, KramaBench, and DA-Code. Moreover, DS-STAR particularly outperforms baselines on hard tasks that require processing multiple data files with heterogeneous formats.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.890777"
    },
    {
        "index": "#37",
        "title": "ProRe: A Proactive Reward System for GUI Agents via Reasoner-Actor Collaboration",
        "link": "/arxiv/2509.21823",
        "arxiv_id": "2509.21823",
        "authors": "Gaole Dai, Shiqi Jiang, Ting Cao, Yuqing Yang, Yuanchun Li, Rui Tan, Mo Li, Lili Qiu",
        "summary": "Reward is critical to the evaluation and training of large language models (LLMs). However, existing rule-based or model-based reward methods struggle to generalize to GUI agents, where access to ground-truth trajectories or application databases is often unavailable, and static trajectory-based LLM-as-a-Judge approaches suffer from limited accuracy. To address these challenges, we propose ProRe, a proactive reward system that leverages a general-purpose reasoner and domain-specific evaluator agents (actors). The reasoner schedules targeted state probing tasks, which the evaluator agents then execute by actively interacting with the environment to collect additional observations. This enables the reasoner to assign more accurate and verifiable rewards to GUI agents. Empirical results on over 3K trajectories demonstrate that ProRe improves reward accuracy and F1 score by up to 5.3% and 19.4%, respectively. Furthermore, integrating ProRe with state-of-the-art policy agents yields a success rate improvement of up to 22.4%.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.891296"
    },
    {
        "index": "#38",
        "title": "D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents",
        "link": "/arxiv/2509.21799",
        "arxiv_id": "2509.21799",
        "authors": "Hongze Mi, Yibo Feng, Wenjie Lu, Yuqi Wang, Jinyuan Li, Song Cao, He Cui, Tengfei Tian, Xuelin Zhang, Haotian Luo, Di Sun, Naiqiang Tan, Gang Pan",
        "summary": "Graphical User Interface (GUI) agents aim to automate a wide spectrum of human tasks by emulating user interaction. Despite rapid advancements, current approaches are hindered by several critical challenges: data bottleneck in end-to-end training, high cost of delayed error detection, and risk of contradictory guidance. Inspired by the human cognitive loop of Thinking, Alignment, and Reflection, we present D-Artemis -- a novel deliberative framework in this paper. D-Artemis leverages a fine-grained, app-specific tip retrieval mechanism to inform its decision-making process. It also employs a proactive Pre-execution Alignment stage, where Thought-Action Consistency (TAC) Check module and Action Correction Agent (ACA) work in concert to mitigate the risk of execution failures. A post-execution Status Reflection Agent (SRA) completes the cognitive loop, enabling strategic learning from experience. Crucially, D-Artemis enhances the capabilities of general-purpose Multimodal large language models (MLLMs) for GUI tasks without the need for training on complex trajectory datasets, demonstrating strong generalization. D-Artemis establishes new state-of-the-art (SOTA) results across both major benchmarks, achieving a 75.8% success rate on AndroidWorld and 96.8% on ScreenSpot-V2. Extensive ablation studies further demonstrate the significant contribution of each component to the framework.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.891891"
    },
    {
        "index": "#39",
        "title": "Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety",
        "link": "/arxiv/2509.21782",
        "arxiv_id": "2509.21782",
        "authors": "Junliang Liu, Jingyu Xiao, Wenxin Tang, Wenxuan Wang, Zhixian Wang, Minrui Zhang, Shuanghe Yu",
        "summary": "Multimodal large language models (MLLMs) are increasingly positioned as AI collaborators for building complex web-related applications like GUI agents and front-end code generation. However, existing benchmarks largely emphasize visual perception or UI code generation, showing insufficient evaluation on the reasoning, robustness and safety capability required for end-to-end web applications. To bridge the gap, we introduce a comprehensive web understanding benchmark, named WebRSSBench, that jointly evaluates Reasoning, Robustness, and Safety across eight tasks, such as position relationship reasoning, color robustness, and safety critical detection, etc. The benchmark is constructed from 729 websites and contains 3799 question answer pairs that probe multi-step inference over page structure, text, widgets, and safety-critical interactions. To ensure reliable measurement, we adopt standardized prompts, deterministic evaluation scripts, and multi-stage quality control combining automatic checks with targeted human verification. We evaluate 12 MLLMs on WebRSSBench. The results reveal significant gaps, models still struggle with compositional and cross-element reasoning over realistic layouts, show limited robustness when facing perturbations in user interfaces and content such as layout rearrangements or visual style shifts, and are rather conservative in recognizing and avoiding safety critical or irreversible actions. Our code is available at https://github.com/jinliang-byte/webssrbench.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.892402"
    },
    {
        "index": "#41",
        "title": "Lifelong Learning with Behavior Consolidation for Vehicle Routing",
        "link": "/arxiv/2509.21765",
        "arxiv_id": "2509.21765",
        "authors": "Jiyuan Pei, Yi Mei, Jialin Liu, Mengjie Zhang, Xin Yao",
        "summary": "Recent neural solvers have demonstrated promising performance in learning to solve routing problems. However, existing studies are primarily based on one-off training on one or a set of predefined problem distributions and scales, i.e., tasks. When a new task arises, they typically rely on either zero-shot generalization, which may be poor due to the discrepancies between the new task and the training task(s), or fine-tuning the pretrained solver on the new task, which possibly leads to catastrophic forgetting of knowledge acquired from previous tasks. This paper explores a novel lifelong learning paradigm for neural VRP solvers, where multiple tasks with diverse distributions and scales arise sequentially over time. Solvers are required to effectively and efficiently learn to solve new tasks while maintaining their performance on previously learned tasks. Consequently, a novel framework called Lifelong Learning Router with Behavior Consolidation (LLR-BC) is proposed. LLR-BC consolidates prior knowledge effectively by aligning behaviors of the solver trained on a new task with the buffered ones in a decision-seeking way. To encourage more focus on crucial experiences, LLR-BC assigns greater consolidated weights to decisions with lower confidence. Extensive experiments on capacitated vehicle routing problems and traveling salesman problems demonstrate LLR-BC's effectiveness in training high-performance neural solvers in a lifelong learning setting, addressing the catastrophic forgetting issue, maintaining their plasticity, and improving zero-shot generalization ability.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.893555"
    },
    {
        "index": "#42",
        "title": "Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts",
        "link": "/arxiv/2509.21743",
        "arxiv_id": "2509.21743",
        "authors": "Ammar Ahmed, Azal Ahmad Khan, Ayaan Ahmad, Sheng Di, Zirui Liu, Ali Anwar",
        "summary": "Large reasoning models improve accuracy by producing long reasoning traces, but this inflates latency and cost, motivating inference-time efficiency. We propose Retrieval-of-Thought (RoT), which reuses prior reasoning as composable ``thought\" steps to guide new problems. RoT organizes steps into a thought graph with sequential and semantic edges to enable fast retrieval and flexible recombination. At inference, RoT retrieves query-relevant nodes and applies reward-guided traversal to assemble a problem-specific template that guides generation. This dynamic template reuse reduces redundant exploration and, therefore, reduces output tokens while preserving accuracy. We evaluate RoT on reasoning benchmarks with multiple models, measuring accuracy, token usage, latency, and memory overhead. Findings show small prompt growth but substantial efficiency gains, with RoT reducing output tokens by up to 40%, inference latency by 82%, and cost by 59% while maintaining accuracy. RoT establishes a scalable paradigm for efficient LRM reasoning via dynamic template construction through retrieval.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.894059"
    },
    {
        "index": "#43",
        "title": "Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization",
        "link": "/arxiv/2509.21718",
        "arxiv_id": "2509.21718",
        "authors": "Shehzeen Hussain, Paarth Neekhara, Xuesong Yang, Edresson Casanova, Subhankar Ghosh, Roy Fejgin, Ryan Langman, Mikyas Desta, Leili Tavabi, Jason Li",
        "summary": "Developing high-quality text-to-speech (TTS) systems for low-resource languages is challenging due to the scarcity of paired text and speech data. In contrast, automatic speech recognition (ASR) models for such languages are often more accessible, owing to large-scale multilingual pre-training efforts. We propose a framework based on Group Relative Policy Optimization (GRPO) to adapt an autoregressive, multilingual TTS model to new languages. Our method first establishes a language-agnostic foundation for TTS synthesis by training a multilingual baseline with International Phonetic Alphabet (IPA) tokens. Next, we fine-tune this model on limited paired data of the new languages to capture the target language's prosodic features. Finally, we apply GRPO to optimize the model using only unpaired text and speaker prompts, guided by a multi-objective reward from pretrained ASR, speaker verification, and audio quality estimation models. Experiments demonstrate that this pipeline produces intelligible and speaker-consistent speech in low-resource languages, substantially outperforming fine-tuning alone. Furthermore, our GRPO-based framework also improves TTS performance in high-resource languages, surpassing offline alignment methods such as Direct Preference Optimization (DPO) yielding superior intelligibility, speaker similarity, and audio quality.",
        "subjects": "Artificial Intelligence, Machine Learning, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.894642"
    },
    {
        "index": "#44",
        "title": "Can AI Perceive Physical Danger and Intervene?",
        "link": "/arxiv/2509.21651",
        "arxiv_id": "2509.21651",
        "authors": "Abhishek Jindal, Dmitry Kalashnikov, Oscar Chang, Divya Garikapati, Anirudha Majumdar, Pierre Sermanet, Vikas Sindhwani",
        "summary": "When AI interacts with the physical world -- as a robot or an assistive agent -- new safety challenges emerge beyond those of purely ``digital AI\". In such interactions, the potential for physical harm is direct and immediate. How well do state-of-the-art foundation models understand common-sense facts about physical safety, e.g. that a box may be too heavy to lift, or that a hot cup of coffee should not be handed to a child? In this paper, our contributions are three-fold: first, we develop a highly scalable approach to continuous physical safety benchmarking of Embodied AI systems, grounded in real-world injury narratives and operational safety constraints. To probe multi-modal safety understanding, we turn these narratives and constraints into photorealistic images and videos capturing transitions from safe to unsafe states, using advanced generative models. Secondly, we comprehensively analyze the ability of major foundation models to perceive risks, reason about safety, and trigger interventions; this yields multi-faceted insights into their deployment readiness for safety-critical agentic applications. Finally, we develop a post-training paradigm to teach models to explicitly reason about embodiment-specific safety constraints provided through system instructions. The resulting models generate thinking traces that make safety reasoning interpretable and transparent, achieving state of the art performance in constraint satisfaction evaluations. The benchmark will be released at https://asimov-benchmark.github.io/v2",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.900253"
    },
    {
        "index": "#45",
        "title": "Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries",
        "link": "/arxiv/2509.21633",
        "arxiv_id": "2509.21633",
        "authors": "Georgios Chochlakis, Jackson Trager, Vedant Jhaveri, Nikhil Ravichandran, Alexandros Potamianos, Shrikanth Narayanan",
        "summary": "We propose Semantic F1 Scores, novel evaluation metrics for subjective or fuzzy multi-label classification that quantify semantic relatedness between predicted and gold labels. Unlike the conventional F1 metrics that treat semantically related predictions as complete failures, Semantic F1 incorporates a label similarity matrix to compute soft precision-like and recall-like scores, from which the Semantic F1 scores are derived. Unlike existing similarity-based metrics, our novel two-step precision-recall formulation enables the comparison of label sets of arbitrary sizes without discarding labels or forcing matches between dissimilar labels. By granting partial credit for semantically related but nonidentical labels, Semantic F1 better reflects the realities of domains marked by human disagreement or fuzzy category boundaries. In this way, it provides fairer evaluations: it recognizes that categories overlap, that annotators disagree, and that downstream decisions based on similar predictions lead to similar outcomes. Through theoretical justification and extensive empirical validation on synthetic and real data, we show that Semantic F1 demonstrates greater interpretability and ecological validity. Because it requires only a domain-appropriate similarity matrix, which is robust to misspecification, and not a rigid ontology, it is applicable across tasks and modalities.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.900763"
    },
    {
        "index": "#46",
        "title": "Automated and Interpretable Survival Analysis from Multimodal Data",
        "link": "/arxiv/2509.21600",
        "arxiv_id": "2509.21600",
        "authors": "Mafalda Malafaia, Peter A. N. Bosman, Coen Rasch, Tanja Alderliesten",
        "summary": "Accurate and interpretable survival analysis remains a core challenge in oncology. With growing multimodal data and the clinical need for transparent models to support validation and trust, this challenge increases in complexity. We propose an interpretable multimodal AI framework to automate survival analysis by integrating clinical variables and computed tomography imaging. Our MultiFIX-based framework uses deep learning to infer survival-relevant features that are further explained: imaging features are interpreted via Grad-CAM, while clinical variables are modeled as symbolic expressions through genetic programming. Risk estimation employs a transparent Cox regression, enabling stratification into groups with distinct survival outcomes. Using the open-source RADCURE dataset for head and neck cancer, MultiFIX achieves a C-index of 0.838 (prediction) and 0.826 (stratification), outperforming the clinical and academic baseline approaches and aligning with known prognostic markers. These results highlight the promise of interpretable multimodal AI for precision oncology with MultiFIX.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.901266"
    },
    {
        "index": "#47",
        "title": "GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models",
        "link": "/arxiv/2509.21593",
        "arxiv_id": "2509.21593",
        "authors": "Peng Luo, Xiayin Lou, Yu Zheng, Zhuo Zheng, Stefano Ermon",
        "summary": "Geospatial modeling provides critical solutions for pressing global challenges such as sustainability and climate change. Existing large language model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at evolving generic code but lack the domain knowledge and multi-step reasoning required for complex geospatial problems. We introduce GeoEvolve, a multi-agent LLM framework that couples evolutionary search with geospatial domain knowledge to automatically design and refine geospatial algorithms. GeoEvolve operates in two nested loops: an inner loop leverages a code evolver to generate and mutate candidate solutions, while an outer agentic controller evaluates global elites and queries a GeoKnowRAG module -- a structured geospatial knowledge base that injects theoretical priors from geography. This knowledge-guided evolution steers the search toward theoretically meaningful and computationally efficient algorithms. We evaluate GeoEvolve on two fundamental and classical tasks: spatial interpolation (kriging) and spatial uncertainty quantification (geospatial conformal prediction). Across these benchmarks, GeoEvolve automatically improves and discovers new algorithms, incorporating geospatial theory on top of classical models. It reduces spatial interpolation error (RMSE) by 13-21% and enhances uncertainty estimation performance by 17\\%. Ablation studies confirm that domain-guided retrieval is essential for stable, high-quality evolution. These results demonstrate that GeoEvolve provides a scalable path toward automated, knowledge-driven geospatial modeling, opening new opportunities for trustworthy and efficient AI-for-Science discovery.",
        "subjects": "Artificial Intelligence, Physics and Society",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.901761"
    },
    {
        "index": "#48",
        "title": "EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks",
        "link": "/arxiv/2509.21567",
        "arxiv_id": "2509.21567",
        "authors": "Mohammad Parsa Afshar, Aryan Azimi",
        "summary": "Prediction of consumer behavior is one of the important purposes in marketing, cognitive neuroscience, and human-computer interaction. The electroencephalography (EEG) data can help analyze the decision process by providing detailed information about the brain's neural activity. In this research, a comparative approach is utilized for predicting consumer behavior by EEG data. In the first step, the features of the EEG data from the NeuMa dataset were extracted and cleaned. For the Graph Neural Network (GNN) models, the brain connectivity features were created. Different machine learning models, such as classical models and Graph Neural Networks, are used and compared. The GNN models with different architectures are implemented to have a comprehensive comparison; furthermore, a wide range of classical models, such as ensemble models, are applied, which can be very helpful to show the difference and performance of each model on the dataset. Although the results did not show a significant difference overall, the GNN models generally performed better in some basic criteria where classical models were not satisfactory. This study not only shows that combining EEG signal analysis and machine learning models can provide an approach to deeper understanding of consumer behavior, but also provides a comprehensive comparison between the machine learning models that have been widely used in previous studies in the EEG-based neuromarketing such as Support Vector Machine (SVM), and the models which are not used or rarely used in the field, like Graph Neural Networks.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.902223"
    },
    {
        "index": "#50",
        "title": "Correct Reasoning Paths Visit Shared Decision Pivots",
        "link": "/arxiv/2509.21549",
        "arxiv_id": "2509.21549",
        "authors": "Dongkyu Cho, Amy B. Z. Zhang, Bilel Fehri, Sheng Wang, Rumi Chunara, Rui Song, Hengrui Cai",
        "summary": "Chain-of-thought (CoT) reasoning exposes the intermediate thinking process of large language models (LLMs), yet verifying those traces at scale remains unsolved. In response, we introduce the idea of decision pivots-minimal, verifiable checkpoints that any correct reasoning path must visit. We hypothesize that correct reasoning, though stylistically diverse, converge on the same pivot set, while incorrect ones violate at least one pivot. Leveraging this property, we propose a self-training pipeline that (i) samples diverse reasoning paths and mines shared decision pivots, (ii) compresses each trace into pivot-focused short-path reasoning using an auxiliary verifier, and (iii) post-trains the model using its self-generated outputs. The proposed method aligns reasoning without ground truth reasoning data or external metrics. Experiments on standard benchmarks such as LogiQA, MedQA, and MATH500 show the effectiveness of our method.",
        "subjects": "Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.903331"
    },
    {
        "index": "#54",
        "title": "Toward a Physics of Deep Learning and Brains",
        "link": "/arxiv/2509.22649",
        "arxiv_id": "2509.22649",
        "authors": "Arsham Ghavasieh, Meritxell Vila-Minana, Akanksha Khurd, John Beggs, Gerardo Ortiz, Santo Fortunato",
        "summary": "Deep neural networks and brains both learn and share superficial similarities: processing nodes are likened to neurons and adjustable weights are likened to modifiable synapses. But can a unified theoretical framework be found to underlie them both? Here we show that the equations used to describe neuronal avalanches in living brains can also be applied to cascades of activity in deep neural networks. These equations are derived from non-equilibrium statistical physics and show that deep neural networks learn best when poised between absorbing and active phases. Because these networks are strongly driven by inputs, however, they do not operate at a true critical point but within a quasi-critical regime -- one that still approximately satisfies crackling noise scaling relations. By training networks with different initializations, we show that maximal susceptibility is a more reliable predictor of learning than proximity to the critical point itself. This provides a blueprint for engineering improved network performance. Finally, using finite-size scaling we identify distinct universality classes, including Barkhausen noise and directed percolation. This theoretical framework demonstrates that universal features are shared by both biological and artificial neural networks.",
        "subjects": "Disordered Systems and Neural Networks, Statistical Mechanics, Artificial Intelligence, Adaptation and Self-Organizing Systems, Biological Physics",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.910753"
    },
    {
        "index": "#64",
        "title": "Learning Admissible Heuristics for A*: Theory and Practice",
        "link": "/arxiv/2509.22626",
        "arxiv_id": "2509.22626",
        "authors": "Ehsan Futuhi, Nathan R. Sturtevant",
        "summary": "Heuristic functions are central to the performance of search algorithms such as A-star, where admissibility - the property of never overestimating the true shortest-path cost - guarantees solution optimality. Recent deep learning approaches often disregard admissibility and provide limited guarantees on generalization beyond the training data. This paper addresses both of these limitations. First, we pose heuristic learning as a constrained optimization problem and introduce Cross-Entropy Admissibility (CEA), a loss function that enforces admissibility during training. On the Rubik's Cube domain, this method yields near-admissible heuristics with significantly stronger guidance than compressed pattern database (PDB) heuristics. Theoretically, we study the sample complexity of learning heuristics. By leveraging PDB abstractions and the structural properties of graphs such as the Rubik's Cube, we tighten the bound on the number of training samples needed for A-star to generalize. Replacing a general hypothesis class with a ReLU neural network gives bounds that depend primarily on the network's width and depth, rather than on graph size. Using the same network, we also provide the first generalization guarantees for goal-dependent heuristics.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.921376"
    },
    {
        "index": "#65",
        "title": "A Theoretical Analysis of Discrete Flow Matching Generative Models",
        "link": "/arxiv/2509.22623",
        "arxiv_id": "2509.22623",
        "authors": "Maojiang Su, Mingcheng Lu, Jerry Yao-Chieh Hu, Shang Wu, Zhao Song, Alex Reneau, Han Liu",
        "summary": "We provide a theoretical analysis for end-to-end training Discrete Flow Matching (DFM) generative models. DFM is a promising discrete generative modeling framework that learns the underlying generative dynamics by training a neural network to approximate the transformative velocity field. Our analysis establishes a clear chain of guarantees by decomposing the final distribution estimation error. We first prove that the total variation distance between the generated and target distributions is controlled by the risk of the learned velocity field. We then bound this risk by analyzing its two primary sources: (i) Approximation Error, where we quantify the capacity of the Transformer architecture to represent the true velocity, and (ii) Estimation Error, where we derive statistical convergence rates that bound the error from training on a finite dataset. By composing these results, we provide the first formal proof that the distribution generated by a trained DFM model provably converges to the true data distribution as the training set size increases.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.921921"
    },
    {
        "index": "#68",
        "title": "Quantile Advantage Estimation for Entropy-Safe Reasoning",
        "link": "/arxiv/2509.22611",
        "arxiv_id": "2509.22611",
        "authors": "Junkang Wu, Kexin Huang, Jiancan Wu, An Zhang, Xiang Wang, Xiangnan He",
        "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) strengthens LLM reasoning, but training often oscillates between {entropy collapse} and {entropy explosion}. We trace both hazards to the mean baseline used in value-free RL (e.g., GRPO and DAPO), which improperly penalizes negative-advantage samples under reward outliers. We propose {Quantile Advantage Estimation} (QAE), replacing the mean with a group-wise K-quantile baseline. QAE induces a response-level, two-regime gate: on hard queries (p <= 1 - K) it reinforces rare successes, while on easy queries (p > 1 - K) it targets remaining failures. Under first-order softmax updates, we prove {two-sided entropy safety}, giving lower and upper bounds on one-step entropy change that curb explosion and prevent collapse. Empirically, this minimal modification stabilizes entropy, sparsifies credit assignment (with tuned K, roughly 80% of responses receive zero advantage), and yields sustained pass@1 gains on Qwen3-8B/14B-Base across AIME 2024/2025 and AMC 2023. These results identify {baseline design} -- rather than token-level heuristics -- as the primary mechanism for scaling RLVR.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.923450"
    },
    {
        "index": "#70",
        "title": "From Parameters to Behavior: Unsupervised Compression of the Policy Space",
        "link": "/arxiv/2509.22566",
        "arxiv_id": "2509.22566",
        "authors": "Davide Tenedini, Riccardo Zamboni, Mirco Mutti, Marcello Restelli",
        "summary": "Despite its recent successes, Deep Reinforcement Learning (DRL) is notoriously sample-inefficient. We argue that this inefficiency stems from the standard practice of optimizing policies directly in the high-dimensional and highly redundant parameter space $\\Theta$. This challenge is greatly compounded in multi-task settings. In this work, we develop a novel, unsupervised approach that compresses the policy parameter space $\\Theta$ into a low-dimensional latent space $\\mathcal{Z}$. We train a generative model $g:\\mathcal{Z}\\to\\Theta$ by optimizing a behavioral reconstruction loss, which ensures that the latent space is organized by functional similarity rather than proximity in parameterization. We conjecture that the inherent dimensionality of this manifold is a function of the environment's complexity, rather than the size of the policy network. We validate our approach in continuous control domains, showing that the parameterization of standard policy networks can be compressed up to five orders of magnitude while retaining most of its expressivity. As a byproduct, we show that the learned manifold enables task-specific adaptation via Policy Gradient operating in the latent space $\\mathcal{Z}$.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.924640"
    },
    {
        "index": "#73",
        "title": "ConQuER: Modular Architectures for Control and Bias Mitigation in IQP Quantum Generative Models",
        "link": "/arxiv/2509.22551",
        "arxiv_id": "2509.22551",
        "authors": "Xiaocheng Zou, Shijin Duan, Charles Fleming, Gaowen Liu, Ramana Rao Kompella, Shaolei Ren, Xiaolin Xu",
        "summary": "Quantum generative models based on instantaneous quantum polynomial (IQP) circuits show great promise in learning complex distributions while maintaining classical trainability. However, current implementations suffer from two key limitations: lack of controllability over generated outputs and severe generation bias towards certain expected patterns. We present a Controllable Quantum Generative Framework, ConQuER, which addresses both challenges through a modular circuit architecture. ConQuER embeds a lightweight controller circuit that can be directly combined with pre-trained IQP circuits to precisely control the output distribution without full retraining. Leveraging the advantages of IQP, our scheme enables precise control over properties such as the Hamming Weight distribution with minimal parameter and gate overhead. In addition, inspired by the controller design, we extend this modular approach through data-driven optimization to embed implicit control paths in the underlying IQP architecture, significantly reducing generation bias on structured datasets. ConQuER retains efficient classical training properties and high scalability. We experimentally validate ConQuER on multiple quantum state datasets, demonstrating its superior control accuracy and balanced generation performance, only with very low overhead cost over original IQP circuits. Our framework bridges the gap between the advantages of quantum computing and the practical needs of controllable generation modeling.",
        "subjects": "Quantum Physics, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.931436"
    },
    {
        "index": "#77",
        "title": "Ontological foundations for contrastive explanatory narration of robot plans",
        "link": "/arxiv/2509.22493",
        "arxiv_id": "2509.22493",
        "authors": "Alberto Olivares-Alarcos, Sergi Foix, Júlia Borràs, Gerard Canal, Guillem Alenyà",
        "summary": "Mutual understanding of artificial agents' decisions is key to ensuring a trustworthy and successful human-robot interaction. Hence, robots are expected to make reasonable decisions and communicate them to humans when needed. In this article, the focus is on an approach to modeling and reasoning about the comparison of two competing plans, so that robots can later explain the divergent result. First, a novel ontological model is proposed to formalize and reason about the differences between competing plans, enabling the classification of the most appropriate one (e.g., the shortest, the safest, the closest to human preferences, etc.). This work also investigates the limitations of a baseline algorithm for ontology-based explanatory narration. To address these limitations, a novel algorithm is presented, leveraging divergent knowledge between plans and facilitating the construction of contrastive narratives. Through empirical evaluation, it is observed that the explanations excel beyond the baseline method.",
        "subjects": "Robotics, Artificial Intelligence, Information Retrieval, Logic in Computer Science",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.933690"
    },
    {
        "index": "#78",
        "title": "A Machine Learning Pipeline for Multiple Sclerosis Biomarker Discovery: Comparing explainable AI and Traditional Statistical Approaches",
        "link": "/arxiv/2509.22484",
        "arxiv_id": "2509.22484",
        "authors": "Samuele Punzo, Silvia Giulia Galfrè, Francesco Massafra, Alessandro Maglione, Corrado Priami, Alina Sîrbu",
        "summary": "We present a machine learning pipeline for biomarker discovery in Multiple Sclerosis (MS), integrating eight publicly available microarray datasets from Peripheral Blood Mononuclear Cells (PBMC). After robust preprocessing we trained an XGBoost classifier optimized via Bayesian search. SHapley Additive exPlanations (SHAP) were used to identify key features for model prediction, indicating thus possible biomarkers. These were compared with genes identified through classical Differential Expression Analysis (DEA). Our comparison revealed both overlapping and unique biomarkers between SHAP and DEA, suggesting complementary strengths. Enrichment analysis confirmed the biological relevance of SHAP-selected genes, linking them to pathways such as sphingolipid signaling, Th1/Th2/Th17 cell differentiation, and Epstein-Barr virus infection all known to be associated with MS. This study highlights the value of combining explainable AI (xAI) with traditional statistical methods to gain deeper insights into disease mechanism.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.934220"
    },
    {
        "index": "#79",
        "title": "OFMU: Optimization-Driven Framework for Machine Unlearning",
        "link": "/arxiv/2509.22483",
        "arxiv_id": "2509.22483",
        "authors": "Sadia Asif, Mohammad Mohammadi Amiri",
        "summary": "Large language models deployed in sensitive applications increasingly require the ability to unlearn specific knowledge, such as user requests, copyrighted materials, or outdated information, without retraining from scratch to ensure regulatory compliance, user privacy, and safety. This task, known as machine unlearning, aims to remove the influence of targeted data (forgetting) while maintaining performance on the remaining data (retention). A common approach is to formulate this as a multi-objective problem and reduce it to a single-objective problem via scalarization, where forgetting and retention losses are combined using a weighted sum. However, this often results in unstable training dynamics and degraded model utility due to conflicting gradient directions. To address these challenges, we propose OFMU, a penalty-based bi-level optimization framework that explicitly prioritizes forgetting while preserving retention through a hierarchical structure. Our method enforces forgetting via an inner maximization step that incorporates a similarity-aware penalty to decorrelate the gradients of the forget and retention objectives, and restores utility through an outer minimization step. To ensure scalability, we develop a two-loop algorithm with provable convergence guarantees under both convex and non-convex regimes. We further provide a rigorous theoretical analysis of convergence rates and show that our approach achieves better trade-offs between forgetting efficacy and model utility compared to prior methods. Extensive experiments across vision and language benchmarks demonstrate that OFMU consistently outperforms existing unlearning methods in both forgetting efficacy and retained utility.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.934687"
    },
    {
        "index": "#82",
        "title": "Learning the Neighborhood: Contrast-Free Multimodal Self-Supervised Molecular Graph Pretraining",
        "link": "/arxiv/2509.22468",
        "arxiv_id": "2509.22468",
        "authors": "Boshra Ariguib, Mathias Niepert, Andrei Manolache",
        "summary": "High-quality molecular representations are essential for property prediction and molecular design, yet large labeled datasets remain scarce. While self-supervised pretraining on molecular graphs has shown promise, many existing approaches either depend on hand-crafted augmentations or complex generative objectives, and often rely solely on 2D topology, leaving valuable 3D structural information underutilized. To address this gap, we introduce C-FREE (Contrast-Free Representation learning on Ego-nets), a simple framework that integrates 2D graphs with ensembles of 3D conformers. C-FREE learns molecular representations by predicting subgraph embeddings from their complementary neighborhoods in the latent space, using fixed-radius ego-nets as modeling units across different conformers. This design allows us to integrate both geometric and topological information within a hybrid Graph Neural Network (GNN)-Transformer backbone, without negatives, positional encodings, or expensive pre-processing. Pretraining on the GEOM dataset, which provides rich 3D conformational diversity, C-FREE achieves state-of-the-art results on MoleculeNet, surpassing contrastive, generative, and other multimodal self-supervised methods. Fine-tuning across datasets with diverse sizes and molecule types further demonstrates that pretraining transfers effectively to new chemical domains, highlighting the importance of 3D-informed molecular representations.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.941313"
    },
    {
        "index": "#84",
        "title": "Physics-informed GNN for medium-high voltage AC power flow with edge-aware attention and line search correction operator",
        "link": "/arxiv/2509.22458",
        "arxiv_id": "2509.22458",
        "authors": "Changhun Kim, Timon Conrad, Redwanul Karim, Julian Oelhaf, David Riebesel, Tomás Arias-Vergara, Andreas Maier, Johann Jäger, Siming Bayer",
        "summary": "Physics-informed graph neural networks (PIGNNs) have emerged as fast AC power-flow solvers that can replace classic Newton--Raphson (NR) solvers, especially when thousands of scenarios must be evaluated. However, current PIGNNs still need accuracy improvements at parity speed; in particular, the physics loss is inoperative at inference, which can deter operational adoption. We address this with PIGNN-Attn-LS, combining an edge-aware attention mechanism that explicitly encodes line physics via per-edge biases, capturing the grid's anisotropy, with a backtracking line-search-based globalized correction operator that restores an operative decrease criterion at inference. Training and testing use a realistic High-/Medium-Voltage scenario generator, with NR used only to construct reference states. On held-out HV cases consisting of 4--32-bus grids, PIGNN-Attn-LS achieves a test RMSE of 0.00033 p.u. in voltage and 0.08$^\\circ$ in angle, outperforming the PIGNN-MLP baseline by 99.5\\% and 87.1\\%, respectively. With streaming micro-batches, it delivers 2--5$\\times$ faster batched inference than NR on 4--1024-bus grids.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.942531"
    },
    {
        "index": "#86",
        "title": "Learning to Ball: Composing Policies for Long-Horizon Basketball Moves",
        "link": "/arxiv/2509.22442",
        "arxiv_id": "2509.22442",
        "authors": "Pei Xu, Zhen Wu, Ruocheng Wang, Vishnu Sarukkai, Kayvon Fatahalian, Ioannis Karamouzas, Victor Zordan, C. Karen Liu",
        "summary": "Learning a control policy for a multi-phase, long-horizon task, such as basketball maneuvers, remains challenging for reinforcement learning approaches due to the need for seamless policy composition and transitions between skills. A long-horizon task typically consists of distinct subtasks with well-defined goals, separated by transitional subtasks with unclear goals but critical to the success of the entire task. Existing methods like the mixture of experts and skill chaining struggle with tasks where individual policies do not share significant commonly explored states or lack well-defined initial and terminal states between different phases. In this paper, we introduce a novel policy integration framework to enable the composition of drastically different motor skills in multi-phase long-horizon tasks with ill-defined intermediate states. Based on that, we further introduce a high-level soft router to enable seamless and robust transitions between the subtasks. We evaluate our framework on a set of fundamental basketball skills and challenging transitions. Policies trained by our approach can effectively control the simulated character to interact with the ball and accomplish the long-horizon task specified by real-time user commands, without relying on ball trajectory references.",
        "subjects": "Graphics, Artificial Intelligence, Machine Learning, Robotics",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.943616"
    },
    {
        "index": "#88",
        "title": "Global Convergence in Neural ODEs: Impact of Activation Functions",
        "link": "/arxiv/2509.22436",
        "arxiv_id": "2509.22436",
        "authors": "Tianxiang Gao, Siyuan Sun, Hailiang Liu, Hongyang Gao",
        "summary": "Neural Ordinary Differential Equations (ODEs) have been successful in various applications due to their continuous nature and parameter-sharing efficiency. However, these unique characteristics also introduce challenges in training, particularly with respect to gradient computation accuracy and convergence analysis. In this paper, we address these challenges by investigating the impact of activation functions. We demonstrate that the properties of activation functions, specifically smoothness and nonlinearity, are critical to the training dynamics. Smooth activation functions guarantee globally unique solutions for both forward and backward ODEs, while sufficient nonlinearity is essential for maintaining the spectral properties of the Neural Tangent Kernel (NTK) during training. Together, these properties enable us to establish the global convergence of Neural ODEs under gradient descent in overparameterized regimes. Our theoretical findings are validated by numerical experiments, which not only support our analysis but also provide practical guidelines for scaling Neural ODEs, potentially leading to faster training and improved performance in real-world applications.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.944667"
    },
    {
        "index": "#89",
        "title": "An Ontology for Unified Modeling of Tasks, Actions, Environments, and Capabilities in Personal Service Robotics",
        "link": "/arxiv/2509.22434",
        "arxiv_id": "2509.22434",
        "authors": "Margherita Martorana, Francesca Urgese, Ilaria Tiddi, Stefan Schlobach",
        "summary": "Personal service robots are increasingly used in domestic settings to assist older adults and people requiring support. Effective operation involves not only physical interaction but also the ability to interpret dynamic environments, understand tasks, and choose appropriate actions based on context. This requires integrating both hardware components (e.g. sensors, actuators) and software systems capable of reasoning about tasks, environments, and robot capabilities. Frameworks such as the Robot Operating System (ROS) provide open-source tools that help connect low-level hardware with higher-level functionalities. However, real-world deployments remain tightly coupled to specific platforms. As a result, solutions are often isolated and hard-coded, limiting interoperability, reusability, and knowledge sharing. Ontologies and knowledge graphs offer a structured way to represent tasks, environments, and robot capabilities. Existing ontologies, such as the Socio-physical Model of Activities (SOMA) and the Descriptive Ontology for Linguistic and Cognitive Engineering (DOLCE), provide models for activities, spatial relationships, and reasoning structures. However, they often focus on specific domains and do not fully capture the connection between environment, action, robot capabilities, and system-level integration. In this work, we propose the Ontology for roBOts and acTions (OntoBOT), which extends existing ontologies to provide a unified representation of tasks, actions, environments, and capabilities. Our contributions are twofold: (1) we unify these aspects into a cohesive ontology to support formal reasoning about task execution, and (2) we demonstrate its generalizability by evaluating competency questions across four embodied agents - TIAGo, HSR, UR3, and Stretch - showing how OntoBOT enables context-aware reasoning, task-oriented execution, and knowledge sharing in service robotics.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.945158"
    },
    {
        "index": "#90",
        "title": "Partial Parameter Updates for Efficient Distributed Training",
        "link": "/arxiv/2509.22418",
        "arxiv_id": "2509.22418",
        "authors": "Anastasiia Filippova, Angelos Katharopoulos, David Grangier, Ronan Collobert",
        "summary": "We introduce a memory- and compute-efficient method for low-communication distributed training. Existing methods reduce communication by performing multiple local updates between infrequent global synchronizations. We demonstrate that their efficiency can be significantly improved by restricting backpropagation: instead of updating all the parameters, each node updates only a fixed subset while keeping the remainder frozen during local steps. This constraint substantially reduces peak memory usage and training FLOPs, while a full forward pass over all parameters eliminates the need for cross-node activation exchange. Experiments on a $1.3$B-parameter language model trained across $32$ nodes show that our method matches the perplexity of prior low-communication approaches under identical token and bandwidth budgets while reducing training FLOPs and peak memory.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.945650"
    },
    {
        "index": "#94",
        "title": "SpinGPT: A Large-Language-Model Approach to Playing Poker Correctly",
        "link": "/arxiv/2509.22387",
        "arxiv_id": "2509.22387",
        "authors": "Narada Maugin, Tristan Cazenave",
        "summary": "The Counterfactual Regret Minimization (CFR) algorithm and its variants have enabled the development of pokerbots capable of beating the best human players in heads-up (1v1) cash games and competing with them in six-player formats. However, CFR's computational complexity rises exponentially with the number of players. Furthermore, in games with three or more players, following Nash equilibrium no longer guarantees a non-losing outcome. These limitations, along with others, significantly restrict the applicability of CFR to the most popular formats: tournaments. Motivated by the recent success of Large Language Models (LLM) in chess and Diplomacy, we present SpinGPT, the first LLM tailored to Spin & Go, a popular three-player online poker format. SpinGPT is trained in two stages: (1) Supervised Fine-Tuning on 320k high-stakes expert decisions; (2) Reinforcement Learning on 270k solver-generated hands. Our results show that SpinGPT matches the solver's actions in 78% of decisions (tolerant accuracy). With a simple deep-stack heuristic, it achieves 13.4 +/- 12.9 BB/100 versus Slumbot in heads-up over 30,000 hands (95% CI). These results suggest that LLMs could be a new way to deal with multi-player imperfect-information games like poker.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Science and Game Theory",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.952948"
    },
    {
        "index": "#95",
        "title": "Zero-Effort Image-to-Music Generation: An Interpretable RAG-based VLM Approach",
        "link": "/arxiv/2509.22378",
        "arxiv_id": "2509.22378",
        "authors": "Zijian Zhao, Dian Jin, Zijing Zhou",
        "summary": "Recently, Image-to-Music (I2M) generation has garnered significant attention, with potential applications in fields such as gaming, advertising, and multi-modal art creation. However, due to the ambiguous and subjective nature of I2M tasks, most end-to-end methods lack interpretability, leaving users puzzled about the generation results. Even methods based on emotion mapping face controversy, as emotion represents only a singular aspect of art. Additionally, most learning-based methods require substantial computational resources and large datasets for training, hindering accessibility for common users. To address these challenges, we propose the first Vision Language Model (VLM)-based I2M framework that offers high interpretability and low computational cost. Specifically, we utilize ABC notation to bridge the text and music modalities, enabling the VLM to generate music using natural language. We then apply multi-modal Retrieval-Augmented Generation (RAG) and self-refinement techniques to allow the VLM to produce high-quality music without external training. Furthermore, we leverage the generated motivations in text and the attention maps from the VLM to provide explanations for the generated results in both text and image modalities. To validate our method, we conduct both human studies and machine evaluations, where our method outperforms others in terms of music quality and music-image consistency, indicating promising results. Our code is available at https://github.com/RS2002/Image2Music .",
        "subjects": "Sound, Artificial Intelligence, Multimedia, Audio and Speech Processing",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.953456"
    },
    {
        "index": "#98",
        "title": "Forecasting the Future with Yesterday's Climate: Temperature Bias in AI Weather and Climate Models",
        "link": "/arxiv/2509.22359",
        "arxiv_id": "2509.22359",
        "authors": "Jacob B. Landsberg, Elizabeth A. Barnes",
        "summary": "AI-based climate and weather models have rapidly gained popularity, providing faster forecasts with skill that can match or even surpass that of traditional dynamical models. Despite this success, these models face a key challenge: predicting future climates while being trained only with historical data. In this study, we investigate this issue by analyzing boreal winter land temperature biases in AI weather and climate models. We examine two weather models, FourCastNet V2 Small (FourCastNet) and Pangu Weather (Pangu), evaluating their predictions for 2020-2025 and Ai2 Climate Emulator version 2 (ACE2) for 1996-2010. These time periods lie outside of the respective models' training sets and are significantly more recent than the bulk of their training data, allowing us to assess how well the models generalize to new, i.e. more modern, conditions. We find that all three models produce cold-biased mean temperatures, resembling climates from 15-20 years earlier than the period they are predicting. In some regions, like the Eastern U.S., the predictions resemble climates from as much as 20-30 years earlier. Further analysis shows that FourCastNet's and Pangu's cold bias is strongest in the hottest predicted temperatures, indicating limited training exposure to modern extreme heat events. In contrast, ACE2's bias is more evenly distributed but largest in regions, seasons, and parts of the temperature distribution where climate change has been most pronounced. These findings underscore the challenge of training AI models exclusively on historical data and highlight the need to account for such biases when applying them to future climate prediction.",
        "subjects": "Atmospheric and Oceanic Physics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.955175"
    },
    {
        "index": "#99",
        "title": "Stochastic activations",
        "link": "/arxiv/2509.22358",
        "arxiv_id": "2509.22358",
        "authors": "Maria Lomeli, Matthijs Douze, Gergely Szilvasy, Loic Cabannes, Jade Copet, Sainbayar Sukhbaatar, Jason Weston, Gabriel Synnaeve, Pierre-Emmanuel Mazaré, Hervé Jégou",
        "summary": "We introduce stochastic activations. This novel strategy randomly selects between several non-linear functions in the feed-forward layer of a large language model. In particular, we choose between SILU or RELU depending on a Bernoulli draw. This strategy circumvents the optimization problem associated with RELU, namely, the constant shape for negative inputs that prevents the gradient flow. We leverage this strategy in two ways: (1) We use stochastic activations during pre-training and fine-tune the model with RELU, which is used at inference time to provide sparse latent vectors. This reduces the inference FLOPs and translates into a significant speedup in the CPU. Interestingly, this leads to much better results than training from scratch with the RELU activation function. (2) We evaluate stochastic activations for generation. This strategy performs reasonably well: it is only slightly inferior to the best deterministic non-linearity, namely SILU combined with temperature scaling. This offers an alternative to existing strategies by providing a controlled way to increase the diversity of the generated text.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.955754"
    },
    {
        "index": "#100",
        "title": "Context and Diversity Matter: The Emergence of In-Context Learning in World Models",
        "link": "/arxiv/2509.22353",
        "arxiv_id": "2509.22353",
        "authors": "Fan Wang, Zhiyuan Chen, Yuxuan Zhong, Sunjian Zheng, Pengtao Shao, Bo Yu, Shaoshan Liu, Jianan Wang, Ning Ding, Yang Cao, Yu Kang",
        "summary": "The capability of predicting environmental dynamics underpins both biological neural systems and general embodied AI in adapting to their surroundings. Yet prevailing approaches rest on static world models that falter when confronted with novel or rare configurations. We investigate in-context environment learning (ICEL), shifting attention from zero-shot performance to the growth and asymptotic limits of the world model. Our contributions are three-fold: (1) we formalize in-context learning of a world model and identify two core mechanisms: environment recognition and environment learning; (2) we derive error upper-bounds for both mechanisms that expose how the mechanisms emerge; and (3) we empirically confirm that distinct ICL mechanisms exist in the world model, and we further investigate how data distribution and model architecture affect ICL in a manner consistent with theory. These findings demonstrate the potential of self-adapting world models and highlight the key factors behind the emergence of ICEL, most notably the necessity of long context and diverse environments.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.956346"
    },
    {
        "index": "#101",
        "title": "SurvDiff: A Diffusion Model for Generating Synthetic Data in Survival Analysis",
        "link": "/arxiv/2509.22352",
        "arxiv_id": "2509.22352",
        "authors": "Marie Brockschmidt, Maresa Schröder, Stefan Feuerriegel",
        "summary": "Survival analysis is a cornerstone of clinical research by modeling time-to-event outcomes such as metastasis, disease relapse, or patient death. Unlike standard tabular data, survival data often come with incomplete event information due to dropout, or loss to follow-up. This poses unique challenges for synthetic data generation, where it is crucial for clinical research to faithfully reproduce both the event-time distribution and the censoring mechanism. In this paper, we propose SurvDiff, an end-to-end diffusion model specifically designed for generating synthetic data in survival analysis. SurvDiff is tailored to capture the data-generating mechanism by jointly generating mixed-type covariates, event times, and right-censoring, guided by a survival-tailored loss function. The loss encodes the time-to-event structure and directly optimizes for downstream survival tasks, which ensures that SurvDiff (i) reproduces realistic event-time distributions and (ii) preserves the censoring mechanism. Across multiple datasets, we show that \\survdiff consistently outperforms state-of-the-art generative baselines in both distributional fidelity and downstream evaluation metrics across multiple medical datasets. To the best of our knowledge, SurvDiff is the first diffusion model explicitly designed for generating synthetic survival data.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.956811"
    },
    {
        "index": "#104",
        "title": "Spectral Collapse Drives Loss of Plasticity in Deep Continual Learning",
        "link": "/arxiv/2509.22335",
        "arxiv_id": "2509.22335",
        "authors": "Naicheng He, Kaicheng Guo, Arjun Prakash, Saket Tiwari, Ruo Yu Tao, Tyrone Serapio, Amy Greenwald, George Konidaris",
        "summary": "We investigate why deep neural networks suffer from \\emph{loss of plasticity} in deep continual learning, failing to learn new tasks without reinitializing parameters. We show that this failure is preceded by Hessian spectral collapse at new-task initialization, where meaningful curvature directions vanish and gradient descent becomes ineffective. To characterize the necessary condition for successful training, we introduce the notion of $\\tau$-trainability and show that current plasticity preserving algorithms can be unified under this framework. Targeting spectral collapse directly, we then discuss the Kronecker factored approximation of the Hessian, which motivates two regularization enhancements: maintaining high effective feature rank and applying $L2$ penalties. Experiments on continual supervised and reinforcement learning tasks confirm that combining these two regularizers effectively preserves plasticity.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.958324"
    },
    {
        "index": "#106",
        "title": "Progressive Weight Loading: Accelerating Initial Inference and Gradually Boosting Performance on Resource-Constrained Environments",
        "link": "/arxiv/2509.22319",
        "arxiv_id": "2509.22319",
        "authors": "Hyunwoo Kim, Junha Lee, Mincheol Choi, Jeonghwan Lee, Jaeshin Cho",
        "summary": "Deep learning models have become increasingly large and complex, resulting in higher memory consumption and computational demands. Consequently, model loading times and initial inference latency have increased, posing significant challenges in mobile and latency-sensitive environments where frequent model loading and unloading are required, which directly impacts user experience. While Knowledge Distillation (KD) offers a solution by compressing large teacher models into smaller student ones, it often comes at the cost of reduced performance. To address this trade-off, we propose Progressive Weight Loading (PWL), a novel technique that enables fast initial inference by first deploying a lightweight student model, then incrementally replacing its layers with those of a pre-trained teacher model. To support seamless layer substitution, we introduce a training method that not only aligns intermediate feature representations between student and teacher layers, but also improves the overall output performance of the student model. Our experiments on VGG, ResNet, and ViT architectures demonstrate that models trained with PWL maintain competitive distillation performance and gradually improve accuracy as teacher layers are loaded-matching the final accuracy of the full teacher model without compromising initial inference speed. This makes PWL particularly suited for dynamic, resource-constrained deployments where both responsiveness and performance are critical.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.964397"
    },
    {
        "index": "#107",
        "title": "Adaptive Policy Backbone via Shared Network",
        "link": "/arxiv/2509.22310",
        "arxiv_id": "2509.22310",
        "authors": "Bumgeun Park, Donghwan Lee",
        "summary": "Reinforcement learning (RL) has achieved impressive results across domains, yet learning an optimal policy typically requires extensive interaction data, limiting practical deployment. A common remedy is to leverage priors, such as pre-collected datasets or reference policies, but their utility degrades under task mismatch between training and deployment. While prior work has sought to address this mismatch, it has largely been restricted to in-distribution settings. To address this challenge, we propose Adaptive Policy Backbone (APB), a meta-transfer RL method that inserts lightweight linear layers before and after a shared backbone, thereby enabling parameter-efficient fine-tuning (PEFT) while preserving prior knowledge during adaptation. Our results show that APB improves sample efficiency over standard RL and adapts to out-of-distribution (OOD) tasks where existing meta-RL baselines typically fail.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.964682"
    },
    {
        "index": "#109",
        "title": "HEAPr: Hessian-based Efficient Atomic Expert Pruning in Output Space",
        "link": "/arxiv/2509.22299",
        "arxiv_id": "2509.22299",
        "authors": "Ke Li, Zheng Yang, Zhongbin Zhou, Feng Xue, Zhonglin Jiang, Wenxiao Wang",
        "summary": "Mixture-of-Experts (MoE) architectures in large language models (LLMs) deliver exceptional performance and reduced inference costs compared to dense LLMs. However, their large parameter counts result in prohibitive memory requirements, limiting practical deployment. While existing pruning methods primarily focus on expert-level pruning, this coarse granularity often leads to substantial accuracy degradation. In this work, we introduce HEAPr, a novel pruning algorithm that decomposes experts into smaller, indivisible atomic experts, enabling more precise and flexible atomic expert pruning. To measure the importance of each atomic expert, we leverage second-order information based on principles similar to Optimal Brain Surgeon (OBS) theory. To address the computational and storage challenges posed by second-order information, HEAPr exploits the inherent properties of atomic experts to transform the second-order information from expert parameters into that of atomic expert parameters, and further simplifies it to the second-order information of atomic expert outputs. This approach reduces the space complexity from $O(d^4)$, where d is the model's dimensionality, to $O(d^2)$. HEAPr requires only two forward passes and one backward pass on a small calibration set to compute the importance of atomic experts. Extensive experiments on MoE models, including DeepSeek MoE and Qwen MoE family, demonstrate that HEAPr outperforms existing expert-level pruning methods across a wide range of compression ratios and benchmarks. Specifically, HEAPr achieves nearly lossless compression at compression ratios of 20% ~ 25% in most models, while also reducing FLOPs nearly by 20%. The code can be found at \\href{https://github.com/LLIKKE/HEAPr}{https://github.com/LLIKKE/HEAPr}.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.965328"
    },
    {
        "index": "#112",
        "title": "Leveraging Large Language Models for Robot-Assisted Learning of Morphological Structures in Preschool Children with Language Vulnerabilities",
        "link": "/arxiv/2509.22287",
        "arxiv_id": "2509.22287",
        "authors": "Stina Sundstedt, Mattias Wingren, Susanne Hägglund, Daniel Ventus",
        "summary": "Preschool children with language vulnerabilities -- such as developmental language disorders or immigration related language challenges -- often require support to strengthen their expressive language skills. Based on the principle of implicit learning, speech-language therapists (SLTs) typically embed target morphological structures (e.g., third person -s) into everyday interactions or game-based learning activities. Educators are recommended by SLTs to do the same. This approach demands precise linguistic knowledge and real-time production of various morphological forms (e.g., \"Daddy wears these when he drives to work\"). The task becomes even more demanding when educators or parent also must keep children engaged and manage turn-taking in a game-based activity. In the TalBot project our multiprofessional team have developed an application in which the Furhat conversational robot plays the word retrieval game \"Alias\" with children to improve language skills. Our application currently employs a large language model (LLM) to manage gameplay, dialogue, affective responses, and turn-taking. Our next step is to further leverage the capacity of LLMs so the robot can generate and deliver specific morphological targets during the game. We hypothesize that a robot could outperform humans at this task. Novel aspects of this approach are that the robot could ultimately serve as a model and tutor for both children and professionals and that using LLM capabilities in this context would support basic communication needs for children with language vulnerabilities. Our long-term goal is to create a robust LLM-based Robot-Assisted Language Learning intervention capable of teaching a variety of morphological structures across different languages.",
        "subjects": "Robotics, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.966248"
    },
    {
        "index": "#113",
        "title": "A Global Analysis of Cyber Threats to the Energy Sector: \"Currents of Conflict\" from a Geopolitical Perspective",
        "link": "/arxiv/2509.22280",
        "arxiv_id": "2509.22280",
        "authors": "Gustavo Sánchez, Ghada Elbez, Veit Hagenmeyer",
        "summary": "The escalating frequency and sophistication of cyber threats increased the need for their comprehensive understanding. This paper explores the intersection of geopolitical dynamics, cyber threat intelligence analysis, and advanced detection technologies, with a focus on the energy domain. We leverage generative artificial intelligence to extract and structure information from raw cyber threat descriptions, enabling enhanced analysis. By conducting a geopolitical comparison of threat actor origins and target regions across multiple databases, we provide insights into trends within the general threat landscape. Additionally, we evaluate the effectiveness of cybersecurity tools -- with particular emphasis on learning-based techniques -- in detecting indicators of compromise for energy-targeted attacks. This analysis yields new insights, providing actionable information to researchers, policy makers, and cybersecurity professionals.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.966537"
    },
    {
        "index": "#114",
        "title": "Wavelet-Induced Rotary Encodings: RoPE Meets Graphs",
        "link": "/arxiv/2509.22259",
        "arxiv_id": "2509.22259",
        "authors": "Isaac Reid, Arijit Sehanobish, Cedrik Höfs, Bruno Mlodozeniec, Leonhard Vulpius, Federico Barbero, Adrian Weller, Krzysztof Choromanski, Richard E. Turner, Petar Veličković",
        "summary": "We introduce WIRE: Wavelet-Induced Rotary Encodings. WIRE extends Rotary Position Encodings (RoPE), a popular algorithm in LLMs and ViTs, to graph-structured data. We demonstrate that WIRE is more general than RoPE, recovering the latter in the special case of grid graphs. WIRE also enjoys a host of desirable theoretical properties, including equivariance under node ordering permutation, compatibility with linear attention, and (under select assumptions) asymptotic dependence on graph resistive distance. We test WIRE on a range of synthetic and real-world tasks, including identifying monochromatic subgraphs, semantic segmentation of point clouds, and more standard graph benchmarks. We find it to be effective in settings where the underlying graph structure is important.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.966871"
    },
    {
        "index": "#116",
        "title": "Secure and Efficient Access Control for Computer-Use Agents via Context Space",
        "link": "/arxiv/2509.22256",
        "arxiv_id": "2509.22256",
        "authors": "Haochen Gong, Chenxiao Li, Rui Chang, Wenbo Shen",
        "summary": "Large language model (LLM)-based computer-use agents represent a convergence of AI and OS capabilities, enabling natural language to control system- and application-level functions. However, due to LLMs' inherent uncertainty issues, granting agents control over computers poses significant security risks. When agent actions deviate from user intentions, they can cause irreversible consequences. Existing mitigation approaches, such as user confirmation and LLM-based dynamic action validation, still suffer from limitations in usability, security, and performance. To address these challenges, we propose CSAgent, a system-level, static policy-based access control framework for computer-use agents. To bridge the gap between static policy and dynamic context and user intent, CSAgent introduces intent- and context-aware policies, and provides an automated toolchain to assist developers in constructing and refining them. CSAgent enforces these policies through an optimized OS service, ensuring that agent actions can only be executed under specific user intents and contexts. CSAgent supports protecting agents that control computers through diverse interfaces, including API, CLI, and GUI. We implement and evaluate CSAgent, which successfully defends against more than 99.36% of attacks while introducing only 6.83% performance overhead.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Operating Systems",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.967500"
    },
    {
        "index": "#119",
        "title": "ASSESS: A Semantic and Structural Evaluation Framework for Statement Similarity",
        "link": "/arxiv/2509.22246",
        "arxiv_id": "2509.22246",
        "authors": "Xiaoyang Liu, Tao Zhu, Zineng Dong, Yuntian Liu, Qingfeng Guo, Zhaoxuan Liu, Yu Chen, Tao Luo",
        "summary": "Statement autoformalization, the automated translation of statements from natural language into formal languages, has seen significant advancements, yet the development of automated evaluation metrics remains limited. Existing metrics for formal statement similarity often fail to balance semantic and structural information. String-based approaches capture syntactic structure but ignore semantic meaning, whereas proof-based methods validate semantic equivalence but disregard structural nuances and, critically, provide no graded similarity score in the event of proof failure. To address these issues, we introduce ASSESS (A Semantic and Structural Evaluation Framework for Statement Similarity), which comprehensively integrates semantic and structural information to provide a continuous similarity score. Our framework first transforms formal statements into Operator Trees to capture their syntactic structure and then computes a similarity score using our novel TransTED (Transformation Tree Edit Distance) Similarity metric, which enhances traditional Tree Edit Distance by incorporating semantic awareness through transformations. For rigorous validation, we present EPLA (Evaluating Provability and Likeness for Autoformalization), a new benchmark of 524 expert-annotated formal statement pairs derived from miniF2F and ProofNet, with labels for both semantic provability and structural likeness. Experiments on EPLA demonstrate that TransTED Similarity outperforms existing methods, achieving state-of-the-art accuracy and the highest Kappa coefficient. The benchmark, and implementation code will be made public soon.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.968771"
    },
    {
        "index": "#121",
        "title": "Fairness-Aware Reinforcement Learning (FAReL): A Framework for Transparent and Balanced Sequential Decision-Making",
        "link": "/arxiv/2509.22232",
        "arxiv_id": "2509.22232",
        "authors": "Alexandra Cimpean, Nicole Orzan, Catholijn Jonker, Pieter Libin, Ann Nowé",
        "summary": "Equity in real-world sequential decision problems can be enforced using fairness-aware methods. Therefore, we require algorithms that can make suitable and transparent trade-offs between performance and the desired fairness notions. As the desired performance-fairness trade-off is hard to specify a priori, we propose a framework where multiple trade-offs can be explored. Insights provided by the reinforcement learning algorithm regarding the obtainable performance-fairness trade-offs can then guide stakeholders in selecting the most appropriate policy. To capture fairness, we propose an extended Markov decision process, $f$MDP, that explicitly encodes individuals and groups. Given this $f$MDP, we formalise fairness notions in the context of sequential decision problems and formulate a fairness framework that computes fairness measures over time. We evaluate our framework in two scenarios with distinct fairness requirements: job hiring, where strong teams must be composed while treating applicants equally, and fraud detection, where fraudulent transactions must be detected while ensuring the burden on customers is fairly distributed. We show that our framework learns policies that are more fair across multiple scenarios, with only minor loss in performance reward. Moreover, we observe that group and individual fairness notions do not necessarily imply one another, highlighting the benefit of our framework in settings where both fairness types are desired. Finally, we provide guidelines on how to apply this framework across different problem settings.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.974928"
    },
    {
        "index": "#125",
        "title": "Automatic Discovery of One Parameter Subgroups of $SO(n)$",
        "link": "/arxiv/2509.22219",
        "arxiv_id": "2509.22219",
        "authors": "Pavan Karjol, Vivek V Kashyap, Rohan Kashyap, Prathosh A P",
        "summary": "We introduce a novel framework for the automatic discovery of one-parameter subgroups ($H_{\\gamma}$) of $SO(3)$ and, more generally, $SO(n)$. One-parameter subgroups of $SO(n)$ are crucial in a wide range of applications, including robotics, quantum mechanics, and molecular structure analysis. Our method utilizes the standard Jordan form of skew-symmetric matrices, which define the Lie algebra of $SO(n)$, to establish a canonical form for orbits under the action of $H_{\\gamma}$. This canonical form is then employed to derive a standardized representation for $H_{\\gamma}$-invariant functions. By learning the appropriate parameters, the framework uncovers the underlying one-parameter subgroup $H_{\\gamma}$. The effectiveness of the proposed approach is demonstrated through tasks such as double pendulum modeling, moment of inertia prediction, top quark tagging and invariant polynomial regression, where it successfully recovers meaningful subgroup structure and produces interpretable, symmetry-aware representations.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.976955"
    },
    {
        "index": "#129",
        "title": "Reversible GNS for Dissipative Fluids with Consistent Bidirectional Dynamics",
        "link": "/arxiv/2509.22207",
        "arxiv_id": "2509.22207",
        "authors": "Mu Huang, Linning Xu, Mingyue Dai, Yidi Shao, Bo Dai",
        "summary": "Simulating physically plausible trajectories toward user-defined goals is a fundamental yet challenging task in fluid dynamics. While particle-based simulators can efficiently reproduce forward dynamics, inverse inference remains difficult, especially in dissipative systems where dynamics are irreversible and optimization-based solvers are slow, unstable, and often fail to converge. In this work, we introduce the Reversible Graph Network Simulator (R-GNS), a unified framework that enforces bidirectional consistency within a single graph architecture. Unlike prior neural simulators that approximate inverse dynamics by fitting backward data, R-GNS does not attempt to reverse the underlying physics. Instead, we propose a mathematically invertible design based on residual reversible message passing with shared parameters, coupling forward dynamics with inverse inference to deliver accurate predictions and efficient recovery of plausible initial states. Experiments on three dissipative benchmarks (Water-3D, WaterRamps, and WaterDrop) show that R-GNS achieves higher accuracy and consistency with only one quarter of the parameters, and performs inverse inference more than 100 times faster than optimization-based baselines. For forward simulation, R-GNS matches the speed of strong GNS baselines, while in goal-conditioned tasks it eliminates iterative optimization and achieves orders-of-magnitude speedups. On goal-conditioned tasks, R-GNS further demonstrates its ability to complex target shapes (e.g., characters \"L\" and \"N\") through vivid, physically consistent trajectories. To our knowledge, this is the first reversible framework that unifies forward and inverse simulation for dissipative fluid systems.",
        "subjects": "Machine Learning, Artificial Intelligence, Fluid Dynamics",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.979096"
    },
    {
        "index": "#131",
        "title": "MimicDreamer: Aligning Human and Robot Demonstrations for Scalable VLA Training",
        "link": "/arxiv/2509.22199",
        "arxiv_id": "2509.22199",
        "authors": "Haoyun Li, Ivan Zhang, Runqi Ouyang, Xiaofeng Wang, Zheng Zhu, Zhiqin Yang, Zhentao Zhang, Boyuan Wang, Chaojun Ni, Wenkang Qin, Xinze Chen, Yun Ye, Guan Huang, Zhenbo Song, Xingang Wang",
        "summary": "Vision Language Action (VLA) models derive their generalization capability from diverse training data, yet collecting embodied robot interaction data remains prohibitively expensive. In contrast, human demonstration videos are far more scalable and cost-efficient to collect, and recent studies confirm their effectiveness in training VLA models. However, a significant domain gap persists between human videos and robot-executed videos, including unstable camera viewpoints, visual discrepancies between human hands and robotic arms, and differences in motion dynamics. To bridge this gap, we propose MimicDreamer, a framework that turns fast, low-cost human demonstrations into robot-usable supervision by jointly aligning vision, viewpoint, and actions to directly support policy training. For visual alignment, we propose H2R Aligner, a video diffusion model that generates high-fidelity robot demonstration videos by transferring motion from human manipulation footage. For viewpoint stabilization, EgoStabilizer is proposed, which canonicalizes egocentric videos via homography and inpaints occlusions and distortions caused by warping. For action alignment, we map human hand trajectories to the robot frame and apply a constrained inverse kinematics solver to produce feasible, low-jitter joint commands with accurate pose tracking. Empirically, VLA models trained purely on our synthesized human-to-robot videos achieve few-shot execution on real robots. Moreover, scaling training with human data significantly boosts performance compared to models trained solely on real robot data; our approach improves the average success rate by 14.7\\% across six representative manipulation tasks.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.985328"
    },
    {
        "index": "#132",
        "title": "Learning Equivariant Functions via Quadratic Forms",
        "link": "/arxiv/2509.22184",
        "arxiv_id": "2509.22184",
        "authors": "Pavan Karjol, Vivek V Kashyap, Rohan Kashyap, Prathosh A P",
        "summary": "In this study, we introduce a method for learning group (known or unknown) equivariant functions by learning the associated quadratic form $x^T A x$ corresponding to the group from the data. Certain groups, known as orthogonal groups, preserve a specific quadratic form, and we leverage this property to uncover the underlying symmetry group under the assumption that it is orthogonal. By utilizing the corresponding unique symmetric matrix and its inherent diagonal form, we incorporate suitable inductive biases into the neural network architecture, leading to models that are both simplified and efficient. Our approach results in an invariant model that preserves norms, while the equivariant model is represented as a product of a norm-invariant model and a scale-invariant model, where the ``product'' refers to the group action. Moreover, we extend our framework to a more general setting where the function acts on tuples of input vectors via a diagonal (or product) group action. In this extension, the equivariant function is decomposed into an angular component extracted solely from the normalized first vector and a scale-invariant component that depends on the full Gram matrix of the tuple. This decomposition captures the inter-dependencies between multiple inputs while preserving the underlying group symmetry. We assess the effectiveness of our framework across multiple tasks, including polynomial regression, top quark tagging, and moment of inertia matrix prediction. Comparative analysis with baseline methods demonstrates that our model consistently excels in both discovering the underlying symmetry and efficiently learning the corresponding equivariant function.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.985822"
    },
    {
        "index": "#133",
        "title": "Efficiency Boost in Decentralized Optimization: Reimagining Neighborhood Aggregation with Minimal Overhead",
        "link": "/arxiv/2509.22174",
        "arxiv_id": "2509.22174",
        "authors": "Durgesh Kalwar, Mayank Baranwal, Harshad Khadilkar",
        "summary": "In today's data-sensitive landscape, distributed learning emerges as a vital tool, not only fortifying privacy measures but also streamlining computational operations. This becomes especially crucial within fully decentralized infrastructures where local processing is imperative due to the absence of centralized aggregation. Here, we introduce DYNAWEIGHT, a novel framework to information aggregation in multi-agent networks. DYNAWEIGHT offers substantial acceleration in decentralized learning with minimal additional communication and memory overhead. Unlike traditional static weight assignments, such as Metropolis weights, DYNAWEIGHT dynamically allocates weights to neighboring servers based on their relative losses on local datasets. Consequently, it favors servers possessing diverse information, particularly in scenarios of substantial data heterogeneity. Our experiments on various datasets MNIST, CIFAR10, and CIFAR100 incorporating various server counts and graph topologies, demonstrate notable enhancements in training speeds. Notably, DYNAWEIGHT functions as an aggregation scheme compatible with any underlying server-level optimization algorithm, underscoring its versatility and potential for widespread integration.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.986299"
    },
    {
        "index": "#134",
        "title": "Teaching AI to Feel: A Collaborative, Full-Body Exploration of Emotive Communication",
        "link": "/arxiv/2509.22168",
        "arxiv_id": "2509.22168",
        "authors": "Esen K. Tütüncü, Lissette Lemus, Kris Pilcher, Holger Sprengel, Jordi Sabater-Mir",
        "summary": "Commonaiverse is an interactive installation exploring human emotions through full-body motion tracking and real-time AI feedback. Participants engage in three phases: Teaching, Exploration and the Cosmos Phase, collaboratively expressing and interpreting emotions with the system. The installation integrates MoveNet for precise motion tracking and a multi-recommender AI system to analyze emotional states dynamically, responding with adaptive audiovisual outputs. By shifting from top-down emotion classification to participant-driven, culturally diverse definitions, we highlight new pathways for inclusive, ethical affective computing. We discuss how this collaborative, out-of-the-box approach pushes multimedia research beyond single-user facial analysis toward a more embodied, co-created paradigm of emotional AI. Furthermore, we reflect on how this reimagined framework fosters user agency, reduces bias, and opens avenues for advanced interactive applications.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.986803"
    },
    {
        "index": "#135",
        "title": "Lightweight error mitigation strategies for post-training N:M activation sparsity in LLMs",
        "link": "/arxiv/2509.22166",
        "arxiv_id": "2509.22166",
        "authors": "Shirin Alanova, Kristina Kazistova, Ekaterina Galaeva, Alina Kostromina, Vladimir Smirnov, Redko Dmitry, Alexey Dontsov, Maxim Zhelnin, Evgeny Burnaev, Egor Shvetsov",
        "summary": "The demand for efficient large language model (LLM) inference has intensified the focus on sparsification techniques. While semi-structured (N:M) pruning is well-established for weights, its application to activation pruning remains underexplored despite its potential for dynamic, input-adaptive compression and reductions in I/O overhead. This work presents a comprehensive analysis of methods for post-training N:M activation pruning in LLMs. Across multiple LLMs, we demonstrate that pruning activations enables superior preservation of generative capabilities compared to weight pruning at equivalent sparsity levels. We evaluate lightweight, plug-and-play error mitigation techniques and pruning criteria, establishing strong hardware-friendly baselines that require minimal calibration. Furthermore, we explore sparsity patterns beyond NVIDIA's standard 2:4, showing that the 16:32 pattern achieves performance nearly on par with unstructured sparsity. However, considering the trade-off between flexibility and hardware implementation complexity, we focus on the 8:16 pattern as a superior candidate. Our findings provide both effective practical methods for activation pruning and a motivation for future hardware to support more flexible sparsity patterns. Our code is available https://anonymous.4open.science/r/Structured-Sparse-Activations-Inference-EC3C/README.md .",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.987369"
    },
    {
        "index": "#136",
        "title": "Pushing Toward the Simplex Vertices: A Simple Remedy for Code Collapse in Smoothed Vector Quantization",
        "link": "/arxiv/2509.22161",
        "arxiv_id": "2509.22161",
        "authors": "Takashi Morita",
        "summary": "Vector quantization, which discretizes a continuous vector space into a finite set of representative vectors (a codebook), has been widely adopted in modern machine learning. Despite its effectiveness, vector quantization poses a fundamental challenge: the non-differentiable quantization step blocks gradient backpropagation. Smoothed vector quantization addresses this issue by relaxing the hard assignment of a codebook vector into a weighted combination of codebook entries, represented as the matrix product of a simplex vector and the codebook. Effective smoothing requires two properties: (1) smoothed quantizers should remain close to a onehot vector, ensuring tight approximation, and (2) all codebook entries should be utilized, preventing code collapse. Existing methods typically address these desiderata separately. By contrast, the present study introduces a simple and intuitive regularization that promotes both simultaneously by minimizing the distance between each simplex vertex and its $K$-nearest smoothed quantizers. Experiments on representative benchmarks, including discrete image autoencoding and contrastive speech representation learning, demonstrate that the proposed method achieves more reliable codebook utilization and improves performance compared to prior approaches.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.987812"
    },
    {
        "index": "#143",
        "title": "The AI_INFN Platform: Artificial Intelligence Development in the Cloud",
        "link": "/arxiv/2509.22117",
        "arxiv_id": "2509.22117",
        "authors": "Lucio Anderlini, Giulio Bianchini, Diego Ciangottini, Stefano Dal Pra, Diego Michelotto, Rosa Petrini, Daniele Spiga",
        "summary": "Machine Learning (ML) is driving a revolution in the way scientists design, develop, and deploy data-intensive software. However, the adoption of ML presents new challenges for the computing infrastructure, particularly in terms of provisioning and orchestrating access to hardware accelerators for development, testing, and production. The INFN-funded project AI_INFN (Artificial Intelligence at INFN) aims at fostering the adoption of ML techniques within INFN use cases by providing support on multiple aspects, including the provisioning of AI-tailored computing resources. It leverages cloud-native solutions in the context of INFN Cloud, to share hardware accelerators as effectively as possible, ensuring the diversity of the Institute's research activities is not compromised. In this contribution, we provide an update on the commissioning of a Kubernetes platform designed to ease the development of GPU-powered data analysis workflows and their scalability on heterogeneous distributed computing resources, also using the offloading mechanism with Virtual Kubelet and InterLink API. This setup can manage workflows across different resource providers, including sites of the Worldwide LHC Computing Grid and supercomputers such as CINECA Leonardo, providing a model for use cases requiring dedicated infrastructures for different parts of the workload. Initial test results, emerging case studies, and integration scenarios will be presented with functional tests and benchmarks.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.996661"
    },
    {
        "index": "#144",
        "title": "Learning More with Less: A Dynamic Dual-Level Down-Sampling Framework for Efficient Policy Optimization",
        "link": "/arxiv/2509.22115",
        "arxiv_id": "2509.22115",
        "authors": "Chao Wang, Tao Yang, Hongtao Tian, Yunsheng Shi, Qiyao Ma, Xiaotao Liu, Ting Yao, Wenbo Ding",
        "summary": "Critic-free methods like GRPO reduce memory demands by estimating advantages from multiple rollouts but tend to converge slowly, as critical learning signals are diluted by an abundance of uninformative samples and tokens. To tackle this challenge, we propose the \\textbf{Dynamic Dual-Level Down-Sampling (D$^3$S)} framework that prioritizes the most informative samples and tokens across groups to improve the efficient of policy optimization. D$^3$S operates along two levels: (1) the sample-level, which selects a subset of rollouts to maximize advantage variance ($\\text{Var}(A)$). We theoretically proven that this selection is positively correlated with the upper bound of the policy gradient norms, yielding higher policy gradients. (2) the token-level, which prioritizes tokens with a high product of advantage magnitude and policy entropy ($|A_{i,t}|\\times H_{i,t}$), focusing updates on tokens where the policy is both uncertain and impactful. Moreover, to prevent overfitting to high-signal data, D$^3$S employs a dynamic down-sampling schedule inspired by curriculum learning. This schedule starts with aggressive down-sampling to accelerate early learning and gradually relaxes to promote robust generalization. Extensive experiments on Qwen2.5 and Llama3.1 demonstrate that integrating D$^3$S into advanced RL algorithms achieves state-of-the-art performance and generalization while requiring \\textit{fewer} samples and tokens across diverse reasoning benchmarks. Our code is added in the supplementary materials and will be made publicly available.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.997210"
    },
    {
        "index": "#145",
        "title": "Reinforcement Learning for Durable Algorithmic Recourse",
        "link": "/arxiv/2509.22102",
        "arxiv_id": "2509.22102",
        "authors": "Marina Ceccon, Alessandro Fabris, Goran Radanović, Asia J. Biega, Gian Antonio Susto",
        "summary": "Algorithmic recourse seeks to provide individuals with actionable recommendations that increase their chances of receiving favorable outcomes from automated decision systems (e.g., loan approvals). While prior research has emphasized robustness to model updates, considerably less attention has been given to the temporal dynamics of recourse--particularly in competitive, resource-constrained settings where recommendations shape future applicant pools. In this work, we present a novel time-aware framework for algorithmic recourse, explicitly modeling how candidate populations adapt in response to recommendations. Additionally, we introduce a novel reinforcement learning (RL)-based recourse algorithm that captures the evolving dynamics of the environment to generate recommendations that are both feasible and valid. We design our recommendations to be durable, supporting validity over a predefined time horizon T. This durability allows individuals to confidently reapply after taking time to implement the suggested changes. Through extensive experiments in complex simulation environments, we show that our approach substantially outperforms existing baselines, offering a superior balance between feasibility and long-term validity. Together, these results underscore the importance of incorporating temporal and behavioral dynamics into the design of practical recourse systems.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.997718"
    },
    {
        "index": "#147",
        "title": "Action-aware Dynamic Pruning for Efficient Vision-Language-Action Manipulation",
        "link": "/arxiv/2509.22093",
        "arxiv_id": "2509.22093",
        "authors": "Xiaohuan Pei, Yuxing Chen, Siyu Xu, Yunke Wang, Yuheng Shi, Chang Xu",
        "summary": "Robotic manipulation with Vision-Language-Action models requires efficient inference over long-horizon multi-modal context, where attention to dense visual tokens dominates computational cost. Existing methods optimize inference speed by reducing visual redundancy within VLA models, but they overlook the varying redundancy across robotic manipulation stages. We observe that the visual token redundancy is higher in coarse manipulation phase than in fine-grained operations, and is strongly correlated with the action dynamic. Motivated by this observation, we propose \\textbf{A}ction-aware \\textbf{D}ynamic \\textbf{P}runing (\\textbf{ADP}), a multi-modal pruning framework that integrates text-driven token selection with action-aware trajectory gating. Our method introduces a gating mechanism that conditions the pruning signal on recent action trajectories, using past motion windows to adaptively adjust token retention ratios in accordance with dynamics, thereby balancing computational efficiency and perceptual precision across different manipulation stages. Extensive experiments on the LIBERO suites and diverse real-world scenarios demonstrate that our method significantly reduces FLOPs and action inference latency (\\textit{e.g.} $1.35 \\times$ speed up on OpenVLA-OFT) while maintaining competitive success rates (\\textit{e.g.} 25.8\\% improvements with OpenVLA) compared to baselines, thereby providing a simple plug-in path to efficient robot policies that advances the efficiency and performance frontier of robotic manipulation. Our project website is: \\href{https://vla-adp.github.io/}{ADP.com}.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.998892"
    },
    {
        "index": "#148",
        "title": "The Rogue Scalpel: Activation Steering Compromises LLM Safety",
        "link": "/arxiv/2509.22067",
        "arxiv_id": "2509.22067",
        "authors": "Anton Korznikov, Andrey Galichin, Alexey Dontsov, Oleg Y. Rogov, Ivan Oseledets, Elena Tutubalina",
        "summary": "Activation steering is a promising technique for controlling LLM behavior by adding semantically meaningful vectors directly into a model's hidden states during inference. It is often framed as a precise, interpretable, and potentially safer alternative to fine-tuning. We demonstrate the opposite: steering systematically breaks model alignment safeguards, making it comply with harmful requests. Through extensive experiments on different model families, we show that even steering in a random direction can increase the probability of harmful compliance from 0% to 2-27%. Alarmingly, steering benign features from a sparse autoencoder (SAE), a common source of interpretable directions, increases these rates by a further 2-4%. Finally, we show that combining 20 randomly sampled vectors that jailbreak a single prompt creates a universal attack, significantly increasing harmful compliance on unseen requests. These results challenge the paradigm of safety through interpretability, showing that precise control over model internals does not guarantee precise control over model behavior.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:03.999398"
    },
    {
        "index": "#150",
        "title": "Decoding Deception: Understanding Automatic Speech Recognition Vulnerabilities in Evasion and Poisoning Attacks",
        "link": "/arxiv/2509.22060",
        "arxiv_id": "2509.22060",
        "authors": "Aravindhan G, Yuvaraj Govindarajulu, Parin Shah",
        "summary": "Recent studies have demonstrated the vulnerability of Automatic Speech Recognition systems to adversarial examples, which can deceive these systems into misinterpreting input speech commands. While previous research has primarily focused on white-box attacks with constrained optimizations, and transferability based black-box attacks against commercial Automatic Speech Recognition devices, this paper explores cost efficient white-box attack and non transferability black-box adversarial attacks on Automatic Speech Recognition systems, drawing insights from approaches such as Fast Gradient Sign Method and Zeroth-Order Optimization. Further, the novelty of the paper includes how poisoning attack can degrade the performances of state-of-the-art models leading to misinterpretation of audio signals. Through experimentation and analysis, we illustrate how hybrid models can generate subtle yet impactful adversarial examples with very little perturbation having Signal Noise Ratio of 35dB that can be generated within a minute. These vulnerabilities of state-of-the-art open source model have practical security implications, and emphasize the need for adversarial security.",
        "subjects": "Sound, Artificial Intelligence, Cryptography and Security",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.005472"
    },
    {
        "index": "#151",
        "title": "An Adaptive ICP LiDAR Odometry Based on Reliable Initial Pose",
        "link": "/arxiv/2509.22058",
        "arxiv_id": "2509.22058",
        "authors": "Qifeng Wang, Weigang Li, Lei Nie, Xin Xu, Wenping Liu, Zhe Xu",
        "summary": "As a key technology for autonomous navigation and positioning in mobile robots, light detection and ranging (LiDAR) odometry is widely used in autonomous driving applications. The Iterative Closest Point (ICP)-based methods have become the core technique in LiDAR odometry due to their efficient and accurate point cloud registration capability. However, some existing ICP-based methods do not consider the reliability of the initial pose, which may cause the method to converge to a local optimum. Furthermore, the absence of an adaptive mechanism hinders the effective handling of complex dynamic environments, resulting in a significant degradation of registration accuracy. To address these issues, this paper proposes an adaptive ICP-based LiDAR odometry method that relies on a reliable initial pose. First, distributed coarse registration based on density filtering is employed to obtain the initial pose estimation. The reliable initial pose is then selected by comparing it with the motion prediction pose, reducing the initial error between the source and target point clouds. Subsequently, by combining the current and historical errors, the adaptive threshold is dynamically adjusted to accommodate the real-time changes in the dynamic environment. Finally, based on the reliable initial pose and the adaptive threshold, point-to-plane adaptive ICP registration is performed from the current frame to the local map, achieving high-precision alignment of the source and target point clouds. Extensive experiments on the public KITTI dataset demonstrate that the proposed method outperforms existing approaches and significantly enhances the accuracy of LiDAR odometry.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.005975"
    },
    {
        "index": "#153",
        "title": "Latent Diffusion : Multi-Dimension Stable Diffusion Latent Space Explorer",
        "link": "/arxiv/2509.22038",
        "arxiv_id": "2509.22038",
        "authors": "Zhihua Zhong, Xuanyang Huang",
        "summary": "Latent space is one of the key concepts in generative AI, offering powerful means for creative exploration through vector manipulation. However, diffusion models like Stable Diffusion lack the intuitive latent vector control found in GANs, limiting their flexibility for artistic expression. This paper introduces \\workname, a framework for integrating customizable latent space operations into the diffusion process. By enabling direct manipulation of conceptual and spatial representations, this approach expands creative possibilities in generative art. We demonstrate the potential of this framework through two artworks, \\textit{Infinitepedia} and \\textit{Latent Motion}, highlighting its use in conceptual blending and dynamic motion generation. Our findings reveal latent space structures with semantic and meaningless regions, offering insights into the geometry of diffusion models and paving the way for further explorations of latent space.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.006979"
    },
    {
        "index": "#157",
        "title": "Developing Vision-Language-Action Model from Egocentric Videos",
        "link": "/arxiv/2509.21986",
        "arxiv_id": "2509.21986",
        "authors": "Tomoya Yoshida, Shuhei Kurita, Taichi Nishimura, Shinsuke Mori",
        "summary": "Egocentric videos capture how humans manipulate objects and tools, providing diverse motion cues for learning object manipulation. Unlike the costly, expert-driven manual teleoperation commonly used in training Vision-Language-Action models (VLAs), egocentric videos offer a scalable alternative. However, prior studies that leverage such videos for training robot policies typically rely on auxiliary annotations, such as detailed hand-pose recordings. Consequently, it remains unclear whether VLAs can be trained directly from raw egocentric videos. In this work, we address this challenge by leveraging EgoScaler, a framework that extracts 6DoF object manipulation trajectories from egocentric videos without requiring auxiliary recordings. We apply EgoScaler to four large-scale egocentric video datasets and automatically refine noisy or incomplete trajectories, thereby constructing a new large-scale dataset for VLA pre-training. Our experiments with a state-of-the-art $\\pi_0$ architecture in both simulated and real-robot environments yield three key findings: (i) pre-training on our dataset improves task success rates by over 20\\% compared to training from scratch, (ii) the performance is competitive with that achieved using real-robot datasets, and (iii) combining our dataset with real-robot data yields further improvements. These results demonstrate that egocentric videos constitute a promising and scalable resource for advancing VLA research.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.009006"
    },
    {
        "index": "#158",
        "title": "Hybrid Diffusion for Simultaneous Symbolic and Continuous Planning",
        "link": "/arxiv/2509.21983",
        "arxiv_id": "2509.21983",
        "authors": "Sigmund Hennum Høeg, Aksel Vaaler, Chaoqi Liu, Olav Egeland, Yilun Du",
        "summary": "Constructing robots to accomplish long-horizon tasks is a long-standing challenge within artificial intelligence. Approaches using generative methods, particularly Diffusion Models, have gained attention due to their ability to model continuous robotic trajectories for planning and control. However, we show that these models struggle with long-horizon tasks that involve complex decision-making and, in general, are prone to confusing different modes of behavior, leading to failure. To remedy this, we propose to augment continuous trajectory generation by simultaneously generating a high-level symbolic plan. We show that this requires a novel mix of discrete variable diffusion and continuous diffusion, which dramatically outperforms the baselines. In addition, we illustrate how this hybrid diffusion process enables flexible trajectory synthesis, allowing us to condition synthesized actions on partial and complete symbolic conditions.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.009486"
    },
    {
        "index": "#161",
        "title": "From Superficial Outputs to Superficial Learning: Risks of Large Language Models in Education",
        "link": "/arxiv/2509.21972",
        "arxiv_id": "2509.21972",
        "authors": "Iris Delikoura, Yi. R, Fung, Pan Hui",
        "summary": "Large Language Models (LLMs) are transforming education by enabling personalization, feedback, and knowledge access, while also raising concerns about risks to students and learning systems. Yet empirical evidence on these risks remains fragmented. This paper presents a systematic review of 70 empirical studies across computer science, education, and psychology. Guided by four research questions, we examine: (i) which applications of LLMs in education have been most frequently explored; (ii) how researchers have measured their impact; (iii) which risks stem from such applications; and (iv) what mitigation strategies have been proposed. We find that research on LLMs clusters around three domains: operational effectiveness, personalized applications, and interactive learning tools. Across these, model-level risks include superficial understanding, bias, limited robustness, anthropomorphism, hallucinations, privacy concerns, and knowledge constraints. When learners interact with LLMs, these risks extend to cognitive and behavioural outcomes, including reduced neural activity, over-reliance, diminished independent learning skills, and a loss of student agency. To capture this progression, we propose an LLM-Risk Adapted Learning Model that illustrates how technical risks cascade through interaction and interpretation to shape educational outcomes. As the first synthesis of empirically assessed risks, this review provides a foundation for responsible, human-centred integration of LLMs in education.",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.016200"
    },
    {
        "index": "#163",
        "title": "FlowDrive: moderated flow matching with data balancing for trajectory planning",
        "link": "/arxiv/2509.21961",
        "arxiv_id": "2509.21961",
        "authors": "Lingguang Wang, Ömer Şahin Taş, Marlon Steiner, Christoph Stiller",
        "summary": "Learning-based planners are sensitive to the long-tailed distribution of driving data. Common maneuvers dominate datasets, while dangerous or rare scenarios are sparse. This imbalance can bias models toward the frequent cases and degrade performance on critical scenarios. To tackle this problem, we compare balancing strategies for sampling training data and find reweighting by trajectory pattern an effective approach. We then present FlowDrive, a flow-matching trajectory planner that learns a conditional rectified flow to map noise directly to trajectory distributions with few flow-matching steps. We further introduce moderated, in-the-loop guidance that injects small perturbation between flow steps to systematically increase trajectory diversity while remaining scene-consistent. On nuPlan and the interaction-focused interPlan benchmarks, FlowDrive achieves state-of-the-art results among learning-based planners and approaches methods with rule-based refinements. After adding moderated guidance and light post-processing (FlowDrive*), it achieves overall state-of-the-art performance across nearly all benchmark splits.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.017185"
    },
    {
        "index": "#164",
        "title": "Active Attacks: Red-teaming LLMs via Adaptive Environments",
        "link": "/arxiv/2509.21947",
        "arxiv_id": "2509.21947",
        "authors": "Taeyoung Yun, Pierre-Luc St-Charles, Jinkyoo Park, Yoshua Bengio, Minsu Kim",
        "summary": "We address the challenge of generating diverse attack prompts for large language models (LLMs) that elicit harmful behaviors (e.g., insults, sexual content) and are used for safety fine-tuning. Rather than relying on manual prompt engineering, attacker LLMs can be trained with reinforcement learning (RL) to automatically generate such prompts using only a toxicity classifier as a reward. However, capturing a wide range of harmful behaviors is a significant challenge that requires explicit diversity objectives. Existing diversity-seeking RL methods often collapse to limited modes: once high-reward prompts are found, exploration of new regions is discouraged. Inspired by the active learning paradigm that encourages adaptive exploration, we introduce \\textit{Active Attacks}, a novel RL-based red-teaming algorithm that adapts its attacks as the victim evolves. By periodically safety fine-tuning the victim LLM with collected attack prompts, rewards in exploited regions diminish, which forces the attacker to seek unexplored vulnerabilities. This process naturally induces an easy-to-hard exploration curriculum, where the attacker progresses beyond easy modes toward increasingly difficult ones. As a result, Active Attacks uncovers a wide range of local attack modes step by step, and their combination achieves wide coverage of the multi-mode distribution. Active Attacks, a simple plug-and-play module that seamlessly integrates into existing RL objectives, unexpectedly outperformed prior RL-based methods -- including GFlowNets, PPO, and REINFORCE -- by improving cross-attack success rates against GFlowNets, the previous state-of-the-art, from 0.07% to 31.28% (a relative gain greater than $400\\ \\times$) with only a 6% increase in computation. Our code is publicly available \\href{https://github.com/dbsxodud-11/active_attacks}{here}.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.017671"
    },
    {
        "index": "#166",
        "title": "Unveiling Many Faces of Surrogate Models for Configuration Tuning: A Fitness Landscape Analysis Perspective",
        "link": "/arxiv/2509.21945",
        "arxiv_id": "2509.21945",
        "authors": "Pengzhou Chen, Hongyuan Liang, Tao Chen",
        "summary": "To efficiently tune configuration for better system performance (e.g., latency), many tuners have leveraged a surrogate model to expedite the process instead of solely relying on the profoundly expensive system measurement. As such, it is naturally believed that we need more accurate models. However, the fact of accuracy can lie-a somewhat surprising finding from prior work-has left us many unanswered questions regarding what role the surrogate model plays in configuration tuning. This paper provides the very first systematic exploration and discussion, together with a resolution proposal, to disclose the many faces of surrogate models for configuration tuning, through the novel perspective of fitness landscape analysis. We present a theory as an alternative to accuracy for assessing the model usefulness in tuning, based on which we conduct an extensive empirical study involving up to 27,000 cases. Drawing on the above, we propose Model4Tune, an automated predictive tool that estimates which model-tuner pairs are the best for an unforeseen system without expensive tuner profiling. Our results suggest that Moldel4Tune, as one of the first of its kind, performs significantly better than random guessing in 79%-82% of the cases. Our results not only shed light on the possible future research directions but also offer a practical resolution that can assist practitioners in evaluating the most useful model for configuration tuning.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.018546"
    },
    {
        "index": "#169",
        "title": "SAGE: Scene Graph-Aware Guidance and Execution for Long-Horizon Manipulation Tasks",
        "link": "/arxiv/2509.21928",
        "arxiv_id": "2509.21928",
        "authors": "Jialiang Li, Wenzheng Wu, Gaojing Zhang, Yifan Han, Wenzhao Lian",
        "summary": "Successfully solving long-horizon manipulation tasks remains a fundamental challenge. These tasks involve extended action sequences and complex object interactions, presenting a critical gap between high-level symbolic planning and low-level continuous control. To bridge this gap, two essential capabilities are required: robust long-horizon task planning and effective goal-conditioned manipulation. Existing task planning methods, including traditional and LLM-based approaches, often exhibit limited generalization or sparse semantic reasoning. Meanwhile, image-conditioned control methods struggle to adapt to unseen tasks. To tackle these problems, we propose SAGE, a novel framework for Scene Graph-Aware Guidance and Execution in Long-Horizon Manipulation Tasks. SAGE utilizes semantic scene graphs as a structural representation for scene states. A structural scene graph enables bridging task-level semantic reasoning and pixel-level visuo-motor control. This also facilitates the controllable synthesis of accurate, novel sub-goal images. SAGE consists of two key components: (1) a scene graph-based task planner that uses VLMs and LLMs to parse the environment and reason about physically-grounded scene state transition sequences, and (2) a decoupled structural image editing pipeline that controllably converts each target sub-goal graph into a corresponding image through image inpainting and composition. Extensive experiments have demonstrated that SAGE achieves state-of-the-art performance on distinct long-horizon tasks.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.019974"
    },
    {
        "index": "#170",
        "title": "Generation Properties of Stochastic Interpolation under Finite Training Set",
        "link": "/arxiv/2509.21925",
        "arxiv_id": "2509.21925",
        "authors": "Yunchen Li, Shaohui Lin, Zhou Yu",
        "summary": "This paper investigates the theoretical behavior of generative models under finite training populations. Within the stochastic interpolation generative framework, we derive closed-form expressions for the optimal velocity field and score function when only a finite number of training samples are available. We demonstrate that, under some regularity conditions, the deterministic generative process exactly recovers the training samples, while the stochastic generative process manifests as training samples with added Gaussian noise. Beyond the idealized setting, we consider model estimation errors and introduce formal definitions of underfitting and overfitting specific to generative models. Our theoretical analysis reveals that, in the presence of estimation errors, the stochastic generation process effectively produces convex combinations of training samples corrupted by a mixture of uniform and Gaussian noise. Experiments on generation tasks and downstream tasks such as classification support our theory.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.025573"
    },
    {
        "index": "#171",
        "title": "EqDiff-CT: Equivariant Conditional Diffusion model for CT Image Synthesis from CBCT",
        "link": "/arxiv/2509.21913",
        "arxiv_id": "2509.21913",
        "authors": "Alzahra Altalib, Chunhui Li, Alessandro Perelli",
        "summary": "Cone-beam computed tomography (CBCT) is widely used for image-guided radiotherapy (IGRT). It provides real time visualization at low cost and dose. However, photon scattering and beam hindrance cause artifacts in CBCT. These include inaccurate Hounsfield Units (HU), reducing reliability for dose calculation, and adaptive planning. By contrast, computed tomography (CT) offers better image quality and accurate HU calibration but is usually acquired offline and fails to capture intra-treatment anatomical changes. Thus, accurate CBCT-to-CT synthesis is needed to close the imaging-quality gap in adaptive radiotherapy workflows. To cater to this, we propose a novel diffusion-based conditional generative model, coined EqDiff-CT, to synthesize high-quality CT images from CBCT. EqDiff-CT employs a denoising diffusion probabilistic model (DDPM) to iteratively inject noise and learn latent representations that enable reconstruction of anatomically consistent CT images. A group-equivariant conditional U-Net backbone, implemented with e2cnn steerable layers, enforces rotational equivariance (cyclic C4 symmetry), helping preserve fine structural details while minimizing noise and artifacts. The system was trained and validated on the SynthRAD2025 dataset, comprising CBCT-CT scans across multiple head-and-neck anatomical sites, and we compared it with advanced methods such as CycleGAN and DDPM. EqDiff-CT provided substantial gains in structural fidelity, HU accuracy and quantitative metrics. Visual findings further confirm the improved recovery, sharper soft tissue boundaries, and realistic bone reconstructions. The findings suggest that the diffusion model has offered a robust and generalizable framework for CBCT improvements. The proposed solution helps in improving the image quality as well as the clinical confidence in the CBCT-guided treatment planning and dose calculations.",
        "subjects": "Medical Physics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.026026"
    },
    {
        "index": "#176",
        "title": "Position: The Hidden Costs and Measurement Gaps of Reinforcement Learning with Verifiable Rewards",
        "link": "/arxiv/2509.21882",
        "arxiv_id": "2509.21882",
        "authors": "Aaron Tu, Weihao Xuan, Heli Qi, Xu Huang, Qingcheng Zeng, Shayan Talaei, Yijia Xiao, Peng Xia, Xiangru Tang, Yuchen Zhuang, Bing Hu, Hanqun Cao, Wenqi Shi, Tianang Leng, Rui Yang, Yingjian Chen, Ziqi Wang, Irene Li, Nan Liu, Huaxiu Yao, Li Erran Li, Ge Liu, Amin Saberi, Naoto Yokoya, Jure Leskovec, Yejin Choi, Fang Wu",
        "summary": "Reinforcement learning with verifiable rewards (RLVR) is a practical and scalable approach to enhancing large language models in areas such as math, code, and other structured tasks. Two questions motivate this paper: how much of the reported gains survive under strictly parity-controlled evaluation, and whether RLVR is cost-free or exacts a measurable tax. We argue that progress is real, but gains are often overstated due to three forces - an RLVR tax, evaluation pitfalls, and data contamination. Using a partial-prompt contamination audit and matched-budget reproductions across base and RL models, we show that several headline gaps shrink or vanish under clean, parity-controlled evaluation. We then propose a tax-aware training and evaluation protocol that co-optimizes accuracy, grounding, and calibrated abstention and standardizes budgeting and provenance checks. Applied to recent RLVR setups, this protocol yields more reliable estimates of reasoning gains and, in several cases, revises prior conclusions. Our position is constructive: RLVR is valuable and industry-ready; we advocate keeping its practical benefits while prioritizing reliability, safety, and measurement.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.028827"
    },
    {
        "index": "#180",
        "title": "Graph of Agents: Principled Long Context Modeling by Emergent Multi-Agent Collaboration",
        "link": "/arxiv/2509.21848",
        "arxiv_id": "2509.21848",
        "authors": "Taejong Joo, Shu Ishida, Ivan Sosnovik, Bryan Lim, Sahand Rezaei-Shoshtari, Adam Gaier, Robert Giaquinto",
        "summary": "As a model-agnostic approach to long context modeling, multi-agent systems can process inputs longer than a large language model's context window without retraining or architectural modifications. However, their performance often heavily relies on hand-crafted multi-agent collaboration strategies and prompt engineering, which limit generalizability. In this work, we introduce a principled framework that formalizes the model-agnostic long context modeling problem as a compression problem, yielding an information-theoretic compression objective. Building on this framework, we propose Graph of Agents (GoA), which dynamically constructs an input-dependent collaboration structure that maximizes this objective. For Llama 3.1 8B and Qwen3 8B across six document question answering benchmarks, GoA improves the average $F_1$ score of retrieval-augmented generation by 5.7\\% and a strong multi-agent baseline using a fixed collaboration structure by 16.35\\%, respectively. Even with only a 2K context window, GoA surpasses the 128K context window Llama 3.1 8B on LongBench, showing a dramatic increase in effective context length. Our source code is available at https://github.com/tjoo512/graph-of-agents.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.035958"
    },
    {
        "index": "#181",
        "title": "Beyond Johnson-Lindenstrauss: Uniform Bounds for Sketched Bilinear Forms",
        "link": "/arxiv/2509.21847",
        "arxiv_id": "2509.21847",
        "authors": "Rohan Deb, Qiaobo Li, Mayank Shrivastava, Arindam Banerjee",
        "summary": "Uniform bounds on sketched inner products of vectors or matrices underpin several important computational and statistical results in machine learning and randomized algorithms, including the Johnson-Lindenstrauss (J-L) lemma, the Restricted Isometry Property (RIP), randomized sketching, and approximate linear algebra. However, many modern analyses involve *sketched bilinear forms*, for which existing uniform bounds either do not apply or are not sharp on general sets. In this work, we develop a general framework to analyze such sketched bilinear forms and derive uniform bounds in terms of geometric complexities of the associated sets. Our approach relies on generic chaining and introduces new techniques for handling suprema over pairs of sets. We further extend these results to the setting where the bilinear form involves a sum of $T$ independent sketching matrices and show that the deviation scales as $\\sqrt{T}$. This unified analysis recovers known results such as the J-L lemma as special cases, while extending RIP-type guarantees. Additionally, we obtain improved convergence bounds for sketched Federated Learning algorithms where such cross terms arise naturally due to sketched gradient compression, and design sketched variants of bandit algorithms with sharper regret bounds that depend on the geometric complexity of the action and parameter sets, rather than the ambient dimension.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.036468"
    },
    {
        "index": "#182",
        "title": "Can Large Language Models Autoformalize Kinematics?",
        "link": "/arxiv/2509.21840",
        "arxiv_id": "2509.21840",
        "authors": "Aditi Kabra, Jonathan Laurent, Sagar Bharadwaj, Ruben Martins, Stefan Mitsch, André Platzer",
        "summary": "Autonomous cyber-physical systems like robots and self-driving cars could greatly benefit from using formal methods to reason reliably about their control decisions. However, before a problem can be solved it needs to be stated. This requires writing a formal physics model of the cyber-physical system, which is a complex task that traditionally requires human expertise and becomes a bottleneck. This paper experimentally studies whether Large Language Models (LLMs) can automate the formalization process. A 20 problem benchmark suite is designed drawing from undergraduate level physics kinematics problems. In each problem, the LLM is provided with a natural language description of the objects' motion and must produce a model in differential game logic (dGL). The model is (1) syntax checked and iteratively refined based on parser feedback, and (2) semantically evaluated by checking whether symbolically executing the dGL formula recovers the solution to the original physics problem. A success rate of 70% (best over 5 samples) is achieved. We analyze failing cases, identifying directions for future improvement. This provides a first quantitative baseline for LLM-based autoformalization from natural language to a hybrid games logic with continuous dynamics.",
        "subjects": "Logic in Computer Science, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.036988"
    },
    {
        "index": "#184",
        "title": "ChaosNexus: A Foundation Model for Universal Chaotic System Forecasting with Multi-scale Representations",
        "link": "/arxiv/2509.21802",
        "arxiv_id": "2509.21802",
        "authors": "Chang Liu, Bohao Zhao, Jingtao Ding, Yong Li",
        "summary": "Accurately forecasting chaotic systems, prevalent in domains such as weather prediction and fluid dynamics, remains a significant scientific challenge. The inherent sensitivity of these systems to initial conditions, coupled with a scarcity of observational data, severely constrains traditional modeling approaches. Since these models are typically trained for a specific system, they lack the generalization capacity necessary for real-world applications, which demand robust zero-shot or few-shot forecasting on novel or data-limited scenarios. To overcome this generalization barrier, we propose ChaosNexus, a foundation model pre-trained on a diverse corpus of chaotic dynamics. ChaosNexus employs a novel multi-scale architecture named ScaleFormer augmented with Mixture-of-Experts layers, to capture both universal patterns and system-specific behaviors. The model demonstrates state-of-the-art zero-shot generalization across both synthetic and real-world benchmarks. On a large-scale testbed comprising over 9,000 synthetic chaotic systems, it improves the fidelity of long-term attractor statistics by more than 40% compared to the leading baseline. This robust performance extends to real-world applications with exceptional data efficiency. For instance, in 5-day global weather forecasting, ChaosNexus achieves a competitive zero-shot mean error below 1 degree, a result that further improves with few-shot fine-tuning. Moreover, experiments on the scaling behavior of ChaosNexus provide a guiding principle for scientific foundation models: cross-system generalization stems from the diversity of training systems, rather than sheer data volume.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.038022"
    },
    {
        "index": "#186",
        "title": "FastGRPO: Accelerating Policy Optimization via Concurrency-aware Speculative Decoding and Online Draft Learning",
        "link": "/arxiv/2509.21792",
        "arxiv_id": "2509.21792",
        "authors": "Yizhou Zhang, Ning Lv, Teng Wang, Jisheng Dang",
        "summary": "Group relative policy optimization (GRPO) has demonstrated significant potential in improving the reasoning capabilities of large language models (LLMs) via reinforcement learning. However, its practical deployment is impeded by an excessively slow training process, primarily attributed to the computationally intensive autoregressive generation of multiple responses per query, which makes the generation phase the primary performance bottleneck. Although speculative decoding presents a promising direction for acceleration, its direct application in GRPO achieves limited speedup under high-concurrency training conditions. To overcome this limitation, we propose a concurrency-aware speculative decoding framework that dynamically adjusts the drafting and verification strategy according to real-time concurrency levels, thereby maximizing the acceleration of the generation process. Furthermore, to address performance degradation arising from distributional drift between the evolving target model and the fixed draft model during training, we introduce an online draft learning mechanism that enables the draft model to continuously adapt using feedback signals from the target model. Experimental results across multiple mathematical reasoning datasets and models demonstrate that the proposed method achieves end-to-end speedups of 2.35x to 2.72x, significantly surpassing baseline approaches in efficiency. The code is available at https://github.com/yedaotian9/GRPO_speculative.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.039015"
    },
    {
        "index": "#187",
        "title": "Unbiased Binning: Fairness-aware Attribute Representation",
        "link": "/arxiv/2509.21785",
        "arxiv_id": "2509.21785",
        "authors": "Abolfazl Asudeh, Zeinab, Asoodeh, Bita Asoodeh, Omid Asudeh",
        "summary": "Discretizing raw features into bucketized attribute representations is a popular step before sharing a dataset. It is, however, evident that this step can cause significant bias in data and amplify unfairness in downstream tasks. In this paper, we address this issue by introducing the unbiased binning problem that, given an attribute to bucketize, finds its closest discretization to equal-size binning that satisfies group parity across different buckets. Defining a small set of boundary candidates, we prove that unbiased binning must select its boundaries from this set. We then develop an efficient dynamic programming algorithm on top of the boundary candidates to solve the unbiased binning problem. Finding an unbiased binning may sometimes result in a high price of fairness, or it may not even exist, especially when group values follow different distributions. Considering that a small bias in the group ratios may be tolerable in such settings, we introduce the epsilon-biased binning problem that bounds the group disparities across buckets to a small value epsilon. We first develop a dynamic programming solution, DP, that finds the optimal binning in quadratic time. The DP algorithm, while polynomial, does not scale to very large settings. Therefore, we propose a practically scalable algorithm, based on local search (LS), for epsilon-biased binning. The key component of the LS algorithm is a divide-and-conquer (D&C) algorithm that finds a near-optimal solution for the problem in near-linear time. We prove that D&C finds a valid solution for the problem unless none exists. The LS algorithm then initiates a local search, using the D&C solution as the upper bound, to find the optimal solution.",
        "subjects": "Databases, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.039513"
    },
    {
        "index": "#188",
        "title": "Beyond Structure: Invariant Crystal Property Prediction with Pseudo-Particle Ray Diffraction",
        "link": "/arxiv/2509.21778",
        "arxiv_id": "2509.21778",
        "authors": "Bin Cao, Yang Liu, Longhan Zhang, Yifan Wu, Zhixun Li, Yuyu Luo, Hong Cheng, Yang Ren, Tong-Yi Zhang",
        "summary": "Crystal property prediction, governed by quantum mechanical principles, is computationally prohibitive to solve exactly for large many-body systems using traditional density functional theory. While machine learning models have emerged as efficient approximations for large-scale applications, their performance is strongly influenced by the choice of atomic representation. Although modern graph-based approaches have progressively incorporated more structural information, they often fail to capture long-term atomic interactions due to finite receptive fields and local encoding schemes. This limitation leads to distinct crystals being mapped to identical representations, hindering accurate property prediction. To address this, we introduce PRDNet that leverages unique reciprocal-space diffraction besides graph representations. To enhance sensitivity to elemental and environmental variations, we employ a data-driven pseudo-particle to generate a synthetic diffraction pattern. PRDNet ensures full invariance to crystallographic symmetries. Extensive experiments are conducted on Materials Project, JARVIS-DFT, and MatBench, demonstrating that the proposed model achieves state-of-the-art performance.",
        "subjects": "Materials Science, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.040072"
    },
    {
        "index": "#189",
        "title": "Backdoor Attribution: Elucidating and Controlling Backdoor in Language Models",
        "link": "/arxiv/2509.21761",
        "arxiv_id": "2509.21761",
        "authors": "Miao Yu, Zhenhong Zhou, Moayad Aloqaily, Kun Wang, Biwei Huang, Stephen Wang, Yueming Jin, Qingsong Wen",
        "summary": "Fine-tuned Large Language Models (LLMs) are vulnerable to backdoor attacks through data poisoning, yet the internal mechanisms governing these attacks remain a black box. Previous research on interpretability for LLM safety tends to focus on alignment, jailbreak, and hallucination, but overlooks backdoor mechanisms, making it difficult to understand and fully eliminate the backdoor threat. In this paper, aiming to bridge this gap, we explore the interpretable mechanisms of LLM backdoors through Backdoor Attribution (BkdAttr), a tripartite causal analysis framework. We first introduce the Backdoor Probe that proves the existence of learnable backdoor features encoded within the representations. Building on this insight, we further develop Backdoor Attention Head Attribution (BAHA), efficiently pinpointing the specific attention heads responsible for processing these features. Our primary experiments reveals these heads are relatively sparse; ablating a minimal \\textbf{$\\sim$ 3%} of total heads is sufficient to reduce the Attack Success Rate (ASR) by \\textbf{over 90%}. More importantly, we further employ these findings to construct the Backdoor Vector derived from these attributed heads as a master controller for the backdoor. Through only \\textbf{1-point} intervention on \\textbf{single} representation, the vector can either boost ASR up to \\textbf{$\\sim$ 100% ($\\uparrow$)} on clean inputs, or completely neutralize backdoor, suppressing ASR down to \\textbf{$\\sim$ 0% ($\\downarrow$)} on triggered inputs. In conclusion, our work pioneers the exploration of mechanistic interpretability in LLM backdoors, demonstrating a powerful method for backdoor control and revealing actionable insights for the community.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.040582"
    },
    {
        "index": "#190",
        "title": "SubZeroCore: A Submodular Approach with Zero Training for Coreset Selection",
        "link": "/arxiv/2509.21748",
        "arxiv_id": "2509.21748",
        "authors": "Brian B. Moser, Tobias C. Nauen, Arundhati S. Shanbhag, Federico Raue, Stanislav Frolov, Joachim Folz, Andreas Dengel",
        "summary": "The goal of coreset selection is to identify representative subsets of datasets for efficient model training. Yet, existing approaches paradoxically require expensive training-based signals, e.g., gradients, decision boundary estimates or forgetting counts, computed over the entire dataset prior to pruning, which undermines their very purpose by requiring training on samples they aim to avoid. We introduce SubZeroCore, a novel, training-free coreset selection method that integrates submodular coverage and density into a single, unified objective. To achieve this, we introduce a sampling strategy based on a closed-form solution to optimally balance these objectives, guided by a single hyperparameter that explicitly controls the desired coverage for local density measures. Despite no training, extensive evaluations show that SubZeroCore matches training-based baselines and significantly outperforms them at high pruning rates, while dramatically reducing computational overhead. SubZeroCore also demonstrates superior robustness to label noise, highlighting its practical effectiveness and scalability for real-world scenarios.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.046276"
    },
    {
        "index": "#191",
        "title": "HyperCore: Coreset Selection under Noise via Hypersphere Models",
        "link": "/arxiv/2509.21746",
        "arxiv_id": "2509.21746",
        "authors": "Brian B. Moser, Arundhati S. Shanbhag, Tobias C. Nauen, Stanislav Frolov, Federico Raue, Joachim Folz, Andreas Dengel",
        "summary": "The goal of coreset selection methods is to identify representative subsets of datasets for efficient model training. Yet, existing methods often ignore the possibility of annotation errors and require fixed pruning ratios, making them impractical in real-world settings. We present HyperCore, a robust and adaptive coreset selection framework designed explicitly for noisy environments. HyperCore leverages lightweight hypersphere models learned per class, embedding in-class samples close to a hypersphere center while naturally segregating out-of-class samples based on their distance. By using Youden's J statistic, HyperCore can adaptively select pruning thresholds, enabling automatic, noise-aware data pruning without hyperparameter tuning. Our experiments reveal that HyperCore consistently surpasses state-of-the-art coreset selection methods, especially under noisy and low-data regimes. HyperCore effectively discards mislabeled and ambiguous points, yielding compact yet highly informative subsets suitable for scalable and noise-free learning.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.046806"
    },
    {
        "index": "#192",
        "title": "Brain PathoGraph Learning",
        "link": "/arxiv/2509.21742",
        "arxiv_id": "2509.21742",
        "authors": "Ciyuan Peng, Nguyen Linh Dan Le, Shan Jin, Dexuan Ding, Shuo Yu, Feng Xia",
        "summary": "Brain graph learning has demonstrated significant achievements in the fields of neuroscience and artificial intelligence. However, existing methods struggle to selectively learn disease-related knowledge, leading to heavy parameters and computational costs. This challenge diminishes their efficiency, as well as limits their practicality for real-world clinical applications. To this end, we propose a lightweight Brain PathoGraph Learning (BrainPoG) model that enables efficient brain graph learning by pathological pattern filtering and pathological feature distillation. Specifically, BrainPoG first contains a filter to extract the pathological pattern formulated by highly disease-relevant subgraphs, achieving graph pruning and lesion localization. A PathoGraph is therefore constructed by dropping less disease-relevant subgraphs from the whole brain graph. Afterwards, a pathological feature distillation module is designed to reduce disease-irrelevant noise features and enhance pathological features of each node in the PathoGraph. BrainPoG can exclusively learn informative disease-related knowledge while avoiding less relevant information, achieving efficient brain graph learning. Extensive experiments on four benchmark datasets demonstrate that BrainPoG exhibits superiority in both model performance and computational efficiency across various brain disease detection tasks.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.047310"
    },
    {
        "index": "#195",
        "title": "POLO: Preference-Guided Multi-Turn Reinforcement Learning for Lead Optimization",
        "link": "/arxiv/2509.21737",
        "arxiv_id": "2509.21737",
        "authors": "Ziqing Wang, Yibo Wen, William Pattie, Xiao Luo, Weimin Wu, Jerry Yao-Chieh Hu, Abhishek Pandey, Han Liu, Kaize Ding",
        "summary": "Lead optimization in drug discovery requires efficiently navigating vast chemical space through iterative cycles to enhance molecular properties while preserving structural similarity to the original lead compound. Despite recent advances, traditional optimization methods struggle with sample efficiency-achieving good optimization performance with limited oracle evaluations. Large Language Models (LLMs) provide a promising approach through their in-context learning and instruction following capabilities, which align naturally with these iterative processes. However, existing LLM-based methods fail to leverage this strength, treating each optimization step independently. To address this, we present POLO (Preference-guided multi-turn Optimization for Lead Optimization), which enables LLMs to learn from complete optimization trajectories rather than isolated steps. At its core, POLO introduces Preference-Guided Policy Optimization (PGPO), a novel reinforcement learning algorithm that extracts learning signals at two complementary levels: trajectory-level optimization reinforces successful strategies, while turn-level preference learning provides dense comparative feedback by ranking intermediate molecules within each trajectory. Through this dual-level learning from intermediate evaluation, POLO achieves superior sample efficiency by fully exploiting each costly oracle call. Extensive experiments demonstrate that POLO achieves 84% average success rate on single-property tasks (2.3x better than baselines) and 50% on multi-property tasks using only 500 oracle evaluations, significantly advancing the state-of-the-art in sample-efficient molecular optimization.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.048849"
    },
    {
        "index": "#196",
        "title": "Uncovering Alzheimer's Disease Progression via SDE-based Spatio-Temporal Graph Deep Learning on Longitudinal Brain Networks",
        "link": "/arxiv/2509.21735",
        "arxiv_id": "2509.21735",
        "authors": "Houliang Zhou, Rong Zhou, Yangying Liu, Kanhao Zhao, Li Shen, Brian Y. Chen, Yu Zhang, Lifang He, Alzheimer's Disease Neuroimaging Initiative",
        "summary": "Identifying objective neuroimaging biomarkers to forecast Alzheimer's disease (AD) progression is crucial for timely intervention. However, this task remains challenging due to the complex dysfunctions in the spatio-temporal characteristics of underlying brain networks, which are often overlooked by existing methods. To address these limitations, we develop an interpretable spatio-temporal graph neural network framework to predict future AD progression, leveraging dual Stochastic Differential Equations (SDEs) to model the irregularly-sampled longitudinal functional magnetic resonance imaging (fMRI) data. We validate our approach on two independent cohorts, including the Open Access Series of Imaging Studies (OASIS-3) and the Alzheimer's Disease Neuroimaging Initiative (ADNI). Our framework effectively learns sparse regional and connective importance probabilities, enabling the identification of key brain circuit abnormalities associated with disease progression. Notably, we detect the parahippocampal cortex, prefrontal cortex, and parietal lobule as salient regions, with significant disruptions in the ventral attention, dorsal attention, and default mode networks. These abnormalities correlate strongly with longitudinal AD-related clinical symptoms. Moreover, our interpretability strategy reveals both established and novel neural systems-level and sex-specific biomarkers, offering new insights into the neurobiological mechanisms underlying AD progression. Our findings highlight the potential of spatio-temporal graph-based learning for early, individualized prediction of AD progression, even in the context of irregularly-sampled longitudinal imaging data.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.049391"
    },
    {
        "index": "#198",
        "title": "Developing Strategies to Increase Capacity in AI Education",
        "link": "/arxiv/2509.21713",
        "arxiv_id": "2509.21713",
        "authors": "Noah Q. Cowit, Sri Yash Tadimalla, Stephanie T. Jones, Mary Lou Maher, Tracy Camp, Enrico Pontelli",
        "summary": "Many institutions are currently grappling with teaching artificial intelligence (AI) in the face of growing demand and relevance in our world. The Computing Research Association (CRA) has conducted 32 moderated virtual roundtable discussions of 202 experts committed to improving AI education. These discussions slot into four focus areas: AI Knowledge Areas and Pedagogy, Infrastructure Challenges in AI Education, Strategies to Increase Capacity in AI Education, and AI Education for All. Roundtables were organized around institution type to consider the particular goals and resources of different AI education environments. We identified the following high-level community needs to increase capacity in AI education. A significant digital divide creates major infrastructure hurdles, especially for smaller and under-resourced institutions. These challenges manifest as a shortage of faculty with AI expertise, who also face limited time for reskilling; a lack of computational infrastructure for students and faculty to develop and test AI models; and insufficient institutional technical support. Compounding these issues is the large burden associated with updating curricula and creating new programs. To address the faculty gap, accessible and continuous professional development is crucial for faculty to learn about AI and its ethical dimensions. This support is particularly needed for under-resourced institutions and must extend to faculty both within and outside of computing programs to ensure all students have access to AI education. We have compiled and organized a list of resources that our participant experts mentioned throughout this study. These resources contribute to a frequent request heard during the roundtables: a central repository of AI education resources for institutions to freely use across higher education.",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.050512"
    },
    {
        "index": "#199",
        "title": "Not My Agent, Not My Boundary? Elicitation of Personal Privacy Boundaries in AI-Delegated Information Sharing",
        "link": "/arxiv/2509.21712",
        "arxiv_id": "2509.21712",
        "authors": "Bingcan Guo, Eryue Xu, Zhiping Zhang, Tianshi Li",
        "summary": "Aligning AI systems with human privacy preferences requires understanding individuals' nuanced disclosure behaviors beyond general norms. Yet eliciting such boundaries remains challenging due to the context-dependent nature of privacy decisions and the complex trade-offs involved. We present an AI-powered elicitation approach that probes individuals' privacy boundaries through a discriminative task. We conducted a between-subjects study that systematically varied communication roles and delegation conditions, resulting in 1,681 boundary specifications from 169 participants for 61 scenarios. We examined how these contextual factors and individual differences influence the boundary specification. Quantitative results show that communication roles influence individuals' acceptance of detailed and identifiable disclosure, AI delegation and individuals' need for privacy heighten sensitivity to disclosed identifiers, and AI delegation results in less consensus across individuals. Our findings highlight the importance of situating privacy preference elicitation within real-world data flows. We advocate using nuanced privacy boundaries as an alignment goal for future AI systems.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.056164"
    },
    {
        "index": "#200",
        "title": "Optimizing the non-Clifford-count in unitary synthesis using Reinforcement Learning",
        "link": "/arxiv/2509.21709",
        "arxiv_id": "2509.21709",
        "authors": "David Kremer, Ali Javadi-Abhari, Priyanka Mukhopadhyay",
        "summary": "An efficient implementation of unitary operators is important in order to practically realize the computational advantages claimed by quantum algorithms over their classical counterparts. In this paper we study the potential of using reinforcement learning (RL) in order to synthesize quantum circuits, while optimizing the T-count and CS-count, of unitaries that are exactly implementable by the Clifford+T and Clifford+CS gate sets, respectively. In general, the complexity of existing algorithms depend exponentially on the number of qubits and the non-Clifford-count of unitaries. We have designed our RL framework to work with channel representation of unitaries, that enables us to perform matrix operations efficiently, using integers only. We have also incorporated pruning heuristics and a canonicalization of operators, in order to reduce the search complexity. As a result, compared to previous works, we are able to implement significantly larger unitaries, in less time, with much better success rate and improvement factor. Our results for Clifford+T synthesis on two qubits achieve close-to-optimal decompositions for up to 100 T gates, 5 times more than previous RL algorithms and to the best of our knowledge, the largest instances achieved with any method to date. Our RL algorithm is able to recover previously-known optimal linear complexity algorithm for T-count-optimal decomposition of 1 qubit unitaries. For 2-qubit Clifford+CS unitaries, our algorithm achieves a linear complexity, something that could only be accomplished by a previous algorithm using $SO(6)$ representation.",
        "subjects": "Quantum Physics, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.056883"
    },
    {
        "index": "#201",
        "title": "QueryGym: Step-by-Step Interaction with Relational Databases",
        "link": "/arxiv/2509.21674",
        "arxiv_id": "2509.21674",
        "authors": "Haritha Ananthakrishanan, Harsha Kokel, Kelsey Sikes, Debarun Bhattacharjya, Michael Katz, Shirin Sohrabi, Kavitha Srinivas",
        "summary": "We introduce QueryGym, an interactive environment for building, testing, and evaluating LLM-based query planning agents. Existing frameworks often tie agents to specific query language dialects or obscure their reasoning; QueryGym instead requires agents to construct explicit sequences of relational algebra operations, ensuring engine-agnostic evaluation and transparent step-by-step planning. The environment is implemented as a Gymnasium interface that supplies observations -- including schema details, intermediate results, and execution feedback -- and receives actions that represent database exploration (e.g., previewing tables, sampling column values, retrieving unique values) as well as relational algebra operations (e.g., filter, project, join). We detail the motivation and the design of the environment. In the demo, we showcase the utility of the environment by contrasting it with contemporary LLMs that query databases. QueryGym serves as a practical testbed for research in error remediation, transparency, and reinforcement learning for query generation. For the associated demo, see https://ibm.biz/QueryGym.",
        "subjects": "Databases, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.057436"
    },
    {
        "index": "#202",
        "title": "SlotFM: A Motion Foundation Model with Slot Attention for Diverse Downstream Tasks",
        "link": "/arxiv/2509.21673",
        "arxiv_id": "2509.21673",
        "authors": "Junyong Park, Oron Levy, Rebecca Adaimi, Asaf Liberman, Gierad Laput, Abdelkareem Bedri",
        "summary": "Wearable accelerometers are used for a wide range of applications, such as gesture recognition, gait analysis, and sports monitoring. Yet most existing foundation models focus primarily on classifying common daily activities such as locomotion and exercise, limiting their applicability to the broader range of tasks that rely on other signal characteristics. We present SlotFM, an accelerometer foundation model that generalizes across diverse downstream tasks. SlotFM uses Time-Frequency Slot Attention, an extension of Slot Attention that processes both time and frequency representations of the raw signals. It generates multiple small embeddings (slots), each capturing different signal components, enabling task-specific heads to focus on the most relevant parts of the data. We also introduce two loss regularizers that capture local structure and frequency patterns, which improve reconstruction of fine-grained details and helps the embeddings preserve task-relevant information. We evaluate SlotFM on 16 classification and regression downstream tasks that extend beyond standard human activity recognition. It outperforms existing self-supervised approaches on 13 of these tasks and achieves comparable results to the best performing approaches on the remaining tasks. On average, our method yields a 4.5% performance gain, demonstrating strong generalization for sensing foundation models.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.057966"
    },
    {
        "index": "#204",
        "title": "DIM: Enforcing Domain-Informed Monotonicity in Deep Neural Networks",
        "link": "/arxiv/2509.21666",
        "arxiv_id": "2509.21666",
        "authors": "Joshua Salim, Jordan Yu, Xilei Zhao",
        "summary": "While deep learning models excel at predictive tasks, they often overfit due to their complex structure and large number of parameters, causing them to memorize training data, including noise, rather than learn patterns that generalize to new data. To tackle this challenge, this paper proposes a new regularization method, i.e., Enforcing Domain-Informed Monotonicity in Deep Neural Networks (DIM), which maintains domain-informed monotonic relationships in complex deep learning models to further improve predictions. Specifically, our method enforces monotonicity by penalizing violations relative to a linear baseline, effectively encouraging the model to follow expected trends while preserving its predictive power. We formalize this approach through a comprehensive mathematical framework that establishes a linear reference, measures deviations from monotonic behavior, and integrates these measurements into the training objective. We test and validate the proposed methodology using a real-world ridesourcing dataset from Chicago and a synthetically created dataset. Experiments across various neural network architectures show that even modest monotonicity constraints consistently enhance model performance. DIM enhances the predictive performance of deep neural networks by applying domain-informed monotonicity constraints to regularize model behavior and mitigate overfitting",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.059041"
    },
    {
        "index": "#205",
        "title": "Logic of Hypotheses: from Zero to Full Knowledge in Neurosymbolic Integration",
        "link": "/arxiv/2509.21663",
        "arxiv_id": "2509.21663",
        "authors": "Davide Bizzaro, Alessandro Daniele",
        "summary": "Neurosymbolic integration (NeSy) blends neural-network learning with symbolic reasoning. The field can be split between methods injecting hand-crafted rules into neural models, and methods inducing symbolic rules from data. We introduce Logic of Hypotheses (LoH), a novel language that unifies these strands, enabling the flexible integration of data-driven rule learning with symbolic priors and expert knowledge. LoH extends propositional logic syntax with a choice operator, which has learnable parameters and selects a subformula from a pool of options. Using fuzzy logic, formulas in LoH can be directly compiled into a differentiable computational graph, so the optimal choices can be learned via backpropagation. This framework subsumes some existing NeSy models, while adding the possibility of arbitrary degrees of knowledge specification. Moreover, the use of Goedel fuzzy logic and the recently developed Goedel trick yields models that can be discretized to hard Boolean-valued functions without any loss in performance. We provide experimental analysis on such models, showing strong results on tabular data and on the Visual Tic-Tac-Toe NeSy task, while producing interpretable decision rules.",
        "subjects": "Machine Learning, Artificial Intelligence, Logic in Computer Science",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.059542"
    },
    {
        "index": "#206",
        "title": "Limitations on Safe, Trusted, Artificial General Intelligence",
        "link": "/arxiv/2509.21654",
        "arxiv_id": "2509.21654",
        "authors": "Rina Panigrahy, Vatsal Sharan",
        "summary": "Safety, trust and Artificial General Intelligence (AGI) are aspirational goals in artificial intelligence (AI) systems, and there are several informal interpretations of these notions. In this paper, we propose strict, mathematical definitions of safety, trust, and AGI, and demonstrate a fundamental incompatibility between them. We define safety of a system as the property that it never makes any false claims, trust as the assumption that the system is safe, and AGI as the property of an AI system always matching or exceeding human capability. Our core finding is that -- for our formal definitions of these notions -- a safe and trusted AI system cannot be an AGI system: for such a safe, trusted system there are task instances which are easily and provably solvable by a human but not by the system. We note that we consider strict mathematical definitions of safety and trust, and it is possible for real-world deployments to instead rely on alternate, practical interpretations of these notions. We show our results for program verification, planning, and graph reachability. Our proofs draw parallels to Gödel's incompleteness theorems and Turing's proof of the undecidability of the halting problem, and can be regarded as interpretations of Gödel's and Turing's results.",
        "subjects": "Machine Learning, Artificial Intelligence, Computational Complexity",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.060072"
    },
    {
        "index": "#207",
        "title": "MobiLLM: An Agentic AI Framework for Closed-Loop Threat Mitigation in 6G Open RANs",
        "link": "/arxiv/2509.21634",
        "arxiv_id": "2509.21634",
        "authors": "Prakhar Sharma, Haohuang Wen, Vinod Yegneswaran, Ashish Gehani, Phillip Porras, Zhiqiang Lin",
        "summary": "The evolution toward 6G networks is being accelerated by the Open Radio Access Network (O-RAN) paradigm -- an open, interoperable architecture that enables intelligent, modular applications across public telecom and private enterprise domains. While this openness creates unprecedented opportunities for innovation, it also expands the attack surface, demanding resilient, low-cost, and autonomous security solutions. Legacy defenses remain largely reactive, labor-intensive, and inadequate for the scale and complexity of next-generation systems. Current O-RAN applications focus mainly on network optimization or passive threat detection, with limited capability for closed-loop, automated response. To address this critical gap, we present an agentic AI framework for fully automated, end-to-end threat mitigation in 6G O-RAN environments. MobiLLM orchestrates security workflows through a modular multi-agent system powered by Large Language Models (LLMs). The framework features a Threat Analysis Agent for real-time data triage, a Threat Classification Agent that uses Retrieval-Augmented Generation (RAG) to map anomalies to specific countermeasures, and a Threat Response Agent that safely operationalizes mitigation actions via O-RAN control interfaces. Grounded in trusted knowledge bases such as the MITRE FiGHT framework and 3GPP specifications, and equipped with robust safety guardrails, MobiLLM provides a blueprint for trustworthy AI-driven network security. Initial evaluations demonstrate that MobiLLM can effectively identify and orchestrate complex mitigation strategies, significantly reducing response latency and showcasing the feasibility of autonomous security operations in 6G.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning, Networking and Internet Architecture",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.060644"
    },
    {
        "index": "#210",
        "title": "Guiding Audio Editing with Audio Language Model",
        "link": "/arxiv/2509.21625",
        "arxiv_id": "2509.21625",
        "authors": "Zitong Lan, Yiduo Hao, Mingmin Zhao",
        "summary": "Audio editing plays a central role in VR/AR immersion, virtual conferencing, sound design, and other interactive media. However, recent generative audio editing models depend on template-like instruction formats and are restricted to mono-channel audio. These models fail to deal with declarative audio editing, where the user declares what the desired outcome should be, while leaving the details of editing operations to the system. We introduce SmartDJ, a novel framework for stereo audio editing that combines the reasoning capability of audio language models with the generative power of latent diffusion. Given a high-level instruction, SmartDJ decomposes it into a sequence of atomic edit operations, such as adding, removing, or spatially relocating events. These operations are then executed by a diffusion model trained to manipulate stereo audio. To support this, we design a data synthesis pipeline that produces paired examples of high-level instructions, atomic edit operations, and audios before and after each edit operation. Experiments demonstrate that SmartDJ achieves superior perceptual quality, spatial realism, and semantic alignment compared to prior audio editing methods. Demos are available at https://zitonglan.github.io/project/smartdj/smartdj.html.",
        "subjects": "Sound, Artificial Intelligence, Machine Learning, Audio and Speech Processing",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.067397"
    },
    {
        "index": "#212",
        "title": "LANCE: Low Rank Activation Compression for Efficient On-Device Continual Learning",
        "link": "/arxiv/2509.21617",
        "arxiv_id": "2509.21617",
        "authors": "Marco Paul E. Apolinario, Kaushik Roy",
        "summary": "On-device learning is essential for personalization, privacy, and long-term adaptation in resource-constrained environments. Achieving this requires efficient learning, both fine-tuning existing models and continually acquiring new tasks without catastrophic forgetting. Yet both settings are constrained by high memory cost of storing activations during backpropagation. Existing activation compression methods reduce this cost but relying on repeated low-rank decompositions, introducing computational overhead. Also, such methods have not been explored for continual learning. We propose LANCE (Low-rank Activation Compression), a framework that performs one-shot higher-order Singular Value Decompsoition (SVD) to obtain a reusable low-rank subspace for activation projection. This eliminates repeated decompositions, reducing both memory and computation. Moreover, fixed low-rank subspaces further enable on-device continual learning by allocating tasks to orthogonal subspaces without storing large task-specific matrices. Experiments show that LANCE reduces activation storage up to 250$\\times$ while maintaining accuracy comparable to full backpropagation on CIFAR-10/100, Oxford-IIIT Pets, Flowers102, and CUB-200 datasets. On continual learning benchmarks (Split CIFAR-100, Split MiniImageNet, 5-Datasets), it achieves performance competitive with orthogonal gradient projection methods at a fraction of the memory cost. These results position LANCE as a practical and scalable solution for efficient fine-tuning and continual learning on edge devices.",
        "subjects": "Machine Learning, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.068471"
    },
    {
        "index": "#219",
        "title": "Psychological and behavioural responses in human-agent vs. human-human interactions: a systematic review and meta-analysis",
        "link": "/arxiv/2509.21542",
        "arxiv_id": "2509.21542",
        "authors": "Jianan Zhou, Fleur Corbett, Joori Byun, Talya Porat, Nejra van Zalk",
        "summary": "Interactive intelligent agents are being integrated across society. Despite achieving human-like capabilities, humans' responses to these agents remain poorly understood, with research fragmented across disciplines. We conducted a first systematic synthesis comparing a range of psychological and behavioural responses in matched human-agent vs. human-human dyadic interactions. A total of 162 eligible studies (146 contributed to the meta-analysis; 468 effect sizes) were included in the systematic review and meta-analysis, which integrated frequentist and Bayesian approaches. Our results indicate that individuals exhibited less prosocial behaviour and moral engagement when interacting with agents vs. humans. They attributed less agency and responsibility to agents, perceiving them as less competent, likeable, and socially present. In contrast, individuals' social alignment (i.e., alignment or adaptation of internal states and behaviours with partners), trust in partners, personal agency, task performance, and interaction experiences were generally comparable when interacting with agents vs. humans. We observed high effect-size heterogeneity for many subjective responses (i.e., social perceptions of partners, subjective trust, and interaction experiences), suggesting context-dependency of partner effects. By examining the characteristics of studies, participants, partners, interaction scenarios, and response measures, we also identified several moderators shaping partner effects. Overall, functional behaviours and interactive experiences with agents can resemble those with humans, whereas fundamental social attributions and moral/prosocial concerns lag in human-agent interactions. Agents are thus afforded instrumental value on par with humans but lack comparable intrinsic value, providing practical implications for agent design and regulation.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.077239"
    },
    {
        "index": "#221",
        "title": "Preemptive Detection and Steering of LLM Misalignment via Latent Reachability",
        "link": "/arxiv/2509.21528",
        "arxiv_id": "2509.21528",
        "authors": "Sathwik Karnik, Somil Bansal",
        "summary": "Large language models (LLMs) are now ubiquitous in everyday tools, raising urgent safety concerns about their tendency to generate harmful content. The dominant safety approach -- reinforcement learning from human feedback (RLHF) -- effectively shapes model behavior during training but offers no safeguards at inference time, where unsafe continuations may still arise. We propose BRT-Align, a reachability-based framework that brings control-theoretic safety tools to LLM inference. BRT-Align models autoregressive generation as a dynamical system in latent space and learn a safety value function via backward reachability, estimating the worst-case evolution of a trajectory. This enables two complementary mechanisms: (1) a runtime monitor that forecasts unsafe completions several tokens in advance, and (2) a least-restrictive steering filter that minimally perturbs latent states to redirect generation away from unsafe regions. Experiments across multiple LLMs and toxicity benchmarks demonstrate that BRT-Align provides more accurate and earlier detection of unsafe continuations than baselines. Moreover, for LLM safety alignment, BRT-Align substantially reduces unsafe generations while preserving sentence diversity and coherence. Qualitative results further highlight emergent alignment properties: BRT-Align consistently produces responses that are less violent, less profane, less offensive, and less politically biased. Together, these findings demonstrate that reachability analysis provides a principled and practical foundation for inference-time LLM safety.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.078247"
    },
    {
        "index": "#222",
        "title": "Shortcut Flow Matching for Speech Enhancement: Step-Invariant flows via single stage training",
        "link": "/arxiv/2509.21522",
        "arxiv_id": "2509.21522",
        "authors": "Naisong Zhou, Saisamarth Rajesh Phaye, Milos Cernak, Tijana Stojkovic, Andy Pearce, Andrea Cavallaro, Andy Harper",
        "summary": "Diffusion-based generative models have achieved state-of-the-art performance for perceptual quality in speech enhancement (SE). However, their iterative nature requires numerous Neural Function Evaluations (NFEs), posing a challenge for real-time applications. On the contrary, flow matching offers a more efficient alternative by learning a direct vector field, enabling high-quality synthesis in just a few steps using deterministic ordinary differential equation~(ODE) solvers. We thus introduce Shortcut Flow Matching for Speech Enhancement (SFMSE), a novel approach that trains a single, step-invariant model. By conditioning the velocity field on the target time step during a one-stage training process, SFMSE can perform single, few, or multi-step denoising without any architectural changes or fine-tuning. Our results demonstrate that a single-step SFMSE inference achieves a real-time factor (RTF) of 0.013 on a consumer GPU while delivering perceptual quality comparable to a strong diffusion baseline requiring 60 NFEs. This work also provides an empirical analysis of the role of stochasticity in training and inference, bridging the gap between high-quality generative SE and low-latency constraints.",
        "subjects": "Sound, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.078787"
    },
    {
        "index": "#223",
        "title": "$\\mathbf{Li_2}$: A Framework on Dynamics of Feature Emergence and Delayed Generalization",
        "link": "/arxiv/2509.21519",
        "arxiv_id": "2509.21519",
        "authors": "Yuandong Tian",
        "summary": "While the phenomenon of grokking, i.e., delayed generalization, has been studied extensively, it remains an open question whether there is a mathematical framework to characterize what kind of features emerge, how and in which conditions it happens from training, for complex structured inputs. We propose a novel framework, named $\\mathbf{Li_2}$, that captures three key stages for the grokking behavior of 2-layer nonlinear networks: (I) Lazy learning, (II) independent feature learning and (III) interactive feature learning, characterized by the structure of backpropagated gradient $G_F$ across layers. In (I), $G_F$ is random, and top layer overfits to random hidden representation. In (II), the gradient of each node (column of $G_F$) only depends on its own activation, and thus each hidden node learns their representation independently from $G_F$, which now carries information about target labels, thanks to weight decay. Interestingly, the independent dynamics follows exactly the gradient ascent of an energy function $E$, and its local maxima are precisely the emerging features. We study whether these local-optima induced features are generalizable, their representation power, and how they change on sample size, in group arithmetic tasks. Finally, in (III), we provably show how hidden nodes interact, and how $G_F$ changes to focus on missing features that need to be learned. Our study sheds lights on roles played by key hyperparameters such as weight decay, learning rate and sample sizes in grokking, leads to provable scaling laws of memorization and generalization, and reveals the underlying cause why recent optimizers such as Muon can be effective, from the first principles of gradient dynamics. Our analysis can be extended to multi-layer architectures.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.079244"
    },
    {
        "index": "#225",
        "title": "New Algorithmic Directions in Optimal Transport and Applications for Product Spaces",
        "link": "/arxiv/2509.21502",
        "arxiv_id": "2509.21502",
        "authors": "Salman Beigi, Omid Etesami, Mohammad Mahmoody, Amir Najafi",
        "summary": "We study optimal transport between two high-dimensional distributions $\\mu,\\nu$ in $R^n$ from an algorithmic perspective: given $x \\sim \\mu$, find a close $y \\sim \\nu$ in $poly(n)$ time, where $n$ is the dimension of $x,y$. Thus, running time depends on the dimension rather than the full representation size of $\\mu,\\nu$. Our main result is a general algorithm for transporting any product distribution $\\mu$ to any $\\nu$ with cost $\\Delta + \\delta$ under $\\ell_p^p$, where $\\Delta$ is the Knothe-Rosenblatt transport cost and $\\delta$ is a computational error decreasing with runtime. This requires $\\nu$ to be \"sequentially samplable\" with bounded average sampling cost, a new but natural notion. We further prove: An algorithmic version of Talagrand's inequality for transporting the standard Gaussian $\\Phi^n$ to arbitrary $\\nu$ under squared Euclidean cost. For $\\nu = \\Phi^n$ conditioned on a set $\\mathcal{S}$ of measure $\\varepsilon$, we construct the sequential sampler in expected time $poly(n/\\varepsilon)$ using membership oracle access to $\\mathcal{S}$. This yields an algorithmic transport from $\\Phi^n$ to $\\Phi^n|\\mathcal{S}$ in $poly(n/\\varepsilon)$ time and expected squared distance $O(\\log 1/\\varepsilon)$, optimal for general $\\mathcal{S}$ of measure $\\varepsilon$. As corollary, we obtain the first computational concentration result (Etesami et al. SODA 2020) for Gaussian measure under Euclidean distance with dimension-independent transportation cost, resolving an open question of Etesami et al. Specifically, for any $\\mathcal{S}$ of Gaussian measure $\\varepsilon$, most $\\Phi^n$ samples can be mapped to $\\mathcal{S}$ within distance $O(\\sqrt{\\log 1/\\varepsilon})$ in $poly(n/\\varepsilon)$ time.",
        "subjects": "Data Structures and Algorithms, Artificial Intelligence, Information Theory, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.080357"
    },
    {
        "index": "#226",
        "title": "Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training",
        "link": "/arxiv/2509.21500",
        "arxiv_id": "2509.21500",
        "authors": "Junkai Zhang, Zihao Wang, Lin Gui, Swarnashree Mysore Sathyendra, Jaehwan Jeong, Victor Veitch, Wei Wang, Yunzhong He, Bing Liu, Lifeng Jin",
        "summary": "Reinforcement fine-tuning (RFT) often suffers from \\emph{reward over-optimization}, where a policy model hacks the reward signals to achieve high scores while producing low-quality outputs. Our theoretical analysis shows that the key lies in reward misspecification at the high-reward tail: the inability to reliably distinguish Excellent responses from merely Great ones. This motivate us to focus on the high-reward region. However, such tail examples are scarce under the base LLM. While off-policy exemplars (e.g. from stronger models or rewrites) are easier to obtain, naively training on them yields a misspecified reward for the policy we aim to align. To address this, we study rubric-based rewards. By design, rubrics can leverage off-policy examples while remaining insensitive to their artifacts. To elicit rubrics that capture the high-reward tail, we highlight the importance of distinguishing among great and diverse responses, and introduce a workflow to implement this idea. We empirically demonstrate that rubric-based rewards substantially mitigate reward over-optimization and deliver effective LLM post-training improvements. Our code can be accessed at https://github.com/Jun-Kai-Zhang/rubrics.git .",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.080939"
    },
    {
        "index": "#228",
        "title": "Neural Operators for Mathematical Modeling of Transient Fluid Flow in Subsurface Reservoir Systems",
        "link": "/arxiv/2509.21485",
        "arxiv_id": "2509.21485",
        "authors": "Daniil D. Sirota, Sergey A. Khan, Sergey L. Kostikov, Kirill A. Butov",
        "summary": "This paper presents a method for modeling transient fluid flow in subsurface reservoir systems based on the developed neural operator architecture (TFNO-opt). Reservoir systems are complex dynamic objects with distributed parameters described by systems of partial differential equations (PDEs). Traditional numerical methods for modeling such systems, despite their high accuracy, are characterized by significant time costs for performing calculations, which limits their applicability in control and decision support problems. The proposed architecture (TFNO-opt) is based on Fourier neural operators, which allow approximating PDE solutions in infinite-dimensional functional spaces, providing invariance to discretization and the possibility of generalization to various implementations of equations. The developed modifications are aimed at increasing the accuracy and stability of the trained neural operator, which is especially important for control problems. These include adjustable internal time resolution of the integral Fourier operator, tensor decomposition of parameters in the spectral domain, use of the Sobolev norm in the error function, and separation of approximation errors and reconstruction of initial conditions for more accurate reproduction of physical processes. The effectiveness of the proposed improvements is confirmed by computational experiments. The practical significance is confirmed by computational experiments using the example of the problem of hydrodynamic modeling of an underground gas storage (UGS), where the acceleration of calculations by six orders of magnitude was achieved, compared to traditional methods. This opens up new opportunities for the effective control of complex reservoir systems.",
        "subjects": "Machine Learning, Artificial Intelligence, Fluid Dynamics, Geophysics",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.087159"
    },
    {
        "index": "#231",
        "title": "Score-based Idempotent Distillation of Diffusion Models",
        "link": "/arxiv/2509.21470",
        "arxiv_id": "2509.21470",
        "authors": "Shehtab Zaman, Chengyan Liu, Kenneth Chiu",
        "summary": "Idempotent generative networks (IGNs) are a new line of generative models based on idempotent mapping to a target manifold. IGNs support both single-and multi-step generation, allowing for a flexible trade-off between computational cost and sample quality. But similar to Generative Adversarial Networks (GANs), conventional IGNs require adversarial training and are prone to training instabilities and mode collapse. Diffusion and score-based models are popular approaches to generative modeling that iteratively transport samples from one distribution, usually a Gaussian, to a target data distribution. These models have gained popularity due to their stable training dynamics and high-fidelity generation quality. However, this stability and quality come at the cost of high computational cost, as the data must be transported incrementally along the entire trajectory. New sampling methods, model distillation, and consistency models have been developed to reduce the sampling cost and even perform one-shot sampling from diffusion models. In this work, we unite diffusion and IGNs by distilling idempotent models from diffusion model scores, called SIGN. Our proposed method is highly stable and does not require adversarial losses. We provide a theoretical analysis of our proposed score-based training methods and empirically show that IGNs can be effectively distilled from a pre-trained diffusion model, enabling faster inference than iterative score-based models. SIGNs can perform multi-step sampling, allowing users to trade off quality for efficiency. These models operate directly on the source domain; they can project corrupted or alternate distributions back onto the target manifold, enabling zero-shot editing of inputs. We validate our models on multiple image datasets, achieving state-of-the-art results for idempotent models on the CIFAR and CelebA datasets.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.088722"
    },
    {
        "index": "#233",
        "title": "Enhanced Generative Machine Listener",
        "link": "/arxiv/2509.21463",
        "arxiv_id": "2509.21463",
        "authors": "Vishnu Raj, Gouthaman KV, Shiv Gehlot, Lars Villemoes, Arijit Biswas",
        "summary": "We present GMLv2, a reference-based model designed for the prediction of subjective audio quality as measured by MUSHRA scores. GMLv2 introduces a Beta distribution-based loss to model the listener ratings and incorporates additional neural audio coding (NAC) subjective datasets to extend its generalization and applicability. Extensive evaluations on diverse testset demonstrate that proposed GMLv2 consistently outperforms widely used metrics, such as PEAQ and ViSQOL, both in terms of correlation with subjective scores and in reliably predicting these scores across diverse content types and codec configurations. Consequently, GMLv2 offers a scalable and automated framework for perceptual audio quality evaluation, poised to accelerate research and development in modern audio coding technologies.",
        "subjects": "Audio and Speech Processing, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.089756"
    },
    {
        "index": "#237",
        "title": "Foundation models for high-energy physics",
        "link": "/arxiv/2509.21434",
        "arxiv_id": "2509.21434",
        "authors": "Anna Hallin",
        "summary": "The rise of foundation models -- large, pretrained machine learning models that can be finetuned to a variety of tasks -- has revolutionized the fields of natural language processing and computer vision. In high-energy physics, the question of whether these models can be implemented directly in physics research, or even built from scratch, tailored for particle physics data, has generated an increasing amount of attention. This review, which is the first on the topic of foundation models in high-energy physics, summarizes and discusses the research that has been published in the field so far.",
        "subjects": "High Energy Physics - Phenomenology, Artificial Intelligence, Machine Learning, High Energy Physics - Experiment, Data Analysis, Statistics and Probability",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.097241"
    },
    {
        "index": "#239",
        "title": "PhenoMoler: Phenotype-Guided Molecular Optimization via Chemistry Large Language Model",
        "link": "/arxiv/2509.21424",
        "arxiv_id": "2509.21424",
        "authors": "Ran Song, Hui Liu",
        "summary": "Current molecular generative models primarily focus on improving drug-target binding affinity and specificity, often neglecting the system-level phenotypic effects elicited by compounds. Transcriptional profiles, as molecule-level readouts of drug-induced phenotypic shifts, offer a powerful opportunity to guide molecular design in a phenotype-aware manner. We present PhenoMoler, a phenotype-guided molecular generation framework that integrates a chemistry large language model with expression profiles to enable biologically informed drug design. By conditioning the generation on drug-induced differential expression signatures, PhenoMoler explicitly links transcriptional responses to chemical structure. By selectively masking and reconstructing specific substructures-scaffolds, side chains, or linkers-PhenoMoler supports fine-grained, controllable molecular optimization. Extensive experiments demonstrate that PhenoMoler generates chemically valid, novel, and diverse molecules aligned with desired phenotypic profiles. Compared to FDA-approved drugs, the generated compounds exhibit comparable or enhanced drug-likeness (QED), optimized physicochemical properties, and superior binding affinity to key cancer targets. These findings highlight PhenoMoler's potential for phenotype-guided and structure-controllable molecular optimization.",
        "subjects": "Chemical Physics, Artificial Intelligence",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.098229"
    },
    {
        "index": "#240",
        "title": "Near-Optimal Experiment Design in Linear non-Gaussian Cyclic Models",
        "link": "/arxiv/2509.21423",
        "arxiv_id": "2509.21423",
        "authors": "Ehsan Sharifian, Saber Salehkaleybar, Negar Kiyavash",
        "summary": "We study the problem of causal structure learning from a combination of observational and interventional data generated by a linear non-Gaussian structural equation model that might contain cycles. Recent results show that using mere observational data identifies the causal graph only up to a permutation-equivalence class. We obtain a combinatorial characterization of this class by showing that each graph in an equivalence class corresponds to a perfect matching in a bipartite graph. This bipartite representation allows us to analyze how interventions modify or constrain the matchings. Specifically, we show that each atomic intervention reveals one edge of the true matching and eliminates all incompatible causal graphs. Consequently, we formalize the optimal experiment design task as an adaptive stochastic optimization problem over the set of equivalence classes with a natural reward function that quantifies how many graphs are eliminated from the equivalence class by an intervention. We show that this reward function is adaptive submodular and provide a greedy policy with a provable near-optimal performance guarantee. A key technical challenge is to efficiently estimate the reward function without having to explicitly enumerate all the graphs in the equivalence class. We propose a sampling-based estimator using random matchings and analyze its bias and concentration behavior. Our simulation results show that performing a small number of interventions guided by our stochastic optimization framework recovers the true underlying causal structure.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-09-25",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.098735"
    },
    {
        "index": "#243",
        "title": "MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering",
        "link": "/arxiv/2509.21391",
        "arxiv_id": "2509.21391",
        "authors": "Lihui Liu, Carl J. Yang",
        "summary": "Large Language Models (LLMs) have achieved impressive performance across a wide range of applications. However, they often suffer from hallucinations in knowledge-intensive domains due to their reliance on static pretraining corpora. To address this limitation, Retrieval-Augmented Generation (RAG) enhances LLMs by incorporating external knowledge sources during inference. Among these sources, textual graphs provide structured and semantically rich information that supports more precise and interpretable reasoning. This has led to growing interest in graph-based RAG systems. Despite their potential, most existing approaches rely on a single retriever to identify relevant subgraphs, which limits their ability to capture the diverse aspects of complex queries. Moreover, these systems often struggle to accurately judge the relevance of retrieved content, making them prone to distraction by irrelevant noise. To address these challenges, in this paper, we propose MIXRAG, a Mixture-of-Experts Graph-RAG framework that introduces multiple specialized graph retrievers and a dynamic routing controller to better handle diverse query intents. Each retriever is trained to focus on a specific aspect of graph semantics, such as entities, relations, or subgraph topology. A Mixture-of-Experts module adaptively selects and fuses relevant retrievers based on the input query. To reduce noise in the retrieved information, we introduce a query-aware GraphEncoder that carefully analyzes relationships within the retrieved subgraphs, highlighting the most relevant parts while down-weighting unnecessary noise. Empirical results demonstrate that our method achieves state-of-the-art performance and consistently outperforms various baselines. MIXRAG is effective across a wide range of graph-based tasks in different domains. The code will be released upon paper acceptance.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-09-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.100189"
    },
    {
        "index": "#244",
        "title": "Towards Adapting Federated & Quantum Machine Learning for Network Intrusion Detection: A Survey",
        "link": "/arxiv/2509.21389",
        "arxiv_id": "2509.21389",
        "authors": "Devashish Chaudhary, Sutharshan Rajasegarar, Shiva Raj Pokhrel",
        "summary": "This survey explores the integration of Federated Learning (FL) with Network Intrusion Detection Systems (NIDS), with particular emphasis on deep learning and quantum machine learning approaches. FL enables collaborative model training across distributed devices while preserving data privacy-a critical requirement in network security contexts where sensitive traffic data cannot be centralized. Our comprehensive analysis systematically examines the full spectrum of FL architectures, deployment strategies, communication protocols, and aggregation methods specifically tailored for intrusion detection. We provide an in-depth investigation of privacy-preserving techniques, model compression approaches, and attack-specific federated solutions for threats including DDoS, MITM, and botnet attacks. The survey further delivers a pioneering exploration of Quantum FL (QFL), discussing quantum feature encoding, quantum machine learning algorithms, and quantum-specific aggregation methods that promise exponential speedups for complex pattern recognition in network traffic. Through rigorous comparative analysis of classical and quantum approaches, identification of research gaps, and evaluation of real-world deployments, we outline a concrete roadmap for industrial adoption and future research directions. This work serves as an authoritative reference for researchers and practitioners seeking to enhance privacy, efficiency, and robustness of federated intrusion detection systems in increasingly complex network environments, while preparing for the quantum-enhanced cybersecurity landscape of tomorrow.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.100679"
    },
    {
        "index": "#246",
        "title": "Toward a Realistic Encoding Model of Auditory Affective Understanding in the Brain",
        "link": "/arxiv/2509.21381",
        "arxiv_id": "2509.21381",
        "authors": "Guandong Pan, Yaqian Yang, Shi Chen, Xin Wang, Longzhao Liu, Hongwei Zheng, Shaoting Tang",
        "summary": "In affective neuroscience and emotion-aware AI, understanding how complex auditory stimuli drive emotion arousal dynamics remains unresolved. This study introduces a computational framework to model the brain's encoding of naturalistic auditory inputs into dynamic behavioral/neural responses across three datasets (SEED, LIRIS, self-collected BAVE). Guided by neurobiological principles of parallel auditory hierarchy, we decompose audio into multilevel auditory features (through classical algorithms and wav2vec 2.0/Hubert) from the original and isolated human voice/background soundtrack elements, mapping them to emotion-related responses via cross-dataset analyses. Our analysis reveals that high-level semantic representations (derived from the final layer of wav2vec 2.0/Hubert) exert a dominant role in emotion encoding, outperforming low-level acoustic features with significantly stronger mappings to behavioral annotations and dynamic neural synchrony across most brain regions ($p < 0.05$). Notably, middle layers of wav2vec 2.0/hubert (balancing acoustic-semantic information) surpass the final layers in emotion induction across datasets. Moreover, human voices and soundtracks show dataset-dependent emotion-evoking biases aligned with stimulus energy distribution (e.g., LIRIS favors soundtracks due to higher background energy), with neural analyses indicating voices dominate prefrontal/temporal activity while soundtracks excel in limbic regions. By integrating affective computing and neuroscience, this work uncovers hierarchical mechanisms of auditory-emotion encoding, providing a foundation for adaptive emotion-aware systems and cross-disciplinary explorations of audio-affective interactions.",
        "subjects": "Audio and Speech Processing, Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-09-23",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.101766"
    },
    {
        "index": "#253",
        "title": "Design and Implementation of a Secure RAG-Enhanced AI Chatbot for Smart Tourism Customer Service: Defending Against Prompt Injection Attacks -- A Case Study of Hsinchu, Taiwan",
        "link": "/arxiv/2509.21367",
        "arxiv_id": "2509.21367",
        "authors": "Yu-Kai Shih, You-Kai Kang",
        "summary": "As smart tourism evolves, AI-powered chatbots have become indispensable for delivering personalized, real-time assistance to travelers while promoting sustainability and efficiency. However, these systems are increasingly vulnerable to prompt injection attacks, where adversaries manipulate inputs to elicit unintended behaviors such as leaking sensitive information or generating harmful content. This paper presents a case study on the design and implementation of a secure retrieval-augmented generation (RAG) chatbot for Hsinchu smart tourism services. The system integrates RAG with API function calls, multi-layered linguistic analysis, and guardrails against injections, achieving high contextual awareness and security. Key features include a tiered response strategy, RAG-driven knowledge grounding, and intent decomposition across lexical, semantic, and pragmatic levels. Defense mechanisms include system norms, gatekeepers for intent judgment, and reverse RAG text to prioritize verified data. We also benchmark a GPT-5 variant (released 2025-08-07) to assess inherent robustness. Evaluations with 674 adversarial prompts and 223 benign queries show over 95% accuracy on benign tasks and substantial detection of injection attacks. GPT-5 blocked about 85% of attacks, showing progress yet highlighting the need for layered defenses. Findings emphasize contributions to sustainable tourism, multilingual accessibility, and ethical AI deployment. This work offers a practical framework for deploying secure chatbots in smart tourism and contributes to resilient, trustworthy AI applications.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-09-22",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.110443"
    },
    {
        "index": "#262",
        "title": "Domain-Informed Genetic Superposition Programming: A Case Study on SFRC Beams",
        "link": "/arxiv/2509.21355",
        "arxiv_id": "2509.21355",
        "authors": "Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Mohammad Reza Nikoo, Fang Chen, Amir H. Gandomi",
        "summary": "This study presents domain-informed genetic superposition programming (DIGSP), a symbolic regression framework tailored for engineering systems governed by separable physical mechanisms. DIGSP partitions the input space into domain-specific feature subsets and evolves independent genetic programming (GP) populations to model material-specific effects. Early evolution occurs in isolation, while ensemble fitness promotes inter-population cooperation. To enable symbolic superposition, an adaptive hierarchical symbolic abstraction mechanism (AHSAM) is triggered after stagnation across all populations. AHSAM performs analysis of variance- (ANOVA) based filtering to identify statistically significant individuals, compresses them into symbolic constructs, and injects them into all populations through a validation-guided pruning cycle. The DIGSP is benchmarked against a baseline multi-gene genetic programming (BGP) model using a dataset of steel fiber-reinforced concrete (SFRC) beams. Across 30 independent trials with 65% training, 10% validation, and 25% testing splits, DIGSP consistently outperformed BGP in training and test root mean squared error (RMSE). The Wilcoxon rank-sum test confirmed statistical significance (p < 0.01), and DIGSP showed tighter error distributions and fewer outliers. No significant difference was observed in validation RMSE due to limited sample size. These results demonstrate that domain-informed structural decomposition and symbolic abstraction improve convergence and generalization. DIGSP offers a principled and interpretable modeling strategy for systems where symbolic superposition aligns with the underlying physical structure.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence",
        "date": "2025-09-20",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.120297"
    },
    {
        "index": "#265",
        "title": "SGNNBench: A Holistic Evaluation of Spiking Graph Neural Network on Large-scale Graph",
        "link": "/arxiv/2509.21342",
        "arxiv_id": "2509.21342",
        "authors": "Huizhe Zhang, Jintang Li, Yuchang Zhu, Liang Chen, Li Kuang",
        "summary": "Graph Neural Networks (GNNs) are exemplary deep models designed for graph data. Message passing mechanism enables GNNs to effectively capture graph topology and push the performance boundaries across various graph tasks. However, the trend of developing such complex machinery for graph representation learning has become unsustainable on large-scale graphs. The computational and time overhead make it imperative to develop more energy-efficient GNNs to cope with the explosive growth of real-world graphs. Spiking Graph Neural Networks (SGNNs), which integrate biologically plausible learning via unique spike-based neurons, have emerged as a promising energy-efficient alternative. Different layers communicate with sparse and binary spikes, which facilitates computation and storage of intermediate graph representations. Despite the proliferation of SGNNs proposed in recent years, there is no systematic benchmark to explore the basic design principles of these brain-inspired networks on the graph data. To bridge this gap, we present SGNNBench to quantify progress in the field of SGNNs. Specifically, SGNNBench conducts an in-depth investigation of SGNNs from multiple perspectives, including effectiveness, energy efficiency, and architectural design. We comprehensively evaluate 9 state-of-the-art SGNNs across 18 datasets. Regarding efficiency, we empirically compare these baselines w.r.t model size, memory usage, and theoretical energy consumption to reveal the often-overlooked energy bottlenecks of SGNNs. Besides, we elaborately investigate the design space of SGNNs to promote the development of a general SGNN paradigm.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Machine Learning",
        "date": "2025-09-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.121858"
    },
    {
        "index": "#266",
        "title": "From Embeddings to Equations: Genetic-Programming Surrogates for Interpretable Transformer Classification",
        "link": "/arxiv/2509.21341",
        "arxiv_id": "2509.21341",
        "authors": "Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Mohammad Reza Nikoo, Fang Chen, Amir H. Gandomi",
        "summary": "We study symbolic surrogate modeling of frozen Transformer embeddings to obtain compact, auditable classifiers with calibrated probabilities. For five benchmarks (SST2G, 20NG, MNIST, CIFAR10, MSC17), embeddings from ModernBERT, DINOv2, and SigLIP are partitioned on the training set into disjoint, information-preserving views via semantic-preserving feature partitioning (SPFP). A cooperative multi-population genetic program (MEGP) then learns additive, closed-form logit programs over these views. Across 30 runs per dataset we report F1, AUC, log-loss, Brier, expected calibration error (ECE), and symbolic complexity; a canonical model is chosen by a one-standard-error rule on validation F1 with a parsimony tie-break. Temperature scaling fitted on validation yields substantial ECE reductions on test. The resulting surrogates achieve strong discrimination (up to F1 around 0.99 on MNIST, CIFAR10, MSC17; around 0.95 on SST2G), while 20NG remains most challenging. We provide reliability diagrams, dimension usage and overlap statistics, contribution-based importances, and global effect profiles (PDP and ALE), demonstrating faithful, cross-modal explanations grounded in explicit programs.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Machine Learning",
        "date": "2025-09-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.122407"
    },
    {
        "index": "#267",
        "title": "Cycle is All You Need: More Is Different",
        "link": "/arxiv/2509.21340",
        "arxiv_id": "2509.21340",
        "authors": "Xin Li",
        "summary": "We propose an information-topological framework in which cycle closure is the fundamental mechanism of memory and consciousness. Memory is not a static store but the ability to re-enter latent cycles in neural state space, with invariant cycles serving as carriers of meaning by filtering order-specific noise and preserving what persists across contexts. The dot-cycle dichotomy captures this: transient dots scaffold exploration, while nontrivial cycles encode low-entropy content invariants that stabilize memory. Biologically, polychronous neural groups realize 1-cycles through delay-locked spiking reinforced by STDP, nested within theta-gamma rhythms that enforce boundary cancellation. These micro-cycles compose hierarchically, extending navigation loops into general memory and cognition. The perception-action cycle introduces high-order invariance: closure holds even across sense-act alternations, generalizing ancestral homing behavior. Sheaf-cosheaf duality formalizes this process: sheaves glue perceptual fragments into global sections, cosheaves decompose global plans into actions and closure aligns top-down predictions with bottom-up cycles. Consciousness then arises as the persistence of high-order invariants that integrate (unity) yet differentiate (richness) across contexts. We conclude that cycle is all you need: persistent invariants enable generalization in non-ergodic environments with long-term coherence at minimal energetic cost.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Machine Learning, Neurons and Cognition",
        "date": "2025-09-15",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.123329"
    },
    {
        "index": "#269",
        "title": "Seismic Velocity Inversion from Multi-Source Shot Gathers Using Deep Segmentation Networks: Benchmarking U-Net Variants and SeismoLabV3+",
        "link": "/arxiv/2509.21331",
        "arxiv_id": "2509.21331",
        "authors": "Mahedi Hasan",
        "summary": "Seismic velocity inversion is a key task in geophysical exploration, enabling the reconstruction of subsurface structures from seismic wave data. It is critical for high-resolution seismic imaging and interpretation. Traditional physics-driven methods, such as Full Waveform Inversion (FWI), are computationally demanding, sensitive to initialization, and limited by the bandwidth of seismic data. Recent advances in deep learning have led to data-driven approaches that treat velocity inversion as a dense prediction task. This research benchmarks three advanced encoder-decoder architectures -- U-Net, U-Net++, and DeepLabV3+ -- together with SeismoLabV3+, an optimized variant of DeepLabV3+ with a ResNeXt50 32x4d backbone and task-specific modifications -- for seismic velocity inversion using the ThinkOnward 2025 Speed \\& Structure dataset, which consists of five-channel seismic shot gathers paired with high-resolution velocity maps. Experimental results show that SeismoLabV3+ achieves the best performance, with MAPE values of 0.03025 on the internal validation split and 0.031246 on the hidden test set as scored via the official ThinkOnward leaderboard. These findings demonstrate the suitability of deep segmentation networks for seismic velocity inversion and underscore the value of tailored architectural refinements in advancing geophysical AI models.",
        "subjects": "Geophysics, Artificial Intelligence, Machine Learning",
        "date": "2025-09-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.124342"
    },
    {
        "index": "#270",
        "title": "Assessment of deep learning models integrated with weather and environmental variables for wildfire spread prediction and a case study of the 2023 Maui fires",
        "link": "/arxiv/2509.21327",
        "arxiv_id": "2509.21327",
        "authors": "Jiyeon Kim, Yingjie Hu, Negar Elhami-Khorasani, Kai Sun, Ryan Zhenqi Zhou",
        "summary": "Predicting the spread of wildfires is essential for effective fire management and risk assessment. With the fast advancements of artificial intelligence (AI), various deep learning models have been developed and utilized for wildfire spread prediction. However, there is limited understanding of the advantages and limitations of these models, and it is also unclear how deep learning-based fire spread models can be compared with existing non-AI fire models. In this work, we assess the ability of five typical deep learning models integrated with weather and environmental variables for wildfire spread prediction based on over ten years of wildfire data in the state of Hawaii. We further use the 2023 Maui fires as a case study to compare the best deep learning models with a widely-used fire spread model, FARSITE. The results show that two deep learning models, i.e., ConvLSTM and ConvLSTM with attention, perform the best among the five tested AI models. FARSITE shows higher precision, lower recall, and higher F1-score than the best AI models, while the AI models offer higher flexibility for the input data. By integrating AI models with an explainable AI method, we further identify important weather and environmental factors associated with the 2023 Maui wildfires.",
        "subjects": "Physics and Society, Artificial Intelligence, Machine Learning",
        "date": "2025-09-05",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.124879"
    },
    {
        "index": "#271",
        "title": "PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation",
        "link": "/arxiv/2509.21325",
        "arxiv_id": "2509.21325",
        "authors": "Baiqiang Wang, Qian Lou, Mengxin Zheng, Dongfang Zhao",
        "summary": "Retrieval-Augmented Generation (RAG) has become a foundational component of modern AI systems, yet it introduces significant privacy risks by exposing user queries to service providers. To address this, we introduce PIR-RAG, a practical system for privacy-preserving RAG. PIR-RAG employs a novel architecture that uses coarse-grained semantic clustering to prune the search space, combined with a fast, lattice-based Private Information Retrieval (PIR) protocol. This design allows for the efficient retrieval of entire document clusters, uniquely optimizing for the end-to-end RAG workflow where full document content is required. Our comprehensive evaluation against strong baseline architectures, including graph-based PIR and Tiptoe-style private scoring, demonstrates PIR-RAG's scalability and its superior performance in terms of \"RAG-Ready Latency\"-the true end-to-end time required to securely fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly efficient solution for privacy in large-scale AI systems.",
        "subjects": "Information Retrieval, Artificial Intelligence, Cryptography and Security",
        "date": "2025-09-01",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.125395"
    },
    {
        "index": "#272",
        "title": "From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data",
        "link": "/arxiv/2509.21324",
        "arxiv_id": "2509.21324",
        "authors": "Gurbinder Gill, Ritvik Gupta, Denis Lusson, Anand Chandrashekar, Donald Nguyen",
        "summary": "Retrieval-Augmented Generation (RAG) has emerged as the standard paradigm for answering questions on enterprise data. Traditionally, RAG has centered on text-based semantic search and re-ranking. However, this approach falls short when dealing with questions beyond data summarization or non-text data. This has led to various attempts to supplement RAG to bridge the gap between RAG, the implementation paradigm, and the question answering problem that enterprise users expect it to solve. Given that contemporary RAG is a collection of techniques rather than a defined implementation, discussion of RAG and related question-answering systems benefits from a problem-oriented understanding. We propose a new classification framework (L1-L5) to categorize systems based on data modalities and task complexity of the underlying question answering problems: L1 (Surface Knowledge of Unstructured Data) through L4 (Reflective and Reasoned Knowledge) and the aspirational L5 (General Intelligence). We also introduce benchmarks aligned with these levels and evaluate four state-of-the-art platforms: LangChain, Azure AI Search, OpenAI, and Corvic AI. Our experiments highlight the value of multi-space retrieval and dynamic orchestration for enabling L1-L4 capabilities. We empirically validate our findings using diverse datasets indicative of enterprise use cases.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-08-27",
        "category": "cs.AI",
        "crawl_time": "2025-10-06T22:42:04.125899"
    }
]