[
    {
        "index": "#1",
        "title": "A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?",
        "link": "/arxiv/2409.15277",
        "arxiv_id": "2409.15277",
        "authors": "Yunfei Xie, Juncheng Wu, Haoqin Tu, Siwei Yang, Bingchen Zhao, Yongshuo Zong, Qiao Jin, Cihang Xie, Yuyin Zhou",
        "summary": "Large language models (LLMs) have exhibited remarkable capabilities across various domains and tasks, pushing the boundaries of our knowledge in learning and cognition. The latest model, OpenAI's o1, stands out as the first LLM with an internalized chain-of-thought technique using reinforcement learning strategies. While it has demonstrated surprisingly strong capabilities on various general language tasks, its performance in specialized fields such as medicine remains unknown. To this end, this report provides a comprehensive exploration of o1 on different medical scenarios, examining 3 key aspects: understanding, reasoning, and multilinguality. Specifically, our evaluation encompasses 6 tasks using data from 37 medical datasets, including two newly constructed and more challenging question-answering (QA) tasks based on professional medical quizzes from the New England Journal of Medicine (NEJM) and The Lancet. These datasets offer greater clinical relevance compared to standard medical QA benchmarks such as MedQA, translating more effectively into real-world clinical utility. Our analysis of o1 suggests that the enhanced reasoning ability of LLMs may (significantly) benefit their capability to understand various medical instructions and reason through complex clinical scenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average of 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios. But meanwhile, we identify several weaknesses in both the model capability and the existing evaluation protocols, including hallucination, inconsistent multilingual ability, and discrepant metrics for evaluation. We release our raw data and model outputs at https://ucsc-vlaa.github.io/o1_medicine/ for future research.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 17:59:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.330663"
    },
    {
        "index": "#3",
        "title": "Behavioral Bias of Vision-Language Models: A Behavioral Finance View",
        "link": "/arxiv/2409.15256",
        "arxiv_id": "2409.15256",
        "authors": "Yuhang Xiao, Yudi Lin, Ming-Chang Chiu",
        "summary": "Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models (LLMs) was equipped with vision modules to create more human-like models. However, we should carefully evaluate their applications in different domains, as they may possess undesired biases. Our work studies the potential behavioral biases of LVLMs from a behavioral finance perspective, an interdisciplinary subject that jointly considers finance and psychology. We propose an end-to-end framework, from data collection to new evaluation metrics, to assess LVLMs' reasoning capabilities and the dynamic behaviors manifested in two established human financial behavioral biases: recency bias and authority bias. Our evaluations find that recent open-source LVLMs such as LLaVA-NeXT, MobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 and Phi-3-vision-128k suffer significantly from these two biases, while the proprietary model GPT-4o is negligibly impacted. Our observations highlight directions in which open-source models can improve. The code is available at https://github.com/mydcxiao/vlm_behavioral_fin.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 17:54:47 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.331302"
    },
    {
        "index": "#4",
        "title": "MemBench: Towards Real-world Evaluation of Memory-Augmented Dialogue Systems",
        "link": "/arxiv/2409.15240",
        "arxiv_id": "2409.15240",
        "authors": "Junqing He, Liang Zhu, Qi Wei, Rui Wang, Jiaxing Zhang",
        "summary": "Long-term memory is so important for chatbots and dialogue systems (DS) that researchers have developed numerous memory-augmented DS. However, their evaluation methods are different from the real situation in human conversation. They only measured the accuracy of factual information or the perplexity of generated responses given a query, which hardly reflected their performance. Moreover, they only consider passive memory retrieval based on similarity, neglecting diverse memory-recalling paradigms in humans, e.g. emotions and surroundings. To bridge the gap, we construct a novel benchmark covering various memory recalling paradigms based on cognitive science and psychology theory. The Memory Benchmark (MemBench) contains two tasks according to the two-phrase theory in cognitive science: memory retrieval, memory recognition and injection. The benchmark considers both passive and proactive memory recalling based on meta information for the first time. In addition, novel scoring aspects are proposed to comprehensively measure the generated responses. Results from the strongest embedding models and LLMs on MemBench show that there is plenty of room for improvement in existing dialogue systems. Extensive experiments also reveal the correlation between memory injection and emotion supporting (ES) skillfulness, and intimacy. Our code and dataset will be released.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 17:38:41 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.331507"
    },
    {
        "index": "#5",
        "title": "ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction",
        "link": "/arxiv/2409.15202",
        "arxiv_id": "2409.15202",
        "authors": "Iwo Naglik, Mateusz Lango",
        "summary": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of aspect-based sentiment analysis that consists in extracting (aspect phrase, opinion phrase, sentiment polarity) triples from a given sentence. Recent state-of-the-art methods approach this task by first extracting all possible text spans from a given text, then filtering the potential aspect and opinion phrases with a classifier, and finally considering all their pairs with another classifier that additionally assigns sentiment polarity to them. Although several variations of the above scheme have been proposed, the common feature is that the final result is constructed by a sequence of independent classifier decisions. This hinders the exploitation of dependencies between extracted phrases and prevents the use of knowledge about the interrelationships between classifier predictions to improve performance. In this paper, we propose a new ASTE approach consisting of three transformer-inspired layers, which enables the modelling of dependencies both between phrases and between the final classifier decisions. Experimental results show that the method achieves higher performance in terms of F1 measure than other methods studied on popular benchmarks. In addition, we show that a simple pre-training technique further improves the performance of the model.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 16:49:47 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.331692"
    },
    {
        "index": "#6",
        "title": "Learning from Contrastive Prompts: Automated Optimization and Adaptation",
        "link": "/arxiv/2409.15199",
        "arxiv_id": "2409.15199",
        "authors": "Mingqi Li, Karan Aggarwal, Yong Xie, Aitzaz Ahmad, Stephen Lau",
        "summary": "As LLMs evolve, significant effort is spent on manually crafting prompts. While existing prompt optimization methods automate this process, they rely solely on learning from incorrect samples, leading to a sub-optimal performance. Additionally, an unexplored challenge in the literature is prompts effective for prior models may not perform well on newer versions or different languages. We propose the Learning from Contrastive Prompts (LCP) framework to address these gaps, enhancing both prompt optimization and adaptation. LCP employs contrastive learning to generate effective prompts by analyzing patterns in good and bad prompt examples. Our evaluation on the Big-Bench Hard dataset shows that LCP has a win rate of over 76% over existing methods in prompt optimization and demonstrates strong adaptability across different model versions, families, and languages. LCP offers a systematic approach to prompt engineering, reducing manual effort in deploying LLMs across varied contexts.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 16:47:23 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.331899"
    },
    {
        "index": "#7",
        "title": "PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large Language Models",
        "link": "/arxiv/2409.15188",
        "arxiv_id": "2409.15188",
        "authors": "Zhiyuan Wang, Fangxu Yuan, Virginia LeBaron, Tabor Flickinger, Laura E. Barnes",
        "summary": "Effective patient-provider communication is crucial in clinical care, directly impacting patient outcomes and quality of life. Traditional evaluation methods, such as human ratings, patient feedback, and provider self-assessments, are often limited by high costs and scalability issues. Although existing natural language processing (NLP) techniques show promise, they struggle with the nuances of clinical communication and require sensitive clinical data for training, reducing their effectiveness in real-world applications. Emerging large language models (LLMs) offer a new approach to assessing complex communication metrics, with the potential to advance the field through integration into passive sensing and just-in-time intervention systems. This study explores LLMs as evaluators of palliative care communication quality, leveraging their linguistic, in-context learning, and reasoning capabilities. Specifically, using simulated scripts crafted and labeled by healthcare professionals, we test proprietary models (e.g., GPT-4) and fine-tune open-source LLMs (e.g., LLaMA2) with a synthetic dataset generated by GPT-4 to evaluate clinical conversations, to identify key metrics such as `understanding' and `empathy'. Our findings demonstrated LLMs' superior performance in evaluating clinical communication, providing actionable feedback with reasoning, and demonstrating the feasibility and practical viability of developing in-house LLMs. This research highlights LLMs' potential to enhance patient-provider interactions and lays the groundwork for downstream steps in developing LLM-empowered clinical health systems.",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2024-09-23 16:39:12 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332107"
    },
    {
        "index": "#8",
        "title": "Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies",
        "link": "/arxiv/2409.15163",
        "arxiv_id": "2409.15163",
        "authors": "Skatje Myers, Timothy A. Miller, Yanjun Gao, Matthew M. Churpek, Anoop Mayampurath, Dmitriy Dligach, Majid Afshar",
        "summary": "Objective: Applying large language models (LLMs) to the clinical domain is challenging due to the context-heavy nature of processing medical records. Retrieval-augmented generation (RAG) offers a solution by facilitating reasoning over large text sources. However, there are many parameters to optimize in just the retrieval system alone. This paper presents an ablation study exploring how different embedding models and pooling methods affect information retrieval for the clinical domain. Methods: Evaluating on three retrieval tasks on two electronic health record (EHR) data sources, we compared seven models, including medical- and general-domain models, specialized encoder embedding models, and off-the-shelf decoder LLMs. We also examine the choice of embedding pooling strategy for each model, independently on the query and the text to retrieve. Results: We found that the choice of embedding model significantly impacts retrieval performance, with BGE, a comparatively small general-domain model, consistently outperforming all others, including medical-specific models. However, our findings also revealed substantial variability across datasets and query text phrasings. We also determined the best pooling methods for each of these models to guide future design of retrieval systems. Discussion: The choice of embedding model, pooling strategy, and query formulation can significantly impact retrieval performance and the performance of these models on other public benchmarks does not necessarily transfer to new domains. Further studies such as this one are vital for guiding empirically-grounded development of retrieval frameworks, such as in the context of RAG, for the clinical domain.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2024-09-23 16:16:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332318"
    },
    {
        "index": "#9",
        "title": "Scientific Cross-Document Coreference and Hierarchy with Definition-Augmented Relational Reasoning",
        "link": "/arxiv/2409.15113",
        "arxiv_id": "2409.15113",
        "authors": "Lior Forer, Tom Hope",
        "summary": "We address the fundamental task of inferring cross-document coreference and hierarchy in scientific texts, which has important applications in knowledge graph construction, search, recommendation and discovery. LLMs still struggle when faced with many long-tail technical concepts with nuanced variations. We present a novel method which generates context-dependent definitions of concept mentions by retrieving full-text literature, and uses the definitions to enhance detection of cross-document mention relations. We further generate relational definitions, which describe how two concept mentions are related or different, and design an efficient re-ranking approach to address the combinatorial explosion involved in inferring links across papers. In both fine-tuning and in-context learning settings we achieve large gains in performance. We provide analysis of generated definitions, shedding light on the relational reasoning ability of LLMs over fine-grained scientific texts.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 15:20:27 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332526"
    },
    {
        "index": "#10",
        "title": "Using Similarity to Evaluate Factual Consistency in Summaries",
        "link": "/arxiv/2409.15090",
        "arxiv_id": "2409.15090",
        "authors": "Yuxuan Ye, Edwin Simpson, Raul Santos Rodriguez",
        "summary": "Cutting-edge abstractive summarisers generate fluent summaries, but the factuality of the generated text is not guaranteed. Early summary factuality evaluation metrics are usually based on n-gram overlap and embedding similarity, but are reported fail to align with human annotations. Therefore, many techniques for detecting factual inconsistencies build pipelines around natural language inference (NLI) or question-answering (QA) models with additional supervised learning steps. In this paper, we revisit similarity-based metrics, showing that this failure stems from the comparison text selection and its granularity. We propose a new zero-shot factuality evaluation metric, Sentence-BERT Score (SBERTScore), which compares sentences between the summary and the source document. It outperforms widely-used word-word metrics including BERTScore and can compete with existing NLI and QA-based factuality metrics on the benchmark without needing any fine-tuning. Our experiments indicate that each technique has different strengths, with SBERTScore particularly effective in identifying correct summaries. We demonstrate how a combination of techniques is more effective in detecting various types of error.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 15:02:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332716"
    },
    {
        "index": "#11",
        "title": "Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory",
        "link": "/arxiv/2409.15084",
        "arxiv_id": "2409.15084",
        "authors": "Kunyao Lan, Bingui Jin, Zichen Zhu, Siyuan Chen, Shu Zhang, Kenny Q. Zhu, Mengyue Wu",
        "summary": "Mental health issues, particularly depressive disorders, present significant challenges in contemporary society, necessitating the development of effective automated diagnostic methods. This paper introduces the Agent Mental Clinic (AMC), a self-improving conversational agent system designed to enhance depression diagnosis through simulated dialogues between patient and psychiatrist agents. To enhance the dialogue quality and diagnosis accuracy, we design a psychiatrist agent consisting of a tertiary memory structure, a dialogue control and reflect plugin that acts as ``supervisor'' and a memory sampling module, fully leveraging the skills reflected by the psychiatrist agent, achieving great accuracy on depression risk and suicide risk diagnosis via conversation. Experiment results on datasets collected in real-life scenarios demonstrate that the system, simulating the procedure of training psychiatrists, can be a promising optimization method for aligning LLMs with real-life distribution in specific domains without modifying the weights of LLMs, even when only a few representative labeled cases are available.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-20 14:25:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332976"
    },
    {
        "index": "#12",
        "title": "Enhancing Scientific Reproducibility Through Automated BioCompute Object Creation Using Retrieval-Augmented Generation from Publications",
        "link": "/arxiv/2409.15076",
        "arxiv_id": "2409.15076",
        "authors": "Sean Kim, Raja Mazumder",
        "summary": "The exponential growth in computational power and accessibility has transformed the complexity and scale of bioinformatics research, necessitating standardized documentation for transparency, reproducibility, and regulatory compliance. The IEEE BioCompute Object (BCO) standard addresses this need but faces adoption challenges due to the overhead of creating compliant documentation, especially for legacy research. This paper presents a novel approach to automate the creation of BCOs from scientific papers using Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). We describe the development of the BCO assistant tool that leverages RAG to extract relevant information from source papers and associated code repositories, addressing key challenges such as LLM hallucination and long-context understanding. The implementation incorporates optimized retrieval processes, including a two-pass retrieval with re-ranking, and employs carefully engineered prompts for each BCO domain. We discuss the tool's architecture, extensibility, and evaluation methods, including automated and manual assessment approaches. The BCO assistant demonstrates the potential to significantly reduce the time and effort required for retroactive documentation of bioinformatics research while maintaining compliance with the standard. This approach opens avenues for AI-assisted scientific documentation and knowledge extraction from publications thereby enhancing scientific reproducibility. The BCO assistant tool and documentation is available at https://biocompute-objects.github.io/bco-rag/.",
        "subjects": "Computation and Language, Artificial Intelligence, Other Quantitative Biology",
        "date": "2024-09-23 14:51:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.333175"
    },
    {
        "index": "#13",
        "title": "Brotherhood at WMT 2024: Leveraging LLM-Generated Contextual Conversations for Cross-Lingual Image Captioning",
        "link": "/arxiv/2409.15052",
        "arxiv_id": "2409.15052",
        "authors": "Siddharth Betala, Ishan Chokshi",
        "summary": "In this paper, we describe our system under the team name Brotherhood for the English-to-Lowres Multi-Modal Translation Task. We participate in the multi-modal translation tasks for English-Hindi, English-Hausa, English-Bengali, and English-Malayalam language pairs. We present a method leveraging multi-modal Large Language Models (LLMs), specifically GPT-4o and Claude 3.5 Sonnet, to enhance cross-lingual image captioning without traditional training or fine-tuning. Our approach utilizes instruction-tuned prompting to generate rich, contextual conversations about cropped images, using their English captions as additional context. These synthetic conversations are then translated into the target languages. Finally, we employ a weighted prompting strategy, balancing the original English caption with the translated conversation to generate captions in the target language. This method achieved competitive results, scoring 37.90 BLEU on the English-Hindi Challenge Set and ranking first and second for English-Hausa on the Challenge and Evaluation Leaderboards, respectively. We conduct additional experiments on a subset of 250 images, exploring the trade-offs between BLEU scores and semantic similarity across various weighting schemes.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 14:29:46 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.333359"
    },
    {
        "index": "#14",
        "title": "Scaling Laws of Decoder-Only Models on the Multilingual Machine Translation Task",
        "link": "/arxiv/2409.15051",
        "arxiv_id": "2409.15051",
        "authors": "Gaëtan Caillaut, Raheel Qader, Mariam Nakhlé, Jingshu Liu, Jean-Gabriel Barthélemy",
        "summary": "Recent studies have showcased remarkable capabilities of decoder-only models in many NLP tasks, including translation. Yet, the machine translation field has been largely dominated by encoder-decoder models based on the Transformer architecture. As a consequence, scaling laws of encoder-decoder models for neural machine translation have already been well studied, but decoder-only models have received less attention. This work explores the scaling laws of decoder-only models on the multilingual and multidomain translation task. We trained a collection of six decoder-only models, ranging from 70M to 7B parameters, on a sentence-level, multilingual and multidomain dataset. We conducted a series of experiments showing that the loss of decoder-only models can be estimated using a scaling law similar to the one discovered for large language models, but we also show that this scaling law has difficulties to generalize to too large models or to a different data distribution. We also study different scaling methods and show that scaling the depth and the width of a model lead to similar test loss improvements, but with different impact on the model's efficiency.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 14:26:01 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.333558"
    },
    {
        "index": "#15",
        "title": "Generative LLM Powered Conversational AI Application for Personalized Risk Assessment: A Case Study in COVID-19",
        "link": "/arxiv/2409.15027",
        "arxiv_id": "2409.15027",
        "authors": "Mohammad Amin Roshani, Xiangyu Zhou, Yao Qiang, Srinivasan Suresh, Steve Hicks, Usha Sethuraman, Dongxiao Zhu",
        "summary": "Large language models (LLMs) have shown remarkable capabilities in various natural language tasks and are increasingly being applied in healthcare domains. This work demonstrates a new LLM-powered disease risk assessment approach via streaming human-AI conversation, eliminating the need for programming required by traditional machine learning approaches. In a COVID-19 severity risk assessment case study, we fine-tune pre-trained generative LLMs (e.g., Llama2-7b and Flan-t5-xl) using a few shots of natural language examples, comparing their performance with traditional classifiers (i.e., Logistic Regression, XGBoost, Random Forest) that are trained de novo using tabular data across various experimental settings. We develop a mobile application that uses these fine-tuned LLMs as its generative AI (GenAI) core to facilitate real-time interaction between clinicians and patients, providing no-code risk assessment through conversational interfaces. This integration not only allows for the use of streaming Questions and Answers (QA) as inputs but also offers personalized feature importance analysis derived from the LLM's attention layers, enhancing the interpretability of risk assessments. By achieving high Area Under the Curve (AUC) scores with a limited number of fine-tuning samples, our results demonstrate the potential of generative LLMs to outperform discriminative classification methods in low-data regimes, highlighting their real-world adaptability and effectiveness. This work aims to fill the existing gap in leveraging generative LLMs for interactive no-code risk assessment and to encourage further research in this emerging field.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 13:55:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.333859"
    },
    {
        "index": "#16",
        "title": "Inference-Friendly Models With MixAttention",
        "link": "/arxiv/2409.15012",
        "arxiv_id": "2409.15012",
        "authors": "Shashank Rajput, Ying Sheng, Sean Owen, Vitaliy Chiley",
        "summary": "The size of the key-value (KV) cache plays a critical role in determining both the maximum context length and the number of concurrent requests supported during inference in modern language models. The KV cache size grows proportionally with the number of attention heads and the tokens processed, leading to increased memory consumption and slower inference for long inputs. In this work, we explore the use of MixAttention, a model architecture modification closely related to a blog published by Character.AI. MixAttention combines sliding window attention, where only a small subset of recent tokens is stored in the KV cache, with KV cache sharing across layers. Our experiments demonstrate that MixAttention significantly reduces memory usage and improves inference speed without sacrificing model performance in both short and long-context tasks. We also explore various configurations of this architecture, identifying those that maintain quality across evaluation metrics while optimizing resource efficiency.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 13:37:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.334174"
    },
    {
        "index": "#17",
        "title": "Enhancing Aspect-based Sentiment Analysis in Tourism Using Large Language Models and Positional Information",
        "link": "/arxiv/2409.14997",
        "arxiv_id": "2409.14997",
        "authors": "Chun Xu, Mengmeng Wang, Yan Ren, Shaolin Zhu",
        "summary": "Aspect-Based Sentiment Analysis (ABSA) in tourism plays a significant role in understanding tourists' evaluations of specific aspects of attractions, which is crucial for driving innovation and development in the tourism industry. However, traditional pipeline models are afflicted by issues such as error propagation and incomplete extraction of sentiment elements. To alleviate this issue, this paper proposes an aspect-based sentiment analysis model, ACOS_LLM, for Aspect-Category-Opinion-Sentiment Quadruple Extraction (ACOSQE). The model comprises two key stages: auxiliary knowledge generation and ACOSQE. Firstly, Adalora is used to fine-tune large language models for generating high-quality auxiliary knowledge. To enhance model efficiency, Sparsegpt is utilized to compress the fine-tuned model to 50% sparsity. Subsequently, Positional information and sequence modeling are employed to achieve the ACOSQE task, with auxiliary knowledge and the original text as inputs. Experiments are conducted on both self-created tourism datasets and publicly available datasets, Rest15 and Rest16. Results demonstrate the model's superior performance, with an F1 improvement of 7.49% compared to other models on the tourism dataset. Additionally, there is an F1 improvement of 0.05% and 1.06% on the Rest15 and Rest16 datasets, respectively.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 13:19:17 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.334425"
    },
    {
        "index": "#18",
        "title": "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs",
        "link": "/arxiv/2409.14988",
        "arxiv_id": "2409.14988",
        "authors": "Clément Christophe, Tathagata Raha, Svetlana Maslenkova, Muhammad Umar Salman, Praveen K Kanithi, Marco AF Pimentel, Shadab Khan",
        "summary": "Large Language Models (LLMs) have demonstrated significant potential in transforming clinical applications. In this study, we investigate the efficacy of four techniques in adapting LLMs for clinical use-cases: continuous pretraining, instruct fine-tuning, NEFTune, and prompt engineering. We employ these methods on Mistral 7B and Mixtral 8x7B models, leveraging a large-scale clinical pretraining dataset of 50 billion tokens and an instruct fine-tuning dataset of 500 million tokens. Our evaluation across various clinical tasks reveals the impact of each technique. While continuous pretraining beyond 250 billion tokens yields marginal improvements on its own, it establishes a strong foundation for instruct fine-tuning. Notably, NEFTune, designed primarily to enhance generation quality, surprisingly demonstrates additional gains on our benchmark. Complex prompt engineering methods further enhance performance. These findings show the importance of tailoring fine-tuning strategies and exploring innovative techniques to optimize LLM performance in the clinical domain.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 13:09:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.334648"
    },
    {
        "index": "#19",
        "title": "Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others in Conversation Forecasting",
        "link": "/arxiv/2409.14986",
        "arxiv_id": "2409.14986",
        "authors": "Anthony Sicilia, Malihe Alikhani",
        "summary": "Typically, when evaluating Theory of Mind, we consider the beliefs of others to be binary: held or not held. But what if someone is unsure about their own beliefs? How can we quantify this uncertainty? We propose a new suite of tasks, challenging language models (LMs) to model the uncertainty of others in dialogue. We design these tasks around conversation forecasting, wherein an agent forecasts an unobserved outcome to a conversation. Uniquely, we view interlocutors themselves as forecasters, asking an LM to predict the uncertainty of the interlocutors (a probability). We experiment with re-scaling methods, variance reduction strategies, and demographic context, for this regression task, conducting experiments on three dialogue corpora (social, negotiation, task-oriented) with eight LMs. While LMs can explain up to 7% variance in the uncertainty of others, we highlight the difficulty of the tasks and room for future work, especially in practical applications, like anticipating ``false",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 13:05:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.334879"
    },
    {
        "index": "#20",
        "title": "Bilingual Rhetorical Structure Parsing with Large Parallel Annotations",
        "link": "/arxiv/2409.14969",
        "arxiv_id": "2409.14969",
        "authors": "Elena Chistova",
        "summary": "Discourse parsing is a crucial task in natural language processing that aims to reveal the higher-level relations in a text. Despite growing interest in cross-lingual discourse parsing, challenges persist due to limited parallel data and inconsistencies in the Rhetorical Structure Theory (RST) application across languages and corpora. To address this, we introduce a parallel Russian annotation for the large and diverse English GUM RST corpus. Leveraging recent advances, our end-to-end RST parser achieves state-of-the-art results on both English and Russian corpora. It demonstrates effectiveness in both monolingual and bilingual settings, successfully transferring even with limited second-language annotation. To the best of our knowledge, this work is the first to evaluate the potential of cross-lingual end-to-end RST parsing on a manually annotated parallel corpus.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 12:40:33 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.335066"
    },
    {
        "index": "#21",
        "title": "Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely",
        "link": "/arxiv/2409.14924",
        "arxiv_id": "2409.14924",
        "authors": "Siyun Zhao, Yuqing Yang, Zilong Wang, Zhiyuan He, Luna K. Qiu, Lili Qiu",
        "summary": "Large language models (LLMs) augmented with external data have demonstrated remarkable capabilities in completing real-world tasks. Techniques for integrating external data into LLMs, such as Retrieval-Augmented Generation (RAG) and fine-tuning, are gaining increasing attention and widespread application. Nonetheless, the effective deployment of data-augmented LLMs across various specialized fields presents substantial challenges. These challenges encompass a wide range of issues, from retrieving relevant data and accurately interpreting user intent to fully harnessing the reasoning capabilities of LLMs for complex tasks. We believe that there is no one-size-fits-all solution for data-augmented LLM applications. In practice, underperformance often arises from a failure to correctly identify the core focus of a task or because the task inherently requires a blend of multiple capabilities that must be disentangled for better resolution. In this survey, we propose a RAG task categorization method, classifying user queries into four levels based on the type of external data required and primary focus of the task: explicit fact queries, implicit fact queries, interpretable rationale queries, and hidden rationale queries. We define these levels of queries, provide relevant datasets, and summarize the key challenges and most effective techniques for addressing these challenges. Finally, we discuss three main forms of integrating external data into LLMs: context, small model, and fine-tuning, highlighting their respective strengths, limitations, and the types of problems they are suited to solve. This work aims to help readers thoroughly understand and decompose the data requirements and key bottlenecks in building LLM applications, offering solutions to the different challenges and serving as a guide to systematically developing such applications.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 11:20:20 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.335281"
    },
    {
        "index": "#22",
        "title": "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models",
        "link": "/arxiv/2409.14917",
        "arxiv_id": "2409.14917",
        "authors": "Tyler Loakman, Yucheng Li, Chenghua Lin",
        "summary": "Recently, Large Language Models (LLMs) and Vision Language Models (VLMs) have demonstrated aptitude as potential substitutes for human participants in experiments testing psycholinguistic phenomena. However, an understudied question is to what extent models that only have access to vision and text modalities are able to implicitly understand sound-based phenomena via abstract reasoning from orthography and imagery alone. To investigate this, we analyse the ability of VLMs and LLMs to demonstrate sound symbolism (i.e., to recognise a non-arbitrary link between sounds and concepts) as well as their ability to ``hear'' via the interplay of the language and vision modules of open and closed-source multimodal models. We perform multiple experiments, including replicating the classic Kiki-Bouba and Mil-Mal shape and magnitude symbolism tasks, and comparing human judgements of linguistic iconicity with that of LLMs. Our results show that VLMs demonstrate varying levels of agreement with human labels, and more task information may be required for VLMs versus their human counterparts for in silico experimentation. We additionally see through higher maximum agreement levels that Magnitude Symbolism is an easier pattern for VLMs to identify than Shape Symbolism, and that an understanding of linguistic iconicity is highly dependent on model size.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 11:13:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.340823"
    },
    {
        "index": "#23",
        "title": "Towards a Realistic Long-Term Benchmark for Open-Web Research Agents",
        "link": "/arxiv/2409.14913",
        "arxiv_id": "2409.14913",
        "authors": "Peter Mühlbacher, Nikos I. Bosse, Lawrence Phillips",
        "summary": "We present initial results of a forthcoming benchmark for evaluating LLM agents on white-collar tasks of economic value. We evaluate eight realistic and ``messy'' tasks that are routine in finance and consulting, drawn from real-world cases from our customers. We lay the groundwork for an LLM agent evaluation suite where good performance directly corresponds to a large economic and societal impact. This fills a gap in existing benchmarks with tasks like ``order a pizza to the following address'' that do not constitute real-human work of economic value. Our evaluations assign credit to agents for partially solving tasks. By doing that, this initial evaluation, and the forthcoming benchmark, allow us to more accurately extrapolate performance of LLM-based agents on economically valuable tasks. We built and tested several architectures with GPT-4o, Claude-3.5 Sonnet, Llama 3.1 (405b), and GPT-4o-mini, ensuring that failure to solve a task was due to failures of reasoning and planning, rather than due to common failures like e.g. the inability to parse a website. On average, LLM agents powered by Claude-3.5 Sonnet substantially outperformed agents using GPT-4o, with agents based on Llama 3.1 (405b) and GPT-4o-mini lagging noticeably behind. Across LLMs, a ReAct architecture with the ability to delegate subtasks to subagents performed best. In addition to quantitative evaluations, we qualitatively assessed the performance of the LLM agents by inspecting their traces and reflecting on their observations.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-23 11:08:04 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341153"
    },
    {
        "index": "#24",
        "title": "Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization",
        "link": "/arxiv/2409.14907",
        "arxiv_id": "2409.14907",
        "authors": "Aseem Srivastava, Smriti Joshi, Tanmoy Chakraborty, Md Shad Akhtar",
        "summary": "In mental health counseling, condensing dialogues into concise and relevant summaries (aka counseling notes) holds pivotal significance. Large Language Models (LLMs) exhibit remarkable capabilities in various generative tasks; however, their adaptation to domain-specific intricacies remains challenging, especially within mental health contexts. Unlike standard LLMs, mental health experts first plan to apply domain knowledge in writing summaries. Our work enhances LLMs' ability by introducing a novel planning engine to orchestrate structuring knowledge alignment. To achieve high-order planning, we divide knowledge encapsulation into two major phases: (i) holding dialogue structure and (ii) incorporating domain-specific knowledge. We employ a planning engine on Llama-2, resulting in a novel framework, PIECE. Our proposed system employs knowledge filtering-cum-scaffolding to encapsulate domain knowledge. Additionally, PIECE leverages sheaf convolution learning to enhance its understanding of the dialogue's structural nuances. We compare PIECE with 14 baseline methods and observe a significant improvement across ROUGE and Bleurt scores. Further, expert evaluation and analyses validate the generation quality to be effective, sometimes even surpassing the gold standard. We further benchmark PIECE with other LLMs and report improvement, including Llama-2 (+2.72%), Mistral (+2.04%), and Zephyr (+1.59%), to justify the generalizability of the planning engine.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 11:01:31 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341355"
    },
    {
        "index": "#25",
        "title": "DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models",
        "link": "/arxiv/2409.14904",
        "arxiv_id": "2409.14904",
        "authors": "Sangyeon Cho, Jangyeong Jeon, Dongjoon Lee, Changhee Lee, Junyeong Kim",
        "summary": "The use of pre-trained language models fine-tuned to address specific downstream tasks is a common approach in natural language processing (NLP). However, acquiring domain-specific knowledge via fine-tuning is challenging. Traditional methods involve pretraining language models using vast amounts of domain-specific data before fine-tuning for particular tasks. This study investigates emergency/non-emergency classification tasks based on electronic medical record (EMR) data obtained from pediatric emergency departments (PEDs) in Korea. Our findings reveal that existing domain-specific pre-trained language models underperform compared to general language models in handling N-lingual free-text data characteristics of non-English-speaking regions. To address these limitations, we propose a domain knowledge transfer methodology that leverages knowledge distillation to infuse general language models with domain-specific knowledge via fine-tuning. This study demonstrates the effective transfer of specialized knowledge between models by defining a general language model as the student model and a domain-specific pre-trained model as the teacher model. In particular, we address the complexities of EMR data obtained from PEDs in non-English-speaking regions, such as Korea, and demonstrate that the proposed method enhances classification performance in such contexts. The proposed methodology not only outperforms baseline models on Korean PED EMR data, but also promises broader applicability in various professional and technical domains. In future works, we intend to extend this methodology to include diverse non-English-speaking regions and address additional downstream tasks, with the aim of developing advanced model architectures using state-of-the-art KD techniques. The code is available in https://github.com/JoSangYeon/DSG-KD.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 10:59:02 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341555"
    },
    {
        "index": "#26",
        "title": "End-to-End Graph Flattening Method for Large Language Models",
        "link": "/arxiv/2409.14880",
        "arxiv_id": "2409.14880",
        "authors": "Bin Hong, Jinze Wu, Jiayu Liu, Liang Ding, Jing Sha, Kai Zhang, Shijin Wang, Zhenya Huang",
        "summary": "In recent years, the breakthrough of Large Language Models (LLMs) offers new ideas for achieving universal methods on graph data. The common practice of converting graphs into natural language for LLMs, which refers to graph flattening, exhibits good generalizability and interpretability. However, the poor organization of the textual format results in poor performance in long-distance scenario understanding. Inspired by human cognitive reasoning habits, we propose a novel method for graph flattening to fit LLMs, termed as End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show that EEDP enhances the reasoning performance of LLMs in long-distance scenarios while maintaining excellent performance in short-distance scenarios, demonstrating good robustness in the face of distance variations.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 10:28:47 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341776"
    },
    {
        "index": "#27",
        "title": "Privacy Policy Analysis through Prompt Engineering for LLMs",
        "link": "/arxiv/2409.14879",
        "arxiv_id": "2409.14879",
        "authors": "Arda Goknil, Femke B. Gelderblom, Simeon Tverdal, Shukun Tokas, Hui Song",
        "summary": "Privacy policies are often obfuscated by their complexity, which impedes transparency and informed consent. Conventional machine learning approaches for automatically analyzing these policies demand significant resources and substantial domain-specific training, causing adaptability issues. Moreover, they depend on extensive datasets that may require regular maintenance due to changing privacy concerns. In this paper, we propose, apply, and assess PAPEL (Privacy Policy Analysis through Prompt Engineering for LLMs), a framework harnessing the power of Large Language Models (LLMs) through prompt engineering to automate the analysis of privacy policies. PAPEL aims to streamline the extraction, annotation, and summarization of information from these policies, enhancing their accessibility and comprehensibility without requiring additional model training. By integrating zero-shot, one-shot, and few-shot learning approaches and the chain-of-thought prompting in creating predefined prompts and prompt templates, PAPEL guides LLMs to efficiently dissect, interpret, and synthesize the critical aspects of privacy policies into user-friendly summaries. We demonstrate the effectiveness of PAPEL with two applications: (i) annotation and (ii) contradiction analysis. We assess the ability of several LLaMa and GPT models to identify and articulate data handling practices, offering insights comparable to existing automated analysis approaches while reducing training efforts and increasing the adaptability to new analytical needs. The experiments demonstrate that the LLMs PAPEL utilizes (LLaMA and Chat GPT models) achieve robust performance in privacy policy annotation, with F1 scores reaching 0.8 and above (using the OPP-115 gold standard), underscoring the effectiveness of simpler prompts across various advanced language models.",
        "subjects": "Computation and Language, Computers and Society, Software Engineering",
        "date": "2024-09-23 10:23:31 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341984"
    },
    {
        "index": "#28",
        "title": "Orthogonal Finetuning for Direct Preference Optimization",
        "link": "/arxiv/2409.14836",
        "arxiv_id": "2409.14836",
        "authors": "Chenxu Yang, Ruipeng Jia, Naibin Gu, Zheng Lin, Siyuan Chen, Chao Pang, Weichong Yin, Yu Sun, Hua Wu, Weiping Wang",
        "summary": "DPO is an effective preference optimization algorithm. However, the DPO-tuned models tend to overfit on the dispreferred samples, manifested as overly long generations lacking diversity. While recent regularization approaches have endeavored to alleviate this issue by modifying the objective function, they achieved that at the cost of alignment performance degradation. In this paper, we innovatively incorporate regularization from the perspective of weight updating to curb alignment overfitting. Through the pilot experiment, we discovered that there exists a positive correlation between overfitting and the hyperspherical energy fluctuation. Hence, we introduce orthogonal finetuning for DPO via a weight-Rotated Preference Optimization (RoPO) method, which merely conducts rotational and magnitude-stretching updates on the weight parameters to maintain the hyperspherical energy invariant, thereby preserving the knowledge encoded in the angle between neurons. Extensive experiments demonstrate that our model aligns perfectly with human preferences while retaining the original expressive capacity using only 0.0086% of the trainable parameters, suggesting an effective regularization against overfitting. Specifically, RoPO outperforms DPO by up to 10 points on MT-Bench and by up to 2.8 points on AlpacaEval 2, while enhancing the generation diversity by an average of 6 points.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 09:09:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.342227"
    },
    {
        "index": "#29",
        "title": "ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback",
        "link": "/arxiv/2409.14826",
        "arxiv_id": "2409.14826",
        "authors": "Qinzhuo Wu, Wei Liu, Jian Luan, Bin Wang",
        "summary": "Recently, tool-augmented LLMs have gained increasing attention. Given an instruction, tool-augmented LLMs can interact with various external tools in multiple rounds and provide a final answer. However, previous LLMs were trained on overly detailed instructions, which included API names or parameters, while real users would not explicitly mention these API details. This leads to a gap between trained LLMs and real-world scenarios. In addition, most works ignore whether the interaction process follows the instruction. To address these issues, we constructed a training dataset called MGToolBench, which contains statement and category-level instructions to better reflect real-world scenarios. In addition, we propose ToolPlanner, a two-stage reinforcement learning framework that utilizes path planning and two feedback mechanisms to enhance the LLM's task completion and instruction-following capabilities. Experimental results show that ToolPlanner significantly improves the Match Rate, Pass Rate and Win Rate by 26.8%, 20.2%, and 5.6% compared to the SOTA model. Human evaluation verifies that the multi-granularity instructions can better align with users' usage habits. Our data and code will be released upon acceptance.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 08:58:48 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.342424"
    },
    {
        "index": "#30",
        "title": "Past Meets Present: Creating Historical Analogy with Large Language Models",
        "link": "/arxiv/2409.14820",
        "arxiv_id": "2409.14820",
        "authors": "Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Feng Wei, Zujie Liang, Deqing Yang, Yanghua Xiao",
        "summary": "Historical analogies, which compare known past events with contemporary but unfamiliar events, are important abilities that help people make decisions and understand the world. However, research in applied history suggests that people have difficulty finding appropriate analogies. And previous studies in the AI community have also overlooked historical analogies. To fill this gap, in this paper, we focus on the historical analogy acquisition task, which aims to acquire analogous historical events for a given event. We explore retrieval and generation methods for acquiring historical analogies based on different large language models (LLMs). Furthermore, we propose a self-reflection method to mitigate hallucinations and stereotypes when LLMs generate historical analogies. Through human evaluations and our specially designed automatic multi-dimensional assessment, we find that LLMs generally have a good potential for historical analogies. And the performance of the models can be further improved by using our self-reflection method.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 08:52:09 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.342640"
    },
    {
        "index": "#31",
        "title": "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding",
        "link": "/arxiv/2409.14818",
        "arxiv_id": "2409.14818",
        "authors": "Qinzhuo Wu, Weikai Xu, Wei Liu, Tao Tan, Jianfeng Liu, Ang Li, Jian Luan, Bin Wang, Shuo Shang",
        "summary": "Recently, mobile AI agents based on VLMs have been gaining increasing attention. These works typically utilize VLM as a foundation, fine-tuning it with instruction-based mobile datasets. However, these VLMs are typically pre-trained on general-domain data, which often results in a lack of fundamental capabilities specific to the mobile domain. Therefore, they may struggle to recognize specific UI elements and understand intra-UI fine-grained information. In addition, the current fine-tuning task focuses on interacting with the most relevant element for the given instruction. These fine-tuned VLMs may still ignore the relationships between UI pages, neglect the roles of elements in page transitions and lack inter-UI understanding. To address issues, we propose a VLM called MobileVLM, which includes two additional pre-training stages to enhance both intra- and inter-UI understanding. We defined four UI-based pre-training tasks, enabling the model to better perceive fine-grained elements and capture page transition actions. To address the lack of mobile pre-training data, we built a large Chinese mobile dataset Mobile3M from scratch, which contains 3 million UI pages, and real-world transition actions, forming a directed graph structure. Experimental results show MobileVLM excels on both our test set and public mobile benchmarks, outperforming existing VLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 08:47:54 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.342863"
    },
    {
        "index": "#32",
        "title": "MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations",
        "link": "/arxiv/2409.14801",
        "arxiv_id": "2409.14801",
        "authors": "Gia-Bao Dinh Ho, Chang Wei Tan, Zahra Zamanzadeh Darban, Mahsa Salehi, Gholamreza Haffari, Wray Buntine",
        "summary": "Detecting critical moments, such as emotional outbursts or changes in decisions during conversations, is crucial for understanding shifts in human behavior and their consequences. Our work introduces a novel problem setting focusing on these moments as turning points (TPs), accompanied by a meticulously curated, high-consensus, human-annotated multi-modal dataset. We provide precise timestamps, descriptions, and visual-textual evidence high-lighting changes in emotions, behaviors, perspectives, and decisions at these turning points. We also propose a framework, TPMaven, utilizing state-of-the-art vision-language models to construct a narrative from the videos and large language models to classify and detect turning points in our multi-modal dataset. Evaluation results show that TPMaven achieves an F1-score of 0.88 in classification and 0.61 in detection, with additional explanations aligning with human expectations.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 08:26:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.343093"
    },
    {
        "index": "#34",
        "title": "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method",
        "link": "/arxiv/2409.14781",
        "arxiv_id": "2409.14781",
        "authors": "Weichao Zhang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng",
        "summary": "As the scale of training corpora for large language models (LLMs) grows, model developers become increasingly reluctant to disclose details on their data. This lack of transparency poses challenges to scientific evaluation and ethical deployment. Recently, pretraining data detection approaches, which infer whether a given text was part of an LLM's training data through black-box access, have been explored. The Min-K% Prob method, which has achieved state-of-the-art results, assumes that a non-training example tends to contain a few outlier words with low token probabilities. However, the effectiveness may be limited as it tends to misclassify non-training texts that contain many common words with high probabilities predicted by LLMs. To address this issue, we introduce a divergence-based calibration method, inspired by the divergence-from-randomness concept, to calibrate token probabilities for pretraining data detection. We compute the cross-entropy (i.e., the divergence) between the token probability distribution and the token frequency distribution to derive a detection score.We have developed a Chinese-language benchmark, PatentMIA, to assess the performance of detection approaches for LLMs on Chinese text. Experimental results on English-language benchmarks and PatentMIA demonstrate that our proposed method significantly outperforms existing methods. Our code and PatentMIA benchmark are available at https://github.com/zhang-wei-chao/DC-PDD",
        "subjects": "Computation and Language, Cryptography and Security",
        "date": "2024-09-23 07:55:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.343528"
    },
    {
        "index": "#35",
        "title": "OMPar: Automatic Parallelization with AI-Driven Source-to-Source Compilation",
        "link": "/arxiv/2409.14771",
        "arxiv_id": "2409.14771",
        "authors": "Tal Kadosh, Niranjan Hasabnis, Prema Soundararajan, Vy A. Vo, Mihai Capota, Nesreen Ahmed, Yuval Pinter, Gal Oren",
        "summary": "Manual parallelization of code remains a significant challenge due to the complexities of modern software systems and the widespread adoption of multi-core architectures. This paper introduces OMPar, an AI-driven tool designed to automate the parallelization of C/C++ code using OpenMP pragmas. OMPar integrates Large Language Models (LLMs) through two key components: OMPify, which assesses loop parallelization potential, and MonoCoder-OMP, a new fine-tuned model which generates precise OpenMP pragmas. The evaluation of OMPar follows the same rigorous process applied to traditional tools like source-to-source AutoPar and ICPC compilers: (1) ensuring the generated code compiles and runs correctly in serial form, (2) assessing performance with the gradual addition of threads and corresponding physical cores, and (3) verifying and validating the correctness of the code's output. Benchmarks from HeCBench and ParEval are used to evaluate accuracy and performance. Experimental results demonstrate that OMPar significantly outperforms traditional methods, achieving higher accuracy in identifying parallelizable loops and generating efficient pragmas. Beyond accuracy, OMPar offers advantages such as the ability to work on partial or incomplete codebases and the capacity to continuously learn from new code patterns, enhancing its parallelization capabilities over time. These results underscore the potential of LLMs in revolutionizing automatic parallelization techniques, paving the way for more efficient and scalable parallel computing systems.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 07:39:01 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.343737"
    },
    {
        "index": "#36",
        "title": "Language-Agnostic Analysis of Speech Depression Detection",
        "link": "/arxiv/2409.14769",
        "arxiv_id": "2409.14769",
        "authors": "Sona Binu, Jismi Jose, Fathima Shimna K V, Alino Luke Hans, Reni K. Cherian, Starlet Ben Alex, Priyanka Srivastava, Chiranjeevi Yarra",
        "summary": "The people with Major Depressive Disorder (MDD) exhibit the symptoms of tonal variations in their speech compared to the healthy counterparts. However, these tonal variations not only confine to the state of MDD but also on the language, which has unique tonal patterns. This work analyzes automatic speech-based depression detection across two languages, English and Malayalam, which exhibits distinctive prosodic and phonemic characteristics. We propose an approach that utilizes speech data collected along with self-reported labels from participants reading sentences from IViE corpus, in both English and Malayalam. The IViE corpus consists of five sets of sentences: simple sentences, WH-questions, questions without morphosyntactic markers, inversion questions and coordinations, that can naturally prompt speakers to speak in different tonal patterns. Convolutional Neural Networks (CNNs) are employed for detecting depression from speech. The CNN model is trained to identify acoustic features associated with depression in speech, focusing on both languages. The model's performance is evaluated on the collected dataset containing recordings from both depressed and non-depressed speakers, analyzing its effectiveness in detecting depression across the two languages. Our findings and collected data could contribute to the development of language-agnostic speech-based depression detection systems, thereby enhancing accessibility for diverse populations.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 07:35:56 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344000"
    },
    {
        "index": "#37",
        "title": "Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?",
        "link": "/arxiv/2409.14762",
        "arxiv_id": "2409.14762",
        "authors": "Yuyan Chen, Tianhao Yu, Yueze Li, Songzhou Yan, Sijia Liu, Jiaqing Liang, Yanghua Xiao",
        "summary": "The evaluation of the problem-solving capability under incomplete information scenarios of Large Language Models (LLMs) is increasingly important, encompassing capabilities such as questioning, knowledge search, error detection, and path planning. Current research mainly focus on LLMs' problem-solving capability such as ``Twenty Questions''. However, these kinds of games do not require recognizing misleading cues which are necessary in the incomplete information scenario. Moreover, the existing game such as ``Who is undercover'' are highly subjective, making it challenging for evaluation. Therefore, in this paper, we introduce a novel game named BrainKing based on the ``Who is undercover'' and ``Twenty Questions'' for evaluating LLM capabilities under incomplete information scenarios. It requires LLMs to identify target entities with limited yes-or-no questions and potential misleading answers. By setting up easy, medium, and hard difficulty modes, we comprehensively assess the performance of LLMs across various aspects. Our results reveal the capabilities and limitations of LLMs in BrainKing, providing significant insights of LLM problem-solving levels.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 07:18:02 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344223"
    },
    {
        "index": "#38",
        "title": "LINKAGE: Listwise Ranking among Varied-Quality References for Non-Factoid QA Evaluation via LLMs",
        "link": "/arxiv/2409.14744",
        "arxiv_id": "2409.14744",
        "authors": "Sihui Yang, Keping Bi, Wanqing Cui, Jiafeng Guo, Xueqi Cheng",
        "summary": "Non-Factoid (NF) Question Answering (QA) is challenging to evaluate due to diverse potential answers and no objective criterion. The commonly used automatic evaluation metrics like ROUGE or BERTScore cannot accurately measure semantic similarities or answers from different perspectives. Recently, Large Language Models (LLMs) have been resorted to for NFQA evaluation due to their compelling performance on various NLP tasks. Common approaches include pointwise scoring of each candidate answer and pairwise comparisons between answers. Inspired by the evolution from pointwise to pairwise to listwise in learning-to-rank methods, we propose a novel listwise NFQA evaluation approach, that utilizes LLMs to rank candidate answers in a list of reference answers sorted by descending quality. Moreover, for NF questions that do not have multi-grade or any golden answers, we leverage LLMs to generate the reference answer list of various quality to facilitate the listwise evaluation. Extensive experimental results on three NFQA datasets, i.e., ANTIQUE, the TREC-DL-NF, and WebGLM show that our method has significantly higher correlations with human annotations compared to automatic scores and common pointwise and pairwise approaches.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 06:42:21 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344417"
    },
    {
        "index": "#39",
        "title": "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information",
        "link": "/arxiv/2409.14740",
        "arxiv_id": "2409.14740",
        "authors": "Zheng Hui, Zhaoxiao Guo, Hang Zhao, Juanyong Duan, Congrui Huang",
        "summary": "In different NLP tasks, detecting harmful content is crucial for online environments, especially with the growing influence of social media. However, previous research has two main issues: 1) a lack of data in low-resource settings, and 2) inconsistent definitions and criteria for judging harmful content, requiring classification models to be robust to spurious features and diverse. We propose Toxicraft, a novel framework for synthesizing datasets of harmful information to address these weaknesses. With only a small amount of seed data, our framework can generate a wide variety of synthetic, yet remarkably realistic, examples of toxic information. Experimentation across various datasets showcases a notable enhancement in detection model robustness and adaptability, surpassing or close to the gold labels. We release the generated data at Github upon acceptance.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 06:36:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344616"
    },
    {
        "index": "#40",
        "title": "ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning",
        "link": "/arxiv/2409.14710",
        "arxiv_id": "2409.14710",
        "authors": "Yihong Tang, Jiao Ou, Che Liu, Fuzheng Zhang, Di Zhang, Kun Gai",
        "summary": "Role-playing is an emerging application in the field of Human-Computer Interaction (HCI), primarily implemented through the alignment training of a large language model (LLM) with assigned characters. Despite significant progress, role-playing agents (RPLAs) still struggle with maintaining role-consistency across conversations, particularly when confronted with boundary queries subtly related to character attributes. In this paper, we present ERABAL, a framework aimed at enhancing RPLAs' role-playing capabilities through boundary-aware learning. ERABAL encompasses a generation pipeline for role-specific dialogues and a concomitant methodology for alignment training. Through comprehensive evaluations, we demonstrate that ERABAL is both efficient and effective. By training with significantly fewer dialogues than those used in leading approaches, ERABAL achieves notable improvements across WikiRoleEval, CharacterEval, and the role-playing subset of MT-Bench compared to the generalist baseline models. Our code and datasets will be made publicly available to support further research.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 05:12:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344818"
    },
    {
        "index": "#41",
        "title": "Target-Aware Language Modeling via Granular Data Sampling",
        "link": "/arxiv/2409.14705",
        "arxiv_id": "2409.14705",
        "authors": "Ernie Chang, Pin-Jie Lin, Yang Li, Changsheng Zhao, Daeil Kim, Rastislav Rabatin, Zechun Liu, Yangyang Shi, Vikas Chandra",
        "summary": "Language model pretraining generally targets a broad range of use cases and incorporates data from diverse sources. However, there are instances where we desire a model that excels in specific areas without markedly compromising performance in other areas. A cost-effective and straightforward approach is sampling with low-dimensional data features, which allows to select large-scale pretraining data for domain-specific use cases. In this work, we revisit importance sampling with n-gram features consisting of multi-granular tokens, which strikes a good balance between sentence compression and representation capabilities. We observed the sampled data to have a high correlation with the target downstream task performance while preserving its effectiveness on other tasks. This leads to the proposed data sampling paradigm where language models can be pretrained more efficiently on selected documents. On eight benchmarks we demonstrate with $\\sim$1% of the data, pretrained models perform on par with the full RefinedWeb data and outperform randomly selected samples for model sizes ranging from 125M to 1.5B.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 04:52:17 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.345056"
    },
    {
        "index": "#42",
        "title": "Instruction Tuning Vs. In-Context Learning: Revisiting Large Language Models in Few-Shot Computational Social Science",
        "link": "/arxiv/2409.14673",
        "arxiv_id": "2409.14673",
        "authors": "Taihang Wang, Xiaoman Xu, Yimin Wang, Ye Jiang",
        "summary": "Real-world applications of large language models (LLMs) in computational social science (CSS) tasks primarily depend on the effectiveness of instruction tuning (IT) or in-context learning (ICL). While IT has shown highly effective at fine-tuning LLMs for various tasks, ICL offers a rapid alternative for task adaptation by learning from examples without explicit gradient updates. In this paper, we evaluate the classification performance of LLMs using IT versus ICL in few-shot CSS tasks. The experimental results indicate that ICL consistently outperforms IT in most CSS tasks. Additionally, we investigate the relationship between the increasing number of training samples and LLM performance. Our findings show that simply increasing the number of samples without considering their quality does not consistently enhance the performance of LLMs with either ICL or IT and can sometimes even result in a performance decline. Finally, we compare three prompting strategies, demonstrating that ICL is more effective than zero-shot and Chain-of-Thought (CoT). Our research highlights the significant advantages of ICL in handling CSS tasks in few-shot settings and emphasizes the importance of optimizing sample quality and prompting strategies to improve LLM classification performance. The code will be made available.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 02:43:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.345283"
    },
    {
        "index": "#43",
        "title": "Direct Judgement Preference Optimization",
        "link": "/arxiv/2409.14664",
        "arxiv_id": "2409.14664",
        "authors": "Peifeng Wang, Austin Xu, Yilun Zhou, Caiming Xiong, Shafiq Joty",
        "summary": "Auto-evaluation is crucial for assessing response quality and offering feedback for model development. Recent studies have explored training large language models (LLMs) as generative judges to evaluate and critique other models' outputs. In this work, we investigate the idea of learning from both positive and negative data with preference optimization to enhance the evaluation capabilities of LLM judges across an array of different use cases. We achieve this by employing three approaches to collect the preference pairs for different use cases, each aimed at improving our generative judge from a different perspective. Our comprehensive study over a wide range of benchmarks demonstrates the effectiveness of our method. In particular, our generative judge achieves the best performance on 10 out of 13 benchmarks, outperforming strong baselines like GPT-4o and specialized judge models. Further analysis show that our judge model robustly counters inherent biases such as position and length bias, flexibly adapts to any evaluation protocol specified by practitioners, and provides helpful language feedback for improving downstream generator models.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 02:08:20 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.345490"
    },
    {
        "index": "#44",
        "title": "Building Tamil Treebanks",
        "link": "/arxiv/2409.14657",
        "arxiv_id": "2409.14657",
        "authors": "Kengatharaiyer Sarveswaran",
        "summary": "Treebanks are important linguistic resources, which are structured and annotated corpora with rich linguistic annotations. These resources are used in Natural Language Processing (NLP) applications, supporting linguistic analyses, and are essential for training and evaluating various computational models. This paper discusses the creation of Tamil treebanks using three distinct approaches: manual annotation, computational grammars, and machine learning techniques. Manual annotation, though time-consuming and requiring linguistic expertise, ensures high-quality and rich syntactic and semantic information. Computational deep grammars, such as Lexical Functional Grammar (LFG), offer deep linguistic analyses but necessitate significant knowledge of the formalism. Machine learning approaches, utilising off-the-shelf frameworks and tools like Stanza, UDpipe, and UUParser, facilitate the automated annotation of large datasets but depend on the availability of quality annotated data, cross-linguistic training resources, and computational power. The paper discusses the challenges encountered in building Tamil treebanks, including issues with Internet data, the need for comprehensive linguistic analysis, and the difficulty of finding skilled annotators. Despite these challenges, the development of Tamil treebanks is essential for advancing linguistic research and improving NLP tools for Tamil.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 01:58:50 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.350937"
    },
    {
        "index": "#45",
        "title": "Harmonising the Clinical Melody: Tuning Large Language Models for Hospital Course Summarisation in Clinical Coding",
        "link": "/arxiv/2409.14638",
        "arxiv_id": "2409.14638",
        "authors": "Bokang Bi, Leibo Liu, Oscar Perez-Concha, Sanja Lujic, Louisa Jorm",
        "summary": "The increasing volume and complexity of clinical documentation in Electronic Medical Records systems pose significant challenges for clinical coders, who must mentally process and summarise vast amounts of clinical text to extract essential information needed for coding tasks. While large language models have been successfully applied to shorter summarisation tasks in recent years, the challenge of summarising a hospital course remains an open area for further research and development. In this study, we adapted three pre trained LLMs, Llama 3, BioMistral, Mistral Instruct v0.1 for the hospital course summarisation task, using Quantized Low Rank Adaptation fine tuning. We created a free text clinical dataset from MIMIC III data by concatenating various clinical notes as the input clinical text, paired with ground truth Brief Hospital Course sections extracted from the discharge summaries for model training. The fine tuned models were evaluated using BERTScore and ROUGE metrics to assess the effectiveness of clinical domain fine tuning. Additionally, we validated their practical utility using a novel hospital course summary assessment metric specifically tailored for clinical coding. Our findings indicate that fine tuning pre trained LLMs for the clinical domain can significantly enhance their performance in hospital course summarisation and suggest their potential as assistive tools for clinical coding. Future work should focus on refining data curation methods to create higher quality clinical datasets tailored for hospital course summary tasks and adapting more advanced open source LLMs comparable to proprietary models to further advance this research.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-23 00:35:23 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.351391"
    },
    {
        "index": "#46",
        "title": "Can a Neural Model Guide Fieldwork? A Case Study on Morphological Inflection",
        "link": "/arxiv/2409.14628",
        "arxiv_id": "2409.14628",
        "authors": "Aso Mahmudi, Borja Herce, Demian Inostroza Amestica, Andreas Scherbakov, Eduard Hovy, Ekaterina Vylomova",
        "summary": "Linguistic fieldwork is an important component in language documentation and preservation. However, it is a long, exhaustive, and time-consuming process. This paper presents a novel model that guides a linguist during the fieldwork and accounts for the dynamics of linguist-speaker interactions. We introduce a novel framework that evaluates the efficiency of various sampling strategies for obtaining morphological data and assesses the effectiveness of state-of-the-art neural models in generalising morphological structures. Our experiments highlight two key strategies for improving the efficiency: (1) increasing the diversity of annotated data by uniform sampling among the cells of the paradigm tables, and (2) using model confidence as a guide to enhance positive interaction by providing reliable predictions during annotation.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 23:40:03 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.351792"
    },
    {
        "index": "#47",
        "title": "Can pre-trained language models generate titles for research papers?",
        "link": "/arxiv/2409.14602",
        "arxiv_id": "2409.14602",
        "authors": "Tohida Rehman, Debarshi Kumar Sanyal, Samiran Chattopadhyay",
        "summary": "The title of a research paper communicates in a succinct style the main theme and, sometimes, the findings of the paper. Coming up with the right title is often an arduous task, and therefore, it would be beneficial to authors if title generation can be automated. In this paper, we fine-tune pre-trained and large language models to generate titles of papers from their abstracts. We also use ChatGPT in a zero-shot setting to generate paper titles. The performance of the models is measured with ROUGE, METEOR, MoverScore, BERTScore and SciBERTScore metrics.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 21:34:49 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352115"
    },
    {
        "index": "#48",
        "title": "EchoAtt: Attend, Copy, then Adjust for More Efficient Large Language Models",
        "link": "/arxiv/2409.14595",
        "arxiv_id": "2409.14595",
        "authors": "Hossein Rajabzadeh, Aref Jafari, Aman Sharma, Benyamin Jami, Hyock Ju Kwon, Ali Ghodsi, Boxing Chen, Mehdi Rezagholizadeh",
        "summary": "Large Language Models (LLMs), with their increasing depth and number of parameters, have demonstrated outstanding performance across a variety of natural language processing tasks. However, this growth in scale leads to increased computational demands, particularly during inference and fine-tuning. To address these challenges, we introduce EchoAtt, a novel framework aimed at optimizing transformer-based models by analyzing and leveraging the similarity of attention patterns across layers. Our analysis reveals that many inner layers in LLMs, especially larger ones, exhibit highly similar attention matrices. By exploiting this similarity, EchoAtt enables the sharing of attention matrices in less critical layers, significantly reducing computational requirements without compromising performance. We incorporate this approach within a knowledge distillation setup, where a pre-trained teacher model guides the training of a smaller student model. The student model selectively shares attention matrices in layers with high similarity while inheriting key parameters from the teacher. Our best results with TinyLLaMA-1.1B demonstrate that EchoAtt improves inference speed by 15\\%, training speed by 25\\%, and reduces the number of parameters by approximately 4\\%, all while improving zero-shot performance. These findings highlight the potential of attention matrix sharing to enhance the efficiency of LLMs, making them more practical for real-time and resource-limited applications.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-22 21:08:37 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352409"
    },
    {
        "index": "#49",
        "title": "The X Types -- Mapping the Semantics of the Twitter Sphere",
        "link": "/arxiv/2409.14584",
        "arxiv_id": "2409.14584",
        "authors": "Ogen Schlachet Drukerman, Einat Minkov",
        "summary": "Social networks form a valuable source of world knowledge, where influential entities correspond to popular accounts. Unlike factual knowledge bases (KBs), which maintain a semantic ontology, structured semantic information is not available on social media. In this work, we consider a social KB of roughly 200K popular Twitter accounts, which denotes entities of interest. We elicit semantic information about those entities. In particular, we associate them with a fine-grained set of 136 semantic types, e.g., determine whether a given entity account belongs to a politician, or a musical artist. In the lack of explicit type information in Twitter, we obtain semantic labels for a subset of the accounts via alignment with the KBs of DBpedia and Wikidata. Given the labeled dataset, we finetune a transformer-based text encoder to generate semantic embeddings of the entities based on the contents of their accounts. We then exploit this evidence alongside network-based embeddings to predict the entities semantic types. In our experiments, we show high type prediction performance on the labeled dataset. Consequently, we apply our type classification model to all of the entity accounts in the social KB. Our analysis of the results offers insights about the global semantics of the Twitter sphere. We discuss downstream applications that should benefit from semantic type information and the semantic embeddings of social entities generated in this work. In particular, we demonstrate enhanced performance on the key task of entity similarity assessment using this information.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 20:22:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352578"
    },
    {
        "index": "#50",
        "title": "Medical Concept Normalization in a Low-Resource Setting",
        "link": "/arxiv/2409.14579",
        "arxiv_id": "2409.14579",
        "authors": "Tim Patzelt",
        "summary": "In the field of biomedical natural language processing, medical concept normalization is a crucial task for accurately mapping mentions of concepts to a large knowledge base. However, this task becomes even more challenging in low-resource settings, where limited data and resources are available. In this thesis, I explore the challenges of medical concept normalization in a low-resource setting. Specifically, I investigate the shortcomings of current medical concept normalization methods applied to German lay texts. Since there is no suitable dataset available, a dataset consisting of posts from a German medical online forum is annotated with concepts from the Unified Medical Language System. The experiments demonstrate that multilingual Transformer-based models are able to outperform string similarity methods. The use of contextual information to improve the normalization of lay mentions is also examined, but led to inferior results. Based on the results of the best performing model, I present a systematic error analysis and lay out potential improvements to mitigate frequent errors.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-06 10:19:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352746"
    },
    {
        "index": "#51",
        "title": "Evaluating the Performance and Robustness of LLMs in Materials Science Q&A and Property Predictions",
        "link": "/arxiv/2409.14572",
        "arxiv_id": "2409.14572",
        "authors": "Hongchen Wang, Kangming Li, Scott Ramsay, Yao Fehlis, Edward Kim, Jason Hattrick-Simpers",
        "summary": "Large Language Models (LLMs) have the potential to revolutionize scientific research, yet their robustness and reliability in domain-specific applications remain insufficiently explored. This study conducts a comprehensive evaluation and robustness analysis of LLMs within the field of materials science, focusing on domain-specific question answering and materials property prediction. Three distinct datasets are used in this study: 1) a set of multiple-choice questions from undergraduate-level materials science courses, 2) a dataset including various steel compositions and yield strengths, and 3) a band gap dataset, containing textual descriptions of material crystal structures and band gap values. The performance of LLMs is assessed using various prompting strategies, including zero-shot chain-of-thought, expert prompting, and few-shot in-context learning. The robustness of these models is tested against various forms of 'noise', ranging from realistic disturbances to intentionally adversarial manipulations, to evaluate their resilience and reliability under real-world conditions. Additionally, the study uncovers unique phenomena of LLMs during predictive tasks, such as mode collapse behavior when the proximity of prompt examples is altered and performance enhancement from train/test mismatch. The findings aim to provide informed skepticism for the broad use of LLMs in materials science and to inspire advancements that enhance their robustness and reliability for practical applications.",
        "subjects": "Computation and Language, Materials Science, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 19:31:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352972"
    },
    {
        "index": "#52",
        "title": "Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training",
        "link": "/arxiv/2409.14552",
        "arxiv_id": "2409.14552",
        "authors": "Zhou Zhang, Dongzeng Tan, Jiaan Wang, Yilong Chen, Jiarong Xu",
        "summary": "Emojis have gained immense popularity on social platforms, serving as a common means to supplement or replace text. However, existing data mining approaches generally either completely ignore or simply treat emojis as ordinary Unicode characters, which may limit the model's ability to grasp the rich semantic information in emojis and the interaction between emojis and texts. Thus, it is necessary to release the emoji's power in social media data mining. To this end, we first construct a heterogeneous graph consisting of three types of nodes, i.e. post, word and emoji nodes to improve the representation of different elements in posts. The edges are also well-defined to model how these three elements interact with each other. To facilitate the sharing of information among post, word and emoji nodes, we propose a graph pre-train framework for text and emoji co-modeling, which contains two graph pre-training tasks: node-level graph contrastive learning and edge-level link reconstruction learning. Extensive experiments on the Xiaohongshu and Twitter datasets with two types of downstream tasks demonstrate that our approach proves significant improvement over previous strong baseline methods.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 18:29:10 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.353215"
    },
    {
        "index": "#53",
        "title": "Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits",
        "link": "/arxiv/2409.14509",
        "arxiv_id": "2409.14509",
        "authors": "Tuhin Chakrabarty, Philippe Laban, Chien-Sheng Wu",
        "summary": "LLM-based applications are helping people write, and LLM-generated text is making its way into social media, journalism, and our classrooms. However, the differences between LLM-generated and human-written text remain unclear. To explore this, we hired professional writers to edit paragraphs in several creative domains. We first found these writers agree on undesirable idiosyncrasies in LLM-generated text, formalizing it into a seven-category taxonomy (e.g. cliches, unnecessary exposition). Second, we curated the LAMP corpus: 1,057 LLM-generated paragraphs edited by professional writers according to our taxonomy. Analysis of LAMP reveals that none of the LLMs used in our study (GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) outperform each other in terms of writing quality, revealing common limitations across model families. Third, we explored automatic editing methods to improve LLM-generated text. A large-scale preference annotation confirms that although experts largely prefer text edited by other experts, automatic editing methods show promise in improving alignment between LLM-generated and human-written text.",
        "subjects": "Computation and Language, Computers and Society, Human-Computer Interaction",
        "date": "2024-09-22 16:13:00 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.353479"
    },
    {
        "index": "#54",
        "title": "A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders",
        "link": "/arxiv/2409.14507",
        "arxiv_id": "2409.14507",
        "authors": "David Chanin, James Wilken-Smith, Tomáš Dulka, Hardik Bhatnagar, Joseph Bloom",
        "summary": "Sparse Autoencoders (SAEs) have emerged as a promising approach to decompose the activations of Large Language Models (LLMs) into human-interpretable latents. In this paper, we pose two questions. First, to what extent do SAEs extract monosemantic and interpretable latents? Second, to what extent does varying the sparsity or the size of the SAE affect monosemanticity / interpretability? By investigating these questions in the context of a simple first-letter identification task where we have complete access to ground truth labels for all tokens in the vocabulary, we are able to provide more detail than prior investigations. Critically, we identify a problematic form of feature-splitting we call feature absorption where seemingly monosemantic latents fail to fire in cases where they clearly should. Our investigation suggests that varying SAE size or sparsity is insufficient to solve this issue, and that there are deeper conceptual issues in need of resolution.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 16:11:02 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.353706"
    },
    {
        "index": "#55",
        "title": "Thought-Path Contrastive Learning via Premise-Oriented Data Augmentation for Logical Reading Comprehension",
        "link": "/arxiv/2409.14495",
        "arxiv_id": "2409.14495",
        "authors": "Chenxu Wang, Ping Jian, Yang Zhen",
        "summary": "Logical reading comprehension is a challenging task that entails grasping the underlying semantics of text and applying reasoning to deduce the correct answer. Prior researches have primarily focused on enhancing logical reasoning capabilities through Chain-of-Thought (CoT) or data augmentation. However, previous work constructing chain-of-thought rationales concentrates solely on analyzing correct options, neglecting the incorrect alternatives. Addtionally, earlier efforts on data augmentation by altering contexts rely on rule-based methods, which result in generated contexts that lack diversity and coherence. To address these issues, we propose a Premise-Oriented Data Augmentation (PODA) framework. This framework can generate CoT rationales including analyses for both correct and incorrect options, while constructing diverse and high-quality counterfactual contexts from incorrect candidate options. We integrate summarizing premises and identifying premises for each option into rationales. Subsequently, we employ multi-step prompts with identified premises to construct counterfactual context. To facilitate the model's capabilities to better differentiate the reasoning process associated with each option, we introduce a novel thought-path contrastive learning method that compares reasoning paths between the original and counterfactual samples. Experimental results on three representative LLMs demonstrate that our method can improve the baselines substantially across two challenging logical reasoning benchmarks (ReClor and LogiQA 2.0). The data and code are released at https://github.com/lalalamdbf/TPReasoner.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 15:44:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.353907"
    },
    {
        "index": "#56",
        "title": "CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for Classroom Environments",
        "link": "/arxiv/2409.14494",
        "arxiv_id": "2409.14494",
        "authors": "Ahmed Adel Attia, Dorottya Demszky, Tolulope Ogunremi, Jing Liu, Carol Espy-Wilson",
        "summary": "Creating Automatic Speech Recognition (ASR) systems that are robust and resilient to classroom conditions is paramount to the development of AI tools to aid teachers and students. In this work, we study the efficacy of continued pretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that CPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of Wav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the model's robustness to different noises, microphones and classroom conditions.",
        "subjects": "Computation and Language, Machine Learning, Sound, Audio and Speech Processing",
        "date": "2024-09-13 19:14:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354162"
    },
    {
        "index": "#57",
        "title": "Rethinking Semantic Parsing for Large Language Models: Enhancing LLM Performance with Semantic Hints",
        "link": "/arxiv/2409.14469",
        "arxiv_id": "2409.14469",
        "authors": "Kaikai An, Shuzheng Si, Helan Hu, Haozhe Zhao, Yuchi Wang, Qingyan Guo, Baobao Chang",
        "summary": "Semantic Parsing aims to capture the meaning of a sentence and convert it into a logical, structured form. Previous studies show that semantic parsing enhances the performance of smaller models (e.g., BERT) on downstream tasks. However, it remains unclear whether the improvements extend similarly to LLMs. In this paper, our empirical findings reveal that, unlike smaller models, directly adding semantic parsing results into LLMs reduces their performance. To overcome this, we propose SENSE, a novel prompting approach that embeds semantic hints within the prompt. Experiments show that SENSE consistently improves LLMs' performance across various tasks, highlighting the potential of integrating semantic information to improve LLM capabilities.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 14:35:09 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354384"
    },
    {
        "index": "#58",
        "title": "AggregHate: An Efficient Aggregative Approach for the Detection of Hatemongers on Social Platforms",
        "link": "/arxiv/2409.14464",
        "arxiv_id": "2409.14464",
        "authors": "Tom Marzea, Abraham Israeli, Oren Tsur",
        "summary": "Automatic detection of online hate speech serves as a crucial step in the detoxification of the online discourse. Moreover, accurate classification can promote a better understanding of the proliferation of hate as a social phenomenon. While most prior work focus on the detection of hateful utterances, we argue that focusing on the user level is as important, albeit challenging. In this paper we consider a multimodal aggregative approach for the detection of hate-mongers, taking into account the potentially hateful texts, user activity, and the user network. We evaluate our methods on three unique datasets X (Twitter), Gab, and Parler showing that a processing a user's texts in her social context significantly improves the detection of hate mongers, compared to previously used text and graph-based methods. Our method can be then used to improve the classification of coded messages, dog-whistling, and racial gas-lighting, as well as inform intervention measures. Moreover, our approach is highly efficient even for very large datasets and networks.",
        "subjects": "Computation and Language, Social and Information Networks",
        "date": "2024-09-22 14:29:49 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354570"
    },
    {
        "index": "#59",
        "title": "Exploring Multilingual Probing in Large Language Models: A Cross-Language Analysis",
        "link": "/arxiv/2409.14459",
        "arxiv_id": "2409.14459",
        "authors": "Daoyang Li, Mingyu Jin, Qingcheng Zeng, Haiyan Zhao, Mengnan Du",
        "summary": "Probing techniques for large language models (LLMs) have primarily focused on English, overlooking the vast majority of the world's languages. In this paper, we extend these probing methods to a multilingual context, investigating the behaviors of LLMs across diverse languages. We conduct experiments on several open-source LLM models, analyzing probing accuracy, trends across layers, and similarities between probing vectors for multiple languages. Our key findings reveal: (1) a consistent performance gap between high-resource and low-resource languages, with high-resource languages achieving significantly higher probing accuracy; (2) divergent layer-wise accuracy trends, where high-resource languages show substantial improvement in deeper layers similar to English; and (3) higher representational similarities among high-resource languages, with low-resource languages demonstrating lower similarities both among themselves and with high-resource languages. These results highlight significant disparities in LLMs' multilingual capabilities and emphasize the need for improved modeling of low-resource languages.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 14:14:05 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354789"
    },
    {
        "index": "#60",
        "title": "Automotive innovation landscaping using LLM",
        "link": "/arxiv/2409.14436",
        "arxiv_id": "2409.14436",
        "authors": "Raju Gorain, Omkar Salunke",
        "summary": "The process of landscaping automotive innovation through patent analysis is crucial for Research and Development teams. It aids in comprehending innovation trends, technological advancements, and the latest technologies from competitors. Traditionally, this process required intensive manual efforts. However, with the advent of Large Language Models (LLMs), it can now be automated, leading to faster and more efficient patent categorization & state-of-the-art of inventive concept extraction. This automation can assist various R\\&D teams in extracting relevant information from extensive patent databases. This paper introduces a method based on prompt engineering to extract essential information for landscaping. The information includes the problem addressed by the patent, the technology utilized, and the area of innovation within the vehicle ecosystem (such as safety, Advanced Driver Assistance Systems and more).The result demonstrates the implementation of this method to create a landscape of fuel cell technology using open-source patent data. This approach provides a comprehensive overview of the current state of fuel cell technology, offering valuable insights for future research and development in this field.",
        "subjects": "Computation and Language, Artificial Intelligence, Robotics",
        "date": "2024-09-22 13:22:39 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354985"
    },
    {
        "index": "#61",
        "title": "Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations",
        "link": "/arxiv/2409.14399",
        "arxiv_id": "2409.14399",
        "authors": "Peixin Qin, Chen Huang, Yang Deng, Wenqiang Lei, Tat-Seng Chua",
        "summary": "With the aid of large language models, current conversational recommender system (CRS) has gaining strong abilities to persuade users to accept recommended items. While these CRSs are highly persuasive, they can mislead users by incorporating incredible information in their explanations, ultimately damaging the long-term trust between users and the CRS. To address this, we propose a simple yet effective method, called PC-CRS, to enhance the credibility of CRS's explanations during persuasion. It guides the explanation generation through our proposed credibility-aware persuasive strategies and then gradually refines explanations via post-hoc self-reflection. Experimental results demonstrate the efficacy of PC-CRS in promoting persuasive and credible explanations. Further analysis reveals the reason behind current methods producing incredible explanations and the potential of credible explanations to improve recommendation accuracy.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 11:35:59 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.355185"
    },
    {
        "index": "#62",
        "title": "Predicting User Stances from Target-Agnostic Information using Large Language Models",
        "link": "/arxiv/2409.14395",
        "arxiv_id": "2409.14395",
        "authors": "Siyuan Brandon Loh, Liang Ze Wong, Prasanta Bhattacharya, Joseph Simons, Wei Gao, Hong Zhang",
        "summary": "We investigate Large Language Models' (LLMs) ability to predict a user's stance on a target given a collection of his/her target-agnostic social media posts (i.e., user-level stance prediction). While we show early evidence that LLMs are capable of this task, we highlight considerable variability in the performance of the model across (i) the type of stance target, (ii) the prediction strategy and (iii) the number of target-agnostic posts supplied. Post-hoc analyses further hint at the usefulness of target-agnostic posts in providing relevant information to LLMs through the presence of both surface-level (e.g., target-relevant keywords) and user-level features (e.g., encoding users' moral values). Overall, our findings suggest that LLMs might offer a viable method for determining public stances towards new topics based on historical and target-agnostic data. At the same time, we also call for further research to better understand LLMs' strong performance on the stance prediction task and how their effectiveness varies across task contexts.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 11:21:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.355497"
    },
    {
        "index": "#63",
        "title": "Investigating Layer Importance in Large Language Models",
        "link": "/arxiv/2409.14381",
        "arxiv_id": "2409.14381",
        "authors": "Yang Zhang, Yanfei Dong, Kenji Kawaguchi",
        "summary": "Large language models (LLMs) have gained increasing attention due to their prominent ability to understand and process texts. Nevertheless, LLMs largely remain opaque. The lack of understanding of LLMs has obstructed the deployment in safety-critical scenarios and hindered the development of better models. In this study, we advance the understanding of LLM by investigating the significance of individual layers in LLMs. We propose an efficient sampling method to faithfully evaluate the importance of layers using Shapley values, a widely used explanation framework in feature attribution and data valuation. In addition, we conduct layer ablation experiments to assess the performance degradation resulting from the exclusion of specific layers. Our findings reveal the existence of cornerstone layers, wherein certain early layers can exhibit a dominant contribution over others. Removing one cornerstone layer leads to a drastic collapse of the model performance, often reducing it to random guessing. Conversely, removing non-cornerstone layers results in only marginal performance changes. This study identifies cornerstone layers in LLMs and underscores their critical role for future research.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-22 09:53:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.355696"
    },
    {
        "index": "#64",
        "title": "J2N -- Nominal Adjective Identification and its Application",
        "link": "/arxiv/2409.14374",
        "arxiv_id": "2409.14374",
        "authors": "Lemeng Qi, Yang Han, Zhuotong Xie",
        "summary": "This paper explores the challenges posed by nominal adjectives (NAs) in natural language processing (NLP) tasks, particularly in part-of-speech (POS) tagging. We propose treating NAs as a distinct POS tag, \"JN,\" and investigate its impact on POS tagging, BIO chunking, and coreference resolution. Our study shows that reclassifying NAs can improve the accuracy of syntactic analysis and structural understanding in NLP. We present experimental results using Hidden Markov Models (HMMs), Maximum Entropy (MaxEnt) models, and Spacy, demonstrating the feasibility and potential benefits of this approach. Additionally we trained a bert model to identify the NA in untagged text.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 09:33:54 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.355874"
    },
    {
        "index": "#65",
        "title": "The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests",
        "link": "/arxiv/2409.14371",
        "arxiv_id": "2409.14371",
        "authors": "Lior Madmoni, Amir Zait, Ilia Labzovsky, Danny Karmon",
        "summary": "Generative AI agents are often expected to respond to complex user requests that have No One Right Answer (NORA), e.g., \"design a vegetarian meal plan below 1800 calories\". Such requests may entail a set of constraints that the agent should adhere to. To successfully develop agents for NORA scenarios, an accurate automatic evaluation framework is essential, and specifically - one capable of validating the satisfaction of constraints in the agent's response. Recently, large language models (LLMs) have been adopted as versatile evaluators for many NORA tasks, but their ability to evaluate constraint-satisfaction in generated text remains unclear. To study this, we develop and release a novel Arithmetic Constraint-Satisfaction (ACS) benchmarking dataset. The dataset consists of complex user requests with corresponding constraints, agent responses and human labels indicating each constraint's satisfaction level in the response. A unique property of this dataset is that validating many of its constraints requires reviewing the response as a whole (in contrast to many other benchmarks that require the validation of a single independent item). Moreover, it assesses LLMs in performing reasoning, in-context data extraction, arithmetic calculations, and counting. We then benchmark both open and proprietary LLMs on evaluating constraint-satisfaction, and show that most models still have a significant headroom for improvement, and that errors primarily stem from reasoning issues. In addition, most models exhibit a skewed constraint-satisfaction prediction pattern, with higher accuracy where the ground-truth label is \"satisfied\". Lastly, few-shot prompting for our task proved to be rather challenging, since many of the studied models showed a degradation in performance when it was introduced.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 09:27:42 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.473885"
    },
    {
        "index": "#66",
        "title": "More Effective LLM Compressed Tokens with Uniformly Spread Position Identifiers and Compression Loss",
        "link": "/arxiv/2409.14364",
        "arxiv_id": "2409.14364",
        "authors": "Runsong Zhao, Pengcheng Huang, Xinyu Liu, Chunyang Xiao, Tong Xiao, Jingbo Zhu",
        "summary": "Compressing Transformer inputs into compressd tokens allows running LLMs with improved speed and cost efficiency. Based on the compression method ICAE, we carefully examine the position identifier choices for compressed tokens and also propose a new compression loss. We demonstrate empirically that our proposed methods achieve significantly higher compression ratios (15x compared to 4x for ICAE), while being able to attain comparable reconstruction performance.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 08:51:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.490842"
    },
    {
        "index": "#67",
        "title": "Using Natural Language Processing to find Indication for Burnout with Text Classification: From Online Data to Real-World Data",
        "link": "/arxiv/2409.14357",
        "arxiv_id": "2409.14357",
        "authors": "Mascha Kurpicz-Briki, Ghofrane Merhbene, Alexandre Puttick, Souhir Ben Souissi, Jannic Bieri, Thomas Jörg Müller, Christoph Golz",
        "summary": "Burnout, classified as a syndrome in the ICD-11, arises from chronic workplace stress that has not been effectively managed. It is characterized by exhaustion, cynicism, and reduced professional efficacy, and estimates of its prevalence vary significantly due to inconsistent measurement methods. Recent advancements in Natural Language Processing (NLP) and machine learning offer promising tools for detecting burnout through textual data analysis, with studies demonstrating high predictive accuracy. This paper contributes to burnout detection in German texts by: (a) collecting an anonymous real-world dataset including free-text answers and Oldenburg Burnout Inventory (OLBI) responses; (b) demonstrating the limitations of a GermanBERT-based classifier trained on online data; (c) presenting two versions of a curated BurnoutExpressions dataset, which yielded models that perform well in real-world applications; and (d) providing qualitative insights from an interdisciplinary focus group on the interpretability of AI models used for burnout detection. Our findings emphasize the need for greater collaboration between AI researchers and clinical experts to refine burnout detection models. Additionally, more real-world data is essential to validate and enhance the effectiveness of current AI methods developed in NLP research, which are often based on data automatically scraped from online sources and not evaluated in a real-world context. This is essential for ensuring AI tools are well suited for practical applications.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-22 08:13:17 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.491271"
    },
    {
        "index": "#68",
        "title": "MQM-APE: Toward High-Quality Error Annotation Predictors with Automatic Post-Editing in LLM Translation Evaluators",
        "link": "/arxiv/2409.14335",
        "arxiv_id": "2409.14335",
        "authors": "Qingyu Lu, Liang Ding, Kanjian Zhang, Jinxia Zhang, Dacheng Tao",
        "summary": "Large Language Models (LLMs) have shown significant potential as judges for Machine Translation (MT) quality assessment, providing both scores and fine-grained feedback. Although approaches such as GEMBA-MQM has shown SOTA performance on reference-free evaluation, the predicted errors do not align well with those annotated by human, limiting their interpretability as feedback signals. To enhance the quality of error annotations predicted by LLM evaluators, we introduce a universal and training-free framework, $\\textbf{MQM-APE}$, based on the idea of filtering out non-impactful errors by Automatically Post-Editing (APE) the original translation based on each error, leaving only those errors that contribute to quality improvement. Specifically, we prompt the LLM to act as 1) $\\textit{evaluator}$ to provide error annotations, 2) $\\textit{post-editor}$ to determine whether errors impact quality improvement and 3) $\\textit{pairwise quality verifier}$ as the error filter. Experiments show that our approach consistently improves both the reliability and quality of error spans against GEMBA-MQM, across eight LLMs in both high- and low-resource languages. Orthogonal to trained approaches, MQM-APE complements translation-specific evaluators such as Tower, highlighting its broad applicability. Further analysis confirm the effectiveness of each module and offer valuable insights into evaluator design and LLMs selection. The code will be released to facilitate the community.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 06:43:40 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.491552"
    },
    {
        "index": "#69",
        "title": "Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses",
        "link": "/arxiv/2409.14324",
        "arxiv_id": "2409.14324",
        "authors": "Hung-Ting Su, Ya-Ching Hsu, Xudong Lin, Xiang-Qian Shi, Yulei Niu, Han-Yuan Hsu, Hung-yi Lee, Winston H. Hsu",
        "summary": "Large language models (LLMs) equipped with chain-of-thoughts (CoT) prompting have shown significant multi-step reasoning capabilities in factual content like mathematics, commonsense, and logic. However, their performance in narrative reasoning, which demands greater abstraction capabilities, remains unexplored. This study utilizes tropes in movie synopses to assess the abstract reasoning abilities of state-of-the-art LLMs and uncovers their low performance. We introduce a trope-wise querying approach to address these challenges and boost the F1 score by 11.8 points. Moreover, while prior studies suggest that CoT enhances multi-step reasoning, this study shows CoT can cause hallucinations in narrative content, reducing GPT-4's performance. We also introduce an Adversarial Injection method to embed trope-related text tokens into movie synopses without explicit tropes, revealing CoT's heightened sensitivity to such injections. Our comprehensive analysis provides insights for future research directions.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 05:50:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.491781"
    },
    {
        "index": "#70",
        "title": "PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation",
        "link": "/arxiv/2409.14302",
        "arxiv_id": "2409.14302",
        "authors": "Yuxuan Zhou, Xien Liu, Chen Ning, Ji Wu",
        "summary": "In the study, we aim to investigate current LLMs' mastery of medical factual knowledge with a dynamic evaluation schema, which can automatically generate multiple test samples for each medical factual knowledge point. Test samples produced directly by LLMs always introduce factual errors and lack diversity in the manner of knowledge expression. To overcome the drawbacks, here we propose a novel evaluation method, Predicate-text Dual Transformation (PretextTrans), by introducing predicate transformations into the dynamic evaluation schema. Specifically, each medical knowledge point is firstly transformed into a predicate expression; then, the predicate expression derives a series of variants through predicate transformations; lastly, the produced predicate variants are transformed back into textual expressions, resulting in a series of test samples with both factual reliability and expression diversity. Using the proposed PretextTrans method, we systematically investigate 12 well-known LLMs' mastery of medical factual knowledge based on two medical datasets. The comparison results show that current LLMs still have significant deficiencies in fully mastering medical knowledge, which may illustrate why current LLMs still perform unsatisfactorily in real-world medical scenarios despite having achieved considerable performance on public benchmarks. Our proposed method serves as an effective solution for evaluation of LLMs in medical domain and offers valuable insights for developing medical-specific LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 03:13:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.491970"
    },
    {
        "index": "#71",
        "title": "ESPERANTO: Evaluating Synthesized Phrases to Enhance Robustness in AI Detection for Text Origination",
        "link": "/arxiv/2409.14285",
        "arxiv_id": "2409.14285",
        "authors": "Navid Ayoobi, Lily Knab, Wen Cheng, David Pantoja, Hamidreza Alikhani, Sylvain Flamant, Jin Kim, Arjun Mukherjee",
        "summary": "While large language models (LLMs) exhibit significant utility across various domains, they simultaneously are susceptible to exploitation for unethical purposes, including academic misconduct and dissemination of misinformation. Consequently, AI-generated text detection systems have emerged as a countermeasure. However, these detection mechanisms demonstrate vulnerability to evasion techniques and lack robustness against textual manipulations. This paper introduces back-translation as a novel technique for evading detection, underscoring the need to enhance the robustness of current detection systems. The proposed method involves translating AI-generated text through multiple languages before back-translating to English. We present a model that combines these back-translated texts to produce a manipulated version of the original AI-generated text. Our findings demonstrate that the manipulated text retains the original semantics while significantly reducing the true positive rate (TPR) of existing detection methods. We evaluate this technique on nine AI detectors, including six open-source and three proprietary systems, revealing their susceptibility to back-translation manipulation. In response to the identified shortcomings of existing AI text detectors, we present a countermeasure to improve the robustness against this form of manipulation. Our results indicate that the TPR of the proposed method declines by only 1.85% after back-translation manipulation. Furthermore, we build a large dataset of 720k texts using eight different LLMs. Our dataset contains both human-authored and LLM-generated texts in various domains and writing styles to assess the performance of our method and existing detectors. This dataset is publicly shared for the benefit of the research community.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 01:13:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.492267"
    },
    {
        "index": "#72",
        "title": "Instruction Following without Instruction Tuning",
        "link": "/arxiv/2409.14254",
        "arxiv_id": "2409.14254",
        "authors": "John Hewitt, Nelson F. Liu, Percy Liang, Christopher D. Manning",
        "summary": "Instruction tuning commonly means finetuning a language model on instruction-response pairs. We discover two forms of adaptation (tuning) that are deficient compared to instruction tuning, yet still yield instruction following; we call this implicit instruction tuning. We first find that instruction-response pairs are not necessary: training solely on responses, without any corresponding instructions, yields instruction following. This suggests pretrained models have an instruction-response mapping which is revealed by teaching the model the desired distribution of responses. However, we then find it's not necessary to teach the desired distribution of responses: instruction-response training on narrow-domain data like poetry still leads to broad instruction-following behavior like recipe generation. In particular, when instructions are very different from those in the narrow finetuning domain, models' responses do not adhere to the style of the finetuning domain. To begin to explain implicit instruction tuning, we hypothesize that very simple changes to a language model's distribution yield instruction following. We support this by hand-writing a rule-based language model which yields instruction following in a product-of-experts with a pretrained model. The rules are to slowly increase the probability of ending the sequence, penalize repetition, and uniformly change 15 words' probabilities. In summary, adaptations made without being designed to yield instruction following can do so implicitly.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 22:36:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.492468"
    },
    {
        "index": "#73",
        "title": "Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models",
        "link": "/arxiv/2409.14247",
        "arxiv_id": "2409.14247",
        "authors": "Javier Chiyah-Garcia, Alessandro Suglia, Arash Eshghi",
        "summary": "In dialogue, the addressee may initially misunderstand the speaker and respond erroneously, often prompting the speaker to correct the misunderstanding in the next turn with a Third Position Repair (TPR). The ability to process and respond appropriately to such repair sequences is thus crucial in conversational AI systems. In this paper, we first collect, analyse, and publicly release BlockWorld-Repairs: a dataset of multi-modal TPR sequences in an instruction-following manipulation task that is, by design, rife with referential ambiguity. We employ this dataset to evaluate several state-of-the-art Vision and Language Models (VLM) across multiple settings, focusing on their capability to process and accurately respond to TPRs and thus recover from miscommunication. We find that, compared to humans, all models significantly underperform in this task. We then show that VLMs can benefit from specialised losses targeting relevant tokens during fine-tuning, achieving better performance and generisability. Our results suggest that these models are not yet ready to be deployed in multi-modal collaborative settings where repairs are common, and highlight the need to design training regimes and objectives that facilitate learning from interaction.",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2024-09-21 21:06:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.492652"
    },
    {
        "index": "#74",
        "title": "Data-centric NLP Backdoor Defense from the Lens of Memorization",
        "link": "/arxiv/2409.14200",
        "arxiv_id": "2409.14200",
        "authors": "Zhenting Wang, Zhizhi Wang, Mingyu Jin, Mengnan Du, Juan Zhai, Shiqing Ma",
        "summary": "Backdoor attack is a severe threat to the trustworthiness of DNN-based language models. In this paper, we first extend the definition of memorization of language models from sample-wise to more fine-grained sentence element-wise (e.g., word, phrase, structure, and style), and then point out that language model backdoors are a type of element-wise memorization. Through further analysis, we find that the strength of such memorization is positively correlated to the frequency of duplicated elements in the training dataset. In conclusion, duplicated sentence elements are necessary for successful backdoor attacks. Based on this, we propose a data-centric defense. We first detect trigger candidates in training data by finding memorizable elements, i.e., duplicated elements, and then confirm real triggers by testing if the candidates can activate backdoor behaviors (i.e., malicious elements). Results show that our method outperforms state-of-the-art defenses in defending against different types of NLP backdoors.",
        "subjects": "Computation and Language, Cryptography and Security, Machine Learning",
        "date": "2024-09-21 17:12:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.492861"
    },
    {
        "index": "#75",
        "title": "The Imperative of Conversation Analysis in the Era of LLMs: A Survey of Tasks, Techniques, and Trends",
        "link": "/arxiv/2409.14195",
        "arxiv_id": "2409.14195",
        "authors": "Xinghua Zhang, Haiyang Yu, Yongbin Li, Minzheng Wang, Longze Chen, Fei Huang",
        "summary": "In the era of large language models (LLMs), a vast amount of conversation logs will be accumulated thanks to the rapid development trend of language UI. Conversation Analysis (CA) strives to uncover and analyze critical information from conversation data, streamlining manual processes and supporting business insights and decision-making. The need for CA to extract actionable insights and drive empowerment is becoming increasingly prominent and attracting widespread attention. However, the lack of a clear scope for CA leads to a dispersion of various techniques, making it difficult to form a systematic technical synergy to empower business applications. In this paper, we perform a thorough review and systematize CA task to summarize the existing related work. Specifically, we formally define CA task to confront the fragmented and chaotic landscape in this field, and derive four key steps of CA from conversation scene reconstruction, to in-depth attribution analysis, and then to performing targeted training, finally generating conversations based on the targeted training for achieving the specific goals. In addition, we showcase the relevant benchmarks, discuss potential challenges and point out future directions in both industry and academia. In view of current advancements, it is evident that the majority of efforts are still concentrated on the analysis of shallow conversation elements, which presents a considerable gap between the research and business, and with the assist of LLMs, recent work has shown a trend towards research on causality and strategic tasks which are sophisticated and high-level. The analyzed experiences and insights will inevitably have broader application value in business operations that target conversation logs.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 16:52:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.493051"
    },
    {
        "index": "#76",
        "title": "Knowledge in Triples for LLMs: Enhancing Table QA Accuracy with Semantic Extraction",
        "link": "/arxiv/2409.14192",
        "arxiv_id": "2409.14192",
        "authors": "Hossein Sholehrasa, Sanaz Saki Norouzi, Pascal Hitzler, Majid Jaberi-Douraki",
        "summary": "Integrating structured knowledge from tabular formats poses significant challenges within natural language processing (NLP), mainly when dealing with complex, semi-structured tables like those found in the FeTaQA dataset. These tables require advanced methods to interpret and generate meaningful responses accurately. Traditional approaches, such as SQL and SPARQL, often fail to fully capture the semantics of such data, especially in the presence of irregular table structures like web tables. This paper addresses these challenges by proposing a novel approach that extracts triples straightforward from tabular data and integrates it with a retrieval-augmented generation (RAG) model to enhance the accuracy, coherence, and contextual richness of responses generated by a fine-tuned GPT-3.5-turbo-0125 model. Our approach significantly outperforms existing baselines on the FeTaQA dataset, particularly excelling in Sacre-BLEU and ROUGE metrics. It effectively generates contextually accurate and detailed long-form answers from tables, showcasing its strength in complex data interpretation.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2024-09-21 16:46:15 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.493239"
    },
    {
        "index": "#77",
        "title": "QMOS: Enhancing LLMs for Telecommunication with Question Masked loss and Option Shuffling",
        "link": "/arxiv/2409.14175",
        "arxiv_id": "2409.14175",
        "authors": "Blessed Guda, Gabrial Zencha A., Lawrence Francis, Carlee Joe-Wong",
        "summary": "Large Language models (LLMs) have brought about substantial advancements in the field of Question Answering (QA) systems. These models do remarkably well in addressing intricate inquiries in a variety of disciplines. However, because of domain-specific vocabulary, complex technological concepts, and the requirement for exact responses applying LLMs to specialized sectors like telecommunications presents additional obstacles. GPT-3.5 has been used in recent work, to obtain noteworthy accuracy for telecom-related questions in a Retrieval Augmented Generation (RAG) framework. Notwithstanding these developments, the practical use of models such as GPT-3.5 is restricted by their proprietary nature and high computing demands. This paper introduces QMOS, an innovative approach which uses a Question-Masked loss and Option Shuffling trick to enhance the performance of LLMs in answering Multiple-Choice Questions in the telecommunications domain. Our focus was on using opensource, smaller language models (Phi-2 and Falcon-7B) within an enhanced RAG framework. Our multi-faceted approach involves several enhancements to the whole LLM-RAG pipeline of finetuning, retrieval, prompt engineering and inference. Our approaches significantly outperform existing results, achieving accuracy improvements from baselines of 24.70% to 49.30% with Falcon-7B and from 42.07% to 84.65% with Phi-2.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-21 15:32:10 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.493432"
    },
    {
        "index": "#78",
        "title": "Towards Building Efficient Sentence BERT Models using Layer Pruning",
        "link": "/arxiv/2409.14168",
        "arxiv_id": "2409.14168",
        "authors": "Anushka Shelke, Riya Savant, Raviraj Joshi",
        "summary": "This study examines the effectiveness of layer pruning in creating efficient Sentence BERT (SBERT) models. Our goal is to create smaller sentence embedding models that reduce complexity while maintaining strong embedding similarity. We assess BERT models like Muril and MahaBERT-v2 before and after pruning, comparing them with smaller, scratch-trained models like MahaBERT-Small and MahaBERT-Smaller. Through a two-phase SBERT fine-tuning process involving Natural Language Inference (NLI) and Semantic Textual Similarity (STS), we evaluate the impact of layer reduction on embedding quality. Our findings show that pruned models, despite fewer layers, perform competitively with fully layered versions. Moreover, pruned models consistently outperform similarly sized, scratch-trained models, establishing layer pruning as an effective strategy for creating smaller, efficient embedding models. These results highlight layer pruning as a practical approach for reducing computational demand while preserving high-quality embeddings, making SBERT models more accessible for languages with limited technological resources.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-21 15:10:06 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.493740"
    },
    {
        "index": "#79",
        "title": "On Importance of Pruning and Distillation for Efficient Low Resource NLP",
        "link": "/arxiv/2409.14162",
        "arxiv_id": "2409.14162",
        "authors": "Aishwarya Mirashi, Purva Lingayat, Srushti Sonavane, Tejas Padhiyar, Raviraj Joshi, Geetanjali Kale",
        "summary": "The rise of large transformer models has revolutionized Natural Language Processing, leading to significant advances in tasks like text classification. However, this progress demands substantial computational resources, escalating training duration, and expenses with larger model sizes. Efforts have been made to downsize and accelerate English models (e.g., Distilbert, MobileBert). Yet, research in this area is scarce for low-resource languages. In this study, we explore the case of the low-resource Indic language Marathi. Leveraging the marathi-topic-all-doc-v2 model as our baseline, we implement optimization techniques to reduce computation time and memory usage. Our focus is on enhancing the efficiency of Marathi transformer models while maintaining top-tier accuracy and reducing computational demands. Using the MahaNews document classification dataset and the marathi-topic-all-doc-v2 model from L3Cube, we apply Block Movement Pruning, Knowledge Distillation, and Mixed Precision methods individually and in combination to boost efficiency. We demonstrate the importance of strategic pruning levels in achieving desired efficiency gains. Furthermore, we analyze the balance between efficiency improvements and environmental impact, highlighting how optimized model architectures can contribute to a more sustainable computational ecosystem. Implementing these techniques on a single GPU system, we determine that the optimal configuration is 25\\% pruning + knowledge distillation. This approach yielded a 2.56x speedup in computation time while maintaining baseline accuracy levels.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-21 14:58:12 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494011"
    },
    {
        "index": "#80",
        "title": "Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis",
        "link": "/arxiv/2409.14144",
        "arxiv_id": "2409.14144",
        "authors": "Zeping Yu, Sophia Ananiadou",
        "summary": "We find arithmetic ability resides within a limited number of attention heads, with each head specializing in distinct operations. To delve into the reason, we introduce the Comparative Neuron Analysis (CNA) method, which identifies an internal logic chain consisting of four distinct stages from input to prediction: feature enhancing with shallow FFN neurons, feature transferring by shallow attention layers, feature predicting by arithmetic heads, and prediction enhancing among deep FFN neurons. Moreover, we identify the human-interpretable FFN neurons within both feature-enhancing and feature-predicting stages. These findings lead us to investigate the mechanism of LoRA, revealing that it enhances prediction probabilities by amplifying the coefficient scores of FFN neurons related to predictions. Finally, we apply our method in model pruning for arithmetic tasks and model editing for reducing gender bias. Code is on https://github.com/zepingyu0512/arithmetic-mechanism.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 13:46:54 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494237"
    },
    {
        "index": "#81",
        "title": "Obliviate: Neutralizing Task-agnostic Backdoors within the Parameter-efficient Fine-tuning Paradigm",
        "link": "/arxiv/2409.14119",
        "arxiv_id": "2409.14119",
        "authors": "Jaehan Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin",
        "summary": "Parameter-efficient fine-tuning (PEFT) has become a key training strategy for large language models. However, its reliance on fewer trainable parameters poses security risks, such as task-agnostic backdoors. Despite their severe impact on a wide range of tasks, there is no practical defense solution available that effectively counters task-agnostic backdoors within the context of PEFT. In this study, we introduce Obliviate, a PEFT-integrable backdoor defense. We develop two techniques aimed at amplifying benign neurons within PEFT layers and penalizing the influence of trigger tokens. Our evaluations across three major PEFT architectures show that our method can significantly reduce the attack success rate of the state-of-the-art task-agnostic backdoors (83.6%$\\downarrow$). Furthermore, our method exhibits robust defense capabilities against both task-specific backdoors and adaptive attacks. Source code will be obtained at https://github.com/obliviateARR/Obliviate.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security, Machine Learning",
        "date": "2024-09-21 12:20:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494480"
    },
    {
        "index": "#82",
        "title": "Routing in Sparsely-gated Language Models responds to Context",
        "link": "/arxiv/2409.14107",
        "arxiv_id": "2409.14107",
        "authors": "Stefan Arnold, Marian Fietta, Dilara Yesilbas",
        "summary": "Language Models (LMs) recently incorporate mixture-of-experts layers consisting of a router and a collection of experts to scale up their parameter count given a fixed computational budget. Building on previous efforts indicating that token-expert assignments are predominantly influenced by token identities and positions, we trace routing decisions of similarity-annotated text pairs to evaluate the context sensitivity of learned token-expert assignments. We observe that routing in encoder layers mainly depends on (semantic) associations, but contextual cues provide an additional layer of refinement. Conversely, routing in decoder layers is more variable and markedly less sensitive to context.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 11:25:19 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494667"
    },
    {
        "index": "#83",
        "title": "Probing Context Localization of Polysemous Words in Pre-trained Language Model Sub-Layers",
        "link": "/arxiv/2409.14097",
        "arxiv_id": "2409.14097",
        "authors": "Soniya Vijayakumar, Josef van Genabith, Simon Ostermann",
        "summary": "In the era of high performing Large Language Models, researchers have widely acknowledged that contextual word representations are one of the key drivers in achieving top performances in downstream tasks. In this work, we investigate the degree of contextualization encoded in the fine-grained sub-layer representations of a Pre-trained Language Model (PLM) by empirical experiments using linear probes. Unlike previous work, we are particularly interested in identifying the strength of contextualization across PLM sub-layer representations (i.e. Self-Attention, Feed-Forward Activation and Output sub-layers). To identify the main contributions of sub-layers to contextualisation, we first extract the sub-layer representations of polysemous words in minimally different sentence pairs, and compare how these representations change through the forward pass of the PLM network. Second, by probing on a sense identification classification task, we try to empirically localize the strength of contextualization information encoded in these sub-layer representations. With these probing experiments, we also try to gain a better understanding of the influence of context length and context richness on the degree of contextualization. Our main conclusion is cautionary: BERT demonstrates a high degree of contextualization in the top sub-layers if the word in question is in a specific position in the sentence with a shorter context window, but this does not systematically generalize across different word positions and context sizes.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 10:42:07 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494843"
    },
    {
        "index": "#84",
        "title": "PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL",
        "link": "/arxiv/2409.14082",
        "arxiv_id": "2409.14082",
        "authors": "Ruilin Luo, Liyuan Wang, Binghuai Lin, Zicheng Lin, Yujiu Yang",
        "summary": "Large Language Models (LLMs) have emerged as powerful tools for Text-to-SQL tasks, exhibiting remarkable reasoning capabilities. Different from tasks such as math word problems and commonsense reasoning, SQL solutions have a relatively fixed pattern. This facilitates the investigation of whether LLMs can benefit from categorical thinking, mirroring how humans acquire knowledge through inductive reasoning based on comparable examples. In this study, we propose that employing query group partitioning allows LLMs to focus on learning the thought processes specific to a single problem type, consequently enhancing their reasoning abilities across diverse difficulty levels and problem categories. Our experiments reveal that multiple advanced LLMs, when equipped with PTD-SQL, can either surpass or match previous state-of-the-art (SOTA) methods on the Spider and BIRD datasets. Intriguingly, models with varying initial performances have exhibited significant improvements, mainly at the boundary of their capabilities after targeted drilling, suggesting a parallel with human progress. Code is available at https://github.com/lrlbbzl/PTD-SQL.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 09:33:14 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.495050"
    },
    {
        "index": "#85",
        "title": "MultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder",
        "link": "/arxiv/2409.14074",
        "arxiv_id": "2409.14074",
        "authors": "Khai Le-Duc, Phuc Phan, Tan-Hanh Pham, Bach Phan Tat, Minh-Huong Ngo, Truong-Son Hy",
        "summary": "Multilingual automatic speech recognition (ASR) in the medical domain serves as a foundational task for various downstream applications such as speech translation, spoken language understanding, and voice-activated assistants. This technology enhances patient care by enabling efficient communication across language barriers, alleviating specialized workforce shortages, and facilitating improved diagnosis and treatment, particularly during pandemics. In this work, we introduce MultiMed, a collection of small-to-large end-to-end ASR models for the medical domain, spanning five languages: Vietnamese, English, German, French, and Mandarin Chinese, together with the corresponding real-world ASR dataset. To our best knowledge, MultiMed stands as the largest and the first multilingual medical ASR dataset, in terms of total duration, number of speakers, diversity of diseases, recording conditions, speaker roles, unique medical terms, accents, and ICD-10 codes. Secondly, we establish the empirical baselines, present the first reproducible study of multilinguality in medical ASR, conduct a layer-wise ablation study for end-to-end ASR training, and provide the first linguistic analysis for multilingual medical ASR. All code, data, and models are available online https://github.com/leduckhai/MultiMed/tree/master/MultiMed",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2024-09-21 09:05:48 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.495267"
    },
    {
        "index": "#86",
        "title": "Temporally Consistent Factuality Probing for Large Language Models",
        "link": "/arxiv/2409.14065",
        "arxiv_id": "2409.14065",
        "authors": "Ashutosh Bajpai, Aaryan Goyal, Atif Anwer, Tanmoy Chakraborty",
        "summary": "The prolific use of Large Language Models (LLMs) as an alternate knowledge base requires them to be factually consistent, necessitating both correctness and consistency traits for paraphrased queries. Recently, significant attempts have been made to benchmark datasets and metrics to evaluate LLMs for these traits. However, structural simplicity (subject-relation-object) and contemporary association in their query formulation limit the broader definition of factuality and consistency. In this study, we introduce TeCFaP, a novel Temporally Consistent Factuality Probe task to expand the consistent factuality probe in the temporal dimension. To this end, we propose TEMP-COFAC, a high-quality dataset of prefix-style English query paraphrases. Subsequently, we extend the definitions of existing metrics to represent consistent factuality across temporal dimension. We experiment with a diverse set of LLMs and find most of them performing poorly on TeCFaP. Next, we propose a novel solution CoTSeLF (Consistent-Time-Sensitive Learning Framework) combining multi-task instruction tuning (MT-IT) with consistent-time-sensitive reinforcement learning (CTSRL) to improve temporally consistent factuality in LLMs. Our experiments demonstrate the efficacy of CoTSeLF over several baselines.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-21 08:41:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.500998"
    },
    {
        "index": "#87",
        "title": "Co-occurrence is not Factual Association in Language Models",
        "link": "/arxiv/2409.14057",
        "arxiv_id": "2409.14057",
        "authors": "Xiao Zhang, Miao Li, Ji Wu",
        "summary": "Pretrained language models can encode a large amount of knowledge and utilize it for various reasoning tasks, yet they can still struggle to learn novel factual knowledge effectively from finetuning on limited textual demonstrations. In this work, we show that the reason for this deficiency is that language models are biased to learn word co-occurrence statistics instead of true factual associations. We identify the differences between two forms of knowledge representation in language models: knowledge in the form of co-occurrence statistics is encoded in the middle layers of the transformer model and does not generalize well to reasoning scenarios beyond simple question answering, while true factual associations are encoded in the lower layers and can be freely utilized in various reasoning tasks. Based on these observations, we propose two strategies to improve the learning of factual associations in language models. We show that training on text with implicit rather than explicit factual associations can force the model to learn factual associations instead of co-occurrence statistics, significantly improving the generalization of newly learned knowledge. We also propose a simple training method to actively forget the learned co-occurrence statistics, which unblocks and enhances the learning of factual associations when training on plain narrative text. On both synthetic and real-world corpora, the two proposed strategies improve the generalization of the knowledge learned during finetuning to reasoning scenarios such as indirect and multi-hop question answering.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 08:13:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.501373"
    },
    {
        "index": "#88",
        "title": "GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion",
        "link": "/arxiv/2409.14051",
        "arxiv_id": "2409.14051",
        "authors": "Tongxuan Liu, Xingyu Wang, Weizhe Huang, Wenjiang Xu, Yuting Zeng, Lei Jiang, Hailong Yang, Jing Li",
        "summary": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse NLP tasks. Extensive research has explored how to enhance the logical reasoning abilities such as Chain-of-Thought, Chain-of-Thought with Self-Consistency, Tree-Of-Thoughts, and multi-agent debates. In the context of multi-agent debates, significant performance improvements can be achieved with an increasing number of agents and debate rounds. However, the escalation in the number of agents and debate rounds can drastically raise the tokens cost of debates, thereby limiting the scalability of the multi-agent debate technique. To better harness the advantages of multi-agent debates in logical reasoning tasks, this paper proposes a method to significantly reduce token cost in multi-agent debates. This approach involves dividing all agents into multiple debate groups, with agents engaging in debates within their respective groups and sharing interim debate results between groups. Comparative experiments across multiple datasets have demonstrated that this method can reduce the total tokens by up to 51.7% during debates and while potentially enhancing accuracy by as much as 25%. Our method significantly enhances the performance and efficiency of interactions in the multi-agent debate.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 07:49:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.501775"
    },
    {
        "index": "#89",
        "title": "Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators",
        "link": "/arxiv/2409.14037",
        "arxiv_id": "2409.14037",
        "authors": "Prasoon Bajpai, Niladri Chatterjee, Subhabrata Dutta, Tanmoy Chakraborty",
        "summary": "Large Language Models (LLMs) and AI assistants driven by these models are experiencing exponential growth in usage among both expert and amateur users. In this work, we focus on evaluating the reliability of current LLMs as science communicators. Unlike existing benchmarks, our approach emphasizes assessing these models on scientific questionanswering tasks that require a nuanced understanding and awareness of answerability. We introduce a novel dataset, SCiPS-QA, comprising 742 Yes/No queries embedded in complex scientific concepts, along with a benchmarking suite that evaluates LLMs for correctness and consistency across various criteria. We benchmark three proprietary LLMs from the OpenAI GPT family and 13 open-access LLMs from the Meta Llama-2, Llama-3, and Mistral families. While most open-access models significantly underperform compared to GPT-4 Turbo, our experiments identify Llama-3-70B as a strong competitor, often surpassing GPT-4 Turbo in various evaluation aspects. We also find that even the GPT models exhibit a general incompetence in reliably verifying LLM responses. Moreover, we observe an alarming trend where human evaluators are deceived by incorrect responses from GPT-4 Turbo.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 06:48:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.502104"
    },
    {
        "index": "#90",
        "title": "Uncovering Latent Chain of Thought Vectors in Language Models",
        "link": "/arxiv/2409.14026",
        "arxiv_id": "2409.14026",
        "authors": "Jason Zhang, Scott Viteri",
        "summary": "As language models grow more influential and trusted in our society, our ability to reliably steer them toward favorable behaviors becomes increasingly paramount. For this, we investigate the technique of steering vectors: biasing the forward pass of language models using a \"steering vector\" derived from a specific task. We apply them to steer language models toward performing Chain of Thought (CoT) Reasoning without the need to prompt through natural language. We demonstrate this approach on Llama3 8b and Mistral 7b v0.2, and obtain competitive results compared to CoT-prompted performances on a series of reasoning benchmarks (GSM8k, MMLU, AGI Eval, ARC AI2) and qualitative examples. We find this approach yields consistent steering towards CoT responses and takes less compute than traditional methods of fine-tuning models towards CoT.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 05:58:07 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.502432"
    },
    {
        "index": "#91",
        "title": "Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature",
        "link": "/arxiv/2409.14000",
        "arxiv_id": "2409.14000",
        "authors": "Linxiao Wu, Yuanshuai Luo, Binrong Zhu, Guiran Liu, Rui Wang, Qian Yu",
        "summary": "Amidst the swift evolution of social media platforms and e-commerce ecosystems, the domain of opinion mining has surged as a pivotal area of exploration within natural language processing. A specialized segment within this field focuses on extracting nuanced evaluations tied to particular elements within textual contexts. This research advances a composite framework that amalgamates the positional cues of topical descriptors. The proposed system converts syntactic structures into a matrix format, leveraging convolutions and attention mechanisms within a graph to distill salient characteristics. Incorporating the positional relevance of descriptors relative to lexical items enhances the sequential integrity of the input. Trials have substantiated that this integrated graph-centric scheme markedly elevates the efficacy of evaluative categorization, showcasing preeminence.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 03:30:59 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.502662"
    },
    {
        "index": "#92",
        "title": "Contrastive Learning for Knowledge-Based Question Generation in Large Language Models",
        "link": "/arxiv/2409.13994",
        "arxiv_id": "2409.13994",
        "authors": "Zhenhong Zhang, Jiajing Chen, Weiyan Shi, Lingjie Yi, Chihang Wang, Qian Yu",
        "summary": "With the rapid development of artificial intelligence technology, especially the increasingly widespread application of question-and-answer systems, high-quality question generation has become a key component in supporting the development of these systems. This article focuses on knowledge-based question generation technology, which aims to enable computers to simulate the human questioning process based on understanding specific texts or knowledge bases. In light of the issues of hallucination and knowledge gaps present in large-scale language models when applied to knowledge-intensive tasks, this paper proposes an enhanced question generation method that incorporates contrastive learning. This method utilizes multiple models to jointly mine domain knowledge and uses contrastive learning to guide the model in reducing noise and hallucinations in generation. Experimental results show that by designing prompts containing contrasting examples, the model's performance in question generation improves considerably, particularly when contrasting instructions and examples are used simultaneously, leading to the highest quality of generated questions and improved accuracy. These results demonstrate that the method proposed in this study, which combines contrasting context and chain-of-thought prompts, can effectively improve both the quality and the practicality of question generation.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 03:09:10 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.502876"
    },
    {
        "index": "#93",
        "title": "SMART-RAG: Selection using Determinantal Matrices for Augmented Retrieval",
        "link": "/arxiv/2409.13992",
        "arxiv_id": "2409.13992",
        "authors": "Jiatao Li, Xinyu Hu, Xiaojun Wan",
        "summary": "Retrieval-Augmented Generation (RAG) has greatly improved large language models (LLMs) by enabling them to generate accurate, contextually grounded responses through the integration of external information. However, conventional RAG approaches, which prioritize top-ranked documents based solely on query-context relevance, often introduce redundancy and conflicting information. This issue is particularly evident in unsupervised retrieval settings, where there are no mechanisms to effectively mitigate these problems, leading to suboptimal context selection. To address this, we propose Selection using Matrices for Augmented Retrieval (SMART) in question answering tasks, a fully unsupervised and training-free framework designed to optimize context selection in RAG. SMART leverages Determinantal Point Processes (DPPs) to simultaneously model relevance, diversity and conflict, ensuring the selection of potentially high-quality contexts. Experimental results across multiple datasets demonstrate that SMART significantly enhances QA performance and surpasses previous unsupervised context selection methods, showing a promising strategy for RAG.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 03:03:09 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.503053"
    },
    {
        "index": "#94",
        "title": "ChemEval: A Comprehensive Multi-Level Chemical Evaluation for Large Language Models",
        "link": "/arxiv/2409.13989",
        "arxiv_id": "2409.13989",
        "authors": "Yuqing Huang, Rongyang Zhang, Xuesong He, Xuyang Zhi, Hao Wang, Xin Li, Feiyang Xu, Deguang Liu, Huadong Liang, Yi Li, Jian Cui, Zimu Liu, Shijin Wang, Guoping Hu, Guiquan Liu, Qi Liu, Defu Lian, Enhong Chen",
        "summary": "There is a growing interest in the role that LLMs play in chemistry which lead to an increased focus on the development of LLMs benchmarks tailored to chemical domains to assess the performance of LLMs across a spectrum of chemical tasks varying in type and complexity. However, existing benchmarks in this domain fail to adequately meet the specific requirements of chemical research professionals. To this end, we propose \\textbf{\\textit{ChemEval}}, which provides a comprehensive assessment of the capabilities of LLMs across a wide range of chemical domain tasks. Specifically, ChemEval identified 4 crucial progressive levels in chemistry, assessing 12 dimensions of LLMs across 42 distinct chemical tasks which are informed by open-source data and the data meticulously crafted by chemical experts, ensuring that the tasks have practical value and can effectively evaluate the capabilities of LLMs. In the experiment, we evaluate 12 mainstream LLMs on ChemEval under zero-shot and few-shot learning contexts, which included carefully selected demonstration examples and carefully designed prompts. The results show that while general LLMs like GPT-4 and Claude-3.5 excel in literature understanding and instruction following, they fall short in tasks demanding advanced chemical knowledge. Conversely, specialized LLMs exhibit enhanced chemical competencies, albeit with reduced literary comprehension. This suggests that LLMs have significant potential for enhancement when tackling sophisticated tasks in the field of chemistry. We believe our work will facilitate the exploration of their potential to drive progress in chemistry. Our benchmark and analysis will be available at {\\color{blue} \\url{https://github.com/USTC-StarTeam/ChemEval}}.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Chemical Physics, Biomolecules",
        "date": "2024-09-21 02:50:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.503368"
    },
    {
        "index": "#95",
        "title": "Bias and Toxicity in Role-Play Reasoning",
        "link": "/arxiv/2409.13979",
        "arxiv_id": "2409.13979",
        "authors": "Jinman Zhao, Zifan Qian, Linbo Cao, Yining Wang, Yitian Ding",
        "summary": "Role-play in the Large Language Model (LLM) is a crucial technique that enables models to adopt specific perspectives, enhancing their ability to generate contextually relevant and accurate responses. By simulating different roles, theis approach improves reasoning capabilities across various NLP benchmarks, making the model's output more aligned with diverse scenarios. However, in this work, we demonstrate that role-play also carries potential risks. We systematically evaluate the impact of role-play by asking the language model to adopt different roles and testing it on multiple benchmarks that contain stereotypical and harmful questions. Despite the significant fluctuations in the benchmark results in different experiments, we find that applying role-play often increases the overall likelihood of generating stereotypical and harmful outputs.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 02:09:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.503637"
    },
    {
        "index": "#96",
        "title": "Can Language Model Understand Word Semantics as A Chatbot? An Empirical Study of Language Model Internal External Mismatch",
        "link": "/arxiv/2409.13972",
        "arxiv_id": "2409.13972",
        "authors": "Jinman Zhao, Xueyan Zhang, Xingyu Yue, Weizhe Chen, Zifan Qian, Ruiyu Wang",
        "summary": "Current common interactions with language models is through full inference. This approach may not necessarily align with the model's internal knowledge. Studies show discrepancies between prompts and internal representations. Most focus on sentence understanding. We study the discrepancy of word semantics understanding in internal and external mismatch across Encoder-only, Decoder-only, and Encoder-Decoder pre-trained language models.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 01:35:58 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.503855"
    },
    {
        "index": "#97",
        "title": "Exploring Automated Keyword Mnemonics Generation with Large Language Models via Overgenerate-and-Rank",
        "link": "/arxiv/2409.13952",
        "arxiv_id": "2409.13952",
        "authors": "Jaewook Lee, Hunter McNichols, Andrew Lan",
        "summary": "In this paper, we study an under-explored area of language and vocabulary learning: keyword mnemonics, a technique for memorizing vocabulary through memorable associations with a target word via a verbal cue. Typically, creating verbal cues requires extensive human effort and is quite time-consuming, necessitating an automated method that is more scalable. We propose a novel overgenerate-and-rank method via prompting large language models (LLMs) to generate verbal cues and then ranking them according to psycholinguistic measures and takeaways from a pilot user study. To assess cue quality, we conduct both an automated evaluation of imageability and coherence, as well as a human evaluation involving English teachers and learners. Results show that LLM-generated mnemonics are comparable to human-generated ones in terms of imageability, coherence, and perceived usefulness, but there remains plenty of room for improvement due to the diversity in background and preference among language learners.",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2024-09-21 00:00:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504072"
    },
    {
        "index": "#98",
        "title": "Mufu: Multilingual Fused Learning for Low-Resource Translation with LLM",
        "link": "/arxiv/2409.13949",
        "arxiv_id": "2409.13949",
        "authors": "Zheng Wei Lim, Nitish Gupta, Honglin Yu, Trevor Cohn",
        "summary": "Multilingual large language models (LLMs) are great translators, but this is largely limited to high-resource languages. For many LLMs, translating in and out of low-resource languages remains a challenging task. To maximize data efficiency in this low-resource setting, we introduce Mufu, which includes a selection of automatically generated multilingual candidates and an instruction to correct inaccurate translations in the prompt. Mufu prompts turn a translation task into a postediting one, and seek to harness the LLM's reasoning capability with auxiliary translation candidates, from which the model is required to assess the input quality, align the semantics cross-lingually, copy from relevant inputs and override instances that are incorrect. Our experiments on En-XX translations over the Flores-200 dataset show LLMs finetuned against Mufu-style prompts are robust to poor quality auxiliary translation candidates, achieving performance superior to NLLB 1.3B distilled model in 64% of low- and very-low-resource language pairs. We then distill these models to reduce inference cost, while maintaining on average 3.1 chrF improvement over finetune-only baseline in low-resource translations.",
        "subjects": "Computation and Language",
        "date": "2024-09-20 23:48:47 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504274"
    },
    {
        "index": "#99",
        "title": "Aligning Language Models Using Follow-up Likelihood as Reward Signal",
        "link": "/arxiv/2409.13948",
        "arxiv_id": "2409.13948",
        "authors": "Chen Zhang, Dading Chong, Feng Jiang, Chengguang Tang, Anningzhe Gao, Guohua Tang, Haizhou Li",
        "summary": "In natural human-to-human conversations, participants often receive feedback signals from one another based on their follow-up reactions. These reactions can include verbal responses, facial expressions, changes in emotional state, and other non-verbal cues. Similarly, in human-machine interactions, the machine can leverage the user's follow-up utterances as feedback signals to assess whether it has appropriately addressed the user's request. Therefore, we propose using the likelihood of follow-up utterances as rewards to differentiate preferred responses from less favored ones, without relying on human or commercial LLM-based preference annotations. Our proposed reward mechanism, ``Follow-up Likelihood as Reward\" (FLR), matches the performance of strong reward models trained on large-scale human or GPT-4 annotated data on 8 pairwise-preference and 4 rating-based benchmarks. Building upon the FLR mechanism, we propose to automatically mine preference data from the online generations of a base policy model. The preference data are subsequently used to boost the helpfulness of the base model through direct alignment from preference (DAP) methods, such as direct preference optimization (DPO). Lastly, we demonstrate that fine-tuning the language model that provides follow-up likelihood with natural language feedback significantly enhances FLR's performance on reward modeling benchmarks and effectiveness in aligning the base policy model's helpfulness.",
        "subjects": "Computation and Language",
        "date": "2024-09-20 23:47:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504515"
    },
    {
        "index": "#100",
        "title": "MirrorStories: Reflecting Diversity through Personalized Narrative Generation with Large Language Models",
        "link": "/arxiv/2409.13935",
        "arxiv_id": "2409.13935",
        "authors": "Sarfaroz Yunusov, Hamza Sidat, Ali Emami",
        "summary": "This study explores the effectiveness of Large Language Models (LLMs) in creating personalized \"mirror stories\" that reflect and resonate with individual readers' identities, addressing the significant lack of diversity in literature. We present MirrorStories, a corpus of 1,500 personalized short stories generated by integrating elements such as name, gender, age, ethnicity, reader interest, and story moral. We demonstrate that LLMs can effectively incorporate diverse identity elements into narratives, with human evaluators identifying personalized elements in the stories with high accuracy. Through a comprehensive evaluation involving 26 diverse human judges, we compare the effectiveness of MirrorStories against generic narratives. We find that personalized LLM-generated stories not only outscore generic human-written and LLM-generated ones across all metrics of engagement (with average ratings of 4.22 versus 3.37 on a 5-point scale), but also achieve higher textual diversity while preserving the intended moral. We also provide analyses that include bias assessments and a study on the potential for integrating images into personalized stories.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society",
        "date": "2024-09-20 22:43:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504730"
    },
    {
        "index": "#101",
        "title": "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks",
        "link": "/arxiv/2409.13920",
        "arxiv_id": "2409.13920",
        "authors": "Sebastian Nehrdich, Oliver Hellwig, Kurt Keutzer",
        "summary": "Morphologically rich languages are notoriously challenging to process for downstream NLP applications. This paper presents a new pretrained language model, ByT5-Sanskrit, designed for NLP applications involving the morphologically rich language Sanskrit. We evaluate ByT5-Sanskrit on established Sanskrit word segmentation tasks, where it outperforms previous data-driven approaches by a considerable margin and matches the performance of the current best lexicon-based model. It is easier to deploy and more robust to data not covered by external linguistic resources. It also achieves new state-of-the-art results in Vedic Sanskrit dependency parsing and OCR post-correction tasks. Additionally, based on the Digital Corpus of Sanskrit, we introduce a novel multitask dataset for the joint training of Sanskrit word segmentation, lemmatization, and morphosyntactic tagging tasks. We fine-tune ByT5-Sanskrit on this dataset, creating a versatile multitask model for various downstream Sanskrit applications. We have used this model in Sanskrit linguistic annotation projects, in information retrieval setups, and as a preprocessing step in a Sanskrit machine translation pipeline. We also show that our approach yields new best scores for lemmatization and dependency parsing of other morphologically rich languages. We thus demonstrate that byte-level pretrained language models can achieve excellent performance for morphologically rich languages, outperforming tokenizer-based models and presenting an important vector of exploration when constructing NLP pipelines for such languages.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-20 22:02:26 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504912"
    },
    {
        "index": "#102",
        "title": "Target word activity detector: An approach to obtain ASR word boundaries without lexicon",
        "link": "/arxiv/2409.13913",
        "arxiv_id": "2409.13913",
        "authors": "Sunit Sivasankaran, Eric Sun, Jinyu Li, Yan Huang, Jing Pan",
        "summary": "Obtaining word timestamp information from end-to-end (E2E) ASR models remains challenging due to the lack of explicit time alignment during training. This issue is further complicated in multilingual models. Existing methods, either rely on lexicons or introduce additional tokens, leading to scalability issues and increased computational costs. In this work, we propose a new approach to estimate word boundaries without relying on lexicons. Our method leverages word embeddings from sub-word token units and a pretrained ASR model, requiring only word alignment information during training. Our proposed method can scale-up to any number of languages without incurring any additional cost. We validate our approach using a multilingual ASR model trained on five languages and demonstrate its effectiveness against a strong baseline.",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2024-09-20 21:40:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.505113"
    },
    {
        "index": "#103",
        "title": "Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology",
        "link": "/arxiv/2409.13902",
        "arxiv_id": "2409.13902",
        "authors": "Aidan Gilson, Xuguang Ai, Thilaka Arunachalam, Ziyou Chen, Ki Xiong Cheong, Amisha Dave, Cameron Duic, Mercy Kibe, Annette Kaminaka, Minali Prasad, Fares Siddig, Maxwell Singer, Wendy Wong, Qiao Jin, Tiarnan D. L. Keenan, Xia Hu, Emily Y. Chew, Zhiyong Lu, Hua Xu, Ron A. Adelman, Yih-Chung Tham, Qingyu Chen",
        "summary": "Despite the potential of Large Language Models (LLMs) in medicine, they may generate responses lacking supporting evidence or based on hallucinated evidence. While Retrieval Augment Generation (RAG) is popular to address this issue, few studies implemented and evaluated RAG in downstream domain-specific applications. We developed a RAG pipeline with 70,000 ophthalmology-specific documents that retrieve relevant documents to augment LLMs during inference time. In a case study on long-form consumer health questions, we systematically evaluated the responses including over 500 references of LLMs with and without RAG on 100 questions with 10 healthcare professionals. The evaluation focuses on factuality of evidence, selection and ranking of evidence, attribution of evidence, and answer accuracy and completeness. LLMs without RAG provided 252 references in total. Of which, 45.3% hallucinated, 34.1% consisted of minor errors, and 20.6% were correct. In contrast, LLMs with RAG significantly improved accuracy (54.5% being correct) and reduced error rates (18.8% with minor hallucinations and 26.7% with errors). 62.5% of the top 10 documents retrieved by RAG were selected as the top references in the LLM response, with an average ranking of 4.9. The use of RAG also improved evidence attribution (increasing from 1.85 to 2.49 on a 5-point scale, P<0.001), albeit with slight decreases in accuracy (from 3.52 to 3.23, P=0.03) and completeness (from 3.47 to 3.27, P=0.17). The results demonstrate that LLMs frequently exhibited hallucinated and erroneous evidence in the responses, raising concerns for downstream applications in the medical domain. RAG substantially reduced the proportion of such evidence but encountered challenges.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-20 21:06:00 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.505487"
    },
    {
        "index": "#104",
        "title": "LLM for Everyone: Representing the Underrepresented in Large Language Models",
        "link": "/arxiv/2409.13897",
        "arxiv_id": "2409.13897",
        "authors": "Samuel Cahyawijaya",
        "summary": "Natural language processing (NLP) has witnessed a profound impact of large language models (LLMs) that excel in a multitude of tasks. However, the limitation of LLMs in multilingual settings, particularly in underrepresented languages, remains a significant hurdle. This thesis aims to bridge the gap in NLP research and development by focusing on underrepresented languages. A comprehensive evaluation of LLMs is conducted to assess their capabilities in these languages, revealing the challenges of multilingual and multicultural generalization. Addressing the multilingual generalization gap, this thesis proposes data-and-compute-efficient methods to mitigate the disparity in LLM ability in underrepresented languages, allowing better generalization on underrepresented languages without the loss of task generalization ability. The proposed solutions cover cross-lingual continual instruction tuning, retrieval-based cross-lingual in-context learning, and in-context query alignment. Furthermore, a novel method to measure cultural values alignment between LLMs operating in different languages is proposed, ensuring cultural sensitivity and inclusivity. These contributions aim to enhance the multilingual and multicultural alignment of LLMs in underrepresented languages, ultimately advancing the NLP field toward greater equality and inclusiveness.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-20 20:53:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.505668"
    },
    {
        "index": "#105",
        "title": "Transfer Learning with Clinical Concept Embeddings from Large Language Models",
        "link": "/arxiv/2409.13893",
        "arxiv_id": "2409.13893",
        "authors": "Yuhe Gao, Runxue Bao, Yuelyu Ji, Yiming Sun, Chenxi Song, Jeffrey P. Ferraro, Ye Ye",
        "summary": "Knowledge sharing is crucial in healthcare, especially when leveraging data from multiple clinical sites to address data scarcity, reduce costs, and enable timely interventions. Transfer learning can facilitate cross-site knowledge transfer, but a major challenge is heterogeneity in clinical concepts across different sites. Large Language Models (LLMs) show significant potential of capturing the semantic meaning of clinical concepts and reducing heterogeneity. This study analyzed electronic health records from two large healthcare systems to assess the impact of semantic embeddings from LLMs on local, shared, and transfer learning models. Results indicate that domain-specific LLMs, such as Med-BERT, consistently outperform in local and direct transfer scenarios, while generic models like OpenAI embeddings require fine-tuning for optimal performance. However, excessive tuning of models with biomedical embeddings may reduce effectiveness, emphasizing the need for balance. This study highlights the importance of domain-specific embeddings and careful model tuning for effective knowledge transfer in healthcare.",
        "subjects": "Computation and Language",
        "date": "2024-09-20 20:50:55 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.511322"
    },
    {
        "index": "#106",
        "title": "A Multi-LLM Debiasing Framework",
        "link": "/arxiv/2409.13884",
        "arxiv_id": "2409.13884",
        "authors": "Deonna M. Owens, Ryan A. Rossi, Sungchul Kim, Tong Yu, Franck Dernoncourt, Xiang Chen, Ruiyi Zhang, Jiuxiang Gu, Hanieh Deilamsalehy, Nedim Lipka",
        "summary": "Large Language Models (LLMs) are powerful tools with the potential to benefit society immensely, yet, they have demonstrated biases that perpetuate societal inequalities. Despite significant advancements in bias mitigation techniques using data augmentation, zero-shot prompting, and model fine-tuning, biases continuously persist, including subtle biases that may elude human detection. Recent research has shown a growing interest in multi-LLM approaches, which have been demonstrated to be effective in improving the quality of reasoning and factuality in LLMs. Building on this approach, we propose a novel multi-LLM debiasing framework aimed at reducing bias in LLMs. Our work is the first to introduce and evaluate two distinct approaches within this framework for debiasing LLMs: a centralized method, where the conversation is facilitated by a single central LLM, and a decentralized method, where all models communicate directly. Our findings reveal that our multi-LLM framework significantly reduces bias in LLMs, outperforming the baseline method across several social groups.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2024-09-20 20:24:50 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.511806"
    },
    {
        "index": "#107",
        "title": "\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification",
        "link": "/arxiv/2409.13879",
        "arxiv_id": "2409.13879",
        "authors": "Konstantinos Thomas, Giorgos Filandrianos, Maria Lymperaiou, Chrysoula Zerva, Giorgos Stamou",
        "summary": "Equivocation and ambiguity in public speech are well-studied discourse phenomena, especially in political science and analysis of political interviews. Inspired by the well-grounded theory on equivocation, we aim to resolve the closely related problem of response clarity in questions extracted from political interviews, leveraging the capabilities of Large Language Models (LLMs) and human expertise. To this end, we introduce a novel taxonomy that frames the task of detecting and classifying response clarity and a corresponding clarity classification dataset which consists of question-answer (QA) pairs drawn from political interviews and annotated accordingly. Our proposed two-level taxonomy addresses the clarity of a response in terms of the information provided for a given question (high-level) and also provides a fine-grained taxonomy of evasion techniques that relate to unclear, ambiguous responses (lower-level). We combine ChatGPT and human annotators to collect, validate and annotate discrete QA pairs from political interviews, to be used for our newly introduced response clarity task. We provide a detailed analysis and conduct several experiments with different model architectures, sizes and adaptation methods to gain insights and establish new baselines over the proposed dataset and task.",
        "subjects": "Computation and Language",
        "date": "2024-09-20 20:15:06 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512043"
    },
    {
        "index": "#108",
        "title": "Instruct-Tuning Pretrained Causal Language Models for Ancient Greek Papyrology and Epigraphy",
        "link": "/arxiv/2409.13870",
        "arxiv_id": "2409.13870",
        "authors": "Eric Cullhed",
        "summary": "This article presents an experiment in fine-tuning a pretrained causal language model (Meta's Llama 3.1 8B Instruct) for aiding in three fundamental tasks of philological research: chronological and geographic attribution as well as text restoration in ancient Greek inscriptions and documentary papyri. Using a prompt-based instruct approach, the fine-tuned models surpass the state of the art in key metrics. For inscriptions, the models achieve a lower average character error rate (CER) of 22.5% (vs. 26.3%), while closely matching top-1 accuracy (60.9% vs. 61.8%) and top-20 accuracy (77.5% vs. 78.3%) for sequences up to 10 characters. They also provide a practical advantage by ignoring spaces during reconstruction, aligning better with the scriptio continua typically used in ancient written artifacts. In geographic attribution, the model outperforms previous benchmarks with a top-1 accuracy of 75.0% (vs. 70.8%) and a top-3 accuracy of 83.7% (vs. 82.1%). For dating, it achieves an average deviation of 26.2 years (vs. 29.3) and a median deviation of 1 year (vs. 3) from the actual date range. The models also set new baselines for documentary papyri, with a CER of 16.3%, a top-1 accuracy of 71.3%, and top-20 of 85.0% in text reconstruction; a top-1 accuracy of 66.4% and top-3 of 79.9% in geographic attribution; and, in chronological attribution, a deviation of 21.7 years from the actual termini post/ante quem, with a median deviation of 0 years.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-20 19:49:45 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512225"
    },
    {
        "index": "#109",
        "title": "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting",
        "link": "/arxiv/2409.13853",
        "arxiv_id": "2409.13853",
        "authors": "Zhepeng Wang, Runxue Bao, Yawen Wu, Jackson Taylor, Cao Xiao, Feng Zheng, Weiwen Jiang, Shangqian Gao, Yanfu Zhang",
        "summary": "Pretrained large language models (LLMs) have revolutionized natural language processing (NLP) tasks such as summarization, question answering, and translation. However, LLMs pose significant security risks due to their tendency to memorize training data, leading to potential privacy breaches and copyright infringement. Accurate measurement of this memorization is essential to evaluate and mitigate these potential risks. However, previous attempts to characterize memorization are constrained by either using prefixes only or by prepending a constant soft prompt to the prefixes, which cannot react to changes in input. To address this challenge, we propose a novel method for estimating LLM memorization using dynamic, prefix-dependent soft prompts. Our approach involves training a transformer-based generator to produce soft prompts that adapt to changes in input, thereby enabling more accurate extraction of memorized data. Our method not only addresses the limitations of previous methods but also demonstrates superior performance in diverse experimental settings compared to state-of-the-art techniques. In particular, our method can achieve the maximum relative improvement of 112.75% and 32.26% over the vanilla baseline in terms of discoverable memorization rate for the text generation task and code generation task respectively.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security, Machine Learning",
        "date": "2024-09-20 18:56:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512486"
    },
    {
        "index": "#110",
        "title": "Do language models practice what they preach? Examining language ideologies about gendered language reform encoded in LLMs",
        "link": "/arxiv/2409.13852",
        "arxiv_id": "2409.13852",
        "authors": "Julia Watson, Sophia Lee, Barend Beekhuizen, Suzanne Stevenson",
        "summary": "We study language ideologies in text produced by LLMs through a case study on English gendered language reform (related to role nouns like congressperson/-woman/-man, and singular they). First, we find political bias: when asked to use language that is \"correct\" or \"natural\", LLMs use language most similarly to when asked to align with conservative (vs. progressive) values. This shows how LLMs' metalinguistic preferences can implicitly communicate the language ideologies of a particular political group, even in seemingly non-political contexts. Second, we find LLMs exhibit internal inconsistency: LLMs use gender-neutral variants more often when more explicit metalinguistic context is provided. This shows how the language ideologies expressed in text produced by LLMs can vary, which may be unexpected to users. We discuss the broader implications of these findings for value alignment.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-20 18:55:48 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512681"
    },
    {
        "index": "#111",
        "title": "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions",
        "link": "/arxiv/2409.13843",
        "arxiv_id": "2409.13843",
        "authors": "Robert Morabito, Sangmitra Madhusudan, Tyler McDonald, Ali Emami",
        "summary": "Mitigating explicit and implicit biases in Large Language Models (LLMs) has become a critical focus in the field of natural language processing. However, many current methodologies evaluate scenarios in isolation, without considering the broader context or the spectrum of potential biases within each situation. To address this, we introduce the Sensitivity Testing on Offensive Progressions (STOP) dataset, which includes 450 offensive progressions containing 2,700 unique sentences of varying severity that progressively escalate from less to more explicitly offensive. Covering a broad spectrum of 9 demographics and 46 sub-demographics, STOP ensures inclusivity and comprehensive coverage. We evaluate several leading closed- and open-source models, including GPT-4, Mixtral, and Llama 3. Our findings reveal that even the best-performing models detect bias inconsistently, with success rates ranging from 19.3% to 69.8%. We also demonstrate how aligning models with human judgments on STOP can improve model answer rates on sensitive tasks such as BBQ, StereoSet, and CrowS-Pairs by up to 191%, while maintaining or even improving performance. STOP presents a novel framework for assessing the complex nature of biases in LLMs, which will enable more effective bias mitigation strategies and facilitates the creation of fairer language models.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society",
        "date": "2024-09-20 18:34:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512937"
    },
    {
        "index": "#112",
        "title": "Measuring Copyright Risks of Large Language Model via Partial Information Probing",
        "link": "/arxiv/2409.13831",
        "arxiv_id": "2409.13831",
        "authors": "Weijie Zhao, Huajie Shao, Zhaozhuo Xu, Suzhen Duan, Denghui Zhang",
        "summary": "Exploring the data sources used to train Large Language Models (LLMs) is a crucial direction in investigating potential copyright infringement by these models. While this approach can identify the possible use of copyrighted materials in training data, it does not directly measure infringing risks. Recent research has shifted towards testing whether LLMs can directly output copyrighted content. Addressing this direction, we investigate and assess LLMs' capacity to generate infringing content by providing them with partial information from copyrighted materials, and try to use iterative prompting to get LLMs to generate more infringing content. Specifically, we input a portion of a copyrighted text into LLMs, prompt them to complete it, and then analyze the overlap between the generated content and the original copyrighted material. Our findings demonstrate that LLMs can indeed generate content highly overlapping with copyrighted materials based on these partial inputs.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security",
        "date": "2024-09-20 18:16:05 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513160"
    },
    {
        "index": "#113",
        "title": "Local Explanations and Self-Explanations for Assessing Faithfulness in black-box LLMs",
        "link": "/arxiv/2409.13764",
        "arxiv_id": "2409.13764",
        "authors": "Christos Fragkathoulas, Odysseas S. Chlapanis",
        "summary": "This paper introduces a novel task to assess the faithfulness of large language models (LLMs) using local perturbations and self-explanations. Many LLMs often require additional context to answer certain questions correctly. For this purpose, we propose a new efficient alternative explainability technique, inspired by the commonly used leave-one-out approach. Using this approach, we identify the sufficient and necessary parts for the LLM to generate correct answers, serving as explanations. We propose a metric for assessing faithfulness that compares these crucial parts with the self-explanations of the model. Using the Natural Questions dataset, we validate our approach, demonstrating its effectiveness in explaining model decisions and assessing faithfulness.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-18 10:16:45 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513345"
    },
    {
        "index": "#114",
        "title": "Do Large Language Models Need a Content Delivery Network?",
        "link": "/arxiv/2409.13761",
        "arxiv_id": "2409.13761",
        "authors": "Yihua Cheng, Kuntai Du, Jiayi Yao, Junchen Jiang",
        "summary": "As the use of large language models (LLMs) expands rapidly, so does the range of knowledge needed to supplement various LLM queries. Thus, enabling flexible and efficient injection of new knowledge in LLM inference is critical. Three high-level options exist: (i) embedding the knowledge in LLM's weights (i.e., fine-tuning), (ii) including the knowledge as a part of LLM's text input (i.e., in-context learning), or (iii) injecting the KV caches of the new knowledge to LLM during prefill. This paper argues that, although fine-tuning and in-context learning are popular, using KV caches as the medium of knowledge could simultaneously enable more modular management of knowledge injection and more efficient LLM serving with low cost and fast response. To realize these benefits, we envision a Knowledge Delivery Network (KDN), a new system component in LLM services that dynamically optimizes the storage, transfer, and composition of KV cache across LLM engines and other compute and storage resources. We believe that, just like content delivery networks (CDNs), such as Akamai, enabled the success of the Internet ecosystem through their efficient data delivery, KDNs will be critical to the success of LLM applications through their efficient knowledge delivery. We have open-sourced a KDN prototype at https://github.com/LMCache/LMCache.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-16 18:46:24 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513543"
    },
    {
        "index": "#115",
        "title": "Optimizing the Songwriting Process: Genre-Based Lyric Generation Using Deep Learning Models",
        "link": "/arxiv/2409.13758",
        "arxiv_id": "2409.13758",
        "authors": "Tracy Cai, Wilson Liang, Donte Townes",
        "summary": "The traditional songwriting process is rather complex and this is evident in the time it takes to produce lyrics that fit the genre and form comprehensive verses. Our project aims to simplify this process with deep learning techniques, thus optimizing the songwriting process and enabling an artist to hit their target audience by staying in genre. Using a dataset of 18,000 songs off Spotify, we developed a unique preprocessing format using tokens to parse lyrics into individual verses. These results were used to train a baseline pretrained seq2seq model, and a LSTM-based neural network models according to song genres. We found that generation yielded higher recall (ROUGE) in the baseline model, but similar precision (BLEU) for both models. Qualitatively, we found that many of the lyrical phrases generated by the original model were still comprehensible and discernible between which genres they fit into, despite not necessarily being the exact the same as the true lyrics. Overall, our results yielded that lyric generation can reasonably be sped up to produce genre-based lyrics and aid in hastening the songwriting process.",
        "subjects": "Computation and Language, Artificial Intelligence, Sound, Audio and Speech Processing",
        "date": "2024-09-15 21:32:46 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513752"
    },
    {
        "index": "#116",
        "title": "Efficient Hybrid Inference for LLMs: Reward-Based Token Modelling with Selective Cloud Assistance",
        "link": "/arxiv/2409.13757",
        "arxiv_id": "2409.13757",
        "authors": "Adarsh MS, Jithin VG, Ditto PS",
        "summary": "Large language models (LLMs) are known for their exceptional performance across a range of natural language processing tasks, but their deployment comes at a high computational and financial cost. On the other hand, smaller language models (SLMs), which can be deployed on lower-cost edge devices, struggle to match the performance of their larger counterparts. This paper presents a novel hybrid inference approach that leverages the strengths of both model types while minimizing reliance on costly cloud-based LLMs. Unlike existing methods that route entire queries to either an SLM or a cloud LLM, our approach introduces a reward-based mechanism to dynamically determine the involvement of the cloud LLM during token generation. Specifically, each token predicted by the SLM is evaluated against a reward score, and only when this score falls below a certain threshold is the cloud LLM consulted for assistance in the next token prediction. This method not only reduces the traffic to the cloud LLM, thereby lowering costs, but also allows for flexible control over response quality depending on the reward score threshold. Experimental results demonstrate that our approach significantly reduces cloud LLM usage with minimal impact on overall response quality, offering a cost-effective solution for deploying high-performance language models",
        "subjects": "Computation and Language",
        "date": "2024-09-15 15:12:45 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513932"
    },
    {
        "index": "#117",
        "title": "Language Models Learn Metadata: Political Stance Detection Case Study",
        "link": "/arxiv/2409.13756",
        "arxiv_id": "2409.13756",
        "authors": "Stanley Cao, Felix Drinkall",
        "summary": "Stance detection is a crucial NLP task with numerous applications in social science, from analyzing online discussions to assessing political campaigns. This paper investigates the optimal way to incorporate metadata into a political stance detection task. We demonstrate that previous methods combining metadata with language-based data for political stance detection have not fully utilized the metadata information; our simple baseline, using only party membership information, surpasses the current state-of-the-art. We then show that prepending metadata (e.g., party and policy) to political speeches performs best, outperforming all baselines, indicating that complex metadata inclusion systems may not learn the task optimally.",
        "subjects": "Computation and Language",
        "date": "2024-09-15 14:57:41 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514099"
    },
    {
        "index": "#118",
        "title": "Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences",
        "link": "/arxiv/2409.13755",
        "arxiv_id": "2409.13755",
        "authors": "Xin Wang, Xinyi Bai",
        "summary": "Relation extraction as an important natural Language processing (NLP) task is to identify relations between named entities in text. Recently, graph convolutional networks over dependency trees have been widely used to capture syntactic features and achieved attractive performance. However, most existing dependency-based approaches ignore the positive influence of the words outside the dependency trees, sometimes conveying rich and useful information on relation extraction. In this paper, we propose a novel model, Entity-aware Self-attention Contextualized GCN (ESC-GCN), which efficiently incorporates syntactic structure of input sentences and semantic context of sequences. To be specific, relative position self-attention obtains the overall semantic pairwise correlation related to word position, and contextualized graph convolutional networks capture rich intra-sentence dependencies between words by adequately pruning operations. Furthermore, entity-aware attention layer dynamically selects which token is more decisive to make final relation prediction. In this way, our proposed model not only reduces the noisy impact from dependency trees, but also obtains easily-ignored entity-related semantic representation. Extensive experiments on various tasks demonstrate that our model achieves encouraging performance as compared to existing dependency-based and sequence-based models. Specially, our model excels in extracting relations between entities of long sentences.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-15 10:50:51 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514277"
    },
    {
        "index": "#119",
        "title": "Thinking Before Speaking: A Role-playing Model with Mindset",
        "link": "/arxiv/2409.13752",
        "arxiv_id": "2409.13752",
        "authors": "Baohua Zhang, Yongyi Huang, Wenyao Cui, Huaping Zhang",
        "summary": "Role-playing is an easy task for Large Language Models (LLMs), as they are skilled at simulating human behaviors. Many current studies have enabled LLMs to generate responses in the tone of a specific role by fine-tuning the models or using specialized prompts. However, it is typically easy to recognize when a role is being played by LLMs. These models tend to perform poorly when confronted with knowledge that the assumed role does not possess, or a question that requires the specific experience or logic of the role to answer. To address this problem and make LLMs act more like real roles, we propose a Thinking Before Speaking (TBS) model in this paper. Unlike other studies, we first extend the data based on the character's real-life scenarios and the historical dialogue, supplementing each pair of dialogue with the character's mindset. Then we add few data points that include elements beyond the role's knowledge, and fine-tune the LLMs. This approach can help LLMs adopt the role's thought process and logic, avoiding responses that fall outside the role's knowledge base. We have also prepared a dataset and evaluation metrics to test these capabilities. Experimental results show that our TBS model can better emulate a role in terms of tone, knowledge, and mindset.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-14 02:41:48 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514473"
    },
    {
        "index": "#120",
        "title": "KodeXv0.1: A Family of State-of-the-Art Financial Large Language Models",
        "link": "/arxiv/2409.13749",
        "arxiv_id": "2409.13749",
        "authors": "Neel Rajani, Lilli Kiessling, Aleksandr Ogaltsov, Claus Lang",
        "summary": "Although powerful, current cutting-edge LLMs may not fulfil the needs of highly specialised sectors. We introduce KodeXv0.1, a family of large language models that outclass GPT-4 in financial question answering. We utilise the base variants of Llama 3.1 8B and 70B and adapt them to the financial domain through a custom training regime. To this end, we collect and process a large number of publicly available financial documents such as earnings calls and business reports. These are used to generate a high-quality, synthetic dataset consisting of Context-Question-Answer triplets which closely mirror real-world financial tasks. Using the train split of this dataset, we perform RAG-aware 4bit LoRA instruction tuning runs of Llama 3.1 base variants to produce KodeX-8Bv0.1 and KodeX-70Bv0.1. We then complete extensive model evaluations using FinanceBench, FinQABench and the withheld test split of our dataset. Our results show that KodeX-8Bv0.1 is more reliable in financial contexts than cutting-edge instruct models in the same parameter regime, surpassing them by up to 9.24%. In addition, it is even capable of outperforming state-of-the-art proprietary models such as GPT-4 by up to 7.07%. KodeX-70Bv0.1 represents a further improvement upon this, exceeding GPT-4's performance on every tested benchmark.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-13 16:43:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514658"
    },
    {
        "index": "#121",
        "title": "TheraGen: Therapy for Every Generation",
        "link": "/arxiv/2409.13748",
        "arxiv_id": "2409.13748",
        "authors": "Kartikey Doshi, Jimit Shah, Narendra Shekokar",
        "summary": "We present TheraGen, an advanced AI-powered mental health chatbot utilizing the LLaMA 2 7B model. This approach builds upon recent advancements in language models and transformer architectures. TheraGen provides all-day personalized, compassionate mental health care by leveraging a large dataset of 1 million conversational entries, combining anonymized therapy transcripts, online mental health discussions, and psychological literature, including APA resources. Our implementation employs transfer learning, fine-tuning, and advanced training techniques to optimize performance. TheraGen offers a user-friendly interface for seamless interaction, providing empathetic responses and evidence-based coping strategies. Evaluation results demonstrate high user satisfaction rates, with 94% of users reporting improved mental well-being. The system achieved a BLEU score of 0.67 and a ROUGE score of 0.62, indicating strong response accuracy. With an average response time of 1395 milliseconds, TheraGen ensures real-time, efficient support. While not a replacement for professional therapy, TheraGen serves as a valuable complementary tool, significantly improving user well-being and addressing the accessibility gap in mental health treatments. This paper details TheraGen's architecture, training methodology, ethical considerations, and future directions, contributing to the growing field of AI-assisted mental healthcare and offering a scalable solution to the pressing need for mental health support.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-12 17:15:44 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514879"
    },
    {
        "index": "#122",
        "title": "Machine Translation with Large Language Models: Decoder Only vs. Encoder-Decoder",
        "link": "/arxiv/2409.13747",
        "arxiv_id": "2409.13747",
        "authors": "Abhinav P. M., SujayKumar Reddy M, Oswald Christopher",
        "summary": "This project, titled \"Machine Translation with Large Language Models: Decoder-only vs. Encoder-Decoder,\" aims to develop a multilingual machine translation (MT) model. Focused on Indian regional languages, especially Telugu, Tamil, and Malayalam, the model seeks to enable accurate and contextually appropriate translations across diverse language pairs. By comparing Decoder-only and Encoder-Decoder architectures, the project aims to optimize translation quality and efficiency, advancing cross-linguistic communication tools.The primary objective is to develop a model capable of delivering high-quality translations that are accurate and contextually appropriate. By leveraging large language models, specifically comparing the effectiveness of Decoder-only and Encoder-Decoder architectures, the project seeks to optimize translation performance and efficiency across multilingual contexts. Through rigorous experimentation and analysis, this project aims to advance the field of machine translation, contributing valuable insights into the effectiveness of different model architectures and paving the way for enhanced cross-linguistic communication tools.",
        "subjects": "Computation and Language, Emerging Technologies, Machine Learning",
        "date": "2024-09-12 00:21:05 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515088"
    },
    {
        "index": "#123",
        "title": "When Less Is Not More: Large Language Models Normalize Less-Frequent Terms with Lower Accuracy",
        "link": "/arxiv/2409.13746",
        "arxiv_id": "2409.13746",
        "authors": "Daniel B. Hier, Thanh Son Do, Tayo Obafemi-Ajayi",
        "summary": "Term normalization is the process of mapping a term from free text to a standardized concept and its machine-readable code in an ontology. Accurate normalization of terms that capture phenotypic differences between patients and diseases is critical to the success of precision medicine initiatives. A large language model (LLM), such as GPT-4o, can normalize terms to the Human Phenotype Ontology (HPO), but it may retrieve incorrect HPO IDs. Reported accuracy rates for LLMs on these tasks may be inflated due to imbalanced test datasets skewed towards high-frequency terms. In our study, using a comprehensive dataset of 268,776 phenotype annotations for 12,655 diseases from the HPO, GPT-4o achieved an accuracy of 13.1% in normalizing 11,225 unique terms. However, the accuracy was unevenly distributed, with higher-frequency and shorter terms normalized more accurately than lower-frequency and longer terms. Feature importance analysis, using SHAP and permutation methods, identified low-term frequency as the most significant predictor of normalization errors. These findings suggest that training and evaluation datasets for LLM-based term normalization should balance low- and high-frequency terms to improve model performance, particularly for infrequent terms critical to precision medicine.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-11 21:34:46 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515270"
    },
    {
        "index": "#124",
        "title": "Context-Aware Membership Inference Attacks against Pre-trained Large Language Models",
        "link": "/arxiv/2409.13745",
        "arxiv_id": "2409.13745",
        "authors": "Hongyan Chang, Ali Shahin Shamsabadi, Kleomenis Katevas, Hamed Haddadi, Reza Shokri",
        "summary": "Prior Membership Inference Attacks (MIAs) on pre-trained Large Language Models (LLMs), adapted from classification model attacks, fail due to ignoring the generative process of LLMs across token sequences. In this paper, we present a novel attack that adapts MIA statistical tests to the perplexity dynamics of subsequences within a data point. Our method significantly outperforms prior loss-based approaches, revealing context-dependent memorization patterns in pre-trained LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security, Machine Learning, Machine Learning",
        "date": "2024-09-11 01:56:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515567"
    },
    {
        "index": "#125",
        "title": "A Simplified Retriever to Improve Accuracy of Phenotype Normalizations by Large Language Models",
        "link": "/arxiv/2409.13744",
        "arxiv_id": "2409.13744",
        "authors": "Daniel B. Hier, Thanh Son Do, Tayo Obafemi-Ajayi",
        "summary": "Large language models (LLMs) have shown improved accuracy in phenotype term normalization tasks when augmented with retrievers that suggest candidate normalizations based on term definitions. In this work, we introduce a simplified retriever that enhances LLM accuracy by searching the Human Phenotype Ontology (HPO) for candidate matches using contextual word embeddings from BioBERT without the need for explicit term definitions. Testing this method on terms derived from the clinical synopses of Online Mendelian Inheritance in Man (OMIM), we demonstrate that the normalization accuracy of a state-of-the-art LLM increases from a baseline of 62.3% without augmentation to 90.3% with retriever augmentation. This approach is potentially generalizable to other biomedical term normalization tasks and offers an efficient alternative to more complex retrieval methods.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-11 00:16:17 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515763"
    },
    {
        "index": "#126",
        "title": "Knowing When to Ask -- Bridging Large Language Models and Data",
        "link": "/arxiv/2409.13741",
        "arxiv_id": "2409.13741",
        "authors": "Prashanth Radhakrishnan, Jennifer Chen, Bo Xu, Prem Ramaswami, Hannah Pho, Adriana Olmos, James Manyika, R. V. Guha",
        "summary": "Large Language Models (LLMs) are prone to generating factually incorrect information when responding to queries that involve numerical and statistical data or other timely facts. In this paper, we present an approach for enhancing the accuracy of LLMs by integrating them with Data Commons, a vast, open-source repository of public statistics from trusted organizations like the United Nations (UN), Center for Disease Control and Prevention (CDC) and global census bureaus. We explore two primary methods: Retrieval Interleaved Generation (RIG), where the LLM is trained to produce natural language queries to retrieve data from Data Commons, and Retrieval Augmented Generation (RAG), where relevant data tables are fetched from Data Commons and used to augment the LLM's prompt. We evaluate these methods on a diverse set of queries, demonstrating their effectiveness in improving the factual accuracy of LLM outputs. Our work represents an early step towards building more trustworthy and reliable LLMs that are grounded in verifiable statistical data and capable of complex factual reasoning.",
        "subjects": "Computation and Language",
        "date": "2024-09-10 17:51:21 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515968"
    },
    {
        "index": "#127",
        "title": "Language agents achieve superhuman synthesis of scientific knowledge",
        "link": "/arxiv/2409.13740",
        "arxiv_id": "2409.13740",
        "authors": "Michael D. Skarlinski, Sam Cox, Jon M. Laurent, James D. Braza, Michaela Hinks, Michael J. Hammerling, Manvitha Ponnapati, Samuel G. Rodriques, Andrew D. White",
        "summary": "Language models are known to produce incorrect information, and their accuracy and reliability for scientific research are still in question. We developed a detailed human-AI comparison method to evaluate language models on real-world literature search tasks, including information retrieval, summarization, and contradiction detection. Our findings show that PaperQA2, an advanced language model focused on improving factual accuracy, matches or outperforms subject matter experts on three realistic literature search tasks, with no restrictions on human participants (full internet access, search tools, and time). PaperQA2 generates cited, Wikipedia-style summaries of scientific topics that are significantly more accurate than current human-written Wikipedia entries. We also present LitQA2, a new benchmark for scientific literature research, which shaped the development of PaperQA2 and contributed to its superior performance. Additionally, PaperQA2 identifies contradictions in scientific literature, a challenging task for humans. It finds an average of 2.34 +/- 1.99 contradictions per paper in a random sample of biology papers, with 70% of these contradictions validated by human experts. These results show that language models can now surpass domain experts in important scientific literature tasks.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval, Physics and Society",
        "date": "2024-09-10 16:37:58 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.521579"
    },
    {
        "index": "#128",
        "title": "Table-to-Text Generation with Pretrained Diffusion Models",
        "link": "/arxiv/2409.13739",
        "arxiv_id": "2409.13739",
        "authors": "Aleksei S. Krylov, Oleg D. Somov",
        "summary": "Diffusion models have demonstrated significant potential in achieving state-of-the-art performance across various text generation tasks. In this systematic study, we investigate their application to the table-to-text problem by adapting the diffusion model to the task and conducting an in-depth analysis. Our experiments cover multiple aspects of diffusion models training. We explore sampling strategy influence by inducing recent diffusion model accelerator DPM-Solver++ into our core model. We have tested different prediction aggregation methods, like ROVER and Minimum Bayes-Risk (MBR). Our studies cover the impact of the pre-training phase in diffusion models and the generation length constraints influence. We also have compared diffusion model generation with auto-regressive text-to-text models with different temperature settings for diversity evaluation. Our key observation is that diffusion models demonstrate the balance between quality and diversity while auto-regressive text-to-text models are not successful at handling both at the same time. Furthermore, we found out that to achieve the highest quality possible, it is preferable to use a regular sampler with the strictest length constraint to create multiple samples, and then use MBR to aggregate the predictions. However, if you are prepared to give up high level of diversity and to accelerate the process, you can also utilize a fast sampler DPM-Solver++. Our findings reveal that diffusion models achieve comparable results in the table-to-text domain, highlighting their viability in the table-to-text challenge as a promising research direction.",
        "subjects": "Computation and Language",
        "date": "2024-09-10 15:36:53 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.521990"
    },
    {
        "index": "#129",
        "title": "NLP4PBM: A Systematic Review on Process Extraction using Natural Language Processing with Rule-based, Machine and Deep Learning Methods",
        "link": "/arxiv/2409.13738",
        "arxiv_id": "2409.13738",
        "authors": "William Van Woensel, Soroor Motie",
        "summary": "This literature review studies the field of automated process extraction, i.e., transforming textual descriptions into structured processes using Natural Language Processing (NLP). We found that Machine Learning (ML) / Deep Learning (DL) methods are being increasingly used for the NLP component. In some cases, they were chosen for their suitability towards process extraction, and results show that they can outperform classic rule-based methods. We also found a paucity of gold-standard, scalable annotated datasets, which currently hinders objective evaluations as well as the training or fine-tuning of ML / DL methods. Finally, we discuss preliminary work on the application of LLMs for automated process extraction, as well as promising developments in this field.",
        "subjects": "Computation and Language",
        "date": "2024-09-10 15:16:02 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.522323"
    },
    {
        "index": "#130",
        "title": "Analysis of Socially Unacceptable Discourse with Zero-shot Learning",
        "link": "/arxiv/2409.13735",
        "arxiv_id": "2409.13735",
        "authors": "Rayane Ghilene, Dimitra Niaouri, Michele Linardi, Julien Longhi",
        "summary": "Socially Unacceptable Discourse (SUD) analysis is crucial for maintaining online positive environments. We investigate the effectiveness of Entailment-based zero-shot text classification (unsupervised method) for SUD detection and characterization by leveraging pre-trained transformer models and prompting techniques. The results demonstrate good generalization capabilities of these models to unseen data and highlight the promising nature of this approach for generating labeled datasets for the analysis and characterization of extremist narratives. The findings of this research contribute to the development of robust tools for studying SUD and promoting responsible communication online.",
        "subjects": "Computation and Language",
        "date": "2024-09-10 07:32:00 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.522654"
    },
    {
        "index": "#131",
        "title": "Enhancing Kurdish Text-to-Speech with Native Corpus Training: A High-Quality WaveGlow Vocoder Approach",
        "link": "/arxiv/2409.13734",
        "arxiv_id": "2409.13734",
        "authors": "Abdulhady Abas Abdullah, Sabat Salih Muhamad, Hadi Veisi",
        "summary": "The ability to synthesize spoken language from text has greatly facilitated access to digital content with the advances in text-to-speech technology. However, effective TTS development for low-resource languages, such as Central Kurdish (CKB), still faces many challenges due mainly to the lack of linguistic information and dedicated resources. In this paper, we improve the Kurdish TTS system based on Tacotron by training the Kurdish WaveGlow vocoder on a 21-hour central Kurdish speech corpus instead of using a pre-trained English vocoder WaveGlow. Vocoder training on the target language corpus is required to accurately and fluently adapt phonetic and prosodic changes in Kurdish language. The effectiveness of these enhancements is that our model is significantly better than the baseline system with English pretrained models. In particular, our adaptive WaveGlow model achieves an impressive MOS of 4.91, which sets a new benchmark for Kurdish speech synthesis. On one hand, this study empowers the advanced features of the TTS system for Central Kurdish, and on the other hand, it opens the doors for other dialects in Kurdish and other related languages to further develop.",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2024-09-10 06:23:52 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.522861"
    },
    {
        "index": "#132",
        "title": "RNR: Teaching Large Language Models to Follow Roles and Rules",
        "link": "/arxiv/2409.13733",
        "arxiv_id": "2409.13733",
        "authors": "Kuan Wang, Alexander Bukharin, Haoming Jiang, Qingyu Yin, Zhengyang Wang, Tuo Zhao, Jingbo Shang, Chao Zhang, Bing Yin, Xian Li, Jianshu Chen, Shiyang Li",
        "summary": "Instruction fine-tuning (IFT) elicits instruction following capabilities and steers the behavior of large language models (LLMs) via supervised learning. However, existing models trained on open-source IFT datasets only have the ability to follow instructions from users, and often fail to follow complex role and rules specified by developers, a.k.a. system prompts. The ability to follow these roles and rules is essential for deployment, as it ensures that the model safely interacts with users within developer defined guidelines. To improve such role and rule following ability, we propose \\model, an automated data generation pipeline that generates diverse roles and rules from existing IFT instructions, along with corresponding responses. This data can then be used to train models that follow complex system prompts. The models are evaluated on our newly created benchmarks for role and rule following ability, as well as standard instruction-following benchmarks and general NLP tasks. Our framework significantly improves role and rule following capability in LLMs, as evidenced by over 25% increase in pass-rate on rule adherence, i.e. following all requirements, in our experiments with the Alpaca and Ultrachat datasets. Moreover, our models achieves this increase without any regression on popular instruction following benchmarks.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-10 06:07:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.523151"
    },
    {
        "index": "#133",
        "title": "TopoChat: Enhancing Topological Materials Retrieval With Large Language Model and Multi-Source Knowledge",
        "link": "/arxiv/2409.13732",
        "arxiv_id": "2409.13732",
        "authors": "HuangChao Xu, Baohua Zhang, Zhong Jin, Tiannian Zhu, Quansheng Wu, Hongming Weng",
        "summary": "Large language models (LLMs), such as ChatGPT, have demonstrated impressive performance in the text generation task, showing the ability to understand and respond to complex instructions. However, the performance of naive LLMs in speciffc domains is limited due to the scarcity of domain-speciffc corpora and specialized training. Moreover, training a specialized large-scale model necessitates signiffcant hardware resources, which restricts researchers from leveraging such models to drive advances. Hence, it is crucial to further improve and optimize LLMs to meet speciffc domain demands and enhance their scalability. Based on the condensed matter data center, we establish a material knowledge graph (MaterialsKG) and integrate it with literature. Using large language models and prompt learning, we develop a specialized dialogue system for topological materials called TopoChat. Compared to naive LLMs, TopoChat exhibits superior performance in structural and property querying, material recommendation, and complex relational reasoning. This system enables efffcient and precise retrieval of information and facilitates knowledge interaction, thereby encouraging the advancement on the ffeld of condensed matter materials.",
        "subjects": "Computation and Language, Materials Science, Machine Learning",
        "date": "2024-09-10 06:01:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.523378"
    },
    {
        "index": "#134",
        "title": "KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation",
        "link": "/arxiv/2409.13731",
        "arxiv_id": "2409.13731",
        "authors": "Lei Liang, Mengshu Sun, Zhengke Gui, Zhongshu Zhu, Zhouyu Jiang, Ling Zhong, Yuan Qu, Peilong Zhao, Zhongpu Bo, Jin Yang, Huaidong Xiong, Lin Yuan, Jun Xu, Zaoyang Wang, Wen Zhang, Huajun Chen, Zhiqiang Zhang, Jun Zhou",
        "summary": "The recently developed retrieval-augmented generation (RAG) technology enables the efficient construction of domain-specific applications. However, it faces limitations due to fuzzy retrieval processes, the \"hallucination\" problem of understanding and reasoning capabilities of general language models, and cascading losses in complex systems. These challenges hinder the effectiveness of specialized knowledge services. However, in scenarios such as scientific computing, medicine, and law, the accuracy of knowledge, the completeness of information, and the logical rigor of rules, time, and values are particularly critical. We Introduce professional domain knowledge service framework: Knowledge Augmented Generation(KAG) to improve generation and reasoning performance by bidirectionally enhancing large language model(LLM)s and knowledge graph(KG)s, including five key enhancements: 1) LLM-friendly knowledge semantic representation, 2) mutual indexing between knowledge graph and original chunks, 3) logicalform-guided hybrid reasoning and solving, 4) Knowledge alignment based on semantic reasoning, 5) Model for KAG. We compared KAG with existing RAG methods in multi-hop question answering. The results show that KAG performs significantly better than the state-of-the-art methods, with a relative improvement from 19.6% to 33.4% in F1. We apply KAG to two professional knowledge Q&A tasks of Ant Group, including E-Goverment Q&A and E-Health Q&A, and has achieved significant improvement in professionalism compared with NaiveRAG. We will soon natively support KAG on the open source KG engine OpenSPG, allowing developers to more easily build rigorous knowledge decision-making or convenient information retrieval services.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-10 02:00:28 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.523660"
    },
    {
        "index": "#135",
        "title": "MathGLM-Vision: Solving Mathematical Problems with Multi-Modal Large Language Model",
        "link": "/arxiv/2409.13729",
        "arxiv_id": "2409.13729",
        "authors": "Zhen Yang, Jinhao Chen, Zhengxiao Du, Wenmeng Yu, Weihan Wang, Wenyi Hong, Zhihuan Jiang, Bin Xu, Yuxiao Dong, Jie Tang",
        "summary": "Large language models (LLMs) have demonstrated significant capabilities in mathematical reasoning, particularly with text-based mathematical problems. However, current multi-modal large language models (MLLMs), especially those specialized in mathematics, tend to focus predominantly on solving geometric problems but ignore the diversity of visual information available in other areas of mathematics. Moreover, the geometric information for these specialized mathematical MLLMs is derived from several public datasets, which are typically limited in diversity and complexity. To address these limitations, we aim to construct a fine-tuning dataset named MathVL, and develop a series of specialized mathematical MLLMs termed MathGLM-Vision by conducting Supervised Fine-Tuning (SFT) on MathVL with various parameter-scale backbones. To extensively evaluate the effectiveness of MathGLM-Vision, we conduct experiments on several public benchmarks and our curated MathVL-test consisting of 2,000 problems. Experimental results demonstrate that MathGLM-Vision achieves significant improvements compared with some existing models, including backbone models and open-source mathematical MLLMs. These findings indicate the importance of diversity dataset in enhancing the mathematical reasoning abilities of MLLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-10 01:20:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.523888"
    },
    {
        "index": "#136",
        "title": "Rule Extrapolation in Language Models: A Study of Compositional Generalization on OOD Prompts",
        "link": "/arxiv/2409.13728",
        "arxiv_id": "2409.13728",
        "authors": "Anna Mészáros, Szilvia Ujváry, Wieland Brendel, Patrik Reizinger, Ferenc Huszár",
        "summary": "LLMs show remarkable emergent abilities, such as inferring concepts from presumably out-of-distribution prompts, known as in-context learning. Though this success is often attributed to the Transformer architecture, our systematic understanding is limited. In complex real-world data sets, even defining what is out-of-distribution is not obvious. To better understand the OOD behaviour of autoregressive LLMs, we focus on formal languages, which are defined by the intersection of rules. We define a new scenario of OOD compositional generalization, termed rule extrapolation. Rule extrapolation describes OOD scenarios, where the prompt violates at least one rule. We evaluate rule extrapolation in formal languages with varying complexity in linear and recurrent architectures, the Transformer, and state space models to understand the architectures' influence on rule extrapolation. We also lay the first stones of a normative theory of rule extrapolation, inspired by the Solomonoff prior in algorithmic information theory.",
        "subjects": "Computation and Language, Machine Learning, Machine Learning",
        "date": "2024-09-09 22:36:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524141"
    },
    {
        "index": "#137",
        "title": "Classification performance and reproducibility of GPT-4 omni for information extraction from veterinary electronic health records",
        "link": "/arxiv/2409.13727",
        "arxiv_id": "2409.13727",
        "authors": "Judit M Wulcan, Kevin L Jacques, Mary Ann Lee, Samantha L Kovacs, Nicole Dausend, Lauren E Prince, Jonatan Wulcan, Sina Marsilio, Stefan M Keller",
        "summary": "Large language models (LLMs) can extract information from veterinary electronic health records (EHRs), but performance differences between models, the effect of temperature settings, and the influence of text ambiguity have not been previously evaluated. This study addresses these gaps by comparing the performance of GPT-4 omni (GPT-4o) and GPT-3.5 Turbo under different conditions and investigating the relationship between human interobserver agreement and LLM errors. The LLMs and five humans were tasked with identifying six clinical signs associated with Feline chronic enteropathy in 250 EHRs from a veterinary referral hospital. At temperature 0, the performance of GPT-4o compared to the majority opinion of human respondents, achieved 96.9% sensitivity (interquartile range [IQR] 92.9-99.3%), 97.6% specificity (IQR 96.5-98.5%), 80.7% positive predictive value (IQR 70.8-84.6%), 99.5% negative predictive value (IQR 99.0-99.9%), 84.4% F1 score (IQR 77.3-90.4%), and 96.3% balanced accuracy (IQR 95.0-97.9%). The performance of GPT-4o was significantly better than that of its predecessor, GPT-3.5 Turbo, particularly with respect to sensitivity where GPT-3.5 Turbo only achieved 81.7% (IQR 78.9-84.8%). Adjusting the temperature for GPT-4o did not significantly impact classification performance. GPT-4o demonstrated greater reproducibility than human pairs regardless of temperature, with an average Cohen's kappa of 0.98 (IQR 0.98-0.99) at temperature 0 compared to 0.8 (IQR 0.78-0.81) for humans. Most GPT-4o errors occurred in instances where humans disagreed (35/43 errors, 81.4%), suggesting that these errors were more likely caused by ambiguity of the EHR than explicit model faults. Using GPT-4o to automate information extraction from veterinary EHRs is a viable alternative to manual extraction.",
        "subjects": "Computation and Language",
        "date": "2024-09-09 21:55:15 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524358"
    },
    {
        "index": "#138",
        "title": "Multilingual Dyadic Interaction Corpus NoXi+J: Toward Understanding Asian-European Non-verbal Cultural Characteristics and their Influences on Engagement",
        "link": "/arxiv/2409.13726",
        "arxiv_id": "2409.13726",
        "authors": "Marius Funk, Shogo Okada, Elisabeth André",
        "summary": "Non-verbal behavior is a central challenge in understanding the dynamics of a conversation and the affective states between interlocutors arising from the interaction. Although psychological research has demonstrated that non-verbal behaviors vary across cultures, limited computational analysis has been conducted to clarify these differences and assess their impact on engagement recognition. To gain a greater understanding of engagement and non-verbal behaviors among a wide range of cultures and language spheres, in this study we conduct a multilingual computational analysis of non-verbal features and investigate their role in engagement and engagement prediction. To achieve this goal, we first expanded the NoXi dataset, which contains interaction data from participants living in France, Germany, and the United Kingdom, by collecting session data of dyadic conversations in Japanese and Chinese, resulting in the enhanced dataset NoXi+J. Next, we extracted multimodal non-verbal features, including speech acoustics, facial expressions, backchanneling and gestures, via various pattern recognition techniques and algorithms. Then, we conducted a statistical analysis of listening behaviors and backchannel patterns to identify culturally dependent and independent features in each language and common features among multiple languages. These features were also correlated with the engagement shown by the interlocutors. Finally, we analyzed the influence of cultural differences in the input features of LSTM models trained to predict engagement for five language datasets. A SHAP analysis combined with transfer learning confirmed a considerable correlation between the importance of input features for a language set and the significant cultural characteristics analyzed.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-09 18:37:34 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524556"
    },
    {
        "index": "#139",
        "title": "Identity-related Speech Suppression in Generative AI Content Moderation",
        "link": "/arxiv/2409.13725",
        "arxiv_id": "2409.13725",
        "authors": "Oghenefejiro Isaacs Anigboro, Charlie M. Crawford, Danaë Metaxa, Sorelle A. Friedler",
        "summary": "Automated content moderation has long been used to help identify and filter undesired user-generated content online. Generative AI systems now use such filters to keep undesired generated content from being created by or shown to users. From classrooms to Hollywood, as generative AI is increasingly used for creative or expressive text generation, whose stories will these technologies allow to be told, and whose will they suppress? In this paper, we define and introduce measures of speech suppression, focusing on speech related to different identity groups incorrectly filtered by a range of content moderation APIs. Using both short-form, user-generated datasets traditional in content moderation and longer generative AI-focused data, including two datasets we introduce in this work, we create a benchmark for measurement of speech suppression for nine identity groups. Across one traditional and four generative AI-focused automated content moderation services tested, we find that identity-related speech is more likely to be incorrectly suppressed than other speech except in the cases of a few non-marginalized groups. Additionally, we find differences between APIs in their abilities to correctly moderate generative AI content.",
        "subjects": "Computation and Language, Computers and Society, Human-Computer Interaction",
        "date": "2024-09-09 14:34:51 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524752"
    },
    {
        "index": "#140",
        "title": "Logically Consistent Language Models via Neuro-Symbolic Integration",
        "link": "/arxiv/2409.13724",
        "arxiv_id": "2409.13724",
        "authors": "Diego Calanzone, Stefano Teso, Antonio Vergari",
        "summary": "Large language models (LLMs) are a promising venue for natural language understanding and generation. However, current LLMs are far from reliable: they are prone to generating non-factual information and, more crucially, to contradicting themselves when prompted to reason about relations between entities of the world. These problems are currently addressed with large scale fine-tuning or by delegating reasoning to external tools. In this work, we strive for a middle ground and introduce a loss based on neuro-symbolic reasoning that teaches an LLM to be logically consistent with an external set of facts and rules and improves self-consistency even when the LLM is fine-tuned on a limited set of facts. Our approach also allows to easily combine multiple logical constraints at once in a principled way, delivering LLMs that are more consistent w.r.t. all constraints and improve over several baselines w.r.t. a given constraint. Moreover, our method allows LLMs to extrapolate to unseen but semantically similar factual knowledge, represented in unseen datasets, more systematically.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-09 10:52:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524950"
    },
    {
        "index": "#141",
        "title": "LegiLM: A Fine-Tuned Legal Language Model for Data Compliance",
        "link": "/arxiv/2409.13721",
        "arxiv_id": "2409.13721",
        "authors": "Linkai Zhu, Lu Yang, Chaofan Li, Shanwen Hu, Lu Liu, Bin Yin",
        "summary": "Ensuring compliance with international data protection standards for privacy and data security is a crucial but complex task, often requiring substantial legal expertise. This paper introduces LegiLM, a novel legal language model specifically tailored for consulting on data or information compliance. LegiLM leverages a pre-trained GDPR Fines dataset and has been fine-tuned to automatically assess whether particular actions or events breach data security and privacy regulations. By incorporating a specialized dataset that includes global data protection laws, meticulously annotated policy documents, and relevant privacy policies, LegiLM is optimized for addressing data compliance challenges. The model integrates advanced legal reasoning methods and information retrieval enhancements to enhance accuracy and reliability in practical legal consulting scenarios. Our evaluation using a custom benchmark dataset demonstrates that LegiLM excels in detecting data regulation breaches, offering sound legal justifications, and recommending necessary compliance modifications, setting a new benchmark for AI-driven legal compliance solutions. Our resources are publicly available at https://github.com/DAOLegalAI/LegiLM",
        "subjects": "Computation and Language",
        "date": "2024-09-09 02:06:52 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.525154"
    },
    {
        "index": "#142",
        "title": "DiVA-DocRE: A Discriminative and Voice-Aware Paradigm for Document-Level Relation Extraction",
        "link": "/arxiv/2409.13717",
        "arxiv_id": "2409.13717",
        "authors": "Yiheng Wu, Roman Yangarber, Xian Mao",
        "summary": "The remarkable capabilities of Large Language Models (LLMs) in text comprehension and generation have revolutionized Information Extraction (IE). One such advancement is in Document-level Relation Triplet Extraction (DocRTE), a critical task in information systems that aims to extract entities and their semantic relationships from documents. However, existing methods are primarily designed for Sentence level Relation Triplet Extraction (SentRTE), which typically handles a limited set of relations and triplet facts within a single sentence. Additionally, some approaches treat relations as candidate choices integrated into prompt templates, resulting in inefficient processing and suboptimal performance when determining the relation elements in triplets. To address these limitations, we introduce a Discriminative and Voice Aware Paradigm DiVA. DiVA involves only two steps: performing document-level relation extraction (DocRE) and then identifying the subject object entities based on the relation. No additional processing is required simply input the document to directly obtain the triplets. This streamlined process more accurately reflects real-world scenarios for triplet extraction. Our innovation lies in transforming DocRE into a discriminative task, where the model pays attention to each relation and to the often overlooked issue of active vs. passive voice within the triplet. Our experiments on the Re-DocRED and DocRED datasets demonstrate state-of-the-art results for the DocRTE task.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-07 18:47:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.525416"
    },
    {
        "index": "#143",
        "title": "Constrained Multi-Layer Contrastive Learning for Implicit Discourse Relationship Recognition",
        "link": "/arxiv/2409.13716",
        "arxiv_id": "2409.13716",
        "authors": "Yiheng Wu, Junhui Li, Muhua Zhu",
        "summary": "Previous approaches to the task of implicit discourse relation recognition (IDRR) generally view it as a classification task. Even with pre-trained language models, like BERT and RoBERTa, IDRR still relies on complicated neural networks with multiple intermediate layers to proper capture the interaction between two discourse units. As a result, the outputs of these intermediate layers may have different capability in discriminating instances of different classes. To this end, we propose to adapt a supervised contrastive learning (CL) method, label- and instance-centered CL, to enhance representation learning. Moreover, we propose a novel constrained multi-layer CL approach to properly impose a constraint that the contrastive loss of higher layers should be smaller than that of lower layers. Experimental results on PDTB 2.0 and PDTB 3.0 show that our approach can significantly improve the performance on both multi-class classification and binary classification.",
        "subjects": "Computation and Language",
        "date": "2024-09-07 17:55:41 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.525610"
    },
    {
        "index": "#144",
        "title": "Introducing MeMo: A Multimodal Dataset for Memory Modelling in Multiparty Conversations",
        "link": "/arxiv/2409.13715",
        "arxiv_id": "2409.13715",
        "authors": "Maria Tsfasman, Bernd Dudzik, Kristian Fenech, Andras Lorincz, Catholijn M. Jonker, Catharine Oertel",
        "summary": "The quality of human social relationships is intricately linked to human memory processes, with memory serving as the foundation for the creation of social bonds. Since human memory is selective, differing recollections of the same events within a group can lead to misunderstandings and misalignments in what is perceived to be common ground in the group. Yet, conversational facilitation systems, aimed at advancing the quality of group interactions, usually focus on tracking users' states within an individual session, ignoring what remains in each participant's memory after the interaction. Conversational memory is the process by which humans encode, retain and retrieve verbal, non-verbal and contextual information from a conversation. Understanding conversational memory can be used as a source of information on the long-term development of social connections within a group. This paper introduces the MeMo corpus, the first conversational dataset annotated with participants' memory retention reports, aimed at facilitating computational modelling of human conversational memory. The MeMo corpus includes 31 hours of small-group discussions on the topic of Covid-19, repeated over the term of 2 weeks. It integrates validated behavioural and perceptual measures, and includes audio, video, and multimodal annotations, offering a valuable resource for studying and modelling conversational memory and group dynamics. By introducing the MeMo corpus, presenting an analysis of its validity, and demonstrating its usefulness for future research, this paper aims to pave the way for future research in conversational memory modelling for intelligent system development.",
        "subjects": "Computation and Language, Artificial Intelligence, Human-Computer Interaction, Machine Learning",
        "date": "2024-09-07 16:09:36 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.525835"
    },
    {
        "index": "#145",
        "title": "TracrBench: Generating Interpretability Testbeds with Large Language Models",
        "link": "/arxiv/2409.13714",
        "arxiv_id": "2409.13714",
        "authors": "Hannes Thurnherr, Jérémy Scheurer",
        "summary": "Achieving a mechanistic understanding of transformer-based language models is an open challenge, especially due to their large number of parameters. Moreover, the lack of ground truth mappings between model weights and their functional roles hinders the effective evaluation of interpretability methods, impeding overall progress. Tracr, a method for generating compiled transformers with inherent ground truth mappings in RASP, has been proposed to address this issue. However, manually creating a large number of models needed for verifying interpretability methods is labour-intensive and time-consuming. In this work, we present a novel approach for generating interpretability test beds using large language models (LLMs) and introduce TracrBench, a novel dataset consisting of 121 manually written and LLM-generated, human-validated RASP programs and their corresponding transformer weights. During this process, we evaluate the ability of frontier LLMs to autonomously generate RASP programs and find that this task poses significant challenges. GPT-4-turbo, with a 20-shot prompt and best-of-5 sampling, correctly implements only 57 out of 101 test programs, necessitating the manual implementation of the remaining programs. With its 121 samples, TracrBench aims to serve as a valuable testbed for evaluating and comparing interpretability methods.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-07 10:02:51 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.526062"
    },
    {
        "index": "#146",
        "title": "Sentiment Informed Sentence BERT-Ensemble Algorithm for Depression Detection",
        "link": "/arxiv/2409.13713",
        "arxiv_id": "2409.13713",
        "authors": "Bayode Ogunleye, Hemlata Sharma, Olamilekan Shobayo",
        "summary": "The World Health Organisation (WHO) revealed approximately 280 million people in the world suffer from depression. Yet, existing studies on early-stage depression detection using machine learning (ML) techniques are limited. Prior studies have applied a single stand-alone algorithm, which is unable to deal with data complexities, prone to overfitting, and limited in generalization. To this end, our paper examined the performance of several ML algorithms for early-stage depression detection using two benchmark social media datasets (D1 and D2). More specifically, we incorporated sentiment indicators to improve our model performance. Our experimental results showed that sentence bidirectional encoder representations from transformers (SBERT) numerical vectors fitted into the stacking ensemble model achieved comparable F1 scores of 69% in the dataset (D1) and 76% in the dataset (D2). Our findings suggest that utilizing sentiment indicators as an additional feature for depression detection yields an improved model performance, and thus, we recommend the development of a depressive term corpus for future work.",
        "subjects": "Computation and Language, Machine Learning, Statistics Theory, Applications",
        "date": "2024-09-07 07:47:55 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.526273"
    },
    {
        "index": "#147",
        "title": "Good Idea or Not, Representation of LLM Could Tell",
        "link": "/arxiv/2409.13712",
        "arxiv_id": "2409.13712",
        "authors": "Yi Xu, Bo Xue, Shuqian Sheng, Cheng Deng, Jiaxin Ding, Zanwei Shen, Luoyi Fu, Xinbing Wang, Chenghu Zhou",
        "summary": "In the ever-expanding landscape of academic research, the proliferation of ideas presents a significant challenge for researchers: discerning valuable ideas from the less impactful ones. The ability to efficiently evaluate the potential of these ideas is crucial for the advancement of science and paper review. In this work, we focus on idea assessment, which aims to leverage the knowledge of large language models to assess the merit of scientific ideas. First, we investigate existing text evaluation research and define the problem of quantitative evaluation of ideas. Second, we curate and release a benchmark dataset from nearly four thousand manuscript papers with full texts, meticulously designed to train and evaluate the performance of different approaches to this task. Third, we establish a framework for quantifying the value of ideas by employing representations in a specific layer of large language models. Experimental results show that the scores predicted by our method are relatively consistent with those of humans. Our findings suggest that the representations of large language models hold more potential in quantifying the value of ideas than their generative outputs, demonstrating a promising avenue for automating the idea assessment process.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-07 02:07:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.526503"
    },
    {
        "index": "#148",
        "title": "You can remove GPT2's LayerNorm by fine-tuning",
        "link": "/arxiv/2409.13710",
        "arxiv_id": "2409.13710",
        "authors": "Stefan Heimersheim",
        "summary": "The LayerNorm (LN) layer in GPT-style transformer models has long been a hindrance to mechanistic interpretability. LN is a crucial component required to stabilize the training of large language models, and LN or the similar RMSNorm have been used in practically all large language models based on the transformer architecture. The non-linear nature of the LN layers is a hindrance for mechanistic interpretability as it hinders interpretation of the residual stream, and makes it difficult to decompose the model into circuits. Some research have gone so far as to name \"reasons interpretability researchers hate layer norm\". In this paper we show that it is possible to remove the LN layers from a pre-trained GPT2-small model by fine-tuning on a fraction (500M tokens) of the training data. We demonstrate that this LN-free model achieves similar performance to the original model on the OpenWebText and ThePile datasets (-0.05 cross-entropy loss), and the Hellaswag benchmark (-0.5% accuracy). We provide the fine-tuning procedure and a Hugging Face repository with the fine-tuned GPT2-small models. Our work not only provides a simplified model for mechanistic interpretability research, but also provides evidence that the LN layers, at inference time, do not play a crucial role in transformer models.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-06 16:17:06 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.532159"
    },
    {
        "index": "#149",
        "title": "Column Vocabulary Association (CVA): semantic interpretation of dataless tables",
        "link": "/arxiv/2409.13709",
        "arxiv_id": "2409.13709",
        "authors": "Margherita Martorana, Xueli Pan, Benno Kruit, Tobias Kuhn, Jacco van Ossenbruggen",
        "summary": "Traditional Semantic Table Interpretation (STI) methods rely primarily on the underlying table data to create semantic annotations. This year's SemTab challenge introduced the ``Metadata to KG'' track, which focuses on performing STI by using only metadata information, without access to the underlying data. In response to this new challenge, we introduce a new term: Column Vocabulary Association (CVA). This term refers to the task of semantic annotation of column headers solely based on metadata information. In this study, we evaluate the performance of various methods in executing the CVA task, including a Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) approach, as well as a more traditional similarity approach with SemanticBERT. Our methodology uses a zero-shot setting, with no pretraining or examples passed to the Large Language Models (LLMs), as we aim to avoid a domain-specific setting. We investigate a total of 7 different LLMs, of which three commercial GPT models (i.e. gpt-3.5-turbo-0.125, gpt-4o and gpt-4-turbo) and four open source models (i.e. llama3-80b, llama3-7b, gemma-7b and mixtral-8x7b). We integrate this models with RAG systems, and we explore how variations in temperature settings affect performances. Moreover, we continue our investigation by performing the CVA task utilizing SemanticBERT, analyzing how various metadata information influence its performance. Initial findings indicate that LLMs generally perform well at temperatures below 1.0, achieving an accuracy of 100\\% in certain cases. Nevertheless, our investigation also reveal that the nature of the data significantly influences CVA task outcomes. In fact, in cases where the input data and glossary are related (for example by being created by the same organizations) traditional methods appear to surpass the performance of LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-06 14:58:30 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.532607"
    },
    {
        "index": "#150",
        "title": "Towards Safe Multilingual Frontier AI",
        "link": "/arxiv/2409.13708",
        "arxiv_id": "2409.13708",
        "authors": "Artūrs Kanepajs, Vladimir Ivanov, Richard Moulange",
        "summary": "Linguistically inclusive LLMs -- which maintain good performance regardless of the language with which they are prompted -- are necessary for the diffusion of AI benefits around the world. Multilingual jailbreaks that rely on language translation to evade safety measures undermine the safe and inclusive deployment of AI systems. We provide policy recommendations to enhance the multilingual capabilities of AI while mitigating the risks of multilingual jailbreaks. We quantitatively assess the relationship between language resourcedness and model vulnerabilities to multilingual jailbreaks for five frontier large language models across 24 official EU languages. Building on prior research, we propose policy actions that align with the EU legal landscape and institutional framework to address multilingual jailbreaks, while promoting linguistic inclusivity. These include mandatory assessments of multilingual capabilities and vulnerabilities, public opinion research, and state support for multilingual AI development. The measures aim to improve AI safety and functionality through EU policy initiatives, guiding the implementation of the EU AI Act and informing regulatory efforts of the European AI Office.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society",
        "date": "2024-09-06 14:26:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.532993"
    },
    {
        "index": "#151",
        "title": "Decolonising Data Systems: Using Jyutping or Pinyin as tonal representations of Chinese names for data linkage",
        "link": "/arxiv/2409.13706",
        "arxiv_id": "2409.13706",
        "authors": "Joseph Lam, Mario Cortina-Borja, Robert Aldridge, Ruth Blackburn, Katie Harron",
        "summary": "Data linkage is increasingly used in health research and policy making and is relied on for understanding health inequalities. However, linked data is only as useful as the underlying data quality, and differential linkage rates may induce selection bias in the linked data. A mechanism that selectively compromises data quality is name romanisation. Converting text of a different writing system into Latin based writing, or romanisation, has long been the standard process of representing names in character-based writing systems such as Chinese, Vietnamese, and other languages such as Swahili. Unstandardised romanisation of Chinese characters, due in part to problems of preserving the correct name orders the lack of proper phonetic representation of a tonal language, has resulted in poor linkage rates for Chinese immigrants. This opinion piece aims to suggests that the use of standardised romanisation systems for Cantonese (Jyutping) or Mandarin (Pinyin) Chinese, which incorporate tonal information, could improve linkage rates and accuracy for individuals with Chinese names. We used 771 Chinese and English names scraped from openly available sources, and compared the utility of Jyutping, Pinyin and the Hong Kong Government Romanisation system (HKG-romanisation) for representing Chinese names. We demonstrate that both Jyutping and Pinyin result in fewer errors compared with the HKG-romanisation system. We suggest that collecting and preserving people's names in their original writing systems is ethically and socially pertinent. This may inform development of language-specific pre-processing and linkage paradigms that result in more inclusive research data which better represents the targeted populations.",
        "subjects": "Computation and Language",
        "date": "2024-09-06 12:01:01 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.533323"
    },
    {
        "index": "#152",
        "title": "Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble",
        "link": "/arxiv/2409.13705",
        "arxiv_id": "2409.13705",
        "authors": "Olivia Sturman, Aparna Joshi, Bhaktipriya Radharapu, Piyush Kumar, Renee Shelby",
        "summary": "Increasing use of large language models (LLMs) demand performant guardrails to ensure the safety of inputs and outputs of LLMs. When these safeguards are trained on imbalanced data, they can learn the societal biases. We present a light-weight, post-processing method for mitigating counterfactual fairness in closed-source text safety classifiers. Our approach involves building an ensemble that not only outperforms the input classifiers and policy-aligns them, but also acts as a debiasing regularizer. We introduce two threshold-agnostic metrics to assess the counterfactual fairness of a model, and demonstrate how combining these metrics with Fair Data Reweighting (FDW) helps mitigate biases. We create an expanded Open AI dataset, and a new templated LLM-generated dataset based on user-prompts, both of which are counterfactually balanced across identity groups and cover four key areas of safety; we will work towards publicly releasing these datasets. Our results show that our approach improves counterfactual fairness with minimal impact on model performance.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-05 14:35:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.533685"
    },
    {
        "index": "#153",
        "title": "Entity Extraction from High-Level Corruption Schemes via Large Language Models",
        "link": "/arxiv/2409.13704",
        "arxiv_id": "2409.13704",
        "authors": "Panagiotis Koletsis, Panagiotis-Konstantinos Gemos, Christos Chronis, Iraklis Varlamis, Vasilis Efthymiou, Georgios Th. Papadopoulos",
        "summary": "The rise of financial crime that has been observed in recent years has created an increasing concern around the topic and many people, organizations and governments are more and more frequently trying to combat it. Despite the increase of interest in this area, there is a lack of specialized datasets that can be used to train and evaluate works that try to tackle those problems. This article proposes a new micro-benchmark dataset for algorithms and models that identify individuals and organizations, and their multiple writings, in news articles, and presents an approach that assists in its creation. Experimental efforts are also reported, using this dataset, to identify individuals and organizations in financial-crime-related articles using various low-billion parameter Large Language Models (LLMs). For these experiments, standard metrics (Accuracy, Precision, Recall, F1 Score) are reported and various prompt variants comprising the best practices of prompt engineering are tested. In addition, to address the problem of ambiguous entity mentions, a simple, yet effective LLM-based disambiguation method is proposed, ensuring that the evaluation aligns with reality. Finally, the proposed approach is compared against a widely used state-of-the-art open-source baseline, showing the superiority of the proposed method.",
        "subjects": "Computation and Language",
        "date": "2024-09-05 10:27:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.533946"
    },
    {
        "index": "#154",
        "title": "Shaping the Future of Endangered and Low-Resource Languages -- Our Role in the Age of LLMs: A Keynote at ECIR 2024",
        "link": "/arxiv/2409.13702",
        "arxiv_id": "2409.13702",
        "authors": "Josiane Mothe",
        "summary": "Isidore of Seville is credited with the adage that it is language that gives birth to a people, and not the other way around , underlining the profound role played by language in the formation of cultural and social identity. Today, of the more than 7100 languages listed, a significant number are endangered. Since the 1970s, linguists, information seekers and enthusiasts have helped develop digital resources and automatic tools to support a wide range of languages, including endangered ones. The advent of Large Language Model (LLM) technologies holds both promise and peril. They offer unprecedented possibilities for the translation and generation of content and resources, key elements in the preservation and revitalisation of languages. They also present threat of homogenisation, cultural oversimplification and the further marginalisation of already vulnerable languages. The talk this paper is based on has proposed an initiatory journey, exploring the potential paths and partnerships between technology and tradition, with a particular focus on the Occitan language. Occitan is a language from Southern France, parts of Spain and Italy that played a major cultural and economic role, particularly in the Middle Ages. It is now endangered according to UNESCO. The talk critically has examined how human expertise and artificial intelligence can work together to offer hope for preserving the linguistic diversity that forms the foundation of our global and especially our European heritage while addressing some of the ethical and practical challenges that accompany the use of these powerful technologies. This paper is based on the keynote I gave at the 46th European Conference on Information Retrieval (ECIR 2024). As an alternative to reading this paper, a video talk is available online. 1 Date: 26 March 2024.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2024-09-05 06:54:30 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534136"
    },
    {
        "index": "#155",
        "title": "CA-BERT: Leveraging Context Awareness for Enhanced Multi-Turn Chat Interaction",
        "link": "/arxiv/2409.13701",
        "arxiv_id": "2409.13701",
        "authors": "Minghao Liu, Mingxiu Sui, Cangqing Wang, Zhejie Zhou",
        "summary": "Effective communication in automated chat systems hinges on the ability to understand and respond to context. Traditional models often struggle with determining when additional context is necessary for generating appropriate responses. This paper introduces Context-Aware BERT (CA-BERT), a transformer-based model specifically fine-tuned to address this challenge. CA-BERT innovatively applies deep learning techniques to discern context necessity in multi-turn chat interactions, enhancing both the relevance and accuracy of responses. We describe the development of CA-BERT, which adapts the robust architecture of BERT with a novel training regimen focused on a specialized dataset of chat dialogues. The model is evaluated on its ability to classify context necessity, demonstrating superior performance over baseline BERT models in terms of accuracy and efficiency. Furthermore, CA-BERT's implementation showcases significant reductions in training time and resource usage, making it feasible for real-time applications. The results indicate that CA-BERT can effectively enhance the functionality of chatbots by providing a nuanced understanding of context, thereby improving user experience and interaction quality in automated systems. This study not only advances the field of NLP in chat applications but also provides a framework for future research into context-sensitive AI developments.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-05 06:27:59 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534340"
    },
    {
        "index": "#156",
        "title": "Lightweight Transducer Based on Frame-Level Criterion",
        "link": "/arxiv/2409.13698",
        "arxiv_id": "2409.13698",
        "authors": "Genshun Wan, Mengzhi Wang, Tingzhi Mao, Hang Chen, Zhongfu Ye",
        "summary": "The transducer model trained based on sequence-level criterion requires a lot of memory due to the generation of the large probability matrix. We proposed a lightweight transducer model based on frame-level criterion, which uses the results of the CTC forced alignment algorithm to determine the label for each frame. Then the encoder output can be combined with the decoder output at the corresponding time, rather than adding each element output by the encoder to each element output by the decoder as in the transducer. This significantly reduces memory and computation requirements. To address the problem of imbalanced classification caused by excessive blanks in the label, we decouple the blank and non-blank probabilities and truncate the gradient of the blank classifier to the main network. This enables the lightweight transducer achieving similar results to transducer. Additionally, we use richer information to predict the probability of blank, achieving superior results to transducer.",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2024-09-05 02:24:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534550"
    },
    {
        "index": "#157",
        "title": "Prompt Baking",
        "link": "/arxiv/2409.13697",
        "arxiv_id": "2409.13697",
        "authors": "Aman Bhargava, Cameron Witkowski, Alexander Detkov, Matt Thomson",
        "summary": "Two primary ways to change LLM behavior are prompting and weight updates (e.g., fine-tuning). Prompting LLMs is simple and effective, specifying the desired changes explicitly in natural language, whereas weight updates provide more expressive and permanent behavior changes, specified implicitly via training on large datasets. We present a technique for \"baking\" prompts into the weights of an LLM. Prompt Baking converts a prompt $u$ and initial weights $\\theta$ to a new set of weights $\\theta_u$ such that new \"baked\" LLM behaves like the original prompted LLM. Mathematically, we minimize the KL divergence between $P_\\theta(\\cdot | u)$ and $P_{\\theta_u}(\\cdot)$, where $P$ is the LLM's probability distribution over token sequences. Across all our experiments, we find prompts can be readily baked into weight updates. Baking chain-of-thought prompts improves zero-shot performance on GSM8K, ASDiv, MBPP, ARC-Easy, ARC-Challenge, and CommonsenseQA benchmarks. Baking news headlines directly updates an LLM's knowledge. And baking instructions & personas alleviates \"prompt forgetting\" over long sequences. Furthermore, stopping baking early creates \"half-baked\" models, continuously scaling prompt strength. Baked models retain their sensitivity to further prompting and baking, including re-prompting with the baked-in prompt. Surprisingly, the re-prompted models yield further performance gains in instruction following, as well as math reasoning and coding benchmarks. Taking re-prompting and re-baking to the limit yields a form of iterative self-improvement we call Prompt Pursuit, and preliminary results on instruction following exhibit dramatic performance gains. Finally, we discuss implications for AI safety, continuous model updating, enhancing real-time learning capabilities in LLM-based agents, and generating more stable AI personas.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-04 04:13:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534741"
    },
    {
        "index": "#158",
        "title": "You Only Use Reactive Attention Slice For Long Context Retrieval",
        "link": "/arxiv/2409.13695",
        "arxiv_id": "2409.13695",
        "authors": "Yun Joon Soh, Hanxian Huang, Yuandong Tian, Jishen Zhao",
        "summary": "Supporting longer context for Large Language Models (LLM) is a promising direction to advance LLMs. As training a model for a longer context window is computationally expensive, many alternative solutions, such as Retrieval Augmented Generation (RAG), have been used. However, most existing RAG methods adopt embedding-based retrieval that falls short on long contexts. To address such challenges, we propose an attention-based retrieval technique, You Only Use Reactive Attention slice (YOURA). YOURA leverages a novel retrieval heuristic called reaction score to rank the relevance of each sentence in the input context with the query sentence. Intuitively, we measure how the per-token attention score \"reacts\" to the query and greedily retrieves the most reactive sentences. Internally, YOURA generates a token-indexed vector (called reaction vector) for the whole input context. To map each sentence to the token-indexed vector, we propose an Embedding-Agnostic Sentence Yield (EASY), a best-effort token wiggling algorithm. We evaluate our retrieval technique on three open-source pre-trained LLM models across six LongBench QA datasets. Our technique achieves up to 30% vLLM inference throughput improvement for serving long-context queries with a nearly identical quality score to the simple yet effective truncate-middle approach.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-03 15:30:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534931"
    },
    {
        "index": "#159",
        "title": "A Knowledge-Centric Benchmarking Framework and Empirical Study for Retrieval-Augmented Generation",
        "link": "/arxiv/2409.13694",
        "arxiv_id": "2409.13694",
        "authors": "Shuo Yu, Mingyue Cheng, Jiqian Yang, Jie Ouyang",
        "summary": "Retrieval-Augmented Generation (RAG) enhances generative models by integrating retrieval mechanisms, which allow these models to access and utilize external knowledge sources. Despite its advantages, RAG encounters significant challenges, particularly in effectively handling real-world queries and mitigating hallucinations. The KDD Cup 2024 CRAG competition brings these issues to the forefront by incorporating both web pages and a mock API as knowledge sources, adding the complexity of parsing HTML before large language models (LLMs) can process the information. In this paper, we propose a novel RAG benchmark designed to address these challenges. Our work provides a comprehensive set of experimental results, offering valuable insights for the study of RAG. We thoroughly examine the entire RAG process, including knowledge source selection, retrieval, organization, and reasoning. Key findings from our study include the impact of automated knowledge source selection using agents and the influence of noise chunks on RAG reasoning. Additionally, we conduct detailed experiments to analyze the effects of various hyperparameters on RAG performance. To support further research, we have made our results, the associated code, and a parsed version of the CRAG dataset publicly available\\footnote{https://github.com/USTCAGI/RAG-X}, contributing to the advancement of RAG methodologies and establishing a solid foundation for future work in this domain.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-03 03:31:37 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.535201"
    },
    {
        "index": "#160",
        "title": "Archon: An Architecture Search Framework for Inference-Time Techniques",
        "link": "/arxiv/2409.15254",
        "arxiv_id": "2409.15254",
        "authors": "Jon Saad-Falcon, Adrian Gamarra Lafuente, Shlok Natarajan, Nahum Maru, Hristo Todorov, E. Kelly Buchanan, Mayee Chen, Neel Guha, Christopher Ré, Azalia Mirhoseini",
        "summary": "Inference-time techniques are emerging as highly effective tools to increase large language model (LLM) capabilities. However, there is still limited understanding of the best practices for developing systems that combine inference-time techniques with one or more LLMs, with challenges including: (1) effectively allocating inference compute budget, (2) understanding the interactions between different combinations of inference-time techniques and their impact on downstream performance, and 3) efficiently searching over the large space of model choices, inference-time techniques, and their compositions. To address these challenges, we introduce Archon, an automated framework for designing inference-time architectures. Archon defines an extensible design space, encompassing methods such as generation ensembling, multi-sampling, ranking, fusion, critiquing, verification, and unit testing. It then transforms the problem of selecting and combining LLMs and inference-time techniques into a hyperparameter optimization objective. To optimize this objective, we introduce automated Inference-Time Architecture Search (ITAS) algorithms. Given target benchmark(s), an inference compute budget, and available LLMs, ITAS outputs optimized architectures. We evaluate Archon architectures across a wide range of instruction-following and reasoning benchmarks, including MT-Bench, Arena-Hard-Auto, AlpacaEval 2.0, MixEval, MixEval Hard, MATH, and CodeContests. We show that automatically designed inference-time architectures by Archon outperform strong models such as GPT-4o and Claude 3.5 Sonnet on these benchmarks, achieving an average increase of 14.1 and 10.3 percentage points with all-source models and open-source models, respectively. We make our code and datasets available publicly on Github: https://github.com/ScalingIntelligence/Archon.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2024-09-23 17:53:42 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.535476"
    },
    {
        "index": "#161",
        "title": "Efficiently Dispatching Flash Attention For Partially Filled Attention Masks",
        "link": "/arxiv/2409.15097",
        "arxiv_id": "2409.15097",
        "authors": "Agniv Sharma, Jonas Geiping",
        "summary": "Transformers are widely used across various applications, many of which yield sparse or partially filled attention matrices. Examples include attention masks designed to reduce the quadratic complexity of attention, sequence packing techniques, and recent innovations like tree masking for fast validation in MEDUSA. Despite the inherent sparsity in these matrices, the state-of-the-art algorithm Flash Attention still processes them with quadratic complexity as though they were dense. In this paper, we introduce \\textbf{Binary Block Masking}, a highly efficient modification that enhances Flash Attention by making it mask-aware. We further propose two optimizations: one tailored for masks with contiguous non-zero patterns and another for extremely sparse masks. Our experiments on attention masks derived from real-world scenarios demonstrate up to a 9x runtime improvement. The implementation will be publicly released to foster further research and application.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2024-09-23 15:11:07 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.535712"
    },
    {
        "index": "#162",
        "title": "Evaluating the Usability of LLMs in Threat Intelligence Enrichment",
        "link": "/arxiv/2409.15072",
        "arxiv_id": "2409.15072",
        "authors": "Sanchana Srikanth, Mohammad Hasanuzzaman, Farah Tasnur Meem",
        "summary": "Large Language Models (LLMs) have the potential to significantly enhance threat intelligence by automating the collection, preprocessing, and analysis of threat data. However, the usability of these tools is critical to ensure their effective adoption by security professionals. Despite the advanced capabilities of LLMs, concerns about their reliability, accuracy, and potential for generating inaccurate information persist. This study conducts a comprehensive usability evaluation of five LLMs ChatGPT, Gemini, Cohere, Copilot, and Meta AI focusing on their user interface design, error handling, learning curve, performance, and integration with existing tools in threat intelligence enrichment. Utilizing a heuristic walkthrough and a user study methodology, we identify key usability issues and offer actionable recommendations for improvement. Our findings aim to bridge the gap between LLM functionality and user experience, thereby promoting more efficient and accurate threat intelligence practices by ensuring these tools are user-friendly and reliable.",
        "subjects": "Cryptography and Security, Computation and Language, Human-Computer Interaction, Machine Learning",
        "date": "2024-09-23 14:44:56 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.535919"
    },
    {
        "index": "#167",
        "title": "MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification",
        "link": "/arxiv/2409.14703",
        "arxiv_id": "2409.14703",
        "authors": "Siddhant Bikram Shah, Shuvam Shiwakoti, Maheep Chaudhary, Haohan Wang",
        "summary": "The complexity of text-embedded images presents a formidable challenge in machine learning given the need for multimodal understanding of the multiple aspects of expression conveyed in them. While previous research in multimodal analysis has primarily focused on singular aspects such as hate speech and its subclasses, our study expands the focus to encompass multiple aspects of linguistics: hate, target, stance, and humor detection. We introduce a novel dataset PrideMM comprising text-embedded images associated with the LGBTQ+ Pride movement, thereby addressing a serious gap in existing resources. We conduct extensive experimentation on PrideMM by using unimodal and multimodal baseline methods to establish benchmarks for each task. Additionally, we propose a novel framework MemeCLIP for efficient downstream learning while preserving the knowledge of the pre-trained CLIP model. The results of our experiments show that MemeCLIP achieves superior performance compared to previously proposed frameworks on two real-world datasets. We further compare the performance of MemeCLIP and zero-shot GPT-4 on the hate classification task. Finally, we discuss the shortcomings of our model by qualitatively analyzing misclassified samples. Our code and dataset are publicly available at: https://github.com/SiddhantBikram/MemeCLIP.",
        "subjects": "Machine Learning, Computation and Language, Multimedia",
        "date": "2024-09-23 04:49:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.542440"
    },
    {
        "index": "#168",
        "title": "Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling",
        "link": "/arxiv/2409.14683",
        "arxiv_id": "2409.14683",
        "authors": "Benjamin Clavié, Antoine Chaffin, Griffin Adams",
        "summary": "Over the last few years, multi-vector retrieval methods, spearheaded by ColBERT, have become an increasingly popular approach to Neural IR. By storing representations at the token level rather than at the document level, these methods have demonstrated very strong retrieval performance, especially in out-of-domain settings. However, the storage and memory requirements necessary to store the large number of associated vectors remain an important drawback, hindering practical adoption. In this paper, we introduce a simple clustering-based token pooling approach to aggressively reduce the number of vectors that need to be stored. This method can reduce the space & memory footprint of ColBERT indexes by 50% with virtually no retrieval performance degradation. This method also allows for further reductions, reducing the vector count by 66%-to-75% , with degradation remaining below 5% on a vast majority of datasets. Importantly, this approach requires no architectural change nor query-time processing, and can be used as a simple drop-in during indexation with any ColBERT-like model.",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language",
        "date": "2024-09-23 03:12:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.542823"
    },
    {
        "index": "#170",
        "title": "Backtracking Improves Generation Safety",
        "link": "/arxiv/2409.14586",
        "arxiv_id": "2409.14586",
        "authors": "Yiming Zhang, Jianfeng Chi, Hailey Nguyen, Kartikeya Upasani, Daniel M. Bikel, Jason Weston, Eric Michael Smith",
        "summary": "Text generation has a fundamental limitation almost by definition: there is no taking back tokens that have been generated, even when they are clearly problematic. In the context of language model safety, when a partial unsafe generation is produced, language models by their nature tend to happily keep on generating similarly unsafe additional text. This is in fact how safety alignment of frontier models gets circumvented in the wild, despite great efforts in improving their safety. Deviating from the paradigm of approaching safety alignment as prevention (decreasing the probability of harmful responses), we propose backtracking, a technique that allows language models to \"undo\" and recover from their own unsafe generation through the introduction of a special [RESET] token. Our method can be incorporated into either SFT or DPO training to optimize helpfulness and harmlessness. We show that models trained to backtrack are consistently safer than baseline models: backtracking Llama-3-8B is four times more safe than the baseline model (6.1\\% $\\to$ 1.5\\%) in our evaluations without regression in helpfulness. Our method additionally provides protection against four adversarial attacks including an adaptive attack, despite not being trained to do so.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2024-09-22 20:28:40 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.543362"
    },
    {
        "index": "#171",
        "title": "What Are They Doing? Joint Audio-Speech Co-Reasoning",
        "link": "/arxiv/2409.14526",
        "arxiv_id": "2409.14526",
        "authors": "Yingzhi Wang, Pooneh Mousavi, Artem Ploujnikov, Mirco Ravanelli",
        "summary": "In audio and speech processing, tasks usually focus on either the audio or speech modality, even when both sounds and human speech are present in the same audio clip. Recent Auditory Large Language Models (ALLMs) have made it possible to process audio and speech simultaneously within a single model, leading to further considerations of joint audio-speech tasks. In this paper, we investigate how well ALLMs can perform joint audio-speech processing. Specifically, we introduce Joint Audio-Speech Co-Reasoning (JASCO), a novel task that unifies audio and speech processing, strictly requiring co-reasoning across both modalities. We release a scene-reasoning dataset called \"What Are They Doing\" and establish a joint audio-speech benchmark to evaluate the joint reasoning capability of popular ALLMs. Additionally, we provide deeper insights into the models' behaviors by analyzing their dependence on each modality.",
        "subjects": "Sound, Computation and Language, Audio and Speech Processing",
        "date": "2024-09-22 16:45:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.543561"
    },
    {
        "index": "#172",
        "title": "Beyond Words: Evaluating Large Language Models in Transportation Planning",
        "link": "/arxiv/2409.14516",
        "arxiv_id": "2409.14516",
        "authors": "Shaowei Ying, Zhenlong Li, Manzhu Yu",
        "summary": "The resurgence and rapid advancement of Generative Artificial Intelligence (GenAI) in 2023 has catalyzed transformative shifts across numerous industry sectors, including urban transportation and logistics. This study investigates the evaluation of Large Language Models (LLMs), specifically GPT-4 and Phi-3-mini, to enhance transportation planning. The study assesses the performance and spatial comprehension of these models through a transportation-informed evaluation framework that includes general geospatial skills, general transportation domain skills, and real-world transportation problem-solving. Utilizing a mixed-methods approach, the research encompasses an evaluation of the LLMs' general Geographic Information System (GIS) skills, general transportation domain knowledge as well as abilities to support human decision-making in the real-world transportation planning scenarios of congestion pricing. Results indicate that GPT-4 demonstrates superior accuracy and reliability across various GIS and transportation-specific tasks compared to Phi-3-mini, highlighting its potential as a robust tool for transportation planners. Nonetheless, Phi-3-mini exhibits competence in specific analytical scenarios, suggesting its utility in resource-constrained environments. The findings underscore the transformative potential of GenAI technologies in urban transportation planning. Future work could explore the application of newer LLMs and the impact of Retrieval-Augmented Generation (RAG) techniques, on a broader set of real-world transportation planning and operations challenges, to deepen the integration of advanced AI models in transportation management practices.",
        "subjects": "Artificial Intelligence, Computation and Language, Information Retrieval",
        "date": "2024-09-22 16:20:00 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.543828"
    },
    {
        "index": "#173",
        "title": "A Large Language Model and Denoising Diffusion Framework for Targeted Design of Microstructures with Commands in Natural Language",
        "link": "/arxiv/2409.14473",
        "arxiv_id": "2409.14473",
        "authors": "Nikita Kartashov, Nikolaos N. Vlassis",
        "summary": "Microstructure plays a critical role in determining the macroscopic properties of materials, with applications spanning alloy design, MEMS devices, and tissue engineering, among many others. Computational frameworks have been developed to capture the complex relationship between microstructure and material behavior. However, despite these advancements, the steep learning curve associated with domain-specific knowledge and complex algorithms restricts the broader application of these tools. To lower this barrier, we propose a framework that integrates Natural Language Processing (NLP), Large Language Models (LLMs), and Denoising Diffusion Probabilistic Models (DDPMs) to enable microstructure design using intuitive natural language commands. Our framework employs contextual data augmentation, driven by a pretrained LLM, to generate and expand a diverse dataset of microstructure descriptors. A retrained NER model extracts relevant microstructure descriptors from user-provided natural language inputs, which are then used by the DDPM to generate microstructures with targeted mechanical properties and topological features. The NLP and DDPM components of the framework are modular, allowing for separate training and validation, which ensures flexibility in adapting the framework to different datasets and use cases. A surrogate model system is employed to rank and filter generated samples based on their alignment with target properties. Demonstrated on a database of nonlinear hyperelastic microstructures, this framework serves as a prototype for accessible inverse design of microstructures, starting from intuitive natural language commands.",
        "subjects": "Computational Engineering, Finance, and Science, Computation and Language",
        "date": "2024-09-22 14:45:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.544055"
    },
    {
        "index": "#174",
        "title": "Opinion Mining on Offshore Wind Energy for Environmental Engineering",
        "link": "/arxiv/2409.14292",
        "arxiv_id": "2409.14292",
        "authors": "Isabele Bittencourt, Aparna S. Varde, Pankaj Lal",
        "summary": "In this paper, we conduct sentiment analysis on social media data to study mass opinion about offshore wind energy. We adapt three machine learning models, namely, TextBlob, VADER, and SentiWordNet because different functions are provided by each model. TextBlob provides subjectivity analysis as well as polarity classification. VADER offers cumulative sentiment scores. SentiWordNet considers sentiments with reference to context and performs classification accordingly. Techniques in NLP are harnessed to gather meaning from the textual data in social media. Data visualization tools are suitably deployed to display the overall results. This work is much in line with citizen science and smart governance via involvement of mass opinion to guide decision support. It exemplifies the role of Machine Learning and NLP here.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2024-09-22 01:51:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.544259"
    },
    {
        "index": "#176",
        "title": "On Lexical Invariance on Multisets and Graphs",
        "link": "/arxiv/2409.14179",
        "arxiv_id": "2409.14179",
        "authors": "Muhan Zhang",
        "summary": "In this draft, we study a novel problem, called lexical invariance, using the medium of multisets and graphs. Traditionally in the NLP domain, lexical invariance indicates that the semantic meaning of a sentence should remain unchanged regardless of the specific lexical or word-based representation of the input. For example, ``The movie was extremely entertaining'' would have the same meaning as ``The film was very enjoyable''. In this paper, we study a more challenging setting, where the output of a function is invariant to any injective transformation applied to the input lexical space. For example, multiset {1,2,3,2} is equivalent to multiset {a,b,c,b} if we specify an injective transformation that maps 1 to a, 2 to b and 3 to c. We study the sufficient and necessary conditions for a most expressive lexical invariant (and permutation invariant) function on multisets and graphs, and proves that for multisets, the function must have a form that only takes the multiset of counts of the unique elements in the original multiset as input. For example, a most expressive lexical invariant function on {a,b,c,b} must have a form that only operates on {1,1,2} (meaning that there are 1, 1, 2 unique elements corresponding to a,c,b). For graphs, we prove that a most expressive lexical invariant and permutation invariant function must have a form that only takes the adjacency matrix and a difference matrix as input, where the (i,j)th element of the difference matrix is 1 if node i and node j have the same feature and 0 otherwise. We perform synthetic experiments on TU datasets to verify our theorems.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2024-09-21 15:52:01 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.544634"
    },
    {
        "index": "#177",
        "title": "Will Large Language Models be a Panacea to Autonomous Driving?",
        "link": "/arxiv/2409.14165",
        "arxiv_id": "2409.14165",
        "authors": "Yuxuan Zhua, Shiyi Wang, Wenqing Zhong, Nianchen Shen, Yunqi Li, Siqi Wang, Zhiheng Li, Cathy Wu, Zhengbing He, Li Li",
        "summary": "Artificial intelligence (AI) plays a crucial role in autonomous driving (AD) research, propelling its development towards intelligence and efficiency. Currently, the development of AD technology follows two main technical paths: modularization and end-to-end. Modularization decompose the driving task into modules such as perception, prediction, planning, and control, and train them separately. Due to the inconsistency of training objectives between modules, the integrated effect suffers from bias. End-to-end attempts to address this issue by utilizing a single model that directly maps from sensor data to control signals. This path has limited learning capabilities in a comprehensive set of features and struggles to handle unpredictable long-tail events and complex urban traffic scenarios. In the face of challenges encountered in both paths, many researchers believe that large language models (LLMs) with powerful reasoning capabilities and extensive knowledge understanding may be the solution, expecting LLMs to provide AD systems with deeper levels of understanding and decision-making capabilities. In light of the challenges faced by both paths, many researchers believe that LLMs, with their powerful reasoning abilities and extensive knowledge, could offer a solution. To understand if LLMs could enhance AD, this paper conducts a thorough analysis of the potential applications of LLMs in AD systems, including exploring their optimization strategies in both modular and end-to-end approaches, with a particular focus on how LLMs can tackle the problems and challenges present in current solutions. Furthermore, we discuss an important question: Can LLM-based artificial general intelligence (AGI) be a key to achieve high-level AD? We further analyze the potential limitations and challenges that LLMs may encounter in promoting the development of AD technology.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning, Robotics, Systems and Control",
        "date": "2024-09-21 15:07:37 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.544891"
    },
    {
        "index": "#179",
        "title": "OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching",
        "link": "/arxiv/2409.14038",
        "arxiv_id": "2409.14038",
        "authors": "Zhangcheng Qiang, Kerry Taylor, Weiqing Wang, Jing Jiang",
        "summary": "Hallucinations of large language models (LLMs) commonly occur in domain-specific downstream tasks, with no exception in ontology matching (OM). The prevalence of using LLMs for OM raises the need for benchmarks to better understand LLM hallucinations. The OAEI-LLM dataset is an extended version of the Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate LLM-specific hallucinations in OM tasks. We outline the methodology used in dataset construction and schema extension, and provide examples of potential use cases.",
        "subjects": "Artificial Intelligence, Computation and Language, Information Retrieval",
        "date": "2024-09-21 06:49:34 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.545324"
    },
    {
        "index": "#180",
        "title": "On-device Collaborative Language Modeling via a Mixture of Generalists and Specialists",
        "link": "/arxiv/2409.13931",
        "arxiv_id": "2409.13931",
        "authors": "Dongyang Fan, Bettina Messmer, Martin Jaggi",
        "summary": "We target on-device collaborative fine-tuning of Large Language Models (LLMs) by adapting a Mixture of Experts (MoE) architecture, where experts are Low-Rank Adaptation (LoRA) modules. In conventional MoE approaches, experts develop into specialists throughout training. In contrast, we propose a novel $\\textbf{Co}$llaborative learning approach via a $\\textbf{Mi}$xture of $\\textbf{G}$eneralists and $\\textbf{S}$pecialists (CoMiGS). Diversifying into the two roles is achieved by aggregating certain experts globally while keeping others localized to specialize in user-specific datasets. Central to our work is a learnable routing network that routes at a token level, balancing collaboration and personalization at the finest granularity. Our method consistently demonstrates superior performance in scenarios with high data heterogeneity across various datasets. By design, our approach accommodates varying computational resource constraints among users as shown in different numbers of LoRA experts. We further showcase that low-resourced users can benefit from high-resourced users with high data quantity.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2024-09-20 22:34:37 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.545516"
    },
    {
        "index": "#181",
        "title": "Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation",
        "link": "/arxiv/2409.13928",
        "arxiv_id": "2409.13928",
        "authors": "Seonghyeon Lee, Suyeon Kim, Joonwon Jang, Heejae Chon, Dongha Lee, Hwanjo Yu",
        "summary": "We study the code generation behavior of instruction-tuned models built on top of code pre-trained language models when they could access an auxiliary function to implement a function. We design several ways to provide auxiliary functions to the models by adding them to the query or providing a response prefix to incorporate the ability to utilize auxiliary functions with the instruction-following capability. Our experimental results show the effectiveness of combining the base models' auxiliary function utilization ability with the instruction following ability. In particular, the performance of adopting our approaches with the open-sourced language models surpasses that of the recent powerful proprietary language models, i.e., gpt-4o.",
        "subjects": "Software Engineering, Artificial Intelligence, Computation and Language",
        "date": "2024-09-20 22:28:20 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.545731"
    },
    {
        "index": "#182",
        "title": "Generative AI Carries Non-Democratic Biases and Stereotypes: Representation of Women, Black Individuals, Age Groups, and People with Disability in AI-Generated Images across Occupations",
        "link": "/arxiv/2409.13869",
        "arxiv_id": "2409.13869",
        "authors": "Ayoob Sadeghiani",
        "summary": "AI governance and ethics in AI development have become critical concerns, prompting active discussions among tech companies, governments, and researchers about the potential risks AI poses to our democracies. This short essay aims to highlight one such risk: how generative AI includes or excludes equity-deserving groups in its outputs. The findings reveal that generative AI is not equitably inclusive regarding gender, race, age, and visible disability.",
        "subjects": "Artificial Intelligence, Computation and Language, Computers and Society",
        "date": "2024-09-20 19:47:31 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.545905"
    },
    {
        "index": "#183",
        "title": "GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks",
        "link": "/arxiv/2409.13832",
        "arxiv_id": "2409.13832",
        "authors": "Yu Zhang, Changhao Pan, Wenxiang Guo, Ruiqi Li, Zhiyuan Zhu, Jialei Wang, Wenhao Xu, Jingyu Lu, Zhiqing Hong, Chuxin Wang, LiChao Zhang, Jinzheng He, Ziyue Jiang, Yuxin Chen, Chen Yang, Jiecheng Zhou, Xinyu Cheng, Zhou Zhao",
        "summary": "The scarcity of high-quality and multi-task singing datasets significantly hinders the development of diverse controllable and personalized singing tasks, as existing singing datasets suffer from low quality, limited diversity of languages and singers, absence of multi-technique information and realistic music scores, and poor task suitability. To tackle these problems, we present \\textbf{GTSinger}, a large \\textbf{G}lobal, multi-\\textbf{T}echnique, free-to-use, high-quality singing corpus with realistic music scores, designed for all singing tasks, along with its benchmarks. Particularly, (1) we collect 80.59 hours of high-quality singing voices, forming the largest recorded singing dataset; (2) 20 professional singers across nine widely spoken languages offer diverse timbres and styles; (3) we provide controlled comparison and phoneme-level annotations of six commonly used singing techniques, helping technique modeling and control; (4) GTSinger offers realistic music scores, assisting real-world musical composition; (5) singing voices are accompanied by manual phoneme-to-audio alignments, global style labels, and 16.16 hours of paired speech for various singing tasks. Moreover, to facilitate the use of GTSinger, we conduct four benchmark experiments: technique-controllable singing voice synthesis, technique recognition, style transfer, and speech-to-singing conversion. The corpus and demos can be found at http://gtsinger.github.io. We provide the dataset and the code for processing data and conducting benchmarks at https://huggingface.co/datasets/GTSinger/GTSinger and https://github.com/GTSinger/GTSinger.",
        "subjects": "Audio and Speech Processing, Computation and Language, Sound",
        "date": "2024-09-20 18:18:14 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.546232"
    },
    {
        "index": "#184",
        "title": "Synergistic Simulations: Multi-Agent Problem Solving with Large Language Models",
        "link": "/arxiv/2409.13753",
        "arxiv_id": "2409.13753",
        "authors": "Asher Sprigler, Alexander Drobek, Keagan Weinstock, Wendpanga Tapsoba, Gavin Childress, Andy Dao, Lucas Gral",
        "summary": "Large Language Models (LLMs) have increasingly demonstrated the ability to facilitate the development of multi-agent systems that allow the interpretation of thoughts and actions generated by each individual. Promising advancements have also been made in LLM-based interaction with existing worlds, particularly in interacting with simulated environments. This paper aims to integrate both aforementioned topics (agents & world interaction) into a single simulation where multiple agents can work together to solve a problem, modeling how groups of humans can often solve problems better than individuals. By showing whether LLMs demonstrate the synergy of human collaboration, it could lead to advancements in the applications of LLMs. We implemented two simulations: a physical studio apartment with two roommates, and another where agents collaborate to complete a programming task. We provide a multi-agent framework, discuss the performance of the agents in each simulation, and discuss potential future additions.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computation and Language, Emerging Technologies",
        "date": "2024-09-14 21:53:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.546464"
    },
    {
        "index": "#185",
        "title": "VisScience: An Extensive Benchmark for Evaluating K12 Educational Multi-modal Scientific Reasoning",
        "link": "/arxiv/2409.13730",
        "arxiv_id": "2409.13730",
        "authors": "Zhihuan Jiang, Zhen Yang, Jinhao Chen, Zhengxiao Du, Weihan Wang, Bin Xu, Yuxiao Dong, Jie Tang",
        "summary": "Multi-modal large language models (MLLMs) have demonstrated promising capabilities across various tasks by integrating textual and visual information to achieve visual understanding in complex scenarios. Despite the availability of several benchmarks aims to evaluating MLLMs in tasks from visual question answering to complex problem-solving, most focus predominantly on mathematics or general visual understanding tasks. This reveals a critical gap in current benchmarks, which often overlook the inclusion of other key scientific disciplines such as physics and chemistry. To address this gap, we meticulously construct a comprehensive benchmark, named VisScience, which is utilized to assess the multi-modal scientific reasoning across the three disciplines of mathematics, physics, and chemistry. This benchmark comprises 3,000 questions drawn from K12 education - spanning elementary school through high school - equally distributed across three disciplines, with 1,000 questions per discipline. The questions within VisScience span 21 distinct subjects and are categorized into five difficulty levels, offering a broad spectrum of topics within each discipline. With VisScience, we present a detailed evaluation of the performance of 25 representative MLLMs in scientific reasoning. Experimental results demonstrate that closed-source MLLMs generally outperform open-source models. The best performance observed include a 53.4\\% accuracy in mathematics by Claude3.5-Sonnet, 38.2\\% in physics by GPT-4o, and 47.0\\% in chemistry by Gemini-1.5-Pro. These results underscore the strengths and limitations of MLLMs, suggesting areas for future improvement and highlighting the importance of developing models that can effectively handle the diverse demands of multi-modal scientific reasoning.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2024-09-10 01:20:26 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.546721"
    },
    {
        "index": "#186",
        "title": "Retrieval Augmented Generation-Based Incident Resolution Recommendation System for IT Support",
        "link": "/arxiv/2409.13707",
        "arxiv_id": "2409.13707",
        "authors": "Paulina Toro Isaza, Michael Nidd, Noah Zheutlin, Jae-wook Ahn, Chidansh Amitkumar Bhatt, Yu Deng, Ruchi Mahindru, Martin Franz, Hans Florian, Salim Roukos",
        "summary": "Clients wishing to implement generative AI in the domain of IT Support and AIOps face two critical issues: domain coverage and model size constraints due to model choice limitations. Clients might choose to not use larger proprietary models such as GPT-4 due to cost and privacy concerns and so are limited to smaller models with potentially less domain coverage that do not generalize to the client's domain. Retrieval augmented generation is a common solution that addresses both of these issues: a retrieval system first retrieves the necessary domain knowledge which a smaller generative model leverages as context for generation. We present a system developed for a client in the IT Support domain for support case solution recommendation that combines retrieval augmented generation (RAG) for answer generation with an encoder-only model for classification and a generative large language model for query generation. We cover architecture details, data collection and annotation, development journey and preliminary validations, expected final deployment process and evaluation plans, and finally lessons learned.",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language",
        "date": "2024-09-06 13:06:29 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.546973"
    },
    {
        "index": "#187",
        "title": "Declarative Integration and Management of Large Language Models through Finite Automata: Application to Automation, Communication, and Ethics",
        "link": "/arxiv/2409.13693",
        "arxiv_id": "2409.13693",
        "authors": "Thierry Petit, Arnault Pachot, Claire Conan-Vrinat, Alexandre Dubarry",
        "summary": "This article introduces an innovative architecture designed to declaratively combine Large Language Models (LLMs) with shared histories, and triggers to identify the most appropriate LLM for a given task. Our approach is general and declarative, relying on the construction of finite automata coupled with an event management system. The developed tool is crafted to facilitate the efficient and complex integration of LLMs with minimal programming effort, especially, but not only, for integrating methods of positive psychology to AI. The flexibility of our technique is demonstrated through applied examples in automation, communication, and ethics.",
        "subjects": "Formal Languages and Automata Theory, Artificial Intelligence, Computation and Language, Emerging Technologies, Human-Computer Interaction",
        "date": "2024-09-02 11:50:52 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.547236"
    }
]