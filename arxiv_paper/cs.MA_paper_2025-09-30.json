[
    {
        "index": "#1",
        "title": "MARLIN: Multi-Agent Reinforcement Learning with Murmuration Intelligence and LLM Guidance for Reservoir Management",
        "link": "/arxiv/2509.25034",
        "arxiv_id": "2509.25034",
        "authors": "Heming Fu, Guojun Xiong, Jian Li, Shan Lin",
        "summary": "As climate change intensifies extreme weather events, water disasters pose growing threats to global communities, making adaptive reservoir management critical for protecting vulnerable populations and ensuring water security. Modern water resource management faces unprecedented challenges from cascading uncertainties propagating through interconnected reservoir networks. These uncertainties, rooted in physical water transfer losses and environmental variability, make precise control difficult. For example, sending 10 tons downstream may yield only 8-12 tons due to evaporation and seepage. Traditional centralized optimization approaches suffer from exponential computational complexity and cannot effectively handle such real-world uncertainties, while existing multi-agent reinforcement learning (MARL) methods fail to achieve effective coordination under uncertainty. To address these challenges, we present MARLIN, a decentralized reservoir management framework inspired by starling murmurations intelligence. Integrating bio-inspired alignment, separation, and cohesion rules with MARL, MARLIN enables individual reservoirs to make local decisions while achieving emergent global coordination. In addition, a LLM provides real-time reward shaping signals, guiding agents to adapt to environmental changes and human-defined preferences. Experiments on real-world USGS data show that MARLIN improves uncertainty handling by 23\\%, cuts computation by 35\\%, and accelerates flood response by 68\\%, exhibiting super-linear coordination, with complexity scaling 5.4x from 400 to 10,000 nodes. These results demonstrate MARLIN's potential for disaster prevention and protecting communities through intelligent, scalable water resource management.",
        "subjects": "Multiagent Systems, Systems and Control",
        "date": "2025-09-29",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.453982"
    },
    {
        "index": "#2",
        "title": "MAS$^2$: Self-Generative, Self-Configuring, Self-Rectifying Multi-Agent Systems",
        "link": "/arxiv/2509.24323",
        "arxiv_id": "2509.24323",
        "authors": "Kun Wang, Guibin Zhang, ManKit Ye, Xinyu Deng, Dongxia Wang, Xiaobin Hu, Jinyang Guo, Yang Liu, Yufei Guo",
        "summary": "The past two years have witnessed the meteoric rise of Large Language Model (LLM)-powered multi-agent systems (MAS), which harness collective intelligence and exhibit a remarkable trajectory toward self-evolution. This paradigm has rapidly progressed from manually engineered systems that require bespoke configuration of prompts, tools, roles, and communication protocols toward frameworks capable of automated orchestration. Yet, dominant automatic multi-agent systems, whether generated by external modules or a single LLM agent, largely adhere to a rigid ``\\textit{generate-once-and-deploy}'' paradigm, rendering the resulting systems brittle and ill-prepared for the dynamism and uncertainty of real-world environments. To transcend this limitation, we introduce MAS$^2$, a paradigm predicated on the principle of recursive self-generation: a multi-agent system that autonomously architects bespoke multi-agent systems for diverse problems. Technically, we devise a ``\\textit{generator-implementer-rectifier}'' tri-agent team capable of dynamically composing and adaptively rectifying a target agent system in response to real-time task demands. Collaborative Tree Optimization is proposed to train and specialize these meta-agents. Extensive evaluation across seven benchmarks reveals that MAS$^2$ achieves performance gains of up to $19.6\\%$ over state-of-the-art MAS in complex scenarios such as deep research and code generation. Moreover, MAS$^2$ exhibits superior cross-backbone generalization, effectively leveraging previously unseen LLMs to yield improvements of up to $15.1\\%$. Crucially, these gains are attained without incurring excessive token costs, as MAS$^2$ consistently resides on the Pareto frontier of cost-performance trade-offs. The source codes are available at https://github.com/yeyeyeah2/MAS2.",
        "subjects": "Multiagent Systems, Computation and Language",
        "date": "2025-09-29",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.454319"
    },
    {
        "index": "#3",
        "title": "CORRECT: COndensed eRror RECognition via knowledge Transfer in multi-agent systems",
        "link": "/arxiv/2509.24088",
        "arxiv_id": "2509.24088",
        "authors": "Yifan Yu, Moyan Li, Shaoyuan Xu, Jinmiao Fu, Xinhai Hou, Fan Lai, Bryan Wang",
        "summary": "Multi-agent systems (MAS) are increasingly capable of tackling complex real-world tasks, yet their reliance on inter-agent coordination, tool use, and long-horizon reasoning makes error recognition particularly challenging. Minor errors can propagate across agents, escalating into task failures while producing long, intertwined execution trajectories that impose significant costs for both human developers and automated systems to debug and analyze. Our key insight is that, despite surface differences in failure trajectories (e.g., logs), MAS errors often recur with similar structural patterns. This paper presents CORRECT, the first lightweight, training-free framework that leverages an online cache of distilled error schemata to recognize and transfer knowledge of failure structures across new requests. This cache-based reuse allows LLMs to perform targeted error localization at inference time, avoiding the need for expensive retraining while adapting to dynamic MAS deployments in subseconds. To support rigorous study in this domain, we also introduce CORRECT-Error, a large-scale dataset of over 2,000 annotated trajectories collected through a novel error-injection pipeline guided by real-world distributions, and further validated through human evaluation to ensure alignment with natural failure patterns. Experiments across seven diverse MAS applications show that CORRECT improves step-level error localization up to 19.8% over existing advances while at near-zero overhead, substantially narrowing the gap between automated and human-level error recognition.",
        "subjects": "Multiagent Systems",
        "date": "2025-09-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.454609"
    },
    {
        "index": "#4",
        "title": "PartnerMAS: An LLM Hierarchical Multi-Agent Framework for Business Partner Selection on High-Dimensional Features",
        "link": "/arxiv/2509.24046",
        "arxiv_id": "2509.24046",
        "authors": "Lingyao Li, Haolun Wu, Zhenkun Li, Jiabei Hu, Yu Wang, Xiaoshan Huang, Wenyue Hua, Wenqian Wang",
        "summary": "High-dimensional decision-making tasks, such as business partner selection, involve evaluating large candidate pools with heterogeneous numerical, categorical, and textual features. While large language models (LLMs) offer strong in-context reasoning capabilities, single-agent or debate-style systems often struggle with scalability and consistency in such settings. We propose PartnerMAS, a hierarchical multi-agent framework that decomposes evaluation into three layers: a Planner Agent that designs strategies, Specialized Agents that perform role-specific assessments, and a Supervisor Agent that integrates their outputs. To support systematic evaluation, we also introduce a curated benchmark dataset of venture capital co-investments, featuring diverse firm attributes and ground-truth syndicates. Across 140 cases, PartnerMAS consistently outperforms single-agent and debate-based multi-agent baselines, achieving up to 10--15\\% higher match rates. Analysis of agent reasoning shows that planners are most responsive to domain-informed prompts, specialists produce complementary feature coverage, and supervisors play an important role in aggregation. Our findings demonstrate that structured collaboration among LLM agents can generate more robust outcomes than scaling individual models, highlighting PartnerMAS as a promising framework for high-dimensional decision-making in data-rich domains.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-09-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.454903"
    },
    {
        "index": "#5",
        "title": "Situational Awareness for Safe and Robust Multi-Agent Interactions Under Uncertainty",
        "link": "/arxiv/2509.23425",
        "arxiv_id": "2509.23425",
        "authors": "Benjamin Alcorn, Eman Hammad",
        "summary": "Multi-agent systems are prevalent in a wide range of domains including power systems, vehicular networks, and robotics. Two important problems to solve in these types of systems are how the intentions of non-coordinating agents can be determined to predict future behavior and how the agents can achieve their objectives under resource constraints without significantly sacrificing performance. To study this, we develop a model where an autonomous agent observes the environment within a safety radius of observation, determines the state of a surrounding agent of interest (within the observation radius), estimates future actions to be taken, and acts in an optimal way. In the absence of observations, agents are able to utilize an estimation algorithm to predict the future actions of other agents based on historical trajectory. The use of the proposed estimation algorithm introduces uncertainty, which is managed via risk analysis. The proposed approach in this study is validated using two different learning-based decision making frameworks: reinforcement learning and game theoretic algorithms.",
        "subjects": "Multiagent Systems",
        "date": "2025-09-27",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.455140"
    },
    {
        "index": "#6",
        "title": "Game-Theoretic Understandings of Multi-Agent Systems with Multiple Objectives",
        "link": "/arxiv/2509.23026",
        "arxiv_id": "2509.23026",
        "authors": "Yue Wang",
        "summary": "In practical multi-agent systems, agents often have diverse objectives, which makes the system more complex, as each agent's performance across multiple criteria depends on the joint actions of all agents, creating intricate strategic trade-offs. To address this, we introduce the Multi-Objective Markov Game (MOMG), a framework for multi-agent reinforcement learning with multiple objectives. We propose the Pareto-Nash Equilibrium (PNE) as the primary solution concept, where no agent can unilaterally improve one objective without sacrificing performance on another. We prove existence of PNE, and establish an equivalence between the PNE and the set of Nash Equilibria of MOMG's corresponding linearly scalarized games, enabling solutions of MOMG by transferring to a standard single-objective Markov game. However, we note that computing a PNE is theoretically and computationally challenging, thus we propose and study weaker but more tractable solution concepts. Building on these foundations, we develop online learning algorithm that identify a single solution to MOMGs. Furthermore, we propose a two-phase, preference-free algorithm that decouples exploration from planning. Our algorithm enables computation of a PNE for any given preference profile without collecting new samples, providing an efficient methodological characterization of the entire Pareto-Nash front.",
        "subjects": "Multiagent Systems, Computer Science and Game Theory",
        "date": "2025-09-27",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.455393"
    },
    {
        "index": "#7",
        "title": "HeDA: An Intelligent Agent System for Heatwave Risk Discovery through Automated Knowledge Graph Construction and Multi-layer Risk Propagation Analysis",
        "link": "/arxiv/2509.25112",
        "arxiv_id": "2509.25112",
        "authors": "Yiquan Wang, Tin-Yeh Huang, Qingyun Gao, Jialin Zhang",
        "summary": "Heatwaves pose complex cascading risks across interconnected climate, social, and economic systems, but knowledge fragmentation in scientific literature hinders comprehensive understanding of these risk pathways. We introduce HeDA (Heatwave Discovery Agent), an intelligent multi-agent system designed for automated scientific discovery through knowledge graph construction and multi-layer risk propagation analysis. HeDA processes over 10,247 academic papers to construct a comprehensive knowledge graph with 23,156 nodes and 89,472 relationships, employing novel multi-layer risk propagation analysis to systematically identify overlooked risk transmission pathways. Our system achieves 78.9% accuracy on complex question-answering tasks, outperforming state-of-the-art baselines including GPT-4 by 13.7%. Critically, HeDA successfully discovered five previously unidentified high-impact risk chains, such as the pathway where a heatwave leads to a water demand surge, resulting in industrial water restrictions and ultimately causing small business disruption, which were validated through historical case studies and domain expert review. This work presents a new paradigm for AI-driven scientific discovery, providing actionable insights for developing more resilient climate adaptation strategies.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-09-29",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.455657"
    },
    {
        "index": "#8",
        "title": "Curriculum Imitation Learning of Distributed Multi-Robot Policies",
        "link": "/arxiv/2509.25097",
        "arxiv_id": "2509.25097",
        "authors": "Jesús Roche, Eduardo Sebastián, Eduardo Montijano",
        "summary": "Learning control policies for multi-robot systems (MRS) remains a major challenge due to long-term coordination and the difficulty of obtaining realistic training data. In this work, we address both limitations within an imitation learning framework. First, we shift the typical role of Curriculum Learning in MRS, from scalability with the number of robots, to focus on improving long-term coordination. We propose a curriculum strategy that gradually increases the length of expert trajectories during training, stabilizing learning and enhancing the accuracy of long-term behaviors. Second, we introduce a method to approximate the egocentric perception of each robot using only third-person global state demonstrations. Our approach transforms idealized trajectories into locally available observations by filtering neighbors, converting reference frames, and simulating onboard sensor variability. Both contributions are integrated into a physics-informed technique to produce scalable, distributed policies from observations. We conduct experiments across two tasks with varying team sizes and noise levels. Results show that our curriculum improves long-term accuracy, while our perceptual estimation method yields policies that are robust to realistic uncertainty. Together, these strategies enable the learning of robust, distributed controllers from global demonstrations, even in the absence of expert actions or onboard measurements.",
        "subjects": "Robotics, Machine Learning, Multiagent Systems",
        "date": "2025-09-29",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.455933"
    },
    {
        "index": "#9",
        "title": "Safety-Critical Input-Constrained Nonlinear Intercept Guidance in Multiple Engagement Zones",
        "link": "/arxiv/2509.25053",
        "arxiv_id": "2509.25053",
        "authors": "Praveen Kumar Ranjan, Abhinav Sinha, Yongcan Cao",
        "summary": "This paper presents an input-constrained nonlinear guidance law to address the problem of intercepting a stationary target in contested environments with multiple defending agents. Contrary to prior approaches that rely on explicit knowledge of defender strategies or utilize conservative safety conditions based on a defender's range, our work characterizes defender threats geometrically through engagement zones that delineate inevitable interception regions. Outside these engagement zones, the interceptor remains invulnerable. The proposed guidance law switches between a repulsive safety maneuver near these zones and a pursuit maneuver outside their influence. To deal with multiple engagement zones, we employ a smooth minimum function (log-sum-exponent approximation) that aggregates threats from all the zones while prioritizing the most critical threats. Input saturation is modeled and embedded in the non-holonomic vehicle dynamics so the controller respects actuator limits while maintaining stability. Numerical simulations with several defenders demonstrate the proposed method's ability to avoid engagement zones and achieve interception across diverse initial conditions.",
        "subjects": "Systems and Control, Multiagent Systems, Robotics, Dynamical Systems",
        "date": "2025-09-29",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.456203"
    },
    {
        "index": "#10",
        "title": "AIPOM: Agent-aware Interactive Planning for Multi-Agent Systems",
        "link": "/arxiv/2509.24826",
        "arxiv_id": "2509.24826",
        "authors": "Hannah Kim, Kushan Mitra, Chen Shen, Dan Zhang, Estevam Hruschka",
        "summary": "Large language models (LLMs) are being increasingly used for planning in orchestrated multi-agent systems. However, existing LLM-based approaches often fall short of human expectations and, critically, lack effective mechanisms for users to inspect, understand, and control their behaviors. These limitations call for enhanced transparency, controllability, and human oversight. To address this, we introduce AIPOM, a system supporting human-in-the-loop planning through conversational and graph-based interfaces. AIPOM enables users to transparently inspect, refine, and collaboratively guide LLM-generated plans, significantly enhancing user control and trust in multi-agent workflows. Our code and demo video are available at https://github.com/megagonlabs/aipom.",
        "subjects": "Human-Computer Interaction, Multiagent Systems",
        "date": "2025-09-29",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.456471"
    },
    {
        "index": "#11",
        "title": "Prompting Robot Teams with Natural Language",
        "link": "/arxiv/2509.24575",
        "arxiv_id": "2509.24575",
        "authors": "Nicolas Pfitzer, Eduardo Sebastián, Ajay Shankar, Amanda Prorok",
        "summary": "This paper presents a framework towards prompting multi-robot teams with high-level tasks using natural language expressions. Our objective is to use the reasoning capabilities demonstrated by recent language models in understanding and decomposing human expressions of intent, and repurpose these for multi-robot collaboration and decision-making. The key challenge is that an individual's behavior in a collective can be hard to specify and interpret, and must continuously adapt to actions from others. This necessitates a framework that possesses the representational capacity required by the logic and semantics of a task, and yet supports decentralized and interactive real-time operation. We solve this dilemma by recognizing that a task can be represented as a deterministic finite automaton (DFA), and that recurrent neural networks (RNNs) can encode numerous automata. This allows us to distill the logic and sequential decompositions of sub-tasks obtained from a language model into an RNN, and align its internal states with the semantics of a given task. By training a graph neural network (GNN) control policy that is conditioned on the hidden states of the RNN and the language embeddings, our method enables robots to execute task-relevant actions in a decentralized manner. We present evaluations of this single light-weight interpretable model on various simulated and real-world multi-robot tasks that require sequential and collaborative behavior by the team -- sites.google.com/view/prompting-teams.",
        "subjects": "Robotics, Machine Learning, Multiagent Systems",
        "date": "2025-09-29",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.456747"
    },
    {
        "index": "#12",
        "title": "TeraAgent: A Distributed Agent-Based Simulation Engine for Simulating Half a Trillion Agents",
        "link": "/arxiv/2509.24063",
        "arxiv_id": "2509.24063",
        "authors": "Lukas Breitwieser, Ahmad Hesam, Abdullah Giray Yağlıkçı, Mohammad Sadrosadati, Fons Rademakers, Onur Mutlu",
        "summary": "Agent-based simulation is an indispensable paradigm for studying complex systems. These systems can comprise billions of agents, requiring the computing resources of multiple servers to simulate. Unfortunately, the state-of-the-art platform, BioDynaMo, does not scale out across servers due to its shared-memory-based implementation. To overcome this key limitation, we introduce TeraAgent, a distributed agent-based simulation engine. A critical challenge in distributed execution is the exchange of agent information across servers, which we identify as a major performance bottleneck. We propose two solutions: 1) a tailored serialization mechanism that allows agents to be accessed and mutated directly from the receive buffer, and 2) leveraging the iterative nature of agent-based simulations to reduce data transfer with delta encoding. Built on our solutions, TeraAgent enables extreme-scale simulations with half a trillion agents (an 84x improvement), reduces time-to-result with additional compute nodes, improves interoperability with third-party tools, and provides users with more hardware flexibility.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Computational Engineering, Finance, and Science, Multiagent Systems, Performance, Quantitative Methods",
        "date": "2025-09-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.457057"
    },
    {
        "index": "#13",
        "title": "GPS-MTM: Capturing Pattern of Normalcy in GPS-Trajectories with self-supervised learning",
        "link": "/arxiv/2509.24031",
        "arxiv_id": "2509.24031",
        "authors": "Umang Garg, Bowen Zhang, Anantanjit Subrahmanya, Chandrakanth Gudavalli, BS Manjunath",
        "summary": "Foundation models have driven remarkable progress in text, vision, and video understanding, and are now poised to unlock similar breakthroughs in trajectory modeling. We introduce the GPSMasked Trajectory Transformer (GPS-MTM), a foundation model for large-scale mobility data that captures patterns of normalcy in human movement. Unlike prior approaches that flatten trajectories into coordinate streams, GPS-MTM decomposes mobility into two complementary modalities: states (point-of-interest categories) and actions (agent transitions). Leveraging a bi-directional Transformer with a self-supervised masked modeling objective, the model reconstructs missing segments across modalities, enabling it to learn rich semantic correlations without manual labels. Across benchmark datasets, including Numosim-LA, Urban Anomalies, and Geolife, GPS-MTM consistently outperforms on downstream tasks such as trajectory infilling and next-stop prediction. Its advantages are most pronounced in dynamic tasks (inverse and forward dynamics), where contextual reasoning is critical. These results establish GPS-MTM as a robust foundation model for trajectory analytics, positioning mobility data as a first-class modality for large-scale representation learning. Code is released for further reference.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Multiagent Systems",
        "date": "2025-09-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.457345"
    },
    {
        "index": "#14",
        "title": "FedAgentBench: Towards Automating Real-world Federated Medical Image Analysis with Server-Client LLM Agents",
        "link": "/arxiv/2509.23803",
        "arxiv_id": "2509.23803",
        "authors": "Pramit Saha, Joshua Strong, Divyanshu Mishra, Cheng Ouyang, J. Alison Noble",
        "summary": "Federated learning (FL) allows collaborative model training across healthcare sites without sharing sensitive patient data. However, real-world FL deployment is often hindered by complex operational challenges that demand substantial human efforts. This includes: (a) selecting appropriate clients (hospitals), (b) coordinating between the central server and clients, (c) client-level data pre-processing, (d) harmonizing non-standardized data and labels across clients, and (e) selecting FL algorithms based on user instructions and cross-client data characteristics. However, the existing FL works overlook these practical orchestration challenges. These operational bottlenecks motivate the need for autonomous, agent-driven FL systems, where intelligent agents at each hospital client and the central server agent collaboratively manage FL setup and model training with minimal human intervention. To this end, we first introduce an agent-driven FL framework that captures key phases of real-world FL workflows from client selection to training completion and a benchmark dubbed FedAgentBench that evaluates the ability of LLM agents to autonomously coordinate healthcare FL. Our framework incorporates 40 FL algorithms, each tailored to address diverse task-specific requirements and cross-client characteristics. Furthermore, we introduce a diverse set of complex tasks across 201 carefully curated datasets, simulating 6 modality-specific real-world healthcare environments, viz., Dermatoscopy, Ultrasound, Fundus, Histopathology, MRI, and X-Ray. We assess the agentic performance of 14 open-source and 10 proprietary LLMs spanning small, medium, and large model scales. While some agent cores such as GPT-4.1 and DeepSeek V3 can automate various stages of the FL pipeline, our results reveal that more complex, interdependent tasks based on implicit goals remain challenging for even the strongest models.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Distributed, Parallel, and Cluster Computing, Multiagent Systems",
        "date": "2025-09-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.457643"
    },
    {
        "index": "#15",
        "title": "Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse",
        "link": "/arxiv/2509.23778",
        "arxiv_id": "2509.23778",
        "authors": "Zeyuan Zhang, Chaoran Li, Shao Zhang, Ying Wen",
        "summary": "Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of Multi-Agent Path Finding (MAPF), where agents are required to sequentially complete tasks with fixed-location pickup and delivery demands. Although learning-based methods have made progress in MAPD, they often perform poorly in warehouse-like environments with narrow pathways and long corridors when relying only on local observations for distributed decision-making. Communication learning can alleviate the lack of global information but introduce high computational complexity due to point-to-point communication. To address this challenge, we formulate MAPF as a sequence modeling problem and prove that path-finding policies under sequence modeling possess order-invariant optimality, ensuring its effectiveness in MAPD. Building on this, we propose the Sequential Pathfinder (SePar), which leverages the Transformer paradigm to achieve implicit information exchange, reducing decision-making complexity from exponential to linear while maintaining efficiency and global awareness. Experiments demonstrate that SePar consistently outperforms existing learning-based methods across various MAPF tasks and their variants, and generalizes well to unseen environments. Furthermore, we highlight the necessity of integrating imitation learning in complex maps like warehouses.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-09-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.457929"
    },
    {
        "index": "#16",
        "title": "SIMPOL Model for Solving Continuous-Time Heterogeneous Agent Problems",
        "link": "/arxiv/2509.23557",
        "arxiv_id": "2509.23557",
        "authors": "Ricardo Alonzo Fernández Salguero",
        "summary": "This paper presents SIMPOL (Simplified Policy Iteration), a modular numerical framework for solving continuous-time heterogeneous agent models. The core economic problem, the optimization of consumption and savings under idiosyncratic uncertainty, is formulated as a coupled system of partial differential equations: a Hamilton-Jacobi-Bellman (HJB) equation for the agent's optimal policy and a Fokker-Planck-Kolmogorov (FPK) equation for the stationary wealth distribution. SIMPOL addresses this system using Howard's policy iteration with an *upwind* finite difference scheme that guarantees stability. A distinctive contribution is a novel consumption policy post-processing module that imposes regularity through smoothing and a projection onto an economically plausible slope band, improving convergence and model behavior. The robustness and accuracy of SIMPOL are validated through a set of integrated diagnostics, including verification of contraction in the Wasserstein-2 metric and comparison with the analytical solution of the Merton model in the no-volatility case. The framework is shown to be not only computationally efficient but also to produce solutions consistent with economic and mathematical theory, offering a reliable tool for research in quantitative macroeconomics.",
        "subjects": "Computational Finance, Multiagent Systems, Theoretical Economics",
        "date": "2025-09-28",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.458176"
    },
    {
        "index": "#17",
        "title": "Grouped Satisficing Paths in Pure Strategy Games: a Topological Perspective",
        "link": "/arxiv/2509.23157",
        "arxiv_id": "2509.23157",
        "authors": "Yanqing Fu, Chao Huang, Chenrun Wang, Zhuping Wang",
        "summary": "In game theory and multi-agent reinforcement learning (MARL), each agent selects a strategy, interacts with the environment and other agents, and subsequently updates its strategy based on the received payoff. This process generates a sequence of joint strategies $(s^t)_{t \\geq 0}$, where $s^t$ represents the strategy profile of all agents at time step $t$. A widely adopted principle in MARL algorithms is \"win-stay, lose-shift\", which dictates that an agent retains its current strategy if it achieves the best response. This principle exhibits a fixed-point property when the joint strategy has become an equilibrium. The sequence of joint strategies under this principle is referred to as a satisficing path, a concept first introduced in [40] and explored in the context of $N$-player games in [39]. A fundamental question arises regarding this principle: Under what conditions does every initial joint strategy $s$ admit a finite-length satisficing path $(s^t)_{0 \\leq t \\leq T}$ where $s^0=s$ and $s^T$ is an equilibrium? This paper establishes a sufficient condition for such a property, and demonstrates that any finite-state Markov game, as well as any $N$-player game, guarantees the existence of a finite-length satisficing path from an arbitrary initial strategy to some equilibrium. These results provide a stronger theoretical foundation for the design of MARL algorithms.",
        "subjects": "Computer Science and Game Theory, Machine Learning, Multiagent Systems",
        "date": "2025-09-27",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.458446"
    },
    {
        "index": "#18",
        "title": "Coordination Requires Simplification: Thermodynamic Bounds on Multi-Objective Compromise in Natural and Artificial Intelligence",
        "link": "/arxiv/2509.23144",
        "arxiv_id": "2509.23144",
        "authors": "Atma Anand",
        "summary": "Information-processing systems coordinating across multiple agents and objectives face fundamental thermodynamic constraints. We show that solutions with maximum utility to act as coordination focal points have much higher selection pressure for being findable across agents rather than accuracy. We derive that the information-theoretic minimum description length of coordination protocols to precision $\\varepsilon$ scales as $L(P)\\geq NK\\log_2 K+N^2d^2\\log (1/\\varepsilon)$ for $N$ agents with $d$ potentially conflicting objectives and internal model complexity $K$. This scaling forces progressive simplification, with coordination dynamics changing the environment itself and shifting optimization across hierarchical levels. Moving from established focal points requires re-coordination, creating persistent metastable states and hysteresis until significant environmental shifts trigger phase transitions through spontaneous symmetry breaking. We operationally define coordination temperature to predict critical phenomena and estimate coordination work costs, identifying measurable signatures across systems from neural networks to restaurant bills to bureaucracies. Extending the topological version of Arrow's theorem on the impossibility of consistent preference aggregation, we find it recursively binds whenever preferences are combined. This potentially explains the indefinite cycling in multi-objective gradient descent and alignment faking in Large Language Models trained with reinforcement learning with human feedback. We term this framework Thermodynamic Coordination Theory (TCT), which demonstrates that coordination requires radical information loss.",
        "subjects": "Artificial Intelligence, Statistical Mechanics, Multiagent Systems, Adaptation and Self-Organizing Systems, Physics and Society",
        "date": "2025-09-27",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T21:53:01.458712"
    }
]