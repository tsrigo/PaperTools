[
    {
        "index": "#1",
        "title": "KaVa: Latent Reasoning via Compressed KV-Cache Distillation",
        "link": "/arxiv/2510.02312",
        "arxiv_id": "2510.02312",
        "authors": "Anna Kuzina, Maciej Pioro, Paul N. Whatmough, Babak Ehteshami Bejnordi",
        "summary": "Large Language Models (LLMs) excel at multi-step reasoning problems with explicit chain-of-thought (CoT), but verbose traces incur significant computational costs and memory overhead, and often carry redundant, stylistic artifacts. Latent reasoning has emerged as an efficient alternative that internalizes the thought process, but it suffers from a critical lack of supervision, limiting its effectiveness on complex, natural-language reasoning traces. In this work, we propose KaVa, the first framework that bridges this gap by distilling knowledge directly from a compressed KV-cache of the teacher into a latent-reasoning student via self-distillation, leveraging the representational flexibility of continuous latent tokens to align stepwise KV trajectories. We show that the abstract, unstructured knowledge within compressed KV-cache, which lacks direct token correspondence, can serve as a rich supervisory signal for a latent reasoning student. Empirically, the approach consistently outperforms strong latent baselines, exhibits markedly smaller degradation from equation-only to natural-language traces, and scales to larger backbones while preserving efficiency. These results establish compressed KV-cache distillation as a scalable supervision signal for latent reasoning, combining the accuracy of CoT-trained teachers with the efficiency and deployability of latent inference.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.275143"
    },
    {
        "index": "#2",
        "title": "Robust Tangent Space Estimation via Laplacian Eigenvector Gradient Orthogonalization",
        "link": "/arxiv/2510.02308",
        "arxiv_id": "2510.02308",
        "authors": "Dhruv Kohli, Sawyer J. Robertson, Gal Mishne, Alexander Cloninger",
        "summary": "Estimating the tangent spaces of a data manifold is a fundamental problem in data analysis. The standard approach, Local Principal Component Analysis (LPCA), struggles in high-noise settings due to a critical trade-off in choosing the neighborhood size. Selecting an optimal size requires prior knowledge of the geometric and noise characteristics of the data that are often unavailable. In this paper, we propose a spectral method, Laplacian Eigenvector Gradient Orthogonalization (LEGO), that utilizes the global structure of the data to guide local tangent space estimation. Instead of relying solely on local neighborhoods, LEGO estimates the tangent space at each data point by orthogonalizing the gradients of low-frequency eigenvectors of the graph Laplacian. We provide two theoretical justifications of our method. First, a differential geometric analysis on a tubular neighborhood of a manifold shows that gradients of the low-frequency Laplacian eigenfunctions of the tube align closely with the manifold's tangent bundle, while an eigenfunction with high gradient in directions orthogonal to the manifold lie deeper in the spectrum. Second, a random matrix theoretic analysis also demonstrates that low-frequency eigenvectors are robust to sub-Gaussian noise. Through comprehensive experiments, we demonstrate that LEGO yields tangent space estimates that are significantly more robust to noise than those from LPCA, resulting in marked improvements in downstream tasks such as manifold learning, boundary detection, and local intrinsic dimension estimation.",
        "subjects": "Machine Learning, Differential Geometry",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.275633"
    },
    {
        "index": "#4",
        "title": "Knowledge Distillation Detection for Open-weights Models",
        "link": "/arxiv/2510.02302",
        "arxiv_id": "2510.02302",
        "authors": "Qin Shi, Amber Yijia Zheng, Qifan Song, Raymond A. Yeh",
        "summary": "We propose the task of knowledge distillation detection, which aims to determine whether a student model has been distilled from a given teacher, under a practical setting where only the student's weights and the teacher's API are available. This problem is motivated by growing concerns about model provenance and unauthorized replication through distillation. To address this task, we introduce a model-agnostic framework that combines data-free input synthesis and statistical score computation for detecting distillation. Our approach is applicable to both classification and generative models. Experiments on diverse architectures for image classification and text-to-image generation show that our method improves detection accuracy over the strongest baselines by 59.6% on CIFAR-10, 71.2% on ImageNet, and 20.0% for text-to-image generation. The code is available at https://github.com/shqii1j/distillation_detection.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.276636"
    },
    {
        "index": "#7",
        "title": "Continual Personalization for Diffusion Models",
        "link": "/arxiv/2510.02296",
        "arxiv_id": "2510.02296",
        "authors": "Yu-Chien Liao, Jr-Jen Chen, Chi-Pin Huang, Ci-Siang Lin, Meng-Lin Wu, Yu-Chiang Frank Wang",
        "summary": "Updating diffusion models in an incremental setting would be practical in real-world applications yet computationally challenging. We present a novel learning strategy of Concept Neuron Selection (CNS), a simple yet effective approach to perform personalization in a continual learning scheme. CNS uniquely identifies neurons in diffusion models that are closely related to the target concepts. In order to mitigate catastrophic forgetting problems while preserving zero-shot text-to-image generation ability, CNS finetunes concept neurons in an incremental manner and jointly preserves knowledge learned of previous concepts. Evaluation of real-world datasets demonstrates that CNS achieves state-of-the-art performance with minimal parameter adjustments, outperforming previous methods in both single and multi-concept personalization works. CNS also achieves fusion-free operation, reducing memory storage and processing time for continual personalization.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.278156"
    },
    {
        "index": "#8",
        "title": "Test-Time Anchoring for Discrete Diffusion Posterior Sampling",
        "link": "/arxiv/2510.02291",
        "arxiv_id": "2510.02291",
        "authors": "Litu Rout, Andreas Lugmayr, Yasamin Jafarian, Srivatsan Varadharajan, Constantine Caramanis, Sanjay Shakkottai, Ira Kemelmacher-Shlizerman",
        "summary": "We study the problem of posterior sampling using pretrained discrete diffusion foundation models, aiming to recover images from noisy measurements without retraining task-specific models. While diffusion models have achieved remarkable success in generative modeling, most advances rely on continuous Gaussian diffusion. In contrast, discrete diffusion offers a unified framework for jointly modeling categorical data such as text and images. Beyond unification, discrete diffusion provides faster inference, finer control, and principled training-free Bayesian inference, making it particularly well-suited for posterior sampling. However, existing approaches to discrete diffusion posterior sampling face severe challenges: derivative-free guidance yields sparse signals, continuous relaxations limit applicability, and split Gibbs samplers suffer from the curse of dimensionality. To overcome these limitations, we introduce Anchored Posterior Sampling (APS) for masked diffusion foundation models, built on two key innovations -- quantized expectation for gradient-like guidance in discrete embedding space, and anchored remasking for adaptive decoding. Our approach achieves state-of-the-art performance among discrete diffusion samplers across linear and nonlinear inverse problems on the standard benchmarks. We further demonstrate the benefits of our approach in training-free stylization and text-guided editing.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.278702"
    },
    {
        "index": "#11",
        "title": "Fine-Grained Urban Traffic Forecasting on Metropolis-Scale Road Networks",
        "link": "/arxiv/2510.02278",
        "arxiv_id": "2510.02278",
        "authors": "Fedor Velikonivtsev, Oleg Platonov, Gleb Bazhenov, Liudmila Prokhorenkova",
        "summary": "Traffic forecasting on road networks is a complex task of significant practical importance that has recently attracted considerable attention from the machine learning community, with spatiotemporal graph neural networks (GNNs) becoming the most popular approach. The proper evaluation of traffic forecasting methods requires realistic datasets, but current publicly available benchmarks have significant drawbacks, including the absence of information about road connectivity for road graph construction, limited information about road properties, and a relatively small number of road segments that falls short of real-world applications. Further, current datasets mostly contain information about intercity highways with sparsely located sensors, while city road networks arguably present a more challenging forecasting task due to much denser roads and more complex urban traffic patterns. In this work, we provide a more complete, realistic, and challenging benchmark for traffic forecasting by releasing datasets representing the road networks of two major cities, with the largest containing almost 100,000 road segments (more than a 10-fold increase relative to existing datasets). Our datasets contain rich road features and provide fine-grained data about both traffic volume and traffic speed, allowing for building more holistic traffic forecasting systems. We show that most current implementations of neural spatiotemporal models for traffic forecasting have problems scaling to datasets of our size. To overcome this issue, we propose an alternative approach to neural traffic forecasting that uses a GNN without a dedicated module for temporal sequence processing, thus achieving much better scalability, while also demonstrating stronger forecasting performance. We hope our datasets and modeling insights will serve as a valuable resource for research in traffic forecasting.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.285646"
    },
    {
        "index": "#12",
        "title": "Diffusion^2: Turning 3D Environments into Radio Frequency Heatmaps",
        "link": "/arxiv/2510.02274",
        "arxiv_id": "2510.02274",
        "authors": "Kyoungjun Park, Yifan Yang, Changhan Ge, Lili Qiu, Shiqi Jiang",
        "summary": "Modeling radio frequency (RF) signal propagation is essential for understanding the environment, as RF signals offer valuable insights beyond the capabilities of RGB cameras, which are limited by the visible-light spectrum, lens coverage, and occlusions. It is also useful for supporting wireless diagnosis, deployment, and optimization. However, accurately predicting RF signals in complex environments remains a challenge due to interactions with obstacles such as absorption and reflection. We introduce Diffusion^2, a diffusion-based approach that uses 3D point clouds to model the propagation of RF signals across a wide range of frequencies, from Wi-Fi to millimeter waves. To effectively capture RF-related features from 3D data, we present the RF-3D Encoder, which encapsulates the complexities of 3D geometry along with signal-specific details. These features undergo multi-scale embedding to simulate the actual RF signal dissemination process. Our evaluation, based on synthetic and real-world measurements, demonstrates that Diffusion^2 accurately estimates the behavior of RF signals in various frequency bands and environmental conditions, with an error margin of just 1.9 dB and 27x faster than existing methods, marking a significant advancement in the field. Refer to https://rfvision-project.github.io/ for more information.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.286139"
    },
    {
        "index": "#14",
        "title": "Transformers Discover Molecular Structure Without Graph Priors",
        "link": "/arxiv/2510.02259",
        "arxiv_id": "2510.02259",
        "authors": "Tobias Kreiman, Yutong Bai, Fadi Atieh, Elizabeth Weaver, Eric Qu, Aditi S. Krishnapriyan",
        "summary": "Graph Neural Networks (GNNs) are the dominant architecture for molecular machine learning, particularly for molecular property prediction and machine learning interatomic potentials (MLIPs). GNNs perform message passing on predefined graphs often induced by a fixed radius cutoff or k-nearest neighbor scheme. While this design aligns with the locality present in many molecular tasks, a hard-coded graph can limit expressivity due to the fixed receptive field and slows down inference with sparse graph operations. In this work, we investigate whether pure, unmodified Transformers trained directly on Cartesian coordinates$\\unicode{x2013}$without predefined graphs or physical priors$\\unicode{x2013}$can approximate molecular energies and forces. As a starting point for our analysis, we demonstrate how to train a Transformer to competitive energy and force mean absolute errors under a matched training compute budget, relative to a state-of-the-art equivariant GNN on the OMol25 dataset. We discover that the Transformer learns physically consistent patterns$\\unicode{x2013}$such as attention weights that decay inversely with interatomic distance$\\unicode{x2013}$and flexibly adapts them across different molecular environments due to the absence of hard-coded biases. The use of a standard Transformer also unlocks predictable improvements with respect to scaling training resources, consistent with empirical scaling laws observed in other domains. Our results demonstrate that many favorable properties of GNNs can emerge adaptively in Transformers, challenging the necessity of hard-coded graph inductive biases and pointing toward standardized, scalable architectures for molecular modeling.",
        "subjects": "Machine Learning, Materials Science, Chemical Physics, Biomolecules",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.287164"
    },
    {
        "index": "#16",
        "title": "Drop-Muon: Update Less, Converge Faster",
        "link": "/arxiv/2510.02239",
        "arxiv_id": "2510.02239",
        "authors": "Kaja Gruntkowska, Yassine Maziane, Zheng Qu, Peter Richtárik",
        "summary": "Conventional wisdom in deep learning optimization dictates updating all layers at every step-a principle followed by all recent state-of-the-art optimizers such as Muon. In this work, we challenge this assumption, showing that full-network updates can be fundamentally suboptimal, both in theory and in practice. We introduce a non-Euclidean Randomized Progressive Training method-Drop-Muon-a simple yet powerful framework that updates only a subset of layers per step according to a randomized schedule, combining the efficiency of progressive training with layer-specific non-Euclidean updates for top-tier performance. We provide rigorous convergence guarantees under both layer-wise smoothness and layer-wise $(L^0, L^1)$-smoothness, covering deterministic and stochastic gradient settings, marking the first such results for progressive training in the stochastic and non-smooth regime. Our cost analysis further reveals that full-network updates are not optimal unless a very specific relationship between layer smoothness constants holds. Through controlled CNN experiments, we empirically demonstrate that Drop-Muon consistently outperforms full-network Muon, achieving the same accuracy up to $1.4\\times$ faster in wall-clock time. Together, our results suggest a shift in how large-scale models can be efficiently trained, challenging the status quo and offering a highly efficient, theoretically grounded alternative to full-network updates.",
        "subjects": "Machine Learning, Optimization and Control, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.288225"
    },
    {
        "index": "#17",
        "title": "PUL-Inter-slice Defender: An Anomaly Detection Solution for Distributed Slice Mobility Attacks",
        "link": "/arxiv/2510.02236",
        "arxiv_id": "2510.02236",
        "authors": "Ricardo Misael Ayala Molina, Hyame Assem Alameddine, Makan Pourzandi, Chadi Assi",
        "summary": "Network Slices (NSs) are virtual networks operating over a shared physical infrastructure, each designed to meet specific application requirements while maintaining consistent Quality of Service (QoS). In Fifth Generation (5G) networks, User Equipment (UE) can connect to and seamlessly switch between multiple NSs to access diverse services. However, this flexibility, known as Inter-Slice Switching (ISS), introduces a potential vulnerability that can be exploited to launch Distributed Slice Mobility (DSM) attacks, a form of Distributed Denial of Service (DDoS) attack. To secure 5G networks and their NSs against DSM attacks, we present in this work, PUL-Inter-Slice Defender; an anomaly detection solution that leverages Positive Unlabeled Learning (PUL) and incorporates a combination of Long Short-Term Memory Autoencoders and K-Means clustering. PUL-Inter-Slice Defender leverages the Third Generation Partnership Project (3GPP) key performance indicators and performance measurement counters as features for its machine learning models to detect DSM attack variants while maintaining robustness in the presence of contaminated training data. When evaluated on data collected from our 5G testbed based on the open-source free5GC and UERANSIM, a UE/ Radio Access Network (RAN) simulator; PUL-Inter-Slice Defender achieved F1-scores exceeding 98.50% on training datasets with 10% to 40% attack contamination, consistently outperforming its counterpart Inter-Slice Defender and other PUL based solutions combining One-Class Support Vector Machine (OCSVM) with Random Forest and XGBoost.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.288671"
    },
    {
        "index": "#18",
        "title": "xLSTM Scaling Laws: Competitive Performance with Linear Time-Complexity",
        "link": "/arxiv/2510.02228",
        "arxiv_id": "2510.02228",
        "authors": "Maximilian Beck, Kajetan Schweighofer, Sebastian Böck, Sebastian Lehner, Sepp Hochreiter",
        "summary": "Scaling laws play a central role in the success of Large Language Models (LLMs), enabling the prediction of model performance relative to compute budgets prior to training. While Transformers have been the dominant architecture, recent alternatives such as xLSTM offer linear complexity with respect to context length while remaining competitive in the billion-parameter regime. We conduct a comparative investigation on the scaling behavior of Transformers and xLSTM along the following lines, providing insights to guide future model design and deployment. First, we study the scaling behavior for xLSTM in compute-optimal and over-training regimes using both IsoFLOP and parametric fit approaches on a wide range of model sizes (80M-7B) and number of training tokens (2B-2T). Second, we examine the dependence of optimal model sizes on context length, a pivotal aspect that was largely ignored in previous work. Finally, we analyze inference-time scaling characteristics. Our findings reveal that in typical LLM training and inference scenarios, xLSTM scales favorably compared to Transformers. Importantly, xLSTM's advantage widens as training and inference contexts grow.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.289134"
    },
    {
        "index": "#19",
        "title": "Efficiently Generating Correlated Sample Paths from Multi-step Time Series Foundation Models",
        "link": "/arxiv/2510.02224",
        "arxiv_id": "2510.02224",
        "authors": "Ethan Baron, Boris Oreshkin, Ruijun Ma, Hanyu Zhang, Kari Torkkola, Michael W. Mahoney, Andrew Gordon Wilson, Tatiana Konstantinova",
        "summary": "Many time series applications require access to multi-step forecast trajectories in the form of sample paths. Recently, time series foundation models have leveraged multi-step lookahead predictions to improve the quality and efficiency of multi-step forecasts. However, these models only predict independent marginal distributions for each time step, rather than a full joint predictive distribution. To generate forecast sample paths with realistic correlation structures, one typically resorts to autoregressive sampling, which can be extremely expensive. In this paper, we present a copula-based approach to efficiently generate accurate, correlated sample paths from existing multi-step time series foundation models in one forward pass. Our copula-based approach generates correlated sample paths orders of magnitude faster than autoregressive sampling, and it yields improved sample path quality by mitigating the snowballing error phenomenon.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.289665"
    },
    {
        "index": "#20",
        "title": "Diffusion Transformers for Imputation: Statistical Efficiency and Uncertainty Quantification",
        "link": "/arxiv/2510.02216",
        "arxiv_id": "2510.02216",
        "authors": "Zeqi Ye, Minshuo Chen",
        "summary": "Imputation methods play a critical role in enhancing the quality of practical time-series data, which often suffer from pervasive missing values. Recently, diffusion-based generative imputation methods have demonstrated remarkable success compared to autoregressive and conventional statistical approaches. Despite their empirical success, the theoretical understanding of how well diffusion-based models capture complex spatial and temporal dependencies between the missing values and observed ones remains limited. Our work addresses this gap by investigating the statistical efficiency of conditional diffusion transformers for imputation and quantifying the uncertainty in missing values. Specifically, we derive statistical sample complexity bounds based on a novel approximation theory for conditional score functions using transformers, and, through this, construct tight confidence regions for missing values. Our findings also reveal that the efficiency and accuracy of imputation are significantly influenced by the missing patterns. Furthermore, we validate these theoretical insights through simulation and propose a mixed-masking training strategy to enhance the imputation performance.",
        "subjects": "Machine Learning, Statistics Theory, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.295240"
    },
    {
        "index": "#21",
        "title": "C2AL: Cohort-Contrastive Auxiliary Learning for Large-scale Recommendation Systems",
        "link": "/arxiv/2510.02215",
        "arxiv_id": "2510.02215",
        "authors": "Mertcan Cokbas, Ziteng Liu, Zeyi Tao, Chengkai Zhang, Elder Veliz, Qin Huang, Ellie Wen, Huayu Li, Qiang Jin, Murat Duman, Benjamin Au, Guy Lebanon, Sagar Chordia",
        "summary": "Training large-scale recommendation models under a single global objective implicitly assumes homogeneity across user populations. However, real-world data are composites of heterogeneous cohorts with distinct conditional distributions. As models increase in scale and complexity and as more data is used for training, they become dominated by central distribution patterns, neglecting head and tail regions. This imbalance limits the model's learning ability and can result in inactive attention weights or dead neurons. In this paper, we reveal how the attention mechanism can play a key role in factorization machines for shared embedding selection, and propose to address this challenge by analyzing the substructures in the dataset and exposing those with strong distributional contrast through auxiliary learning. Unlike previous research, which heuristically applies weighted labels or multi-task heads to mitigate such biases, we leverage partially conflicting auxiliary labels to regularize the shared representation. This approach customizes the learning process of attention layers to preserve mutual information with minority cohorts while improving global performance. We evaluated C2AL on massive production datasets with billions of data points each for six SOTA models. Experiments show that the factorization machine is able to capture fine-grained user-ad interactions using the proposed method, achieving up to a 0.16% reduction in normalized entropy overall and delivering gains exceeding 0.30% on targeted minority cohorts.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.295845"
    },
    {
        "index": "#24",
        "title": "Poolformer: Recurrent Networks with Pooling for Long-Sequence Modeling",
        "link": "/arxiv/2510.02206",
        "arxiv_id": "2510.02206",
        "authors": "Daniel Gallo Fernández",
        "summary": "Sequence-to-sequence models have become central in Artificial Intelligence, particularly following the introduction of the transformer architecture. While initially developed for Natural Language Processing, these models have demonstrated utility across domains, including Computer Vision. Such models require mechanisms to exchange information along the time dimension, typically using recurrent or self-attention layers. However, self-attention scales quadratically with sequence length, limiting its practicality for very long sequences. We introduce Poolformer, a sequence-to-sequence model that replaces self-attention with recurrent layers and incorporates pooling operations to reduce sequence length. Poolformer is defined recursively using SkipBlocks, which contain residual blocks, a down-pooling layer, a nested SkipBlock, an up-pooling layer, and additional residual blocks. We conduct extensive experiments to support our architectural choices. Our results show that pooling greatly accelerates training, improves perceptual metrics (FID and IS), and prevents overfitting. Our experiments also suggest that long-range dependencies are handled by deep layers, while shallow layers take care of short-term features. Evaluated on raw audio, which naturally features long sequence lengths, Poolformer outperforms state-of-the-art models such as SaShiMi and Mamba. Future directions include applications to text and vision, as well as multi-modal scenarios, where a Poolformer-based LLM could effectively process dense representations of images and videos.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.297316"
    },
    {
        "index": "#27",
        "title": "Flatness-Aware Stochastic Gradient Langevin Dynamics",
        "link": "/arxiv/2510.02174",
        "arxiv_id": "2510.02174",
        "authors": "Stefano Bruno, Youngsik Hwang, Jaehyeon An, Sotirios Sabanis, Dong-Young Lim",
        "summary": "Generalization in deep learning is closely tied to the pursuit of flat minima in the loss landscape, yet classical Stochastic Gradient Langevin Dynamics (SGLD) offers no mechanism to bias its dynamics toward such low-curvature solutions. This work introduces Flatness-Aware Stochastic Gradient Langevin Dynamics (fSGLD), designed to efficiently and provably seek flat minima in high-dimensional nonconvex optimization problems. At each iteration, fSGLD uses the stochastic gradient evaluated at parameters perturbed by isotropic Gaussian noise, commonly referred to as Random Weight Perturbation (RWP), thereby optimizing a randomized-smoothing objective that implicitly captures curvature information. Leveraging these properties, we prove that the invariant measure of fSGLD stays close to a stationary measure concentrated on the global minimizers of a loss function regularized by the Hessian trace whenever the inverse temperature and the scale of random weight perturbation are properly coupled. This result provides a rigorous theoretical explanation for the benefits of random weight perturbation. In particular, we establish non-asymptotic convergence guarantees in Wasserstein distance with the best known rate and derive an excess-risk bound for the Hessian-trace regularized objective. Extensive experiments on noisy-label and large-scale vision tasks, in both training-from-scratch and fine-tuning settings, demonstrate that fSGLD achieves superior or comparable generalization and robustness to baseline algorithms while maintaining the computational cost of SGD, about half that of SAM. Hessian-spectrum analysis further confirms that fSGLD converges to significantly flatter minima.",
        "subjects": "Machine Learning, Optimization and Control, Probability, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.299010"
    },
    {
        "index": "#28",
        "title": "Reinforcement Learning with Action-Triggered Observations",
        "link": "/arxiv/2510.02149",
        "arxiv_id": "2510.02149",
        "authors": "Alexander Ryabchenko, Wenlong Mou",
        "summary": "We study reinforcement learning problems where state observations are stochastically triggered by actions, a constraint common in many real-world applications. This framework is formulated as Action-Triggered Sporadically Traceable Markov Decision Processes (ATST-MDPs), where each action has a specified probability of triggering a state observation. We derive tailored Bellman optimality equations for this framework and introduce the action-sequence learning paradigm in which agents commit to executing a sequence of actions until the next observation arrives. Under the linear MDP assumption, value-functions are shown to admit linear representations in an induced action-sequence feature map. Leveraging this structure, we propose off-policy estimators with statistical error guarantees for such feature maps and introduce ST-LSVI-UCB, a variant of LSVI-UCB adapted for action-triggered settings. ST-LSVI-UCB achieves regret $\\widetilde O(\\sqrt{Kd^3(1-\\gamma)^{-3}})$, where $K$ is the number of episodes, $d$ the feature dimension, and $\\gamma$ the discount factor (per-step episode non-termination probability). Crucially, this work establishes the theoretical foundation for learning with sporadic, action-triggered observations while demonstrating that efficient learning remains feasible under such observation constraints.",
        "subjects": "Machine Learning, Optimization and Control, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.299474"
    },
    {
        "index": "#29",
        "title": "Policy Gradient Guidance Enables Test Time Control",
        "link": "/arxiv/2510.02148",
        "arxiv_id": "2510.02148",
        "authors": "Jianing Qi, Hao Tang, Zhigang Zhu",
        "summary": "We introduce Policy Gradient Guidance (PGG), a simple extension of classifier-free guidance from diffusion models to classical policy gradient methods. PGG augments the policy gradient with an unconditional branch and interpolates conditional and unconditional branches, yielding a test-time control knob that modulates behavior without retraining. We provide a theoretical derivation showing that the additional normalization term vanishes under advantage estimation, leading to a clean guided policy gradient update. Empirically, we evaluate PGG on discrete and continuous control benchmarks. We find that conditioning dropout-central to diffusion guidance-offers gains in simple discrete tasks and low sample regimes, but dropout destabilizes continuous control. Training with modestly larger guidance ($\\gamma>1$) consistently improves stability, sample efficiency, and controllability. Our results show that guidance, previously confined to diffusion policies, can be adapted to standard on-policy methods, opening new directions for controllable online reinforcement learning.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.299952"
    },
    {
        "index": "#30",
        "title": "Catalyst GFlowNet for electrocatalyst design: A hydrogen evolution reaction case study",
        "link": "/arxiv/2510.02142",
        "arxiv_id": "2510.02142",
        "authors": "Lena Podina, Christina Humer, Alexandre Duval, Victor Schmidt, Ali Ramlaoui, Shahana Chatterjee, Yoshua Bengio, Alex Hernandez-Garcia, David Rolnick, Félix Therrien",
        "summary": "Efficient and inexpensive energy storage is essential for accelerating the adoption of renewable energy and ensuring a stable supply, despite fluctuations in sources such as wind and solar. Electrocatalysts play a key role in hydrogen energy storage (HES), allowing the energy to be stored as hydrogen. However, the development of affordable and high-performance catalysts for this process remains a significant challenge. We introduce Catalyst GFlowNet, a generative model that leverages machine learning-based predictors of formation and adsorption energy to design crystal surfaces that act as efficient catalysts. We demonstrate the performance of the model through a proof-of-concept application to the hydrogen evolution reaction, a key reaction in HES, for which we successfully identified platinum as the most efficient known catalyst. In future work, we aim to extend this approach to the oxygen evolution reaction, where current optimal catalysts are expensive metal oxides, and open the search space to discover new materials. This generative modeling framework offers a promising pathway for accelerating the search for novel and efficient catalysts.",
        "subjects": "Machine Learning, Materials Science",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.305660"
    },
    {
        "index": "#31",
        "title": "DAG DECORation: Continuous Optimization for Structure Learning under Hidden Confounding",
        "link": "/arxiv/2510.02117",
        "arxiv_id": "2510.02117",
        "authors": "Samhita Pal, James O'quinn, Kaveh Aryan, Heather Pua, James P. Long, Amir Asiaee",
        "summary": "We study structure learning for linear Gaussian SEMs in the presence of latent confounding. Existing continuous methods excel when errors are independent, while deconfounding-first pipelines rely on pervasive factor structure or nonlinearity. We propose \\textsc{DECOR}, a single likelihood-based and fully differentiable estimator that jointly learns a DAG and a correlated noise model. Our theory gives simple sufficient conditions for global parameter identifiability: if the mixed graph is bow free and the noise covariance has a uniform eigenvalue margin, then the map from $(\\B,\\OmegaMat)$ to the observational covariance is injective, so both the directed structure and the noise are uniquely determined. The estimator alternates a smooth-acyclic graph update with a convex noise update and can include a light bow complementarity penalty or a post hoc reconciliation step. On synthetic benchmarks that vary confounding density, graph density, latent rank, and dimension with $n<p$, \\textsc{DECOR} matches or outperforms strong baselines and is especially robust when confounding is non-pervasive, while remaining competitive under pervasiveness.",
        "subjects": "Machine Learning, Methodology",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.306194"
    },
    {
        "index": "#32",
        "title": "Ensemble Threshold Calibration for Stable Sensitivity Control",
        "link": "/arxiv/2510.02116",
        "arxiv_id": "2510.02116",
        "authors": "John N. Daras",
        "summary": "Precise recall control is critical in large-scale spatial conflation and entity-matching tasks, where missing even a few true matches can break downstream analytics, while excessive manual review inflates cost. Classical confidence-interval cuts such as Clopper-Pearson or Wilson provide lower bounds on recall, but they routinely overshoot the target by several percentage points and exhibit high run-to-run variance under skewed score distributions. We present an end-to-end framework that achieves exact recall with sub-percent variance over tens of millions of geometry pairs, while remaining TPU-friendly. Our pipeline starts with an equigrid bounding-box filter and compressed sparse row (CSR) candidate representation, reducing pair enumeration by two orders of magnitude. A deterministic xxHash bootstrap sample trains a lightweight neural ranker; its scores are propagated to all remaining pairs via a single forward pass and used to construct a reproducible, score-decile-stratified calibration set. Four complementary threshold estimators - Clopper-Pearson, Jeffreys, Wilson, and an exact quantile - are aggregated via inverse-variance weighting, then fused across nine independent subsamples. This ensemble reduces threshold variance compared to any single method. Evaluated on two real cadastral datasets (approximately 6.31M and 67.34M pairs), our approach consistently hits a recall target within a small error, decreases redundant verifications relative to other calibrations, and runs end-to-end on a single TPU v3 core.",
        "subjects": "Machine Learning, Databases, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.306650"
    },
    {
        "index": "#33",
        "title": "Hybrid Deep Learning Modeling Approach to Predict Natural Gas Consumption of Home Subscribers on Limited Data",
        "link": "/arxiv/2510.02115",
        "arxiv_id": "2510.02115",
        "authors": "Milad Firoozeh, Nader Dashti, Mohammad Ali Hatefi",
        "summary": "Today, natural gas, as a clean fuel and the best alternative to crude oil, covers a significant part of global demand. Iran is one of the largest countries with energy resources and in terms of gas is the second-largest country in the world. But, due to the increase in population and energy consumption, it faces problems such as pressure drops and gas outages yearly in cold seasons and therefore it is necessary to control gas consumption, especially in the residential sector, which has the largest share in Iran. This study aims to analyze and predict gas consumption for residential customers in Zanjan province, Iran, using machine learning models, including LSTM, GRU, and a hybrid BiLSTM-XGBoost model. The dataset consists of gas consumption and meteorology data collected over six years, from 2017 to 2022. The models were trained and evaluated based on their ability to accurately predict consumption patterns. The results indicate that the hybrid BiLSTM-XGBoost model outperformed the other models in terms of accuracy, with lower Root Mean Squared Error (RMSE), Mean Absolute Percentage Error (MAPE) values, and Mean Percentage Error (MPE). Additionally, the Hybrid model demonstrated robust performance, particularly in scenarios with limited data. The findings suggest that machine learning approaches, particularly hybrid models, can be effectively utilized to manage and predict gas consumption, contributing to more efficient resource management and reducing seasonal shortages. This study highlights the importance of incorporating geographical and climatic factors in predictive modeling, as these significantly influence gas usage across different regions.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.307092"
    },
    {
        "index": "#34",
        "title": "PENEX: AdaBoost-Inspired Neural Network Regularization",
        "link": "/arxiv/2510.02107",
        "arxiv_id": "2510.02107",
        "authors": "Klaus-Rudolf Kladny, Bernhard Schölkopf, Michael Muehlebach",
        "summary": "AdaBoost sequentially fits so-called weak learners to minimize an exponential loss, which penalizes mislabeled data points more severely than other loss functions like cross-entropy. Paradoxically, AdaBoost generalizes well in practice as the number of weak learners grows. In the present work, we introduce Penalized Exponential Loss (PENEX), a new formulation of the multi-class exponential loss that is theoretically grounded and, in contrast to the existing formulation, amenable to optimization via first-order methods. We demonstrate both empirically and theoretically that PENEX implicitly maximizes margins of data points. Also, we show that gradient increments on PENEX implicitly parameterize weak learners in the boosting framework. Across computer vision and language tasks, we show that PENEX exhibits a regularizing effect often better than established methods with similar computational cost. Our results highlight PENEX's potential as an AdaBoost-inspired alternative for effective training and fine-tuning of deep neural networks.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.307535"
    },
    {
        "index": "#35",
        "title": "Learning Model Representations Using Publicly Available Model Hubs",
        "link": "/arxiv/2510.02096",
        "arxiv_id": "2510.02096",
        "authors": "Damian Falk, Konstantin Schürholt, Konstantinos Tzevelekakis, Léo Meynent, Damian Borth",
        "summary": "The weights of neural networks have emerged as a novel data modality, giving rise to the field of weight space learning. A central challenge in this area is that learning meaningful representations of weights typically requires large, carefully constructed collections of trained models, typically referred to as model zoos. These model zoos are often trained ad-hoc, requiring large computational resources, constraining the learned weight space representations in scale and flexibility. In this work, we drop this requirement by training a weight space learning backbone on arbitrary models downloaded from large, unstructured model repositories such as Hugging Face. Unlike curated model zoos, these repositories contain highly heterogeneous models: they vary in architecture and dataset, and are largely undocumented. To address the methodological challenges posed by such heterogeneity, we propose a new weight space backbone designed to handle unstructured model populations. We demonstrate that weight space representations trained on models from Hugging Face achieve strong performance, often outperforming backbones trained on laboratory-generated model zoos. Finally, we show that the diversity of the model weights in our training set allows our weight space model to generalize to unseen data modalities. By demonstrating that high-quality weight space representations can be learned in the wild, we show that curated model zoos are not indispensable, thereby overcoming a strong limitation currently faced by the weight space learning community.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.308050"
    },
    {
        "index": "#37",
        "title": "Fine-Tuning Flow Matching via Maximum Likelihood Estimation of Reconstructions",
        "link": "/arxiv/2510.02081",
        "arxiv_id": "2510.02081",
        "authors": "Zhaoyi Li, Jingtao Ding, Yong Li, Shihua Li",
        "summary": "Flow Matching (FM) algorithm achieves remarkable results in generative tasks especially in robotic manipulation. Building upon the foundations of diffusion models, the simulation-free paradigm of FM enables simple and efficient training, but inherently introduces a train-inference gap. Specifically, we cannot assess the model's output during the training phase. In contrast, other generative models including Variational Autoencoder (VAE), Normalizing Flow and Generative Adversarial Networks (GANs) directly optimize on the reconstruction loss. Such a gap is particularly evident in scenarios that demand high precision, such as robotic manipulation. Moreover, we show that FM's over-pursuit of straight predefined paths may introduce some serious problems such as stiffness into the system. These motivate us to fine-tune FM via Maximum Likelihood Estimation of reconstructions - an approach made feasible by FM's underlying smooth ODE formulation, in contrast to the stochastic differential equations (SDEs) used in diffusion models. This paper first theoretically analyzes the relation between training loss and inference error in FM. Then we propose a method of fine-tuning FM via Maximum Likelihood Estimation of reconstructions, which includes both straightforward fine-tuning and residual-based fine-tuning approaches. Furthermore, through specifically designed architectures, the residual-based fine-tuning can incorporate the contraction property into the model, which is crucial for the model's robustness and interpretability. Experimental results in image generation and robotic manipulation verify that our method reliably improves the inference performance of FM.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.309047"
    },
    {
        "index": "#38",
        "title": "Inferring Optical Tissue Properties from Photoplethysmography using Hybrid Amortized Inference",
        "link": "/arxiv/2510.02073",
        "arxiv_id": "2510.02073",
        "authors": "Jens Behrmann, Maria R. Cervera, Antoine Wehenkel, Andrew C. Miller, Albert Cerussi, Pranay Jain, Vivek Venugopal, Shijie Yan, Guillermo Sapiro, Luca Pegolotti, Jörn-Henrik Jacobsen",
        "summary": "Smart wearables enable continuous tracking of established biomarkers such as heart rate, heart rate variability, and blood oxygen saturation via photoplethysmography (PPG). Beyond these metrics, PPG waveforms contain richer physiological information, as recent deep learning (DL) studies demonstrate. However, DL models often rely on features with unclear physiological meaning, creating a tension between predictive power, clinical interpretability, and sensor design. We address this gap by introducing PPGen, a biophysical model that relates PPG signals to interpretable physiological and optical parameters. Building on PPGen, we propose hybrid amortized inference (HAI), enabling fast, robust, and scalable estimation of relevant physiological parameters from PPG signals while correcting for model misspecification. In extensive in-silico experiments, we show that HAI can accurately infer physiological parameters under diverse noise and sensor conditions. Our results illustrate a path toward PPG models that retain the fidelity needed for DL-based features while supporting clinical interpretation and informed hardware design.",
        "subjects": "Machine Learning, Biological Physics, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.309670"
    },
    {
        "index": "#39",
        "title": "Adaptive Heterogeneous Mixtures of Normalising Flows for Robust Variational Inference",
        "link": "/arxiv/2510.02056",
        "arxiv_id": "2510.02056",
        "authors": "Benjamin Wiriyapong, Oktay Karakuş, Kirill Sidorov",
        "summary": "Normalising-flow variational inference (VI) can approximate complex posteriors, yet single-flow models often behave inconsistently across qualitatively different distributions. We propose Adaptive Mixture Flow Variational Inference (AMF-VI), a heterogeneous mixture of complementary flows (MAF, RealNVP, RBIG) trained in two stages: (i) sequential expert training of individual flows, and (ii) adaptive global weight estimation via likelihood-driven updates, without per-sample gating or architectural changes. Evaluated on six canonical posterior families of banana, X-shape, two-moons, rings, a bimodal, and a five-mode mixture, AMF-VI achieves consistently lower negative log-likelihood than each single-flow baseline and delivers stable gains in transport metrics (Wasserstein-2) and maximum mean discrepancy (MDD), indicating improved robustness across shapes and modalities. The procedure is efficient and architecture-agnostic, incurring minimal overhead relative to standard flow training, and demonstrates that adaptive mixtures of diverse flows provide a reliable route to robust VI across diverse posterior families whilst preserving each expert's inductive bias.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.310132"
    },
    {
        "index": "#40",
        "title": "Mathematical Modeling and Convergence Analysis of Deep Neural Networks with Dense Layer Connectivities in Deep Learning",
        "link": "/arxiv/2510.02049",
        "arxiv_id": "2510.02049",
        "authors": "Jinshu Huang, Haibin Su, Xue-Cheng Tai, Chunlin Wu",
        "summary": "In deep learning, dense layer connectivity has become a key design principle in deep neural networks (DNNs), enabling efficient information flow and strong performance across a range of applications. In this work, we model densely connected DNNs mathematically and analyze their learning problems in the deep-layer limit. For a broad applicability, we present our analysis in a framework setting of DNNs with densely connected layers and general non-local feature transformations (with local feature transformations as special cases) within layers, which is called dense non-local (DNL) framework and includes standard DenseNets and variants as special examples. In this formulation, the densely connected networks are modeled as nonlinear integral equations, in contrast to the ordinary differential equation viewpoint commonly adopted in prior works. We study the associated training problems from an optimal control perspective and prove convergence results from the network learning problem to its continuous-time counterpart. In particular, we show the convergence of optimal values and the subsequence convergence of minimizers, using a piecewise linear extension and $\\Gamma$-convergence analysis. Our results provide a mathematical foundation for understanding densely connected DNNs and further suggest that such architectures can offer stability of training deep models.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.315686"
    },
    {
        "index": "#41",
        "title": "FairContrast: Enhancing Fairness through Contrastive learning and Customized Augmenting Methods on Tabular Data",
        "link": "/arxiv/2510.02017",
        "arxiv_id": "2510.02017",
        "authors": "Aida Tayebi, Ali Khodabandeh Yalabadi, Mehdi Yazdani-Jahromi, Ozlem Ozmen Garibay",
        "summary": "As AI systems become more embedded in everyday life, the development of fair and unbiased models becomes more critical. Considering the social impact of AI systems is not merely a technical challenge but a moral imperative. As evidenced in numerous research studies, learning fair and robust representations has proven to be a powerful approach to effectively debiasing algorithms and improving fairness while maintaining essential information for prediction tasks. Representation learning frameworks, particularly those that utilize self-supervised and contrastive learning, have demonstrated superior robustness and generalizability across various domains. Despite the growing interest in applying these approaches to tabular data, the issue of fairness in these learned representations remains underexplored. In this study, we introduce a contrastive learning framework specifically designed to address bias and learn fair representations in tabular datasets. By strategically selecting positive pair samples and employing supervised and self-supervised contrastive learning, we significantly reduce bias compared to existing state-of-the-art contrastive learning models for tabular data. Our results demonstrate the efficacy of our approach in mitigating bias with minimum trade-off in accuracy and leveraging the learned fair representations in various downstream tasks.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.316200"
    },
    {
        "index": "#42",
        "title": "Normality Calibration in Semi-supervised Graph Anomaly Detection",
        "link": "/arxiv/2510.02014",
        "arxiv_id": "2510.02014",
        "authors": "Guolei Zeng, Hezhe Qiao, Guoguo Ai, Jinsong Guo, Guansong Pang",
        "summary": "Graph anomaly detection (GAD) has attracted growing interest for its crucial ability to uncover irregular patterns in broad applications. Semi-supervised GAD, which assumes a subset of annotated normal nodes available during training, is among the most widely explored application settings. However, the normality learned by existing semi-supervised GAD methods is limited to the labeled normal nodes, often inclining to overfitting the given patterns. These can lead to high detection errors, such as high false positives. To overcome this limitation, we propose GraphNC , a graph normality calibration framework that leverages both labeled and unlabeled data to calibrate the normality from a teacher model (a pre-trained semi-supervised GAD model) jointly in anomaly score and node representation spaces. GraphNC includes two main components, anomaly score distribution alignment (ScoreDA) and perturbation-based normality regularization (NormReg). ScoreDA optimizes the anomaly scores of our model by aligning them with the score distribution yielded by the teacher model. Due to accurate scores in most of the normal nodes and part of the anomaly nodes in the teacher model, the score alignment effectively pulls the anomaly scores of the normal and abnormal classes toward the two ends, resulting in more separable anomaly scores. Nevertheless, there are inaccurate scores from the teacher model. To mitigate the misleading by these scores, NormReg is designed to regularize the graph normality in the representation space, making the representations of normal nodes more compact by minimizing a perturbation-guided consistency loss solely on the labeled nodes.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.316677"
    },
    {
        "index": "#43",
        "title": "PepCompass: Navigating peptide embedding spaces using Riemannian Geometry",
        "link": "/arxiv/2510.01988",
        "arxiv_id": "2510.01988",
        "authors": "Marcin Możejko, Adam Bielecki, Jurand Prądzyński, Marcin Traskowski, Antoni Janowski, Karol Jurasz, Michał Kucharczyk, Hyun-Su Lee, Marcelo Der Torossian Torres, Cesar de la Fuente-Nunez, Paulina Szymczak, Michał Kmicikiewicz, Ewa Szczurek",
        "summary": "Antimicrobial peptide discovery is challenged by the astronomical size of peptide space and the relative scarcity of active peptides. Generative models provide continuous latent \"maps\" of peptide space, but conventionally ignore decoder-induced geometry and rely on flat Euclidean metrics, rendering exploration and optimization distorted and inefficient. Prior manifold-based remedies assume fixed intrinsic dimensionality, which critically fails in practice for peptide data. Here, we introduce PepCompass, a geometry-aware framework for peptide exploration and optimization. At its core, we define a Union of $\\kappa$-Stable Riemannian Manifolds $\\mathbb{M}^{\\kappa}$, a family of decoder-induced manifolds that captures local geometry while ensuring computational stability. We propose two local exploration methods: Second-Order Riemannian Brownian Efficient Sampling, which provides a convergent second-order approximation to Riemannian Brownian motion, and Mutation Enumeration in Tangent Space, which reinterprets tangent directions as discrete amino-acid substitutions. Combining these yields Local Enumeration Bayesian Optimization (LE-BO), an efficient algorithm for local activity optimization. Finally, we introduce Potential-minimizing Geodesic Search (PoGS), which interpolates between prototype embeddings along property-enriched geodesics, biasing discovery toward seeds, i.e. peptides with favorable activity. In-vitro validation confirms the effectiveness of PepCompass: PoGS yields four novel seeds, and subsequent optimization with LE-BO discovers 25 highly active peptides with broad-spectrum activity, including against resistant bacterial strains. These results demonstrate that geometry-informed exploration provides a powerful new paradigm for antimicrobial peptide design.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.317275"
    },
    {
        "index": "#44",
        "title": "Private Federated Multiclass Post-hoc Calibration",
        "link": "/arxiv/2510.01987",
        "arxiv_id": "2510.01987",
        "authors": "Samuel Maddock, Graham Cormode, Carsten Maple",
        "summary": "Calibrating machine learning models so that predicted probabilities better reflect the true outcome frequencies is crucial for reliable decision-making across many applications. In Federated Learning (FL), the goal is to train a global model on data which is distributed across multiple clients and cannot be centralized due to privacy concerns. FL is applied in key areas such as healthcare and finance where calibration is strongly required, yet federated private calibration has been largely overlooked. This work introduces the integration of post-hoc model calibration techniques within FL. Specifically, we transfer traditional centralized calibration methods such as histogram binning and temperature scaling into federated environments and define new methods to operate them under strong client heterogeneity. We study (1) a federated setting and (2) a user-level Differential Privacy (DP) setting and demonstrate how both federation and DP impacts calibration accuracy. We propose strategies to mitigate degradation commonly observed under heterogeneity and our findings highlight that our federated temperature scaling works best for DP-FL whereas our weighted binning approach is best when DP is not required.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.317752"
    },
    {
        "index": "#45",
        "title": "$\\text{G}^2$RPO: Granular GRPO for Precise Reward in Flow Models",
        "link": "/arxiv/2510.01982",
        "arxiv_id": "2510.01982",
        "authors": "Yujie Zhou, Pengyang Ling, Jiazi Bu, Yibin Wang, Yuhang Zang, Jiaqi Wang, Li Niu, Guangtao Zhai",
        "summary": "The integration of online reinforcement learning (RL) into diffusion and flow models has recently emerged as a promising approach for aligning generative models with human preferences. Stochastic sampling via Stochastic Differential Equations (SDE) is employed during the denoising process to generate diverse denoising directions for RL exploration. While existing methods effectively explore potential high-value samples, they suffer from sub-optimal preference alignment due to sparse and narrow reward signals. To address these challenges, we propose a novel Granular-GRPO ($\\text{G}^2$RPO ) framework that achieves precise and comprehensive reward assessments of sampling directions in reinforcement learning of flow models. Specifically, a Singular Stochastic Sampling strategy is introduced to support step-wise stochastic exploration while enforcing a high correlation between the reward and the injected noise, thereby facilitating a faithful reward for each SDE perturbation. Concurrently, to eliminate the bias inherent in fixed-granularity denoising, we introduce a Multi-Granularity Advantage Integration module that aggregates advantages computed at multiple diffusion scales, producing a more comprehensive and robust evaluation of the sampling directions. Experiments conducted on various reward models, including both in-domain and out-of-domain evaluations, demonstrate that our $\\text{G}^2$RPO significantly outperforms existing flow-based GRPO baselines,highlighting its effectiveness and robustness.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.318286"
    },
    {
        "index": "#46",
        "title": "Moon: A Modality Conversion-based Efficient Multivariate Time Series Anomaly Detection",
        "link": "/arxiv/2510.01970",
        "arxiv_id": "2510.01970",
        "authors": "Yuanyuan Yao, Yuhan Shi, Lu Chen, Ziquan Fang, Yunjun Gao, Leong Hou U, Yushuai Li, Tianyi Li",
        "summary": "Multivariate time series (MTS) anomaly detection identifies abnormal patterns where each timestamp contains multiple variables. Existing MTS anomaly detection methods fall into three categories: reconstruction-based, prediction-based, and classifier-based methods. However, these methods face two key challenges: (1) Unsupervised learning methods, such as reconstruction-based and prediction-based methods, rely on error thresholds, which can lead to inaccuracies; (2) Semi-supervised methods mainly model normal data and often underuse anomaly labels, limiting detection of subtle anomalies;(3) Supervised learning methods, such as classifier-based approaches, often fail to capture local relationships, incur high computational costs, and are constrained by the scarcity of labeled data. To address these limitations, we propose Moon, a supervised modality conversion-based multivariate time series anomaly detection framework. Moon enhances the efficiency and accuracy of anomaly detection while providing detailed anomaly analysis reports. First, Moon introduces a novel multivariate Markov Transition Field (MV-MTF) technique to convert numeric time series data into image representations, capturing relationships across variables and timestamps. Since numeric data retains unique patterns that cannot be fully captured by image conversion alone, Moon employs a Multimodal-CNN to integrate numeric and image data through a feature fusion model with parameter sharing, enhancing training efficiency. Finally, a SHAP-based anomaly explainer identifies key variables contributing to anomalies, improving interpretability. Extensive experiments on six real-world MTS datasets demonstrate that Moon outperforms six state-of-the-art methods by up to 93% in efficiency, 4% in accuracy and, 10.8% in interpretation performance.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.318810"
    },
    {
        "index": "#47",
        "title": "Lower Bounds on Adversarial Robustness for Multiclass Classification with General Loss Functions",
        "link": "/arxiv/2510.01969",
        "arxiv_id": "2510.01969",
        "authors": "Camilo Andrés García Trillos, Nicolás García Trillos",
        "summary": "We consider adversarially robust classification in a multiclass setting under arbitrary loss functions and derive dual and barycentric reformulations of the corresponding learner-agnostic robust risk minimization problem. We provide explicit characterizations for important cases such as the cross-entropy loss, loss functions with a power form, and the quadratic loss, extending in this way available results for the 0-1 loss. These reformulations enable efficient computation of sharp lower bounds for adversarial risks and facilitate the design of robust classifiers beyond the 0-1 loss setting. Our paper uncovers interesting connections between adversarial robustness, $\\alpha$-fair packing problems, and generalized barycenter problems for arbitrary positive measures where Kullback-Leibler and Tsallis entropies are used as penalties. Our theoretical results are accompanied with illustrative numerical experiments where we obtain tighter lower bounds for adversarial risks with the cross-entropy loss function.",
        "subjects": "Machine Learning, Optimization and Control, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.319273"
    },
    {
        "index": "#48",
        "title": "StelLA: Subspace Learning in Low-rank Adaptation using Stiefel Manifold",
        "link": "/arxiv/2510.01938",
        "arxiv_id": "2510.01938",
        "authors": "Zhizhong Li, Sina Sajadmanesh, Jingtao Li, Lingjuan Lyu",
        "summary": "Low-rank adaptation (LoRA) has been widely adopted as a parameter-efficient technique for fine-tuning large-scale pre-trained models. However, it still lags behind full fine-tuning in performance, partly due to its insufficient exploitation of the geometric structure underlying low-rank manifolds. In this paper, we propose a geometry-aware extension of LoRA that uses a three-factor decomposition $U\\!SV^\\top$. Analogous to the structure of singular value decomposition (SVD), it separates the adapter's input and output subspaces, $V$ and $U$, from the scaling factor $S$. Our method constrains $U$ and $V$ to lie on the Stiefel manifold, ensuring their orthonormality throughout the training. To optimize on the Stiefel manifold, we employ a flexible and modular geometric optimization design that converts any Euclidean optimizer to a Riemannian one. It enables efficient subspace learning while remaining compatible with existing fine-tuning pipelines. Empirical results across a wide range of downstream tasks, including commonsense reasoning, math and code generation, image classification, and image generation, demonstrate the superior performance of our approach against the recent state-of-the-art variants of LoRA. Code is available at https://github.com/SonyResearch/stella.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.319745"
    },
    {
        "index": "#50",
        "title": "A Methodology for Transparent Logic-Based Classification Using a Multi-Task Convolutional Tsetlin Machine",
        "link": "/arxiv/2510.01906",
        "arxiv_id": "2510.01906",
        "authors": "Mayur Kishor Shende, Ole-Christoffer Granmo, Runar Helin, Vladimir I. Zadorozhny, Rishad Shafik",
        "summary": "The Tsetlin Machine (TM) is a novel machine learning paradigm that employs finite-state automata for learning and utilizes propositional logic to represent patterns. Due to its simplistic approach, TMs are inherently more interpretable than learning algorithms based on Neural Networks. The Convolutional TM has shown comparable performance on various datasets such as MNIST, K-MNIST, F-MNIST and CIFAR-2. In this paper, we explore the applicability of the TM architecture for large-scale multi-channel (RGB) image classification. We propose a methodology to generate both local interpretations and global class representations. The local interpretations can be used to explain the model predictions while the global class representations aggregate important patterns for each class. These interpretations summarize the knowledge captured by the convolutional clauses, which can be visualized as images. We evaluate our methods on MNIST and CelebA datasets, using models that achieve 98.5\\% accuracy on MNIST and 86.56\\% F1-score on CelebA (compared to 88.07\\% for ResNet50) respectively. We show that the TM performs competitively to this deep learning model while maintaining its interpretability, even in large-scale complex training environments. This contributes to a better understanding of TM clauses and provides insights into how these models can be applied to more complex and diverse datasets.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.325842"
    },
    {
        "index": "#52",
        "title": "Multi-marginal temporal Schrödinger Bridge Matching for video generation from unpaired data",
        "link": "/arxiv/2510.01894",
        "arxiv_id": "2510.01894",
        "authors": "Thomas Gravier, Thomas Boyer, Auguste Genovesio",
        "summary": "Many natural dynamic processes -- such as in vivo cellular differentiation or disease progression -- can only be observed through the lens of static sample snapshots. While challenging, reconstructing their temporal evolution to decipher underlying dynamic properties is of major interest to scientific research. Existing approaches enable data transport along a temporal axis but are poorly scalable in high dimension and require restrictive assumptions to be met. To address these issues, we propose \\textit{\\textbf{Multi-Marginal temporal Schrödinger Bridge Matching}} (\\textbf{MMtSBM}) \\textit{for video generation from unpaired data}, extending the theoretical guarantees and empirical efficiency of Diffusion Schrödinger Bridge Matching (arXiv:archive/2303.16852) by deriving the Iterative Markovian Fitting algorithm to multiple marginals in a novel factorized fashion. Experiments show that MMtSBM retains theoretical properties on toy examples, achieves state-of-the-art performance on real world datasets such as transcriptomic trajectory inference in 100 dimensions, and for the first time recovers couplings and dynamics in very high dimensional image settings. Our work establishes multi-marginal Schrödinger bridges as a practical and principled approach for recovering hidden dynamics from static data.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.326768"
    },
    {
        "index": "#53",
        "title": "Randomized Gradient Subspaces for Efficient Large Language Model Training",
        "link": "/arxiv/2510.01878",
        "arxiv_id": "2510.01878",
        "authors": "Sahar Rajabi, Nayeema Nonta, Samanvay Vajpayee, Sirisha Rambhatla",
        "summary": "Training large language models (LLMs) is often bottlenecked by extreme memory demands, with optimizer states dominating the footprint. Recent works mitigates this cost by projecting gradients into low-dimensional subspaces using sophisticated update strategies. In this paper, we analyze the dynamics of gradient space and its underlying subspaces. We find that while a small subspace captures most gradient energy, a significant portion still resides in the residual bulk; moreover, the influence of the core subspace diminishes over time and in deeper layers. We also observe that the gradient space exhibits near-flat curvature, calling for algorithms that explicitly account for this geometry. Motivated by these insights, we introduce a suite of randomized algorithms, GrassWalk and GrassJump, which exploit subspace and achieve state-of-the-art memory savings while improving performance on LLaMA-1B and LLaMA-7B pretraining.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.327222"
    },
    {
        "index": "#54",
        "title": "Universal Dynamic Regret and Constraint Violation Bounds for Constrained Online Convex Optimization",
        "link": "/arxiv/2510.01867",
        "arxiv_id": "2510.01867",
        "authors": "Subhamon Supantha, Abhishek Sinha",
        "summary": "We consider a generalization of the celebrated Online Convex Optimization (OCO) framework with online adversarial constraints. We present two algorithms having simple modular structures that yield universal dynamic regret and cumulative constraint violation bounds, improving upon the state-of-the-art results. Our results hold in the most general case when both the cost and constraint functions are chosen arbitrarily by an adversary, and the constraint functions need not contain any common feasible point. The results are established by reducing the constrained learning problem to an instance of the standard OCO problem with specially constructed surrogate cost functions.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.327649"
    },
    {
        "index": "#55",
        "title": "Compositional meta-learning through probabilistic task inference",
        "link": "/arxiv/2510.01858",
        "arxiv_id": "2510.01858",
        "authors": "Jacob J. W. Bakermans, Pablo Tano, Reidar Riveland, Charles Findling, Alexandre Pouget",
        "summary": "To solve a new task from minimal experience, it is essential to effectively reuse knowledge from previous tasks, a problem known as meta-learning. Compositional solutions, where common elements of computation are flexibly recombined into new configurations, are particularly well-suited for meta-learning. Here, we propose a compositional meta-learning model that explicitly represents tasks as structured combinations of reusable computations. We achieve this by learning a generative model that captures the underlying components and their statistics shared across a family of tasks. This approach transforms learning a new task into a probabilistic inference problem, which allows for finding solutions without parameter updates through highly constrained hypothesis testing. Our model successfully recovers ground truth components and statistics in rule learning and motor learning tasks. We then demonstrate its ability to quickly infer new solutions from just single examples. Together, our framework joins the expressivity of neural networks with the data-efficiency of probabilistic inference to achieve rapid compositional meta-learning.",
        "subjects": "Machine Learning, Neurons and Cognition",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.328180"
    },
    {
        "index": "#56",
        "title": "Explicit Discovery of Nonlinear Symmetries from Dynamic Data",
        "link": "/arxiv/2510.01855",
        "arxiv_id": "2510.01855",
        "authors": "Lexiang Hu, Yikang Li, Zhouchen Lin",
        "summary": "Symmetry is widely applied in problems such as the design of equivariant networks and the discovery of governing equations, but in complex scenarios, it is not known in advance. Most previous symmetry discovery methods are limited to linear symmetries, and recent attempts to discover nonlinear symmetries fail to explicitly get the Lie algebra subspace. In this paper, we propose LieNLSD, which is, to our knowledge, the first method capable of determining the number of infinitesimal generators with nonlinear terms and their explicit expressions. We specify a function library for the infinitesimal group action and aim to solve for its coefficient matrix, proving that its prolongation formula for differential equations, which governs dynamic data, is also linear with respect to the coefficient matrix. By substituting the central differences of the data and the Jacobian matrix of the trained neural network into the infinitesimal criterion, we get a system of linear equations for the coefficient matrix, which can then be solved using SVD. On top quark tagging and a series of dynamic systems, LieNLSD shows qualitative advantages over existing methods and improves the long rollout accuracy of neural PDE solvers by over 20% while applying to guide data augmentation. Code and data are available at https://github.com/hulx2002/LieNLSD.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.328630"
    },
    {
        "index": "#57",
        "title": "Learning Representations Through Contrastive Neural Model Checking",
        "link": "/arxiv/2510.01853",
        "arxiv_id": "2510.01853",
        "authors": "Vladimir Krsmanovic, Matthias Cosler, Mohamed Ghanem, Bernd Finkbeiner",
        "summary": "Model checking is a key technique for verifying safety-critical systems against formal specifications, where recent applications of deep learning have shown promise. However, while ubiquitous for vision and language domains, representation learning remains underexplored in formal verification. We introduce Contrastive Neural Model Checking (CNML), a novel method that leverages the model checking task as a guiding signal for learning aligned representations. CNML jointly embeds logical specifications and systems into a shared latent space through a self-supervised contrastive objective. On industry-inspired retrieval tasks, CNML considerably outperforms both algorithmic and neural baselines in cross-modal and intra-modal settings.We further show that the learned representations effectively transfer to downstream tasks and generalize to more complex formulas. These findings demonstrate that model checking can serve as an objective for learning representations for formal languages.",
        "subjects": "Machine Learning, Logic in Computer Science",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.329113"
    },
    {
        "index": "#59",
        "title": "Black-Box Combinatorial Optimization with Order-Invariant Reinforcement Learning",
        "link": "/arxiv/2510.01824",
        "arxiv_id": "2510.01824",
        "authors": "Olivier Goudet, Quentin Suire, Adrien Goëffon, Frédéric Saubion, Sylvain Lamprier",
        "summary": "We introduce an order-invariant reinforcement learning framework for black-box combinatorial optimization. Classical estimation-of-distribution algorithms (EDAs) often rely on learning explicit variable dependency graphs, which can be costly and fail to capture complex interactions efficiently. In contrast, we parameterize a multivariate autoregressive generative model trained without a fixed variable ordering. By sampling random generation orders during training - a form of information-preserving dropout - the model is encouraged to be invariant to variable order, promoting search-space diversity and shaping the model to focus on the most relevant variable dependencies, improving sample efficiency. We adapt Generalized Reinforcement Policy Optimization (GRPO) to this setting, providing stable policy-gradient updates from scale-invariant advantages. Across a wide range of benchmark algorithms and problem instances of varying sizes, our method frequently achieves the best performance and consistently avoids catastrophic failures.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.330085"
    },
    {
        "index": "#62",
        "title": "Sensitivity, Specificity, and Consistency: A Tripartite Evaluation of Privacy Filters for Synthetic Data Generation",
        "link": "/arxiv/2510.01793",
        "arxiv_id": "2510.01793",
        "authors": "Adil Koeken, Alexander Ziller, Moritz Knolle, Daniel Rueckert",
        "summary": "The generation of privacy-preserving synthetic datasets is a promising avenue for overcoming data scarcity in medical AI research. Post-hoc privacy filtering techniques, designed to remove samples containing personally identifiable information, have recently been proposed as a solution. However, their effectiveness remains largely unverified. This work presents a rigorous evaluation of a filtering pipeline applied to chest X-ray synthesis. Contrary to claims from the original publications, our results demonstrate that current filters exhibit limited specificity and consistency, achieving high sensitivity only for real images while failing to reliably detect near-duplicates generated from training data. These results demonstrate a critical limitation of post-hoc filtering: rather than effectively safeguarding patient privacy, these methods may provide a false sense of security while leaving unacceptable levels of patient information exposed. We conclude that substantial advances in filter design are needed before these methods can be confidently deployed in sensitive applications.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.336633"
    },
    {
        "index": "#63",
        "title": "Neural non-canonical Hamiltonian dynamics for long-time simulations",
        "link": "/arxiv/2510.01788",
        "arxiv_id": "2510.01788",
        "authors": "Clémentine Courtès, Emmanuel Franck, Michael Kraus, Laurent Navoret, Léopold Trémant",
        "summary": "This work focuses on learning non-canonical Hamiltonian dynamics from data, where long-term predictions require the preservation of structure both in the learned model and in numerical schemes. Previous research focused on either facet, respectively with a potential-based architecture and with degenerate variational integrators, but new issues arise when combining both. In experiments, the learnt model is sometimes numerically unstable due to the gauge dependency of the scheme, rendering long-time simulations impossible. In this paper, we identify this problem and propose two different training strategies to address it, either by directly learning the vector field or by learning a time-discrete dynamics through the scheme. Several numerical test cases assess the ability of the methods to learn complex physical dynamics, like the guiding center from gyrokinetic plasma physics.",
        "subjects": "Machine Learning, Numerical Analysis",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.337173"
    },
    {
        "index": "#64",
        "title": "Octax: Accelerated CHIP-8 Arcade Environments for Reinforcement Learning in JAX",
        "link": "/arxiv/2510.01764",
        "arxiv_id": "2510.01764",
        "authors": "Waris Radji, Thomas Michel, Hector Piteau",
        "summary": "Reinforcement learning (RL) research requires diverse, challenging environments that are both tractable and scalable. While modern video games may offer rich dynamics, they are computationally expensive and poorly suited for large-scale experimentation due to their CPU-bound execution. We introduce Octax, a high-performance suite of classic arcade game environments implemented in JAX, based on CHIP-8 emulation, a predecessor to Atari, which is widely adopted as a benchmark in RL research. Octax provides the JAX community with a long-awaited end-to-end GPU alternative to the Atari benchmark, offering image-based environments, spanning puzzle, action, and strategy genres, all executable at massive scale on modern GPUs. Our JAX-based implementation achieves orders-of-magnitude speedups over traditional CPU emulators while maintaining perfect fidelity to the original game mechanics. We demonstrate Octax's capabilities by training RL agents across multiple games, showing significant improvements in training speed and scalability compared to existing solutions. The environment's modular design enables researchers to easily extend the suite with new games or generate novel environments using large language models, making it an ideal platform for large-scale RL experimentation.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.337612"
    },
    {
        "index": "#66",
        "title": "Learning Regularization Functionals for Inverse Problems: A Comparative Study",
        "link": "/arxiv/2510.01755",
        "arxiv_id": "2510.01755",
        "authors": "Johannes Hertrich, Hok Shing Wong, Alexander Denker, Stanislas Ducotterd, Zhenghan Fang, Markus Haltmeier, Željko Kereta, Erich Kobler, Oscar Leong, Mohammad Sadegh Salehi, Carola-Bibiane Schönlieb, Johannes Schwab, Zakhar Shumaylov, Jeremias Sulam, German Shâma Wache, Martin Zach, Yasi Zhang, Matthias J. Ehrhardt, Sebastian Neumayer",
        "summary": "In recent years, a variety of learned regularization frameworks for solving inverse problems in imaging have emerged. These offer flexible modeling together with mathematical insights. The proposed methods differ in their architectural design and training strategies, making direct comparison challenging due to non-modular implementations. We address this gap by collecting and unifying the available code into a common framework. This unified view allows us to systematically compare the approaches and highlight their strengths and limitations, providing valuable insights into their future potential. We also provide concise descriptions of each method, complemented by practical guidelines.",
        "subjects": "Machine Learning, Numerical Analysis, Optimization and Control",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.338813"
    },
    {
        "index": "#67",
        "title": "Private and Fair Machine Learning: Revisiting the Disparate Impact of Differentially Private SGD",
        "link": "/arxiv/2510.01744",
        "arxiv_id": "2510.01744",
        "authors": "Lea Demelius, Dominik Kowald, Simone Kopeinik, Roman Kern, Andreas Trügler",
        "summary": "Differential privacy (DP) is a prominent method for protecting information about individuals during data analysis. Training neural networks with differentially private stochastic gradient descent (DPSGD) influences the model's learning dynamics and, consequently, its output. This can affect the model's performance and fairness. While the majority of studies on the topic report a negative impact on fairness, it has recently been suggested that fairness levels comparable to non-private models can be achieved by optimizing hyperparameters for performance directly on differentially private models (rather than re-using hyperparameters from non-private models, as is common practice). In this work, we analyze the generalizability of this claim by 1) comparing the disparate impact of DPSGD on different performance metrics, and 2) analyzing it over a wide range of hyperparameter settings. We highlight that a disparate impact on one metric does not necessarily imply a disparate impact on another. Most importantly, we show that while optimizing hyperparameters directly on differentially private models does not mitigate the disparate impact of DPSGD reliably, it can still lead to improved utility-fairness trade-offs compared to re-using hyperparameters from non-private models. We stress, however, that any form of hyperparameter tuning entails additional privacy leakage, calling for careful considerations of how to balance privacy, utility and fairness. Finally, we extend our analyses to DPSGD-Global-Adapt, a variant of DPSGD designed to mitigate the disparate impact on accuracy, and conclude that this alternative may not be a robust solution with respect to hyperparameter choice.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.339290"
    },
    {
        "index": "#68",
        "title": "Workplace Location Choice Model based on Deep Neural Network",
        "link": "/arxiv/2510.01723",
        "arxiv_id": "2510.01723",
        "authors": "Tanay Rastogi, Anders Karlström",
        "summary": "Discrete choice models (DCMs) have long been used to analyze workplace location decisions, but they face challenges in accurately mirroring individual decision-making processes. This paper presents a deep neural network (DNN) method for modeling workplace location choices, which aims to better understand complex decision patterns and provides better results than traditional discrete choice models (DCMs). The study demonstrates that DNNs show significant potential as a robust alternative to DCMs in this domain. While both models effectively replicate the impact of job opportunities on workplace location choices, the DNN outperforms the DCM in certain aspects. However, the DCM better aligns with data when assessing the influence of individual attributes on workplace distance. Notably, DCMs excel at shorter distances, while DNNs perform comparably to both data and DCMs for longer distances. These findings underscore the importance of selecting the appropriate model based on specific application requirements in workplace location choice analysis.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.339715"
    },
    {
        "index": "#69",
        "title": "Finite-Time Bounds for Distributionally Robust TD Learning with Linear Function Approximation",
        "link": "/arxiv/2510.01721",
        "arxiv_id": "2510.01721",
        "authors": "Saptarshi Mandal, Yashaswini Murthy, R. Srikant",
        "summary": "Distributionally robust reinforcement learning (DRRL) focuses on designing policies that achieve good performance under model uncertainties. In particular, we are interested in maximizing the worst-case long-term discounted reward, where the data for RL comes from a nominal model while the deployed environment can deviate from the nominal model within a prescribed uncertainty set. Existing convergence guarantees for robust temporal-difference (TD) learning for policy evaluation are limited to tabular MDPs or are dependent on restrictive discount-factor assumptions when function approximation is used. We present the first robust TD learning with linear function approximation, where robustness is measured with respect to the total-variation distance and Wasserstein-l distance uncertainty set. Additionally, our algorithm is both model-free and does not require generative access to the MDP. Our algorithm combines a two-time-scale stochastic-approximation update with an outer-loop target-network update. We establish an $\\tilde{O}(1/\\epsilon^2)$ sample complexity to obtain an $\\epsilon$-accurate value estimate. Our results close a key gap between the empirical success of robust RL algorithms and the non-asymptotic guarantees enjoyed by their non-robust counterparts. The key ideas in the paper also extend in a relatively straightforward fashion to robust Q-learning with function approximation.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.340184"
    },
    {
        "index": "#70",
        "title": "Accelerating Attention with Basis Decomposition",
        "link": "/arxiv/2510.01718",
        "arxiv_id": "2510.01718",
        "authors": "Jialin Zhao",
        "summary": "Attention is a core operation in large language models (LLMs) and vision-language models (VLMs). We present BD Attention (BDA), the first lossless algorithmic reformulation of attention. BDA is enabled by a simple matrix identity from Basis Decomposition (BD), which restructures multi-head projections into a compact form while preserving exact outputs. Unlike I/O-aware system optimizations such as FlashAttention, BDA provides a mathematically guaranteed acceleration that is architecture-agnostic. On DeepSeek-V2-Lite (16B, FP16), BDA requires only 4s of offline preparation with no retraining required and, on modern GPUs, achieves 32% faster key/value projections and 25% smaller weights, while increasing end-to-end perplexity (PPL) by just 0.02% (FP16) or 0.0004% (FP32), a negligible effect on model performance. These results position BDA as the first theoretically exact method for lossless attention acceleration that is complementary to existing engineering-level optimizations. Our code is available at https://github.com/abcbdf/basis-decomposition-official.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.340613"
    },
    {
        "index": "#72",
        "title": "ActiNet: Activity intensity classification of wrist-worn accelerometers using self-supervised deep learning",
        "link": "/arxiv/2510.01712",
        "arxiv_id": "2510.01712",
        "authors": "Aidan Acquah, Shing Chan, Aiden Doherty",
        "summary": "The use of reliable and accurate human activity recognition (HAR) models on passively collected wrist-accelerometer data is essential in large-scale epidemiological studies that investigate the association between physical activity and health outcomes. While the use of self-supervised learning has generated considerable excitement in improving HAR, it remains unknown the extent to which these models, coupled with hidden Markov models (HMMs), would make a tangible improvement to classification performance, and the effect this may have on the predicted daily activity intensity compositions. Using 151 CAPTURE-24 participants' data, we trained the ActiNet model, a self-supervised, 18-layer, modified ResNet-V2 model, followed by hidden Markov model (HMM) smoothing to classify labels of activity intensity. The performance of this model, evaluated using 5-fold stratified group cross-validation, was then compared to a baseline random forest (RF) + HMM, established in existing literature. Differences in performance and classification outputs were compared with different subgroups of age and sex within the Capture-24 population. The ActiNet model was able to distinguish labels of activity intensity with a mean macro F1 score of 0.82, and mean Cohen's kappa score of 0.86. This exceeded the performance of the RF + HMM, trained and validated on the same dataset, with mean scores of 0.77 and 0.81, respectively. These findings were consistent across subgroups of age and sex. These findings encourage the use of ActiNet for the extraction of activity intensity labels from wrist-accelerometer data in future epidemiological studies.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.346797"
    },
    {
        "index": "#74",
        "title": "PASTA: A Unified Framework for Offline Assortment Learning",
        "link": "/arxiv/2510.01693",
        "arxiv_id": "2510.01693",
        "authors": "Juncheng Dong, Weibin Mo, Zhengling Qi, Cong Shi, Ethan X. Fang, Vahid Tarokh",
        "summary": "We study a broad class of assortment optimization problems in an offline and data-driven setting. In such problems, a firm lacks prior knowledge of the underlying choice model, and aims to determine an optimal assortment based on historical customer choice data. The combinatorial nature of assortment optimization often results in insufficient data coverage, posing a significant challenge in designing provably effective solutions. To address this, we introduce a novel Pessimistic Assortment Optimization (PASTA) framework that leverages the principle of pessimism to achieve optimal expected revenue under general choice models. Notably, PASTA requires only that the offline data distribution contains an optimal assortment, rather than providing the full coverage of all feasible assortments. Theoretically, we establish the first finite-sample regret bounds for offline assortment optimization across several widely used choice models, including the multinomial logit and nested logit models. Additionally, we derive a minimax regret lower bound, proving that PASTA is minimax optimal in terms of sample and model complexity. Numerical experiments further demonstrate that our method outperforms existing baseline approaches.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.347772"
    },
    {
        "index": "#75",
        "title": "Beyond Simple Fusion: Adaptive Gated Fusion for Robust Multimodal Sentiment Analysis",
        "link": "/arxiv/2510.01677",
        "arxiv_id": "2510.01677",
        "authors": "Han Wu, Yanming Sun, Yunhe Yang, Derek F. Wong",
        "summary": "Multimodal sentiment analysis (MSA) leverages information fusion from diverse modalities (e.g., text, audio, visual) to enhance sentiment prediction. However, simple fusion techniques often fail to account for variations in modality quality, such as those that are noisy, missing, or semantically conflicting. This oversight leads to suboptimal performance, especially in discerning subtle emotional nuances. To mitigate this limitation, we introduce a simple yet efficient \\textbf{A}daptive \\textbf{G}ated \\textbf{F}usion \\textbf{N}etwork that adaptively adjusts feature weights via a dual gate fusion mechanism based on information entropy and modality importance. This mechanism mitigates the influence of noisy modalities and prioritizes informative cues following unimodal encoding and cross-modal interaction. Experiments on CMU-MOSI and CMU-MOSEI show that AGFN significantly outperforms strong baselines in accuracy, effectively discerning subtle emotions with robust performance. Visualization analysis of feature representations demonstrates that AGFN enhances generalization by learning from a broader feature distribution, achieved by reducing the correlation between feature location and prediction error, thereby decreasing reliance on specific locations and creating more robust multimodal feature representations.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.348245"
    },
    {
        "index": "#81",
        "title": "Support Basis: Fast Attention Beyond Bounded Entries",
        "link": "/arxiv/2510.01643",
        "arxiv_id": "2510.01643",
        "authors": "Maryam Aliakbarpour, Vladimir Braverman, Junze Yin, Haochen Zhang",
        "summary": "The quadratic complexity of softmax attention remains a central bottleneck in scaling large language models (LLMs). [Alman and Song, NeurIPS 2023] proposed a sub-quadratic attention approximation algorithm, but it works only under the restrictive bounded-entry assumption. Since this assumption rarely holds in practice, its applicability to modern LLMs is limited. In this paper, we introduce support-basis decomposition, a new framework for efficient attention approximation beyond bounded entries. We empirically demonstrate that the entries of the query and key matrices exhibit sub-Gaussian behavior. Our approach uses this property to split large and small entries, enabling exact computation on sparse components and polynomial approximation on dense components. We establish rigorous theoretical guarantees, proving a sub-quadratic runtime, and extend the method to a multi-threshold setting that eliminates all distributional assumptions. Furthermore, we provide the first theoretical justification for the empirical success of polynomial attention [Kacham, Mirrokni, and Zhong, ICML 2024], showing that softmax attention can be closely approximated by a combination of multiple polynomial attentions with sketching.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.351291"
    },
    {
        "index": "#82",
        "title": "Detecting Post-generation Edits to Watermarked LLM Outputs via Combinatorial Watermarking",
        "link": "/arxiv/2510.01637",
        "arxiv_id": "2510.01637",
        "authors": "Liyan Xie, Muhammad Siddeek, Mohamed Seif, Andrea J. Goldsmith, Mengdi Wang",
        "summary": "Watermarking has become a key technique for proprietary language models, enabling the distinction between AI-generated and human-written text. However, in many real-world scenarios, LLM-generated content may undergo post-generation edits, such as human revisions or even spoofing attacks, making it critical to detect and localize such modifications. In this work, we introduce a new task: detecting post-generation edits locally made to watermarked LLM outputs. To this end, we propose a combinatorial pattern-based watermarking framework, which partitions the vocabulary into disjoint subsets and embeds the watermark by enforcing a deterministic combinatorial pattern over these subsets during generation. We accompany the combinatorial watermark with a global statistic that can be used to detect the watermark. Furthermore, we design lightweight local statistics to flag and localize potential edits. We introduce two task-specific evaluation metrics, Type-I error rate and detection accuracy, and evaluate our method on open-source LLMs across a variety of editing scenarios, demonstrating strong empirical performance in edit localization.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.356869"
    },
    {
        "index": "#83",
        "title": "CAT: Curvature-Adaptive Transformers for Geometry-Aware Learning",
        "link": "/arxiv/2510.01634",
        "arxiv_id": "2510.01634",
        "authors": "Ryan Y. Lin, Siddhartha Ojha, Nicholas Bai",
        "summary": "Transformers achieve strong performance across diverse domains but implicitly assume Euclidean geometry in their attention mechanisms, limiting their effectiveness on data with non-Euclidean structure. While recent extensions to hyperbolic and spherical spaces show promise for hierarchical and cyclical patterns, respectively, they require committing to a single geometry a priori, reducing flexibility when data exhibits mixed geometric properties. We introduce the Curvature-Adaptive Transformer (CAT), a novel architecture that dynamically learns per-token routing across three geometric attention branches through a lightweight, differentiable gating mechanism. Unlike fixed-geometry approaches, CAT enables adaptive geometric specialization, routing tokens to the appropriate curvature based on their local relational structure. The routing network provides interpretable curvature preferences while each branch employs geometry-specific operations optimized for its respective manifold. On knowledge graph completion benchmarks (FB15k-237, WN18RR), CAT achieves approximately 10% improvements in MRR and Hits@10 over fixed-geometry baselines with minimal overhead (5% parameter increase, comparable inference time). These results demonstrate that learned geometric adaptation outperforms any single fixed geometry for complex relational reasoning, establishing CAT as a scalable and interpretable foundation for mixture-of-geometry architectures across language, vision, and multimodal domains.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.357320"
    },
    {
        "index": "#86",
        "title": "Posterior Collapse as a Phase Transition in Variational Autoencoders",
        "link": "/arxiv/2510.01621",
        "arxiv_id": "2510.01621",
        "authors": "Zhen Li, Fan Zhang, Zheng Zhang, Yu Chen",
        "summary": "We investigate the phenomenon of posterior collapse in variational autoencoders (VAEs) from the perspective of statistical physics, and reveal that it constitutes a phase transition governed jointly by data structure and model hyper-parameters. By analyzing the stability of the trivial solution associated with posterior collapse, we identify a critical hyper-parameter threshold. This critical boundary, separating meaningful latent inference from collapse, is characterized by a discontinuity in the KL divergence between the approximate posterior and the prior distribution. We validate this critical behavior on both synthetic and real-world datasets, confirming the existence of a phase transition. Our results demonstrate that posterior collapse is not merely an optimization failure, but rather an emerging phase transition arising from the interplay between data structure and variational constraints. This perspective offers new insights into the trainability and representational capacity of deep generative models.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.358912"
    },
    {
        "index": "#87",
        "title": "Securing generative artificial intelligence with parallel magnetic tunnel junction true randomness",
        "link": "/arxiv/2510.01598",
        "arxiv_id": "2510.01598",
        "authors": "Youwei Bao, Shuhan Yang, Hyunsoo Yang",
        "summary": "Deterministic pseudo random number generators (PRNGs) used in generative artificial intelligence (GAI) models produce predictable patterns vulnerable to exploitation by attackers. Conventional defences against the vulnerabilities often come with significant energy and latency overhead. Here, we embed hardware-generated true random bits from spin-transfer torque magnetic tunnel junctions (STT-MTJs) to address the challenges. A highly parallel, FPGA-assisted prototype computing system delivers megabit-per-second true random numbers, passing NIST randomness tests after in-situ operations with minimal overhead. Integrating the hardware random bits into a generative adversarial network (GAN) trained on CIFAR-10 reduces insecure outputs by up to 18.6 times compared to the low-quality random number generators (RNG) baseline. With nanosecond switching speed, high energy efficiency, and established scalability, our STT-MTJ-based system holds the potential to scale beyond 106 parallel cells, achieving gigabit-per-second throughput suitable for large language model sampling. This advancement highlights spintronic RNGs as practical security components for next-generation GAI systems.",
        "subjects": "Machine Learning, Materials Science, Data Analysis, Statistics and Probability",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.359390"
    },
    {
        "index": "#90",
        "title": "Gradient Shaping Beyond Clipping: A Functional Perspective on Update Magnitude Control",
        "link": "/arxiv/2510.01578",
        "arxiv_id": "2510.01578",
        "authors": "Haochen You, Baojing Liu",
        "summary": "Gradient clipping is widely used to stabilize deep network training, but its formulation as a hard, fixed threshold limits flexibility and ignores gradient distribution dynamics. We propose SPAMP (Statistical Per-layer Adaptive Modulation and Projection), a unified framework that generalizes clipping into smooth, per-layer gradient shaping. SPAMP tracks local gradient statistics, dynamically estimates thresholds, and applies power-based transformations to modulate update magnitudes in a differentiable manner. This perspective recasts clipping and warmup as dual mechanisms for controlling the effective update scale $\\eta_t \\|g_t\\|$, offering a principled alternative to rigid heuristics. Extensive experiments across image and language tasks demonstrate that SPAMP improves stability, convergence, and robustness over existing methods.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.360858"
    },
    {
        "index": "#92",
        "title": "TetriServe: Efficient DiT Serving for Heterogeneous Image Generation",
        "link": "/arxiv/2510.01565",
        "arxiv_id": "2510.01565",
        "authors": "Runyu Lu, Shiqi He, Wenxuan Tan, Shenggui Li, Ruofan Wu, Jeff J. Ma, Ang Chen, Mosharaf Chowdhury",
        "summary": "Diffusion Transformer (DiT) models excel at generating highquality images through iterative denoising steps, but serving them under strict Service Level Objectives (SLOs) is challenging due to their high computational cost, particularly at large resolutions. Existing serving systems use fixed degree sequence parallelism, which is inefficient for heterogeneous workloads with mixed resolutions and deadlines, leading to poor GPU utilization and low SLO attainment. In this paper, we propose step-level sequence parallelism to dynamically adjust the parallel degree of individual requests according to their deadlines. We present TetriServe, a DiT serving system that implements this strategy for highly efficient image generation. Specifically, TetriServe introduces a novel round-based scheduling mechanism that improves SLO attainment: (1) discretizing time into fixed rounds to make deadline-aware scheduling tractable, (2) adapting parallelism at the step level and minimize GPU hour consumption, and (3) jointly packing requests to minimize late completions. Extensive evaluation on state-of-the-art DiT models shows that TetriServe achieves up to 32% higher SLO attainment compared to existing solutions without degrading image quality.",
        "subjects": "Machine Learning, Distributed, Parallel, and Cluster Computing",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.367189"
    },
    {
        "index": "#93",
        "title": "Large-Scale Bayesian Causal Discovery with Interventional Data",
        "link": "/arxiv/2510.01562",
        "arxiv_id": "2510.01562",
        "authors": "Seong Woo Han, Daniel Duy Vo, Brielin C. Brown",
        "summary": "Inferring the causal relationships among a set of variables in the form of a directed acyclic graph (DAG) is an important but notoriously challenging problem. Recently, advancements in high-throughput genomic perturbation screens have inspired development of methods that leverage interventional data to improve model identification. However, existing methods still suffer poor performance on large-scale tasks and fail to quantify uncertainty. Here, we propose Interventional Bayesian Causal Discovery (IBCD), an empirical Bayesian framework for causal discovery with interventional data. Our approach models the likelihood of the matrix of total causal effects, which can be approximated by a matrix normal distribution, rather than the full data matrix. We place a spike-and-slab horseshoe prior on the edges and separately learn data-driven weights for scale-free and Erdős-Rényi structures from observational data, treating each edge as a latent variable to enable uncertainty-aware inference. Through extensive simulation, we show that IBCD achieves superior structure recovery compared to existing baselines. We apply IBCD to CRISPR perturbation (Perturb-seq) data on 521 genes, demonstrating that edge posterior inclusion probabilities enable identification of robust graph structures.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.367631"
    },
    {
        "index": "#95",
        "title": "MIRA: Towards Mitigating Reward Hacking in Inference-Time Alignment of T2I Diffusion Models",
        "link": "/arxiv/2510.01549",
        "arxiv_id": "2510.01549",
        "authors": "Kevin Zhai, Utsav Singh, Anirudh Thatipelli, Souradip Chakraborty, Anit Kumar Sahu, Furong Huang, Amrit Singh Bedi, Mubarak Shah",
        "summary": "Diffusion models excel at generating images conditioned on text prompts, but the resulting images often do not satisfy user-specific criteria measured by scalar rewards such as Aesthetic Scores. This alignment typically requires fine-tuning, which is computationally demanding. Recently, inference-time alignment via noise optimization has emerged as an efficient alternative, modifying initial input noise to steer the diffusion denoising process towards generating high-reward images. However, this approach suffers from reward hacking, where the model produces images that score highly, yet deviate significantly from the original prompt. We show that noise-space regularization is insufficient and that preventing reward hacking requires an explicit image-space constraint. To this end, we propose MIRA (MItigating Reward hAcking), a training-free, inference-time alignment method. MIRA introduces an image-space, score-based KL surrogate that regularizes the sampling trajectory with a frozen backbone, constraining the output distribution so reward can increase without off-distribution drift (reward hacking). We derive a tractable approximation to KL using diffusion scores. Across SDv1.5 and SDXL, multiple rewards (Aesthetic, HPSv2, PickScore), and public datasets (e.g., Animal-Animal, HPDv2), MIRA achieves >60\\% win rate vs. strong baselines while preserving prompt adherence; mechanism plots show reward gains with near-zero drift, whereas DNO drifts as compute increases. We further introduce MIRA-DPO, mapping preference optimization to inference time with a frozen backbone, extending MIRA to non-differentiable rewards without fine-tuning.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.368623"
    },
    {
        "index": "#97",
        "title": "Executable Counterfactuals: Improving LLMs' Causal Reasoning Through Code",
        "link": "/arxiv/2510.01539",
        "arxiv_id": "2510.01539",
        "authors": "Aniket Vashishtha, Qirun Dai, Hongyuan Mei, Amit Sharma, Chenhao Tan, Hao Peng",
        "summary": "Counterfactual reasoning, a hallmark of intelligence, consists of three steps: inferring latent variables from observations (abduction), constructing alternatives (interventions), and predicting their outcomes (prediction). This skill is essential for advancing LLMs' causal understanding and expanding their applications in high-stakes domains such as scientific research. However, existing efforts in assessing LLM's counterfactual reasoning capabilities tend to skip the abduction step, effectively reducing to interventional reasoning and leading to overestimation of LLM performance. To address this, we introduce executable counterfactuals, a novel framework that operationalizes causal reasoning through code and math problems. Our framework explicitly requires all three steps of counterfactual reasoning and enables scalable synthetic data creation with varying difficulty, creating a frontier for evaluating and improving LLM's reasoning. Our results reveal substantial drop in accuracy (25-40%) from interventional to counterfactual reasoning for SOTA models like o4-mini and Claude-4-Sonnet. To address this gap, we construct a training set comprising counterfactual code problems having if-else condition and test on out-of-domain code structures (e.g. having while-loop); we also test whether a model trained on code would generalize to counterfactual math word problems. While supervised finetuning on stronger models' reasoning traces improves in-domain performance of Qwen models, it leads to a decrease in accuracy on OOD tasks such as counterfactual math problems. In contrast, reinforcement learning induces the core cognitive behaviors and generalizes to new domains, yielding gains over the base model on both code (improvement of 1.5x-2x) and math problems. Analysis of the reasoning traces reinforces these findings and highlights the promise of RL for improving LLMs' counterfactual reasoning.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.369584"
    },
    {
        "index": "#98",
        "title": "TimeSeriesScientist: A General-Purpose AI Agent for Time Series Analysis",
        "link": "/arxiv/2510.01538",
        "arxiv_id": "2510.01538",
        "authors": "Haokun Zhao, Xiang Zhang, Jiaqi Wei, Yiwei Xu, Yuting He, Siqi Sun, Chenyu You",
        "summary": "Time series forecasting is central to decision-making in domains as diverse as energy, finance, climate, and public health. In practice, forecasters face thousands of short, noisy series that vary in frequency, quality, and horizon, where the dominant cost lies not in model fitting, but in the labor-intensive preprocessing, validation, and ensembling required to obtain reliable predictions. Prevailing statistical and deep learning models are tailored to specific datasets or domains and generalize poorly. A general, domain-agnostic framework that minimizes human intervention is urgently in demand. In this paper, we introduce TimeSeriesScientist (TSci), the first LLM-driven agentic framework for general time series forecasting. The framework comprises four specialized agents: Curator performs LLM-guided diagnostics augmented by external tools that reason over data statistics to choose targeted preprocessing; Planner narrows the hypothesis space of model choice by leveraging multi-modal diagnostics and self-planning over the input; Forecaster performs model fitting and validation and, based on the results, adaptively selects the best model configuration as well as ensemble strategy to make final predictions; and Reporter synthesizes the whole process into a comprehensive, transparent report. With transparent natural-language rationales and comprehensive reports, TSci transforms the forecasting workflow into a white-box system that is both interpretable and extensible across tasks. Empirical results on eight established benchmarks demonstrate that TSci consistently outperforms both statistical and LLM-based baselines, reducing forecast error by an average of 10.4% and 38.2%, respectively. Moreover, TSci produces a clear and rigorous report that makes the forecasting workflow more transparent and interpretable.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.370077"
    },
    {
        "index": "#99",
        "title": "NVIDIA AI Aerial: AI-Native Wireless Communications",
        "link": "/arxiv/2510.01533",
        "arxiv_id": "2510.01533",
        "authors": "Kobi Cohen-Arazi, Michael Roe, Zhen Hu, Rohan Chavan, Anna Ptasznik, Joanna Lin, Joao Morais, Joseph Boccuzzi, Tommaso Balercia",
        "summary": "6G brings a paradigm shift towards AI-native wireless systems, necessitating the seamless integration of digital signal processing (DSP) and machine learning (ML) within the software stacks of cellular networks. This transformation brings the life cycle of modern networks closer to AI systems, where models and algorithms are iteratively trained, simulated, and deployed across adjacent environments. In this work, we propose a robust framework that compiles Python-based algorithms into GPU-runnable blobs. The result is a unified approach that ensures efficiency, flexibility, and the highest possible performance on NVIDIA GPUs. As an example of the capabilities of the framework, we demonstrate the efficacy of performing the channel estimation function in the PUSCH receiver through a convolutional neural network (CNN) trained in Python. This is done in a digital twin first, and subsequently in a real-time testbed. Our proposed methodology, realized in the NVIDIA AI Aerial platform, lays the foundation for scalable integration of AI/ML models into next-generation cellular systems, and is essential for realizing the vision of natively intelligent 6G networks.",
        "subjects": "Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.370590"
    },
    {
        "index": "#100",
        "title": "Bypassing Prompt Guards in Production with Controlled-Release Prompting",
        "link": "/arxiv/2510.01529",
        "arxiv_id": "2510.01529",
        "authors": "Jaiden Fairoze, Sanjam Garg, Keewoo Lee, Mingyuan Wang",
        "summary": "As large language models (LLMs) advance, ensuring AI safety and alignment is paramount. One popular approach is prompt guards, lightweight mechanisms designed to filter malicious queries while being easy to implement and update. In this work, we introduce a new attack that circumvents such prompt guards, highlighting their limitations. Our method consistently jailbreaks production models while maintaining response quality, even under the highly protected chat interfaces of Google Gemini (2.5 Flash/Pro), DeepSeek Chat (DeepThink), Grok (3), and Mistral Le Chat (Magistral). The attack exploits a resource asymmetry between the prompt guard and the main LLM, encoding a jailbreak prompt that lightweight guards cannot decode but the main model can. This reveals an attack surface inherent to lightweight prompt guards in modern LLM architectures and underscores the need to shift defenses from blocking malicious inputs to preventing malicious outputs. We additionally identify other critical alignment issues, such as copyrighted data extraction, training data extraction, and malicious response leakage during thinking.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.371086"
    },
    {
        "index": "#101",
        "title": "Round-trip Reinforcement Learning: Self-Consistent Training for Better Chemical LLMs",
        "link": "/arxiv/2510.01527",
        "arxiv_id": "2510.01527",
        "authors": "Lecheng Kong, Xiyuan Wang, Yixin Chen, Muhan Zhang",
        "summary": "Large Language Models (LLMs) are emerging as versatile foundation models for computational chemistry, handling bidirectional tasks like reaction prediction and retrosynthesis. However, these models often lack round-trip consistency. For instance, a state-of-the-art chemical LLM may successfully caption a molecule, yet be unable to accurately reconstruct the original structure from its own generated text. This inconsistency suggests that models are learning unidirectional memorization rather than flexible mastery. Indeed, recent work has demonstrated a strong correlation between a model's round-trip consistency and its performance on the primary tasks. This strong correlation reframes consistency into a direct target for model improvement. We therefore introduce Round-Trip Reinforcement Learning (RTRL), a novel framework that trains a model to improve its consistency by using the success of a round-trip transformation as a reward signal. We further propose an iterative variant where forward and reverse mappings alternately train each other in a self-improvement loop, a process that is highly data-efficient and notably effective with the massive amount of unlabelled data common in chemistry. Experiments demonstrate that RTRL significantly \\textbf{boosts performance and consistency} over strong baselines across supervised, self-supervised, and synthetic data regimes. This work shows that round-trip consistency is not just a desirable property but a trainable objective, offering a new path toward more robust and reliable foundation models.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.371527"
    },
    {
        "index": "#102",
        "title": "On Integer Programming for the Binarized Neural Network Verification Problem",
        "link": "/arxiv/2510.01525",
        "arxiv_id": "2510.01525",
        "authors": "Woojin Kim, James R. Luedtke",
        "summary": "Binarized neural networks (BNNs) are feedforward neural networks with binary weights and activation functions. In the context of using a BNN for classification, the verification problem seeks to determine whether a small perturbation of a given input can lead it to be misclassified by the BNN, and the robustness of the BNN can be measured by solving the verification problem over multiple inputs. The BNN verification problem can be formulated as an integer programming (IP) problem. However, the natural IP formulation is often challenging to solve due to a large integrality gap induced by big-$M$ constraints. We present two techniques to improve the IP formulation. First, we introduce a new method for obtaining a linear objective for the multi-class setting. Second, we introduce a new technique for generating valid inequalities for the IP formulation that exploits the recursive structure of BNNs. We find that our techniques enable verifying BNNs against a higher range of input perturbation than existing IP approaches within a limited time.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.377093"
    },
    {
        "index": "#103",
        "title": "CarbonX: An Open-Source Tool for Computational Decarbonization Using Time Series Foundation Models",
        "link": "/arxiv/2510.01521",
        "arxiv_id": "2510.01521",
        "authors": "Diptyaroop Maji, Kang Yang, Prashant Shenoy, Ramesh K Sitaraman, Mani Srivastava",
        "summary": "Computational decarbonization aims to reduce carbon emissions in computing and societal systems such as data centers, transportation, and built environments. This requires accurate, fine-grained carbon intensity forecasts, yet existing tools have several key limitations: (i) they require grid-specific electricity mix data, restricting use where such information is unavailable; (ii) they depend on separate grid-specific models that make it challenging to provide global coverage; and (iii) they provide forecasts without uncertainty estimates, limiting reliability for downstream carbon-aware applications. In this paper, we present CarbonX, an open-source tool that leverages Time Series Foundation Models (TSFMs) for a range of decarbonization tasks. CarbonX utilizes the versatility of TSFMs to provide strong performance across multiple tasks, such as carbon intensity forecasting and imputation, and across diverse grids. Using only historical carbon intensity data and a single general model, our tool achieves a zero-shot forecasting Mean Absolute Percentage Error (MAPE) of 15.82% across 214 grids worldwide. Across 13 benchmark grids, CarbonX performance is comparable with the current state-of-the-art, with an average MAPE of 9.59% and tail forecasting MAPE of 16.54%, while also providing prediction intervals with 95% coverage. CarbonX can provide forecasts for up to 21 days with minimal accuracy degradation. Further, when fully fine-tuned, CarbonX outperforms the statistical baselines by 1.2--3.9X on the imputation task. Overall, these results demonstrate that CarbonX can be used easily on any grid with limited data and still deliver strong performance, making it a practical tool for global-scale decarbonization.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.381127"
    },
    {
        "index": "#105",
        "title": "Flock: A Knowledge Graph Foundation Model via Learning on Random Walks",
        "link": "/arxiv/2510.01510",
        "arxiv_id": "2510.01510",
        "authors": "Jinwoo Kim, Xingyue Huang, Krzysztof Olejniczak, Kyungbin Min, Michael Bronstein, Seunghoon Hong, İsmail İlkan Ceylan",
        "summary": "We study the problem of zero-shot link prediction on knowledge graphs (KGs), which requires models to generalize over novel entities and novel relations. Knowledge graph foundation models (KGFMs) address this task by enforcing equivariance over both nodes and relations, learning from structural properties of nodes and relations, which are then transferable to novel graphs with similar structural properties. However, the conventional notion of deterministic equivariance imposes inherent limits on the expressive power of KGFMs, preventing them from distinguishing structurally similar but semantically distinct relations. To overcome this limitation, we introduce probabilistic node-relation equivariance, which preserves equivariance in distribution while incorporating a principled randomization to break symmetries during inference. Building on this principle, we present Flock, a KGFM that iteratively samples random walks, encodes them into sequences via a recording protocol, embeds them with a sequence model, and aggregates representations of nodes and relations via learned pooling. Crucially, Flock respects probabilistic node-relation equivariance and is a universal approximator for isomorphism-invariant link-level functions over KGs. Empirically, Flock perfectly solves our new diagnostic dataset Petals where current KGFMs fail, and achieves state-of-the-art performances on entity- and relation prediction tasks on 54 KGs from diverse domains.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.382162"
    },
    {
        "index": "#106",
        "title": "Realistic CDSS Drug Dosing with End-to-end Recurrent Q-learning for Dual Vasopressor Control",
        "link": "/arxiv/2510.01508",
        "arxiv_id": "2510.01508",
        "authors": "Will Y. Zou, Jean Feng, Alexandre Kalimouttou, Jennifer Yuntong Zhang, Christopher W. Seymour, Romain Pirracchio",
        "summary": "Reinforcement learning (RL) applications in Clinical Decision Support Systems (CDSS) frequently encounter skepticism from practitioners regarding inoperable dosing decisions. We address this challenge with an end-to-end approach for learning optimal drug dosing and control policies for dual vasopressor administration in intensive care unit (ICU) patients with septic shock. For realistic drug dosing, we apply action space design that accommodates discrete, continuous, and directional dosing strategies in a system that combines offline conservative Q-learning with a novel recurrent modeling in a replay buffer to capture temporal dependencies in ICU time-series data. Our comparative analysis of norepinephrine dosing strategies across different action space formulations reveals that the designed action spaces improve interpretability and facilitate clinical adoption while preserving efficacy. Empirical results1 on eICU and MIMIC demonstrate that action space design profoundly influences learned behavioral policies. The proposed methods achieve improved patient outcomes of over 15% in survival improvement probability, while aligning with established clinical protocols.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.382658"
    },
    {
        "index": "#109",
        "title": "Density-Ratio Weighted Behavioral Cloning: Learning Control Policies from Corrupted Datasets",
        "link": "/arxiv/2510.01479",
        "arxiv_id": "2510.01479",
        "authors": "Shriram Karpoora Sundara Pandian, Ali Baheri",
        "summary": "Offline reinforcement learning (RL) enables policy optimization from fixed datasets, making it suitable for safety-critical applications where online exploration is infeasible. However, these datasets are often contaminated by adversarial poisoning, system errors, or low-quality samples, leading to degraded policy performance in standard behavioral cloning (BC) and offline RL methods. This paper introduces Density-Ratio Weighted Behavioral Cloning (Weighted BC), a robust imitation learning approach that uses a small, verified clean reference set to estimate trajectory-level density ratios via a binary discriminator. These ratios are clipped and used as weights in the BC objective to prioritize clean expert behavior while down-weighting or discarding corrupted data, without requiring knowledge of the contamination mechanism. We establish theoretical guarantees showing convergence to the clean expert policy with finite-sample bounds that are independent of the contamination rate. A comprehensive evaluation framework is established, which incorporates various poisoning protocols (reward, state, transition, and action) on continuous control benchmarks. Experiments demonstrate that Weighted BC maintains near-optimal performance even at high contamination ratios outperforming baselines such as traditional BC, batch-constrained Q-learning (BCQ) and behavior regularized actor-critic (BRAC).",
        "subjects": "Machine Learning, Systems and Control",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.384171"
    },
    {
        "index": "#110",
        "title": "PEL-NAS: Search Space Partitioned Architecture Prompt Co-Evolutionary LLM-driven Hardware-Aware Neural Architecture Search",
        "link": "/arxiv/2510.01472",
        "arxiv_id": "2510.01472",
        "authors": "Hengyi Zhu, Grace Li Zhang, Shaoyi Huang",
        "summary": "Hardware-Aware Neural Architecture Search (HW-NAS) requires joint optimization of accuracy and latency under device constraints. Traditional supernet-based methods require multiple GPU days per dataset. Large Language Model (LLM)-driven approaches avoid training a large supernet and can provide quick feedback, but we observe an exploration bias: the LLM repeatedly proposes neural network designs within limited search space and fails to discover architectures across different latency ranges in the entire search space. To address this issue, we propose PEL-NAS: a search space Partitioned, architecture prompt co-Evolutionary and LLM-driven Neural Architecture Search that can generate neural networks with high accuracy and low latency with reduced search cost. Our proposed PEL-NAS has three key components: 1) a complexity-driven partitioning engine that divides the search space by complexity to enforce diversity and mitigate exploration bias; 2) an LLM-powered architecture prompt co-evolution operator, in which the LLM first updates a knowledge base of design heuristics based on results from the previous round, then performs a guided evolution algorithm on architectures with prompts that incorporate this knowledge base. Prompts and designs improve together across rounds which avoids random guesswork and improve efficiency; 3) a zero-cost predictor to avoid training a large number of candidates from scratch. Experimental results show that on HW-NAS-Bench, PEL-NAS can achieve overall higher HV, lower IGD, and up to 54% lower latency than baselines at similar accuracy. Meanwhile, the search cost drops from days to minutes compared with traditional supernet baselines.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.384637"
    },
    {
        "index": "#111",
        "title": "Fine-tuning LLMs with variational Bayesian last layer for high-dimensional Bayesian optimzation",
        "link": "/arxiv/2510.01471",
        "arxiv_id": "2510.01471",
        "authors": "Haotian Xiang, Jinwen Xu, Qin Lu",
        "summary": "A plethora of applications entail solving black-box optimization problems with high evaluation costs, including drug discovery, material design, as well as hyperparameter tuning. Toward finding the global optimum of such black-box optimization problems with sample efficiency, Bayesian optimization (BO) is a theoretically elegant framework that relies on a probabilistic surrogate model so as to iteratively select the query point with well-balanced exploration-exploitation tradeoffs. The Gaussian process (GP), as the de-facto choice for surrogate modeling, has achieved compelling performances for vanilla BO with low-dimensional continuous variables. However, GPs fall short in coping with high-dimensional counterparts with {\\it irregular} variables (e.g., categorical, ordinal, etc.). To alleviate this, neural network-based surrogates have been explored. Inspired by the powerful capabilities of LLMs, we adopt the LLM as the surrogate to model the mapping from the high-dimensional input variables to the objective function. To adapt to the current problem, we leverage the low-rank adaptation (LoRA) to fine-tune the LLM parameters together with the posterior of a linear regression head via the variational Bayesian last layer (VBLL) framework. The resulting LoRA-VBLL is not only computationally light compared to existing alternatives, but also admits recursive updates. To automate the critical selection of the LoRA rank as well as other hyperparameters, a weighted ensemble (ENS) of LoRA-VBLL surrogates has been devised, which further accommodates continual update of the per-model weight and individual LoRA-VBLL parameters via recursive Bayes. Extensive experimental results demonstrate the compelling performance of the proposed (ENS-)LoRA-VBLL approaches on various high-dimensional benchmarks and the real-world molecular optimization tasks.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.385098"
    },
    {
        "index": "#114",
        "title": "How Well Can Preference Optimization Generalize Under Noisy Feedback?",
        "link": "/arxiv/2510.01458",
        "arxiv_id": "2510.01458",
        "authors": "Shawn Im, Yixuan Li",
        "summary": "As large language models (LLMs) advance their capabilities, aligning these models with human preferences has become crucial. Preference optimization, which trains models to distinguish between preferred and non-preferred responses based on human feedback, has become a crucial component for aligning LLMs. However, most existing works assume noise-free feedback, which is unrealistic due to the inherent errors and inconsistencies in human judgments. This paper addresses the impact of noisy feedback on preference optimization, providing generalization guarantees under these conditions. In particular, we consider noise models that correspond to common real-world sources of noise, such as mislabeling and uncertainty. Unlike traditional analyses that assume convergence, our work focuses on finite-step preference optimization, offering new insights that are more aligned with practical LLM training. We describe how generalization decays with different types of noise across levels of noise rates based on the preference data distribution and number of samples. Our analysis for noisy preference learning applies to a broad family of preference optimization losses such as DPO, IPO, SLiC, etc. Empirical validation on contemporary LLMs confirms the practical relevance of our findings, offering valuable insights for developing AI systems that align with human preferences.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.391712"
    },
    {
        "index": "#115",
        "title": "Fixing That Free Lunch: When, Where, and Why Synthetic Data Fails in Model-Based Policy Optimization",
        "link": "/arxiv/2510.01457",
        "arxiv_id": "2510.01457",
        "authors": "Brett Barkley, David Fridovich-Keil",
        "summary": "Synthetic data is a core component of data-efficient Dyna-style model-based reinforcement learning, yet it can also degrade performance. We study when it helps, where it fails, and why, and we show that addressing the resulting failure modes enables policy improvement that was previously unattainable. We focus on Model-Based Policy Optimization (MBPO), which performs actor and critic updates using synthetic action counterfactuals. Despite reports of strong and generalizable sample-efficiency gains in OpenAI Gym, recent work shows that MBPO often underperforms its model-free counterpart, Soft Actor-Critic (SAC), in the DeepMind Control Suite (DMC). Although both suites involve continuous control with proprioceptive robots, this shift leads to sharp performance losses across seven challenging DMC tasks, with MBPO failing in cases where claims of generalization from Gym would imply success. This reveals how environment-specific assumptions can become implicitly encoded into algorithm design when evaluation is limited. We identify two coupled issues behind these failures: scale mismatches between dynamics and reward models that induce critic underestimation and hinder policy improvement during model-policy coevolution, and a poor choice of target representation that inflates model variance and produces error-prone rollouts. Addressing these failure modes enables policy improvement where none was previously possible, allowing MBPO to outperform SAC in five of seven tasks while preserving the strong performance previously reported in OpenAI Gym. Rather than aiming only for incremental average gains, we hope our findings motivate the community to develop taxonomies that tie MDP task- and environment-level structure to algorithmic failure modes, pursue unified solutions where possible, and clarify how benchmark choices ultimately shape the conditions under which algorithms generalize.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.392152"
    },
    {
        "index": "#116",
        "title": "SCOPED: Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion",
        "link": "/arxiv/2510.01456",
        "arxiv_id": "2510.01456",
        "authors": "Brett Barkley, Preston Culbertson, David Fridovich-Keil",
        "summary": "Out-of-distribution (OOD) detection is essential for reliable deployment of machine learning systems in vision, robotics, reinforcement learning, and beyond. We introduce Score-Curvature Out-of-distribution Proximity Evaluator for Diffusion (SCOPED), a fast and general-purpose OOD detection method for diffusion models that reduces the number of forward passes on the trained model by an order of magnitude compared to prior methods, outperforming most diffusion-based baselines and closely approaching the accuracy of the strongest ones. SCOPED is computed from a single diffusion model trained once on a diverse dataset, and combines the Jacobian trace and squared norm of the model's score function into a single test statistic. Rather than thresholding on a fixed value, we estimate the in-distribution density of SCOPED scores using kernel density estimation, enabling a flexible, unsupervised test that, in the simplest case, only requires a single forward pass and one Jacobian-vector product (JVP), made efficient by Hutchinson's trace estimator. On four vision benchmarks, SCOPED achieves competitive or state-of-the-art precision-recall scores despite its low computational cost. The same method generalizes to robotic control tasks with shared state and action spaces, identifying distribution shifts across reward functions and training regimes. These results position SCOPED as a practical foundation for fast and reliable OOD detection in real-world domains, including perceptual artifacts in vision, outlier detection in autoregressive models, exploration in reinforcement learning, and dataset curation for unsupervised training.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.392603"
    },
    {
        "index": "#118",
        "title": "SoftAdaClip: A Smooth Clipping Strategy for Fair and Private Model Training",
        "link": "/arxiv/2510.01447",
        "arxiv_id": "2510.01447",
        "authors": "Dorsa Soleymani, Ali Dadsetan, Frank Rudzicz",
        "summary": "Differential privacy (DP) provides strong protection for sensitive data, but often reduces model performance and fairness, especially for underrepresented groups. One major reason is gradient clipping in DP-SGD, which can disproportionately suppress learning signals for minority subpopulations. Although adaptive clipping can enhance utility, it still relies on uniform hard clipping, which may restrict fairness. To address this, we introduce SoftAdaClip, a differentially private training method that replaces hard clipping with a smooth, tanh-based transformation to preserve relative gradient magnitudes while bounding sensitivity. We evaluate SoftAdaClip on various datasets, including MIMIC-III (clinical text), GOSSIS-eICU (structured healthcare), and Adult Income (tabular data). Our results show that SoftAdaClip reduces subgroup disparities by up to 87% compared to DP-SGD and up to 48% compared to Adaptive-DPSGD, and these reductions in subgroup disparities are statistically significant. These findings underscore the importance of integrating smooth transformations with adaptive mechanisms to achieve fair and private model training.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.393545"
    },
    {
        "index": "#119",
        "title": "Edge Artificial Intelligence: A Systematic Review of Evolution, Taxonomic Frameworks, and Future Horizons",
        "link": "/arxiv/2510.01439",
        "arxiv_id": "2510.01439",
        "authors": "Mohamad Abou Ali, Fadi Dornaika",
        "summary": "Edge Artificial Intelligence (Edge AI) embeds intelligence directly into devices at the network edge, enabling real-time processing with improved privacy and reduced latency by processing data close to its source. This review systematically examines the evolution, current landscape, and future directions of Edge AI through a multi-dimensional taxonomy including deployment location, processing capabilities such as TinyML and federated learning, application domains, and hardware types. Following PRISMA guidelines, the analysis traces the field from early content delivery networks and fog computing to modern on-device intelligence. Core enabling technologies such as specialized hardware accelerators, optimized software, and communication protocols are explored. Challenges including resource limitations, security, model management, power consumption, and connectivity are critically assessed. Emerging opportunities in neuromorphic hardware, continual learning algorithms, edge-cloud collaboration, and trustworthiness integration are highlighted, providing a comprehensive framework for researchers and practitioners.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.393969"
    },
    {
        "index": "#120",
        "title": "Ultra-Efficient Decoding for End-to-End Neural Compression and Reconstruction",
        "link": "/arxiv/2510.01407",
        "arxiv_id": "2510.01407",
        "authors": "Ethan G. Rogers, Cheng Wang",
        "summary": "Image compression and reconstruction are crucial for various digital applications. While contemporary neural compression methods achieve impressive compression rates, the adoption of such technology has been largely hindered by the complexity and large computational costs of the convolution-based decoders during data reconstruction. To address the decoder bottleneck in neural compression, we develop a new compression-reconstruction framework based on incorporating low-rank representation in an autoencoder with vector quantization. We demonstrated that performing a series of computationally efficient low-rank operations on the learned latent representation of images can efficiently reconstruct the data with high quality. Our approach dramatically reduces the computational overhead in the decoding phase of neural compression/reconstruction, essentially eliminating the decoder compute bottleneck while maintaining high fidelity of image outputs.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.394410"
    },
    {
        "index": "#123",
        "title": "Fine-Tuning Masked Diffusion for Provable Self-Correction",
        "link": "/arxiv/2510.01384",
        "arxiv_id": "2510.01384",
        "authors": "Jaeyeon Kim, Seunggeun Kim, Taekyun Lee, David Z. Pan, Hyeji Kim, Sham Kakade, Sitan Chen",
        "summary": "A natural desideratum for generative models is self-correction--detecting and revising low-quality tokens at inference. While Masked Diffusion Models (MDMs) have emerged as a promising approach for generative modeling in discrete spaces, their capacity for self-correction remains poorly understood. Prior attempts to incorporate self-correction into MDMs either require overhauling MDM architectures/training or rely on imprecise proxies for token quality, limiting their applicability. Motivated by this, we introduce PRISM--Plug-in Remasking for Inference-time Self-correction of Masked Diffusions--a lightweight, model-agnostic approach that applies to any pretrained MDM. Theoretically, PRISM defines a self-correction loss that provably learns per-token quality scores, without RL or a verifier. These quality scores are computed in the same forward pass with MDM and used to detect low-quality tokens. Empirically, PRISM advances MDM inference across domains and scales: Sudoku; unconditional text (170M); and code with LLaDA (8B).",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.401056"
    },
    {
        "index": "#124",
        "title": "Selective Underfitting in Diffusion Models",
        "link": "/arxiv/2510.01378",
        "arxiv_id": "2510.01378",
        "authors": "Kiwhan Song, Jaeyeon Kim, Sitan Chen, Yilun Du, Sham Kakade, Vincent Sitzmann",
        "summary": "Diffusion models have emerged as the principal paradigm for generative modeling across various domains. During training, they learn the score function, which in turn is used to generate samples at inference. They raise a basic yet unsolved question: which score do they actually learn? In principle, a diffusion model that matches the empirical score in the entire data space would simply reproduce the training data, failing to generate novel samples. Recent work addresses this question by arguing that diffusion models underfit the empirical score due to training-time inductive biases. In this work, we refine this perspective, introducing the notion of selective underfitting: instead of underfitting the score everywhere, better diffusion models more accurately approximate the score in certain regions of input space, while underfitting it in others. We characterize these regions and design empirical interventions to validate our perspective. Our results establish that selective underfitting is essential for understanding diffusion models, yielding new, testable insights into their generalization and generative performance.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.401546"
    },
    {
        "index": "#125",
        "title": "RheOFormer: A generative transformer model for simulation of complex fluids and flows",
        "link": "/arxiv/2510.01365",
        "arxiv_id": "2510.01365",
        "authors": "Maedeh Saberi, Amir Barati Farimani, Safa Jamali",
        "summary": "The ability to model mechanics of soft materials under flowing conditions is key in designing and engineering processes and materials with targeted properties. This generally requires solution of internal stress tensor, related to the deformation tensor through nonlinear and history-dependent constitutive models. Traditional numerical methods for non-Newtonian fluid dynamics often suffer from prohibitive computational demands and poor scalability to new problem instances. Developments in data-driven methods have mitigated some limitations but still require retraining across varied physical conditions. In this work, we introduce Rheological Operator Transformer (RheOFormer), a generative operator learning method leveraging self-attention to efficiently learn different spatial interactions and features of complex fluid flows. We benchmark RheOFormer across a range of different viscometric and non-viscometric flows with different types of viscoelastic and elastoviscoplastic mechanics in complex domains against ground truth solutions. Our results demonstrate that RheOFormer can accurately learn both scalar and tensorial nonlinear mechanics of different complex fluids and predict the spatio-temporal evolution of their flows, even when trained on limited datasets. Its strong generalization capabilities and computational efficiency establish RheOFormer as a robust neural surrogate for accelerating predictive complex fluid simulations, advancing data-driven experimentation, and enabling real-time process optimization across a wide range of applications.",
        "subjects": "Machine Learning, Fluid Dynamics",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.402018"
    },
    {
        "index": "#126",
        "title": "To Augment or Not to Augment? Diagnosing Distributional Symmetry Breaking",
        "link": "/arxiv/2510.01349",
        "arxiv_id": "2510.01349",
        "authors": "Hannah Lawrence, Elyssa Hofgard, Vasco Portilheiro, Yuxuan Chen, Tess Smidt, Robin Walters",
        "summary": "Symmetry-aware methods for machine learning, such as data augmentation and equivariant architectures, encourage correct model behavior on all transformations (e.g. rotations or permutations) of the original dataset. These methods can improve generalization and sample efficiency, under the assumption that the transformed datapoints are highly probable, or \"important\", under the test distribution. In this work, we develop a method for critically evaluating this assumption. In particular, we propose a metric to quantify the amount of anisotropy, or symmetry-breaking, in a dataset, via a two-sample neural classifier test that distinguishes between the original dataset and its randomly augmented equivalent. We validate our metric on synthetic datasets, and then use it to uncover surprisingly high degrees of alignment in several benchmark point cloud datasets. We show theoretically that distributional symmetry-breaking can actually prevent invariant methods from performing optimally even when the underlying labels are truly invariant, as we show for invariant ridge regression in the infinite feature limit. Empirically, we find that the implication for symmetry-aware methods is dataset-dependent: equivariant methods still impart benefits on some anisotropic datasets, but not others. Overall, these findings suggest that understanding equivariance -- both when it works, and why -- may require rethinking symmetry biases in the data.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.402519"
    },
    {
        "index": "#127",
        "title": "Self-Supervised Representation Learning as Mutual Information Maximization",
        "link": "/arxiv/2510.01345",
        "arxiv_id": "2510.01345",
        "authors": "Akhlaqur Rahman Sabby, Yi Sui, Tongzi Wu, Jesse C. Cresswell, Ga Wu",
        "summary": "Self-supervised representation learning (SSRL) has demonstrated remarkable empirical success, yet its underlying principles remain insufficiently understood. While recent works attempt to unify SSRL methods by examining their information-theoretic objectives or summarizing their heuristics for preventing representation collapse, architectural elements like the predictor network, stop-gradient operation, and statistical regularizer are often viewed as empirically motivated additions. In this paper, we adopt a first-principles approach and investigate whether the learning objective of an SSRL algorithm dictates its possible optimization strategies and model design choices. In particular, by starting from a variational mutual information (MI) lower bound, we derive two training paradigms, namely Self-Distillation MI (SDMI) and Joint MI (JMI), each imposing distinct structural constraints and covering a set of existing SSRL algorithms. SDMI inherently requires alternating optimization, making stop-gradient operations theoretically essential. In contrast, JMI admits joint optimization through symmetric architectures without such components. Under the proposed formulation, predictor networks in SDMI and statistical regularizers in JMI emerge as tractable surrogates for the MI objective. We show that many existing SSRL methods are specific instances or approximations of these two paradigms. This paper provides a theoretical explanation behind the choices of different architectural components of existing SSRL methods, beyond heuristic conveniences.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.402982"
    },
    {
        "index": "#128",
        "title": "On the Identifiability of Latent Action Policies",
        "link": "/arxiv/2510.01337",
        "arxiv_id": "2510.01337",
        "authors": "Sébastien Lachapelle",
        "summary": "We study the identifiability of latent action policy learning (LAPO), a framework introduced recently to discover representations of actions from video data. We formally describe desiderata for such representations, their statistical benefits and potential sources of unidentifiability. Finally, we prove that an entropy-regularized LAPO objective identifies action representations satisfying our desiderata, under suitable conditions. Our analysis provides an explanation for why discrete action representations perform well in practice.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.403416"
    },
    {
        "index": "#129",
        "title": "Quantum-inspired Benchmark for Estimating Intrinsic Dimension",
        "link": "/arxiv/2510.01335",
        "arxiv_id": "2510.01335",
        "authors": "Aritra Das, Joseph T. Iosue, Victor V. Albert",
        "summary": "Machine learning models can generalize well on real-world datasets. According to the manifold hypothesis, this is possible because datasets lie on a latent manifold with small intrinsic dimension (ID). There exist many methods for ID estimation (IDE), but their estimates vary substantially. This warrants benchmarking IDE methods on manifolds that are more complex than those in existing benchmarks. We propose a Quantum-Inspired Intrinsic-dimension Estimation (QuIIEst) benchmark consisting of infinite families of topologically non-trivial manifolds with known ID. Our benchmark stems from a quantum-optical method of embedding arbitrary homogeneous spaces while allowing for curvature modification and additive noise. The IDE methods tested were generally less accurate on QuIIEst manifolds than on existing benchmarks under identical resource allocation. We also observe minimal performance degradation with increasingly non-uniform curvature, underscoring the benchmark's inherent difficulty. As a result of independent interest, we perform IDE on the fractal Hofstadter's butterfly and identify which methods are capable of extracting the effective dimension of a space that is not a manifold.",
        "subjects": "Machine Learning, Disordered Systems and Neural Networks, Metric Geometry, Data Analysis, Statistics and Probability, Quantum Physics",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.403959"
    },
    {
        "index": "#132",
        "title": "Network-Level Vehicle Delay Estimation at Heterogeneous Signalized Intersections",
        "link": "/arxiv/2510.01292",
        "arxiv_id": "2510.01292",
        "authors": "Xiaobo Ma, Hyunsoo Noh, James Tokishi, Ryan Hatch",
        "summary": "Accurate vehicle delay estimation is essential for evaluating the performance of signalized intersections and informing traffic management strategies. Delay reflects congestion levels and affects travel time reliability, fuel use, and emissions. Machine learning (ML) offers a scalable, cost-effective alternative; However, conventional models typically assume that training and testing data follow the same distribution, an assumption that is rarely satisfied in real-world applications. Variations in road geometry, signal timing, and driver behavior across intersections often lead to poor generalization and reduced model accuracy. To address this issue, this study introduces a domain adaptation (DA) framework for estimating vehicle delays across diverse intersections. The framework separates data into source and target domains, extracts key traffic features, and fine-tunes the model using a small, labeled subset from the target domain. A novel DA model, Gradient Boosting with Balanced Weighting (GBBW), reweights source data based on similarity to the target domain, improving adaptability. The framework is tested using data from 57 heterogeneous intersections in Pima County, Arizona. Performance is evaluated against eight state-of-the-art ML regression models and seven instance-based DA methods. Results demonstrate that the GBBW framework provides more accurate and robust delay estimates. This approach supports more reliable traffic signal optimization, congestion management, and performance-based planning. By enhancing model transferability, the framework facilitates broader deployment of machine learning techniques in real-world transportation systems.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.405337"
    },
    {
        "index": "#133",
        "title": "ThinKV: Thought-Adaptive KV Cache Compression for Efficient Reasoning Models",
        "link": "/arxiv/2510.01290",
        "arxiv_id": "2510.01290",
        "authors": "Akshat Ramachandran, Marina Neseem, Charbel Sakr, Rangharajan Venkatesan, Brucek Khailany, Tushar Krishna",
        "summary": "The long-output context generation of large reasoning models enables extended chain of thought (CoT) but also drives rapid growth of the key-value (KV) cache, quickly overwhelming GPU memory. To address this challenge, we propose ThinKV, a thought-adaptive KV cache compression framework. ThinKV is based on the observation that attention sparsity reveals distinct thought types with varying importance within the CoT. It applies a hybrid quantization-eviction strategy, assigning token precision by thought importance and progressively evicting tokens from less critical thoughts as reasoning trajectories evolve. Furthermore, to implement ThinKV, we design a kernel that extends PagedAttention to enable efficient reuse of evicted tokens' memory slots, eliminating compaction overheads. Extensive experiments on DeepSeek-R1-Distill, GPT-OSS, and NVIDIA AceReason across mathematics and coding benchmarks show that ThinKV achieves near-lossless accuracy with less than 5% of the original KV cache, while improving performance with up to 5.8x higher inference throughput over state-of-the-art baselines.",
        "subjects": "Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.405797"
    },
    {
        "index": "#137",
        "title": "Safe Reinforcement Learning-Based Vibration Control: Overcoming Training Risks with LQR Guidance",
        "link": "/arxiv/2510.01269",
        "arxiv_id": "2510.01269",
        "authors": "Rohan Vitthal Thorat, Juhi Singh, Rajdip Nayek",
        "summary": "Structural vibrations induced by external excitations pose significant risks, including safety hazards for occupants, structural damage, and increased maintenance costs. While conventional model-based control strategies, such as Linear Quadratic Regulator (LQR), effectively mitigate vibrations, their reliance on accurate system models necessitates tedious system identification. This tedious system identification process can be avoided by using a model-free Reinforcement learning (RL) method. RL controllers derive their policies solely from observed structural behaviour, eliminating the requirement for an explicit structural model. For an RL controller to be truly model-free, its training must occur on the actual physical system rather than in simulation. However, during this training phase, the RL controller lacks prior knowledge and it exerts control force on the structure randomly, which can potentially harm the structure. To mitigate this risk, we propose guiding the RL controller using a Linear Quadratic Regulator (LQR) controller. While LQR control typically relies on an accurate structural model for optimal performance, our observations indicate that even an LQR controller based on an entirely incorrect model outperforms the uncontrolled scenario. Motivated by this finding, we introduce a hybrid control framework that integrates both LQR and RL controllers. In this approach, the LQR policy is derived from a randomly selected model and its parameters. As this LQR policy does not require knowledge of the true or an approximate structural model the overall framework remains model-free. This hybrid approach eliminates dependency on explicit system models while minimizing exploration risks inherent in naive RL implementations. As per our knowledge, this is the first study to address the critical training safety challenge of RL-based vibration control and provide a validated solution.",
        "subjects": "Machine Learning, Systems and Control, Machine Learning",
        "date": "2025-09-29",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.412816"
    },
    {
        "index": "#139",
        "title": "A Framework for Scalable Heterogeneous Multi-Agent Adversarial Reinforcement Learning in IsaacLab",
        "link": "/arxiv/2510.01264",
        "arxiv_id": "2510.01264",
        "authors": "Isaac Peterson, Christopher Allred, Jacob Morrey, Mario Harper",
        "summary": "Multi-Agent Reinforcement Learning (MARL) is central to robotic systems cooperating in dynamic environments. While prior work has focused on these collaborative settings, adversarial interactions are equally critical for real-world applications such as pursuit-evasion, security, and competitive manipulation. In this work, we extend the IsaacLab framework to support scalable training of adversarial policies in high-fidelity physics simulations. We introduce a suite of adversarial MARL environments featuring heterogeneous agents with asymmetric goals and capabilities. Our platform integrates a competitive variant of Heterogeneous Agent Reinforcement Learning with Proximal Policy Optimization (HAPPO), enabling efficient training and evaluation under adversarial dynamics. Experiments across several benchmark scenarios demonstrate the framework's ability to model and train robust policies for morphologically diverse multi-agent competition while maintaining high throughput and simulation realism. Code and benchmarks are available at: https://github.com/DIRECTLab/IsaacLab-HARL .",
        "subjects": "Machine Learning, Robotics",
        "date": "2025-09-26",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.413913"
    },
    {
        "index": "#142",
        "title": "Adaptive Federated Learning Defences via Trust-Aware Deep Q-Networks",
        "link": "/arxiv/2510.01261",
        "arxiv_id": "2510.01261",
        "authors": "Vedant Palit",
        "summary": "Federated learning is vulnerable to poisoning and backdoor attacks under partial observability. We formulate defence as a partially observable sequential decision problem and introduce a trust-aware Deep Q-Network that integrates multi-signal evidence into client trust updates while optimizing a long-horizon robustness--accuracy objective. On CIFAR-10, we (i) establish a baseline showing steadily improving accuracy, (ii) show through a Dirichlet sweep that increased client overlap consistently improves accuracy and reduces ASR with stable detection, and (iii) demonstrate in a signal-budget study that accuracy remains steady while ASR increases and ROC-AUC declines as observability is reduced, which highlights that sequential belief updates mitigate weaker signals. Finally, a comparison with random, linear-Q, and policy gradient controllers confirms that DQN achieves the best robustness--accuracy trade-off.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2025-09-25",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.415359"
    },
    {
        "index": "#146",
        "title": "Accelerating Long-Term Molecular Dynamics with Physics-Informed Time-Series Forecasting",
        "link": "/arxiv/2510.01206",
        "arxiv_id": "2510.01206",
        "authors": "Hung Le, Sherif Abbas, Minh Hoang Nguyen, Van Dai Do, Huu Hiep Nguyen, Dung Nguyen",
        "summary": "Efficient molecular dynamics (MD) simulation is vital for understanding atomic-scale processes in materials science and biophysics. Traditional density functional theory (DFT) methods are computationally expensive, which limits the feasibility of long-term simulations. We propose a novel approach that formulates MD simulation as a time-series forecasting problem, enabling advanced forecasting models to predict atomic trajectories via displacements rather than absolute positions. We incorporate a physics-informed loss and inference mechanism based on DFT-parametrised pair-wise Morse potential functions that penalize unphysical atomic proximity to enforce physical plausibility. Our method consistently surpasses standard baselines in simulation accuracy across diverse materials. The results highlight the importance of incorporating physics knowledge to enhance the reliability and precision of atomic trajectory forecasting. Remarkably, it enables stable modeling of thousands of MD steps in minutes, offering a scalable alternative to costly DFT simulations.",
        "subjects": "Machine Learning",
        "date": "2025-09-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.422425"
    },
    {
        "index": "#147",
        "title": "Inferring Dynamic Physical Properties from Video Foundation Models",
        "link": "/arxiv/2510.02311",
        "arxiv_id": "2510.02311",
        "authors": "Guanqi Zhan, Xianzheng Ma, Weidi Xie, Andrew Zisserman",
        "summary": "We study the task of predicting dynamic physical properties from videos. More specifically, we consider physical properties that require temporal information to be inferred: elasticity of a bouncing object, viscosity of a flowing liquid, and dynamic friction of an object sliding on a surface. To this end, we make the following contributions: (i) We collect a new video dataset for each physical property, consisting of synthetic training and testing splits, as well as a real split for real world evaluation. (ii) We explore three ways to infer the physical property from videos: (a) an oracle method where we supply the visual cues that intrinsically reflect the property using classical computer vision techniques; (b) a simple read out mechanism using a visual prompt and trainable prompt vector for cross-attention on pre-trained video generative and self-supervised models; and (c) prompt strategies for Multi-modal Large Language Models (MLLMs). (iii) We show that video foundation models trained in a generative or self-supervised manner achieve a similar performance, though behind that of the oracle, and MLLMs are currently inferior to the other models, though their performance can be improved through suitable prompting.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.422909"
    },
    {
        "index": "#150",
        "title": "VidGuard-R1: AI-Generated Video Detection and Explanation via Reasoning MLLMs and RL",
        "link": "/arxiv/2510.02282",
        "arxiv_id": "2510.02282",
        "authors": "Kyoungjun Park, Yifan Yang, Juheon Yi, Shicheng Zheng, Yifei Shen, Dongqi Han, Caihua Shan, Muhammad Muaz, Lili Qiu",
        "summary": "With the rapid advancement of AI-generated videos, there is an urgent need for effective detection tools to mitigate societal risks such as misinformation and reputational harm. In addition to accurate classification, it is essential that detection models provide interpretable explanations to ensure transparency for regulators and end users. To address these challenges, we introduce VidGuard-R1, the first video authenticity detector that fine-tunes a multi-modal large language model (MLLM) using group relative policy optimization (GRPO). Our model delivers both highly accurate judgments and insightful reasoning. We curate a challenging dataset of 140k real and AI-generated videos produced by state-of-the-art generation models, carefully designing the generation process to maximize discrimination difficulty. We then fine-tune Qwen-VL using GRPO with two specialized reward models that target temporal artifacts and generation complexity. Extensive experiments demonstrate that VidGuard-R1 achieves state-of-the-art zero-shot performance on existing benchmarks, with additional training pushing accuracy above 95%. Case studies further show that VidGuard-R1 produces precise and interpretable rationales behind its predictions. The code is publicly available at https://VidGuard-R1.github.io.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.424536"
    },
    {
        "index": "#158",
        "title": "Quantum Fisher information matrices from Rényi relative entropies",
        "link": "/arxiv/2510.02218",
        "arxiv_id": "2510.02218",
        "authors": "Mark M. Wilde",
        "summary": "Quantum generalizations of the Fisher information are important in quantum information science, with applications in high energy and condensed matter physics and in quantum estimation theory, machine learning, and optimization. One can derive a quantum generalization of the Fisher information matrix in a natural way as the Hessian matrix arising in a Taylor expansion of a smooth divergence. Such an approach is appealing for quantum information theorists, given the ubiquity of divergences in quantum information theory. In contrast to the classical case, there is not a unique quantum generalization of the Fisher information matrix, similar to how there is not a unique quantum generalization of the relative entropy or the Rényi relative entropy. In this paper, I derive information matrices arising from the log-Euclidean, $\\alpha$-$z$, and geometric Rényi relative entropies, with the main technical tool for doing so being the method of divided differences for calculating matrix derivatives. Interestingly, for all non-negative values of the Rényi parameter $\\alpha$, the log-Euclidean Rényi relative entropy leads to the Kubo-Mori information matrix, and the geometric Rényi relative entropy leads to the right-logarithmic derivative Fisher information matrix. Thus, the resulting information matrices obey the data-processing inequality for all non-negative values of the Rényi parameter $\\alpha$ even though the original quantities do not. Additionally, I derive and establish basic properties of $\\alpha$-$z$ information matrices resulting from the $\\alpha$-$z$ Rényi relative entropies. For parameterized thermal states, I establish formulas for their $\\alpha$-$z$ information matrices and hybrid quantum-classical algorithms for estimating them, with applications in quantum Boltzmann machine learning.",
        "subjects": "Quantum Physics, Statistical Mechanics, Information Theory, Machine Learning, High Energy Physics - Theory",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.433934"
    },
    {
        "index": "#159",
        "title": "Measurement-Guided Consistency Model Sampling for Inverse Problems",
        "link": "/arxiv/2510.02208",
        "arxiv_id": "2510.02208",
        "authors": "Amirreza Tanevardi, Pooria Abbas Rad Moghadam, Sajjad Amini",
        "summary": "Diffusion models have become powerful generative priors for solving inverse imaging problems, but their reliance on slow multi-step sampling limits practical deployment. Consistency models address this bottleneck by enabling high-quality generation in a single or only a few steps, yet their direct adaptation to inverse problems is underexplored. In this paper, we present a modified consistency sampling approach tailored for inverse problem reconstruction: the sampler's stochasticity is guided by a measurement-consistency mechanism tied to the measurement operator, which enforces fidelity to the acquired measurements while retaining the efficiency of consistency-based generation. Experiments on Fashion-MNIST and LSUN Bedroom datasets demonstrate consistent improvements in perceptual and pixel-level metrics, including Fréchet Inception Distance, Kernel Inception Distance, peak signal-to-noise ratio, and structural similarity index measure, compared to baseline consistency sampling, yielding competitive or superior reconstructions with only a handful of steps.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.434408"
    },
    {
        "index": "#161",
        "title": "Hybrid Physics-ML Framework for Pan-Arctic Permafrost Infrastructure Risk at Record 2.9-Million Observation Scale",
        "link": "/arxiv/2510.02189",
        "arxiv_id": "2510.02189",
        "authors": "Boris Kriuk",
        "summary": "Arctic warming threatens over 100 billion in permafrost-dependent infrastructure across Northern territories, yet existing risk assessment frameworks lack spatiotemporal validation, uncertainty quantification, and operational decision-support capabilities. We present a hybrid physics-machine learning framework integrating 2.9 million observations from 171,605 locations (2005-2021) combining permafrost fraction data with climate reanalysis. Our stacked ensemble model (Random Forest + Histogram Gradient Boosting + Elastic Net) achieves R2=0.980 (RMSE=5.01 pp) with rigorous spatiotemporal cross-validation preventing data leakage. To address machine learning limitations in extrapolative climate scenarios, we develop a hybrid approach combining learned climate-permafrost relationships (60%) with physical permafrost sensitivity models (40%, -10 pp/C). Under RCP8.5 forcing (+5C over 10 years), we project mean permafrost fraction decline of -20.3 pp (median: -20.0 pp), with 51.5% of Arctic Russia experiencing over 20 percentage point loss. Infrastructure risk classification identifies 15% high-risk zones (25% medium-risk) with spatially explicit uncertainty maps. Our framework represents the largest validated permafrost ML dataset globally, provides the first operational hybrid physics-ML forecasting system for Arctic infrastructure, and delivers open-source tools enabling probabilistic permafrost projections for engineering design codes and climate adaptation planning. The methodology is generalizable to other permafrost regions and demonstrates how hybrid approaches can overcome pure data-driven limitations in climate change applications.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.435353"
    },
    {
        "index": "#162",
        "title": "High-Fidelity Speech Enhancement via Discrete Audio Tokens",
        "link": "/arxiv/2510.02187",
        "arxiv_id": "2510.02187",
        "authors": "Luca A. Lanzendörfer, Frédéric Berdoz, Antonis Asonitis, Roger Wattenhofer",
        "summary": "Recent autoregressive transformer-based speech enhancement (SE) methods have shown promising results by leveraging advanced semantic understanding and contextual modeling of speech. However, these approaches often rely on complex multi-stage pipelines and low sampling rate codecs, limiting them to narrow and task-specific speech enhancement. In this work, we introduce DAC-SE1, a simplified language model-based SE framework leveraging discrete high-resolution audio representations; DAC-SE1 preserves fine-grained acoustic details while maintaining semantic coherence. Our experiments show that DAC-SE1 surpasses state-of-the-art autoregressive SE methods on both objective perceptual metrics and in a MUSHRA human evaluation. We release our codebase and model checkpoints to support further research in scalable, unified, and high-quality speech enhancement.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.435865"
    },
    {
        "index": "#163",
        "title": "GeoPurify: A Data-Efficient Geometric Distillation Framework for Open-Vocabulary 3D Segmentation",
        "link": "/arxiv/2510.02186",
        "arxiv_id": "2510.02186",
        "authors": "Weijia Dou, Xu Zhang, Yi Bin, Jian Liu, Bo Peng, Guoqing Wang, Yang Yang, Heng Tao Shen",
        "summary": "Recent attempts to transfer features from 2D Vision-Language Models (VLMs) to 3D semantic segmentation expose a persistent trade-off. Directly projecting 2D features into 3D yields noisy and fragmented predictions, whereas enforcing geometric coherence necessitates costly training pipelines and large-scale annotated 3D data. We argue that this limitation stems from the dominant segmentation-and-matching paradigm, which fails to reconcile 2D semantics with 3D geometric structure. The geometric cues are not eliminated during the 2D-to-3D transfer but remain latent within the noisy and view-aggregated features. To exploit this property, we propose GeoPurify that applies a small Student Affinity Network to purify 2D VLM-generated 3D point features using geometric priors distilled from a 3D self-supervised teacher model. During inference, we devise a Geometry-Guided Pooling module to further denoise the point cloud and ensure the semantic and structural consistency. Benefiting from latent geometric information and the learned affinity network, GeoPurify effectively mitigates the trade-off and achieves superior data efficiency. Extensive experiments on major 3D benchmarks demonstrate that GeoPurify achieves or surpasses state-of-the-art performance while utilizing only about 1.5% of the training data. Our codes and checkpoints are available at [https://github.com/tj12323/GeoPurify](https://github.com/tj12323/GeoPurify).",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.436379"
    },
    {
        "index": "#164",
        "title": "Uncovering Semantic Selectivity of Latent Groups in Higher Visual Cortex with Mutual Information-Guided Diffusion",
        "link": "/arxiv/2510.02182",
        "arxiv_id": "2510.02182",
        "authors": "Yule Wang, Joseph Yu, Chengrui Li, Weihan Li, Anqi Wu",
        "summary": "Understanding how neural populations in higher visual areas encode object-centered visual information remains a central challenge in computational neuroscience. Prior works have investigated representational alignment between artificial neural networks and the visual cortex. Nevertheless, these findings are indirect and offer limited insights to the structure of neural populations themselves. Similarly, decoding-based methods have quantified semantic features from neural populations but have not uncovered their underlying organizations. This leaves open a scientific question: \"how feature-specific visual information is distributed across neural populations in higher visual areas, and whether it is organized into structured, semantically meaningful subspaces.\" To tackle this problem, we present MIG-Vis, a method that leverages the generative power of diffusion models to visualize and validate the visual-semantic attributes encoded in neural latent subspaces. Our method first uses a variational autoencoder to infer a group-wise disentangled neural latent subspace from neural populations. Subsequently, we propose a mutual information (MI)-guided diffusion synthesis procedure to visualize the specific visual-semantic features encoded by each latent group. We validate MIG-Vis on multi-session neural spiking datasets from the inferior temporal (IT) cortex of two macaques. The synthesized results demonstrate that our method identifies neural latent groups with clear semantic selectivity to diverse visual features, including object pose, inter-category transformations, and intra-class content. These findings provide direct, interpretable evidence of structured semantic representation in the higher visual cortex and advance our understanding of its encoding principles.",
        "subjects": "Neurons and Cognition, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.442064"
    },
    {
        "index": "#166",
        "title": "NoMod: A Non-modular Attack on Module Learning With Errors",
        "link": "/arxiv/2510.02162",
        "arxiv_id": "2510.02162",
        "authors": "Cristian Bassotto, Ermes Franch, Marina Krček, Stjepan Picek",
        "summary": "The advent of quantum computing threatens classical public-key cryptography, motivating NIST's adoption of post-quantum schemes such as those based on the Module Learning With Errors (Module-LWE) problem. We present NoMod ML-Attack, a hybrid white-box cryptanalytic method that circumvents the challenge of modeling modular reduction by treating wrap-arounds as statistical corruption and casting secret recovery as robust linear estimation. Our approach combines optimized lattice preprocessing--including reduced-vector saving and algebraic amplification--with robust estimators trained via Tukey's Biweight loss. Experiments show NoMod achieves full recovery of binary secrets for dimension $n = 350$, recovery of sparse binomial secrets for $n = 256$, and successful recovery of sparse secrets in CRYSTALS-Kyber settings with parameters $(n, k) = (128, 3)$ and $(256, 2)$. We release our implementation in an anonymous repository https://anonymous.4open.science/r/NoMod-3BD4.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.443107"
    },
    {
        "index": "#172",
        "title": "Non-Asymptotic Analysis of Data Augmentation for Precision Matrix Estimation",
        "link": "/arxiv/2510.02119",
        "arxiv_id": "2510.02119",
        "authors": "Lucas Morisset, Adrien Hardy, Alain Durmus",
        "summary": "This paper addresses the problem of inverse covariance (also known as precision matrix) estimation in high-dimensional settings. Specifically, we focus on two classes of estimators: linear shrinkage estimators with a target proportional to the identity matrix, and estimators derived from data augmentation (DA). Here, DA refers to the common practice of enriching a dataset with artificial samples--typically generated via a generative model or through random transformations of the original data--prior to model fitting. For both classes of estimators, we derive estimators and provide concentration bounds for their quadratic error. This allows for both method comparison and hyperparameter tuning, such as selecting the optimal proportion of artificial samples. On the technical side, our analysis relies on tools from random matrix theory. We introduce a novel deterministic equivalent for generalized resolvent matrices, accommodating dependent samples with specific structure. We support our theoretical results with numerical experiments.",
        "subjects": "Machine Learning, Machine Learning, Probability, Statistics Theory",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.446125"
    },
    {
        "index": "#173",
        "title": "SoundReactor: Frame-level Online Video-to-Audio Generation",
        "link": "/arxiv/2510.02110",
        "arxiv_id": "2510.02110",
        "authors": "Koichi Saito, Julian Tanke, Christian Simon, Masato Ishii, Kazuki Shimada, Zachary Novack, Zhi Zhong, Akio Hayakawa, Takashi Shibuya, Yuki Mitsufuji",
        "summary": "Prevailing Video-to-Audio (V2A) generation models operate offline, assuming an entire video sequence or chunks of frames are available beforehand. This critically limits their use in interactive applications such as live content creation and emerging generative world models. To address this gap, we introduce the novel task of frame-level online V2A generation, where a model autoregressively generates audio from video without access to future video frames. Furthermore, we propose SoundReactor, which, to the best of our knowledge, is the first simple yet effective framework explicitly tailored for this task. Our design enforces end-to-end causality and targets low per-frame latency with audio-visual synchronization. Our model's backbone is a decoder-only causal transformer over continuous audio latents. For vision conditioning, it leverages grid (patch) features extracted from the smallest variant of the DINOv2 vision encoder, which are aggregated into a single token per frame to maintain end-to-end causality and efficiency. The model is trained through a diffusion pre-training followed by consistency fine-tuning to accelerate the diffusion head decoding. On a benchmark of diverse gameplay videos from AAA titles, our model successfully generates semantically and temporally aligned, high-quality full-band stereo audio, validated by both objective and human evaluations. Furthermore, our model achieves low per-frame waveform-level latency (26.3ms with the head NFE=1, 31.5ms with NFE=4) on 30FPS, 480p videos using a single H100. Demo samples are available at https://koichi-saito-sony.github.io/soundreactor/.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.446674"
    },
    {
        "index": "#174",
        "title": "Adaptive Kernel Selection for Stein Variational Gradient Descent",
        "link": "/arxiv/2510.02067",
        "arxiv_id": "2510.02067",
        "authors": "Moritz Melcher, Simon Weissmann, Ashia C. Wilson, Jakob Zech",
        "summary": "A central challenge in Bayesian inference is efficiently approximating posterior distributions. Stein Variational Gradient Descent (SVGD) is a popular variational inference method which transports a set of particles to approximate a target distribution. The SVGD dynamics are governed by a reproducing kernel Hilbert space (RKHS) and are highly sensitive to the choice of the kernel function, which directly influences both convergence and approximation quality. The commonly used median heuristic offers a simple approach for setting kernel bandwidths but lacks flexibility and often performs poorly, particularly in high-dimensional settings. In this work, we propose an alternative strategy for adaptively choosing kernel parameters over an abstract family of kernels. Recent convergence analyses based on the kernelized Stein discrepancy (KSD) suggest that optimizing the kernel parameters by maximizing the KSD can improve performance. Building on this insight, we introduce Adaptive SVGD (Ad-SVGD), a method that alternates between updating the particles via SVGD and adaptively tuning kernel bandwidths through gradient ascent on the KSD. We provide a simplified theoretical analysis that extends existing results on minimizing the KSD for fixed kernels to our adaptive setting, showing convergence properties for the maximal KSD over our kernel class. Our empirical results further support this intuition: Ad-SVGD consistently outperforms standard heuristics in a variety of tasks.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.452293"
    },
    {
        "index": "#176",
        "title": "Multidata Causal Discovery for Statistical Hurricane Intensity Forecasting",
        "link": "/arxiv/2510.02050",
        "arxiv_id": "2510.02050",
        "authors": "Saranya Ganesh S., Frederick Iat-Hin Tam, Milton S. Gomez, Marie McGraw, Mark DeMaria, Kate Musgrave, Jakob Runge, Tom Beucler",
        "summary": "Improving statistical forecasts of Atlantic hurricane intensity is limited by complex nonlinear interactions and difficulty in identifying relevant predictors. Conventional methods prioritize correlation or fit, often overlooking confounding variables and limiting generalizability to unseen tropical storms. To address this, we leverage a multidata causal discovery framework with a replicated dataset based on Statistical Hurricane Intensity Prediction Scheme (SHIPS) using ERA5 meteorological reanalysis. We conduct multiple experiments to identify and select predictors causally linked to hurricane intensity changes. We train multiple linear regression models to compare causal feature selection with no selection, correlation, and random forest feature importance across five forecast lead times from 1 to 5 days (24 to 120 hours). Causal feature selection consistently outperforms on unseen test cases, especially for lead times shorter than 3 days. The causal features primarily include vertical shear, mid-tropospheric potential vorticity and surface moisture conditions, which are physically significant yet often underutilized in hurricane intensity predictions. Further, we build an extended predictor set (SHIPS+) by adding selected features to the standard SHIPS predictors. SHIPS+ yields increased short-term predictive skill at lead times of 24, 48, and 72 hours. Adding nonlinearity using multilayer perceptron further extends skill to longer lead times, despite our framework being purely regional and not requiring global forecast data. Operational SHIPS tests confirm that three of the six added causally discovered predictors improve forecasts, with the largest gains at longer lead times. Our results demonstrate that causal discovery improves hurricane intensity prediction and pave the way toward more empirical forecasts.",
        "subjects": "Applications, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.453335"
    },
    {
        "index": "#177",
        "title": "Variational Secret Common Randomness Extraction",
        "link": "/arxiv/2510.02048",
        "arxiv_id": "2510.02048",
        "authors": "Xinyang Li, Vlad C. Andrei, Peter J. Gu, Yiqi Chen, Ullrich J. Mönich, Holger Boche",
        "summary": "This paper studies the problem of extracting common randomness (CR) or secret keys from correlated random sources observed by two legitimate parties, Alice and Bob, through public discussion in the presence of an eavesdropper, Eve. We propose a practical two-stage CR extraction framework. In the first stage, the variational probabilistic quantization (VPQ) step is introduced, where Alice and Bob employ probabilistic neural network (NN) encoders to map their observations into discrete, nearly uniform random variables (RVs) with high agreement probability while minimizing information leakage to Eve. This is realized through a variational learning objective combined with adversarial training. In the second stage, a secure sketch using code-offset construction reconciles the encoder outputs into identical secret keys, whose secrecy is guaranteed by the VPQ objective. As a representative application, we study physical layer key (PLK) generation. Beyond the traditional methods, which rely on the channel reciprocity principle and require two-way channel probing, thus suffering from large protocol overhead and being unsuitable in high mobility scenarios, we propose a sensing-based PLK generation method for integrated sensing and communications (ISAC) systems, where paired range-angle (RA) maps measured at Alice and Bob serve as correlated sources. The idea is verified through both end-to-end simulations and real-world software-defined radio (SDR) measurements, including scenarios where Eve has partial knowledge about Bob's position. The results demonstrate the feasibility and convincing performance of both the proposed CR extraction framework and sensing-based PLK generation method.",
        "subjects": "Information Theory, Machine Learning, Signal Processing",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.453846"
    },
    {
        "index": "#178",
        "title": "Zero-shot Human Pose Estimation using Diffusion-based Inverse solvers",
        "link": "/arxiv/2510.02043",
        "arxiv_id": "2510.02043",
        "authors": "Sahil Bhandary Karnoor, Romit Roy Choudhury",
        "summary": "Pose estimation refers to tracking a human's full body posture, including their head, torso, arms, and legs. The problem is challenging in practical settings where the number of body sensors are limited. Past work has shown promising results using conditional diffusion models, where the pose prediction is conditioned on both <location, rotation> measurements from the sensors. Unfortunately, nearly all these approaches generalize poorly across users, primarly because location measurements are highly influenced by the body size of the user. In this paper, we formulate pose estimation as an inverse problem and design an algorithm capable of zero-shot generalization. Our idea utilizes a pre-trained diffusion model and conditions it on rotational measurements alone; the priors from this model are then guided by a likelihood term, derived from the measured locations. Thus, given any user, our proposed InPose method generatively estimates the highly likely sequence of poses that best explains the sparse on-body measurements.",
        "subjects": "Computer Vision and Pattern Recognition, Human-Computer Interaction, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.454301"
    },
    {
        "index": "#179",
        "title": "ShapeGen3DCP: A Deep Learning Framework for Layer Shape Prediction in 3D Concrete Printing",
        "link": "/arxiv/2510.02009",
        "arxiv_id": "2510.02009",
        "authors": "Giacomo Rizzieri, Federico Lanteri, Liberato Ferrara, Massimiliano Cremonesi",
        "summary": "This work introduces ShapeGen3DCP, a deep learning framework for fast and accurate prediction of filament cross-sectional geometry in 3D Concrete Printing (3DCP). The method is based on a neural network architecture that takes as input both material properties in the fluid state (density, yield stress, plastic viscosity) and process parameters (nozzle diameter, nozzle height, printing and flow velocities) to directly predict extruded layer shapes. To enhance generalization, some inputs are reformulated into dimensionless parameters that capture underlying physical principles. Predicted geometries are compactly represented using Fourier descriptors, which enforce smooth, closed, and symmetric profiles while reducing the prediction task to a small set of coefficients. The training dataset was synthetically generated using a well-established Particle Finite Element (PFEM) model of 3DCP, overcoming the scarcity of experimental data. Validation against diverse numerical and experimental cases shows strong agreement, confirming the framework's accuracy and reliability. This opens the way to practical uses ranging from pre-calibration of print settings, minimizing or even eliminating trial-and-error adjustments, to toolpath optimization for more advanced designs. Looking ahead, coupling the framework with simulations and sensor feedback could enable closed-loop digital twins for 3DCP, driving real-time process optimization, defect detection, and adaptive control of printing parameters.",
        "subjects": "Computational Engineering, Finance, and Science, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.454792"
    },
    {
        "index": "#180",
        "title": "Multi-bit Audio Watermarking",
        "link": "/arxiv/2510.01968",
        "arxiv_id": "2510.01968",
        "authors": "Luca A. Lanzendörfer, Kyle Fearne, Florian Grötschla, Roger Wattenhofer",
        "summary": "We present Timbru, a post-hoc audio watermarking model that achieves state-of-the-art robustness and imperceptibility trade-offs without training an embedder-detector model. Given any 44.1 kHz stereo music snippet, our method performs per-audio gradient optimization to add imperceptible perturbations in the latent space of a pretrained audio VAE, guided by a combined message and perceptual loss. The watermark can then be extracted using a pretrained CLAP model. We evaluate 16-bit watermarking on MUSDB18-HQ against AudioSeal, WavMark, and SilentCipher across common filtering, noise, compression, resampling, cropping, and regeneration attacks. Our approach attains the best average bit error rates, while preserving perceptual quality, demonstrating an efficient, dataset-free path to imperceptible audio watermarking.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.455298"
    },
    {
        "index": "#181",
        "title": "Bias beyond Borders: Global Inequalities in AI-Generated Music",
        "link": "/arxiv/2510.01963",
        "arxiv_id": "2510.01963",
        "authors": "Ahmet Solak, Florian Grötschla, Luca A. Lanzendörfer, Roger Wattenhofer",
        "summary": "While recent years have seen remarkable progress in music generation models, research on their biases across countries, languages, cultures, and musical genres remains underexplored. This gap is compounded by the lack of datasets and benchmarks that capture the global diversity of music. To address these challenges, we introduce GlobalDISCO, a large-scale dataset consisting of 73k music tracks generated by state-of-the-art commercial generative music models, along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset spans 147 languages and includes musical style prompts extracted from MusicBrainz and Wikipedia. The dataset is globally balanced, representing musical styles from artists across 79 countries and five continents. Our evaluation reveals large disparities in music quality and alignment with reference music between high-resource and low-resource regions. Furthermore, we find marked differences in model performance between mainstream and geographically niche genres, including cases where models generate music for regional genres that more closely align with the distribution of mainstream styles.",
        "subjects": "Sound, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.455778"
    },
    {
        "index": "#182",
        "title": "Uniform-in-time convergence bounds for Persistent Contrastive Divergence Algorithms",
        "link": "/arxiv/2510.01944",
        "arxiv_id": "2510.01944",
        "authors": "Paul Felix Valsecchi Oliva, O. Deniz Akyildiz, Andrew Duncan",
        "summary": "We propose a continuous-time formulation of persistent contrastive divergence (PCD) for maximum likelihood estimation (MLE) of unnormalised densities. Our approach expresses PCD as a coupled, multiscale system of stochastic differential equations (SDEs), which perform optimisation of the parameter and sampling of the associated parametrised density, simultaneously. From this novel formulation, we are able to derive explicit bounds for the error between the PCD iterates and the MLE solution for the model parameter. This is made possible by deriving uniform-in-time (UiT) bounds for the difference in moments between the multiscale system and the averaged regime. An efficient implementation of the continuous-time scheme is introduced, leveraging a class of explicit, stable intregators, stochastic orthogonal Runge-Kutta Chebyshev (S-ROCK), for which we provide explicit error estimates in the long-time regime. This leads to a novel method for training energy-based models (EBMs) with explicit error guarantees.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.456226"
    },
    {
        "index": "#183",
        "title": "Smooth Quasar-Convex Optimization with Constraints",
        "link": "/arxiv/2510.01943",
        "arxiv_id": "2510.01943",
        "authors": "David Martínez-Rubio",
        "summary": "Quasar-convex functions form a broad nonconvex class with applications to linear dynamical systems, generalized linear models, and Riemannian optimization, among others. Current nearly optimal algorithms work only in affine spaces due to the loss of one degree of freedom when working with general convex constraints. Obtaining an accelerated algorithm that makes nearly optimal $\\widetilde{O}(1/(\\gamma\\sqrt{\\epsilon}))$ first-order queries to a $\\gamma$-quasar convex smooth function \\emph{with constraints} was independently asked as an open problem in Martínez-Rubio (2022); Lezane, Langer, and Koolen (2024). In this work, we solve this question by designing an inexact accelerated proximal point algorithm that we implement using a first-order method achieving the aforementioned rate and, as a consequence, we improve the complexity of the accelerated geodesically Riemannian optimization solution in Martínez-Rubio (2022). We also analyze projected gradient descent and Frank-Wolfe algorithms in this constrained quasar-convex setting. To the best of our knowledge, our work provides the first analyses of first-order methods for quasar-convex smooth functions with general convex constraints.",
        "subjects": "Optimization and Control, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.456662"
    },
    {
        "index": "#185",
        "title": "Precise Dynamics of Diagonal Linear Networks: A Unifying Analysis by Dynamical Mean-Field Theory",
        "link": "/arxiv/2510.01930",
        "arxiv_id": "2510.01930",
        "authors": "Sota Nishiyama, Masaaki Imaizumi",
        "summary": "Diagonal linear networks (DLNs) are a tractable model that captures several nontrivial behaviors in neural network training, such as initialization-dependent solutions and incremental learning. These phenomena are typically studied in isolation, leaving the overall dynamics insufficiently understood. In this work, we present a unified analysis of various phenomena in the gradient flow dynamics of DLNs. Using Dynamical Mean-Field Theory (DMFT), we derive a low-dimensional effective process that captures the asymptotic gradient flow dynamics in high dimensions. Analyzing this effective process yields new insights into DLN dynamics, including loss convergence rates and their trade-off with generalization, and systematically reproduces many of the previously observed phenomena. These findings deepen our understanding of DLNs and demonstrate the effectiveness of the DMFT approach in analyzing high-dimensional learning dynamics of neural networks.",
        "subjects": "Machine Learning, Disordered Systems and Neural Networks, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.462886"
    },
    {
        "index": "#188",
        "title": "Deep Hedging Under Non-Convexity: Limitations and a Case for AlphaZero",
        "link": "/arxiv/2510.01874",
        "arxiv_id": "2510.01874",
        "authors": "Matteo Maggiolo, Giuseppe Nuti, Miroslav Štrupl, Oleg Szehr",
        "summary": "This paper examines replication portfolio construction in incomplete markets - a key problem in financial engineering with applications in pricing, hedging, balance sheet management, and energy storage planning. We model this as a two-player game between an investor and the market, where the investor makes strategic bets on future states while the market reveals outcomes. Inspired by the success of Monte Carlo Tree Search in stochastic games, we introduce an AlphaZero-based system and compare its performance to deep hedging - a widely used industry method based on gradient descent. Through theoretical analysis and experiments, we show that deep hedging struggles in environments where the $Q$-function is not subject to convexity constraints - such as those involving non-convex transaction costs, capital constraints, or regulatory limitations - converging to local optima. We construct specific market environments to highlight these limitations and demonstrate that AlphaZero consistently finds near-optimal replication strategies. On the theoretical side, we establish a connection between deep hedging and convex optimization, suggesting that its effectiveness is contingent on convexity assumptions. Our experiments further suggest that AlphaZero is more sample-efficient - an important advantage in data-scarce, overfitting-prone derivative markets.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.464459"
    },
    {
        "index": "#189",
        "title": "Ranking Items from Discrete Ratings: The Cost of Unknown User Thresholds",
        "link": "/arxiv/2510.01871",
        "arxiv_id": "2510.01871",
        "authors": "Oscar Villemaud, Suryanarayana Sankagiri, Matthias Grossglauser",
        "summary": "Ranking items is a central task in many information retrieval and recommender systems. User input for the ranking task often comes in the form of ratings on a coarse discrete scale. We ask whether it is possible to recover a fine-grained item ranking from such coarse-grained ratings. We model items as having scores and users as having thresholds; a user rates an item positively if the item's score exceeds the user's threshold. Although all users agree on the total item order, estimating that order is challenging when both the scores and the thresholds are latent. Under our model, any ranking method naturally partitions the $n$ items into bins; the bins are ordered, but the items inside each bin are still unordered. Users arrive sequentially, and every new user can be queried to refine the current ranking. We prove that achieving a near-perfect ranking, measured by Spearman distance, requires $\\Theta(n^2)$ users (and therefore $\\Omega(n^2)$ queries). This is significantly worse than the $O(n\\log n)$ queries needed to rank from comparisons; the gap reflects the additional queries needed to identify the users who have the appropriate thresholds. Our bound also quantifies the impact of a mismatch between score and threshold distributions via a quadratic divergence factor. To show the tightness of our results, we provide a ranking algorithm whose query complexity matches our bound up to a logarithmic factor. Our work reveals a tension in online ranking: diversity in thresholds is necessary to merge coarse ratings from many users into a fine-grained ranking, but this diversity has a cost if the thresholds are a priori unknown.",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.464938"
    },
    {
        "index": "#190",
        "title": "Microscaling Floating Point Formats for Large Language Models",
        "link": "/arxiv/2510.01863",
        "arxiv_id": "2510.01863",
        "authors": "Marco Cococcioni, Dario Pagani, Federico Rossi",
        "summary": "The increasing computational and memory demands of large language models (LLMs) necessitate innovative approaches to optimize resource usage without compromising performance. This paper leverages microscaling floating-point formats, a novel technique designed to address these challenges by reducing the storage and computational overhead associated with numerical representations in LLMs. Unlike traditional floating-point representations that allocate a dedicated scale for each value, microscaling employs a shared scale across a block of values, enabling compact one-byte floating-point representations while maintaining an extended dynamic range. We explore the application of microscaling in the context of 8-bit floating-point formats to significantly reduce memory footprint and computational costs. We tested several configurations of microscaling floats within the GPT-2 LLM architecture, demonstrating that microscaling data formats can achieve competitive accuracy during training and inference, proving its efficacy as a resource-efficient alternative for deploying LLMs at scale. The source code is publicly available at: https://github.com/unipi-dii-compressedarith/llm.c-sve",
        "subjects": "Neural and Evolutionary Computing, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.465403"
    },
    {
        "index": "#192",
        "title": "A reproducible comparative study of categorical kernels for Gaussian process regression, with new clustering-based nested kernels",
        "link": "/arxiv/2510.01840",
        "arxiv_id": "2510.01840",
        "authors": "Raphaël Carpintero Perez, Sébastien Da Veiga, Josselin Garnier",
        "summary": "Designing categorical kernels is a major challenge for Gaussian process regression with continuous and categorical inputs. Despite previous studies, it is difficult to identify a preferred method, either because the evaluation metrics, the optimization procedure, or the datasets change depending on the study. In particular, reproducible code is rarely available. The aim of this paper is to provide a reproducible comparative study of all existing categorical kernels on many of the test cases investigated so far. We also propose new evaluation metrics inspired by the optimization community, which provide quantitative rankings of the methods across several tasks. From our results on datasets which exhibit a group structure on the levels of categorical inputs, it appears that nested kernels methods clearly outperform all competitors. When the group structure is unknown or when there is no prior knowledge of such a structure, we propose a new clustering-based strategy using target encodings of categorical variables. We show that on a large panel of datasets, which do not necessarily have a known group structure, this estimation strategy still outperforms other approaches while maintaining low computational cost.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.466428"
    },
    {
        "index": "#193",
        "title": "PRESOL: a web-based computational setting for feature-based flare forecasting",
        "link": "/arxiv/2510.01799",
        "arxiv_id": "2510.01799",
        "authors": "Chiara Curletto, Paolo Massa, Valeria Tagliafico, Cristina Campi, Federico Benvenuto, Michele Piana, Andrea Tacchino",
        "summary": "Solar flares are the most explosive phenomena in the solar system and the main trigger of the events' chain that starts from Coronal Mass Ejections and leads to geomagnetic storms with possible impacts on the infrastructures at Earth. Data-driven solar flare forecasting relies on either deep learning approaches, which are operationally promising but with a low explainability degree, or machine learning algorithms, which can provide information on the physical descriptors that mostly impact the prediction. This paper describes a web-based technological platform for the execution of a computational pipeline of feature-based machine learning methods that provide predictions of the flare occurrence, feature ranking information, and assessment of the prediction performances.",
        "subjects": "Solar and Stellar Astrophysics, Instrumentation and Methods for Astrophysics, Machine Learning, Space Physics",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.467028"
    },
    {
        "index": "#195",
        "title": "Scalable Asynchronous Federated Modeling for Spatial Data",
        "link": "/arxiv/2510.01771",
        "arxiv_id": "2510.01771",
        "authors": "Jianwei Shi, Sameh Abdulah, Ying Sun, Marc G. Genton",
        "summary": "Spatial data are central to applications such as environmental monitoring and urban planning, but are often distributed across devices where privacy and communication constraints limit direct sharing. Federated modeling offers a practical solution that preserves data privacy while enabling global modeling across distributed data sources. For instance, environmental sensor networks are privacy- and bandwidth-constrained, motivating federated spatial modeling that shares only privacy-preserving summaries to produce timely, high-resolution pollution maps without centralizing raw data. However, existing federated modeling approaches either ignore spatial dependence or rely on synchronous updates that suffer from stragglers in heterogeneous environments. This work proposes an asynchronous federated modeling framework for spatial data based on low-rank Gaussian process approximations. The method employs block-wise optimization and introduces strategies for gradient correction, adaptive aggregation, and stabilized updates. We establish linear convergence with explicit dependence on staleness, a result of standalone theoretical significance. Moreover, numerical experiments demonstrate that the asynchronous algorithm achieves synchronous performance under balanced resource allocation and significantly outperforms it in heterogeneous settings, showcasing superior robustness and scalability.",
        "subjects": "Methodology, Machine Learning, Computation, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.473195"
    },
    {
        "index": "#196",
        "title": "Reducing Simulation Dependence in Neutrino Telescopes with Masked Point Transformers",
        "link": "/arxiv/2510.01733",
        "arxiv_id": "2510.01733",
        "authors": "Felix J. Yu, Nicholas Kamp, Carlos A. Argüelles",
        "summary": "Machine learning techniques in neutrino physics have traditionally relied on simulated data, which provides access to ground-truth labels. However, the accuracy of these simulations and the discrepancies between simulated and real data remain significant concerns, particularly for large-scale neutrino telescopes that operate in complex natural media. In recent years, self-supervised learning has emerged as a powerful paradigm for reducing dependence on labeled datasets. Here, we present the first self-supervised training pipeline for neutrino telescopes, leveraging point cloud transformers and masked autoencoders. By shifting the majority of training to real data, this approach minimizes reliance on simulations, thereby mitigating associated systematic uncertainties. This represents a fundamental departure from previous machine learning applications in neutrino telescopes, paving the way for substantial improvements in event reconstruction and classification.",
        "subjects": "High Energy Physics - Experiment, Instrumentation and Methods for Astrophysics, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.473669"
    },
    {
        "index": "#197",
        "title": "Contrastive Representation Regularization for Vision-Language-Action Models",
        "link": "/arxiv/2510.01711",
        "arxiv_id": "2510.01711",
        "authors": "Taeyoung Kim, Jimin Lee, Myungkyu Koo, Dongyoung Kim, Kyungmin Lee, Changyeon Kim, Younggyo Seo, Jinwoo Shin",
        "summary": "Vision-Language-Action (VLA) models have shown its capabilities in robot manipulation by leveraging rich representations from pre-trained Vision-Language Models (VLMs). However, their representations arguably remain suboptimal, lacking sensitivity to robotic signals such as control actions and proprioceptive states. To address the issue, we introduce Robot State-aware Contrastive Loss (RS-CL), a simple and effective representation regularization for VLA models, designed to bridge the gap between VLM representations and robotic signals. In particular, RS-CL aligns the representations more closely with the robot's proprioceptive states, by using relative distances between the states as soft supervision. Complementing the original action prediction objective, RS-CL effectively enhances control-relevant representation learning, while being lightweight and fully compatible with standard VLA training pipeline. Our empirical results demonstrate that RS-CL substantially improves the manipulation performance of state-of-the-art VLA models; it pushes the prior art from 30.8% to 41.5% on pick-and-place tasks in RoboCasa-Kitchen, through more accurate positioning during grasping and placing, and boosts success rates from 45.0% to 58.3% on challenging real-robot manipulation tasks.",
        "subjects": "Robotics, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.474213"
    },
    {
        "index": "#200",
        "title": "Evaluating the Robustness of a Production Malware Detection System to Transferable Adversarial Attacks",
        "link": "/arxiv/2510.01676",
        "arxiv_id": "2510.01676",
        "authors": "Milad Nasr, Yanick Fratantonio, Luca Invernizzi, Ange Albertini, Loua Farah, Alex Petit-Bianco, Andreas Terzis, Kurt Thomas, Elie Bursztein, Nicholas Carlini",
        "summary": "As deep learning models become widely deployed as components within larger production systems, their individual shortcomings can create system-level vulnerabilities with real-world impact. This paper studies how adversarial attacks targeting an ML component can degrade or bypass an entire production-grade malware detection system, performing a case study analysis of Gmail's pipeline where file-type identification relies on a ML model. The malware detection pipeline in use by Gmail contains a machine learning model that routes each potential malware sample to a specialized malware classifier to improve accuracy and performance. This model, called Magika, has been open sourced. By designing adversarial examples that fool Magika, we can cause the production malware service to incorrectly route malware to an unsuitable malware detector thereby increasing our chance of evading detection. Specifically, by changing just 13 bytes of a malware sample, we can successfully evade Magika in 90% of cases and thereby allow us to send malware files over Gmail. We then turn our attention to defenses, and develop an approach to mitigate the severity of these types of attacks. For our defended production model, a highly resourced adversary requires 50 bytes to achieve just a 20% attack success rate. We implement this defense, and, thanks to a collaboration with Google engineers, it has already been deployed in production for the Gmail classifier.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.475793"
    },
    {
        "index": "#203",
        "title": "ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models",
        "link": "/arxiv/2510.01582",
        "arxiv_id": "2510.01582",
        "authors": "Krishna Teja Chitty-Venkata, Murali Emani",
        "summary": "We develop ImageNet-Think, a multimodal reasoning dataset designed to aid the development of Vision Language Models (VLMs) with explicit reasoning capabilities. Our dataset is built on 250,000 images from ImageNet21k dataset, providing structured thinking tokens and corresponding answers. Our synthetic dataset is generated by two state-of-the-art VLMs: GLM-4.1V-9B-Thinking and Kimi-VL-A3B-Thinking-2506. Each image is accompanied by two pairs of thinking-answer sequences, creating a resource for training and evaluating multimodal reasoning models. We capture the step-by-step reasoning process of VLMs and the final descriptive answers. Our goal with this dataset is to enable the development of more robust VLMs while contributing to the broader understanding of multimodal reasoning mechanisms. The dataset and evaluation benchmarks will be publicly available to aid research in reasoning/thinking multimodal VLMs.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.477319"
    },
    {
        "index": "#205",
        "title": "AI Foundation Model for Time Series with Innovations Representation",
        "link": "/arxiv/2510.01560",
        "arxiv_id": "2510.01560",
        "authors": "Lang Tong, Xinyi Wang",
        "summary": "This paper introduces an Artificial Intelligence (AI) foundation model for time series in engineering applications, where causal operations are required for real-time monitoring and control. Since engineering time series are governed by physical, rather than linguistic, laws, large-language-model-based AI foundation models may be ineffective or inefficient. Building on the classical innovations representation theory of Wiener, Kallianpur, and Rosenblatt, we propose Time Series GPT (TS-GPT) -- an innovations-representation-based Generative Pre-trained Transformer for engineering monitoring and control. As an example of foundation model adaptation, we consider Probabilistic Generative Forecasting, which produces future time series samples from conditional probability distributions given past realizations. We demonstrate the effectiveness of TS-GPT in forecasting real-time locational marginal prices using historical data from U.S. independent system operators.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.478485"
    },
    {
        "index": "#206",
        "title": "CardioRAG: A Retrieval-Augmented Generation Framework for Multimodal Chagas Disease Detection",
        "link": "/arxiv/2510.01558",
        "arxiv_id": "2510.01558",
        "authors": "Zhengyang Shen, Xuehao Zhai, Hua Tu, Mayue Shi",
        "summary": "Chagas disease affects nearly 6 million people worldwide, with Chagas cardiomyopathy representing its most severe complication. In regions where serological testing capacity is limited, AI-enhanced electrocardiogram (ECG) screening provides a critical diagnostic alternative. However, existing machine learning approaches face challenges such as limited accuracy, reliance on large labeled datasets, and more importantly, weak integration with evidence-based clinical diagnostic indicators. We propose a retrieval-augmented generation framework, CardioRAG, integrating large language models with interpretable ECG-based clinical features, including right bundle branch block, left anterior fascicular block, and heart rate variability metrics. The framework uses variational autoencoder-learned representations for semantic case retrieval, providing contextual cases to guide clinical reasoning. Evaluation demonstrated high recall performance of 89.80%, with a maximum F1 score of 0.68 for effective identification of positive cases requiring prioritized serological testing. CardioRAG provides an interpretable, clinical evidence-based approach particularly valuable for resource-limited settings, demonstrating a pathway for embedding clinical indicators into trustworthy medical AI systems.",
        "subjects": "Computational Engineering, Finance, and Science, Machine Learning, Signal Processing",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.478993"
    },
    {
        "index": "#207",
        "title": "Robust Classification of Oral Cancer with Limited Training Data",
        "link": "/arxiv/2510.01547",
        "arxiv_id": "2510.01547",
        "authors": "Akshay Bhagwan Sonawane, Lena D. Swamikannan, Lakshman Tamil",
        "summary": "Oral cancer ranks among the most prevalent cancers globally, with a particularly high mortality rate in regions lacking adequate healthcare access. Early diagnosis is crucial for reducing mortality; however, challenges persist due to limited oral health programs, inadequate infrastructure, and a shortage of healthcare practitioners. Conventional deep learning models, while promising, often rely on point estimates, leading to overconfidence and reduced reliability. Critically, these models require large datasets to mitigate overfitting and ensure generalizability, an unrealistic demand in settings with limited training data. To address these issues, we propose a hybrid model that combines a convolutional neural network (CNN) with Bayesian deep learning for oral cancer classification using small training sets. This approach employs variational inference to enhance reliability through uncertainty quantification. The model was trained on photographic color images captured by smartphones and evaluated on three distinct test datasets. The proposed method achieved 94% accuracy on a test dataset with a distribution similar to that of the training data, comparable to traditional CNN performance. Notably, for real-world photographic image data, despite limitations and variations differing from the training dataset, the proposed model demonstrated superior generalizability, achieving 88% accuracy on diverse datasets compared to 72.94% for traditional CNNs, even with a smaller dataset. Confidence analysis revealed that the model exhibits low uncertainty (high confidence) for correctly classified samples and high uncertainty (low confidence) for misclassified samples. These results underscore the effectiveness of Bayesian inference in data-scarce environments in enhancing early oral cancer diagnosis by improving model reliability and generalizability.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.479456"
    },
    {
        "index": "#208",
        "title": "Growing Visual Generative Capacity for Pre-Trained MLLMs",
        "link": "/arxiv/2510.01546",
        "arxiv_id": "2510.01546",
        "authors": "Hanyu Wang, Jiaming Han, Ziyan Yang, Qi Zhao, Shanchuan Lin, Xiangyu Yue, Abhinav Shrivastava, Zhenheng Yang, Hao Chen",
        "summary": "Multimodal large language models (MLLMs) extend the success of language models to visual understanding, and recent efforts have sought to build unified MLLMs that support both understanding and generation. However, constructing such models remains challenging: hybrid approaches combine continuous embeddings with diffusion or flow-based objectives, producing high-quality images but breaking the autoregressive paradigm, while pure autoregressive approaches unify text and image prediction over discrete visual tokens but often face trade-offs between semantic alignment and pixel-level fidelity. In this work, we present Bridge, a pure autoregressive unified MLLM that augments pre-trained visual understanding models with generative ability through a Mixture-of-Transformers architecture, enabling both image understanding and generation within a single next-token prediction framework. To further improve visual generation fidelity, we propose a semantic-to-pixel discrete representation that integrates compact semantic tokens with fine-grained pixel tokens, achieving strong language alignment and precise description of visual details with only a 7.9% increase in sequence length. Extensive experiments across diverse multimodal benchmarks demonstrate that Bridge achieves competitive or superior results in both understanding and generation benchmarks, while requiring less training data and reduced training time compared to prior unified MLLMs.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.480065"
    },
    {
        "index": "#211",
        "title": "Aligning Video Models with Human Social Judgments via Behavior-Guided Fine-Tuning",
        "link": "/arxiv/2510.01502",
        "arxiv_id": "2510.01502",
        "authors": "Kathy Garcia, Leyla Isik",
        "summary": "Humans intuitively perceive complex social signals in visual scenes, yet it remains unclear whether state-of-the-art AI models encode the same similarity structure. We study (Q1) whether modern video and language models capture human-perceived similarity in social videos, and (Q2) how to instill this structure into models using human behavioral data. To address this, we introduce a new benchmark of over 49,000 odd-one-out similarity judgments on 250 three-second video clips of social interactions, and discover a modality gap: despite the task being visual, caption-based language embeddings align better with human similarity than any pretrained video model. We close this gap by fine-tuning a TimeSformer video model on these human judgments with our novel hybrid triplet-RSA objective using low-rank adaptation (LoRA), aligning pairwise distances to human similarity. This fine-tuning protocol yields significantly improved alignment with human perceptions on held-out videos in terms of both explained variance and odd-one-out triplet accuracy. Variance partitioning shows that the fine-tuned video model increases shared variance with language embeddings and explains additional unique variance not captured by the language model. Finally, we test transfer via linear probes and find that human-similarity fine-tuning strengthens the encoding of social-affective attributes (intimacy, valence, dominance, communication) relative to the pretrained baseline. Overall, our findings highlight a gap in pretrained video models' social recognition and demonstrate that behavior-guided fine-tuning shapes video representations toward human social perception.",
        "subjects": "Neurons and Cognition, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.481624"
    },
    {
        "index": "#213",
        "title": "Comparative Field Deployment of Reinforcement Learning and Model Predictive Control for Residential HVAC",
        "link": "/arxiv/2510.01475",
        "arxiv_id": "2510.01475",
        "authors": "Ozan Baris Mulayim, Elias N. Pergantis, Levi D. Reyes Premer, Bingqing Chen, Guannan Qu, Kevin J. Kircher, Mario Bergés",
        "summary": "Advanced control strategies like Model Predictive Control (MPC) offer significant energy savings for HVAC systems but often require substantial engineering effort, limiting scalability. Reinforcement Learning (RL) promises greater automation and adaptability, yet its practical application in real-world residential settings remains largely undemonstrated, facing challenges related to safety, interpretability, and sample efficiency. To investigate these practical issues, we performed a direct comparison of an MPC and a model-based RL controller, with each controller deployed for a one-month period in an occupied house with a heat pump system in West Lafayette, Indiana. This investigation aimed to explore scalability of the chosen RL and MPC implementations while ensuring safety and comparability. The advanced controllers were evaluated against each other and against the existing controller. RL achieved substantial energy savings (22\\% relative to the existing controller), slightly exceeding MPC's savings (20\\%), albeit with modestly higher occupant discomfort. However, when energy savings were normalized for the level of comfort provided, MPC demonstrated superior performance. This study's empirical results show that while RL reduces engineering overhead, it introduces practical trade-offs in model accuracy and operational robustness. The key lessons learned concern the difficulties of safe controller initialization, navigating the mismatch between control actions and their practical implementation, and maintaining the integrity of online learning in a live environment. These insights pinpoint the essential research directions needed to advance RL from a promising concept to a truly scalable HVAC control solution.",
        "subjects": "Systems and Control, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.487765"
    },
    {
        "index": "#215",
        "title": "Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories",
        "link": "/arxiv/2510.01454",
        "arxiv_id": "2510.01454",
        "authors": "Nilay Naharas, Dang Nguyen, Nesihan Bulut, Mohammadhossein Bateni, Vahab Mirrokni, Baharan Mirzasoleiman",
        "summary": "Data-efficient learning aims to eliminate redundancy in large training datasets by training models on smaller subsets of the most informative examples. While data selection has been extensively explored for vision models and large language models (LLMs), it remains underexplored for Large Vision-Language Models (LVLMs). Notably, none of existing methods can outperform random selection at different subset sizes. In this work, we propose the first principled method for data-efficient instruction tuning of LVLMs. We prove that examples with similar cross-modal attention matrices during instruction tuning have similar gradients. Thus, they influence model parameters in a similar manner and convey the same information to the model during training. Building on this insight, we propose XMAS, which clusters examples based on the trajectories of the top singular values of their attention matrices obtained from fine-tuning a small proxy LVLM. By sampling a balanced subset from these clusters, XMAS effectively removes redundancy in large-scale LVLM training data. Extensive experiments show that XMAS can discard 50% of the LLaVA-665k dataset and 85% of the Vision-Flan dataset while fully preserving performance of LLaVA-1.5-7B on 10 downstream benchmarks and speeding up its training by 1.2x. This is 30% more data reduction compared to the best baseline for LLaVA-665k. The project's website can be found at https://bigml-cs-ucla.github.io/XMAS-project-page/.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.488410"
    },
    {
        "index": "#216",
        "title": "Financial Stability Implications of Generative AI: Taming the Animal Spirits",
        "link": "/arxiv/2510.01451",
        "arxiv_id": "2510.01451",
        "authors": "Anne Lundgaard Hansen, Seung Jung Lee",
        "summary": "This paper investigates the impact of the adoption of generative AI on financial stability. We conduct laboratory-style experiments using large language models to replicate classic studies on herd behavior in trading decisions. Our results show that AI agents make more rational decisions than humans, relying predominantly on private information over market trends. Increased reliance on AI-powered trading advice could therefore potentially lead to fewer asset price bubbles arising from animal spirits that trade by following the herd. However, exploring variations in the experimental settings reveals that AI agents can be induced to herd optimally when explicitly guided to make profit-maximizing decisions. While optimal herding improves market discipline, this behavior still carries potential implications for financial stability. In other experimental variations, we show that AI agents are not purely algorithmic, but have inherited some elements of human conditioning and bias.",
        "subjects": "General Finance, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.488691"
    },
    {
        "index": "#220",
        "title": "Learning to Play Multi-Follower Bayesian Stackelberg Games",
        "link": "/arxiv/2510.01387",
        "arxiv_id": "2510.01387",
        "authors": "Gerson Personnat, Tao Lin, Safwan Hossain, David C. Parkes",
        "summary": "In a multi-follower Bayesian Stackelberg game, a leader plays a mixed strategy over $L$ actions to which $n\\ge 1$ followers, each having one of $K$ possible private types, best respond. The leader's optimal strategy depends on the distribution of the followers' private types. We study an online learning version of this problem: a leader interacts for $T$ rounds with $n$ followers with types sampled from an unknown distribution every round. The leader's goal is to minimize regret, defined as the difference between the cumulative utility of the optimal strategy and that of the actually chosen strategies. We design learning algorithms for the leader under different feedback settings. Under type feedback, where the leader observes the followers' types after each round, we design algorithms that achieve $\\mathcal O\\big(\\sqrt{\\min\\{L\\log(nKA T), nK \\} \\cdot T} \\big)$ regret for independent type distributions and $\\mathcal O\\big(\\sqrt{\\min\\{L\\log(nKA T), K^n \\} \\cdot T} \\big)$ regret for general type distributions. Interestingly, those bounds do not grow with $n$ at a polynomial rate. Under action feedback, where the leader only observes the followers' actions, we design algorithms with $\\mathcal O( \\min\\{\\sqrt{ n^L K^L A^{2L} L T \\log T}, K^n\\sqrt{ T } \\log T \\} )$ regret. We also provide a lower bound of $\\Omega(\\sqrt{\\min\\{L, nK\\}T})$, almost matching the type-feedback upper bounds.",
        "subjects": "Computer Science and Game Theory, Machine Learning, Theoretical Economics",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.489965"
    },
    {
        "index": "#224",
        "title": "Continuously Augmented Discrete Diffusion model for Categorical Generative Modeling",
        "link": "/arxiv/2510.01329",
        "arxiv_id": "2510.01329",
        "authors": "Huangjie Zheng, Shansan Gong, Ruixiang Zhang, Tianrong Chen, Jiatao Gu, Mingyuan Zhou, Navdeep Jaitly, Yizhe Zhang",
        "summary": "Standard discrete diffusion models treat all unobserved states identically by mapping them to an absorbing [MASK] token. This creates an 'information void' where semantic information that could be inferred from unmasked tokens is lost between denoising steps. We introduce Continuously Augmented Discrete Diffusion (CADD), a framework that augments the discrete state space with a paired diffusion in a continuous latent space. This yields graded, gradually corrupted states in which masked tokens are represented by noisy yet informative latent vectors rather than collapsed 'information voids'. At each reverse step, CADD may leverage the continuous latent as a semantic hint to guide discrete denoising. The design is clean and compatible with existing discrete diffusion training. At sampling time, the strength and choice of estimator for the continuous latent vector enables a controlled trade-off between mode-coverage (generating diverse outputs) and mode-seeking (generating contextually precise outputs) behaviors. Empirically, we demonstrate CADD improves generative quality over mask-based diffusion across text generation, image synthesis, and code modeling, with consistent gains on both qualitative and quantitative metrics against strong discrete baselines.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.491231"
    },
    {
        "index": "#225",
        "title": "Combining complex Langevin dynamics with score-based and energy-based diffusion models",
        "link": "/arxiv/2510.01328",
        "arxiv_id": "2510.01328",
        "authors": "Gert Aarts, Diaa E. Habibi, Lingxiao Wang, Kai Zhou",
        "summary": "Theories with a sign problem due to a complex action or Boltzmann weight can sometimes be numerically solved using a stochastic process in the complexified configuration space. However, the probability distribution effectively sampled by this complex Langevin process is not known a priori and notoriously hard to understand. In generative AI, diffusion models can learn distributions, or their log derivatives, from data. We explore the ability of diffusion models to learn the distributions sampled by a complex Langevin process, comparing score-based and energy-based diffusion models, and speculate about possible applications.",
        "subjects": "High Energy Physics - Lattice, Disordered Systems and Neural Networks, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.491538"
    },
    {
        "index": "#226",
        "title": "Hybrid Predictive Modeling of Malaria Incidence in the Amhara Region, Ethiopia: Integrating Multi-Output Regression and Time-Series Forecasting",
        "link": "/arxiv/2510.01302",
        "arxiv_id": "2510.01302",
        "authors": "Kassahun Azezew, Amsalu Tesema, Bitew Mekuria, Ayenew Kassie, Animut Embiale, Ayodeji Olalekan Salau, Tsega Asresa",
        "summary": "Malaria remains a major public health concern in Ethiopia, particularly in the Amhara Region, where seasonal and unpredictable transmission patterns make prevention and control challenging. Accurately forecasting malaria outbreaks is essential for effective resource allocation and timely interventions. This study proposes a hybrid predictive modeling framework that combines time-series forecasting, multi-output regression, and conventional regression-based prediction to forecast the incidence of malaria. Environmental variables, past malaria case data, and demographic information from Amhara Region health centers were used to train and validate the models. The multi-output regression approach enables the simultaneous prediction of multiple outcomes, including Plasmodium species-specific cases, temporal trends, and spatial variations, whereas the hybrid framework captures both seasonal patterns and correlations among predictors. The proposed model exhibits higher prediction accuracy than single-method approaches, exposing hidden patterns and providing valuable information to public health authorities. This study provides a valid and repeatable malaria incidence prediction framework that can support evidence-based decision-making, targeted interventions, and resource optimization in endemic areas.",
        "subjects": "Other Quantitative Biology, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.491883"
    },
    {
        "index": "#227",
        "title": "MorphGen: Controllable and Morphologically Plausible Generative Cell-Imaging",
        "link": "/arxiv/2510.01298",
        "arxiv_id": "2510.01298",
        "authors": "Berker Demirel, Marco Fumero, Theofanis Karaletsos, Francesco Locatello",
        "summary": "Simulating in silico cellular responses to interventions is a promising direction to accelerate high-content image-based assays, critical for advancing drug discovery and gene editing. To support this, we introduce MorphGen, a state-of-the-art diffusion-based generative model for fluorescent microscopy that enables controllable generation across multiple cell types and perturbations. To capture biologically meaningful patterns consistent with known cellular morphologies, MorphGen is trained with an alignment loss to match its representations to the phenotypic embeddings of OpenPhenom, a state-of-the-art biological foundation model. Unlike prior approaches that compress multichannel stains into RGB images -- thus sacrificing organelle-specific detail -- MorphGen generates the complete set of fluorescent channels jointly, preserving per-organelle structures and enabling a fine-grained morphological analysis that is essential for biological interpretation. We demonstrate biological consistency with real images via CellProfiler features, and MorphGen attains an FID score over $35\\%$ lower than the prior state-of-the-art MorphoDiff, which only generates RGB images for a single cell type. Code is available at https://github.com/czi-ai/MorphGen.",
        "subjects": "Quantitative Methods, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.492185"
    },
    {
        "index": "#229",
        "title": "Private Realizable-to-Agnostic Transformation with Near-Optimal Sample Complexity",
        "link": "/arxiv/2510.01291",
        "arxiv_id": "2510.01291",
        "authors": "Bo Li, Wei Wang, Peng Ye",
        "summary": "The realizable-to-agnostic transformation (Beimel et al., 2015; Alon et al., 2020) provides a general mechanism to convert a private learner in the realizable setting (where the examples are labeled by some function in the concept class) to a private learner in the agnostic setting (where no assumptions are imposed on the data). Specifically, for any concept class $\\mathcal{C}$ and error parameter $\\alpha$, a private realizable learner for $\\mathcal{C}$ can be transformed into a private agnostic learner while only increasing the sample complexity by $\\widetilde{O}(\\mathrm{VC}(\\mathcal{C})/\\alpha^2)$, which is essentially tight assuming a constant privacy parameter $\\varepsilon = \\Theta(1)$. However, when $\\varepsilon$ can be arbitrary, one has to apply the standard privacy-amplification-by-subsampling technique (Kasiviswanathan et al., 2011), resulting in a suboptimal extra sample complexity of $\\widetilde{O}(\\mathrm{VC}(\\mathcal{C})/\\alpha^2\\varepsilon)$ that involves a $1/\\varepsilon$ factor. In this work, we give an improved construction that eliminates the dependence on $\\varepsilon$, thereby achieving a near-optimal extra sample complexity of $\\widetilde{O}(\\mathrm{VC}(\\mathcal{C})/\\alpha^2)$ for any $\\varepsilon\\le 1$. Moreover, our result reveals that in private agnostic learning, the privacy cost is only significant for the realizable part. We also leverage our technique to obtain a nearly tight sample complexity bound for the private prediction problem, resolving an open question posed by Dwork and Feldman (2018) and Dagan and Feldman (2020).",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.497045"
    },
    {
        "index": "#243",
        "title": "Location Matters: Leveraging Multi-Resolution Geo-Embeddings for Housing Search",
        "link": "/arxiv/2510.01196",
        "arxiv_id": "2510.01196",
        "authors": "Ivo Silva, Pedro Nogueira, Guilherme Bonaldo",
        "summary": "QuintoAndar Group is Latin America's largest housing platform, revolutionizing property rentals and sales. Headquartered in Brazil, it simplifies the housing process by eliminating paperwork and enhancing accessibility for tenants, buyers, and landlords. With thousands of houses available for each city, users struggle to find the ideal home. In this context, location plays a pivotal role, as it significantly influences property value, access to amenities, and life quality. A great location can make even a modest home highly desirable. Therefore, incorporating location into recommendations is essential for their effectiveness. We propose a geo-aware embedding framework to address sparsity and spatial nuances in housing recommendations on digital rental platforms. Our approach integrates an hierarchical H3 grid at multiple levels into a two-tower neural architecture. We compare our method with a traditional matrix factorization baseline and a single-resolution variant using interaction data from our platform. Embedding specific evaluation reveals richer and more balanced embedding representations, while offline ranking simulations demonstrate a substantial uplift in recommendation quality.",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2025-09-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-07T00:44:34.503973"
    }
]