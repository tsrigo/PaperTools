[
    {
        "index": "#1",
        "title": "SimCity: Multi-Agent Urban Development Simulation with Rich Interactions",
        "link": "/arxiv/2510.01297",
        "arxiv_id": "2510.01297",
        "authors": "Yeqi Feng, Yucheng Lu, Hongyu Su, Tianxing He",
        "summary": "Large Language Models (LLMs) open new possibilities for constructing realistic and interpretable macroeconomic simulations. We present SimCity, a multi-agent framework that leverages LLMs to model an interpretable macroeconomic system with heterogeneous agents and rich interactions. Unlike classical equilibrium models that limit heterogeneity for tractability, or traditional agent-based models (ABMs) that rely on hand-crafted decision rules, SimCity enables flexible, adaptive behavior with transparent natural-language reasoning. Within SimCity, four core agent types (households, firms, a central bank, and a government) deliberate and participate in a frictional labor market, a heterogeneous goods market, and a financial market. Furthermore, a Vision-Language Model (VLM) determines the geographic placement of new firms and renders a mapped virtual city, allowing us to study both macroeconomic regularities and urban expansion dynamics within a unified environment. To evaluate the framework, we compile a checklist of canonical macroeconomic phenomena, including price elasticity of demand, Engel's Law, Okun's Law, the Phillips Curve, and the Beveridge Curve, and show that SimCity naturally reproduces these empirical patterns while remaining robust across simulation runs.",
        "subjects": "Multiagent Systems",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.287932"
    },
    {
        "index": "#2",
        "title": "LLM-based Multi-Agent Blackboard System for Information Discovery in Data Science",
        "link": "/arxiv/2510.01285",
        "arxiv_id": "2510.01285",
        "authors": "Alireza Salemi, Mihir Parmar, Palash Goyal, Yiwen Song, Jinsung Yoon, Hamed Zamani, Hamid Palangi, Tomas Pfister",
        "summary": "The rapid advancement of Large Language Models (LLMs) has opened new opportunities in data science, yet their practical deployment is often constrained by the challenge of discovering relevant data within large heterogeneous data lakes. Existing methods struggle with this: single-agent systems are quickly overwhelmed by large, heterogeneous files in the large data lakes, while multi-agent systems designed based on a master-slave paradigm depend on a rigid central controller for task allocation that requires precise knowledge of each sub-agent's capabilities. To address these limitations, we propose a novel multi-agent communication paradigm inspired by the blackboard architecture for traditional AI models. In this framework, a central agent posts requests to a shared blackboard, and autonomous subordinate agents -- either responsible for a partition of the data lake or general information retrieval -- volunteer to respond based on their capabilities. This design improves scalability and flexibility by eliminating the need for a central coordinator to have prior knowledge of all sub-agents' expertise. We evaluate our method on three benchmarks that require explicit data discovery: KramaBench and modified versions of DS-Bench and DA-Code to incorporate data discovery. Experimental results demonstrate that the blackboard architecture substantially outperforms baselines, including RAG and the master-slave multi-agent paradigm, achieving between 13% to 57% relative improvement in end-to-end task success and up to a 9% relative gain in F1 score for data discovery over the best-performing baselines across both proprietary and open-source LLMs. Our findings establish the blackboard paradigm as a scalable and generalizable communication framework for multi-agent systems.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computation and Language, Information Retrieval, Machine Learning",
        "date": "2025-09-30",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.288321"
    },
    {
        "index": "#3",
        "title": "FalseCrashReducer: Mitigating False Positive Crashes in OSS-Fuzz-Gen Using Agentic AI",
        "link": "/arxiv/2510.02185",
        "arxiv_id": "2510.02185",
        "authors": "Paschal C. Amusuo, Dongge Liu, Ricardo Andres Calvo Mendez, Jonathan Metzman, Oliver Chang, James C. Davis",
        "summary": "Fuzz testing has become a cornerstone technique for identifying software bugs and security vulnerabilities, with broad adoption in both industry and open-source communities. Directly fuzzing a function requires fuzz drivers, which translate random fuzzer inputs into valid arguments for the target function. Given the cost and expertise required to manually develop fuzz drivers, methods exist that leverage program analysis and Large Language Models to automatically generate these drivers. However, the generated fuzz drivers frequently lead to false positive crashes, especially in functions highly structured input and complex state requirements. This problem is especially crucial in industry-scale fuzz driver generation efforts like OSS-Fuzz-en, as reporting false positive crashes to maintainers impede trust in both the system and the team. This paper presents two AI-driven strategies to reduce false positives in OSS-Fuzz-Gen, a multi-agent system for automated fuzz driver generation. First, constraint-based fuzz driver generation proactively enforces constraints on a function's inputs and state to guide driver creation. Second, context-based crash validation reactively analyzes function callers to determine whether reported crashes are feasible from program entry points. Using 1,500 benchmark functions from OSS-Fuzz, we show that these strategies reduce spurious crashes by up to 8%, cut reported crashes by more than half, and demonstrate that frontier LLMs can serve as reliable program analysis agents. Our results highlight the promise and challenges of integrating AI into large-scale fuzzing pipelines.",
        "subjects": "Software Engineering, Cryptography and Security, Multiagent Systems",
        "date": "2025-10-02",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.288623"
    },
    {
        "index": "#4",
        "title": "BioinfoMCP: A Unified Platform Enabling MCP Interfaces in Agentic Bioinformatics",
        "link": "/arxiv/2510.02139",
        "arxiv_id": "2510.02139",
        "authors": "Florensia Widjaja, Zhangtianyi Chen, Juexiao Zhou",
        "summary": "Bioinformatics tools are essential for complex computational biology tasks, yet their integration with emerging AI-agent frameworks is hindered by incompatible interfaces, heterogeneous input-output formats, and inconsistent parameter conventions. The Model Context Protocol (MCP) provides a standardized framework for tool-AI communication, but manually converting hundreds of existing and rapidly growing specialized bioinformatics tools into MCP-compliant servers is labor-intensive and unsustainable. Here, we present BioinfoMCP, a unified platform comprising two components: BioinfoMCP Converter, which automatically generates robust MCP servers from tool documentation using large language models, and BioinfoMCP Benchmark, which systematically validates the reliability and versatility of converted tools across diverse computational tasks. We present a platform of 38 MCP-converted bioinformatics tools, extensively validated to show that 94.7% successfully executed complex workflows across three widely used AI-agent platforms. By removing technical barriers to AI automation, BioinfoMCP enables natural-language interaction with sophisticated bioinformatics analyses without requiring extensive programming expertise, offering a scalable path to intelligent, interoperable computational biology.",
        "subjects": "Quantitative Methods, Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-10-02",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.288899"
    },
    {
        "index": "#5",
        "title": "Cooperative Guidance for Aerial Defense in Multiagent Systems",
        "link": "/arxiv/2510.02087",
        "arxiv_id": "2510.02087",
        "authors": "Shivam Bajpai, Abhinav Sinha, Shashi Ranjan Kumar",
        "summary": "This paper addresses a critical aerial defense challenge in contested airspace, involving three autonomous aerial vehicles -- a hostile drone (the pursuer), a high-value drone (the evader), and a protective drone (the defender). We present a cooperative guidance framework for the evader-defender team that guarantees interception of the pursuer before it can capture the evader, even under highly dynamic and uncertain engagement conditions. Unlike traditional heuristic, optimal control, or differential game-based methods, we approach the problem within a time-constrained guidance framework, leveraging true proportional navigation based approach that ensures robust and guaranteed solutions to the aerial defense problem. The proposed strategy is computationally lightweight, scalable to a large number of agent configurations, and does not require knowledge of the pursuer's strategy or control laws. From arbitrary initial geometries, our method guarantees that key engagement errors are driven to zero within a fixed time, leading to a successful mission. Extensive simulations across diverse and adversarial scenarios confirm the effectiveness of the proposed strategy and its relevance for real-time autonomous defense in contested airspace environments.",
        "subjects": "Systems and Control, Multiagent Systems, Robotics, Dynamical Systems",
        "date": "2025-10-02",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.289173"
    },
    {
        "index": "#6",
        "title": "To Mask or to Mirror: Human-AI Alignment in Collective Reasoning",
        "link": "/arxiv/2510.01924",
        "arxiv_id": "2510.01924",
        "authors": "Crystal Qian, Aaron Parisi, Clémentine Bouleau, Vivian Tsai, Maël Lebreton, Lucas Dixon",
        "summary": "As large language models (LLMs) are increasingly used to model and augment collective decision-making, it is critical to examine their alignment with human social reasoning. We present an empirical framework for assessing collective alignment, in contrast to prior work on the individual level. Using the Lost at Sea social psychology task, we conduct a large-scale online experiment (N=748), randomly assigning groups to leader elections with either visible demographic attributes (e.g. name, gender) or pseudonymous aliases. We then simulate matched LLM groups conditioned on the human data, benchmarking Gemini 2.5, GPT 4.1, Claude Haiku 3.5, and Gemma 3. LLM behaviors diverge: some mirror human biases; others mask these biases and attempt to compensate for them. We empirically demonstrate that human-AI alignment in collective reasoning depends on context, cues, and model-specific inductive biases. Understanding how LLMs align with collective human behavior is critical to advancing socially-aligned AI, and demands dynamic benchmarks that capture the complexities of collective reasoning.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-02",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.289462"
    },
    {
        "index": "#7",
        "title": "TACOS: Task Agnostic COordinator of a multi-drone System",
        "link": "/arxiv/2510.01869",
        "arxiv_id": "2510.01869",
        "authors": "Alessandro Nazzari, Roberto Rubinacci, Marco Lovera",
        "summary": "When a single pilot is responsible for managing a multi-drone system, the task demands varying levels of autonomy, from direct control of individual UAVs, to group-level coordination, to fully autonomous swarm behaviors for accomplishing high-level tasks. Enabling such flexible interaction requires a framework that supports multiple modes of shared autonomy. As language models continue to improve in reasoning and planning, they provide a natural foundation for such systems, reducing pilot workload by enabling high-level task delegation through intuitive, language-based interfaces. In this paper we present TACOS (Task-Agnostic COordinator of a multi-drone System), a unified framework that enables high-level natural language control of multi-UAV systems through Large Language Models (LLMs). TACOS integrates three key capabilities into a single architecture: a one-to-many natural language interface for intuitive user interaction, an intelligent coordinator for translating user intent into structured task plans, and an autonomous agent that executes plans interacting with the real-world. TACOS allows a LLM to interact with a library of executable APIs, bridging semantic reasoning with real-time multi-robot coordination. We demonstrate the system in real-world multi-drone system and conduct an ablation study to assess the contribution of each module.",
        "subjects": "Robotics, Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-02",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.289761"
    },
    {
        "index": "#8",
        "title": "FOR-Prompting: From Objection to Revision via an Asymmetric Prompting Protocol",
        "link": "/arxiv/2510.01674",
        "arxiv_id": "2510.01674",
        "authors": "He Zhang, Anzhou Zhang, Jian Dai",
        "summary": "Reasoning protocols such as Chain of Thought (CoT) and Tree of Thought (ToT) organize internal deliberation but lack an explicit mechanism for external questioning that elicits self-revision. We present FOR-Prompting (From Objection to Revision Prompting), an asymmetric protocol where a Defender proposes an answer, an Objectioner raises question-style objections with no direct fixes, and a Host enforces consistency and closure. On GSM8K we observe about a 22% point gain over single-prompt and accuracy on par with CoT, with more than 10% higher ratings in reasoning and coherence from a uniform GPT 4.1 judge. FOR-Prompting also corrects mistakes without tools or human supervision on tricky queries, and improves performance for small-scale model (approx. 19% accuracy improved on Llama3.2:1b for GSM8K task), highlighting promise for small models and on personal device use. Beyond factual QA, qualitative analyses on open-ended tasks show enhanced exploration and refinement, with dialogue traces that make assumptions and trade-offs explicit. The protocol is model agnostic and operates purely at the prompt level through role-structured turns, so it works with hosted and local models of different sizes without retraining, and it supports large-scale study of objection-guided reasoning.",
        "subjects": "Computation and Language, Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-02",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.290034"
    },
    {
        "index": "#9",
        "title": "DeMuon: A Decentralized Muon for Matrix Optimization over Graphs",
        "link": "/arxiv/2510.01377",
        "arxiv_id": "2510.01377",
        "authors": "Chuan He, Shuyi Ren, Jingwei Mao, Erik G. Larsson",
        "summary": "In this paper, we propose DeMuon, a method for decentralized matrix optimization over a given communication topology. DeMuon incorporates matrix orthogonalization via Newton-Schulz iterations-a technique inherited from its centralized predecessor, Muon-and employs gradient tracking to mitigate heterogeneity among local functions. Under heavy-tailed noise conditions and additional mild assumptions, we establish the iteration complexity of DeMuon for reaching an approximate stochastic stationary point. This complexity result matches the best-known complexity bounds of centralized algorithms in terms of dependence on the target tolerance. To the best of our knowledge, DeMuon is the first direct extension of Muon to decentralized optimization over graphs with provable complexity guarantees. We conduct preliminary numerical experiments on decentralized transformer pretraining over graphs with varying degrees of connectivity. Our numerical results demonstrate a clear margin of improvement of DeMuon over other popular decentralized algorithms across different network topologies.",
        "subjects": "Optimization and Control, Artificial Intelligence, Machine Learning, Multiagent Systems, Systems and Control",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.290322"
    },
    {
        "index": "#10",
        "title": "The Social Laboratory: A Psychometric Framework for Multi-Agent LLM Evaluation",
        "link": "/arxiv/2510.01295",
        "arxiv_id": "2510.01295",
        "authors": "Zarreen Reza",
        "summary": "As Large Language Models (LLMs) transition from static tools to autonomous agents, traditional evaluation benchmarks that measure performance on downstream tasks are becoming insufficient. These methods fail to capture the emergent social and cognitive dynamics that arise when agents communicate, persuade, and collaborate in interactive environments. To address this gap, we introduce a novel evaluation framework that uses multi-agent debate as a controlled \"social laboratory\" to discover and quantify these behaviors. In our framework, LLM-based agents, instantiated with distinct personas and incentives, deliberate on a wide range of challenging topics under the supervision of an LLM moderator. Our analysis, enabled by a new suite of psychometric and semantic metrics, reveals several key findings. Across hundreds of debates, we uncover a powerful and robust emergent tendency for agents to seek consensus, consistently reaching high semantic agreement ({\\mu} > 0.88) even without explicit instruction and across sensitive topics. We show that assigned personas induce stable, measurable psychometric profiles, particularly in cognitive effort, and that the moderators persona can significantly alter debate outcomes by structuring the environment, a key finding for external AI alignment. This work provides a blueprint for a new class of dynamic, psychometrically grounded evaluation protocols designed for the agentic setting, offering a crucial methodology for understanding and shaping the social behaviors of the next generation of AI agents. We have released the code and results at https://github.com/znreza/multi-agent-LLM-eval-for-debate.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-07T00:44:32.290566"
    }
]