[
    {
        "index": "#1",
        "title": "PixWizard: Versatile Image-to-Image Visual Assistant with Open-Language Instructions",
        "link": "/arxiv/2409.15278",
        "arxiv_id": "2409.15278",
        "authors": "Weifeng Lin, Xinyu Wei, Renrui Zhang, Le Zhuo, Shitian Zhao, Siyuan Huang, Junlin Xie, Yu Qiao, Peng Gao, Hongsheng Li",
        "summary": "This paper presents a versatile image-to-image visual assistant, PixWizard, designed for image generation, manipulation, and translation based on free-from language instructions. To this end, we tackle a variety of vision tasks into a unified image-text-to-image generation framework and curate an Omni Pixel-to-Pixel Instruction-Tuning Dataset. By constructing detailed instruction templates in natural language, we comprehensively include a large set of diverse vision tasks such as text-to-image generation, image restoration, image grounding, dense image prediction, image editing, controllable generation, inpainting/outpainting, and more. Furthermore, we adopt Diffusion Transformers (DiT) as our foundation model and extend its capabilities with a flexible any resolution mechanism, enabling the model to dynamically process images based on the aspect ratio of the input, closely aligning with human perceptual processes. The model also incorporates structure-aware and semantic-aware guidance to facilitate effective fusion of information from the input image. Our experiments demonstrate that PixWizard not only shows impressive generative and understanding abilities for images with diverse resolutions but also exhibits promising generalization capabilities with unseen tasks and human instructions. The code and related resources are available at https://github.com/AFeng-x/PixWizard",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 17:59:46 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.975202"
    },
    {
        "index": "#2",
        "title": "MaterialFusion: Enhancing Inverse Rendering with Material Diffusion Priors",
        "link": "/arxiv/2409.15273",
        "arxiv_id": "2409.15273",
        "authors": "Yehonathan Litman, Or Patashnik, Kangle Deng, Aviral Agrawal, Rushikesh Zawar, Fernando De la Torre, Shubham Tulsiani",
        "summary": "Recent works in inverse rendering have shown promise in using multi-view images of an object to recover shape, albedo, and materials. However, the recovered components often fail to render accurately under new lighting conditions due to the intrinsic challenge of disentangling albedo and material properties from input images. To address this challenge, we introduce MaterialFusion, an enhanced conventional 3D inverse rendering pipeline that incorporates a 2D prior on texture and material properties. We present StableMaterial, a 2D diffusion model prior that refines multi-lit data to estimate the most likely albedo and material from given input appearances. This model is trained on albedo, material, and relit image data derived from a curated dataset of approximately ~12K artist-designed synthetic Blender objects called BlenderVault. we incorporate this diffusion prior with an inverse rendering framework where we use score distillation sampling (SDS) to guide the optimization of the albedo and materials, improving relighting performance in comparison with previous work. We validate MaterialFusion's relighting performance on 4 datasets of synthetic and real objects under diverse illumination conditions, showing our diffusion-aided approach significantly improves the appearance of reconstructed objects under novel lighting conditions. We intend to publicly release our BlenderVault dataset to support further research in this field.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 17:59:06 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.975454"
    },
    {
        "index": "#3",
        "title": "ReLoo: Reconstructing Humans Dressed in Loose Garments from Monocular Video in the Wild",
        "link": "/arxiv/2409.15269",
        "arxiv_id": "2409.15269",
        "authors": "Chen Guo, Tianjian Jiang, Manuel Kaufmann, Chengwei Zheng, Julien Valentin, Jie Song, Otmar Hilliges",
        "summary": "While previous years have seen great progress in the 3D reconstruction of humans from monocular videos, few of the state-of-the-art methods are able to handle loose garments that exhibit large non-rigid surface deformations during articulation. This limits the application of such methods to humans that are dressed in standard pants or T-shirts. Our method, ReLoo, overcomes this limitation and reconstructs high-quality 3D models of humans dressed in loose garments from monocular in-the-wild videos. To tackle this problem, we first establish a layered neural human representation that decomposes clothed humans into a neural inner body and outer clothing. On top of the layered neural representation, we further introduce a non-hierarchical virtual bone deformation module for the clothing layer that can freely move, which allows the accurate recovery of non-rigidly deforming loose clothing. A global optimization jointly optimizes the shape, appearance, and deformations of the human body and clothing via multi-layer differentiable volume rendering. To evaluate ReLoo, we record subjects with dynamically deforming garments in a multi-view capture studio. This evaluation, both on existing and our novel dataset, demonstrates ReLoo's clear superiority over prior art on both indoor datasets and in-the-wild videos.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 17:58:39 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.975655"
    },
    {
        "index": "#4",
        "title": "S$^2$AG-Vid: Enhancing Multi-Motion Alignment in Video Diffusion Models via Spatial and Syntactic Attention-Based Guidance",
        "link": "/arxiv/2409.15259",
        "arxiv_id": "2409.15259",
        "authors": "Yuanhang Li, Qi Mao, Lan Chen, Zhen Fang, Lei Tian, Xinyan Xiao, Libiao Jin, Hua Wu",
        "summary": "Recent advancements in text-to-video (T2V) generation using diffusion models have garnered significant attention. However, existing T2V models primarily focus on simple scenes featuring a single object performing a single motion. Challenges arise in scenarios involving multiple objects with distinct motions, often leading to incorrect video-text alignment between subjects and their corresponding motions. To address this challenge, we propose \\textbf{S$^2$AG-Vid}, a training-free inference-stage optimization method that improves the alignment of multiple objects with their corresponding motions in T2V models. S$^2$AG-Vid initially applies a spatial position-based, cross-attention (CA) constraint in the early stages of the denoising process, facilitating multiple nouns distinctly attending to the correct subject regions. To enhance the motion-subject binding, we implement a syntax-guided contrastive constraint in the subsequent denoising phase, aimed at improving the correlations between the CA maps of verbs and their corresponding nouns.Both qualitative and quantitative evaluations demonstrate that the proposed framework significantly outperforms baseline approaches, producing higher-quality videos with improved subject-motion consistency.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 17:56:03 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.975867"
    },
    {
        "index": "#5",
        "title": "ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models",
        "link": "/arxiv/2409.15250",
        "arxiv_id": "2409.15250",
        "authors": "Sombit Dey, Jan-Nico Zaech, Nikolay Nikolov, Luc Van Gool, Danda Pani Paudel",
        "summary": "Recent progress in large language models and access to large-scale robotic datasets has sparked a paradigm shift in robotics models transforming them into generalists able to adapt to various tasks, scenes, and robot modalities. A large step for the community are open Vision Language Action models which showcase strong performance in a wide variety of tasks. In this work, we study the visual generalization capabilities of three existing robotic foundation models, and propose a corresponding evaluation framework. Our study shows that the existing models do not exhibit robustness to visual out-of-domain scenarios. This is potentially caused by limited variations in the training data and/or catastrophic forgetting, leading to domain limitations in the vision foundation models. We further explore OpenVLA, which uses two pre-trained vision foundation models and is, therefore, expected to generalize to out-of-domain experiments. However, we showcase catastrophic forgetting by DINO-v2 in OpenVLA through its failure to fulfill the task of depth regression. To overcome the aforementioned issue of visual catastrophic forgetting, we propose a gradual backbone reversal approach founded on model merging. This enables OpenVLA which requires the adaptation of the visual backbones during initial training -- to regain its visual generalization ability. Regaining this capability enables our ReVLA model to improve over OpenVLA by a factor of 77% and 66% for grasping and lifting in visual OOD tasks .",
        "subjects": "Computer Vision and Pattern Recognition, Robotics",
        "date": "2024-09-23 17:47:59 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.976063"
    },
    {
        "index": "#6",
        "title": "Enhancing Pedestrian Trajectory Prediction with Crowd Trip Information",
        "link": "/arxiv/2409.15224",
        "arxiv_id": "2409.15224",
        "authors": "Rei Tamaru, Pei Li, Bin Ran",
        "summary": "Pedestrian trajectory prediction is essential for various applications in active traffic management, urban planning, traffic control, crowd management, and autonomous driving, aiming to enhance traffic safety and efficiency. Accurately predicting pedestrian trajectories requires a deep understanding of individual behaviors, social interactions, and road environments. Existing studies have developed various models to capture the influence of social interactions and road conditions on pedestrian trajectories. However, these approaches are limited by the lack of a comprehensive view of social interactions and road environments. To address these limitations and enhance the accuracy of pedestrian trajectory prediction, we propose a novel approach incorporating trip information as a new modality into pedestrian trajectory models. We propose RNTransformer, a generic model that utilizes crowd trip information to capture global information on social interactions. We incorporated RNTransformer with various socially aware local pedestrian trajectory prediction models to demonstrate its performance. Specifically, by leveraging a pre-trained RNTransformer when training different pedestrian trajectory prediction models, we observed improvements in performance metrics: a 1.3/2.2% enhancement in ADE/FDE on Social-LSTM, a 6.5/28.4% improvement on Social-STGCNN, and an 8.6/4.3% improvement on S-Implicit. Evaluation results demonstrate that RNTransformer significantly enhances the accuracy of various pedestrian trajectory prediction models across multiple datasets. Further investigation reveals that the RNTransformer effectively guides local models to more accurate directions due to the consideration of global information. By exploring crowd behavior within the road network, our approach shows great promise in improving pedestrian safety through accurate trajectory predictions.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 17:11:31 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.976246"
    },
    {
        "index": "#7",
        "title": "HydroVision: LiDAR-Guided Hydrometric Prediction with Vision Transformers and Hybrid Graph Learning",
        "link": "/arxiv/2409.15213",
        "arxiv_id": "2409.15213",
        "authors": "Naghmeh Shafiee Roudbari, Ursula Eicker, Charalambos Poullis, Zachary Patterson",
        "summary": "Hydrometric forecasting is crucial for managing water resources, flood prediction, and environmental protection. Water stations are interconnected, and this connectivity influences the measurements at other stations. However, the dynamic and implicit nature of water flow paths makes it challenging to extract a priori knowledge of the connectivity structure. We hypothesize that terrain elevation significantly affects flow and connectivity. To incorporate this, we use LiDAR terrain elevation data encoded through a Vision Transformer (ViT). The ViT, which has demonstrated excellent performance in image classification by directly applying transformers to sequences of image patches, efficiently captures spatial features of terrain elevation. To account for both spatial and temporal features, we employ GRU blocks enhanced with graph convolution, a method widely used in the literature. We propose a hybrid graph learning structure that combines static and dynamic graph learning. A static graph, derived from transformer-encoded LiDAR data, captures terrain elevation relationships, while a dynamic graph adapts to temporal changes, improving the overall graph representation. We apply graph convolution in two layers through these static and dynamic graphs. Our method makes daily predictions up to 12 days ahead. Empirical results from multiple water stations in Quebec demonstrate that our method significantly reduces prediction error by an average of 10\\% across all days, with greater improvements for longer forecasting horizons.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-23 16:57:43 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.976466"
    },
    {
        "index": "#8",
        "title": "HOTVCOM: Generating Buzzworthy Comments for Videos",
        "link": "/arxiv/2409.15196",
        "arxiv_id": "2409.15196",
        "authors": "Yuyan Chen, Yiwen Qian, Songzhou Yan, Jiyuan Jia, Zhixu Li, Yanghua Xiao, Xiaobo Li, Ming Yang, Qingpei Guo",
        "summary": "In the era of social media video platforms, popular ``hot-comments'' play a crucial role in attracting user impressions of short-form videos, making them vital for marketing and branding purpose. However, existing research predominantly focuses on generating descriptive comments or ``danmaku'' in English, offering immediate reactions to specific video moments. Addressing this gap, our study introduces \\textsc{HotVCom}, the largest Chinese video hot-comment dataset, comprising 94k diverse videos and 137 million comments. We also present the \\texttt{ComHeat} framework, which synergistically integrates visual, auditory, and textual data to generate influential hot-comments on the Chinese video dataset. Empirical evaluations highlight the effectiveness of our framework, demonstrating its excellence on both the newly constructed and existing datasets.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 16:45:13 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.976738"
    },
    {
        "index": "#9",
        "title": "Interpretability-Guided Test-Time Adversarial Defense",
        "link": "/arxiv/2409.15190",
        "arxiv_id": "2409.15190",
        "authors": "Akshay Kulkarni, Tsui-Wei Weng",
        "summary": "We propose a novel and low-cost test-time adversarial defense by devising interpretability-guided neuron importance ranking methods to identify neurons important to the output classes. Our method is a training-free approach that can significantly improve the robustness-accuracy tradeoff while incurring minimal computational overhead. While being among the most efficient test-time defenses (4x faster), our method is also robust to a wide range of black-box, white-box, and adaptive attacks that break previous test-time defenses. We demonstrate the efficacy of our method for CIFAR10, CIFAR100, and ImageNet-1k on the standard RobustBench benchmark (with average gains of 2.6%, 4.9%, and 2.8% respectively). We also show improvements (average 1.5%) over the state-of-the-art test-time defenses even under strong adaptive attacks.",
        "subjects": "Computer Vision and Pattern Recognition, Cryptography and Security, Machine Learning",
        "date": "2024-09-23 16:40:10 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.976928"
    },
    {
        "index": "#10",
        "title": "MIMAFace: Face Animation via Motion-Identity Modulated Appearance Feature Learning",
        "link": "/arxiv/2409.15179",
        "arxiv_id": "2409.15179",
        "authors": "Yue Han, Junwei Zhu, Yuxiang Feng, Xiaozhong Ji, Keke He, Xiangtai Li, zhucun xue, Yong Liu",
        "summary": "Current diffusion-based face animation methods generally adopt a ReferenceNet (a copy of U-Net) and a large amount of curated self-acquired data to learn appearance features, as robust appearance features are vital for ensuring temporal stability. However, when trained on public datasets, the results often exhibit a noticeable performance gap in image quality and temporal consistency. To address this issue, we meticulously examine the essential appearance features in the facial animation tasks, which include motion-agnostic (e.g., clothing, background) and motion-related (e.g., facial details) texture components, along with high-level discriminative identity features. Drawing from this analysis, we introduce a Motion-Identity Modulated Appearance Learning Module (MIA) that modulates CLIP features at both motion and identity levels. Additionally, to tackle the semantic/ color discontinuities between clips, we design an Inter-clip Affinity Learning Module (ICA) to model temporal relationships across clips. Our method achieves precise facial motion control (i.e., expressions and gaze), faithful identity preservation, and generates animation videos that maintain both intra/inter-clip temporal consistency. Moreover, it easily adapts to various modalities of driving sources. Extensive experiments demonstrate the superiority of our method.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 16:33:53 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.977128"
    },
    {
        "index": "#11",
        "title": "SpikeGS: Learning 3D Gaussian Fields from Continuous Spike Stream",
        "link": "/arxiv/2409.15176",
        "arxiv_id": "2409.15176",
        "authors": "Jinze Yu, Xi Peng, Zhengda Lu, Laurent Kneip, Yiqun Wang",
        "summary": "A spike camera is a specialized high-speed visual sensor that offers advantages such as high temporal resolution and high dynamic range compared to conventional frame cameras. These features provide the camera with significant advantages in many computer vision tasks. However, the tasks of 3D reconstruction and novel view synthesis based on spike cameras remain underdeveloped. Although there are existing methods for learning neural radiance fields from spike stream, they either lack robustness in extremely noisy, low-quality lighting conditions or suffer from high computational complexity due to the deep fully connected neural networks and ray marching rendering strategies used in neural radiance fields, making it difficult to recover fine texture details. In contrast, the latest advancements in 3DGS have achieved high-quality real-time rendering by optimizing the point cloud representation into Gaussian ellipsoids. Building on this, we introduce SpikeGS, the first method to learn 3D Gaussian fields solely from spike stream. We designed a differentiable spike stream rendering framework based on 3DGS, incorporating noise embedding and spiking neurons. By leveraging the multi-view consistency of 3DGS and the tile-based multi-threaded parallel rendering mechanism, we achieved high-quality real-time rendering results. Additionally, we introduced a spike rendering loss function that generalizes under varying illumination conditions. Our method can reconstruct view synthesis results with fine texture details from a continuous spike stream captured by a moving spike camera, while demonstrating high robustness in extremely noisy low-light scenarios. Experimental results on both real and synthetic datasets demonstrate that our method surpasses existing approaches in terms of rendering quality and speed. Our code will be available at https://github.com/520jz/SpikeGS.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 16:28:41 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.977307"
    },
    {
        "index": "#12",
        "title": "FusionRF: High-Fidelity Satellite Neural Radiance Fields from Multispectral and Panchromatic Acquisitions",
        "link": "/arxiv/2409.15132",
        "arxiv_id": "2409.15132",
        "authors": "Michael Sprintson, Rama Chellappa, Cheng Peng",
        "summary": "We introduce FusionRF, a novel neural rendering terrain reconstruction method from optically unprocessed satellite imagery. While previous methods depend on external pansharpening methods to fuse low resolution multispectral imagery and high resolution panchromatic imagery, FusionRF directly performs reconstruction based on optically unprocessed acquisitions with no prior knowledge. This is accomplished through the addition of a sharpening kernel which models the resolution loss in multispectral images. Additionally, novel modal embeddings allow the model to perform image fusion as a bottleneck to novel view synthesis. We evaluate our method on multispectral and panchromatic satellite images from the WorldView-3 satellite in various locations, and FusionRF outperforms previous State-of-The-Art methods in depth reconstruction on unprocessed imagery, renders sharp training and novel views, and retains multi-spectral information.",
        "subjects": "Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2024-09-23 15:38:03 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.977483"
    },
    {
        "index": "#13",
        "title": "Detect, Describe, Discriminate: Moving Beyond VQA for MLLM Evaluation",
        "link": "/arxiv/2409.15125",
        "arxiv_id": "2409.15125",
        "authors": "Manu Gaur, Darshan Singh S, Makarand Tapaswi",
        "summary": "Visual Question Answering (VQA) with multiple choice questions enables a vision-centric evaluation of Multimodal Large Language Models (MLLMs). Although it reliably checks the existence of specific visual abilities, it is easier for the model to select an answer from multiple choices (VQA evaluation) than to generate the answer itself. In this work, we offer a novel perspective: we evaluate how well an MLLM understands a specific visual concept by its ability to uniquely describe two extremely similar images that differ only in the targeted visual concept. Specifically, we assess the ability of MLLMs to capture specific points of visual differences using self-retrieval, i.e., by retrieving the target image using its generated caption against the other image in the pair serving as the distractor. We curate 247 highly similar image pairs as part of the D3 benchmark. For each image pair, the model is prompted to: (1) Detect a specific visual difference, and (2) Describe the target image uniquely such that it (3) Discriminates the target image from the distractor. Self-retrieval within D3 enables whitebox evaluation across six different visual patterns, revealing that current models struggle to independently discern fine-grained visual differences, with open-source models failing to outperform random guess.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 15:31:25 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.977650"
    },
    {
        "index": "#14",
        "title": "Diffusion-based RGB-D Semantic Segmentation with Deformable Attention Transformer",
        "link": "/arxiv/2409.15117",
        "arxiv_id": "2409.15117",
        "authors": "Minh Bui, Kostas Alexis",
        "summary": "Vision-based perception and reasoning is essential for scene understanding in any autonomous system. RGB and depth images are commonly used to capture both the semantic and geometric features of the environment. Developing methods to reliably interpret this data is critical for real-world applications, where noisy measurements are often unavoidable. In this work, we introduce a diffusion-based framework to address the RGB-D semantic segmentation problem. Additionally, we demonstrate that utilizing a Deformable Attention Transformer as the encoder to extract features from depth images effectively captures the characteristics of invalid regions in depth measurements. Our generative framework shows a greater capacity to model the underlying distribution of RGB-D images, achieving robust performance in challenging scenarios with significantly less training time compared to discriminative methods. Experimental results indicate that our approach achieves State-of-the-Art performance on both the NYUv2 and SUN-RGBD datasets in general and especially in the most challenging of their image data. Our project page will be available at https://diffusionmms.github.io/",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 15:23:01 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.977843"
    },
    {
        "index": "#15",
        "title": "The BRAVO Semantic Segmentation Challenge Results in UNCV2024",
        "link": "/arxiv/2409.15107",
        "arxiv_id": "2409.15107",
        "authors": "Tuan-Hung Vu, Eduardo Valle, Andrei Bursuc, Tommie Kerssies, Daan de Geus, Gijs Dubbelman, Long Qian, Bingke Zhu, Yingying Chen, Ming Tang, Jinqiao Wang, Tomáš Vojíř, Jan Šochman, Jiří Matas, Michael Smith, Frank Ferrie, Shamik Basu, Christos Sakaridis, Luc Van Gool",
        "summary": "We propose the unified BRAVO challenge to benchmark the reliability of semantic segmentation models under realistic perturbations and unknown out-of-distribution (OOD) scenarios. We define two categories of reliability: (1) semantic reliability, which reflects the model's accuracy and calibration when exposed to various perturbations; and (2) OOD reliability, which measures the model's ability to detect object classes that are unknown during training. The challenge attracted nearly 100 submissions from international teams representing notable research institutions. The results reveal interesting insights into the importance of large-scale pre-training and minimal architectural design in developing robust and reliable semantic segmentation models.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 15:17:30 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.978161"
    },
    {
        "index": "#16",
        "title": "M2OST: Many-to-one Regression for Predicting Spatial Transcriptomics from Digital Pathology Images",
        "link": "/arxiv/2409.15092",
        "arxiv_id": "2409.15092",
        "authors": "Hongyi Wang, Xiuju Du, Jing Liu, Shuyi Ouyang, Yen-Wei Chen, Lanfen Lin",
        "summary": "The advancement of Spatial Transcriptomics (ST) has facilitated the spatially-aware profiling of gene expressions based on histopathology images. Although ST data offers valuable insights into the micro-environment of tumors, its acquisition cost remains expensive. Therefore, directly predicting the ST expressions from digital pathology images is desired. Current methods usually adopt existing regression backbones along with patch-sampling for this task, which ignores the inherent multi-scale information embedded in the pyramidal data structure of digital pathology images, and wastes the inter-spot visual information crucial for accurate gene expression prediction. To address these limitations, we propose M2OST, a many-to-one regression Transformer that can accommodate the hierarchical structure of the pathology images via a decoupled multi-scale feature extractor. Unlike traditional models that are trained with one-to-one image-label pairs, M2OST uses multiple images from different levels of the digital pathology image to jointly predict the gene expressions in their common corresponding spot. Built upon our many-to-one scheme, M2OST can be easily scaled to fit different numbers of inputs, and its network structure inherently incorporates nearby inter-spot features, enhancing regression performance. We have tested M2OST on three public ST datasets and the experimental results show that M2OST can achieve state-of-the-art performance with fewer parameters and floating-point operations (FLOPs). The code will be released upon acceptance.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 15:06:37 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.978359"
    },
    {
        "index": "#17",
        "title": "TSCLIP: Robust CLIP Fine-Tuning for Worldwide Cross-Regional Traffic Sign Recognition",
        "link": "/arxiv/2409.15077",
        "arxiv_id": "2409.15077",
        "authors": "Guoyang Zhao, Fulong Ma, Weiqing Qi, Chenguang Zhang, Yuxuan Liu, Ming Liu, Jun Ma",
        "summary": "Traffic sign is a critical map feature for navigation and traffic control. Nevertheless, current methods for traffic sign recognition rely on traditional deep learning models, which typically suffer from significant performance degradation considering the variations in data distribution across different regions. In this paper, we propose TSCLIP, a robust fine-tuning approach with the contrastive language-image pre-training (CLIP) model for worldwide cross-regional traffic sign recognition. We first curate a cross-regional traffic sign benchmark dataset by combining data from ten different sources. Then, we propose a prompt engineering scheme tailored to the characteristics of traffic signs, which involves specific scene descriptions and corresponding rules to generate targeted text descriptions for optimizing the model training process. During the TSCLIP fine-tuning process, we implement adaptive dynamic weight ensembling (ADWE) to seamlessly incorporate outcomes from each training iteration with the zero-shot CLIP model. This approach ensures that the model retains its ability to generalize while acquiring new knowledge about traffic signs. Our method surpasses conventional classification benchmark models in cross-regional traffic sign evaluations, and it achieves state-of-the-art performance compared to existing CLIP fine-tuning techniques. To the best knowledge of authors, TSCLIP is the first contrastive language-image model used for the worldwide cross-regional traffic sign recognition task. The project website is available at: https://github.com/guoyangzhao/TSCLIP.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 14:51:26 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.978577"
    },
    {
        "index": "#18",
        "title": "FisheyeDepth: A Real Scale Self-Supervised Depth Estimation Model for Fisheye Camera",
        "link": "/arxiv/2409.15054",
        "arxiv_id": "2409.15054",
        "authors": "Guoyang Zhao, Yuxuan Liu, Weiqing Qi, Fulong Ma, Ming Liu, Jun Ma",
        "summary": "Accurate depth estimation is crucial for 3D scene comprehension in robotics and autonomous vehicles. Fisheye cameras, known for their wide field of view, have inherent geometric benefits. However, their use in depth estimation is restricted by a scarcity of ground truth data and image distortions. We present FisheyeDepth, a self-supervised depth estimation model tailored for fisheye cameras. We incorporate a fisheye camera model into the projection and reprojection stages during training to handle image distortions, thereby improving depth estimation accuracy and training stability. Furthermore, we incorporate real-scale pose information into the geometric projection between consecutive frames, replacing the poses estimated by the conventional pose network. Essentially, this method offers the necessary physical depth for robotic tasks, and also streamlines the training and inference procedures. Additionally, we devise a multi-channel output strategy to improve robustness by adaptively fusing features at various scales, which reduces the noise from real pose data. We demonstrate the superior performance and robustness of our model in fisheye image depth estimation through evaluations on public datasets and real-world scenarios. The project website is available at: https://github.com/guoyangzhao/FisheyeDepth.",
        "subjects": "Computer Vision and Pattern Recognition, Robotics",
        "date": "2024-09-23 14:31:42 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.978812"
    },
    {
        "index": "#19",
        "title": "AIM 2024 Sparse Neural Rendering Challenge: Methods and Results",
        "link": "/arxiv/2409.15045",
        "arxiv_id": "2409.15045",
        "authors": "Michal Nazarczuk, Sibi Catley-Chandar, Thomas Tanay, Richard Shaw, Eduardo Pérez-Pellitero, Radu Timofte, Xing Yan, Pan Wang, Yali Guo, Yongxin Wu, Youcheng Cai, Yanan Yang, Junting Li, Yanghong Zhou, P. Y. Mok, Zongqi He, Zhe Xiao, Kin-Chung Chan, Hana Lebeta Goshu, Cuixin Yang, Rongkang Dong, Jun Xiao, Kin-Man Lam, Jiayao Hao, Qiong Gao, Yanyan Zu, Junpei Zhang, Licheng Jiao, Xu Liu, Kuldeep Purohit",
        "summary": "This paper reviews the challenge on Sparse Neural Rendering that was part of the Advances in Image Manipulation (AIM) workshop, held in conjunction with ECCV 2024. This manuscript focuses on the competition set-up, the proposed methods and their respective results. The challenge aims at producing novel camera view synthesis of diverse scenes from sparse image observations. It is composed of two tracks, with differing levels of sparsity; 3 views in Track 1 (very sparse) and 9 views in Track 2 (sparse). Participants are asked to optimise objective fidelity to the ground-truth images as measured via the Peak Signal-to-Noise Ratio (PSNR) metric. For both tracks, we use the newly introduced Sparse Rendering (SpaRe) dataset and the popular DTU MVS dataset. In this challenge, 5 teams submitted final results to Track 1 and 4 teams submitted final results to Track 2. The submitted models are varied and push the boundaries of the current state-of-the-art in sparse neural rendering. A detailed description of all models developed in the challenge is provided in this paper.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 14:17:40 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.979163"
    },
    {
        "index": "#20",
        "title": "AIM 2024 Sparse Neural Rendering Challenge: Dataset and Benchmark",
        "link": "/arxiv/2409.15041",
        "arxiv_id": "2409.15041",
        "authors": "Michal Nazarczuk, Thomas Tanay, Sibi Catley-Chandar, Richard Shaw, Radu Timofte, Eduardo Pérez-Pellitero",
        "summary": "Recent developments in differentiable and neural rendering have made impressive breakthroughs in a variety of 2D and 3D tasks, e.g. novel view synthesis, 3D reconstruction. Typically, differentiable rendering relies on a dense viewpoint coverage of the scene, such that the geometry can be disambiguated from appearance observations alone. Several challenges arise when only a few input views are available, often referred to as sparse or few-shot neural rendering. As this is an underconstrained problem, most existing approaches introduce the use of regularisation, together with a diversity of learnt and hand-crafted priors. A recurring problem in sparse rendering literature is the lack of an homogeneous, up-to-date, dataset and evaluation protocol. While high-resolution datasets are standard in dense reconstruction literature, sparse rendering methods often evaluate with low-resolution images. Additionally, data splits are inconsistent across different manuscripts, and testing ground-truth images are often publicly available, which may lead to over-fitting. In this work, we propose the Sparse Rendering (SpaRe) dataset and benchmark. We introduce a new dataset that follows the setup of the DTU MVS dataset. The dataset is composed of 97 new scenes based on synthetic, high-quality assets. Each scene has up to 64 camera views and 7 lighting configurations, rendered at 1600x1200 resolution. We release a training split of 82 scenes to foster generalizable approaches, and provide an online evaluation platform for the validation and test sets, whose ground-truth images remain hidden. We propose two different sparse configurations (3 and 9 input images respectively). This provides a powerful and convenient tool for reproducible evaluation, and enable researchers easy access to a public leaderboard with the state-of-the-art performance scores. Available at: https://sparebenchmark.github.io/",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 14:10:06 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.979358"
    },
    {
        "index": "#21",
        "title": "Can CLIP Count Stars? An Empirical Study on Quantity Bias in CLIP",
        "link": "/arxiv/2409.15035",
        "arxiv_id": "2409.15035",
        "authors": "Zeliang Zhang, Zhuo Liu, Mingqian Feng, Chenliang Xu",
        "summary": "CLIP has demonstrated great versatility in adapting to various downstream tasks, such as image editing and generation, visual question answering, and video understanding. However, CLIP-based applications often suffer from misunderstandings regarding user intent, leading to discrepancies between the required number of objects and the actual outputs in image generation tasks. In this work, we empirically investigate the quantity bias in CLIP. By carefully designing different experimental settings and datasets, we comprehensively evaluate CLIP's understanding of quantity from text, image, and cross-modal perspectives. Our experimental results reveal a quantity bias in CLIP embeddings, impacting the reliability of downstream tasks.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2024-09-23 14:01:16 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.979545"
    },
    {
        "index": "#22",
        "title": "Region Mixup",
        "link": "/arxiv/2409.15028",
        "arxiv_id": "2409.15028",
        "authors": "Saptarshi Saha, Utpal Garain",
        "summary": "This paper introduces a simple extension of mixup (Zhang et al., 2018) data augmentation to enhance generalization in visual recognition tasks. Unlike the vanilla mixup method, which blends entire images, our approach focuses on combining regions from multiple images.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 13:55:16 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.979722"
    },
    {
        "index": "#23",
        "title": "Cross Branch Feature Fusion Decoder for Consistency Regularization-based Semi-Supervised Change Detection",
        "link": "/arxiv/2409.15021",
        "arxiv_id": "2409.15021",
        "authors": "Yan Xing, Qi'ao Xu, Jingcheng Zeng, Rui Huang, Sihua Gao, Weifeng Xu, Yuxiang Zhang, Wei Fan",
        "summary": "Semi-supervised change detection (SSCD) utilizes partially labeled data and a large amount of unlabeled data to detect changes. However, the transformer-based SSCD network does not perform as well as the convolution-based SSCD network due to the lack of labeled data. To overcome this limitation, we introduce a new decoder called Cross Branch Feature Fusion CBFF, which combines the strengths of both local convolutional branch and global transformer branch. The convolutional branch is easy to learn and can produce high-quality features with a small amount of labeled data. The transformer branch, on the other hand, can extract global context features but is hard to learn without a lot of labeled data. Using CBFF, we build our SSCD model based on a strong-to-weak consistency strategy. Through comprehensive experiments on WHU-CD and LEVIR-CD datasets, we have demonstrated the superiority of our method over seven state-of-the-art SSCD methods.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 13:47:59 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.979920"
    },
    {
        "index": "#24",
        "title": "DepthART: Monocular Depth Estimation as Autoregressive Refinement Task",
        "link": "/arxiv/2409.15010",
        "arxiv_id": "2409.15010",
        "authors": "Bulat Gabdullin, Nina Konovalova, Nikolay Patakin, Dmitry Senushkin, Anton Konushin",
        "summary": "Despite recent success in discriminative approaches in monocular depth estimation its quality remains limited by training datasets. Generative approaches mitigate this issue by leveraging strong priors derived from training on internet-scale datasets. Recent studies have demonstrated that large text-to-image diffusion models achieve state-of-the-art results in depth estimation when fine-tuned on small depth datasets. Concurrently, autoregressive generative approaches, such as the Visual AutoRegressive modeling~(VAR), have shown promising results in conditioned image synthesis. Following the visual autoregressive modeling paradigm, we introduce the first autoregressive depth estimation model based on the visual autoregressive transformer. Our primary contribution is DepthART -- a novel training method formulated as Depth Autoregressive Refinement Task. Unlike the original VAR training procedure, which employs static targets, our method utilizes a dynamic target formulation that enables model self-refinement and incorporates multi-modal guidance during training. Specifically, we use model predictions as inputs instead of ground truth token maps during training, framing the objective as residual minimization. Our experiments demonstrate that the proposed training approach significantly outperforms visual autoregressive modeling via next-scale prediction in the depth estimation task. The Visual Autoregressive Transformer trained with our approach on Hypersim achieves superior results on a set of unseen benchmarks compared to other generative and discriminative baselines.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 13:36:34 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.985620"
    },
    {
        "index": "#25",
        "title": "Generalizing monocular colonoscopy image depth estimation by uncertainty-based global and local fusion network",
        "link": "/arxiv/2409.15006",
        "arxiv_id": "2409.15006",
        "authors": "Sijia Du, Chengfeng Zhou, Suncheng Xiang, Jianwei Xu, Dahong Qian",
        "summary": "Objective: Depth estimation is crucial for endoscopic navigation and manipulation, but obtaining ground-truth depth maps in real clinical scenarios, such as the colon, is challenging. This study aims to develop a robust framework that generalizes well to real colonoscopy images, overcoming challenges like non-Lambertian surface reflection and diverse data distributions. Methods: We propose a framework combining a convolutional neural network (CNN) for capturing local features and a Transformer for capturing global information. An uncertainty-based fusion block was designed to enhance generalization by identifying complementary contributions from the CNN and Transformer branches. The network can be trained with simulated datasets and generalize directly to unseen clinical data without any fine-tuning. Results: Our method is validated on multiple datasets and demonstrates an excellent generalization ability across various datasets and anatomical structures. Furthermore, qualitative analysis in real clinical scenarios confirmed the robustness of the proposed method. Conclusion: The integration of local and global features through the CNN-Transformer architecture, along with the uncertainty-based fusion block, improves depth estimation performance and generalization in both simulated and real-world endoscopic environments. Significance: This study offers a novel approach to estimate depth maps for endoscopy images despite the complex conditions in clinic, serving as a foundation for endoscopic automatic navigation and other clinical tasks, such as polyp detection and segmentation.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 13:30:59 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.985972"
    },
    {
        "index": "#26",
        "title": "Sparse-to-Dense LiDAR Point Generation by LiDAR-Camera Fusion for 3D Object Detection",
        "link": "/arxiv/2409.14985",
        "arxiv_id": "2409.14985",
        "authors": "Minseung Lee, Seokha Moon, Seung Joon Lee, Jinkyu Kim",
        "summary": "Accurately detecting objects at long distances remains a critical challenge in 3D object detection when relying solely on LiDAR sensors due to the inherent limitations of data sparsity. To address this issue, we propose the LiDAR-Camera Augmentation Network (LCANet), a novel framework that reconstructs LiDAR point cloud data by fusing 2D image features, which contain rich semantic information, generating additional points to improve detection accuracy. LCANet fuses data from LiDAR sensors and cameras by projecting image features into the 3D space, integrating semantic information into the point cloud data. This fused data is then encoded to produce 3D features that contain both semantic and spatial information, which are further refined to reconstruct final points before bounding box prediction. This fusion effectively compensates for LiDAR's weakness in detecting objects at long distances, which are often represented by sparse points. Additionally, due to the sparsity of many objects in the original dataset, which makes effective supervision for point generation challenging, we employ a point cloud completion network to create a complete point cloud dataset that supervises the generation of dense point clouds in our network. Extensive experiments on the KITTI and Waymo datasets demonstrate that LCANet significantly outperforms existing models, particularly in detecting sparse and distant objects.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 13:03:31 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.986322"
    },
    {
        "index": "#27",
        "title": "SocialCircle+: Learning the Angle-based Conditioned Interaction Representation for Pedestrian Trajectory Prediction",
        "link": "/arxiv/2409.14984",
        "arxiv_id": "2409.14984",
        "authors": "Conghao Wong, Beihao Xia, Ziqian Zou, Xinge You",
        "summary": "Trajectory prediction is a crucial aspect of understanding human behaviors. Researchers have made efforts to represent socially interactive behaviors among pedestrians and utilize various networks to enhance prediction capability. Unfortunately, they still face challenges not only in fully explaining and measuring how these interactive behaviors work to modify trajectories but also in modeling pedestrians' preferences to plan or participate in social interactions in response to the changeable physical environments as extra conditions. This manuscript mainly focuses on the above explainability and conditionality requirements for trajectory prediction networks. Inspired by marine animals perceiving other companions and the environment underwater by echolocation, this work constructs an angle-based conditioned social interaction representation SocialCircle+ to represent the socially interactive context and its corresponding conditions. It employs a social branch and a conditional branch to describe how pedestrians are positioned in prediction scenes socially and physically in angle-based-cyclic-sequence forms. Then, adaptive fusion is applied to fuse the above conditional clues onto the social ones to learn the final interaction representation. Experiments demonstrate the superiority of SocialCircle+ with different trajectory prediction backbones. Moreover, counterfactual interventions have been made to simultaneously verify the modeling capacity of causalities among interactive variables and the conditioning capability.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 13:02:12 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.986503"
    },
    {
        "index": "#28",
        "title": "Dynamic Integration of Task-Specific Adapters for Class Incremental Learning",
        "link": "/arxiv/2409.14983",
        "arxiv_id": "2409.14983",
        "authors": "Jiashuo Li, Shaokun Wang, Bo Qian, Yuhang He, Xing Wei, Yihong Gong",
        "summary": "Non-exemplar class Incremental Learning (NECIL) enables models to continuously acquire new classes without retraining from scratch and storing old task exemplars, addressing privacy and storage issues. However, the absence of data from earlier tasks exacerbates the challenge of catastrophic forgetting in NECIL. In this paper, we propose a novel framework called Dynamic Integration of task-specific Adapters (DIA), which comprises two key components: Task-Specific Adapter Integration (TSAI) and Patch-Level Model Alignment. TSAI boosts compositionality through a patch-level adapter integration strategy, which provides a more flexible compositional solution while maintaining low computation costs. Patch-Level Model Alignment maintains feature consistency and accurate decision boundaries via two specialized mechanisms: Patch-Level Distillation Loss (PDL) and Patch-Level Feature Reconstruction method (PFR). Specifically, the PDL preserves feature-level consistency between successive models by implementing a distillation loss based on the contributions of patch tokens to new class learning. The PFR facilitates accurate classifier alignment by reconstructing old class features from previous tasks that adapt to new task knowledge. Extensive experiments validate the effectiveness of our DIA, revealing significant improvements on benchmark datasets in the NECIL setting, maintaining an optimal balance between computational complexity and accuracy. The full code implementation will be made publicly available upon the publication of this paper.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 13:01:33 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.986714"
    },
    {
        "index": "#29",
        "title": "A new baseline for edge detection: Make Encoder-Decoder great again",
        "link": "/arxiv/2409.14976",
        "arxiv_id": "2409.14976",
        "authors": "Yachuan Li, Xavier Soria Pomab, Yongke Xi, Guanlin Li, Chaozhi Yang, Qian Xiao, Yun Bai, Zongmin LI",
        "summary": "The performance of deep learning based edge detector has far exceeded that of humans, but the huge computational cost and complex training strategy hinder its further development and application. In this paper, we eliminate these complexities with a vanilla encoder-decoder based detector. Firstly, we design a bilateral encoder to decouple the extraction process of location features and semantic features. Since the location branch no longer provides cues for the semantic branch, the richness of features can be further compressed, which is the key to make our model more compact. We propose a cascaded feature fusion decoder, where the location features are progressively refined by semantic features. The refined location features are the only basis for generating the edge map. The coarse original location features and semantic features are avoided from direct contact with the final result. So the noise in the location features and the location error in the semantic features can be suppressed in the generated edge map. The proposed New Baseline for Edge Detection (NBED) achieves superior performance consistently across multiple edge detection benchmarks, even compared with those methods with huge computational cost and complex training strategy. The ODS of NBED on BSDS500 is 0.838, achieving state-of-the-art performance. Our study shows that what really matters in the current edge detection is high-quality features, and we can make the encoder-decoder based detector great again even without complex training strategies and huge computational cost. The code is available at https://github.com/Li-yachuan/NBED.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 12:54:38 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.986964"
    },
    {
        "index": "#30",
        "title": "Exploring Fine-grained Retail Product Discrimination with Zero-shot Object Classification Using Vision-Language Models",
        "link": "/arxiv/2409.14963",
        "arxiv_id": "2409.14963",
        "authors": "Anil Osman Tur, Alessandro Conti, Cigdem Beyan, Davide Boscaini, Roberto Larcher, Stefano Messelodi, Fabio Poiesi, Elisa Ricci",
        "summary": "In smart retail applications, the large number of products and their frequent turnover necessitate reliable zero-shot object classification methods. The zero-shot assumption is essential to avoid the need for re-training the classifier every time a new product is introduced into stock or an existing product undergoes rebranding. In this paper, we make three key contributions. Firstly, we introduce the MIMEX dataset, comprising 28 distinct product categories. Unlike existing datasets in the literature, MIMEX focuses on fine-grained product classification and includes a diverse range of retail products. Secondly, we benchmark the zero-shot object classification performance of state-of-the-art vision-language models (VLMs) on the proposed MIMEX dataset. Our experiments reveal that these models achieve unsatisfactory fine-grained classification performance, highlighting the need for specialized approaches. Lastly, we propose a novel ensemble approach that integrates embeddings from CLIP and DINOv2 with dimensionality reduction techniques to enhance classification performance. By combining these components, our ensemble approach outperforms VLMs, effectively capturing visual cues crucial for fine-grained product discrimination. Additionally, we introduce a class adaptation method that utilizes visual prototyping with limited samples in scenarios with scarce labeled data, addressing a critical need in retail environments where product variety frequently changes. To encourage further research into zero-shot object classification for smart retail applications, we will release both the MIMEX dataset and benchmark to the research community. Interested researchers can contact the authors for details on the terms and conditions of use. The code is available: https://github.com/AnilOsmanTur/Zero-shot-Retail-Product-Classification.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 12:28:40 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.987208"
    },
    {
        "index": "#31",
        "title": "Improving Adversarial Robustness for 3D Point Cloud Recognition at Test-Time through Purified Self-Training",
        "link": "/arxiv/2409.14940",
        "arxiv_id": "2409.14940",
        "authors": "Jinpeng Lin, Xulei Yang, Tianrui Li, Xun Xu",
        "summary": "Recognizing 3D point cloud plays a pivotal role in many real-world applications. However, deploying 3D point cloud deep learning model is vulnerable to adversarial attacks. Despite many efforts into developing robust model by adversarial training, they may become less effective against emerging attacks. This limitation motivates the development of adversarial purification which employs generative model to mitigate the impact of adversarial attacks. In this work, we highlight the remaining challenges from two perspectives. First, the purification based method requires retraining the classifier on purified samples which introduces additional computation overhead. Moreover, in a more realistic scenario, testing samples arrives in a streaming fashion and adversarial samples are not isolated from clean samples. These challenges motivates us to explore dynamically update model upon observing testing samples. We proposed a test-time purified self-training strategy to achieve this objective. Adaptive thresholding and feature distribution alignment are introduced to improve the robustness of self-training. Extensive results on different adversarial attacks suggest the proposed method is complementary to purification based method in handling continually changing adversarial attacks on the testing data stream.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 11:46:38 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.987398"
    },
    {
        "index": "#32",
        "title": "Deep Cost Ray Fusion for Sparse Depth Video Completion",
        "link": "/arxiv/2409.14935",
        "arxiv_id": "2409.14935",
        "authors": "Jungeon Kim, Soongjin Kim, Jaesik Park, Seungyong Lee",
        "summary": "In this paper, we present a learning-based framework for sparse depth video completion. Given a sparse depth map and a color image at a certain viewpoint, our approach makes a cost volume that is constructed on depth hypothesis planes. To effectively fuse sequential cost volumes of the multiple viewpoints for improved depth completion, we introduce a learning-based cost volume fusion framework, namely RayFusion, that effectively leverages the attention mechanism for each pair of overlapped rays in adjacent cost volumes. As a result of leveraging feature statistics accumulated over time, our proposed framework consistently outperforms or rivals state-of-the-art approaches on diverse indoor and outdoor datasets, including the KITTI Depth Completion benchmark, VOID Depth Completion benchmark, and ScanNetV2 dataset, using much fewer network parameters.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 11:42:16 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.987590"
    },
    {
        "index": "#33",
        "title": "DanceCamAnimator: Keyframe-Based Controllable 3D Dance Camera Synthesis",
        "link": "/arxiv/2409.14925",
        "arxiv_id": "2409.14925",
        "authors": "Zixuan Wang, Jiayi Li, Xiaoyu Qin, Shikun Sun, Songtao Zhou, Jia Jia, Jiebo Luo",
        "summary": "Synthesizing camera movements from music and dance is highly challenging due to the contradicting requirements and complexities of dance cinematography. Unlike human movements, which are always continuous, dance camera movements involve both continuous sequences of variable lengths and sudden drastic changes to simulate the switching of multiple cameras. However, in previous works, every camera frame is equally treated and this causes jittering and unavoidable smoothing in post-processing. To solve these problems, we propose to integrate animator dance cinematography knowledge by formulating this task as a three-stage process: keyframe detection, keyframe synthesis, and tween function prediction. Following this formulation, we design a novel end-to-end dance camera synthesis framework \\textbf{DanceCamAnimator}, which imitates human animation procedures and shows powerful keyframe-based controllability with variable lengths. Extensive experiments on the DCM dataset demonstrate that our method surpasses previous baselines quantitatively and qualitatively. Code will be available at \\url{https://github.com/Carmenw1203/DanceCamAnimator-Official}.",
        "subjects": "Computer Vision and Pattern Recognition, Multimedia",
        "date": "2024-09-23 11:20:44 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.987799"
    },
    {
        "index": "#34",
        "title": "Advancing Video Quality Assessment for AIGC",
        "link": "/arxiv/2409.14888",
        "arxiv_id": "2409.14888",
        "authors": "Xinli Yue, Jianhui Sun, Han Kong, Liangchao Yao, Tianyi Wang, Lei Li, Fengyun Rao, Jing Lv, Fan Xia, Yuetang Deng, Qian Wang, Lingchen Zhao",
        "summary": "In recent years, AI generative models have made remarkable progress across various domains, including text generation, image generation, and video generation. However, assessing the quality of text-to-video generation is still in its infancy, and existing evaluation frameworks fall short when compared to those for natural videos. Current video quality assessment (VQA) methods primarily focus on evaluating the overall quality of natural videos and fail to adequately account for the substantial quality discrepancies between frames in generated videos. To address this issue, we propose a novel loss function that combines mean absolute error with cross-entropy loss to mitigate inter-frame quality inconsistencies. Additionally, we introduce the innovative S2CNet technique to retain critical content, while leveraging adversarial training to enhance the model's generalization capabilities. Experimental results demonstrate that our method outperforms existing VQA techniques on the AIGC Video dataset, surpassing the previous state-of-the-art by 3.1% in terms of PLCC.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 10:36:22 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.988032"
    },
    {
        "index": "#35",
        "title": "Probabilistically Aligned View-unaligned Clustering with Adaptive Template Selection",
        "link": "/arxiv/2409.14882",
        "arxiv_id": "2409.14882",
        "authors": "Wenhua Dong, Xiao-Jun Wu, Zhenhua Feng, Sara Atito, Muhammad Awais, Josef Kittler",
        "summary": "In most existing multi-view modeling scenarios, cross-view correspondence (CVC) between instances of the same target from different views, like paired image-text data, is a crucial prerequisite for effortlessly deriving a consistent representation. Nevertheless, this premise is frequently compromised in certain applications, where each view is organized and transmitted independently, resulting in the view-unaligned problem (VuP). Restoring CVC of unaligned multi-view data is a challenging and highly demanding task that has received limited attention from the research community. To tackle this practical challenge, we propose to integrate the permutation derivation procedure into the bipartite graph paradigm for view-unaligned clustering, termed Probabilistically Aligned View-unaligned Clustering with Adaptive Template Selection (PAVuC-ATS). Specifically, we learn consistent anchors and view-specific graphs by the bipartite graph, and derive permutations applied to the unaligned graphs by reformulating the alignment between two latent representations as a 2-step transition of a Markov chain with adaptive template selection, thereby achieving the probabilistic alignment. The convergence of the resultant optimization problem is validated both experimentally and theoretically. Extensive experiments on six benchmark datasets demonstrate the superiority of the proposed PAVuC-ATS over the baseline methods.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 10:30:09 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.988284"
    },
    {
        "index": "#36",
        "title": "Mammo-Clustering:A Weakly Supervised Multi-view Global-Local Context Clustering Network for Detection and Classification in Mammography",
        "link": "/arxiv/2409.14876",
        "arxiv_id": "2409.14876",
        "authors": "Shilong Yang, Chulong Zhang, Qi Zang, Juan Yu, Liang Zeng, Xiao Luo, Yexuan Xing, Xin Pan, Qi Li, Xiaokun Liang, Yaoqin Xie",
        "summary": "Breast cancer has long posed a significant threat to women's health, making early screening crucial for mitigating its impact. However, mammography, the preferred method for early screening, faces limitations such as the burden of double reading by radiologists, challenges in widespread adoption in remote and underdeveloped areas, and obstacles in intelligent early screening development due to data constraints. To address these challenges, we propose a weakly supervised multi-view mammography early screening model for breast cancer based on context clustering. Context clustering, a feature extraction structure that is neither CNN nor transformer, combined with multi-view learning for information complementation, presents a promising approach. The weak supervision design specifically addresses data limitations. Our model achieves state-of-the-art performance with fewer parameters on two public datasets, with an AUC of 0.828 on the Vindr-Mammo dataset and 0.805 on the CBIS-DDSM dataset. Our model shows potential in reducing the burden on doctors and increasing the feasibility of breast cancer screening for women in underdeveloped regions.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 10:17:13 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.988529"
    },
    {
        "index": "#37",
        "title": "FUSED-Net: Enhancing Few-Shot Traffic Sign Detection with Unfrozen Parameters, Pseudo-Support Sets, Embedding Normalization, and Domain Adaptation",
        "link": "/arxiv/2409.14852",
        "arxiv_id": "2409.14852",
        "authors": "Md. Atiqur Rahman, Nahian Ibn Asad, Md. Mushfiqul Haque Omi, Md. Bakhtiar Hasan, Sabbir Ahmed, Md. Hasanul Kabir",
        "summary": "Automatic Traffic Sign Recognition is paramount in modern transportation systems, motivating several research endeavors to focus on performance improvement by utilizing large-scale datasets. As the appearance of traffic signs varies across countries, curating large-scale datasets is often impractical; and requires efficient models that can produce satisfactory performance using limited data. In this connection, we present 'FUSED-Net', built-upon Faster RCNN for traffic sign detection, enhanced by Unfrozen Parameters, Pseudo-Support Sets, Embedding Normalization, and Domain Adaptation while reducing data requirement. Unlike traditional approaches, we keep all parameters unfrozen during training, enabling FUSED-Net to learn from limited samples. The generation of a Pseudo-Support Set through data augmentation further enhances performance by compensating for the scarcity of target domain data. Additionally, Embedding Normalization is incorporated to reduce intra-class variance, standardizing feature representation. Domain Adaptation, achieved by pre-training on a diverse traffic sign dataset distinct from the target domain, improves model generalization. Evaluating FUSED-Net on the BDTSD dataset, we achieved 2.4x, 2.2x, 1.5x, and 1.3x improvements of mAP in 1-shot, 3-shot, 5-shot, and 10-shot scenarios, respectively compared to the state-of-the-art Few-Shot Object Detection (FSOD) models. Additionally, we outperform state-of-the-art works on the cross-domain FSOD benchmark under several scenarios.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 09:34:42 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.988738"
    },
    {
        "index": "#38",
        "title": "Disentanglement with Factor Quantized Variational Autoencoders",
        "link": "/arxiv/2409.14851",
        "arxiv_id": "2409.14851",
        "authors": "Gulcin Baykal, Melih Kandemir, Gozde Unal",
        "summary": "Disentangled representation learning aims to represent the underlying generative factors of a dataset in a latent representation independently of one another. In our work, we propose a discrete variational autoencoder (VAE) based model where the ground truth information about the generative factors are not provided to the model. We demonstrate the advantages of learning discrete representations over learning continuous representations in facilitating disentanglement. Furthermore, we propose incorporating an inductive bias into the model to further enhance disentanglement. Precisely, we propose scalar quantization of the latent variables in a latent representation with scalar values from a global codebook, and we add a total correlation term to the optimization as an inductive bias. Our method called FactorQVAE is the first method that combines optimization based disentanglement approaches with discrete representation learning, and it outperforms the former disentanglement methods in terms of two disentanglement metrics (DCI and InfoMEC) while improving the reconstruction performance. Our code can be found at \\url{https://github.com/ituvisionlab/FactorQVAE}.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-23 09:33:53 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.988954"
    },
    {
        "index": "#39",
        "title": "GroCo: Ground Constraint for Metric Self-Supervised Monocular Depth",
        "link": "/arxiv/2409.14850",
        "arxiv_id": "2409.14850",
        "authors": "Aurélien Cecille, Stefan Duffner, Franck Davoine, Thibault Neveu, Rémi Agier",
        "summary": "Monocular depth estimation has greatly improved in the recent years but models predicting metric depth still struggle to generalize across diverse camera poses and datasets. While recent supervised methods mitigate this issue by leveraging ground prior information at inference, their adaptability to self-supervised settings is limited due to the additional challenge of scale recovery. Addressing this gap, we propose in this paper a novel constraint on ground areas designed specifically for the self-supervised paradigm. This mechanism not only allows to accurately recover the scale but also ensures coherence between the depth prediction and the ground prior. Experimental results show that our method surpasses existing scale recovery techniques on the KITTI benchmark and significantly enhances model generalization capabilities. This improvement can be observed by its more robust performance across diverse camera rotations and its adaptability in zero-shot conditions with previously unseen driving datasets such as DDAD.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning, Robotics",
        "date": "2024-09-23 09:30:27 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.989189"
    },
    {
        "index": "#40",
        "title": "Revisiting Video Quality Assessment from the Perspective of Generalization",
        "link": "/arxiv/2409.14847",
        "arxiv_id": "2409.14847",
        "authors": "Xinli Yue, Jianhui Sun, Liangchao Yao, Fan Xia, Yuetang Deng, Tianyi Wang, Lei Li, Fengyun Rao, Jing Lv, Qian Wang, Lingchen Zhao",
        "summary": "The increasing popularity of short video platforms such as YouTube Shorts, TikTok, and Kwai has led to a surge in User-Generated Content (UGC), which presents significant challenges for the generalization performance of Video Quality Assessment (VQA) tasks. These challenges not only affect performance on test sets but also impact the ability to generalize across different datasets. While prior research has primarily focused on enhancing feature extractors, sampling methods, and network branches, it has largely overlooked the generalization capabilities of VQA tasks. In this work, we reevaluate the VQA task from a generalization standpoint. We begin by analyzing the weight loss landscape of VQA models, identifying a strong correlation between this landscape and the generalization gaps. We then investigate various techniques to regularize the weight loss landscape. Our results reveal that adversarial weight perturbations can effectively smooth this landscape, significantly improving the generalization performance, with cross-dataset generalization and fine-tuning performance enhanced by up to 1.8% and 3%, respectively. Through extensive experiments across various VQA methods and datasets, we validate the effectiveness of our approach. Furthermore, by leveraging our insights, we achieve state-of-the-art performance in Image Quality Assessment (IQA) tasks. Our code is available at https://github.com/XinliYue/VQA-Generalization.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 09:24:55 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.989415"
    },
    {
        "index": "#41",
        "title": "Two Deep Learning Solutions for Automatic Blurring of Faces in Videos",
        "link": "/arxiv/2409.14828",
        "arxiv_id": "2409.14828",
        "authors": "Roman Plaud, Jose-Luis Lisani",
        "summary": "The widespread use of cameras in everyday life situations generates a vast amount of data that may contain sensitive information about the people and vehicles moving in front of them (location, license plates, physical characteristics, etc). In particular, people's faces are recorded by surveillance cameras in public spaces. In order to ensure the privacy of individuals, face blurring techniques can be applied to the collected videos. In this paper we present two deep-learning based options to tackle the problem. First, a direct approach, consisting of a classical object detector (based on the YOLO architecture) trained to detect faces, which are subsequently blurred. Second, an indirect approach, in which a Unet-like segmentation network is trained to output a version of the input image in which all the faces have been blurred.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 08:59:44 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.989588"
    },
    {
        "index": "#42",
        "title": "AIM 2024 Challenge on Video Saliency Prediction: Methods and Results",
        "link": "/arxiv/2409.14827",
        "arxiv_id": "2409.14827",
        "authors": "Andrey Moskalenko, Alexey Bryncev, Dmitry Vatolin, Radu Timofte, Gen Zhan, Li Yang, Yunlong Tang, Yiting Liao, Jiongzhi Lin, Baitao Huang, Morteza Moradi, Mohammad Moradi, Francesco Rundo, Concetto Spampinato, Ali Borji, Simone Palazzo, Yuxin Zhu, Yinan Sun, Huiyu Duan, Yuqin Cao, Ziheng Jia, Qiang Hu, Xiongkuo Min, Guangtao Zhai, Hao Fang, Runmin Cong, Xiankai Lu, Xiaofei Zhou, Wei Zhang, Chunyu Zhao, Wentao Mu, Tao Deng, Hamed R. Tavakoli",
        "summary": "This paper reviews the Challenge on Video Saliency Prediction at AIM 2024. The goal of the participants was to develop a method for predicting accurate saliency maps for the provided set of video sequences. Saliency maps are widely exploited in various applications, including video compression, quality assessment, visual perception studies, the advertising industry, etc. For this competition, a previously unused large-scale audio-visual mouse saliency (AViMoS) dataset of 1500 videos with more than 70 observers per video was collected using crowdsourced mouse tracking. The dataset collection methodology has been validated using conventional eye-tracking data and has shown high consistency. Over 30 teams registered in the challenge, and there are 7 teams that submitted the results in the final phase. The final phase solutions were tested and ranked by commonly used quality metrics on a private test subset. The results of this evaluation and the descriptions of the solutions are presented in this report. All data, including the private test subset, is made publicly available on the challenge homepage - https://challenges.videoprocessing.ai/challenges/video-saliency-prediction.html.",
        "subjects": "Computer Vision and Pattern Recognition, Human-Computer Interaction, Multimedia",
        "date": "2024-09-23 08:59:22 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.989974"
    },
    {
        "index": "#43",
        "title": "Advancing Depression Detection on Social Media Platforms Through Fine-Tuned Large Language Models",
        "link": "/arxiv/2409.14794",
        "arxiv_id": "2409.14794",
        "authors": "Shahid Munir Shah, Syeda Anshrah Gillani, Mirza Samad Ahmed Baig, Muhammad Aamer Saleem, Muhammad Hamzah Siddiqui",
        "summary": "This study investigates the use of Large Language Models (LLMs) for improved depression detection from users social media data. Through the use of fine-tuned GPT 3.5 Turbo 1106 and LLaMA2-7B models and a sizable dataset from earlier studies, we were able to identify depressed content in social media posts with a high accuracy of nearly 96.0 percent. The comparative analysis of the obtained results with the relevant studies in the literature shows that the proposed fine-tuned LLMs achieved enhanced performance compared to existing state of the-art systems. This demonstrates the robustness of LLM-based fine-tuned systems to be used as potential depression detection systems. The study describes the approach in depth, including the parameters used and the fine-tuning procedure, and it addresses the important implications of our results for the early diagnosis of depression on several social media platforms.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 08:18:25 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.990168"
    },
    {
        "index": "#44",
        "title": "Human Hair Reconstruction with Strand-Aligned 3D Gaussians",
        "link": "/arxiv/2409.14778",
        "arxiv_id": "2409.14778",
        "authors": "Egor Zakharov, Vanessa Sklyarova, Michael Black, Giljoo Nam, Justus Thies, Otmar Hilliges",
        "summary": "We introduce a new hair modeling method that uses a dual representation of classical hair strands and 3D Gaussians to produce accurate and realistic strand-based reconstructions from multi-view data. In contrast to recent approaches that leverage unstructured Gaussians to model human avatars, our method reconstructs the hair using 3D polylines, or strands. This fundamental difference allows the use of the resulting hairstyles out-of-the-box in modern computer graphics engines for editing, rendering, and simulation. Our 3D lifting method relies on unstructured Gaussians to generate multi-view ground truth data to supervise the fitting of hair strands. The hairstyle itself is represented in the form of the so-called strand-aligned 3D Gaussians. This representation allows us to combine strand-based hair priors, which are essential for realistic modeling of the inner structure of hairstyles, with the differentiable rendering capabilities of 3D Gaussian Splatting. Our method, named Gaussian Haircut, is evaluated on synthetic and real scenes and demonstrates state-of-the-art performance in the task of strand-based hair reconstruction.",
        "subjects": "Computer Vision and Pattern Recognition, Graphics",
        "date": "2024-09-23 07:49:46 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.995652"
    },
    {
        "index": "#45",
        "title": "CFVNet: An End-to-End Cancelable Finger Vein Network for Recognition",
        "link": "/arxiv/2409.14774",
        "arxiv_id": "2409.14774",
        "authors": "Yifan Wang, Jie Gui, Yuan Yan Tang, James Tin-Yau Kwok",
        "summary": "Finger vein recognition technology has become one of the primary solutions for high-security identification systems. However, it still has information leakage problems, which seriously jeopardizes users privacy and anonymity and cause great security risks. In addition, there is no work to consider a fully integrated secure finger vein recognition system. So, different from the previous systems, we integrate preprocessing and template protection into an integrated deep learning model. We propose an end-to-end cancelable finger vein network (CFVNet), which can be used to design an secure finger vein recognition system.It includes a plug-and-play BWR-ROIAlign unit, which consists of three sub-modules: Localization, Compression and Transformation. The localization module achieves automated localization of stable and unique finger vein ROI. The compression module losslessly removes spatial and channel redundancies. The transformation module uses the proposed BWR method to introduce unlinkability, irreversibility and revocability to the system. BWR-ROIAlign can directly plug into the model to introduce the above features for DCNN-based finger vein recognition systems. We perform extensive experiments on four public datasets to study the performance and cancelable biometric attributes of the CFVNet-based recognition system. The average accuracy, EERs and Dsys on the four datasets are 99.82%, 0.01% and 0.025, respectively, and achieves competitive performance compared with the state-of-the-arts.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 07:43:44 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.995886"
    },
    {
        "index": "#46",
        "title": "Robust and Flexible Omnidirectional Depth Estimation with Multiple 360° Cameras",
        "link": "/arxiv/2409.14766",
        "arxiv_id": "2409.14766",
        "authors": "Ming Li, Xueqian Jin, Xuejiao Hu, Jinghao Cao, Sidan Du, Yang Li",
        "summary": "Omnidirectional depth estimation has received much attention from researchers in recent years. However, challenges arise due to camera soiling and variations in camera layouts, affecting the robustness and flexibility of the algorithm. In this paper, we use the geometric constraints and redundant information of multiple 360-degree cameras to achieve robust and flexible multi-view omnidirectional depth estimation. We implement two algorithms, in which the two-stage algorithm obtains initial depth maps by pairwise stereo matching of multiple cameras and fuses the multiple depth maps to achieve the final depth estimation; the one-stage algorithm adopts spherical sweeping based on hypothetical depths to construct a uniform spherical matching cost of the multi-camera images and obtain the depth. Additionally, a generalized epipolar equirectangular projection is introduced to simplify the spherical epipolar constraints. To overcome panorama distortion, a spherical feature extractor is implemented. Furthermore, a synthetic 360-degree dataset consisting of 12K road scene panoramas and 3K ground truth depth maps is presented to train and evaluate 360-degree depth estimation algorithms. Our dataset takes soiled camera lenses and glare into consideration, which is more consistent with the real-world environment. Experiments show that our two algorithms achieve state-of-the-art performance, accurately predicting depth maps even when provided with soiled panorama inputs. The flexibility of the algorithms is experimentally validated in terms of camera layouts and numbers.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 07:31:48 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.996211"
    },
    {
        "index": "#47",
        "title": "VLM's Eye Examination: Instruct and Inspect Visual Competency of Vision Language Models",
        "link": "/arxiv/2409.14759",
        "arxiv_id": "2409.14759",
        "authors": "Nam Hyeon-Woo, Moon Ye-Bin, Wonseok Choi, Lee Hyun, Tae-Hyun Oh",
        "summary": "Vision language models (VLMs) have shown promising reasoning capabilities across various benchmarks; however, our understanding of their visual perception remains limited. In this work, we propose an eye examination process to investigate how a VLM perceives images, specifically focusing on key elements of visual recognition, from primitive color and shape to semantic levels. To this end, we introduce a dataset named LENS to guide a VLM to follow the examination and check its readiness. Once the model is ready, we conduct the examination. Through this examination, we quantify and visualize VLMs' sensitivities to color and shape, and semantic matching. Our findings reveal that VLMs have varying sensitivity to different colors while consistently showing insensitivity to green across different VLMs. Also, we found different shape sensitivity and semantic recognition depending on LLM's capacity despite using the same fixed visual encoder. Our analyses and findings have potential to inspire the design of VLMs and the pre-processing of visual input to VLMs for improving application performance.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 07:15:29 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.996420"
    },
    {
        "index": "#48",
        "title": "BranchPoseNet: Characterizing tree branching with a deep learning-based pose estimation approach",
        "link": "/arxiv/2409.14755",
        "arxiv_id": "2409.14755",
        "authors": "Stefano Puliti, Carolin Fischer, Rasmus Astrup",
        "summary": "This paper presents an automated pipeline for detecting tree whorls in proximally laser scanning data using a pose-estimation deep learning model. Accurate whorl detection provides valuable insights into tree growth patterns, wood quality, and offers potential for use as a biometric marker to track trees throughout the forestry value chain. The workflow processes point cloud data to create sectional images, which are subsequently used to identify keypoints representing tree whorls and branches along the stem. The method was tested on a dataset of destructively sampled individual trees, where the whorls were located along the stems of felled trees. The results demonstrated strong potential, with accurate identification of tree whorls and precise calculation of key structural metrics, unlocking new insights and deeper levels of information from individual tree point clouds.",
        "subjects": "Computer Vision and Pattern Recognition, Quantitative Methods",
        "date": "2024-09-23 07:10:11 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.996609"
    },
    {
        "index": "#49",
        "title": "UniBEVFusion: Unified Radar-Vision BEVFusion for 3D Object Detection",
        "link": "/arxiv/2409.14751",
        "arxiv_id": "2409.14751",
        "authors": "Haocheng Zhao, Runwei Guan, Taoyu Wu, Ka Lok Man, Limin Yu, Yutao Yue",
        "summary": "4D millimeter-wave (MMW) radar, which provides both height information and dense point cloud data over 3D MMW radar, has become increasingly popular in 3D object detection. In recent years, radar-vision fusion models have demonstrated performance close to that of LiDAR-based models, offering advantages in terms of lower hardware costs and better resilience in extreme conditions. However, many radar-vision fusion models treat radar as a sparse LiDAR, underutilizing radar-specific information. Additionally, these multi-modal networks are often sensitive to the failure of a single modality, particularly vision. To address these challenges, we propose the Radar Depth Lift-Splat-Shoot (RDL) module, which integrates radar-specific data into the depth prediction process, enhancing the quality of visual Bird-Eye View (BEV) features. We further introduce a Unified Feature Fusion (UFF) approach that extracts BEV features across different modalities using shared module. To assess the robustness of multi-modal models, we develop a novel Failure Test (FT) ablation experiment, which simulates vision modality failure by injecting Gaussian noise. We conduct extensive experiments on the View-of-Delft (VoD) and TJ4D datasets. The results demonstrate that our proposed Unified BEVFusion (UniBEVFusion) network significantly outperforms state-of-the-art models on the TJ4D dataset, with improvements of 1.44 in 3D and 1.72 in BEV object detection accuracy.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 06:57:27 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.996815"
    },
    {
        "index": "#50",
        "title": "FineCops-Ref: A new Dataset and Task for Fine-Grained Compositional Referring Expression Comprehension",
        "link": "/arxiv/2409.14750",
        "arxiv_id": "2409.14750",
        "authors": "Junzhuo Liu, Xuzheng Yang, Weiwei Li, Peng Wang",
        "summary": "Referring Expression Comprehension (REC) is a crucial cross-modal task that objectively evaluates the capabilities of language understanding, image comprehension, and language-to-image grounding. Consequently, it serves as an ideal testing ground for Multi-modal Large Language Models (MLLMs). In pursuit of this goal, we have established a new REC dataset characterized by two key features: Firstly, it is designed with controllable varying levels of difficulty, necessitating multi-level fine-grained reasoning across object categories, attributes, and multi-hop relationships. Secondly, it includes negative text and images created through fine-grained editing and generation based on existing data, thereby testing the model's ability to correctly reject scenarios where the target object is not visible in the image--an essential aspect often overlooked in existing datasets and approaches. Utilizing this high-quality dataset, we conducted comprehensive evaluations of both state-of-the-art specialist models and MLLMs. Our findings indicate that there remains a significant gap in achieving satisfactory grounding performance. We anticipate that our dataset will inspire new approaches to enhance visual reasoning and develop more advanced cross-modal interaction strategies, ultimately unlocking the full potential of MLLMs. Our code and the datasets are available at https://github.com/liujunzhuo/FineCops-Ref.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2024-09-23 06:56:51 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.997012"
    },
    {
        "index": "#51",
        "title": "Distribution-Level Feature Distancing for Machine Unlearning: Towards a Better Trade-off Between Model Utility and Forgetting",
        "link": "/arxiv/2409.14747",
        "arxiv_id": "2409.14747",
        "authors": "Dasol Choi, Dongbin Na",
        "summary": "With the explosive growth of deep learning applications, the right to be forgotten has become increasingly in demand in various AI industries. For example, given a facial recognition system, some individuals may wish to remove images that might have been used in the training phase from the trained model. Unfortunately, modern deep neural networks sometimes unexpectedly leak personal identities. Recent studies have presented various machine unlearning algorithms to make a trained model unlearn the data to be forgotten. While these methods generally perform well in terms of forgetting scores, we have found that an unexpected modelutility drop can occur. This phenomenon, which we term correlation collapse, happens when the machine unlearning algorithms reduce the useful correlation between image features and the true label. To address this challenge, we propose Distribution-Level Feature Distancing (DLFD), a novel method that efficiently forgets instances while preventing correlation collapse. Our method synthesizes data samples so that the generated data distribution is far from the distribution of samples being forgotten in the feature space, achieving effective results within a single training epoch. Through extensive experiments on facial recognition datasets, we demonstrate that our approach significantly outperforms state-of-the-art machine unlearning methods.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 06:51:10 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.997188"
    },
    {
        "index": "#52",
        "title": "Less yet robust: crucial region selection for scene recognition",
        "link": "/arxiv/2409.14741",
        "arxiv_id": "2409.14741",
        "authors": "Jianqi Zhang, Mengxuan Wang, Jingyao Wang, Lingyu Si, Changwen Zheng, Fanjiang Xu",
        "summary": "Scene recognition, particularly for aerial and underwater images, often suffers from various types of degradation, such as blurring or overexposure. Previous works that focus on convolutional neural networks have been shown to be able to extract panoramic semantic features and perform well on scene recognition tasks. However, low-quality images still impede model performance due to the inappropriate use of high-level semantic features. To address these To address these challenges, we propose an adaptive selection mechanism to identify the most important and robust regions with high-level features. Thus, the model can perform learning via these regions to avoid interference. implement a learnable mask in the neural network, which can filter high-level features by assigning weights to different regions of the feature matrix. We also introduce a regularization term to further enhance the significance of key high-level feature regions. Different from previous methods, our learnable matrix pays extra attention to regions that are important to multiple categories but may cause misclassification and sets constraints to reduce the influence of such regions.This is a plug-and-play architecture that can be easily extended to other methods. Additionally, we construct an Underwater Geological Scene Classification dataset to assess the effectiveness of our model. Extensive experimental results demonstrate the superiority and robustness of our proposed method over state-of-the-art techniques on two datasets.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-23 06:39:35 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.997385"
    },
    {
        "index": "#53",
        "title": "EDSNet: Efficient-DSNet for Video Summarization",
        "link": "/arxiv/2409.14724",
        "arxiv_id": "2409.14724",
        "authors": "Ashish Prasad, Pranav Jeevan, Amit Sethi",
        "summary": "Current video summarization methods largely rely on transformer-based architectures, which, due to their quadratic complexity, require substantial computational resources. In this work, we address these inefficiencies by enhancing the Direct-to-Summarize Network (DSNet) with more resource-efficient token mixing mechanisms. We show that replacing traditional attention with alternatives like Fourier, Wavelet transforms, and Nyströmformer improves efficiency and performance. Furthermore, we explore various pooling strategies within the Regional Proposal Network, including ROI pooling, Fast Fourier Transform pooling, and flat pooling. Our experimental results on TVSum and SumMe datasets demonstrate that these modifications significantly reduce computational costs while maintaining competitive summarization performance. Thus, our work offers a more scalable solution for video summarization tasks.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 05:43:37 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.997571"
    },
    {
        "index": "#54",
        "title": "ControlEdit: A MultiModal Local Clothing Image Editing Method",
        "link": "/arxiv/2409.14720",
        "arxiv_id": "2409.14720",
        "authors": "Di Cheng, YingJie Shi, ShiXin Sun, JiaFu Zhang, WeiJing Wang, Yu Liu",
        "summary": "Multimodal clothing image editing refers to the precise adjustment and modification of clothing images using data such as textual descriptions and visual images as control conditions, which effectively improves the work efficiency of designers and reduces the threshold for user design. In this paper, we propose a new image editing method ControlEdit, which transfers clothing image editing to multimodal-guided local inpainting of clothing images. We address the difficulty of collecting real image datasets by leveraging the self-supervised learning approach. Based on this learning approach, we extend the channels of the feature extraction network to ensure consistent clothing image style before and after editing, and we design an inverse latent loss function to achieve soft control over the content of non-edited areas. In addition, we adopt Blended Latent Diffusion as the sampling method to make the editing boundaries transition naturally and enforce consistency of non-edited area content. Extensive experiments demonstrate that ControlEdit surpasses baseline algorithms in both qualitative and quantitative evaluations.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 05:34:59 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.997761"
    },
    {
        "index": "#55",
        "title": "Phantom of Latent for Large Language and Vision Models",
        "link": "/arxiv/2409.14713",
        "arxiv_id": "2409.14713",
        "authors": "Byung-Kwan Lee, Sangyun Chung, Chae Won Kim, Beomchan Park, Yong Man Ro",
        "summary": "The success of visual instruction tuning has accelerated the development of large language and vision models (LLVMs). Following the scaling laws of instruction-tuned large language models (LLMs), LLVMs either have further increased their sizes, reaching 26B, 34B, and even 80B parameters. While this increase in model size has yielded significant performance gains, it demands substantially more hardware resources for both training and inference. Consequently, there naturally exists a strong need for efficient LLVMs that achieve the performance of larger models while being smaller in size. To achieve this need, we present a new efficient LLVM family with model sizes of 0.5B, 1.8B, 3.8B, and 7B parameters, Phantom, which significantly enhances learning capabilities within limited structures. By temporarily increasing the latent hidden dimension during multi-head self-attention (MHSA), we make LLVMs prepare to look and understand much more vision-language knowledge on the latent, without substantially increasing physical model sizes. To maximize its advantage, we introduce Phantom Optimization (PO) using both autoregressive supervised fine-tuning (SFT) and direct preference optimization (DPO)-like concept, which effectively follows correct answers while eliminating incorrect and ambiguous ones. Phantom outperforms numerous larger open- and closed-source LLVMs, positioning itself as a leading solution in the landscape of efficient LLVMs.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 05:19:06 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.997984"
    },
    {
        "index": "#56",
        "title": "VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models",
        "link": "/arxiv/2409.14704",
        "arxiv_id": "2409.14704",
        "authors": "Jingtao Cao, Zheng Zhang, Hongru Wang, Kam-Fai Wong",
        "summary": "Progress in Text-to-Image (T2I) models has significantly improved the generation of images from textual descriptions. However, existing evaluation metrics do not adequately assess the models' ability to handle a diverse range of textual prompts, which is crucial for their generalizability. To address this, we introduce a new metric called Visual Language Evaluation Understudy (VLEU). VLEU uses large language models to sample from the visual text domain, the set of all possible input texts for T2I models, to generate a wide variety of prompts. The images generated from these prompts are evaluated based on their alignment with the input text using the CLIP model.VLEU quantifies a model's generalizability by computing the Kullback-Leibler divergence between the marginal distribution of the visual text and the conditional distribution of the images generated by the model. This metric provides a quantitative way to compare different T2I models and track improvements during model finetuning. Our experiments demonstrate the effectiveness of VLEU in evaluating the generalization capability of various T2I models, positioning it as an essential metric for future research in text-to-image synthesis.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2024-09-23 04:50:36 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.998213"
    },
    {
        "index": "#57",
        "title": "Dynamic Realms: 4D Content Analysis, Recovery and Generation with Geometric, Topological and Physical Priors",
        "link": "/arxiv/2409.14692",
        "arxiv_id": "2409.14692",
        "authors": "Zhiyang Dou",
        "summary": "My research focuses on the analysis, recovery, and generation of 4D content, where 4D includes three spatial dimensions (x, y, z) and a temporal dimension t, such as shape and motion. This focus goes beyond static objects to include dynamic changes over time, providing a comprehensive understanding of both spatial and temporal variations. These techniques are critical in applications like AR/VR, embodied AI, and robotics. My research aims to make 4D content generation more efficient, accessible, and higher in quality by incorporating geometric, topological, and physical priors. I also aim to develop effective methods for 4D content recovery and analysis using these priors.",
        "subjects": "Computer Vision and Pattern Recognition, Graphics",
        "date": "2024-09-23 03:46:51 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.998390"
    },
    {
        "index": "#58",
        "title": "Quantifying Context Bias in Domain Adaptation for Object Detection",
        "link": "/arxiv/2409.14679",
        "arxiv_id": "2409.14679",
        "authors": "Hojun Son, Arpan Kusari",
        "summary": "Domain adaptation for object detection (DAOD) aims to transfer a trained model from a source to a target domain. Various DAOD methods exist, some of which minimize context bias between foreground-background associations in various domains. However, no prior work has studied context bias in DAOD by analyzing changes in background features during adaptation and how context bias is represented in different domains. Our research experiment highlights the potential usability of context bias in DAOD. We address the problem by varying activation values over different layers of trained models and by masking the background, both of which impact the number and quality of detections. We then use one synthetic dataset from CARLA and two different versions of real open-source data, Cityscapes and Cityscapes foggy, as separate domains to represent and quantify context bias. We utilize different metrics such as Maximum Mean Discrepancy (MMD) and Maximum Variance Discrepancy (MVD) to find the layer-specific conditional probability estimates of foreground given manipulated background regions for separate domains. We demonstrate through detailed analysis that understanding of the context bias can affect DAOD approach and foc",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Robotics",
        "date": "2024-09-23 03:01:50 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.998577"
    },
    {
        "index": "#59",
        "title": "Reflecting Reality: Enabling Diffusion Models to Produce Faithful Mirror Reflections",
        "link": "/arxiv/2409.14677",
        "arxiv_id": "2409.14677",
        "authors": "Ankit Dhiman, Manan Shah, Rishubh Parihar, Yash Bhalgat, Lokesh R Boregowda, R Venkatesh Babu",
        "summary": "We tackle the problem of generating highly realistic and plausible mirror reflections using diffusion-based generative models. We formulate this problem as an image inpainting task, allowing for more user control over the placement of mirrors during the generation process. To enable this, we create SynMirror, a large-scale dataset of diverse synthetic scenes with objects placed in front of mirrors. SynMirror contains around 198K samples rendered from 66K unique 3D objects, along with their associated depth maps, normal maps and instance-wise segmentation masks, to capture relevant geometric properties of the scene. Using this dataset, we propose a novel depth-conditioned inpainting method called MirrorFusion, which generates high-quality geometrically consistent and photo-realistic mirror reflections given an input image and a mask depicting the mirror region. MirrorFusion outperforms state-of-the-art methods on SynMirror, as demonstrated by extensive quantitative and qualitative analysis. To the best of our knowledge, we are the first to successfully tackle the challenging problem of generating controlled and faithful mirror reflections of an object in a scene using diffusion based models. SynMirror and MirrorFusion open up new avenues for image editing and augmented reality applications for practitioners and researchers alike.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 02:59:07 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.998766"
    },
    {
        "index": "#60",
        "title": "AEANet: Affinity Enhanced Attentional Networks for Arbitrary Style Transfer",
        "link": "/arxiv/2409.14652",
        "arxiv_id": "2409.14652",
        "authors": "Gen Li",
        "summary": "Arbitrary artistic style transfer is a field that integrates rational academic research with emotional artistic creation. It aims to produce an image that not only features artistic characteristics of the target style but also preserves the texture structure of the content image itself. Existing style transfer methods primarily rely either on global statistics-based information or local patch-based. As a result, the generated images often either superficially apply a filter to the content image or capture extraneous semantic information from the style image, leading to a significant deviation from the global style. In this paper, we propose Affinity Enhanced-Attentional Networks (AEANet), which include a content affinity-enhanced attention (CAEA) module, style affinity-enhanced attention (SAEA) module, and hybrid attention (HA) module. The CAEA and SAEA modules first use attention to improve content and style representations with a Detail Enhanced(DE) module to reinforce fine details. Then, it aligns the global statistical information of the content and style features to fine-tune the feature information. Subsequently, the HA module adjusts the distribution of style features based on the distribution of content features. Additionally, we introduce affinity attention-based Local Dissimilarity Loss to preserve the affinities between the content and style images. Experimental results demonstrate that our approach outperforms state-of-the-art methods in arbitrary style transfer.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-23 01:39:11 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.998920"
    },
    {
        "index": "#61",
        "title": "EQ-CBM: A Probabilistic Concept Bottleneck with Energy-based Models and Quantized Vectors",
        "link": "/arxiv/2409.14630",
        "arxiv_id": "2409.14630",
        "authors": "Sangwon Kim, Dasom Ahn, Byoung Chul Ko, In-su Jang, Kwang-Ju Kim",
        "summary": "The demand for reliable AI systems has intensified the need for interpretable deep neural networks. Concept bottleneck models (CBMs) have gained attention as an effective approach by leveraging human-understandable concepts to enhance interpretability. However, existing CBMs face challenges due to deterministic concept encoding and reliance on inconsistent concepts, leading to inaccuracies. We propose EQ-CBM, a novel framework that enhances CBMs through probabilistic concept encoding using energy-based models (EBMs) with quantized concept activation vectors (qCAVs). EQ-CBM effectively captures uncertainties, thereby improving prediction reliability and accuracy. By employing qCAVs, our method selects homogeneous vectors during concept encoding, enabling more decisive task performance and facilitating higher levels of human intervention. Empirical results using benchmark datasets demonstrate that our approach outperforms the state-of-the-art in both concept and task accuracy.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-22 23:43:45 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.999123"
    },
    {
        "index": "#62",
        "title": "SOS: Segment Object System for Open-World Instance Segmentation With Object Priors",
        "link": "/arxiv/2409.14627",
        "arxiv_id": "2409.14627",
        "authors": "Christian Wilms, Tim Rolff, Maris Hillemann, Robert Johanson, Simone Frintrop",
        "summary": "We propose an approach for Open-World Instance Segmentation (OWIS), a task that aims to segment arbitrary unknown objects in images by generalizing from a limited set of annotated object classes during training. Our Segment Object System (SOS) explicitly addresses the generalization ability and the low precision of state-of-the-art systems, which often generate background detections. To this end, we generate high-quality pseudo annotations based on the foundation model SAM. We thoroughly study various object priors to generate prompts for SAM, explicitly focusing the foundation model on objects. The strongest object priors were obtained by self-attention maps from self-supervised Vision Transformers, which we utilize for prompting SAM. Finally, the post-processed segments from SAM are used as pseudo annotations to train a standard instance segmentation system. Our approach shows strong generalization capabilities on COCO, LVIS, and ADE20k datasets and improves on the precision by up to 81.6% compared to the state-of-the-art. Source code is available at: https://github.com/chwilms/SOS",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 23:35:31 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.999316"
    },
    {
        "index": "#63",
        "title": "Secrets of Edge-Informed Contrast Maximization for Event-Based Vision",
        "link": "/arxiv/2409.14611",
        "arxiv_id": "2409.14611",
        "authors": "Pritam P. Karmokar, Quan H. Nguyen, William J. Beksi",
        "summary": "Event cameras capture the motion of intensity gradients (edges) in the image plane in the form of rapid asynchronous events. When accumulated in 2D histograms, these events depict overlays of the edges in motion, consequently obscuring the spatial structure of the generating edges. Contrast maximization (CM) is an optimization framework that can reverse this effect and produce sharp spatial structures that resemble the moving intensity gradients by estimating the motion trajectories of the events. Nonetheless, CM is still an underexplored area of research with avenues for improvement. In this paper, we propose a novel hybrid approach that extends CM from uni-modal (events only) to bi-modal (events and edges). We leverage the underpinning concept that, given a reference time, optimally warped events produce sharp gradients consistent with the moving edge at that time. Specifically, we formalize a correlation-based objective to aid CM and provide key insights into the incorporation of multiscale and multireference techniques. Moreover, our edge-informed CM method yields superior sharpness scores and establishes new state-of-the-art event optical flow benchmarks on the MVSEC, DSEC, and ECD datasets.",
        "subjects": "Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2024-09-22 22:22:26 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.999505"
    },
    {
        "index": "#64",
        "title": "Patch Ranking: Efficient CLIP by Learning to Rank Local Patches",
        "link": "/arxiv/2409.14607",
        "arxiv_id": "2409.14607",
        "authors": "Cheng-En Wu, Jinhong Lin, Yu Hen Hu, Pedro Morgado",
        "summary": "Contrastive image-text pre-trained models such as CLIP have shown remarkable adaptability to downstream tasks. However, they face challenges due to the high computational requirements of the Vision Transformer (ViT) backbone. Current strategies to boost ViT efficiency focus on pruning patch tokens but fall short in addressing the multimodal nature of CLIP and identifying the optimal subset of tokens for maximum performance. To address this, we propose greedy search methods to establish a \"Golden Ranking\" and introduce a lightweight predictor specifically trained to approximate this Ranking. To compensate for any performance degradation resulting from token pruning, we incorporate learnable visual tokens that aid in restoring and potentially enhancing the model's performance. Our work presents a comprehensive and systematic investigation of pruning tokens within the ViT backbone of CLIP models. Through our framework, we successfully reduced 40% of patch tokens in CLIP's ViT while only suffering a minimal average accuracy loss of 0.3 across seven datasets. Our study lays the groundwork for building more computationally efficient multimodal models without sacrificing their performance, addressing a key challenge in the application of advanced vision-language models.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-22 22:04:26 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.999701"
    },
    {
        "index": "#65",
        "title": "URSimulator: Human-Perception-Driven Prompt Tuning for Enhanced Virtual Urban Renewal via Diffusion Models",
        "link": "/arxiv/2409.14589",
        "arxiv_id": "2409.14589",
        "authors": "Chuanbo Hu, Shan Jia, Xin Li",
        "summary": "Tackling Urban Physical Disorder (e.g., abandoned buildings, litter, messy vegetation, graffiti) is essential, as it negatively impacts the safety, well-being, and psychological state of communities. Urban Renewal is the process of revitalizing these neglected and decayed areas within a city to improve the physical environment and quality of life for residents. Effective urban renewal efforts can transform these environments, enhancing their appeal and livability. However, current research lacks simulation tools that can quantitatively assess and visualize the impacts of renewal efforts, often relying on subjective judgments. Such tools are crucial for planning and implementing effective strategies by providing a clear visualization of potential changes and their impacts. This paper presents a novel framework addressing this gap by using human perception feedback to simulate street environment enhancement. We develop a prompt tuning approach that integrates text-driven Stable Diffusion with human perception feedback, iteratively editing local areas of street view images to better align with perceptions of beauty, liveliness, and safety. Our experiments show that this framework significantly improves perceptions of urban environments, with increases of 17.60% in safety, 31.15% in beauty, and 28.82% in liveliness. In contrast, advanced methods like DiffEdit achieve only 2.31%, 11.87%, and 15.84% improvements, respectively. We applied this framework across various virtual scenarios, including neighborhood improvement, building redevelopment, green space expansion, and community garden creation. The results demonstrate its effectiveness in simulating urban renewal, offering valuable insights for urban planning and policy-making.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 20:39:32 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:30:59.999880"
    },
    {
        "index": "#66",
        "title": "Space evaluation based on pitch control using drone video in Ultimate",
        "link": "/arxiv/2409.14588",
        "arxiv_id": "2409.14588",
        "authors": "Shunsuke Iwashita, Atom Scott, Rikuhei Umemoto, Ning Ding, Keisuke Fujii",
        "summary": "Ultimate is a sport in which teams of seven players compete for points by passing a disc into the end zone. A distinctive aspect of Ultimate is that the player holding the disc is unable to move, underscoring the significance of creating space to receive passes. Despite extensive research into space evaluation in sports such as football and basketball, there is a paucity of information available for Ultimate. This study focuses on the 3-on-3 format, which is widely practiced in Ultimate, and evaluates space during offensive play. The data collection process entailed the use of drones for filming and the subsequent correction of the angles for the purpose of obtaining positional data. The model is derived from the pitch control model of soccer and adapted to the rules of Ultimate, where the player holding the disc is stationary. The integration of position and distance weights with pitch control values enables the derivation of space evaluation metrics. The findings of this study indicate that movement to create space and accurate passing into that space are both significant factors in scoring. The code is available at https://github.com/shunsuke-iwashita/USO.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-03 01:19:02 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.000126"
    },
    {
        "index": "#67",
        "title": "Deep Learning Techniques for Atmospheric Turbulence Removal: A Review",
        "link": "/arxiv/2409.14587",
        "arxiv_id": "2409.14587",
        "authors": "Paul Hill, Nantheera Anantrasirichai, Alin Achim, David Bull",
        "summary": "The influence of atmospheric turbulence on acquired imagery makes image interpretation and scene analysis extremely difficult and reduces the effectiveness of conventional approaches for classifying and tracking objects of interest in the scene. Restoring a scene distorted by atmospheric turbulence is also a challenging problem. The effect, which is caused by random, spatially varying perturbations, makes conventional model-based approaches difficult and, in most cases, impractical due to complexity and memory requirements. Deep learning approaches offer faster operation and are capable of implementation on small devices. This paper reviews the characteristics of atmospheric turbulence and its impact on acquired imagery. It compares the performance of various state-of-the-art deep neural networks, including Transformers, SWIN and Mamba, when used to mitigate spatio-temporal image distortions.",
        "subjects": "Computer Vision and Pattern Recognition, Instrumentation and Methods for Astrophysics",
        "date": "2024-09-03 15:53:22 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.000373"
    },
    {
        "index": "#68",
        "title": "AR Overlay: Training Image Pose Estimation on Curved Surface in a Synthetic Way",
        "link": "/arxiv/2409.14577",
        "arxiv_id": "2409.14577",
        "authors": "Sining Huang, Yukun Song, Yixiao Kang, Chang Yu",
        "summary": "In the field of spatial computing, one of the most essential tasks is the pose estimation of 3D objects. While rigid transformations of arbitrary 3D objects are relatively hard to detect due to varying environment introducing factors like insufficient lighting or even occlusion, objects with pre-defined shapes are often easy to track, leveraging geometric constraints. Curved images, with flexible dimensions but a confined shape, are essential shapes often targeted in 3D tracking. Traditionally, proprietary algorithms often require specific curvature measures as the input along with the original flattened images to enable pose estimation for a single image target. In this paper, we propose a pipeline that can detect several logo images simultaneously and only requires the original images as the input, unlocking more effects in downstream fields such as Augmented Reality (AR).",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 19:44:46 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.010904"
    },
    {
        "index": "#69",
        "title": "Event-ECC: Asynchronous Tracking of Events with Continuous Optimization",
        "link": "/arxiv/2409.14564",
        "arxiv_id": "2409.14564",
        "authors": "Maria Zafeiri, Georgios Evangelidis, Emmanouil Psarakis",
        "summary": "In this paper, an event-based tracker is presented. Inspired by recent advances in asynchronous processing of individual events, we develop a direct matching scheme that aligns spatial distributions of events at different times. More specifically, we adopt the Enhanced Correlation Coefficient (ECC) criterion and propose a tracking algorithm that computes a 2D motion warp per single event, called event-ECC (eECC). The complete tracking of a feature along time is cast as a \\emph{single} iterative continuous optimization problem, whereby every single iteration is executed per event. The computational burden of event-wise processing is alleviated through a lightweight version that benefits from incremental processing and updating scheme. We test the proposed algorithm on publicly available datasets and we report improvements in tracking accuracy and feature age over state-of-the-art event-based asynchronous trackers.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 19:03:19 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.011333"
    },
    {
        "index": "#70",
        "title": "GlamTry: Advancing Virtual Try-On for High-End Accessories",
        "link": "/arxiv/2409.14553",
        "arxiv_id": "2409.14553",
        "authors": "Ting-Yu Chang, Seretsi Khabane Lekena",
        "summary": "The paper aims to address the lack of photorealistic virtual try-on models for accessories such as jewelry and watches, which are particularly relevant for online retail applications. While existing virtual try-on models focus primarily on clothing items, there is a gap in the market for accessories. This research explores the application of techniques from 2D virtual try-on models for clothing, such as VITON-HD, and integrates them with other computer vision models, notably MediaPipe Hand Landmarker. Drawing on existing literature, the study customizes and retrains a unique model using accessory-specific data and network architecture modifications to assess the feasibility of extending virtual try-on technology to accessories. Results demonstrate improved location prediction compared to the original model for clothes, even with a small dataset. This underscores the model's potential with larger datasets exceeding 10,000 images, paving the way for future research in virtual accessory try-on applications.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 18:29:32 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.011575"
    },
    {
        "index": "#71",
        "title": "TrackNetV4: Enhancing Fast Sports Object Tracking with Motion Attention Maps",
        "link": "/arxiv/2409.14543",
        "arxiv_id": "2409.14543",
        "authors": "Arjun Raj, Lei Wang, Tom Gedeon",
        "summary": "Accurately detecting and tracking high-speed, small objects, such as balls in sports videos, is challenging due to factors like motion blur and occlusion. Although recent deep learning frameworks like TrackNetV1, V2, and V3 have advanced tennis ball and shuttlecock tracking, they often struggle in scenarios with partial occlusion or low visibility. This is primarily because these models rely heavily on visual features without explicitly incorporating motion information, which is crucial for precise tracking and trajectory prediction. In this paper, we introduce an enhancement to the TrackNet family by fusing high-level visual features with learnable motion attention maps through a motion-aware fusion mechanism, effectively emphasizing the moving ball's location and improving tracking performance. Our approach leverages frame differencing maps, modulated by a motion prompt layer, to highlight key motion regions over time. Experimental results on the tennis ball and shuttlecock datasets show that our method enhances the tracking performance of both TrackNetV2 and V3. We refer to our lightweight, plug-and-play solution, built on top of the existing TrackNet, as TrackNetV4.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 17:58:09 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.011765"
    },
    {
        "index": "#72",
        "title": "Towards Model-Agnostic Dataset Condensation by Heterogeneous Models",
        "link": "/arxiv/2409.14538",
        "arxiv_id": "2409.14538",
        "authors": "Jun-Yeong Moon, Jung Uk Kim, Gyeong-Moon Park",
        "summary": "Abstract. The advancement of deep learning has coincided with the proliferation of both models and available data. The surge in dataset sizes and the subsequent surge in computational requirements have led to the development of the Dataset Condensation (DC). While prior studies have delved into generating synthetic images through methods like distribution alignment and training trajectory tracking for more efficient model training, a significant challenge arises when employing these condensed images practically. Notably, these condensed images tend to be specific to particular models, constraining their versatility and practicality. In response to this limitation, we introduce a novel method, Heterogeneous Model Dataset Condensation (HMDC), designed to produce universally applicable condensed images through cross-model interactions. To address the issues of gradient magnitude difference and semantic distance in models when utilizing heterogeneous models, we propose the Gradient Balance Module (GBM) and Mutual Distillation (MD) with the SpatialSemantic Decomposition method. By balancing the contribution of each model and maintaining their semantic meaning closely, our approach overcomes the limitations associated with model-specific condensed images and enhances the broader utility. The source code is available in https://github.com/KHU-AGI/HMDC.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 17:13:07 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.011936"
    },
    {
        "index": "#73",
        "title": "Video-XL: Extra-Long Vision Language Model for Hour-Scale Video Understanding",
        "link": "/arxiv/2409.14485",
        "arxiv_id": "2409.14485",
        "authors": "Yan Shu, Peitian Zhang, Zheng Liu, Minghao Qin, Junjie Zhou, Tiejun Huang, Bo Zhao",
        "summary": "Although current Multi-modal Large Language Models (MLLMs) demonstrate promising results in video understanding, processing extremely long videos remains an ongoing challenge. Typically, MLLMs struggle with handling thousands of tokens that exceed the maximum context length of LLMs, and they experience reduced visual clarity due to token aggregation. Another challenge is the high computational cost stemming from the large number of video tokens. To tackle these issues, we propose Video-XL, an extra-long vision language model designed for efficient hour-scale video understanding. Specifically, we argue that LLMs can be adapted as effective visual condensers and introduce Visual Context Latent Summarization, which condenses visual contexts into highly compact forms. Extensive experiments demonstrate that our model achieves promising results on popular long video understanding benchmarks, despite being trained on limited image data. Moreover, Video-XL strikes a promising balance between efficiency and effectiveness, processing 1024 frames on a single 80GB GPU while achieving nearly 100\\% accuracy in the Needle-in-a-Haystack evaluation. We envision Video-XL becoming a valuable tool for long video applications such as video summarization, surveillance anomaly detection, and Ad placement identification.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 15:13:31 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.012134"
    },
    {
        "index": "#74",
        "title": "Effectively Enhancing Vision Language Large Models by Prompt Augmentation and Caption Utilization",
        "link": "/arxiv/2409.14484",
        "arxiv_id": "2409.14484",
        "authors": "Minyi Zhao, Jie Wang, Zhaoyang Li, Jiyuan Zhang, Zhenbang Sun, Shuigeng Zhou",
        "summary": "Recent studies have shown that Vision Language Large Models (VLLMs) may output content not relevant to the input images. This problem, called the hallucination phenomenon, undoubtedly degrades VLLM performance. Therefore, various anti-hallucination techniques have been proposed to make model output more reasonable and accurate. Despite their successes, from extensive tests we found that augmenting the prompt (e.g. word appending, rewriting, and spell error etc.) may change model output and make the output hallucinate again. To cure this drawback, we propose a new instruct-tuning framework called Prompt Augmentation and Caption Utilization (PACU) to boost VLLM's generation ability under the augmented prompt scenario. Concretely, on the one hand, PACU exploits existing LLMs to augment and evaluate diverse prompts automatically. The resulting high-quality prompts are utilized to enhance VLLM's ability to process different prompts. On the other hand, PACU exploits image captions to jointly work with image features as well as the prompts for response generation. When the visual feature is inaccurate, LLM can capture useful information from the image captions for response generation. Extensive experiments on hallucination evaluation and prompt-augmented datasets demonstrate that our PACU method can work well with existing schemes to effectively boost VLLM model performance. Code is available in https://github.com/zhaominyiz/PACU.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 15:07:18 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.012322"
    },
    {
        "index": "#75",
        "title": "One Model for Two Tasks: Cooperatively Recognizing and Recovering Low-Resolution Scene Text Images by Iterative Mutual Guidance",
        "link": "/arxiv/2409.14483",
        "arxiv_id": "2409.14483",
        "authors": "Minyi Zhao, Yang Wang, Jihong Guan, Shuigeng Zhou",
        "summary": "Scene text recognition (STR) from high-resolution (HR) images has been significantly successful, however text reading on low-resolution (LR) images is still challenging due to insufficient visual information. Therefore, recently many scene text image super-resolution (STISR) models have been proposed to generate super-resolution (SR) images for the LR ones, then STR is done on the SR images, which thus boosts recognition performance. Nevertheless, these methods have two major weaknesses. On the one hand, STISR approaches may generate imperfect or even erroneous SR images, which mislead the subsequent recognition of STR models. On the other hand, as the STISR and STR models are jointly optimized, to pursue high recognition accuracy, the fidelity of SR images may be spoiled. As a result, neither the recognition performance nor the fidelity of STISR models are desirable. Then, can we achieve both high recognition performance and good fidelity? To this end, in this paper we propose a novel method called IMAGE (the abbreviation of Iterative MutuAl GuidancE) to effectively recognize and recover LR scene text images simultaneously. Concretely, IMAGE consists of a specialized STR model for recognition and a tailored STISR model to recover LR images, which are optimized separately. And we develop an iterative mutual guidance mechanism, with which the STR model provides high-level semantic information as clue to the STISR model for better super-resolution, meanwhile the STISR model offers essential low-level pixel clue to the STR model for more accurate recognition. Extensive experiments on two LR datasets demonstrate the superiority of our method over the existing works on both recognition performance and super-resolution fidelity.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 15:05:25 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.012500"
    },
    {
        "index": "#76",
        "title": "SynBench: A Synthetic Benchmark for Non-rigid 3D Point Cloud Registration",
        "link": "/arxiv/2409.14474",
        "arxiv_id": "2409.14474",
        "authors": "Sara Monji-Azad, Marvin Kinz, Claudia Scherl, David Männle, Jürgen Hesser, Nikolas Löw",
        "summary": "Non-rigid point cloud registration is a crucial task in computer vision. Evaluating a non-rigid point cloud registration method requires a dataset with challenges such as large deformation levels, noise, outliers, and incompleteness. Despite the existence of several datasets for deformable point cloud registration, the absence of a comprehensive benchmark with all challenges makes it difficult to achieve fair evaluations among different methods. This paper introduces SynBench, a new non-rigid point cloud registration dataset created using SimTool, a toolset for soft body simulation in Flex and Unreal Engine. SynBench provides the ground truth of corresponding points between two point sets and encompasses key registration challenges, including varying levels of deformation, noise, outliers, and incompleteness. To the best of the authors' knowledge, compared to existing datasets, SynBench possesses three particular characteristics: (1) it is the first benchmark that provides various challenges for non-rigid point cloud registration, (2) SynBench encompasses challenges of varying difficulty levels, and (3) it includes ground truth corresponding points both before and after deformation. The authors believe that SynBench enables future non-rigid point cloud registration methods to present a fair comparison of their achievements. SynBench is publicly available at: https://doi.org/10.11588/data/R9IKCF.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Graphics, Machine Learning",
        "date": "2024-09-22 14:46:20 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.012780"
    },
    {
        "index": "#77",
        "title": "Low-Light Enhancement Effect on Classification and Detection: An Empirical Study",
        "link": "/arxiv/2409.14461",
        "arxiv_id": "2409.14461",
        "authors": "Xu Wu, Zhihui Lai, Zhou Jie, Can Gao, Xianxu Hou, Ya-nan Zhang, Linlin Shen",
        "summary": "Low-light images are commonly encountered in real-world scenarios, and numerous low-light image enhancement (LLIE) methods have been proposed to improve the visibility of these images. The primary goal of LLIE is to generate clearer images that are more visually pleasing to humans. However, the impact of LLIE methods in high-level vision tasks, such as image classification and object detection, which rely on high-quality image datasets, is not well {explored}. To explore the impact, we comprehensively evaluate LLIE methods on these high-level vision tasks by utilizing an empirical investigation comprising image classification and object detection experiments. The evaluation reveals a dichotomy: {\\textit{While Low-Light Image Enhancement (LLIE) methods enhance human visual interpretation, their effect on computer vision tasks is inconsistent and can sometimes be harmful. }} Our findings suggest a disconnect between image enhancement for human visual perception and for machine analysis, indicating a need for LLIE methods tailored to support high-level vision tasks effectively. This insight is crucial for the development of LLIE techniques that align with the needs of both human and machine vision.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 14:21:31 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.012986"
    },
    {
        "index": "#78",
        "title": "Fake It till You Make It: Curricular Dynamic Forgery Augmentations towards General Deepfake Detection",
        "link": "/arxiv/2409.14444",
        "arxiv_id": "2409.14444",
        "authors": "Yuzhen Lin, Wentang Song, Bin Li, Yuezun Li, Jiangqun Ni, Han Chen, Qiushi Li",
        "summary": "Previous studies in deepfake detection have shown promising results when testing face forgeries from the same dataset as the training. However, the problem remains challenging when one tries to generalize the detector to forgeries from unseen datasets and created by unseen methods. In this work, we present a novel general deepfake detection method, called \\textbf{C}urricular \\textbf{D}ynamic \\textbf{F}orgery \\textbf{A}ugmentation (CDFA), which jointly trains a deepfake detector with a forgery augmentation policy network. Unlike the previous works, we propose to progressively apply forgery augmentations following a monotonic curriculum during the training. We further propose a dynamic forgery searching strategy to select one suitable forgery augmentation operation for each image varying between training stages, producing a forgery augmentation policy optimized for better generalization. In addition, we propose a novel forgery augmentation named self-shifted blending image to simply imitate the temporal inconsistency of deepfake generation. Comprehensive experiments show that CDFA can significantly improve both cross-datasets and cross-manipulations performances of various naive deepfake detectors in a plug-and-play way, and make them attain superior performances over the existing methods in several benchmark datasets.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 13:51:22 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.013191"
    },
    {
        "index": "#79",
        "title": "EM-DARTS: Hierarchical Differentiable Architecture Search for Eye Movement Recognition",
        "link": "/arxiv/2409.14432",
        "arxiv_id": "2409.14432",
        "authors": "Huafeng Qin, Hongyu Zhu, Xin Jin, Xin Yu, Mounim A. El-Yacoubi, Xinbo Gao",
        "summary": "Eye movement biometrics has received increasing attention thanks to its high secure identification. Although deep learning (DL) models have been recently successfully applied for eye movement recognition, the DL architecture still is determined by human prior knowledge. Differentiable Neural Architecture Search (DARTS) automates the manual process of architecture design with high search efficiency. DARTS, however, usually stacks the same multiple learned cells to form a final neural network for evaluation, limiting therefore the diversity of the network. Incidentally, DARTS usually searches the architecture in a shallow network while evaluating it in a deeper one, which results in a large gap between the architecture depths in the search and evaluation scenarios. To address this issue, we propose EM-DARTS, a hierarchical differentiable architecture search algorithm to automatically design the DL architecture for eye movement recognition. First, we define a supernet and propose a global and local alternate Neural Architecture Search method to search the optimal architecture alternately with an differentiable neural architecture search. The local search strategy aims to find an optimal architecture for different cells while the global search strategy is responsible for optimizing the architecture of the target network. To further reduce redundancy, a transfer entropy is proposed to compute the information amount of each layer, so as to further simplify search network. Our experiments on three public databases demonstrate that the proposed EM-DARTS is capable of producing an optimal architecture that leads to state-of-the-art recognition performance.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 13:11:08 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.013432"
    },
    {
        "index": "#80",
        "title": "Pomo3D: 3D-Aware Portrait Accessorizing and More",
        "link": "/arxiv/2409.14430",
        "arxiv_id": "2409.14430",
        "authors": "Tzu-Chieh Liu, Chih-Ting Liu, Shao-Yi Chien",
        "summary": "We propose Pomo3D, a 3D portrait manipulation framework that allows free accessorizing by decomposing and recomposing portraits and accessories. It enables the avatars to attain out-of-distribution (OOD) appearances of simultaneously wearing multiple accessories. Existing methods still struggle to offer such explicit and fine-grained editing; they either fail to generate additional objects on given portraits or cause alterations to portraits (e.g., identity shift) when generating accessories. This restriction presents a noteworthy obstacle as people typically seek to create charming appearances with diverse and fashionable accessories in the virtual universe. Our approach provides an effective solution to this less-addressed issue. We further introduce the Scribble2Accessories module, enabling Pomo3D to create 3D accessories from user-drawn accessory scribble maps. Moreover, we design a bias-conscious mapper to mitigate biased associations present in real-world datasets. In addition to object-level manipulation above, Pomo3D also offers extensive editing options on portraits, including global or local editing of geometry and texture and avatar stylization, elevating 3D editing of neural portraits to a more comprehensive level.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-22 13:03:24 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.013642"
    },
    {
        "index": "#81",
        "title": "Prior Knowledge Distillation Network for Face Super-Resolution",
        "link": "/arxiv/2409.14385",
        "arxiv_id": "2409.14385",
        "authors": "Qiu Yang, Xiao Sun, Xin-yu Li, Feng-Qi Cui, Yu-Tong Guo, Shuang-Zhen Hu, Ping Luo, Si-Ying Li",
        "summary": "The purpose of face super-resolution (FSR) is to reconstruct high-resolution (HR) face images from low-resolution (LR) inputs. With the continuous advancement of deep learning technologies, contemporary prior-guided FSR methods initially estimate facial priors and then use this information to assist in the super-resolution reconstruction process. However, ensuring the accuracy of prior estimation remains challenging, and straightforward cascading and convolutional operations often fail to fully leverage prior knowledge. Inaccurate or insufficiently utilized prior information inevitably degrades FSR performance. To address this issue, we propose a prior knowledge distillation network (PKDN) for FSR, which involves transferring prior information from the teacher network to the student network. This approach enables the network to learn priors during the training stage while relying solely on low-resolution facial images during the testing stage, thus mitigating the adverse effects of prior estimation inaccuracies. Additionally, we incorporate robust attention mechanisms to design a parsing map fusion block that effectively utilizes prior information. To prevent feature loss, we retain multi-scale features during the feature extraction stage and employ them in the subsequent super-resolution reconstruction process. Experimental results on benchmark datasets demonstrate that our PKDN approach surpasses existing FSR methods in generating high-quality face images.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 09:58:20 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.013907"
    },
    {
        "index": "#82",
        "title": "GroupDiff: Diffusion-based Group Portrait Editing",
        "link": "/arxiv/2409.14379",
        "arxiv_id": "2409.14379",
        "authors": "Yuming Jiang, Nanxuan Zhao, Qing Liu, Krishna Kumar Singh, Shuai Yang, Chen Change Loy, Ziwei Liu",
        "summary": "Group portrait editing is highly desirable since users constantly want to add a person, delete a person, or manipulate existing persons. It is also challenging due to the intricate dynamics of human interactions and the diverse gestures. In this work, we present GroupDiff, a pioneering effort to tackle group photo editing with three dedicated contributions: 1) Data Engine: Since there is no labeled data for group photo editing, we create a data engine to generate paired data for training. The training data engine covers the diverse needs of group portrait editing. 2) Appearance Preservation: To keep the appearance consistent after editing, we inject the images of persons from the group photo into the attention modules and employ skeletons to provide intra-person guidance. 3) Control Flexibility: Bounding boxes indicating the locations of each person are used to reweight the attention matrix so that the features of each person can be injected into the correct places. This inter-person guidance provides flexible manners for manipulation. Extensive experiments demonstrate that GroupDiff exhibits state-of-the-art performance compared to existing methods. GroupDiff offers controllability for editing and maintains the fidelity of the original photos.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 09:50:28 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.014169"
    },
    {
        "index": "#83",
        "title": "Memory Matching is not Enough: Jointly Improving Memory Matching and Decoding for Video Object Segmentation",
        "link": "/arxiv/2409.14343",
        "arxiv_id": "2409.14343",
        "authors": "Jintu Zheng, Yun Liang, Yuqing Zhang, Wanchao Su",
        "summary": "Memory-based video object segmentation methods model multiple objects over long temporal-spatial spans by establishing memory bank, which achieve the remarkable performance. However, they struggle to overcome the false matching and are prone to lose critical information, resulting in confusion among different objects. In this paper, we propose an effective approach which jointly improving the matching and decoding stages to alleviate the false matching issue.For the memory matching stage, we present a cost aware mechanism that suppresses the slight errors for short-term memory and a shunted cross-scale matching for long-term memory which establish a wide filed matching spaces for various object scales. For the readout decoding stage, we implement a compensatory mechanism aims at recovering the essential information where missing at the matching stage. Our approach achieves the outstanding performance in several popular benchmarks (i.e., DAVIS 2016&2017 Val (92.4%&88.1%), and DAVIS 2017 Test (83.9%)), and achieves 84.8%&84.6% on YouTubeVOS 2018&2019 Val.",
        "subjects": "Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2024-09-22 07:08:59 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.014364"
    },
    {
        "index": "#84",
        "title": "Self-Supervised Audio-Visual Soundscape Stylization",
        "link": "/arxiv/2409.14340",
        "arxiv_id": "2409.14340",
        "authors": "Tingle Li, Renhao Wang, Po-Yao Huang, Andrew Owens, Gopala Anumanchipalli",
        "summary": "Speech sounds convey a great deal of information about the scenes, resulting in a variety of effects ranging from reverberation to additional ambient sounds. In this paper, we manipulate input speech to sound as though it was recorded within a different scene, given an audio-visual conditional example recorded from that scene. Our model learns through self-supervision, taking advantage of the fact that natural video contains recurring sound events and textures. We extract an audio clip from a video and apply speech enhancement. We then train a latent diffusion model to recover the original speech, using another audio-visual clip taken from elsewhere in the video as a conditional hint. Through this process, the model learns to transfer the conditional example's sound properties to the input speech. We show that our model can be successfully trained using unlabeled, in-the-wild videos, and that an additional visual signal can improve its sound prediction abilities. Please see our project webpage for video results: https://tinglok.netlify.app/files/avsoundscape/",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning, Multimedia, Sound, Audio and Speech Processing",
        "date": "2024-09-22 06:57:33 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.014624"
    },
    {
        "index": "#85",
        "title": "Zero-Shot Skeleton-based Action Recognition with Dual Visual-Text Alignment",
        "link": "/arxiv/2409.14336",
        "arxiv_id": "2409.14336",
        "authors": "Jidong Kuang, Hongsong Wang, Chaolei Han, Jie Gui",
        "summary": "Zero-shot action recognition, which addresses the issue of scalability and generalization in action recognition and allows the models to adapt to new and unseen actions dynamically, is an important research topic in computer vision communities. The key to zero-shot action recognition lies in aligning visual features with semantic vectors representing action categories. Most existing methods either directly project visual features onto the semantic space of text category or learn a shared embedding space between the two modalities. However, a direct projection cannot accurately align the two modalities, and learning robust and discriminative embedding space between visual and text representations is often difficult. To address these issues, we introduce Dual Visual-Text Alignment (DVTA) for skeleton-based zero-shot action recognition. The DVTA consists of two alignment modules-Direct Alignment (DA) and Augmented Alignment (AA)-along with a designed Semantic Description Enhancement (SDE). The DA module maps the skeleton features to the semantic space through a specially designed visual projector, followed by the SDE, which is based on cross-attention to enhance the connection between skeleton and text, thereby reducing the gap between modalities. The AA module further strengthens the learning of the embedding space by utilizing deep metric learning to learn the similarity between skeleton and text. Our approach achieves state-of-the-art performances on several popular zero-shot skeleton-based action recognition benchmarks.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 06:44:58 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.014847"
    },
    {
        "index": "#86",
        "title": "PISR: Polarimetric Neural Implicit Surface Reconstruction for Textureless and Specular Objects",
        "link": "/arxiv/2409.14331",
        "arxiv_id": "2409.14331",
        "authors": "Guangcheng Chen, Yicheng He, Li He, Hong Zhang",
        "summary": "Neural implicit surface reconstruction has achieved remarkable progress recently. Despite resorting to complex radiance modeling, state-of-the-art methods still struggle with textureless and specular surfaces. Different from RGB images, polarization images can provide direct constraints on the azimuth angles of the surface normals. In this paper, we present PISR, a novel method that utilizes a geometrically accurate polarimetric loss to refine shape independently of appearance. In addition, PISR smooths surface normals in image space to eliminate severe shape distortions and leverages the hash-grid-based neural signed distance function to accelerate the reconstruction. Experimental results demonstrate that PISR achieves higher accuracy and robustness, with an L1 Chamfer distance of 0.5 mm and an F-score of 99.5% at 1 mm, while converging 4~30 times faster than previous polarimetric surface reconstruction methods.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 06:31:11 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.015034"
    },
    {
        "index": "#87",
        "title": "Scene-Text Grounding for Text-Based Video Question Answering",
        "link": "/arxiv/2409.14319",
        "arxiv_id": "2409.14319",
        "authors": "Sheng Zhou, Junbin Xiao, Xun Yang, Peipei Song, Dan Guo, Angela Yao, Meng Wang, Tat-Seng Chua",
        "summary": "Existing efforts in text-based video question answering (TextVideoQA) are criticized for their opaque decisionmaking and heavy reliance on scene-text recognition. In this paper, we propose to study Grounded TextVideoQA by forcing models to answer questions and spatio-temporally localize the relevant scene-text regions, thus decoupling QA from scenetext recognition and promoting research towards interpretable QA. The task has three-fold significance. First, it encourages scene-text evidence versus other short-cuts for answer predictions. Second, it directly accepts scene-text regions as visual answers, thus circumventing the problem of ineffective answer evaluation by stringent string matching. Third, it isolates the challenges inherited in VideoQA and scene-text recognition. This enables the diagnosis of the root causes for failure predictions, e.g., wrong QA or wrong scene-text recognition? To achieve Grounded TextVideoQA, we propose the T2S-QA model that highlights a disentangled temporal-to-spatial contrastive learning strategy for weakly-supervised scene-text grounding and grounded TextVideoQA. To facilitate evaluation, we construct a new dataset ViTXT-GQA which features 52K scene-text bounding boxes within 2.2K temporal segments related to 2K questions and 729 videos. With ViTXT-GQA, we perform extensive experiments and demonstrate the severe limitations of existing techniques in Grounded TextVideoQA. While T2S-QA achieves superior results, the large performance gap with human leaves ample space for improvement. Our further analysis of oracle scene-text inputs posits that the major challenge is scene-text recognition. To advance the research of Grounded TextVideoQA, our dataset and code are at \\url{https://github.com/zhousheng97/ViTXT-GQA.git}",
        "subjects": "Computer Vision and Pattern Recognition, Multimedia",
        "date": "2024-09-22 05:13:11 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.015257"
    },
    {
        "index": "#88",
        "title": "MVPGS: Excavating Multi-view Priors for Gaussian Splatting from Sparse Input Views",
        "link": "/arxiv/2409.14316",
        "arxiv_id": "2409.14316",
        "authors": "Wangze Xu, Huachen Gao, Shihe Shen, Rui Peng, Jianbo Jiao, Ronggang Wang",
        "summary": "Recently, the Neural Radiance Field (NeRF) advancement has facilitated few-shot Novel View Synthesis (NVS), which is a significant challenge in 3D vision applications. Despite numerous attempts to reduce the dense input requirement in NeRF, it still suffers from time-consumed training and rendering processes. More recently, 3D Gaussian Splatting (3DGS) achieves real-time high-quality rendering with an explicit point-based representation. However, similar to NeRF, it tends to overfit the train views for lack of constraints. In this paper, we propose \\textbf{MVPGS}, a few-shot NVS method that excavates the multi-view priors based on 3D Gaussian Splatting. We leverage the recent learning-based Multi-view Stereo (MVS) to enhance the quality of geometric initialization for 3DGS. To mitigate overfitting, we propose a forward-warping method for additional appearance constraints conforming to scenes based on the computed geometry. Furthermore, we introduce a view-consistent geometry constraint for Gaussian parameters to facilitate proper optimization convergence and utilize a monocular depth regularization as compensation. Experiments show that the proposed method achieves state-of-the-art performance with real-time rendering speed. Project page: https://zezeaaa.github.io/projects/MVPGS/",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 05:07:20 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.015476"
    },
    {
        "index": "#89",
        "title": "Anisotropic Diffusion Probabilistic Model for Imbalanced Image Classification",
        "link": "/arxiv/2409.14313",
        "arxiv_id": "2409.14313",
        "authors": "Jingyu Kong, Yuan Guo, Yu Wang, Yuping Duan",
        "summary": "Real-world data often has a long-tailed distribution, where the scarcity of tail samples significantly limits the model's generalization ability. Denoising Diffusion Probabilistic Models (DDPM) are generative models based on stochastic differential equation theory and have demonstrated impressive performance in image classification tasks. However, existing diffusion probabilistic models do not perform satisfactorily in classifying tail classes. In this work, we propose the Anisotropic Diffusion Probabilistic Model (ADPM) for imbalanced image classification problems. We utilize the data distribution to control the diffusion speed of different class samples during the forward process, effectively improving the classification accuracy of the denoiser in the reverse process. Specifically, we provide a theoretical strategy for selecting noise levels for different categories in the diffusion process based on error analysis theory to address the imbalanced classification problem. Furthermore, we integrate global and local image prior in the forward process to enhance the model's discriminative ability in the spatial dimension, while incorporate semantic-level contextual information in the reverse process to boost the model's discriminative power and robustness. Through comparisons with state-of-the-art methods on four medical benchmark datasets, we validate the effectiveness of the proposed method in handling long-tail data. Our results confirm that the anisotropic diffusion model significantly improves the classification accuracy of rare classes while maintaining the accuracy of head classes. On the skin lesion datasets, PAD-UFES and HAM10000, the F1-scores of our method improved by 4% and 3%, respectively compared to the original diffusion probabilistic model.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 04:42:52 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.015718"
    },
    {
        "index": "#90",
        "title": "DilateQuant: Accurate and Efficient Diffusion Quantization via Weight Dilation",
        "link": "/arxiv/2409.14307",
        "arxiv_id": "2409.14307",
        "authors": "Xuewen Liu, Zhikai Li, Qingyi Gu",
        "summary": "Diffusion models have shown excellent performance on various image generation tasks, but the substantial computational costs and huge memory footprint hinder their low-latency applications in real-world scenarios. Quantization is a promising way to compress and accelerate models. Nevertheless, due to the wide range and time-varying activations in diffusion models, existing methods cannot maintain both accuracy and efficiency simultaneously for low-bit quantization. To tackle this issue, we propose DilateQuant, a novel quantization framework for diffusion models that offers comparable accuracy and high efficiency. Specifically, we keenly aware of numerous unsaturated in-channel weights, which can be cleverly exploited to reduce the range of activations without additional computation cost. Based on this insight, we propose Weight Dilation (WD) that maximally dilates the unsaturated in-channel weights to a constrained range through a mathematically equivalent scaling. WD costlessly absorbs the activation quantization errors into weight quantization. The range of activations decreases, which makes activations quantization easy. The range of weights remains constant, which makes model easy to converge in training stage. Considering the temporal network leads to time-varying activations, we design a Temporal Parallel Quantizer (TPQ), which sets time-step quantization parameters and supports parallel quantization for different time steps, significantly improving the performance and reducing time cost. To further enhance performance while preserving efficiency, we introduce a Block-wise Knowledge Distillation (BKD) to align the quantized models with the full-precision models at a block level. The simultaneous training of time-step quantization parameters and weights minimizes the time required, and the shorter backpropagation paths decreases the memory footprint of the quantization process.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-22 04:21:29 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.015934"
    },
    {
        "index": "#91",
        "title": "Deep Learning Technology for Face Forgery Detection: A Survey",
        "link": "/arxiv/2409.14289",
        "arxiv_id": "2409.14289",
        "authors": "Lixia Ma, Puning Yang, Yuting Xu, Ziming Yang, Peipei Li, Huaibo Huang",
        "summary": "Currently, the rapid development of computer vision and deep learning has enabled the creation or manipulation of high-fidelity facial images and videos via deep generative approaches. This technology, also known as deepfake, has achieved dramatic progress and become increasingly popular in social media. However, the technology can generate threats to personal privacy and national security by spreading misinformation. To diminish the risks of deepfake, it is desirable to develop powerful forgery detection methods to distinguish fake faces from real faces. This paper presents a comprehensive survey of recent deep learning-based approaches for facial forgery detection. We attempt to provide the reader with a deeper understanding of the current advances as well as the major challenges for deepfake detection based on deep learning. We present an overview of deepfake techniques and analyse the characteristics of various deepfake datasets. We then provide a systematic review of different categories of deepfake detection and state-of-the-art deepfake detection methods. The drawbacks of existing detection methods are analyzed, and future research directions are discussed to address the challenges in improving both the performance and generalization of deepfake detection.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 01:42:01 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.021369"
    },
    {
        "index": "#92",
        "title": "Lidar Panoptic Segmentation in an Open World",
        "link": "/arxiv/2409.14273",
        "arxiv_id": "2409.14273",
        "authors": "Anirudh S Chakravarthy, Meghana Reddy Ganesina, Peiyun Hu, Laura Leal-Taixe, Shu Kong, Deva Ramanan, Aljosa Osep",
        "summary": "Addressing Lidar Panoptic Segmentation (LPS ) is crucial for safe deployment of autonomous vehicles. LPS aims to recognize and segment lidar points w.r.t. a pre-defined vocabulary of semantic classes, including thing classes of countable objects (e.g., pedestrians and vehicles) and stuff classes of amorphous regions (e.g., vegetation and road). Importantly, LPS requires segmenting individual thing instances (e.g., every single vehicle). Current LPS methods make an unrealistic assumption that the semantic class vocabulary is fixed in the real open world, but in fact, class ontologies usually evolve over time as robots encounter instances of novel classes that are considered to be unknowns w.r.t. the pre-defined class vocabulary. To address this unrealistic assumption, we study LPS in the Open World (LiPSOW): we train models on a dataset with a pre-defined semantic class vocabulary and study their generalization to a larger dataset where novel instances of thing and stuff classes can appear. This experimental setting leads to interesting conclusions. While prior art train class-specific instance segmentation methods and obtain state-of-the-art results on known classes, methods based on class-agnostic bottom-up grouping perform favorably on classes outside of the initial class vocabulary (i.e., unknown classes). Unfortunately, these methods do not perform on-par with fully data-driven methods on known classes. Our work suggests a middle ground: we perform class-agnostic point clustering and over-segment the input cloud in a hierarchical fashion, followed by binary point segment classification, akin to Region Proposal Network [1]. We obtain the final point cloud segmentation by computing a cut in the weighted hierarchical tree of point segments, independently of semantic classification. Remarkably, this unified approach leads to strong performance on both known and unknown classes.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-22 00:10:20 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.021629"
    },
    {
        "index": "#93",
        "title": "Combining Absolute and Semi-Generalized Relative Poses for Visual Localization",
        "link": "/arxiv/2409.14269",
        "arxiv_id": "2409.14269",
        "authors": "Vojtech Panek, Torsten Sattler, Zuzana Kukelova",
        "summary": "Visual localization is the problem of estimating the camera pose of a given query image within a known scene. Most state-of-the-art localization approaches follow the structure-based paradigm and use 2D-3D matches between pixels in a query image and 3D points in the scene for pose estimation. These approaches assume an accurate 3D model of the scene, which might not always be available, especially if only a few images are available to compute the scene representation. In contrast, structure-less methods rely on 2D-2D matches and do not require any 3D scene model. However, they are also less accurate than structure-based methods. Although one prior work proposed to combine structure-based and structure-less pose estimation strategies, its practical relevance has not been shown. We analyze combining structure-based and structure-less strategies while exploring how to select between poses obtained from 2D-2D and 2D-3D matches, respectively. We show that combining both strategies improves localization performance in multiple practically relevant scenarios.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 23:55:42 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.021825"
    },
    {
        "index": "#94",
        "title": "End to End Face Reconstruction via Differentiable PnP",
        "link": "/arxiv/2409.14249",
        "arxiv_id": "2409.14249",
        "authors": "Yiren Lu, Huawei Wei",
        "summary": "This is a challenge report of the ECCV 2022 WCPA Challenge, Face Reconstruction Track. Inside this report is a brief explanation of how we accomplish this challenge. We design a two-branch network to accomplish this task, whose roles are Face Reconstruction and Face Landmark Detection. The former outputs canonical 3D face coordinates. The latter outputs pixel coordinates, i.e. 2D mapping of 3D coordinates with head pose and perspective projection. In addition, we utilize a differentiable PnP (Perspective-n-Points) layer to finetune the outputs of the two branch. Our method achieves very competitive quantitative results on the MVP-Human dataset and wins a $3^{rd}$ prize in the challenge.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 21:30:24 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.021995"
    },
    {
        "index": "#95",
        "title": "Cloud Adversarial Example Generation for Remote Sensing Image Classification",
        "link": "/arxiv/2409.14240",
        "arxiv_id": "2409.14240",
        "authors": "Fei Ma, Yuqiang Feng, Fan Zhang, Yongsheng Zhou",
        "summary": "Most existing adversarial attack methods for remote sensing images merely add adversarial perturbations or patches, resulting in unnatural modifications. Clouds are common atmospheric effects in remote sensing images. Generating clouds on these images can produce adversarial examples better aligning with human perception. In this paper, we propose a Perlin noise based cloud generation attack method. Common Perlin noise based cloud generation is a random, non-optimizable process, which cannot be directly used to attack the target models. We design a Perlin Gradient Generator Network (PGGN), which takes a gradient parameter vector as input and outputs the grids of Perlin noise gradient vectors at different scales. After a series of computations based on the gradient vectors, cloud masks at corresponding scales can be produced. These cloud masks are then weighted and summed depending on a mixing coefficient vector and a scaling factor to produce the final cloud masks. The gradient vector, coefficient vector and scaling factor are collectively represented as a cloud parameter vector, transforming the cloud generation into a black-box optimization problem. The Differential Evolution (DE) algorithm is employed to solve for the optimal solution of the cloud parameter vector, achieving a query-based black-box attack. Detailed experiments confirm that this method has strong attack capabilities and achieves high query efficiency. Additionally, we analyze the transferability of the generated adversarial examples and their robustness in adversarial defense scenarios.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 20:15:22 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.022181"
    },
    {
        "index": "#96",
        "title": "Masks and Boxes: Combining the Best of Both Worlds for Multi-Object Tracking",
        "link": "/arxiv/2409.14220",
        "arxiv_id": "2409.14220",
        "authors": "Tomasz Stanczyk, Francois Bremond",
        "summary": "Multi-object tracking (MOT) involves identifying and consistently tracking objects across video sequences. Traditional tracking-by-detection methods, while effective, often require extensive tuning and lack generalizability. On the other hand, segmentation mask-based methods are more generic but struggle with tracking management, making them unsuitable for MOT. We propose a novel approach, McByte, which incorporates a temporally propagated segmentation mask as a strong association cue within a tracking-by-detection framework. By combining bounding box and mask information, McByte enhances robustness and generalizability without per-sequence tuning. Evaluated on four benchmark datasets - DanceTrack, MOT17, SoccerNet-tracking 2022, and KITTI-tracking - McByte demonstrates performance gain in all cases examined. At the same time, it outperforms existing mask-based methods. Implementation code will be provided upon acceptance.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 18:52:07 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.022350"
    },
    {
        "index": "#97",
        "title": "@Bench: Benchmarking Vision-Language Models for Human-centered Assistive Technology",
        "link": "/arxiv/2409.14215",
        "arxiv_id": "2409.14215",
        "authors": "Xin Jiang, Junwei Zheng, Ruiping Liu, Jiahang Li, Jiaming Zhang, Sven Matthiesen, Rainer Stiefelhagen",
        "summary": "As Vision-Language Models (VLMs) advance, human-centered Assistive Technologies (ATs) for helping People with Visual Impairments (PVIs) are evolving into generalists, capable of performing multiple tasks simultaneously. However, benchmarking VLMs for ATs remains under-explored. To bridge this gap, we first create a novel AT benchmark (@Bench). Guided by a pre-design user study with PVIs, our benchmark includes the five most crucial vision-language tasks: Panoptic Segmentation, Depth Estimation, Optical Character Recognition (OCR), Image Captioning, and Visual Question Answering (VQA). Besides, we propose a novel AT model (@Model) that addresses all tasks simultaneously and can be expanded to more assistive functions for helping PVIs. Our framework exhibits outstanding performance across tasks by integrating multi-modal information, and it offers PVIs a more comprehensive assistance. Extensive experiments prove the effectiveness and generalizability of our framework.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 18:30:17 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.022551"
    },
    {
        "index": "#98",
        "title": "Egocentric zone-aware action recognition across environments",
        "link": "/arxiv/2409.14205",
        "arxiv_id": "2409.14205",
        "authors": "Simone Alberto Peirone, Gabriele Goletto, Mirco Planamente, Andrea Bottino, Barbara Caputo, Giuseppe Averta",
        "summary": "Human activities exhibit a strong correlation between actions and the places where these are performed, such as washing something at a sink. More specifically, in daily living environments we may identify particular locations, hereinafter named activity-centric zones, which may afford a set of homogeneous actions. Their knowledge can serve as a prior to favor vision models to recognize human activities. However, the appearance of these zones is scene-specific, limiting the transferability of this prior information to unfamiliar areas and domains. This problem is particularly relevant in egocentric vision, where the environment takes up most of the image, making it even more difficult to separate the action from the context. In this paper, we discuss the importance of decoupling the domain-specific appearance of activity-centric zones from their universal, domain-agnostic representations, and show how the latter can improve the cross-domain transferability of Egocentric Action Recognition (EAR) models. We validate our solution on the EPIC-Kitchens-100 and Argo1M datasets",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 17:40:48 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.022744"
    },
    {
        "index": "#99",
        "title": "LATTE: Improving Latex Recognition for Tables and Formulae with Iterative Refinement",
        "link": "/arxiv/2409.14201",
        "arxiv_id": "2409.14201",
        "authors": "Nan Jiang, Shanchao Liang, Chengxiao Wang, Jiannan Wang, Lin Tan",
        "summary": "Portable Document Format (PDF) files are dominantly used for storing and disseminating scientific research, legal documents, and tax information. LaTeX is a popular application for creating PDF documents. Despite its advantages, LaTeX is not WYSWYG -- what you see is what you get, i.e., the LaTeX source and rendered PDF images look drastically different, especially for formulae and tables. This gap makes it hard to modify or export LaTeX sources for formulae and tables from PDF images, and existing work is still limited. First, prior work generates LaTeX sources in a single iteration and struggles with complex LaTeX formulae. Second, existing work mainly recognizes and extracts LaTeX sources for formulae; and is incapable or ineffective for tables. This paper proposes LATTE, the first iterative refinement framework for LaTeX recognition. Specifically, we propose delta-view as feedback, which compares and pinpoints the differences between a pair of rendered images of the extracted LaTeX source and the expected correct image. Such delta-view feedback enables our fault localization model to localize the faulty parts of the incorrect recognition more accurately and enables our LaTeX refinement model to repair the incorrect extraction more accurately. LATTE improves the LaTeX source extraction accuracy of both LaTeX formulae and tables, outperforming existing techniques as well as GPT-4V by at least 7.07% of exact match, with a success refinement rate of 46.08% (formula) and 25.51% (table).",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 17:18:49 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.022926"
    },
    {
        "index": "#100",
        "title": "Content-aware Tile Generation using Exterior Boundary Inpainting",
        "link": "/arxiv/2409.14184",
        "arxiv_id": "2409.14184",
        "authors": "Sam Sartor, Pieter Peers",
        "summary": "We present a novel and flexible learning-based method for generating tileable image sets. Our method goes beyond simple self-tiling, supporting sets of mutually tileable images that exhibit a high degree of diversity. To promote diversity we decouple structure from content by foregoing explicit copying of patches from an exemplar image. Instead we leverage the prior knowledge of natural images and textures embedded in large-scale pretrained diffusion models to guide tile generation constrained by exterior boundary conditions and a text prompt to specify the content. By carefully designing and selecting the exterior boundary conditions, we can reformulate the tile generation process as an inpainting problem, allowing us to directly employ existing diffusion-based inpainting models without the need to retrain a model on a custom training set. We demonstrate the flexibility and efficacy of our content-aware tile generation method on different tiling schemes, such as Wang tiles, from only a text prompt. Furthermore, we introduce a novel Dual Wang tiling scheme that provides greater texture continuity and diversity than existing Wang tile variants.",
        "subjects": "Computer Vision and Pattern Recognition, Graphics",
        "date": "2024-09-21 16:04:13 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.023132"
    },
    {
        "index": "#101",
        "title": "LFP: Efficient and Accurate End-to-End Lane-Level Planning via Camera-LiDAR Fusion",
        "link": "/arxiv/2409.14170",
        "arxiv_id": "2409.14170",
        "authors": "Guoliang You, Xiaomeng Chu, Yifan Duan, Xingchen Li, Sha Zhang, Jianmin Ji, Yanyong Zhang",
        "summary": "Multi-modal systems enhance performance in autonomous driving but face inefficiencies due to indiscriminate processing within each modality. Additionally, the independent feature learning of each modality lacks interaction, which results in extracted features that do not possess the complementary characteristics. These issue increases the cost of fusing redundant information across modalities. To address these challenges, we propose targeting driving-relevant elements, which reduces the volume of LiDAR features while preserving critical information. This approach enhances lane level interaction between the image and LiDAR branches, allowing for the extraction and fusion of their respective advantageous features. Building upon the camera-only framework PHP, we introduce the Lane-level camera-LiDAR Fusion Planning (LFP) method, which balances efficiency with performance by using lanes as the unit for sensor fusion. Specifically, we design three modules to enhance efficiency and performance. For efficiency, we propose an image-guided coarse lane prior generation module that forecasts the region of interest (ROI) for lanes and assigns a confidence score, guiding LiDAR processing. The LiDAR feature extraction modules leverages lane-aware priors from the image branch to guide sampling for pillar, retaining essential pillars. For performance, the lane-level cross-modal query integration and feature enhancement module uses confidence score from ROI to combine low-confidence image queries with LiDAR queries, extracting complementary depth features. These features enhance the low-confidence image features, compensating for the lack of depth. Experiments on the Carla benchmarks show that our method achieves state-of-the-art performance in both driving score and infraction score, with maximum improvement of 15% and 14% over existing algorithms, respectively, maintaining high frame rate of 19.27 FPS.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 15:22:01 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.023348"
    },
    {
        "index": "#102",
        "title": "PromptTA: Prompt-driven Text Adapter for Source-free Domain Generalization",
        "link": "/arxiv/2409.14163",
        "arxiv_id": "2409.14163",
        "authors": "Haoran Zhang, Shuanghao Bai, Wanqi Zhou, Jingwen Fu, Badong Chen",
        "summary": "Source-free domain generalization (SFDG) tackles the challenge of adapting models to unseen target domains without access to source domain data. To deal with this challenging task, recent advances in SFDG have primarily focused on leveraging the text modality of vision-language models such as CLIP. These methods involve developing a transferable linear classifier based on diverse style features extracted from the text and learned prompts or deriving domain-unified text representations from domain banks. However, both style features and domain banks have limitations in capturing comprehensive domain knowledge. In this work, we propose Prompt-Driven Text Adapter (PromptTA) method, which is designed to better capture the distribution of style features and employ resampling to ensure thorough coverage of domain knowledge. To further leverage this rich domain information, we introduce a text adapter that learns from these style features for efficient domain information storage. Extensive experiments conducted on four benchmark datasets demonstrate that PromptTA achieves state-of-the-art performance. The code is available at https://github.com/zhanghr2001/PromptTA.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language, Machine Learning",
        "date": "2024-09-21 15:02:13 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.023575"
    },
    {
        "index": "#103",
        "title": "MSSDA: Multi-Sub-Source Adaptation for Diabetic Foot Neuropathy Recognition",
        "link": "/arxiv/2409.14154",
        "arxiv_id": "2409.14154",
        "authors": "Yan Zhong, Zhixin Yan, Yi Xie, Shibin Wu, Huaidong Zhang, Lin Shu, Peiru Zhou",
        "summary": "Diabetic foot neuropathy (DFN) is a critical factor leading to diabetic foot ulcers, which is one of the most common and severe complications of diabetes mellitus (DM) and is associated with high risks of amputation and mortality. Despite its significance, existing datasets do not directly derive from plantar data and lack continuous, long-term foot-specific information. To advance DFN research, we have collected a novel dataset comprising continuous plantar pressure data to recognize diabetic foot neuropathy. This dataset includes data from 94 DM patients with DFN and 41 DM patients without DFN. Moreover, traditional methods divide datasets by individuals, potentially leading to significant domain discrepancies in some feature spaces due to the absence of mid-domain data. In this paper, we propose an effective domain adaptation method to address this proplem. We split the dataset based on convolutional feature statistics and select appropriate sub-source domains to enhance efficiency and avoid negative transfer. We then align the distributions of each source and target domain pair in specific feature spaces to minimize the domain gap. Comprehensive results validate the effectiveness of our method on both the newly proposed dataset for DFN recognition and an existing dataset.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-21 14:16:20 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.023904"
    },
    {
        "index": "#104",
        "title": "JVID: Joint Video-Image Diffusion for Visual-Quality and Temporal-Consistency in Video Generation",
        "link": "/arxiv/2409.14149",
        "arxiv_id": "2409.14149",
        "authors": "Hadrien Reynaud, Matthew Baugh, Mischa Dombrowski, Sarah Cechnicka, Qingjie Meng, Bernhard Kainz",
        "summary": "We introduce the Joint Video-Image Diffusion model (JVID), a novel approach to generating high-quality and temporally coherent videos. We achieve this by integrating two diffusion models: a Latent Image Diffusion Model (LIDM) trained on images and a Latent Video Diffusion Model (LVDM) trained on video data. Our method combines these models in the reverse diffusion process, where the LIDM enhances image quality and the LVDM ensures temporal consistency. This unique combination allows us to effectively handle the complex spatio-temporal dynamics in video generation. Our results demonstrate quantitative and qualitative improvements in producing realistic and coherent videos.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 13:59:50 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.024122"
    },
    {
        "index": "#105",
        "title": "A Feature Generator for Few-Shot Learning",
        "link": "/arxiv/2409.14141",
        "arxiv_id": "2409.14141",
        "authors": "Heethanjan Kanagalingam, Thenukan Pathmanathan, Navaneethan Ketheeswaran, Mokeeshan Vathanakumar, Mohamed Afham, Ranga Rodrigo",
        "summary": "Few-shot learning (FSL) aims to enable models to recognize novel objects or classes with limited labelled data. Feature generators, which synthesize new data points to augment limited datasets, have emerged as a promising solution to this challenge. This paper investigates the effectiveness of feature generators in enhancing the embedding process for FSL tasks. To address the issue of inaccurate embeddings due to the scarcity of images per class, we introduce a feature generator that creates visual features from class-level textual descriptions. By training the generator with a combination of classifier loss, discriminator loss, and distance loss between the generated features and true class embeddings, we ensure the generation of accurate same-class features and enhance the overall feature representation. Our results show a significant improvement in accuracy over baseline methods, with our approach outperforming the baseline model by 10% in 1-shot and around 5% in 5-shot approaches. Additionally, both visual-only and visual + textual generators have also been tested in this paper.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 13:31:12 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.024344"
    },
    {
        "index": "#106",
        "title": "Present and Future Generalization of Synthetic Image Detectors",
        "link": "/arxiv/2409.14128",
        "arxiv_id": "2409.14128",
        "authors": "Pablo Bernabeu-Perez, Enrique Lopez-Cuena, Dario Garcia-Gasulla",
        "summary": "The continued release of new and better image generation models increases the demand for synthetic image detectors. In such a dynamic field, detectors need to be able to generalize widely and be robust to uncontrolled alterations. The present work is motivated by this setting, when looking at the role of time, image transformations and data sources, for detector generalization. In these experiments, none of the evaluated detectors is found universal, but results indicate an ensemble could be. Experiments on data collected in the wild show this task to be more challenging than the one defined by large-scale datasets, pointing to a gap between experimentation and actual practice. Finally, we observe a race equilibrium effect, where better generators lead to better detectors, and vice versa. We hypothesize this pushes the field towards a perpetually close race between generators and detectors.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2024-09-21 12:46:17 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.024546"
    },
    {
        "index": "#107",
        "title": "Local Patterns Generalize Better for Novel Anomalies",
        "link": "/arxiv/2409.14109",
        "arxiv_id": "2409.14109",
        "authors": "Yalong Jiang, Liquan Mao",
        "summary": "Video anomaly detection (VAD) aims at identifying novel actions or events which are unseen during training. Existing mainstream VAD techniques focus on the global patterns of events and cannot properly generalize to novel samples. In this paper, we propose a framework to identify the spatial local patterns which generalize to novel samples and model the dynamics of local patterns. In spatial part of the framework, the capability of extracting local patterns is gained from image-text contrastive learning with Image-Text Alignment Module (ITAM). To detect different types of anomalies, a two-branch framework is proposed for representing the local patterns in both actions and appearances. In temporal part of the framework, a State Machine Module (SMM) is proposed to model the dynamics of local patterns by decomposing their temporal variations into motion components. Different dynamics are represented with different weighted sums of a fixed set of motion components. The video sequences with either novel spatial distributions of local patterns or distinctive dynamics of local patterns are deemed as anomalies. Extensive experiments on popular benchmark datasets demonstrate that state-of-the-art performance can be achieved.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 11:48:54 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.024718"
    },
    {
        "index": "#108",
        "title": "ExFMan: Rendering 3D Dynamic Humans with Hybrid Monocular Blurry Frames and Events",
        "link": "/arxiv/2409.14103",
        "arxiv_id": "2409.14103",
        "authors": "Kanghao Chen, Zeyu Wang, Lin Wang",
        "summary": "Recent years have witnessed tremendous progress in the 3D reconstruction of dynamic humans from a monocular video with the advent of neural rendering techniques. This task has a wide range of applications, including the creation of virtual characters for virtual reality (VR) environments. However, it is still challenging to reconstruct clear humans when the monocular video is affected by motion blur, particularly caused by rapid human motion (e.g., running, dancing), as often occurs in the wild. This leads to distinct inconsistency of shape and appearance for the rendered 3D humans, especially in the blurry regions with rapid motion, e.g., hands and legs. In this paper, we propose ExFMan, the first neural rendering framework that unveils the possibility of rendering high-quality humans in rapid motion with a hybrid frame-based RGB and bio-inspired event camera. The ``out-of-the-box'' insight is to leverage the high temporal information of event data in a complementary manner and adaptively reweight the effect of losses for both RGB frames and events in the local regions, according to the velocity of the rendered human. This significantly mitigates the inconsistency associated with motion blur in the RGB frames. Specifically, we first formulate a velocity field of the 3D body in the canonical space and render it to image space to identify the body parts with motion blur. We then propose two novel losses, i.e., velocity-aware photometric loss and velocity-relative event loss, to optimize the neural human for both modalities under the guidance of the estimated velocity. In addition, we incorporate novel pose regularization and alpha losses to facilitate continuous pose and clear boundary. Extensive experiments on synthetic and real-world datasets demonstrate that ExFMan can reconstruct sharper and higher quality humans.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 10:58:01 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.024898"
    },
    {
        "index": "#109",
        "title": "PoseAugment: Generative Human Pose Data Augmentation with Physical Plausibility for IMU-based Motion Capture",
        "link": "/arxiv/2409.14101",
        "arxiv_id": "2409.14101",
        "authors": "Zhuojun Li, Chun Yu, Chen Liang, Yuanchun Shi",
        "summary": "The data scarcity problem is a crucial factor that hampers the model performance of IMU-based human motion capture. However, effective data augmentation for IMU-based motion capture is challenging, since it has to capture the physical relations and constraints of the human body, while maintaining the data distribution and quality. We propose PoseAugment, a novel pipeline incorporating VAE-based pose generation and physical optimization. Given a pose sequence, the VAE module generates infinite poses with both high fidelity and diversity, while keeping the data distribution. The physical module optimizes poses to satisfy physical constraints with minimal motion restrictions. High-quality IMU data are then synthesized from the augmented poses for training motion capture models. Experiments show that PoseAugment outperforms previous data augmentation and pose generation methods in terms of motion capture accuracy, revealing a strong potential of our method to alleviate the data collection burden for IMU-based motion capture and related tasks driven by human poses.",
        "subjects": "Computer Vision and Pattern Recognition, Human-Computer Interaction",
        "date": "2024-09-21 10:51:16 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.025082"
    },
    {
        "index": "#110",
        "title": "Foundation Models for Amodal Video Instance Segmentation in Automated Driving",
        "link": "/arxiv/2409.14095",
        "arxiv_id": "2409.14095",
        "authors": "Jasmin Breitenstein, Franz Jünger, Andreas Bär, Tim Fingscheidt",
        "summary": "In this work, we study amodal video instance segmentation for automated driving. Previous works perform amodal video instance segmentation relying on methods trained on entirely labeled video data with techniques borrowed from standard video instance segmentation. Such amodally labeled video data is difficult and expensive to obtain and the resulting methods suffer from a trade-off between instance segmentation and tracking performance. To largely solve this issue, we propose to study the application of foundation models for this task. More precisely, we exploit the extensive knowledge of the Segment Anything Model (SAM), while fine-tuning it to the amodal instance segmentation task. Given an initial video instance segmentation, we sample points from the visible masks to prompt our amodal SAM. We use a point memory to store those points. If a previously observed instance is not predicted in a following frame, we retrieve its most recent points from the point memory and use a point tracking method to follow those points to the current frame, together with the corresponding last amodal instance mask. This way, while basing our method on an amodal instance segmentation, we nevertheless obtain video-level amodal instance segmentation results. Our resulting S-AModal method achieves state-of-the-art results in amodal video instance segmentation while resolving the need for amodal video-based labels. Code for S-AModal is available at https://github.com/ifnspaml/S-AModal.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 10:31:46 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.025336"
    },
    {
        "index": "#111",
        "title": "BRep Boundary and Junction Detection for CAD Reverse Engineering",
        "link": "/arxiv/2409.14087",
        "arxiv_id": "2409.14087",
        "authors": "Sk Aziz Ali, Mohammad Sadil Khan, Didier Stricker",
        "summary": "In machining process, 3D reverse engineering of the mechanical system is an integral, highly important, and yet time consuming step to obtain parametric CAD models from 3D scans. Therefore, deep learning-based Scan-to-CAD modeling can offer designers enormous editability to quickly modify CAD model, being able to parse all its structural compositions and design steps. In this paper, we propose a supervised boundary representation (BRep) detection network BRepDetNet from 3D scans of CC3D and ABC dataset. We have carefully annotated the 50K and 45K scans of both the datasets with appropriate topological relations (e.g., next, mate, previous) between the geometrical primitives (i.e., boundaries, junctions, loops, faces) of their BRep data structures. The proposed solution decomposes the Scan-to-CAD problem in Scan-to-BRep ensuring the right step towards feature-based modeling, and therefore, leveraging other existing BRep-to-CAD modeling methods. Our proposed Scan-to-BRep neural network learns to detect BRep boundaries and junctions by minimizing focal-loss and non-maximal suppression (NMS) during training time. Experimental results show that our BRepDetNet with NMS-Loss achieves impressive results.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning, Multimedia",
        "date": "2024-09-21 09:53:11 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.025562"
    },
    {
        "index": "#112",
        "title": "SURf: Teaching Large Vision-Language Models to Selectively Utilize Retrieved Information",
        "link": "/arxiv/2409.14083",
        "arxiv_id": "2409.14083",
        "authors": "Jiashuo Sun, Jihai Zhang, Yucheng Zhou, Zhaochen Su, Xiaoye Qu, Yu Cheng",
        "summary": "Large Vision-Language Models (LVLMs) have become pivotal at the intersection of computer vision and natural language processing. However, the full potential of LVLMs Retrieval-Augmented Generation (RAG) capabilities remains underutilized. Existing works either focus solely on the text modality or are limited to specific tasks. Moreover, most LVLMs struggle to selectively utilize retrieved information and are sensitive to irrelevant or misleading references. To address these challenges, we propose a self-refinement framework designed to teach LVLMs to Selectively Utilize Retrieved Information (SURf). Specifically, when given questions that are incorrectly answered by the LVLM backbone, we obtain references that help correct the answers (positive references) and those that do not (negative references). We then fine-tune the LVLM backbone using a combination of these positive and negative references. Our experiments across three tasks and seven datasets demonstrate that our framework significantly enhances LVLMs ability to effectively utilize retrieved multimodal references and improves their robustness against irrelevant or misleading information. The source code is available at https://github.com/GasolSun36/SURf.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 09:36:14 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.025793"
    },
    {
        "index": "#113",
        "title": "Dynamic 2D Gaussians: Geometrically accurate radiance fields for dynamic objects",
        "link": "/arxiv/2409.14072",
        "arxiv_id": "2409.14072",
        "authors": "Shuai Zhang, Guanjun Wu, Xinggang Wang, Bin Feng, Wenyu Liu",
        "summary": "Reconstructing objects and extracting high-quality surfaces play a vital role in the real world. Current 4D representations show the ability to render high-quality novel views for dynamic objects but cannot reconstruct high-quality meshes due to their implicit or geometrically inaccurate representations. In this paper, we propose a novel representation that can reconstruct accurate meshes from sparse image input, named Dynamic 2D Gaussians (D-2DGS). We adopt 2D Gaussians for basic geometry representation and use sparse-controlled points to capture 2D Gaussian's deformation. By extracting the object mask from the rendered high-quality image and masking the rendered depth map, a high-quality dynamic mesh sequence of the object can be extracted. Experiments demonstrate that our D-2DGS is outstanding in reconstructing high-quality meshes from sparse input. More demos and code are available at https://github.com/hustvl/Dynamic-2DGS.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 09:01:49 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.025985"
    },
    {
        "index": "#114",
        "title": "SplatLoc: 3D Gaussian Splatting-based Visual Localization for Augmented Reality",
        "link": "/arxiv/2409.14067",
        "arxiv_id": "2409.14067",
        "authors": "Hongjia Zhai, Xiyu Zhang, Boming Zhao, Hai Li, Yijia He, Zhaopeng Cui, Hujun Bao, Guofeng Zhang",
        "summary": "Visual localization plays an important role in the applications of Augmented Reality (AR), which enable AR devices to obtain their 6-DoF pose in the pre-build map in order to render virtual content in real scenes. However, most existing approaches can not perform novel view rendering and require large storage capacities for maps. To overcome these limitations, we propose an efficient visual localization method capable of high-quality rendering with fewer parameters. Specifically, our approach leverages 3D Gaussian primitives as the scene representation. To ensure precise 2D-3D correspondences for pose estimation, we develop an unbiased 3D scene-specific descriptor decoder for Gaussian primitives, distilled from a constructed feature volume. Additionally, we introduce a salient 3D landmark selection algorithm that selects a suitable primitive subset based on the saliency score for localization. We further regularize key Gaussian primitives to prevent anisotropic effects, which also improves localization performance. Extensive experiments on two widely used datasets demonstrate that our method achieves superior or comparable rendering and localization performance to state-of-the-art implicit-based visual localization approaches. Project page: \\href{https://zju3dv.github.io/splatloc}{https://zju3dv.github.io/splatloc}.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 08:46:16 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.036625"
    },
    {
        "index": "#115",
        "title": "Soft Segmented Randomization: Enhancing Domain Generalization in SAR-ATR for Synthetic-to-Measured",
        "link": "/arxiv/2409.14060",
        "arxiv_id": "2409.14060",
        "authors": "Minjun Kim, Ohtae Jang, Haekang Song, Heesub Shin, Jaewoo Ok, Minyoung Back, Jaehyuk Youn, Sungho Kim",
        "summary": "Synthetic aperture radar technology is crucial for high-resolution imaging under various conditions; however, the acquisition of real-world synthetic aperture radar data for deep learning-based automatic target recognition remains challenging due to high costs and data availability issues. To overcome these challenges, synthetic data generated through simulations have been employed, although discrepancies between synthetic and real data can degrade model performance. In this study, we introduce a novel framework, soft segmented randomization, designed to reduce domain discrepancy and improve the generalize ability of synthetic aperture radar automatic target recognition models. The soft segmented randomization framework applies a Gaussian mixture model to segment target and clutter regions softly, introducing randomized variations that align the synthetic data's statistical properties more closely with those of real-world data. Experimental results demonstrate that the proposed soft segmented randomization framework significantly enhances model performance on measured synthetic aperture radar data, making it a promising approach for robust automatic target recognition in scenarios with limited or no access to measured data.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 08:24:51 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.036948"
    },
    {
        "index": "#116",
        "title": "BrainDreamer: Reasoning-Coherent and Controllable Image Generation from EEG Brain Signals via Language Guidance",
        "link": "/arxiv/2409.14021",
        "arxiv_id": "2409.14021",
        "authors": "Ling Wang, Chen Wu, Lin Wang",
        "summary": "Can we directly visualize what we imagine in our brain together with what we describe? The inherent nature of human perception reveals that, when we think, our body can combine language description and build a vivid picture in our brain. Intuitively, generative models should also hold such versatility. In this paper, we introduce BrainDreamer, a novel end-to-end language-guided generative framework that can mimic human reasoning and generate high-quality images from electroencephalogram (EEG) brain signals. Our method is superior in its capacity to eliminate the noise introduced by non-invasive EEG data acquisition and meanwhile achieve a more precise mapping between the EEG and image modality, thus leading to significantly better-generated images. Specifically, BrainDreamer consists of two key learning stages: 1) modality alignment and 2) image generation. In the alignment stage, we propose a novel mask-based triple contrastive learning strategy to effectively align EEG, text, and image embeddings to learn a unified representation. In the generation stage, we inject the EEG embeddings into the pre-trained Stable Diffusion model by designing a learnable EEG adapter to generate high-quality reasoning-coherent images. Moreover, BrainDreamer can accept textual descriptions (e.g., color, position, etc.) to achieve controllable image generation. Extensive experiments show that our method significantly outperforms prior arts in terms of generating quality and quantitative performance.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-21 05:16:31 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.037150"
    },
    {
        "index": "#117",
        "title": "MOSE: Monocular Semantic Reconstruction Using NeRF-Lifted Noisy Priors",
        "link": "/arxiv/2409.14019",
        "arxiv_id": "2409.14019",
        "authors": "Zhenhua Du, Binbin Xu, Haoyu Zhang, Kai Huo, Shuaifeng Zhi",
        "summary": "Accurately reconstructing dense and semantically annotated 3D meshes from monocular images remains a challenging task due to the lack of geometry guidance and imperfect view-dependent 2D priors. Though we have witnessed recent advancements in implicit neural scene representations enabling precise 2D rendering simply from multi-view images, there have been few works addressing 3D scene understanding with monocular priors alone. In this paper, we propose MOSE, a neural field semantic reconstruction approach to lift inferred image-level noisy priors to 3D, producing accurate semantics and geometry in both 3D and 2D space. The key motivation for our method is to leverage generic class-agnostic segment masks as guidance to promote local consistency of rendered semantics during training. With the help of semantics, we further apply a smoothness regularization to texture-less regions for better geometric quality, thus achieving mutual benefits of geometry and semantics. Experiments on the ScanNet dataset show that our MOSE outperforms relevant baselines across all metrics on tasks of 3D semantic segmentation, 2D semantic segmentation and 3D surface reconstruction.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Robotics",
        "date": "2024-09-21 05:12:13 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.037368"
    },
    {
        "index": "#118",
        "title": "Generalizable Non-Line-of-Sight Imaging with Learnable Physical Priors",
        "link": "/arxiv/2409.14011",
        "arxiv_id": "2409.14011",
        "authors": "Shida Sun, Yue Li, Yueyi Zhang, Zhiwei Xiong",
        "summary": "Non-line-of-sight (NLOS) imaging, recovering the hidden volume from indirect reflections, has attracted increasing attention due to its potential applications. Despite promising results, existing NLOS reconstruction approaches are constrained by the reliance on empirical physical priors, e.g., single fixed path compensation. Moreover, these approaches still possess limited generalization ability, particularly when dealing with scenes at a low signal-to-noise ratio (SNR). To overcome the above problems, we introduce a novel learning-based solution, comprising two key designs: Learnable Path Compensation (LPC) and Adaptive Phasor Field (APF). The LPC applies tailored path compensation coefficients to adapt to different objects in the scene, effectively reducing light wave attenuation, especially in distant regions. Meanwhile, the APF learns the precise Gaussian window of the illumination function for the phasor field, dynamically selecting the relevant spectrum band of the transient measurement. Experimental validations demonstrate that our proposed approach, only trained on synthetic data, exhibits the capability to seamlessly generalize across various real-world datasets captured by different imaging systems and characterized by low SNRs.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 04:39:45 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.037553"
    },
    {
        "index": "#119",
        "title": "Multiple-Exit Tuning: Towards Inference-Efficient Adaptation for Vision Transformer",
        "link": "/arxiv/2409.13999",
        "arxiv_id": "2409.13999",
        "authors": "Zheng Liu, Jinchao Zhu, Nannan Li, Gao Huang",
        "summary": "Parameter-efficient transfer learning (PETL) has shown great potential in adapting a vision transformer (ViT) pre-trained on large-scale datasets to various downstream tasks. Existing studies primarily focus on minimizing the number of learnable parameters. Although these methods are storage-efficient, they allocate excessive computational resources to easy samples, leading to inefficient inference. To address this issue, we introduce an inference-efficient tuning method termed multiple-exit tuning (MET). MET integrates multiple exits into the pre-trained ViT backbone. Since the predictions in ViT are made by a linear classifier, each exit is equipped with a linear prediction head. In inference stage, easy samples will exit at early exits and only hard enough samples will flow to the last exit, thus saving the computational cost for easy samples. MET consists of exit-specific adapters (E-adapters) and graph regularization. E-adapters are designed to extract suitable representations for different exits. To ensure parameter efficiency, all E-adapters share the same down-projection and up-projection matrices. As the performances of linear classifiers are influenced by the relationship among samples, we employ graph regularization to improve the representations fed into the classifiers at early exits. Finally, we conduct extensive experiments to verify the performance of MET. Experimental results show that MET has an obvious advantage over the state-of-the-art methods in terms of both accuracy and inference efficiency.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 03:25:18 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.037735"
    },
    {
        "index": "#120",
        "title": "GAInS: Gradient Anomaly-aware Biomedical Instance Segmentation",
        "link": "/arxiv/2409.13988",
        "arxiv_id": "2409.13988",
        "authors": "Runsheng Liu, Hao Jiang, Yanning Zhou, Huangjing Lin, Liansheng Wang, Hao Chen",
        "summary": "Instance segmentation plays a vital role in the morphological quantification of biomedical entities such as tissues and cells, enabling precise identification and delineation of different structures. Current methods often address the challenges of touching, overlapping or crossing instances through individual modeling, while neglecting the intrinsic interrelation between these conditions. In this work, we propose a Gradient Anomaly-aware Biomedical Instance Segmentation approach (GAInS), which leverages instance gradient information to perceive local gradient anomaly regions, thus modeling the spatial relationship between instances and refining local region segmentation. Specifically, GAInS is firstly built on a Gradient Anomaly Mapping Module (GAMM), which encodes the radial fields of instances through window sliding to obtain instance gradient anomaly maps. To efficiently refine boundaries and regions with gradient anomaly attention, we propose an Adaptive Local Refinement Module (ALRM) with a gradient anomaly-aware loss function. Extensive comparisons and ablation experiments in three biomedical scenarios demonstrate that our proposed GAInS outperforms other state-of-the-art (SOTA) instance segmentation methods. The code is available at https://github.com/DeepGAInS/GAInS.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 02:36:46 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.037924"
    },
    {
        "index": "#121",
        "title": "Holistic and Historical Instance Comparison for Cervical Cell Detection",
        "link": "/arxiv/2409.13987",
        "arxiv_id": "2409.13987",
        "authors": "Hao Jiang, Runsheng Liu, Yanning Zhou, Huangjing Lin, Hao Chen",
        "summary": "Cytology screening from Papanicolaou (Pap) smears is a common and effective tool for the preventive clinical management of cervical cancer, where abnormal cell detection from whole slide images serves as the foundation for reporting cervical cytology. However, cervical cell detection remains challenging due to 1) hazily-defined cell types (e.g., ASC-US) with subtle morphological discrepancies caused by the dynamic cancerization process, i.e., cell class ambiguity, and 2) imbalanced class distributions of clinical data may cause missed detection, especially for minor categories, i.e., cell class imbalance. To this end, we propose a holistic and historical instance comparison approach for cervical cell detection. Specifically, we first develop a holistic instance comparison scheme enforcing both RoI-level and class-level cell discrimination. This coarse-to-fine cell comparison encourages the model to learn foreground-distinguishable and class-wise representations. To emphatically improve the distinguishability of minor classes, we then introduce a historical instance comparison scheme with a confident sample selection-based memory bank, which involves comparing current embeddings with historical embeddings for better cell instance discrimination. Extensive experiments and analysis on two large-scale cytology datasets including 42,592 and 114,513 cervical cells demonstrate the effectiveness of our method. The code is available at https://github.com/hjiangaz/HERO.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 02:36:19 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.038124"
    },
    {
        "index": "#122",
        "title": "Cycle-Consistency Uncertainty Estimation for Visual Prompting based One-Shot Defect Segmentation",
        "link": "/arxiv/2409.13984",
        "arxiv_id": "2409.13984",
        "authors": "Geonuk Kim",
        "summary": "Industrial defect detection traditionally relies on supervised learning models trained on fixed datasets of known defect types. While effective within a closed set, these models struggle with new, unseen defects, necessitating frequent re-labeling and re-training. Recent advances in visual prompting offer a solution by allowing models to adaptively infer novel categories based on provided visual cues. However, a prevalent issue in these methods is the over-confdence problem, where models can mis-classify unknown objects as known objects with high certainty. To addresssing the fundamental concerns about the adaptability, we propose a solution to estimate uncertainty of the visual prompting process by cycle-consistency. We designed to check whether it can accurately restore the original prompt from its predictions. To quantify this, we measure the mean Intersection over Union (mIoU) between the restored prompt mask and the originally provided prompt mask. Without using complex designs or ensemble methods with multiple networks, our approach achieved a yield rate of 0.9175 in the VISION24 one-shot industrial challenge.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 02:25:32 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.038359"
    },
    {
        "index": "#123",
        "title": "Enhanced Semantic Segmentation for Large-Scale and Imbalanced Point Clouds",
        "link": "/arxiv/2409.13983",
        "arxiv_id": "2409.13983",
        "authors": "Haoran Gong, Haodong Wang, Di Wang",
        "summary": "Semantic segmentation of large-scale point clouds is of significant importance in environment perception and scene understanding. However, point clouds collected from real-world environments are usually imbalanced and small-sized objects are prone to be under-sampled or misclassified due to their low occurrence frequency, thereby reducing the overall accuracy of semantic segmentation. In this study, we propose the Multilateral Cascading Network (MCNet) for large-scale and sample-imbalanced point cloud scenes. To increase the frequency of small-sized objects, we introduce the semantic-weighted sampling module, which incorporates a probability parameter into the collected data group. To facilitate feature learning, we propose a Multilateral Cascading Attention Enhancement (MCAE) module to learn complex local features through multilateral cascading operations and attention mechanisms. To promote feature fusion, we propose a Point Cross Stage Partial (P-CSP) module to combine global and local features, optimizing the integration of valuable feature information across multiple scales. Finally, we introduce the neighborhood voting module to integrate results at the output layer. Our proposed method demonstrates either competitive or superior performance relative to state-of-the-art approaches across three widely recognized benchmark datasets: S3DIS, Toronto3D, and SensatUrban with mIoU scores of 74.0\\%, 82.9\\% and 64.5\\%, respectively. Notably, our work yielded consistent optimal results on the under-sampled semantic categories, thereby demonstrating exceptional performance in the recognition of small-sized objects.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 02:23:01 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.038546"
    },
    {
        "index": "#124",
        "title": "CUS3D :CLIP-based Unsupervised 3D Segmentation via Object-level Denoise",
        "link": "/arxiv/2409.13982",
        "arxiv_id": "2409.13982",
        "authors": "Fuyang Yu, Runze Tian, Zhen Wang, Xiaochuan Wang, Xiaohui Liang",
        "summary": "To ease the difficulty of acquiring annotation labels in 3D data, a common method is using unsupervised and open-vocabulary semantic segmentation, which leverage 2D CLIP semantic knowledge. In this paper, unlike previous research that ignores the ``noise'' raised during feature projection from 2D to 3D, we propose a novel distillation learning framework named CUS3D. In our approach, an object-level denosing projection module is designed to screen out the ``noise'' and ensure more accurate 3D feature. Based on the obtained features, a multimodal distillation learning module is designed to align the 3D feature with CLIP semantic feature space with object-centered constrains to achieve advanced unsupervised semantic segmentation. We conduct comprehensive experiments in both unsupervised and open-vocabulary segmentation, and the results consistently showcase the superiority of our model in achieving advanced unsupervised segmentation results and its effectiveness in open-vocabulary segmentation.",
        "subjects": "Computer Vision and Pattern Recognition, Multimedia",
        "date": "2024-09-21 02:17:35 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.038751"
    },
    {
        "index": "#125",
        "title": "Enhancing Advanced Visual Reasoning Ability of Large Language Models",
        "link": "/arxiv/2409.13980",
        "arxiv_id": "2409.13980",
        "authors": "Zhiyuan Li, Dongnan Liu, Chaoyi Zhang, Heng Wang, Tengfei Xue, Weidong Cai",
        "summary": "Recent advancements in Vision-Language (VL) research have sparked new benchmarks for complex visual reasoning, challenging models' advanced reasoning ability. Traditional Vision-Language Models (VLMs) perform well in visual perception tasks while struggling with complex reasoning scenarios. Conversely, Large Language Models (LLMs) demonstrate robust text reasoning capabilities; however, they lack visual acuity. To bridge this gap, we propose Complex Visual Reasoning Large Language Models (CVR-LLM), capitalizing on VLMs' visual perception proficiency and LLMs' extensive reasoning capability. Unlike recent multimodal large language models (MLLMs) that require a projection layer, our approach transforms images into detailed, context-aware descriptions using an iterative self-refinement loop and leverages LLMs' text knowledge for accurate predictions without extra training. We also introduce a novel multi-modal in-context learning (ICL) methodology to enhance LLMs' contextual understanding and reasoning. Additionally, we introduce Chain-of-Comparison (CoC), a step-by-step comparison technique enabling contrasting various aspects of predictions. Our CVR-LLM presents the first comprehensive study across a wide array of complex visual reasoning tasks and achieves SOTA performance among all.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-21 02:10:19 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.038957"
    },
    {
        "index": "#126",
        "title": "FracGM: A Fast Fractional Programming Technique for Geman-McClure Robust Estimator",
        "link": "/arxiv/2409.13978",
        "arxiv_id": "2409.13978",
        "authors": "Bang-Shien Chen, Yu-Kai Lin, Jian-Yu Chen, Chih-Wei Huang, Jann-Long Chern, Ching-Cherng Sun",
        "summary": "Robust estimation is essential in computer vision, robotics, and navigation, aiming to minimize the impact of outlier measurements for improved accuracy. We present a fast algorithm for Geman-McClure robust estimation, FracGM, leveraging fractional programming techniques. This solver reformulates the original non-convex fractional problem to a convex dual problem and a linear equation system, iteratively solving them in an alternating optimization pattern. Compared to graduated non-convexity approaches, this strategy exhibits a faster convergence rate and better outlier rejection capability. In addition, the global optimality of the proposed solver can be guaranteed under given conditions. We demonstrate the proposed FracGM solver with Wahba's rotation problem and 3-D point-cloud registration along with relaxation pre-processing and projection post-processing. Compared to state-of-the-art algorithms, when the outlier rates increase from 20\\% to 80\\%, FracGM shows 53\\% and 88\\% lower rotation and translation increases. In real-world scenarios, FracGM achieves better results in 13 out of 18 outcomes, while having a 19.43\\% improvement in the computation time.",
        "subjects": "Computer Vision and Pattern Recognition, Robotics, Optimization and Control",
        "date": "2024-09-21 02:01:55 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.039162"
    },
    {
        "index": "#127",
        "title": "Improving 3D Semi-supervised Learning by Effectively Utilizing All Unlabelled Data",
        "link": "/arxiv/2409.13977",
        "arxiv_id": "2409.13977",
        "authors": "Sneha Paul, Zachary Patterson, Nizar Bouguila",
        "summary": "Semi-supervised learning (SSL) has shown its effectiveness in learning effective 3D representation from a small amount of labelled data while utilizing large unlabelled data. Traditional semi-supervised approaches rely on the fundamental concept of predicting pseudo-labels for unlabelled data and incorporating them into the learning process. However, we identify that the existing methods do not fully utilize all the unlabelled samples and consequently limit their potential performance. To address this issue, we propose AllMatch, a novel SSL-based 3D classification framework that effectively utilizes all the unlabelled samples. AllMatch comprises three modules: (1) an adaptive hard augmentation module that applies relatively hard augmentations to the high-confident unlabelled samples with lower loss values, thereby enhancing the contribution of such samples, (2) an inverse learning module that further improves the utilization of unlabelled data by learning what not to learn, and (3) a contrastive learning module that ensures learning from all the samples in both supervised and unsupervised settings. Comprehensive experiments on two popular 3D datasets demonstrate a performance improvement of up to 11.2% with 1% labelled data, surpassing the SOTA by a significant margin. Furthermore, AllMatch exhibits its efficiency in effectively leveraging all the unlabelled data, demonstrated by the fact that only 10% of labelled data reaches nearly the same performance as fully-supervised learning with all labelled data. The code of our work is available at: https://github.com/snehaputul/AllMatch.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-21 01:53:52 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.039338"
    },
    {
        "index": "#128",
        "title": "Detecting Inpainted Video with Frequency Domain Insights",
        "link": "/arxiv/2409.13976",
        "arxiv_id": "2409.13976",
        "authors": "Quanhui Tang, Jingtao Cao",
        "summary": "Video inpainting enables seamless content removal and replacement within frames, posing ethical and legal risks when misused. To mitigate these risks, detecting manipulated regions in inpainted videos is critical. Previous detection methods often focus solely on the characteristics derived from spatial and temporal dimensions, which limits their effectiveness by overlooking the unique frequency characteristics of different inpainting algorithms. In this paper, we propose the Frequency Domain Insights Network (FDIN), which significantly enhances detection accuracy by incorporating insights from the frequency domain. Our network features an Adaptive Band Selective Response module to discern frequency characteristics specific to various inpainting techniques and a Fast Fourier Convolution-based Attention module for identifying periodic artifacts in inpainted regions. Utilizing 3D ResBlocks for spatiotemporal analysis, FDIN progressively refines detection precision from broad assessments to detailed localization. Experimental evaluations on public datasets demonstrate that FDIN achieves state-of-the-art performance, setting a new benchmark in video inpainting detection.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-21 01:51:07 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.039524"
    },
    {
        "index": "#129",
        "title": "Monocular Event-Inertial Odometry with Adaptive decay-based Time Surface and Polarity-aware Tracking",
        "link": "/arxiv/2409.13971",
        "arxiv_id": "2409.13971",
        "authors": "Kai Tang, Xiaolei Lang, Yukai Ma, Yuehao Huang, Laijian Li, Yong Liu, Jiajun Lv",
        "summary": "Event cameras have garnered considerable attention due to their advantages over traditional cameras in low power consumption, high dynamic range, and no motion blur. This paper proposes a monocular event-inertial odometry incorporating an adaptive decay kernel-based time surface with polarity-aware tracking. We utilize an adaptive decay-based Time Surface to extract texture information from asynchronous events, which adapts to the dynamic characteristics of the event stream and enhances the representation of environmental textures. However, polarity-weighted time surfaces suffer from event polarity shifts during changes in motion direction. To mitigate its adverse effects on feature tracking, we optimize the feature tracking by incorporating an additional polarity-inverted time surface to enhance the robustness. Comparative analysis with visual-inertial and event-inertial odometry methods shows that our approach outperforms state-of-the-art techniques, with competitive results across various datasets.",
        "subjects": "Computer Vision and Pattern Recognition, Robotics",
        "date": "2024-09-21 01:35:12 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.039789"
    },
    {
        "index": "#130",
        "title": "Deep learning for fast segmentation and critical dimension metrology & characterization enabling AR/VR design and fabrication",
        "link": "/arxiv/2409.13951",
        "arxiv_id": "2409.13951",
        "authors": "Kundan Chaudhary, Subhei Shaar, Raja Muthinti",
        "summary": "Quantitative analysis of microscopy images is essential in the design and fabrication of components used in augmented reality/virtual reality (AR/VR) modules. However, segmenting regions of interest (ROIs) from these complex images and extracting critical dimensions (CDs) requires novel techniques, such as deep learning models which are key for actionable decisions on process, material and device optimization. In this study, we report on the fine-tuning of a pre-trained Segment Anything Model (SAM) using a diverse dataset of electron microscopy images. We employed methods such as low-rank adaptation (LoRA) to reduce training time and enhance the accuracy of ROI extraction. The model's ability to generalize to unseen images facilitates zero-shot learning and supports a CD extraction model that precisely extracts CDs from the segmented ROIs. We demonstrate the accurate extraction of binary images from cross-sectional images of surface relief gratings (SRGs) and Fresnel lenses in both single and multiclass modes. Furthermore, these binary images are used to identify transition points, aiding in the extraction of relevant CDs. The combined use of the fine-tuned segmentation model and the CD extraction model offers substantial advantages to various industrial applications by enhancing analytical capabilities, time to data and insights, and optimizing manufacturing processes.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning, Image and Video Processing",
        "date": "2024-09-20 23:54:58 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.039993"
    },
    {
        "index": "#131",
        "title": "TalkMosaic: Interactive PhotoMosaic with Multi-modal LLM Q&A Interactions",
        "link": "/arxiv/2409.13941",
        "arxiv_id": "2409.13941",
        "authors": "Kevin Li, Fulu Li",
        "summary": "We use images of cars of a wide range of varieties to compose an image of an animal such as a bird or a lion for the theme of environmental protection to maximize the information about cars in a single composed image and to raise the awareness about environmental challenges. We present a novel way of image interaction with an artistically-composed photomosaic image, in which a simple operation of \"click and display\" is used to demonstrate the interactive switch between a tile image in a photomosaic image and the corresponding original car image, which will be automatically saved on the Desktop. We build a multimodal custom GPT named TalkMosaic by incorporating car images information and the related knowledge to ChatGPT. By uploading the original car image to TalkMosaic, we can ask questions about the given car image and get the corresponding answers efficiently and effectively such as where to buy the tire in the car image that satisfies high environmental standards. We give an in-depth analysis on how to speed up the inference of multimodal LLM using sparse attention and quantization techniques with presented probabilistic FlashAttention (PrFlashAttention) and Staircase Adaptive Quantization (SAQ) methods. The implemented prototype demonstrates the feasibility and effectiveness of the presented approach.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2024-09-20 23:04:21 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.040167"
    },
    {
        "index": "#132",
        "title": "Data Pruning via Separability, Integrity, and Model Uncertainty-Aware Importance Sampling",
        "link": "/arxiv/2409.13915",
        "arxiv_id": "2409.13915",
        "authors": "Steven Grosz, Rui Zhao, Rajeev Ranjan, Hongcheng Wang, Manoj Aggarwal, Gerard Medioni, Anil Jain",
        "summary": "This paper improves upon existing data pruning methods for image classification by introducing a novel pruning metric and pruning procedure based on importance sampling. The proposed pruning metric explicitly accounts for data separability, data integrity, and model uncertainty, while the sampling procedure is adaptive to the pruning ratio and considers both intra-class and inter-class separation to further enhance the effectiveness of pruning. Furthermore, the sampling method can readily be applied to other pruning metrics to improve their performance. Overall, the proposed approach scales well to high pruning ratio and generalizes better across different classification models, as demonstrated by experiments on four benchmark datasets, including the fine-grained classification scenario.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-20 21:45:02 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.040447"
    },
    {
        "index": "#133",
        "title": "OneBEV: Using One Panoramic Image for Bird's-Eye-View Semantic Mapping",
        "link": "/arxiv/2409.13912",
        "arxiv_id": "2409.13912",
        "authors": "Jiale Wei, Junwei Zheng, Ruiping Liu, Jie Hu, Jiaming Zhang, Rainer Stiefelhagen",
        "summary": "In the field of autonomous driving, Bird's-Eye-View (BEV) perception has attracted increasing attention in the community since it provides more comprehensive information compared with pinhole front-view images and panoramas. Traditional BEV methods, which rely on multiple narrow-field cameras and complex pose estimations, often face calibration and synchronization issues. To break the wall of the aforementioned challenges, in this work, we introduce OneBEV, a novel BEV semantic mapping approach using merely a single panoramic image as input, simplifying the mapping process and reducing computational complexities. A distortion-aware module termed Mamba View Transformation (MVT) is specifically designed to handle the spatial distortions in panoramas, transforming front-view features into BEV features without leveraging traditional attention mechanisms. Apart from the efficient framework, we contribute two datasets, i.e., nuScenes-360 and DeepAccident-360, tailored for the OneBEV task. Experimental results showcase that OneBEV achieves state-of-the-art performance with 51.1% and 36.1% mIoU on nuScenes-360 and DeepAccident-360, respectively. This work advances BEV semantic mapping in autonomous driving, paving the way for more advanced and reliable autonomous systems.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-20 21:33:53 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.040735"
    },
    {
        "index": "#134",
        "title": "Brain-Cognition Fingerprinting via Graph-GCCA with Contrastive Learning",
        "link": "/arxiv/2409.13887",
        "arxiv_id": "2409.13887",
        "authors": "Yixin Wang, Wei Peng, Yu Zhang, Ehsan Adeli, Qingyu Zhao, Kilian M. Pohl",
        "summary": "Many longitudinal neuroimaging studies aim to improve the understanding of brain aging and diseases by studying the dynamic interactions between brain function and cognition. Doing so requires accurate encoding of their multidimensional relationship while accounting for individual variability over time. For this purpose, we propose an unsupervised learning model (called \\underline{\\textbf{Co}}ntrastive Learning-based \\underline{\\textbf{Gra}}ph Generalized \\underline{\\textbf{Ca}}nonical Correlation Analysis (CoGraCa)) that encodes their relationship via Graph Attention Networks and generalized Canonical Correlational Analysis. To create brain-cognition fingerprints reflecting unique neural and cognitive phenotype of each person, the model also relies on individualized and multimodal contrastive learning. We apply CoGraCa to longitudinal dataset of healthy individuals consisting of resting-state functional MRI and cognitive measures acquired at multiple visits for each participant. The generated fingerprints effectively capture significant individual differences and outperform current single-modal and CCA-based multimodal models in identifying sex and age. More importantly, our encoding provides interpretable interactions between those two modalities.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-20 20:36:20 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.040944"
    },
    {
        "index": "#135",
        "title": "SSE: Multimodal Semantic Data Selection and Enrichment for Industrial-scale Data Assimilation",
        "link": "/arxiv/2409.13860",
        "arxiv_id": "2409.13860",
        "authors": "Maying Shen, Nadine Chang, Sifei Liu, Jose M. Alvarez",
        "summary": "In recent years, the data collected for artificial intelligence has grown to an unmanageable amount. Particularly within industrial applications, such as autonomous vehicles, model training computation budgets are being exceeded while model performance is saturating -- and yet more data continues to pour in. To navigate the flood of data, we propose a framework to select the most semantically diverse and important dataset portion. Then, we further semantically enrich it by discovering meaningful new data from a massive unlabeled data pool. Importantly, we can provide explainability by leveraging foundation models to generate semantics for every data point. We quantitatively show that our Semantic Selection and Enrichment framework (SSE) can a) successfully maintain model performance with a smaller training dataset and b) improve model performance by enriching the smaller dataset without exceeding the original dataset size. Consequently, we demonstrate that semantic diversity is imperative for optimal data selection and model performance.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2024-09-20 19:17:52 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.041129"
    },
    {
        "index": "#136",
        "title": "Multi-Modality Conditioned Variational U-Net for Field-of-View Extension in Brain Diffusion MRI",
        "link": "/arxiv/2409.13846",
        "arxiv_id": "2409.13846",
        "authors": "Zhiyuan Li, Tianyuan Yao, Praitayini Kanakaraj, Chenyu Gao, Shunxing Bao, Lianrui Zuo, Michael E. Kim, Nancy R. Newlin, Gaurav Rudravaram, Nazirah M. Khairi, Yuankai Huo, Kurt G. Schilling, Walter A. Kukull, Arthur W. Toga, Derek B. Archer, Timothy J. Hohman, Bennett A. Landman",
        "summary": "An incomplete field-of-view (FOV) in diffusion magnetic resonance imaging (dMRI) can severely hinder the volumetric and bundle analyses of whole-brain white matter connectivity. Although existing works have investigated imputing the missing regions using deep generative models, it remains unclear how to specifically utilize additional information from paired multi-modality data and whether this can enhance the imputation quality and be useful for downstream tractography. To fill this gap, we propose a novel framework for imputing dMRI scans in the incomplete part of the FOV by integrating the learned diffusion features in the acquired part of the FOV to the complete brain anatomical structure. We hypothesize that by this design the proposed framework can enhance the imputation performance of the dMRI scans and therefore be useful for repairing whole-brain tractography in corrupted dMRI scans with incomplete FOV. We tested our framework on two cohorts from different sites with a total of 96 subjects and compared it with a baseline imputation method that treats the information from T1w and dMRI scans equally. The proposed framework achieved significant improvements in imputation performance, as demonstrated by angular correlation coefficient (p < 1E-5), and in downstream tractography accuracy, as demonstrated by Dice score (p < 0.01). Results suggest that the proposed framework improved imputation performance in dMRI scans by specifically utilizing additional information from paired multi-modality data, compared with the baseline method. The imputation achieved by the proposed framework enhances whole brain tractography, and therefore reduces the uncertainty when analyzing bundles associated with neurodegenerative.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-20 18:41:29 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.041401"
    },
    {
        "index": "#137",
        "title": "ViTGuard: Attention-aware Detection against Adversarial Examples for Vision Transformer",
        "link": "/arxiv/2409.13828",
        "arxiv_id": "2409.13828",
        "authors": "Shihua Sun, Kenechukwu Nwodo, Shridatt Sugrim, Angelos Stavrou, Haining Wang",
        "summary": "The use of transformers for vision tasks has challenged the traditional dominant role of convolutional neural networks (CNN) in computer vision (CV). For image classification tasks, Vision Transformer (ViT) effectively establishes spatial relationships between patches within images, directing attention to important areas for accurate predictions. However, similar to CNNs, ViTs are vulnerable to adversarial attacks, which mislead the image classifier into making incorrect decisions on images with carefully designed perturbations. Moreover, adversarial patch attacks, which introduce arbitrary perturbations within a small area, pose a more serious threat to ViTs. Even worse, traditional detection methods, originally designed for CNN models, are impractical or suffer significant performance degradation when applied to ViTs, and they generally overlook patch attacks. In this paper, we propose ViTGuard as a general detection method for defending ViT models against adversarial attacks, including typical attacks where perturbations spread over the entire input and patch attacks. ViTGuard uses a Masked Autoencoder (MAE) model to recover randomly masked patches from the unmasked regions, providing a flexible image reconstruction strategy. Then, threshold-based detectors leverage distinctive ViT features, including attention maps and classification (CLS) token representations, to distinguish between normal and adversarial samples. The MAE model does not involve any adversarial samples during training, ensuring the effectiveness of our detectors against unseen attacks. ViTGuard is compared with seven existing detection methods under nine attacks across three datasets. The evaluation results show the superiority of ViTGuard over existing detectors. Finally, considering the potential detection evasion, we further demonstrate ViTGuard's robustness against adaptive attacks for evasion.",
        "subjects": "Computer Vision and Pattern Recognition, Cryptography and Security",
        "date": "2024-09-20 18:11:56 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.041598"
    },
    {
        "index": "#138",
        "title": "Intrinsic Single-Image HDR Reconstruction",
        "link": "/arxiv/2409.13803",
        "arxiv_id": "2409.13803",
        "authors": "Sebastian Dille, Chris Careaga, Yağız Aksoy",
        "summary": "The low dynamic range (LDR) of common cameras fails to capture the rich contrast in natural scenes, resulting in loss of color and details in saturated pixels. Reconstructing the high dynamic range (HDR) of luminance present in the scene from single LDR photographs is an important task with many applications in computational photography and realistic display of images. The HDR reconstruction task aims to infer the lost details using the context present in the scene, requiring neural networks to understand high-level geometric and illumination cues. This makes it challenging for data-driven algorithms to generate accurate and high-resolution results. In this work, we introduce a physically-inspired remodeling of the HDR reconstruction problem in the intrinsic domain. The intrinsic model allows us to train separate networks to extend the dynamic range in the shading domain and to recover lost color details in the albedo domain. We show that dividing the problem into two simpler sub-tasks improves performance in a wide variety of photographs.",
        "subjects": "Computer Vision and Pattern Recognition, Graphics, Image and Video Processing",
        "date": "2024-09-20 17:56:51 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.047119"
    },
    {
        "index": "#139",
        "title": "OmniBench: Towards The Future of Universal Omni-Language Models",
        "link": "/arxiv/2409.15272",
        "arxiv_id": "2409.15272",
        "authors": "Yizhi Li, Ge Zhang, Yinghao Ma, Ruibin Yuan, Kang Zhu, Hangyu Guo, Yiming Liang, Jiaheng Liu, Jian Yang, Siwei Wu, Xingwei Qu, Jinjie Shi, Xinyue Zhang, Zhenzhu Yang, Xiangzhou Wang, Zhaoxiang Zhang, Zachary Liu, Emmanouil Benetos, Wenhao Huang, Chenghua Lin",
        "summary": "Recent advancements in multimodal large language models (MLLMs) have aimed to integrate and interpret data across diverse modalities. However, the capacity of these models to concurrently process and reason about multiple modalities remains inadequately explored, partly due to the lack of comprehensive modality-wise benchmarks. We introduce OmniBench, a novel benchmark designed to rigorously evaluate models' ability to recognize, interpret, and reason across visual, acoustic, and textual inputs simultaneously. We define models capable of such tri-modal processing as omni-language models (OLMs). OmniBench is distinguished by high-quality human annotations, ensuring that accurate responses require integrated understanding and reasoning across all three modalities. Our main findings reveal that: i) open-source OLMs exhibit critical limitations in instruction-following and reasoning capabilities within tri-modal contexts; and ii) the baseline models perform poorly (below 50% accuracy) even when provided with alternative textual representations of images and audio. These results suggest that the ability to construct a consistent context from text, image, and audio is often overlooked in existing MLLM training paradigms. We advocate for future research to focus on developing more robust tri-modal integration techniques and training strategies to enhance OLM performance across diverse modalities. The codes and live leaderboard could be found at https://m-a-p.ai/OmniBench.",
        "subjects": "Computation and Language, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 17:59:05 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.047496"
    },
    {
        "index": "#140",
        "title": "UDA-Bench: Revisiting Common Assumptions in Unsupervised Domain Adaptation Using a Standardized Framework",
        "link": "/arxiv/2409.15264",
        "arxiv_id": "2409.15264",
        "authors": "Tarun Kalluri, Sreyas Ravichandran, Manmohan Chandraker",
        "summary": "In this work, we take a deeper look into the diverse factors that influence the efficacy of modern unsupervised domain adaptation (UDA) methods using a large-scale, controlled empirical study. To facilitate our analysis, we first develop UDA-Bench, a novel PyTorch framework that standardizes training and evaluation for domain adaptation enabling fair comparisons across several UDA methods. Using UDA-Bench, our comprehensive empirical study into the impact of backbone architectures, unlabeled data quantity, and pre-training datasets reveals that: (i) the benefits of adaptation methods diminish with advanced backbones, (ii) current methods underutilize unlabeled data, and (iii) pre-training data significantly affects downstream adaptation in both supervised and self-supervised settings. In the context of unsupervised adaptation, these observations uncover several novel and surprising properties, while scientifically validating several others that were often considered empirical heuristics or practitioner intuitions in the absence of a standardized training and evaluation framework. The UDA-Bench framework and trained models are publicly available at https://github.com/ViLab-UCSD/UDABench_ECCV2024.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 17:57:07 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.047703"
    },
    {
        "index": "#141",
        "title": "ZeroSCD: Zero-Shot Street Scene Change Detection",
        "link": "/arxiv/2409.15255",
        "arxiv_id": "2409.15255",
        "authors": "Shyam Sundar Kannan, Byung-Cheol Min",
        "summary": "Scene Change Detection is a challenging task in computer vision and robotics that aims to identify differences between two images of the same scene captured at different times. Traditional change detection methods rely on training models that take these image pairs as input and estimate the changes, which requires large amounts of annotated data, a costly and time-consuming process. To overcome this, we propose ZeroSCD, a zero-shot scene change detection framework that eliminates the need for training. ZeroSCD leverages pre-existing models for place recognition and semantic segmentation, utilizing their features and outputs to perform change detection. In this framework, features extracted from the place recognition model are used to estimate correspondences and detect changes between the two images. These are then combined with segmentation results from the semantic segmentation model to precisely delineate the boundaries of the detected changes. Extensive experiments on benchmark datasets demonstrate that ZeroSCD outperforms several state-of-the-art methods in change detection accuracy, despite not being trained on any of the benchmark datasets, proving its effectiveness and adaptability across different scenarios.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 17:53:44 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.047885"
    },
    {
        "index": "#142",
        "title": "Investigating Robot Dogs for Construction Monitoring: A Comparative Analysis of Specifications and On-site Requirements",
        "link": "/arxiv/2409.15253",
        "arxiv_id": "2409.15253",
        "authors": "Miguel Arturo Vega Torres, Fabian Pfitzner",
        "summary": "Robot dogs are receiving increasing attention in various fields of research. However, the number of studies investigating their potential usability on construction sites is scarce. The construction industry implies several human resource-demanding tasks such as safety monitoring, material transportation, and site inspections. Robot dogs can address some of these challenges by providing automated support and lowering manual effort. In this paper, we investigate the potential usability of currently available robot dogs on construction sites in terms of focusing on their different specifications and on-site requirements to support data acquisition. In addition, we conducted a real-world experiment on a large-scale construction site using a quadruped robot. In conclusion, we consider robot dogs to be a valuable asset for monitoring intricate construction environments in the future, particularly as their limitations are mitigated through technical advancements.",
        "subjects": "Robotics, Hardware Architecture, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 17:51:31 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.048073"
    },
    {
        "index": "#143",
        "title": "Semantic Inference-Based Deep Learning and Modeling for Earth Observation: Cognitive Semantic Augmentation Satellite Networks",
        "link": "/arxiv/2409.15246",
        "arxiv_id": "2409.15246",
        "authors": "Hong-fu Chou, Vu Nguyen Ha, Prabhu Thiruvasagam, Thanh-Dung Le, Geoffrey Eappen, Ti Ti Nguyen, Luis M. Garces-Socarras, Jorge L. Gonzalez-Rios, Juan Carlos Merlano-Duncan, Symeon Chatzinotas",
        "summary": "Earth Observation (EO) systems play a crucial role in achieving Sustainable Development Goals by collecting and analyzing vital global data through satellite networks. These systems are essential for tasks like mapping, disaster monitoring, and resource management, but they face challenges in processing and transmitting large volumes of EO data, especially in specialized fields such as agriculture and real-time disaster response. Domain-adapted Large Language Models (LLMs) provide a promising solution by facilitating data fusion between extensive EO data and semantic EO data. By improving integration and interpretation of diverse datasets, LLMs address the challenges of processing specialized information in agriculture and disaster response applications. This fusion enhances the accuracy and relevance of transmitted data. This paper presents a framework for semantic communication in EO satellite networks, aimed at improving data transmission efficiency and overall system performance through cognitive processing techniques. The proposed system employs Discrete-Task-Oriented Source-Channel Coding (DT-JSCC) and Semantic Data Augmentation (SA) to focus on relevant information while minimizing communication overhead. By integrating cognitive semantic processing and inter-satellite links, the framework enhances the analysis and transmission of multispectral satellite imagery, improving object detection, pattern recognition, and real-time decision-making. The introduction of Cognitive Semantic Augmentation (CSA) allows satellites to process and transmit semantic information, boosting adaptability to changing environments and application needs. This end-to-end architecture is tailored for next-generation satellite networks, such as those supporting 6G, and demonstrates significant improvements in efficiency and accuracy.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Networking and Internet Architecture",
        "date": "2024-09-23 17:42:05 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.048322"
    },
    {
        "index": "#144",
        "title": "FLeNS: Federated Learning with Enhanced Nesterov-Newton Sketch",
        "link": "/arxiv/2409.15216",
        "arxiv_id": "2409.15216",
        "authors": "Sunny Gupta, Mohit, Pankhi Kashyap, Pranav Jeevan, Amit Sethi",
        "summary": "Federated learning faces a critical challenge in balancing communication efficiency with rapid convergence, especially for second-order methods. While Newton-type algorithms achieve linear convergence in communication rounds, transmitting full Hessian matrices is often impractical due to quadratic complexity. We introduce Federated Learning with Enhanced Nesterov-Newton Sketch (FLeNS), a novel method that harnesses both the acceleration capabilities of Nesterov's method and the dimensionality reduction benefits of Hessian sketching. FLeNS approximates the centralized Newton's method without relying on the exact Hessian, significantly reducing communication overhead. By combining Nesterov's acceleration with adaptive Hessian sketching, FLeNS preserves crucial second-order information while preserving the rapid convergence characteristics. Our theoretical analysis, grounded in statistical learning, demonstrates that FLeNS achieves super-linear convergence rates in communication rounds - a notable advancement in federated optimization. We provide rigorous convergence guarantees and characterize tradeoffs between acceleration, sketch size, and convergence speed. Extensive empirical evaluation validates our theoretical findings, showcasing FLeNS's state-of-the-art performance with reduced communication requirements, particularly in privacy-sensitive and edge-computing scenarios. The code is available at https://github.com/sunnyinAI/FLeNS",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Distributed, Parallel, and Cluster Computing, Optimization and Control",
        "date": "2024-09-23 17:00:35 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.048532"
    },
    {
        "index": "#145",
        "title": "MAR-DTN: Metal Artifact Reduction using Domain Transformation Network for Radiotherapy Planning",
        "link": "/arxiv/2409.15155",
        "arxiv_id": "2409.15155",
        "authors": "Belén Serrano-Antón, Mubashara Rehman, Niki Martinel, Michele Avanzo, Riccardo Spizzo, Giuseppe Fanetti, Alberto P. Muñuzuri, Christian Micheloni",
        "summary": "For the planning of radiotherapy treatments for head and neck cancers, Computed Tomography (CT) scans of the patients are typically employed. However, in patients with head and neck cancer, the quality of standard CT scans generated using kilo-Voltage (kVCT) tube potentials is severely degraded by streak artifacts occurring in the presence of metallic implants such as dental fillings. Some radiotherapy devices offer the possibility of acquiring Mega-Voltage CT (MVCT) for daily patient setup verification, due to the higher energy of X-rays used, MVCT scans are almost entirely free from artifacts making them more suitable for radiotherapy treatment planning. In this study, we leverage the advantages of kVCT scans with those of MVCT scans (artifact-free). We propose a deep learning-based approach capable of generating artifact-free MVCT images from acquired kVCT images. The outcome offers the benefits of artifact-free MVCT images with enhanced soft tissue contrast, harnessing valuable information obtained through kVCT technology for precise therapy calibration. Our proposed method employs UNet-inspired model, and is compared with adversarial learning and transformer networks. This first and unique approach achieves remarkable success, with PSNR of 30.02 dB across the entire patient volume and 27.47 dB in artifact-affected regions exclusively. It is worth noting that the PSNR calculation excludes the background, concentrating solely on the region of interest.",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 16:04:00 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.048759"
    },
    {
        "index": "#146",
        "title": "Towards Accountable AI-Assisted Eye Disease Diagnosis: Workflow Design, External Validation, and Continual Learning",
        "link": "/arxiv/2409.15087",
        "arxiv_id": "2409.15087",
        "authors": "Qingyu Chen, Tiarnan D L Keenan, Elvira Agron, Alexis Allot, Emily Guan, Bryant Duong, Amr Elsawy, Benjamin Hou, Cancan Xue, Sanjeeb Bhandari, Geoffrey Broadhead, Chantal Cousineau-Krieger, Ellen Davis, William G Gensheimer, David Grasic, Seema Gupta, Luis Haddock, Eleni Konstantinou, Tania Lamba, Michele Maiberger, Dimosthenis Mantopoulos, Mitul C Mehta, Ayman G Nahri, Mutaz AL-Nawaflh, Arnold Oshinsky, Brittany E Powell, Boonkit Purt, Soo Shin, Hillary Stiefel, Alisa T Thavikulwat, Keith James Wroblewski, Tham Yih Chung, Chui Ming Gemmy Cheung, Ching-Yu Cheng, Emily Y Chew, Michelle R. Hribar, Michael F. Chiang, Zhiyong Lu",
        "summary": "Timely disease diagnosis is challenging due to increasing disease burdens and limited clinician availability. AI shows promise in diagnosis accuracy but faces real-world application issues due to insufficient validation in clinical workflows and diverse populations. This study addresses gaps in medical AI downstream accountability through a case study on age-related macular degeneration (AMD) diagnosis and severity classification. We designed and implemented an AI-assisted diagnostic workflow for AMD, comparing diagnostic performance with and without AI assistance among 24 clinicians from 12 institutions with real patient data sampled from the Age-Related Eye Disease Study (AREDS). Additionally, we demonstrated continual enhancement of an existing AI model by incorporating approximately 40,000 additional medical images (named AREDS2 dataset). The improved model was then systematically evaluated using both AREDS and AREDS2 test sets, as well as an external test set from Singapore. AI assistance markedly enhanced diagnostic accuracy and classification for 23 out of 24 clinicians, with the average F1-score increasing by 20% from 37.71 (Manual) to 45.52 (Manual + AI) (P-value < 0.0001), achieving an improvement of over 50% in some cases. In terms of efficiency, AI assistance reduced diagnostic times for 17 out of the 19 clinicians tracked, with time savings of up to 40%. Furthermore, a model equipped with continual learning showed robust performance across three independent datasets, recording a 29% increase in accuracy, and elevating the F1-score from 42 to 54 in the Singapore population.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-23 15:01:09 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.049177"
    },
    {
        "index": "#147",
        "title": "ViBERTgrid BiLSTM-CRF: Multimodal Key Information Extraction from Unstructured Financial Documents",
        "link": "/arxiv/2409.15004",
        "arxiv_id": "2409.15004",
        "authors": "Furkan Pala, Mehmet Yasin Akpınar, Onur Deniz, Gülşen Eryiğit",
        "summary": "Multimodal key information extraction (KIE) models have been studied extensively on semi-structured documents. However, their investigation on unstructured documents is an emerging research topic. The paper presents an approach to adapt a multimodal transformer (i.e., ViBERTgrid previously explored on semi-structured documents) for unstructured financial documents, by incorporating a BiLSTM-CRF layer. The proposed ViBERTgrid BiLSTM-CRF model demonstrates a significant improvement in performance (up to 2 percentage points) on named entity recognition from unstructured documents in financial domain, while maintaining its KIE performance on semi-structured documents. As an additional contribution, we publicly released token-level annotations for the SROIE dataset in order to pave the way for its use in multimodal sequence labeling models.",
        "subjects": "Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Information Retrieval",
        "date": "2024-09-23 13:28:06 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.049436"
    },
    {
        "index": "#148",
        "title": "Multi-Modal Generative AI: Multi-modal LLM, Diffusion and Beyond",
        "link": "/arxiv/2409.14993",
        "arxiv_id": "2409.14993",
        "authors": "Hong Chen, Xin Wang, Yuwei Zhou, Bin Huang, Yipeng Zhang, Wei Feng, Houlun Chen, Zeyang Zhang, Siao Tang, Wenwu Zhu",
        "summary": "Multi-modal generative AI has received increasing attention in both academia and industry. Particularly, two dominant families of techniques are: i) The multi-modal large language model (MLLM) such as GPT-4V, which shows impressive ability for multi-modal understanding; ii) The diffusion model such as Sora, which exhibits remarkable multi-modal powers, especially with respect to visual generation. As such, one natural question arises: Is it possible to have a unified model for both understanding and generation? To answer this question, in this paper, we first provide a detailed review of both MLLM and diffusion models, including their probabilistic modeling procedure, multi-modal architecture design, and advanced applications to image/video large language models as well as text-to-image/video generation. Then, we discuss the two important questions on the unified model: i) whether the unified model should adopt the auto-regressive or diffusion probabilistic modeling, and ii) whether the model should utilize a dense architecture or the Mixture of Experts(MoE) architectures to better support generation and understanding, two objectives. We further provide several possible strategies for building a unified model and analyze their potential advantages and disadvantages. We also summarize existing large-scale multi-modal datasets for better model pretraining in the future. To conclude the paper, we present several challenging future directions, which we believe can contribute to the ongoing advancement of multi-modal generative AI.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 13:16:09 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.049676"
    },
    {
        "index": "#149",
        "title": "CON: Continual Object Navigation via Data-Free Inter-Agent Knowledge Transfer in Unseen and Unfamiliar Places",
        "link": "/arxiv/2409.14899",
        "arxiv_id": "2409.14899",
        "authors": "Kouki Terashima, Daiki Iwata, Kanji Tanaka",
        "summary": "This work explores the potential of brief inter-agent knowledge transfer (KT) to enhance the robotic object goal navigation (ON) in unseen and unfamiliar environments. Drawing on the analogy of human travelers acquiring local knowledge, we propose a framework in which a traveler robot (student) communicates with local robots (teachers) to obtain ON knowledge through minimal interactions. We frame this process as a data-free continual learning (CL) challenge, aiming to transfer knowledge from a black-box model (teacher) to a new model (student). In contrast to approaches like zero-shot ON using large language models (LLMs), which utilize inherently communication-friendly natural language for knowledge representation, the other two major ON approaches -- frontier-driven methods using object feature maps and learning-based ON using neural state-action maps -- present complex challenges where data-free KT remains largely uncharted. To address this gap, we propose a lightweight, plug-and-play KT module targeting non-cooperative black-box teachers in open-world settings. Using the universal assumption that every teacher robot has vision and mobility capabilities, we define state-action history as the primary knowledge base. Our formulation leads to the development of a query-based occupancy map that dynamically represents target object locations, serving as an effective and communication-friendly knowledge representation. We validate the effectiveness of our method through experiments conducted in the Habitat environment.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-23 10:50:11 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.049869"
    },
    {
        "index": "#150",
        "title": "Observe Then Act: Asynchronous Active Vision-Action Model for Robotic Manipulation",
        "link": "/arxiv/2409.14891",
        "arxiv_id": "2409.14891",
        "authors": "Guokang Wang, Hang Li, Shuyuan Zhang, Yanhong Liu, Huaping Liu",
        "summary": "In real-world scenarios, many robotic manipulation tasks are hindered by occlusions and limited fields of view, posing significant challenges for passive observation-based models that rely on fixed or wrist-mounted cameras. In this paper, we investigate the problem of robotic manipulation under limited visual observation and propose a task-driven asynchronous active vision-action model.Our model serially connects a camera Next-Best-View (NBV) policy with a gripper Next-Best Pose (NBP) policy, and trains them in a sensor-motor coordination framework using few-shot reinforcement learning. This approach allows the agent to adjust a third-person camera to actively observe the environment based on the task goal, and subsequently infer the appropriate manipulation actions.We trained and evaluated our model on 8 viewpoint-constrained tasks in RLBench. The results demonstrate that our model consistently outperforms baseline algorithms, showcasing its effectiveness in handling visual constraints in manipulation tasks.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 10:38:20 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.050064"
    },
    {
        "index": "#151",
        "title": "Towards Ground-truth-free Evaluation of Any Segmentation in Medical Images",
        "link": "/arxiv/2409.14874",
        "arxiv_id": "2409.14874",
        "authors": "Ahjol Senbi, Tianyu Huang, Fei Lyu, Qing Li, Yuhui Tao, Wei Shao, Qiang Chen, Chengyan Wang, Shuo Wang, Tao Zhou, Yizhe Zhang",
        "summary": "We are interested in building a ground-truth-free evaluation model to assess the quality of segmentations produced by SAM (Segment Anything Model) and its variants in medical images. This model estimates segmentation quality scores by comparing input images with their corresponding segmentation maps. Building on prior research, we frame this as a regression problem within a supervised learning framework, using Dice scores (and optionally other metrics) to compute the training loss. The model is trained using a large collection of public datasets of medical images with segmentation predictions from SAM and its variants. We name this model EvanySeg (Evaluation of Any Segmentation in Medical Images). Our exploration of convolution-based models (e.g., ResNet) and transformer-based models (e.g., ViT) revealed that ViT offers superior performance for EvanySeg. This model can be employed for various tasks, including: (1) identifying poorly segmented samples by detecting low-percentile segmentation quality scores; (2) benchmark segmentation models without ground truth by averaging scores across test samples; (3) alerting human experts during human-AI collaboration by applying a threshold within the score space; and (4) selecting the best segmentation prediction for each test sample at test time when multiple segmentation models are available, by choosing the prediction with the highest score. Models and code will be made available at https://github.com/ahjolsenbics/EvanySeg.",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-23 10:12:08 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.050307"
    },
    {
        "index": "#152",
        "title": "A-VL: Adaptive Attention for Large Vision-Language Models",
        "link": "/arxiv/2409.14846",
        "arxiv_id": "2409.14846",
        "authors": "Junyang Zhang, Mu Yuan, Ruiguang Zhong, Puhan Luo, Huiyou Zhan, Ningkang Zhang, Chengchen Hu, Xiangyang Li",
        "summary": "The Large Vision-Language Model (LVLM) integrates computer vision and natural language processing techniques, offering substantial application potential. However, these models demand extensive resources during inference. Adaptive attention techniques can dynamically reduce computational redundancy and thus improve efficiency. Although current adaptive attention methods significantly reduce the memory requirements of Transformer-based language models, they are not tailored for LVLMs. We observe that LVLMs generate responses from both remote image tokens and local text tokens, and different modalities have different attention patterns. This observation inspires us to manage the attention for each modality separately. Specifically, for visual input, we store the cache of potentially useful information but only compute the most critical parts. For language input, we care more about local information. Based on our observation and analysis of vision-language attention patterns, we develop A-VL, a plug-and-play adaptive attention tailored for LVLM inference. Extensive evaluations on three vision-language tasks and five datasets show the effectiveness of our designs. Our approach A-VL outperforms existing adaptive attention methods in reducing memory usage and computational load without compromising performance.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 09:22:59 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.050520"
    },
    {
        "index": "#153",
        "title": "RoWSFormer: A Robust Watermarking Framework with Swin Transformer for Enhanced Geometric Attack Resilience",
        "link": "/arxiv/2409.14829",
        "arxiv_id": "2409.14829",
        "authors": "Weitong Chen, Yuheng Li",
        "summary": "In recent years, digital watermarking techniques based on deep learning have been widely studied. To achieve both imperceptibility and robustness of image watermarks, most current methods employ convolutional neural networks to build robust watermarking frameworks. However, despite the success of CNN-based watermarking models, they struggle to achieve robustness against geometric attacks due to the limitations of convolutional neural networks in capturing global and long-range relationships. To address this limitation, we propose a robust watermarking framework based on the Swin Transformer, named RoWSFormer. Specifically, we design the Locally-Channel Enhanced Swin Transformer Block as the core of both the encoder and decoder. This block utilizes the self-attention mechanism to capture global and long-range information, thereby significantly improving adaptation to geometric distortions. Additionally, we construct the Frequency-Enhanced Transformer Block to extract frequency domain information, which further strengthens the robustness of the watermarking framework. Experimental results demonstrate that our RoWSFormer surpasses existing state-of-the-art watermarking methods. For most non-geometric attacks, RoWSFormer improves the PSNR by 3 dB while maintaining the same extraction accuracy. In the case of geometric attacks (such as rotation, scaling, and affine transformations), RoWSFormer achieves over a 6 dB improvement in PSNR, with extraction accuracy exceeding 97\\%.",
        "subjects": "Multimedia, Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2024-09-23 08:59:55 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.050701"
    },
    {
        "index": "#154",
        "title": "Towards Efficient and Robust VQA-NLE Data Generation with Large Vision-Language Models",
        "link": "/arxiv/2409.14785",
        "arxiv_id": "2409.14785",
        "authors": "Patrick Amadeus Irawan, Genta Indra Winata, Samuel Cahyawijaya, Ayu Purwarianti",
        "summary": "Natural Language Explanation (NLE) aims to elucidate the decision-making process by providing detailed, human-friendly explanations in natural language. It helps demystify the decision-making processes of large vision-language models (LVLMs) through the use of language models. While existing methods for creating a Vision Question-Answering with Natural Language Explanation (VQA-NLE) datasets can provide explanations, they heavily rely on human annotations that are time-consuming and costly. In this study, we propose a novel approach that leverages LVLMs to efficiently generate high-quality synthetic VQA-NLE datasets. By evaluating our synthetic data, we showcase how advanced prompting techniques can lead to the production of high-quality VQA-NLE data. Our findings indicate that this proposed method achieves up to 20x faster than human annotation, with only a minimal decrease in qualitative metrics, achieving robust quality that is nearly equivalent to human-annotated data. Furthermore, we show that incorporating visual prompts significantly enhances the relevance of text generation. Our study paves the way for a more efficient and robust automated generation of multi-modal NLE data, offering a promising solution to the problem.",
        "subjects": "Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 07:59:50 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.050884"
    },
    {
        "index": "#155",
        "title": "TransUKAN:Computing-Efficient Hybrid KAN-Transformer for Enhanced Medical Image Segmentation",
        "link": "/arxiv/2409.14676",
        "arxiv_id": "2409.14676",
        "authors": "Yanlin Wu, Tao Li, Zhihong Wang, Hong Kang, Along He",
        "summary": "U-Net is currently the most widely used architecture for medical image segmentation. Benefiting from its unique encoder-decoder architecture and skip connections, it can effectively extract features from input images to segment target regions. The commonly used U-Net is typically based on convolutional operations or Transformers, modeling the dependencies between local or global information to accomplish medical image analysis tasks. However, convolutional layers, fully connected layers, and attention mechanisms used in this process introduce a significant number of parameters, often requiring the stacking of network layers to model complex nonlinear relationships, which can impact the training process. To address these issues, we propose TransUKAN. Specifically, we have improved the KAN to reduce memory usage and computational load. On this basis, we explored an effective combination of KAN, Transformer, and U-Net structures. This approach enhances the model's capability to capture nonlinear relationships by introducing only a small number of additional parameters and compensates for the Transformer structure's deficiency in local information extraction. We validated TransUKAN on multiple medical image segmentation tasks. Experimental results demonstrate that TransUKAN achieves excellent performance with significantly reduced parameters. The code will be available athttps://github.com/wuyanlin-wyl/TransUKAN.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 02:52:49 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.051078"
    },
    {
        "index": "#156",
        "title": "RACER: Rich Language-Guided Failure Recovery Policies for Imitation Learning",
        "link": "/arxiv/2409.14674",
        "arxiv_id": "2409.14674",
        "authors": "Yinpei Dai, Jayjun Lee, Nima Fazeli, Joyce Chai",
        "summary": "Developing robust and correctable visuomotor policies for robotic manipulation is challenging due to the lack of self-recovery mechanisms from failures and the limitations of simple language instructions in guiding robot actions. To address these issues, we propose a scalable data generation pipeline that automatically augments expert demonstrations with failure recovery trajectories and fine-grained language annotations for training. We then introduce Rich languAge-guided failure reCovERy (RACER), a supervisor-actor framework, which combines failure recovery data with rich language descriptions to enhance robot control. RACER features a vision-language model (VLM) that acts as an online supervisor, providing detailed language guidance for error correction and task execution, and a language-conditioned visuomotor policy as an actor to predict the next actions. Our experimental results show that RACER outperforms the state-of-the-art Robotic View Transformer (RVT) on RLbench across various evaluation settings, including standard long-horizon tasks, dynamic goal-change tasks and zero-shot unseen tasks, achieving superior performance in both simulated and real world environments. Videos and code are available at: https://rich-language-failure-recovery.github.io.",
        "subjects": "Robotics, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 02:50:33 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.051292"
    },
    {
        "index": "#157",
        "title": "FedGCA: Global Consistent Augmentation Based Single-Source Federated Domain Generalization",
        "link": "/arxiv/2409.14671",
        "arxiv_id": "2409.14671",
        "authors": "Yuan Liu, Shu Wang, Zhe Qu, Xingyu Li, Shichao Kan, Jianxin Wang",
        "summary": "Federated Domain Generalization (FedDG) aims to train the global model for generalization ability to unseen domains with multi-domain training samples. However, clients in federated learning networks are often confined to a single, non-IID domain due to inherent sampling and temporal limitations. The lack of cross-domain interaction and the in-domain divergence impede the learning of domain-common features and limit the effectiveness of existing FedDG, referred to as the single-source FedDG (sFedDG) problem. To address this, we introduce the Federated Global Consistent Augmentation (FedGCA) method, which incorporates a style-complement module to augment data samples with diverse domain styles. To ensure the effective integration of augmented samples, FedGCA employs both global guided semantic consistency and class consistency, mitigating inconsistencies from local semantics within individual clients and classes across multiple clients. The conducted extensive experiments demonstrate the superiority of FedGCA.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-23 02:24:46 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.051562"
    },
    {
        "index": "#158",
        "title": "RobotFingerPrint: Unified Gripper Coordinate Space for Multi-Gripper Grasp Synthesis",
        "link": "/arxiv/2409.14519",
        "arxiv_id": "2409.14519",
        "authors": "Ninad Khargonkar, Luis Felipe Casas, Balakrishnan Prabhakaran, Yu Xiang",
        "summary": "We introduce a novel representation named as the unified gripper coordinate space for grasp synthesis of multiple grippers. The space is a 2D surface of a sphere in 3D using longitude and latitude as its coordinates, and it is shared for all robotic grippers. We propose a new algorithm to map the palm surface of a gripper into the unified gripper coordinate space, and design a conditional variational autoencoder to predict the unified gripper coordinates given an input object. The predicted unified gripper coordinates establish correspondences between the gripper and the object, which can be used in an optimization problem to solve the grasp pose and the finger joints for grasp synthesis. We demonstrate that using the unified gripper coordinate space improves the success rate and diversity in the grasp synthesis of multiple grippers.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-22 16:25:31 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.051775"
    },
    {
        "index": "#159",
        "title": "SPAQ-DL-SLAM: Towards Optimizing Deep Learning-based SLAM for Resource-Constrained Embedded Platforms",
        "link": "/arxiv/2409.14515",
        "arxiv_id": "2409.14515",
        "authors": "Niraj Pudasaini, Muhammad Abdullah Hanif, Muhammad Shafique",
        "summary": "Optimizing Deep Learning-based Simultaneous Localization and Mapping (DL-SLAM) algorithms is essential for efficient implementation on resource-constrained embedded platforms, enabling real-time on-board computation in autonomous mobile robots. This paper presents SPAQ-DL-SLAM, a framework that strategically applies Structured Pruning and Quantization (SPAQ) to the architecture of one of the state-ofthe-art DL-SLAM algorithms, DROID-SLAM, for resource and energy-efficiency. Specifically, we perform structured pruning with fine-tuning based on layer-wise sensitivity analysis followed by 8-bit post-training static quantization (PTQ) on the deep learning modules within DROID-SLAM. Our SPAQ-DROIDSLAM model, optimized version of DROID-SLAM model using our SPAQ-DL-SLAM framework with 20% structured pruning and 8-bit PTQ, achieves an 18.9% reduction in FLOPs and a 79.8% reduction in overall model size compared to the DROID-SLAM model. Our evaluations on the TUM-RGBD benchmark shows that SPAQ-DROID-SLAM model surpasses the DROID-SLAM model by an average of 10.5% on absolute trajectory error (ATE) metric. Additionally, our results on the ETH3D SLAM training benchmark demonstrate enhanced generalization capabilities of the SPAQ-DROID-SLAM model, seen by a higher Area Under the Curve (AUC) score and success in 2 additional data sequences compared to the DROIDSLAM model. Despite these improvements, the model exhibits performance variance on the distinct Vicon Room sequences from the EuRoC dataset, which are captured at high angular velocities. This varying performance at some distinct scenarios suggests that designing DL-SLAM algorithms taking operating environments and tasks in consideration can achieve optimal performance and resource efficiency for deployment in resource-constrained embedded platforms.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-22 16:19:47 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.114103"
    },
    {
        "index": "#160",
        "title": "Lesion Segmentation in Whole-Body Multi-Tracer PET-CT Images; a Contribution to AutoPET 2024 Challenge",
        "link": "/arxiv/2409.14475",
        "arxiv_id": "2409.14475",
        "authors": "Mehdi Astaraki, Simone Bendazzoli",
        "summary": "The automatic segmentation of pathological regions within whole-body PET-CT volumes has the potential to streamline various clinical applications such as diagno-sis, prognosis, and treatment planning. This study aims to address this challenge by contributing to the AutoPET MICCAI 2024 challenge through a proposed workflow that incorporates image preprocessing, tracer classification, and lesion segmentation steps. The implementation of this pipeline led to a significant enhancement in the segmentation accuracy of the models. This improvement is evidenced by an average overall Dice score of 0.548 across 1611 training subjects, 0.631 and 0.559 for classi-fied FDG and PSMA subjects of the training set, and 0.792 on the preliminary testing phase dataset.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-22 14:50:46 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.228970"
    },
    {
        "index": "#161",
        "title": "Detection of pulmonary pathologies using convolutional neural networks, Data Augmentation, ResNet50 and Vision Transformers",
        "link": "/arxiv/2409.14446",
        "arxiv_id": "2409.14446",
        "authors": "Pablo Ramirez Amador, Dinarle Milagro Ortega, Arnold Cesarano",
        "summary": "Pulmonary diseases are a public health problem that requires accurate and fast diagnostic techniques. In this paper, a method based on convolutional neural networks (CNN), Data Augmentation, ResNet50 and Vision Transformers (ViT) is proposed to detect lung pathologies from medical images. A dataset of X-ray images and CT scans of patients with different lung diseases, such as cancer, pneumonia, tuberculosis and fibrosis, is used. The results obtained by the proposed method are compared with those of other existing methods, using performance metrics such as accuracy, sensitivity, specificity and area under the ROC curve. The results show that the proposed method outperforms the other methods in all metrics, achieving an accuracy of 98% and an area under the ROC curve of 99%. It is concluded that the proposed method is an effective and promising tool for the diagnosis of pulmonary pathologies by medical imaging.",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-22 13:54:28 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.229207"
    },
    {
        "index": "#162",
        "title": "Dormant: Defending against Pose-driven Human Image Animation",
        "link": "/arxiv/2409.14424",
        "arxiv_id": "2409.14424",
        "authors": "Jiachen Zhou, Mingsi Wang, Tianlin Li, Guozhu Meng, Kai Chen",
        "summary": "Pose-driven human image animation has achieved tremendous progress, enabling the generation of vivid and realistic human videos from just one single photo. However, it conversely exacerbates the risk of image misuse, as attackers may use one available image to create videos involving politics, violence and other illegal content. To counter this threat, we propose Dormant, a novel protection approach tailored to defend against pose-driven human image animation techniques. Dormant applies protective perturbation to one human image, preserving the visual similarity to the original but resulting in poor-quality video generation. The protective perturbation is optimized to induce misextraction of appearance features from the image and create incoherence among the generated video frames. Our extensive evaluation across 8 animation methods and 4 datasets demonstrates the superiority of Dormant over 6 baseline protection methods, leading to misaligned identities, visual distortions, noticeable artifacts, and inconsistent frames in the generated videos. Moreover, Dormant shows effectiveness on 6 real-world commercial services, even with fully black-box access.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-22 12:51:32 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.229421"
    },
    {
        "index": "#163",
        "title": "GraspMamba: A Mamba-based Language-driven Grasp Detection Framework with Hierarchical Feature Learning",
        "link": "/arxiv/2409.14403",
        "arxiv_id": "2409.14403",
        "authors": "Huy Hoang Nguyen, An Vuong, Anh Nguyen, Ian Reid, Minh Nhat Vu",
        "summary": "Grasp detection is a fundamental robotic task critical to the success of many industrial applications. However, current language-driven models for this task often struggle with cluttered images, lengthy textual descriptions, or slow inference speed. We introduce GraspMamba, a new language-driven grasp detection method that employs hierarchical feature fusion with Mamba vision to tackle these challenges. By leveraging rich visual features of the Mamba-based backbone alongside textual information, our approach effectively enhances the fusion of multimodal features. GraspMamba represents the first Mamba-based grasp detection model to extract vision and language features at multiple scales, delivering robust performance and rapid inference time. Intensive experiments show that GraspMamba outperforms recent methods by a clear margin. We validate our approach through real-world robotic experiments, highlighting its fast inference speed.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition",
        "date": "2024-09-22 11:45:48 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.229621"
    },
    {
        "index": "#164",
        "title": "Frequency-regularized Neural Representation Method for Sparse-view Tomographic Reconstruction",
        "link": "/arxiv/2409.14394",
        "arxiv_id": "2409.14394",
        "authors": "Jingmou Xian, Jian Zhu, Haolin Liao, Si Li",
        "summary": "Sparse-view tomographic reconstruction is a pivotal direction for reducing radiation dose and augmenting clinical applicability. While many research works have proposed the reconstruction of tomographic images from sparse 2D projections, existing models tend to excessively focus on high-frequency information while overlooking low-frequency components within the sparse input images. This bias towards high-frequency information often leads to overfitting, particularly intense at edges and boundaries in the reconstructed slices. In this paper, we introduce the Frequency Regularized Neural Attenuation/Activity Field (Freq-NAF) for self-supervised sparse-view tomographic reconstruction. Freq-NAF mitigates overfitting by incorporating frequency regularization, directly controlling the visible frequency bands in the neural network input. This approach effectively balances high-frequency and low-frequency information. We conducted numerical experiments on CBCT and SPECT datasets, and our method demonstrates state-of-the-art accuracy.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-22 11:19:38 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.229816"
    },
    {
        "index": "#165",
        "title": "Thinking in Granularity: Dynamic Quantization for Image Super-Resolution by Intriguing Multi-Granularity Clues",
        "link": "/arxiv/2409.14330",
        "arxiv_id": "2409.14330",
        "authors": "Mingshen Wang, Zhao Zhang, Feng Li, Ke Xu, Kang Miao, Meng Wang",
        "summary": "Dynamic quantization has attracted rising attention in image super-resolution (SR) as it expands the potential of heavy SR models onto mobile devices while preserving competitive performance. Existing methods explore layer-to-bit configuration upon varying local regions, adaptively allocating the bit to each layer and patch. Despite the benefits, they still fall short in the trade-off of SR accuracy and quantization efficiency. Apart from this, adapting the quantization level for each layer individually can disturb the original inter-layer relationships, thus diminishing the representation capability of quantized models. In this work, we propose Granular-DQ, which capitalizes on the intrinsic characteristics of images while dispensing with the previous consideration for layer sensitivity in quantization. Granular-DQ conducts a multi-granularity analysis of local patches with further exploration of their information densities, achieving a distinctive patch-wise and layer-invariant dynamic quantization paradigm. Specifically, Granular-DQ initiates by developing a granularity-bit controller (GBC) to apprehend the coarse-to-fine granular representations of different patches, matching their proportional contribution to the entire image to determine the proper bit-width allocation. On this premise, we investigate the relation between bit-width and information density, devising an entropy-to-bit (E2B) mechanism that enables further fine-grained dynamic bit adaption of high-bit patches. Extensive experiments validate the superiority and generalization ability of Granular-DQ over recent state-of-the-art methods on various SR models. Code will be available at \\url{https://github.com/MmmingS/Granular-DQ.git}.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-22 06:29:54 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.230098"
    },
    {
        "index": "#166",
        "title": "Can-Do! A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning with Large Multimodal Models",
        "link": "/arxiv/2409.14277",
        "arxiv_id": "2409.14277",
        "authors": "Yew Ken Chia, Qi Sun, Lidong Bing, Soujanya Poria",
        "summary": "Large multimodal models have demonstrated impressive problem-solving abilities in vision and language tasks, and have the potential to encode extensive world knowledge. However, it remains an open challenge for these models to perceive, reason, plan, and act in realistic environments. In this work, we introduce Can-Do, a benchmark dataset designed to evaluate embodied planning abilities through more diverse and complex scenarios than previous datasets. Our dataset includes 400 multimodal samples, each consisting of natural language user instructions, visual images depicting the environment, state changes, and corresponding action plans. The data encompasses diverse aspects of commonsense knowledge, physical understanding, and safety awareness. Our fine-grained analysis reveals that state-of-the-art models, including GPT-4V, face bottlenecks in visual perception, comprehension, and reasoning abilities. To address these challenges, we propose NeuroGround, a neurosymbolic framework that first grounds the plan generation in the perceived environment states and then leverages symbolic planning engines to augment the model-generated plans. Experimental results demonstrate the effectiveness of our framework compared to strong baselines. Our code and dataset are available at https://embodied-planning.github.io.",
        "subjects": "Artificial Intelligence, Computation and Language, Computer Vision and Pattern Recognition, Robotics",
        "date": "2024-09-22 00:30:11 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.230358"
    },
    {
        "index": "#167",
        "title": "FeDETR: a Federated Approach for Stenosis Detection in Coronary Angiography",
        "link": "/arxiv/2409.14268",
        "arxiv_id": "2409.14268",
        "authors": "Raffaele Mineo, Amelia Sorrenti, Federica Proietto Salanitri",
        "summary": "Assessing the severity of stenoses in coronary angiography is critical to the patient's health, as coronary stenosis is an underlying factor in heart failure. Current practice for grading coronary lesions, i.e. fractional flow reserve (FFR) or instantaneous wave-free ratio (iFR), suffers from several drawbacks, including time, cost and invasiveness, alongside potential interobserver variability. In this context, some deep learning methods have emerged to assist cardiologists in automating the estimation of FFR/iFR values. Despite the effectiveness of these methods, their reliance on large datasets is challenging due to the distributed nature of sensitive medical data. Federated learning addresses this challenge by aggregating knowledge from multiple nodes to improve model generalization, while preserving data privacy. We propose the first federated detection transformer approach, FeDETR, to assess stenosis severity in angiography videos based on FFR/iFR values estimation. In our approach, each node trains a detection transformer (DETR) on its local dataset, with the central server federating the backbone part of the network. The proposed method is trained and evaluated on a dataset collected from five hospitals, consisting of 1001 angiographic examinations, and its performance is compared with state-of-the-art federated learning methods.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-21 23:52:05 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.230574"
    },
    {
        "index": "#168",
        "title": "R-AIF: Solving Sparse-Reward Robotic Tasks from Pixels with Active Inference and World Models",
        "link": "/arxiv/2409.14216",
        "arxiv_id": "2409.14216",
        "authors": "Viet Dung Nguyen, Zhizhuo Yang, Christopher L. Buckley, Alexander Ororbia",
        "summary": "Although research has produced promising results demonstrating the utility of active inference (AIF) in Markov decision processes (MDPs), there is relatively less work that builds AIF models in the context of environments and problems that take the form of partially observable Markov decision processes (POMDPs). In POMDP scenarios, the agent must infer the unobserved environmental state from raw sensory observations, e.g., pixels in an image. Additionally, less work exists in examining the most difficult form of POMDP-centered control: continuous action space POMDPs under sparse reward signals. In this work, we address issues facing the AIF modeling paradigm by introducing novel prior preference learning techniques and self-revision schedules to help the agent excel in sparse-reward, continuous action, goal-based robotic control POMDP environments. Empirically, we show that our agents offer improved performance over state-of-the-art models in terms of cumulative rewards, relative stability, and success rate. The code in support of this work can be found at https://github.com/NACLab/robust-active-inference.",
        "subjects": "Robotics, Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-21 18:32:44 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.230791"
    },
    {
        "index": "#169",
        "title": "UniMo: Universal Motion Correction For Medical Images without Network Retraining",
        "link": "/arxiv/2409.14204",
        "arxiv_id": "2409.14204",
        "authors": "Jian Wang, Razieh Faghihpirayesh, Danny Joca, Polina Golland, Ali Gholipour",
        "summary": "In this paper, we introduce a Universal Motion Correction (UniMo) framework, leveraging deep neural networks to tackle the challenges of motion correction across diverse imaging modalities. Our approach employs advanced neural network architectures with equivariant filters, overcoming the limitations of current models that require iterative inference or retraining for new image modalities. UniMo enables one-time training on a single modality while maintaining high stability and adaptability for inference across multiple unseen image modalities. We developed a joint learning framework that integrates multimodal knowledge from both shape and images that faithfully improve motion correction accuracy despite image appearance variations. UniMo features a geometric deformation augmenter that enhances the robustness of global motion correction by addressing any local deformations whether they are caused by object deformations or geometric distortions, and also generates augmented data to improve the training process. Our experimental results, conducted on various datasets with four different image modalities, demonstrate that UniMo surpasses existing motion correction methods in terms of accuracy. By offering a comprehensive solution to motion correction, UniMo marks a significant advancement in medical imaging, especially in challenging applications with wide ranges of motion, such as fetal imaging. The code for this work is available online, https://github.com/IntelligentImaging/UNIMO/.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-21 17:36:11 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.231050"
    },
    {
        "index": "#170",
        "title": "A Sinkhorn Regularized Adversarial Network for Image Guided DEM Super-resolution using Frequency Selective Hybrid Graph Transformer",
        "link": "/arxiv/2409.14198",
        "arxiv_id": "2409.14198",
        "authors": "Subhajit Paul, Ashutosh Gupta",
        "summary": "Digital Elevation Model (DEM) is an essential aspect in the remote sensing (RS) domain to analyze various applications related to surface elevations. Here, we address the generation of high-resolution (HR) DEMs using HR multi-spectral (MX) satellite imagery as a guide by introducing a novel hybrid transformer model consisting of Densely connected Multi-Residual Block (DMRB) and multi-headed Frequency Selective Graph Attention (M-FSGA). To promptly regulate this process, we utilize the notion of discriminator spatial maps as the conditional attention to the MX guide. Further, we present a novel adversarial objective related to optimizing Sinkhorn distance with classical GAN. In this regard, we provide both theoretical and empirical substantiation of better performance in terms of vanishing gradient issues and numerical convergence. Based on our experiments on 4 different DEM datasets, we demonstrate both qualitative and quantitative comparisons with available baseline methods and show that the performance of our proposed model is superior to others with sharper details and minimal errors.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-21 16:59:08 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.231241"
    },
    {
        "index": "#171",
        "title": "Accelerated Multi-Contrast MRI Reconstruction via Frequency and Spatial Mutual Learning",
        "link": "/arxiv/2409.14113",
        "arxiv_id": "2409.14113",
        "authors": "Qi Chen, Xiaohan Xing, Zhen Chen, Zhiwei Xiong",
        "summary": "To accelerate Magnetic Resonance (MR) imaging procedures, Multi-Contrast MR Reconstruction (MCMR) has become a prevalent trend that utilizes an easily obtainable modality as an auxiliary to support high-quality reconstruction of the target modality with under-sampled k-space measurements. The exploration of global dependency and complementary information across different modalities is essential for MCMR. However, existing methods either struggle to capture global dependency due to the limited receptive field or suffer from quadratic computational complexity. To tackle this dilemma, we propose a novel Frequency and Spatial Mutual Learning Network (FSMNet), which efficiently explores global dependencies across different modalities. Specifically, the features for each modality are extracted by the Frequency-Spatial Feature Extraction (FSFE) module, featuring a frequency branch and a spatial branch. Benefiting from the global property of the Fourier transform, the frequency branch can efficiently capture global dependency with an image-size receptive field, while the spatial branch can extract local features. To exploit complementary information from the auxiliary modality, we propose a Cross-Modal Selective fusion (CMS-fusion) module that selectively incorporate the frequency and spatial features from the auxiliary modality to enhance the corresponding branch of the target modality. To further integrate the enhanced global features from the frequency branch and the enhanced local features from the spatial branch, we develop a Frequency-Spatial fusion (FS-fusion) module, resulting in a comprehensive feature representation for the target modality. Extensive experiments on the BraTS and fastMRI datasets demonstrate that the proposed FSMNet achieves state-of-the-art performance for the MCMR task with different acceleration factors. The code is available at: https://github.com/qic999/FSMNet.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-21 12:02:47 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.231440"
    },
    {
        "index": "#172",
        "title": "Window-based Channel Attention for Wavelet-enhanced Learned Image Compression",
        "link": "/arxiv/2409.14090",
        "arxiv_id": "2409.14090",
        "authors": "Heng Xu, Bowen Hai, Yushun Tang, Zhihai He",
        "summary": "Learned Image Compression (LIC) models have achieved superior rate-distortion performance than traditional codecs. Existing LIC models use CNN, Transformer, or Mixed CNN-Transformer as basic blocks. However, limited by the shifted window attention, Swin-Transformer-based LIC exhibits a restricted growth of receptive fields, affecting the ability to model large objects in the image. To address this issue, we incorporate window partition into channel attention for the first time to obtain large receptive fields and capture more global information. Since channel attention hinders local information learning, it is important to extend existing attention mechanisms in Transformer codecs to the space-channel attention to establish multiple receptive fields, being able to capture global correlations with large receptive fields while maintaining detailed characterization of local correlations with small receptive fields. We also incorporate the discrete wavelet transform into our Spatial-Channel Hybrid (SCH) framework for efficient frequency-dependent down-sampling and further enlarging receptive fields. Experiment results demonstrate that our method achieves state-of-the-art performances, reducing BD-rate by 18.54%, 23.98%, 22.33%, and 24.71% on four standard datasets compared to VTM-23.1.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-21 10:08:52 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.231637"
    },
    {
        "index": "#173",
        "title": "Recovering Global Data Distribution Locally in Federated Learning",
        "link": "/arxiv/2409.14063",
        "arxiv_id": "2409.14063",
        "authors": "Ziyu Yao",
        "summary": "Federated Learning (FL) is a distributed machine learning paradigm that enables collaboration among multiple clients to train a shared model without sharing raw data. However, a major challenge in FL is the label imbalance, where clients may exclusively possess certain classes while having numerous minority and missing classes. Previous works focus on optimizing local updates or global aggregation but ignore the underlying imbalanced label distribution across clients. In this paper, we propose a novel approach ReGL to address this challenge, whose key idea is to Recover the Global data distribution Locally. Specifically, each client uses generative models to synthesize images that complement the minority and missing classes, thereby alleviating label imbalance. Moreover, we adaptively fine-tune the image generation process using local real data, which makes the synthetic images align more closely with the global distribution. Importantly, both the generation and fine-tuning processes are conducted at the client-side without leaking data privacy. Through comprehensive experiments on various image classification datasets, we demonstrate the remarkable superiority of our approach over existing state-of-the-art works in fundamentally tackling label imbalance in FL.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2024-09-21 08:35:04 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.231816"
    },
    {
        "index": "#174",
        "title": "ECHO: Environmental Sound Classification with Hierarchical Ontology-guided Semi-Supervised Learning",
        "link": "/arxiv/2409.14043",
        "arxiv_id": "2409.14043",
        "authors": "Pranav Gupta, Raunak Sharma, Rashmi Kumari, Sri Krishna Aditya, Shwetank Choudhary, Sumit Kumar, Kanchana M, Thilagavathy R",
        "summary": "Environment Sound Classification has been a well-studied research problem in the field of signal processing and up till now more focus has been laid on fully supervised approaches. Over the last few years, focus has moved towards semi-supervised methods which concentrate on the utilization of unlabeled data, and self-supervised methods which learn the intermediate representation through pretext task or contrastive learning. However, both approaches require a vast amount of unlabelled data to improve performance. In this work, we propose a novel framework called Environmental Sound Classification with Hierarchical Ontology-guided semi-supervised Learning (ECHO) that utilizes label ontology-based hierarchy to learn semantic representation by defining a novel pretext task. In the pretext task, the model tries to predict coarse labels defined by the Large Language Model (LLM) based on ground truth label ontology. The trained model is further fine-tuned in a supervised way to predict the actual task. Our proposed novel semi-supervised framework achieves an accuracy improvement in the range of 1\\% to 8\\% over baseline systems across three datasets namely UrbanSound8K, ESC-10, and ESC-50.",
        "subjects": "Sound, Computer Vision and Pattern Recognition, Audio and Speech Processing",
        "date": "2024-09-21 07:08:57 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.232046"
    },
    {
        "index": "#175",
        "title": "MSDet: Receptive Field Enhanced Multiscale Detection for Tiny Pulmonary Nodule",
        "link": "/arxiv/2409.14028",
        "arxiv_id": "2409.14028",
        "authors": "Guohui Cai, Ying Cai, Zeyu Zhang, Daji Ergu, Yuanzhouhan Cao, Binbin Hu, Zhibin Liao, Yang Zhao",
        "summary": "Pulmonary nodules are critical indicators for the early diagnosis of lung cancer, making their detection essential for timely treatment. However, traditional CT imaging methods suffered from cumbersome procedures, low detection rates, and poor localization accuracy. The subtle differences between pulmonary nodules and surrounding tissues in complex lung CT images, combined with repeated downsampling in feature extraction networks, often lead to missed or false detections of small nodules. Existing methods such as FPN, with its fixed feature fusion and limited receptive field, struggle to effectively overcome these issues. To address these challenges, our paper proposed three key contributions: Firstly, we proposed MSDet, a multiscale attention and receptive field network for detecting tiny pulmonary nodules. Secondly, we proposed the extended receptive domain (ERD) strategy to capture richer contextual information and reduce false positives caused by nodule occlusion. We also proposed the position channel attention mechanism (PCAM) to optimize feature learning and reduce multiscale detection errors, and designed the tiny object detection block (TODB) to enhance the detection of tiny nodules. Lastly, we conducted thorough experiments on the public LUNA16 dataset, achieving state-of-the-art performance, with an mAP improvement of 8.8% over the previous state-of-the-art method YOLOv8. These advancements significantly boosted detection accuracy and reliability, providing a more effective solution for early lung cancer diagnosis. The code will be available at https://github.com/CaiGuoHui123/MSDet",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-21 06:08:23 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.232273"
    },
    {
        "index": "#176",
        "title": "Simple Unsupervised Knowledge Distillation With Space Similarity",
        "link": "/arxiv/2409.13939",
        "arxiv_id": "2409.13939",
        "authors": "Aditya Singh, Haohan Wang",
        "summary": "As per recent studies, Self-supervised learning (SSL) does not readily extend to smaller architectures. One direction to mitigate this shortcoming while simultaneously training a smaller network without labels is to adopt unsupervised knowledge distillation (UKD). Existing UKD approaches handcraft preservation worthy inter/intra sample relationships between the teacher and its student. However, this may overlook/ignore other key relationships present in the mapping of a teacher. In this paper, instead of heuristically constructing preservation worthy relationships between samples, we directly motivate the student to model the teacher's embedding manifold. If the mapped manifold is similar, all inter/intra sample relationships are indirectly conserved. We first demonstrate that prior methods cannot preserve teacher's latent manifold due to their sole reliance on $L_2$ normalised embedding features. Subsequently, we propose a simple objective to capture the lost information due to normalisation. Our proposed loss component, termed \\textbf{space similarity}, motivates each dimension of a student's feature space to be similar to the corresponding dimension of its teacher. We perform extensive experiments demonstrating strong performance of our proposed approach on various benchmarks.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-20 22:54:39 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.232501"
    },
    {
        "index": "#177",
        "title": "RN-SDEs: Limited-Angle CT Reconstruction with Residual Null-Space Diffusion Stochastic Differential Equations",
        "link": "/arxiv/2409.13930",
        "arxiv_id": "2409.13930",
        "authors": "Jiaqi Guo, Santiago Lopez-Tapia, Wing Shun Li, Yunnan Wu, Marcelo Carignano, Vadim Backman, Vinayak P. Dravid, Aggelos K. Katsaggelos",
        "summary": "Computed tomography is a widely used imaging modality with applications ranging from medical imaging to material analysis. One major challenge arises from the lack of scanning information at certain angles, leading to distorted CT images with artifacts. This results in an ill-posed problem known as the Limited Angle Computed Tomography (LACT) reconstruction problem. To address this problem, we propose Residual Null-Space Diffusion Stochastic Differential Equations (RN-SDEs), which are a variant of diffusion models that characterize the diffusion process with mean-reverting (MR) stochastic differential equations. To demonstrate the generalizability of RN-SDEs, our experiments are conducted on two different LACT datasets, i.e., ChromSTEM and C4KC-KiTS. Through extensive experiments, we show that by leveraging learned Mean-Reverting SDEs as a prior and emphasizing data consistency using Range-Null Space Decomposition (RNSD) based rectification, RN-SDEs can restore high-quality images from severe degradation and achieve state-of-the-art performance in most LACT tasks. Additionally, we present a quantitative comparison of computational complexity and runtime efficiency, highlighting the superior effectiveness of our proposed approach.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-20 22:33:36 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.232733"
    },
    {
        "index": "#178",
        "title": "Learning to Play Video Games with Intuitive Physics Priors",
        "link": "/arxiv/2409.13886",
        "arxiv_id": "2409.13886",
        "authors": "Abhishek Jaiswal, Nisheeth Srivastava",
        "summary": "Video game playing is an extremely structured domain where algorithmic decision-making can be tested without adverse real-world consequences. While prevailing methods rely on image inputs to avoid the problem of hand-crafting state space representations, this approach systematically diverges from the way humans actually learn to play games. In this paper, we design object-based input representations that generalize well across a number of video games. Using these representations, we evaluate an agent's ability to learn games similar to an infant - with limited world experience, employing simple inductive biases derived from intuitive representations of physics from the real world. Using such biases, we construct an object category representation to be used by a Q-learning algorithm and assess how well it learns to play multiple games based on observed object affordances. Our results suggest that a human-like object interaction setup capably learns to play several video games, and demonstrates superior generalizability, particularly for unfamiliar objects. Further exploring such methods will allow machines to learn in a human-centric way, thus incorporating more human-like learning benefits.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-20 20:30:27 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.232989"
    },
    {
        "index": "#179",
        "title": "Deep Learning-Based Channel Squeeze U-Structure for Lung Nodule Detection and Segmentation",
        "link": "/arxiv/2409.13868",
        "arxiv_id": "2409.13868",
        "authors": "Mingxiu Sui, Jiacheng Hu, Tong Zhou, Zibo Liu, Likang Wen, Junliang Du",
        "summary": "This paper introduces a novel deep-learning method for the automatic detection and segmentation of lung nodules, aimed at advancing the accuracy of early-stage lung cancer diagnosis. The proposed approach leverages a unique \"Channel Squeeze U-Structure\" that optimizes feature extraction and information integration across multiple semantic levels of the network. This architecture includes three key modules: shallow information processing, channel residual structure, and channel squeeze integration. These modules enhance the model's ability to detect and segment small, imperceptible, or ground-glass nodules, which are critical for early diagnosis. The method demonstrates superior performance in terms of sensitivity, Dice similarity coefficient, precision, and mean Intersection over Union (IoU). Extensive experiments were conducted on the Lung Image Database Consortium (LIDC) dataset using five-fold cross-validation, showing excellent stability and robustness. The results indicate that this approach holds significant potential for improving computer-aided diagnosis systems, providing reliable support for radiologists in clinical practice and aiding in the early detection of lung cancer, especially in resource-limited settings",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2024-09-20 19:47:07 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.233342"
    },
    {
        "index": "#180",
        "title": "AutoPET III Challenge: Tumor Lesion Segmentation using ResEnc-Model Ensemble",
        "link": "/arxiv/2409.13779",
        "arxiv_id": "2409.13779",
        "authors": "Tanya Chutani, Saikiran Bonthu, Pranab Samanta, Nitin Singhal",
        "summary": "Positron Emission Tomography (PET) /Computed Tomography (CT) is crucial for diagnosing, managing, and planning treatment for various cancers. Developing reliable deep learning models for the segmentation of tumor lesions in PET/CT scans in a multi-tracer multicenter environment, is a critical area of research. Different tracers, such as Fluorodeoxyglucose (FDG) and Prostate-Specific Membrane Antigen (PSMA), have distinct physiological uptake patterns and data from different centers often vary in terms of acquisition protocols, scanner types, and patient populations. Because of this variability, it becomes more difficult to design reliable segmentation algorithms and generalization techniques due to variations in image quality and lesion detectability. To address this challenge, We trained a 3D Residual encoder U-Net within the no new U-Net framework, aiming to generalize the performance of automatic lesion segmentation of whole body PET/CT scans, across different tracers and clinical sites. Further, We explored several preprocessing techniques and ultimately settled on using the Total Segmentator to crop our training data. Additionally, we applied resampling during this process. During inference, we leveraged test-time augmentations and other post-processing techniques to enhance tumor lesion segmentation. Our team currently hold the top position in the Auto-PET III challenge and outperformed the challenge baseline model in the preliminary test set with Dice score of 0.9627.",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2024-09-19 20:18:39 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.233590"
    },
    {
        "index": "#181",
        "title": "Efficient Classification of Histopathology Images",
        "link": "/arxiv/2409.13720",
        "arxiv_id": "2409.13720",
        "authors": "Mohammad Iqbal Nouyed, Mary-Anne Hartley, Gianfranco Doretto, Donald A. Adjeroh",
        "summary": "This work addresses how to efficiently classify challenging histopathology images, such as gigapixel whole-slide images for cancer diagnostics with image-level annotation. We use images with annotated tumor regions to identify a set of tumor patches and a set of benign patches in a cancerous slide. Due to the variable nature of region of interest the tumor positive regions may refer to an extreme minority of the pixels. This creates an important problem during patch-level classification, where the majority of patches from an image labeled as 'cancerous' are actually tumor-free. This problem is different from semantic segmentation which associates a label to every pixel in an image, because after patch extraction we are only dealing with patch-level labels.Most existing approaches address the data imbalance issue by mitigating the data shortage in minority classes in order to prevent the model from being dominated by the majority classes. These methods include data re-sampling, loss re-weighting, margin modification, and data augmentation. In this work, we mitigate the patch-level class imbalance problem by taking a divide-and-conquer approach. First, we partition the data into sub-groups, and define three separate classification sub-problems based on these data partitions. Then, using an information-theoretic cluster-based sampling of deep image patch features, we sample discriminative patches from the sub-groups. Using these sampled patches, we build corresponding deep models to solve the new classification sub-problems. Finally, we integrate information learned from the respective models to make a final decision on the patches. Our result shows that the proposed approach can perform competitively using a very low percentage of the available patches in a given whole-slide image.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition",
        "date": "2024-09-08 17:41:04 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.239110"
    },
    {
        "index": "#182",
        "title": "A Stochastic Geo-spatiotemporal Bipartite Network to Optimize GCOOS Sensor Placement Strategies",
        "link": "/arxiv/2404.14357",
        "arxiv_id": "2404.14357",
        "authors": "Ted Edward Holmberg, Elias Ioup, Mahdi Abdelguerfi",
        "summary": "This paper proposes two new measures applicable in a spatial bipartite network model: coverage and coverage robustness. The bipartite network must consist of observer nodes, observable nodes, and edges that connect observer nodes to observable nodes. The coverage and coverage robustness scores evaluate the effectiveness of the observer node placements. This measure is beneficial for stochastic data as it may be coupled with Monte Carlo simulations to identify optimal placements for new observer nodes. In this paper, we construct a Geo-SpatioTemporal Bipartite Network (GSTBN) within the stochastic and dynamical environment of the Gulf of Mexico. This GSTBN consists of GCOOS sensor nodes and HYCOM Region of Interest (RoI) event nodes. The goal is to identify optimal placements to expand GCOOS to improve the forecasting outcomes by the HYCOM ocean prediction model.",
        "subjects": "Multiagent Systems",
        "date": "2024-04-22 17:12:06 UTC",
        "category": "cs.CV",
        "crawl_time": "2025-09-24T16:31:00.239315"
    },
    {
        "index": "#1",
        "title": "A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor?",
        "link": "/arxiv/2409.15277",
        "arxiv_id": "2409.15277",
        "authors": "Yunfei Xie, Juncheng Wu, Haoqin Tu, Siwei Yang, Bingchen Zhao, Yongshuo Zong, Qiao Jin, Cihang Xie, Yuyin Zhou",
        "summary": "Large language models (LLMs) have exhibited remarkable capabilities across various domains and tasks, pushing the boundaries of our knowledge in learning and cognition. The latest model, OpenAI's o1, stands out as the first LLM with an internalized chain-of-thought technique using reinforcement learning strategies. While it has demonstrated surprisingly strong capabilities on various general language tasks, its performance in specialized fields such as medicine remains unknown. To this end, this report provides a comprehensive exploration of o1 on different medical scenarios, examining 3 key aspects: understanding, reasoning, and multilinguality. Specifically, our evaluation encompasses 6 tasks using data from 37 medical datasets, including two newly constructed and more challenging question-answering (QA) tasks based on professional medical quizzes from the New England Journal of Medicine (NEJM) and The Lancet. These datasets offer greater clinical relevance compared to standard medical QA benchmarks such as MedQA, translating more effectively into real-world clinical utility. Our analysis of o1 suggests that the enhanced reasoning ability of LLMs may (significantly) benefit their capability to understand various medical instructions and reason through complex clinical scenarios. Notably, o1 surpasses the previous GPT-4 in accuracy by an average of 6.2% and 6.6% across 19 datasets and two newly created complex QA scenarios. But meanwhile, we identify several weaknesses in both the model capability and the existing evaluation protocols, including hallucination, inconsistent multilingual ability, and discrepant metrics for evaluation. We release our raw data and model outputs at https://ucsc-vlaa.github.io/o1_medicine/ for future research.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 17:59:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.330663"
    },
    {
        "index": "#3",
        "title": "Behavioral Bias of Vision-Language Models: A Behavioral Finance View",
        "link": "/arxiv/2409.15256",
        "arxiv_id": "2409.15256",
        "authors": "Yuhang Xiao, Yudi Lin, Ming-Chang Chiu",
        "summary": "Large Vision-Language Models (LVLMs) evolve rapidly as Large Language Models (LLMs) was equipped with vision modules to create more human-like models. However, we should carefully evaluate their applications in different domains, as they may possess undesired biases. Our work studies the potential behavioral biases of LVLMs from a behavioral finance perspective, an interdisciplinary subject that jointly considers finance and psychology. We propose an end-to-end framework, from data collection to new evaluation metrics, to assess LVLMs' reasoning capabilities and the dynamic behaviors manifested in two established human financial behavioral biases: recency bias and authority bias. Our evaluations find that recent open-source LVLMs such as LLaVA-NeXT, MobileVLM-V2, Mini-Gemini, MiniCPM-Llama3-V 2.5 and Phi-3-vision-128k suffer significantly from these two biases, while the proprietary model GPT-4o is negligibly impacted. Our observations highlight directions in which open-source models can improve. The code is available at https://github.com/mydcxiao/vlm_behavioral_fin.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 17:54:47 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.331302"
    },
    {
        "index": "#4",
        "title": "MemBench: Towards Real-world Evaluation of Memory-Augmented Dialogue Systems",
        "link": "/arxiv/2409.15240",
        "arxiv_id": "2409.15240",
        "authors": "Junqing He, Liang Zhu, Qi Wei, Rui Wang, Jiaxing Zhang",
        "summary": "Long-term memory is so important for chatbots and dialogue systems (DS) that researchers have developed numerous memory-augmented DS. However, their evaluation methods are different from the real situation in human conversation. They only measured the accuracy of factual information or the perplexity of generated responses given a query, which hardly reflected their performance. Moreover, they only consider passive memory retrieval based on similarity, neglecting diverse memory-recalling paradigms in humans, e.g. emotions and surroundings. To bridge the gap, we construct a novel benchmark covering various memory recalling paradigms based on cognitive science and psychology theory. The Memory Benchmark (MemBench) contains two tasks according to the two-phrase theory in cognitive science: memory retrieval, memory recognition and injection. The benchmark considers both passive and proactive memory recalling based on meta information for the first time. In addition, novel scoring aspects are proposed to comprehensively measure the generated responses. Results from the strongest embedding models and LLMs on MemBench show that there is plenty of room for improvement in existing dialogue systems. Extensive experiments also reveal the correlation between memory injection and emotion supporting (ES) skillfulness, and intimacy. Our code and dataset will be released.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 17:38:41 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.331507"
    },
    {
        "index": "#5",
        "title": "ASTE Transformer Modelling Dependencies in Aspect-Sentiment Triplet Extraction",
        "link": "/arxiv/2409.15202",
        "arxiv_id": "2409.15202",
        "authors": "Iwo Naglik, Mateusz Lango",
        "summary": "Aspect-Sentiment Triplet Extraction (ASTE) is a recently proposed task of aspect-based sentiment analysis that consists in extracting (aspect phrase, opinion phrase, sentiment polarity) triples from a given sentence. Recent state-of-the-art methods approach this task by first extracting all possible text spans from a given text, then filtering the potential aspect and opinion phrases with a classifier, and finally considering all their pairs with another classifier that additionally assigns sentiment polarity to them. Although several variations of the above scheme have been proposed, the common feature is that the final result is constructed by a sequence of independent classifier decisions. This hinders the exploitation of dependencies between extracted phrases and prevents the use of knowledge about the interrelationships between classifier predictions to improve performance. In this paper, we propose a new ASTE approach consisting of three transformer-inspired layers, which enables the modelling of dependencies both between phrases and between the final classifier decisions. Experimental results show that the method achieves higher performance in terms of F1 measure than other methods studied on popular benchmarks. In addition, we show that a simple pre-training technique further improves the performance of the model.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 16:49:47 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.331692"
    },
    {
        "index": "#6",
        "title": "Learning from Contrastive Prompts: Automated Optimization and Adaptation",
        "link": "/arxiv/2409.15199",
        "arxiv_id": "2409.15199",
        "authors": "Mingqi Li, Karan Aggarwal, Yong Xie, Aitzaz Ahmad, Stephen Lau",
        "summary": "As LLMs evolve, significant effort is spent on manually crafting prompts. While existing prompt optimization methods automate this process, they rely solely on learning from incorrect samples, leading to a sub-optimal performance. Additionally, an unexplored challenge in the literature is prompts effective for prior models may not perform well on newer versions or different languages. We propose the Learning from Contrastive Prompts (LCP) framework to address these gaps, enhancing both prompt optimization and adaptation. LCP employs contrastive learning to generate effective prompts by analyzing patterns in good and bad prompt examples. Our evaluation on the Big-Bench Hard dataset shows that LCP has a win rate of over 76% over existing methods in prompt optimization and demonstrates strong adaptability across different model versions, families, and languages. LCP offers a systematic approach to prompt engineering, reducing manual effort in deploying LLMs across varied contexts.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 16:47:23 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.331899"
    },
    {
        "index": "#7",
        "title": "PALLM: Evaluating and Enhancing PALLiative Care Conversations with Large Language Models",
        "link": "/arxiv/2409.15188",
        "arxiv_id": "2409.15188",
        "authors": "Zhiyuan Wang, Fangxu Yuan, Virginia LeBaron, Tabor Flickinger, Laura E. Barnes",
        "summary": "Effective patient-provider communication is crucial in clinical care, directly impacting patient outcomes and quality of life. Traditional evaluation methods, such as human ratings, patient feedback, and provider self-assessments, are often limited by high costs and scalability issues. Although existing natural language processing (NLP) techniques show promise, they struggle with the nuances of clinical communication and require sensitive clinical data for training, reducing their effectiveness in real-world applications. Emerging large language models (LLMs) offer a new approach to assessing complex communication metrics, with the potential to advance the field through integration into passive sensing and just-in-time intervention systems. This study explores LLMs as evaluators of palliative care communication quality, leveraging their linguistic, in-context learning, and reasoning capabilities. Specifically, using simulated scripts crafted and labeled by healthcare professionals, we test proprietary models (e.g., GPT-4) and fine-tune open-source LLMs (e.g., LLaMA2) with a synthetic dataset generated by GPT-4 to evaluate clinical conversations, to identify key metrics such as `understanding' and `empathy'. Our findings demonstrated LLMs' superior performance in evaluating clinical communication, providing actionable feedback with reasoning, and demonstrating the feasibility and practical viability of developing in-house LLMs. This research highlights LLMs' potential to enhance patient-provider interactions and lays the groundwork for downstream steps in developing LLM-empowered clinical health systems.",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2024-09-23 16:39:12 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332107"
    },
    {
        "index": "#8",
        "title": "Lessons Learned on Information Retrieval in Electronic Health Records: A Comparison of Embedding Models and Pooling Strategies",
        "link": "/arxiv/2409.15163",
        "arxiv_id": "2409.15163",
        "authors": "Skatje Myers, Timothy A. Miller, Yanjun Gao, Matthew M. Churpek, Anoop Mayampurath, Dmitriy Dligach, Majid Afshar",
        "summary": "Objective: Applying large language models (LLMs) to the clinical domain is challenging due to the context-heavy nature of processing medical records. Retrieval-augmented generation (RAG) offers a solution by facilitating reasoning over large text sources. However, there are many parameters to optimize in just the retrieval system alone. This paper presents an ablation study exploring how different embedding models and pooling methods affect information retrieval for the clinical domain. Methods: Evaluating on three retrieval tasks on two electronic health record (EHR) data sources, we compared seven models, including medical- and general-domain models, specialized encoder embedding models, and off-the-shelf decoder LLMs. We also examine the choice of embedding pooling strategy for each model, independently on the query and the text to retrieve. Results: We found that the choice of embedding model significantly impacts retrieval performance, with BGE, a comparatively small general-domain model, consistently outperforming all others, including medical-specific models. However, our findings also revealed substantial variability across datasets and query text phrasings. We also determined the best pooling methods for each of these models to guide future design of retrieval systems. Discussion: The choice of embedding model, pooling strategy, and query formulation can significantly impact retrieval performance and the performance of these models on other public benchmarks does not necessarily transfer to new domains. Further studies such as this one are vital for guiding empirically-grounded development of retrieval frameworks, such as in the context of RAG, for the clinical domain.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2024-09-23 16:16:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332318"
    },
    {
        "index": "#9",
        "title": "Scientific Cross-Document Coreference and Hierarchy with Definition-Augmented Relational Reasoning",
        "link": "/arxiv/2409.15113",
        "arxiv_id": "2409.15113",
        "authors": "Lior Forer, Tom Hope",
        "summary": "We address the fundamental task of inferring cross-document coreference and hierarchy in scientific texts, which has important applications in knowledge graph construction, search, recommendation and discovery. LLMs still struggle when faced with many long-tail technical concepts with nuanced variations. We present a novel method which generates context-dependent definitions of concept mentions by retrieving full-text literature, and uses the definitions to enhance detection of cross-document mention relations. We further generate relational definitions, which describe how two concept mentions are related or different, and design an efficient re-ranking approach to address the combinatorial explosion involved in inferring links across papers. In both fine-tuning and in-context learning settings we achieve large gains in performance. We provide analysis of generated definitions, shedding light on the relational reasoning ability of LLMs over fine-grained scientific texts.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 15:20:27 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332526"
    },
    {
        "index": "#10",
        "title": "Using Similarity to Evaluate Factual Consistency in Summaries",
        "link": "/arxiv/2409.15090",
        "arxiv_id": "2409.15090",
        "authors": "Yuxuan Ye, Edwin Simpson, Raul Santos Rodriguez",
        "summary": "Cutting-edge abstractive summarisers generate fluent summaries, but the factuality of the generated text is not guaranteed. Early summary factuality evaluation metrics are usually based on n-gram overlap and embedding similarity, but are reported fail to align with human annotations. Therefore, many techniques for detecting factual inconsistencies build pipelines around natural language inference (NLI) or question-answering (QA) models with additional supervised learning steps. In this paper, we revisit similarity-based metrics, showing that this failure stems from the comparison text selection and its granularity. We propose a new zero-shot factuality evaluation metric, Sentence-BERT Score (SBERTScore), which compares sentences between the summary and the source document. It outperforms widely-used word-word metrics including BERTScore and can compete with existing NLI and QA-based factuality metrics on the benchmark without needing any fine-tuning. Our experiments indicate that each technique has different strengths, with SBERTScore particularly effective in identifying correct summaries. We demonstrate how a combination of techniques is more effective in detecting various types of error.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 15:02:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332716"
    },
    {
        "index": "#11",
        "title": "Depression Diagnosis Dialogue Simulation: Self-improving Psychiatrist with Tertiary Memory",
        "link": "/arxiv/2409.15084",
        "arxiv_id": "2409.15084",
        "authors": "Kunyao Lan, Bingui Jin, Zichen Zhu, Siyuan Chen, Shu Zhang, Kenny Q. Zhu, Mengyue Wu",
        "summary": "Mental health issues, particularly depressive disorders, present significant challenges in contemporary society, necessitating the development of effective automated diagnostic methods. This paper introduces the Agent Mental Clinic (AMC), a self-improving conversational agent system designed to enhance depression diagnosis through simulated dialogues between patient and psychiatrist agents. To enhance the dialogue quality and diagnosis accuracy, we design a psychiatrist agent consisting of a tertiary memory structure, a dialogue control and reflect plugin that acts as ``supervisor'' and a memory sampling module, fully leveraging the skills reflected by the psychiatrist agent, achieving great accuracy on depression risk and suicide risk diagnosis via conversation. Experiment results on datasets collected in real-life scenarios demonstrate that the system, simulating the procedure of training psychiatrists, can be a promising optimization method for aligning LLMs with real-life distribution in specific domains without modifying the weights of LLMs, even when only a few representative labeled cases are available.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-20 14:25:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.332976"
    },
    {
        "index": "#12",
        "title": "Enhancing Scientific Reproducibility Through Automated BioCompute Object Creation Using Retrieval-Augmented Generation from Publications",
        "link": "/arxiv/2409.15076",
        "arxiv_id": "2409.15076",
        "authors": "Sean Kim, Raja Mazumder",
        "summary": "The exponential growth in computational power and accessibility has transformed the complexity and scale of bioinformatics research, necessitating standardized documentation for transparency, reproducibility, and regulatory compliance. The IEEE BioCompute Object (BCO) standard addresses this need but faces adoption challenges due to the overhead of creating compliant documentation, especially for legacy research. This paper presents a novel approach to automate the creation of BCOs from scientific papers using Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). We describe the development of the BCO assistant tool that leverages RAG to extract relevant information from source papers and associated code repositories, addressing key challenges such as LLM hallucination and long-context understanding. The implementation incorporates optimized retrieval processes, including a two-pass retrieval with re-ranking, and employs carefully engineered prompts for each BCO domain. We discuss the tool's architecture, extensibility, and evaluation methods, including automated and manual assessment approaches. The BCO assistant demonstrates the potential to significantly reduce the time and effort required for retroactive documentation of bioinformatics research while maintaining compliance with the standard. This approach opens avenues for AI-assisted scientific documentation and knowledge extraction from publications thereby enhancing scientific reproducibility. The BCO assistant tool and documentation is available at https://biocompute-objects.github.io/bco-rag/.",
        "subjects": "Computation and Language, Artificial Intelligence, Other Quantitative Biology",
        "date": "2024-09-23 14:51:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.333175"
    },
    {
        "index": "#13",
        "title": "Brotherhood at WMT 2024: Leveraging LLM-Generated Contextual Conversations for Cross-Lingual Image Captioning",
        "link": "/arxiv/2409.15052",
        "arxiv_id": "2409.15052",
        "authors": "Siddharth Betala, Ishan Chokshi",
        "summary": "In this paper, we describe our system under the team name Brotherhood for the English-to-Lowres Multi-Modal Translation Task. We participate in the multi-modal translation tasks for English-Hindi, English-Hausa, English-Bengali, and English-Malayalam language pairs. We present a method leveraging multi-modal Large Language Models (LLMs), specifically GPT-4o and Claude 3.5 Sonnet, to enhance cross-lingual image captioning without traditional training or fine-tuning. Our approach utilizes instruction-tuned prompting to generate rich, contextual conversations about cropped images, using their English captions as additional context. These synthetic conversations are then translated into the target languages. Finally, we employ a weighted prompting strategy, balancing the original English caption with the translated conversation to generate captions in the target language. This method achieved competitive results, scoring 37.90 BLEU on the English-Hindi Challenge Set and ranking first and second for English-Hausa on the Challenge and Evaluation Leaderboards, respectively. We conduct additional experiments on a subset of 250 images, exploring the trade-offs between BLEU scores and semantic similarity across various weighting schemes.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 14:29:46 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.333359"
    },
    {
        "index": "#14",
        "title": "Scaling Laws of Decoder-Only Models on the Multilingual Machine Translation Task",
        "link": "/arxiv/2409.15051",
        "arxiv_id": "2409.15051",
        "authors": "Gaëtan Caillaut, Raheel Qader, Mariam Nakhlé, Jingshu Liu, Jean-Gabriel Barthélemy",
        "summary": "Recent studies have showcased remarkable capabilities of decoder-only models in many NLP tasks, including translation. Yet, the machine translation field has been largely dominated by encoder-decoder models based on the Transformer architecture. As a consequence, scaling laws of encoder-decoder models for neural machine translation have already been well studied, but decoder-only models have received less attention. This work explores the scaling laws of decoder-only models on the multilingual and multidomain translation task. We trained a collection of six decoder-only models, ranging from 70M to 7B parameters, on a sentence-level, multilingual and multidomain dataset. We conducted a series of experiments showing that the loss of decoder-only models can be estimated using a scaling law similar to the one discovered for large language models, but we also show that this scaling law has difficulties to generalize to too large models or to a different data distribution. We also study different scaling methods and show that scaling the depth and the width of a model lead to similar test loss improvements, but with different impact on the model's efficiency.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 14:26:01 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.333558"
    },
    {
        "index": "#15",
        "title": "Generative LLM Powered Conversational AI Application for Personalized Risk Assessment: A Case Study in COVID-19",
        "link": "/arxiv/2409.15027",
        "arxiv_id": "2409.15027",
        "authors": "Mohammad Amin Roshani, Xiangyu Zhou, Yao Qiang, Srinivasan Suresh, Steve Hicks, Usha Sethuraman, Dongxiao Zhu",
        "summary": "Large language models (LLMs) have shown remarkable capabilities in various natural language tasks and are increasingly being applied in healthcare domains. This work demonstrates a new LLM-powered disease risk assessment approach via streaming human-AI conversation, eliminating the need for programming required by traditional machine learning approaches. In a COVID-19 severity risk assessment case study, we fine-tune pre-trained generative LLMs (e.g., Llama2-7b and Flan-t5-xl) using a few shots of natural language examples, comparing their performance with traditional classifiers (i.e., Logistic Regression, XGBoost, Random Forest) that are trained de novo using tabular data across various experimental settings. We develop a mobile application that uses these fine-tuned LLMs as its generative AI (GenAI) core to facilitate real-time interaction between clinicians and patients, providing no-code risk assessment through conversational interfaces. This integration not only allows for the use of streaming Questions and Answers (QA) as inputs but also offers personalized feature importance analysis derived from the LLM's attention layers, enhancing the interpretability of risk assessments. By achieving high Area Under the Curve (AUC) scores with a limited number of fine-tuning samples, our results demonstrate the potential of generative LLMs to outperform discriminative classification methods in low-data regimes, highlighting their real-world adaptability and effectiveness. This work aims to fill the existing gap in leveraging generative LLMs for interactive no-code risk assessment and to encourage further research in this emerging field.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 13:55:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.333859"
    },
    {
        "index": "#16",
        "title": "Inference-Friendly Models With MixAttention",
        "link": "/arxiv/2409.15012",
        "arxiv_id": "2409.15012",
        "authors": "Shashank Rajput, Ying Sheng, Sean Owen, Vitaliy Chiley",
        "summary": "The size of the key-value (KV) cache plays a critical role in determining both the maximum context length and the number of concurrent requests supported during inference in modern language models. The KV cache size grows proportionally with the number of attention heads and the tokens processed, leading to increased memory consumption and slower inference for long inputs. In this work, we explore the use of MixAttention, a model architecture modification closely related to a blog published by Character.AI. MixAttention combines sliding window attention, where only a small subset of recent tokens is stored in the KV cache, with KV cache sharing across layers. Our experiments demonstrate that MixAttention significantly reduces memory usage and improves inference speed without sacrificing model performance in both short and long-context tasks. We also explore various configurations of this architecture, identifying those that maintain quality across evaluation metrics while optimizing resource efficiency.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 13:37:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.334174"
    },
    {
        "index": "#17",
        "title": "Enhancing Aspect-based Sentiment Analysis in Tourism Using Large Language Models and Positional Information",
        "link": "/arxiv/2409.14997",
        "arxiv_id": "2409.14997",
        "authors": "Chun Xu, Mengmeng Wang, Yan Ren, Shaolin Zhu",
        "summary": "Aspect-Based Sentiment Analysis (ABSA) in tourism plays a significant role in understanding tourists' evaluations of specific aspects of attractions, which is crucial for driving innovation and development in the tourism industry. However, traditional pipeline models are afflicted by issues such as error propagation and incomplete extraction of sentiment elements. To alleviate this issue, this paper proposes an aspect-based sentiment analysis model, ACOS_LLM, for Aspect-Category-Opinion-Sentiment Quadruple Extraction (ACOSQE). The model comprises two key stages: auxiliary knowledge generation and ACOSQE. Firstly, Adalora is used to fine-tune large language models for generating high-quality auxiliary knowledge. To enhance model efficiency, Sparsegpt is utilized to compress the fine-tuned model to 50% sparsity. Subsequently, Positional information and sequence modeling are employed to achieve the ACOSQE task, with auxiliary knowledge and the original text as inputs. Experiments are conducted on both self-created tourism datasets and publicly available datasets, Rest15 and Rest16. Results demonstrate the model's superior performance, with an F1 improvement of 7.49% compared to other models on the tourism dataset. Additionally, there is an F1 improvement of 0.05% and 1.06% on the Rest15 and Rest16 datasets, respectively.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 13:19:17 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.334425"
    },
    {
        "index": "#18",
        "title": "Beyond Fine-tuning: Unleashing the Potential of Continuous Pretraining for Clinical LLMs",
        "link": "/arxiv/2409.14988",
        "arxiv_id": "2409.14988",
        "authors": "Clément Christophe, Tathagata Raha, Svetlana Maslenkova, Muhammad Umar Salman, Praveen K Kanithi, Marco AF Pimentel, Shadab Khan",
        "summary": "Large Language Models (LLMs) have demonstrated significant potential in transforming clinical applications. In this study, we investigate the efficacy of four techniques in adapting LLMs for clinical use-cases: continuous pretraining, instruct fine-tuning, NEFTune, and prompt engineering. We employ these methods on Mistral 7B and Mixtral 8x7B models, leveraging a large-scale clinical pretraining dataset of 50 billion tokens and an instruct fine-tuning dataset of 500 million tokens. Our evaluation across various clinical tasks reveals the impact of each technique. While continuous pretraining beyond 250 billion tokens yields marginal improvements on its own, it establishes a strong foundation for instruct fine-tuning. Notably, NEFTune, designed primarily to enhance generation quality, surprisingly demonstrates additional gains on our benchmark. Complex prompt engineering methods further enhance performance. These findings show the importance of tailoring fine-tuning strategies and exploring innovative techniques to optimize LLM performance in the clinical domain.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 13:09:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.334648"
    },
    {
        "index": "#19",
        "title": "Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others in Conversation Forecasting",
        "link": "/arxiv/2409.14986",
        "arxiv_id": "2409.14986",
        "authors": "Anthony Sicilia, Malihe Alikhani",
        "summary": "Typically, when evaluating Theory of Mind, we consider the beliefs of others to be binary: held or not held. But what if someone is unsure about their own beliefs? How can we quantify this uncertainty? We propose a new suite of tasks, challenging language models (LMs) to model the uncertainty of others in dialogue. We design these tasks around conversation forecasting, wherein an agent forecasts an unobserved outcome to a conversation. Uniquely, we view interlocutors themselves as forecasters, asking an LM to predict the uncertainty of the interlocutors (a probability). We experiment with re-scaling methods, variance reduction strategies, and demographic context, for this regression task, conducting experiments on three dialogue corpora (social, negotiation, task-oriented) with eight LMs. While LMs can explain up to 7% variance in the uncertainty of others, we highlight the difficulty of the tasks and room for future work, especially in practical applications, like anticipating ``false",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 13:05:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.334879"
    },
    {
        "index": "#20",
        "title": "Bilingual Rhetorical Structure Parsing with Large Parallel Annotations",
        "link": "/arxiv/2409.14969",
        "arxiv_id": "2409.14969",
        "authors": "Elena Chistova",
        "summary": "Discourse parsing is a crucial task in natural language processing that aims to reveal the higher-level relations in a text. Despite growing interest in cross-lingual discourse parsing, challenges persist due to limited parallel data and inconsistencies in the Rhetorical Structure Theory (RST) application across languages and corpora. To address this, we introduce a parallel Russian annotation for the large and diverse English GUM RST corpus. Leveraging recent advances, our end-to-end RST parser achieves state-of-the-art results on both English and Russian corpora. It demonstrates effectiveness in both monolingual and bilingual settings, successfully transferring even with limited second-language annotation. To the best of our knowledge, this work is the first to evaluate the potential of cross-lingual end-to-end RST parsing on a manually annotated parallel corpus.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 12:40:33 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.335066"
    },
    {
        "index": "#21",
        "title": "Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make your LLMs use External Data More Wisely",
        "link": "/arxiv/2409.14924",
        "arxiv_id": "2409.14924",
        "authors": "Siyun Zhao, Yuqing Yang, Zilong Wang, Zhiyuan He, Luna K. Qiu, Lili Qiu",
        "summary": "Large language models (LLMs) augmented with external data have demonstrated remarkable capabilities in completing real-world tasks. Techniques for integrating external data into LLMs, such as Retrieval-Augmented Generation (RAG) and fine-tuning, are gaining increasing attention and widespread application. Nonetheless, the effective deployment of data-augmented LLMs across various specialized fields presents substantial challenges. These challenges encompass a wide range of issues, from retrieving relevant data and accurately interpreting user intent to fully harnessing the reasoning capabilities of LLMs for complex tasks. We believe that there is no one-size-fits-all solution for data-augmented LLM applications. In practice, underperformance often arises from a failure to correctly identify the core focus of a task or because the task inherently requires a blend of multiple capabilities that must be disentangled for better resolution. In this survey, we propose a RAG task categorization method, classifying user queries into four levels based on the type of external data required and primary focus of the task: explicit fact queries, implicit fact queries, interpretable rationale queries, and hidden rationale queries. We define these levels of queries, provide relevant datasets, and summarize the key challenges and most effective techniques for addressing these challenges. Finally, we discuss three main forms of integrating external data into LLMs: context, small model, and fine-tuning, highlighting their respective strengths, limitations, and the types of problems they are suited to solve. This work aims to help readers thoroughly understand and decompose the data requirements and key bottlenecks in building LLM applications, offering solutions to the different challenges and serving as a guide to systematically developing such applications.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 11:20:20 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.335281"
    },
    {
        "index": "#22",
        "title": "With Ears to See and Eyes to Hear: Sound Symbolism Experiments with Multimodal Large Language Models",
        "link": "/arxiv/2409.14917",
        "arxiv_id": "2409.14917",
        "authors": "Tyler Loakman, Yucheng Li, Chenghua Lin",
        "summary": "Recently, Large Language Models (LLMs) and Vision Language Models (VLMs) have demonstrated aptitude as potential substitutes for human participants in experiments testing psycholinguistic phenomena. However, an understudied question is to what extent models that only have access to vision and text modalities are able to implicitly understand sound-based phenomena via abstract reasoning from orthography and imagery alone. To investigate this, we analyse the ability of VLMs and LLMs to demonstrate sound symbolism (i.e., to recognise a non-arbitrary link between sounds and concepts) as well as their ability to ``hear'' via the interplay of the language and vision modules of open and closed-source multimodal models. We perform multiple experiments, including replicating the classic Kiki-Bouba and Mil-Mal shape and magnitude symbolism tasks, and comparing human judgements of linguistic iconicity with that of LLMs. Our results show that VLMs demonstrate varying levels of agreement with human labels, and more task information may be required for VLMs versus their human counterparts for in silico experimentation. We additionally see through higher maximum agreement levels that Magnitude Symbolism is an easier pattern for VLMs to identify than Shape Symbolism, and that an understanding of linguistic iconicity is highly dependent on model size.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 11:13:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.340823"
    },
    {
        "index": "#23",
        "title": "Towards a Realistic Long-Term Benchmark for Open-Web Research Agents",
        "link": "/arxiv/2409.14913",
        "arxiv_id": "2409.14913",
        "authors": "Peter Mühlbacher, Nikos I. Bosse, Lawrence Phillips",
        "summary": "We present initial results of a forthcoming benchmark for evaluating LLM agents on white-collar tasks of economic value. We evaluate eight realistic and ``messy'' tasks that are routine in finance and consulting, drawn from real-world cases from our customers. We lay the groundwork for an LLM agent evaluation suite where good performance directly corresponds to a large economic and societal impact. This fills a gap in existing benchmarks with tasks like ``order a pizza to the following address'' that do not constitute real-human work of economic value. Our evaluations assign credit to agents for partially solving tasks. By doing that, this initial evaluation, and the forthcoming benchmark, allow us to more accurately extrapolate performance of LLM-based agents on economically valuable tasks. We built and tested several architectures with GPT-4o, Claude-3.5 Sonnet, Llama 3.1 (405b), and GPT-4o-mini, ensuring that failure to solve a task was due to failures of reasoning and planning, rather than due to common failures like e.g. the inability to parse a website. On average, LLM agents powered by Claude-3.5 Sonnet substantially outperformed agents using GPT-4o, with agents based on Llama 3.1 (405b) and GPT-4o-mini lagging noticeably behind. Across LLMs, a ReAct architecture with the ability to delegate subtasks to subagents performed best. In addition to quantitative evaluations, we qualitatively assessed the performance of the LLM agents by inspecting their traces and reflecting on their observations.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-23 11:08:04 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341153"
    },
    {
        "index": "#24",
        "title": "Knowledge Planning in Large Language Models for Domain-Aligned Counseling Summarization",
        "link": "/arxiv/2409.14907",
        "arxiv_id": "2409.14907",
        "authors": "Aseem Srivastava, Smriti Joshi, Tanmoy Chakraborty, Md Shad Akhtar",
        "summary": "In mental health counseling, condensing dialogues into concise and relevant summaries (aka counseling notes) holds pivotal significance. Large Language Models (LLMs) exhibit remarkable capabilities in various generative tasks; however, their adaptation to domain-specific intricacies remains challenging, especially within mental health contexts. Unlike standard LLMs, mental health experts first plan to apply domain knowledge in writing summaries. Our work enhances LLMs' ability by introducing a novel planning engine to orchestrate structuring knowledge alignment. To achieve high-order planning, we divide knowledge encapsulation into two major phases: (i) holding dialogue structure and (ii) incorporating domain-specific knowledge. We employ a planning engine on Llama-2, resulting in a novel framework, PIECE. Our proposed system employs knowledge filtering-cum-scaffolding to encapsulate domain knowledge. Additionally, PIECE leverages sheaf convolution learning to enhance its understanding of the dialogue's structural nuances. We compare PIECE with 14 baseline methods and observe a significant improvement across ROUGE and Bleurt scores. Further, expert evaluation and analyses validate the generation quality to be effective, sometimes even surpassing the gold standard. We further benchmark PIECE with other LLMs and report improvement, including Llama-2 (+2.72%), Mistral (+2.04%), and Zephyr (+1.59%), to justify the generalizability of the planning engine.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 11:01:31 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341355"
    },
    {
        "index": "#25",
        "title": "DSG-KD: Knowledge Distillation from Domain-Specific to General Language Models",
        "link": "/arxiv/2409.14904",
        "arxiv_id": "2409.14904",
        "authors": "Sangyeon Cho, Jangyeong Jeon, Dongjoon Lee, Changhee Lee, Junyeong Kim",
        "summary": "The use of pre-trained language models fine-tuned to address specific downstream tasks is a common approach in natural language processing (NLP). However, acquiring domain-specific knowledge via fine-tuning is challenging. Traditional methods involve pretraining language models using vast amounts of domain-specific data before fine-tuning for particular tasks. This study investigates emergency/non-emergency classification tasks based on electronic medical record (EMR) data obtained from pediatric emergency departments (PEDs) in Korea. Our findings reveal that existing domain-specific pre-trained language models underperform compared to general language models in handling N-lingual free-text data characteristics of non-English-speaking regions. To address these limitations, we propose a domain knowledge transfer methodology that leverages knowledge distillation to infuse general language models with domain-specific knowledge via fine-tuning. This study demonstrates the effective transfer of specialized knowledge between models by defining a general language model as the student model and a domain-specific pre-trained model as the teacher model. In particular, we address the complexities of EMR data obtained from PEDs in non-English-speaking regions, such as Korea, and demonstrate that the proposed method enhances classification performance in such contexts. The proposed methodology not only outperforms baseline models on Korean PED EMR data, but also promises broader applicability in various professional and technical domains. In future works, we intend to extend this methodology to include diverse non-English-speaking regions and address additional downstream tasks, with the aim of developing advanced model architectures using state-of-the-art KD techniques. The code is available in https://github.com/JoSangYeon/DSG-KD.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 10:59:02 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341555"
    },
    {
        "index": "#26",
        "title": "End-to-End Graph Flattening Method for Large Language Models",
        "link": "/arxiv/2409.14880",
        "arxiv_id": "2409.14880",
        "authors": "Bin Hong, Jinze Wu, Jiayu Liu, Liang Ding, Jing Sha, Kai Zhang, Shijin Wang, Zhenya Huang",
        "summary": "In recent years, the breakthrough of Large Language Models (LLMs) offers new ideas for achieving universal methods on graph data. The common practice of converting graphs into natural language for LLMs, which refers to graph flattening, exhibits good generalizability and interpretability. However, the poor organization of the textual format results in poor performance in long-distance scenario understanding. Inspired by human cognitive reasoning habits, we propose a novel method for graph flattening to fit LLMs, termed as End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show that EEDP enhances the reasoning performance of LLMs in long-distance scenarios while maintaining excellent performance in short-distance scenarios, demonstrating good robustness in the face of distance variations.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 10:28:47 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341776"
    },
    {
        "index": "#27",
        "title": "Privacy Policy Analysis through Prompt Engineering for LLMs",
        "link": "/arxiv/2409.14879",
        "arxiv_id": "2409.14879",
        "authors": "Arda Goknil, Femke B. Gelderblom, Simeon Tverdal, Shukun Tokas, Hui Song",
        "summary": "Privacy policies are often obfuscated by their complexity, which impedes transparency and informed consent. Conventional machine learning approaches for automatically analyzing these policies demand significant resources and substantial domain-specific training, causing adaptability issues. Moreover, they depend on extensive datasets that may require regular maintenance due to changing privacy concerns. In this paper, we propose, apply, and assess PAPEL (Privacy Policy Analysis through Prompt Engineering for LLMs), a framework harnessing the power of Large Language Models (LLMs) through prompt engineering to automate the analysis of privacy policies. PAPEL aims to streamline the extraction, annotation, and summarization of information from these policies, enhancing their accessibility and comprehensibility without requiring additional model training. By integrating zero-shot, one-shot, and few-shot learning approaches and the chain-of-thought prompting in creating predefined prompts and prompt templates, PAPEL guides LLMs to efficiently dissect, interpret, and synthesize the critical aspects of privacy policies into user-friendly summaries. We demonstrate the effectiveness of PAPEL with two applications: (i) annotation and (ii) contradiction analysis. We assess the ability of several LLaMa and GPT models to identify and articulate data handling practices, offering insights comparable to existing automated analysis approaches while reducing training efforts and increasing the adaptability to new analytical needs. The experiments demonstrate that the LLMs PAPEL utilizes (LLaMA and Chat GPT models) achieve robust performance in privacy policy annotation, with F1 scores reaching 0.8 and above (using the OPP-115 gold standard), underscoring the effectiveness of simpler prompts across various advanced language models.",
        "subjects": "Computation and Language, Computers and Society, Software Engineering",
        "date": "2024-09-23 10:23:31 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.341984"
    },
    {
        "index": "#28",
        "title": "Orthogonal Finetuning for Direct Preference Optimization",
        "link": "/arxiv/2409.14836",
        "arxiv_id": "2409.14836",
        "authors": "Chenxu Yang, Ruipeng Jia, Naibin Gu, Zheng Lin, Siyuan Chen, Chao Pang, Weichong Yin, Yu Sun, Hua Wu, Weiping Wang",
        "summary": "DPO is an effective preference optimization algorithm. However, the DPO-tuned models tend to overfit on the dispreferred samples, manifested as overly long generations lacking diversity. While recent regularization approaches have endeavored to alleviate this issue by modifying the objective function, they achieved that at the cost of alignment performance degradation. In this paper, we innovatively incorporate regularization from the perspective of weight updating to curb alignment overfitting. Through the pilot experiment, we discovered that there exists a positive correlation between overfitting and the hyperspherical energy fluctuation. Hence, we introduce orthogonal finetuning for DPO via a weight-Rotated Preference Optimization (RoPO) method, which merely conducts rotational and magnitude-stretching updates on the weight parameters to maintain the hyperspherical energy invariant, thereby preserving the knowledge encoded in the angle between neurons. Extensive experiments demonstrate that our model aligns perfectly with human preferences while retaining the original expressive capacity using only 0.0086% of the trainable parameters, suggesting an effective regularization against overfitting. Specifically, RoPO outperforms DPO by up to 10 points on MT-Bench and by up to 2.8 points on AlpacaEval 2, while enhancing the generation diversity by an average of 6 points.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 09:09:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.342227"
    },
    {
        "index": "#29",
        "title": "ToolPlanner: A Tool Augmented LLM for Multi Granularity Instructions with Path Planning and Feedback",
        "link": "/arxiv/2409.14826",
        "arxiv_id": "2409.14826",
        "authors": "Qinzhuo Wu, Wei Liu, Jian Luan, Bin Wang",
        "summary": "Recently, tool-augmented LLMs have gained increasing attention. Given an instruction, tool-augmented LLMs can interact with various external tools in multiple rounds and provide a final answer. However, previous LLMs were trained on overly detailed instructions, which included API names or parameters, while real users would not explicitly mention these API details. This leads to a gap between trained LLMs and real-world scenarios. In addition, most works ignore whether the interaction process follows the instruction. To address these issues, we constructed a training dataset called MGToolBench, which contains statement and category-level instructions to better reflect real-world scenarios. In addition, we propose ToolPlanner, a two-stage reinforcement learning framework that utilizes path planning and two feedback mechanisms to enhance the LLM's task completion and instruction-following capabilities. Experimental results show that ToolPlanner significantly improves the Match Rate, Pass Rate and Win Rate by 26.8%, 20.2%, and 5.6% compared to the SOTA model. Human evaluation verifies that the multi-granularity instructions can better align with users' usage habits. Our data and code will be released upon acceptance.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 08:58:48 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.342424"
    },
    {
        "index": "#30",
        "title": "Past Meets Present: Creating Historical Analogy with Large Language Models",
        "link": "/arxiv/2409.14820",
        "arxiv_id": "2409.14820",
        "authors": "Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Feng Wei, Zujie Liang, Deqing Yang, Yanghua Xiao",
        "summary": "Historical analogies, which compare known past events with contemporary but unfamiliar events, are important abilities that help people make decisions and understand the world. However, research in applied history suggests that people have difficulty finding appropriate analogies. And previous studies in the AI community have also overlooked historical analogies. To fill this gap, in this paper, we focus on the historical analogy acquisition task, which aims to acquire analogous historical events for a given event. We explore retrieval and generation methods for acquiring historical analogies based on different large language models (LLMs). Furthermore, we propose a self-reflection method to mitigate hallucinations and stereotypes when LLMs generate historical analogies. Through human evaluations and our specially designed automatic multi-dimensional assessment, we find that LLMs generally have a good potential for historical analogies. And the performance of the models can be further improved by using our self-reflection method.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 08:52:09 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.342640"
    },
    {
        "index": "#31",
        "title": "MobileVLM: A Vision-Language Model for Better Intra- and Inter-UI Understanding",
        "link": "/arxiv/2409.14818",
        "arxiv_id": "2409.14818",
        "authors": "Qinzhuo Wu, Weikai Xu, Wei Liu, Tao Tan, Jianfeng Liu, Ang Li, Jian Luan, Bin Wang, Shuo Shang",
        "summary": "Recently, mobile AI agents based on VLMs have been gaining increasing attention. These works typically utilize VLM as a foundation, fine-tuning it with instruction-based mobile datasets. However, these VLMs are typically pre-trained on general-domain data, which often results in a lack of fundamental capabilities specific to the mobile domain. Therefore, they may struggle to recognize specific UI elements and understand intra-UI fine-grained information. In addition, the current fine-tuning task focuses on interacting with the most relevant element for the given instruction. These fine-tuned VLMs may still ignore the relationships between UI pages, neglect the roles of elements in page transitions and lack inter-UI understanding. To address issues, we propose a VLM called MobileVLM, which includes two additional pre-training stages to enhance both intra- and inter-UI understanding. We defined four UI-based pre-training tasks, enabling the model to better perceive fine-grained elements and capture page transition actions. To address the lack of mobile pre-training data, we built a large Chinese mobile dataset Mobile3M from scratch, which contains 3 million UI pages, and real-world transition actions, forming a directed graph structure. Experimental results show MobileVLM excels on both our test set and public mobile benchmarks, outperforming existing VLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 08:47:54 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.342863"
    },
    {
        "index": "#32",
        "title": "MTP: A Dataset for Multi-Modal Turning Points in Casual Conversations",
        "link": "/arxiv/2409.14801",
        "arxiv_id": "2409.14801",
        "authors": "Gia-Bao Dinh Ho, Chang Wei Tan, Zahra Zamanzadeh Darban, Mahsa Salehi, Gholamreza Haffari, Wray Buntine",
        "summary": "Detecting critical moments, such as emotional outbursts or changes in decisions during conversations, is crucial for understanding shifts in human behavior and their consequences. Our work introduces a novel problem setting focusing on these moments as turning points (TPs), accompanied by a meticulously curated, high-consensus, human-annotated multi-modal dataset. We provide precise timestamps, descriptions, and visual-textual evidence high-lighting changes in emotions, behaviors, perspectives, and decisions at these turning points. We also propose a framework, TPMaven, utilizing state-of-the-art vision-language models to construct a narrative from the videos and large language models to classify and detect turning points in our multi-modal dataset. Evaluation results show that TPMaven achieves an F1-score of 0.88 in classification and 0.61 in detection, with additional explanations aligning with human expectations.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 08:26:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.343093"
    },
    {
        "index": "#34",
        "title": "Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method",
        "link": "/arxiv/2409.14781",
        "arxiv_id": "2409.14781",
        "authors": "Weichao Zhang, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng",
        "summary": "As the scale of training corpora for large language models (LLMs) grows, model developers become increasingly reluctant to disclose details on their data. This lack of transparency poses challenges to scientific evaluation and ethical deployment. Recently, pretraining data detection approaches, which infer whether a given text was part of an LLM's training data through black-box access, have been explored. The Min-K% Prob method, which has achieved state-of-the-art results, assumes that a non-training example tends to contain a few outlier words with low token probabilities. However, the effectiveness may be limited as it tends to misclassify non-training texts that contain many common words with high probabilities predicted by LLMs. To address this issue, we introduce a divergence-based calibration method, inspired by the divergence-from-randomness concept, to calibrate token probabilities for pretraining data detection. We compute the cross-entropy (i.e., the divergence) between the token probability distribution and the token frequency distribution to derive a detection score.We have developed a Chinese-language benchmark, PatentMIA, to assess the performance of detection approaches for LLMs on Chinese text. Experimental results on English-language benchmarks and PatentMIA demonstrate that our proposed method significantly outperforms existing methods. Our code and PatentMIA benchmark are available at https://github.com/zhang-wei-chao/DC-PDD",
        "subjects": "Computation and Language, Cryptography and Security",
        "date": "2024-09-23 07:55:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.343528"
    },
    {
        "index": "#35",
        "title": "OMPar: Automatic Parallelization with AI-Driven Source-to-Source Compilation",
        "link": "/arxiv/2409.14771",
        "arxiv_id": "2409.14771",
        "authors": "Tal Kadosh, Niranjan Hasabnis, Prema Soundararajan, Vy A. Vo, Mihai Capota, Nesreen Ahmed, Yuval Pinter, Gal Oren",
        "summary": "Manual parallelization of code remains a significant challenge due to the complexities of modern software systems and the widespread adoption of multi-core architectures. This paper introduces OMPar, an AI-driven tool designed to automate the parallelization of C/C++ code using OpenMP pragmas. OMPar integrates Large Language Models (LLMs) through two key components: OMPify, which assesses loop parallelization potential, and MonoCoder-OMP, a new fine-tuned model which generates precise OpenMP pragmas. The evaluation of OMPar follows the same rigorous process applied to traditional tools like source-to-source AutoPar and ICPC compilers: (1) ensuring the generated code compiles and runs correctly in serial form, (2) assessing performance with the gradual addition of threads and corresponding physical cores, and (3) verifying and validating the correctness of the code's output. Benchmarks from HeCBench and ParEval are used to evaluate accuracy and performance. Experimental results demonstrate that OMPar significantly outperforms traditional methods, achieving higher accuracy in identifying parallelizable loops and generating efficient pragmas. Beyond accuracy, OMPar offers advantages such as the ability to work on partial or incomplete codebases and the capacity to continuously learn from new code patterns, enhancing its parallelization capabilities over time. These results underscore the potential of LLMs in revolutionizing automatic parallelization techniques, paving the way for more efficient and scalable parallel computing systems.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 07:39:01 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.343737"
    },
    {
        "index": "#36",
        "title": "Language-Agnostic Analysis of Speech Depression Detection",
        "link": "/arxiv/2409.14769",
        "arxiv_id": "2409.14769",
        "authors": "Sona Binu, Jismi Jose, Fathima Shimna K V, Alino Luke Hans, Reni K. Cherian, Starlet Ben Alex, Priyanka Srivastava, Chiranjeevi Yarra",
        "summary": "The people with Major Depressive Disorder (MDD) exhibit the symptoms of tonal variations in their speech compared to the healthy counterparts. However, these tonal variations not only confine to the state of MDD but also on the language, which has unique tonal patterns. This work analyzes automatic speech-based depression detection across two languages, English and Malayalam, which exhibits distinctive prosodic and phonemic characteristics. We propose an approach that utilizes speech data collected along with self-reported labels from participants reading sentences from IViE corpus, in both English and Malayalam. The IViE corpus consists of five sets of sentences: simple sentences, WH-questions, questions without morphosyntactic markers, inversion questions and coordinations, that can naturally prompt speakers to speak in different tonal patterns. Convolutional Neural Networks (CNNs) are employed for detecting depression from speech. The CNN model is trained to identify acoustic features associated with depression in speech, focusing on both languages. The model's performance is evaluated on the collected dataset containing recordings from both depressed and non-depressed speakers, analyzing its effectiveness in detecting depression across the two languages. Our findings and collected data could contribute to the development of language-agnostic speech-based depression detection systems, thereby enhancing accessibility for diverse populations.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 07:35:56 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344000"
    },
    {
        "index": "#37",
        "title": "Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios?",
        "link": "/arxiv/2409.14762",
        "arxiv_id": "2409.14762",
        "authors": "Yuyan Chen, Tianhao Yu, Yueze Li, Songzhou Yan, Sijia Liu, Jiaqing Liang, Yanghua Xiao",
        "summary": "The evaluation of the problem-solving capability under incomplete information scenarios of Large Language Models (LLMs) is increasingly important, encompassing capabilities such as questioning, knowledge search, error detection, and path planning. Current research mainly focus on LLMs' problem-solving capability such as ``Twenty Questions''. However, these kinds of games do not require recognizing misleading cues which are necessary in the incomplete information scenario. Moreover, the existing game such as ``Who is undercover'' are highly subjective, making it challenging for evaluation. Therefore, in this paper, we introduce a novel game named BrainKing based on the ``Who is undercover'' and ``Twenty Questions'' for evaluating LLM capabilities under incomplete information scenarios. It requires LLMs to identify target entities with limited yes-or-no questions and potential misleading answers. By setting up easy, medium, and hard difficulty modes, we comprehensively assess the performance of LLMs across various aspects. Our results reveal the capabilities and limitations of LLMs in BrainKing, providing significant insights of LLM problem-solving levels.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 07:18:02 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344223"
    },
    {
        "index": "#38",
        "title": "LINKAGE: Listwise Ranking among Varied-Quality References for Non-Factoid QA Evaluation via LLMs",
        "link": "/arxiv/2409.14744",
        "arxiv_id": "2409.14744",
        "authors": "Sihui Yang, Keping Bi, Wanqing Cui, Jiafeng Guo, Xueqi Cheng",
        "summary": "Non-Factoid (NF) Question Answering (QA) is challenging to evaluate due to diverse potential answers and no objective criterion. The commonly used automatic evaluation metrics like ROUGE or BERTScore cannot accurately measure semantic similarities or answers from different perspectives. Recently, Large Language Models (LLMs) have been resorted to for NFQA evaluation due to their compelling performance on various NLP tasks. Common approaches include pointwise scoring of each candidate answer and pairwise comparisons between answers. Inspired by the evolution from pointwise to pairwise to listwise in learning-to-rank methods, we propose a novel listwise NFQA evaluation approach, that utilizes LLMs to rank candidate answers in a list of reference answers sorted by descending quality. Moreover, for NF questions that do not have multi-grade or any golden answers, we leverage LLMs to generate the reference answer list of various quality to facilitate the listwise evaluation. Extensive experimental results on three NFQA datasets, i.e., ANTIQUE, the TREC-DL-NF, and WebGLM show that our method has significantly higher correlations with human annotations compared to automatic scores and common pointwise and pairwise approaches.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 06:42:21 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344417"
    },
    {
        "index": "#39",
        "title": "ToxiCraft: A Novel Framework for Synthetic Generation of Harmful Information",
        "link": "/arxiv/2409.14740",
        "arxiv_id": "2409.14740",
        "authors": "Zheng Hui, Zhaoxiao Guo, Hang Zhao, Juanyong Duan, Congrui Huang",
        "summary": "In different NLP tasks, detecting harmful content is crucial for online environments, especially with the growing influence of social media. However, previous research has two main issues: 1) a lack of data in low-resource settings, and 2) inconsistent definitions and criteria for judging harmful content, requiring classification models to be robust to spurious features and diverse. We propose Toxicraft, a novel framework for synthesizing datasets of harmful information to address these weaknesses. With only a small amount of seed data, our framework can generate a wide variety of synthetic, yet remarkably realistic, examples of toxic information. Experimentation across various datasets showcases a notable enhancement in detection model robustness and adaptability, surpassing or close to the gold labels. We release the generated data at Github upon acceptance.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 06:36:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344616"
    },
    {
        "index": "#40",
        "title": "ERABAL: Enhancing Role-Playing Agents through Boundary-Aware Learning",
        "link": "/arxiv/2409.14710",
        "arxiv_id": "2409.14710",
        "authors": "Yihong Tang, Jiao Ou, Che Liu, Fuzheng Zhang, Di Zhang, Kun Gai",
        "summary": "Role-playing is an emerging application in the field of Human-Computer Interaction (HCI), primarily implemented through the alignment training of a large language model (LLM) with assigned characters. Despite significant progress, role-playing agents (RPLAs) still struggle with maintaining role-consistency across conversations, particularly when confronted with boundary queries subtly related to character attributes. In this paper, we present ERABAL, a framework aimed at enhancing RPLAs' role-playing capabilities through boundary-aware learning. ERABAL encompasses a generation pipeline for role-specific dialogues and a concomitant methodology for alignment training. Through comprehensive evaluations, we demonstrate that ERABAL is both efficient and effective. By training with significantly fewer dialogues than those used in leading approaches, ERABAL achieves notable improvements across WikiRoleEval, CharacterEval, and the role-playing subset of MT-Bench compared to the generalist baseline models. Our code and datasets will be made publicly available to support further research.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 05:12:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.344818"
    },
    {
        "index": "#41",
        "title": "Target-Aware Language Modeling via Granular Data Sampling",
        "link": "/arxiv/2409.14705",
        "arxiv_id": "2409.14705",
        "authors": "Ernie Chang, Pin-Jie Lin, Yang Li, Changsheng Zhao, Daeil Kim, Rastislav Rabatin, Zechun Liu, Yangyang Shi, Vikas Chandra",
        "summary": "Language model pretraining generally targets a broad range of use cases and incorporates data from diverse sources. However, there are instances where we desire a model that excels in specific areas without markedly compromising performance in other areas. A cost-effective and straightforward approach is sampling with low-dimensional data features, which allows to select large-scale pretraining data for domain-specific use cases. In this work, we revisit importance sampling with n-gram features consisting of multi-granular tokens, which strikes a good balance between sentence compression and representation capabilities. We observed the sampled data to have a high correlation with the target downstream task performance while preserving its effectiveness on other tasks. This leads to the proposed data sampling paradigm where language models can be pretrained more efficiently on selected documents. On eight benchmarks we demonstrate with $\\sim$1% of the data, pretrained models perform on par with the full RefinedWeb data and outperform randomly selected samples for model sizes ranging from 125M to 1.5B.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 04:52:17 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.345056"
    },
    {
        "index": "#42",
        "title": "Instruction Tuning Vs. In-Context Learning: Revisiting Large Language Models in Few-Shot Computational Social Science",
        "link": "/arxiv/2409.14673",
        "arxiv_id": "2409.14673",
        "authors": "Taihang Wang, Xiaoman Xu, Yimin Wang, Ye Jiang",
        "summary": "Real-world applications of large language models (LLMs) in computational social science (CSS) tasks primarily depend on the effectiveness of instruction tuning (IT) or in-context learning (ICL). While IT has shown highly effective at fine-tuning LLMs for various tasks, ICL offers a rapid alternative for task adaptation by learning from examples without explicit gradient updates. In this paper, we evaluate the classification performance of LLMs using IT versus ICL in few-shot CSS tasks. The experimental results indicate that ICL consistently outperforms IT in most CSS tasks. Additionally, we investigate the relationship between the increasing number of training samples and LLM performance. Our findings show that simply increasing the number of samples without considering their quality does not consistently enhance the performance of LLMs with either ICL or IT and can sometimes even result in a performance decline. Finally, we compare three prompting strategies, demonstrating that ICL is more effective than zero-shot and Chain-of-Thought (CoT). Our research highlights the significant advantages of ICL in handling CSS tasks in few-shot settings and emphasizes the importance of optimizing sample quality and prompting strategies to improve LLM classification performance. The code will be made available.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-23 02:43:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.345283"
    },
    {
        "index": "#43",
        "title": "Direct Judgement Preference Optimization",
        "link": "/arxiv/2409.14664",
        "arxiv_id": "2409.14664",
        "authors": "Peifeng Wang, Austin Xu, Yilun Zhou, Caiming Xiong, Shafiq Joty",
        "summary": "Auto-evaluation is crucial for assessing response quality and offering feedback for model development. Recent studies have explored training large language models (LLMs) as generative judges to evaluate and critique other models' outputs. In this work, we investigate the idea of learning from both positive and negative data with preference optimization to enhance the evaluation capabilities of LLM judges across an array of different use cases. We achieve this by employing three approaches to collect the preference pairs for different use cases, each aimed at improving our generative judge from a different perspective. Our comprehensive study over a wide range of benchmarks demonstrates the effectiveness of our method. In particular, our generative judge achieves the best performance on 10 out of 13 benchmarks, outperforming strong baselines like GPT-4o and specialized judge models. Further analysis show that our judge model robustly counters inherent biases such as position and length bias, flexibly adapts to any evaluation protocol specified by practitioners, and provides helpful language feedback for improving downstream generator models.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 02:08:20 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.345490"
    },
    {
        "index": "#44",
        "title": "Building Tamil Treebanks",
        "link": "/arxiv/2409.14657",
        "arxiv_id": "2409.14657",
        "authors": "Kengatharaiyer Sarveswaran",
        "summary": "Treebanks are important linguistic resources, which are structured and annotated corpora with rich linguistic annotations. These resources are used in Natural Language Processing (NLP) applications, supporting linguistic analyses, and are essential for training and evaluating various computational models. This paper discusses the creation of Tamil treebanks using three distinct approaches: manual annotation, computational grammars, and machine learning techniques. Manual annotation, though time-consuming and requiring linguistic expertise, ensures high-quality and rich syntactic and semantic information. Computational deep grammars, such as Lexical Functional Grammar (LFG), offer deep linguistic analyses but necessitate significant knowledge of the formalism. Machine learning approaches, utilising off-the-shelf frameworks and tools like Stanza, UDpipe, and UUParser, facilitate the automated annotation of large datasets but depend on the availability of quality annotated data, cross-linguistic training resources, and computational power. The paper discusses the challenges encountered in building Tamil treebanks, including issues with Internet data, the need for comprehensive linguistic analysis, and the difficulty of finding skilled annotators. Despite these challenges, the development of Tamil treebanks is essential for advancing linguistic research and improving NLP tools for Tamil.",
        "subjects": "Computation and Language",
        "date": "2024-09-23 01:58:50 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.350937"
    },
    {
        "index": "#45",
        "title": "Harmonising the Clinical Melody: Tuning Large Language Models for Hospital Course Summarisation in Clinical Coding",
        "link": "/arxiv/2409.14638",
        "arxiv_id": "2409.14638",
        "authors": "Bokang Bi, Leibo Liu, Oscar Perez-Concha, Sanja Lujic, Louisa Jorm",
        "summary": "The increasing volume and complexity of clinical documentation in Electronic Medical Records systems pose significant challenges for clinical coders, who must mentally process and summarise vast amounts of clinical text to extract essential information needed for coding tasks. While large language models have been successfully applied to shorter summarisation tasks in recent years, the challenge of summarising a hospital course remains an open area for further research and development. In this study, we adapted three pre trained LLMs, Llama 3, BioMistral, Mistral Instruct v0.1 for the hospital course summarisation task, using Quantized Low Rank Adaptation fine tuning. We created a free text clinical dataset from MIMIC III data by concatenating various clinical notes as the input clinical text, paired with ground truth Brief Hospital Course sections extracted from the discharge summaries for model training. The fine tuned models were evaluated using BERTScore and ROUGE metrics to assess the effectiveness of clinical domain fine tuning. Additionally, we validated their practical utility using a novel hospital course summary assessment metric specifically tailored for clinical coding. Our findings indicate that fine tuning pre trained LLMs for the clinical domain can significantly enhance their performance in hospital course summarisation and suggest their potential as assistive tools for clinical coding. Future work should focus on refining data curation methods to create higher quality clinical datasets tailored for hospital course summary tasks and adapting more advanced open source LLMs comparable to proprietary models to further advance this research.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-23 00:35:23 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.351391"
    },
    {
        "index": "#46",
        "title": "Can a Neural Model Guide Fieldwork? A Case Study on Morphological Inflection",
        "link": "/arxiv/2409.14628",
        "arxiv_id": "2409.14628",
        "authors": "Aso Mahmudi, Borja Herce, Demian Inostroza Amestica, Andreas Scherbakov, Eduard Hovy, Ekaterina Vylomova",
        "summary": "Linguistic fieldwork is an important component in language documentation and preservation. However, it is a long, exhaustive, and time-consuming process. This paper presents a novel model that guides a linguist during the fieldwork and accounts for the dynamics of linguist-speaker interactions. We introduce a novel framework that evaluates the efficiency of various sampling strategies for obtaining morphological data and assesses the effectiveness of state-of-the-art neural models in generalising morphological structures. Our experiments highlight two key strategies for improving the efficiency: (1) increasing the diversity of annotated data by uniform sampling among the cells of the paradigm tables, and (2) using model confidence as a guide to enhance positive interaction by providing reliable predictions during annotation.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 23:40:03 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.351792"
    },
    {
        "index": "#47",
        "title": "Can pre-trained language models generate titles for research papers?",
        "link": "/arxiv/2409.14602",
        "arxiv_id": "2409.14602",
        "authors": "Tohida Rehman, Debarshi Kumar Sanyal, Samiran Chattopadhyay",
        "summary": "The title of a research paper communicates in a succinct style the main theme and, sometimes, the findings of the paper. Coming up with the right title is often an arduous task, and therefore, it would be beneficial to authors if title generation can be automated. In this paper, we fine-tune pre-trained and large language models to generate titles of papers from their abstracts. We also use ChatGPT in a zero-shot setting to generate paper titles. The performance of the models is measured with ROUGE, METEOR, MoverScore, BERTScore and SciBERTScore metrics.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 21:34:49 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352115"
    },
    {
        "index": "#48",
        "title": "EchoAtt: Attend, Copy, then Adjust for More Efficient Large Language Models",
        "link": "/arxiv/2409.14595",
        "arxiv_id": "2409.14595",
        "authors": "Hossein Rajabzadeh, Aref Jafari, Aman Sharma, Benyamin Jami, Hyock Ju Kwon, Ali Ghodsi, Boxing Chen, Mehdi Rezagholizadeh",
        "summary": "Large Language Models (LLMs), with their increasing depth and number of parameters, have demonstrated outstanding performance across a variety of natural language processing tasks. However, this growth in scale leads to increased computational demands, particularly during inference and fine-tuning. To address these challenges, we introduce EchoAtt, a novel framework aimed at optimizing transformer-based models by analyzing and leveraging the similarity of attention patterns across layers. Our analysis reveals that many inner layers in LLMs, especially larger ones, exhibit highly similar attention matrices. By exploiting this similarity, EchoAtt enables the sharing of attention matrices in less critical layers, significantly reducing computational requirements without compromising performance. We incorporate this approach within a knowledge distillation setup, where a pre-trained teacher model guides the training of a smaller student model. The student model selectively shares attention matrices in layers with high similarity while inheriting key parameters from the teacher. Our best results with TinyLLaMA-1.1B demonstrate that EchoAtt improves inference speed by 15\\%, training speed by 25\\%, and reduces the number of parameters by approximately 4\\%, all while improving zero-shot performance. These findings highlight the potential of attention matrix sharing to enhance the efficiency of LLMs, making them more practical for real-time and resource-limited applications.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-22 21:08:37 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352409"
    },
    {
        "index": "#49",
        "title": "The X Types -- Mapping the Semantics of the Twitter Sphere",
        "link": "/arxiv/2409.14584",
        "arxiv_id": "2409.14584",
        "authors": "Ogen Schlachet Drukerman, Einat Minkov",
        "summary": "Social networks form a valuable source of world knowledge, where influential entities correspond to popular accounts. Unlike factual knowledge bases (KBs), which maintain a semantic ontology, structured semantic information is not available on social media. In this work, we consider a social KB of roughly 200K popular Twitter accounts, which denotes entities of interest. We elicit semantic information about those entities. In particular, we associate them with a fine-grained set of 136 semantic types, e.g., determine whether a given entity account belongs to a politician, or a musical artist. In the lack of explicit type information in Twitter, we obtain semantic labels for a subset of the accounts via alignment with the KBs of DBpedia and Wikidata. Given the labeled dataset, we finetune a transformer-based text encoder to generate semantic embeddings of the entities based on the contents of their accounts. We then exploit this evidence alongside network-based embeddings to predict the entities semantic types. In our experiments, we show high type prediction performance on the labeled dataset. Consequently, we apply our type classification model to all of the entity accounts in the social KB. Our analysis of the results offers insights about the global semantics of the Twitter sphere. We discuss downstream applications that should benefit from semantic type information and the semantic embeddings of social entities generated in this work. In particular, we demonstrate enhanced performance on the key task of entity similarity assessment using this information.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 20:22:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352578"
    },
    {
        "index": "#50",
        "title": "Medical Concept Normalization in a Low-Resource Setting",
        "link": "/arxiv/2409.14579",
        "arxiv_id": "2409.14579",
        "authors": "Tim Patzelt",
        "summary": "In the field of biomedical natural language processing, medical concept normalization is a crucial task for accurately mapping mentions of concepts to a large knowledge base. However, this task becomes even more challenging in low-resource settings, where limited data and resources are available. In this thesis, I explore the challenges of medical concept normalization in a low-resource setting. Specifically, I investigate the shortcomings of current medical concept normalization methods applied to German lay texts. Since there is no suitable dataset available, a dataset consisting of posts from a German medical online forum is annotated with concepts from the Unified Medical Language System. The experiments demonstrate that multilingual Transformer-based models are able to outperform string similarity methods. The use of contextual information to improve the normalization of lay mentions is also examined, but led to inferior results. Based on the results of the best performing model, I present a systematic error analysis and lay out potential improvements to mitigate frequent errors.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-06 10:19:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352746"
    },
    {
        "index": "#51",
        "title": "Evaluating the Performance and Robustness of LLMs in Materials Science Q&A and Property Predictions",
        "link": "/arxiv/2409.14572",
        "arxiv_id": "2409.14572",
        "authors": "Hongchen Wang, Kangming Li, Scott Ramsay, Yao Fehlis, Edward Kim, Jason Hattrick-Simpers",
        "summary": "Large Language Models (LLMs) have the potential to revolutionize scientific research, yet their robustness and reliability in domain-specific applications remain insufficiently explored. This study conducts a comprehensive evaluation and robustness analysis of LLMs within the field of materials science, focusing on domain-specific question answering and materials property prediction. Three distinct datasets are used in this study: 1) a set of multiple-choice questions from undergraduate-level materials science courses, 2) a dataset including various steel compositions and yield strengths, and 3) a band gap dataset, containing textual descriptions of material crystal structures and band gap values. The performance of LLMs is assessed using various prompting strategies, including zero-shot chain-of-thought, expert prompting, and few-shot in-context learning. The robustness of these models is tested against various forms of 'noise', ranging from realistic disturbances to intentionally adversarial manipulations, to evaluate their resilience and reliability under real-world conditions. Additionally, the study uncovers unique phenomena of LLMs during predictive tasks, such as mode collapse behavior when the proximity of prompt examples is altered and performance enhancement from train/test mismatch. The findings aim to provide informed skepticism for the broad use of LLMs in materials science and to inspire advancements that enhance their robustness and reliability for practical applications.",
        "subjects": "Computation and Language, Materials Science, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 19:31:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.352972"
    },
    {
        "index": "#52",
        "title": "Unleashing the Power of Emojis in Texts via Self-supervised Graph Pre-Training",
        "link": "/arxiv/2409.14552",
        "arxiv_id": "2409.14552",
        "authors": "Zhou Zhang, Dongzeng Tan, Jiaan Wang, Yilong Chen, Jiarong Xu",
        "summary": "Emojis have gained immense popularity on social platforms, serving as a common means to supplement or replace text. However, existing data mining approaches generally either completely ignore or simply treat emojis as ordinary Unicode characters, which may limit the model's ability to grasp the rich semantic information in emojis and the interaction between emojis and texts. Thus, it is necessary to release the emoji's power in social media data mining. To this end, we first construct a heterogeneous graph consisting of three types of nodes, i.e. post, word and emoji nodes to improve the representation of different elements in posts. The edges are also well-defined to model how these three elements interact with each other. To facilitate the sharing of information among post, word and emoji nodes, we propose a graph pre-train framework for text and emoji co-modeling, which contains two graph pre-training tasks: node-level graph contrastive learning and edge-level link reconstruction learning. Extensive experiments on the Xiaohongshu and Twitter datasets with two types of downstream tasks demonstrate that our approach proves significant improvement over previous strong baseline methods.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 18:29:10 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.353215"
    },
    {
        "index": "#53",
        "title": "Can AI writing be salvaged? Mitigating Idiosyncrasies and Improving Human-AI Alignment in the Writing Process through Edits",
        "link": "/arxiv/2409.14509",
        "arxiv_id": "2409.14509",
        "authors": "Tuhin Chakrabarty, Philippe Laban, Chien-Sheng Wu",
        "summary": "LLM-based applications are helping people write, and LLM-generated text is making its way into social media, journalism, and our classrooms. However, the differences between LLM-generated and human-written text remain unclear. To explore this, we hired professional writers to edit paragraphs in several creative domains. We first found these writers agree on undesirable idiosyncrasies in LLM-generated text, formalizing it into a seven-category taxonomy (e.g. cliches, unnecessary exposition). Second, we curated the LAMP corpus: 1,057 LLM-generated paragraphs edited by professional writers according to our taxonomy. Analysis of LAMP reveals that none of the LLMs used in our study (GPT4o, Claude-3.5-Sonnet, Llama-3.1-70b) outperform each other in terms of writing quality, revealing common limitations across model families. Third, we explored automatic editing methods to improve LLM-generated text. A large-scale preference annotation confirms that although experts largely prefer text edited by other experts, automatic editing methods show promise in improving alignment between LLM-generated and human-written text.",
        "subjects": "Computation and Language, Computers and Society, Human-Computer Interaction",
        "date": "2024-09-22 16:13:00 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.353479"
    },
    {
        "index": "#54",
        "title": "A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders",
        "link": "/arxiv/2409.14507",
        "arxiv_id": "2409.14507",
        "authors": "David Chanin, James Wilken-Smith, Tomáš Dulka, Hardik Bhatnagar, Joseph Bloom",
        "summary": "Sparse Autoencoders (SAEs) have emerged as a promising approach to decompose the activations of Large Language Models (LLMs) into human-interpretable latents. In this paper, we pose two questions. First, to what extent do SAEs extract monosemantic and interpretable latents? Second, to what extent does varying the sparsity or the size of the SAE affect monosemanticity / interpretability? By investigating these questions in the context of a simple first-letter identification task where we have complete access to ground truth labels for all tokens in the vocabulary, we are able to provide more detail than prior investigations. Critically, we identify a problematic form of feature-splitting we call feature absorption where seemingly monosemantic latents fail to fire in cases where they clearly should. Our investigation suggests that varying SAE size or sparsity is insufficient to solve this issue, and that there are deeper conceptual issues in need of resolution.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 16:11:02 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.353706"
    },
    {
        "index": "#55",
        "title": "Thought-Path Contrastive Learning via Premise-Oriented Data Augmentation for Logical Reading Comprehension",
        "link": "/arxiv/2409.14495",
        "arxiv_id": "2409.14495",
        "authors": "Chenxu Wang, Ping Jian, Yang Zhen",
        "summary": "Logical reading comprehension is a challenging task that entails grasping the underlying semantics of text and applying reasoning to deduce the correct answer. Prior researches have primarily focused on enhancing logical reasoning capabilities through Chain-of-Thought (CoT) or data augmentation. However, previous work constructing chain-of-thought rationales concentrates solely on analyzing correct options, neglecting the incorrect alternatives. Addtionally, earlier efforts on data augmentation by altering contexts rely on rule-based methods, which result in generated contexts that lack diversity and coherence. To address these issues, we propose a Premise-Oriented Data Augmentation (PODA) framework. This framework can generate CoT rationales including analyses for both correct and incorrect options, while constructing diverse and high-quality counterfactual contexts from incorrect candidate options. We integrate summarizing premises and identifying premises for each option into rationales. Subsequently, we employ multi-step prompts with identified premises to construct counterfactual context. To facilitate the model's capabilities to better differentiate the reasoning process associated with each option, we introduce a novel thought-path contrastive learning method that compares reasoning paths between the original and counterfactual samples. Experimental results on three representative LLMs demonstrate that our method can improve the baselines substantially across two challenging logical reasoning benchmarks (ReClor and LogiQA 2.0). The data and code are released at https://github.com/lalalamdbf/TPReasoner.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 15:44:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.353907"
    },
    {
        "index": "#56",
        "title": "CPT-Boosted Wav2vec2.0: Towards Noise Robust Speech Recognition for Classroom Environments",
        "link": "/arxiv/2409.14494",
        "arxiv_id": "2409.14494",
        "authors": "Ahmed Adel Attia, Dorottya Demszky, Tolulope Ogunremi, Jing Liu, Carol Espy-Wilson",
        "summary": "Creating Automatic Speech Recognition (ASR) systems that are robust and resilient to classroom conditions is paramount to the development of AI tools to aid teachers and students. In this work, we study the efficacy of continued pretraining (CPT) in adapting Wav2vec2.0 to the classroom domain. We show that CPT is a powerful tool in that regard and reduces the Word Error Rate (WER) of Wav2vec2.0-based models by upwards of 10%. More specifically, CPT improves the model's robustness to different noises, microphones and classroom conditions.",
        "subjects": "Computation and Language, Machine Learning, Sound, Audio and Speech Processing",
        "date": "2024-09-13 19:14:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354162"
    },
    {
        "index": "#57",
        "title": "Rethinking Semantic Parsing for Large Language Models: Enhancing LLM Performance with Semantic Hints",
        "link": "/arxiv/2409.14469",
        "arxiv_id": "2409.14469",
        "authors": "Kaikai An, Shuzheng Si, Helan Hu, Haozhe Zhao, Yuchi Wang, Qingyan Guo, Baobao Chang",
        "summary": "Semantic Parsing aims to capture the meaning of a sentence and convert it into a logical, structured form. Previous studies show that semantic parsing enhances the performance of smaller models (e.g., BERT) on downstream tasks. However, it remains unclear whether the improvements extend similarly to LLMs. In this paper, our empirical findings reveal that, unlike smaller models, directly adding semantic parsing results into LLMs reduces their performance. To overcome this, we propose SENSE, a novel prompting approach that embeds semantic hints within the prompt. Experiments show that SENSE consistently improves LLMs' performance across various tasks, highlighting the potential of integrating semantic information to improve LLM capabilities.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 14:35:09 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354384"
    },
    {
        "index": "#58",
        "title": "AggregHate: An Efficient Aggregative Approach for the Detection of Hatemongers on Social Platforms",
        "link": "/arxiv/2409.14464",
        "arxiv_id": "2409.14464",
        "authors": "Tom Marzea, Abraham Israeli, Oren Tsur",
        "summary": "Automatic detection of online hate speech serves as a crucial step in the detoxification of the online discourse. Moreover, accurate classification can promote a better understanding of the proliferation of hate as a social phenomenon. While most prior work focus on the detection of hateful utterances, we argue that focusing on the user level is as important, albeit challenging. In this paper we consider a multimodal aggregative approach for the detection of hate-mongers, taking into account the potentially hateful texts, user activity, and the user network. We evaluate our methods on three unique datasets X (Twitter), Gab, and Parler showing that a processing a user's texts in her social context significantly improves the detection of hate mongers, compared to previously used text and graph-based methods. Our method can be then used to improve the classification of coded messages, dog-whistling, and racial gas-lighting, as well as inform intervention measures. Moreover, our approach is highly efficient even for very large datasets and networks.",
        "subjects": "Computation and Language, Social and Information Networks",
        "date": "2024-09-22 14:29:49 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354570"
    },
    {
        "index": "#59",
        "title": "Exploring Multilingual Probing in Large Language Models: A Cross-Language Analysis",
        "link": "/arxiv/2409.14459",
        "arxiv_id": "2409.14459",
        "authors": "Daoyang Li, Mingyu Jin, Qingcheng Zeng, Haiyan Zhao, Mengnan Du",
        "summary": "Probing techniques for large language models (LLMs) have primarily focused on English, overlooking the vast majority of the world's languages. In this paper, we extend these probing methods to a multilingual context, investigating the behaviors of LLMs across diverse languages. We conduct experiments on several open-source LLM models, analyzing probing accuracy, trends across layers, and similarities between probing vectors for multiple languages. Our key findings reveal: (1) a consistent performance gap between high-resource and low-resource languages, with high-resource languages achieving significantly higher probing accuracy; (2) divergent layer-wise accuracy trends, where high-resource languages show substantial improvement in deeper layers similar to English; and (3) higher representational similarities among high-resource languages, with low-resource languages demonstrating lower similarities both among themselves and with high-resource languages. These results highlight significant disparities in LLMs' multilingual capabilities and emphasize the need for improved modeling of low-resource languages.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 14:14:05 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354789"
    },
    {
        "index": "#60",
        "title": "Automotive innovation landscaping using LLM",
        "link": "/arxiv/2409.14436",
        "arxiv_id": "2409.14436",
        "authors": "Raju Gorain, Omkar Salunke",
        "summary": "The process of landscaping automotive innovation through patent analysis is crucial for Research and Development teams. It aids in comprehending innovation trends, technological advancements, and the latest technologies from competitors. Traditionally, this process required intensive manual efforts. However, with the advent of Large Language Models (LLMs), it can now be automated, leading to faster and more efficient patent categorization & state-of-the-art of inventive concept extraction. This automation can assist various R\\&D teams in extracting relevant information from extensive patent databases. This paper introduces a method based on prompt engineering to extract essential information for landscaping. The information includes the problem addressed by the patent, the technology utilized, and the area of innovation within the vehicle ecosystem (such as safety, Advanced Driver Assistance Systems and more).The result demonstrates the implementation of this method to create a landscape of fuel cell technology using open-source patent data. This approach provides a comprehensive overview of the current state of fuel cell technology, offering valuable insights for future research and development in this field.",
        "subjects": "Computation and Language, Artificial Intelligence, Robotics",
        "date": "2024-09-22 13:22:39 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.354985"
    },
    {
        "index": "#61",
        "title": "Beyond Persuasion: Towards Conversational Recommender System with Credible Explanations",
        "link": "/arxiv/2409.14399",
        "arxiv_id": "2409.14399",
        "authors": "Peixin Qin, Chen Huang, Yang Deng, Wenqiang Lei, Tat-Seng Chua",
        "summary": "With the aid of large language models, current conversational recommender system (CRS) has gaining strong abilities to persuade users to accept recommended items. While these CRSs are highly persuasive, they can mislead users by incorporating incredible information in their explanations, ultimately damaging the long-term trust between users and the CRS. To address this, we propose a simple yet effective method, called PC-CRS, to enhance the credibility of CRS's explanations during persuasion. It guides the explanation generation through our proposed credibility-aware persuasive strategies and then gradually refines explanations via post-hoc self-reflection. Experimental results demonstrate the efficacy of PC-CRS in promoting persuasive and credible explanations. Further analysis reveals the reason behind current methods producing incredible explanations and the potential of credible explanations to improve recommendation accuracy.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 11:35:59 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.355185"
    },
    {
        "index": "#62",
        "title": "Predicting User Stances from Target-Agnostic Information using Large Language Models",
        "link": "/arxiv/2409.14395",
        "arxiv_id": "2409.14395",
        "authors": "Siyuan Brandon Loh, Liang Ze Wong, Prasanta Bhattacharya, Joseph Simons, Wei Gao, Hong Zhang",
        "summary": "We investigate Large Language Models' (LLMs) ability to predict a user's stance on a target given a collection of his/her target-agnostic social media posts (i.e., user-level stance prediction). While we show early evidence that LLMs are capable of this task, we highlight considerable variability in the performance of the model across (i) the type of stance target, (ii) the prediction strategy and (iii) the number of target-agnostic posts supplied. Post-hoc analyses further hint at the usefulness of target-agnostic posts in providing relevant information to LLMs through the presence of both surface-level (e.g., target-relevant keywords) and user-level features (e.g., encoding users' moral values). Overall, our findings suggest that LLMs might offer a viable method for determining public stances towards new topics based on historical and target-agnostic data. At the same time, we also call for further research to better understand LLMs' strong performance on the stance prediction task and how their effectiveness varies across task contexts.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 11:21:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.355497"
    },
    {
        "index": "#63",
        "title": "Investigating Layer Importance in Large Language Models",
        "link": "/arxiv/2409.14381",
        "arxiv_id": "2409.14381",
        "authors": "Yang Zhang, Yanfei Dong, Kenji Kawaguchi",
        "summary": "Large language models (LLMs) have gained increasing attention due to their prominent ability to understand and process texts. Nevertheless, LLMs largely remain opaque. The lack of understanding of LLMs has obstructed the deployment in safety-critical scenarios and hindered the development of better models. In this study, we advance the understanding of LLM by investigating the significance of individual layers in LLMs. We propose an efficient sampling method to faithfully evaluate the importance of layers using Shapley values, a widely used explanation framework in feature attribution and data valuation. In addition, we conduct layer ablation experiments to assess the performance degradation resulting from the exclusion of specific layers. Our findings reveal the existence of cornerstone layers, wherein certain early layers can exhibit a dominant contribution over others. Removing one cornerstone layer leads to a drastic collapse of the model performance, often reducing it to random guessing. Conversely, removing non-cornerstone layers results in only marginal performance changes. This study identifies cornerstone layers in LLMs and underscores their critical role for future research.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-22 09:53:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.355696"
    },
    {
        "index": "#64",
        "title": "J2N -- Nominal Adjective Identification and its Application",
        "link": "/arxiv/2409.14374",
        "arxiv_id": "2409.14374",
        "authors": "Lemeng Qi, Yang Han, Zhuotong Xie",
        "summary": "This paper explores the challenges posed by nominal adjectives (NAs) in natural language processing (NLP) tasks, particularly in part-of-speech (POS) tagging. We propose treating NAs as a distinct POS tag, \"JN,\" and investigate its impact on POS tagging, BIO chunking, and coreference resolution. Our study shows that reclassifying NAs can improve the accuracy of syntactic analysis and structural understanding in NLP. We present experimental results using Hidden Markov Models (HMMs), Maximum Entropy (MaxEnt) models, and Spacy, demonstrating the feasibility and potential benefits of this approach. Additionally we trained a bert model to identify the NA in untagged text.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 09:33:54 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.355874"
    },
    {
        "index": "#65",
        "title": "The Ability of Large Language Models to Evaluate Constraint-satisfaction in Agent Responses to Open-ended Requests",
        "link": "/arxiv/2409.14371",
        "arxiv_id": "2409.14371",
        "authors": "Lior Madmoni, Amir Zait, Ilia Labzovsky, Danny Karmon",
        "summary": "Generative AI agents are often expected to respond to complex user requests that have No One Right Answer (NORA), e.g., \"design a vegetarian meal plan below 1800 calories\". Such requests may entail a set of constraints that the agent should adhere to. To successfully develop agents for NORA scenarios, an accurate automatic evaluation framework is essential, and specifically - one capable of validating the satisfaction of constraints in the agent's response. Recently, large language models (LLMs) have been adopted as versatile evaluators for many NORA tasks, but their ability to evaluate constraint-satisfaction in generated text remains unclear. To study this, we develop and release a novel Arithmetic Constraint-Satisfaction (ACS) benchmarking dataset. The dataset consists of complex user requests with corresponding constraints, agent responses and human labels indicating each constraint's satisfaction level in the response. A unique property of this dataset is that validating many of its constraints requires reviewing the response as a whole (in contrast to many other benchmarks that require the validation of a single independent item). Moreover, it assesses LLMs in performing reasoning, in-context data extraction, arithmetic calculations, and counting. We then benchmark both open and proprietary LLMs on evaluating constraint-satisfaction, and show that most models still have a significant headroom for improvement, and that errors primarily stem from reasoning issues. In addition, most models exhibit a skewed constraint-satisfaction prediction pattern, with higher accuracy where the ground-truth label is \"satisfied\". Lastly, few-shot prompting for our task proved to be rather challenging, since many of the studied models showed a degradation in performance when it was introduced.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 09:27:42 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.473885"
    },
    {
        "index": "#66",
        "title": "More Effective LLM Compressed Tokens with Uniformly Spread Position Identifiers and Compression Loss",
        "link": "/arxiv/2409.14364",
        "arxiv_id": "2409.14364",
        "authors": "Runsong Zhao, Pengcheng Huang, Xinyu Liu, Chunyang Xiao, Tong Xiao, Jingbo Zhu",
        "summary": "Compressing Transformer inputs into compressd tokens allows running LLMs with improved speed and cost efficiency. Based on the compression method ICAE, we carefully examine the position identifier choices for compressed tokens and also propose a new compression loss. We demonstrate empirically that our proposed methods achieve significantly higher compression ratios (15x compared to 4x for ICAE), while being able to attain comparable reconstruction performance.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 08:51:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.490842"
    },
    {
        "index": "#67",
        "title": "Using Natural Language Processing to find Indication for Burnout with Text Classification: From Online Data to Real-World Data",
        "link": "/arxiv/2409.14357",
        "arxiv_id": "2409.14357",
        "authors": "Mascha Kurpicz-Briki, Ghofrane Merhbene, Alexandre Puttick, Souhir Ben Souissi, Jannic Bieri, Thomas Jörg Müller, Christoph Golz",
        "summary": "Burnout, classified as a syndrome in the ICD-11, arises from chronic workplace stress that has not been effectively managed. It is characterized by exhaustion, cynicism, and reduced professional efficacy, and estimates of its prevalence vary significantly due to inconsistent measurement methods. Recent advancements in Natural Language Processing (NLP) and machine learning offer promising tools for detecting burnout through textual data analysis, with studies demonstrating high predictive accuracy. This paper contributes to burnout detection in German texts by: (a) collecting an anonymous real-world dataset including free-text answers and Oldenburg Burnout Inventory (OLBI) responses; (b) demonstrating the limitations of a GermanBERT-based classifier trained on online data; (c) presenting two versions of a curated BurnoutExpressions dataset, which yielded models that perform well in real-world applications; and (d) providing qualitative insights from an interdisciplinary focus group on the interpretability of AI models used for burnout detection. Our findings emphasize the need for greater collaboration between AI researchers and clinical experts to refine burnout detection models. Additionally, more real-world data is essential to validate and enhance the effectiveness of current AI methods developed in NLP research, which are often based on data automatically scraped from online sources and not evaluated in a real-world context. This is essential for ensuring AI tools are well suited for practical applications.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-22 08:13:17 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.491271"
    },
    {
        "index": "#68",
        "title": "MQM-APE: Toward High-Quality Error Annotation Predictors with Automatic Post-Editing in LLM Translation Evaluators",
        "link": "/arxiv/2409.14335",
        "arxiv_id": "2409.14335",
        "authors": "Qingyu Lu, Liang Ding, Kanjian Zhang, Jinxia Zhang, Dacheng Tao",
        "summary": "Large Language Models (LLMs) have shown significant potential as judges for Machine Translation (MT) quality assessment, providing both scores and fine-grained feedback. Although approaches such as GEMBA-MQM has shown SOTA performance on reference-free evaluation, the predicted errors do not align well with those annotated by human, limiting their interpretability as feedback signals. To enhance the quality of error annotations predicted by LLM evaluators, we introduce a universal and training-free framework, $\\textbf{MQM-APE}$, based on the idea of filtering out non-impactful errors by Automatically Post-Editing (APE) the original translation based on each error, leaving only those errors that contribute to quality improvement. Specifically, we prompt the LLM to act as 1) $\\textit{evaluator}$ to provide error annotations, 2) $\\textit{post-editor}$ to determine whether errors impact quality improvement and 3) $\\textit{pairwise quality verifier}$ as the error filter. Experiments show that our approach consistently improves both the reliability and quality of error spans against GEMBA-MQM, across eight LLMs in both high- and low-resource languages. Orthogonal to trained approaches, MQM-APE complements translation-specific evaluators such as Tower, highlighting its broad applicability. Further analysis confirm the effectiveness of each module and offer valuable insights into evaluator design and LLMs selection. The code will be released to facilitate the community.",
        "subjects": "Computation and Language",
        "date": "2024-09-22 06:43:40 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.491552"
    },
    {
        "index": "#69",
        "title": "Unveiling Narrative Reasoning Limits of Large Language Models with Trope in Movie Synopses",
        "link": "/arxiv/2409.14324",
        "arxiv_id": "2409.14324",
        "authors": "Hung-Ting Su, Ya-Ching Hsu, Xudong Lin, Xiang-Qian Shi, Yulei Niu, Han-Yuan Hsu, Hung-yi Lee, Winston H. Hsu",
        "summary": "Large language models (LLMs) equipped with chain-of-thoughts (CoT) prompting have shown significant multi-step reasoning capabilities in factual content like mathematics, commonsense, and logic. However, their performance in narrative reasoning, which demands greater abstraction capabilities, remains unexplored. This study utilizes tropes in movie synopses to assess the abstract reasoning abilities of state-of-the-art LLMs and uncovers their low performance. We introduce a trope-wise querying approach to address these challenges and boost the F1 score by 11.8 points. Moreover, while prior studies suggest that CoT enhances multi-step reasoning, this study shows CoT can cause hallucinations in narrative content, reducing GPT-4's performance. We also introduce an Adversarial Injection method to embed trope-related text tokens into movie synopses without explicit tropes, revealing CoT's heightened sensitivity to such injections. Our comprehensive analysis provides insights for future research directions.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 05:50:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.491781"
    },
    {
        "index": "#70",
        "title": "PretextTrans: Investigating Medical Factual Knowledge Mastery of LLMs with Predicate-text Dual Transformation",
        "link": "/arxiv/2409.14302",
        "arxiv_id": "2409.14302",
        "authors": "Yuxuan Zhou, Xien Liu, Chen Ning, Ji Wu",
        "summary": "In the study, we aim to investigate current LLMs' mastery of medical factual knowledge with a dynamic evaluation schema, which can automatically generate multiple test samples for each medical factual knowledge point. Test samples produced directly by LLMs always introduce factual errors and lack diversity in the manner of knowledge expression. To overcome the drawbacks, here we propose a novel evaluation method, Predicate-text Dual Transformation (PretextTrans), by introducing predicate transformations into the dynamic evaluation schema. Specifically, each medical knowledge point is firstly transformed into a predicate expression; then, the predicate expression derives a series of variants through predicate transformations; lastly, the produced predicate variants are transformed back into textual expressions, resulting in a series of test samples with both factual reliability and expression diversity. Using the proposed PretextTrans method, we systematically investigate 12 well-known LLMs' mastery of medical factual knowledge based on two medical datasets. The comparison results show that current LLMs still have significant deficiencies in fully mastering medical knowledge, which may illustrate why current LLMs still perform unsatisfactorily in real-world medical scenarios despite having achieved considerable performance on public benchmarks. Our proposed method serves as an effective solution for evaluation of LLMs in medical domain and offers valuable insights for developing medical-specific LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 03:13:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.491970"
    },
    {
        "index": "#71",
        "title": "ESPERANTO: Evaluating Synthesized Phrases to Enhance Robustness in AI Detection for Text Origination",
        "link": "/arxiv/2409.14285",
        "arxiv_id": "2409.14285",
        "authors": "Navid Ayoobi, Lily Knab, Wen Cheng, David Pantoja, Hamidreza Alikhani, Sylvain Flamant, Jin Kim, Arjun Mukherjee",
        "summary": "While large language models (LLMs) exhibit significant utility across various domains, they simultaneously are susceptible to exploitation for unethical purposes, including academic misconduct and dissemination of misinformation. Consequently, AI-generated text detection systems have emerged as a countermeasure. However, these detection mechanisms demonstrate vulnerability to evasion techniques and lack robustness against textual manipulations. This paper introduces back-translation as a novel technique for evading detection, underscoring the need to enhance the robustness of current detection systems. The proposed method involves translating AI-generated text through multiple languages before back-translating to English. We present a model that combines these back-translated texts to produce a manipulated version of the original AI-generated text. Our findings demonstrate that the manipulated text retains the original semantics while significantly reducing the true positive rate (TPR) of existing detection methods. We evaluate this technique on nine AI detectors, including six open-source and three proprietary systems, revealing their susceptibility to back-translation manipulation. In response to the identified shortcomings of existing AI text detectors, we present a countermeasure to improve the robustness against this form of manipulation. Our results indicate that the TPR of the proposed method declines by only 1.85% after back-translation manipulation. Furthermore, we build a large dataset of 720k texts using eight different LLMs. Our dataset contains both human-authored and LLM-generated texts in various domains and writing styles to assess the performance of our method and existing detectors. This dataset is publicly shared for the benefit of the research community.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-22 01:13:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.492267"
    },
    {
        "index": "#72",
        "title": "Instruction Following without Instruction Tuning",
        "link": "/arxiv/2409.14254",
        "arxiv_id": "2409.14254",
        "authors": "John Hewitt, Nelson F. Liu, Percy Liang, Christopher D. Manning",
        "summary": "Instruction tuning commonly means finetuning a language model on instruction-response pairs. We discover two forms of adaptation (tuning) that are deficient compared to instruction tuning, yet still yield instruction following; we call this implicit instruction tuning. We first find that instruction-response pairs are not necessary: training solely on responses, without any corresponding instructions, yields instruction following. This suggests pretrained models have an instruction-response mapping which is revealed by teaching the model the desired distribution of responses. However, we then find it's not necessary to teach the desired distribution of responses: instruction-response training on narrow-domain data like poetry still leads to broad instruction-following behavior like recipe generation. In particular, when instructions are very different from those in the narrow finetuning domain, models' responses do not adhere to the style of the finetuning domain. To begin to explain implicit instruction tuning, we hypothesize that very simple changes to a language model's distribution yield instruction following. We support this by hand-writing a rule-based language model which yields instruction following in a product-of-experts with a pretrained model. The rules are to slowly increase the probability of ending the sequence, penalize repetition, and uniformly change 15 words' probabilities. In summary, adaptations made without being designed to yield instruction following can do so implicitly.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 22:36:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.492468"
    },
    {
        "index": "#73",
        "title": "Repairs in a Block World: A New Benchmark for Handling User Corrections with Multi-Modal Language Models",
        "link": "/arxiv/2409.14247",
        "arxiv_id": "2409.14247",
        "authors": "Javier Chiyah-Garcia, Alessandro Suglia, Arash Eshghi",
        "summary": "In dialogue, the addressee may initially misunderstand the speaker and respond erroneously, often prompting the speaker to correct the misunderstanding in the next turn with a Third Position Repair (TPR). The ability to process and respond appropriately to such repair sequences is thus crucial in conversational AI systems. In this paper, we first collect, analyse, and publicly release BlockWorld-Repairs: a dataset of multi-modal TPR sequences in an instruction-following manipulation task that is, by design, rife with referential ambiguity. We employ this dataset to evaluate several state-of-the-art Vision and Language Models (VLM) across multiple settings, focusing on their capability to process and accurately respond to TPRs and thus recover from miscommunication. We find that, compared to humans, all models significantly underperform in this task. We then show that VLMs can benefit from specialised losses targeting relevant tokens during fine-tuning, achieving better performance and generisability. Our results suggest that these models are not yet ready to be deployed in multi-modal collaborative settings where repairs are common, and highlight the need to design training regimes and objectives that facilitate learning from interaction.",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2024-09-21 21:06:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.492652"
    },
    {
        "index": "#74",
        "title": "Data-centric NLP Backdoor Defense from the Lens of Memorization",
        "link": "/arxiv/2409.14200",
        "arxiv_id": "2409.14200",
        "authors": "Zhenting Wang, Zhizhi Wang, Mingyu Jin, Mengnan Du, Juan Zhai, Shiqing Ma",
        "summary": "Backdoor attack is a severe threat to the trustworthiness of DNN-based language models. In this paper, we first extend the definition of memorization of language models from sample-wise to more fine-grained sentence element-wise (e.g., word, phrase, structure, and style), and then point out that language model backdoors are a type of element-wise memorization. Through further analysis, we find that the strength of such memorization is positively correlated to the frequency of duplicated elements in the training dataset. In conclusion, duplicated sentence elements are necessary for successful backdoor attacks. Based on this, we propose a data-centric defense. We first detect trigger candidates in training data by finding memorizable elements, i.e., duplicated elements, and then confirm real triggers by testing if the candidates can activate backdoor behaviors (i.e., malicious elements). Results show that our method outperforms state-of-the-art defenses in defending against different types of NLP backdoors.",
        "subjects": "Computation and Language, Cryptography and Security, Machine Learning",
        "date": "2024-09-21 17:12:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.492861"
    },
    {
        "index": "#75",
        "title": "The Imperative of Conversation Analysis in the Era of LLMs: A Survey of Tasks, Techniques, and Trends",
        "link": "/arxiv/2409.14195",
        "arxiv_id": "2409.14195",
        "authors": "Xinghua Zhang, Haiyang Yu, Yongbin Li, Minzheng Wang, Longze Chen, Fei Huang",
        "summary": "In the era of large language models (LLMs), a vast amount of conversation logs will be accumulated thanks to the rapid development trend of language UI. Conversation Analysis (CA) strives to uncover and analyze critical information from conversation data, streamlining manual processes and supporting business insights and decision-making. The need for CA to extract actionable insights and drive empowerment is becoming increasingly prominent and attracting widespread attention. However, the lack of a clear scope for CA leads to a dispersion of various techniques, making it difficult to form a systematic technical synergy to empower business applications. In this paper, we perform a thorough review and systematize CA task to summarize the existing related work. Specifically, we formally define CA task to confront the fragmented and chaotic landscape in this field, and derive four key steps of CA from conversation scene reconstruction, to in-depth attribution analysis, and then to performing targeted training, finally generating conversations based on the targeted training for achieving the specific goals. In addition, we showcase the relevant benchmarks, discuss potential challenges and point out future directions in both industry and academia. In view of current advancements, it is evident that the majority of efforts are still concentrated on the analysis of shallow conversation elements, which presents a considerable gap between the research and business, and with the assist of LLMs, recent work has shown a trend towards research on causality and strategic tasks which are sophisticated and high-level. The analyzed experiences and insights will inevitably have broader application value in business operations that target conversation logs.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 16:52:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.493051"
    },
    {
        "index": "#76",
        "title": "Knowledge in Triples for LLMs: Enhancing Table QA Accuracy with Semantic Extraction",
        "link": "/arxiv/2409.14192",
        "arxiv_id": "2409.14192",
        "authors": "Hossein Sholehrasa, Sanaz Saki Norouzi, Pascal Hitzler, Majid Jaberi-Douraki",
        "summary": "Integrating structured knowledge from tabular formats poses significant challenges within natural language processing (NLP), mainly when dealing with complex, semi-structured tables like those found in the FeTaQA dataset. These tables require advanced methods to interpret and generate meaningful responses accurately. Traditional approaches, such as SQL and SPARQL, often fail to fully capture the semantics of such data, especially in the presence of irregular table structures like web tables. This paper addresses these challenges by proposing a novel approach that extracts triples straightforward from tabular data and integrates it with a retrieval-augmented generation (RAG) model to enhance the accuracy, coherence, and contextual richness of responses generated by a fine-tuned GPT-3.5-turbo-0125 model. Our approach significantly outperforms existing baselines on the FeTaQA dataset, particularly excelling in Sacre-BLEU and ROUGE metrics. It effectively generates contextually accurate and detailed long-form answers from tables, showcasing its strength in complex data interpretation.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2024-09-21 16:46:15 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.493239"
    },
    {
        "index": "#77",
        "title": "QMOS: Enhancing LLMs for Telecommunication with Question Masked loss and Option Shuffling",
        "link": "/arxiv/2409.14175",
        "arxiv_id": "2409.14175",
        "authors": "Blessed Guda, Gabrial Zencha A., Lawrence Francis, Carlee Joe-Wong",
        "summary": "Large Language models (LLMs) have brought about substantial advancements in the field of Question Answering (QA) systems. These models do remarkably well in addressing intricate inquiries in a variety of disciplines. However, because of domain-specific vocabulary, complex technological concepts, and the requirement for exact responses applying LLMs to specialized sectors like telecommunications presents additional obstacles. GPT-3.5 has been used in recent work, to obtain noteworthy accuracy for telecom-related questions in a Retrieval Augmented Generation (RAG) framework. Notwithstanding these developments, the practical use of models such as GPT-3.5 is restricted by their proprietary nature and high computing demands. This paper introduces QMOS, an innovative approach which uses a Question-Masked loss and Option Shuffling trick to enhance the performance of LLMs in answering Multiple-Choice Questions in the telecommunications domain. Our focus was on using opensource, smaller language models (Phi-2 and Falcon-7B) within an enhanced RAG framework. Our multi-faceted approach involves several enhancements to the whole LLM-RAG pipeline of finetuning, retrieval, prompt engineering and inference. Our approaches significantly outperform existing results, achieving accuracy improvements from baselines of 24.70% to 49.30% with Falcon-7B and from 42.07% to 84.65% with Phi-2.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-21 15:32:10 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.493432"
    },
    {
        "index": "#78",
        "title": "Towards Building Efficient Sentence BERT Models using Layer Pruning",
        "link": "/arxiv/2409.14168",
        "arxiv_id": "2409.14168",
        "authors": "Anushka Shelke, Riya Savant, Raviraj Joshi",
        "summary": "This study examines the effectiveness of layer pruning in creating efficient Sentence BERT (SBERT) models. Our goal is to create smaller sentence embedding models that reduce complexity while maintaining strong embedding similarity. We assess BERT models like Muril and MahaBERT-v2 before and after pruning, comparing them with smaller, scratch-trained models like MahaBERT-Small and MahaBERT-Smaller. Through a two-phase SBERT fine-tuning process involving Natural Language Inference (NLI) and Semantic Textual Similarity (STS), we evaluate the impact of layer reduction on embedding quality. Our findings show that pruned models, despite fewer layers, perform competitively with fully layered versions. Moreover, pruned models consistently outperform similarly sized, scratch-trained models, establishing layer pruning as an effective strategy for creating smaller, efficient embedding models. These results highlight layer pruning as a practical approach for reducing computational demand while preserving high-quality embeddings, making SBERT models more accessible for languages with limited technological resources.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-21 15:10:06 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.493740"
    },
    {
        "index": "#79",
        "title": "On Importance of Pruning and Distillation for Efficient Low Resource NLP",
        "link": "/arxiv/2409.14162",
        "arxiv_id": "2409.14162",
        "authors": "Aishwarya Mirashi, Purva Lingayat, Srushti Sonavane, Tejas Padhiyar, Raviraj Joshi, Geetanjali Kale",
        "summary": "The rise of large transformer models has revolutionized Natural Language Processing, leading to significant advances in tasks like text classification. However, this progress demands substantial computational resources, escalating training duration, and expenses with larger model sizes. Efforts have been made to downsize and accelerate English models (e.g., Distilbert, MobileBert). Yet, research in this area is scarce for low-resource languages. In this study, we explore the case of the low-resource Indic language Marathi. Leveraging the marathi-topic-all-doc-v2 model as our baseline, we implement optimization techniques to reduce computation time and memory usage. Our focus is on enhancing the efficiency of Marathi transformer models while maintaining top-tier accuracy and reducing computational demands. Using the MahaNews document classification dataset and the marathi-topic-all-doc-v2 model from L3Cube, we apply Block Movement Pruning, Knowledge Distillation, and Mixed Precision methods individually and in combination to boost efficiency. We demonstrate the importance of strategic pruning levels in achieving desired efficiency gains. Furthermore, we analyze the balance between efficiency improvements and environmental impact, highlighting how optimized model architectures can contribute to a more sustainable computational ecosystem. Implementing these techniques on a single GPU system, we determine that the optimal configuration is 25\\% pruning + knowledge distillation. This approach yielded a 2.56x speedup in computation time while maintaining baseline accuracy levels.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-21 14:58:12 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494011"
    },
    {
        "index": "#80",
        "title": "Interpreting Arithmetic Mechanism in Large Language Models through Comparative Neuron Analysis",
        "link": "/arxiv/2409.14144",
        "arxiv_id": "2409.14144",
        "authors": "Zeping Yu, Sophia Ananiadou",
        "summary": "We find arithmetic ability resides within a limited number of attention heads, with each head specializing in distinct operations. To delve into the reason, we introduce the Comparative Neuron Analysis (CNA) method, which identifies an internal logic chain consisting of four distinct stages from input to prediction: feature enhancing with shallow FFN neurons, feature transferring by shallow attention layers, feature predicting by arithmetic heads, and prediction enhancing among deep FFN neurons. Moreover, we identify the human-interpretable FFN neurons within both feature-enhancing and feature-predicting stages. These findings lead us to investigate the mechanism of LoRA, revealing that it enhances prediction probabilities by amplifying the coefficient scores of FFN neurons related to predictions. Finally, we apply our method in model pruning for arithmetic tasks and model editing for reducing gender bias. Code is on https://github.com/zepingyu0512/arithmetic-mechanism.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 13:46:54 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494237"
    },
    {
        "index": "#81",
        "title": "Obliviate: Neutralizing Task-agnostic Backdoors within the Parameter-efficient Fine-tuning Paradigm",
        "link": "/arxiv/2409.14119",
        "arxiv_id": "2409.14119",
        "authors": "Jaehan Kim, Minkyoo Song, Seung Ho Na, Seungwon Shin",
        "summary": "Parameter-efficient fine-tuning (PEFT) has become a key training strategy for large language models. However, its reliance on fewer trainable parameters poses security risks, such as task-agnostic backdoors. Despite their severe impact on a wide range of tasks, there is no practical defense solution available that effectively counters task-agnostic backdoors within the context of PEFT. In this study, we introduce Obliviate, a PEFT-integrable backdoor defense. We develop two techniques aimed at amplifying benign neurons within PEFT layers and penalizing the influence of trigger tokens. Our evaluations across three major PEFT architectures show that our method can significantly reduce the attack success rate of the state-of-the-art task-agnostic backdoors (83.6%$\\downarrow$). Furthermore, our method exhibits robust defense capabilities against both task-specific backdoors and adaptive attacks. Source code will be obtained at https://github.com/obliviateARR/Obliviate.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security, Machine Learning",
        "date": "2024-09-21 12:20:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494480"
    },
    {
        "index": "#82",
        "title": "Routing in Sparsely-gated Language Models responds to Context",
        "link": "/arxiv/2409.14107",
        "arxiv_id": "2409.14107",
        "authors": "Stefan Arnold, Marian Fietta, Dilara Yesilbas",
        "summary": "Language Models (LMs) recently incorporate mixture-of-experts layers consisting of a router and a collection of experts to scale up their parameter count given a fixed computational budget. Building on previous efforts indicating that token-expert assignments are predominantly influenced by token identities and positions, we trace routing decisions of similarity-annotated text pairs to evaluate the context sensitivity of learned token-expert assignments. We observe that routing in encoder layers mainly depends on (semantic) associations, but contextual cues provide an additional layer of refinement. Conversely, routing in decoder layers is more variable and markedly less sensitive to context.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 11:25:19 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494667"
    },
    {
        "index": "#83",
        "title": "Probing Context Localization of Polysemous Words in Pre-trained Language Model Sub-Layers",
        "link": "/arxiv/2409.14097",
        "arxiv_id": "2409.14097",
        "authors": "Soniya Vijayakumar, Josef van Genabith, Simon Ostermann",
        "summary": "In the era of high performing Large Language Models, researchers have widely acknowledged that contextual word representations are one of the key drivers in achieving top performances in downstream tasks. In this work, we investigate the degree of contextualization encoded in the fine-grained sub-layer representations of a Pre-trained Language Model (PLM) by empirical experiments using linear probes. Unlike previous work, we are particularly interested in identifying the strength of contextualization across PLM sub-layer representations (i.e. Self-Attention, Feed-Forward Activation and Output sub-layers). To identify the main contributions of sub-layers to contextualisation, we first extract the sub-layer representations of polysemous words in minimally different sentence pairs, and compare how these representations change through the forward pass of the PLM network. Second, by probing on a sense identification classification task, we try to empirically localize the strength of contextualization information encoded in these sub-layer representations. With these probing experiments, we also try to gain a better understanding of the influence of context length and context richness on the degree of contextualization. Our main conclusion is cautionary: BERT demonstrates a high degree of contextualization in the top sub-layers if the word in question is in a specific position in the sentence with a shorter context window, but this does not systematically generalize across different word positions and context sizes.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 10:42:07 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.494843"
    },
    {
        "index": "#84",
        "title": "PTD-SQL: Partitioning and Targeted Drilling with LLMs in Text-to-SQL",
        "link": "/arxiv/2409.14082",
        "arxiv_id": "2409.14082",
        "authors": "Ruilin Luo, Liyuan Wang, Binghuai Lin, Zicheng Lin, Yujiu Yang",
        "summary": "Large Language Models (LLMs) have emerged as powerful tools for Text-to-SQL tasks, exhibiting remarkable reasoning capabilities. Different from tasks such as math word problems and commonsense reasoning, SQL solutions have a relatively fixed pattern. This facilitates the investigation of whether LLMs can benefit from categorical thinking, mirroring how humans acquire knowledge through inductive reasoning based on comparable examples. In this study, we propose that employing query group partitioning allows LLMs to focus on learning the thought processes specific to a single problem type, consequently enhancing their reasoning abilities across diverse difficulty levels and problem categories. Our experiments reveal that multiple advanced LLMs, when equipped with PTD-SQL, can either surpass or match previous state-of-the-art (SOTA) methods on the Spider and BIRD datasets. Intriguingly, models with varying initial performances have exhibited significant improvements, mainly at the boundary of their capabilities after targeted drilling, suggesting a parallel with human progress. Code is available at https://github.com/lrlbbzl/PTD-SQL.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 09:33:14 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.495050"
    },
    {
        "index": "#85",
        "title": "MultiMed: Multilingual Medical Speech Recognition via Attention Encoder Decoder",
        "link": "/arxiv/2409.14074",
        "arxiv_id": "2409.14074",
        "authors": "Khai Le-Duc, Phuc Phan, Tan-Hanh Pham, Bach Phan Tat, Minh-Huong Ngo, Truong-Son Hy",
        "summary": "Multilingual automatic speech recognition (ASR) in the medical domain serves as a foundational task for various downstream applications such as speech translation, spoken language understanding, and voice-activated assistants. This technology enhances patient care by enabling efficient communication across language barriers, alleviating specialized workforce shortages, and facilitating improved diagnosis and treatment, particularly during pandemics. In this work, we introduce MultiMed, a collection of small-to-large end-to-end ASR models for the medical domain, spanning five languages: Vietnamese, English, German, French, and Mandarin Chinese, together with the corresponding real-world ASR dataset. To our best knowledge, MultiMed stands as the largest and the first multilingual medical ASR dataset, in terms of total duration, number of speakers, diversity of diseases, recording conditions, speaker roles, unique medical terms, accents, and ICD-10 codes. Secondly, we establish the empirical baselines, present the first reproducible study of multilinguality in medical ASR, conduct a layer-wise ablation study for end-to-end ASR training, and provide the first linguistic analysis for multilingual medical ASR. All code, data, and models are available online https://github.com/leduckhai/MultiMed/tree/master/MultiMed",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2024-09-21 09:05:48 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.495267"
    },
    {
        "index": "#86",
        "title": "Temporally Consistent Factuality Probing for Large Language Models",
        "link": "/arxiv/2409.14065",
        "arxiv_id": "2409.14065",
        "authors": "Ashutosh Bajpai, Aaryan Goyal, Atif Anwer, Tanmoy Chakraborty",
        "summary": "The prolific use of Large Language Models (LLMs) as an alternate knowledge base requires them to be factually consistent, necessitating both correctness and consistency traits for paraphrased queries. Recently, significant attempts have been made to benchmark datasets and metrics to evaluate LLMs for these traits. However, structural simplicity (subject-relation-object) and contemporary association in their query formulation limit the broader definition of factuality and consistency. In this study, we introduce TeCFaP, a novel Temporally Consistent Factuality Probe task to expand the consistent factuality probe in the temporal dimension. To this end, we propose TEMP-COFAC, a high-quality dataset of prefix-style English query paraphrases. Subsequently, we extend the definitions of existing metrics to represent consistent factuality across temporal dimension. We experiment with a diverse set of LLMs and find most of them performing poorly on TeCFaP. Next, we propose a novel solution CoTSeLF (Consistent-Time-Sensitive Learning Framework) combining multi-task instruction tuning (MT-IT) with consistent-time-sensitive reinforcement learning (CTSRL) to improve temporally consistent factuality in LLMs. Our experiments demonstrate the efficacy of CoTSeLF over several baselines.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-21 08:41:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.500998"
    },
    {
        "index": "#87",
        "title": "Co-occurrence is not Factual Association in Language Models",
        "link": "/arxiv/2409.14057",
        "arxiv_id": "2409.14057",
        "authors": "Xiao Zhang, Miao Li, Ji Wu",
        "summary": "Pretrained language models can encode a large amount of knowledge and utilize it for various reasoning tasks, yet they can still struggle to learn novel factual knowledge effectively from finetuning on limited textual demonstrations. In this work, we show that the reason for this deficiency is that language models are biased to learn word co-occurrence statistics instead of true factual associations. We identify the differences between two forms of knowledge representation in language models: knowledge in the form of co-occurrence statistics is encoded in the middle layers of the transformer model and does not generalize well to reasoning scenarios beyond simple question answering, while true factual associations are encoded in the lower layers and can be freely utilized in various reasoning tasks. Based on these observations, we propose two strategies to improve the learning of factual associations in language models. We show that training on text with implicit rather than explicit factual associations can force the model to learn factual associations instead of co-occurrence statistics, significantly improving the generalization of newly learned knowledge. We also propose a simple training method to actively forget the learned co-occurrence statistics, which unblocks and enhances the learning of factual associations when training on plain narrative text. On both synthetic and real-world corpora, the two proposed strategies improve the generalization of the knowledge learned during finetuning to reasoning scenarios such as indirect and multi-hop question answering.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 08:13:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.501373"
    },
    {
        "index": "#88",
        "title": "GroupDebate: Enhancing the Efficiency of Multi-Agent Debate Using Group Discussion",
        "link": "/arxiv/2409.14051",
        "arxiv_id": "2409.14051",
        "authors": "Tongxuan Liu, Xingyu Wang, Weizhe Huang, Wenjiang Xu, Yuting Zeng, Lei Jiang, Hailong Yang, Jing Li",
        "summary": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse NLP tasks. Extensive research has explored how to enhance the logical reasoning abilities such as Chain-of-Thought, Chain-of-Thought with Self-Consistency, Tree-Of-Thoughts, and multi-agent debates. In the context of multi-agent debates, significant performance improvements can be achieved with an increasing number of agents and debate rounds. However, the escalation in the number of agents and debate rounds can drastically raise the tokens cost of debates, thereby limiting the scalability of the multi-agent debate technique. To better harness the advantages of multi-agent debates in logical reasoning tasks, this paper proposes a method to significantly reduce token cost in multi-agent debates. This approach involves dividing all agents into multiple debate groups, with agents engaging in debates within their respective groups and sharing interim debate results between groups. Comparative experiments across multiple datasets have demonstrated that this method can reduce the total tokens by up to 51.7% during debates and while potentially enhancing accuracy by as much as 25%. Our method significantly enhances the performance and efficiency of interactions in the multi-agent debate.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 07:49:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.501775"
    },
    {
        "index": "#89",
        "title": "Can LLMs replace Neil deGrasse Tyson? Evaluating the Reliability of LLMs as Science Communicators",
        "link": "/arxiv/2409.14037",
        "arxiv_id": "2409.14037",
        "authors": "Prasoon Bajpai, Niladri Chatterjee, Subhabrata Dutta, Tanmoy Chakraborty",
        "summary": "Large Language Models (LLMs) and AI assistants driven by these models are experiencing exponential growth in usage among both expert and amateur users. In this work, we focus on evaluating the reliability of current LLMs as science communicators. Unlike existing benchmarks, our approach emphasizes assessing these models on scientific questionanswering tasks that require a nuanced understanding and awareness of answerability. We introduce a novel dataset, SCiPS-QA, comprising 742 Yes/No queries embedded in complex scientific concepts, along with a benchmarking suite that evaluates LLMs for correctness and consistency across various criteria. We benchmark three proprietary LLMs from the OpenAI GPT family and 13 open-access LLMs from the Meta Llama-2, Llama-3, and Mistral families. While most open-access models significantly underperform compared to GPT-4 Turbo, our experiments identify Llama-3-70B as a strong competitor, often surpassing GPT-4 Turbo in various evaluation aspects. We also find that even the GPT models exhibit a general incompetence in reliably verifying LLM responses. Moreover, we observe an alarming trend where human evaluators are deceived by incorrect responses from GPT-4 Turbo.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 06:48:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.502104"
    },
    {
        "index": "#90",
        "title": "Uncovering Latent Chain of Thought Vectors in Language Models",
        "link": "/arxiv/2409.14026",
        "arxiv_id": "2409.14026",
        "authors": "Jason Zhang, Scott Viteri",
        "summary": "As language models grow more influential and trusted in our society, our ability to reliably steer them toward favorable behaviors becomes increasingly paramount. For this, we investigate the technique of steering vectors: biasing the forward pass of language models using a \"steering vector\" derived from a specific task. We apply them to steer language models toward performing Chain of Thought (CoT) Reasoning without the need to prompt through natural language. We demonstrate this approach on Llama3 8b and Mistral 7b v0.2, and obtain competitive results compared to CoT-prompted performances on a series of reasoning benchmarks (GSM8k, MMLU, AGI Eval, ARC AI2) and qualitative examples. We find this approach yields consistent steering towards CoT responses and takes less compute than traditional methods of fine-tuning models towards CoT.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 05:58:07 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.502432"
    },
    {
        "index": "#91",
        "title": "Graph Neural Network Framework for Sentiment Analysis Using Syntactic Feature",
        "link": "/arxiv/2409.14000",
        "arxiv_id": "2409.14000",
        "authors": "Linxiao Wu, Yuanshuai Luo, Binrong Zhu, Guiran Liu, Rui Wang, Qian Yu",
        "summary": "Amidst the swift evolution of social media platforms and e-commerce ecosystems, the domain of opinion mining has surged as a pivotal area of exploration within natural language processing. A specialized segment within this field focuses on extracting nuanced evaluations tied to particular elements within textual contexts. This research advances a composite framework that amalgamates the positional cues of topical descriptors. The proposed system converts syntactic structures into a matrix format, leveraging convolutions and attention mechanisms within a graph to distill salient characteristics. Incorporating the positional relevance of descriptors relative to lexical items enhances the sequential integrity of the input. Trials have substantiated that this integrated graph-centric scheme markedly elevates the efficacy of evaluative categorization, showcasing preeminence.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 03:30:59 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.502662"
    },
    {
        "index": "#92",
        "title": "Contrastive Learning for Knowledge-Based Question Generation in Large Language Models",
        "link": "/arxiv/2409.13994",
        "arxiv_id": "2409.13994",
        "authors": "Zhenhong Zhang, Jiajing Chen, Weiyan Shi, Lingjie Yi, Chihang Wang, Qian Yu",
        "summary": "With the rapid development of artificial intelligence technology, especially the increasingly widespread application of question-and-answer systems, high-quality question generation has become a key component in supporting the development of these systems. This article focuses on knowledge-based question generation technology, which aims to enable computers to simulate the human questioning process based on understanding specific texts or knowledge bases. In light of the issues of hallucination and knowledge gaps present in large-scale language models when applied to knowledge-intensive tasks, this paper proposes an enhanced question generation method that incorporates contrastive learning. This method utilizes multiple models to jointly mine domain knowledge and uses contrastive learning to guide the model in reducing noise and hallucinations in generation. Experimental results show that by designing prompts containing contrasting examples, the model's performance in question generation improves considerably, particularly when contrasting instructions and examples are used simultaneously, leading to the highest quality of generated questions and improved accuracy. These results demonstrate that the method proposed in this study, which combines contrasting context and chain-of-thought prompts, can effectively improve both the quality and the practicality of question generation.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-21 03:09:10 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.502876"
    },
    {
        "index": "#93",
        "title": "SMART-RAG: Selection using Determinantal Matrices for Augmented Retrieval",
        "link": "/arxiv/2409.13992",
        "arxiv_id": "2409.13992",
        "authors": "Jiatao Li, Xinyu Hu, Xiaojun Wan",
        "summary": "Retrieval-Augmented Generation (RAG) has greatly improved large language models (LLMs) by enabling them to generate accurate, contextually grounded responses through the integration of external information. However, conventional RAG approaches, which prioritize top-ranked documents based solely on query-context relevance, often introduce redundancy and conflicting information. This issue is particularly evident in unsupervised retrieval settings, where there are no mechanisms to effectively mitigate these problems, leading to suboptimal context selection. To address this, we propose Selection using Matrices for Augmented Retrieval (SMART) in question answering tasks, a fully unsupervised and training-free framework designed to optimize context selection in RAG. SMART leverages Determinantal Point Processes (DPPs) to simultaneously model relevance, diversity and conflict, ensuring the selection of potentially high-quality contexts. Experimental results across multiple datasets demonstrate that SMART significantly enhances QA performance and surpasses previous unsupervised context selection methods, showing a promising strategy for RAG.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 03:03:09 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.503053"
    },
    {
        "index": "#94",
        "title": "ChemEval: A Comprehensive Multi-Level Chemical Evaluation for Large Language Models",
        "link": "/arxiv/2409.13989",
        "arxiv_id": "2409.13989",
        "authors": "Yuqing Huang, Rongyang Zhang, Xuesong He, Xuyang Zhi, Hao Wang, Xin Li, Feiyang Xu, Deguang Liu, Huadong Liang, Yi Li, Jian Cui, Zimu Liu, Shijin Wang, Guoping Hu, Guiquan Liu, Qi Liu, Defu Lian, Enhong Chen",
        "summary": "There is a growing interest in the role that LLMs play in chemistry which lead to an increased focus on the development of LLMs benchmarks tailored to chemical domains to assess the performance of LLMs across a spectrum of chemical tasks varying in type and complexity. However, existing benchmarks in this domain fail to adequately meet the specific requirements of chemical research professionals. To this end, we propose \\textbf{\\textit{ChemEval}}, which provides a comprehensive assessment of the capabilities of LLMs across a wide range of chemical domain tasks. Specifically, ChemEval identified 4 crucial progressive levels in chemistry, assessing 12 dimensions of LLMs across 42 distinct chemical tasks which are informed by open-source data and the data meticulously crafted by chemical experts, ensuring that the tasks have practical value and can effectively evaluate the capabilities of LLMs. In the experiment, we evaluate 12 mainstream LLMs on ChemEval under zero-shot and few-shot learning contexts, which included carefully selected demonstration examples and carefully designed prompts. The results show that while general LLMs like GPT-4 and Claude-3.5 excel in literature understanding and instruction following, they fall short in tasks demanding advanced chemical knowledge. Conversely, specialized LLMs exhibit enhanced chemical competencies, albeit with reduced literary comprehension. This suggests that LLMs have significant potential for enhancement when tackling sophisticated tasks in the field of chemistry. We believe our work will facilitate the exploration of their potential to drive progress in chemistry. Our benchmark and analysis will be available at {\\color{blue} \\url{https://github.com/USTC-StarTeam/ChemEval}}.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Chemical Physics, Biomolecules",
        "date": "2024-09-21 02:50:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.503368"
    },
    {
        "index": "#95",
        "title": "Bias and Toxicity in Role-Play Reasoning",
        "link": "/arxiv/2409.13979",
        "arxiv_id": "2409.13979",
        "authors": "Jinman Zhao, Zifan Qian, Linbo Cao, Yining Wang, Yitian Ding",
        "summary": "Role-play in the Large Language Model (LLM) is a crucial technique that enables models to adopt specific perspectives, enhancing their ability to generate contextually relevant and accurate responses. By simulating different roles, theis approach improves reasoning capabilities across various NLP benchmarks, making the model's output more aligned with diverse scenarios. However, in this work, we demonstrate that role-play also carries potential risks. We systematically evaluate the impact of role-play by asking the language model to adopt different roles and testing it on multiple benchmarks that contain stereotypical and harmful questions. Despite the significant fluctuations in the benchmark results in different experiments, we find that applying role-play often increases the overall likelihood of generating stereotypical and harmful outputs.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 02:09:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.503637"
    },
    {
        "index": "#96",
        "title": "Can Language Model Understand Word Semantics as A Chatbot? An Empirical Study of Language Model Internal External Mismatch",
        "link": "/arxiv/2409.13972",
        "arxiv_id": "2409.13972",
        "authors": "Jinman Zhao, Xueyan Zhang, Xingyu Yue, Weizhe Chen, Zifan Qian, Ruiyu Wang",
        "summary": "Current common interactions with language models is through full inference. This approach may not necessarily align with the model's internal knowledge. Studies show discrepancies between prompts and internal representations. Most focus on sentence understanding. We study the discrepancy of word semantics understanding in internal and external mismatch across Encoder-only, Decoder-only, and Encoder-Decoder pre-trained language models.",
        "subjects": "Computation and Language",
        "date": "2024-09-21 01:35:58 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.503855"
    },
    {
        "index": "#97",
        "title": "Exploring Automated Keyword Mnemonics Generation with Large Language Models via Overgenerate-and-Rank",
        "link": "/arxiv/2409.13952",
        "arxiv_id": "2409.13952",
        "authors": "Jaewook Lee, Hunter McNichols, Andrew Lan",
        "summary": "In this paper, we study an under-explored area of language and vocabulary learning: keyword mnemonics, a technique for memorizing vocabulary through memorable associations with a target word via a verbal cue. Typically, creating verbal cues requires extensive human effort and is quite time-consuming, necessitating an automated method that is more scalable. We propose a novel overgenerate-and-rank method via prompting large language models (LLMs) to generate verbal cues and then ranking them according to psycholinguistic measures and takeaways from a pilot user study. To assess cue quality, we conduct both an automated evaluation of imageability and coherence, as well as a human evaluation involving English teachers and learners. Results show that LLM-generated mnemonics are comparable to human-generated ones in terms of imageability, coherence, and perceived usefulness, but there remains plenty of room for improvement due to the diversity in background and preference among language learners.",
        "subjects": "Computation and Language, Human-Computer Interaction",
        "date": "2024-09-21 00:00:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504072"
    },
    {
        "index": "#98",
        "title": "Mufu: Multilingual Fused Learning for Low-Resource Translation with LLM",
        "link": "/arxiv/2409.13949",
        "arxiv_id": "2409.13949",
        "authors": "Zheng Wei Lim, Nitish Gupta, Honglin Yu, Trevor Cohn",
        "summary": "Multilingual large language models (LLMs) are great translators, but this is largely limited to high-resource languages. For many LLMs, translating in and out of low-resource languages remains a challenging task. To maximize data efficiency in this low-resource setting, we introduce Mufu, which includes a selection of automatically generated multilingual candidates and an instruction to correct inaccurate translations in the prompt. Mufu prompts turn a translation task into a postediting one, and seek to harness the LLM's reasoning capability with auxiliary translation candidates, from which the model is required to assess the input quality, align the semantics cross-lingually, copy from relevant inputs and override instances that are incorrect. Our experiments on En-XX translations over the Flores-200 dataset show LLMs finetuned against Mufu-style prompts are robust to poor quality auxiliary translation candidates, achieving performance superior to NLLB 1.3B distilled model in 64% of low- and very-low-resource language pairs. We then distill these models to reduce inference cost, while maintaining on average 3.1 chrF improvement over finetune-only baseline in low-resource translations.",
        "subjects": "Computation and Language",
        "date": "2024-09-20 23:48:47 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504274"
    },
    {
        "index": "#99",
        "title": "Aligning Language Models Using Follow-up Likelihood as Reward Signal",
        "link": "/arxiv/2409.13948",
        "arxiv_id": "2409.13948",
        "authors": "Chen Zhang, Dading Chong, Feng Jiang, Chengguang Tang, Anningzhe Gao, Guohua Tang, Haizhou Li",
        "summary": "In natural human-to-human conversations, participants often receive feedback signals from one another based on their follow-up reactions. These reactions can include verbal responses, facial expressions, changes in emotional state, and other non-verbal cues. Similarly, in human-machine interactions, the machine can leverage the user's follow-up utterances as feedback signals to assess whether it has appropriately addressed the user's request. Therefore, we propose using the likelihood of follow-up utterances as rewards to differentiate preferred responses from less favored ones, without relying on human or commercial LLM-based preference annotations. Our proposed reward mechanism, ``Follow-up Likelihood as Reward\" (FLR), matches the performance of strong reward models trained on large-scale human or GPT-4 annotated data on 8 pairwise-preference and 4 rating-based benchmarks. Building upon the FLR mechanism, we propose to automatically mine preference data from the online generations of a base policy model. The preference data are subsequently used to boost the helpfulness of the base model through direct alignment from preference (DAP) methods, such as direct preference optimization (DPO). Lastly, we demonstrate that fine-tuning the language model that provides follow-up likelihood with natural language feedback significantly enhances FLR's performance on reward modeling benchmarks and effectiveness in aligning the base policy model's helpfulness.",
        "subjects": "Computation and Language",
        "date": "2024-09-20 23:47:25 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504515"
    },
    {
        "index": "#100",
        "title": "MirrorStories: Reflecting Diversity through Personalized Narrative Generation with Large Language Models",
        "link": "/arxiv/2409.13935",
        "arxiv_id": "2409.13935",
        "authors": "Sarfaroz Yunusov, Hamza Sidat, Ali Emami",
        "summary": "This study explores the effectiveness of Large Language Models (LLMs) in creating personalized \"mirror stories\" that reflect and resonate with individual readers' identities, addressing the significant lack of diversity in literature. We present MirrorStories, a corpus of 1,500 personalized short stories generated by integrating elements such as name, gender, age, ethnicity, reader interest, and story moral. We demonstrate that LLMs can effectively incorporate diverse identity elements into narratives, with human evaluators identifying personalized elements in the stories with high accuracy. Through a comprehensive evaluation involving 26 diverse human judges, we compare the effectiveness of MirrorStories against generic narratives. We find that personalized LLM-generated stories not only outscore generic human-written and LLM-generated ones across all metrics of engagement (with average ratings of 4.22 versus 3.37 on a 5-point scale), but also achieve higher textual diversity while preserving the intended moral. We also provide analyses that include bias assessments and a study on the potential for integrating images into personalized stories.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society",
        "date": "2024-09-20 22:43:13 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504730"
    },
    {
        "index": "#101",
        "title": "One Model is All You Need: ByT5-Sanskrit, a Unified Model for Sanskrit NLP Tasks",
        "link": "/arxiv/2409.13920",
        "arxiv_id": "2409.13920",
        "authors": "Sebastian Nehrdich, Oliver Hellwig, Kurt Keutzer",
        "summary": "Morphologically rich languages are notoriously challenging to process for downstream NLP applications. This paper presents a new pretrained language model, ByT5-Sanskrit, designed for NLP applications involving the morphologically rich language Sanskrit. We evaluate ByT5-Sanskrit on established Sanskrit word segmentation tasks, where it outperforms previous data-driven approaches by a considerable margin and matches the performance of the current best lexicon-based model. It is easier to deploy and more robust to data not covered by external linguistic resources. It also achieves new state-of-the-art results in Vedic Sanskrit dependency parsing and OCR post-correction tasks. Additionally, based on the Digital Corpus of Sanskrit, we introduce a novel multitask dataset for the joint training of Sanskrit word segmentation, lemmatization, and morphosyntactic tagging tasks. We fine-tune ByT5-Sanskrit on this dataset, creating a versatile multitask model for various downstream Sanskrit applications. We have used this model in Sanskrit linguistic annotation projects, in information retrieval setups, and as a preprocessing step in a Sanskrit machine translation pipeline. We also show that our approach yields new best scores for lemmatization and dependency parsing of other morphologically rich languages. We thus demonstrate that byte-level pretrained language models can achieve excellent performance for morphologically rich languages, outperforming tokenizer-based models and presenting an important vector of exploration when constructing NLP pipelines for such languages.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-20 22:02:26 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.504912"
    },
    {
        "index": "#102",
        "title": "Target word activity detector: An approach to obtain ASR word boundaries without lexicon",
        "link": "/arxiv/2409.13913",
        "arxiv_id": "2409.13913",
        "authors": "Sunit Sivasankaran, Eric Sun, Jinyu Li, Yan Huang, Jing Pan",
        "summary": "Obtaining word timestamp information from end-to-end (E2E) ASR models remains challenging due to the lack of explicit time alignment during training. This issue is further complicated in multilingual models. Existing methods, either rely on lexicons or introduce additional tokens, leading to scalability issues and increased computational costs. In this work, we propose a new approach to estimate word boundaries without relying on lexicons. Our method leverages word embeddings from sub-word token units and a pretrained ASR model, requiring only word alignment information during training. Our proposed method can scale-up to any number of languages without incurring any additional cost. We validate our approach using a multilingual ASR model trained on five languages and demonstrate its effectiveness against a strong baseline.",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2024-09-20 21:40:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.505113"
    },
    {
        "index": "#103",
        "title": "Enhancing Large Language Models with Domain-specific Retrieval Augment Generation: A Case Study on Long-form Consumer Health Question Answering in Ophthalmology",
        "link": "/arxiv/2409.13902",
        "arxiv_id": "2409.13902",
        "authors": "Aidan Gilson, Xuguang Ai, Thilaka Arunachalam, Ziyou Chen, Ki Xiong Cheong, Amisha Dave, Cameron Duic, Mercy Kibe, Annette Kaminaka, Minali Prasad, Fares Siddig, Maxwell Singer, Wendy Wong, Qiao Jin, Tiarnan D. L. Keenan, Xia Hu, Emily Y. Chew, Zhiyong Lu, Hua Xu, Ron A. Adelman, Yih-Chung Tham, Qingyu Chen",
        "summary": "Despite the potential of Large Language Models (LLMs) in medicine, they may generate responses lacking supporting evidence or based on hallucinated evidence. While Retrieval Augment Generation (RAG) is popular to address this issue, few studies implemented and evaluated RAG in downstream domain-specific applications. We developed a RAG pipeline with 70,000 ophthalmology-specific documents that retrieve relevant documents to augment LLMs during inference time. In a case study on long-form consumer health questions, we systematically evaluated the responses including over 500 references of LLMs with and without RAG on 100 questions with 10 healthcare professionals. The evaluation focuses on factuality of evidence, selection and ranking of evidence, attribution of evidence, and answer accuracy and completeness. LLMs without RAG provided 252 references in total. Of which, 45.3% hallucinated, 34.1% consisted of minor errors, and 20.6% were correct. In contrast, LLMs with RAG significantly improved accuracy (54.5% being correct) and reduced error rates (18.8% with minor hallucinations and 26.7% with errors). 62.5% of the top 10 documents retrieved by RAG were selected as the top references in the LLM response, with an average ranking of 4.9. The use of RAG also improved evidence attribution (increasing from 1.85 to 2.49 on a 5-point scale, P<0.001), albeit with slight decreases in accuracy (from 3.52 to 3.23, P=0.03) and completeness (from 3.47 to 3.27, P=0.17). The results demonstrate that LLMs frequently exhibited hallucinated and erroneous evidence in the responses, raising concerns for downstream applications in the medical domain. RAG substantially reduced the proportion of such evidence but encountered challenges.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-20 21:06:00 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.505487"
    },
    {
        "index": "#104",
        "title": "LLM for Everyone: Representing the Underrepresented in Large Language Models",
        "link": "/arxiv/2409.13897",
        "arxiv_id": "2409.13897",
        "authors": "Samuel Cahyawijaya",
        "summary": "Natural language processing (NLP) has witnessed a profound impact of large language models (LLMs) that excel in a multitude of tasks. However, the limitation of LLMs in multilingual settings, particularly in underrepresented languages, remains a significant hurdle. This thesis aims to bridge the gap in NLP research and development by focusing on underrepresented languages. A comprehensive evaluation of LLMs is conducted to assess their capabilities in these languages, revealing the challenges of multilingual and multicultural generalization. Addressing the multilingual generalization gap, this thesis proposes data-and-compute-efficient methods to mitigate the disparity in LLM ability in underrepresented languages, allowing better generalization on underrepresented languages without the loss of task generalization ability. The proposed solutions cover cross-lingual continual instruction tuning, retrieval-based cross-lingual in-context learning, and in-context query alignment. Furthermore, a novel method to measure cultural values alignment between LLMs operating in different languages is proposed, ensuring cultural sensitivity and inclusivity. These contributions aim to enhance the multilingual and multicultural alignment of LLMs in underrepresented languages, ultimately advancing the NLP field toward greater equality and inclusiveness.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-20 20:53:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.505668"
    },
    {
        "index": "#105",
        "title": "Transfer Learning with Clinical Concept Embeddings from Large Language Models",
        "link": "/arxiv/2409.13893",
        "arxiv_id": "2409.13893",
        "authors": "Yuhe Gao, Runxue Bao, Yuelyu Ji, Yiming Sun, Chenxi Song, Jeffrey P. Ferraro, Ye Ye",
        "summary": "Knowledge sharing is crucial in healthcare, especially when leveraging data from multiple clinical sites to address data scarcity, reduce costs, and enable timely interventions. Transfer learning can facilitate cross-site knowledge transfer, but a major challenge is heterogeneity in clinical concepts across different sites. Large Language Models (LLMs) show significant potential of capturing the semantic meaning of clinical concepts and reducing heterogeneity. This study analyzed electronic health records from two large healthcare systems to assess the impact of semantic embeddings from LLMs on local, shared, and transfer learning models. Results indicate that domain-specific LLMs, such as Med-BERT, consistently outperform in local and direct transfer scenarios, while generic models like OpenAI embeddings require fine-tuning for optimal performance. However, excessive tuning of models with biomedical embeddings may reduce effectiveness, emphasizing the need for balance. This study highlights the importance of domain-specific embeddings and careful model tuning for effective knowledge transfer in healthcare.",
        "subjects": "Computation and Language",
        "date": "2024-09-20 20:50:55 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.511322"
    },
    {
        "index": "#106",
        "title": "A Multi-LLM Debiasing Framework",
        "link": "/arxiv/2409.13884",
        "arxiv_id": "2409.13884",
        "authors": "Deonna M. Owens, Ryan A. Rossi, Sungchul Kim, Tong Yu, Franck Dernoncourt, Xiang Chen, Ruiyi Zhang, Jiuxiang Gu, Hanieh Deilamsalehy, Nedim Lipka",
        "summary": "Large Language Models (LLMs) are powerful tools with the potential to benefit society immensely, yet, they have demonstrated biases that perpetuate societal inequalities. Despite significant advancements in bias mitigation techniques using data augmentation, zero-shot prompting, and model fine-tuning, biases continuously persist, including subtle biases that may elude human detection. Recent research has shown a growing interest in multi-LLM approaches, which have been demonstrated to be effective in improving the quality of reasoning and factuality in LLMs. Building on this approach, we propose a novel multi-LLM debiasing framework aimed at reducing bias in LLMs. Our work is the first to introduce and evaluate two distinct approaches within this framework for debiasing LLMs: a centralized method, where the conversation is facilitated by a single central LLM, and a decentralized method, where all models communicate directly. Our findings reveal that our multi-LLM framework significantly reduces bias in LLMs, outperforming the baseline method across several social groups.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2024-09-20 20:24:50 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.511806"
    },
    {
        "index": "#107",
        "title": "\"I Never Said That\": A dataset, taxonomy and baselines on response clarity classification",
        "link": "/arxiv/2409.13879",
        "arxiv_id": "2409.13879",
        "authors": "Konstantinos Thomas, Giorgos Filandrianos, Maria Lymperaiou, Chrysoula Zerva, Giorgos Stamou",
        "summary": "Equivocation and ambiguity in public speech are well-studied discourse phenomena, especially in political science and analysis of political interviews. Inspired by the well-grounded theory on equivocation, we aim to resolve the closely related problem of response clarity in questions extracted from political interviews, leveraging the capabilities of Large Language Models (LLMs) and human expertise. To this end, we introduce a novel taxonomy that frames the task of detecting and classifying response clarity and a corresponding clarity classification dataset which consists of question-answer (QA) pairs drawn from political interviews and annotated accordingly. Our proposed two-level taxonomy addresses the clarity of a response in terms of the information provided for a given question (high-level) and also provides a fine-grained taxonomy of evasion techniques that relate to unclear, ambiguous responses (lower-level). We combine ChatGPT and human annotators to collect, validate and annotate discrete QA pairs from political interviews, to be used for our newly introduced response clarity task. We provide a detailed analysis and conduct several experiments with different model architectures, sizes and adaptation methods to gain insights and establish new baselines over the proposed dataset and task.",
        "subjects": "Computation and Language",
        "date": "2024-09-20 20:15:06 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512043"
    },
    {
        "index": "#108",
        "title": "Instruct-Tuning Pretrained Causal Language Models for Ancient Greek Papyrology and Epigraphy",
        "link": "/arxiv/2409.13870",
        "arxiv_id": "2409.13870",
        "authors": "Eric Cullhed",
        "summary": "This article presents an experiment in fine-tuning a pretrained causal language model (Meta's Llama 3.1 8B Instruct) for aiding in three fundamental tasks of philological research: chronological and geographic attribution as well as text restoration in ancient Greek inscriptions and documentary papyri. Using a prompt-based instruct approach, the fine-tuned models surpass the state of the art in key metrics. For inscriptions, the models achieve a lower average character error rate (CER) of 22.5% (vs. 26.3%), while closely matching top-1 accuracy (60.9% vs. 61.8%) and top-20 accuracy (77.5% vs. 78.3%) for sequences up to 10 characters. They also provide a practical advantage by ignoring spaces during reconstruction, aligning better with the scriptio continua typically used in ancient written artifacts. In geographic attribution, the model outperforms previous benchmarks with a top-1 accuracy of 75.0% (vs. 70.8%) and a top-3 accuracy of 83.7% (vs. 82.1%). For dating, it achieves an average deviation of 26.2 years (vs. 29.3) and a median deviation of 1 year (vs. 3) from the actual date range. The models also set new baselines for documentary papyri, with a CER of 16.3%, a top-1 accuracy of 71.3%, and top-20 of 85.0% in text reconstruction; a top-1 accuracy of 66.4% and top-3 of 79.9% in geographic attribution; and, in chronological attribution, a deviation of 21.7 years from the actual termini post/ante quem, with a median deviation of 0 years.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-20 19:49:45 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512225"
    },
    {
        "index": "#109",
        "title": "Unlocking Memorization in Large Language Models with Dynamic Soft Prompting",
        "link": "/arxiv/2409.13853",
        "arxiv_id": "2409.13853",
        "authors": "Zhepeng Wang, Runxue Bao, Yawen Wu, Jackson Taylor, Cao Xiao, Feng Zheng, Weiwen Jiang, Shangqian Gao, Yanfu Zhang",
        "summary": "Pretrained large language models (LLMs) have revolutionized natural language processing (NLP) tasks such as summarization, question answering, and translation. However, LLMs pose significant security risks due to their tendency to memorize training data, leading to potential privacy breaches and copyright infringement. Accurate measurement of this memorization is essential to evaluate and mitigate these potential risks. However, previous attempts to characterize memorization are constrained by either using prefixes only or by prepending a constant soft prompt to the prefixes, which cannot react to changes in input. To address this challenge, we propose a novel method for estimating LLM memorization using dynamic, prefix-dependent soft prompts. Our approach involves training a transformer-based generator to produce soft prompts that adapt to changes in input, thereby enabling more accurate extraction of memorized data. Our method not only addresses the limitations of previous methods but also demonstrates superior performance in diverse experimental settings compared to state-of-the-art techniques. In particular, our method can achieve the maximum relative improvement of 112.75% and 32.26% over the vanilla baseline in terms of discoverable memorization rate for the text generation task and code generation task respectively.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security, Machine Learning",
        "date": "2024-09-20 18:56:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512486"
    },
    {
        "index": "#110",
        "title": "Do language models practice what they preach? Examining language ideologies about gendered language reform encoded in LLMs",
        "link": "/arxiv/2409.13852",
        "arxiv_id": "2409.13852",
        "authors": "Julia Watson, Sophia Lee, Barend Beekhuizen, Suzanne Stevenson",
        "summary": "We study language ideologies in text produced by LLMs through a case study on English gendered language reform (related to role nouns like congressperson/-woman/-man, and singular they). First, we find political bias: when asked to use language that is \"correct\" or \"natural\", LLMs use language most similarly to when asked to align with conservative (vs. progressive) values. This shows how LLMs' metalinguistic preferences can implicitly communicate the language ideologies of a particular political group, even in seemingly non-political contexts. Second, we find LLMs exhibit internal inconsistency: LLMs use gender-neutral variants more often when more explicit metalinguistic context is provided. This shows how the language ideologies expressed in text produced by LLMs can vary, which may be unexpected to users. We discuss the broader implications of these findings for value alignment.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-20 18:55:48 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512681"
    },
    {
        "index": "#111",
        "title": "STOP! Benchmarking Large Language Models with Sensitivity Testing on Offensive Progressions",
        "link": "/arxiv/2409.13843",
        "arxiv_id": "2409.13843",
        "authors": "Robert Morabito, Sangmitra Madhusudan, Tyler McDonald, Ali Emami",
        "summary": "Mitigating explicit and implicit biases in Large Language Models (LLMs) has become a critical focus in the field of natural language processing. However, many current methodologies evaluate scenarios in isolation, without considering the broader context or the spectrum of potential biases within each situation. To address this, we introduce the Sensitivity Testing on Offensive Progressions (STOP) dataset, which includes 450 offensive progressions containing 2,700 unique sentences of varying severity that progressively escalate from less to more explicitly offensive. Covering a broad spectrum of 9 demographics and 46 sub-demographics, STOP ensures inclusivity and comprehensive coverage. We evaluate several leading closed- and open-source models, including GPT-4, Mixtral, and Llama 3. Our findings reveal that even the best-performing models detect bias inconsistently, with success rates ranging from 19.3% to 69.8%. We also demonstrate how aligning models with human judgments on STOP can improve model answer rates on sensitive tasks such as BBQ, StereoSet, and CrowS-Pairs by up to 191%, while maintaining or even improving performance. STOP presents a novel framework for assessing the complex nature of biases in LLMs, which will enable more effective bias mitigation strategies and facilitates the creation of fairer language models.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society",
        "date": "2024-09-20 18:34:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.512937"
    },
    {
        "index": "#112",
        "title": "Measuring Copyright Risks of Large Language Model via Partial Information Probing",
        "link": "/arxiv/2409.13831",
        "arxiv_id": "2409.13831",
        "authors": "Weijie Zhao, Huajie Shao, Zhaozhuo Xu, Suzhen Duan, Denghui Zhang",
        "summary": "Exploring the data sources used to train Large Language Models (LLMs) is a crucial direction in investigating potential copyright infringement by these models. While this approach can identify the possible use of copyrighted materials in training data, it does not directly measure infringing risks. Recent research has shifted towards testing whether LLMs can directly output copyrighted content. Addressing this direction, we investigate and assess LLMs' capacity to generate infringing content by providing them with partial information from copyrighted materials, and try to use iterative prompting to get LLMs to generate more infringing content. Specifically, we input a portion of a copyrighted text into LLMs, prompt them to complete it, and then analyze the overlap between the generated content and the original copyrighted material. Our findings demonstrate that LLMs can indeed generate content highly overlapping with copyrighted materials based on these partial inputs.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security",
        "date": "2024-09-20 18:16:05 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513160"
    },
    {
        "index": "#113",
        "title": "Local Explanations and Self-Explanations for Assessing Faithfulness in black-box LLMs",
        "link": "/arxiv/2409.13764",
        "arxiv_id": "2409.13764",
        "authors": "Christos Fragkathoulas, Odysseas S. Chlapanis",
        "summary": "This paper introduces a novel task to assess the faithfulness of large language models (LLMs) using local perturbations and self-explanations. Many LLMs often require additional context to answer certain questions correctly. For this purpose, we propose a new efficient alternative explainability technique, inspired by the commonly used leave-one-out approach. Using this approach, we identify the sufficient and necessary parts for the LLM to generate correct answers, serving as explanations. We propose a metric for assessing faithfulness that compares these crucial parts with the self-explanations of the model. Using the Natural Questions dataset, we validate our approach, demonstrating its effectiveness in explaining model decisions and assessing faithfulness.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-18 10:16:45 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513345"
    },
    {
        "index": "#114",
        "title": "Do Large Language Models Need a Content Delivery Network?",
        "link": "/arxiv/2409.13761",
        "arxiv_id": "2409.13761",
        "authors": "Yihua Cheng, Kuntai Du, Jiayi Yao, Junchen Jiang",
        "summary": "As the use of large language models (LLMs) expands rapidly, so does the range of knowledge needed to supplement various LLM queries. Thus, enabling flexible and efficient injection of new knowledge in LLM inference is critical. Three high-level options exist: (i) embedding the knowledge in LLM's weights (i.e., fine-tuning), (ii) including the knowledge as a part of LLM's text input (i.e., in-context learning), or (iii) injecting the KV caches of the new knowledge to LLM during prefill. This paper argues that, although fine-tuning and in-context learning are popular, using KV caches as the medium of knowledge could simultaneously enable more modular management of knowledge injection and more efficient LLM serving with low cost and fast response. To realize these benefits, we envision a Knowledge Delivery Network (KDN), a new system component in LLM services that dynamically optimizes the storage, transfer, and composition of KV cache across LLM engines and other compute and storage resources. We believe that, just like content delivery networks (CDNs), such as Akamai, enabled the success of the Internet ecosystem through their efficient data delivery, KDNs will be critical to the success of LLM applications through their efficient knowledge delivery. We have open-sourced a KDN prototype at https://github.com/LMCache/LMCache.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-16 18:46:24 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513543"
    },
    {
        "index": "#115",
        "title": "Optimizing the Songwriting Process: Genre-Based Lyric Generation Using Deep Learning Models",
        "link": "/arxiv/2409.13758",
        "arxiv_id": "2409.13758",
        "authors": "Tracy Cai, Wilson Liang, Donte Townes",
        "summary": "The traditional songwriting process is rather complex and this is evident in the time it takes to produce lyrics that fit the genre and form comprehensive verses. Our project aims to simplify this process with deep learning techniques, thus optimizing the songwriting process and enabling an artist to hit their target audience by staying in genre. Using a dataset of 18,000 songs off Spotify, we developed a unique preprocessing format using tokens to parse lyrics into individual verses. These results were used to train a baseline pretrained seq2seq model, and a LSTM-based neural network models according to song genres. We found that generation yielded higher recall (ROUGE) in the baseline model, but similar precision (BLEU) for both models. Qualitatively, we found that many of the lyrical phrases generated by the original model were still comprehensible and discernible between which genres they fit into, despite not necessarily being the exact the same as the true lyrics. Overall, our results yielded that lyric generation can reasonably be sped up to produce genre-based lyrics and aid in hastening the songwriting process.",
        "subjects": "Computation and Language, Artificial Intelligence, Sound, Audio and Speech Processing",
        "date": "2024-09-15 21:32:46 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513752"
    },
    {
        "index": "#116",
        "title": "Efficient Hybrid Inference for LLMs: Reward-Based Token Modelling with Selective Cloud Assistance",
        "link": "/arxiv/2409.13757",
        "arxiv_id": "2409.13757",
        "authors": "Adarsh MS, Jithin VG, Ditto PS",
        "summary": "Large language models (LLMs) are known for their exceptional performance across a range of natural language processing tasks, but their deployment comes at a high computational and financial cost. On the other hand, smaller language models (SLMs), which can be deployed on lower-cost edge devices, struggle to match the performance of their larger counterparts. This paper presents a novel hybrid inference approach that leverages the strengths of both model types while minimizing reliance on costly cloud-based LLMs. Unlike existing methods that route entire queries to either an SLM or a cloud LLM, our approach introduces a reward-based mechanism to dynamically determine the involvement of the cloud LLM during token generation. Specifically, each token predicted by the SLM is evaluated against a reward score, and only when this score falls below a certain threshold is the cloud LLM consulted for assistance in the next token prediction. This method not only reduces the traffic to the cloud LLM, thereby lowering costs, but also allows for flexible control over response quality depending on the reward score threshold. Experimental results demonstrate that our approach significantly reduces cloud LLM usage with minimal impact on overall response quality, offering a cost-effective solution for deploying high-performance language models",
        "subjects": "Computation and Language",
        "date": "2024-09-15 15:12:45 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.513932"
    },
    {
        "index": "#117",
        "title": "Language Models Learn Metadata: Political Stance Detection Case Study",
        "link": "/arxiv/2409.13756",
        "arxiv_id": "2409.13756",
        "authors": "Stanley Cao, Felix Drinkall",
        "summary": "Stance detection is a crucial NLP task with numerous applications in social science, from analyzing online discussions to assessing political campaigns. This paper investigates the optimal way to incorporate metadata into a political stance detection task. We demonstrate that previous methods combining metadata with language-based data for political stance detection have not fully utilized the metadata information; our simple baseline, using only party membership information, surpasses the current state-of-the-art. We then show that prepending metadata (e.g., party and policy) to political speeches performs best, outperforming all baselines, indicating that complex metadata inclusion systems may not learn the task optimally.",
        "subjects": "Computation and Language",
        "date": "2024-09-15 14:57:41 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514099"
    },
    {
        "index": "#118",
        "title": "Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation Extraction in Long Sentences",
        "link": "/arxiv/2409.13755",
        "arxiv_id": "2409.13755",
        "authors": "Xin Wang, Xinyi Bai",
        "summary": "Relation extraction as an important natural Language processing (NLP) task is to identify relations between named entities in text. Recently, graph convolutional networks over dependency trees have been widely used to capture syntactic features and achieved attractive performance. However, most existing dependency-based approaches ignore the positive influence of the words outside the dependency trees, sometimes conveying rich and useful information on relation extraction. In this paper, we propose a novel model, Entity-aware Self-attention Contextualized GCN (ESC-GCN), which efficiently incorporates syntactic structure of input sentences and semantic context of sequences. To be specific, relative position self-attention obtains the overall semantic pairwise correlation related to word position, and contextualized graph convolutional networks capture rich intra-sentence dependencies between words by adequately pruning operations. Furthermore, entity-aware attention layer dynamically selects which token is more decisive to make final relation prediction. In this way, our proposed model not only reduces the noisy impact from dependency trees, but also obtains easily-ignored entity-related semantic representation. Extensive experiments on various tasks demonstrate that our model achieves encouraging performance as compared to existing dependency-based and sequence-based models. Specially, our model excels in extracting relations between entities of long sentences.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-15 10:50:51 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514277"
    },
    {
        "index": "#119",
        "title": "Thinking Before Speaking: A Role-playing Model with Mindset",
        "link": "/arxiv/2409.13752",
        "arxiv_id": "2409.13752",
        "authors": "Baohua Zhang, Yongyi Huang, Wenyao Cui, Huaping Zhang",
        "summary": "Role-playing is an easy task for Large Language Models (LLMs), as they are skilled at simulating human behaviors. Many current studies have enabled LLMs to generate responses in the tone of a specific role by fine-tuning the models or using specialized prompts. However, it is typically easy to recognize when a role is being played by LLMs. These models tend to perform poorly when confronted with knowledge that the assumed role does not possess, or a question that requires the specific experience or logic of the role to answer. To address this problem and make LLMs act more like real roles, we propose a Thinking Before Speaking (TBS) model in this paper. Unlike other studies, we first extend the data based on the character's real-life scenarios and the historical dialogue, supplementing each pair of dialogue with the character's mindset. Then we add few data points that include elements beyond the role's knowledge, and fine-tune the LLMs. This approach can help LLMs adopt the role's thought process and logic, avoiding responses that fall outside the role's knowledge base. We have also prepared a dataset and evaluation metrics to test these capabilities. Experimental results show that our TBS model can better emulate a role in terms of tone, knowledge, and mindset.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-14 02:41:48 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514473"
    },
    {
        "index": "#120",
        "title": "KodeXv0.1: A Family of State-of-the-Art Financial Large Language Models",
        "link": "/arxiv/2409.13749",
        "arxiv_id": "2409.13749",
        "authors": "Neel Rajani, Lilli Kiessling, Aleksandr Ogaltsov, Claus Lang",
        "summary": "Although powerful, current cutting-edge LLMs may not fulfil the needs of highly specialised sectors. We introduce KodeXv0.1, a family of large language models that outclass GPT-4 in financial question answering. We utilise the base variants of Llama 3.1 8B and 70B and adapt them to the financial domain through a custom training regime. To this end, we collect and process a large number of publicly available financial documents such as earnings calls and business reports. These are used to generate a high-quality, synthetic dataset consisting of Context-Question-Answer triplets which closely mirror real-world financial tasks. Using the train split of this dataset, we perform RAG-aware 4bit LoRA instruction tuning runs of Llama 3.1 base variants to produce KodeX-8Bv0.1 and KodeX-70Bv0.1. We then complete extensive model evaluations using FinanceBench, FinQABench and the withheld test split of our dataset. Our results show that KodeX-8Bv0.1 is more reliable in financial contexts than cutting-edge instruct models in the same parameter regime, surpassing them by up to 9.24%. In addition, it is even capable of outperforming state-of-the-art proprietary models such as GPT-4 by up to 7.07%. KodeX-70Bv0.1 represents a further improvement upon this, exceeding GPT-4's performance on every tested benchmark.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-13 16:43:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514658"
    },
    {
        "index": "#121",
        "title": "TheraGen: Therapy for Every Generation",
        "link": "/arxiv/2409.13748",
        "arxiv_id": "2409.13748",
        "authors": "Kartikey Doshi, Jimit Shah, Narendra Shekokar",
        "summary": "We present TheraGen, an advanced AI-powered mental health chatbot utilizing the LLaMA 2 7B model. This approach builds upon recent advancements in language models and transformer architectures. TheraGen provides all-day personalized, compassionate mental health care by leveraging a large dataset of 1 million conversational entries, combining anonymized therapy transcripts, online mental health discussions, and psychological literature, including APA resources. Our implementation employs transfer learning, fine-tuning, and advanced training techniques to optimize performance. TheraGen offers a user-friendly interface for seamless interaction, providing empathetic responses and evidence-based coping strategies. Evaluation results demonstrate high user satisfaction rates, with 94% of users reporting improved mental well-being. The system achieved a BLEU score of 0.67 and a ROUGE score of 0.62, indicating strong response accuracy. With an average response time of 1395 milliseconds, TheraGen ensures real-time, efficient support. While not a replacement for professional therapy, TheraGen serves as a valuable complementary tool, significantly improving user well-being and addressing the accessibility gap in mental health treatments. This paper details TheraGen's architecture, training methodology, ethical considerations, and future directions, contributing to the growing field of AI-assisted mental healthcare and offering a scalable solution to the pressing need for mental health support.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-12 17:15:44 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.514879"
    },
    {
        "index": "#122",
        "title": "Machine Translation with Large Language Models: Decoder Only vs. Encoder-Decoder",
        "link": "/arxiv/2409.13747",
        "arxiv_id": "2409.13747",
        "authors": "Abhinav P. M., SujayKumar Reddy M, Oswald Christopher",
        "summary": "This project, titled \"Machine Translation with Large Language Models: Decoder-only vs. Encoder-Decoder,\" aims to develop a multilingual machine translation (MT) model. Focused on Indian regional languages, especially Telugu, Tamil, and Malayalam, the model seeks to enable accurate and contextually appropriate translations across diverse language pairs. By comparing Decoder-only and Encoder-Decoder architectures, the project aims to optimize translation quality and efficiency, advancing cross-linguistic communication tools.The primary objective is to develop a model capable of delivering high-quality translations that are accurate and contextually appropriate. By leveraging large language models, specifically comparing the effectiveness of Decoder-only and Encoder-Decoder architectures, the project seeks to optimize translation performance and efficiency across multilingual contexts. Through rigorous experimentation and analysis, this project aims to advance the field of machine translation, contributing valuable insights into the effectiveness of different model architectures and paving the way for enhanced cross-linguistic communication tools.",
        "subjects": "Computation and Language, Emerging Technologies, Machine Learning",
        "date": "2024-09-12 00:21:05 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515088"
    },
    {
        "index": "#123",
        "title": "When Less Is Not More: Large Language Models Normalize Less-Frequent Terms with Lower Accuracy",
        "link": "/arxiv/2409.13746",
        "arxiv_id": "2409.13746",
        "authors": "Daniel B. Hier, Thanh Son Do, Tayo Obafemi-Ajayi",
        "summary": "Term normalization is the process of mapping a term from free text to a standardized concept and its machine-readable code in an ontology. Accurate normalization of terms that capture phenotypic differences between patients and diseases is critical to the success of precision medicine initiatives. A large language model (LLM), such as GPT-4o, can normalize terms to the Human Phenotype Ontology (HPO), but it may retrieve incorrect HPO IDs. Reported accuracy rates for LLMs on these tasks may be inflated due to imbalanced test datasets skewed towards high-frequency terms. In our study, using a comprehensive dataset of 268,776 phenotype annotations for 12,655 diseases from the HPO, GPT-4o achieved an accuracy of 13.1% in normalizing 11,225 unique terms. However, the accuracy was unevenly distributed, with higher-frequency and shorter terms normalized more accurately than lower-frequency and longer terms. Feature importance analysis, using SHAP and permutation methods, identified low-term frequency as the most significant predictor of normalization errors. These findings suggest that training and evaluation datasets for LLM-based term normalization should balance low- and high-frequency terms to improve model performance, particularly for infrequent terms critical to precision medicine.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-11 21:34:46 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515270"
    },
    {
        "index": "#124",
        "title": "Context-Aware Membership Inference Attacks against Pre-trained Large Language Models",
        "link": "/arxiv/2409.13745",
        "arxiv_id": "2409.13745",
        "authors": "Hongyan Chang, Ali Shahin Shamsabadi, Kleomenis Katevas, Hamed Haddadi, Reza Shokri",
        "summary": "Prior Membership Inference Attacks (MIAs) on pre-trained Large Language Models (LLMs), adapted from classification model attacks, fail due to ignoring the generative process of LLMs across token sequences. In this paper, we present a novel attack that adapts MIA statistical tests to the perplexity dynamics of subsequences within a data point. Our method significantly outperforms prior loss-based approaches, revealing context-dependent memorization patterns in pre-trained LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security, Machine Learning, Machine Learning",
        "date": "2024-09-11 01:56:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515567"
    },
    {
        "index": "#125",
        "title": "A Simplified Retriever to Improve Accuracy of Phenotype Normalizations by Large Language Models",
        "link": "/arxiv/2409.13744",
        "arxiv_id": "2409.13744",
        "authors": "Daniel B. Hier, Thanh Son Do, Tayo Obafemi-Ajayi",
        "summary": "Large language models (LLMs) have shown improved accuracy in phenotype term normalization tasks when augmented with retrievers that suggest candidate normalizations based on term definitions. In this work, we introduce a simplified retriever that enhances LLM accuracy by searching the Human Phenotype Ontology (HPO) for candidate matches using contextual word embeddings from BioBERT without the need for explicit term definitions. Testing this method on terms derived from the clinical synopses of Online Mendelian Inheritance in Man (OMIM), we demonstrate that the normalization accuracy of a state-of-the-art LLM increases from a baseline of 62.3% without augmentation to 90.3% with retriever augmentation. This approach is potentially generalizable to other biomedical term normalization tasks and offers an efficient alternative to more complex retrieval methods.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-11 00:16:17 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515763"
    },
    {
        "index": "#126",
        "title": "Knowing When to Ask -- Bridging Large Language Models and Data",
        "link": "/arxiv/2409.13741",
        "arxiv_id": "2409.13741",
        "authors": "Prashanth Radhakrishnan, Jennifer Chen, Bo Xu, Prem Ramaswami, Hannah Pho, Adriana Olmos, James Manyika, R. V. Guha",
        "summary": "Large Language Models (LLMs) are prone to generating factually incorrect information when responding to queries that involve numerical and statistical data or other timely facts. In this paper, we present an approach for enhancing the accuracy of LLMs by integrating them with Data Commons, a vast, open-source repository of public statistics from trusted organizations like the United Nations (UN), Center for Disease Control and Prevention (CDC) and global census bureaus. We explore two primary methods: Retrieval Interleaved Generation (RIG), where the LLM is trained to produce natural language queries to retrieve data from Data Commons, and Retrieval Augmented Generation (RAG), where relevant data tables are fetched from Data Commons and used to augment the LLM's prompt. We evaluate these methods on a diverse set of queries, demonstrating their effectiveness in improving the factual accuracy of LLM outputs. Our work represents an early step towards building more trustworthy and reliable LLMs that are grounded in verifiable statistical data and capable of complex factual reasoning.",
        "subjects": "Computation and Language",
        "date": "2024-09-10 17:51:21 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.515968"
    },
    {
        "index": "#127",
        "title": "Language agents achieve superhuman synthesis of scientific knowledge",
        "link": "/arxiv/2409.13740",
        "arxiv_id": "2409.13740",
        "authors": "Michael D. Skarlinski, Sam Cox, Jon M. Laurent, James D. Braza, Michaela Hinks, Michael J. Hammerling, Manvitha Ponnapati, Samuel G. Rodriques, Andrew D. White",
        "summary": "Language models are known to produce incorrect information, and their accuracy and reliability for scientific research are still in question. We developed a detailed human-AI comparison method to evaluate language models on real-world literature search tasks, including information retrieval, summarization, and contradiction detection. Our findings show that PaperQA2, an advanced language model focused on improving factual accuracy, matches or outperforms subject matter experts on three realistic literature search tasks, with no restrictions on human participants (full internet access, search tools, and time). PaperQA2 generates cited, Wikipedia-style summaries of scientific topics that are significantly more accurate than current human-written Wikipedia entries. We also present LitQA2, a new benchmark for scientific literature research, which shaped the development of PaperQA2 and contributed to its superior performance. Additionally, PaperQA2 identifies contradictions in scientific literature, a challenging task for humans. It finds an average of 2.34 +/- 1.99 contradictions per paper in a random sample of biology papers, with 70% of these contradictions validated by human experts. These results show that language models can now surpass domain experts in important scientific literature tasks.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval, Physics and Society",
        "date": "2024-09-10 16:37:58 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.521579"
    },
    {
        "index": "#128",
        "title": "Table-to-Text Generation with Pretrained Diffusion Models",
        "link": "/arxiv/2409.13739",
        "arxiv_id": "2409.13739",
        "authors": "Aleksei S. Krylov, Oleg D. Somov",
        "summary": "Diffusion models have demonstrated significant potential in achieving state-of-the-art performance across various text generation tasks. In this systematic study, we investigate their application to the table-to-text problem by adapting the diffusion model to the task and conducting an in-depth analysis. Our experiments cover multiple aspects of diffusion models training. We explore sampling strategy influence by inducing recent diffusion model accelerator DPM-Solver++ into our core model. We have tested different prediction aggregation methods, like ROVER and Minimum Bayes-Risk (MBR). Our studies cover the impact of the pre-training phase in diffusion models and the generation length constraints influence. We also have compared diffusion model generation with auto-regressive text-to-text models with different temperature settings for diversity evaluation. Our key observation is that diffusion models demonstrate the balance between quality and diversity while auto-regressive text-to-text models are not successful at handling both at the same time. Furthermore, we found out that to achieve the highest quality possible, it is preferable to use a regular sampler with the strictest length constraint to create multiple samples, and then use MBR to aggregate the predictions. However, if you are prepared to give up high level of diversity and to accelerate the process, you can also utilize a fast sampler DPM-Solver++. Our findings reveal that diffusion models achieve comparable results in the table-to-text domain, highlighting their viability in the table-to-text challenge as a promising research direction.",
        "subjects": "Computation and Language",
        "date": "2024-09-10 15:36:53 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.521990"
    },
    {
        "index": "#129",
        "title": "NLP4PBM: A Systematic Review on Process Extraction using Natural Language Processing with Rule-based, Machine and Deep Learning Methods",
        "link": "/arxiv/2409.13738",
        "arxiv_id": "2409.13738",
        "authors": "William Van Woensel, Soroor Motie",
        "summary": "This literature review studies the field of automated process extraction, i.e., transforming textual descriptions into structured processes using Natural Language Processing (NLP). We found that Machine Learning (ML) / Deep Learning (DL) methods are being increasingly used for the NLP component. In some cases, they were chosen for their suitability towards process extraction, and results show that they can outperform classic rule-based methods. We also found a paucity of gold-standard, scalable annotated datasets, which currently hinders objective evaluations as well as the training or fine-tuning of ML / DL methods. Finally, we discuss preliminary work on the application of LLMs for automated process extraction, as well as promising developments in this field.",
        "subjects": "Computation and Language",
        "date": "2024-09-10 15:16:02 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.522323"
    },
    {
        "index": "#130",
        "title": "Analysis of Socially Unacceptable Discourse with Zero-shot Learning",
        "link": "/arxiv/2409.13735",
        "arxiv_id": "2409.13735",
        "authors": "Rayane Ghilene, Dimitra Niaouri, Michele Linardi, Julien Longhi",
        "summary": "Socially Unacceptable Discourse (SUD) analysis is crucial for maintaining online positive environments. We investigate the effectiveness of Entailment-based zero-shot text classification (unsupervised method) for SUD detection and characterization by leveraging pre-trained transformer models and prompting techniques. The results demonstrate good generalization capabilities of these models to unseen data and highlight the promising nature of this approach for generating labeled datasets for the analysis and characterization of extremist narratives. The findings of this research contribute to the development of robust tools for studying SUD and promoting responsible communication online.",
        "subjects": "Computation and Language",
        "date": "2024-09-10 07:32:00 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.522654"
    },
    {
        "index": "#131",
        "title": "Enhancing Kurdish Text-to-Speech with Native Corpus Training: A High-Quality WaveGlow Vocoder Approach",
        "link": "/arxiv/2409.13734",
        "arxiv_id": "2409.13734",
        "authors": "Abdulhady Abas Abdullah, Sabat Salih Muhamad, Hadi Veisi",
        "summary": "The ability to synthesize spoken language from text has greatly facilitated access to digital content with the advances in text-to-speech technology. However, effective TTS development for low-resource languages, such as Central Kurdish (CKB), still faces many challenges due mainly to the lack of linguistic information and dedicated resources. In this paper, we improve the Kurdish TTS system based on Tacotron by training the Kurdish WaveGlow vocoder on a 21-hour central Kurdish speech corpus instead of using a pre-trained English vocoder WaveGlow. Vocoder training on the target language corpus is required to accurately and fluently adapt phonetic and prosodic changes in Kurdish language. The effectiveness of these enhancements is that our model is significantly better than the baseline system with English pretrained models. In particular, our adaptive WaveGlow model achieves an impressive MOS of 4.91, which sets a new benchmark for Kurdish speech synthesis. On one hand, this study empowers the advanced features of the TTS system for Central Kurdish, and on the other hand, it opens the doors for other dialects in Kurdish and other related languages to further develop.",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2024-09-10 06:23:52 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.522861"
    },
    {
        "index": "#132",
        "title": "RNR: Teaching Large Language Models to Follow Roles and Rules",
        "link": "/arxiv/2409.13733",
        "arxiv_id": "2409.13733",
        "authors": "Kuan Wang, Alexander Bukharin, Haoming Jiang, Qingyu Yin, Zhengyang Wang, Tuo Zhao, Jingbo Shang, Chao Zhang, Bing Yin, Xian Li, Jianshu Chen, Shiyang Li",
        "summary": "Instruction fine-tuning (IFT) elicits instruction following capabilities and steers the behavior of large language models (LLMs) via supervised learning. However, existing models trained on open-source IFT datasets only have the ability to follow instructions from users, and often fail to follow complex role and rules specified by developers, a.k.a. system prompts. The ability to follow these roles and rules is essential for deployment, as it ensures that the model safely interacts with users within developer defined guidelines. To improve such role and rule following ability, we propose \\model, an automated data generation pipeline that generates diverse roles and rules from existing IFT instructions, along with corresponding responses. This data can then be used to train models that follow complex system prompts. The models are evaluated on our newly created benchmarks for role and rule following ability, as well as standard instruction-following benchmarks and general NLP tasks. Our framework significantly improves role and rule following capability in LLMs, as evidenced by over 25% increase in pass-rate on rule adherence, i.e. following all requirements, in our experiments with the Alpaca and Ultrachat datasets. Moreover, our models achieves this increase without any regression on popular instruction following benchmarks.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-10 06:07:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.523151"
    },
    {
        "index": "#133",
        "title": "TopoChat: Enhancing Topological Materials Retrieval With Large Language Model and Multi-Source Knowledge",
        "link": "/arxiv/2409.13732",
        "arxiv_id": "2409.13732",
        "authors": "HuangChao Xu, Baohua Zhang, Zhong Jin, Tiannian Zhu, Quansheng Wu, Hongming Weng",
        "summary": "Large language models (LLMs), such as ChatGPT, have demonstrated impressive performance in the text generation task, showing the ability to understand and respond to complex instructions. However, the performance of naive LLMs in speciffc domains is limited due to the scarcity of domain-speciffc corpora and specialized training. Moreover, training a specialized large-scale model necessitates signiffcant hardware resources, which restricts researchers from leveraging such models to drive advances. Hence, it is crucial to further improve and optimize LLMs to meet speciffc domain demands and enhance their scalability. Based on the condensed matter data center, we establish a material knowledge graph (MaterialsKG) and integrate it with literature. Using large language models and prompt learning, we develop a specialized dialogue system for topological materials called TopoChat. Compared to naive LLMs, TopoChat exhibits superior performance in structural and property querying, material recommendation, and complex relational reasoning. This system enables efffcient and precise retrieval of information and facilitates knowledge interaction, thereby encouraging the advancement on the ffeld of condensed matter materials.",
        "subjects": "Computation and Language, Materials Science, Machine Learning",
        "date": "2024-09-10 06:01:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.523378"
    },
    {
        "index": "#134",
        "title": "KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation",
        "link": "/arxiv/2409.13731",
        "arxiv_id": "2409.13731",
        "authors": "Lei Liang, Mengshu Sun, Zhengke Gui, Zhongshu Zhu, Zhouyu Jiang, Ling Zhong, Yuan Qu, Peilong Zhao, Zhongpu Bo, Jin Yang, Huaidong Xiong, Lin Yuan, Jun Xu, Zaoyang Wang, Wen Zhang, Huajun Chen, Zhiqiang Zhang, Jun Zhou",
        "summary": "The recently developed retrieval-augmented generation (RAG) technology enables the efficient construction of domain-specific applications. However, it faces limitations due to fuzzy retrieval processes, the \"hallucination\" problem of understanding and reasoning capabilities of general language models, and cascading losses in complex systems. These challenges hinder the effectiveness of specialized knowledge services. However, in scenarios such as scientific computing, medicine, and law, the accuracy of knowledge, the completeness of information, and the logical rigor of rules, time, and values are particularly critical. We Introduce professional domain knowledge service framework: Knowledge Augmented Generation(KAG) to improve generation and reasoning performance by bidirectionally enhancing large language model(LLM)s and knowledge graph(KG)s, including five key enhancements: 1) LLM-friendly knowledge semantic representation, 2) mutual indexing between knowledge graph and original chunks, 3) logicalform-guided hybrid reasoning and solving, 4) Knowledge alignment based on semantic reasoning, 5) Model for KAG. We compared KAG with existing RAG methods in multi-hop question answering. The results show that KAG performs significantly better than the state-of-the-art methods, with a relative improvement from 19.6% to 33.4% in F1. We apply KAG to two professional knowledge Q&A tasks of Ant Group, including E-Goverment Q&A and E-Health Q&A, and has achieved significant improvement in professionalism compared with NaiveRAG. We will soon natively support KAG on the open source KG engine OpenSPG, allowing developers to more easily build rigorous knowledge decision-making or convenient information retrieval services.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-10 02:00:28 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.523660"
    },
    {
        "index": "#135",
        "title": "MathGLM-Vision: Solving Mathematical Problems with Multi-Modal Large Language Model",
        "link": "/arxiv/2409.13729",
        "arxiv_id": "2409.13729",
        "authors": "Zhen Yang, Jinhao Chen, Zhengxiao Du, Wenmeng Yu, Weihan Wang, Wenyi Hong, Zhihuan Jiang, Bin Xu, Yuxiao Dong, Jie Tang",
        "summary": "Large language models (LLMs) have demonstrated significant capabilities in mathematical reasoning, particularly with text-based mathematical problems. However, current multi-modal large language models (MLLMs), especially those specialized in mathematics, tend to focus predominantly on solving geometric problems but ignore the diversity of visual information available in other areas of mathematics. Moreover, the geometric information for these specialized mathematical MLLMs is derived from several public datasets, which are typically limited in diversity and complexity. To address these limitations, we aim to construct a fine-tuning dataset named MathVL, and develop a series of specialized mathematical MLLMs termed MathGLM-Vision by conducting Supervised Fine-Tuning (SFT) on MathVL with various parameter-scale backbones. To extensively evaluate the effectiveness of MathGLM-Vision, we conduct experiments on several public benchmarks and our curated MathVL-test consisting of 2,000 problems. Experimental results demonstrate that MathGLM-Vision achieves significant improvements compared with some existing models, including backbone models and open-source mathematical MLLMs. These findings indicate the importance of diversity dataset in enhancing the mathematical reasoning abilities of MLLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-10 01:20:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.523888"
    },
    {
        "index": "#136",
        "title": "Rule Extrapolation in Language Models: A Study of Compositional Generalization on OOD Prompts",
        "link": "/arxiv/2409.13728",
        "arxiv_id": "2409.13728",
        "authors": "Anna Mészáros, Szilvia Ujváry, Wieland Brendel, Patrik Reizinger, Ferenc Huszár",
        "summary": "LLMs show remarkable emergent abilities, such as inferring concepts from presumably out-of-distribution prompts, known as in-context learning. Though this success is often attributed to the Transformer architecture, our systematic understanding is limited. In complex real-world data sets, even defining what is out-of-distribution is not obvious. To better understand the OOD behaviour of autoregressive LLMs, we focus on formal languages, which are defined by the intersection of rules. We define a new scenario of OOD compositional generalization, termed rule extrapolation. Rule extrapolation describes OOD scenarios, where the prompt violates at least one rule. We evaluate rule extrapolation in formal languages with varying complexity in linear and recurrent architectures, the Transformer, and state space models to understand the architectures' influence on rule extrapolation. We also lay the first stones of a normative theory of rule extrapolation, inspired by the Solomonoff prior in algorithmic information theory.",
        "subjects": "Computation and Language, Machine Learning, Machine Learning",
        "date": "2024-09-09 22:36:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524141"
    },
    {
        "index": "#137",
        "title": "Classification performance and reproducibility of GPT-4 omni for information extraction from veterinary electronic health records",
        "link": "/arxiv/2409.13727",
        "arxiv_id": "2409.13727",
        "authors": "Judit M Wulcan, Kevin L Jacques, Mary Ann Lee, Samantha L Kovacs, Nicole Dausend, Lauren E Prince, Jonatan Wulcan, Sina Marsilio, Stefan M Keller",
        "summary": "Large language models (LLMs) can extract information from veterinary electronic health records (EHRs), but performance differences between models, the effect of temperature settings, and the influence of text ambiguity have not been previously evaluated. This study addresses these gaps by comparing the performance of GPT-4 omni (GPT-4o) and GPT-3.5 Turbo under different conditions and investigating the relationship between human interobserver agreement and LLM errors. The LLMs and five humans were tasked with identifying six clinical signs associated with Feline chronic enteropathy in 250 EHRs from a veterinary referral hospital. At temperature 0, the performance of GPT-4o compared to the majority opinion of human respondents, achieved 96.9% sensitivity (interquartile range [IQR] 92.9-99.3%), 97.6% specificity (IQR 96.5-98.5%), 80.7% positive predictive value (IQR 70.8-84.6%), 99.5% negative predictive value (IQR 99.0-99.9%), 84.4% F1 score (IQR 77.3-90.4%), and 96.3% balanced accuracy (IQR 95.0-97.9%). The performance of GPT-4o was significantly better than that of its predecessor, GPT-3.5 Turbo, particularly with respect to sensitivity where GPT-3.5 Turbo only achieved 81.7% (IQR 78.9-84.8%). Adjusting the temperature for GPT-4o did not significantly impact classification performance. GPT-4o demonstrated greater reproducibility than human pairs regardless of temperature, with an average Cohen's kappa of 0.98 (IQR 0.98-0.99) at temperature 0 compared to 0.8 (IQR 0.78-0.81) for humans. Most GPT-4o errors occurred in instances where humans disagreed (35/43 errors, 81.4%), suggesting that these errors were more likely caused by ambiguity of the EHR than explicit model faults. Using GPT-4o to automate information extraction from veterinary EHRs is a viable alternative to manual extraction.",
        "subjects": "Computation and Language",
        "date": "2024-09-09 21:55:15 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524358"
    },
    {
        "index": "#138",
        "title": "Multilingual Dyadic Interaction Corpus NoXi+J: Toward Understanding Asian-European Non-verbal Cultural Characteristics and their Influences on Engagement",
        "link": "/arxiv/2409.13726",
        "arxiv_id": "2409.13726",
        "authors": "Marius Funk, Shogo Okada, Elisabeth André",
        "summary": "Non-verbal behavior is a central challenge in understanding the dynamics of a conversation and the affective states between interlocutors arising from the interaction. Although psychological research has demonstrated that non-verbal behaviors vary across cultures, limited computational analysis has been conducted to clarify these differences and assess their impact on engagement recognition. To gain a greater understanding of engagement and non-verbal behaviors among a wide range of cultures and language spheres, in this study we conduct a multilingual computational analysis of non-verbal features and investigate their role in engagement and engagement prediction. To achieve this goal, we first expanded the NoXi dataset, which contains interaction data from participants living in France, Germany, and the United Kingdom, by collecting session data of dyadic conversations in Japanese and Chinese, resulting in the enhanced dataset NoXi+J. Next, we extracted multimodal non-verbal features, including speech acoustics, facial expressions, backchanneling and gestures, via various pattern recognition techniques and algorithms. Then, we conducted a statistical analysis of listening behaviors and backchannel patterns to identify culturally dependent and independent features in each language and common features among multiple languages. These features were also correlated with the engagement shown by the interlocutors. Finally, we analyzed the influence of cultural differences in the input features of LSTM models trained to predict engagement for five language datasets. A SHAP analysis combined with transfer learning confirmed a considerable correlation between the importance of input features for a language set and the significant cultural characteristics analyzed.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-09 18:37:34 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524556"
    },
    {
        "index": "#139",
        "title": "Identity-related Speech Suppression in Generative AI Content Moderation",
        "link": "/arxiv/2409.13725",
        "arxiv_id": "2409.13725",
        "authors": "Oghenefejiro Isaacs Anigboro, Charlie M. Crawford, Danaë Metaxa, Sorelle A. Friedler",
        "summary": "Automated content moderation has long been used to help identify and filter undesired user-generated content online. Generative AI systems now use such filters to keep undesired generated content from being created by or shown to users. From classrooms to Hollywood, as generative AI is increasingly used for creative or expressive text generation, whose stories will these technologies allow to be told, and whose will they suppress? In this paper, we define and introduce measures of speech suppression, focusing on speech related to different identity groups incorrectly filtered by a range of content moderation APIs. Using both short-form, user-generated datasets traditional in content moderation and longer generative AI-focused data, including two datasets we introduce in this work, we create a benchmark for measurement of speech suppression for nine identity groups. Across one traditional and four generative AI-focused automated content moderation services tested, we find that identity-related speech is more likely to be incorrectly suppressed than other speech except in the cases of a few non-marginalized groups. Additionally, we find differences between APIs in their abilities to correctly moderate generative AI content.",
        "subjects": "Computation and Language, Computers and Society, Human-Computer Interaction",
        "date": "2024-09-09 14:34:51 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524752"
    },
    {
        "index": "#140",
        "title": "Logically Consistent Language Models via Neuro-Symbolic Integration",
        "link": "/arxiv/2409.13724",
        "arxiv_id": "2409.13724",
        "authors": "Diego Calanzone, Stefano Teso, Antonio Vergari",
        "summary": "Large language models (LLMs) are a promising venue for natural language understanding and generation. However, current LLMs are far from reliable: they are prone to generating non-factual information and, more crucially, to contradicting themselves when prompted to reason about relations between entities of the world. These problems are currently addressed with large scale fine-tuning or by delegating reasoning to external tools. In this work, we strive for a middle ground and introduce a loss based on neuro-symbolic reasoning that teaches an LLM to be logically consistent with an external set of facts and rules and improves self-consistency even when the LLM is fine-tuned on a limited set of facts. Our approach also allows to easily combine multiple logical constraints at once in a principled way, delivering LLMs that are more consistent w.r.t. all constraints and improve over several baselines w.r.t. a given constraint. Moreover, our method allows LLMs to extrapolate to unseen but semantically similar factual knowledge, represented in unseen datasets, more systematically.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-09 10:52:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.524950"
    },
    {
        "index": "#141",
        "title": "LegiLM: A Fine-Tuned Legal Language Model for Data Compliance",
        "link": "/arxiv/2409.13721",
        "arxiv_id": "2409.13721",
        "authors": "Linkai Zhu, Lu Yang, Chaofan Li, Shanwen Hu, Lu Liu, Bin Yin",
        "summary": "Ensuring compliance with international data protection standards for privacy and data security is a crucial but complex task, often requiring substantial legal expertise. This paper introduces LegiLM, a novel legal language model specifically tailored for consulting on data or information compliance. LegiLM leverages a pre-trained GDPR Fines dataset and has been fine-tuned to automatically assess whether particular actions or events breach data security and privacy regulations. By incorporating a specialized dataset that includes global data protection laws, meticulously annotated policy documents, and relevant privacy policies, LegiLM is optimized for addressing data compliance challenges. The model integrates advanced legal reasoning methods and information retrieval enhancements to enhance accuracy and reliability in practical legal consulting scenarios. Our evaluation using a custom benchmark dataset demonstrates that LegiLM excels in detecting data regulation breaches, offering sound legal justifications, and recommending necessary compliance modifications, setting a new benchmark for AI-driven legal compliance solutions. Our resources are publicly available at https://github.com/DAOLegalAI/LegiLM",
        "subjects": "Computation and Language",
        "date": "2024-09-09 02:06:52 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.525154"
    },
    {
        "index": "#142",
        "title": "DiVA-DocRE: A Discriminative and Voice-Aware Paradigm for Document-Level Relation Extraction",
        "link": "/arxiv/2409.13717",
        "arxiv_id": "2409.13717",
        "authors": "Yiheng Wu, Roman Yangarber, Xian Mao",
        "summary": "The remarkable capabilities of Large Language Models (LLMs) in text comprehension and generation have revolutionized Information Extraction (IE). One such advancement is in Document-level Relation Triplet Extraction (DocRTE), a critical task in information systems that aims to extract entities and their semantic relationships from documents. However, existing methods are primarily designed for Sentence level Relation Triplet Extraction (SentRTE), which typically handles a limited set of relations and triplet facts within a single sentence. Additionally, some approaches treat relations as candidate choices integrated into prompt templates, resulting in inefficient processing and suboptimal performance when determining the relation elements in triplets. To address these limitations, we introduce a Discriminative and Voice Aware Paradigm DiVA. DiVA involves only two steps: performing document-level relation extraction (DocRE) and then identifying the subject object entities based on the relation. No additional processing is required simply input the document to directly obtain the triplets. This streamlined process more accurately reflects real-world scenarios for triplet extraction. Our innovation lies in transforming DocRE into a discriminative task, where the model pays attention to each relation and to the often overlooked issue of active vs. passive voice within the triplet. Our experiments on the Re-DocRED and DocRED datasets demonstrate state-of-the-art results for the DocRTE task.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-07 18:47:38 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.525416"
    },
    {
        "index": "#143",
        "title": "Constrained Multi-Layer Contrastive Learning for Implicit Discourse Relationship Recognition",
        "link": "/arxiv/2409.13716",
        "arxiv_id": "2409.13716",
        "authors": "Yiheng Wu, Junhui Li, Muhua Zhu",
        "summary": "Previous approaches to the task of implicit discourse relation recognition (IDRR) generally view it as a classification task. Even with pre-trained language models, like BERT and RoBERTa, IDRR still relies on complicated neural networks with multiple intermediate layers to proper capture the interaction between two discourse units. As a result, the outputs of these intermediate layers may have different capability in discriminating instances of different classes. To this end, we propose to adapt a supervised contrastive learning (CL) method, label- and instance-centered CL, to enhance representation learning. Moreover, we propose a novel constrained multi-layer CL approach to properly impose a constraint that the contrastive loss of higher layers should be smaller than that of lower layers. Experimental results on PDTB 2.0 and PDTB 3.0 show that our approach can significantly improve the performance on both multi-class classification and binary classification.",
        "subjects": "Computation and Language",
        "date": "2024-09-07 17:55:41 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.525610"
    },
    {
        "index": "#144",
        "title": "Introducing MeMo: A Multimodal Dataset for Memory Modelling in Multiparty Conversations",
        "link": "/arxiv/2409.13715",
        "arxiv_id": "2409.13715",
        "authors": "Maria Tsfasman, Bernd Dudzik, Kristian Fenech, Andras Lorincz, Catholijn M. Jonker, Catharine Oertel",
        "summary": "The quality of human social relationships is intricately linked to human memory processes, with memory serving as the foundation for the creation of social bonds. Since human memory is selective, differing recollections of the same events within a group can lead to misunderstandings and misalignments in what is perceived to be common ground in the group. Yet, conversational facilitation systems, aimed at advancing the quality of group interactions, usually focus on tracking users' states within an individual session, ignoring what remains in each participant's memory after the interaction. Conversational memory is the process by which humans encode, retain and retrieve verbal, non-verbal and contextual information from a conversation. Understanding conversational memory can be used as a source of information on the long-term development of social connections within a group. This paper introduces the MeMo corpus, the first conversational dataset annotated with participants' memory retention reports, aimed at facilitating computational modelling of human conversational memory. The MeMo corpus includes 31 hours of small-group discussions on the topic of Covid-19, repeated over the term of 2 weeks. It integrates validated behavioural and perceptual measures, and includes audio, video, and multimodal annotations, offering a valuable resource for studying and modelling conversational memory and group dynamics. By introducing the MeMo corpus, presenting an analysis of its validity, and demonstrating its usefulness for future research, this paper aims to pave the way for future research in conversational memory modelling for intelligent system development.",
        "subjects": "Computation and Language, Artificial Intelligence, Human-Computer Interaction, Machine Learning",
        "date": "2024-09-07 16:09:36 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.525835"
    },
    {
        "index": "#145",
        "title": "TracrBench: Generating Interpretability Testbeds with Large Language Models",
        "link": "/arxiv/2409.13714",
        "arxiv_id": "2409.13714",
        "authors": "Hannes Thurnherr, Jérémy Scheurer",
        "summary": "Achieving a mechanistic understanding of transformer-based language models is an open challenge, especially due to their large number of parameters. Moreover, the lack of ground truth mappings between model weights and their functional roles hinders the effective evaluation of interpretability methods, impeding overall progress. Tracr, a method for generating compiled transformers with inherent ground truth mappings in RASP, has been proposed to address this issue. However, manually creating a large number of models needed for verifying interpretability methods is labour-intensive and time-consuming. In this work, we present a novel approach for generating interpretability test beds using large language models (LLMs) and introduce TracrBench, a novel dataset consisting of 121 manually written and LLM-generated, human-validated RASP programs and their corresponding transformer weights. During this process, we evaluate the ability of frontier LLMs to autonomously generate RASP programs and find that this task poses significant challenges. GPT-4-turbo, with a 20-shot prompt and best-of-5 sampling, correctly implements only 57 out of 101 test programs, necessitating the manual implementation of the remaining programs. With its 121 samples, TracrBench aims to serve as a valuable testbed for evaluating and comparing interpretability methods.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-07 10:02:51 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.526062"
    },
    {
        "index": "#146",
        "title": "Sentiment Informed Sentence BERT-Ensemble Algorithm for Depression Detection",
        "link": "/arxiv/2409.13713",
        "arxiv_id": "2409.13713",
        "authors": "Bayode Ogunleye, Hemlata Sharma, Olamilekan Shobayo",
        "summary": "The World Health Organisation (WHO) revealed approximately 280 million people in the world suffer from depression. Yet, existing studies on early-stage depression detection using machine learning (ML) techniques are limited. Prior studies have applied a single stand-alone algorithm, which is unable to deal with data complexities, prone to overfitting, and limited in generalization. To this end, our paper examined the performance of several ML algorithms for early-stage depression detection using two benchmark social media datasets (D1 and D2). More specifically, we incorporated sentiment indicators to improve our model performance. Our experimental results showed that sentence bidirectional encoder representations from transformers (SBERT) numerical vectors fitted into the stacking ensemble model achieved comparable F1 scores of 69% in the dataset (D1) and 76% in the dataset (D2). Our findings suggest that utilizing sentiment indicators as an additional feature for depression detection yields an improved model performance, and thus, we recommend the development of a depressive term corpus for future work.",
        "subjects": "Computation and Language, Machine Learning, Statistics Theory, Applications",
        "date": "2024-09-07 07:47:55 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.526273"
    },
    {
        "index": "#147",
        "title": "Good Idea or Not, Representation of LLM Could Tell",
        "link": "/arxiv/2409.13712",
        "arxiv_id": "2409.13712",
        "authors": "Yi Xu, Bo Xue, Shuqian Sheng, Cheng Deng, Jiaxin Ding, Zanwei Shen, Luoyi Fu, Xinbing Wang, Chenghu Zhou",
        "summary": "In the ever-expanding landscape of academic research, the proliferation of ideas presents a significant challenge for researchers: discerning valuable ideas from the less impactful ones. The ability to efficiently evaluate the potential of these ideas is crucial for the advancement of science and paper review. In this work, we focus on idea assessment, which aims to leverage the knowledge of large language models to assess the merit of scientific ideas. First, we investigate existing text evaluation research and define the problem of quantitative evaluation of ideas. Second, we curate and release a benchmark dataset from nearly four thousand manuscript papers with full texts, meticulously designed to train and evaluate the performance of different approaches to this task. Third, we establish a framework for quantifying the value of ideas by employing representations in a specific layer of large language models. Experimental results show that the scores predicted by our method are relatively consistent with those of humans. Our findings suggest that the representations of large language models hold more potential in quantifying the value of ideas than their generative outputs, demonstrating a promising avenue for automating the idea assessment process.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-07 02:07:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.526503"
    },
    {
        "index": "#148",
        "title": "You can remove GPT2's LayerNorm by fine-tuning",
        "link": "/arxiv/2409.13710",
        "arxiv_id": "2409.13710",
        "authors": "Stefan Heimersheim",
        "summary": "The LayerNorm (LN) layer in GPT-style transformer models has long been a hindrance to mechanistic interpretability. LN is a crucial component required to stabilize the training of large language models, and LN or the similar RMSNorm have been used in practically all large language models based on the transformer architecture. The non-linear nature of the LN layers is a hindrance for mechanistic interpretability as it hinders interpretation of the residual stream, and makes it difficult to decompose the model into circuits. Some research have gone so far as to name \"reasons interpretability researchers hate layer norm\". In this paper we show that it is possible to remove the LN layers from a pre-trained GPT2-small model by fine-tuning on a fraction (500M tokens) of the training data. We demonstrate that this LN-free model achieves similar performance to the original model on the OpenWebText and ThePile datasets (-0.05 cross-entropy loss), and the Hellaswag benchmark (-0.5% accuracy). We provide the fine-tuning procedure and a Hugging Face repository with the fine-tuned GPT2-small models. Our work not only provides a simplified model for mechanistic interpretability research, but also provides evidence that the LN layers, at inference time, do not play a crucial role in transformer models.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2024-09-06 16:17:06 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.532159"
    },
    {
        "index": "#149",
        "title": "Column Vocabulary Association (CVA): semantic interpretation of dataless tables",
        "link": "/arxiv/2409.13709",
        "arxiv_id": "2409.13709",
        "authors": "Margherita Martorana, Xueli Pan, Benno Kruit, Tobias Kuhn, Jacco van Ossenbruggen",
        "summary": "Traditional Semantic Table Interpretation (STI) methods rely primarily on the underlying table data to create semantic annotations. This year's SemTab challenge introduced the ``Metadata to KG'' track, which focuses on performing STI by using only metadata information, without access to the underlying data. In response to this new challenge, we introduce a new term: Column Vocabulary Association (CVA). This term refers to the task of semantic annotation of column headers solely based on metadata information. In this study, we evaluate the performance of various methods in executing the CVA task, including a Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) approach, as well as a more traditional similarity approach with SemanticBERT. Our methodology uses a zero-shot setting, with no pretraining or examples passed to the Large Language Models (LLMs), as we aim to avoid a domain-specific setting. We investigate a total of 7 different LLMs, of which three commercial GPT models (i.e. gpt-3.5-turbo-0.125, gpt-4o and gpt-4-turbo) and four open source models (i.e. llama3-80b, llama3-7b, gemma-7b and mixtral-8x7b). We integrate this models with RAG systems, and we explore how variations in temperature settings affect performances. Moreover, we continue our investigation by performing the CVA task utilizing SemanticBERT, analyzing how various metadata information influence its performance. Initial findings indicate that LLMs generally perform well at temperatures below 1.0, achieving an accuracy of 100\\% in certain cases. Nevertheless, our investigation also reveal that the nature of the data significantly influences CVA task outcomes. In fact, in cases where the input data and glossary are related (for example by being created by the same organizations) traditional methods appear to surpass the performance of LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-06 14:58:30 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.532607"
    },
    {
        "index": "#150",
        "title": "Towards Safe Multilingual Frontier AI",
        "link": "/arxiv/2409.13708",
        "arxiv_id": "2409.13708",
        "authors": "Artūrs Kanepajs, Vladimir Ivanov, Richard Moulange",
        "summary": "Linguistically inclusive LLMs -- which maintain good performance regardless of the language with which they are prompted -- are necessary for the diffusion of AI benefits around the world. Multilingual jailbreaks that rely on language translation to evade safety measures undermine the safe and inclusive deployment of AI systems. We provide policy recommendations to enhance the multilingual capabilities of AI while mitigating the risks of multilingual jailbreaks. We quantitatively assess the relationship between language resourcedness and model vulnerabilities to multilingual jailbreaks for five frontier large language models across 24 official EU languages. Building on prior research, we propose policy actions that align with the EU legal landscape and institutional framework to address multilingual jailbreaks, while promoting linguistic inclusivity. These include mandatory assessments of multilingual capabilities and vulnerabilities, public opinion research, and state support for multilingual AI development. The measures aim to improve AI safety and functionality through EU policy initiatives, guiding the implementation of the EU AI Act and informing regulatory efforts of the European AI Office.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society",
        "date": "2024-09-06 14:26:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.532993"
    },
    {
        "index": "#151",
        "title": "Decolonising Data Systems: Using Jyutping or Pinyin as tonal representations of Chinese names for data linkage",
        "link": "/arxiv/2409.13706",
        "arxiv_id": "2409.13706",
        "authors": "Joseph Lam, Mario Cortina-Borja, Robert Aldridge, Ruth Blackburn, Katie Harron",
        "summary": "Data linkage is increasingly used in health research and policy making and is relied on for understanding health inequalities. However, linked data is only as useful as the underlying data quality, and differential linkage rates may induce selection bias in the linked data. A mechanism that selectively compromises data quality is name romanisation. Converting text of a different writing system into Latin based writing, or romanisation, has long been the standard process of representing names in character-based writing systems such as Chinese, Vietnamese, and other languages such as Swahili. Unstandardised romanisation of Chinese characters, due in part to problems of preserving the correct name orders the lack of proper phonetic representation of a tonal language, has resulted in poor linkage rates for Chinese immigrants. This opinion piece aims to suggests that the use of standardised romanisation systems for Cantonese (Jyutping) or Mandarin (Pinyin) Chinese, which incorporate tonal information, could improve linkage rates and accuracy for individuals with Chinese names. We used 771 Chinese and English names scraped from openly available sources, and compared the utility of Jyutping, Pinyin and the Hong Kong Government Romanisation system (HKG-romanisation) for representing Chinese names. We demonstrate that both Jyutping and Pinyin result in fewer errors compared with the HKG-romanisation system. We suggest that collecting and preserving people's names in their original writing systems is ethically and socially pertinent. This may inform development of language-specific pre-processing and linkage paradigms that result in more inclusive research data which better represents the targeted populations.",
        "subjects": "Computation and Language",
        "date": "2024-09-06 12:01:01 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.533323"
    },
    {
        "index": "#152",
        "title": "Debiasing Text Safety Classifiers through a Fairness-Aware Ensemble",
        "link": "/arxiv/2409.13705",
        "arxiv_id": "2409.13705",
        "authors": "Olivia Sturman, Aparna Joshi, Bhaktipriya Radharapu, Piyush Kumar, Renee Shelby",
        "summary": "Increasing use of large language models (LLMs) demand performant guardrails to ensure the safety of inputs and outputs of LLMs. When these safeguards are trained on imbalanced data, they can learn the societal biases. We present a light-weight, post-processing method for mitigating counterfactual fairness in closed-source text safety classifiers. Our approach involves building an ensemble that not only outperforms the input classifiers and policy-aligns them, but also acts as a debiasing regularizer. We introduce two threshold-agnostic metrics to assess the counterfactual fairness of a model, and demonstrate how combining these metrics with Fair Data Reweighting (FDW) helps mitigate biases. We create an expanded Open AI dataset, and a new templated LLM-generated dataset based on user-prompts, both of which are counterfactually balanced across identity groups and cover four key areas of safety; we will work towards publicly releasing these datasets. Our results show that our approach improves counterfactual fairness with minimal impact on model performance.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2024-09-05 14:35:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.533685"
    },
    {
        "index": "#153",
        "title": "Entity Extraction from High-Level Corruption Schemes via Large Language Models",
        "link": "/arxiv/2409.13704",
        "arxiv_id": "2409.13704",
        "authors": "Panagiotis Koletsis, Panagiotis-Konstantinos Gemos, Christos Chronis, Iraklis Varlamis, Vasilis Efthymiou, Georgios Th. Papadopoulos",
        "summary": "The rise of financial crime that has been observed in recent years has created an increasing concern around the topic and many people, organizations and governments are more and more frequently trying to combat it. Despite the increase of interest in this area, there is a lack of specialized datasets that can be used to train and evaluate works that try to tackle those problems. This article proposes a new micro-benchmark dataset for algorithms and models that identify individuals and organizations, and their multiple writings, in news articles, and presents an approach that assists in its creation. Experimental efforts are also reported, using this dataset, to identify individuals and organizations in financial-crime-related articles using various low-billion parameter Large Language Models (LLMs). For these experiments, standard metrics (Accuracy, Precision, Recall, F1 Score) are reported and various prompt variants comprising the best practices of prompt engineering are tested. In addition, to address the problem of ambiguous entity mentions, a simple, yet effective LLM-based disambiguation method is proposed, ensuring that the evaluation aligns with reality. Finally, the proposed approach is compared against a widely used state-of-the-art open-source baseline, showing the superiority of the proposed method.",
        "subjects": "Computation and Language",
        "date": "2024-09-05 10:27:32 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.533946"
    },
    {
        "index": "#154",
        "title": "Shaping the Future of Endangered and Low-Resource Languages -- Our Role in the Age of LLMs: A Keynote at ECIR 2024",
        "link": "/arxiv/2409.13702",
        "arxiv_id": "2409.13702",
        "authors": "Josiane Mothe",
        "summary": "Isidore of Seville is credited with the adage that it is language that gives birth to a people, and not the other way around , underlining the profound role played by language in the formation of cultural and social identity. Today, of the more than 7100 languages listed, a significant number are endangered. Since the 1970s, linguists, information seekers and enthusiasts have helped develop digital resources and automatic tools to support a wide range of languages, including endangered ones. The advent of Large Language Model (LLM) technologies holds both promise and peril. They offer unprecedented possibilities for the translation and generation of content and resources, key elements in the preservation and revitalisation of languages. They also present threat of homogenisation, cultural oversimplification and the further marginalisation of already vulnerable languages. The talk this paper is based on has proposed an initiatory journey, exploring the potential paths and partnerships between technology and tradition, with a particular focus on the Occitan language. Occitan is a language from Southern France, parts of Spain and Italy that played a major cultural and economic role, particularly in the Middle Ages. It is now endangered according to UNESCO. The talk critically has examined how human expertise and artificial intelligence can work together to offer hope for preserving the linguistic diversity that forms the foundation of our global and especially our European heritage while addressing some of the ethical and practical challenges that accompany the use of these powerful technologies. This paper is based on the keynote I gave at the 46th European Conference on Information Retrieval (ECIR 2024). As an alternative to reading this paper, a video talk is available online. 1 Date: 26 March 2024.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2024-09-05 06:54:30 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534136"
    },
    {
        "index": "#155",
        "title": "CA-BERT: Leveraging Context Awareness for Enhanced Multi-Turn Chat Interaction",
        "link": "/arxiv/2409.13701",
        "arxiv_id": "2409.13701",
        "authors": "Minghao Liu, Mingxiu Sui, Cangqing Wang, Zhejie Zhou",
        "summary": "Effective communication in automated chat systems hinges on the ability to understand and respond to context. Traditional models often struggle with determining when additional context is necessary for generating appropriate responses. This paper introduces Context-Aware BERT (CA-BERT), a transformer-based model specifically fine-tuned to address this challenge. CA-BERT innovatively applies deep learning techniques to discern context necessity in multi-turn chat interactions, enhancing both the relevance and accuracy of responses. We describe the development of CA-BERT, which adapts the robust architecture of BERT with a novel training regimen focused on a specialized dataset of chat dialogues. The model is evaluated on its ability to classify context necessity, demonstrating superior performance over baseline BERT models in terms of accuracy and efficiency. Furthermore, CA-BERT's implementation showcases significant reductions in training time and resource usage, making it feasible for real-time applications. The results indicate that CA-BERT can effectively enhance the functionality of chatbots by providing a nuanced understanding of context, thereby improving user experience and interaction quality in automated systems. This study not only advances the field of NLP in chat applications but also provides a framework for future research into context-sensitive AI developments.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-05 06:27:59 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534340"
    },
    {
        "index": "#156",
        "title": "Lightweight Transducer Based on Frame-Level Criterion",
        "link": "/arxiv/2409.13698",
        "arxiv_id": "2409.13698",
        "authors": "Genshun Wan, Mengzhi Wang, Tingzhi Mao, Hang Chen, Zhongfu Ye",
        "summary": "The transducer model trained based on sequence-level criterion requires a lot of memory due to the generation of the large probability matrix. We proposed a lightweight transducer model based on frame-level criterion, which uses the results of the CTC forced alignment algorithm to determine the label for each frame. Then the encoder output can be combined with the decoder output at the corresponding time, rather than adding each element output by the encoder to each element output by the decoder as in the transducer. This significantly reduces memory and computation requirements. To address the problem of imbalanced classification caused by excessive blanks in the label, we decouple the blank and non-blank probabilities and truncate the gradient of the blank classifier to the main network. This enables the lightweight transducer achieving similar results to transducer. Additionally, we use richer information to predict the probability of blank, achieving superior results to transducer.",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2024-09-05 02:24:18 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534550"
    },
    {
        "index": "#157",
        "title": "Prompt Baking",
        "link": "/arxiv/2409.13697",
        "arxiv_id": "2409.13697",
        "authors": "Aman Bhargava, Cameron Witkowski, Alexander Detkov, Matt Thomson",
        "summary": "Two primary ways to change LLM behavior are prompting and weight updates (e.g., fine-tuning). Prompting LLMs is simple and effective, specifying the desired changes explicitly in natural language, whereas weight updates provide more expressive and permanent behavior changes, specified implicitly via training on large datasets. We present a technique for \"baking\" prompts into the weights of an LLM. Prompt Baking converts a prompt $u$ and initial weights $\\theta$ to a new set of weights $\\theta_u$ such that new \"baked\" LLM behaves like the original prompted LLM. Mathematically, we minimize the KL divergence between $P_\\theta(\\cdot | u)$ and $P_{\\theta_u}(\\cdot)$, where $P$ is the LLM's probability distribution over token sequences. Across all our experiments, we find prompts can be readily baked into weight updates. Baking chain-of-thought prompts improves zero-shot performance on GSM8K, ASDiv, MBPP, ARC-Easy, ARC-Challenge, and CommonsenseQA benchmarks. Baking news headlines directly updates an LLM's knowledge. And baking instructions & personas alleviates \"prompt forgetting\" over long sequences. Furthermore, stopping baking early creates \"half-baked\" models, continuously scaling prompt strength. Baked models retain their sensitivity to further prompting and baking, including re-prompting with the baked-in prompt. Surprisingly, the re-prompted models yield further performance gains in instruction following, as well as math reasoning and coding benchmarks. Taking re-prompting and re-baking to the limit yields a form of iterative self-improvement we call Prompt Pursuit, and preliminary results on instruction following exhibit dramatic performance gains. Finally, we discuss implications for AI safety, continuous model updating, enhancing real-time learning capabilities in LLM-based agents, and generating more stable AI personas.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-04 04:13:16 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534741"
    },
    {
        "index": "#158",
        "title": "You Only Use Reactive Attention Slice For Long Context Retrieval",
        "link": "/arxiv/2409.13695",
        "arxiv_id": "2409.13695",
        "authors": "Yun Joon Soh, Hanxian Huang, Yuandong Tian, Jishen Zhao",
        "summary": "Supporting longer context for Large Language Models (LLM) is a promising direction to advance LLMs. As training a model for a longer context window is computationally expensive, many alternative solutions, such as Retrieval Augmented Generation (RAG), have been used. However, most existing RAG methods adopt embedding-based retrieval that falls short on long contexts. To address such challenges, we propose an attention-based retrieval technique, You Only Use Reactive Attention slice (YOURA). YOURA leverages a novel retrieval heuristic called reaction score to rank the relevance of each sentence in the input context with the query sentence. Intuitively, we measure how the per-token attention score \"reacts\" to the query and greedily retrieves the most reactive sentences. Internally, YOURA generates a token-indexed vector (called reaction vector) for the whole input context. To map each sentence to the token-indexed vector, we propose an Embedding-Agnostic Sentence Yield (EASY), a best-effort token wiggling algorithm. We evaluate our retrieval technique on three open-source pre-trained LLM models across six LongBench QA datasets. Our technique achieves up to 30% vLLM inference throughput improvement for serving long-context queries with a nearly identical quality score to the simple yet effective truncate-middle approach.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-03 15:30:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.534931"
    },
    {
        "index": "#159",
        "title": "A Knowledge-Centric Benchmarking Framework and Empirical Study for Retrieval-Augmented Generation",
        "link": "/arxiv/2409.13694",
        "arxiv_id": "2409.13694",
        "authors": "Shuo Yu, Mingyue Cheng, Jiqian Yang, Jie Ouyang",
        "summary": "Retrieval-Augmented Generation (RAG) enhances generative models by integrating retrieval mechanisms, which allow these models to access and utilize external knowledge sources. Despite its advantages, RAG encounters significant challenges, particularly in effectively handling real-world queries and mitigating hallucinations. The KDD Cup 2024 CRAG competition brings these issues to the forefront by incorporating both web pages and a mock API as knowledge sources, adding the complexity of parsing HTML before large language models (LLMs) can process the information. In this paper, we propose a novel RAG benchmark designed to address these challenges. Our work provides a comprehensive set of experimental results, offering valuable insights for the study of RAG. We thoroughly examine the entire RAG process, including knowledge source selection, retrieval, organization, and reasoning. Key findings from our study include the impact of automated knowledge source selection using agents and the influence of noise chunks on RAG reasoning. Additionally, we conduct detailed experiments to analyze the effects of various hyperparameters on RAG performance. To support further research, we have made our results, the associated code, and a parsed version of the CRAG dataset publicly available\\footnote{https://github.com/USTCAGI/RAG-X}, contributing to the advancement of RAG methodologies and establishing a solid foundation for future work in this domain.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2024-09-03 03:31:37 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.535201"
    },
    {
        "index": "#160",
        "title": "Archon: An Architecture Search Framework for Inference-Time Techniques",
        "link": "/arxiv/2409.15254",
        "arxiv_id": "2409.15254",
        "authors": "Jon Saad-Falcon, Adrian Gamarra Lafuente, Shlok Natarajan, Nahum Maru, Hristo Todorov, E. Kelly Buchanan, Mayee Chen, Neel Guha, Christopher Ré, Azalia Mirhoseini",
        "summary": "Inference-time techniques are emerging as highly effective tools to increase large language model (LLM) capabilities. However, there is still limited understanding of the best practices for developing systems that combine inference-time techniques with one or more LLMs, with challenges including: (1) effectively allocating inference compute budget, (2) understanding the interactions between different combinations of inference-time techniques and their impact on downstream performance, and 3) efficiently searching over the large space of model choices, inference-time techniques, and their compositions. To address these challenges, we introduce Archon, an automated framework for designing inference-time architectures. Archon defines an extensible design space, encompassing methods such as generation ensembling, multi-sampling, ranking, fusion, critiquing, verification, and unit testing. It then transforms the problem of selecting and combining LLMs and inference-time techniques into a hyperparameter optimization objective. To optimize this objective, we introduce automated Inference-Time Architecture Search (ITAS) algorithms. Given target benchmark(s), an inference compute budget, and available LLMs, ITAS outputs optimized architectures. We evaluate Archon architectures across a wide range of instruction-following and reasoning benchmarks, including MT-Bench, Arena-Hard-Auto, AlpacaEval 2.0, MixEval, MixEval Hard, MATH, and CodeContests. We show that automatically designed inference-time architectures by Archon outperform strong models such as GPT-4o and Claude 3.5 Sonnet on these benchmarks, achieving an average increase of 14.1 and 10.3 percentage points with all-source models and open-source models, respectively. We make our code and datasets available publicly on Github: https://github.com/ScalingIntelligence/Archon.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2024-09-23 17:53:42 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.535476"
    },
    {
        "index": "#161",
        "title": "Efficiently Dispatching Flash Attention For Partially Filled Attention Masks",
        "link": "/arxiv/2409.15097",
        "arxiv_id": "2409.15097",
        "authors": "Agniv Sharma, Jonas Geiping",
        "summary": "Transformers are widely used across various applications, many of which yield sparse or partially filled attention matrices. Examples include attention masks designed to reduce the quadratic complexity of attention, sequence packing techniques, and recent innovations like tree masking for fast validation in MEDUSA. Despite the inherent sparsity in these matrices, the state-of-the-art algorithm Flash Attention still processes them with quadratic complexity as though they were dense. In this paper, we introduce \\textbf{Binary Block Masking}, a highly efficient modification that enhances Flash Attention by making it mask-aware. We further propose two optimizations: one tailored for masks with contiguous non-zero patterns and another for extremely sparse masks. Our experiments on attention masks derived from real-world scenarios demonstrate up to a 9x runtime improvement. The implementation will be publicly released to foster further research and application.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2024-09-23 15:11:07 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.535712"
    },
    {
        "index": "#162",
        "title": "Evaluating the Usability of LLMs in Threat Intelligence Enrichment",
        "link": "/arxiv/2409.15072",
        "arxiv_id": "2409.15072",
        "authors": "Sanchana Srikanth, Mohammad Hasanuzzaman, Farah Tasnur Meem",
        "summary": "Large Language Models (LLMs) have the potential to significantly enhance threat intelligence by automating the collection, preprocessing, and analysis of threat data. However, the usability of these tools is critical to ensure their effective adoption by security professionals. Despite the advanced capabilities of LLMs, concerns about their reliability, accuracy, and potential for generating inaccurate information persist. This study conducts a comprehensive usability evaluation of five LLMs ChatGPT, Gemini, Cohere, Copilot, and Meta AI focusing on their user interface design, error handling, learning curve, performance, and integration with existing tools in threat intelligence enrichment. Utilizing a heuristic walkthrough and a user study methodology, we identify key usability issues and offer actionable recommendations for improvement. Our findings aim to bridge the gap between LLM functionality and user experience, thereby promoting more efficient and accurate threat intelligence practices by ensuring these tools are user-friendly and reliable.",
        "subjects": "Cryptography and Security, Computation and Language, Human-Computer Interaction, Machine Learning",
        "date": "2024-09-23 14:44:56 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.535919"
    },
    {
        "index": "#167",
        "title": "MemeCLIP: Leveraging CLIP Representations for Multimodal Meme Classification",
        "link": "/arxiv/2409.14703",
        "arxiv_id": "2409.14703",
        "authors": "Siddhant Bikram Shah, Shuvam Shiwakoti, Maheep Chaudhary, Haohan Wang",
        "summary": "The complexity of text-embedded images presents a formidable challenge in machine learning given the need for multimodal understanding of the multiple aspects of expression conveyed in them. While previous research in multimodal analysis has primarily focused on singular aspects such as hate speech and its subclasses, our study expands the focus to encompass multiple aspects of linguistics: hate, target, stance, and humor detection. We introduce a novel dataset PrideMM comprising text-embedded images associated with the LGBTQ+ Pride movement, thereby addressing a serious gap in existing resources. We conduct extensive experimentation on PrideMM by using unimodal and multimodal baseline methods to establish benchmarks for each task. Additionally, we propose a novel framework MemeCLIP for efficient downstream learning while preserving the knowledge of the pre-trained CLIP model. The results of our experiments show that MemeCLIP achieves superior performance compared to previously proposed frameworks on two real-world datasets. We further compare the performance of MemeCLIP and zero-shot GPT-4 on the hate classification task. Finally, we discuss the shortcomings of our model by qualitatively analyzing misclassified samples. Our code and dataset are publicly available at: https://github.com/SiddhantBikram/MemeCLIP.",
        "subjects": "Machine Learning, Computation and Language, Multimedia",
        "date": "2024-09-23 04:49:08 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.542440"
    },
    {
        "index": "#168",
        "title": "Reducing the Footprint of Multi-Vector Retrieval with Minimal Performance Impact via Token Pooling",
        "link": "/arxiv/2409.14683",
        "arxiv_id": "2409.14683",
        "authors": "Benjamin Clavié, Antoine Chaffin, Griffin Adams",
        "summary": "Over the last few years, multi-vector retrieval methods, spearheaded by ColBERT, have become an increasingly popular approach to Neural IR. By storing representations at the token level rather than at the document level, these methods have demonstrated very strong retrieval performance, especially in out-of-domain settings. However, the storage and memory requirements necessary to store the large number of associated vectors remain an important drawback, hindering practical adoption. In this paper, we introduce a simple clustering-based token pooling approach to aggressively reduce the number of vectors that need to be stored. This method can reduce the space & memory footprint of ColBERT indexes by 50% with virtually no retrieval performance degradation. This method also allows for further reductions, reducing the vector count by 66%-to-75% , with degradation remaining below 5% on a vast majority of datasets. Importantly, this approach requires no architectural change nor query-time processing, and can be used as a simple drop-in during indexation with any ColBERT-like model.",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language",
        "date": "2024-09-23 03:12:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.542823"
    },
    {
        "index": "#170",
        "title": "Backtracking Improves Generation Safety",
        "link": "/arxiv/2409.14586",
        "arxiv_id": "2409.14586",
        "authors": "Yiming Zhang, Jianfeng Chi, Hailey Nguyen, Kartikeya Upasani, Daniel M. Bikel, Jason Weston, Eric Michael Smith",
        "summary": "Text generation has a fundamental limitation almost by definition: there is no taking back tokens that have been generated, even when they are clearly problematic. In the context of language model safety, when a partial unsafe generation is produced, language models by their nature tend to happily keep on generating similarly unsafe additional text. This is in fact how safety alignment of frontier models gets circumvented in the wild, despite great efforts in improving their safety. Deviating from the paradigm of approaching safety alignment as prevention (decreasing the probability of harmful responses), we propose backtracking, a technique that allows language models to \"undo\" and recover from their own unsafe generation through the introduction of a special [RESET] token. Our method can be incorporated into either SFT or DPO training to optimize helpfulness and harmlessness. We show that models trained to backtrack are consistently safer than baseline models: backtracking Llama-3-8B is four times more safe than the baseline model (6.1\\% $\\to$ 1.5\\%) in our evaluations without regression in helpfulness. Our method additionally provides protection against four adversarial attacks including an adaptive attack, despite not being trained to do so.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2024-09-22 20:28:40 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.543362"
    },
    {
        "index": "#171",
        "title": "What Are They Doing? Joint Audio-Speech Co-Reasoning",
        "link": "/arxiv/2409.14526",
        "arxiv_id": "2409.14526",
        "authors": "Yingzhi Wang, Pooneh Mousavi, Artem Ploujnikov, Mirco Ravanelli",
        "summary": "In audio and speech processing, tasks usually focus on either the audio or speech modality, even when both sounds and human speech are present in the same audio clip. Recent Auditory Large Language Models (ALLMs) have made it possible to process audio and speech simultaneously within a single model, leading to further considerations of joint audio-speech tasks. In this paper, we investigate how well ALLMs can perform joint audio-speech processing. Specifically, we introduce Joint Audio-Speech Co-Reasoning (JASCO), a novel task that unifies audio and speech processing, strictly requiring co-reasoning across both modalities. We release a scene-reasoning dataset called \"What Are They Doing\" and establish a joint audio-speech benchmark to evaluate the joint reasoning capability of popular ALLMs. Additionally, we provide deeper insights into the models' behaviors by analyzing their dependence on each modality.",
        "subjects": "Sound, Computation and Language, Audio and Speech Processing",
        "date": "2024-09-22 16:45:57 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.543561"
    },
    {
        "index": "#172",
        "title": "Beyond Words: Evaluating Large Language Models in Transportation Planning",
        "link": "/arxiv/2409.14516",
        "arxiv_id": "2409.14516",
        "authors": "Shaowei Ying, Zhenlong Li, Manzhu Yu",
        "summary": "The resurgence and rapid advancement of Generative Artificial Intelligence (GenAI) in 2023 has catalyzed transformative shifts across numerous industry sectors, including urban transportation and logistics. This study investigates the evaluation of Large Language Models (LLMs), specifically GPT-4 and Phi-3-mini, to enhance transportation planning. The study assesses the performance and spatial comprehension of these models through a transportation-informed evaluation framework that includes general geospatial skills, general transportation domain skills, and real-world transportation problem-solving. Utilizing a mixed-methods approach, the research encompasses an evaluation of the LLMs' general Geographic Information System (GIS) skills, general transportation domain knowledge as well as abilities to support human decision-making in the real-world transportation planning scenarios of congestion pricing. Results indicate that GPT-4 demonstrates superior accuracy and reliability across various GIS and transportation-specific tasks compared to Phi-3-mini, highlighting its potential as a robust tool for transportation planners. Nonetheless, Phi-3-mini exhibits competence in specific analytical scenarios, suggesting its utility in resource-constrained environments. The findings underscore the transformative potential of GenAI technologies in urban transportation planning. Future work could explore the application of newer LLMs and the impact of Retrieval-Augmented Generation (RAG) techniques, on a broader set of real-world transportation planning and operations challenges, to deepen the integration of advanced AI models in transportation management practices.",
        "subjects": "Artificial Intelligence, Computation and Language, Information Retrieval",
        "date": "2024-09-22 16:20:00 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.543828"
    },
    {
        "index": "#173",
        "title": "A Large Language Model and Denoising Diffusion Framework for Targeted Design of Microstructures with Commands in Natural Language",
        "link": "/arxiv/2409.14473",
        "arxiv_id": "2409.14473",
        "authors": "Nikita Kartashov, Nikolaos N. Vlassis",
        "summary": "Microstructure plays a critical role in determining the macroscopic properties of materials, with applications spanning alloy design, MEMS devices, and tissue engineering, among many others. Computational frameworks have been developed to capture the complex relationship between microstructure and material behavior. However, despite these advancements, the steep learning curve associated with domain-specific knowledge and complex algorithms restricts the broader application of these tools. To lower this barrier, we propose a framework that integrates Natural Language Processing (NLP), Large Language Models (LLMs), and Denoising Diffusion Probabilistic Models (DDPMs) to enable microstructure design using intuitive natural language commands. Our framework employs contextual data augmentation, driven by a pretrained LLM, to generate and expand a diverse dataset of microstructure descriptors. A retrained NER model extracts relevant microstructure descriptors from user-provided natural language inputs, which are then used by the DDPM to generate microstructures with targeted mechanical properties and topological features. The NLP and DDPM components of the framework are modular, allowing for separate training and validation, which ensures flexibility in adapting the framework to different datasets and use cases. A surrogate model system is employed to rank and filter generated samples based on their alignment with target properties. Demonstrated on a database of nonlinear hyperelastic microstructures, this framework serves as a prototype for accessible inverse design of microstructures, starting from intuitive natural language commands.",
        "subjects": "Computational Engineering, Finance, and Science, Computation and Language",
        "date": "2024-09-22 14:45:22 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.544055"
    },
    {
        "index": "#174",
        "title": "Opinion Mining on Offshore Wind Energy for Environmental Engineering",
        "link": "/arxiv/2409.14292",
        "arxiv_id": "2409.14292",
        "authors": "Isabele Bittencourt, Aparna S. Varde, Pankaj Lal",
        "summary": "In this paper, we conduct sentiment analysis on social media data to study mass opinion about offshore wind energy. We adapt three machine learning models, namely, TextBlob, VADER, and SentiWordNet because different functions are provided by each model. TextBlob provides subjectivity analysis as well as polarity classification. VADER offers cumulative sentiment scores. SentiWordNet considers sentiments with reference to context and performs classification accordingly. Techniques in NLP are harnessed to gather meaning from the textual data in social media. Data visualization tools are suitably deployed to display the overall results. This work is much in line with citizen science and smart governance via involvement of mass opinion to guide decision support. It exemplifies the role of Machine Learning and NLP here.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2024-09-22 01:51:43 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.544259"
    },
    {
        "index": "#176",
        "title": "On Lexical Invariance on Multisets and Graphs",
        "link": "/arxiv/2409.14179",
        "arxiv_id": "2409.14179",
        "authors": "Muhan Zhang",
        "summary": "In this draft, we study a novel problem, called lexical invariance, using the medium of multisets and graphs. Traditionally in the NLP domain, lexical invariance indicates that the semantic meaning of a sentence should remain unchanged regardless of the specific lexical or word-based representation of the input. For example, ``The movie was extremely entertaining'' would have the same meaning as ``The film was very enjoyable''. In this paper, we study a more challenging setting, where the output of a function is invariant to any injective transformation applied to the input lexical space. For example, multiset {1,2,3,2} is equivalent to multiset {a,b,c,b} if we specify an injective transformation that maps 1 to a, 2 to b and 3 to c. We study the sufficient and necessary conditions for a most expressive lexical invariant (and permutation invariant) function on multisets and graphs, and proves that for multisets, the function must have a form that only takes the multiset of counts of the unique elements in the original multiset as input. For example, a most expressive lexical invariant function on {a,b,c,b} must have a form that only operates on {1,1,2} (meaning that there are 1, 1, 2 unique elements corresponding to a,c,b). For graphs, we prove that a most expressive lexical invariant and permutation invariant function must have a form that only takes the adjacency matrix and a difference matrix as input, where the (i,j)th element of the difference matrix is 1 if node i and node j have the same feature and 0 otherwise. We perform synthetic experiments on TU datasets to verify our theorems.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2024-09-21 15:52:01 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.544634"
    },
    {
        "index": "#177",
        "title": "Will Large Language Models be a Panacea to Autonomous Driving?",
        "link": "/arxiv/2409.14165",
        "arxiv_id": "2409.14165",
        "authors": "Yuxuan Zhua, Shiyi Wang, Wenqing Zhong, Nianchen Shen, Yunqi Li, Siqi Wang, Zhiheng Li, Cathy Wu, Zhengbing He, Li Li",
        "summary": "Artificial intelligence (AI) plays a crucial role in autonomous driving (AD) research, propelling its development towards intelligence and efficiency. Currently, the development of AD technology follows two main technical paths: modularization and end-to-end. Modularization decompose the driving task into modules such as perception, prediction, planning, and control, and train them separately. Due to the inconsistency of training objectives between modules, the integrated effect suffers from bias. End-to-end attempts to address this issue by utilizing a single model that directly maps from sensor data to control signals. This path has limited learning capabilities in a comprehensive set of features and struggles to handle unpredictable long-tail events and complex urban traffic scenarios. In the face of challenges encountered in both paths, many researchers believe that large language models (LLMs) with powerful reasoning capabilities and extensive knowledge understanding may be the solution, expecting LLMs to provide AD systems with deeper levels of understanding and decision-making capabilities. In light of the challenges faced by both paths, many researchers believe that LLMs, with their powerful reasoning abilities and extensive knowledge, could offer a solution. To understand if LLMs could enhance AD, this paper conducts a thorough analysis of the potential applications of LLMs in AD systems, including exploring their optimization strategies in both modular and end-to-end approaches, with a particular focus on how LLMs can tackle the problems and challenges present in current solutions. Furthermore, we discuss an important question: Can LLM-based artificial general intelligence (AGI) be a key to achieve high-level AD? We further analyze the potential limitations and challenges that LLMs may encounter in promoting the development of AD technology.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning, Robotics, Systems and Control",
        "date": "2024-09-21 15:07:37 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.544891"
    },
    {
        "index": "#179",
        "title": "OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching",
        "link": "/arxiv/2409.14038",
        "arxiv_id": "2409.14038",
        "authors": "Zhangcheng Qiang, Kerry Taylor, Weiqing Wang, Jing Jiang",
        "summary": "Hallucinations of large language models (LLMs) commonly occur in domain-specific downstream tasks, with no exception in ontology matching (OM). The prevalence of using LLMs for OM raises the need for benchmarks to better understand LLM hallucinations. The OAEI-LLM dataset is an extended version of the Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate LLM-specific hallucinations in OM tasks. We outline the methodology used in dataset construction and schema extension, and provide examples of potential use cases.",
        "subjects": "Artificial Intelligence, Computation and Language, Information Retrieval",
        "date": "2024-09-21 06:49:34 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.545324"
    },
    {
        "index": "#180",
        "title": "On-device Collaborative Language Modeling via a Mixture of Generalists and Specialists",
        "link": "/arxiv/2409.13931",
        "arxiv_id": "2409.13931",
        "authors": "Dongyang Fan, Bettina Messmer, Martin Jaggi",
        "summary": "We target on-device collaborative fine-tuning of Large Language Models (LLMs) by adapting a Mixture of Experts (MoE) architecture, where experts are Low-Rank Adaptation (LoRA) modules. In conventional MoE approaches, experts develop into specialists throughout training. In contrast, we propose a novel $\\textbf{Co}$llaborative learning approach via a $\\textbf{Mi}$xture of $\\textbf{G}$eneralists and $\\textbf{S}$pecialists (CoMiGS). Diversifying into the two roles is achieved by aggregating certain experts globally while keeping others localized to specialize in user-specific datasets. Central to our work is a learnable routing network that routes at a token level, balancing collaboration and personalization at the finest granularity. Our method consistently demonstrates superior performance in scenarios with high data heterogeneity across various datasets. By design, our approach accommodates varying computational resource constraints among users as shown in different numbers of LoRA experts. We further showcase that low-resourced users can benefit from high-resourced users with high data quantity.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2024-09-20 22:34:37 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.545516"
    },
    {
        "index": "#181",
        "title": "Eliciting Instruction-tuned Code Language Models' Capabilities to Utilize Auxiliary Function for Code Generation",
        "link": "/arxiv/2409.13928",
        "arxiv_id": "2409.13928",
        "authors": "Seonghyeon Lee, Suyeon Kim, Joonwon Jang, Heejae Chon, Dongha Lee, Hwanjo Yu",
        "summary": "We study the code generation behavior of instruction-tuned models built on top of code pre-trained language models when they could access an auxiliary function to implement a function. We design several ways to provide auxiliary functions to the models by adding them to the query or providing a response prefix to incorporate the ability to utilize auxiliary functions with the instruction-following capability. Our experimental results show the effectiveness of combining the base models' auxiliary function utilization ability with the instruction following ability. In particular, the performance of adopting our approaches with the open-sourced language models surpasses that of the recent powerful proprietary language models, i.e., gpt-4o.",
        "subjects": "Software Engineering, Artificial Intelligence, Computation and Language",
        "date": "2024-09-20 22:28:20 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.545731"
    },
    {
        "index": "#182",
        "title": "Generative AI Carries Non-Democratic Biases and Stereotypes: Representation of Women, Black Individuals, Age Groups, and People with Disability in AI-Generated Images across Occupations",
        "link": "/arxiv/2409.13869",
        "arxiv_id": "2409.13869",
        "authors": "Ayoob Sadeghiani",
        "summary": "AI governance and ethics in AI development have become critical concerns, prompting active discussions among tech companies, governments, and researchers about the potential risks AI poses to our democracies. This short essay aims to highlight one such risk: how generative AI includes or excludes equity-deserving groups in its outputs. The findings reveal that generative AI is not equitably inclusive regarding gender, race, age, and visible disability.",
        "subjects": "Artificial Intelligence, Computation and Language, Computers and Society",
        "date": "2024-09-20 19:47:31 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.545905"
    },
    {
        "index": "#183",
        "title": "GTSinger: A Global Multi-Technique Singing Corpus with Realistic Music Scores for All Singing Tasks",
        "link": "/arxiv/2409.13832",
        "arxiv_id": "2409.13832",
        "authors": "Yu Zhang, Changhao Pan, Wenxiang Guo, Ruiqi Li, Zhiyuan Zhu, Jialei Wang, Wenhao Xu, Jingyu Lu, Zhiqing Hong, Chuxin Wang, LiChao Zhang, Jinzheng He, Ziyue Jiang, Yuxin Chen, Chen Yang, Jiecheng Zhou, Xinyu Cheng, Zhou Zhao",
        "summary": "The scarcity of high-quality and multi-task singing datasets significantly hinders the development of diverse controllable and personalized singing tasks, as existing singing datasets suffer from low quality, limited diversity of languages and singers, absence of multi-technique information and realistic music scores, and poor task suitability. To tackle these problems, we present \\textbf{GTSinger}, a large \\textbf{G}lobal, multi-\\textbf{T}echnique, free-to-use, high-quality singing corpus with realistic music scores, designed for all singing tasks, along with its benchmarks. Particularly, (1) we collect 80.59 hours of high-quality singing voices, forming the largest recorded singing dataset; (2) 20 professional singers across nine widely spoken languages offer diverse timbres and styles; (3) we provide controlled comparison and phoneme-level annotations of six commonly used singing techniques, helping technique modeling and control; (4) GTSinger offers realistic music scores, assisting real-world musical composition; (5) singing voices are accompanied by manual phoneme-to-audio alignments, global style labels, and 16.16 hours of paired speech for various singing tasks. Moreover, to facilitate the use of GTSinger, we conduct four benchmark experiments: technique-controllable singing voice synthesis, technique recognition, style transfer, and speech-to-singing conversion. The corpus and demos can be found at http://gtsinger.github.io. We provide the dataset and the code for processing data and conducting benchmarks at https://huggingface.co/datasets/GTSinger/GTSinger and https://github.com/GTSinger/GTSinger.",
        "subjects": "Audio and Speech Processing, Computation and Language, Sound",
        "date": "2024-09-20 18:18:14 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.546232"
    },
    {
        "index": "#184",
        "title": "Synergistic Simulations: Multi-Agent Problem Solving with Large Language Models",
        "link": "/arxiv/2409.13753",
        "arxiv_id": "2409.13753",
        "authors": "Asher Sprigler, Alexander Drobek, Keagan Weinstock, Wendpanga Tapsoba, Gavin Childress, Andy Dao, Lucas Gral",
        "summary": "Large Language Models (LLMs) have increasingly demonstrated the ability to facilitate the development of multi-agent systems that allow the interpretation of thoughts and actions generated by each individual. Promising advancements have also been made in LLM-based interaction with existing worlds, particularly in interacting with simulated environments. This paper aims to integrate both aforementioned topics (agents & world interaction) into a single simulation where multiple agents can work together to solve a problem, modeling how groups of humans can often solve problems better than individuals. By showing whether LLMs demonstrate the synergy of human collaboration, it could lead to advancements in the applications of LLMs. We implemented two simulations: a physical studio apartment with two roommates, and another where agents collaborate to complete a programming task. We provide a multi-agent framework, discuss the performance of the agents in each simulation, and discuss potential future additions.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computation and Language, Emerging Technologies",
        "date": "2024-09-14 21:53:35 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.546464"
    },
    {
        "index": "#185",
        "title": "VisScience: An Extensive Benchmark for Evaluating K12 Educational Multi-modal Scientific Reasoning",
        "link": "/arxiv/2409.13730",
        "arxiv_id": "2409.13730",
        "authors": "Zhihuan Jiang, Zhen Yang, Jinhao Chen, Zhengxiao Du, Weihan Wang, Bin Xu, Yuxiao Dong, Jie Tang",
        "summary": "Multi-modal large language models (MLLMs) have demonstrated promising capabilities across various tasks by integrating textual and visual information to achieve visual understanding in complex scenarios. Despite the availability of several benchmarks aims to evaluating MLLMs in tasks from visual question answering to complex problem-solving, most focus predominantly on mathematics or general visual understanding tasks. This reveals a critical gap in current benchmarks, which often overlook the inclusion of other key scientific disciplines such as physics and chemistry. To address this gap, we meticulously construct a comprehensive benchmark, named VisScience, which is utilized to assess the multi-modal scientific reasoning across the three disciplines of mathematics, physics, and chemistry. This benchmark comprises 3,000 questions drawn from K12 education - spanning elementary school through high school - equally distributed across three disciplines, with 1,000 questions per discipline. The questions within VisScience span 21 distinct subjects and are categorized into five difficulty levels, offering a broad spectrum of topics within each discipline. With VisScience, we present a detailed evaluation of the performance of 25 representative MLLMs in scientific reasoning. Experimental results demonstrate that closed-source MLLMs generally outperform open-source models. The best performance observed include a 53.4\\% accuracy in mathematics by Claude3.5-Sonnet, 38.2\\% in physics by GPT-4o, and 47.0\\% in chemistry by Gemini-1.5-Pro. These results underscore the strengths and limitations of MLLMs, suggesting areas for future improvement and highlighting the importance of developing models that can effectively handle the diverse demands of multi-modal scientific reasoning.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2024-09-10 01:20:26 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.546721"
    },
    {
        "index": "#186",
        "title": "Retrieval Augmented Generation-Based Incident Resolution Recommendation System for IT Support",
        "link": "/arxiv/2409.13707",
        "arxiv_id": "2409.13707",
        "authors": "Paulina Toro Isaza, Michael Nidd, Noah Zheutlin, Jae-wook Ahn, Chidansh Amitkumar Bhatt, Yu Deng, Ruchi Mahindru, Martin Franz, Hans Florian, Salim Roukos",
        "summary": "Clients wishing to implement generative AI in the domain of IT Support and AIOps face two critical issues: domain coverage and model size constraints due to model choice limitations. Clients might choose to not use larger proprietary models such as GPT-4 due to cost and privacy concerns and so are limited to smaller models with potentially less domain coverage that do not generalize to the client's domain. Retrieval augmented generation is a common solution that addresses both of these issues: a retrieval system first retrieves the necessary domain knowledge which a smaller generative model leverages as context for generation. We present a system developed for a client in the IT Support domain for support case solution recommendation that combines retrieval augmented generation (RAG) for answer generation with an encoder-only model for classification and a generative large language model for query generation. We cover architecture details, data collection and annotation, development journey and preliminary validations, expected final deployment process and evaluation plans, and finally lessons learned.",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language",
        "date": "2024-09-06 13:06:29 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.546973"
    },
    {
        "index": "#187",
        "title": "Declarative Integration and Management of Large Language Models through Finite Automata: Application to Automation, Communication, and Ethics",
        "link": "/arxiv/2409.13693",
        "arxiv_id": "2409.13693",
        "authors": "Thierry Petit, Arnault Pachot, Claire Conan-Vrinat, Alexandre Dubarry",
        "summary": "This article introduces an innovative architecture designed to declaratively combine Large Language Models (LLMs) with shared histories, and triggers to identify the most appropriate LLM for a given task. Our approach is general and declarative, relying on the construction of finite automata coupled with an event management system. The developed tool is crafted to facilitate the efficient and complex integration of LLMs with minimal programming effort, especially, but not only, for integrating methods of positive psychology to AI. The flexibility of our technique is demonstrated through applied examples in automation, communication, and ethics.",
        "subjects": "Formal Languages and Automata Theory, Artificial Intelligence, Computation and Language, Emerging Technologies, Human-Computer Interaction",
        "date": "2024-09-02 11:50:52 UTC",
        "category": "cs.CL",
        "crawl_time": "2025-09-24T16:31:00.547236"
    },
    {
        "index": "#1",
        "title": "Generative AI Is Not Ready for Clinical Use in Patient Education for Lower Back Pain Patients, Even With Retrieval-Augmented Generation",
        "link": "/arxiv/2409.15260",
        "arxiv_id": "2409.15260",
        "authors": "Yi-Fei Zhao, Allyn Bove, David Thompson, James Hill, Yi Xu, Yufan Ren, Andrea Hassman, Leming Zhou, Yanshan Wang",
        "summary": "Low back pain (LBP) is a leading cause of disability globally. Following the onset of LBP and subsequent treatment, adequate patient education is crucial for improving functionality and long-term outcomes. Despite advancements in patient education strategies, significant gaps persist in delivering personalized, evidence-based information to patients with LBP. Recent advancements in large language models (LLMs) and generative artificial intelligence (GenAI) have demonstrated the potential to enhance patient education. However, their application and efficacy in delivering educational content to patients with LBP remain underexplored and warrant further investigation. In this study, we introduce a novel approach utilizing LLMs with Retrieval-Augmented Generation (RAG) and few-shot learning to generate tailored educational materials for patients with LBP. Physical therapists manually evaluated our model responses for redundancy, accuracy, and completeness using a Likert scale. In addition, the readability of the generated education materials is assessed using the Flesch Reading Ease score. The findings demonstrate that RAG-based LLMs outperform traditional LLMs, providing more accurate, complete, and readable patient education materials with less redundancy. Having said that, our analysis reveals that the generated materials are not yet ready for use in clinical practice. This study underscores the potential of AI-driven models utilizing RAG to improve patient education for LBP; however, significant challenges remain in ensuring the clinical relevance and granularity of content generated by these models.",
        "subjects": "Artificial Intelligence, Information Retrieval",
        "date": "2024-09-23 17:56:08 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.745429"
    },
    {
        "index": "#2",
        "title": "MACeIP: A Multimodal Ambient Context-enriched Intelligence Platform in Smart Cities",
        "link": "/arxiv/2409.15243",
        "arxiv_id": "2409.15243",
        "authors": "Truong Thanh Hung Nguyen, Phuc Truong Loc Nguyen, Monica Wachowicz, Hung Cao",
        "summary": "This paper presents a Multimodal Ambient Context-enriched Intelligence Platform (MACeIP) for Smart Cities, a comprehensive system designed to enhance urban management and citizen engagement. Our platform integrates advanced technologies, including Internet of Things (IoT) sensors, edge and cloud computing, and Multimodal AI, to create a responsive and intelligent urban ecosystem. Key components include Interactive Hubs for citizen interaction, an extensive IoT sensor network, intelligent public asset management, a pedestrian monitoring system, a City Planning Portal, and a Cloud Computing System. We demonstrate the prototype of MACeIP in several cities, focusing on Fredericton, New Brunswick. This work contributes to innovative city development by offering a scalable, efficient, and user-centric approach to urban intelligence and management.",
        "subjects": "Artificial Intelligence, Emerging Technologies, Human-Computer Interaction",
        "date": "2024-09-23 17:39:53 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.745794"
    },
    {
        "index": "#3",
        "title": "Chattronics: using GPTs to assist in the design of data acquisition systems",
        "link": "/arxiv/2409.15183",
        "arxiv_id": "2409.15183",
        "authors": "Jonathan Paul Driemeyer Brown, Tiago Oliveira Weber",
        "summary": "The usefulness of Large Language Models (LLM) is being continuously tested in various fields. However, their intrinsic linguistic characteristic is still one of the limiting factors when applying these models to exact sciences. In this article, a novel approach to use General Pre-Trained Transformers to assist in the design phase of data acquisition systems will be presented. The solution is packaged in the form of an application that retains the conversational aspects of LLMs, in such a manner that the user must provide details on the desired project in order for the model to draft both a system-level architectural diagram and the block-level specifications, following a Top-Down methodology based on restrictions. To test this tool, two distinct user emulations were used, one of which uses an additional GPT model. In total, 4 different data acquisition projects were used in the testing phase, each with its own measurement requirements: angular position, temperature, acceleration and a fourth project with both pressure and superficial temperature measurements. After 160 test iterations, the study concludes that there is potential for these models to serve adequately as synthesis/assistant tools for data acquisition systems, but there are still technological limitations. The results show coherent architectures and topologies, but that GPTs have difficulties in simultaneously considering all requirements and many times commits theoretical mistakes.",
        "subjects": "Artificial Intelligence, Hardware Architecture, Signal Processing",
        "date": "2024-09-23 16:36:16 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.746076"
    },
    {
        "index": "#4",
        "title": "Goal-based Neural Physics Vehicle Trajectory Prediction Model",
        "link": "/arxiv/2409.15182",
        "arxiv_id": "2409.15182",
        "authors": "Rui Gan, Haotian Shi, Pei Li, Keshu Wu, Bocheng An, Linheng Li, Junyi Ma, Chengyuan Ma, Bin Ran",
        "summary": "Vehicle trajectory prediction plays a vital role in intelligent transportation systems and autonomous driving, as it significantly affects vehicle behavior planning and control, thereby influencing traffic safety and efficiency. Numerous studies have been conducted to predict short-term vehicle trajectories in the immediate future. However, long-term trajectory prediction remains a major challenge due to accumulated errors and uncertainties. Additionally, balancing accuracy with interpretability in the prediction is another challenging issue in predicting vehicle trajectory. To address these challenges, this paper proposes a Goal-based Neural Physics Vehicle Trajectory Prediction Model (GNP). The GNP model simplifies vehicle trajectory prediction into a two-stage process: determining the vehicle's goal and then choosing the appropriate trajectory to reach this goal. The GNP model contains two sub-modules to achieve this process. The first sub-module employs a multi-head attention mechanism to accurately predict goals. The second sub-module integrates a deep learning model with a physics-based social force model to progressively predict the complete trajectory using the generated goals. The GNP demonstrates state-of-the-art long-term prediction accuracy compared to four baseline models. We provide interpretable visualization results to highlight the multi-modality and inherent nature of our neural physics framework. Additionally, ablation studies are performed to validate the effectiveness of our key designs.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 16:35:43 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.746304"
    },
    {
        "index": "#5",
        "title": "Automatic Feature Learning for Essence: a Case Study on Car Sequencing",
        "link": "/arxiv/2409.15158",
        "arxiv_id": "2409.15158",
        "authors": "Alessio Pellegrino, Özgür Akgün, Nguyen Dang, Zeynep Kiziltan, Ian Miguel",
        "summary": "Constraint modelling languages such as Essence offer a means to describe combinatorial problems at a high-level, i.e., without committing to detailed modelling decisions for a particular solver or solving paradigm. Given a problem description written in Essence, there are multiple ways to translate it to a low-level constraint model. Choosing the right combination of a low-level constraint model and a target constraint solver can have significant impact on the effectiveness of the solving process. Furthermore, the choice of the best combination of constraint model and solver can be instance-dependent, i.e., there may not exist a single combination that works best for all instances of the same problem. In this paper, we consider the task of building machine learning models to automatically select the best combination for a problem instance. A critical part of the learning process is to define instance features, which serve as input to the selection model. Our contribution is automatic learning of instance features directly from the high-level representation of a problem instance using a language model. We evaluate the performance of our approach using the Essence modelling language with a case study involving the car sequencing problem.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 16:06:44 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.746525"
    },
    {
        "index": "#6",
        "title": "Boosting Healthcare LLMs Through Retrieved Context",
        "link": "/arxiv/2409.15127",
        "arxiv_id": "2409.15127",
        "authors": "Jordi Bayarri-Planas, Ashwin Kumar Gururajan, Dario Garcia-Gasulla",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing, and yet, their factual inaccuracies and hallucinations limits their application, particularly in critical domains like healthcare. Context retrieval methods, by introducing relevant information as input, have emerged as a crucial approach for enhancing LLM factuality and reliability. This study explores the boundaries of context retrieval methods within the healthcare domain, optimizing their components and benchmarking their performance against open and closed alternatives. Our findings reveal how open LLMs, when augmented with an optimized retrieval system, can achieve performance comparable to the biggest private solutions on established healthcare benchmarks (multiple-choice question answering). Recognizing the lack of realism of including the possible answers within the question (a setup only found in medical exams), and after assessing a strong LLM performance degradation in the absence of those options, we extend the context retrieval system in that direction. In particular, we propose OpenMedPrompt a pipeline that improves the generation of more reliable open-ended answers, moving this technology closer to practical application.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 15:33:38 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.746745"
    },
    {
        "index": "#7",
        "title": "Log-normal Mutations and their Use in Detecting Surreptitious Fake Images",
        "link": "/arxiv/2409.15119",
        "arxiv_id": "2409.15119",
        "authors": "Ismail Labiad, Thomas Bäck, Pierre Fernandez, Laurent Najman, Tom Sanders, Furong Ye, Mariia Zameshina, Olivier Teytaud",
        "summary": "In many cases, adversarial attacks are based on specialized algorithms specifically dedicated to attacking automatic image classifiers. These algorithms perform well, thanks to an excellent ad hoc distribution of initial attacks. However, these attacks are easily detected due to their specific initial distribution. We therefore consider other black-box attacks, inspired from generic black-box optimization tools, and in particular the log-normal algorithm. We apply the log-normal method to the attack of fake detectors, and get successful attacks: importantly, these attacks are not detected by detectors specialized on classical adversarial attacks. Then, combining these attacks and deep detection, we create improved fake detectors.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 15:25:26 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.746956"
    },
    {
        "index": "#8",
        "title": "Evaluating ML Robustness in GNSS Interference Classification, Characterization \\& Localization",
        "link": "/arxiv/2409.15114",
        "arxiv_id": "2409.15114",
        "authors": "Lucas Heublein, Tobias Feigl, Thorsten Nowak, Alexander Rügamer, Christopher Mutschler, Felix Ott",
        "summary": "Jamming devices present a significant threat by disrupting signals from the global navigation satellite system (GNSS), compromising the robustness of accurate positioning. The detection of anomalies within frequency snapshots is crucial to counteract these interferences effectively. A critical preliminary measure involves the reliable classification of interferences and characterization and localization of jamming devices. This paper introduces an extensive dataset compromising snapshots obtained from a low-frequency antenna, capturing diverse generated interferences within a large-scale environment including controlled multipath effects. Our objective is to assess the resilience of ML models against environmental changes, such as multipath effects, variations in interference attributes, such as the interference class, bandwidth, and signal-to-noise ratio, the accuracy jamming device localization, and the constraints imposed by snapshot input lengths. By analyzing the aleatoric and epistemic uncertainties, we demonstrate the adaptness of our model in generalizing across diverse facets, thus establishing its suitability for real-world applications. https://gitlab.cc-asp.fraunhofer.de/darcy_gnss/controlled_low_frequency",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 15:20:33 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.747149"
    },
    {
        "index": "#9",
        "title": "ChatGPT as a Solver and Grader of Programming Exams written in Spanish",
        "link": "/arxiv/2409.15112",
        "arxiv_id": "2409.15112",
        "authors": "Pablo Fernández-Saborido, Marcos Fernández-Pichel, David E. Losada",
        "summary": "Evaluating the capabilities of Large Language Models (LLMs) to assist teachers and students in educational tasks is receiving increasing attention. In this paper, we assess ChatGPT's capacities to solve and grade real programming exams, from an accredited BSc degree in Computer Science, written in Spanish. Our findings suggest that this AI model is only effective for solving simple coding tasks. Its proficiency in tackling complex problems or evaluating solutions authored by others are far from effective. As part of this research, we also release a new corpus of programming tasks and the corresponding prompts for solving the problems or grading the solutions. This resource can be further exploited by other research teams.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 15:20:07 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.747320"
    },
    {
        "index": "#10",
        "title": "SPformer: A Transformer Based DRL Decision Making Method for Connected Automated Vehicles",
        "link": "/arxiv/2409.15105",
        "arxiv_id": "2409.15105",
        "authors": "Ye Han, Lijun Zhang, Dejian Meng, Xingyu Hu, Yixia Lu",
        "summary": "In mixed autonomy traffic environment, every decision made by an autonomous-driving car may have a great impact on the transportation system. Because of the complex interaction between vehicles, it is challenging to make decisions that can ensure both high traffic efficiency and safety now and futher. Connected automated vehicles (CAVs) have great potential to improve the quality of decision-making in this continuous, highly dynamic and interactive environment because of their stronger sensing and communicating ability. For multi-vehicle collaborative decision-making algorithms based on deep reinforcement learning (DRL), we need to represent the interactions between vehicles to obtain interactive features. The representation in this aspect directly affects the learning efficiency and the quality of the learned policy. To this end, we propose a CAV decision-making architecture based on transformer and reinforcement learning algorithms. A learnable policy token is used as the learning medium of the multi-vehicle joint policy, the states of all vehicles in the area of interest can be adaptively noticed in order to extract interactive features among agents. We also design an intuitive physical positional encodings, the redundant location information of which optimizes the performance of the network. Simulations show that our model can make good use of all the state information of vehicles in traffic scenario, so as to obtain high-quality driving decisions that meet efficiency and safety objectives. The comparison shows that our method significantly improves existing DRL-based multi-vehicle cooperative decision-making algorithms.",
        "subjects": "Artificial Intelligence, Multiagent Systems, Systems and Control",
        "date": "2024-09-23 15:16:35 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.747528"
    },
    {
        "index": "#11",
        "title": "Acting for the Right Reasons: Creating Reason-Sensitive Artificial Moral Agents",
        "link": "/arxiv/2409.15014",
        "arxiv_id": "2409.15014",
        "authors": "Kevin Baum, Lisa Dargasz, Felix Jahn, Timo P. Gros, Verena Wolf",
        "summary": "We propose an extension of the reinforcement learning architecture that enables moral decision-making of reinforcement learning agents based on normative reasons. Central to this approach is a reason-based shield generator yielding a moral shield that binds the agent to actions that conform with recognized normative reasons so that our overall architecture restricts the agent to actions that are (internally) morally justified. In addition, we describe an algorithm that allows to iteratively improve the reason-based shield generator through case-based feedback from a moral judge.",
        "subjects": "Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2024-09-23 13:38:57 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.747734"
    },
    {
        "index": "#12",
        "title": "Analogous Alignments: Digital \"Formally\" meets Analog",
        "link": "/arxiv/2409.15013",
        "arxiv_id": "2409.15013",
        "authors": "Hansa Mohanty, Deepak Narayan Gadde",
        "summary": "The complexity of modern-day System-on-Chips (SoCs) is continually increasing, and it becomes increasingly challenging to deliver dependable and credible chips in a short time-to-market. Especially, in the case of test chips, where the aim is to study the feasibility of the design, time is a crucial factor. Pre-silicon functional verification is one of the main contributors that makes up a large portion of the product development cycle. Verification engineers often loosely verify test chips that turn out to be non-functional on the silicon, ultimately resulting in expensive re-spins. To left-shift the verification efforts, formal verification is a powerful methodology that aims to exhaustively verify designs, giving better confidence in the overall quality. This paper focuses on the pragmatic formal verification of a mixed signal Intellectual Property (IP) that has a combination of digital and analog blocks. This paper discusses a novel approach of including the analog behavioral model into the formal verification setup. Digital and Analog Mixed-Signal (AMS) designs, which are fundamentally different in nature, are integrated seamlessly in a formal verification setup, a concept that can be referred to as \"Analogous Alignments\". Our formal setup leverages powerful formal techniques such as FPV, CSR verification, and connectivity checks. The properties used for FPV are auto-generated using a metamodeling framework. The paper also discusses the challenges faced especially related to state-space explosion, non-compatibility of formal with AMS models, and techniques to mitigate them such as k-induction. With this verification approach, we were able to exhaustively verify the design within a reasonable time and with sufficient coverage. We also reported several bugs at an early stage, making the complete design verification process iterative and effective.",
        "subjects": "Artificial Intelligence, Hardware Architecture",
        "date": "2024-09-23 13:38:31 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.747911"
    },
    {
        "index": "#15",
        "title": "TS-TCD: Triplet-Level Cross-Modal Distillation for Time-Series Forecasting Using Large Language Models",
        "link": "/arxiv/2409.14978",
        "arxiv_id": "2409.14978",
        "authors": "Pengfei Wang, Huanran Zheng, Silong Dai, Wenjing Yue, Wei Zhu, Xiaoling Wang",
        "summary": "In recent years, large language models (LLMs) have shown great potential in time-series analysis by capturing complex dependencies and improving predictive performance. However, existing approaches often struggle with modality alignment, leading to suboptimal results. To address these challenges, we present a novel framework, TS-TCD, which introduces a comprehensive three-tiered cross-modal knowledge distillation mechanism. Unlike prior work that focuses on isolated alignment techniques, our framework systematically integrates: 1) Dynamic Adaptive Gating for Input Encoding and Alignment}, ensuring coherent alignment between time-series tokens and QR-decomposed textual embeddings; 2) Layer-Wise Contrastive Learning}, aligning intermediate representations across modalities to reduce feature-level discrepancies; and 3) Optimal Transport-Driven Output Alignment}, which ensures consistent output predictions through fine-grained cross-modal alignment. Extensive experiments on benchmark time-series datasets demonstrate that TS-TCD achieves state-of-the-art results, outperforming traditional methods in both accuracy and robustness.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 12:57:24 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.748556"
    },
    {
        "index": "#17",
        "title": "HW-TSC's Submission to the CCMT 2024 Machine Translation Tasks",
        "link": "/arxiv/2409.14842",
        "arxiv_id": "2409.14842",
        "authors": "Zhanglin Wu, Yuanchang Luo, Daimeng Wei, Jiawei Zheng, Bin Wei, Zongyao Li, Hengchao Shang, Jiaxin Guo, Shaojun Li, Weidong Zhang, Ning Xie, Hao Yang",
        "summary": "This paper presents the submission of Huawei Translation Services Center (HW-TSC) to machine translation tasks of the 20th China Conference on Machine Translation (CCMT 2024). We participate in the bilingual machine translation task and multi-domain machine translation task. For these two translation tasks, we use training strategies such as regularized dropout, bidirectional training, data diversification, forward translation, back translation, alternated training, curriculum learning, and transductive ensemble learning to train neural machine translation (NMT) models based on the deep Transformer-big architecture. Furthermore, to explore whether large language model (LLM) can help improve the translation quality of NMT systems, we use supervised fine-tuning to train llama2-13b as an Automatic post-editing (APE) model to improve the translation results of the NMT model on the multi-domain machine translation task. By using these plyometric strategies, our submission achieves a competitive result in the final evaluation.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 09:20:19 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.749184"
    },
    {
        "index": "#18",
        "title": "Explainable and Human-Grounded AI for Decision Support Systems: The Theory of Epistemic Quasi-Partnerships",
        "link": "/arxiv/2409.14839",
        "arxiv_id": "2409.14839",
        "authors": "John Dorsch, Maximilian Moll",
        "summary": "In the context of AI decision support systems (AI-DSS), we argue that meeting the demands of ethical and explainable AI (XAI) is about developing AI-DSS to provide human decision-makers with three types of human-grounded explanations: reasons, counterfactuals, and confidence, an approach we refer to as the RCC approach. We begin by reviewing current empirical XAI literature that investigates the relationship between various methods for generating model explanations (e.g., LIME, SHAP, Anchors), the perceived trustworthiness of the model, and end-user accuracy. We demonstrate how current theories about what constitutes good human-grounded reasons either do not adequately explain this evidence or do not offer sound ethical advice for development. Thus, we offer a novel theory of human-machine interaction: the theory of epistemic quasi-partnerships (EQP). Finally, we motivate adopting EQP and demonstrate how it explains the empirical evidence, offers sound ethical advice, and entails adopting the RCC approach.",
        "subjects": "Artificial Intelligence, Emerging Technologies, Human-Computer Interaction",
        "date": "2024-09-23 09:14:25 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.749368"
    },
    {
        "index": "#19",
        "title": "MICSim: A Modular Simulator for Mixed-signal Compute-in-Memory based AI Accelerator",
        "link": "/arxiv/2409.14838",
        "arxiv_id": "2409.14838",
        "authors": "Cong Wang, Zeming Chen, Shanshi Huang",
        "summary": "This work introduces MICSim, an open-source, pre-circuit simulator designed for early-stage evaluation of chip-level software performance and hardware overhead of mixed-signal compute-in-memory (CIM) accelerators. MICSim features a modular design, allowing easy multi-level co-design and design space exploration. Modularized from the state-of-the-art CIM simulator NeuroSim, MICSim provides a highly configurable simulation framework supporting multiple quantization algorithms, diverse circuit/architecture designs, and different memory devices. This modular approach also allows MICSim to be effectively extended to accommodate new designs. MICSim natively supports evaluating accelerators' software and hardware performance for CNNs and Transformers in Python, leveraging the popular PyTorch and HuggingFace Transformers frameworks. These capabilities make MICSim highly adaptive when simulating different networks and user-friendly. This work demonstrates that MICSim can easily be combined with optimization strategies to perform design space exploration and used for chip-level Transformers CIM accelerators evaluation. Also, MICSim can achieve a 9x - 32x speedup of NeuroSim through a statistic-based average mode proposed by this work.",
        "subjects": "Artificial Intelligence, Hardware Architecture",
        "date": "2024-09-23 09:12:46 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.749557"
    },
    {
        "index": "#20",
        "title": "Benchmarking Edge AI Platforms for High-Performance ML Inference",
        "link": "/arxiv/2409.14803",
        "arxiv_id": "2409.14803",
        "authors": "Rakshith Jayanth, Neelesh Gupta, Viktor Prasanna",
        "summary": "Edge computing's growing prominence, due to its ability to reduce communication latency and enable real-time processing, is promoting the rise of high-performance, heterogeneous System-on-Chip solutions. While current approaches often involve scaling down modern hardware, the performance characteristics of neural network workloads on these platforms can vary significantly, especially when it comes to parallel processing, which is a critical consideration for edge deployments. To address this, we conduct a comprehensive study comparing the latency and throughput of various linear algebra and neural network inference tasks across CPU-only, CPU/GPU, and CPU/NPU integrated solutions. {We find that the Neural Processing Unit (NPU) excels in matrix-vector multiplication (58.6% faster) and some neural network tasks (3.2$\\times$ faster for video classification and large language models). GPU outperforms in matrix multiplication (22.6% faster) and LSTM networks (2.7$\\times$ faster) while CPU excels at less parallel operations like dot product. NPU-based inference offers a balance of latency and throughput at lower power consumption. GPU-based inference, though more energy-intensive, performs best with large dimensions and batch sizes. We highlight the potential of heterogeneous computing solutions for edge AI, where diverse compute units can be strategically leveraged to boost accurate and real-time inference.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 08:27:27 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.749733"
    },
    {
        "index": "#21",
        "title": "Choose the Final Translation from NMT and LLM hypotheses Using MBR Decoding: HW-TSC's Submission to the WMT24 General MT Shared Task",
        "link": "/arxiv/2409.14800",
        "arxiv_id": "2409.14800",
        "authors": "Zhanglin Wu, Daimeng Wei, Zongyao Li, Hengchao Shang, Jiaxin Guo, Shaojun Li, Zhiqiang Rao, Yuanchang Luo, Ning Xie, Hao Yang",
        "summary": "This paper presents the submission of Huawei Translate Services Center (HW-TSC) to the WMT24 general machine translation (MT) shared task, where we participate in the English to Chinese (en2zh) language pair. Similar to previous years' work, we use training strategies such as regularized dropout, bidirectional training, data diversification, forward translation, back translation, alternated training, curriculum learning, and transductive ensemble learning to train the neural machine translation (NMT) model based on the deep Transformer-big architecture. The difference is that we also use continue pre-training, supervised fine-tuning, and contrastive preference optimization to train the large language model (LLM) based MT model. By using Minimum Bayesian risk (MBR) decoding to select the final translation from multiple hypotheses for NMT and LLM-based MT models, our submission receives competitive results in the final evaluation.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 08:25:37 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.749949"
    },
    {
        "index": "#22",
        "title": "SAMEdge: An Edge-cloud Video Analytics Architecture for the Segment Anything Model",
        "link": "/arxiv/2409.14784",
        "arxiv_id": "2409.14784",
        "authors": "Rui Lu, Siping Shi, Yanting Liu, Dan Wang",
        "summary": "As artificial intelligence continues to evolve, it is increasingly capable of handling a wide range of video analytics tasks with merely one large model. One of the key foundation technologies is the Segment Anything Model (SAM), which allows the video analytics tasks to be determined on the fly according to the input prompts from the user. However, achieving real-time response in video analytics applications is crucial for user experiences due to the limited communication and computation resources on the edge, especially with SAM, where users may continuously interact by adding or adjusting prompts. In this paper, we propose SAMEdge, a novel edge-cloud computing architecture designed to support SAM computations for edge users. SAMEdge integrates new modules on the edge and the cloud to maximize analytics accuracy under visual prompts and image prompts input with latency constraints. It addresses resource challenges associated with prompt encoding and image encoding by offering a visual prompt transformation algorithm for visual prompts and efficient workload partitioning for image encoding. SAMEdge is implemented by extending the open-source SAM project from Meta AI. We demonstrate the practical application of SAMEdge through a case study on a Visual Tour Guide application. Our evaluation indicates that SAMEdge significantly enhances the accuracy of the video analytics application under distinct network bandwidths across various prompts.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 07:59:09 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.755397"
    },
    {
        "index": "#23",
        "title": "Speechworthy Instruction-tuned Language Models",
        "link": "/arxiv/2409.14672",
        "arxiv_id": "2409.14672",
        "authors": "Hyundong Cho, Nicolaas Jedema, Leonardo F. R. Ribeiro, Karishma Sharma, Pedro Szekely, Alessandro Moschitti, Ruben Janssen, Jonathan May",
        "summary": "Current instruction-tuned language models are exclusively trained with textual preference data and thus are often not aligned with the unique requirements of other modalities, such as speech. To better align language models with the speech domain, we explore (i) prompting strategies grounded in radio-industry best practices and (ii) preference learning using a novel speech-based preference data of 20K samples, generated with a wide spectrum of prompts that induce varying dimensions of speech-suitability and labeled by annotators who listen to response pairs. Both human and automatic evaluation show that both prompting and preference learning increase the speech-suitability of popular instruction-tuned LLMs. Interestingly, we find that prompting and preference learning can be additive; combining them achieves the best win rates in head-to-head comparison, resulting in responses that are preferred or tied to the base model in 76.2% of comparisons on average. Lastly, we share lexical, syntactical, and qualitative analyses to showcase how each method contributes to improving the speech-suitability of generated responses.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 02:34:42 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.755653"
    },
    {
        "index": "#25",
        "title": "Semi-supervised Learning For Robust Speech Evaluation",
        "link": "/arxiv/2409.14666",
        "arxiv_id": "2409.14666",
        "authors": "Huayun Zhang, Jeremy H. M. Wong, Geyu Lin, Nancy F. Chen",
        "summary": "Speech evaluation measures a learners oral proficiency using automatic models. Corpora for training such models often pose sparsity challenges given that there often is limited scored data from teachers, in addition to the score distribution across proficiency levels being often imbalanced among student cohorts. Automatic scoring is thus not robust when faced with under-represented samples or out-of-distribution samples, which inevitably exist in real-world deployment scenarios. This paper proposes to address such challenges by exploiting semi-supervised pre-training and objective regularization to approximate subjective evaluation criteria. In particular, normalized mutual information is used to quantify the speech characteristics from the learner and the reference. An anchor model is trained using pseudo labels to predict the correctness of pronunciation. An interpolated loss function is proposed to minimize not only the prediction error with respect to ground-truth scores but also the divergence between two probability distributions estimated by the speech evaluation model and the anchor model. Compared to other state-of-the-art methods on a public data-set, this approach not only achieves high performance while evaluating the entire test-set as a whole, but also brings the most evenly distributed prediction error across distinct proficiency levels. Furthermore, empirical results show the model accuracy on out-of-distribution data also compares favorably with competitive baselines.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-23 02:11:24 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.756046"
    },
    {
        "index": "#26",
        "title": "Brain Surgery: Ensuring GDPR Compliance in Large Language Models via Concept Erasure",
        "link": "/arxiv/2409.14603",
        "arxiv_id": "2409.14603",
        "authors": "Michele Laurelli",
        "summary": "As large-scale AI systems proliferate, ensuring compliance with data privacy laws such as the General Data Protection Regulation (GDPR) has become critical. This paper introduces Brain Surgery, a transformative methodology for making every local AI model GDPR-ready by enabling real-time privacy management and targeted unlearning. Building on advanced techniques such as Embedding-Corrupted Prompts (ECO Prompts), blockchain-based privacy management, and privacy-aware continual learning, Brain Surgery provides a modular solution that can be deployed across various AI architectures. This tool not only ensures compliance with privacy regulations but also empowers users to define their own privacy limits, creating a new paradigm in AI ethics and governance.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 21:42:20 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.756212"
    },
    {
        "index": "#27",
        "title": "Evaluating Gender, Racial, and Age Biases in Large Language Models: A Comparative Analysis of Occupational and Crime Scenarios",
        "link": "/arxiv/2409.14583",
        "arxiv_id": "2409.14583",
        "authors": "Vishal Mirza, Rahul Kulkarni, Aakanksha Jadhav",
        "summary": "Recent advancements in Large Language Models(LLMs) have been notable, yet widespread enterprise adoption remains limited due to various constraints. This paper examines bias in LLMs-a crucial issue affecting their usability, reliability, and fairness. Researchers are developing strategies to mitigate bias, including debiasing layers, specialized reference datasets like Winogender and Winobias, and reinforcement learning with human feedback (RLHF). These techniques have been integrated into the latest LLMs. Our study evaluates gender bias in occupational scenarios and gender, age, and racial bias in crime scenarios across four leading LLMs released in 2024: Gemini 1.5 Pro, Llama 3 70B, Claude 3 Opus, and GPT-4o. Findings reveal that LLMs often depict female characters more frequently than male ones in various occupations, showing a 37% deviation from US BLS data. In crime scenarios, deviations from US FBI data are 54% for gender, 28% for race, and 17% for age. We observe that efforts to reduce gender and racial bias often lead to outcomes that may over-index one sub-class, potentially exacerbating the issue. These results highlight the limitations of current bias mitigation techniques and underscore the need for more effective approaches.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 20:21:20 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.756390"
    },
    {
        "index": "#28",
        "title": "Encoder with the Empirical Mode Decomposition (EMD) to remove muscle artefacts from EEG signal",
        "link": "/arxiv/2409.14571",
        "arxiv_id": "2409.14571",
        "authors": "Ildar Rakhmatulin",
        "summary": "This paper introduces a novel method for effectively removing artifacts from EEG signals by combining the Empirical Mode Decomposition (EMD) method with a machine learning architecture. The proposed method addresses the limitations of existing artifact removal techniques by enhancing the EMD method through interpolation of the upper and lower. For conventional artifact removal methods, the EMD technique is commonly employed. However, the challenge lies in accurately interpolating the missing components of the signal while preserving its inherent frequency components. To overcome this limitation, we incorporated machine learning technique, which enables us to carefully handle the interpolation process without directly manipulating the data. The key advantage of our approach lies in the preservation of the natural characteristics of the EEG signal during artifact removal. By utilizing machine learning for interpolation, we ensure that the average component obtained through the EMD method retains the crucial frequency components of the original signal. This preservation is essential for maintaining the integrity and fidelity of the EEG data, allowing for accurate analysis and interpretation. The results obtained from our evaluation serve to validate the effectiveness of our approach and pave the way for further advancements in EEG signal processing and analysis.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 19:22:22 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.756554"
    },
    {
        "index": "#29",
        "title": "Why Is Anything Conscious?",
        "link": "/arxiv/2409.14545",
        "arxiv_id": "2409.14545",
        "authors": "Michael Timothy Bennett, Sean Welsh, Anna Ciaunica",
        "summary": "We tackle the hard problem of consciousness taking the naturally-selected, self-organising, embodied organism as our starting point. We provide a mathematical formalism describing how biological systems self-organise to hierarchically interpret unlabelled sensory information according to valence and specific needs. Such interpretations imply behavioural policies which can only be differentiated from each other by the qualitative aspect of information processing. Selection pressures favour systems that can intervene in the world to achieve homeostatic and reproductive goals. Quality is a property arising in such systems to link cause to affect to motivate real world interventions. This produces a range of qualitative classifiers (interoceptive and exteroceptive) that motivate specific actions and determine priorities and preferences. Building upon the seminal distinction between access and phenomenal consciousness, our radical claim here is that phenomenal consciousness without access consciousness is likely very common, but the reverse is implausible. To put it provocatively: Nature does not like zombies. We formally describe the multilayered architecture of self-organisation from rocks to Einstein, illustrating how our argument applies in the real world. We claim that access consciousness at the human level is impossible without the ability to hierarchically model i) the self, ii) the world/others and iii) the self as modelled by others. Phenomenal consciousness is therefore required for human-level functionality. Our proposal lays the foundations of a formal science of consciousness, deeply connected with natural selection rather than abstract thinking, closer to human fact than zombie fiction.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 18:01:30 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.756730"
    },
    {
        "index": "#31",
        "title": "On a measure of intelligence",
        "link": "/arxiv/2409.14496",
        "arxiv_id": "2409.14496",
        "authors": "Yuri Gurevich",
        "summary": "The Fall 2024 Logic in Computer Science column of the Bulletin of EATCS is a little discussion on intelligence, measuring intelligence, and related issues, provoked by a fascinating must-read article ``On the measure of intelligence'' by François Chollet. The discussion includes a modicum of critique of the article.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 15:49:31 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.757187"
    },
    {
        "index": "#32",
        "title": "Can Large Language Models Logically Predict Myocardial Infarction? Evaluation based on UK Biobank Cohort",
        "link": "/arxiv/2409.14478",
        "arxiv_id": "2409.14478",
        "authors": "Yuxing Zhi, Yuan Guo, Kai Yuan, Hesong Wang, Heng Xu, Haina Yao, Albert C Yang, Guangrui Huang, Yuping Duan",
        "summary": "Background: Large language models (LLMs) have seen extraordinary advances with applications in clinical decision support. However, high-quality evidence is urgently needed on the potential and limitation of LLMs in providing accurate clinical decisions based on real-world medical data. Objective: To evaluate quantitatively whether universal state-of-the-art LLMs (ChatGPT and GPT-4) can predict the incidence risk of myocardial infarction (MI) with logical inference, and to further make comparison between various models to assess the performance of LLMs comprehensively. Methods: In this retrospective cohort study, 482,310 participants recruited from 2006 to 2010 were initially included in UK Biobank database and later on resampled into a final cohort of 690 participants. For each participant, tabular data of the risk factors of MI were transformed into standardized textual descriptions for ChatGPT recognition. Responses were generated by asking ChatGPT to select a score ranging from 0 to 10 representing the risk. Chain of Thought (CoT) questioning was used to evaluate whether LLMs make prediction logically. The predictive performance of ChatGPT was compared with published medical indices, traditional machine learning models and other large language models. Conclusions: Current LLMs are not ready to be applied in clinical medicine fields. Future medical LLMs are suggested to be expert in medical domain knowledge to understand both natural languages and quantified medical data, and further make logical inferences.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 14:57:31 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.757413"
    },
    {
        "index": "#33",
        "title": "On logic and generative AI",
        "link": "/arxiv/2409.14465",
        "arxiv_id": "2409.14465",
        "authors": "Yuri Gurevich, Andreas Blass",
        "summary": "A hundred years ago, logic was almost synonymous with foundational studies. The ongoing AI revolution raises many deep foundational problems involving neuroscience, philosophy, computer science, and logic. The goal of the following dialog is to provoke young logicians with a taste for foundations to notice the foundational problems raised by the AI revolution.",
        "subjects": "Artificial Intelligence, Logic in Computer Science",
        "date": "2024-09-22 14:31:58 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.757589"
    },
    {
        "index": "#34",
        "title": "Large Model Agents: State-of-the-Art, Cooperation Paradigms, Security and Privacy, and Future Trends",
        "link": "/arxiv/2409.14457",
        "arxiv_id": "2409.14457",
        "authors": "Yuntao Wang, Yanghe Pan, Quan Zhao, Yi Deng, Zhou Su, Linkang Du, Tom H. Luan",
        "summary": "Large Model (LM) agents, powered by large foundation models such as GPT-4 and DALL-E 2, represent a significant step towards achieving Artificial General Intelligence (AGI). LM agents exhibit key characteristics of autonomy, embodiment, and connectivity, allowing them to operate across physical, virtual, and mixed-reality environments while interacting seamlessly with humans, other agents, and their surroundings. This paper provides a comprehensive survey of the state-of-the-art in LM agents, focusing on the architecture, cooperation paradigms, security, privacy, and future prospects. Specifically, we first explore the foundational principles of LM agents, including general architecture, key components, enabling technologies, and modern applications. Then, we discuss practical collaboration paradigms from data, computation, and knowledge perspectives towards connected intelligence of LM agents. Furthermore, we systematically analyze the security vulnerabilities and privacy breaches associated with LM agents, particularly in multi-agent settings. We also explore their underlying mechanisms and review existing and potential countermeasures. Finally, we outline future research directions for building robust and secure LM agent ecosystems.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 14:09:49 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.757792"
    },
    {
        "index": "#35",
        "title": "Scoring rule nets: beyond mean target prediction in multivariate regression",
        "link": "/arxiv/2409.14456",
        "arxiv_id": "2409.14456",
        "authors": "Daan Roordink, Sibylle Hess",
        "summary": "Probabilistic regression models trained with maximum likelihood estimation (MLE), can sometimes overestimate variance to an unacceptable degree. This is mostly problematic in the multivariate domain. While univariate models often optimize the popular Continuous Ranked Probability Score (CRPS), in the multivariate domain, no such alternative to MLE has yet been widely accepted. The Energy Score - the most investigated alternative - notoriously lacks closed-form expressions and sensitivity to the correlation between target variables. In this paper, we propose Conditional CRPS: a multivariate strictly proper scoring rule that extends CRPS. We show that closed-form expressions exist for popular distributions and illustrate their sensitivity to correlation. We then show in a variety of experiments on both synthetic and real data, that Conditional CRPS often outperforms MLE, and produces results comparable to state-of-the-art non-parametric models, such as Distributional Random Forest (DRF).",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 14:09:12 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.757963"
    },
    {
        "index": "#36",
        "title": "OStr-DARTS: Differentiable Neural Architecture Search based on Operation Strength",
        "link": "/arxiv/2409.14433",
        "arxiv_id": "2409.14433",
        "authors": "Le Yang, Ziwei Zheng, Yizeng Han, Shiji Song, Gao Huang, Fan Li",
        "summary": "Differentiable architecture search (DARTS) has emerged as a promising technique for effective neural architecture search, and it mainly contains two steps to find the high-performance architecture: First, the DARTS supernet that consists of mixed operations will be optimized via gradient descent. Second, the final architecture will be built by the selected operations that contribute the most to the supernet. Although DARTS improves the efficiency of NAS, it suffers from the well-known degeneration issue which can lead to deteriorating architectures. Existing works mainly attribute the degeneration issue to the failure of its supernet optimization, while little attention has been paid to the selection method. In this paper, we cease to apply the widely-used magnitude-based selection method and propose a novel criterion based on operation strength that estimates the importance of an operation by its effect on the final loss. We show that the degeneration issue can be effectively addressed by using the proposed criterion without any modification of supernet optimization, indicating that the magnitude-based selection method can be a critical reason for the instability of DARTS. The experiments on NAS-Bench-201 and DARTS search spaces show the effectiveness of our method.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 13:16:07 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.758159"
    },
    {
        "index": "#37",
        "title": "MaskedMimic: Unified Physics-Based Character Control Through Masked Motion Inpainting",
        "link": "/arxiv/2409.14393",
        "arxiv_id": "2409.14393",
        "authors": "Chen Tessler, Yunrong Guo, Ofir Nabati, Gal Chechik, Xue Bin Peng",
        "summary": "Crafting a single, versatile physics-based controller that can breathe life into interactive characters across a wide spectrum of scenarios represents an exciting frontier in character animation. An ideal controller should support diverse control modalities, such as sparse target keyframes, text instructions, and scene information. While previous works have proposed physically simulated, scene-aware control models, these systems have predominantly focused on developing controllers that each specializes in a narrow set of tasks and control modalities. This work presents MaskedMimic, a novel approach that formulates physics-based character control as a general motion inpainting problem. Our key insight is to train a single unified model to synthesize motions from partial (masked) motion descriptions, such as masked keyframes, objects, text descriptions, or any combination thereof. This is achieved by leveraging motion tracking data and designing a scalable training method that can effectively utilize diverse motion descriptions to produce coherent animations. Through this process, our approach learns a physics-based controller that provides an intuitive control interface without requiring tedious reward engineering for all behaviors of interest. The resulting controller supports a wide range of control modalities and enables seamless transitions between disparate tasks. By unifying character control through motion inpainting, MaskedMimic creates versatile virtual characters. These characters can dynamically adapt to complex scenes and compose diverse motions on demand, enabling more interactive and immersive experiences.",
        "subjects": "Artificial Intelligence, Robotics",
        "date": "2024-09-22 11:10:59 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.758351"
    },
    {
        "index": "#38",
        "title": "To Err Is AI! Debugging as an Intervention to Facilitate Appropriate Reliance on AI Systems",
        "link": "/arxiv/2409.14377",
        "arxiv_id": "2409.14377",
        "authors": "Gaole He, Abri Bharos, Ujwal Gadiraju",
        "summary": "Powerful predictive AI systems have demonstrated great potential in augmenting human decision making. Recent empirical work has argued that the vision for optimal human-AI collaboration requires 'appropriate reliance' of humans on AI systems. However, accurately estimating the trustworthiness of AI advice at the instance level is quite challenging, especially in the absence of performance feedback pertaining to the AI system. In practice, the performance disparity of machine learning models on out-of-distribution data makes the dataset-specific performance feedback unreliable in human-AI collaboration. Inspired by existing literature on critical thinking and a critical mindset, we propose the use of debugging an AI system as an intervention to foster appropriate reliance. In this paper, we explore whether a critical evaluation of AI performance within a debugging setting can better calibrate users' assessment of an AI system and lead to more appropriate reliance. Through a quantitative empirical study (N = 234), we found that our proposed debugging intervention does not work as expected in facilitating appropriate reliance. Instead, we observe a decrease in reliance on the AI system after the intervention -- potentially resulting from an early exposure to the AI system's weakness. We explore the dynamics of user confidence and user estimation of AI trustworthiness across groups with different performance levels to help explain how inappropriate reliance patterns occur. Our findings have important implications for designing effective interventions to facilitate appropriate reliance and better human-AI collaboration.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 09:43:27 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.758519"
    },
    {
        "index": "#39",
        "title": "MANTA -- Model Adapter Native generations that's Affordable",
        "link": "/arxiv/2409.14363",
        "arxiv_id": "2409.14363",
        "authors": "Ansh Chaurasia",
        "summary": "The presiding model generation algorithms rely on simple, inflexible adapter selection to provide personalized results. We propose the model-adapter composition problem as a generalized problem to past work factoring in practical hardware and affordability constraints, and introduce MANTA as a new approach to the problem. Experiments on COCO 2014 validation show MANTA to be superior in image task diversity and quality at the cost of a modest drop in alignment. Our system achieves a $94\\%$ win rate in task diversity and a $80\\%$ task quality win rate versus the best known system, and demonstrates strong potential for direct use in synthetic data generation and the creative art domains.",
        "subjects": "Artificial Intelligence, Image and Video Processing",
        "date": "2024-09-22 08:38:23 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.758684"
    },
    {
        "index": "#40",
        "title": "LLMs are One-Shot URL Classifiers and Explainers",
        "link": "/arxiv/2409.14306",
        "arxiv_id": "2409.14306",
        "authors": "Fariza Rashid, Nishavi Ranaweera, Ben Doyle, Suranga Seneviratne",
        "summary": "Malicious URL classification represents a crucial aspect of cyber security. Although existing work comprises numerous machine learning and deep learning-based URL classification models, most suffer from generalisation and domain-adaptation issues arising from the lack of representative training datasets. Furthermore, these models fail to provide explanations for a given URL classification in natural human language. In this work, we investigate and demonstrate the use of Large Language Models (LLMs) to address this issue. Specifically, we propose an LLM-based one-shot learning framework that uses Chain-of-Thought (CoT) reasoning to predict whether a given URL is benign or phishing. We evaluate our framework using three URL datasets and five state-of-the-art LLMs and show that one-shot LLM prompting indeed provides performances close to supervised models, with GPT 4-Turbo being the best model, followed by Claude 3 Opus. We conduct a quantitative analysis of the LLM explanations and show that most of the explanations provided by LLMs align with the post-hoc explanations of the supervised classifiers, and the explanations have high readability, coherency, and informativeness.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 03:52:39 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.758892"
    },
    {
        "index": "#41",
        "title": "UU-Mamba: Uncertainty-aware U-Mamba for Cardiovascular Segmentation",
        "link": "/arxiv/2409.14305",
        "arxiv_id": "2409.14305",
        "authors": "Ting Yu Tsai, Li Lin, Shu Hu, Connie W. Tsao, Xin Li, Ming-Ching Chang, Hongtu Zhu, Xin Wang",
        "summary": "Building on the success of deep learning models in cardiovascular structure segmentation, increasing attention has been focused on improving generalization and robustness, particularly in small, annotated datasets. Despite recent advancements, current approaches often face challenges such as overfitting and accuracy limitations, largely due to their reliance on large datasets and narrow optimization techniques. This paper introduces the UU-Mamba model, an extension of the U-Mamba architecture, designed to address these challenges in both cardiac and vascular segmentation. By incorporating Sharpness-Aware Minimization (SAM), the model enhances generalization by targeting flatter minima in the loss landscape. Additionally, we propose an uncertainty-aware loss function that combines region-based, distribution-based, and pixel-based components to improve segmentation accuracy by capturing both local and global features. While the UU-Mamba model has already demonstrated great performance, further testing is required to fully assess its generalization and robustness. We expand our evaluation by conducting new trials on the ImageCAS (coronary artery) and Aorta (aortic branches and zones) datasets, which present more complex segmentation challenges than the ACDC dataset (left and right ventricles) used in our previous work, showcasing the model's adaptability and resilience. We confirm UU-Mamba's superior performance over leading models such as TransUNet, Swin-Unet, nnUNet, and nnFormer. Moreover, we provide a more comprehensive evaluation of the model's robustness and segmentation accuracy, as demonstrated by extensive experiments.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-22 03:22:06 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.759120"
    },
    {
        "index": "#42",
        "title": "HM3D-OVON: A Dataset and Benchmark for Open-Vocabulary Object Goal Navigation",
        "link": "/arxiv/2409.14296",
        "arxiv_id": "2409.14296",
        "authors": "Naoki Yokoyama, Ram Ramrakhya, Abhishek Das, Dhruv Batra, Sehoon Ha",
        "summary": "We present the Habitat-Matterport 3D Open Vocabulary Object Goal Navigation dataset (HM3D-OVON), a large-scale benchmark that broadens the scope and semantic range of prior Object Goal Navigation (ObjectNav) benchmarks. Leveraging the HM3DSem dataset, HM3D-OVON incorporates over 15k annotated instances of household objects across 379 distinct categories, derived from photo-realistic 3D scans of real-world environments. In contrast to earlier ObjectNav datasets, which limit goal objects to a predefined set of 6-20 categories, HM3D-OVON facilitates the training and evaluation of models with an open-set of goals defined through free-form language at test-time. Through this open-vocabulary formulation, HM3D-OVON encourages progress towards learning visuo-semantic navigation behaviors that are capable of searching for any object specified by text in an open-vocabulary manner. Additionally, we systematically evaluate and compare several different types of approaches on HM3D-OVON. We find that HM3D-OVON can be used to train an open-vocabulary ObjectNav agent that achieves both higher performance and is more robust to localization and actuation noise than the state-of-the-art ObjectNav approach. We hope that our benchmark and baseline results will drive interest in developing embodied agents that can navigate real-world spaces to find household objects specified through free-form language, taking a step towards more flexible and human-like semantic visual navigation. Code and videos available at: naoki.io/ovon.",
        "subjects": "Artificial Intelligence, Robotics",
        "date": "2024-09-22 02:12:29 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.759318"
    },
    {
        "index": "#44",
        "title": "Predicting Coronary Heart Disease Using a Suite of Machine Learning Models",
        "link": "/arxiv/2409.14231",
        "arxiv_id": "2409.14231",
        "authors": "Jamal Al-Karaki, Philip Ilono, Sanchit Baweja, Jalal Naghiyev, Raja Singh Yadav, Muhammad Al-Zafar Khan",
        "summary": "Coronary Heart Disease affects millions of people worldwide and is a well-studied area of healthcare. There are many viable and accurate methods for the diagnosis and prediction of heart disease, but they have limiting points such as invasiveness, late detection, or cost. Supervised learning via machine learning algorithms presents a low-cost (computationally speaking), non-invasive solution that can be a precursor for early diagnosis. In this study, we applied several well-known methods and benchmarked their performance against each other. It was found that Random Forest with oversampling of the predictor variable produced the highest accuracy of 84%.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-21 19:22:41 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.759711"
    },
    {
        "index": "#45",
        "title": "AI Assistants for Spaceflight Procedures: Combining Generative Pre-Trained Transformer and Retrieval-Augmented Generation on Knowledge Graphs With Augmented Reality Cues",
        "link": "/arxiv/2409.14206",
        "arxiv_id": "2409.14206",
        "authors": "Oliver Bensch, Leonie Bensch, Tommy Nilsson, Florian Saling, Bernd Bewer, Sophie Jentzsch, Tobias Hecking, J. Nathan Kutz",
        "summary": "This paper describes the capabilities and potential of the intelligent personal assistant (IPA) CORE (Checklist Organizer for Research and Exploration), designed to support astronauts during procedures onboard the International Space Station (ISS), the Lunar Gateway station, and beyond. We reflect on the importance of a reliable and flexible assistant capable of offline operation and highlight the usefulness of audiovisual interaction using augmented reality elements to intuitively display checklist information. We argue that current approaches to the design of IPAs in space operations fall short of meeting these criteria. Therefore, we propose CORE as an assistant that combines Knowledge Graphs (KGs), Retrieval-Augmented Generation (RAG) for a Generative Pre-Trained Transformer (GPT), and Augmented Reality (AR) elements to ensure an intuitive understanding of procedure steps, reliability, offline availability, and flexibility in terms of response style and procedure updates.",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2024-09-21 17:41:46 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.759919"
    },
    {
        "index": "#46",
        "title": "Loop-Residual Neural Networks for Iterative Refinement",
        "link": "/arxiv/2409.14199",
        "arxiv_id": "2409.14199",
        "authors": "Kei-Sing Ng, Qingchen Wang",
        "summary": "The success of large-scale language models like GPT can be attributed to their ability to efficiently predict the next token in a sequence. However, these models rely on constant computational effort regardless of the complexity of the token they are predicting, lacking the capacity for iterative refinement. In this paper, we introduce a novel Loop-Residual Neural Network, which achieves better performance by utilizing longer computational time without increasing the model size. Our approach revisits the input multiple times, refining the prediction by iteratively looping over a subset of the model with residual connections. We demonstrate the effectiveness of this method through experiments comparing versions of GPT-2 with our Loop-Residual models, showing improved performance in language modeling tasks while maintaining similar parameter counts. Importantly, these improvements are achieved without the need for extra training data.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-21 17:07:42 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.760087"
    },
    {
        "index": "#47",
        "title": "Addressing and Visualizing Misalignments in Human Task-Solving Trajectories",
        "link": "/arxiv/2409.14191",
        "arxiv_id": "2409.14191",
        "authors": "Sejin Kim, Hosung Lee, Sundong Kim",
        "summary": "The effectiveness of AI model training hinges on the quality of the trajectory data used, particularly in aligning the model's decision with human intentions. However, in the human task-solving trajectories, we observe significant misalignments between human intentions and the recorded trajectories, which can undermine AI model training. This paper addresses the challenges of these misalignments by proposing a visualization tool and a heuristic algorithm designed to detect and categorize discrepancies in trajectory data. Although the heuristic algorithm requires a set of predefined human intentions to function, which we currently cannot extract, the visualization tool offers valuable insights into the nature of these misalignments. We expect that eliminating these misalignments could significantly improve the utility of trajectory data for AI model training. We also propose that future work should focus on developing methods, such as Topic Modeling, to accurately extract human intentions from trajectory data, thereby enhancing the alignment between user actions and AI learning processes.",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2024-09-21 16:38:22 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.765523"
    },
    {
        "index": "#48",
        "title": "Democratising Artificial Intelligence for Pandemic Preparedness and Global Governance in Latin American and Caribbean Countries",
        "link": "/arxiv/2409.14181",
        "arxiv_id": "2409.14181",
        "authors": "Andre de Carvalho, Robson Bonidia, Jude Dzevela Kong, Mariana Dauhajre, Claudio Struchiner, Guilherme Goedert, Peter F. Stadler, Maria Emilia Walter, Danilo Sanches, Troy Day, Marcia Castro, John Edmunds, Manuel Colome-Hidalgo, Demian Arturo Herrera Morban, Edian F. Franco, Cesar Ugarte-Gil, Patricia Espinoza-Lopez, Gabriel Carrasco-Escobar, Ulisses Rocha",
        "summary": "Infectious diseases, transmitted directly or indirectly, are among the leading causes of epidemics and pandemics. Consequently, several open challenges exist in predicting epidemic outbreaks, detecting variants, tracing contacts, discovering new drugs, and fighting misinformation. Artificial Intelligence (AI) can provide tools to deal with these scenarios, demonstrating promising results in the fight against the COVID-19 pandemic. AI is becoming increasingly integrated into various aspects of society. However, ensuring that AI benefits are distributed equitably and that they are used responsibly is crucial. Multiple countries are creating regulations to address these concerns, but the borderless nature of AI requires global cooperation to define regulatory and guideline consensus. Considering this, The Global South AI for Pandemic & Epidemic Preparedness & Response Network (AI4PEP) has developed an initiative comprising 16 projects across 16 countries in the Global South, seeking to strengthen equitable and responsive public health systems that leverage Southern-led responsible AI solutions to improve prevention, preparedness, and response to emerging and re-emerging infectious disease outbreaks. This opinion introduces our branches in Latin American and Caribbean (LAC) countries and discusses AI governance in LAC in the light of biotechnology. Our network in LAC has high potential to help fight infectious diseases, particularly in low- and middle-income countries, generating opportunities for the widespread use of AI techniques to improve the health and well-being of their communities.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-21 15:59:13 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.765984"
    },
    {
        "index": "#49",
        "title": "An Evolutionary Algorithm For the Vehicle Routing Problem with Drones with Interceptions",
        "link": "/arxiv/2409.14173",
        "arxiv_id": "2409.14173",
        "authors": "Carlos Pambo, Jacomine Grobler",
        "summary": "The use of trucks and drones as a solution to address last-mile delivery challenges is a new and promising research direction explored in this paper. The variation of the problem where the drone can intercept the truck while in movement or at the customer location is part of an optimisation problem called the vehicle routing problem with drones with interception (VRPDi). This paper proposes an evolutionary algorithm to solve the VRPDi. In this variation of the VRPDi, multiple pairs of trucks and drones need to be scheduled. The pairs leave and return to a depot location together or separately to make deliveries to customer nodes. The drone can intercept the truck after the delivery or meet up with the truck at the following customer location. The algorithm was executed on the travelling salesman problem with drones (TSPD) datasets by Bouman et al. (2015), and the performance of the algorithm was compared by benchmarking the results of the VRPDi against the results of the VRP of the same dataset. This comparison showed improvements in total delivery time between 39% and 60%. Further detailed analysis of the algorithm results examined the total delivery time, distance, node delivery scheduling and the degree of diversity during the algorithm execution. This analysis also considered how the algorithm handled the VRPDi constraints. The results of the algorithm were then benchmarked against algorithms in Dillon et al. (2023) and Ernst (2024). The latter solved the problem with a maximum drone distance constraint added to the VRPDi. The analysis and benchmarking of the algorithm results showed that the algorithm satisfactorily solved 50 and 100-nodes problems in a reasonable amount of time, and the solutions found were better than those found by the algorithms in Dillon et al. (2023) and Ernst (2024) for the same problems.",
        "subjects": "Artificial Intelligence, Computers and Society, Emerging Technologies, Optimization and Control",
        "date": "2024-09-21 15:26:24 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.766243"
    },
    {
        "index": "#51",
        "title": "FineMolTex: Towards Fine-grained Molecular Graph-Text Pre-training",
        "link": "/arxiv/2409.14106",
        "arxiv_id": "2409.14106",
        "authors": "Yibo Li, Yuan Fang, Mengmei Zhang, Chuan Shi",
        "summary": "Understanding molecular structure and related knowledge is crucial for scientific research. Recent studies integrate molecular graphs with their textual descriptions to enhance molecular representation learning. However, they focus on the whole molecular graph and neglect frequently occurring subgraphs, known as motifs,which are essential for determining molecular properties. Without such fine-grained knowledge, these models struggle to generalize to unseen molecules and tasks that require motif-level insights. To bridge this gap, we propose FineMolTex, a novel Fine-grained Molecular graph-Text pre-training framework to jointly learn coarse-grained molecule-level knowledge and fine-grained motif-level knowledge. Specifically, FineMolTex consists of two pre-training tasks: a contrastive alignment task for coarse-grained matching and a masked multi-modal modeling task for fine-grained matching. In particular, the latter predicts the labels of masked motifs and words, leveraging insights from each other, thereby enabling FineMolTex to understand the fine-grained matching between motifs and words. Finally, we conduct extensive experiments across three downstream tasks, achieving up to 230% improvement in the text-based molecule editing task. Additionally, our case studies reveal that FineMolTex successfully captures fine-grained knowledge, potentially offering valuable insights for drug discovery and catalyst design.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-21 11:19:15 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.766751"
    },
    {
        "index": "#52",
        "title": "Normalized Narrow Jump To Conclusions: Normalized Narrow Shortcuts for Parameter Efficient Early Exit Transformer Prediction",
        "link": "/arxiv/2409.14091",
        "arxiv_id": "2409.14091",
        "authors": "Amrit Diggavi Seshadri",
        "summary": "With the size and cost of large transformer-based language models growing, recently, there has been interest in shortcut casting of early transformer hidden-representations to final-representations for cheaper model inference. In particular, shortcutting pre-trained transformers with linear transformations over early layers has been shown to improve precision in early inference. However, for large language models, even this becomes computationally expensive. In this work, we propose Narrow Jump to Conclusions (NJTC) and Normalized Narrow Jump to Conclusions (N-NJTC) - parameter efficient alternatives to standard linear shortcutting that reduces shortcut parameter count by over 97%. We show that N-NJTC reliably outperforms Identity shortcuts at early stages and offers stable precision from all transformer block levels for GPT-2-XL, Phi3-Mini and Llama2-7B transformer models, demonstrating the viability of more parameter efficient short-cutting approaches.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-21 10:09:26 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.766966"
    },
    {
        "index": "#53",
        "title": "The use of GPT-4o and Other Large Language Models for the Improvement and Design of Self-Assessment Scales for Measurement of Interpersonal Communication Skills",
        "link": "/arxiv/2409.14050",
        "arxiv_id": "2409.14050",
        "authors": "Goran Bubaš",
        "summary": "OpenAI's ChatGPT (GPT-4 and GPT-4o) and other Large Language Models (LLMs) like Microsoft's Copilot, Google's Gemini 1.5 Pro, and Antrophic's Claude 3.5 Sonnet can be effectively used in various phases of scientific research. Their performance in diverse verbal tasks and reasoning is close to or above the average human level and rapidly increasing, providing those models with a capacity that resembles a relatively high level of theory of mind. The current ability of LLMs to process information about human psychology and communication creates an opportunity for their scientific use in the fields of personality psychology and interpersonal communication skills. This article illustrates the possible uses of GPT-4o and other advanced LLMs for typical tasks in designing self-assessment scales for interpersonal communication skills measurement like the selection and improvement of scale items and evaluation of content validity of scales. The potential for automated item generation and application is illustrated as well. The case study examples are accompanied by prompts for LLMs that can be useful for these purposes. Finally, a summary is provided of the potential benefits of using LLMs in the process of evaluation, design, and improvement of interpersonal communication skills self-assessment scales.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-21 07:37:21 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.767174"
    },
    {
        "index": "#55",
        "title": "Drift to Remember",
        "link": "/arxiv/2409.13997",
        "arxiv_id": "2409.13997",
        "authors": "Jin Du, Xinhe Zhang, Hao Shen, Xun Xian, Ganghua Wang, Jiawei Zhang, Yuhong Yang, Na Li, Jia Liu, Jie Ding",
        "summary": "Lifelong learning in artificial intelligence (AI) aims to mimic the biological brain's ability to continuously learn and retain knowledge, yet it faces challenges such as catastrophic forgetting. Recent neuroscience research suggests that neural activity in biological systems undergoes representational drift, where neural responses evolve over time, even with consistent inputs and tasks. We hypothesize that representational drift can alleviate catastrophic forgetting in AI during new task acquisition. To test this, we introduce DriftNet, a network designed to constantly explore various local minima in the loss landscape while dynamically retrieving relevant tasks. This approach ensures efficient integration of new information and preserves existing knowledge. Experimental studies in image classification and natural language processing demonstrate that DriftNet outperforms existing models in lifelong learning. Importantly, DriftNet is scalable in handling a sequence of tasks such as sentiment analysis and question answering using large language models (LLMs) with billions of parameters on a single Nvidia A100 GPU. DriftNet efficiently updates LLMs using only new data, avoiding the need for full dataset retraining. Tested on GPT-2 and RoBERTa, DriftNet is a robust, cost-effective solution for lifelong learning in LLMs. This study not only advances AI systems to emulate biological learning, but also provides insights into the adaptive mechanisms of biological neural systems, deepening our understanding of lifelong learning in nature.",
        "subjects": "Artificial Intelligence, Neurons and Cognition",
        "date": "2024-09-21 03:18:44 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.767699"
    },
    {
        "index": "#56",
        "title": "PureDiffusion: Using Backdoor to Counter Backdoor in Generative Diffusion Models",
        "link": "/arxiv/2409.13945",
        "arxiv_id": "2409.13945",
        "authors": "Vu Tuan Truong, Long Bao Le",
        "summary": "Diffusion models (DMs) are advanced deep learning models that achieved state-of-the-art capability on a wide range of generative tasks. However, recent studies have shown their vulnerability regarding backdoor attacks, in which backdoored DMs consistently generate a designated result (e.g., a harmful image) called backdoor target when the models' input contains a backdoor trigger. Although various backdoor techniques have been investigated to attack DMs, defense methods against these threats are still limited and underexplored, especially in inverting the backdoor trigger. In this paper, we introduce PureDiffusion, a novel backdoor defense framework that can efficiently detect backdoor attacks by inverting backdoor triggers embedded in DMs. Our extensive experiments on various trigger-target pairs show that PureDiffusion outperforms existing defense methods with a large gap in terms of fidelity (i.e., how much the inverted trigger resembles the original trigger) and backdoor success rate (i.e., the rate that the inverted trigger leads to the corresponding backdoor target). Notably, in certain cases, backdoor triggers inverted by PureDiffusion even achieve higher attack success rate than the original triggers.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-20 23:19:26 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.767878"
    },
    {
        "index": "#58",
        "title": "Failures in Perspective-taking of Multimodal AI Systems",
        "link": "/arxiv/2409.13929",
        "arxiv_id": "2409.13929",
        "authors": "Bridget Leonard, Kristin Woodard, Scott O. Murray",
        "summary": "This study extends previous research on spatial representations in multimodal AI systems. Although current models demonstrate a rich understanding of spatial information from images, this information is rooted in propositional representations, which differ from the analog representations employed in human and animal spatial cognition. To further explore these limitations, we apply techniques from cognitive and developmental science to assess the perspective-taking abilities of GPT-4o. Our analysis enables a comparison between the cognitive development of the human brain and that of multimodal AI, offering guidance for future research and model development.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-20 22:31:46 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.768228"
    },
    {
        "index": "#59",
        "title": "SpaceBlender: Creating Context-Rich Collaborative Spaces Through Generative 3D Scene Blending",
        "link": "/arxiv/2409.13926",
        "arxiv_id": "2409.13926",
        "authors": "Nels Numan, Shwetha Rajaram, Balasaravanan Thoravi Kumaravel, Nicolai Marquardt, Andrew D. Wilson",
        "summary": "There is increased interest in using generative AI to create 3D spaces for Virtual Reality (VR) applications. However, today's models produce artificial environments, falling short of supporting collaborative tasks that benefit from incorporating the user's physical context. To generate environments that support VR telepresence, we introduce SpaceBlender, a novel pipeline that utilizes generative AI techniques to blend users' physical surroundings into unified virtual spaces. This pipeline transforms user-provided 2D images into context-rich 3D environments through an iterative process consisting of depth estimation, mesh alignment, and diffusion-based space completion guided by geometric priors and adaptive text prompts. In a preliminary within-subjects study, where 20 participants performed a collaborative VR affinity diagramming task in pairs, we compared SpaceBlender with a generic virtual environment and a state-of-the-art scene generation framework, evaluating its ability to create virtual spaces suitable for collaboration. Participants appreciated the enhanced familiarity and context provided by SpaceBlender but also noted complexities in the generative environments that could detract from task focus. Drawing on participant feedback, we propose directions for improving the pipeline and discuss the value and design of blended spaces for different scenarios.",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2024-09-20 22:27:31 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.768418"
    },
    {
        "index": "#60",
        "title": "Measuring Error Alignment for Decision-Making Systems",
        "link": "/arxiv/2409.13919",
        "arxiv_id": "2409.13919",
        "authors": "Binxia Xu, Antonis Bikakis, Daniel Onah, Andreas Vlachidis, Luke Dickens",
        "summary": "Given that AI systems are set to play a pivotal role in future decision-making processes, their trustworthiness and reliability are of critical concern. Due to their scale and complexity, modern AI systems resist direct interpretation, and alternative ways are needed to establish trust in those systems, and determine how well they align with human values. We argue that good measures of the information processing similarities between AI and humans, may be able to achieve these same ends. While Representational alignment (RA) approaches measure similarity between the internal states of two systems, the associated data can be expensive and difficult to collect for human systems. In contrast, Behavioural alignment (BA) comparisons are cheaper and easier, but questions remain as to their sensitivity and reliability. We propose two new behavioural alignment metrics misclassification agreement which measures the similarity between the errors of two systems on the same instances, and class-level error similarity which measures the similarity between the error distributions of two systems. We show that our metrics correlate well with RA metrics, and provide complementary information to another BA metric, within a range of domains, and set the scene for a new approach to value alignment.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-20 21:59:13 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.768609"
    },
    {
        "index": "#61",
        "title": "Nonlinear Inverse Design of Mechanical Multi-Material Metamaterials Enabled by Video Denoising Diffusion and Structure Identifier",
        "link": "/arxiv/2409.13908",
        "arxiv_id": "2409.13908",
        "authors": "Jaewan Park, Shashank Kushwaha, Junyan He, Seid Koric, Qibang Liu, Iwona Jasiuk, Diab Abueidda",
        "summary": "Metamaterials, synthetic materials with customized properties, have emerged as a promising field due to advancements in additive manufacturing. These materials derive unique mechanical properties from their internal lattice structures, which are often composed of multiple materials that repeat geometric patterns. While traditional inverse design approaches have shown potential, they struggle to map nonlinear material behavior to multiple possible structural configurations. This paper presents a novel framework leveraging video diffusion models, a type of generative artificial Intelligence (AI), for inverse multi-material design based on nonlinear stress-strain responses. Our approach consists of two key components: (1) a fields generator using a video diffusion model to create solution fields based on target nonlinear stress-strain responses, and (2) a structure identifier employing two UNet models to determine the corresponding multi-material 2D design. By incorporating multiple materials, plasticity, and large deformation, our innovative design method allows for enhanced control over the highly nonlinear mechanical behavior of metamaterials commonly seen in real-world applications. It offers a promising solution for generating next-generation metamaterials with finely tuned mechanical characteristics.",
        "subjects": "Artificial Intelligence, Computational Engineering, Finance, and Science",
        "date": "2024-09-20 21:26:15 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.768879"
    },
    {
        "index": "#62",
        "title": "CI-Bench: Benchmarking Contextual Integrity of AI Assistants on Synthetic Data",
        "link": "/arxiv/2409.13903",
        "arxiv_id": "2409.13903",
        "authors": "Zhao Cheng, Diane Wan, Matthew Abueg, Sahra Ghalebikesabi, Ren Yi, Eugene Bagdasarian, Borja Balle, Stefan Mellem, Shawn O'Banion",
        "summary": "Advances in generative AI point towards a new era of personalized applications that perform diverse tasks on behalf of users. While general AI assistants have yet to fully emerge, their potential to share personal data raises significant privacy challenges. This paper introduces CI-Bench, a comprehensive synthetic benchmark for evaluating the ability of AI assistants to protect personal information during model inference. Leveraging the Contextual Integrity framework, our benchmark enables systematic assessment of information flow across important context dimensions, including roles, information types, and transmission principles. We present a novel, scalable, multi-step synthetic data pipeline for generating natural communications, including dialogues and emails. Unlike previous work with smaller, narrowly focused evaluations, we present a novel, scalable, multi-step data pipeline that synthetically generates natural communications, including dialogues and emails, which we use to generate 44 thousand test samples across eight domains. Additionally, we formulate and evaluate a naive AI assistant to demonstrate the need for further study and careful training towards personal assistant tasks. We envision CI-Bench as a valuable tool for guiding future language model development, deployment, system design, and dataset construction, ultimately contributing to the development of AI assistants that align with users' privacy expectations.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-20 21:14:36 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.769135"
    },
    {
        "index": "#64",
        "title": "A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics",
        "link": "/arxiv/2409.13825",
        "arxiv_id": "2409.13825",
        "authors": "Mengyun Qiao, Kathryn A McGurk, Shuo Wang, Paul M. Matthews, Declan P O Regan, Wenjia Bai",
        "summary": "Understanding the structure and motion of the heart is crucial for diagnosing and managing cardiovascular diseases, the leading cause of global death. There is wide variation in cardiac shape and motion patterns, that are influenced by demographic, anthropometric and disease factors. Unravelling the normal patterns of shape and motion, as well as understanding how each individual deviates from the norm, would facilitate accurate diagnosis and personalised treatment strategies. To this end, we developed a novel conditional generative model, MeshHeart, to learn the distribution of cardiac shape and motion patterns. MeshHeart is capable of generating 3D+t cardiac mesh sequences, taking into account clinical factors such as age, sex, weight and height. To model the high-dimensional and complex spatio-temporal mesh data, MeshHeart employs a geometric encoder to represent cardiac meshes in a latent space, followed by a temporal Transformer to model the motion dynamics of latent representations. Based on MeshHeart, we investigate the latent space of 3D+t cardiac mesh sequences and propose a novel distance metric termed latent delta, which quantifies the deviation of a real heart from its personalised normative pattern in the latent space. In experiments using a large dataset of 38,309 subjects, MeshHeart demonstrates a high performance in cardiac mesh sequence reconstruction and generation. Features defined in the latent space are highly discriminative for cardiac disease classification, whereas the latent delta exhibits strong correlation with clinical phenotypes in phenome-wide association studies. The codes and models of this study will be released to benefit further research on digital heart modelling.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-20 18:08:37 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.769580"
    },
    {
        "index": "#65",
        "title": "Simulación de la distribución de alimento en el cultivo de camarón",
        "link": "/arxiv/2409.13759",
        "arxiv_id": "2409.13759",
        "authors": "Renato L. Conforme Rosado, Francisco C. Calderon Bocanegra",
        "summary": "This document presents the experimentation of 4 cases of food distribution for shrimp farming. The distributions are based on the location of the automatic feeders. Three cases applied in reality and a fourth case where the food is irrigated on the crop simultaneously and uniformly. In a first stage, the simulation of the three distribution cases is successfully adjusted to reality, where the trend of the shrimp growth curve is correlated with the historical data curve. A second stage where you experiment in 16 configurations that are based on the amount of food, the density of biomass and the distribution of the food. The simulation adopts the concepts of genetic algorithms to improve the population and fuzzy logic as an agent evaluation technique for decision-making against the quality of physical-chemical parameters in the simulated environment. The results of these interactions reveal a reduction in the simulated total culture time from 22 weeks to 14 weeks.",
        "subjects": "Artificial Intelligence",
        "date": "2024-09-16 01:29:49 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.769749"
    },
    {
        "index": "#66",
        "title": "Increasing the Value of Information During Planning in Uncertain Environments",
        "link": "/arxiv/2409.13754",
        "arxiv_id": "2409.13754",
        "authors": "Gaurab Pokharel",
        "summary": "Prior studies have demonstrated that for many real-world problems, POMDPs can be solved through online algorithms both quickly and with near optimality. However, on an important set of problems where there is a large time delay between when the agent can gather information and when it needs to use that information, these solutions fail to adequately consider the value of information. As a result, information gathering actions, even when they are critical in the optimal policy, will be ignored by existing solutions, leading to sub-optimal decisions by the agent. In this research, we develop a novel solution that rectifies this problem by introducing a new algorithm that improves upon state-of-the-art online planning by better reflecting on the value of actions that gather information. We do this by adding Entropy to the UCB1 heuristic in the POMCP algorithm. We test this solution on the hallway problem. Results indicate that our new algorithm performs significantly better than POMCP.",
        "subjects": "Artificial Intelligence, Multiagent Systems, Robotics",
        "date": "2024-09-14 22:04:34 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.769930"
    },
    {
        "index": "#70",
        "title": "Style over Substance: Failure Modes of LLM Judges in Alignment Benchmarking",
        "link": "/arxiv/2409.15268",
        "arxiv_id": "2409.15268",
        "authors": "Benjamin Feuer, Micah Goldblum, Teresa Datta, Sanjana Nambiar, Raz Besaleli, Samuel Dooley, Max Cembalest, John P. Dickerson",
        "summary": "The release of ChatGPT in November 2022 sparked an explosion of interest in post-training and an avalanche of new preference optimization (PO) methods. These methods claim superior alignment by virtue of better correspondence with human pairwise preferences, often measured by LLM judges. In this work, we attempt to answer the following question -- do LLM-judge preferences translate to progress on other, more concrete metrics for alignment, and if not, why not? We define a concrete metric for alignment, and introduce SOS-Bench, the largest standardized, reproducible LLM meta-benchmark to date. We find that (1) LLM-judgments do not correlate with concrete measures of safety, world knowledge, and instruction following; (2) LLM judges have powerful implicit biases, prioritizing style over factuality and safety; and (3) the supervised fine-tuning (SFT) stage of post-training, and not the PO stage, has the greatest impact on alignment, with data scaling and prompt diversity as the driving factors. Our codebase and complete results can be found at https://github.com/penfever/sos-bench.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-23 17:58:07 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.776504"
    },
    {
        "index": "#71",
        "title": "The Palomar twilight survey of 'Ayló'chaxnim, Atiras, and comets",
        "link": "/arxiv/2409.15263",
        "arxiv_id": "2409.15263",
        "authors": "B. T. Bolin, F. J. Masci, M. W. Coughlin, D. A. Duev, Ž. Ivezić, R. L. Jones, P. Yoachim, T. Ahumada, V. Bhalerao, H. Choudhary, C. Contreras, Y. -C. Cheng, C. M. Copperwheat, K. Deshmukh, C. Fremling, M. Granvik, K. K. Hardegree-Ullman, A. Y. Q. Ho, R. Jedicke, M. Kasliwal, H. Kumar, Z. -Y. Lin, A. Mahabal, A. Monson, J. D. Neill, D. Nesvorný, D. A. Perley, J. N. Purdum, R. Quimby, E. Serabyn, K. Sharma, V. Swain",
        "summary": "Near-sun sky twilight observations allow for the detection of asteroid interior to the orbit of Venus (Aylos), the Earth (Atiras), and comets. We present the results of observations with the Palomar 48-inch telescope (P48)/Zwicky Transient Facility (ZTF) camera in 30 s r-band exposures taken during evening astronomical twilight from 2019 Sep 20 to 2022 March 7 and during morning astronomical twilight sky from 2019 Sep 21 to 2022 Sep 29. More than 46,000 exposures were taken in evening and morning astronomical twilight within 31 to 66 degrees from the Sun with an r-band limiting magnitude between 18.1 and 20.9. The twilight pointings show a slight seasonal dependence in limiting magnitude and ability to point closer towards the Sun, with limiting magnitude slightly improving during summer. In total, the one Aylo, (594913) 'Ayló'chaxnim, and 4 Atiras, 2020 OV1, 2021 BS1, 2021 PB2, and 2021 VR3, were discovered in evening and morning twilight observations. Additional twilight survey discoveries also include 6 long-period comets: C/2020 T2, C/2020 V2, C/2021 D2, C/2021 E3, C/2022 E3, and C/2022 P3, and two short-period comets: P/2021 N1 and P/2022 P2 using deep learning comet detection pipelines. The P48/ZTF twilight survey also recovered 11 known Atiras, one Aylo, three short-period comes, two long-period comets, and one interstellar object. Lastly, the Vera Rubin Observatory will conduct a twilight survey starting in its first year of operations and will cover the sky within 45 degrees of the Sun. Twilight surveys such as those by ZTF and future surveys will provide opportunities for discovering asteroids inside the orbits of Earth and Venus.",
        "subjects": "Earth and Planetary Astrophysics, Instrumentation and Methods for Astrophysics, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 17:56:45 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.777227"
    },
    {
        "index": "#72",
        "title": "Identification and Localization of Cometary Activity in Solar System Objects with Machine Learning",
        "link": "/arxiv/2409.15261",
        "arxiv_id": "2409.15261",
        "authors": "Bryce T. Bolin, Michael W. Coughlin",
        "summary": "In this chapter, we will discuss the use of Machine Learning methods for the identification and localization of cometary activity for Solar System objects in ground and in space-based wide-field all-sky surveys. We will begin the chapter by discussing the challenges of identifying known and unknown active, extended Solar System objects in the presence of stellar-type sources and the application of classical pre-ML identification techniques and their limitations. We will then transition to the discussion of implementing ML techniques to address the challenge of extended object identification. We will finish with prospective future methods and the application to future surveys such as the Vera C. Rubin Observatory.",
        "subjects": "Earth and Planetary Astrophysics, Instrumentation and Methods for Astrophysics, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 17:56:32 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.777440"
    },
    {
        "index": "#76",
        "title": "Domino: Eliminating Communication in LLM Training via Generic Tensor Slicing and Overlapping",
        "link": "/arxiv/2409.15241",
        "arxiv_id": "2409.15241",
        "authors": "Guanhua Wang, Chengming Zhang, Zheyu Shen, Ang Li, Olatunji Ruwase",
        "summary": "Given the popularity of generative AI, Large Language Models (LLMs) often consume hundreds or thousands of GPUs for parallelizing and accelerating the training process. Communication overhead becomes more pronounced when training LLMs at scale. To eliminate communication overhead in distributed LLM training, we propose Domino, which provides a generic scheme to hide communication behind computation. By breaking data dependency of a single batch training into smaller independent pieces, Domino pipelines these independent pieces training and provides generic strategy of fine-grained communication and computation overlapping. Extensive results show that, comparing with Megatron-LM, Domino achieves up to 1.3x speedup for LLM training on Nvidia DGX-H100 GPUs.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 17:38:52 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.778368"
    },
    {
        "index": "#78",
        "title": "AutoAPIEval: A Framework for Automated Evaluation of LLMs in API-Oriented Code Generation",
        "link": "/arxiv/2409.15228",
        "arxiv_id": "2409.15228",
        "authors": "Yixi Wu, Pengfei He, Zehao Wang, Shaowei Wang, Yuan Tian, Tse-Hsun, Chen",
        "summary": "Large language models (LLMs) like GitHub Copilot and ChatGPT have emerged as powerful tools for code generation, significantly enhancing productivity and accelerating software development. However, existing benchmarks primarily focus on general code generation without considering API-oriented code generation, i.e., generating code that invokes APIs from specific libraries. Given the growing demand for API-oriented code generation, there is a pressing need for a systematic and automated approach to evaluate LLM on API-oriented code generation. To address this gap, we propose AutoAPIEval, a lightweight and automated framework designed to evaluate the capabilities of LLMs in API-oriented code generation. Our framework works with any library that provides API documentation and focuses on two unit tasks: API recommendation and code example generation, along with four metrics to evaluate the generated APIs and code examples, such as the proportion of incorrect API recommendations for Task 1, and the proportion of code examples where no specific API is invoked and uncompilable/unexecutable code examples for Task 2. In addition, we conducted a case study on three LLMs (ChatGPT, MagiCoder, and DeepSeek Coder) and Java Runtime Environment 8 to demonstrate the framework's effectiveness. Our findings reveal substantial variability in LLM performance across tasks, with ChatGPT adhering better to instructions, while sharing similar effectiveness in code example generation with its counterparts (i.e., MagiCoder and DeekSeek Coder). We also identify key factors associated with code quality, such as API popularity and model confidence, and build classifiers that achieve high accuracy in detecting incorrect API recommendations and erroneous code examples. Retrieval-augmented generation enhances the quality of code generated by LLMs, though its effectiveness varies across different LLMs.",
        "subjects": "Software Engineering, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 17:22:09 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.778789"
    },
    {
        "index": "#83",
        "title": "Location is Key: Leveraging Large Language Model for Functional Bug Localization in Verilog",
        "link": "/arxiv/2409.15186",
        "arxiv_id": "2409.15186",
        "authors": "Bingkun Yao, Ning Wang, Jie Zhou, Xi Wang, Hong Gao, Zhe Jiang, Nan Guan",
        "summary": "Bug localization in Verilog code is a crucial and time-consuming task during the verification of hardware design. Since introduction, Large Language Models (LLMs) have showed their strong programming capabilities. However, no work has yet considered using LLMs for bug localization in Verilog code. This paper presents Location-is-Key, an opensource LLM solution to locate functional errors in Verilog snippets. LiK achieves high localization accuracy, with a pass@1 localization accuracy of 93.3% on our test dataset based on RTLLM, surpassing GPT-4's 77.9% and comparable to Claude-3.5's 90.8%. Additionally, the bug location obtained by LiK significantly improves GPT-3.5's bug repair efficiency (Functional pass@1 increased from 40.39% to 58.92%), highlighting the importance of bug localization in LLM-based Verilog debugging. Compared to existing methods, LiK only requires the design specification and the erroneous code snippet, without the need for testbenches, assertions, or any other EDA tools. This research demonstrates the feasibility of using LLMs for Verilog error localization, thus providing a new direction for automatic Verilog code debugging.",
        "subjects": "Hardware Architecture, Artificial Intelligence",
        "date": "2024-09-23 16:38:53 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.779875"
    },
    {
        "index": "#84",
        "title": "Skills Made to Order: Efficient Acquisition of Robot Cooking Skills Guided by Multiple Forms of Internet Data",
        "link": "/arxiv/2409.15172",
        "arxiv_id": "2409.15172",
        "authors": "Mrinal Verghese, Christopher Atkeson",
        "summary": "This study explores the utility of various internet data sources to select among a set of template robot behaviors to perform skills. Learning contact-rich skills involving tool use from internet data sources has typically been challenging due to the lack of physical information such as contact existence, location, areas, and force in this data. Prior works have generally used internet data and foundation models trained on this data to generate low-level robot behavior. We hypothesize that these data and models may be better suited to selecting among a set of basic robot behaviors to perform these contact-rich skills. We explore three methods of template selection: querying large language models, comparing video of robot execution to retrieved human video using features from a pretrained video encoder common in prior work, and performing the same comparison using features from an optic flow encoder trained on internet data. Our results show that LLMs are surprisingly capable template selectors despite their lack of visual information, optical flow encoding significantly outperforms video encoders trained with an order of magnitude more data, and important synergies exist between various forms of internet data for template selection. By exploiting these synergies, we create a template selector using multiple forms of internet data that achieves a 79\\% success rate on a set of 16 different cooking skills involving tool-use.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 16:25:44 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.780100"
    },
    {
        "index": "#85",
        "title": "DeepCloth-ROB$^2_{\\text{QS}}$P&P: Towards a Robust Robot Deployment for Quasi-Static Pick-and-Place Cloth-Shaping Neural Controllers",
        "link": "/arxiv/2409.15159",
        "arxiv_id": "2409.15159",
        "authors": "Halid Abdulrahim Kadi, Jose Alex Chandy, Luis Figueredo, Kasim Terzić, Praminda Caleb-Solly",
        "summary": "The fidelity gap between simulation-trained vision-based data-driven cloth neural controllers and real-world operation impedes reliable deployment of methods from simulation into physical trials. Real-world grasping errors, such as misgrasping and multilayer grasping, degrade their performance; additionally, some fabrics made of synthetic material also tend to stick to the commonly employed Franka Emika Panda's original gripper. Different approaches adopted various strategies to resolve these problems, further complicating real-world comparison between state-of-the-art methods. We propose DeepCloth-ROB$^2_{\\text{QS}}$P&P with a simulation-to-reality transfer strategy Towel-Sim2Real and a cloth grasping protocol to consider and mitigate these grasping errors for robustly deploying quasi-static pick-and-place neural controllers in cloth shaping and demonstrate its generalisability across different deep-learning methods, fabric contexts and robot platforms. Our approach allows us to compare multiple neural controllers in a real environment for the first time, offering valuable insights to the cloth manipulation community.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2024-09-23 16:08:16 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.780306"
    },
    {
        "index": "#87",
        "title": "RMCBench: Benchmarking Large Language Models' Resistance to Malicious Code",
        "link": "/arxiv/2409.15154",
        "arxiv_id": "2409.15154",
        "authors": "Jiachi Chen, Qingyuan Zhong, Yanlin Wang, Kaiwen Ning, Yongkun Liu, Zenan Xu, Zhe Zhao, Ting Chen, Zibin Zheng",
        "summary": "The emergence of Large Language Models (LLMs) has significantly influenced various aspects of software development activities. Despite their benefits, LLMs also pose notable risks, including the potential to generate harmful content and being abused by malicious developers to create malicious code. Several previous studies have focused on the ability of LLMs to resist the generation of harmful content that violates human ethical standards, such as biased or offensive content. However, there is no research evaluating the ability of LLMs to resist malicious code generation. To fill this gap, we propose RMCBench, the first benchmark comprising 473 prompts designed to assess the ability of LLMs to resist malicious code generation. This benchmark employs two scenarios: a text-to-code scenario, where LLMs are prompted with descriptions to generate code, and a code-to-code scenario, where LLMs translate or complete existing malicious code. Based on RMCBench, we conduct an empirical study on 11 representative LLMs to assess their ability to resist malicious code generation. Our findings indicate that current LLMs have a limited ability to resist malicious code generation with an average refusal rate of 40.36% in text-to-code scenario and 11.52% in code-to-code scenario. The average refusal rate of all LLMs in RMCBench is only 28.71%; ChatGPT-4 has a refusal rate of only 35.73%. We also analyze the factors that affect LLMs' ability to resist malicious code generation and provide implications for developers to enhance model robustness.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2024-09-23 16:03:26 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.786007"
    },
    {
        "index": "#88",
        "title": "COHERENT: Collaboration of Heterogeneous Multi-Robot System with Large Language Models",
        "link": "/arxiv/2409.15146",
        "arxiv_id": "2409.15146",
        "authors": "Kehui Liu, Zixin Tang, Dong Wang, Zhigang Wang, Bin Zhao, Xuelong Li",
        "summary": "Leveraging the powerful reasoning capabilities of large language models (LLMs), recent LLM-based robot task planning methods yield promising results. However, they mainly focus on single or multiple homogeneous robots on simple tasks. Practically, complex long-horizon tasks always require collaborations among multiple heterogeneous robots especially with more complex action spaces, which makes these tasks more challenging. To this end, we propose COHERENT, a novel LLM-based task planning framework for collaboration of heterogeneous multi-robot systems including quadrotors, robotic dogs, and robotic arms. Specifically, a Proposal-Execution-Feedback-Adjustment (PEFA) mechanism is designed to decompose and assign actions for individual robots, where a centralized task assigner makes a task planning proposal to decompose the complex task into subtasks, and then assigns subtasks to robot executors. Each robot executor selects a feasible action to implement the assigned subtask and reports self-reflection feedback to the task assigner for plan adjustment. The PEFA loops until the task is completed. Moreover, we create a challenging heterogeneous multi-robot task planning benchmark encompassing 100 complex long-horizon tasks. The experimental results show that our work surpasses the previous methods by a large margin in terms of success rate and execution efficiency. The experimental videos, code, and benchmark are released at https://github.com/MrKeee/COHERENT.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2024-09-23 15:53:41 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.786253"
    },
    {
        "index": "#89",
        "title": "CAMAL: Optimizing LSM-trees via Active Learning",
        "link": "/arxiv/2409.15130",
        "arxiv_id": "2409.15130",
        "authors": "Weiping Yu, Siqiang Luo, Zihao Yu, Gao Cong",
        "summary": "We use machine learning to optimize LSM-tree structure, aiming to reduce the cost of processing various read/write operations. We introduce a new approach Camal, which boasts the following features: (1) ML-Aided: Camal is the first attempt to apply active learning to tune LSM-tree based key-value stores. The learning process is coupled with traditional cost models to improve the training process; (2) Decoupled Active Learning: backed by rigorous analysis, Camal adopts active learning paradigm based on a decoupled tuning of each parameter, which further accelerates the learning process; (3) Easy Extrapolation: Camal adopts an effective mechanism to incrementally update the model with the growth of the data size; (4) Dynamic Mode: Camal is able to tune LSM-tree online under dynamically changing workloads; (5) Significant System Improvement: By integrating Camal into a full system RocksDB, the system performance improves by 28% on average and up to 8x compared to a state-of-the-art RocksDB design.",
        "subjects": "Databases, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 15:35:23 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.786497"
    },
    {
        "index": "#91",
        "title": "Robust Federated Learning Over the Air: Combating Heavy-Tailed Noise with Median Anchored Clipping",
        "link": "/arxiv/2409.15100",
        "arxiv_id": "2409.15100",
        "authors": "Jiaxing Li, Zihan Chen, Kai Fong Ernest Chong, Bikramjit Das, Tony Q. S. Quek, Howard H. Yang",
        "summary": "Leveraging over-the-air computations for model aggregation is an effective approach to cope with the communication bottleneck in federated edge learning. By exploiting the superposition properties of multi-access channels, this approach facilitates an integrated design of communication and computation, thereby enhancing system privacy while reducing implementation costs. However, the inherent electromagnetic interference in radio channels often exhibits heavy-tailed distributions, giving rise to exceptionally strong noise in globally aggregated gradients that can significantly deteriorate the training performance. To address this issue, we propose a novel gradient clipping method, termed Median Anchored Clipping (MAC), to combat the detrimental effects of heavy-tailed noise. We also derive analytical expressions for the convergence rate of model training with analog over-the-air federated learning under MAC, which quantitatively demonstrates the effect of MAC on training performance. Extensive experimental results show that the proposed MAC algorithm effectively mitigates the impact of heavy-tailed noise, hence substantially enhancing system robustness.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-23 15:11:40 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.787000"
    },
    {
        "index": "#93",
        "title": "Zero-Cost Whole-Body Teleoperation for Mobile Manipulation",
        "link": "/arxiv/2409.15095",
        "arxiv_id": "2409.15095",
        "authors": "Daniel Honerkamp, Harsh Mahesheka, Jan Ole von Hartz, Tim Welschehold, Abhinav Valada",
        "summary": "Demonstration data plays a key role in learning complex behaviors and training robotic foundation models. While effective control interfaces exist for static manipulators, data collection remains cumbersome and time intensive for mobile manipulators due to their large number of degrees of freedom. While specialized hardware, avatars, or motion tracking can enable whole-body control, these approaches are either expensive, robot-specific, or suffer from the embodiment mismatch between robot and human demonstrator. In this work, we present MoMa-Teleop, a novel teleoperation method that delegates the base motions to a reinforcement learning agent, leaving the operator to focus fully on the task-relevant end-effector motions. This enables whole-body teleoperation of mobile manipulators with zero additional hardware or setup costs via standard interfaces such as joysticks or hand guidance. Moreover, the operator is not bound to a tracked workspace and can move freely with the robot over spatially extended tasks. We demonstrate that our approach results in a significant reduction in task completion time across a variety of robots and tasks. As the generated data covers diverse whole-body motions without embodiment mismatch, it enables efficient imitation learning. By focusing on task-specific end-effector motions, our approach learns skills that transfer to unseen settings, such as new obstacles or changed object positions, from as little as five demonstrations. We make code and videos available at http://moma-teleop.cs.uni-freiburg.de.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2024-09-23 15:09:45 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.787494"
    },
    {
        "index": "#99",
        "title": "AlphaZip: Neural Network-Enhanced Lossless Text Compression",
        "link": "/arxiv/2409.15046",
        "arxiv_id": "2409.15046",
        "authors": "Swathi Shree Narashiman, Nitin Chandrachoodan",
        "summary": "Data compression continues to evolve, with traditional information theory methods being widely used for compressing text, images, and videos. Recently, there has been growing interest in leveraging Generative AI for predictive compression techniques. This paper introduces a lossless text compression approach using a Large Language Model (LLM). The method involves two key steps: first, prediction using a dense neural network architecture, such as a transformer block; second, compressing the predicted ranks with standard compression algorithms like Adaptive Huffman, LZ77, or Gzip. Extensive analysis and benchmarking against conventional information-theoretic baselines demonstrate that neural compression offers improved performance.",
        "subjects": "Information Theory, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 14:21:06 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.788856"
    },
    {
        "index": "#102",
        "title": "A Diagonal Structured State Space Model on Loihi 2 for Efficient Streaming Sequence Processing",
        "link": "/arxiv/2409.15022",
        "arxiv_id": "2409.15022",
        "authors": "Svea Marie Meyer, Philipp Weidel, Philipp Plank, Leobardo Campos-Macias, Sumit Bam Shrestha, Philipp Stratmann, Mathis Richter",
        "summary": "Deep State-Space Models (SSM) demonstrate state-of-the art performance on long-range sequence modeling tasks. While the recurrent structure of SSMs can be efficiently implemented as a convolution or as a parallel scan during training, recurrent token-by-token processing cannot currently be implemented efficiently on GPUs. Here, we demonstrate efficient token-by-token inference of the SSM S4D on Intel's Loihi 2 state-of-the-art neuromorphic processor. We compare this first ever neuromorphic-hardware implementation of an SSM on sMNIST, psMNIST, and sCIFAR to a recurrent and a convolutional implementation of S4D on Jetson Orin Nano (Jetson). While we find Jetson to perform better in an offline sample-by-sample based batched processing mode, Loihi 2 outperforms during token-by-token based processing, where it consumes 1000 times less energy with a 75 times lower latency and a 75 times higher throughput compared to the recurrent implementation of S4D on Jetson. This opens up new avenues towards efficient real-time streaming applications of SSMs.",
        "subjects": "Machine Learning, Artificial Intelligence, Emerging Technologies, Neural and Evolutionary Computing",
        "date": "2024-09-23 13:50:11 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.789484"
    },
    {
        "index": "#105",
        "title": "Method of Equal Shares with Bounded Overspending",
        "link": "/arxiv/2409.15005",
        "arxiv_id": "2409.15005",
        "authors": "Georgios Papasotiropoulos, Seyedeh Zeinab Pishbin, Oskar Skibski, Piotr Skowron, Tomasz Wąs",
        "summary": "In participatory budgeting (PB), voters decide through voting which subset of projects to fund within a given budget. Proportionality in the context of PB is crucial to ensure equal treatment of all groups of voters. However, pure proportional rules can sometimes lead to suboptimal outcomes. We introduce the Method of Equal Shares with Bounded Overspending (BOS Equal Shares), a robust variant of Equal Shares that balances proportionality and efficiency. BOS Equal Shares addresses inefficiencies inherent in strict proportionality guarantees yet still provides good proportionality similar to the original Method of Equal Shares. In the course of the analysis, we also discuss a fractional variant of the method which allows for partial funding of projects.",
        "subjects": "Computer Science and Game Theory, Artificial Intelligence, Multiagent Systems",
        "date": "2024-09-23 13:30:25 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.790071"
    },
    {
        "index": "#109",
        "title": "On The Specialization of Neural Modules",
        "link": "/arxiv/2409.14981",
        "arxiv_id": "2409.14981",
        "authors": "Devon Jarvis, Richard Klein, Benjamin Rosman, Andrew M. Saxe",
        "summary": "A number of machine learning models have been proposed with the goal of achieving systematic generalization: the ability to reason about new situations by combining aspects of previous experiences. These models leverage compositional architectures which aim to learn specialized modules dedicated to structures in a task that can be composed to solve novel problems with similar structures. While the compositionality of these architectures is guaranteed by design, the modules specializing is not. Here we theoretically study the ability of network modules to specialize to useful structures in a dataset and achieve systematic generalization. To this end we introduce a minimal space of datasets motivated by practical systematic generalization benchmarks. From this space of datasets we present a mathematical definition of systematicity and study the learning dynamics of linear neural modules when solving components of the task. Our results shed light on the difficulty of module specialization, what is required for modules to successfully specialize, and the necessity of modular architectures to achieve systematicity. Finally, we confirm that the theoretical results in our tractable setting generalize to more complex datasets and non-linear architectures.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-23 12:58:11 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.790895"
    },
    {
        "index": "#110",
        "title": "Deep Reinforcement Learning-based Obstacle Avoidance for Robot Movement in Warehouse Environments",
        "link": "/arxiv/2409.14972",
        "arxiv_id": "2409.14972",
        "authors": "Keqin Li, Jiajing Chen, Denzhi Yu, Tao Dajun, Xinyu Qiu, Lian Jieting, Sun Baiwei, Zhang Shengyuan, Zhenyu Wan, Ran Ji, Bo Hong, Fanghao Ni",
        "summary": "At present, in most warehouse environments, the accumulation of goods is complex, and the management personnel in the control of goods at the same time with the warehouse mobile robot trajectory interaction, the traditional mobile robot can not be very good on the goods and pedestrians to feed back the correct obstacle avoidance strategy, in order to control the mobile robot in the warehouse environment efficiently and friendly to complete the obstacle avoidance task, this paper proposes a deep reinforcement learning based on the warehouse environment, the mobile robot obstacle avoidance Algorithm. Firstly, for the insufficient learning ability of the value function network in the deep reinforcement learning algorithm, the value function network is improved based on the pedestrian interaction, the interaction information between pedestrians is extracted through the pedestrian angle grid, and the temporal features of individual pedestrians are extracted through the attention mechanism, so that we can learn to obtain the relative importance of the current state and the historical trajectory state as well as the joint impact on the robot's obstacle avoidance strategy, which provides an opportunity for the learning of multi-layer perceptual machines afterwards. Secondly, the reward function of reinforcement learning is designed based on the spatial behaviour of pedestrians, and the robot is punished for the state where the angle changes too much, so as to achieve the requirement of comfortable obstacle avoidance; Finally, the feasibility and effectiveness of the deep reinforcement learning-based mobile robot obstacle avoidance algorithm in the warehouse environment in the complex environment of the warehouse are verified through simulation experiments.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2024-09-23 12:42:35 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.792738"
    },
    {
        "index": "#112",
        "title": "KARMA: Augmenting Embodied AI Agents with Long-and-short Term Memory Systems",
        "link": "/arxiv/2409.14908",
        "arxiv_id": "2409.14908",
        "authors": "Zixuan Wang, Bo Yu, Junzhe Zhao, Wenhao Sun, Sai Hou, Shuai Liang, Xing Hu, Yinhe Han, Yiming Gan",
        "summary": "Embodied AI agents responsible for executing interconnected, long-sequence household tasks often face difficulties with in-context memory, leading to inefficiencies and errors in task execution. To address this issue, we introduce KARMA, an innovative memory system that integrates long-term and short-term memory modules, enhancing large language models (LLMs) for planning in embodied agents through memory-augmented prompting. KARMA distinguishes between long-term and short-term memory, with long-term memory capturing comprehensive 3D scene graphs as representations of the environment, while short-term memory dynamically records changes in objects' positions and states. This dual-memory structure allows agents to retrieve relevant past scene experiences, thereby improving the accuracy and efficiency of task planning. Short-term memory employs strategies for effective and adaptive memory replacement, ensuring the retention of critical information while discarding less pertinent data. Compared to state-of-the-art embodied agents enhanced with memory, our memory-augmented embodied AI agent improves success rates by 1.3x and 2.3x in Composite Tasks and Complex Tasks within the AI2-THOR simulator, respectively, and enhances task execution efficiency by 3.4x and 62.7x. Furthermore, we demonstrate that KARMA's plug-and-play capability allows for seamless deployment on real-world robotic systems, such as mobile manipulation platforms.Through this plug-and-play memory system, KARMA significantly enhances the ability of embodied agents to generate coherent and contextually appropriate plans, making the execution of complex household tasks more efficient. The experimental videos from the work can be found at https://youtu.be/4BT7fnw9ehs.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2024-09-23 11:02:46 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.793185"
    },
    {
        "index": "#114",
        "title": "Deploying Open-Source Large Language Models: A performance Analysis",
        "link": "/arxiv/2409.14887",
        "arxiv_id": "2409.14887",
        "authors": "Yannis Bendi-Ouis, Dan Dutarte, Xavier Hinaut",
        "summary": "Since the release of ChatGPT in November 2023, large language models (LLMs) have seen considerable success, including in the open-source community, with many open-weight models available. However, the requirements to deploy such a service are often unknown and difficult to evaluate in advance. To facilitate this process, we conducted numerous tests at the Centre Inria de l'Université de Bordeaux. In this article, we propose a comparison of the performance of several models of different sizes (mainly Mistral and LLaMa) depending on the available GPUs, using vLLM, a Python library designed to optimize the inference of these models. Our results provide valuable information for private and public groups wishing to deploy LLMs, allowing them to evaluate the performance of different models based on their available hardware. This study thus contributes to facilitating the adoption and use of these large language models in various application domains.",
        "subjects": "Performance, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 10:35:57 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.793581"
    },
    {
        "index": "#118",
        "title": "FedSlate:A Federated Deep Reinforcement Learning Recommender System",
        "link": "/arxiv/2409.14872",
        "arxiv_id": "2409.14872",
        "authors": "Yongxin Deng, Xiaoyu Tan, Xihe Qiu, Yaochu Jin",
        "summary": "Reinforcement learning methods have been used to optimize long-term user engagement in recommendation systems. However, existing reinforcement learning-based recommendation systems do not fully exploit the relevance of individual user behavior across different platforms. One potential solution is to aggregate data from various platforms in a centralized location and use the aggregated data for training. However, this approach raises economic and legal concerns, including increased communication costs and potential threats to user privacy. To address these challenges, we propose \\textbf{FedSlate}, a federated reinforcement learning recommendation algorithm that effectively utilizes information that is prohibited from being shared at a legal level. We employ the SlateQ algorithm to assist FedSlate in learning users' long-term behavior and evaluating the value of recommended content. We extend the existing application scope of recommendation systems from single-user single-platform to single-user multi-platform and address cross-platform learning challenges by introducing federated learning. We use RecSim to construct a simulation environment for evaluating FedSlate and compare its performance with state-of-the-art benchmark recommendation models. Experimental results demonstrate the superior effects of FedSlate over baseline methods in various environmental settings, and FedSlate facilitates the learning of recommendation strategies in scenarios where baseline methods are completely inapplicable. Code is available at \\textit{https://github.com/TianYaDY/FedSlate}.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2024-09-23 10:10:24 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.794595"
    },
    {
        "index": "#119",
        "title": "A novel agent with formal goal-reaching guarantees: an experimental study with a mobile robot",
        "link": "/arxiv/2409.14867",
        "arxiv_id": "2409.14867",
        "authors": "Grigory Yaremenko, Dmitrii Dobriborsci, Roman Zashchitin, Ruben Contreras Maestre, Ngoc Quoc Huy Hoang, Pavel Osinenko",
        "summary": "Reinforcement Learning (RL) has been shown to be effective and convenient for a number of tasks in robotics. However, it requires the exploration of a sufficiently large number of state-action pairs, many of which may be unsafe or unimportant. For instance, online model-free learning can be hazardous and inefficient in the absence of guarantees that a certain set of desired states will be reached during an episode. An increasingly common approach to address safety involves the addition of a shielding system that constrains the RL actions to a safe set of actions. In turn, a difficulty for such frameworks is how to effectively couple RL with the shielding system to make sure the exploration is not excessively restricted. This work presents a novel safe model-free RL agent called Critic As Lyapunov Function (CALF) and showcases how CALF can be used to improve upon control baselines in robotics in an efficient and convenient fashion while ensuring guarantees of stable goal reaching. The latter is a crucial part of safety, as seen generally. With CALF all state-action pairs remain explorable and yet reaching of desired goal states is formally guaranteed. Formal analysis is provided that shows the goal stabilization-ensuring properties of CALF and a set of real-world and numerical experiments with a non-holonomic wheeled mobile robot (WMR) TurtleBot3 Burger confirmed the superiority of CALF over such a well-established RL agent as proximal policy optimization (PPO), and a modified version of SARSA in a few-episode setting in terms of attained total cost.",
        "subjects": "Robotics, Artificial Intelligence, Dynamical Systems, Optimization and Control",
        "date": "2024-09-23 10:04:28 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.794852"
    },
    {
        "index": "#120",
        "title": "Effective and Evasive Fuzz Testing-Driven Jailbreaking Attacks against LLMs",
        "link": "/arxiv/2409.14866",
        "arxiv_id": "2409.14866",
        "authors": "Xueluan Gong, Mingzhe Li, Yilin Zhang, Fengyuan Ran, Chen Chen, Yanjiao Chen, Qian Wang, Kwok-Yan Lam",
        "summary": "Large Language Models (LLMs) have excelled in various tasks but are still vulnerable to jailbreaking attacks, where attackers create jailbreak prompts to mislead the model to produce harmful or offensive content. Current jailbreak methods either rely heavily on manually crafted templates, which pose challenges in scalability and adaptability, or struggle to generate semantically coherent prompts, making them easy to detect. Additionally, most existing approaches involve lengthy prompts, leading to higher query costs.In this paper, to remedy these challenges, we introduce a novel jailbreaking attack framework, which is an automated, black-box jailbreaking attack framework that adapts the black-box fuzz testing approach with a series of customized designs. Instead of relying on manually crafted templates, our method starts with an empty seed pool, removing the need to search for any related jailbreaking templates. We also develop three novel question-dependent mutation strategies using an LLM helper to generate prompts that maintain semantic coherence while significantly reducing their length. Additionally, we implement a two-level judge module to accurately detect genuine successful jailbreaks. We evaluated our method on 7 representative LLMs and compared it with 5 state-of-the-art jailbreaking attack strategies. For proprietary LLM APIs, such as GPT-3.5 turbo, GPT-4, and Gemini-Pro, our method achieves attack success rates of over 90%, 80%, and 74%, respectively, exceeding existing baselines by more than 60%. Additionally, our method can maintain high semantic coherence while significantly reducing the length of jailbreak prompts. When targeting GPT-4, our method can achieve over 78\\% attack success rate even with 100 tokens. Moreover, our method demonstrates transferability and is robust to state-of-the-art defenses. We will open-source our codes upon publication.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2024-09-23 10:03:09 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.795069"
    },
    {
        "index": "#121",
        "title": "Embedding Knowledge Graph in Function Space",
        "link": "/arxiv/2409.14857",
        "arxiv_id": "2409.14857",
        "authors": "Louis Mozart Kamdem Teyou, Caglar Demir, Axel-Cyrille Ngonga Ngomo",
        "summary": "We introduce a novel embedding method diverging from conventional approaches by operating within function spaces of finite dimension rather than finite vector space, thus departing significantly from standard knowledge graph embedding techniques. Initially employing polynomial functions to compute embeddings, we progress to more intricate representations using neural networks with varying layer complexities. We argue that employing functions for embedding computation enhances expressiveness and allows for more degrees of freedom, enabling operations such as composition, derivatives and primitive of entities representation. Additionally, we meticulously outline the step-by-step construction of our approach and provide code for reproducibility, thereby facilitating further exploration and application in the field.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 09:49:57 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.795263"
    },
    {
        "index": "#125",
        "title": "Identify As A Human Does: A Pathfinder of Next-Generation Anti-Cheat Framework for First-Person Shooter Games",
        "link": "/arxiv/2409.14830",
        "arxiv_id": "2409.14830",
        "authors": "Jiayi Zhang, Chenxin Sun, Yue Gu, Qingyu Zhang, Jiayi Lin, Xiaojiang Du, Chenxiong Qian",
        "summary": "The gaming industry has experienced substantial growth, but cheating in online games poses a significant threat to the integrity of the gaming experience. Cheating, particularly in first-person shooter (FPS) games, can lead to substantial losses for the game industry. Existing anti-cheat solutions have limitations, such as client-side hardware constraints, security risks, server-side unreliable methods, and both-sides suffer from a lack of comprehensive real-world datasets. To address these limitations, the paper proposes HAWK, a server-side FPS anti-cheat framework for the popular game CS:GO. HAWK utilizes machine learning techniques to mimic human experts' identification process, leverages novel multi-view features, and it is equipped with a well-defined workflow. The authors evaluate HAWK with the first large and real-world datasets containing multiple cheat types and cheating sophistication, and it exhibits promising efficiency and acceptable overheads, shorter ban times compared to the in-use anti-cheat, a significant reduction in manual labor, and the ability to capture cheaters who evaded official inspections.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 09:00:07 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.796376"
    },
    {
        "index": "#127",
        "title": "Towards Real-world Deployment of NILM Systems: Challenges and Practices",
        "link": "/arxiv/2409.14821",
        "arxiv_id": "2409.14821",
        "authors": "Junyu Xue, Yu Zhang, Xudong Wang, Yi Wang, Guoming Tang",
        "summary": "Non-intrusive load monitoring (NILM), as a key load monitoring technology, can much reduce the deployment cost of traditional power sensors. Previous research has largely focused on developing cloud-exclusive NILM algorithms, which often result in high computation costs and significant service delays. To address these issues, we propose a three-tier framework to enhance the real-world applicability of NILM systems through edge-cloud collaboration. Considering the computational resources available at both the edge and cloud, we implement a lightweight NILM model at the edge and a deep learning based model at the cloud, respectively. In addition to the differential model implementations, we also design a NILM-specific deployment scheme that integrates Gunicorn and NGINX to bridge the gap between theoretical algorithms and practical applications. To verify the effectiveness of the proposed framework, we apply real-world NILM scenario settings and implement the entire process of data acquisition, model training, and system deployment. The results demonstrate that our framework can achieve high decomposition accuracy while significantly reducing the cloud workload and communication overhead under practical considerations.",
        "subjects": "Systems and Control, Artificial Intelligence",
        "date": "2024-09-23 08:54:05 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.796831"
    },
    {
        "index": "#130",
        "title": "VARADE: a Variational-based AutoRegressive model for Anomaly Detection on the Edge",
        "link": "/arxiv/2409.14816",
        "arxiv_id": "2409.14816",
        "authors": "Alessio Mascolini, Sebastiano Gaiardelli, Francesco Ponzio, Nicola Dall'Ora, Enrico Macii, Sara Vinco, Santa Di Cataldo, Franco Fummi",
        "summary": "Detecting complex anomalies on massive amounts of data is a crucial task in Industry 4.0, best addressed by deep learning. However, available solutions are computationally demanding, requiring cloud architectures prone to latency and bandwidth issues. This work presents VARADE, a novel solution implementing a light autoregressive framework based on variational inference, which is best suited for real-time execution on the edge. The proposed approach was validated on a robotic arm, part of a pilot production line, and compared with several state-of-the-art algorithms, obtaining the best trade-off between anomaly detection accuracy, power consumption and inference frequency on two different edge platforms.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-23 08:46:15 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.797503"
    },
    {
        "index": "#131",
        "title": "Research on Dynamic Data Flow Anomaly Detection based on Machine Learning",
        "link": "/arxiv/2409.14796",
        "arxiv_id": "2409.14796",
        "authors": "Liyang Wang, Yu Cheng, Hao Gong, Jiacheng Hu, Xirui Tang, Iris Li",
        "summary": "The sophistication and diversity of contemporary cyberattacks have rendered the use of proxies, gateways, firewalls, and encrypted tunnels as a standalone defensive strategy inadequate. Consequently, the proactive identification of data anomalies has emerged as a prominent area of research within the field of data security. The majority of extant studies concentrate on sample equilibrium data, with the consequence that the detection effect is not optimal in the context of unbalanced data. In this study, the unsupervised learning method is employed to identify anomalies in dynamic data flows. Initially, multi-dimensional features are extracted from real-time data, and a clustering algorithm is utilised to analyse the patterns of the data. This enables the potential outliers to be automatically identified. By clustering similar data, the model is able to detect data behaviour that deviates significantly from normal traffic without the need for labelled data. The results of the experiments demonstrate that the proposed method exhibits high accuracy in the detection of anomalies across a range of scenarios. Notably, it demonstrates robust and adaptable performance, particularly in the context of unbalanced data.",
        "subjects": "Machine Learning, Artificial Intelligence, Cryptography and Security",
        "date": "2024-09-23 08:19:15 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.797884"
    },
    {
        "index": "#138",
        "title": "PROMPTFUZZ: Harnessing Fuzzing Techniques for Robust Testing of Prompt Injection in LLMs",
        "link": "/arxiv/2409.14729",
        "arxiv_id": "2409.14729",
        "authors": "Jiahao Yu, Yangguang Shao, Hanwen Miao, Junzheng Shi, Xinyu Xing",
        "summary": "Large Language Models (LLMs) have gained widespread use in various applications due to their powerful capability to generate human-like text. However, prompt injection attacks, which involve overwriting a model's original instructions with malicious prompts to manipulate the generated text, have raised significant concerns about the security and reliability of LLMs. Ensuring that LLMs are robust against such attacks is crucial for their deployment in real-world applications, particularly in critical tasks. In this paper, we propose PROMPTFUZZ, a novel testing framework that leverages fuzzing techniques to systematically assess the robustness of LLMs against prompt injection attacks. Inspired by software fuzzing, PROMPTFUZZ selects promising seed prompts and generates a diverse set of prompt injections to evaluate the target LLM's resilience. PROMPTFUZZ operates in two stages: the prepare phase, which involves selecting promising initial seeds and collecting few-shot examples, and the focus phase, which uses the collected examples to generate diverse, high-quality prompt injections. Using PROMPTFUZZ, we can uncover more vulnerabilities in LLMs, even those with strong defense prompts. By deploying the generated attack prompts from PROMPTFUZZ in a real-world competition, we achieved the 7th ranking out of over 4000 participants (top 0.14%) within 2 hours. Additionally, we construct a dataset to fine-tune LLMs for enhanced robustness against prompt injection attacks. While the fine-tuned model shows improved robustness, PROMPTFUZZ continues to identify vulnerabilities, highlighting the importance of robust testing for LLMs. Our work emphasizes the critical need for effective testing tools and provides a practical framework for evaluating and improving the robustness of LLMs against prompt injection attacks.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2024-09-23 06:08:32 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.799286"
    },
    {
        "index": "#146",
        "title": "zsLLMCode: An Effective Approach for Functional Code Embedding via LLM with Zero-Shot Learning",
        "link": "/arxiv/2409.14644",
        "arxiv_id": "2409.14644",
        "authors": "Zixiang Xian, Chenhui Cui, Rubing Huang, Chunrong Fang, Zhenyu Chen",
        "summary": "Regarding software engineering (SE) tasks, Large language models (LLMs) have the capability of zero-shot learning, which does not require training or fine-tuning, unlike pre-trained models (PTMs). However, LLMs are primarily designed for natural language output, and cannot directly produce intermediate embeddings from source code. They also face some challenges, for example, the restricted context length may prevent them from handling larger inputs, limiting their applicability to many SE tasks; while hallucinations may occur when LLMs are applied to complex downstream tasks. Motivated by the above facts, we propose zsLLMCode, a novel approach that generates functional code embeddings using LLMs. Our approach utilizes LLMs to convert source code into concise summaries through zero-shot learning, which is then transformed into functional code embeddings using specialized embedding models. This unsupervised approach eliminates the need for training and addresses the issue of hallucinations encountered with LLMs. To the best of our knowledge, this is the first approach that combines LLMs and embedding models to generate code embeddings. We conducted experiments to evaluate the performance of our approach. The results demonstrate the effectiveness and superiority of our approach over state-of-the-art unsupervised methods.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2024-09-23 01:03:15 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.800998"
    },
    {
        "index": "#147",
        "title": "Not Only the Last-Layer Features for Spurious Correlations: All Layer Deep Feature Reweighting",
        "link": "/arxiv/2409.14637",
        "arxiv_id": "2409.14637",
        "authors": "Humza Wajid Hameed, Geraldin Nanfack, Eugene Belilovsky",
        "summary": "Spurious correlations are a major source of errors for machine learning models, in particular when aiming for group-level fairness. It has been recently shown that a powerful approach to combat spurious correlations is to re-train the last layer on a balanced validation dataset, isolating robust features for the predictor. However, key attributes can sometimes be discarded by neural networks towards the last layer. In this work, we thus consider retraining a classifier on a set of features derived from all layers. We utilize a recently proposed feature selection strategy to select unbiased features from all the layers. We observe this approach gives significant improvements in worst-group accuracy on several standard benchmarks.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-23 00:31:39 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.801183"
    },
    {
        "index": "#148",
        "title": "Scideator: Human-LLM Scientific Idea Generation Grounded in Research-Paper Facet Recombination",
        "link": "/arxiv/2409.14634",
        "arxiv_id": "2409.14634",
        "authors": "Marissa Radensky, Simra Shahid, Raymond Fok, Pao Siangliulue, Tom Hope, Daniel S. Weld",
        "summary": "The scientific ideation process often involves blending salient aspects of existing papers to create new ideas. To see if large language models (LLMs) can assist this process, we contribute Scideator, a novel mixed-initiative tool for scientific ideation. Starting from a user-provided set of papers, Scideator extracts key facets (purposes, mechanisms, and evaluations) from these and relevant papers, allowing users to explore the idea space by interactively recombining facets to synthesize inventive ideas. Scideator also helps users to gauge idea novelty by searching the literature for potential overlaps and showing automated novelty assessments and explanations. To support these tasks, Scideator introduces four LLM-powered retrieval-augmented generation (RAG) modules: Analogous Paper Facet Finder, Faceted Idea Generator, Idea Novelty Checker, and Idea Novelty Iterator. In a within-subjects user study, 19 computer-science researchers identified significantly more interesting ideas using Scideator compared to a strong baseline combining a scientific search engine with LLM interaction.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2024-09-23 00:09:34 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.801397"
    },
    {
        "index": "#149",
        "title": "Hierarchical end-to-end autonomous navigation through few-shot waypoint detection",
        "link": "/arxiv/2409.14633",
        "arxiv_id": "2409.14633",
        "authors": "Amin Ghafourian, Zhongying CuiZhu, Debo Shi, Ian Chuang, Francois Charette, Rithik Sachdeva, Iman Soltani",
        "summary": "Human navigation is facilitated through the association of actions with landmarks, tapping into our ability to recognize salient features in our environment. Consequently, navigational instructions for humans can be extremely concise, such as short verbal descriptions, indicating a small memory requirement and no reliance on complex and overly accurate navigation tools. Conversely, current autonomous navigation schemes rely on accurate positioning devices and algorithms as well as extensive streams of sensory data collected from the environment. Inspired by this human capability and motivated by the associated technological gap, in this work we propose a hierarchical end-to-end meta-learning scheme that enables a mobile robot to navigate in a previously unknown environment upon presentation of only a few sample images of a set of landmarks along with their corresponding high-level navigation actions. This dramatically simplifies the wayfinding process and enables easy adoption to new environments. For few-shot waypoint detection, we implement a metric-based few-shot learning technique through distribution embedding. Waypoint detection triggers the multi-task low-level maneuver controller module to execute the corresponding high-level navigation action. We demonstrate the effectiveness of the scheme using a small-scale autonomous vehicle on novel indoor navigation tasks in several previously unseen environments.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2024-09-23 00:03:39 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.801647"
    },
    {
        "index": "#151",
        "title": "LatentQGAN: A Hybrid QGAN with Classical Convolutional Autoencoder",
        "link": "/arxiv/2409.14622",
        "arxiv_id": "2409.14622",
        "authors": "Vieloszynski Alexis, Soumaya Cherkaoui, Jean-Frédéric Laprade, Oliver Nahman-Lévesque, Abdallah Aaraba, Shengrui Wang",
        "summary": "Quantum machine learning consists in taking advantage of quantum computations to generate classical data. A potential application of quantum machine learning is to harness the power of quantum computers for generating classical data, a process essential to a multitude of applications such as enriching training datasets, anomaly detection, and risk management in finance. Given the success of Generative Adversarial Networks in classical image generation, the development of its quantum versions has been actively conducted. However, existing implementations on quantum computers often face significant challenges, such as scalability and training convergence issues. To address these issues, we propose LatentQGAN, a novel quantum model that uses a hybrid quantum-classical GAN coupled with an autoencoder. Although it was initially designed for image generation, the LatentQGAN approach holds potential for broader application across various practical data generation tasks. Experimental outcomes on both classical simulators and noisy intermediate scale quantum computers have demonstrated significant performance enhancements over existing quantum methods, alongside a significant reduction in quantum resources overhead.",
        "subjects": "Quantum Physics, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 23:18:06 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.802058"
    },
    {
        "index": "#153",
        "title": "Testing Causal Models with Hidden Variables in Polynomial Delay via Conditional Independencies",
        "link": "/arxiv/2409.14593",
        "arxiv_id": "2409.14593",
        "authors": "Hyunchai Jeong, Adiba Ejaz, Jin Tian, Elias Bareinboim",
        "summary": "Testing a hypothesized causal model against observational data is a key prerequisite for many causal inference tasks. A natural approach is to test whether the conditional independence relations (CIs) assumed in the model hold in the data. While a model can assume exponentially many CIs (with respect to the number of variables), testing all of them is both impractical and unnecessary. Causal graphs, which encode these CIs in polynomial space, give rise to local Markov properties that enable model testing with a significantly smaller subset of CIs. Model testing based on local properties requires an algorithm to list the relevant CIs. However, existing algorithms for realistic settings with hidden variables and non-parametric distributions can take exponential time to produce even a single CI constraint. In this paper, we introduce the c-component local Markov property (C-LMP) for causal graphs with hidden variables. Since C-LMP can still invoke an exponential number of CIs, we develop a polynomial delay algorithm to list these CIs in poly-time intervals. To our knowledge, this is the first algorithm that enables poly-delay testing of CIs in causal graphs with hidden variables against arbitrary data distributions. Experiments on real-world and synthetic data demonstrate the practicality of our algorithm.",
        "subjects": "Machine Learning, Artificial Intelligence, Methodology, Machine Learning",
        "date": "2024-09-22 21:05:56 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.802455"
    },
    {
        "index": "#154",
        "title": "Explainable AI needs formal notions of explanation correctness",
        "link": "/arxiv/2409.14590",
        "arxiv_id": "2409.14590",
        "authors": "Stefan Haufe, Rick Wilming, Benedict Clark, Rustam Zhumagambetov, Danny Panknin, Ahcène Boubekki",
        "summary": "The use of machine learning (ML) in critical domains such as medicine poses risks and requires regulation. One requirement is that decisions of ML systems in high-risk applications should be human-understandable. The field of \"explainable artificial intelligence\" (XAI) seemingly addresses this need. However, in its current form, XAI is unfit to provide quality control for ML; it itself needs scrutiny. Popular XAI methods cannot reliably answer important questions about ML models, their training data, or a given test input. We recapitulate results demonstrating that popular XAI methods systematically attribute importance to input features that are independent of the prediction target. This limits their utility for purposes such as model and data (in)validation, model improvement, and scientific discovery. We argue that the fundamental reason for this limitation is that current XAI methods do not address well-defined problems and are not evaluated against objective criteria of explanation correctness. Researchers should formally define the problems they intend to solve first and then design methods accordingly. This will lead to notions of explanation correctness that can be theoretically verified and objective metrics of explanation performance that can be assessed using ground-truth data.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 20:47:04 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.802665"
    },
    {
        "index": "#157",
        "title": "Combating Spatial Disorientation in a Dynamic Self-Stabilization Task Using AI Assistants",
        "link": "/arxiv/2409.14565",
        "arxiv_id": "2409.14565",
        "authors": "Sheikh Mannan, Paige Hansen, Vivekanand Pandey Vimal, Hannah N. Davies, Paul DiZio, Nikhil Krishnaswamy",
        "summary": "Spatial disorientation is a leading cause of fatal aircraft accidents. This paper explores the potential of AI agents to aid pilots in maintaining balance and preventing unrecoverable losses of control by offering cues and corrective measures that ameliorate spatial disorientation. A multi-axis rotation system (MARS) was used to gather data from human subjects self-balancing in a spaceflight analog condition. We trained models over this data to create \"digital twins\" that exemplified performance characteristics of humans with different proficiency levels. We then trained various reinforcement learning and deep learning models to offer corrective cues if loss of control is predicted. Digital twins and assistant models then co-performed a virtual inverted pendulum (VIP) programmed with identical physics. From these simulations, we picked the 5 best-performing assistants based on task metrics such as crash frequency and mean distance from the direction of balance. These were used in a co-performance study with 20 new human subjects performing a version of the VIP task with degraded spatial information. We show that certain AI assistants were able to improve human performance and that reinforcement-learning based assistants were objectively more effective but rated as less trusted and preferable by humans.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Machine Learning, Multiagent Systems, Robotics",
        "date": "2024-09-09 21:06:22 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.803868"
    },
    {
        "index": "#158",
        "title": "RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph",
        "link": "/arxiv/2409.14556",
        "arxiv_id": "2409.14556",
        "authors": "Linxi Wei, Guorui Xiao, Magdalena Balazinska",
        "summary": "As an important component of data exploration and integration, Column Type Annotation (CTA) aims to label columns of a table with one or more semantic types. With the recent development of Large Language Models (LLMs), researchers have started to explore the possibility of using LLMs for CTA, leveraging their strong zero-shot capabilities. In this paper, we build on this promising work and improve on LLM-based methods for CTA by showing how to use a Knowledge Graph (KG) to augment the context information provided to the LLM. Our approach, called RACOON, combines both pre-trained parametric and non-parametric knowledge during generation to improve LLMs' performance on CTA. Our experiments show that RACOON achieves up to a 0.21 micro F-1 improvement compared against vanilla LLM inference.",
        "subjects": "Databases, Artificial Intelligence",
        "date": "2024-09-22 18:39:27 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.804058"
    },
    {
        "index": "#162",
        "title": "TabGraphs: A Benchmark and Strong Baselines for Learning on Graphs with Tabular Features",
        "link": "/arxiv/2409.14500",
        "arxiv_id": "2409.14500",
        "authors": "Gleb Bazhenov, Oleg Platonov, Liudmila Prokhorenkova",
        "summary": "Tabular machine learning is an important field for industry and science. In this field, table rows are usually treated as independent data samples, but additional information about relations between them is sometimes available and can be used to improve predictive performance. Such information can be naturally modeled with a graph, thus tabular machine learning may benefit from graph machine learning methods. However, graph machine learning models are typically evaluated on datasets with homogeneous node features, which have little in common with heterogeneous mixtures of numerical and categorical features present in tabular datasets. Thus, there is a critical difference between the data used in tabular and graph machine learning studies, which does not allow one to understand how successfully graph models can be transferred to tabular data. To bridge this gap, we propose a new benchmark of diverse graphs with heterogeneous tabular node features and realistic prediction tasks. We use this benchmark to evaluate a vast set of models, including simple methods previously overlooked in the literature. Our experiments show that graph neural networks (GNNs) can indeed often bring gains in predictive performance for tabular data, but standard tabular models also can be adapted to work with graph data by using simple feature preprocessing, which sometimes enables them to compete with and even outperform GNNs. Based on our empirical study, we provide insights for researchers and practitioners in both tabular and graph machine learning fields.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-22 15:53:19 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.804852"
    },
    {
        "index": "#164",
        "title": "Enhancing LLM-based Autonomous Driving Agents to Mitigate Perception Attacks",
        "link": "/arxiv/2409.14488",
        "arxiv_id": "2409.14488",
        "authors": "Ruoyu Song, Muslum Ozgur Ozmen, Hyungsub Kim, Antonio Bianchi, Z. Berkay Celik",
        "summary": "There is a growing interest in integrating Large Language Models (LLMs) with autonomous driving (AD) systems. However, AD systems are vulnerable to attacks against their object detection and tracking (ODT) functions. Unfortunately, our evaluation of four recent LLM agents against ODT attacks shows that the attacks are 63.26% successful in causing them to crash or violate traffic rules due to (1) misleading memory modules that provide past experiences for decision making, (2) limitations of prompts in identifying inconsistencies, and (3) reliance on ground truth perception data. In this paper, we introduce Hudson, a driving reasoning agent that extends prior LLM-based driving systems to enable safer decision making during perception attacks while maintaining effectiveness under benign conditions. Hudson achieves this by first instrumenting the AD software to collect real-time perception results and contextual information from the driving scene. This data is then formalized into a domain-specific language (DSL). To guide the LLM in detecting and making safe control decisions during ODT attacks, Hudson translates the DSL into natural language, along with a list of custom attack detection instructions. Following query execution, Hudson analyzes the LLM's control decision to understand its causal reasoning process. We evaluate the effectiveness of Hudson using a proprietary LLM (GPT-4) and two open-source LLMs (Llama and Gemma) in various adversarial driving scenarios. GPT-4, Llama, and Gemma achieve, on average, an attack detection accuracy of 83. 3%, 63. 6%, and 73. 6%. Consequently, they make safe control decisions in 86.4%, 73.9%, and 80% of the attacks. Our results, following the growing interest in integrating LLMs into AD systems, highlight the strengths of LLMs and their potential to detect and mitigate ODT attacks.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2024-09-22 15:18:59 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.805228"
    },
    {
        "index": "#168",
        "title": "A Visualized Malware Detection Framework with CNN and Conditional GAN",
        "link": "/arxiv/2409.14439",
        "arxiv_id": "2409.14439",
        "authors": "Fang Wang, Hussam Al Hamadi, Ernesto Damiani",
        "summary": "Malware visualization analysis incorporating with Machine Learning (ML) has been proven to be a promising solution for improving security defenses on different platforms. In this work, we propose an integrated framework for addressing common problems experienced by ML utilizers in developing malware detection systems. Namely, a pictorial presentation system with extensions is designed to preserve the identities of benign/malign samples by encoding each variable into binary digits and mapping them into black and white pixels. A conditional Generative Adversarial Network based model is adopted to produce synthetic images and mitigate issues of imbalance classes. Detection models architected by Convolutional Neural Networks are for validating performances while training on datasets with and without artifactual samples. Result demonstrates accuracy rates of 98.51% and 97.26% for these two training scenarios.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning",
        "date": "2024-09-22 13:29:10 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.806161"
    },
    {
        "index": "#171",
        "title": "Challenging the Performance-Interpretability Trade-off: An Evaluation of Interpretable Machine Learning Models",
        "link": "/arxiv/2409.14429",
        "arxiv_id": "2409.14429",
        "authors": "Sven Kruschel, Nico Hambauer, Sven Weinzierl, Sandra Zilker, Mathias Kraus, Patrick Zschech",
        "summary": "Machine learning is permeating every conceivable domain to promote data-driven decision support. The focus is often on advanced black-box models due to their assumed performance advantages, whereas interpretable models are often associated with inferior predictive qualities. More recently, however, a new generation of generalized additive models (GAMs) has been proposed that offer promising properties for capturing complex, non-linear patterns while remaining fully interpretable. To uncover the merits and limitations of these models, this study examines the predictive performance of seven different GAMs in comparison to seven commonly used machine learning models based on a collection of twenty tabular benchmark datasets. To ensure a fair and robust model comparison, an extensive hyperparameter search combined with cross-validation was performed, resulting in 68,500 model runs. In addition, this study qualitatively examines the visual output of the models to assess their level of interpretability. Based on these results, the paper dispels the misconception that only black-box models can achieve high accuracy by demonstrating that there is no strict trade-off between predictive performance and model interpretability for tabular data. Furthermore, the paper discusses the importance of GAMs as powerful interpretable models for the field of information systems and derives implications for future work from a socio-technical perspective.",
        "subjects": "Machine Learning, Artificial Intelligence, Human-Computer Interaction, Neural and Evolutionary Computing",
        "date": "2024-09-22 12:58:52 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.806804"
    },
    {
        "index": "#173",
        "title": "COSBO: Conservative Offline Simulation-Based Policy Optimization",
        "link": "/arxiv/2409.14412",
        "arxiv_id": "2409.14412",
        "authors": "Eshagh Kargar, Ville Kyrki",
        "summary": "Offline reinforcement learning allows training reinforcement learning models on data from live deployments. However, it is limited to choosing the best combination of behaviors present in the training data. In contrast, simulation environments attempting to replicate the live environment can be used instead of the live data, yet this approach is limited by the simulation-to-reality gap, resulting in a bias. In an attempt to get the best of both worlds, we propose a method that combines an imperfect simulation environment with data from the target environment, to train an offline reinforcement learning policy. Our experiments demonstrate that the proposed method outperforms state-of-the-art approaches CQL, MOPO, and COMBO, especially in scenarios with diverse and challenging dynamics, and demonstrates robust behavior across a variety of experimental conditions. The results highlight that using simulator-generated data can effectively enhance offline policy learning despite the sim-to-real gap, when direct interaction with the real-world is not possible.",
        "subjects": "Machine Learning, Artificial Intelligence, Robotics",
        "date": "2024-09-22 12:20:55 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.807198"
    },
    {
        "index": "#175",
        "title": "Sparse Low-Ranked Self-Attention Transformer for Remaining Useful Lifetime Prediction of Optical Fiber Amplifiers",
        "link": "/arxiv/2409.14378",
        "arxiv_id": "2409.14378",
        "authors": "Dominic Schneider, Lutz Rapp",
        "summary": "Optical fiber amplifiers are key elements in present optical networks. Failures of these components result in high financial loss of income of the network operator as the communication traffic over an affected link is interrupted. Applying Remaining useful lifetime (RUL) prediction in the context of Predictive Maintenance (PdM) to optical fiber amplifiers to predict upcoming system failures at an early stage, so that network outages can be minimized through planning of targeted maintenance actions, ensures reliability and safety. Optical fiber amplifier are complex systems, that work under various operating conditions, which makes correct forecasting a difficult task. Increased monitoring capabilities of systems results in datasets that facilitate the application of data-driven RUL prediction methods. Deep learning models in particular have shown good performance, but generalization based on comparatively small datasets for RUL prediction is difficult. In this paper, we propose Sparse Low-ranked self-Attention Transformer (SLAT) as a novel RUL prediction method. SLAT is based on an encoder-decoder architecture, wherein two parallel working encoders extract features for sensors and time steps. By utilizing the self-attention mechanism, long-term dependencies can be learned from long sequences. The implementation of sparsity in the attention matrix and a low-rank parametrization reduce overfitting and increase generalization. Experimental application to optical fiber amplifiers exemplified on EDFA, as well as a reference dataset from turbofan engines, shows that SLAT outperforms the state-of-the-art methods.",
        "subjects": "Machine Learning, Artificial Intelligence, Signal Processing",
        "date": "2024-09-22 09:48:45 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.807614"
    },
    {
        "index": "#176",
        "title": "Evaluating the Quality of Code Comments Generated by Large Language Models for Novice Programmers",
        "link": "/arxiv/2409.14368",
        "arxiv_id": "2409.14368",
        "authors": "Aysa Xuemo Fan, Arun Balajiee Lekshmi Narayanan, Mohammad Hassany, Jiaze Ke",
        "summary": "Large Language Models (LLMs) show promise in generating code comments for novice programmers, but their educational effectiveness remains under-evaluated. This study assesses the instructional quality of code comments produced by GPT-4, GPT-3.5-Turbo, and Llama2, compared to expert-developed comments, focusing on their suitability for novices. Analyzing a dataset of ``easy'' level Java solutions from LeetCode, we find that GPT-4 exhibits comparable quality to expert comments in aspects critical for beginners, such as clarity, beginner-friendliness, concept elucidation, and step-by-step guidance. GPT-4 outperforms Llama2 in discussing complexity (chi-square = 11.40, p = 0.001) and is perceived as significantly more supportive for beginners than GPT-3.5 and Llama2 with Mann-Whitney U-statistics = 300.5 and 322.5, p = 0.0017 and 0.0003). This study highlights the potential of LLMs for generating code comments tailored to novice programmers.",
        "subjects": "Software Engineering, Artificial Intelligence, Human-Computer Interaction",
        "date": "2024-09-22 09:03:48 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.807825"
    },
    {
        "index": "#177",
        "title": "Data-Driven Spatiotemporal Feature Representation and Mining in Multidimensional Time Series",
        "link": "/arxiv/2409.14327",
        "arxiv_id": "2409.14327",
        "authors": "Xu Yan, Yaoting Jiang, Wenyi Liu, Didi Yi, Haoyang Sang, Jianjun Wei",
        "summary": "This paper explores a new method for time series data analysis, aiming to overcome the limitations of traditional mining techniques when dealing with multidimensional time series data. Time series data are extensively utilized in diverse fields, including backend services for monitoring and optimizing IT infrastructure, medical diagnosis through continuous patient monitoring and health trend analysis, and internet business for tracking user behavior and forecasting sales. However, since the effective information in time series data is often hidden in sequence fragments, the uncertainty of their length, quantity, and morphological variables brings challenges to mining. To this end, this paper proposes a new spatiotemporal feature representation method, which converts multidimensional time series (MTS) into one-dimensional event sequences by transforming spatially varying events, and uses a series of event symbols to represent the spatial structural information of multidimensional coupling in the sequence, which has good interpretability. Then, this paper introduces a variable-length tuple mining method to extract non-redundant key event subsequences in event sequences as spatiotemporal structural features of motion sequences. This method is an unsupervised method that does not rely on large-scale training samples and defines a new model for representing the spatiotemporal structural features of multidimensional time series. The superior performance of the STEM model is verified by pattern classification experiments on a variety of motion sequences. The research results of this paper provide an important theoretical basis and technical support for understanding and predicting human behavior patterns, and have far-reaching practical application value.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-22 06:27:07 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.808028"
    },
    {
        "index": "#183",
        "title": "Proof Automation with Large Language Models",
        "link": "/arxiv/2409.14274",
        "arxiv_id": "2409.14274",
        "authors": "Minghai Lu, Benjamin Delaware, Tianyi Zhang",
        "summary": "Interactive theorem provers such as Coq are powerful tools to formally guarantee the correctness of software. However, using these tools requires significant manual effort and expertise. While Large Language Models (LLMs) have shown promise in automatically generating informal proofs in natural language, they are less effective at generating formal proofs in interactive theorem provers. In this paper, we conduct a formative study to identify common mistakes made by LLMs when asked to generate formal proofs. By analyzing 520 proof generation errors made by GPT-3.5, we found that GPT-3.5 often identified the correct high-level structure of a proof, but struggled to get the lower-level details correct. Based on this insight, we propose PALM, a novel generate-then-repair approach that first prompts an LLM to generate an initial proof and then leverages targeted symbolic methods to iteratively repair low-level problems. We evaluate PALM on a large dataset that includes more than 10K theorems. Our results show that PALM significantly outperforms other state-of-the-art approaches, successfully proving 76.6% to 180.4% more theorems. Moreover, PALM proves 1270 theorems beyond the reach of existing approaches. We also demonstrate the generalizability of PALM across different LLMs.",
        "subjects": "Software Engineering, Artificial Intelligence, Machine Learning, Logic in Computer Science, Programming Languages",
        "date": "2024-09-22 00:19:27 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.809441"
    },
    {
        "index": "#184",
        "title": "Higher-order-ReLU-KANs (HRKANs) for solving physics-informed neural networks (PINNs) more accurately, robustly and faster",
        "link": "/arxiv/2409.14248",
        "arxiv_id": "2409.14248",
        "authors": "Chi Chiu So, Siu Pang Yung",
        "summary": "Finding solutions to partial differential equations (PDEs) is an important and essential component in many scientific and engineering discoveries. One of the common approaches empowered by deep learning is Physics-informed Neural Networks (PINNs). Recently, a new type of fundamental neural network model, Kolmogorov-Arnold Networks (KANs), has been proposed as a substitute of Multilayer Perceptions (MLPs), and possesses trainable activation functions. To enhance KANs in fitting accuracy, a modification of KANs, so called ReLU-KANs, using \"square of ReLU\" as the basis of its activation functions has been suggested. In this work, we propose another basis of activation functions, namely, Higher-order-ReLU, which is simpler than the basis of activation functions used in KANs, namely, B-splines; allows efficient KAN matrix operations; and possesses smooth and non-zero higher-order derivatives, essential for physics-informed neural networks. Our detailed experiments on two standard and typical PDEs, namely, the linear Poisson equation and nonlinear Burgers' equation with viscosity, reveal that our proposed Higher-order-ReLU-KANs (HRKANs) achieve the highest fitting accuracy and training robustness and lowest training time significantly among KANs, ReLUKANs and HRKANs.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Computational Engineering, Finance, and Science, Machine Learning, Computational Physics",
        "date": "2024-08-09 03:50:58 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.809641"
    },
    {
        "index": "#185",
        "title": "An Instance-based Plus Ensemble Learning Method for Classification of Scientific Papers",
        "link": "/arxiv/2409.14237",
        "arxiv_id": "2409.14237",
        "authors": "Fang Zhang, Shengli Wu",
        "summary": "The exponential growth of scientific publications in recent years has posed a significant challenge in effective and efficient categorization. This paper introduces a novel approach that combines instance-based learning and ensemble learning techniques for classifying scientific papers into relevant research fields. Working with a classification system with a group of research fields, first a number of typical seed papers are allocated to each of the fields manually. Then for each paper that needs to be classified, we compare it with all the seed papers in every field. Contents and citations are considered separately. An ensemble-based method is then employed to make the final decision. Experimenting with the datasets from DBLP, our experimental results demonstrate that the proposed classification method is effective and efficient in categorizing papers into various research areas. We also find that both content and citation features are useful for the classification of scientific papers.",
        "subjects": "Digital Libraries, Artificial Intelligence",
        "date": "2024-09-21 19:42:15 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.809876"
    },
    {
        "index": "#186",
        "title": "MEGA-PT: A Meta-Game Framework for Agile Penetration Testing",
        "link": "/arxiv/2409.14219",
        "arxiv_id": "2409.14219",
        "authors": "Yunfei Ge, Quanyan Zhu",
        "summary": "Penetration testing is an essential means of proactive defense in the face of escalating cybersecurity incidents. Traditional manual penetration testing methods are time-consuming, resource-intensive, and prone to human errors. Current trends in automated penetration testing are also impractical, facing significant challenges such as the curse of dimensionality, scalability issues, and lack of adaptability to network changes. To address these issues, we propose MEGA-PT, a meta-game penetration testing framework, featuring micro tactic games for node-level local interactions and a macro strategy process for network-wide attack chains. The micro- and macro-level modeling enables distributed, adaptive, collaborative, and fast penetration testing. MEGA-PT offers agile solutions for various security schemes, including optimal local penetration plans, purple teaming solutions, and risk assessment, providing fundamental principles to guide future automated penetration testing. Our experiments demonstrate the effectiveness and agility of our model by providing improved defense strategies and adaptability to changes at both local and network levels.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computer Science and Game Theory",
        "date": "2024-09-21 18:46:29 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.810068"
    },
    {
        "index": "#188",
        "title": "Data-Driven Approach to assess and identify gaps in healthcare set up in South Asia",
        "link": "/arxiv/2409.14194",
        "arxiv_id": "2409.14194",
        "authors": "Rusham Elahi, Zia Tahseen, Tehreem Fatima, Syed Wafa Zahra, Hafiz Muhammad Abubakar, Tehreem Zafar, Aqs Younas, Muhammad Talha Quddoos, Usman Nazir",
        "summary": "Primary healthcare is a crucial strategy for achieving universal health coverage. South Asian countries are working to improve their primary healthcare system through their country specific policies designed in line with WHO health system framework using the six thematic pillars: Health Financing, Health Service delivery, Human Resource for Health, Health Information Systems, Governance, Essential Medicines and Technology, and an addition area of Cross-Sectoral Linkages. Measuring the current accessibility of healthcare facilities and workforce availability is essential for improving healthcare standards and achieving universal health coverage in developing countries. Data-driven surveillance approaches are required that can provide rapid, reliable, and geographically scalable solutions to understand a) which communities and areas are most at risk of inequitable access and when, b) what barriers to health access exist, and c) how they can be overcome in ways tailored to the specific challenges faced by individual communities. We propose to harness current breakthroughs in Earth-observation (EO) technology, which provide the ability to generate accurate, up-to-date, publicly accessible, and reliable data, which is necessary for equitable access planning and resource allocation to ensure that vaccines, and other interventions reach everyone, particularly those in greatest need, during normal and crisis times. This requires collaboration among countries to identify evidence based solutions to shape health policy and interventions, and drive innovations and research in the region.",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2024-09-21 16:50:16 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.810550"
    },
    {
        "index": "#189",
        "title": "PathSeeker: Exploring LLM Security Vulnerabilities with a Reinforcement Learning-Based Jailbreak Approach",
        "link": "/arxiv/2409.14177",
        "arxiv_id": "2409.14177",
        "authors": "Zhihao Lin, Wei Ma, Mingyi Zhou, Yanjie Zhao, Haoyu Wang, Yang Liu, Jun Wang, Li Li",
        "summary": "In recent years, Large Language Models (LLMs) have gained widespread use, accompanied by increasing concerns over their security. Traditional jailbreak attacks rely on internal model details or have limitations when exploring the unsafe behavior of the victim model, limiting their generalizability. In this paper, we introduce PathSeeker, a novel black-box jailbreak method inspired by the concept of escaping a security maze. This work is inspired by the game of rats escaping a maze. We think that each LLM has its unique \"security maze\", and attackers attempt to find the exit learning from the received feedback and their accumulated experience to compromise the target LLM's security defences. Our approach leverages multi-agent reinforcement learning, where smaller models collaborate to guide the main LLM in performing mutation operations to achieve the attack objectives. By progressively modifying inputs based on the model's feedback, our system induces richer, harmful responses. During our manual attempts to perform jailbreak attacks, we found that the vocabulary of the response of the target model gradually became richer and eventually produced harmful responses. Based on the observation, we also introduce a reward mechanism that exploits the expansion of vocabulary richness in LLM responses to weaken security constraints. Our method outperforms five state-of-the-art attack techniques when tested across 13 commercial and open-source LLMs, achieving high attack success rates, especially in strongly aligned commercial models like GPT-4o-mini, Claude-3.5, and GLM-4-air with strong safety alignment. This study aims to improve the understanding of LLM security vulnerabilities and we hope that this sturdy can contribute to the development of more robust defenses.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2024-09-21 15:36:26 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.810767"
    },
    {
        "index": "#194",
        "title": "One-shot World Models Using a Transformer Trained on a Synthetic Prior",
        "link": "/arxiv/2409.14084",
        "arxiv_id": "2409.14084",
        "authors": "Fabio Ferreira, Moreno Schlageter, Raghu Rajan, Andre Biedenkapp, Frank Hutter",
        "summary": "A World Model is a compressed spatial and temporal representation of a real world environment that allows one to train an agent or execute planning methods. However, world models are typically trained on observations from the real world environment, and they usually do not enable learning policies for other real environments. We propose One-Shot World Model (OSWM), a transformer world model that is learned in an in-context learning fashion from purely synthetic data sampled from a prior distribution. Our prior is composed of multiple randomly initialized neural networks, where each network models the dynamics of each state and reward dimension of a desired target environment. We adopt the supervised learning procedure of Prior-Fitted Networks by masking next-state and reward at random context positions and query OSWM to make probabilistic predictions based on the remaining transition context. During inference time, OSWM is able to quickly adapt to the dynamics of a simple grid world, as well as the CartPole gym and a custom control environment by providing 1k transition steps as context and is then able to successfully train environment-solving agent policies. However, transferring to more complex environments remains a challenge, currently. Despite these limitations, we see this work as an important stepping-stone in the pursuit of learning world models purely from synthetic data.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-21 09:39:32 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.811809"
    },
    {
        "index": "#196",
        "title": "N-Version Assessment and Enhancement of Generative AI",
        "link": "/arxiv/2409.14071",
        "arxiv_id": "2409.14071",
        "authors": "Marcus Kessel, Colin Atkinson",
        "summary": "Generative AI (GAI) holds great potential to improve software engineering productivity, but its untrustworthy outputs, particularly in code synthesis, pose significant challenges. The need for extensive verification and validation (V&V) of GAI-generated artifacts may undermine the potential productivity gains. This paper proposes a way of mitigating these risks by exploiting GAI's ability to generate multiple versions of code and tests to facilitate comparative analysis across versions. Rather than relying on the quality of a single test or code module, this \"differential GAI\" (D-GAI) approach promotes more reliable quality evaluation through version diversity. We introduce the Large-Scale Software Observatorium (LASSO), a platform that supports D-GAI by executing and analyzing large sets of code versions and tests. We discuss how LASSO enables rigorous evaluation of GAI-generated artifacts and propose its application in both software development and GAI research.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2024-09-21 09:00:16 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.812175"
    },
    {
        "index": "#197",
        "title": "KALIE: Fine-Tuning Vision-Language Models for Open-World Manipulation without Robot Data",
        "link": "/arxiv/2409.14066",
        "arxiv_id": "2409.14066",
        "authors": "Grace Tang, Swetha Rajkumar, Yifei Zhou, Homer Rich Walke, Sergey Levine, Kuan Fang",
        "summary": "Building generalist robotic systems involves effectively endowing robots with the capabilities to handle novel objects in an open-world setting. Inspired by the advances of large pre-trained models, we propose Keypoint Affordance Learning from Imagined Environments (KALIE), which adapts pre-trained Vision Language Models (VLMs) for robotic control in a scalable manner. Instead of directly producing motor commands, KALIE controls the robot by predicting point-based affordance representations based on natural language instructions and visual observations of the scene. The VLM is trained on 2D images with affordances labeled by humans, bypassing the need for training data collected on robotic systems. Through an affordance-aware data synthesis pipeline, KALIE automatically creates massive high-quality training data based on limited example data manually collected by humans. We demonstrate that KALIE can learn to robustly solve new manipulation tasks with unseen objects given only 50 example data points. Compared to baselines using pre-trained VLMs, our approach consistently achieves superior performance.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning",
        "date": "2024-09-21 08:45:16 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.812383"
    },
    {
        "index": "#199",
        "title": "PepINVENT: Generative peptide design beyond the natural amino acids",
        "link": "/arxiv/2409.14040",
        "arxiv_id": "2409.14040",
        "authors": "Gökçe Geylan, Jon Paul Janet, Alessandro Tibo, Jiazhen He, Atanas Patronov, Mikhail Kabeshov, Florian David, Werngard Czechtizky, Ola Engkvist, Leonardo De Maria",
        "summary": "Peptides play a crucial role in the drug design and discovery whether as a therapeutic modality or a delivery agent. Non-natural amino acids (NNAAs) have been used to enhance the peptide properties from binding affinity, plasma stability to permeability. Incorporating novel NNAAs facilitates the design of more effective peptides with improved properties. The generative models used in the field, have focused on navigating the peptide sequence space. The sequence space is formed by combinations of a predefined set of amino acids. However, there is still a need for a tool to explore the peptide landscape beyond this enumerated space to unlock and effectively incorporate de novo design of new amino acids. To thoroughly explore the theoretical chemical space of the peptides, we present PepINVENT, a novel generative AI-based tool as an extension to the small molecule molecular design platform, REINVENT. PepINVENT navigates the vast space of natural and non-natural amino acids to propose valid, novel, and diverse peptide designs. The generative model can serve as a central tool for peptide-related tasks, as it was not trained on peptides with specific properties or topologies. The prior was trained to understand the granularity of peptides and to design amino acids for filling the masked positions within a peptide. PepINVENT coupled with reinforcement learning enables the goal-oriented design of peptides using its chemistry-informed generative capabilities. This study demonstrates PepINVENT's ability to explore the peptide space with unique and novel designs, and its capacity for property optimization in the context of therapeutically relevant peptides. Our tool can be employed for multi-parameter learning objectives, peptidomimetics, lead optimization, and variety of other tasks within the peptide domain.",
        "subjects": "Biomolecules, Artificial Intelligence",
        "date": "2024-09-21 06:53:03 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.812980"
    },
    {
        "index": "#202",
        "title": "FAMOUS: Flexible Accelerator for the Attention Mechanism of Transformer on UltraScale+ FPGAs",
        "link": "/arxiv/2409.14023",
        "arxiv_id": "2409.14023",
        "authors": "Ehsan Kabir, Md. Arafat Kabir, Austin R. J. Downey, Jason D. Bakos, David Andrews, Miaoqing Huang",
        "summary": "Transformer neural networks (TNNs) are being applied across a widening range of application domains, including natural language processing (NLP), machine translation, and computer vision (CV). Their popularity is largely attributed to the exceptional performance of their multi-head self-attention blocks when analyzing sequential data and extracting features. To date, there are limited hardware accelerators tailored for this mechanism, which is the first step before designing an accelerator for a complete model. This paper proposes \\textit{FAMOUS}, a flexible hardware accelerator for dense multi-head attention (MHA) computation of TNNs on field-programmable gate arrays (FPGAs). It is optimized for high utilization of processing elements and on-chip memories to improve parallelism and reduce latency. An efficient tiling of large matrices has been employed to distribute memory and computing resources across different modules on various FPGA platforms. The design is evaluated on Xilinx Alveo U55C and U200 data center cards containing Ultrascale+ FPGAs. Experimental results are presented that show that it can attain a maximum throughput, number of parallel attention heads, embedding dimension and tile size of 328 (giga operations/second (GOPS)), 8, 768 and 64 respectively on the U55C. Furthermore, it is 3.28$\\times$ and 2.6$\\times$ faster than the Intel Xeon Gold 5220R CPU and NVIDIA V100 GPU respectively. It is also 1.3$\\times$ faster than the fastest state-of-the-art FPGA-based accelerator.",
        "subjects": "Hardware Architecture, Artificial Intelligence, Machine Learning",
        "date": "2024-09-21 05:25:46 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.818817"
    },
    {
        "index": "#205",
        "title": "Enhancing Multivariate Time Series-based Solar Flare Prediction with Multifaceted Preprocessing and Contrastive Learning",
        "link": "/arxiv/2409.14016",
        "arxiv_id": "2409.14016",
        "authors": "MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi",
        "summary": "Accurate solar flare prediction is crucial due to the significant risks that intense solar flares pose to astronauts, space equipment, and satellite communication systems. Our research enhances solar flare prediction by utilizing advanced data preprocessing and classification methods on a multivariate time series-based dataset of photospheric magnetic field parameters. First, our study employs a novel preprocessing pipeline that includes missing value imputation, normalization, balanced sampling, near decision boundary sample removal, and feature selection to significantly boost prediction accuracy. Second, we integrate contrastive learning with a GRU regression model to develop a novel classifier, termed ContReg, which employs dual learning methodologies, thereby further enhancing prediction performance. To validate the effectiveness of our preprocessing pipeline, we compare and demonstrate the performance gain of each step, and to demonstrate the efficacy of the ContReg classifier, we compare its performance to that of sequence-based deep learning architectures, machine learning models, and findings from previous studies. Our results illustrate exceptional True Skill Statistic (TSS) scores, surpassing previous methods and highlighting the critical role of precise data preprocessing and classifier development in time series-based solar flare prediction.",
        "subjects": "Solar and Stellar Astrophysics, Artificial Intelligence, Machine Learning, Machine Learning",
        "date": "2024-09-21 05:00:34 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.819413"
    },
    {
        "index": "#206",
        "title": "Mitigating Exposure Bias in Score-Based Generation of Molecular Conformations",
        "link": "/arxiv/2409.14014",
        "arxiv_id": "2409.14014",
        "authors": "Sijia Wang, Chen Wang, Zhenhao Zhao, Jiqiang Zhang, Weiran Cai",
        "summary": "Molecular conformation generation poses a significant challenge in the field of computational chemistry. Recently, Diffusion Probabilistic Models (DPMs) and Score-Based Generative Models (SGMs) are effectively used due to their capacity for generating accurate conformations far beyond conventional physics-based approaches. However, the discrepancy between training and inference rises a critical problem known as the exposure bias. While this issue has been extensively investigated in DPMs, the existence of exposure bias in SGMs and its effective measurement remain unsolved, which hinders the use of compensation methods for SGMs, including ConfGF and Torsional Diffusion as the representatives. In this work, we first propose a method for measuring exposure bias in SGMs used for molecular conformation generation, which confirms the significant existence of exposure bias in these models and measures its value. We design a new compensation algorithm Input Perturbation (IP), which is adapted from a method originally designed for DPMs only. Experimental results show that by introducing IP, SGM-based molecular conformation models can significantly improve both the accuracy and diversity of the generated conformations. Especially by using the IP-enhanced Torsional Diffusion model, we achieve new state-of-the-art performance on the GEOM-Drugs dataset and are on par on GEOM-QM9. We provide the code publicly at https://github.com/jia-975/torsionalDiff-ip.",
        "subjects": "Machine Learning, Artificial Intelligence, Biomolecules",
        "date": "2024-09-21 04:54:37 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.819615"
    },
    {
        "index": "#207",
        "title": "ChronoGAN: Supervised and Embedded Generative Adversarial Networks for Time Series Generation",
        "link": "/arxiv/2409.14013",
        "arxiv_id": "2409.14013",
        "authors": "MohammadReza EskandariNasab, Shah Muhammad Hamdi, Soukaina Filali Boubrahimi",
        "summary": "Generating time series data using Generative Adversarial Networks (GANs) presents several prevalent challenges, such as slow convergence, information loss in embedding spaces, instability, and performance variability depending on the series length. To tackle these obstacles, we introduce a robust framework aimed at addressing and mitigating these issues effectively. This advanced framework integrates the benefits of an Autoencoder-generated embedding space with the adversarial training dynamics of GANs. This framework benefits from a time series-based loss function and oversight from a supervisory network, both of which capture the stepwise conditional distributions of the data effectively. The generator functions within the latent space, while the discriminator offers essential feedback based on the feature space. Moreover, we introduce an early generation algorithm and an improved neural network architecture to enhance stability and ensure effective generalization across both short and long time series. Through joint training, our framework consistently outperforms existing benchmarks, generating high-quality time series data across a range of real and synthetic datasets with diverse characteristics.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-21 04:51:35 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.819802"
    },
    {
        "index": "#208",
        "title": "Test Time Learning for Time Series Forecasting",
        "link": "/arxiv/2409.14012",
        "arxiv_id": "2409.14012",
        "authors": "Panayiotis Christou, Shichu Chen, Xupeng Chen, Parijat Dube",
        "summary": "Time-series forecasting has seen significant advancements with the introduction of token prediction mechanisms such as multi-head attention. However, these methods often struggle to achieve the same performance as in language modeling, primarily due to the quadratic computational cost and the complexity of capturing long-range dependencies in time-series data. State-space models (SSMs), such as Mamba, have shown promise in addressing these challenges by offering efficient solutions with linear RNNs capable of modeling long sequences with larger context windows. However, there remains room for improvement in accuracy and scalability. We propose the use of Test-Time Training (TTT) modules in a parallel architecture to enhance performance in long-term time series forecasting. Through extensive experiments on standard benchmark datasets, we demonstrate that TTT modules consistently outperform state-of-the-art models, including the Mamba-based TimeMachine, particularly in scenarios involving extended sequence and prediction lengths. Our results show significant improvements in Mean Squared Error (MSE) and Mean Absolute Error (MAE), especially on larger datasets such as Electricity, Traffic, and Weather, underscoring the effectiveness of TTT in capturing long-range dependencies. Additionally, we explore various convolutional architectures within the TTT framework, showing that even simple configurations like 1D convolution with small filters can achieve competitive results. This work sets a new benchmark for time-series forecasting and lays the groundwork for future research in scalable, high-performance forecasting models.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-21 04:40:08 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.819993"
    },
    {
        "index": "#209",
        "title": "Boolean Product Graph Neural Networks",
        "link": "/arxiv/2409.14001",
        "arxiv_id": "2409.14001",
        "authors": "Ziyan Wang, Bin Liu, Ling Xiang",
        "summary": "Graph Neural Networks (GNNs) have recently achieved significant success, with a key operation involving the aggregation of information from neighboring nodes. Substantial researchers have focused on defining neighbors for aggregation, predominantly based on observed adjacency matrices. However, in many scenarios, the explicitly given graphs contain noise, which can be amplified during the messages-passing process. Therefore, many researchers have turned their attention to latent graph inference, specifically learning a parametric graph. To mitigate fluctuations in latent graph structure learning, this paper proposes a novel Boolean product-based graph residual connection in GNNs to link the latent graph and the original graph. It computes the Boolean product between the latent graph and the original graph at each layer to correct the learning process. The Boolean product between two adjacency matrices is equivalent to triangle detection. Accordingly, the proposed Boolean product graph neural networks can be interpreted as discovering triangular cliques from the original and the latent graph. We validate the proposed method in benchmark datasets and demonstrate its ability to enhance the performance and robustness of GNNs.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-21 03:31:33 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.820250"
    },
    {
        "index": "#211",
        "title": "Relevance-driven Decision Making for Safer and More Efficient Human Robot Collaboration",
        "link": "/arxiv/2409.13998",
        "arxiv_id": "2409.13998",
        "authors": "Xiaotong Zhang, Dingcheng Huang, Kamal Youcef-Toumi",
        "summary": "Human intelligence possesses the ability to effectively focus on important environmental components, which enhances perception, learning, reasoning, and decision-making. Inspired by this cognitive mechanism, we introduced a novel concept termed relevance for Human-Robot Collaboration (HRC). Relevance is defined as the importance of the objects based on the applicability and pertinence of the objects for the human objective or other factors. In this paper, we further developed a novel two-loop framework integrating real-time and asynchronous processing to quantify relevance and apply relevance for safer and more efficient HRC. The asynchronous loop leverages the world knowledge from an LLM and quantifies relevance, and the real-time loop executes scene understanding, human intent prediction, and decision-making based on relevance. In decision making, we proposed and developed a human robot task allocation method based on relevance and a novel motion generation and collision avoidance methodology considering the prediction of human trajectory. Simulations and experiments show that our methodology for relevance quantification can accurately and robustly predict the human objective and relevance, with an average accuracy of up to 0.90 for objective prediction and up to 0.96 for relevance prediction. Moreover, our motion generation methodology reduces collision cases by 63.76% and collision frames by 44.74% when compared with a state-of-the-art (SOTA) collision avoidance method. Our framework and methodologies, with relevance, guide the robot on how to best assist humans and generate safer and more efficient actions for HRC.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2024-09-21 03:20:53 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.820658"
    },
    {
        "index": "#216",
        "title": "ProTEA: Programmable Transformer Encoder Acceleration on FPGA",
        "link": "/arxiv/2409.13975",
        "arxiv_id": "2409.13975",
        "authors": "Ehsan Kabir, Jason D. Bakos, David Andrews, Miaoqing Huang",
        "summary": "Transformer neural networks (TNN) have been widely utilized on a diverse range of applications, including natural language processing (NLP), machine translation, and computer vision (CV). Their widespread adoption has been primarily driven by the exceptional performance of their multi-head self-attention block used to extract key features from sequential data. The multi-head self-attention block is followed by feedforward neural networks, which play a crucial role in introducing non-linearity to assist the model in learning complex patterns. Despite the popularity of TNNs, there has been limited numbers of hardware accelerators targeting these two critical blocks. Most prior works have concentrated on sparse architectures that are not flexible for popular TNN variants. This paper introduces \\textit{ProTEA}, a runtime programmable accelerator tailored for the dense computations of most of state-of-the-art transformer encoders. \\textit{ProTEA} is designed to reduce latency by maximizing parallelism. We introduce an efficient tiling of large matrices that can distribute memory and computing resources across different hardware components within the FPGA. We provide run time evaluations of \\textit{ProTEA} on a Xilinx Alveo U55C high-performance data center accelerator card. Experimental results demonstrate that \\textit{ProTEA} can host a wide range of popular transformer networks and achieve near optimal performance with a tile size of 64 in the multi-head self-attention block and 6 in the feedforward networks block when configured with 8 parallel attention heads, 12 layers, and an embedding dimension of 768 on the U55C. Comparative results are provided showing \\textit{ProTEA} is 2.5$\\times$ faster than an NVIDIA Titan XP GPU. Results also show that it achieves 1.3 -- 2.8$\\times$ speed up compared with current state-of-the-art custom designed FPGA accelerators.",
        "subjects": "Hardware Architecture, Artificial Intelligence, Machine Learning, Systems and Control",
        "date": "2024-09-21 01:44:13 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.821765"
    },
    {
        "index": "#217",
        "title": "One Model, Any Conjunctive Query: Graph Neural Networks for Answering Complex Queries over Knowledge Graphs",
        "link": "/arxiv/2409.13959",
        "arxiv_id": "2409.13959",
        "authors": "Krzysztof Olejniczak, Xingyue Huang, İsmail İlkan Ceylan, Mikhail Galkin",
        "summary": "Traditional query answering over knowledge graphs -- or broadly over relational data -- is one of the most fundamental problems in data management. Motivated by the incompleteness of modern knowledge graphs, a new setup for query answering has emerged, where the goal is to predict answers that do not necessarily appear in the knowledge graph, but are present in its completion. In this work, we propose AnyCQ, a graph neural network model that can classify answers to any conjunctive query on any knowledge graph, following training. At the core of our framework lies a graph neural network model trained using a reinforcement learning objective to answer Boolean queries. Our approach and problem setup differ from existing query answering studies in multiple dimensions. First, we focus on the problem of query answer classification: given a query and a set of possible answers, classify these proposals as true or false relative to the complete knowledge graph. Second, we study the problem of query answer retrieval: given a query, retrieve an answer to the query relative to the complete knowledge graph or decide that no correct solutions exist. Trained on simple, small instances, AnyCQ can generalize to large queries of arbitrary structure, reliably classifying and retrieving answers to samples where existing approaches fail, which is empirically validated on new and challenging benchmarks. Furthermore, we demonstrate that our AnyCQ models effectively transfer to out-of-distribution knowledge graphs, when equipped with a relevant link predictor, highlighting their potential to serve as a general engine for query answering.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-21 00:30:44 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.821953"
    },
    {
        "index": "#219",
        "title": "Learning Recourse Costs from Pairwise Feature Comparisons",
        "link": "/arxiv/2409.13940",
        "arxiv_id": "2409.13940",
        "authors": "Kaivalya Rawal, Himabindu Lakkaraju",
        "summary": "This paper presents a novel technique for incorporating user input when learning and inferring user preferences. When trying to provide users of black-box machine learning models with actionable recourse, we often wish to incorporate their personal preferences about the ease of modifying each individual feature. These recourse finding algorithms usually require an exhaustive set of tuples associating each feature to its cost of modification. Since it is hard to obtain such costs by directly surveying humans, in this paper, we propose the use of the Bradley-Terry model to automatically infer feature-wise costs using non-exhaustive human comparison surveys. We propose that users only provide inputs comparing entire recourses, with all candidate feature modifications, determining which recourses are easier to implement relative to others, without explicit quantification of their costs. We demonstrate the efficient learning of individual feature costs using MAP estimates, and show that these non-exhaustive human surveys, which do not necessarily contain data for each feature pair comparison, are sufficient to learn an exhaustive set of feature costs, where each feature is associated with a modification cost.",
        "subjects": "Machine Learning, Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2024-09-20 23:04:08 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.822414"
    },
    {
        "index": "#226",
        "title": "Tabular Data Generation using Binary Diffusion",
        "link": "/arxiv/2409.13882",
        "arxiv_id": "2409.13882",
        "authors": "Vitaliy Kinakh, Slava Voloshynovskiy",
        "summary": "Generating synthetic tabular data is critical in machine learning, especially when real data is limited or sensitive. Traditional generative models often face challenges due to the unique characteristics of tabular data, such as mixed data types and varied distributions, and require complex preprocessing or large pretrained models. In this paper, we introduce a novel, lossless binary transformation method that converts any tabular data into fixed-size binary representations, and a corresponding new generative model called Binary Diffusion, specifically designed for binary data. Binary Diffusion leverages the simplicity of XOR operations for noise addition and removal and employs binary cross-entropy loss for training. Our approach eliminates the need for extensive preprocessing, complex noise parameter tuning, and pretraining on large datasets. We evaluate our model on several popular tabular benchmark datasets, demonstrating that Binary Diffusion outperforms existing state-of-the-art models on Travel, Adult Income, and Diabetes datasets while being significantly smaller in size.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-20 20:22:28 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.829800"
    },
    {
        "index": "#228",
        "title": "MAGICS: Adversarial RL with Minimax Actors Guided by Implicit Critic Stackelberg for Convergent Neural Synthesis of Robot Safety",
        "link": "/arxiv/2409.13867",
        "arxiv_id": "2409.13867",
        "authors": "Justin Wang, Haimin Hu, Duy Phuong Nguyen, Jaime Fernández Fisac",
        "summary": "While robust optimal control theory provides a rigorous framework to compute robot control policies that are provably safe, it struggles to scale to high-dimensional problems, leading to increased use of deep learning for tractable synthesis of robot safety. Unfortunately, existing neural safety synthesis methods often lack convergence guarantees and solution interpretability. In this paper, we present Minimax Actors Guided by Implicit Critic Stackelberg (MAGICS), a novel adversarial reinforcement learning (RL) algorithm that guarantees local convergence to a minimax equilibrium solution. We then build on this approach to provide local convergence guarantees for a general deep RL-based robot safety synthesis algorithm. Through both simulation studies on OpenAI Gym environments and hardware experiments with a 36-dimensional quadruped robot, we show that MAGICS can yield robust control policies outperforming the state-of-the-art neural safety synthesis methods.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning, Systems and Control",
        "date": "2024-09-20 19:45:48 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.830250"
    },
    {
        "index": "#229",
        "title": "Wormhole: Concept-Aware Deep Representation Learning for Co-Evolving Sequences",
        "link": "/arxiv/2409.13857",
        "arxiv_id": "2409.13857",
        "authors": "Kunpeng Xu, Lifei Chen, Shengrui Wang",
        "summary": "Identifying and understanding dynamic concepts in co-evolving sequences is crucial for analyzing complex systems such as IoT applications, financial markets, and online activity logs. These concepts provide valuable insights into the underlying structures and behaviors of sequential data, enabling better decision-making and forecasting. This paper introduces Wormhole, a novel deep representation learning framework that is concept-aware and designed for co-evolving time sequences. Our model presents a self-representation layer and a temporal smoothness constraint to ensure robust identification of dynamic concepts and their transitions. Additionally, concept transitions are detected by identifying abrupt changes in the latent space, signifying a shift to new behavior - akin to passing through a wormhole. This novel mechanism accurately discerns concepts within co-evolving sequences and pinpoints the exact locations of these wormholes, enhancing the interpretability of the learned representations. Experiments demonstrate that this method can effectively segment time series data into meaningful concepts, providing a valuable tool for analyzing complex temporal patterns and advancing the detection of concept drifts.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-20 19:11:39 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.830450"
    },
    {
        "index": "#230",
        "title": "More Consideration to the Perceptron",
        "link": "/arxiv/2409.13854",
        "arxiv_id": "2409.13854",
        "authors": "Slimane Larabi",
        "summary": "In this paper, we introduce the gated perceptron, an enhancement of the conventional perceptron, which incorporates an additional input computed as the product of the existing inputs. This allows the perceptron to capture non-linear interactions between features, significantly improving its ability to classify and regress on complex datasets. We explore its application in both linear and non-linear regression tasks using the Iris dataset, as well as binary and multi-class classification problems, including the PIMA Indian dataset and Breast Cancer Wisconsin dataset. Our results demonstrate that the gated perceptron can generate more distinct decision regions compared to traditional perceptrons, enhancing its classification capabilities, particularly in handling non-linear data. Performance comparisons show that the gated perceptron competes with state-of-the-art classifiers while maintaining a simple architecture.",
        "subjects": "Machine Learning, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2024-09-20 19:01:29 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.830704"
    },
    {
        "index": "#235",
        "title": "On the Feasibility of Fully AI-automated Vishing Attacks",
        "link": "/arxiv/2409.13793",
        "arxiv_id": "2409.13793",
        "authors": "João Figueiredo, Afonso Carvalho, Daniel Castro, Daniel Gonçalves, Nuno Santos",
        "summary": "A vishing attack is a form of social engineering where attackers use phone calls to deceive individuals into disclosing sensitive information, such as personal data, financial information, or security credentials. Attackers exploit the perceived urgency and authenticity of voice communication to manipulate victims, often posing as legitimate entities like banks or tech support. Vishing is a particularly serious threat as it bypasses security controls designed to protect information. In this work, we study the potential for vishing attacks to escalate with the advent of AI. In theory, AI-powered software bots may have the ability to automate these attacks by initiating conversations with potential victims via phone calls and deceiving them into disclosing sensitive information. To validate this thesis, we introduce ViKing, an AI-powered vishing system developed using publicly available AI technology. It relies on a Large Language Model (LLM) as its core cognitive processor to steer conversations with victims, complemented by a pipeline of speech-to-text and text-to-speech modules that facilitate audio-text conversion in phone calls. Through a controlled social experiment involving 240 participants, we discovered that ViKing has successfully persuaded many participants to reveal sensitive information, even those who had been explicitly warned about the risk of vishing campaigns. Interactions with ViKing's bots were generally considered realistic. From these findings, we conclude that tools like ViKing may already be accessible to potential malicious actors, while also serving as an invaluable resource for cyber awareness programs.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Audio and Speech Processing",
        "date": "2024-09-20 10:47:09 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.831943"
    },
    {
        "index": "#236",
        "title": "Continual Learning for Multimodal Data Fusion of a Soft Gripper",
        "link": "/arxiv/2409.13792",
        "arxiv_id": "2409.13792",
        "authors": "Nilay Kushawaha, Egidio Falotico",
        "summary": "Continual learning (CL) refers to the ability of an algorithm to continuously and incrementally acquire new knowledge from its environment while retaining previously learned information. A model trained on one data modality often fails when tested with a different modality. A straightforward approach might be to fuse the two modalities by concatenating their features and training the model on the fused data. However, this requires retraining the model from scratch each time it encounters a new domain. In this paper, we introduce a continual learning algorithm capable of incrementally learning different data modalities by leveraging both class-incremental and domain-incremental learning scenarios in an artificial environment where labeled data is scarce, yet non-iid (independent and identical distribution) unlabeled data from the environment is plentiful. The proposed algorithm is efficient and only requires storing prototypes for each class. We evaluate the algorithm's effectiveness on a challenging custom multimodal dataset comprising of tactile data from a soft pneumatic gripper, and visual data from non-stationary images of objects extracted from video sequences. Additionally, we conduct an ablation study on the custom dataset and the Core50 dataset to highlight the contributions of different components of the algorithm. To further demonstrate the robustness of the algorithm, we perform a real-time experiment for object classification using the soft gripper and an external independent camera setup, all synchronized with the Robot Operating System (ROS) framework.",
        "subjects": "Machine Learning, Artificial Intelligence, Robotics",
        "date": "2024-09-20 09:53:27 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.832148"
    },
    {
        "index": "#237",
        "title": "Multi-omics data integration for early diagnosis of hepatocellular carcinoma (HCC) using machine learning",
        "link": "/arxiv/2409.13791",
        "arxiv_id": "2409.13791",
        "authors": "Annette Spooner, Mohammad Karimi Moridani, Azadeh Safarchi, Salim Maher, Fatemeh Vafaee, Amany Zekry, Arcot Sowmya",
        "summary": "The complementary information found in different modalities of patient data can aid in more accurate modelling of a patient's disease state and a better understanding of the underlying biological processes of a disease. However, the analysis of multi-modal, multi-omics data presents many challenges, including high dimensionality and varying size, statistical distribution, scale and signal strength between modalities. In this work we compare the performance of a variety of ensemble machine learning algorithms that are capable of late integration of multi-class data from different modalities. The ensemble methods and their variations tested were i) a voting ensemble, with hard and soft vote, ii) a meta learner, iii) a multi-modal Adaboost model using a hard vote, a soft vote and a meta learner to integrate the modalities on each boosting round, the PB-MVBoost model and a novel application of a mixture of experts model. These were compared to simple concatenation as a baseline. We examine these methods using data from an in-house study on hepatocellular carcinoma (HCC), along with four validation datasets on studies from breast cancer and irritable bowel disease (IBD). Using the area under the receiver operating curve as a measure of performance we develop models that achieve a performance value of up to 0.85 and find that two boosted methods, PB-MVBoost and Adaboost with a soft vote were the overall best performing models. We also examine the stability of features selected, and the size of the clinical signature determined. Finally, we provide recommendations for the integration of multi-modal multi-class data.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-20 09:38:02 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.832446"
    },
    {
        "index": "#238",
        "title": "Revisiting Synthetic Human Trajectories: Imitative Generation and Benchmarks Beyond Datasaurus",
        "link": "/arxiv/2409.13790",
        "arxiv_id": "2409.13790",
        "authors": "Bangchao Deng, Xin Jing, Tianyue Yang, Bingqing Qu, Philippe Cudre-Mauroux, Dingqi Yang",
        "summary": "Human trajectory data, which plays a crucial role in various applications such as crowd management and epidemic prevention, is challenging to obtain due to practical constraints and privacy concerns. In this context, synthetic human trajectory data is generated to simulate as close as possible to real-world human trajectories, often under summary statistics and distributional similarities. However, the complexity of human mobility patterns is oversimplified by these similarities (a.k.a. ``Datasaurus''), resulting in intrinsic biases in both generative model design and benchmarks of the generated trajectories. Against this background, we propose MIRAGE, a huMan-Imitative tRAjectory GenErative model designed as a neural Temporal Point Process integrating an Exploration and Preferential Return model. It imitates the human decision-making process in trajectory generation, rather than fitting any specific statistical distributions as traditional methods do, thus avoiding the Datasaurus issue. Moreover, we also propose a comprehensive task-based evaluation protocol beyond Datasaurus to systematically benchmark trajectory generative models on four typical downstream tasks, integrating multiple techniques and evaluation metrics for each task, to comprehensively assess the ultimate utility of the generated trajectories. We conduct a thorough evaluation of MIRAGE on three real-world user trajectory datasets against a sizeable collection of baselines. Results show that compared to the best baselines, MIRAGE-generated trajectory data not only achieves the best statistical and distributional similarities with 59.0-71.5% improvement, but also yields the best performance in the task-based evaluation with 10.9-33.4% improvement.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-20 09:07:27 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.832737"
    },
    {
        "index": "#239",
        "title": "Quantum evolutionary algorithm for TSP combinatorial optimisation problem",
        "link": "/arxiv/2409.13788",
        "arxiv_id": "2409.13788",
        "authors": "Yijiang Ma, Tan Chye Cheah",
        "summary": "This paper implements a new way of solving a problem called the traveling salesman problem (TSP) using quantum genetic algorithm (QGA). We compared how well this new approach works to the traditional method known as a classical genetic algorithm (CGA). The TSP is a well-established challenge in combinatorial optimization where the objective is to find the most efficient path to visit a series of cities, minimizing the total distance, and returning to the starting point. We chose the TSP to test the performance of both algorithms because of its computational complexity and importance in practical applications. We choose the dataset from the international standard library TSPLIB for our experiments. By designing and implementing both algorithms and conducting experiments on various sizes and types of TSP instances, we provide an in-depth analysis of the accuracy of the optimal solution, the number of iterations, the execution time, and the stability of the algorithms for both. The empirical findings indicate that the CGA outperforms the QGA in terms of finding superior solutions more quickly in most of the test instances, especially when the problem size is large. This suggests that although the principle of quantum computing provides a new way to solve complex combinatorial optimisation problems, the implementation of quantum phenomena and the setting of parameters such as the optimal angle for a quantum revolving gate is challenging and need further optimisation to achieve the desired results. Additionally, it is important to note that the QGA has not been tested on real quantum hardware, so its true performance remains unverified. These limitations provide rich opportunities for further research in the future.",
        "subjects": "Quantum Physics, Artificial Intelligence",
        "date": "2024-09-20 08:27:42 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.832958"
    },
    {
        "index": "#240",
        "title": "Learning to Generalize Unseen Domains via Multi-Source Meta Learning for Text Classification",
        "link": "/arxiv/2409.13787",
        "arxiv_id": "2409.13787",
        "authors": "Yuxuan Hu, Chenwei Zhang, Min Yang, Xiaodan Liang, Chengming Li, Xiping Hu",
        "summary": "With the rapid development of deep learning methods, there have been many breakthroughs in the field of text classification. Models developed for this task have been shown to achieve high accuracy. However, most of these models are trained using labeled data from seen domains. It is difficult for these models to maintain high accuracy in a new challenging unseen domain, which is directly related to the generalization of the model. In this paper, we study the multi-source Domain Generalization of text classification and propose a framework to use multiple seen domains to train a model that can achieve high accuracy in an unseen domain. Specifically, we propose a multi-source meta-learning Domain Generalization framework to simulate the process of model generalization to an unseen domain, so as to extract sufficient domain-related features. We introduced a memory mechanism to store domain-specific features, which coordinate with the meta-learning framework. Besides, we adopt the novel \"jury\" mechanism that enables the model to learn sufficient domain-invariant features. Experiments demonstrate that our meta-learning framework can effectively enhance the ability of the model to generalize to an unseen domain and can outperform the state-of-the-art methods on multi-source text classification datasets.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2024-09-20 07:46:21 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.833180"
    },
    {
        "index": "#241",
        "title": "A Value Based Parallel Update MCTS Method for Multi-Agent Cooperative Decision Making of Connected and Automated Vehicles",
        "link": "/arxiv/2409.13783",
        "arxiv_id": "2409.13783",
        "authors": "Ye Han, Lijun Zhang, Dejian Meng, Xingyu Hu, Songyu Weng",
        "summary": "To solve the problem of lateral and logitudinal joint decision-making of multi-vehicle cooperative driving for connected and automated vehicles (CAVs), this paper proposes a Monte Carlo tree search (MCTS) method with parallel update for multi-agent Markov game with limited horizon and time discounted setting. By analyzing the parallel actions in the multi-vehicle joint action space in the partial-steady-state traffic flow, the parallel update method can quickly exclude potential dangerous actions, thereby increasing the search depth without sacrificing the search breadth. The proposed method is tested in a large number of randomly generated traffic flow. The experiment results show that the algorithm has good robustness and better performance than the SOTA reinforcement learning algorithms and heuristic methods. The vehicle driving strategy using the proposed algorithm shows rationality beyond human drivers, and has advantages in traffic efficiency and safety in the coordinating zone.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Computer Science and Game Theory, Systems and Control",
        "date": "2024-09-20 03:13:01 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.833484"
    },
    {
        "index": "#243",
        "title": "Trustworthy Intrusion Detection: Confidence Estimation Using Latent Space",
        "link": "/arxiv/2409.13774",
        "arxiv_id": "2409.13774",
        "authors": "Ioannis Pitsiorlas, George Arvanitakis, Marios Kountouris",
        "summary": "This work introduces a novel method for enhancing confidence in anomaly detection in Intrusion Detection Systems (IDS) through the use of a Variational Autoencoder (VAE) architecture. By developing a confidence metric derived from latent space representations, we aim to improve the reliability of IDS predictions against cyberattacks. Applied to the NSL-KDD dataset, our approach focuses on binary classification tasks to effectively distinguish between normal and malicious network activities. The methodology demonstrates a significant enhancement in anomaly detection, evidenced by a notable correlation of 0.45 between the reconstruction error and the proposed metric. Our findings highlight the potential of employing VAEs for more accurate and trustworthy anomaly detection in network security.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning",
        "date": "2024-09-19 08:09:44 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.839172"
    },
    {
        "index": "#244",
        "title": "A Case Study of Web App Coding with OpenAI Reasoning Models",
        "link": "/arxiv/2409.13773",
        "arxiv_id": "2409.13773",
        "authors": "Yi Cui",
        "summary": "This paper presents a case study of coding tasks by the latest reasoning models of OpenAI, i.e. o1-preview and o1-mini, in comparison with other frontier models. The o1 models deliver SOTA results for WebApp1K, a single-task benchmark. To this end, we introduce WebApp1K-Duo, a harder benchmark doubling number of tasks and test cases. The new benchmark causes the o1 model performances to decline significantly, falling behind Claude 3.5. Moreover, they consistently fail when confronted with atypical yet correct test cases, a trap non-reasoning models occasionally avoid. We hypothesize that the performance variability is due to instruction comprehension. Specifically, the reasoning mechanism boosts performance when all expectations are captured, meanwhile exacerbates errors when key expectations are missed, potentially impacted by input lengths. As such, we argue that the coding success of reasoning models hinges on the top-notch base model and SFT to ensure meticulous adherence to instructions.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2024-09-19 06:58:02 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.839420"
    },
    {
        "index": "#245",
        "title": "Magika: AI-Powered Content-Type Detection",
        "link": "/arxiv/2409.13768",
        "arxiv_id": "2409.13768",
        "authors": "Yanick Fratantonio, Luca Invernizzi, Loua Farah, Kurt Thomas, Marina Zhang, Ange Albertini, Francois Galilee, Giancarlo Metitieri, Julien Cretin, Alex Petit-Bianco, David Tao, Elie Bursztein",
        "summary": "The task of content-type detection -- which entails identifying the data encoded in an arbitrary byte sequence -- is critical for operating systems, development, reverse engineering environments, and a variety of security applications. In this paper, we introduce Magika, a novel AI-powered content-type detection tool. Under the hood, Magika employs a deep learning model that can execute on a single CPU with just 1MB of memory to store the model's weights. We show that Magika achieves an average F1 score of 99% across over a hundred content types and a test set of more than 1M files, outperforming all existing content-type detection tools today. In order to foster adoption and improvements, we open source Magika under an Apache 2 license on GitHub and make our model and training pipeline publicly available. Our tool has already seen adoption by the Gmail email provider for attachment scanning, and it has been integrated with VirusTotal to aid with malware analysis. We note that this paper discusses the first iteration of Magika, and a more recent version already supports more than 200 content types. The interested reader can see the latest development on the Magika GitHub repository, available at https://github.com/google/magika.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2024-09-18 17:24:39 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.839747"
    },
    {
        "index": "#263",
        "title": "Explainable Malware Analysis: Concepts, Approaches and Challenges",
        "link": "/arxiv/2409.13723",
        "arxiv_id": "2409.13723",
        "authors": "Harikha Manthena, Shaghayegh Shajarian, Jeffrey Kimmell, Mahmoud Abdelsalam, Sajad Khorsandroo, Maanak Gupta",
        "summary": "Machine learning (ML) has seen exponential growth in recent years, finding applications in various domains such as finance, medicine, and cybersecurity. Malware remains a significant threat to modern computing, frequently used by attackers to compromise systems. While numerous machine learning-based approaches for malware detection achieve high performance, they often lack transparency and fail to explain their predictions. This is a critical drawback in malware analysis, where understanding the rationale behind detections is essential for security analysts to verify and disseminate information. Explainable AI (XAI) addresses this issue by maintaining high accuracy while producing models that provide clear, understandable explanations for their decisions. In this survey, we comprehensively review the current state-of-the-art ML-based malware detection techniques and popular XAI approaches. Additionally, we discuss research implementations and the challenges of explainable malware analysis. This theoretical survey serves as an entry point for researchers interested in XAI applications in malware detection. By analyzing recent advancements in explainable malware analysis, we offer a broad overview of the progress in this field, positioning our work as the first to extensively cover XAI methods for malware classification and detection.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2024-09-09 08:19:33 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.843755"
    },
    {
        "index": "#268",
        "title": "WebQuest: A Benchmark for Multimodal QA on Web Page Sequences",
        "link": "/arxiv/2409.13711",
        "arxiv_id": "2409.13711",
        "authors": "Maria Wang, Srinivas Sunkara, Gilles Baechler, Jason Lin, Yun Zhu, Fedir Zubach, Lei Shu, Jindong Chen",
        "summary": "The rise of multimodal LLMs and web agents calls for the creation of challenging benchmarks to evaluate neural architectures. Unlike existing benchmarks that focus on multi-step web navigation, we present WebQuest, a multi-page question-answering dataset that requires simultaneous retrieval and reasoning across web interaction sequences grounded in real-world usage. WebQuest includes three question categories: single-screen reasoning, multi-screen reasoning, and questions based on navigation traces. We evaluate some of the leading multimodal models like GPT-4V, Gemini Flash, and Claude 3 on our dataset, revealing a significant gap between single-screen and multi-screen reasoning. Finally, we investigate inference time techniques like Chain-of-Thought prompting to improve model capabilities on multi-screen reasoning.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2024-09-06 18:44:25 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.866305"
    },
    {
        "index": "#274",
        "title": "MAS4POI: a Multi-Agents Collaboration System for Next POI Recommendation",
        "link": "/arxiv/2409.13700",
        "arxiv_id": "2409.13700",
        "authors": "Yuqian Wu, Yuhong Peng, Jiapeng Yu, Raymond S. T. Lee",
        "summary": "LLM-based Multi-Agent Systems have potential benefits of complex decision-making tasks management across various domains but their applications in the next Point-of-Interest (POI) recommendation remain underexplored. This paper proposes a novel MAS4POI system designed to enhance next POI recommendations through multi-agent interactions. MAS4POI supports Large Language Models (LLMs) specializing in distinct agents such as DataAgent, Manager, Analyst, and Navigator with each contributes to a collaborative process of generating the next POI recommendations.The system is examined by integrating six distinct LLMs and evaluated by two real-world datasets for recommendation accuracy improvement in real-world scenarios. Our code is available at https://github.com/yuqian2003/MAS4POI.",
        "subjects": "Information Retrieval, Artificial Intelligence, Social and Information Networks",
        "date": "2024-09-05 02:47:49 UTC",
        "category": "cs.AI",
        "crawl_time": "2025-09-24T16:31:00.867658"
    },
    {
        "index": "#2",
        "title": "Peer-to-Peer Learning Dynamics of Wide Neural Networks",
        "link": "/arxiv/2409.15267",
        "arxiv_id": "2409.15267",
        "authors": "Shreyas Chaudhari, Srinivasa Pranav, Emile Anand, José M. F. Moura",
        "summary": "Peer-to-peer learning is an increasingly popular framework that enables beyond-5G distributed edge devices to collaboratively train deep neural networks in a privacy-preserving manner without the aid of a central server. Neural network training algorithms for emerging environments, e.g., smart cities, have many design considerations that are difficult to tune in deployment settings -- such as neural network architectures and hyperparameters. This presents a critical need for characterizing the training dynamics of distributed optimization algorithms used to train highly nonconvex neural networks in peer-to-peer learning environments. In this work, we provide an explicit, non-asymptotic characterization of the learning dynamics of wide neural networks trained using popular distributed gradient descent (DGD) algorithms. Our results leverage both recent advancements in neural tangent kernel (NTK) theory and extensive previous work on distributed learning and consensus. We validate our analytical results by accurately predicting the parameter and error dynamics of wide neural networks trained for classification tasks.",
        "subjects": "Machine Learning, Systems and Control",
        "date": "2024-09-23 17:57:58 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.813826"
    },
    {
        "index": "#6",
        "title": "MotifDisco: Motif Causal Discovery For Time Series Motifs",
        "link": "/arxiv/2409.15219",
        "arxiv_id": "2409.15219",
        "authors": "Josephine Lamp, Mark Derdzinski, Christopher Hannemann, Sam Hatfield, Joost van der Linden",
        "summary": "Many time series, particularly health data streams, can be best understood as a sequence of phenomenon or events, which we call motifs. A time series motif is a short trace segment which may implicitly capture an underlying phenomenon within the time series. Specifically, we focus on glucose traces collected from continuous glucose monitors (CGMs), which inherently contain motifs representing underlying human behaviors such as eating and exercise. The ability to identify and quantify causal relationships amongst motifs can provide a mechanism to better understand and represent these patterns, useful for improving deep learning and generative models and for advanced technology development (e.g., personalized coaching and artificial insulin delivery systems). However, no previous work has developed causal discovery methods for time series motifs. Therefore, in this paper we develop MotifDisco (motif disco-very of causality), a novel causal discovery framework to learn causal relations amongst motifs from time series traces. We formalize a notion of Motif Causality (MC), inspired from Granger Causality and Transfer Entropy, and develop a Graph Neural Network-based framework that learns causality between motifs by solving an unsupervised link prediction problem. We also integrate MC with three model use cases of forecasting, anomaly detection and clustering, to showcase the use of MC as a building block for other downstream tasks. Finally, we evaluate our framework and find that Motif Causality provides a significant performance improvement in all use cases.",
        "subjects": "Machine Learning",
        "date": "2024-09-23 17:08:37 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.814705"
    },
    {
        "index": "#8",
        "title": "Enabling Tensor Decomposition for Time-Series Classification via A Simple Pseudo-Laplacian Contrast",
        "link": "/arxiv/2409.15200",
        "arxiv_id": "2409.15200",
        "authors": "Man Li, Ziyue Li, Lijun Sun, Fugee Tsung",
        "summary": "Tensor decomposition has emerged as a prominent technique to learn low-dimensional representation under the supervision of reconstruction error, primarily benefiting data inference tasks like completion and imputation, but not classification task. We argue that the non-uniqueness and rotation invariance of tensor decomposition allow us to identify the directions with largest class-variability and simple graph Laplacian can effectively achieve this objective. Therefore we propose a novel Pseudo Laplacian Contrast (PLC) tensor decomposition framework, which integrates the data augmentation and cross-view Laplacian to enable the extraction of class-aware representations while effectively capturing the intrinsic low-rank structure within reconstruction constraint. An unsupervised alternative optimization algorithm is further developed to iteratively estimate the pseudo graph and minimize the loss using Alternating Least Square (ALS). Extensive experimental results on various datasets demonstrate the effectiveness of our approach.",
        "subjects": "Machine Learning",
        "date": "2024-09-23 16:48:13 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.815099"
    },
    {
        "index": "#9",
        "title": "Data-driven model discovery with Kolmogorov-Arnold networks",
        "link": "/arxiv/2409.15167",
        "arxiv_id": "2409.15167",
        "authors": "Mohammadamin Moradi, Shirin Panahi, Erik M. Bollt, Ying-Cheng Lai",
        "summary": "Data-driven model discovery of complex dynamical systems is typically done using sparse optimization, but it has a fundamental limitation: sparsity in that the underlying governing equations of the system contain only a small number of elementary mathematical terms. Examples where sparse optimization fails abound, such as the classic Ikeda or optical-cavity map in nonlinear dynamics and a large variety of ecosystems. Exploiting the recently articulated Kolmogorov-Arnold networks, we develop a general model-discovery framework for any dynamical systems including those that do not satisfy the sparsity condition. In particular, we demonstrate non-uniqueness in that a large number of approximate models of the system can be found which generate the same invariant set with the correct statistics such as the Lyapunov exponents and Kullback-Leibler divergence. An analogy to shadowing of numerical trajectories in chaotic systems is pointed out.",
        "subjects": "Machine Learning, Dynamical Systems, Chaotic Dynamics, Data Analysis, Statistics and Probability",
        "date": "2024-09-23 16:22:07 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.815336"
    },
    {
        "index": "#10",
        "title": "A Gated Residual Kolmogorov-Arnold Networks for Mixtures of Experts",
        "link": "/arxiv/2409.15161",
        "arxiv_id": "2409.15161",
        "authors": "Hugo Inzirillo, Remi Genet",
        "summary": "This paper introduces KAMoE, a novel Mixture of Experts (MoE) framework based on Gated Residual Kolmogorov-Arnold Networks (GRKAN). We propose GRKAN as an alternative to the traditional gating function, aiming to enhance efficiency and interpretability in MoE modeling. Through extensive experiments on digital asset markets and real estate valuation, we demonstrate that KAMoE consistently outperforms traditional MoE architectures across various tasks and model types. Our results show that GRKAN exhibits superior performance compared to standard Gating Residual Networks, particularly in LSTM-based models for sequential tasks. We also provide insights into the trade-offs between model complexity and performance gains in MoE and KAMoE architectures.",
        "subjects": "Machine Learning, Neural and Evolutionary Computing",
        "date": "2024-09-23 16:11:43 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.815512"
    },
    {
        "index": "#11",
        "title": "Rethinking Conventional Wisdom in Machine Learning: From Generalization to Scaling",
        "link": "/arxiv/2409.15156",
        "arxiv_id": "2409.15156",
        "authors": "Lechao Xiao",
        "summary": "The remarkable success of large language pretraining and the discovery of scaling laws signify a paradigm shift in machine learning. Notably, the primary objective has evolved from minimizing generalization error to reducing approximation error, and the most effective strategy has transitioned from regularization (in a broad sense) to scaling up models. This raises a critical question: Do the established principles that proved successful in the generalization-centric era remain valid in this new era of scaling? This paper examines several influential regularization-based principles that may no longer hold true in the scaling-centric, large language model (LLM) era. These principles include explicit L2 regularization and implicit regularization through small batch sizes and large learning rates. Additionally, we identify a new phenomenon termed ``scaling law crossover,'' where two scaling curves intersect at a certain scale, implying that methods effective at smaller scales may not generalize to larger ones. Together, these observations highlight two fundamental questions within this new paradigm: $\\bullet$ Guiding Principles for Scaling: If regularization is no longer the primary guiding principle for model design, what new principles are emerging to guide scaling? $\\bullet$ Model Comparison at Scale: How to reliably and effectively compare models at the scale where only a single experiment is feasible?",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2024-09-23 16:04:03 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.815685"
    },
    {
        "index": "#12",
        "title": "Designing an Interpretable Interface for Contextual Bandits",
        "link": "/arxiv/2409.15143",
        "arxiv_id": "2409.15143",
        "authors": "Andrew Maher, Matia Gobbo, Lancelot Lachartre, Subash Prabanantham, Rowan Swiers, Puli Liyanagama",
        "summary": "Contextual bandits have become an increasingly popular solution for personalized recommender systems. Despite their growing use, the interpretability of these systems remains a significant challenge, particularly for the often non-expert operators tasked with ensuring their optimal performance. In this paper, we address this challenge by designing a new interface to explain to domain experts the underlying behaviour of a bandit. Central is a metric we term \"value gain\", a measure derived from off-policy evaluation to quantify the real-world impact of sub-components within a bandit. We conduct a qualitative user study to evaluate the effectiveness of our interface. Our findings suggest that by carefully balancing technical rigour with accessible presentation, it is possible to empower non-experts to manage complex machine learning systems. We conclude by outlining guiding principles that other researchers should consider when building similar such interfaces in future.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2024-09-23 15:47:44 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.815932"
    },
    {
        "index": "#13",
        "title": "The Number of Trials Matters in Infinite-Horizon General-Utility Markov Decision Processes",
        "link": "/arxiv/2409.15128",
        "arxiv_id": "2409.15128",
        "authors": "Pedro P. Santos, Alberto Sardinha, Francisco S. Melo",
        "summary": "The general-utility Markov decision processes (GUMDPs) framework generalizes the MDPs framework by considering objective functions that depend on the frequency of visitation of state-action pairs induced by a given policy. In this work, we contribute with the first analysis on the impact of the number of trials, i.e., the number of randomly sampled trajectories, in infinite-horizon GUMDPs. We show that, as opposed to standard MDPs, the number of trials plays a key-role in infinite-horizon GUMDPs and the expected performance of a given policy depends, in general, on the number of trials. We consider both discounted and average GUMDPs, where the objective function depends, respectively, on discounted and average frequencies of visitation of state-action pairs. First, we study policy evaluation under discounted GUMDPs, proving lower and upper bounds on the mismatch between the finite and infinite trials formulations for GUMDPs. Second, we address average GUMDPs, studying how different classes of GUMDPs impact the mismatch between the finite and infinite trials formulations. Third, we provide a set of empirical results to support our claims, highlighting how the number of trajectories and the structure of the underlying GUMDP influence policy evaluation.",
        "subjects": "Machine Learning",
        "date": "2024-09-23 15:34:45 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.816116"
    },
    {
        "index": "#16",
        "title": "AdapFair: Ensuring Continuous Fairness for Machine Learning Operations",
        "link": "/arxiv/2409.15088",
        "arxiv_id": "2409.15088",
        "authors": "Yinghui Huang, Zihao Tang, Xiangyu Chang",
        "summary": "The biases and discrimination of machine learning algorithms have attracted significant attention, leading to the development of various algorithms tailored to specific contexts. However, these solutions often fall short of addressing fairness issues inherent in machine learning operations. In this paper, we present a debiasing framework designed to find an optimal fair transformation of input data that maximally preserves data predictability. A distinctive feature of our approach is its flexibility and efficiency. It can be integrated with any downstream black-box classifiers, providing continuous fairness guarantees with minimal retraining efforts, even in the face of frequent data drifts, evolving fairness requirements, and batches of similar tasks. To achieve this, we leverage the normalizing flows to enable efficient, information-preserving data transformation, ensuring that no critical information is lost during the debiasing process. Additionally, we incorporate the Wasserstein distance as the unfairness measure to guide the optimization of data transformations. Finally, we introduce an efficient optimization algorithm with closed-formed gradient computations, making our framework scalable and suitable for dynamic, real-world environments.",
        "subjects": "Machine Learning, Computers and Society",
        "date": "2024-09-23 15:01:47 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.816680"
    },
    {
        "index": "#17",
        "title": "SHFL: Secure Hierarchical Federated Learning Framework for Edge Networks",
        "link": "/arxiv/2409.15067",
        "arxiv_id": "2409.15067",
        "authors": "Omid Tavallaie, Kanchana Thilakarathna, Suranga Seneviratne, Aruna Seneviratne, Albert Y. Zomaya",
        "summary": "Federated Learning (FL) is a distributed machine learning paradigm designed for privacy-sensitive applications that run on resource-constrained devices with non-Identically and Independently Distributed (IID) data. Traditional FL frameworks adopt the client-server model with a single-level aggregation (AGR) process, where the server builds the global model by aggregating all trained local models received from client devices. However, this conventional approach encounters challenges, including susceptibility to model/data poisoning attacks. In recent years, advancements in the Internet of Things (IoT) and edge computing have enabled the development of hierarchical FL systems with a two-level AGR process running at edge and cloud servers. In this paper, we propose a Secure Hierarchical FL (SHFL) framework to address poisoning attacks in hierarchical edge networks. By aggregating trained models at the edge, SHFL employs two novel methods to address model/data poisoning attacks in the presence of client adversaries: 1) a client selection algorithm running at the edge for choosing IoT devices to participate in training, and 2) a model AGR method designed based on convex optimization theory to reduce the impact of edge models from networks with adversaries in the process of computing the global model (at the cloud level). The evaluation results reveal that compared to state-of-the-art methods, SHFL significantly increases the maximum accuracy achieved by the global model in the presence of client adversaries applying model/data poisoning attacks.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2024-09-23 14:38:20 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.816877"
    },
    {
        "index": "#18",
        "title": "Anomaly Detection from a Tensor Train Perspective",
        "link": "/arxiv/2409.15030",
        "arxiv_id": "2409.15030",
        "authors": "Alejandro Mata Ali, Aitor Moreno Fdez. de Leceta, Jorge López Rubio",
        "summary": "We present a series of algorithms in tensor networks for anomaly detection in datasets, by using data compression in a Tensor Train representation. These algorithms consist of preserving the structure of normal data in compression and deleting the structure of anomalous data. The algorithms can be applied to any tensor network representation. We test the effectiveness of the methods with digits and Olivetti faces datasets and a cybersecurity dataset to determine cyber-attacks.",
        "subjects": "Machine Learning, Cryptography and Security, Emerging Technologies, Information Theory, Quantum Physics",
        "date": "2024-09-23 13:55:58 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.817086"
    },
    {
        "index": "#20",
        "title": "Evaluating Synthetic Activations composed of SAE Latents in GPT-2",
        "link": "/arxiv/2409.15019",
        "arxiv_id": "2409.15019",
        "authors": "Giorgi Giglemiani, Nora Petrova, Chatrik Singh Mangat, Jett Janiak, Stefan Heimersheim",
        "summary": "Sparse Auto-Encoders (SAEs) are commonly employed in mechanistic interpretability to decompose the residual stream into monosemantic SAE latents. Recent work demonstrates that perturbing a model's activations at an early layer results in a step-function-like change in the model's final layer activations. Furthermore, the model's sensitivity to this perturbation differs between model-generated (real) activations and random activations. In our study, we assess model sensitivity in order to compare real activations to synthetic activations composed of SAE latents. Our findings indicate that synthetic activations closely resemble real activations when we control for the sparsity and cosine similarity of the constituent SAE latents. This suggests that real activations cannot be explained by a simple \"bag of SAE latents\" lacking internal structure, and instead suggests that SAE latents possess significant geometric and statistical properties. Notably, we observe that our synthetic activations exhibit less pronounced activation plateaus compared to those typically surrounding real activations.",
        "subjects": "Machine Learning",
        "date": "2024-09-23 13:46:38 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.817500"
    },
    {
        "index": "#22",
        "title": "Adaptive Learning on User Segmentation: Universal to Specific Representation via Bipartite Neural Interaction",
        "link": "/arxiv/2409.14945",
        "arxiv_id": "2409.14945",
        "authors": "Xiaoyu Tan, Yongxin Deng, Chao Qu, Siqiao Xue, Xiaoming Shi, James Zhang, Xihe Qiu",
        "summary": "Recently, models for user representation learning have been widely applied in click-through-rate (CTR) and conversion-rate (CVR) prediction. Usually, the model learns a universal user representation as the input for subsequent scenario-specific models. However, in numerous industrial applications (e.g., recommendation and marketing), the business always operates such applications as various online activities among different user segmentation. These segmentation are always created by domain experts. Due to the difference in user distribution (i.e., user segmentation) and business objectives in subsequent tasks, learning solely on universal representation may lead to detrimental effects on both model performance and robustness. In this paper, we propose a novel learning framework that can first learn general universal user representation through information bottleneck. Then, merge and learn a segmentation-specific or a task-specific representation through neural interaction. We design the interactive learning process by leveraging a bipartite graph architecture to model the representation learning and merging between contextual clusters and each user segmentation. Our proposed method is evaluated in two open-source benchmarks, two offline business datasets, and deployed on two online marketing applications to predict users' CVR. The results demonstrate that our method can achieve superior performance and surpass the baseline methods.",
        "subjects": "Machine Learning, Information Retrieval",
        "date": "2024-09-23 12:02:23 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.817942"
    },
    {
        "index": "#23",
        "title": "FastGL: A GPU-Efficient Framework for Accelerating Sampling-Based GNN Training at Large Scale",
        "link": "/arxiv/2409.14939",
        "arxiv_id": "2409.14939",
        "authors": "Zeyu Zhu, Peisong Wang, Qinghao Hu, Gang Li, Xiaoyao Liang, Jian Cheng",
        "summary": "Graph Neural Networks (GNNs) have shown great superiority on non-Euclidean graph data, achieving ground-breaking performance on various graph-related tasks. As a practical solution to train GNN on large graphs with billions of nodes and edges, the sampling-based training is widely adopted by existing training frameworks. However, through an in-depth analysis, we observe that the efficiency of existing sampling-based training frameworks is still limited due to the key bottlenecks lying in all three phases of sampling-based training, i.e., subgraph sample, memory IO, and computation. To this end, we propose FastGL, a GPU-efficient Framework for accelerating sampling-based training of GNN at Large scale by simultaneously optimizing all above three phases, taking into account both GPU characteristics and graph structure. Specifically, by exploiting the inherent overlap within graph structures, FastGL develops the Match-Reorder strategy to reduce the data traffic, which accelerates the memory IO without incurring any GPU memory overhead. Additionally, FastGL leverages a Memory-Aware computation method, harnessing the GPU memory's hierarchical nature to mitigate irregular data access during computation. FastGL further incorporates the Fused-Map approach aimed at diminishing the synchronization overhead during sampling. Extensive experiments demonstrate that FastGL can achieve an average speedup of 11.8x, 2.2x and 1.5x over the state-of-the-art frameworks PyG, DGL, and GNNLab, respectively.Our code is available at https://github.com/a1bc2def6g/fastgl-ae.",
        "subjects": "Machine Learning, Hardware Architecture, Distributed, Parallel, and Cluster Computing",
        "date": "2024-09-23 11:45:47 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.818159"
    },
    {
        "index": "#24",
        "title": "Kriformer: A Novel Spatiotemporal Kriging Approach Based on Graph Transformers",
        "link": "/arxiv/2409.14906",
        "arxiv_id": "2409.14906",
        "authors": "Renbin Pan, Feng Xiao, Hegui Zhang, Minyu Shen",
        "summary": "Accurately estimating data in sensor-less areas is crucial for understanding system dynamics, such as traffic state estimation and environmental monitoring. This study addresses challenges posed by sparse sensor deployment and unreliable data by framing the problem as a spatiotemporal kriging task and proposing a novel graph transformer model, Kriformer. This model estimates data at locations without sensors by mining spatial and temporal correlations, even with limited resources. Kriformer utilizes transformer architecture to enhance the model's perceptual range and solve edge information aggregation challenges, capturing spatiotemporal information effectively. A carefully constructed positional encoding module embeds the spatiotemporal features of nodes, while a sophisticated spatiotemporal attention mechanism enhances estimation accuracy. The multi-head spatial interaction attention module captures subtle spatial relationships between observed and unobserved locations. During training, a random masking strategy prompts the model to learn with partial information loss, allowing the spatiotemporal embedding and multi-head attention mechanisms to synergistically capture correlations among locations. Experimental results show that Kriformer excels in representation learning for unobserved locations, validated on two real-world traffic speed datasets, demonstrating its effectiveness in spatiotemporal kriging tasks.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2024-09-23 11:01:18 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.818346"
    },
    {
        "index": "#25",
        "title": "Novel Gradient Sparsification Algorithm via Bayesian Inference",
        "link": "/arxiv/2409.14893",
        "arxiv_id": "2409.14893",
        "authors": "Ali Bereyhi, Ben Liang, Gary Boudreau, Ali Afana",
        "summary": "Error accumulation is an essential component of the Top-$k$ sparsification method in distributed gradient descent. It implicitly scales the learning rate and prevents the slow-down of lateral movement, but it can also deteriorate convergence. This paper proposes a novel sparsification algorithm called regularized Top-$k$ (RegTop-$k$) that controls the learning rate scaling of error accumulation. The algorithm is developed by looking at the gradient sparsification as an inference problem and determining a Bayesian optimal sparsification mask via maximum-a-posteriori estimation. It utilizes past aggregated gradients to evaluate posterior statistics, based on which it prioritizes the local gradient entries. Numerical experiments with ResNet-18 on CIFAR-10 show that at $0.1\\%$ sparsification, RegTop-$k$ achieves about $8\\%$ higher accuracy than standard Top-$k$.",
        "subjects": "Machine Learning, Information Theory, Signal Processing",
        "date": "2024-09-23 10:42:34 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.823914"
    },
    {
        "index": "#26",
        "title": "Testing Dependency of Weighted Random Graphs",
        "link": "/arxiv/2409.14870",
        "arxiv_id": "2409.14870",
        "authors": "Mor Oren, Vered Paslev, Wasim Huleihel",
        "summary": "In this paper, we study the task of detecting the edge dependency between two weighted random graphs. We formulate this task as a simple hypothesis testing problem, where under the null hypothesis, the two observed graphs are statistically independent, whereas under the alternative, the edges of one graph are dependent on the edges of a randomly vertex-permuted version of the other graph. For general edge-weights distributions, we establish thresholds at which optimal testing is information-theoretically impossible and possible, as a function of the total number of nodes in the observed graphs and the generative distributions of the weights. Finally, we observe a statistical-computational gap in our problem, and we provide evidence that this is fundamental using the framework of low-degree polynomials.",
        "subjects": "Machine Learning, Information Theory",
        "date": "2024-09-23 10:07:41 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.824114"
    },
    {
        "index": "#28",
        "title": "SDBA: A Stealthy and Long-Lasting Durable Backdoor Attack in Federated Learning",
        "link": "/arxiv/2409.14805",
        "arxiv_id": "2409.14805",
        "authors": "Minyeong Choe, Cheolhee Park, Changho Seo, Hyunil Kim",
        "summary": "Federated Learning is a promising approach for training machine learning models while preserving data privacy, but its distributed nature makes it vulnerable to backdoor attacks, particularly in NLP tasks while related research remains limited. This paper introduces SDBA, a novel backdoor attack mechanism designed for NLP tasks in FL environments. Our systematic analysis across LSTM and GPT-2 models identifies the most vulnerable layers for backdoor injection and achieves both stealth and long-lasting durability through layer-wise gradient masking and top-k% gradient masking within these layers. Experiments on next token prediction and sentiment analysis tasks show that SDBA outperforms existing backdoors in durability and effectively bypasses representative defense mechanisms, with notable performance in LLM such as GPT-2. These results underscore the need for robust defense strategies in NLP-based FL systems.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2024-09-23 08:30:57 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.824513"
    },
    {
        "index": "#30",
        "title": "Isometric Immersion Learning with Riemannian Geometry",
        "link": "/arxiv/2409.14760",
        "arxiv_id": "2409.14760",
        "authors": "Zihao Chen, Wenyong Wang, Yu Xiang",
        "summary": "Manifold learning has been proven to be an effective method for capturing the implicitly intrinsic structure of non-Euclidean data, in which one of the primary challenges is how to maintain the distortion-free (isometry) of the data representations. Actually, there is still no manifold learning method that provides a theoretical guarantee of isometry. Inspired by Nash's isometric theorem, we introduce a new concept called isometric immersion learning based on Riemannian geometry principles. Following this concept, an unsupervised neural network-based model that simultaneously achieves metric and manifold learning is proposed by integrating Riemannian geometry priors. What's more, we theoretically derive and algorithmically implement a maximum likelihood estimation-based training method for the new model. In the simulation experiments, we compared the new model with the state-of-the-art baselines on various 3-D geometry datasets, demonstrating that the new model exhibited significantly superior performance in multiple evaluation metrics. Moreover, we applied the Riemannian metric learned from the new model to downstream prediction tasks in real-world scenarios, and the accuracy was improved by an average of 8.8%.",
        "subjects": "Machine Learning",
        "date": "2024-09-23 07:17:06 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.824890"
    },
    {
        "index": "#33",
        "title": "From Lazy to Rich: Exact Learning Dynamics in Deep Linear Networks",
        "link": "/arxiv/2409.14623",
        "arxiv_id": "2409.14623",
        "authors": "Clémentine C. J. Dominé, Nicolas Anguita, Alexandra M. Proca, Lukas Braun, Daniel Kunin, Pedro A. M. Mediano, Andrew M. Saxe",
        "summary": "Biological and artificial neural networks develop internal representations that enable them to perform complex tasks. In artificial networks, the effectiveness of these models relies on their ability to build task specific representation, a process influenced by interactions among datasets, architectures, initialization strategies, and optimization algorithms. Prior studies highlight that different initializations can place networks in either a lazy regime, where representations remain static, or a rich/feature learning regime, where representations evolve dynamically. Here, we examine how initialization influences learning dynamics in deep linear neural networks, deriving exact solutions for lambda-balanced initializations-defined by the relative scale of weights across layers. These solutions capture the evolution of representations and the Neural Tangent Kernel across the spectrum from the rich to the lazy regimes. Our findings deepen the theoretical understanding of the impact of weight initialization on learning regimes, with implications for continual learning, reversal learning, and transfer learning, relevant to both neuroscience and practical applications.",
        "subjects": "Machine Learning",
        "date": "2024-09-22 23:19:04 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.825530"
    },
    {
        "index": "#34",
        "title": "Protein-Mamba: Biological Mamba Models for Protein Function Prediction",
        "link": "/arxiv/2409.14617",
        "arxiv_id": "2409.14617",
        "authors": "Bohao Xu, Yingzhou Lu, Yoshitaka Inoue, Namkyeong Lee, Tianfan Fu, Jintai Chen",
        "summary": "Protein function prediction is a pivotal task in drug discovery, significantly impacting the development of effective and safe therapeutics. Traditional machine learning models often struggle with the complexity and variability inherent in predicting protein functions, necessitating more sophisticated approaches. In this work, we introduce Protein-Mamba, a novel two-stage model that leverages both self-supervised learning and fine-tuning to improve protein function prediction. The pre-training stage allows the model to capture general chemical structures and relationships from large, unlabeled datasets, while the fine-tuning stage refines these insights using specific labeled datasets, resulting in superior prediction performance. Our extensive experiments demonstrate that Protein-Mamba achieves competitive performance, compared with a couple of state-of-the-art methods across a range of protein function datasets. This model's ability to effectively utilize both unlabeled and labeled data highlights the potential of self-supervised learning in advancing protein function prediction and offers a promising direction for future research in drug discovery.",
        "subjects": "Machine Learning, Biomolecules, Quantitative Methods",
        "date": "2024-09-22 22:51:56 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.825743"
    },
    {
        "index": "#35",
        "title": "Implicit Dynamical Flow Fusion (IDFF) for Generative Modeling",
        "link": "/arxiv/2409.14599",
        "arxiv_id": "2409.14599",
        "authors": "Mohammad R. Rezaei, Rahul G. Krishnan, Milos R. Popovic, Milad Lankarany",
        "summary": "Conditional Flow Matching (CFM) models can generate high-quality samples from a non-informative prior, but they can be slow, often needing hundreds of network evaluations (NFE). To address this, we propose Implicit Dynamical Flow Fusion (IDFF); IDFF learns a new vector field with an additional momentum term that enables taking longer steps during sample generation while maintaining the fidelity of the generated distribution. Consequently, IDFFs reduce the NFEs by a factor of ten (relative to CFMs) without sacrificing sample quality, enabling rapid sampling and efficient handling of image and time-series data generation tasks. We evaluate IDFF on standard benchmarks such as CIFAR-10 and CelebA for image generation. We achieved likelihood and quality performance comparable to CFMs and diffusion-based models with fewer NFEs. IDFF also shows superior performance on time-series datasets modeling, including molecular simulation and sea surface temperature (SST) datasets, highlighting its versatility and effectiveness across different domains.",
        "subjects": "Machine Learning",
        "date": "2024-09-22 21:22:35 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.825920"
    },
    {
        "index": "#39",
        "title": "Domain knowledge-guided machine learning framework for state of health estimation in Lithium-ion batteries",
        "link": "/arxiv/2409.14575",
        "arxiv_id": "2409.14575",
        "authors": "Andrea Lanubile, Pietro Bosoni, Gabriele Pozzato, Anirudh Allam, Matteo Acquarone, Simona Onori",
        "summary": "Accurate estimation of battery state of health is crucial for effective electric vehicle battery management. Here, we propose five health indicators that can be extracted online from real-world electric vehicle operation and develop a machine learning-based method to estimate the battery state of health. The proposed indicators provide physical insights into the energy and power fade of the battery and enable accurate capacity estimation even with partially missing data. Moreover, they can be computed for portions of the charging profile and real-world driving discharging conditions, facilitating real-time battery degradation estimation. The indicators are computed using experimental data from five cells aged under electric vehicle conditions, and a linear regression model is used to estimate the state of health. The results show that models trained with power autocorrelation and energy-based features achieve capacity estimation with maximum absolute percentage error within 1.5% to 2.5% .",
        "subjects": "Machine Learning, Systems and Control",
        "date": "2024-09-22 19:39:53 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.826749"
    },
    {
        "index": "#40",
        "title": "Adaptive Feedforward Gradient Estimation in Neural ODEs",
        "link": "/arxiv/2409.14549",
        "arxiv_id": "2409.14549",
        "authors": "Jaouad Dabounou",
        "summary": "Neural Ordinary Differential Equations (Neural ODEs) represent a significant breakthrough in deep learning, promising to bridge the gap between machine learning and the rich theoretical frameworks developed in various mathematical fields over centuries. In this work, we propose a novel approach that leverages adaptive feedforward gradient estimation to improve the efficiency, consistency, and interpretability of Neural ODEs. Our method eliminates the need for backpropagation and the adjoint method, reducing computational overhead and memory usage while maintaining accuracy. The proposed approach has been validated through practical applications, and showed good performance relative to Neural ODEs state of the art methods.",
        "subjects": "Machine Learning",
        "date": "2024-09-22 18:21:01 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.826907"
    },
    {
        "index": "#41",
        "title": "Distributionally Robust Inverse Reinforcement Learning for Identifying Multi-Agent Coordinated Sensing",
        "link": "/arxiv/2409.14542",
        "arxiv_id": "2409.14542",
        "authors": "Luke Snow, Vikram Krishnamurthy",
        "summary": "We derive a minimax distributionally robust inverse reinforcement learning (IRL) algorithm to reconstruct the utility functions of a multi-agent sensing system. Specifically, we construct utility estimators which minimize the worst-case prediction error over a Wasserstein ambiguity set centered at noisy signal observations. We prove the equivalence between this robust estimation and a semi-infinite optimization reformulation, and we propose a consistent algorithm to compute solutions. We illustrate the efficacy of this robust IRL scheme in numerical studies to reconstruct the utility functions of a cognitive radar network from observed tracking signals.",
        "subjects": "Machine Learning, Multiagent Systems, Signal Processing",
        "date": "2024-09-22 17:44:32 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.827084"
    },
    {
        "index": "#42",
        "title": "Order of Magnitude Speedups for LLM Membership Inference",
        "link": "/arxiv/2409.14513",
        "arxiv_id": "2409.14513",
        "authors": "Martin Bertran, Rongting Zhang, Aaron Roth",
        "summary": "Large Language Models (LLMs) have the promise to revolutionize computing broadly, but their complexity and extensive training data also expose significant privacy vulnerabilities. One of the simplest privacy risks associated with LLMs is their susceptibility to membership inference attacks (MIAs), wherein an adversary aims to determine whether a specific data point was part of the model's training set. Although this is a known risk, state of the art methodologies for MIAs rely on training multiple computationally costly shadow models, making risk evaluation prohibitive for large models. Here we adapt a recent line of work which uses quantile regression to mount membership inference attacks; we extend this work by proposing a low-cost MIA that leverages an ensemble of small quantile regression models to determine if a document belongs to the model's training set or not. We demonstrate the effectiveness of this approach on fine-tuned LLMs of varying families (OPT, Pythia, Llama) and across multiple datasets. Across all scenarios we obtain comparable or improved accuracy compared to state of the art shadow model approaches, with as little as 6% of their computation budget. We demonstrate increased effectiveness across multi-epoch trained target models, and architecture miss-specification robustness, that is, we can mount an effective attack against a model using a different tokenizer and architecture, without requiring knowledge on the target model.",
        "subjects": "Machine Learning, Cryptography and Security, Machine Learning",
        "date": "2024-09-22 16:18:14 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.827367"
    },
    {
        "index": "#46",
        "title": "Investigating the Impact of Hard Samples on Accuracy Reveals In-class Data Imbalance",
        "link": "/arxiv/2409.14401",
        "arxiv_id": "2409.14401",
        "authors": "Pawel Pukowski, Haiping Lu",
        "summary": "In the AutoML domain, test accuracy is heralded as the quintessential metric for evaluating model efficacy, underpinning a wide array of applications from neural architecture search to hyperparameter optimization. However, the reliability of test accuracy as the primary performance metric has been called into question, notably through research highlighting how label noise can obscure the true ranking of state-of-the-art models. We venture beyond, along another perspective where the existence of hard samples within datasets casts further doubt on the generalization capabilities inferred from test accuracy alone. Our investigation reveals that the distribution of hard samples between training and test sets affects the difficulty levels of those sets, thereby influencing the perceived generalization capability of models. We unveil two distinct generalization pathways-toward easy and hard samples-highlighting the complexity of achieving balanced model evaluation. Finally, we propose a benchmarking procedure for comparing hard sample identification methods, facilitating the advancement of more nuanced approaches in this area. Our primary goal is not to propose a definitive solution but to highlight the limitations of relying primarily on test accuracy as an evaluation metric, even when working with balanced datasets, by introducing the in-class data imbalance problem. By doing so, we aim to stimulate a critical discussion within the research community and open new avenues for research that consider a broader spectrum of model evaluation criteria. The anonymous code is available at https://github.com/PawPuk/CurvBIM blueunder the GPL-3.0 license.",
        "subjects": "Machine Learning",
        "date": "2024-09-22 11:38:14 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.828210"
    },
    {
        "index": "#47",
        "title": "Flat-LoRA: Low-Rank Adaption over a Flat Loss Landscape",
        "link": "/arxiv/2409.14396",
        "arxiv_id": "2409.14396",
        "authors": "Tao Li, Zhengbao He, Yujun Li, Yasheng Wang, Lifeng Shang, Xiaolin Huang",
        "summary": "Fine-tuning large-scale pre-trained models is prohibitively expensive in terms of computational and memory costs. Low-Rank Adaptation (LoRA), a popular Parameter-Efficient Fine-Tuning (PEFT) method, provides an efficient way to fine-tune models by optimizing only a low-rank matrix. Despite recent progress made in improving LoRA's performance, the connection between the LoRA optimization space and the original full parameter space is often overlooked. A solution that appears flat in the LoRA space may exist sharp directions in the full parameter space, potentially harming generalization performance. In this paper, we propose Flat-LoRA, an efficient approach that seeks a low-rank adaptation located in a flat region of the full parameter space.Instead of relying on the well-established sharpness-aware minimization approach, which can incur significant computational and memory burdens, we utilize random weight perturbation with a Bayesian expectation loss objective to maintain training efficiency and design a refined perturbation generation strategy for improved performance. Experiments on natural language processing and image classification tasks with various architectures demonstrate the effectiveness of our approach.",
        "subjects": "Machine Learning",
        "date": "2024-09-22 11:24:10 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.828405"
    },
    {
        "index": "#50",
        "title": "Sketch-and-Solve: Optimized Overdetermined Least-Squares Using Randomized Numerical Linear Algebra",
        "link": "/arxiv/2409.14309",
        "arxiv_id": "2409.14309",
        "authors": "Alex Lavaee",
        "summary": "Sketch-and-solve is a powerful paradigm for tackling large-scale computational problems by reducing their dimensionality using sketching matrices. This paper focuses on applying sketch-and-solve algorithms to efficiently solve the overdetermined least squares problem, which is fundamental in various domains such as machine learning, signal processing, and numerical optimization. We provide a comprehensive overview of the sketch-and-solve paradigm and analyze different sketching operators, including dense and sparse variants. We introduce the Sketch-and-Apply (SAA-SAS) algorithm, which leverages randomized numerical linear algebra techniques to compute approximate solutions efficiently. Through extensive experiments on large-scale least squares problems, we demonstrate that our proposed approach significantly outperforms the traditional Least-Squares QR (LSQR) algorithm in terms of runtime while maintaining comparable accuracy. Our results highlight the potential of sketch-and-solve techniques in efficiently handling large-scale numerical linear algebra problems.",
        "subjects": "Machine Learning, Numerical Analysis",
        "date": "2024-09-22 04:29:51 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.834237"
    },
    {
        "index": "#52",
        "title": "Structure Learning via Mutual Information",
        "link": "/arxiv/2409.14235",
        "arxiv_id": "2409.14235",
        "authors": "Jeremy Nixon",
        "summary": "This paper presents a novel approach to machine learning algorithm design based on information theory, specifically mutual information (MI). We propose a framework for learning and representing functional relationships in data using MI-based features. Our method aims to capture the underlying structure of information in datasets, enabling more efficient and generalizable learning algorithms. We demonstrate the efficacy of our approach through experiments on synthetic and real-world datasets, showing improved performance in tasks such as function classification, regression, and cross-dataset transfer. This work contributes to the growing field of metalearning and automated machine learning, offering a new perspective on how to leverage information theory for algorithm design and dataset analysis and proposing new mutual information theoretic foundations to learning algorithms.",
        "subjects": "Machine Learning, Information Theory",
        "date": "2024-09-21 19:33:56 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.834639"
    },
    {
        "index": "#53",
        "title": "ReFine: Boosting Time Series Prediction of Extreme Events by Reweighting and Fine-tuning",
        "link": "/arxiv/2409.14232",
        "arxiv_id": "2409.14232",
        "authors": "Jimeng Shi, Azam Shirali, Giri Narasimhan",
        "summary": "Extreme events are of great importance since they often represent impactive occurrences. For instance, in terms of climate and weather, extreme events might be major storms, floods, extreme heat or cold waves, and more. However, they are often located at the tail of the data distribution. Consequently, accurately predicting these extreme events is challenging due to their rarity and irregularity. Prior studies have also referred to this as the out-of-distribution (OOD) problem, which occurs when the distribution of the test data is substantially different from that used for training. In this work, we propose two strategies, reweighting and fine-tuning, to tackle the challenge. Reweighting is a strategy used to force machine learning models to focus on extreme events, which is achieved by a weighted loss function that assigns greater penalties to the prediction errors for the extreme samples relative to those on the remainder of the data. Unlike previous intuitive reweighting methods based on simple heuristics of data distribution, we employ meta-learning to dynamically optimize these penalty weights. To further boost the performance on extreme samples, we start from the reweighted models and fine-tune them using only rare extreme samples. Through extensive experiments on multiple data sets, we empirically validate that our meta-learning-based reweighting outperforms existing heuristic ones, and the fine-tuning strategy can further increase the model performance. More importantly, these two strategies are model-agnostic, which can be implemented on any type of neural network for time series forecasting. The open-sourced code is available at \\url{https://github.com/JimengShi/ReFine}.",
        "subjects": "Machine Learning",
        "date": "2024-09-21 19:29:29 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.834814"
    },
    {
        "index": "#54",
        "title": "Advancing Employee Behavior Analysis through Synthetic Data: Leveraging ABMs, GANs, and Statistical Models for Enhanced Organizational Efficiency",
        "link": "/arxiv/2409.14197",
        "arxiv_id": "2409.14197",
        "authors": "Rakshitha Jayashankar, Mahesh Balan",
        "summary": "Success in todays data-driven corporate climate requires a deep understanding of employee behavior. Companies aim to improve employee satisfaction, boost output, and optimize workflow. This research study delves into creating synthetic data, a powerful tool that allows us to comprehensively understand employee performance, flexibility, cooperation, and team dynamics. Synthetic data provides a detailed and accurate picture of employee activities while protecting individual privacy thanks to cutting-edge methods like agent-based models (ABMs), Generative Adversarial Networks (GANs), and statistical models. Through the creation of multiple situations, this method offers insightful viewpoints regarding increasing teamwork, improving adaptability, and accelerating overall productivity. We examine how synthetic data has evolved from a specialized field to an essential resource for researching employee behavior and enhancing management efficiency. Keywords: Agent-Based Model, Generative Adversarial Network, workflow optimization, organizational success",
        "subjects": "Machine Learning, Formal Languages and Automata Theory, Other Statistics",
        "date": "2024-09-21 16:58:23 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.835002"
    },
    {
        "index": "#56",
        "title": "A Distribution-Aware Flow-Matching for Generating Unstructured Data for Few-Shot Reinforcement Learning",
        "link": "/arxiv/2409.14178",
        "arxiv_id": "2409.14178",
        "authors": "Mohammad Pivezhandi, Abusayeed Saifullah",
        "summary": "Generating realistic and diverse unstructured data is a significant challenge in reinforcement learning (RL), particularly in few-shot learning scenarios where data is scarce. Traditional RL methods often rely on extensive datasets or simulations, which are costly and time-consuming. In this paper, we introduce a distribution-aware flow matching, designed to generate synthetic unstructured data tailored specifically for an application of few-shot RL called Dynamic Voltage and Frequency Scaling (DVFS) on embedded processors. This method leverages the sample efficiency of flow matching and incorporates statistical learning techniques such as bootstrapping to improve its generalization and robustness of the latent space. Additionally, we apply feature weighting through Random Forests to prioritize critical data aspects, thereby improving the precision of the generated synthetic data. This approach not only mitigates the challenges of overfitting and data correlation in unstructured data in traditional Model-Based RL but also aligns with the Law of Large Numbers, ensuring convergence to true empirical values and optimal policy as the number of samples increases. Through extensive experimentation on an application of DVFS for low energy processing, we demonstrate that our method provides an stable convergence based on max Q-value while enhancing frame rate by 30\\% in the very beginning first timestamps, making this RL model efficient in resource-constrained environments.",
        "subjects": "Machine Learning",
        "date": "2024-09-21 15:50:59 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.835389"
    },
    {
        "index": "#57",
        "title": "Component-based Sketching for Deep ReLU Nets",
        "link": "/arxiv/2409.14174",
        "arxiv_id": "2409.14174",
        "authors": "Di Wang, Shao-Bo Lin, Deyu Meng, Feilong Cao",
        "summary": "Deep learning has made profound impacts in the domains of data mining and AI, distinguished by the groundbreaking achievements in numerous real-world applications and the innovative algorithm design philosophy. However, it suffers from the inconsistency issue between optimization and generalization, as achieving good generalization, guided by the bias-variance trade-off principle, favors under-parameterized networks, whereas ensuring effective convergence of gradient-based algorithms demands over-parameterized networks. To address this issue, we develop a novel sketching scheme based on deep net components for various tasks. Specifically, we use deep net components with specific efficacy to build a sketching basis that embodies the advantages of deep networks. Subsequently, we transform deep net training into a linear empirical risk minimization problem based on the constructed basis, successfully avoiding the complicated convergence analysis of iterative algorithms. The efficacy of the proposed component-based sketching is validated through both theoretical analysis and numerical experiments. Theoretically, we show that the proposed component-based sketching provides almost optimal rates in approximating saturated functions for shallow nets and also achieves almost optimal generalization error bounds. Numerically, we demonstrate that, compared with the existing gradient-based training methods, component-based sketching possesses superior generalization performance with reduced training costs.",
        "subjects": "Machine Learning, Statistics Theory",
        "date": "2024-09-21 15:30:43 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.835663"
    },
    {
        "index": "#58",
        "title": "When Witnesses Defend: A Witness Graph Topological Layer for Adversarial Graph Learning",
        "link": "/arxiv/2409.14161",
        "arxiv_id": "2409.14161",
        "authors": "Naheed Anjum Arafat, Debabrota Basu, Yulia Gel, Yuzhou Chen",
        "summary": "Capitalizing on the intuitive premise that shape characteristics are more robust to perturbations, we bridge adversarial graph learning with the emerging tools from computational topology, namely, persistent homology representations of graphs. We introduce the concept of witness complex to adversarial analysis on graphs, which allows us to focus only on the salient shape characteristics of graphs, yielded by the subset of the most essential nodes (i.e., landmarks), with minimal loss of topological information on the whole graph. The remaining nodes are then used as witnesses, governing which higher-order graph substructures are incorporated into the learning process. Armed with the witness mechanism, we design Witness Graph Topological Layer (WGTL), which systematically integrates both local and global topological graph feature representations, the impact of which is, in turn, automatically controlled by the robust regularized topological loss. Given the attacker's budget, we derive the important stability guarantees of both local and global topology encodings and the associated robust topological loss. We illustrate the versatility and efficiency of WGTL by its integration with five GNNs and three existing non-topological defense mechanisms. Our extensive experiments across six datasets demonstrate that WGTL boosts the robustness of GNNs across a range of perturbations and against a range of adversarial attacks, leading to relative gains of up to 18%.",
        "subjects": "Machine Learning",
        "date": "2024-09-21 14:53:32 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.835857"
    },
    {
        "index": "#59",
        "title": "ESDS: AI-Powered Early Stunting Detection and Monitoring System using Edited Radius-SMOTE Algorithm",
        "link": "/arxiv/2409.14105",
        "arxiv_id": "2409.14105",
        "authors": "A. A. Gde Yogi Pramana, Haidar Muhammad Zidan, Muhammad Fazil Maulana, Oskar Natan",
        "summary": "Stunting detection is a significant issue in Indonesian healthcare, causing lower cognitive function, lower productivity, a weakened immunity, delayed neuro-development, and degenerative diseases. In regions with a high prevalence of stunting and limited welfare resources, identifying children in need of treatment is critical. The diagnostic process often raises challenges, such as the lack of experience in medical workers, incompatible anthropometric equipment, and inefficient medical bureaucracy. To counteract the issues, the use of load cell sensor and ultrasonic sensor can provide suitable anthropometric equipment and streamline the medical bureaucracy for stunting detection. This paper also employs machine learning for stunting detection based on sensor readings. The experiment results show that the sensitivity of the load cell sensor and the ultrasonic sensor is 0.9919 and 0.9986, respectively. Also, the machine learning test results have three classification classes, which are normal, stunted, and stunting with an accuracy rate of 98\\%.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2024-09-21 11:15:13 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.836048"
    },
    {
        "index": "#62",
        "title": "Implicit Neural Representations for Speed-of-Sound Estimation in Ultrasound",
        "link": "/arxiv/2409.14035",
        "arxiv_id": "2409.14035",
        "authors": "Michal Byra, Piotr Jarosik, Piotr Karwat, Ziemowit Klimonda, Marcin Lewandowski",
        "summary": "Accurate estimation of the speed-of-sound (SoS) is important for ultrasound (US) image reconstruction techniques and tissue characterization. Various approaches have been proposed to calculate SoS, ranging from tomography-inspired algorithms like CUTE to convolutional networks, and more recently, physics-informed optimization frameworks based on differentiable beamforming. In this work, we utilize implicit neural representations (INRs) for SoS estimation in US. INRs are a type of neural network architecture that encodes continuous functions, such as images or physical quantities, through the weights of a network. Implicit networks may overcome the current limitations of SoS estimation techniques, which mainly arise from the use of non-adaptable and oversimplified physical models of tissue. Moreover, convolutional networks for SoS estimation, usually trained using simulated data, often fail when applied to real tissues due to out-of-distribution and data-shift issues. In contrast, implicit networks do not require extensive training datasets since each implicit network is optimized for an individual data case. This adaptability makes them suitable for processing US data collected from varied tissues and across different imaging protocols. We evaluated the proposed SoS estimation method based on INRs using data collected from a tissue-mimicking phantom containing four cylindrical inclusions, with SoS values ranging from 1480 m/s to 1600 m/s. The inclusions were immersed in a material with an SoS value of 1540 m/s. In experiments, the proposed method achieved strong performance, clearly demonstrating the usefulness of implicit networks for quantitative US applications.",
        "subjects": "Machine Learning, Medical Physics",
        "date": "2024-09-21 06:43:38 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.836664"
    },
    {
        "index": "#69",
        "title": "High-Resolution Flood Probability Mapping Using Generative Machine Learning with Large-Scale Synthetic Precipitation and Inundation Data",
        "link": "/arxiv/2409.13936",
        "arxiv_id": "2409.13936",
        "authors": "Lipai Huang, Federico Antolini, Ali Mostafavi, Russell Blessing, Matthew Garcia, Samuel D. Brody",
        "summary": "High-resolution flood probability maps are essential for addressing the limitations of existing flood risk assessment approaches but are often limited by the availability of historical event data. Also, producing simulated data needed for creating probabilistic flood maps using physics-based models involves significant computation and time effort inhibiting the feasibility. To address this gap, this study introduces Flood-Precip GAN (Flood-Precipitation Generative Adversarial Network), a novel methodology that leverages generative machine learning to simulate large-scale synthetic inundation data to produce probabilistic flood maps. With a focus on Harris County, Texas, Flood-Precip GAN begins with training a cell-wise depth estimator using a limited number of physics-based model-generated precipitation-flood events. This model, which emphasizes precipitation-based features, outperforms universal models. Subsequently, a Generative Adversarial Network (GAN) with constraints is employed to conditionally generate synthetic precipitation records. Strategic thresholds are established to filter these records, ensuring close alignment with true precipitation patterns. For each cell, synthetic events are smoothed using a K-nearest neighbors algorithm and processed through the depth estimator to derive synthetic depth distributions. By iterating this procedure and after generating 10,000 synthetic precipitation-flood events, we construct flood probability maps in various formats, considering different inundation depths. Validation through similarity and correlation metrics confirms the fidelity of the synthetic depth distributions relative to true data. Flood-Precip GAN provides a scalable solution for generating synthetic flood depth data needed to create high-resolution flood probability maps, significantly enhancing flood preparedness and mitigation efforts.",
        "subjects": "Machine Learning",
        "date": "2024-09-20 22:43:31 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.837998"
    },
    {
        "index": "#71",
        "title": "Causal Feature Selection Method for Contextual Multi-Armed Bandits in Recommender System",
        "link": "/arxiv/2409.13888",
        "arxiv_id": "2409.13888",
        "authors": "Zhenyu Zhao, Yexi Jiang",
        "summary": "Features (a.k.a. context) are critical for contextual multi-armed bandits (MAB) performance. In practice of large scale online system, it is important to select and implement important features for the model: missing important features can led to sub-optimal reward outcome, and including irrelevant features can cause overfitting, poor model interpretability, and implementation cost. However, feature selection methods for conventional machine learning models fail short for contextual MAB use cases, as conventional methods select features correlated with the outcome variable, but not necessarily causing heterogeneuous treatment effect among arms which are truely important for contextual MAB. In this paper, we introduce model-free feature selection methods designed for contexutal MAB problem, based on heterogeneous causal effect contributed by the feature to the reward distribution. Empirical evaluation is conducted based on synthetic data as well as real data from an online experiment for optimizing content cover image in a recommender system. The results show this feature selection method effectively selects the important features that lead to higher contextual MAB reward than unimportant features. Compared with model embedded method, this model-free method has advantage of fast computation speed, ease of implementation, and prune of model mis-specification issues.",
        "subjects": "Machine Learning, Information Retrieval, Machine Learning",
        "date": "2024-09-20 20:39:23 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.838401"
    },
    {
        "index": "#74",
        "title": "Achieving Predictive Precision: Leveraging LSTM and Pseudo Labeling for Volvo's Discovery Challenge at ECML-PKDD 2024",
        "link": "/arxiv/2409.13877",
        "arxiv_id": "2409.13877",
        "authors": "Carlo Metta, Marco Gregnanin, Andrea Papini, Silvia Giulia Galfrè, Andrea Fois, Francesco Morandin, Marco Fantozzi, Maurizio Parton",
        "summary": "This paper presents the second-place methodology in the Volvo Discovery Challenge at ECML-PKDD 2024, where we used Long Short-Term Memory networks and pseudo-labeling to predict maintenance needs for a component of Volvo trucks. We processed the training data to mirror the test set structure and applied a base LSTM model to label the test data iteratively. This approach refined our model's predictive capabilities and culminated in a macro-average F1-score of 0.879, demonstrating robust performance in predictive maintenance. This work provides valuable insights for applying machine learning techniques effectively in industrial settings.",
        "subjects": "Machine Learning",
        "date": "2024-09-20 20:12:12 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.844230"
    },
    {
        "index": "#75",
        "title": "Physics-Informed Variational State-Space Gaussian Processes",
        "link": "/arxiv/2409.13876",
        "arxiv_id": "2409.13876",
        "authors": "Oliver Hamelijnck, Arno Solin, Theodoros Damoulas",
        "summary": "Differential equations are important mechanistic models that are integral to many scientific and engineering applications. With the abundance of available data there has been a growing interest in data-driven physics-informed models. Gaussian processes (GPs) are particularly suited to this task as they can model complex, non-linear phenomena whilst incorporating prior knowledge and quantifying uncertainty. Current approaches have found some success but are limited as they either achieve poor computational scalings or focus only on the temporal setting. This work addresses these issues by introducing a variational spatio-temporal state-space GP that handles linear and non-linear physical constraints while achieving efficient linear-in-time computation costs. We demonstrate our methods in a range of synthetic and real-world settings and outperform the current state-of-the-art in both predictive and computational performance.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2024-09-20 20:12:11 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.844435"
    },
    {
        "index": "#76",
        "title": "Data Distribution Shifts in (Industrial) Federated Learning as a Privacy Issue",
        "link": "/arxiv/2409.13875",
        "arxiv_id": "2409.13875",
        "authors": "David Brunner, Alessio Montuoro",
        "summary": "We consider industrial federated learning, a collaboration between a small number of powerful, potentially competing industrial players, mediated by a third party aspiring to improve the service it provides to its customers. We argue that this configuration harbours covert privacy risks that do not arise in e.g. cross-device settings. Companies are very protective of their intellectual property and production processes. Information about changes to their production and the timing of which is to be kept private. We study a scenario in which one of the collaborators infers changes to their competitors' production by detecting potentially subtle temporal data distribution shifts. In this framing, a data distribution shift is always problematic, even if it has no negative effect on training convergence. Thus, our goal is to find means that allow the detection of distributional shifts better than customary evaluation metrics. Based on the assumption that even minor shifts translate into the collaboratively learned machine learning model, the attacker tracks the shared models' internal state with a selection of metrics from literature in order to pick up on relevant changes. In an empirical study on benchmark datasets, we show an honest-but-curious attacker to be capable of detecting subtle distributional shifts on other clients, in some cases long before they become obvious in evaluation.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2024-09-20 20:09:19 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.844670"
    },
    {
        "index": "#77",
        "title": "Persistent Backdoor Attacks in Continual Learning",
        "link": "/arxiv/2409.13864",
        "arxiv_id": "2409.13864",
        "authors": "Zhen Guo, Abhinav Kumar, Reza Tourani",
        "summary": "Backdoor attacks pose a significant threat to neural networks, enabling adversaries to manipulate model outputs on specific inputs, often with devastating consequences, especially in critical applications. While backdoor attacks have been studied in various contexts, little attention has been given to their practicality and persistence in continual learning, particularly in understanding how the continual updates to model parameters, as new data distributions are learned and integrated, impact the effectiveness of these attacks over time. To address this gap, we introduce two persistent backdoor attacks-Blind Task Backdoor and Latent Task Backdoor-each leveraging minimal adversarial influence. Our blind task backdoor subtly alters the loss computation without direct control over the training process, while the latent task backdoor influences only a single task's training, with all other tasks trained benignly. We evaluate these attacks under various configurations, demonstrating their efficacy with static, dynamic, physical, and semantic triggers. Our results show that both attacks consistently achieve high success rates across different continual learning algorithms, while effectively evading state-of-the-art defenses, such as SentiNet and I-BAU.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2024-09-20 19:28:48 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.844864"
    },
    {
        "index": "#80",
        "title": "Segment Discovery: Enhancing E-commerce Targeting",
        "link": "/arxiv/2409.13847",
        "arxiv_id": "2409.13847",
        "authors": "Qiqi Li, Roopali Singh, Charin Polpanumas, Tanner Fiez, Namita Kumar, Shreya Chakrabarti",
        "summary": "Modern e-commerce services frequently target customers with incentives or interventions to engage them in their products such as games, shopping, video streaming, etc. This customer engagement increases acquisition of more customers and retention of existing ones, leading to more business for the company while improving customer experience. Often, customers are either randomly targeted or targeted based on the propensity of desirable behavior. However, such policies can be suboptimal as they do not target the set of customers who would benefit the most from the intervention and they may also not take account of any constraints. In this paper, we propose a policy framework based on uplift modeling and constrained optimization that identifies customers to target for a use-case specific intervention so as to maximize the value to the business, while taking account of any given constraints. We demonstrate improvement over state-of-the-art targeting approaches using two large-scale experimental studies and a production implementation.",
        "subjects": "Machine Learning, Information Retrieval",
        "date": "2024-09-20 18:42:04 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.845463"
    },
    {
        "index": "#85",
        "title": "A constrained optimization approach to improve robustness of neural networks",
        "link": "/arxiv/2409.13770",
        "arxiv_id": "2409.13770",
        "authors": "Shudian Zhao, Jan Kronqvist",
        "summary": "In this paper, we present a novel nonlinear programming-based approach to fine-tune pre-trained neural networks to improve robustness against adversarial attacks while maintaining high accuracy on clean data. Our method introduces adversary-correction constraints to ensure correct classification of adversarial data and minimizes changes to the model parameters. We propose an efficient cutting-plane-based algorithm to iteratively solve the large-scale nonconvex optimization problem by approximating the feasible region through polyhedral cuts and balancing between robustness and accuracy. Computational experiments on standard datasets such as MNIST and CIFAR10 demonstrate that the proposed approach significantly improves robustness, even with a very small set of adversarial data, while maintaining minimal impact on accuracy.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2024-09-18 18:37:14 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.846437"
    },
    {
        "index": "#88",
        "title": "Machine Learning Toric Duality in Brane Tilings",
        "link": "/arxiv/2409.15251",
        "arxiv_id": "2409.15251",
        "authors": "Pietro Capuozzo, Tancredi Schettini Gherardini, Benjamin Suzzoni",
        "summary": "We apply a variety of machine learning methods to the study of Seiberg duality within 4d $\\mathcal{N}=1$ quantum field theories arising on the worldvolumes of D3-branes probing toric Calabi-Yau 3-folds. Such theories admit an elegant description in terms of bipartite tessellations of the torus known as brane tilings or dimer models. An intricate network of infrared dualities interconnects the space of such theories and partitions it into universality classes, the prediction and classification of which is a problem that naturally lends itself to a machine learning investigation. In this paper, we address a preliminary set of such enquiries. We begin by training a fully connected neural network to identify classes of Seiberg dual theories realised on $\\mathbb{Z}_m\\times\\mathbb{Z}_n$ orbifolds of the conifold and achieve $R^2=0.988$. Then, we evaluate various notions of robustness of our methods against perturbations of the space of theories under investigation, and discuss these results in terms of the nature of the neural network's learning. Finally, we employ a more sophisticated residual architecture to classify the toric phase space of the $Y^{6,0}$ theories, and to predict the individual gauged linear $\\sigma$-model multiplicities in toric diagrams thereof. In spite of the non-trivial nature of this task, we achieve remarkably accurate results; namely, upon fixing a choice of Kasteleyn matrix representative, the regressor achieves a mean absolute error of $0.021$. We also discuss how the performance is affected by relaxing these assumptions.",
        "subjects": "High Energy Physics - Theory, Machine Learning",
        "date": "2024-09-23 17:48:14 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.847254"
    },
    {
        "index": "#91",
        "title": "Intelligent Routing Algorithm over SDN: Reusable Reinforcement Learning Approach",
        "link": "/arxiv/2409.15226",
        "arxiv_id": "2409.15226",
        "authors": "Wang Wumian, Sajal Saha, Anwar Haque, Greg Sidebottom",
        "summary": "Traffic routing is vital for the proper functioning of the Internet. As users and network traffic increase, researchers try to develop adaptive and intelligent routing algorithms that can fulfill various QoS requirements. Reinforcement Learning (RL) based routing algorithms have shown better performance than traditional approaches. We developed a QoS-aware, reusable RL routing algorithm, RLSR-Routing over SDN. During the learning process, our algorithm ensures loop-free path exploration. While finding the path for one traffic demand (a source destination pair with certain amount of traffic), RLSR-Routing learns the overall network QoS status, which can be used to speed up algorithm convergence when finding the path for other traffic demands. By adapting Segment Routing, our algorithm can achieve flow-based, source packet routing, and reduce communications required between SDN controller and network plane. Our algorithm shows better performance in terms of load balancing than the traditional approaches. It also has faster convergence than the non-reusable RL approach when finding paths for multiple traffic demands.",
        "subjects": "Networking and Internet Architecture, Machine Learning",
        "date": "2024-09-23 17:15:24 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.847855"
    },
    {
        "index": "#94",
        "title": "Fast and Accurate Triangle Counting in Graph Streams Using Predictions",
        "link": "/arxiv/2409.15205",
        "arxiv_id": "2409.15205",
        "authors": "Cristian Boldrin, Fabio Vandin",
        "summary": "In this work, we present the first efficient and practical algorithm for estimating the number of triangles in a graph stream using predictions. Our algorithm combines waiting room sampling and reservoir sampling with a predictor for the heaviness of edges, that is, the number of triangles in which an edge is involved. As a result, our algorithm is fast, provides guarantees on the amount of memory used, and exploits the additional information provided by the predictor to produce highly accurate estimates. We also propose a simple and domain-independent predictor, based on the degree of nodes, that can be easily computed with one pass on a stream of edges when the stream is available beforehand. Our analytical results show that, when the predictor provides useful information on the heaviness of edges, it leads to estimates with reduced variance compared to the state-of-the-art, even when the predictions are far from perfect. Our experimental results show that, when analyzing a single graph stream, our algorithm is faster than the state-of-the-art for a given memory budget, while providing significantly more accurate estimates. Even more interestingly, when sequences of hundreds of graph streams are analyzed, our algorithm significantly outperforms the state-of-the-art using our simple degree-based predictor built by analyzing only the first graph of the sequence.",
        "subjects": "Data Structures and Algorithms, Machine Learning",
        "date": "2024-09-23 16:52:11 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.848495"
    },
    {
        "index": "#95",
        "title": "RAMBO: Enhancing RAG-based Repository-Level Method Body Completion",
        "link": "/arxiv/2409.15204",
        "arxiv_id": "2409.15204",
        "authors": "Tuan-Dung Bui, Duc-Thieu Luu-Van, Thanh-Phat Nguyen, Thu-Trang Nguyen, Son Nguyen, Hieu Dinh Vo",
        "summary": "Code completion is essential in software development, helping developers by predicting code snippets based on context. Among completion tasks, Method Body Completion (MBC) is particularly challenging as it involves generating complete method bodies based on their signatures and context. This task becomes significantly harder in large repositories, where method bodies must integrate repositoryspecific elements such as custom APIs, inter-module dependencies, and project-specific conventions. In this paper, we introduce RAMBO, a novel RAG-based approach for repository-level MBC. Instead of retrieving similar method bodies, RAMBO identifies essential repositoryspecific elements, such as classes, methods, and variables/fields, and their relevant usages. By incorporating these elements and their relevant usages into the code generation process, RAMBO ensures more accurate and contextually relevant method bodies. Our experimental results with leading code LLMs across 40 Java projects show that RAMBO significantly outperformed the state-of-the-art repository-level MBC approaches, with the improvements of up to 46% in BLEU, 57% in CodeBLEU, 36% in Compilation Rate, and up to 3X in Exact Match. Notably, RAMBO surpassed RepoCoder Oracle method by up to 12% in Exact Match, setting a new benchmark for repository-level MBC.",
        "subjects": "Software Engineering, Machine Learning",
        "date": "2024-09-23 16:51:43 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.848721"
    },
    {
        "index": "#99",
        "title": "Harmonic Path Integral Diffusion",
        "link": "/arxiv/2409.15166",
        "arxiv_id": "2409.15166",
        "authors": "Hamidreza Behjoo, Michael Chertkov",
        "summary": "In this manuscript, we present a novel approach for sampling from a continuous multivariate probability distribution, which may either be explicitly known (up to a normalization factor) or represented via empirical samples. Our method constructs a time-dependent bridge from a delta function centered at the origin of the state space at $t=0$, optimally transforming it into the target distribution at $t=1$. We formulate this as a Stochastic Optimal Control problem of the Path Integral Control type, with a cost function comprising (in its basic form) a quadratic control term, a quadratic state term, and a terminal constraint. This framework, which we refer to as Harmonic Path Integral Diffusion (H-PID), leverages an analytical solution through a mapping to an auxiliary quantum harmonic oscillator in imaginary time. The H-PID framework results in a set of efficient sampling algorithms, without the incorporation of Neural Networks. The algorithms are validated on two standard use cases: a mixture of Gaussians over a grid and images from CIFAR-10. We contrast these algorithms with other sampling methods, particularly simulated annealing and path integral sampling, highlighting their advantages in terms of analytical control, accuracy, and computational efficiency on benchmark problems. Additionally, we extend the methodology to more general cases where the underlying stochastic differential equation includes an external deterministic, possibly non-conservative force, and where the cost function incorporates a gauge potential term. These extensions open up new possibilities for applying our framework to a broader range of statistics specific to applications.",
        "subjects": "Machine Learning, Machine Learning, Computation",
        "date": "2024-09-23 16:20:21 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.849824"
    },
    {
        "index": "#101",
        "title": "UTrace: Poisoning Forensics for Private Collaborative Learning",
        "link": "/arxiv/2409.15126",
        "arxiv_id": "2409.15126",
        "authors": "Evan Rose, Hidde Lycklama, Harsh Chaudhari, Anwar Hithnawi, Alina Oprea",
        "summary": "Privacy-preserving machine learning (PPML) enables multiple data owners to contribute their data privately to a set of servers that run a secure multi-party computation (MPC) protocol to train a joint ML model. In these protocols, the input data remains private throughout the training process, and only the resulting model is made available. While this approach benefits privacy, it also exacerbates the risks of data poisoning, where compromised data owners induce undesirable model behavior by contributing malicious datasets. Existing MPC mechanisms can mitigate certain poisoning attacks, but these measures are not exhaustive. To complement existing poisoning defenses, we introduce UTrace: a framework for User-level Traceback of poisoning attacks in PPML. Utrace computes user responsibility scores using gradient similarity metrics aggregated across the most relevant samples in an owner's dataset. UTrace is effective at low poisoning rates and is resilient to poisoning attacks distributed across multiple data owners, unlike existing unlearning-based methods. We introduce methods for checkpointing gradients with low storage overhead, enabling traceback in the absence of data owners at deployment time. We also design several optimizations that reduce traceback time and communication in MPC. We provide a comprehensive evaluation of UTrace across four datasets from three data modalities (vision, text, and malware) and show its effectiveness against 10 poisoning attacks.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2024-09-23 15:32:46 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.850257"
    },
    {
        "index": "#103",
        "title": "CSPS: A Communication-Efficient Sequence-Parallelism based Serving System for Transformer based Models with Long Prompts",
        "link": "/arxiv/2409.15104",
        "arxiv_id": "2409.15104",
        "authors": "Zeyu Zhang, Haiying Shen",
        "summary": "Long-sequence generative large-language model (LLM) applications have become increasingly popular. In this paper, through trace-based experiments, we found that the existing method for long sequences results in a high Time-To-First-Token (TTFT) due to sequential chunk processing, long Time-Between-Tokens (TBT) from batching long-sequence prefills and decodes, and low throughput due to constrained key-value cache (KVC) for long sequences. To address these issues, we propose two Sequence-Parallelism (SP) architectures for both tensor parallelism (TP) and non-TP. However, SP introduces two challenges: 1) network communication and computation become performance bottlenecks; 2) the latter two issues above are mitigated but not resolved, and SP's resultant KV value distribution across GPUs still requires communication for decode, increasing TBT. Hence, we propose a Communication-efficient Sparse Attention (CSA) and communication-computation-communication three-phase pipelining. We also propose SP-based decode that processes decode separately from prefill, distributes KV values of a request across different GPUs, and novelly moves Query (Q) values instead of KV values to reduce communication overhead. These methods constitute a communication-efficient Sequence-Parallelism based LLM Serving System (SPS2). Our trace-driven evaluation demonstrates that SPS2 improves the average TTFT, TBT, and response time by up to 7.5x, 1.92x, and 9.8x and improves the prefill and decode throughput by 8.2x and 5.2x while maintaining the accuracy compared to Sarathi-Serve. We distributed our source code.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Machine Learning",
        "date": "2024-09-23 15:16:29 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.850788"
    },
    {
        "index": "#109",
        "title": "Methods for Convex $(L_0,L_1)$-Smooth Optimization: Clipping, Acceleration, and Adaptivity",
        "link": "/arxiv/2409.14989",
        "arxiv_id": "2409.14989",
        "authors": "Eduard Gorbunov, Nazarii Tupitsa, Sayantan Choudhury, Alen Aliev, Peter Richtárik, Samuel Horváth, Martin Takáč",
        "summary": "Due to the non-smoothness of optimization problems in Machine Learning, generalized smoothness assumptions have been gaining a lot of attention in recent years. One of the most popular assumptions of this type is $(L_0,L_1)$-smoothness (Zhang et al., 2020). In this paper, we focus on the class of (strongly) convex $(L_0,L_1)$-smooth functions and derive new convergence guarantees for several existing methods. In particular, we derive improved convergence rates for Gradient Descent with (Smoothed) Gradient Clipping and for Gradient Descent with Polyak Stepsizes. In contrast to the existing results, our rates do not rely on the standard smoothness assumption and do not suffer from the exponential dependency from the initial distance to the solution. We also extend these results to the stochastic case under the over-parameterization assumption, propose a new accelerated method for convex $(L_0,L_1)$-smooth optimization, and derive new convergence rates for Adaptive Gradient Descent (Malitsky and Mishchenko, 2020).",
        "subjects": "Optimization and Control, Machine Learning",
        "date": "2024-09-23 13:11:37 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.852263"
    },
    {
        "index": "#111",
        "title": "(De)-regularized Maximum Mean Discrepancy Gradient Flow",
        "link": "/arxiv/2409.14980",
        "arxiv_id": "2409.14980",
        "authors": "Zonghao Chen, Aratrika Mustafi, Pierre Glaser, Anna Korba, Arthur Gretton, Bharath K. Sriperumbudur",
        "summary": "We introduce a (de)-regularization of the Maximum Mean Discrepancy (DrMMD) and its Wasserstein gradient flow. Existing gradient flows that transport samples from source distribution to target distribution with only target samples, either lack tractable numerical implementation ($f$-divergence flows) or require strong assumptions, and modifications such as noise injection, to ensure convergence (Maximum Mean Discrepancy flows). In contrast, DrMMD flow can simultaneously (i) guarantee near-global convergence for a broad class of targets in both continuous and discrete time, and (ii) be implemented in closed form using only samples. The former is achieved by leveraging the connection between the DrMMD and the $\\chi^2$-divergence, while the latter comes by treating DrMMD as MMD with a de-regularized kernel. Our numerical scheme uses an adaptive de-regularization schedule throughout the flow to optimally trade off between discretization errors and deviations from the $\\chi^2$ regime. The potential application of the DrMMD flow is demonstrated across several numerical experiments, including a large-scale setting of training student/teacher networks.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2024-09-23 12:57:42 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.852687"
    },
    {
        "index": "#112",
        "title": "Blind Spatial Impulse Response Generation from Separate Room- and Scene-Specific Information",
        "link": "/arxiv/2409.14971",
        "arxiv_id": "2409.14971",
        "authors": "Francesc Lluís, Nils Meyer-Kahlen",
        "summary": "For audio in augmented reality (AR), knowledge of the users' real acoustic environment is crucial for rendering virtual sounds that seamlessly blend into the environment. As acoustic measurements are usually not feasible in practical AR applications, information about the room needs to be inferred from available sound sources. Then, additional sound sources can be rendered with the same room acoustic qualities. Crucially, these are placed at different positions than the sources available for estimation. Here, we propose to use an encoder network trained using a contrastive loss that maps input sounds to a low-dimensional feature space representing only room-specific information. Then, a diffusion-based spatial room impulse response generator is trained to take the latent space and generate a new response, given a new source-receiver position. We show how both room- and position-specific parameters are considered in the final output.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2024-09-23 12:41:31 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.852878"
    },
    {
        "index": "#113",
        "title": "A Realistic Simulation Framework for Analog/Digital Neuromorphic Architectures",
        "link": "/arxiv/2409.14918",
        "arxiv_id": "2409.14918",
        "authors": "Fernando M. Quintana, Maryada, Pedro L. Galindo, Elisa Donati, Giacomo Indiveri, Fernando Perez-Peña",
        "summary": "Developing dedicated neuromorphic computing platforms optimized for embedded or edge-computing applications requires time-consuming design, fabrication, and deployment of full-custom neuromorphic processors.bTo ensure that initial prototyping efforts, exploring the properties of different network architectures and parameter settings, lead to realistic results it is important to use simulation frameworks that match as best as possible the properties of the final hardware. This is particularly challenging for neuromorphic hardware platforms made using mixed-signal analog/digital circuits, due to the variability and noise sensitivity of their components. In this paper, we address this challenge by developing a software spiking neural network simulator explicitly designed to account for the properties of mixed-signal neuromorphic circuits, including device mismatch variability. The simulator, called ARCANA (A Realistic Simulation Framework for Analog/Digital Neuromorphic Architectures), is designed to reproduce the dynamics of mixed-signal synapse and neuron electronic circuits with autogradient differentiation for parameter optimization and GPU acceleration. We demonstrate the effectiveness of this approach by matching software simulation results with measurements made from an existing neuromorphic processor. We show how the results obtained provide a reliable estimate of the behavior of the spiking neural network trained in software, once deployed in hardware. This framework enables the development and innovation of new learning rules and processing architectures in neuromorphic embedded systems.",
        "subjects": "Neural and Evolutionary Computing, Hardware Architecture, Machine Learning",
        "date": "2024-09-23 11:16:46 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.853093"
    },
    {
        "index": "#115",
        "title": "Efficient Tabular Data Preprocessing of ML Pipelines",
        "link": "/arxiv/2409.14912",
        "arxiv_id": "2409.14912",
        "authors": "Yu Zhu, Wenqi Jiang, Gustavo Alonso",
        "summary": "Data preprocessing pipelines, which includes data decoding, cleaning, and transforming, are a crucial component of Machine Learning (ML) training. Thy are computationally intensive and often become a major bottleneck, due to the increasing performance gap between the CPUs used for preprocessing and the GPUs used for model training. Recent studies show that a significant number of CPUs across several machines are required to achieve sufficient throughput to saturate the GPUs, leading to increased resource and energy consumption. When the pipeline involves vocabulary generation, the preprocessing performance scales poorly due to significant row-wise synchronization overhead between different CPU cores and servers. To address this limitation, in this paper we present the design of Piper, a hardware accelerator for tabular data preprocessing, prototype it on FPGAs, and demonstrate its potential for training pipelines of commercial recommender systems. Piper achieves 4.7 $\\sim$ 71.3$\\times$ speedup in latency over a 128-core CPU server and outperforms a data-center GPU by 4.8$\\sim$ 20.3$\\times$ when using binary input. The impressive performance showcases Piper's potential to increase the efficiency of data preprocessing pipelines and significantly reduce their resource consumption.",
        "subjects": "Hardware Architecture, Machine Learning",
        "date": "2024-09-23 11:07:57 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.853460"
    },
    {
        "index": "#117",
        "title": "Built Different: Tactile Perception to Overcome Cross-Embodiment Capability Differences in Collaborative Manipulation",
        "link": "/arxiv/2409.14896",
        "arxiv_id": "2409.14896",
        "authors": "William van den Bogert, Madhavan Iyengar, Nima Fazeli",
        "summary": "Tactile sensing is a powerful means of implicit communication between a human and a robot assistant. In this paper, we investigate how tactile sensing can transcend cross-embodiment differences across robotic systems in the context of collaborative manipulation. Consider tasks such as collaborative object carrying where the human-robot interaction is force rich. Learning and executing such skills requires the robot to comply to the human and to learn behaviors at the joint-torque level. However, most robots do not offer this compliance or provide access to their joint torques. To address this challenge, we present an approach that uses tactile sensors to transfer policies from robots with these capabilities to those without. We show how our method can enable a cooperative task where a robot and human must work together to maneuver objects through space. We first demonstrate the skill on an impedance control-capable robot equipped with tactile sensing, then show the positive transfer of the tactile policy to a planar prismatic robot that is only capable of position control and does not come equipped with any sort of force/torque feedback, yet is able to comply to the human motions only using tactile feedback. Further details and videos can be found on our project website at https://www.mmintlab.com/research/tactile-collaborative/.",
        "subjects": "Robotics, Machine Learning",
        "date": "2024-09-23 10:45:41 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.853889"
    },
    {
        "index": "#124",
        "title": "Energy-Aware Federated Learning in Satellite Constellations",
        "link": "/arxiv/2409.14832",
        "arxiv_id": "2409.14832",
        "authors": "Nasrin Razmi, Bho Matthiesen, Armin Dekorsy, Petar Popovski",
        "summary": "Federated learning in satellite constellations, where the satellites collaboratively train a machine learning model, is a promising technology towards enabling globally connected intelligence and the integration of space networks into terrestrial mobile networks. The energy required for this computationally intensive task is provided either by solar panels or by an internal battery if the satellite is in Earth's shadow. Careful management of this battery and system's available energy resources is not only necessary for reliable satellite operation, but also to avoid premature battery aging. We propose a novel energy-aware computation time scheduler for satellite FL, which aims to minimize battery usage without any impact on the convergence speed. Numerical results indicate an increase of more than 3x in battery lifetime can be achieved over energy-agnostic task scheduling.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Machine Learning, Signal Processing",
        "date": "2024-09-23 09:01:17 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.856024"
    },
    {
        "index": "#126",
        "title": "Pre-trained Language Model and Knowledge Distillation for Lightweight Sequential Recommendation",
        "link": "/arxiv/2409.14810",
        "arxiv_id": "2409.14810",
        "authors": "Li Li, Mingyue Cheng, Zhiding Liu, Hao Zhang, Qi Liu, Enhong Chen",
        "summary": "Sequential recommendation models user interests based on historical behaviors to provide personalized recommendation. Previous sequential recommendation algorithms primarily employ neural networks to extract features of user interests, achieving good performance. However, due to the recommendation system datasets sparsity, these algorithms often employ small-scale network frameworks, resulting in weaker generalization capability. Recently, a series of sequential recommendation algorithms based on large pre-trained language models have been proposed. Nonetheless, given the real-time demands of recommendation systems, the challenge remains in applying pre-trained language models for rapid recommendations in real scenarios. To address this, we propose a sequential recommendation algorithm based on a pre-trained language model and knowledge distillation. The key of proposed algorithm is to transfer pre-trained knowledge across domains and achieve lightweight inference by knowledge distillation. The algorithm operates in two stages: in the first stage, we fine-tune the pre-trained language model on the recommendation dataset to transfer the pre-trained knowledge to the recommendation task; in the second stage, we distill the trained language model to transfer the learned knowledge to a lightweight model. Extensive experiments on multiple public recommendation datasets show that the proposed algorithm enhances recommendation accuracy and provide timely recommendation services.",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2024-09-23 08:39:07 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.856465"
    },
    {
        "index": "#127",
        "title": "Adaptive Conformal Inference for Multi-Step Ahead Time-Series Forecasting Online",
        "link": "/arxiv/2409.14792",
        "arxiv_id": "2409.14792",
        "authors": "Johan Hallberg Szabadváry",
        "summary": "The aim of this paper is to propose an adaptation of the well known adaptive conformal inference (ACI) algorithm to achieve finite-sample coverage guarantees in multi-step ahead time-series forecasting in the online setting. ACI dynamically adjusts significance levels, and comes with finite-sample guarantees on coverage, even for non-exchangeable data. Our multi-step ahead ACI procedure inherits these guarantees at each prediction step, as well as for the overall error rate. The multi-step ahead ACI algorithm can be used with different target error and learning rates at different prediction steps, which is illustrated in our numerical examples, where we employ a version of the confromalised ridge regression algorithm, adapted to multi-input multi-output forecasting. The examples serve to show how the method works in practice, illustrating the effect of variable target error and learning rates for different prediction steps, which suggests that a balance may be struck between efficiency (interval width) and coverage.t",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2024-09-23 08:07:49 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.856636"
    },
    {
        "index": "#128",
        "title": "Multiscale scattered data analysis in samplet coordinates",
        "link": "/arxiv/2409.14791",
        "arxiv_id": "2409.14791",
        "authors": "Sara Avesani, Rüdiger Kempf, Michael Multerer, Holger Wendland",
        "summary": "We study multiscale scattered data interpolation schemes for globally supported radial basis functions, with a focus on the Matérn class. The multiscale approximation is constructed through a sequence of residual corrections, where radial basis functions with different lengthscale parameters are employed to capture varying levels of detail. To apply this approach to large data sets, we suggest to represent the resulting generalized Vandermonde matrices in samplet coordinates. Samplets are localized, discrete signed measures exhibiting vanishing moments and allow for the sparse approximation of generalized Vandermonde matrices issuing from a vast class of radial basis functions. Given a quasi-uniform set of $N$ data sites, and local approximation spaces with geometrically decreasing dimension, the full multiscale system can be assembled with cost $\\mathcal{O}(N \\log N)$. We prove that the condition numbers of the linear systems at each level remain bounded independent of the particular level, allowing us to use an iterative solver with a bounded number of iterations for the numerical solution. Hence, the overall cost of the proposed approach is $\\mathcal{O}(N \\log N)$. The theoretical findings are accompanied by extensive numerical studies in two and three spatial dimensions.",
        "subjects": "Numerical Analysis, Machine Learning",
        "date": "2024-09-23 08:07:47 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.856826"
    },
    {
        "index": "#130",
        "title": "Neural refractive index field: Unlocking the Potential of Background-oriented Schlieren Tomography in Volumetric Flow Visualization",
        "link": "/arxiv/2409.14722",
        "arxiv_id": "2409.14722",
        "authors": "Yuanzhe He, Yutao Zheng, Shijie Xu, Chang Liu, Di Peng, Yingzheng Liu, Weiwei Cai",
        "summary": "Background-oriented Schlieren tomography (BOST) is a prevalent method for visualizing intricate turbulent flows, valued for its ease of implementation and capacity to capture three-dimensional distributions of a multitude of flow parameters. However, the voxel-based meshing scheme leads to significant challenges, such as inadequate spatial resolution, substantial discretization errors, poor noise immunity, and excessive computational costs. This work presents an innovative reconstruction approach termed neural refractive index field (NeRIF) which implicitly represents the flow field with a neural network, which is trained with tailored strategies. Both numerical simulations and experimental demonstrations on turbulent Bunsen flames suggest that our approach can significantly improve the reconstruction accuracy and spatial resolution while concurrently reducing computational expenses. Although showcased in the context of background-oriented schlieren tomography here, the key idea embedded in the NeRIF can be readily adapted to various other tomographic modalities including tomographic absorption spectroscopy and tomographic particle imaging velocimetry, broadening its potential impact across different domains of flow visualization and analysis.",
        "subjects": "Fluid Dynamics, Human-Computer Interaction, Machine Learning",
        "date": "2024-09-23 05:40:50 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.857291"
    },
    {
        "index": "#131",
        "title": "EDGE-Rec: Efficient and Data-Guided Edge Diffusion For Recommender Systems Graphs",
        "link": "/arxiv/2409.14689",
        "arxiv_id": "2409.14689",
        "authors": "Utkarsh Priyam, Hemit Shah, Edoardo Botta",
        "summary": "Most recommender systems research focuses on binary historical user-item interaction encodings to predict future interactions. User features, item features, and interaction strengths remain largely under-utilized in this space or only indirectly utilized, despite proving largely effective in large-scale production recommendation systems. We propose a new attention mechanism, loosely based on the principles of collaborative filtering, called Row-Column Separable Attention RCSA to take advantage of real-valued interaction weights as well as user and item features directly. Building on this mechanism, we additionally propose a novel Graph Diffusion Transformer GDiT architecture which is trained to iteratively denoise the weighted interaction matrix of the user-item interaction graph directly. The weighted interaction matrix is built from the bipartite structure of the user-item interaction graph and corresponding edge weights derived from user-item rating interactions. Inspired by the recent progress in text-conditioned image generation, our method directly produces user-item rating predictions on the same scale as the original ratings by conditioning the denoising process on user and item features with a principled approach.",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2024-09-23 03:23:20 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.857484"
    },
    {
        "index": "#132",
        "title": "Robust Training Objectives Improve Embedding-based Retrieval in Industrial Recommendation Systems",
        "link": "/arxiv/2409.14682",
        "arxiv_id": "2409.14682",
        "authors": "Matthew Kolodner, Mingxuan Ju, Zihao Fan, Tong Zhao, Elham Ghazizadeh, Yan Wu, Neil Shah, Yozen Liu",
        "summary": "Improving recommendation systems (RS) can greatly enhance the user experience across many domains, such as social media. Many RS utilize embedding-based retrieval (EBR) approaches to retrieve candidates for recommendation. In an EBR system, the embedding quality is key. According to recent literature, self-supervised multitask learning (SSMTL) has showed strong performance on academic benchmarks in embedding learning and resulted in an overall improvement in multiple downstream tasks, demonstrating a larger resilience to the adverse conditions between each downstream task and thereby increased robustness and task generalization ability through the training objective. However, whether or not the success of SSMTL in academia as a robust training objectives translates to large-scale (i.e., over hundreds of million users and interactions in-between) industrial RS still requires verification. Simply adopting academic setups in industrial RS might entail two issues. Firstly, many self-supervised objectives require data augmentations (e.g., embedding masking/corruption) over a large portion of users and items, which is prohibitively expensive in industrial RS. Furthermore, some self-supervised objectives might not align with the recommendation task, which might lead to redundant computational overheads or negative transfer. In light of these two challenges, we evaluate using a robust training objective, specifically SSMTL, through a large-scale friend recommendation system on a social media platform in the tech sector, identifying whether this increase in robustness can work at scale in enhancing retrieval in the production setting. Through online A/B testing with SSMTL-based EBR, we observe statistically significant increases in key metrics in the friend recommendations, with up to 5.45% improvements in new friends made and 1.91% improvements in new friends made with cold-start users.",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2024-09-23 03:12:33 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.857715"
    },
    {
        "index": "#133",
        "title": "Fourier neural operators for spatiotemporal dynamics in two-dimensional turbulence",
        "link": "/arxiv/2409.14660",
        "arxiv_id": "2409.14660",
        "authors": "Mohammad Atif, Pulkit Dubey, Pratik P. Aghor, Vanessa Lopez-Marrero, Tao Zhang, Abdullah Sharfuddin, Kwangmin Yu, Fan Yang, Foluso Ladeinde, Yangang Liu, Meifeng Lin, Lingda Li",
        "summary": "High-fidelity direct numerical simulation of turbulent flows for most real-world applications remains an outstanding computational challenge. Several machine learning approaches have recently been proposed to alleviate the computational cost even though they become unstable or unphysical for long time predictions. We identify that the Fourier neural operator (FNO) based models combined with a partial differential equation (PDE) solver can accelerate fluid dynamic simulations and thus address computational expense of large-scale turbulence simulations. We treat the FNO model on the same footing as a PDE solver and answer important questions about the volume and temporal resolution of data required to build pre-trained models for turbulence. We also discuss the pitfalls of purely data-driven approaches that need to be avoided by the machine learning models to become viable and competitive tools for long time simulations of turbulence.",
        "subjects": "Fluid Dynamics, Machine Learning, Chaotic Dynamics",
        "date": "2024-09-23 02:02:02 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.857981"
    },
    {
        "index": "#134",
        "title": "Federated Graph Learning with Adaptive Importance-based Sampling",
        "link": "/arxiv/2409.14655",
        "arxiv_id": "2409.14655",
        "authors": "Anran Li, Yuanyuan Chen, Chao Ren, Wenhan Wang, Ming Hu, Tianlin Li, Han Yu, Qingyu Chen",
        "summary": "For privacy-preserving graph learning tasks involving distributed graph datasets, federated learning (FL)-based GCN (FedGCN) training is required. A key challenge for FedGCN is scaling to large-scale graphs, which typically incurs high computation and communication costs when dealing with the explosively increasing number of neighbors. Existing graph sampling-enhanced FedGCN training approaches ignore graph structural information or dynamics of optimization, resulting in high variance and inaccurate node embeddings. To address this limitation, we propose the Federated Adaptive Importance-based Sampling (FedAIS) approach. It achieves substantial computational cost saving by focusing the limited resources on training important nodes, while reducing communication overhead via adaptive historical embedding synchronization. The proposed adaptive importance-based sampling method jointly considers the graph structural heterogeneity and the optimization dynamics to achieve optimal trade-off between efficiency and accuracy. Extensive evaluations against five state-of-the-art baselines on five real-world graph datasets show that FedAIS achieves comparable or up to 3.23% higher test accuracy, while saving communication and computation costs by 91.77% and 85.59%.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Cryptography and Security, Machine Learning",
        "date": "2024-09-23 01:49:20 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.858209"
    },
    {
        "index": "#135",
        "title": "Demystifying Trajectory Recovery From Ash: An Open-Source Evaluation and Enhancement",
        "link": "/arxiv/2409.14645",
        "arxiv_id": "2409.14645",
        "authors": "Nicholas D'Silva, Toran Shahi, Øyvind Timian Dokk Husveg, Adith Sanjeeve, Erik Buchholz, Salil S. Kanhere",
        "summary": "Once analysed, location trajectories can provide valuable insights beneficial to various applications. However, such data is also highly sensitive, rendering them susceptible to privacy risks in the event of mismanagement, for example, revealing an individual's identity, home address, or political affiliations. Hence, ensuring that privacy is preserved for this data is a priority. One commonly taken measure to mitigate this concern is aggregation. Previous work by Xu et al. shows that trajectories are still recoverable from anonymised and aggregated datasets. However, the study lacks implementation details, obfuscating the mechanisms of the attack. Additionally, the attack was evaluated on commercial non-public datasets, rendering the results and subsequent claims unverifiable. This study reimplements the trajectory recovery attack from scratch and evaluates it on two open-source datasets, detailing the preprocessing steps and implementation. Results confirm that privacy leakage still exists despite common anonymisation and aggregation methods but also indicate that the initial accuracy claims may have been overly ambitious. We release all code as open-source to ensure the results are entirely reproducible and, therefore, verifiable. Moreover, we propose a stronger attack by designing a series of enhancements to the baseline attack. These enhancements yield higher accuracies by up to 16%, providing an improved benchmark for future research in trajectory recovery methods. Our improvements also enable online execution of the attack, allowing partial attacks on larger datasets previously considered unprocessable, thereby furthering the extent of privacy leakage. The findings emphasise the importance of using strong privacy-preserving mechanisms when releasing aggregated mobility data and not solely relying on aggregation as a means of anonymisation.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2024-09-23 01:06:41 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.858418"
    },
    {
        "index": "#144",
        "title": "Optimizing Feature Selection with Genetic Algorithms: A Review of Methods and Applications",
        "link": "/arxiv/2409.14563",
        "arxiv_id": "2409.14563",
        "authors": "Zhila Yaseen Taha, Abdulhady Abas Abdullah, Tarik A. Rashid",
        "summary": "Analyzing large datasets to select optimal features is one of the most important research areas in machine learning and data mining. This feature selection procedure involves dimensionality reduction which is crucial in enhancing the performance of the model, making it less complex. Recently, several types of attribute selection methods have been proposed that use different approaches to obtain representative subsets of the attributes. However, population-based evolutionary algorithms like Genetic Algorithms (GAs) have been proposed to provide remedies for these drawbacks by avoiding local optima and improving the selection process itself. This manuscript presents a sweeping review on GA-based feature selection techniques in applications and their effectiveness across different domains. This review was conducted using the PRISMA methodology; hence, the systematic identification, screening, and analysis of relevant literature were performed. Thus, our results hint that the field's hybrid GA methodologies including, but not limited to, GA-Wrapper feature selector and HGA-neural networks, have substantially improved their potential through the resolution of problems such as exploration of unnecessary search space, accuracy performance problems, and complexity. The conclusions of this paper would result in discussing the potential that GAs bear in feature selection and future research directions for their enhancement in applicability and performance.",
        "subjects": "Neural and Evolutionary Computing, Machine Learning",
        "date": "2024-09-05 22:28:42 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.861153"
    },
    {
        "index": "#145",
        "title": "Exploiting Exogenous Structure for Sample-Efficient Reinforcement Learning",
        "link": "/arxiv/2409.14557",
        "arxiv_id": "2409.14557",
        "authors": "Jia Wan, Sean R. Sinclair, Devavrat Shah, Martin J. Wainwright",
        "summary": "We study a class of structured Markov Decision Processes (MDPs) known as Exo-MDPs, characterized by a partition of the state space into two components. The exogenous states evolve stochastically in a manner not affected by the agent's actions, whereas the endogenous states are affected by the actions, and evolve in a deterministic and known way conditional on the exogenous states. Exo-MDPs are a natural model for various applications including inventory control, finance, power systems, ride sharing, among others. Despite seeming restrictive, this work establishes that any discrete MDP can be represented as an Exo-MDP. Further, Exo-MDPs induce a natural representation of the transition and reward dynamics as linear functions of the exogenous state distribution. This linear representation leads to near-optimal algorithms with regret guarantees scaling only with the (effective) size of the exogenous state space $d$, independent of the sizes of the endogenous state and action spaces. Specifically, when the exogenous state is fully observed, a simple plug-in approach achieves a regret upper bound of $O(H^{3/2}\\sqrt{dK})$, where $H$ denotes the horizon and $K$ denotes the total number of episodes. When the exogenous state is unobserved, the linear representation leads to a regret upper bound of $O(H^{3/2}d\\sqrt{K})$. We also establish a nearly matching regret lower bound of $\\Omega(Hd\\sqrt{K})$ for the no observation regime. We complement our theoretical findings with an experimental study on inventory control problems.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2024-09-22 18:45:38 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.861344"
    },
    {
        "index": "#148",
        "title": "Sliding Window Training -- Utilizing Historical Recommender Systems Data for Foundation Models",
        "link": "/arxiv/2409.14517",
        "arxiv_id": "2409.14517",
        "authors": "Swanand Joshi, Yesu Feng, Ko-Jen Hsiao, Zhe Zhang, Sudarshan Lamkhede",
        "summary": "Long-lived recommender systems (RecSys) often encounter lengthy user-item interaction histories that span many years. To effectively learn long term user preferences, Large RecSys foundation models (FM) need to encode this information in pretraining. Usually, this is done by either generating a long enough sequence length to take all history sequences as input at the cost of large model input dimension or by dropping some parts of the user history to accommodate model size and latency requirements on the production serving side. In this paper, we introduce a sliding window training technique to incorporate long user history sequences during training time without increasing the model input dimension. We show the quantitative & qualitative improvements this technique brings to the RecSys FM in learning user long term preferences. We additionally show that the average quality of items in the catalog learnt in pretraining also improves.",
        "subjects": "Information Retrieval, Machine Learning",
        "date": "2024-08-21 18:59:52 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.862000"
    },
    {
        "index": "#153",
        "title": "A High-Performance External Validity Index for Clustering with a Large Number of Clusters",
        "link": "/arxiv/2409.14455",
        "arxiv_id": "2409.14455",
        "authors": "Mohammad Yasin Karbasian, Ramin Javadi",
        "summary": "This paper introduces the Stable Matching Based Pairing (SMBP) algorithm, a high-performance external validity index for clustering evaluation in large-scale datasets with a large number of clusters. SMBP leverages the stable matching framework to pair clusters across different clustering methods, significantly reducing computational complexity to $O(N^2)$, compared to traditional Maximum Weighted Matching (MWM) with $O(N^3)$ complexity. Through comprehensive evaluations on real-world and synthetic datasets, SMBP demonstrates comparable accuracy to MWM and superior computational efficiency. It is particularly effective for balanced, unbalanced, and large-scale datasets with a large number of clusters, making it a scalable and practical solution for modern clustering tasks. Additionally, SMBP is easily implementable within machine learning frameworks like PyTorch and TensorFlow, offering a robust tool for big data applications. The algorithm is validated through extensive experiments, showcasing its potential as a powerful alternative to existing methods such as Maximum Match Measure (MMM) and Centroid Ratio (CR).",
        "subjects": "Data Structures and Algorithms, Computer Science and Game Theory, Machine Learning",
        "date": "2024-09-22 14:08:57 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.863041"
    },
    {
        "index": "#154",
        "title": "A Unified Approach for Learning the Dynamics of Power System Generators and Inverter-based Resources",
        "link": "/arxiv/2409.14454",
        "arxiv_id": "2409.14454",
        "authors": "Shaohui Liu, Weiqian Cai, Hao Zhu, Brian Johnson",
        "summary": "The growing prevalence of inverter-based resources (IBRs) for renewable energy integration and electrification greatly challenges power system dynamic analysis. To account for both synchronous generators (SGs) and IBRs, this work presents an approach for learning the model of an individual dynamic component. The recurrent neural network (RNN) model is used to match the recursive structure in predicting the key dynamical states of a component from its terminal bus voltage and set-point input. To deal with the fast transients especially due to IBRs, we develop a Stable Integral (SI-)RNN to mimic high-order integral methods that can enhance the stability and accuracy for the dynamic learning task. We demonstrate that the proposed SI-RNN model not only can successfully predict the component's dynamic behaviors, but also offers the possibility of efficiently computing the dynamic sensitivity relative to a set-point change. These capabilities have been numerically validated based on full-order Electromagnetic Transient (EMT) simulations on a small test system with both SGs and IBRs, particularly for predicting the dynamics of grid-forming inverters.",
        "subjects": "Systems and Control, Machine Learning",
        "date": "2024-09-22 14:07:10 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.863230"
    },
    {
        "index": "#158",
        "title": "A Feature Engineering Approach for Literary and Colloquial Tamil Speech Classification using 1D-CNN",
        "link": "/arxiv/2409.14348",
        "arxiv_id": "2409.14348",
        "authors": "M. Nanmalar, S. Johanan Joysingh, P. Vijayalakshmi, T. Nagarajan",
        "summary": "In ideal human computer interaction (HCI), the colloquial form of a language would be preferred by most users, since it is the form used in their day-to-day conversations. However, there is also an undeniable necessity to preserve the formal literary form. By embracing the new and preserving the old, both service to the common man (practicality) and service to the language itself (conservation) can be rendered. Hence, it is ideal for computers to have the ability to accept, process, and converse in both forms of the language, as required. To address this, it is first necessary to identify the form of the input speech, which in the current work is between literary and colloquial Tamil speech. Such a front-end system must consist of a simple, effective, and lightweight classifier that is trained on a few effective features that are capable of capturing the underlying patterns of the speech signal. To accomplish this, a one-dimensional convolutional neural network (1D-CNN) that learns the envelope of features across time, is proposed. The network is trained on a select number of handcrafted features initially, and then on Mel frequency cepstral coefficients (MFCC) for comparison. The handcrafted features were selected to address various aspects of speech such as the spectral and temporal characteristics, prosody, and voice quality. The features are initially analyzed by considering ten parallel utterances and observing the trend of each feature with respect to time. The proposed 1D-CNN, trained using the handcrafted features, offers an F1 score of 0.9803, while that trained on the MFCC offers an F1 score of 0.9895. In light of this, feature ablation and feature combination are explored. When the best ranked handcrafted features, from the feature ablation study, are combined with the MFCC, they offer the best results with an F1 score of 0.9946.",
        "subjects": "Audio and Speech Processing, Machine Learning, Sound",
        "date": "2024-09-22 07:20:42 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.864172"
    },
    {
        "index": "#161",
        "title": "A competitive baseline for deep learning enhanced data assimilation using conditional Gaussian ensemble Kalman filtering",
        "link": "/arxiv/2409.14300",
        "arxiv_id": "2409.14300",
        "authors": "Zachariah Malik, Romit Maulik",
        "summary": "Ensemble Kalman Filtering (EnKF) is a popular technique for data assimilation, with far ranging applications. However, the vanilla EnKF framework is not well-defined when perturbations are nonlinear. We study two non-linear extensions of the vanilla EnKF - dubbed the conditional-Gaussian EnKF (CG-EnKF) and the normal score EnKF (NS-EnKF) - which sidestep assumptions of linearity by constructing the Kalman gain matrix with the `conditional Gaussian' update formula in place of the traditional one. We then compare these models against a state-of-the-art deep learning based particle filter called the score filter (SF). This model uses an expensive score diffusion model for estimating densities and also requires a strong assumption on the perturbation operator for validity. In our comparison, we find that CG-EnKF and NS-EnKF dramatically outperform SF for a canonical problem in high-dimensional multiscale data assimilation given by the Lorenz-96 system. Our analysis also demonstrates that the CG-EnKF and NS-EnKF can handle highly non-Gaussian additive noise perturbations, with the latter typically outperforming the former.",
        "subjects": "Machine Learning, Machine Learning, Dynamical Systems, Atmospheric and Oceanic Physics",
        "date": "2024-09-22 02:54:33 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.864812"
    },
    {
        "index": "#162",
        "title": "Accelerated Stochastic ExtraGradient: Mixing Hessian and Gradient Similarity to Reduce Communication in Distributed and Federated Learning",
        "link": "/arxiv/2409.14280",
        "arxiv_id": "2409.14280",
        "authors": "Dmitry Bylinkin, Kirill Degtyarev, Aleksandr Beznosikov",
        "summary": "Modern realities and trends in learning require more and more generalization ability of models, which leads to an increase in both models and training sample size. It is already difficult to solve such tasks in a single device mode. This is the reason why distributed and federated learning approaches are becoming more popular every day. Distributed computing involves communication between devices, which requires solving two key problems: efficiency and privacy. One of the most well-known approaches to combat communication costs is to exploit the similarity of local data. Both Hessian similarity and homogeneous gradients have been studied in the literature, but separately. In this paper, we combine both of these assumptions in analyzing a new method that incorporates the ideas of using data similarity and clients sampling. Moreover, to address privacy concerns, we apply the technique of additional noise and analyze its impact on the convergence of the proposed method. The theory is confirmed by training on real datasets.",
        "subjects": "Optimization and Control, Machine Learning",
        "date": "2024-09-22 00:49:10 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.864994"
    },
    {
        "index": "#173",
        "title": "Are Music Foundation Models Better at Singing Voice Deepfake Detection? Far-Better Fuse them with Speech Foundation Models",
        "link": "/arxiv/2409.14131",
        "arxiv_id": "2409.14131",
        "authors": "Orchid Chetia Phukan, Sarthak Jain, Swarup Ranjan Behera, Arun Balaji Buduru, Rajesh Sharma, S. R Mahadeva Prasanna",
        "summary": "In this study, for the first time, we extensively investigate whether music foundation models (MFMs) or speech foundation models (SFMs) work better for singing voice deepfake detection (SVDD), which has recently attracted attention in the research community. For this, we perform a comprehensive comparative study of state-of-the-art (SOTA) MFMs (MERT variants and music2vec) and SFMs (pre-trained for general speech representation learning as well as speaker recognition). We show that speaker recognition SFM representations perform the best amongst all the foundation models (FMs), and this performance can be attributed to its higher efficacy in capturing the pitch, tone, intensity, etc, characteristics present in singing voices. To our end, we also explore the fusion of FMs for exploiting their complementary behavior for improved SVDD, and we propose a novel framework, FIONA for the same. With FIONA, through the synchronization of x-vector (speaker recognition SFM) and MERT-v1-330M (MFM), we report the best performance with the lowest Equal Error Rate (EER) of 13.74 %, beating all the individual FMs as well as baseline FM fusions and achieving SOTA results.",
        "subjects": "Audio and Speech Processing, Machine Learning, Sound",
        "date": "2024-09-21 12:50:53 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.871386"
    },
    {
        "index": "#175",
        "title": "Consistency for Large Neural Networks",
        "link": "/arxiv/2409.14123",
        "arxiv_id": "2409.14123",
        "authors": "Haoran Zhan, Yingcun Xia",
        "summary": "Neural networks have shown remarkable success, especially in overparameterized or \"large\" models. Despite increasing empirical evidence and intuitive understanding, a formal mathematical justification for the behavior of such models, particularly regarding overfitting, remains incomplete. In this paper, we prove that the Mean Integrated Squared Error (MISE) of neural networks with either $L^1$ or $L^2$ penalty decreases after a certain model size threshold, provided that the sample size is sufficiently large, and achieves nearly the minimax optimality in the Barron space. These results challenge conventional statistical modeling frameworks and broadens recent findings on the double descent phenomenon in neural networks. Our theoretical results also extend to deep learning models with ReLU activation functions.",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory",
        "date": "2024-09-21 12:25:44 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.871770"
    },
    {
        "index": "#176",
        "title": "Efficient and Effective Model Extraction",
        "link": "/arxiv/2409.14122",
        "arxiv_id": "2409.14122",
        "authors": "Hongyu Zhu, Wentao Hu, Sichu Liang, Fangqi Li, Wenwen Wang, Shilin Wang",
        "summary": "Model extraction aims to create a functionally similar copy from a machine learning as a service (MLaaS) API with minimal overhead, often for illicit purposes or as a precursor to further attacks, posing a significant threat to the MLaaS ecosystem. However, recent studies show that model extraction is inefficient, especially when the target task distribution is unavailable. In such cases, even significantly increasing the attack budget fails to yield a sufficiently similar model, reducing the adversary's incentive. In this paper, we revisit the basic design choices throughout the extraction process and propose an efficient and effective algorithm, Efficient and Effective Model Extraction (E3), which optimizes both query preparation and the training routine. E3 achieves superior generalization over state-of-the-art methods while minimizing computational costs. For example, with only 0.005 times the query budget and less than 0.2 times the runtime, E3 outperforms classical generative model-based data-free model extraction with over 50% absolute accuracy improvement on CIFAR-10. Our findings highlight the ongoing risk of model extraction and propose E3 as a useful benchmark for future security evaluations.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2024-09-21 12:22:09 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.871980"
    },
    {
        "index": "#177",
        "title": "CONGRA: Benchmarking Automatic Conflict Resolution",
        "link": "/arxiv/2409.14121",
        "arxiv_id": "2409.14121",
        "authors": "Qingyu Zhang, Liangcai Su, Kai Ye, Chenxiong Qian",
        "summary": "Resolving conflicts from merging different software versions is a challenging task. To reduce the overhead of manual merging, researchers develop various program analysis-based tools which only solve specific types of conflicts and have a limited scope of application. With the development of language models, researchers treat conflict code as text, which theoretically allows for addressing almost all types of conflicts. However, the absence of effective conflict difficulty grading methods hinders a comprehensive evaluation of large language models (LLMs), making it difficult to gain a deeper understanding of their limitations. Furthermore, there is a notable lack of large-scale open benchmarks for evaluating the performance of LLMs in automatic conflict resolution. To address these issues, we introduce ConGra, a CONflict-GRAded benchmarking scheme designed to evaluate the performance of software merging tools under varying complexity conflict scenarios. We propose a novel approach to classify conflicts based on code operations and use it to build a large-scale evaluation dataset based on 44,948 conflicts from 34 real-world projects. We evaluate state-of-the-art LLMs on conflict resolution tasks using this dataset. By employing the dataset, we assess the performance of multiple state-of-the-art LLMs and code LLMs, ultimately uncovering two counterintuitive yet insightful phenomena. ConGra will be released at https://github.com/HKU-System-Security-Lab/ConGra.",
        "subjects": "Software Engineering, Machine Learning",
        "date": "2024-09-21 12:21:41 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.872168"
    },
    {
        "index": "#179",
        "title": "Quantum enhanced stratification of Breast Cancer: exploring quantum expressivity for real omics data",
        "link": "/arxiv/2409.14089",
        "arxiv_id": "2409.14089",
        "authors": "Valeria Repetto, Elia Giuseppe Ceroni, Giuseppe Buonaiuto, Romina D'Aurizio",
        "summary": "Quantum Machine Learning (QML) is considered one of the most promising applications of Quantum Computing in the Noisy Intermediate Scale Quantum (NISQ) era for the impact it is thought to have in the near future. Although promising theoretical assumptions, the exploration of how QML could foster new discoveries in Medicine and Biology fields is still in its infancy with few examples. In this study, we aimed to assess whether Quantum Kernels (QK) could effectively classify subtypes of Breast Cancer (BC) patients on the basis of molecular characteristics. We performed an heuristic exploration of encoding configurations with different entanglement levels to determine a trade-off between kernel expressivity and performances. Our results show that QKs yield comparable clustering results with classical methods while using fewer data points, and are able to fit the data with a higher number of clusters. Additionally, we conducted the experiments on the Quantum Processing Unit (QPU) to evaluate the effect of noise on the outcome. We found that less expressive encodings showed a higher resilience to noise, indicating that the computational pipeline can be reliably implemented on the NISQ devices. Our findings suggest that QK methods show promises for application in Precision Oncology, especially in scenarios where the dataset is limited in size and a granular non-trivial stratification of complex molecular data cannot be achieved classically.",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2024-09-21 10:00:09 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.872563"
    },
    {
        "index": "#181",
        "title": "AMT-APC: Automatic Piano Cover by Fine-Tuning an Automatic Music Transcription Model",
        "link": "/arxiv/2409.14086",
        "arxiv_id": "2409.14086",
        "authors": "Kazuma Komiya, Yoshihisa Fukuhara",
        "summary": "There have been several studies on automatically generating piano covers, and recent advancements in deep learning have enabled the creation of more sophisticated covers. However, existing automatic piano cover models still have room for improvement in terms of expressiveness and fidelity to the original. To address these issues, we propose a learning algorithm called AMT-APC, which leverages the capabilities of automatic music transcription models. By utilizing the strengths of well-established automatic music transcription models, we aim to improve the accuracy of piano cover generation. Our experiments demonstrate that the AMT-APC model reproduces original tracks more accurately than any existing models.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2024-09-21 09:51:22 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.872952"
    },
    {
        "index": "#188",
        "title": "Training Large ASR Encoders with Differential Privacy",
        "link": "/arxiv/2409.13953",
        "arxiv_id": "2409.13953",
        "authors": "Geeticka Chauhan, Steve Chien, Om Thakkar, Abhradeep Thakurta, Arun Narayanan",
        "summary": "Self-supervised learning (SSL) methods for large speech models have proven to be highly effective at ASR. With the interest in public deployment of large pre-trained models, there is a rising concern for unintended memorization and leakage of sensitive data points from the training data. In this paper, we apply differentially private (DP) pre-training to a SOTA Conformer-based encoder, and study its performance on a downstream ASR task assuming the fine-tuning data is public. This paper is the first to apply DP to SSL for ASR, investigating the DP noise tolerance of the BEST-RQ pre-training method. Notably, we introduce a novel variant of model pruning called gradient-based layer freezing that provides strong improvements in privacy-utility-compute trade-offs. Our approach yields a LibriSpeech test-clean/other WER (%) of 3.78/ 8.41 with ($10$, 1e^-9)-DP for extrapolation towards low dataset scales, and 2.81/ 5.89 with (10, 7.9e^-11)-DP for extrapolation towards high scales.",
        "subjects": "Sound, Cryptography and Security, Machine Learning, Audio and Speech Processing",
        "date": "2024-09-21 00:01:49 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.874763"
    },
    {
        "index": "#191",
        "title": "High-dimensional learning of narrow neural networks",
        "link": "/arxiv/2409.13904",
        "arxiv_id": "2409.13904",
        "authors": "Hugo Cui",
        "summary": "Recent years have been marked with the fast-pace diversification and increasing ubiquity of machine learning applications. Yet, a firm theoretical understanding of the surprising efficiency of neural networks to learn from high-dimensional data still proves largely elusive. In this endeavour, analyses inspired by statistical physics have proven instrumental, enabling the tight asymptotic characterization of the learning of neural networks in high dimensions, for a broad class of solvable models. This manuscript reviews the tools and ideas underlying recent progress in this line of work. We introduce a generic model -- the sequence multi-index model -- which encompasses numerous previously studied models as special instances. This unified framework covers a broad class of machine learning architectures with a finite number of hidden units, including multi-layer perceptrons, autoencoders, attention mechanisms; and tasks, including (un)supervised learning, denoising, contrastive learning, in the limit of large data dimension, and comparably large number of samples. We explicate in full detail the analysis of the learning of sequence multi-index models, using statistical physics techniques such as the replica method and approximate message-passing algorithms. This manuscript thus provides a unified presentation of analyses reported in several previous works, and a detailed overview of central techniques in the field of statistical physics of machine learning. This review should be a useful primer for machine learning theoreticians curious of statistical physics approaches; it should also be of value to statistical physicists interested in the transfer of such ideas to the study of neural networks.",
        "subjects": "Machine Learning, Disordered Systems and Neural Networks, Machine Learning",
        "date": "2024-09-20 21:20:04 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.875355"
    },
    {
        "index": "#192",
        "title": "PTQ4ADM: Post-Training Quantization for Efficient Text Conditional Audio Diffusion Models",
        "link": "/arxiv/2409.13894",
        "arxiv_id": "2409.13894",
        "authors": "Jayneel Vora, Aditya Krishnan, Nader Bouacida, Prabhu RV Shankar, Prasant Mohapatra",
        "summary": "Denoising diffusion models have emerged as state-of-the-art in generative tasks across image, audio, and video domains, producing high-quality, diverse, and contextually relevant data. However, their broader adoption is limited by high computational costs and large memory footprints. Post-training quantization (PTQ) offers a promising approach to mitigate these challenges by reducing model complexity through low-bandwidth parameters. Yet, direct application of PTQ to diffusion models can degrade synthesis quality due to accumulated quantization noise across multiple denoising steps, particularly in conditional tasks like text-to-audio synthesis. This work introduces PTQ4ADM, a novel framework for quantizing audio diffusion models(ADMs). Our key contributions include (1) a coverage-driven prompt augmentation method and (2) an activation-aware calibration set generation algorithm for text-conditional ADMs. These techniques ensure comprehensive coverage of audio aspects and modalities while preserving synthesis fidelity. We validate our approach on TANGO, Make-An-Audio, and AudioLDM models for text-conditional audio generation. Extensive experiments demonstrate PTQ4ADM's capability to reduce the model size by up to 70\\% while achieving synthesis quality metrics comparable to full-precision models($<$5\\% increase in FD scores). We show that specific layers in the backbone network can be quantized to 4-bit weights and 8-bit activations without significant quality loss. This work paves the way for more efficient deployment of ADMs in resource-constrained environments.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2024-09-20 20:52:56 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.875618"
    },
    {
        "index": "#194",
        "title": "Investigation of Time-Frequency Feature Combinations with Histogram Layer Time Delay Neural Networks",
        "link": "/arxiv/2409.13881",
        "arxiv_id": "2409.13881",
        "authors": "Amirmohammad Mohammadi, Iren'e Masabarakiza, Ethan Barnes, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples",
        "summary": "While deep learning has reduced the prevalence of manual feature extraction, transformation of data via feature engineering remains essential for improving model performance, particularly for underwater acoustic signals. The methods by which audio signals are converted into time-frequency representations and the subsequent handling of these spectrograms can significantly impact performance. This work demonstrates the performance impact of using different combinations of time-frequency features in a histogram layer time delay neural network. An optimal set of features is identified with results indicating that specific feature combinations outperform single data features.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2024-09-20 20:22:24 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.876124"
    },
    {
        "index": "#195",
        "title": "Transfer Learning for Passive Sonar Classification using Pre-trained Audio and ImageNet Models",
        "link": "/arxiv/2409.13878",
        "arxiv_id": "2409.13878",
        "authors": "Amirmohammad Mohammadi, Tejashri Kelhe, Davelle Carreiro, Alexandra Van Dine, Joshua Peeples",
        "summary": "Transfer learning is commonly employed to leverage large, pre-trained models and perform fine-tuning for downstream tasks. The most prevalent pre-trained models are initially trained using ImageNet. However, their ability to generalize can vary across different data modalities. This study compares pre-trained Audio Neural Networks (PANNs) and ImageNet pre-trained models within the context of underwater acoustic target recognition (UATR). It was observed that the ImageNet pre-trained models slightly out-perform pre-trained audio models in passive sonar classification. We also analyzed the impact of audio sampling rates for model pre-training and fine-tuning. This study contributes to transfer learning applications of UATR, illustrating the potential of pre-trained models to address limitations caused by scarce, labeled data in the UATR domain.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2024-09-20 20:13:45 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.876348"
    },
    {
        "index": "#199",
        "title": "Learning to Simulate Aerosol Dynamics with Graph Neural Networks",
        "link": "/arxiv/2409.13861",
        "arxiv_id": "2409.13861",
        "authors": "Fabiana Ferracina, Payton Beeler, Mahantesh Halappanavar, Bala Krishnamoorthy, Marco Minutoli, Laura Fierce",
        "summary": "Aerosol effects on climate, weather, and air quality depend on characteristics of individual particles, which are tremendously diverse and change in time. Particle-resolved models are the only models able to capture this diversity in particle physiochemical properties, and these models are computationally expensive. As a strategy for accelerating particle-resolved microphysics models, we introduce Graph-based Learning of Aerosol Dynamics (GLAD) and use this model to train a surrogate of the particle-resolved model PartMC-MOSAIC. GLAD implements a Graph Network-based Simulator (GNS), a machine learning framework that has been used to simulate particle-based fluid dynamics models. In GLAD, each particle is represented as a node in a graph, and the evolution of the particle population over time is simulated through learned message passing. We demonstrate our GNS approach on a simple aerosol system that includes condensation of sulfuric acid onto particles composed of sulfate, black carbon, organic carbon, and water. A graph with particles as nodes is constructed, and a graph neural network (GNN) is then trained using the model output from PartMC-MOSAIC. The trained GNN can then be used for simulating and predicting aerosol dynamics over time. Results demonstrate the framework's ability to accurately learn chemical dynamics and generalize across different scenarios, achieving efficient training and prediction times. We evaluate the performance across three scenarios, highlighting the framework's robustness and adaptability in modeling aerosol microphysics and chemistry.",
        "subjects": "Atmospheric and Oceanic Physics, Machine Learning",
        "date": "2024-09-20 19:21:43 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.877145"
    },
    {
        "index": "#201",
        "title": "Learning Ordering in Crystalline Materials with Symmetry-Aware Graph Neural Networks",
        "link": "/arxiv/2409.13851",
        "arxiv_id": "2409.13851",
        "authors": "Jiayu Peng, James Damewood, Jessica Karaguesian, Jaclyn R. Lunger, Rafael Gómez-Bombarelli",
        "summary": "Graph convolutional neural networks (GCNNs) have become a machine learning workhorse for screening the chemical space of crystalline materials in fields such as catalysis and energy storage, by predicting properties from structures. Multicomponent materials, however, present a unique challenge since they can exhibit chemical (dis)order, where a given lattice structure can encompass a variety of elemental arrangements ranging from highly ordered structures to fully disordered solid solutions. Critically, properties like stability, strength, and catalytic performance depend not only on structures but also on orderings. To enable rigorous materials design, it is thus critical to ensure GCNNs are capable of distinguishing among atomic orderings. However, the ordering-aware capability of GCNNs has been poorly understood. Here, we benchmark various neural network architectures for capturing the ordering-dependent energetics of multicomponent materials in a custom-made dataset generated with high-throughput atomistic simulations. Conventional symmetry-invariant GCNNs were found unable to discern the structural difference between the diverse symmetrically inequivalent atomic orderings of the same material, while symmetry-equivariant model architectures could inherently preserve and differentiate the distinct crystallographic symmetries of various orderings.",
        "subjects": "Materials Science, Machine Learning, Chemical Physics",
        "date": "2024-09-20 18:53:48 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.877621"
    },
    {
        "index": "#203",
        "title": "Physics-informed kernel learning",
        "link": "/arxiv/2409.13786",
        "arxiv_id": "2409.13786",
        "authors": "Nathan Doumèche, Francis Bach, Gérard Biau, Claire Boyer",
        "summary": "Physics-informed machine learning typically integrates physical priors into the learning process by minimizing a loss function that includes both a data-driven term and a partial differential equation (PDE) regularization. Building on the formulation of the problem as a kernel regression task, we use Fourier methods to approximate the associated kernel, and propose a tractable estimator that minimizes the physics-informed risk function. We refer to this approach as physics-informed kernel learning (PIKL). This framework provides theoretical guarantees, enabling the quantification of the physical prior's impact on convergence speed. We demonstrate the numerical performance of the PIKL estimator through simulations, both in the context of hybrid modeling and in solving PDEs. In particular, we show that PIKL can outperform physics-informed neural networks in terms of both accuracy and computation time. Additionally, we identify cases where PIKL surpasses traditional PDE solvers, particularly in scenarios with noisy boundary conditions.",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory",
        "date": "2024-09-20 06:55:20 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.878207"
    },
    {
        "index": "#207",
        "title": "Effect of Clinical History on Predictive Model Performance for Renal Complications of Diabetes",
        "link": "/arxiv/2409.13743",
        "arxiv_id": "2409.13743",
        "authors": "Davide Dei Cas, Barbara Di Camillo, Gian Paolo Fadini, Giovanni Sparacino, Enrico Longato",
        "summary": "Diabetes is a chronic disease characterised by a high risk of developing diabetic nephropathy, which, in turn, is the leading cause of end-stage chronic kidney disease. The early identification of individuals at heightened risk of such complications or their exacerbation can be of paramount importance to set a correct course of treatment. In the present work, from the data collected in the DARWIN-Renal (DApagliflozin Real-World evIdeNce-Renal) study, a nationwide multicentre retrospective real-world study, we develop an array of logistic regression models to predict, over different prediction horizons, the crossing of clinically relevant glomerular filtration rate (eGFR) thresholds for patients with diabetes by means of variables associated with demographic, anthropometric, laboratory, pathology, and therapeutic data. In doing so, we investigate the impact of information coming from patient's past visits on the model's predictive performance, coupled with an analysis of feature importance through the Boruta algorithm. Our models yield very good performance (AUROC as high as 0.98). We also show that the introduction of information from patient's past visits leads to improved model performance of up to 4%. The usefulness of past information is further corroborated by a feature importance analysis.",
        "subjects": "Quantitative Methods, Machine Learning",
        "date": "2024-09-10 20:27:00 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.879289"
    },
    {
        "index": "#217",
        "title": "Artificial neural networks on graded vector spaces",
        "link": "/arxiv/2407.19031",
        "arxiv_id": "2407.19031",
        "authors": "T. Shaska",
        "summary": "We develop new artificial neural network models for graded vector spaces, which are suitable when different features in the data have different significance (weights). This is the first time that such models are designed mathematically and they are expected to perform better than neural networks over usual vector spaces, which are the special case when the gradings are all 1s.",
        "subjects": "Artificial Intelligence",
        "date": "2024-07-26 18:17:58 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.881791"
    },
    {
        "index": "#218",
        "title": "Team QUST at SemEval-2023 Task 3: A Comprehensive Study of Monolingual and Multilingual Approaches for Detecting Online News Genre, Framing and Persuasion Techniques",
        "link": "/arxiv/2304.04190",
        "arxiv_id": "2304.04190",
        "authors": "Ye Jiang",
        "summary": "This paper describes the participation of team QUST in the SemEval2023 task 3. The monolingual models are first evaluated with the under-sampling of the majority classes in the early stage of the task. Then, the pre-trained multilingual model is fine-tuned with a combination of the class weights and the sample weights. Two different fine-tuning strategies, the task-agnostic and the task-dependent, are further investigated. All experiments are conducted under the 10-fold cross-validation, the multilingual approaches are superior to the monolingual ones. The submitted system achieves the second best in Italian and Spanish (zero-shot) in subtask-1.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2023-04-09 08:14:01 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.881980"
    },
    {
        "index": "#219",
        "title": "Lecture notes on high-dimensional data",
        "link": "/arxiv/2101.05841",
        "arxiv_id": "2101.05841",
        "authors": "Sven-Ake Wegner",
        "summary": "These are lecture notes based on the first part of a course on 'Mathematical Data Science', which I taught to final year BSc students in the UK in 2019-2020. Topics include: concentration of measure in high dimensions; Gaussian random vectors in high dimensions; random projections; separation/disentangling of Gaussian data. A revised version has been published as part of the textbook [Mathematical Introduction to Data Science, Springer, Berlin, Heidelberg, 2024, https://link.springer.com/book/10.1007/978-3-662-69426-8].",
        "subjects": "Functional Analysis, Machine Learning",
        "date": "2021-01-14 19:31:44 UTC",
        "category": "cs.LG",
        "crawl_time": "2025-09-24T16:31:00.882152"
    },
    {
        "index": "#1",
        "title": "Work Smarter Not Harder: Simple Imitation Learning with CS-PIBT Outperforms Large Scale Imitation Learning for MAPF",
        "link": "/arxiv/2409.14491",
        "arxiv_id": "2409.14491",
        "authors": "Rishi Veerapaneni, Arthur Jakobsson, Kevin Ren, Samuel Kim, Jiaoyang Li, Maxim Likhachev",
        "summary": "Multi-Agent Path Finding (MAPF) is the problem of effectively finding efficient collision-free paths for a group of agents in a shared workspace. The MAPF community has largely focused on developing high-performance heuristic search methods. Recently, several works have applied various machine learning (ML) techniques to solve MAPF, usually involving sophisticated architectures, reinforcement learning techniques, and set-ups, but none using large amounts of high-quality supervised data. Our initial objective in this work was to show how simple large scale imitation learning of high-quality heuristic search methods can lead to state-of-the-art ML MAPF performance. However, we find that, at least with our model architecture, simple large scale (700k examples with hundreds of agents per example) imitation learning does \\textit{not} produce impressive results. Instead, we find that by using prior work that post-processes MAPF model predictions to resolve 1-step collisions (CS-PIBT), we can train a simple ML MAPF model in minutes that dramatically outperforms existing ML MAPF policies. This has serious implications for all future ML MAPF policies (with local communication) which currently struggle to scale. In particular, this finding implies that future learnt policies should (1) always use smart 1-step collision shields (e.g. CS-PIBT), (2) always include the collision shield with greedy actions as a baseline (e.g. PIBT) and (3) motivates future models to focus on longer horizon / more complex planning as 1-step collisions can be efficiently resolved.",
        "subjects": "Multiagent Systems, Robotics",
        "date": "2024-09-22 15:36:29 UTC",
        "category": "cs.MA",
        "crawl_time": "2025-09-24T16:31:03.690338"
    },
    {
        "index": "#2",
        "title": "A novel load distribution strategy for aggregators using IoT-enabled mobile devices",
        "link": "/arxiv/2409.14293",
        "arxiv_id": "2409.14293",
        "authors": "Nitin Shivaraman, Jakob Fittler, Saravanan Ramanathan, Arvind Easwaran, Sebastian Steinhorst",
        "summary": "The rapid proliferation of Internet-of-things (IoT) as well as mobile devices such as Electric Vehicles (EVs), has led to unpredictable load at the grid. The demand to supply ratio is particularly exacerbated at a few grid aggregators (charging stations) with excessive demand due to the geographic location, peak time, etc. Existing solutions on demand response cannot achieve significant improvements based only on time-shifting the loads without considering the device properties such as charging modes and movement capabilities to enable geographic migration. Additionally, the information on the spare capacity at a few aggregators can aid in re-channeling the load from other aggregators facing excess demand to allow migration of devices. In this paper, we model these flexible properties of the devices as a mixed-integer non-linear problem (MINLP) to minimize excess load and the improve the utility (benefit) across all devices. We propose an online distributed low-complexity heuristic that prioritizes devices based on demand and deadlines to minimize the cumulative loss in utility. The proposed heuristic is tested on an exhaustive set of synthetic data and compared with solutions from a solver/optimization tool for the same runtime to show the impracticality of using a solver. A real-world EV testbed data is also tested with our proposed solution and other scheduling solutions to show the practicality of generating a feasible schedule and a loss improvement of at least 57.23%.",
        "subjects": "Multiagent Systems, Systems and Control, Optimization and Control",
        "date": "2024-09-22 01:58:37 UTC",
        "category": "cs.MA",
        "crawl_time": "2025-09-24T16:31:03.690616"
    },
    {
        "index": "#7",
        "title": "Kinodynamic Motion Planning for Collaborative Object Transportation by Multiple Mobile Manipulators",
        "link": "/arxiv/2409.14910",
        "arxiv_id": "2409.14910",
        "authors": "Keshab Patra, Arpita Sinha, Anirban Guha",
        "summary": "This work proposes a kinodynamic motion planning technique for collaborative object transportation by multiple mobile manipulators in dynamic environments. A global path planner computes a linear piecewise path from start to goal. A novel algorithm detects the narrow regions between the static obstacles and aids in defining the obstacle-free region to enhance the feasibility of the global path. We then formulate a local online motion planning technique for trajectory generation that minimizes the control efforts in a receding horizon manner. It plans the trajectory for finite time horizons, considering the kinodynamic constraints and the static and dynamic obstacles. The planning technique jointly plans for the mobile bases and the arms to utilize the locomotion capability of the mobile base and the manipulation capability of the arm efficiently. We use a convex cone approach to avoid self-collision of the formation by modifying the mobile manipulators admissible state without imposing additional constraints. Numerical simulations and hardware experiments showcase the efficiency of the proposed approach.",
        "subjects": "Robotics, Multiagent Systems, Optimization and Control",
        "date": "2024-09-23 11:03:16 UTC",
        "category": "cs.MA",
        "crawl_time": "2025-09-24T16:31:03.691677"
    },
    {
        "index": "#9",
        "title": "Cloud and IoT based Smart Agent-driven Simulation of Human Gait for Detecting Muscles Disorder",
        "link": "/arxiv/2409.14561",
        "arxiv_id": "2409.14561",
        "authors": "Sina Saadati, Mohammadreza Razzazi",
        "summary": "Motion disorders pose a significant global health concern and are often managed with pharmacological treatments that may lead to undesirable long-term effects. Current therapeutic strategies lack differentiation between healthy and unhealthy muscles in a patient, necessitating a targeted approach to distinguish between musculature. There is still no motion analyzer application for this purpose. Additionally, there is a deep gap in motion analysis software as some studies prioritize simulation, neglecting software needs, while others concentrate on computational aspects, disregarding simulation nuances. We introduce a comprehensive five-phase methodology to analyze the neuromuscular system of the lower body during gait. The first phase employs an innovative IoT-based method for motion signal capture. The second and third phases involve an agent-driven biomechanical model of the lower body skeleton and a model of human voluntary muscle. Thus, using an agent-driven approach, motion-captured signals can be converted to neural stimuli. The simulation results are then analyzed by our proposed ensemble neural network framework in the fourth step in order to detect abnormal motion in each joint. Finally, the results are shown by a userfriendly graphical interface which promotes the usability of the method. Utilizing the developed application, we simulate the neuromusculoskeletal system of some patients during the gait cycle, enabling the classification of healthy and pathological muscle activity through joint-based analysis. This study leverages cloud computing to create an infrastructure-independent application which is globally accessible. The proposed application enables experts to differentiate between healthy and unhealthy muscles in a patient by simulating his gait.",
        "subjects": "Human-Computer Interaction, Multiagent Systems",
        "date": "2024-08-30 09:30:56 UTC",
        "category": "cs.MA",
        "crawl_time": "2025-09-24T16:31:03.692062"
    },
    {
        "index": "#11",
        "title": "Adaptive bias for dissensus in nonlinear opinion dynamics with application to evolutionary division of labor games",
        "link": "/arxiv/2409.13964",
        "arxiv_id": "2409.13964",
        "authors": "Tyler M. Paine, Anastasia Bizyaeva, Michael R. Benjamin",
        "summary": "This paper addresses the problem of adaptively controlling the bias parameter in nonlinear opinion dynamics (NOD) to allocate agents into groups of arbitrary sizes for the purpose of maximizing collective rewards. In previous work, an algorithm based on the coupling of NOD with an multi-objective behavior optimization was successfully deployed as part of a multi-robot system in an autonomous task allocation field experiment. Motivated by the field results, in this paper we propose and analyze a new task allocation model that synthesizes NOD with an evolutionary game framework. We prove sufficient conditions under which it is possible to control the opinion state in the group to a desired allocation of agents between two tasks through an adaptive bias using decentralized feedback. We then verify the theoretical results with a simulation study of a collaborative evolutionary division of labor game.",
        "subjects": "Systems and Control, Multiagent Systems, Robotics",
        "date": "2024-09-21 00:54:15 UTC",
        "category": "cs.MA",
        "crawl_time": "2025-09-24T16:31:03.692469"
    }
]