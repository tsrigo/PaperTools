[
    {
        "index": "#1",
        "title": "Partial Resilient Leader-Follower Consensus in Time-Varying Graphs",
        "link": "/arxiv/2510.01144",
        "arxiv_id": "2510.01144",
        "authors": "Haejoon Lee, Dimitra Panagou",
        "summary": "This work studies resilient leader-follower consensus with a bounded number of adversaries. Existing approaches typically require robustness conditions of the entire network to guarantee resilient consensus. However, the behavior of such systems when these conditions are not fully met remains unexplored. To address this gap, we introduce the notion of partial leader-follower consensus, in which a subset of non-adversarial followers successfully tracks the leader's reference state despite insufficient robustness. We propose a novel distributed algorithm - the Bootstrap Percolation and Mean Subsequence Reduced (BP-MSR) algorithm - and establish sufficient conditions for individual followers to achieve consensus via the BP-MSR algorithm in arbitrary time-varying graphs. We validate our findings through simulations, demonstrating that our method guarantees partial leader-follower consensus, even when standard resilient consensus algorithms fail.",
        "subjects": "Multiagent Systems, Systems and Control",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.396131"
    },
    {
        "index": "#2",
        "title": "Stochastic Self-Organization in Multi-Agent Systems",
        "link": "/arxiv/2510.00685",
        "arxiv_id": "2510.00685",
        "authors": "Nurbek Tastan, Samuel Horvath, Karthik Nandakumar",
        "summary": "Multi-agent systems (MAS) based on Large Language Models (LLMs) have the potential to solve tasks that are beyond the reach of any single LLM. However, this potential can only be realized when the collaboration mechanism between agents is optimized. Specifically, optimizing the communication structure between agents is critical for fruitful collaboration. Most existing approaches rely on fixed topologies, pretrained graph generators, optimization over edges, or employ external LLM judges, thereby adding to the complexity. In this work, we introduce a response-conditioned framework that adapts communication on-the-fly. Agents independently generate responses to the user query and assess peer contributions using an approximation of the Shapley value. A directed acyclic graph (DAG) is then constructed to regulate the propagation of the responses among agents, which ensures stable and efficient message transmission from high-contributing agents to others. This graph is dynamically updated based on the agent responses from the previous collaboration round. Since the proposed framework enables the self-organization of agents without additional supervision or training, we refer to it as SelfOrg. The SelfOrg framework goes beyond task- and query-level optimization and takes into account the stochastic nature of agent responses. Experiments with both strong and weak LLM backends demonstrate robust performance, with significant gains in the weak regime where prior methods collapse. We also theoretically show that multiple agents increase the chance of correctness and that the correct responses naturally dominate the information flow.",
        "subjects": "Multiagent Systems, Computation and Language, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.396452"
    },
    {
        "index": "#3",
        "title": "Conflict-Based Search as a Protocol: A Multi-Agent Motion Planning Protocol for Heterogeneous Agents, Solvers, and Independent Tasks",
        "link": "/arxiv/2510.00425",
        "arxiv_id": "2510.00425",
        "authors": "Rishi Veerapaneni, Alvin Tang, Haodong He, Sophia Zhao, Viraj Shah, Yidai Cen, Ziteng Ji, Gabriel Olin, Jon Arrizabalaga, Yorai Shaoul, Jiaoyang Li, Maxim Likhachev",
        "summary": "Imagine the future construction site, hospital, office, or even sophisticated household with dozens of robots bought from different manufacturers. How can we enable these different systems to effectively move in a shared environment, given that each robot may have its own independent motion planning system? This work shows how we can get efficient collision-free movements between algorithmically heterogeneous agents by using Conflict-Based Search (Sharon et al. 2015) as a protocol. At its core, the CBS Protocol requires one specific single-agent motion planning API; finding a collision-free path that satisfies certain space-time constraints. Given such an API, CBS uses a central planner to find collision-free paths - independent of how the API is implemented. We show how this protocol enables multi-agent motion planning for a heterogeneous team of agents completing independent tasks with a variety of single-agent planners including: Heuristic Search (e.g., A*), Sampling Based Search (e.g., RRT), Optimization (e.g., Direct Collocation), Diffusion, and Reinforcement Learning.",
        "subjects": "Multiagent Systems, Robotics",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.396788"
    },
    {
        "index": "#4",
        "title": "Reasoning-Aware Prompt Orchestration: A Foundation Model for Multi-Agent Language Model Coordination",
        "link": "/arxiv/2510.00326",
        "arxiv_id": "2510.00326",
        "authors": "Hassen Dhrif",
        "summary": "The emergence of large language models has enabled sophisticated multi-agent systems, yet coordinating their reasoning capabilities through prompt engineering remains challenging. We present a theoretically-grounded framework for dynamic prompt orchestration that enhances reasoning across multiple specialized agents. This framework addresses three core challenges: logical consistency preservation during agent transitions, reasoning-aware prompt adaptation, and scalable coordination of distributed inference. Our approach formalizes agent states using prompt templates, reasoning context vectors, and capability matrices. We prove system convergence to stable coordination patterns when step sizes satisfy $\\alpha < \\frac{1}{2L}$ where $L$ is the Lipschitz constant of the state transition function. We implement this through a distributed architecture that dynamically routes reasoning tasks while maintaining semantic coherence. Experimental results on 1,000 synthetic multi-agent conversations demonstrate a 42% reduction in reasoning latency, a 23% improvement in logical consistency measured by ROUGE-L score, and an 89% success rate for task completion without context loss across agent transitions. Ablation studies identify the consensus mechanism as the primary performance driver, while revealing limitations: performance degrades beyond 10 agent transitions, and the system requires 76.5GB memory for 1,000 concurrent agents. These findings establish a new paradigm for scalable reasoning in multi-agent systems, providing theoretical foundations for understanding reasoning emergence across coordinated language models.",
        "subjects": "Multiagent Systems, Artificial Intelligence",
        "date": "2025-09-30",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.397035"
    },
    {
        "index": "#5",
        "title": "A Hierarchical Agentic Framework for Autonomous Drone-Based Visual Inspection",
        "link": "/arxiv/2510.00259",
        "arxiv_id": "2510.00259",
        "authors": "Ethan Herron, Xian Yeow Lee, Gregory Sin, Teresa Gonzalez Diaz, Ahmed Farahat, Chetan Gupta",
        "summary": "Autonomous inspection systems are essential for ensuring the performance and longevity of industrial assets. Recently, agentic frameworks have demonstrated significant potential for automating inspection workflows but have been limited to digital tasks. Their application to physical assets in real-world environments, however, remains underexplored. In this work, our contributions are two-fold: first, we propose a hierarchical agentic framework for autonomous drone control, and second, a reasoning methodology for individual function executions which we refer to as ReActEval. Our framework focuses on visual inspection tasks in indoor industrial settings, such as interpreting industrial readouts or inspecting equipment. It employs a multi-agent system comprising a head agent and multiple worker agents, each controlling a single drone. The head agent performs high-level planning and evaluates outcomes, while worker agents implement ReActEval to reason over and execute low-level actions. Operating entirely in natural language, ReActEval follows a plan, reason, act, evaluate cycle, enabling drones to handle tasks ranging from simple navigation (e.g., flying forward 10 meters and land) to complex high-level tasks (e.g., locating and reading a pressure gauge). The evaluation phase serves as a feedback and/or replanning stage, ensuring actions align with user objectives while preventing undesirable outcomes. We evaluate the framework in a simulated environment with two worker agents, assessing performance qualitatively and quantitatively based on task completion across varying complexity levels and workflow efficiency. By leveraging natural language processing for agent communication, our approach offers a novel, flexible, and user-accessible alternative to traditional drone-based solutions, enabling autonomous problem-solving for industrial inspection without extensive user intervention.",
        "subjects": "Multiagent Systems, Artificial Intelligence, Robotics, Systems and Control",
        "date": "2025-09-30",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.397336"
    },
    {
        "index": "#6",
        "title": "Exploring Network-Knowledge Graph Duality: A Case Study in Agentic Supply Chain Risk Analysis",
        "link": "/arxiv/2510.01115",
        "arxiv_id": "2510.01115",
        "authors": "Evan Heus, Rick Bookstaber, Dhruv Sharma",
        "summary": "Large Language Models (LLMs) struggle with the complex, multi-modal, and network-native data underlying financial risk. Standard Retrieval-Augmented Generation (RAG) oversimplifies relationships, while specialist models are costly and static. We address this gap with an LLM-centric agent framework for supply chain risk analysis. Our core contribution is to exploit the inherent duality between networks and knowledge graphs (KG). We treat the supply chain network as a KG, allowing us to use structural network science principles for retrieval. A graph traverser, guided by network centrality scores, efficiently extracts the most economically salient risk paths. An agentic architecture orchestrates this graph retrieval alongside data from numerical factor tables and news streams. Crucially, it employs novel ``context shells'' -- descriptive templates that embed raw figures in natural language -- to make quantitative data fully intelligible to the LLM. This lightweight approach enables the model to generate concise, explainable, and context-rich risk narratives in real-time without costly fine-tuning or a dedicated graph database.",
        "subjects": "Artificial Intelligence, Multiagent Systems, Theoretical Economics, Physics and Society",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.397618"
    },
    {
        "index": "#7",
        "title": "Shared Object Manipulation with a Team of Collaborative Quadrupeds",
        "link": "/arxiv/2510.00682",
        "arxiv_id": "2510.00682",
        "authors": "Shengzhi Wang, Niels Dehio, Xuanqi Zeng, Xian Yang, Lingwei Zhang, Yun-Hui Liu, K. W. Samuel Au",
        "summary": "Utilizing teams of multiple robots is advantageous for handling bulky objects. Many related works focus on multi-manipulator systems, which are limited by workspace constraints. In this paper, we extend a classical hybrid motion-force controller to a team of legged manipulator systems, enabling collaborative loco-manipulation of rigid objects with a force-closed grasp. Our novel approach allows the robots to flexibly coordinate their movements, achieving efficient and stable object co-manipulation and transport, validated through extensive simulations and real-world experiments.",
        "subjects": "Robotics, Multiagent Systems, Systems and Control",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.397918"
    },
    {
        "index": "#8",
        "title": "Capital Games and Growth Equilibria",
        "link": "/arxiv/2510.00472",
        "arxiv_id": "2510.00472",
        "authors": "Ben Abramowitz",
        "summary": "We examine formal games that we call \"capital games\" in which player payoffs are known, but their payoffs are not guaranteed to be von Neumann-Morgenstern utilities. In capital games, the dynamics of player payoffs determine their utility functions. Different players can have different payoff dynamics. We make no assumptions about where these dynamics come from, but implicitly assume that they come from the players' actions and interactions over time. We define an equilibrium concept called \"growth equilibrium\" and show a correspondence between the growth equilibria of capital games and the Nash equilibria of standard games.",
        "subjects": "Computer Science and Game Theory, Multiagent Systems, Theoretical Economics",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.398174"
    },
    {
        "index": "#9",
        "title": "Cloud Investigation Automation Framework (CIAF): An AI-Driven Approach to Cloud Forensics",
        "link": "/arxiv/2510.00452",
        "arxiv_id": "2510.00452",
        "authors": "Dalal Alharthi, Ivan Roberto Kawaminami Garcia",
        "summary": "Large Language Models (LLMs) have gained prominence in domains including cloud security and forensics. Yet cloud forensic investigations still rely on manual analysis, making them time-consuming and error-prone. LLMs can mimic human reasoning, offering a pathway to automating cloud log analysis. To address this, we introduce the Cloud Investigation Automation Framework (CIAF), an ontology-driven framework that systematically investigates cloud forensic logs while improving efficiency and accuracy. CIAF standardizes user inputs through semantic validation, eliminating ambiguity and ensuring consistency in log interpretation. This not only enhances data quality but also provides investigators with reliable, standardized information for decision-making. To evaluate security and performance, we analyzed Microsoft Azure logs containing ransomware-related events. By simulating attacks and assessing CIAF's impact, results showed significant improvement in ransomware detection, achieving precision, recall, and F1 scores of 93 percent. CIAF's modular, adaptable design extends beyond ransomware, making it a robust solution for diverse cyberattacks. By laying the foundation for standardized forensic methodologies and informing future AI-driven automation, this work underscores the role of deterministic prompt engineering and ontology-based validation in enhancing cloud forensic investigations. These advancements improve cloud security while paving the way for efficient, automated forensic workflows.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.398446"
    },
    {
        "index": "#10",
        "title": "A Call to Action for a Secure-by-Design Generative AI Paradigm",
        "link": "/arxiv/2510.00451",
        "arxiv_id": "2510.00451",
        "authors": "Dalal Alharthi, Ivan Roberto Kawaminami Garcia",
        "summary": "Large language models have gained widespread prominence, yet their vulnerability to prompt injection and other adversarial attacks remains a critical concern. This paper argues for a security-by-design AI paradigm that proactively mitigates LLM vulnerabilities while enhancing performance. To achieve this, we introduce PromptShield, an ontology-driven framework that ensures deterministic and secure prompt interactions. It standardizes user inputs through semantic validation, eliminating ambiguity and mitigating adversarial manipulation. To assess PromptShield's security and performance capabilities, we conducted an experiment on an agent-based system to analyze cloud logs within Amazon Web Services (AWS), containing 493 distinct events related to malicious activities and anomalies. By simulating prompt injection attacks and assessing the impact of deploying PromptShield, our results demonstrate a significant improvement in model security and performance, achieving precision, recall, and F1 scores of approximately 94%. Notably, the ontology-based framework not only mitigates adversarial threats but also enhances the overall performance and reliability of the system. Furthermore, PromptShield's modular and adaptable design ensures its applicability beyond cloud security, making it a robust solution for safeguarding generative AI applications across various domains. By laying the groundwork for AI safety standards and informing future policy development, this work stimulates a crucial dialogue on the pivotal role of deterministic prompt engineering and ontology-based validation in ensuring the safe and responsible deployment of LLMs in high-stakes environments.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.398713"
    },
    {
        "index": "#11",
        "title": "Physics-Informed Neural Controlled Differential Equations for Scalable Long Horizon Multi-Agent Motion Forecasting",
        "link": "/arxiv/2510.00401",
        "arxiv_id": "2510.00401",
        "authors": "Shounak Sural, Charles Kekeh, Wenliang Liu, Federico Pecora, Mouhacine Benosman",
        "summary": "Long-horizon motion forecasting for multiple autonomous robots is challenging due to non-linear agent interactions, compounding prediction errors, and continuous-time evolution of dynamics. Learned dynamics of such a system can be useful in various applications such as travel time prediction, prediction-guided planning and generative simulation. In this work, we aim to develop an efficient trajectory forecasting model conditioned on multi-agent goals. Motivated by the recent success of physics-guided deep learning for partially known dynamical systems, we develop a model based on neural Controlled Differential Equations (CDEs) for long-horizon motion forecasting. Unlike discrete-time methods such as RNNs and transformers, neural CDEs operate in continuous time, allowing us to combine physics-informed constraints and biases to jointly model multi-robot dynamics. Our approach, named PINCoDE (Physics-Informed Neural Controlled Differential Equations), learns differential equation parameters that can be used to predict the trajectories of a multi-agent system starting from an initial condition. PINCoDE is conditioned on future goals and enforces physics constraints for robot motion over extended periods of time. We adopt a strategy that scales our model from 10 robots to 100 robots without the need for additional model parameters, while producing predictions with an average ADE below 0.5 m for a 1-minute horizon. Furthermore, progressive training with curriculum learning for our PINCoDE model results in a 2.7X reduction of forecasted pose error over 4 minute horizons compared to analytical models.",
        "subjects": "Robotics, Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-10-01",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.399009"
    },
    {
        "index": "#12",
        "title": "In-Context Curiosity: Distilling Exploration for Decision-Pretrained Transformers on Bandit Tasks",
        "link": "/arxiv/2510.00347",
        "arxiv_id": "2510.00347",
        "authors": "Huitao Yang, Guanting Chen",
        "summary": "As large language models (LLMs) continue to grow in capability, there is increasing interest in incorporating them into decision-making tasks. A common pipeline for this is Decision-Pretrained Transformers (DPTs). However, existing training methods for DPTs often struggle to generalize beyond their pretraining data distribution. To explore mitigation of this limitation, we propose in-context curiosity -- a lightweight, exploration-inspired regularizer for offline pretraining -- and introduce the Prediction-Powered Transformer (PPT) framework. PPT augments DPT with an auxiliary reward predictor, using prediction error as an intrinsic curiosity signal to encourage broader exploration during training. In proof-of-concept experiments on Gaussian multi-armed bandits, PPT shows improved robustness: it moderates the performance degradation observed in DPT when test environments exhibit higher variance in reward, particularly when pretraining data has limited diversity. While the quality of offline data remain fundamental, our preliminary results suggest that curiosity-driven pretraining offers a promising direction for enhancing out-of-distribution generalization in in-context RL agents.",
        "subjects": "Machine Learning, Artificial Intelligence, Multiagent Systems",
        "date": "2025-09-30",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.399270"
    },
    {
        "index": "#13",
        "title": "Robust Federated Inference",
        "link": "/arxiv/2510.00310",
        "arxiv_id": "2510.00310",
        "authors": "Akash Dhasade, Sadegh Farhadkhani, Rachid Guerraoui, Nirupam Gupta, Maxime Jacovella, Anne-Marie Kermarrec, Rafael Pinot",
        "summary": "Federated inference, in the form of one-shot federated learning, edge ensembles, or federated ensembles, has emerged as an attractive solution to combine predictions from multiple models. This paradigm enables each model to remain local and proprietary while a central server queries them and aggregates predictions. Yet, the robustness of federated inference has been largely neglected, leaving them vulnerable to even simple attacks. To address this critical gap, we formalize the problem of robust federated inference and provide the first robustness analysis of this class of methods. Our analysis of averaging-based aggregators shows that the error of the aggregator is small either when the dissimilarity between honest responses is small or the margin between the two most probable classes is large. Moving beyond linear averaging, we show that problem of robust federated inference with non-linear aggregators can be cast as an adversarial machine learning problem. We then introduce an advanced technique using the DeepSet aggregation model, proposing a novel composition of adversarial training and test-time robust aggregation to robustify non-linear aggregators. Our composition yields significant improvements, surpassing existing robust aggregation methods by 4.7 - 22.2% in accuracy points across diverse benchmarks.",
        "subjects": "Machine Learning, Multiagent Systems",
        "date": "2025-09-30",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.399557"
    },
    {
        "index": "#14",
        "title": "MAGIC-MASK: Multi-Agent Guided Inter-Agent Collaboration with Mask-Based Explainability for Reinforcement Learning",
        "link": "/arxiv/2510.00274",
        "arxiv_id": "2510.00274",
        "authors": "Maisha Maliha, Dean Hougen",
        "summary": "Understanding the decision-making process of Deep Reinforcement Learning agents remains a key challenge for deploying these systems in safety-critical and multi-agent environments. While prior explainability methods like StateMask, have advanced the identification of critical states, they remain limited by computational cost, exploration coverage, and lack of adaptation to multi-agent settings. To overcome these limitations, we propose a mathematically grounded framework, MAGIC-MASK (Multi-Agent Guided Inter-agent Collaboration with Mask-Based Explainability for Reinforcement Learning), that extends perturbation-based explanation to Multi-Agent Reinforcement Learning. Our method integrates Proximal Policy Optimization, adaptive epsilon-greedy exploration, and lightweight inter-agent collaboration to share masked state information and peer experience. This collaboration enables each agent to perform saliency-guided masking and share reward-based insights with peers, reducing the time required for critical state discovery, improving explanation fidelity, and leading to faster and more robust learning. The core novelty of our approach lies in generalizing explainability from single-agent to multi-agent systems through a unified mathematical formalism built on trajectory perturbation, reward fidelity analysis, and Kullback-Leibler divergence regularization. This framework yields localized, interpretable explanations grounded in probabilistic modeling and multi-agent Markov decision processes. We validate our framework on both single-agent and multi-agent benchmarks, including a multi-agent highway driving environment and Google Research Football, demonstrating that MAGIC-MASK consistently outperforms state-of-the-art baselines in fidelity, learning efficiency, and policy robustness while offering interpretable and transferable explanations.",
        "subjects": "Artificial Intelligence, Machine Learning, Multiagent Systems",
        "date": "2025-09-30",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.399828"
    },
    {
        "index": "#15",
        "title": "Learning to Lead Themselves: Agentic AI in MAS using MARL",
        "link": "/arxiv/2510.00022",
        "arxiv_id": "2510.00022",
        "authors": "Ansh Kamthan",
        "summary": "As autonomous systems move from prototypes to real deployments, the ability of multiple agents to make decentralized, cooperative decisions becomes a core requirement. This paper examines how agentic artificial intelligence, agents that act independently, adaptively and proactively can improve task allocation and coordination in multi-agent systems, with primary emphasis on drone delivery and secondary relevance to warehouse automation. We formulate the problem in a cooperative multi-agent reinforcement learning setting and implement a lightweight multi-agent Proximal Policy Optimization, called IPPO, approach in PyTorch under a centralized-training, decentralized-execution paradigm. Experiments are conducted in PettingZoo environment, where multiple homogeneous drones or agents must self-organize to cover distinct targets without explicit communication.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-09-24",
        "category": "cs.MA",
        "crawl_time": "2025-10-06T23:26:03.400070"
    }
]