[
    {
        "index": "#1",
        "title": "Grassroots Logic Programs: A Secure, Multiagent, Concurrent, Logic Programming Language",
        "link": "/arxiv/2510.15747",
        "arxiv_id": "2510.15747",
        "authors": "Ehud Shapiro",
        "summary": "Grassroots platforms are distributed applications run by\\linebreak cryptographically-identified people on their networked personal devices, where multiple disjoint platform instances emerge independently and coalesce when they interoperate. Their foundation is the grassroots social graph, upon which grassroots social networks, grassroots cryptocurrencies, and grassroots democratic federations can be built. Grassroots platforms have yet to be implemented, the key challenge being faulty and malicious participants: without secure programming support, correct participants cannot reliably identify each other, establish secure communication, or verify each other's code integrity. We present Grassroots Logic Programs (GLP), a secure, multiagent, concurrent, logic programming language for implementing grassroots platforms. GLP extends logic programs with paired single-reader/single-writer (SRSW) logic variables, providing secure communication channels among cryptographically-identified people through encrypted, signed and attested messages, which enable identity and code integrity verification. We present GLP progressively: logic programs, concurrent GLP, multiagent GLP, augmenting it with cryptographic security, and providing smartphone implementation-ready specifications. We prove safety properties including that GLP computations are deductions, SRSW preservation, acyclicity, and monotonicity. We prove multiagent GLP is grassroots and that GLP streams achieve blockchain security properties. We present a grassroots social graph protocol establishing authenticated peer-to-peer connections and demonstrate secure grassroots social networking applications.",
        "subjects": "Programming Languages, Cryptography and Security, Distributed, Parallel, and Cluster Computing, Logic in Computer Science, Multiagent Systems",
        "date": "2025-10-17",
        "category": "cs.MA",
        "crawl_time": "2025-10-20T11:00:04.141189"
    },
    {
        "index": "#2",
        "title": "AURA: An Agent Autonomy Risk Assessment Framework",
        "link": "/arxiv/2510.15739",
        "arxiv_id": "2510.15739",
        "authors": "Lorenzo Satta Chiris, Ayush Mishra",
        "summary": "As autonomous agentic AI systems see increasing adoption across organisations, persistent challenges in alignment, governance, and risk management threaten to impede deployment at scale. We present AURA (Agent aUtonomy Risk Assessment), a unified framework designed to detect, quantify, and mitigate risks arising from agentic AI. Building on recent research and practical deployments, AURA introduces a gamma-based risk scoring methodology that balances risk assessment accuracy with computational efficiency and practical considerations. AURA provides an interactive process to score, evaluate and mitigate the risks of running one or multiple AI Agents, synchronously or asynchronously (autonomously). The framework is engineered for Human-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H) communication mechanisms, allowing for seamless integration with agentic systems for autonomous self-assessment, rendering it interoperable with established protocols (MCP and A2A) and tools. AURA supports a responsible and transparent adoption of agentic AI and provides robust risk detection and mitigation while balancing computational resources, positioning it as a critical enabler for large-scale, governable agentic AI in enterprise environments.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-17",
        "category": "cs.MA",
        "crawl_time": "2025-10-20T11:00:04.141488"
    },
    {
        "index": "#3",
        "title": "Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation",
        "link": "/arxiv/2510.15624",
        "arxiv_id": "2510.15624",
        "authors": "Ed Li, Junyu Ren, Xintian Pan, Cat Yan, Chuanhao Li, Dirk Bergemann, Zhuoran Yang",
        "summary": "The automation of scientific discovery represents a critical milestone in Artificial Intelligence (AI) research. However, existing agentic systems for science suffer from two fundamental limitations: rigid, pre-programmed workflows that cannot adapt to intermediate findings, and inadequate context management that hinders long-horizon research. We present \\texttt{freephdlabor}, an open-source multiagent framework featuring \\textit{fully dynamic workflows} determined by real-time agent reasoning and a \\coloremph{\\textit{modular architecture}} enabling seamless customization -- users can modify, add, or remove agents to address domain-specific requirements. The framework provides comprehensive infrastructure including \\textit{automatic context compaction}, \\textit{workspace-based communication} to prevent information degradation, \\textit{memory persistence} across sessions, and \\textit{non-blocking human intervention} mechanisms. These features collectively transform automated research from isolated, single-run attempts into \\textit{continual research programs} that build systematically on prior explorations and incorporate human feedback. By providing both the architectural principles and practical implementation for building customizable co-scientist systems, this work aims to facilitate broader adoption of automated research across scientific domains, enabling practitioners to deploy interactive multiagent systems that autonomously conduct end-to-end research -- from ideation through experimentation to publication-ready manuscripts.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning, Multiagent Systems",
        "date": "2025-10-17",
        "category": "cs.MA",
        "crawl_time": "2025-10-20T11:00:04.141851"
    },
    {
        "index": "#4",
        "title": "Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic",
        "link": "/arxiv/2510.15573",
        "arxiv_id": "2510.15573",
        "authors": "Jianguo Chen, Zhengqin Liu, Jinlong Lei, Peng Yi, Yiguang Hong, Hong Chen",
        "summary": "With the practical implementation of connected and autonomous vehicles (CAVs), the traffic system is expected to remain a mix of CAVs and human-driven vehicles (HVs) for the foreseeable future. To enhance safety and traffic efficiency, the trajectory planning strategies of CAVs must account for the influence of HVs, necessitating accurate HV trajectory prediction. Current research often assumes that human drivers have perfect knowledge of all vehicles' objectives, an unrealistic premise. This paper bridges the gap by leveraging hypergame theory to account for cognitive and perception limitations in HVs. We model human bounded rationality without assuming them to be merely passive followers and propose a hierarchical cognition modeling framework that captures cognitive relationships among vehicles. We further analyze the cognitive stability of the system, proving that the strategy profile where all vehicles adopt cognitively equilibrium strategies constitutes a hyper Nash equilibrium when CAVs accurately learn HV parameters. To achieve this, we develop an inverse learning algorithm for distributed intention interpretation via vehicle-to-everything (V2X) communication, which extends the framework to both offline and online scenarios. Additionally, we introduce a distributed trajectory prediction and planning approach for CAVs, leveraging the learned parameters in real time. Simulations in highway lane-changing scenarios demonstrate the proposed method's accuracy in parameter learning, robustness to noisy trajectory observations, and safety in HV trajectory prediction. The results validate the effectiveness of our method in both offline and online implementations.",
        "subjects": "Systems and Control, Multiagent Systems",
        "date": "2025-10-17",
        "category": "cs.MA",
        "crawl_time": "2025-10-20T11:00:04.142136"
    },
    {
        "index": "#5",
        "title": "TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making",
        "link": "/arxiv/2510.15365",
        "arxiv_id": "2510.15365",
        "authors": "Maonan Wang, Yirong Chen, Yuxin Cai, Aoyu Pang, Yuejiao Xie, Zian Ma, Chengcheng Xu, Kemou Jiang, Ding Wang, Laurent Roullet, Chung Shue Chen, Zhiyong Cui, Yuheng Kan, Michael Lepech, Man-On Pun",
        "summary": "Air-ground collaborative intelligence is becoming a key approach for next-generation urban intelligent transportation management, where aerial and ground systems work together on perception, communication, and decision-making. However, the lack of a unified multi-modal simulation environment has limited progress in studying cross-domain perception, coordination under communication constraints, and joint decision optimization. To address this gap, we present TranSimHub, a unified simulation platform for air-ground collaborative intelligence. TranSimHub offers synchronized multi-view rendering across RGB, depth, and semantic segmentation modalities, ensuring consistent perception between aerial and ground viewpoints. It also supports information exchange between the two domains and includes a causal scene editor that enables controllable scenario creation and counterfactual analysis under diverse conditions such as different weather, emergency events, and dynamic obstacles. We release TranSimHub as an open-source platform that supports end-to-end research on perception, fusion, and control across realistic air and ground traffic scenes. Our code is available at https://github.com/Traffic-Alpha/TranSimHub.",
        "subjects": "Systems and Control, Machine Learning, Multiagent Systems",
        "date": "2025-10-17",
        "category": "cs.MA",
        "crawl_time": "2025-10-20T11:00:04.142496"
    },
    {
        "index": "#6",
        "title": "Decentralizing Multi-Agent Reinforcement Learning with Temporal Causal Information",
        "link": "/arxiv/2506.07829",
        "arxiv_id": "2506.07829",
        "authors": "Jan Corazza, Hadi Partovi Aria, Hyohun Kim, Daniel Neider, Zhe Xu",
        "summary": "Reinforcement learning (RL) algorithms can find an optimal policy for a single agent to accomplish a particular task. However, many real-world problems require multiple agents to collaborate in order to achieve a common goal. For example, a robot executing a task in a warehouse may require the assistance of a drone to retrieve items from high shelves. In Decentralized Multi-Agent RL (DMARL), agents learn independently and then combine their policies at execution time, but often must satisfy constraints on compatibility of local policies to ensure that they can achieve the global task when combined. In this paper, we study how providing high-level symbolic knowledge to agents can help address unique challenges of this setting, such as privacy constraints, communication limitations, and performance concerns. In particular, we extend the formal tools used to check the compatibility of local policies with the team task, making decentralized training with theoretical guarantees usable in more scenarios. Furthermore, we empirically demonstrate that symbolic knowledge about the temporal evolution of events in the environment can significantly expedite the learning process in DMARL.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-06-09",
        "category": "cs.MA",
        "crawl_time": "2025-10-20T11:00:04.142808"
    },
    {
        "index": "#1",
        "title": "PolySkill: Learning Generalizable Skills Through Polymorphic Abstraction",
        "link": "/arxiv/2510.15863",
        "arxiv_id": "2510.15863",
        "authors": "Simon Yu, Gang Li, Weiyan Shi, Peng Qi",
        "summary": "Large language models (LLMs) are moving beyond static uses and are now powering agents that learn continually during their interaction with external environments. For example, agents can learn reusable skills while navigating web pages or toggling new tools. However, existing methods for skill learning often create skills that are over-specialized to a single website and fail to generalize. We introduce PolySkill, a new framework that enables agents to learn generalizable and compositional skills. The core idea, inspired by polymorphism in software engineering, is to decouple a skill's abstract goal (what it accomplishes) and its concrete implementation (how it is executed). Experiments show that our method (1) improves skill reuse by 1.7x on seen websites and (2) boosts success rates by up to 9.4% on Mind2Web and 13.9% on unseen websites, while reducing steps by over 20%. (3) In self-exploration settings without specified tasks, our framework improves the quality of proposed tasks and enables agents to learn generalizable skills that work across different sites. By enabling the agent to identify and refine its own goals, the PolySkill enhances the agent's ability to learn a better curriculum, leading to the acquisition of more generalizable skills compared to baseline methods. This work provides a practical path toward building agents capable of continual learning in adaptive environments. Our findings show that separating a skill's goal from its execution is a crucial step toward developing autonomous agents that can learn and generalize across the open web continuously.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.930152"
    },
    {
        "index": "#2",
        "title": "InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training",
        "link": "/arxiv/2510.15859",
        "arxiv_id": "2510.15859",
        "authors": "Pengkai Wang, Qi Zuo, Pengwei Liu, Zhijie Sang, Congkai Xie, Hongxia Yang",
        "summary": "Large Language Models (LLMs) have shown substantial advances through reinforcement learning (RL), particularly in domains where rewards can be programmatically verified, such as mathematics and code. In these areas, models benefit from a well-defined operational base guided by explicit rule-based objectives. However, this progress reveals a significant limitation: in open-ended domains where rewards are ambiguous, subjective, or context-dependent, such as creative writing, scientific reasoning, and notably medical consultation, robust reward functions are lacking, making these areas challenging for current RL strategies. To bridge this gap, we introduce ORBIT, an open-ended rubric-based incremental training framework specifically designed for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue generation with the dynamic creation of rubrics, employing these rubrics to direct an incremental RL process. In particular, this approach does not depend on external medical knowledge or manual rules, instead utilizing rubric-guided feedback to shape learning. When implemented on the Qwen3-4B-Instruct model, our method can greatly enhance its performance on the HealthBench-Hard benchmark from 7.0 to 27.2 using only 2k samples, thus achieving state-of-the-art results for models of this scale. Our analysis confirms that rubric-driven RL fos-ters consistent performance gains across diverse consultation scenarios, going beyond simple numerical improvements. These findings underscore rubric-based feedback as a scalable strategy for advancing LLMs in intricate, open-ended tasks.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.930702"
    },
    {
        "index": "#3",
        "title": "SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling",
        "link": "/arxiv/2510.15851",
        "arxiv_id": "2510.15851",
        "authors": "Kadri Hacioglu, Manjunath K E, Andreas Stolcke",
        "summary": "Slot filling is a crucial subtask in spoken language understanding (SLU), traditionally implemented as a cascade of speech recognition followed by one or more natural language understanding (NLU) components. The recent advent of speech-based large language models (speechLLMs), which integrate speech and textual foundation models, has opened new avenues for achieving speech understanding tasks in a more unified, generative, and instruction-following manner while promising data and compute efficiency with zero-shot abilities, generalizing to unseen slot labels. We address the slot-filling task by creating an empirical upper bound for the task, identifying performance, robustness, and generalization gaps, and proposing improvements to the training data, architecture, and training strategies to narrow the gap with the upper bound result. We show that each of these measures improve performance substantially, while highlighting practical challenges and providing empirical guidance and insights for harnessing these emerging models.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.931299"
    },
    {
        "index": "#4",
        "title": "Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer Framework",
        "link": "/arxiv/2510.15843",
        "arxiv_id": "2510.15843",
        "authors": "Shayan Rokhva, Mousa Alizadeh, Maryam Abdollahi Shamami",
        "summary": "Accurately detecting sentiment polarity and intensity in product reviews and social media posts remains challenging due to informal and domain-specific language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer framework that combines rule-based heuristics, contextual deep learning, and fuzzy logic to generate continuous sentiment scores reflecting both polarity and strength. The pipeline begins with VADER-based initial sentiment estimations, which are refined through a two-stage adjustment process. This involves leveraging confidence scores from DistilBERT, a lightweight transformer and applying fuzzy logic principles to mitigate excessive neutrality bias and enhance granularity. A custom fuzzy inference system then maps the refined scores onto a 0 to 1 continuum, producing expert)like judgments. The framework is rigorously evaluated on four domain-specific datasets. food delivery, e-commerce, tourism, and fashion. Results show improved alignment with user ratings, better identification of sentiment extremes, and reduced misclassifications. Both quantitative metrics (distributional alignment, confusion matrices) and qualitative insights (case studies, runtime analysis) affirm the models robustness and efficiency. This work demonstrates the value of integrating symbolic reasoning with neural models for interpretable, finegrained sentiment analysis in linguistically dynamic domains.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.931915"
    },
    {
        "index": "#5",
        "title": "Paper2Web: Let's Make Your Paper Alive!",
        "link": "/arxiv/2510.15842",
        "arxiv_id": "2510.15842",
        "authors": "Yuhang Chen, Tianpeng Lv, Siyi Zhang, Yixiang Yin, Yao Wan, Philip S. Yu, Dongping Chen",
        "summary": "Academic project websites can more effectively disseminate research when they clearly present core content and enable intuitive navigation and interaction. However, current approaches such as direct Large Language Model (LLM) generation, templates, or direct HTML conversion struggle to produce layout-aware, interactive sites, and a comprehensive evaluation suite for this task has been lacking. In this paper, we introduce Paper2Web, a benchmark dataset and multi-dimensional evaluation framework for assessing academic webpage generation. It incorporates rule-based metrics like Connectivity, Completeness and human-verified LLM-as-a-Judge (covering interactivity, aesthetics, and informativeness), and PaperQuiz, which measures paper-level knowledge retention. We further present PWAgent, an autonomous pipeline that converts scientific papers into interactive and multimedia-rich academic homepages. The agent iteratively refines both content and layout through MCP tools that enhance emphasis, balance, and presentation quality. Our experiments show that PWAgent consistently outperforms end-to-end baselines like template-based webpages and arXiv/alphaXiv versions by a large margin while maintaining low cost, achieving the Pareto-front in academic webpage generation.",
        "subjects": "Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.932591"
    },
    {
        "index": "#6",
        "title": "Emergence of Linear Truth Encodings in Language Models",
        "link": "/arxiv/2510.15804",
        "arxiv_id": "2510.15804",
        "authors": "Shauli Ravfogel, Gilad Yehudai, Tal Linzen, Joan Bruna, Alberto Bietti",
        "summary": "Recent probing studies reveal that large language models exhibit linear subspaces that separate true from false statements, yet the mechanism behind their emergence is unclear. We introduce a transparent, one-layer transformer toy model that reproduces such truth subspaces end-to-end and exposes one concrete route by which they can arise. We study one simple setting in which truth encoding can emerge: a data distribution where factual statements co-occur with other factual statements (and vice-versa), encouraging the model to learn this distinction in order to lower the LM loss on future tokens. We corroborate this pattern with experiments in pretrained language models. Finally, in the toy setting we observe a two-phase learning dynamic: networks first memorize individual factual associations in a few steps, then -- over a longer horizon -- learn to linearly separate true from false, which in turn lowers language-modeling loss. Together, these results provide both a mechanistic demonstration and an empirical motivation for how and why linear truth representations can emerge in language models.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.933212"
    },
    {
        "index": "#7",
        "title": "On Non-interactive Evaluation of Animal Communication Translators",
        "link": "/arxiv/2510.15768",
        "arxiv_id": "2510.15768",
        "authors": "Orr Paradise, David F. Gruber, Adam Tauman Kalai",
        "summary": "If you had an AI Whale-to-English translator, how could you validate whether or not it is working? Does one need to interact with the animals or rely on grounded observations such as temperature? We provide theoretical and proof-of-concept experimental evidence suggesting that interaction and even observations may not be necessary for sufficiently complex languages. One may be able to evaluate translators solely by their English outputs, offering potential advantages in terms of safety, ethics, and cost. This is an instance of machine translation quality evaluation (MTQE) without any reference translations available. A key challenge is identifying ``hallucinations,'' false translations which may appear fluent and plausible. We propose using segment-by-segment translation together with the classic NLP shuffle test to evaluate translators. The idea is to translate animal communication, turn by turn, and evaluate how often the resulting translations make more sense in order than permuted. Proof-of-concept experiments on data-scarce human languages and constructed languages demonstrate the potential utility of this evaluation methodology. These human-language experiments serve solely to validate our reference-free metric under data scarcity. It is found to correlate highly with a standard evaluation based on reference translations, which are available in our experiments. We also perform a theoretical analysis suggesting that interaction may not be necessary nor efficient in the early stages of learning to translate.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.933797"
    },
    {
        "index": "#8",
        "title": "LLMs Judge Themselves: A Game-Theoretic Framework for Human-Aligned Evaluation",
        "link": "/arxiv/2510.15746",
        "arxiv_id": "2510.15746",
        "authors": "Gao Yang, Yuhang Liu, Siyu Miao, Xinyue Liang, Zhengyang Liu, Heyan Huang",
        "summary": "Ideal or real - that is the question.In this work, we explore whether principles from game theory can be effectively applied to the evaluation of large language models (LLMs). This inquiry is motivated by the growing inadequacy of conventional evaluation practices, which often rely on fixed-format tasks with reference answers and struggle to capture the nuanced, subjective, and open-ended nature of modern LLM behavior. To address these challenges, we propose a novel alternative: automatic mutual evaluation, where LLMs assess each other's output through self-play and peer review. These peer assessments are then systematically compared with human voting behavior to evaluate their alignment with human judgment. Our framework incorporates game-theoretic voting algorithms to aggregate peer reviews, enabling a principled investigation into whether model-generated rankings reflect human preferences. Empirical results reveal both convergences and divergences between theoretical predictions and human evaluations, offering valuable insights into the promises and limitations of mutual evaluation. To the best of our knowledge, this is the first work to jointly integrate mutual evaluation, game-theoretic aggregation, and human-grounded validation for evaluating the capabilities of LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.934585"
    },
    {
        "index": "#9",
        "title": "Attention Sinks in Diffusion Language Models",
        "link": "/arxiv/2510.15731",
        "arxiv_id": "2510.15731",
        "authors": "Maximo Eduardo Rulli, Simone Petruzzi, Edoardo Michielon, Fabrizio Silvestri, Simone Scardapane, Alessio Devoto",
        "summary": "Masked Diffusion Language Models (DLMs) have recently emerged as a promising alternative to traditional Autoregressive Models (ARMs). DLMs employ transformer encoders with bidirectional attention, enabling parallel token generation while maintaining competitive performance. Although their efficiency and effectiveness have been extensively studied, the internal mechanisms that govern DLMs remain largely unexplored. In this work, we conduct an empirical analysis of DLM attention patterns, focusing on the attention sinking phenomenon, an effect previously observed in various transformer-based architectures. Our findings reveal that DLMs also exhibit attention sinks, but with distinct characteristics. First, unlike in ARMs, the sink positions in DLMs tend to shift throughout the generation process, displaying a dynamic behaviour. Second, while ARMs are highly sensitive to the removal of attention sinks, DLMs remain robust: masking sinks leads to only a minor degradation in performance. These results provide new insights into the inner workings of diffusion-based language models and highlight fundamental differences in how they allocate and utilize attention compared to autoregressive models.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.940449"
    },
    {
        "index": "#10",
        "title": "Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth",
        "link": "/arxiv/2510.15719",
        "arxiv_id": "2510.15719",
        "authors": "Helia Hashemi, Victor Rühle, Saravan Rajmohan",
        "summary": "Reasoning models have gained significant attention due to their strong performance, particularly when enhanced with retrieval augmentation. However, these models often incur high computational costs, as both retrieval and reasoning tokens contribute substantially to the overall resource usage. In this work, we make the following contributions: (1) we propose a retrieval-augmented reasoning model that dynamically adjusts the length of the retrieved document list based on the query and retrieval results; (2) we develop a cost-aware advantage function for training of efficient retrieval-augmented reasoning models through reinforcement learning; and (3) we explore both memory- and latency-bound implementations of the proposed cost-aware framework for both proximal and group relative policy optimization algorithms. We evaluate our approach on seven public question answering datasets and demonstrate significant efficiency gains, without compromising effectiveness. In fact, we observed that the model latency decreases by ~16-20% across datasets, while its effectiveness increases by ~5% on average, in terms of exact match.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.940967"
    },
    {
        "index": "#11",
        "title": "Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection",
        "link": "/arxiv/2510.15685",
        "arxiv_id": "2510.15685",
        "authors": "Joshua Wolfe Brook, Ilia Markov",
        "summary": "This research introduces a novel approach to textual and multimodal Hate Speech Detection (HSD), using Large Language Models (LLMs) as dynamic knowledge bases to generate background context and incorporate it into the input of HSD classifiers. Two context generation strategies are examined: one focused on named entities and the other on full-text prompting. Four methods of incorporating context into the classifier input are compared: text concatenation, embedding concatenation, a hierarchical transformer-based fusion, and LLM-driven text enhancement. Experiments are conducted on the textual Latent Hatred dataset of implicit hate speech and applied in a multimodal setting on the MAMI dataset of misogynous memes. Results suggest that both the contextual information and the method by which it is incorporated are key, with gains of up to 3 and 6 F1 points on textual and multimodal setups respectively, from a zero-context baseline to the highest-performing system, based on embedding concatenation.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.941398"
    },
    {
        "index": "#12",
        "title": "HypoSpace: Evaluating LLM Creativity as Set-Valued Hypothesis Generators under Underdetermination",
        "link": "/arxiv/2510.15614",
        "arxiv_id": "2510.15614",
        "authors": "Tingting Chen, Beibei Lin, Zifeng Yuan, Qiran Zou, Hongyu He, Yew-Soon Ong, Anirudh Goyal, Dianbo Liu",
        "summary": "As language models are increasingly used in scientific workflows, evaluating their ability to propose sets of explanations-not just a single correct answer-becomes critical. Many scientific problems are underdetermined: multiple, mechanistically distinct hypotheses are consistent with the same observations. We introduce HypoSpace, a diagnostic suite that treats LLMs as samplers of finite hypothesis sets and measures three complementary indicators: Validity (precision of proposals consistent with observations), Uniqueness (non-redundancy among proposals), and Recovery (coverage of the enumerated admissible set). We instantiate HypoSpace in three structured domains with deterministic validators and exactly enumerated hypothesis spaces: (i) causal graphs from perturbations, (ii) gravity-constrained 3D voxel reconstruction from top-down projections, and (iii) Boolean genetic interactions. Across instruction-tuned and reasoning-focused models, Validity often remains high while Uniqueness and Recovery degrade as the admissible space grows, revealing mode collapse that is invisible to correctness-only metrics. HypoSpace offers a controlled probe-rather than a leaderboard-for methods that explicitly explore and cover admissible explanation spaces. Code is available at: https://github.com/CTT-Pavilion/_HypoSpace.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.941907"
    },
    {
        "index": "#13",
        "title": "The Elephant in the Coreference Room: Resolving Coreference in Full-Length French Fiction Works",
        "link": "/arxiv/2510.15594",
        "arxiv_id": "2510.15594",
        "authors": "Antoine Bourgois, Thierry Poibeau",
        "summary": "While coreference resolution is attracting more interest than ever from computational literature researchers, representative datasets of fully annotated long documents remain surprisingly scarce. In this paper, we introduce a new annotated corpus of three full-length French novels, totaling over 285,000 tokens. Unlike previous datasets focused on shorter texts, our corpus addresses the challenges posed by long, complex literary works, enabling evaluation of coreference models in the context of long reference chains. We present a modular coreference resolution pipeline that allows for fine-grained error analysis. We show that our approach is competitive and scales effectively to long documents. Finally, we demonstrate its usefulness to infer the gender of fictional characters, showcasing its relevance for both literary analysis and downstream NLP tasks.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.942327"
    },
    {
        "index": "#14",
        "title": "BiMax: Bidirectional MaxSim Score for Document-Level Alignment",
        "link": "/arxiv/2510.15577",
        "arxiv_id": "2510.15577",
        "authors": "Xiaotian Wang, Takehito Utsuro, Masaaki Nagata",
        "summary": "Document alignment is necessary for the hierarchical mining (Bañón et al., 2020; Morishita et al., 2022), which aligns documents across source and target languages within the same web domain. Several high precision sentence embedding-based methods have been developed, such as TK-PERT (Thompson and Koehn, 2020) and Optimal Transport (OT) (Clark et al., 2019; El-Kishky and Guzmán, 2020). However, given the massive scale of web mining data, both accuracy and speed must be considered. In this paper, we propose a cross-lingual Bidirectional Maxsim score (BiMax) for computing doc-to-doc similarity, to improve efficiency compared to the OT method. Consequently, on the WMT16 bilingual document alignment task, BiMax attains accuracy comparable to OT with an approximate 100-fold speed increase. Meanwhile, we also conduct a comprehensive analysis to investigate the performance of current state-of-the-art multilingual sentence embedding models. All the alignment methods in this paper are publicly available as a tool called EmbDA (https://github.com/EternalEdenn/EmbDA).",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.942763"
    },
    {
        "index": "#15",
        "title": "From Ghazals to Sonnets: Decoding the Polysemous Expressions of Love Across Languages",
        "link": "/arxiv/2510.15569",
        "arxiv_id": "2510.15569",
        "authors": "Syed Mohammad Sualeh Ali",
        "summary": "This paper delves into the intricate world of Urdu poetry, exploring its thematic depths through a lens of polysemy. By focusing on the nuanced differences between three seemingly synonymous words (pyaar, muhabbat, and ishq) we expose a spectrum of emotions and experiences unique to the Urdu language. This study employs a polysemic case study approach, meticulously examining how these words are interwoven within the rich tapestry of Urdu poetry. By analyzing their usage and context, we uncover a hidden layer of meaning, revealing subtle distinctions which lack direct equivalents in English literature. Furthermore, we embark on a comparative analysis, generating word embeddings for both Urdu and English terms related to love. This enables us to quantify and visualize the semantic space occupied by these words, providing valuable insights into the cultural and linguistic nuances of expressing love. Through this multifaceted approach, our study sheds light on the captivating complexities of Urdu poetry, offering a deeper understanding and appreciation for its unique portrayal of love and its myriad expressions",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.943169"
    },
    {
        "index": "#16",
        "title": "Finetuning LLMs for EvaCun 2025 token prediction shared task",
        "link": "/arxiv/2510.15561",
        "arxiv_id": "2510.15561",
        "authors": "Josef Jon, Ondřej Bojar",
        "summary": "In this paper, we present our submission for the token prediction task of EvaCun 2025. Our sys-tems are based on LLMs (Command-R, Mistral, and Aya Expanse) fine-tuned on the task data provided by the organizers. As we only pos-sess a very superficial knowledge of the subject field and the languages of the task, we simply used the training data without any task-specific adjustments, preprocessing, or filtering. We compare 3 different approaches (based on 3 different prompts) of obtaining the predictions, and we evaluate them on a held-out part of the data.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.943591"
    },
    {
        "index": "#17",
        "title": "KITE: A Benchmark for Evaluating Korean Instruction-Following Abilities in Large Language Models",
        "link": "/arxiv/2510.15558",
        "arxiv_id": "2510.15558",
        "authors": "Dongjun Kim, Chanhee Park, Chanjun Park, Heuiseok Lim",
        "summary": "The instruction-following capabilities of large language models (LLMs) are pivotal for numerous applications, from conversational agents to complex reasoning systems. However, current evaluations predominantly focus on English models, neglecting the linguistic and cultural nuances of other languages. Specifically, Korean, with its distinct syntax, rich morphological features, honorific system, and dual numbering systems, lacks a dedicated benchmark for assessing open-ended instruction-following capabilities. To address this gap, we introduce the Korean Instruction-following Task Evaluation (KITE), a comprehensive benchmark designed to evaluate both general and Korean-specific instructions. Unlike existing Korean benchmarks that focus mainly on factual knowledge or multiple-choice testing, KITE directly targets diverse, open-ended instruction-following tasks. Our evaluation pipeline combines automated metrics with human assessments, revealing performance disparities across models and providing deeper insights into their strengths and weaknesses. By publicly releasing the KITE dataset and code, we aim to foster further research on culturally and linguistically inclusive LLM development and inspire similar endeavors for other underrepresented languages.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.944101"
    },
    {
        "index": "#18",
        "title": "Think Parallax: Solving Multi-Hop Problems via Multi-View Knowledge-Graph-Based Retrieval-Augmented Generation",
        "link": "/arxiv/2510.15552",
        "arxiv_id": "2510.15552",
        "authors": "Jinliang Liu",
        "summary": "Large language models (LLMs) excel at language understanding but often hallucinate and struggle with multi-hop reasoning. Knowledge-graph-based retrieval-augmented generation (KG-RAG) offers grounding, yet most methods rely on flat embeddings and noisy path exploration. We propose ParallaxRAG, a framework that symmetrically decouples queries and graph triples into multi-view spaces, enabling a robust retrieval architecture that explicitly enforces head diversity while constraining weakly related paths. Central to our approach is the observation that different attention heads specialize in semantic relations at distinct reasoning stages, contributing to different hops of the reasoning chain. This specialization allows ParallaxRAG to construct cleaner subgraphs and guide LLMs through grounded, step-wise reasoning. Experiments on WebQSP and CWQ, under our unified, reproducible setup (BGE-M3 + Llama3.1-8B), demonstrate competitive retrieval and QA performance, alongside reduced hallucination and good generalization. Our results highlight multi-view head specialization as a principled direction for knowledge-grounded multi-hop reasoning. Our implementation will be released as soon as the paper is accepted.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.944529"
    },
    {
        "index": "#19",
        "title": "Rethinking Cross-lingual Gaps from a Statistical Viewpoint",
        "link": "/arxiv/2510.15551",
        "arxiv_id": "2510.15551",
        "authors": "Vihari Piratla, Purvam Jain, Darshan Singh, Partha Talukdar, Trevor Cohn",
        "summary": "Any piece of knowledge is usually expressed in one or a handful of natural languages on the web or in any large corpus. Large Language Models (LLMs) act as a bridge by acquiring knowledge from a source language and making it accessible when queried from target languages. Prior research has pointed to a cross-lingual gap, viz., a drop in accuracy when the knowledge is queried in a target language compared to when the query is in the source language. Existing research has rationalized divergence in latent representations in source and target languages as the source of cross-lingual gap. In this work, we take an alternative view and hypothesize that the variance of responses in the target language is the main cause of this gap. For the first time, we formalize the cross-lingual gap in terms of bias-variance decomposition. We present extensive experimental evidence which support proposed formulation and hypothesis. We then reinforce our hypothesis through multiple inference-time interventions that control the variance and reduce the cross-lingual gap. We demonstrate a simple prompt instruction to reduce the response variance, which improved target accuracy by 20-25% across different models.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.960579"
    },
    {
        "index": "#20",
        "title": "TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs",
        "link": "/arxiv/2510.15545",
        "arxiv_id": "2510.15545",
        "authors": "Sibo Xiao, Jinyuan Fu, Zhongle Xie, Lidan Shou",
        "summary": "Accelerating the inference of large language models (LLMs) has been a critical challenge in generative AI. Speculative decoding (SD) substantially improves LLM inference efficiency. However, its utility is limited by a fundamental constraint: the draft and target models must share the same vocabulary, thus limiting the herd of available draft models and often necessitating the training of a new model from scratch. Inspired by Dynamic Time Warping (DTW), a classic algorithm for aligning time series, we propose the algorithm TokenTiming for universal speculative decoding. It operates by re-encoding the draft token sequence to get a new target token sequence, and then uses DTW to build a mapping to transfer the probability distributions for speculative sampling. Benefiting from this, our method accommodates mismatched vocabularies and works with any off-the-shelf models without retraining and modification. We conduct comprehensive experiments on various tasks, demonstrating 1.57x speedup. This work enables a universal approach for draft model selection, making SD a more versatile and practical tool for LLM acceleration.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.961152"
    },
    {
        "index": "#21",
        "title": "MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval",
        "link": "/arxiv/2510.15543",
        "arxiv_id": "2510.15543",
        "authors": "Qiyu Wu, Shuyang Cui, Satoshi Hayakawa, Wei-Yao Wang, Hiromi Wakaki, Yuki Mitsufuji",
        "summary": "Multimodal retrieval, which seeks to retrieve relevant content across modalities such as text or image, supports applications from AI search to contents production. Despite the success of separate-encoder approaches like CLIP align modality-specific embeddings with contrastive learning, recent multimodal large language models (MLLMs) enable a unified encoder that directly processes composed inputs. While flexible and advanced, we identify that unified encoders trained with conventional contrastive learning are prone to learn modality shortcut, leading to poor robustness under distribution shifts. We propose a modality composition awareness framework to mitigate this issue. Concretely, a preference loss enforces multimodal embeddings to outperform their unimodal counterparts, while a composition regularization objective aligns multimodal embeddings with prototypes composed from its unimodal parts. These objectives explicitly model structural relationships between the composed representation and its unimodal counterparts. Experiments on various benchmarks show gains in out-of-distribution retrieval, highlighting modality composition awareness as a effective principle for robust composed multimodal retrieval when utilizing MLLMs as the unified encoder.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval, Multimedia",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.961834"
    },
    {
        "index": "#22",
        "title": "Latent Reasoning in LLMs as a Vocabulary-Space Superposition",
        "link": "/arxiv/2510.15522",
        "arxiv_id": "2510.15522",
        "authors": "Jingcheng Deng, Liang Pang, Zihao Wei, Shichen Xu, Zenghao Duan, Kun Xu, Yang Song, Huawei Shen, Xueqi Cheng",
        "summary": "Large language models (LLMs) demonstrate strong reasoning abilities with chain-of-thought prompting, but explicit reasoning introduces substantial computational overhead. Recent work on latent reasoning reduces this cost by reasoning in latent space without explicit supervision, but performance drops significantly. Our preliminary experiments suggest that this degradation stems from the unstructured latent space, which makes fitting latent tokens difficult. To address this, we restrict the latent space to the column space of the LLM vocabulary, treating latent reasoning as a superposition over vocabulary probabilities. Once latent reasoning concludes, it collapses into an eigenstate of explicit reasoning to yield the final answer. Based on this idea, we propose Latent-SFT, a two-stage learning framework. In the first stage, we design two specialized attention masks to guide the Latent Token Encoder in generating latent tokens, allowing the LLM to produce the correct answer conditioned on them. In the second stage, the Latent Token Encoder is discarded, and the LLM is directly trained to generate these latent tokens autonomously for latent reasoning, optimized with KL and CE losses. Latent-SFT sets a new state of the art on GSM8k, matching explicit SFT performance while cutting reasoning chains by up to 4 times and outperforming prior latent methods. On Math500 and AIME24, lexical probability-based latent reasoning also clearly surpasses hidden-state-based approaches. Our metrics of effective compression rate and effective global parallelism further show that latent reasoning is both the compression of a single path and the superposition of multiple paths.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.962526"
    },
    {
        "index": "#23",
        "title": "From Characters to Tokens: Dynamic Grouping with Hierarchical BPE",
        "link": "/arxiv/2510.15517",
        "arxiv_id": "2510.15517",
        "authors": "Rares Dolga, Lucas Maystre, Tudor Berariu, David Barber",
        "summary": "Subword tokenization methods like Byte Pair Encoding (BPE) are widely used in large language models due to their balance of vocabulary compactness and representational power. However, they suffer from inefficiencies in representing rare words and require large embedding matrices. Character-level models address these issues but introduce performance bottlenecks, particularly in Transformer-based architectures. Recent hierarchical models attempt to merge the benefits of both paradigms by grouping characters into patches, but existing patching strategies either rely on whitespace-limiting applicability to certain languages, or require auxiliary models that introduce new dependencies. In this paper, we propose a dynamic character grouping method that leverages the structure of existing BPE tokenization without requiring additional models. By appending explicit end-of-patch markers to BPE tokens and introducing a second-level BPE compression stage to control patch granularity, our method offers efficient, flexible, and language-agnostic representations. Empirical results demonstrate that our approach matches or exceeds the performance of dynamic entropy- and whitespace-based patching strategies, while maintaining a compact vocabulary.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.963107"
    },
    {
        "index": "#24",
        "title": "Temporal Referential Consistency: Do LLMs Favor Sequences Over Absolute Time References?",
        "link": "/arxiv/2510.15513",
        "arxiv_id": "2510.15513",
        "authors": "Ashutosh Bajpai, Tanmoy Chakraborty",
        "summary": "The increasing acceptance of large language models (LLMs) as an alternative to knowledge sources marks a significant paradigm shift across various domains, including time-sensitive fields such as law, healthcare, and finance. To fulfill this expanded role, LLMs must not only be factually accurate but also demonstrate consistency across temporal dimensions, necessitating robust temporal reasoning capabilities. Despite this critical requirement, efforts to ensure temporal consistency in LLMs remain scarce including noticeable absence of endeavors aimed at evaluating or augmenting LLMs across temporal references in time-sensitive inquiries. In this paper, we seek to address this gap by introducing a novel benchmark entitled temporal referential consistency, accompanied by a resource TEMP-ReCon designed to benchmark a wide range of both open-source and closed-source LLMs with various linguistic contexts characterized by differing resource richness (including English, French, and Romanian). The findings emphasis that LLMs do exhibit insufficient temporal referent consistency. To address this, we propose \\newmodel, a reasoning path alignment-based model that aims to enhance the temporal referential consistency of LLMs. Our empirical experiments substantiate the efficacy of UnTRaP compared to several baseline models.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.963655"
    },
    {
        "index": "#25",
        "title": "DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios",
        "link": "/arxiv/2510.15501",
        "arxiv_id": "2510.15501",
        "authors": "Yao Huang, Yitong Sun, Yichi Zhang, Ruochen Zhang, Yinpeng Dong, Xingxing Wei",
        "summary": "Despite the remarkable advances of Large Language Models (LLMs) across diverse cognitive tasks, the rapid enhancement of these capabilities also introduces emergent deceptive behaviors that may induce severe risks in high-stakes deployments. More critically, the characterization of deception across realistic real-world scenarios remains underexplored. To bridge this gap, we establish DeceptionBench, the first benchmark that systematically evaluates how deceptive tendencies manifest across different societal domains, what their intrinsic behavioral patterns are, and how extrinsic factors affect them. Specifically, on the static count, the benchmark encompasses 150 meticulously designed scenarios in five domains, i.e., Economy, Healthcare, Education, Social Interaction, and Entertainment, with over 1,000 samples, providing sufficient empirical foundations for deception analysis. On the intrinsic dimension, we explore whether models exhibit self-interested egoistic tendencies or sycophantic behaviors that prioritize user appeasement. On the extrinsic dimension, we investigate how contextual factors modulate deceptive outputs under neutral conditions, reward-based incentivization, and coercive pressures. Moreover, we incorporate sustained multi-turn interaction loops to construct a more realistic simulation of real-world feedback dynamics. Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal critical vulnerabilities, particularly amplified deception under reinforcement dynamics, demonstrating that current models lack robust resistance to manipulative contextual cues and the urgent need for advanced safeguards against various deception behaviors. Code and resources are publicly available at https://github.com/Aries-iai/DeceptionBench.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.964351"
    },
    {
        "index": "#26",
        "title": "CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs",
        "link": "/arxiv/2510.15455",
        "arxiv_id": "2510.15455",
        "authors": "Gucongcong Fan, Chaoyue Niu, Chengfei Lyu, Fan Wu, Guihai Chen",
        "summary": "Mobile agents rely on Large Language Models (LLMs) to plan and execute tasks on smartphone user interfaces (UIs). While cloud-based LLMs achieve high task accuracy, they require uploading the full UI state at every step, exposing unnecessary and often irrelevant information. In contrast, local LLMs avoid UI uploads but suffer from limited capacity, resulting in lower task success rates. We propose $\\textbf{CORE}$, a $\\textbf{CO}$llaborative framework that combines the strengths of cloud and local LLMs to $\\textbf{R}$educe UI $\\textbf{E}$xposure, while maintaining task accuracy for mobile agents. CORE comprises three key components: (1) $\\textbf{Layout-aware block partitioning}$, which groups semantically related UI elements based on the XML screen hierarchy; (2) $\\textbf{Co-planning}$, where local and cloud LLMs collaboratively identify the current sub-task; and (3) $\\textbf{Co-decision-making}$, where the local LLM ranks relevant UI blocks, and the cloud LLM selects specific UI elements within the top-ranked block. CORE further introduces a multi-round accumulation mechanism to mitigate local misjudgment or limited context. Experiments across diverse mobile apps and tasks show that CORE reduces UI exposure by up to 55.6% while maintaining task success rates slightly below cloud-only agents, effectively mitigating unnecessary privacy exposure to the cloud. The code is available at https://github.com/Entropy-Fighter/CORE.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.964953"
    },
    {
        "index": "#27",
        "title": "Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering",
        "link": "/arxiv/2510.15436",
        "arxiv_id": "2510.15436",
        "authors": "Xiangchen Song, Yuchen Liu, Yaxuan Luan, Jinxu Guo, Xiaofan Guo",
        "summary": "This study presents a controllable abstract summary generation method for large language models based on prompt engineering. To address the issues of summary quality and controllability in traditional methods, we design a multi-stage prompt generation framework. This framework generates summaries with varying levels of abstraction by performing semantic analysis, topic modeling, and noise control on the input text. The experiment uses the CNN/Daily Mail dataset and provides a detailed analysis of different prompt lengths, data noise, and text types. The experimental results show that prompt length has a significant impact on the quality of generated summaries. Both very short and very long prompt tokens result in a decrease in summary quality. Data noise also negatively affects the summary generation process. As noise levels increase, the ROUGE-L score gradually decreases. Furthermore, different text types have varying effects on the model's ability to generate summaries. The model performs best when handling news texts, while its performance is worse when processing academic articles. This research provides new insights into improving summary generation using large language models, particularly in how controlling prompt strategies and optimizing text preprocessing can enhance summary accuracy and controllability.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.975748"
    },
    {
        "index": "#28",
        "title": "When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs",
        "link": "/arxiv/2510.15421",
        "arxiv_id": "2510.15421",
        "authors": "Hongcheng Liu, Pingjie Wang, Yuhao Wang, Siqu Ou, Yanfeng Wang, Yu Wang",
        "summary": "Multimodal large language models (MLLMs) have shown strong capabilities across a broad range of benchmarks. However, most existing evaluations focus on passive inference, where models perform step-by-step reasoning under complete information. This setup is misaligned with real-world use, where seeing is not enough. This raises a fundamental question: Can MLLMs actively acquire missing evidence under incomplete information? To bridge this gap, we require the MLLMs to actively acquire missing evidence and iteratively refine decisions under incomplete information, by selecting a target image from a candidate pool without task-specific priors. To support systematic study, we propose GuessBench, a benchmark with both perception-oriented and knowledge-oriented images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs and find that performance on active reasoning lags far behind it on passive settings, indicating substantial room for improvement. Further analysis identifies fine-grained perception and timely decision-making as key challenges. Ablation studies show that perceptual enhancements benefit smaller models, whereas thinking-oriented methods provide consistent gains across model sizes. These results suggest promising directions for future research on multimodal active reasoning.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.976250"
    },
    {
        "index": "#29",
        "title": "Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs",
        "link": "/arxiv/2510.15418",
        "arxiv_id": "2510.15418",
        "authors": "Lee Qi Zun, Mohamad Zulhilmi Bin Abdul Halim, Goh Man Fye",
        "summary": "Retrieval-Augmented Generation systems are essential for providing fact-based guidance from Malaysian Clinical Practice Guidelines. However, their effectiveness with image-based queries is limited, as general Vision-Language Model captions often lack clinical specificity and factual grounding. This study proposes and validates a framework to specialize the MedGemma model for generating high-fidelity captions that serve as superior queries. To overcome data scarcity, we employ a knowledge distillation pipeline to create a synthetic dataset across dermatology, fundus, and chest radiography domains, and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance was rigorously assessed through a dual framework measuring both classification accuracy and, via a novel application of the RAGAS framework, caption faithfulness, relevancy, and correctness. The fine-tuned model demonstrated substantial improvements in classification performance, while RAGAS evaluation confirmed significant gains in caption faithfulness and correctness, validating the models ability to produce reliable, factually grounded descriptions. This work establishes a robust pipeline for specializing medical VLMs and validates the resulting model as a high-quality query generator, laying the groundwork for enhancing multimodal RAG systems in evidence-based clinical decision support.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.976721"
    },
    {
        "index": "#30",
        "title": "Large-scale User Game Lifecycle Representation Learning",
        "link": "/arxiv/2510.15412",
        "arxiv_id": "2510.15412",
        "authors": "Yanjie Gou, Jiangming Liu, Kouying Xue, Yi Hua",
        "summary": "The rapid expansion of video game production necessitates the development of effective advertising and recommendation systems for online game platforms. Recommending and advertising games to users hinges on capturing their interest in games. However, existing representation learning methods crafted for handling billions of items in recommendation systems are unsuitable for game advertising and recommendation. This is primarily due to game sparsity, where the mere hundreds of games fall short for large-scale user representation learning, and game imbalance, where user behaviors are overwhelmingly dominated by a handful of popular games. To address the sparsity issue, we introduce the User Game Lifecycle (UGL), designed to enrich user behaviors in games. Additionally, we propose two innovative strategies aimed at manipulating user behaviors to more effectively extract both short and long-term interests. To tackle the game imbalance challenge, we present an Inverse Probability Masking strategy for UGL representation learning. The offline and online experimental results demonstrate that the UGL representations significantly enhance model by achieving a 1.83% AUC offline increase on average and a 21.67% CVR online increase on average for game advertising and a 0.5% AUC offline increase and a 0.82% ARPU online increase for in-game item recommendation.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.977194"
    },
    {
        "index": "#31",
        "title": "VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency",
        "link": "/arxiv/2510.15406",
        "arxiv_id": "2510.15406",
        "authors": "Hongcheng Liu, Yixuan Hou, Heyang Liu, Yuhao Wang, Yanfeng Wang, Yu Wang",
        "summary": "While Speech Large Language Models (Speech-LLMs) show strong performance in many applications, their robustness is critically under-tested, especially to speech disfluency. Existing evaluations often rely on idealized inputs, overlooking common disfluencies, particularly those associated with conditions like Parkinson's disease. This work investigates whether current Speech-LLMs can maintain performance when interacting with users who have speech impairments. To facilitate this inquiry, we introduce VocalBench-DF, a framework for the systematic evaluation of disfluency across a multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals substantial performance degradation, indicating that their real-world readiness is limited. Further analysis identifies phoneme-level processing and long-context modeling as primary bottlenecks responsible for these failures. Strengthening recognition and reasoning capability from components and pipelines can substantially improve robustness. These findings highlight the urgent need for new methods to improve disfluency handling and build truly inclusive Speech-LLMs",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.977689"
    },
    {
        "index": "#32",
        "title": "Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing",
        "link": "/arxiv/2510.15349",
        "arxiv_id": "2510.15349",
        "authors": "Baode Wang, Biao Wu, Weizhen Li, Meng Fang, Zuming Huang, Jun Huang, Haozhe Wang, Yanjie Liang, Ling Chen, Wei Chu, Yuan Qi",
        "summary": "Document parsing from scanned images into structured formats remains a significant challenge due to its complexly intertwined elements such as text paragraphs, figures, formulas, and tables. Existing supervised fine-tuning methods often struggle to generalize across diverse document types, leading to poor performance, particularly on out-of-distribution data. This issue is further exacerbated by the limited availability of high-quality training data for layout-aware parsing tasks. To address these challenges, we introduce LayoutRL, a reinforcement learning framework that optimizes layout understanding through composite rewards integrating normalized edit distance, paragraph count accuracy, and reading order preservation. To support this training, we construct the Infinity-Doc-400K dataset, which we use to train Infinity-Parser, a vision-language model demonstrating robust generalization across various domains. Extensive evaluations on benchmarks including OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser consistently achieves state-of-the-art performance across a broad range of document types, languages, and structural complexities, substantially outperforming both specialized document parsing systems and general-purpose vision-language models. We will release our code, dataset, and model to facilitate reproducible research in document parsing.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.978289"
    },
    {
        "index": "#33",
        "title": "When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling",
        "link": "/arxiv/2510.15346",
        "arxiv_id": "2510.15346",
        "authors": "Heecheol Yun, Kwangmin Ki, Junghyun Lee, Eunho Yang",
        "summary": "Ensembling Large Language Models (LLMs) has gained attention as a promising approach to surpass the performance of individual models by leveraging their complementary strengths. In particular, aggregating models' next-token probability distributions to select the next token has been shown to be effective in various tasks. However, while successful for short-form answers, its application to long-form generation remains underexplored. In this paper, we show that using existing ensemble methods in long-form generation requires a careful choice of ensembling positions, since the standard practice of ensembling at every token often degrades performance. We identify two key factors for determining these positions: tokenization mismatch across models and consensus in their next-token probability distributions. Based on this, we propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively ensembles by jointly considering these factors. To further improve stability, we introduce a probability sharpening strategy that consolidates probabilities spread across multiple sub-word tokens representing the same word into a single representative token. Our experiments on diverse benchmarks, including MATH500 and BBH, demonstrate that SAFE outperforms existing methods in both accuracy and efficiency, with gains achieved even when ensembling fewer than 1% of tokens.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.978772"
    },
    {
        "index": "#34",
        "title": "Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics",
        "link": "/arxiv/2510.15345",
        "arxiv_id": "2510.15345",
        "authors": "Catarina G Belem, Parker Glenn, Alfy Samuel, Anoop Kumar, Daben Liu",
        "summary": "Automatic readability assessment plays a key role in ensuring effective and accessible written communication. Despite significant progress, the field is hindered by inconsistent definitions of readability and measurements that rely on surface-level text properties. In this work, we investigate the factors shaping human perceptions of readability through the analysis of 897 judgments, finding that, beyond surface-level cues, information content and topic strongly shape text comprehensibility. Furthermore, we evaluate 15 popular readability metrics across five English datasets, contrasting them with six more nuanced, model-based metrics. Our results show that four model-based metrics consistently place among the top four in rank correlations with human judgments, while the best performing traditional metric achieves an average rank of 8.6. These findings highlight a mismatch between current readability metrics and human perceptions, pointing to model-based approaches as a more promising direction.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.979277"
    },
    {
        "index": "#35",
        "title": "AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction",
        "link": "/arxiv/2510.15339",
        "arxiv_id": "2510.15339",
        "authors": "Hong Ting Tsang, Jiaxin Bai, Haoyu Huang, Qiao Xiao, Tianshi Zheng, Baixuan Xu, Shujie Liu, Yangqiu Song",
        "summary": "Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation (RAG) is pivotal for advancing question answering (QA) systems. However, its effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG) construction process is decoupled from its downstream application, yielding suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the first framework to directly optimize KG construction for task performance using Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing graph generation as a policy learning problem, where the reward is derived from the graph's functional utility in a RAG pipeline. We design two novel, task-aware reward functions, one for graphs as knowledge carriers and another as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently enables graph RAG methods to achieve significant performance gains over using task-agnostic baseline graphs. Our work shows it is possible to close the loop between construction and application, shifting the paradigm from building intrinsically ``good'' graphs to building demonstrably ``useful'' ones.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.979856"
    },
    {
        "index": "#36",
        "title": "Capabilities and Evaluation Biases of Large Language Models in Classical Chinese Poetry Generation: A Case Study on Tang Poetry",
        "link": "/arxiv/2510.15313",
        "arxiv_id": "2510.15313",
        "authors": "Bolei Ma, Yina Yao, Anna-Carolina Haensch",
        "summary": "Large Language Models (LLMs) are increasingly applied to creative domains, yet their performance in classical Chinese poetry generation and evaluation remains poorly understood. We propose a three-step evaluation framework that combines computational metrics, LLM-as-a-judge assessment, and human expert validation. Using this framework, we evaluate six state-of-the-art LLMs across multiple dimensions of poetic quality, including themes, emotions, imagery, form, and style. Our analysis reveals systematic generation and evaluation biases: LLMs exhibit \"echo chamber\" effects when assessing creative quality, often converging on flawed standards that diverge from human judgments. These findings highlight both the potential and limitations of current capabilities of LLMs as proxy for literacy generation and the limited evaluation practices, thereby demonstrating the continued need of hybrid validation from both humans and models in culturally and technically complex creative tasks.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.980321"
    },
    {
        "index": "#37",
        "title": "Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination",
        "link": "/arxiv/2510.15312",
        "arxiv_id": "2510.15312",
        "authors": "Zhiyang Chen, Daliang Xu, Haiyang Shen, Mengwei Xu, Shangguang Wang, Yun Ma",
        "summary": "Enhancing on-device large language models (LLMs) with contextual information from local data enables personalized and task-aware generation, powering use cases such as intelligent assistants and UI agents. While recent developments in neural processors have substantially improved the efficiency of prefill on mobile devices, the token-by-token generation process still suffers from high latency and limited hardware utilization due to its inherently memory-bound characteristics. This work presents CoordGen, a mobile inference framework that integrates speculative decoding with dynamic hardware scheduling to accelerate context-aware text generation on mobile devices. The framework introduces three synergistic components: (1) adaptive execution scheduling, which dynamically balances compute graphs between prefill and decoding phases; (2) context-aligned drafting, which improves speculative efficiency through lightweight online calibration to current tasks; and (3) hardware-efficient draft extension, which reuses and expands intermediate sequences to improve processing parallelism and reduce verification cost. Experiments on multiple smartphones and representative workloads show consistent improvements of up to 3.8x in generation speed and 4.7x in energy efficiency compared with existing mobile inference solutions. Component-level analysis further validates the contribution of each optimization.",
        "subjects": "Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.996275"
    },
    {
        "index": "#38",
        "title": "Automatic essay scoring: leveraging Jaccard coefficient and Cosine similaritywith n-gram variation in vector space model approach",
        "link": "/arxiv/2510.15311",
        "arxiv_id": "2510.15311",
        "authors": "Andharini Dwi Cahyani, Moh. Wildan Fathoni, Fika Hastarita Rachman, Ari Basuki, Salman Amin, Bain Khusnul Khotimah",
        "summary": "Automated essay scoring (AES) is a vital area of research aiming to provide efficient and accurate assessment tools for evaluating written content. This study investigates the effectiveness of two popular similarity metrics, Jaccard coefficient, and Cosine similarity, within the context of vector space models(VSM)employing unigram, bigram, and trigram representations. The data used in this research was obtained from the formative essay of the citizenship education subject in a junior high school. Each essay undergoes preprocessing to extract features using n-gram models, followed by vectorization to transform text data into numerical representations. Then, similarity scores are computed between essays using both Jaccard coefficient and Cosine similarity. The performance of the system is evaluated by analyzing the root mean square error (RMSE), which measures the difference between the scores given by human graders and those generated by the system. The result shows that the Cosine similarity outperformed the Jaccard coefficient. In terms of n-gram, unigrams have lower RMSE compared to bigrams and trigrams.",
        "subjects": "Computation and Language, Computers and Society, Software Engineering",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.996965"
    },
    {
        "index": "#39",
        "title": "Exemplar-Guided Planing: Enhanced LLM Agent for KGQA",
        "link": "/arxiv/2510.15283",
        "arxiv_id": "2510.15283",
        "authors": "Jingao Xu, Shuoyoucheng Ma, Xin Song, Rong Jiang, Hongkui Tu, Bin Zhou",
        "summary": "Large Language Models (LLMs) as interactive agents show significant promise in Knowledge Graph Question Answering (KGQA) but often struggle with the semantic gap between natural language queries and structured knowledge graph (KG) representations. This leads to suboptimal planning and inefficient exploration on KG, while training-free approaches often underutilize valuable reasoning patterns in training data. To address these limitations, we propose a novel framework, Exemplar-Guided Planning (EGP), which enhances the planning capabilities of LLM agents for KGQA. EGP first preprocesses the training set questions via entity templating to normalize semantic variations. It then retrieves highly similar exemplary questions and their successful reasoning paths from this preprocessed set using semantic embeddings and an efficient FAISS index. These retrieved exemplars dynamically guide the LLM's planning process in two key phases: (1) Task Decomposition, by aligning generated sub-objectives with proven reasoning steps, and (2) Relation Exploration, by providing high-quality auxiliary information to improve relation pruning accuracy. Additionally, we introduce a Smart Lookahead mechanism during relation exploration to improve efficiency by preemptively exploring promising paths and potentially terminating exploration earlier. We apply EGP to the Plan-on-Graph (PoG) framework, termed PoG-EGP. Extensive experiments on two real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP significantly improves over the baseline PoG system and other compared methods.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.997624"
    },
    {
        "index": "#40",
        "title": "TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding",
        "link": "/arxiv/2510.15269",
        "arxiv_id": "2510.15269",
        "authors": "Mucheng Ren, Yucheng Yan, He Chen, Danqing Hu, Jun Xu, Xian Zeng",
        "summary": "Medical texts, particularly electronic medical records (EMRs), are a cornerstone of modern healthcare, capturing critical information about patient care, diagnoses, and treatments. These texts hold immense potential for advancing clinical decision-making and healthcare analytics. However, their unstructured nature, domain-specific language, and variability across contexts make automated understanding an intricate challenge. Despite the advancements in natural language processing, existing methods often treat all data as equally challenging, ignoring the inherent differences in complexity across clinical records. This oversight limits the ability of models to effectively generalize and perform well on rare or complex cases. In this paper, we present TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to address these challenges by rethinking how models interact with medical texts during training. Inspired by the principle of progressive learning, TACL dynamically adjusts the training process based on the complexity of individual samples. By categorizing data into difficulty levels and prioritizing simpler cases early in training, the model builds a strong foundation before tackling more complex records. By applying TACL to multilingual medical data, including English and Chinese clinical records, we observe significant improvements across diverse clinical tasks, including automatic ICD coding, readmission prediction and TCM syndrome differentiation. TACL not only enhances the performance of automated systems but also demonstrates the potential to unify approaches across disparate medical domains, paving the way for more accurate, scalable, and globally applicable medical text understanding solutions.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.998274"
    },
    {
        "index": "#41",
        "title": "TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration",
        "link": "/arxiv/2510.15267",
        "arxiv_id": "2510.15267",
        "authors": "Mucheng Ren, He Chen, Yuchen Yan, Danqing Hu, Jun Xu, Xian Zeng",
        "summary": "Automated International Classification of Diseases (ICD) coding assigns standardized diagnosis and procedure codes to clinical records, playing a critical role in healthcare systems. However, existing methods face challenges such as semantic gaps between clinical text and ICD codes, poor performance on rare and long-tail codes, and limited interpretability. To address these issues, we propose TraceCoder, a novel framework integrating multi-source external knowledge to enhance traceability and explainability in ICD coding. TraceCoder dynamically incorporates diverse knowledge sources, including UMLS, Wikipedia, and large language models (LLMs), to enrich code representations, bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a hybrid attention mechanism to model interactions among labels, clinical context, and knowledge, improving long-tail code recognition and making predictions interpretable by grounding them in external evidence. Experiments on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that TraceCoder achieves state-of-the-art performance, with ablation studies validating the effectiveness of its components. TraceCoder offers a scalable and robust solution for automated ICD coding, aligning with clinical needs for accuracy, interpretability, and reliability.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.998932"
    },
    {
        "index": "#42",
        "title": "Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding",
        "link": "/arxiv/2510.15253",
        "arxiv_id": "2510.15253",
        "authors": "Sensen Gao, Shanshan Zhao, Xu Jiang, Lunhao Duan, Yong Xien Chng, Qing-Guo Chen, Weihua Luo, Kaifu Zhang, Jia-Wang Bian, Mingming Gong",
        "summary": "Document understanding is critical for applications from financial analysis to scientific discovery. Current approaches, whether OCR-based pipelines feeding Large Language Models (LLMs) or native Multimodal LLMs (MLLMs), face key limitations: the former loses structural detail, while the latter struggles with context modeling. Retrieval-Augmented Generation (RAG) helps ground models in external data, but documents' multimodal nature, i.e., combining text, tables, charts, and layout, demands a more advanced paradigm: Multimodal RAG. This approach enables holistic retrieval and reasoning across all modalities, unlocking comprehensive document intelligence. Recognizing its importance, this paper presents a systematic survey of Multimodal RAG for document understanding. We propose a taxonomy based on domain, retrieval modality, and granularity, and review advances involving graph structures and agentic frameworks. We also summarize key datasets, benchmarks, and applications, and highlight open challenges in efficiency, fine-grained representation, and robustness, providing a roadmap for future progress in document AI.",
        "subjects": "Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:04.999654"
    },
    {
        "index": "#43",
        "title": "Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning",
        "link": "/arxiv/2510.15244",
        "arxiv_id": "2510.15244",
        "authors": "Lina Berrayana, Ahmed Heakl, Muhammad Abdullah Sohail, Thomas Hofmann, Salman Khan, Wei Chen",
        "summary": "Current autoregressive language models (ARMs) achieve high accuracy but require long token sequences, making them costly. Discrete diffusion language models (DDLMs) enable parallel and flexible generation within a fixed number of steps and have recently emerged for their strong performance in complex reasoning and long-term planning tasks. We present a study exploring hybrid architectures that couple DDLMs with ARMs to assess whether their collaboration can yield complementary benefits. We first examine collaboration in text space, where one model plans the reasoning process and another executes the final answer based on that plan. We then extend this setup to latent-space communication, introducing a learned projector that maps DDLM latents into the ARM's embedding space, potentially bypassing some of the text-generation limitations of diffusion models. We find that shifting DDLM --> ARM communication from text space to latent space yields significant accuracy gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to 14.0% on AIME24. We also find that combining a DDLM planner with an ARM executor can provide substantial computational savings with little to no impact on accuracy. For example, the latent-space pipeline, using 64 tokens for planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME, despite Qwen using 44 times more tokens. Overall, our study offers new insights into reasoning with DDLMs and highlights their potential in hybrid architectures.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.000355"
    },
    {
        "index": "#44",
        "title": "Extending Audio Context for Long-Form Understanding in Large Audio-Language Models",
        "link": "/arxiv/2510.15231",
        "arxiv_id": "2510.15231",
        "authors": "Yuatyong Chaichana, Pittawat Taveekitworachai, Warit Sirichotedumrong, Potsawee Manakul, Kunat Pipatanakul",
        "summary": "Large Audio-Language Models (LALMs) are often constrained by short audio context windows, even when their text backbones support long contexts, limiting long-form audio understanding. Prior work has introduced context-extension methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains unexplored. First, building on RoPE-based context extension, we introduce Partial YaRN, a training-free, audio-only extension method that modifies only audio token positions, leaving text positions intact to preserve the base LLM's text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a training strategy that extends Partial YaRN into a training-time positional augmentation. VLAT simulates diverse audio lengths during training, enabling generalization to inputs far longer than those seen in training and improving robustness for long-context audio understanding. Our experiments on SALMONN and Qwen2-Audio show that Partial YaRN outperforms the original models across wide range of settings, and VLAT training strategy provides substantial improvement, achieving strong performance on long audio of unseen lengths.",
        "subjects": "Computation and Language, Artificial Intelligence, Sound, Audio and Speech Processing",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.006368"
    },
    {
        "index": "#45",
        "title": "Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning",
        "link": "/arxiv/2510.15191",
        "arxiv_id": "2510.15191",
        "authors": "Junlin Wu, Xianrui Zhong, Jiashuo Sun, Bolian Li, Bowen Jin, Jiawei Han, Qingkai Zeng",
        "summary": "Large language models (LLMs) have demonstrated remarkable advances in reasoning capabilities. However, their performance remains constrained by limited access to explicit and structured domain knowledge. Retrieval-Augmented Generation (RAG) addresses this by incorporating external information as context to augment reasoning. Nevertheless, traditional RAG systems typically operate over unstructured and fragmented text, resulting in low information density and suboptimal reasoning. To overcome these limitations, we propose \\textsc{Structure-R1}, a novel framework that transforms retrieved content into structured representations optimized for reasoning. Leveraging reinforcement learning, \\textsc{Structure-R1} learns a content representation policy that dynamically generates and adapts structural formats based on the demands of multi-step reasoning. Unlike prior methods that rely on fixed schemas, our approach adopts a generative paradigm capable of producing task-specific structures tailored to individual queries. To ensure the quality and reliability of these representations, we introduce a self-reward structural verification mechanism that checks whether the generated structures are both correct and self-contained. Extensive experiments on seven knowledge-intensive benchmarks show that \\textsc{Structure-R1} consistently achieves competitive performance with a 7B-scale backbone model and matches the performance of much larger models. Additionally, our theoretical analysis demonstrates how structured representations enhance reasoning by improving information density and contextual clarity. Our code and data are available at: https://github.com/jlwu002/sr1.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.006950"
    },
    {
        "index": "#46",
        "title": "FarsiMCQGen: a Persian Multiple-choice Question Generation Framework",
        "link": "/arxiv/2510.15134",
        "arxiv_id": "2510.15134",
        "authors": "Mohammad Heydari Rad, Rezvan Afari, Saeedeh Momtazi",
        "summary": "Multiple-choice questions (MCQs) are commonly used in educational testing, as they offer an efficient means of evaluating learners' knowledge. However, generating high-quality MCQs, particularly in low-resource languages such as Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an innovative approach for generating Persian-language MCQs. Our methodology combines candidate generation, filtering, and ranking techniques to build a model that generates answer choices resembling those in real MCQs. We leverage advanced methods, including Transformers and knowledge graphs, integrated with rule-based approaches to craft credible distractors that challenge test-takers. Our work is based on data from Wikipedia, which includes general knowledge questions. Furthermore, this study introduces a novel Persian MCQ dataset comprising 10,289 questions. This dataset is evaluated by different state-of-the-art large language models (LLMs). Our results demonstrate the effectiveness of our model and the quality of the generated dataset, which has the potential to inspire further research on MCQs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.007410"
    },
    {
        "index": "#47",
        "title": "Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis",
        "link": "/arxiv/2510.15125",
        "arxiv_id": "2510.15125",
        "authors": "Alexander Brady, Tunazzina Islam",
        "summary": "Social media platforms play a pivotal role in shaping political discourse, but analyzing their vast and rapidly evolving content remains a major challenge. We introduce an end-to-end framework for automatically generating an interpretable topic taxonomy from an unlabeled corpus. By combining unsupervised clustering with prompt-based labeling, our method leverages large language models (LLMs) to iteratively construct a taxonomy without requiring seed sets or domain expertise. We apply this framework to a large corpus of Meta (previously known as Facebook) political ads from the month ahead of the 2024 U.S. Presidential election. Our approach uncovers latent discourse structures, synthesizes semantically rich topic labels, and annotates topics with moral framing dimensions. We show quantitative and qualitative analyses to demonstrate the effectiveness of our framework. Our findings reveal that voting and immigration ads dominate overall spending and impressions, while abortion and election-integrity achieve disproportionate reach. Funding patterns are equally polarized: economic appeals are driven mainly by conservative PACs, abortion messaging splits between pro- and anti-rights coalitions, and crime-and-justice campaigns are fragmented across local committees. The framing of these appeals also diverges--abortion ads emphasize liberty/oppression rhetoric, while economic messaging blends care/harm, fairness/cheating, and liberty/oppression narratives. Topic salience further reveals strong correlations between moral foundations and issues. Demographic targeting also emerges. This work supports scalable, interpretable analysis of political messaging on social media, enabling researchers, policymakers, and the public to better understand emerging narratives, polarization dynamics, and the moral underpinnings of digital political communication.",
        "subjects": "Computation and Language, Artificial Intelligence, Computers and Society, Machine Learning, Social and Information Networks",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.007943"
    },
    {
        "index": "#48",
        "title": "Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks",
        "link": "/arxiv/2510.15115",
        "arxiv_id": "2510.15115",
        "authors": "Kirill Semenov, Rico Sennrich",
        "summary": "For multilingual factual knowledge assessment of LLMs, benchmarks such as MLAMA use template translations that do not take into account the grammatical and semantic information of the named entities inserted in the sentence. This leads to numerous instances of ungrammaticality or wrong wording of the final prompts, which complicates the interpretation of scores, especially for languages that have a rich morphological inventory. In this work, we sample 4 Slavic languages from the MLAMA dataset and compare the knowledge retrieval scores between the initial (templated) MLAMA dataset and its sentence-level translations made by Google Translate and ChatGPT. We observe a significant increase in knowledge retrieval scores, and provide a qualitative analysis for possible reasons behind it. We also make an additional analysis of 5 more languages from different families and see similar patterns. Therefore, we encourage the community to control the grammaticality of highly multilingual datasets for higher and more interpretable results, which is well approximated by whole sentence translation with neural MT or LLM systems. The dataset and all related code is published at the Github repository: https://github.com/ZurichNLP/Fluent-mLAMA.",
        "subjects": "Computation and Language",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.008371"
    },
    {
        "index": "#49",
        "title": "Continual Learning via Sparse Memory Finetuning",
        "link": "/arxiv/2510.15103",
        "arxiv_id": "2510.15103",
        "authors": "Jessy Lin, Luke Zettlemoyer, Gargi Ghosh, Wen-Tau Yih, Aram Markosyan, Vincent-Pierre Berges, Barlas Oğuz",
        "summary": "Modern language models are powerful, but typically static after deployment. A major obstacle to building models that continually learn over time is catastrophic forgetting, where updating on new data erases previously acquired capabilities. Motivated by the intuition that mitigating forgetting is challenging because trainable parameters are shared across all tasks, we investigate whether sparse parameter updates can enable learning without catastrophic forgetting. We introduce sparse memory finetuning, leveraging memory layer models (Berges et al., 2024), which are sparsely updated by design. By updating only the memory slots that are highly activated by a new piece of knowledge relative to usage on pretraining data, we reduce interference between new knowledge and the model's existing capabilities. We evaluate learning and forgetting compared to full finetuning and parameter-efficient finetuning with LoRA on two question answering tasks. We find that sparse memory finetuning learns new knowledge while exhibiting substantially less forgetting: while NaturalQuestions F1 drops by 89% after full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields only an 11% drop with the same level of new knowledge acquisition. Our results suggest sparsity in memory layers offers a promising path toward continual learning in large language models.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.008877"
    },
    {
        "index": "#50",
        "title": "A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling",
        "link": "/arxiv/2510.15081",
        "arxiv_id": "2510.15081",
        "authors": "Shiyu Ji, Farnoosh Hashemi, Joice Chen, Juanwen Pan, Weicheng Ma, Hefan Zhang, Sophia Pan, Ming Cheng, Shubham Mohole, Saeed Hassanpour, Soroush Vosoughi, Michael Macy",
        "summary": "Rhetorical strategies are central to persuasive communication, from political discourse and marketing to legal argumentation. However, analysis of rhetorical strategies has been limited by reliance on human annotation, which is costly, inconsistent, difficult to scale. Their associated datasets are often limited to specific topics and strategies, posing challenges for robust model development. We propose a novel framework that leverages large language models (LLMs) to automatically generate and label synthetic debate data based on a four-part rhetorical typology (causal, empirical, emotional, moral). We fine-tune transformer-based classifiers on this LLM-labeled dataset and validate its performance against human-labeled data on this dataset and on multiple external corpora. Our model achieves high performance and strong generalization across topical domains. We illustrate two applications with the fine-tuned model: (1) the improvement in persuasiveness prediction from incorporating rhetorical strategy labels, and (2) analyzing temporal and partisan shifts in rhetorical strategies in U.S. Presidential debates (1960-2020), revealing increased use of affective over cognitive argument in U.S. Presidential debates.",
        "subjects": "Computation and Language, Social and Information Networks",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.009462"
    },
    {
        "index": "#51",
        "title": "Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek",
        "link": "/arxiv/2510.15009",
        "arxiv_id": "2510.15009",
        "authors": "Enis Oğuz",
        "summary": "The developments in Generative AI technologies have paved the way for numerous innovations in different fields. Recently, Generative AI has been proposed as a competitor to AES systems in evaluating student essays automatically. Considering the potential limitations of AI in processing idioms, this study assessed the scoring performances of Generative AI models for essays with and without idioms by incorporating insights from Corpus Linguistics and Computational Linguistics. Two equal essay lists were created from 348 student essays taken from a corpus: one with multiple idioms present in each essay and another with no idioms in essays. Three Generative AI models (ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists three times, using the same rubric used by human raters in assigning essay scores. The results revealed excellent consistency for all models, but Gemini outperformed its competitors in interrater reliability with human raters. There was also no detectable bias for any demographic group in AI assessment. For essays with multiple idioms, Gemini followed a the most similar pattern to human raters. While the models in the study demonstrated potential for a hybrid approach, Gemini was the best candidate for the task due to its ability to handle figurative language and showed promise for handling essay-scoring tasks alone in the future.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.009895"
    },
    {
        "index": "#52",
        "title": "Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective",
        "link": "/arxiv/2510.15007",
        "arxiv_id": "2510.15007",
        "authors": "Zhiqiang Kou, Junyang Chen, Xin-Qiang Cai, Ming-Kun Xie, Biao Liu, Changwei Wang, Lei Feng, Yuheng Jia, Gang Niu, Masashi Sugiyama, Xin Geng",
        "summary": "Large language models (LLMs) have achieved impressive results across a range of natural language processing tasks, but their potential to generate harmful content has raised serious safety concerns. Current toxicity detectors primarily rely on single-label benchmarks, which cannot adequately capture the inherently ambiguous and multi-dimensional nature of real-world toxic prompts. This limitation results in biased evaluations, including missed toxic detections and false positives, undermining the reliability of existing detectors. Additionally, gathering comprehensive multi-label annotations across fine-grained toxicity categories is prohibitively costly, further hindering effective evaluation and development. To tackle these issues, we introduce three novel multi-label benchmarks for toxicity detection: \\textbf{Q-A-MLL}, \\textbf{R-A-MLL}, and \\textbf{H-X-MLL}, derived from public toxicity datasets and annotated according to a detailed 15-category taxonomy. We further provide a theoretical proof that, on our released datasets, training with pseudo-labels yields better performance than directly learning from single-label supervision. In addition, we develop a pseudo-label-based toxicity detection method. Extensive experimental results show that our approach significantly surpasses advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate and reliable evaluation of multi-label toxicity in LLM-generated content.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.010453"
    },
    {
        "index": "#53",
        "title": "OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM",
        "link": "/arxiv/2510.15870",
        "arxiv_id": "2510.15870",
        "authors": "Hanrong Ye, Chao-Han Huck Yang, Arushi Goel, Wei Huang, Ligeng Zhu, Yuanhang Su, Sean Lin, An-Chieh Cheng, Zhen Wan, Jinchuan Tian, Yuming Lou, Dong Yang, Zhijian Liu, Yukang Chen, Ambrish Dantrey, Ehsan Jahangiri, Sreyan Ghosh, Daguang Xu, Ehsan Hosseini-Asl, Danial Mohseni Taheri, Vidya Murali, Sifei Liu, Jason Lu, Oluwatobi Olabiyi, Frank Wang, Rafael Valle, Bryan Catanzaro, Andrew Tao, Song Han, Jan Kautz, Hongxu Yin, Pavlo Molchanov",
        "summary": "Advancing machine intelligence requires developing the ability to perceive across multiple modalities, much as humans sense the world. We introduce OmniVinci, an initiative to build a strong, open-source, omni-modal LLM. We carefully study the design choices across model architecture and data curation. For model architecture, we present three key innovations: (i) OmniAlignNet for strengthening alignment between vision and audio embeddings in a shared omni-modal latent space; (ii) Temporal Embedding Grouping for capturing relative temporal alignment between vision and audio signals; and (iii) Constrained Rotary Time Embedding for encoding absolute temporal information in omni-modal embeddings. We introduce a curation and synthesis pipeline that generates 24M single-modal and omni-modal conversations. We find that modalities reinforce one another in both perception and reasoning. Our model, OmniVinci, outperforms Qwen2.5-Omni with +19.05 on DailyOmni (cross-modal understanding), +1.7 on MMAR (audio), and +3.9 on Video-MME (vision), while using just 0.2T training tokens - a 6 times reduction compared to Qwen2.5-Omni's 1.2T. We finally demonstrate omni-modal advantages in downstream applications spanning robotics, medical AI, and smart factory.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.026660"
    },
    {
        "index": "#54",
        "title": "GraphMind: Interactive Novelty Assessment System for Accelerating Scientific Discovery",
        "link": "/arxiv/2510.15706",
        "arxiv_id": "2510.15706",
        "authors": "Italo Luis da Silva, Hanqi Yan, Lin Gui, Yulan He",
        "summary": "Large Language Models (LLMs) show strong reasoning and text generation capabilities, prompting their use in scientific literature analysis, including novelty assessment. While evaluating novelty of scientific papers is crucial for peer review, it requires extensive knowledge of related work, something not all reviewers have. While recent work on LLM-assisted scientific literature analysis supports literature comparison, existing approaches offer limited transparency and lack mechanisms for result traceability via an information retrieval module. To address this gap, we introduce $\\textbf{GraphMind}$, an easy-to-use interactive web tool designed to assist users in evaluating the novelty of scientific papers or drafted ideas. Specially, $\\textbf{GraphMind}$ enables users to capture the main structure of a scientific paper, explore related ideas through various perspectives, and assess novelty via providing verifiable contextual insights. $\\textbf{GraphMind}$ enables users to annotate key elements of a paper, explore related papers through various relationships, and assess novelty with contextual insight. This tool integrates external APIs such as arXiv and Semantic Scholar with LLMs to support annotation, extraction, retrieval and classification of papers. This combination provides users with a rich, structured view of a scientific idea's core contributions and its connections to existing work. $\\textbf{GraphMind}$ is available at https://oyarsa.github.io/graphmind and a demonstration video at https://youtu.be/wKbjQpSvwJg. The source code is available at https://github.com/oyarsa/graphmind.",
        "subjects": "Information Retrieval, Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.027177"
    },
    {
        "index": "#55",
        "title": "Exploring the Synergy of Quantitative Factors and Newsflow Representations from Large Language Models for Stock Return Prediction",
        "link": "/arxiv/2510.15691",
        "arxiv_id": "2510.15691",
        "authors": "Tian Guo, Emmanuel Hauptmann",
        "summary": "In quantitative investing, return prediction supports various tasks, including stock selection, portfolio optimization, and risk management. Quantitative factors, such as valuation, quality, and growth, capture various characteristics of stocks. Unstructured financial data, like news and transcripts, has attracted growing attention, driven by recent advances in large language models (LLMs). This paper examines effective methods for leveraging multimodal factors and newsflow in return prediction and stock selection. First, we introduce a fusion learning framework to learn a unified representation from factors and newsflow representations generated by an LLM. Within this framework, we compare three representative methods: representation combination, representation summation, and attentive representations. Next, building on empirical observations from fusion learning, we explore the mixture model that adaptively combines predictions made by single modalities and their fusion. To mitigate the training instability observed in the mixture model, we introduce a decoupled training approach with theoretical insights. Finally, our experiments on real investment universes yield several insights into effective multimodal modeling of factors and news for stock return prediction.",
        "subjects": "Computational Finance, Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.027674"
    },
    {
        "index": "#56",
        "title": "SQuAI: Scientific Question-Answering with Multi-Agent Retrieval-Augmented Generation",
        "link": "/arxiv/2510.15682",
        "arxiv_id": "2510.15682",
        "authors": "Ines Besrour, Jingbo He, Tobias Schreieder, Michael Färber",
        "summary": "We present SQuAI (https://squai.scads.ai/), a scalable and trustworthy multi-agent retrieval-augmented generation (RAG) framework for scientific question answering (QA) with large language models (LLMs). SQuAI addresses key limitations of existing RAG systems in the scholarly domain, where complex, open-domain questions demand accurate answers, explicit claims with citations, and retrieval across millions of scientific documents. Built on over 2.3 million full-text papers from arXiv.org, SQuAI employs four collaborative agents to decompose complex questions into sub-questions, retrieve targeted evidence via hybrid sparse-dense retrieval, and adaptively filter documents to improve contextual relevance. To ensure faithfulness and traceability, SQuAI integrates in-line citations for each generated claim and provides supporting sentences from the source documents. Our system improves faithfulness, answer relevance, and contextual relevance by up to +0.088 (12%) over a strong RAG baseline. We further release a benchmark of 1,000 scientific question-answer-evidence triplets to support reproducibility. With transparent reasoning, verifiable citations, and domain-wide scalability, SQuAI demonstrates how multi-agent RAG enables more trustworthy scientific QA with LLMs.",
        "subjects": "Information Retrieval, Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.028157"
    },
    {
        "index": "#58",
        "title": "Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism",
        "link": "/arxiv/2510.15600",
        "arxiv_id": "2510.15600",
        "authors": "Haoran Sun, Yankai Jiang, Zhenyu Tang, Yaning Pan, Shuang Gu, Zekai Lin, Lilong Wang, Wenjie Lou, Lei Liu, Lei Bai, Xiaosong Wang",
        "summary": "The foundation of reproducible science lies in protocols that are precise, logically ordered, and executable. The autonomous generation of these protocols through natural language queries could greatly improve the efficiency of the reproduction process. However, current leading large language models (LLMs) often generate incomplete or inconsistent protocols, limiting their utility. To address this limitation, we first introduce SciRecipe, a large-scale dataset of over 12K structured protocols spanning 27 biological subfields and encompassing both comprehension and problem-solving tasks. To further improve protocol generation, we propose the \"Sketch-and-Fill\" paradigm, which separates analysis, structuring, and expression to ensure each step is explicit and verifiable. Complementing this, the structured component-based reward mechanism evaluates step granularity, action order, and semantic fidelity, aligning model optimization with experimental reliability. Building on these components, we develop Thoth, trained through a staged Knowledge-to-Action process that progresses from knowledge acquisition to operational reasoning and ultimately to robust, executable protocol generation. Across multiple benchmarks, Thoth consistently surpasses both proprietary and open-source LLMs, achieving significant improvements in step alignment, logical sequencing, and semantic accuracy. Our approach paves the way for reliable scientific assistants that bridge knowledge with experimental execution. All data, code, and models will be released publicly.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.029279"
    },
    {
        "index": "#59",
        "title": "Leveraging Test Driven Development with Large Language Models for Reliable and Verifiable Spreadsheet Code Generation: A Research Framework",
        "link": "/arxiv/2510.15585",
        "arxiv_id": "2510.15585",
        "authors": "Dr Simon Thorne, Dr Advait Sarkar",
        "summary": "Large Language Models (LLMs), such as ChatGPT, are increasingly leveraged for generating both traditional software code and spreadsheet logic. Despite their impressive generative capabilities, these models frequently exhibit critical issues such as hallucinations, subtle logical inconsistencies, and syntactic errors, risks particularly acute in high stakes domains like financial modelling and scientific computations, where accuracy and reliability are paramount. This position paper proposes a structured research framework that integrates the proven software engineering practice of Test-Driven Development (TDD) with Large Language Model (LLM) driven generation to enhance the correctness of, reliability of, and user confidence in generated outputs. We hypothesise that a \"test first\" methodology provides both technical constraints and cognitive scaffolding, guiding LLM outputs towards more accurate, verifiable, and comprehensible solutions. Our framework, applicable across diverse programming contexts, from spreadsheet formula generation to scripting languages such as Python and strongly typed languages like Rust, includes an explicitly outlined experimental design with clearly defined participant groups, evaluation metrics, and illustrative TDD based prompting examples. By emphasising test driven thinking, we aim to improve computational thinking, prompt engineering skills, and user engagement, particularly benefiting spreadsheet users who often lack formal programming training yet face serious consequences from logical errors. We invite collaboration to refine and empirically evaluate this approach, ultimately aiming to establish responsible and reliable LLM integration in both educational and professional development practices.",
        "subjects": "Software Engineering, Computation and Language, Programming Languages",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.029750"
    },
    {
        "index": "#60",
        "title": "BeLLMan: Controlling LLM Congestion",
        "link": "/arxiv/2510.15330",
        "arxiv_id": "2510.15330",
        "authors": "Tella Rajashekhar Reddy, Atharva Deshmukh, Karan Tandon, Rohan Gandhi, Anjaly Parayil, Debopam Bhattacherjee",
        "summary": "Large language model (LLM) applications are blindfolded to the infrastructure underneath and generate tokens autoregressively, indifferent to the system load, thus risking inferencing latency inflation and poor user experience. Our first-cut controller, named beLLMan, enables the LLM infrastructure to actively and progressively signal the first-party LLM application to adjust the output length in response to changing system load. On a real testbed with H100 GPUs, beLLMan helps keep inferencing latency under control (upto 8X lower end-to-end latency) and reduces energy consumption by 25% (while serving 19% more requests) during periods of congestion for a summarization workload.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Computation and Language, Networking and Internet Architecture",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.045961"
    },
    {
        "index": "#61",
        "title": "DRO-InstructZero: Distributionally Robust Prompt Optimization for Large Language Models",
        "link": "/arxiv/2510.15260",
        "arxiv_id": "2510.15260",
        "authors": "Yangyang Li",
        "summary": "Large language models are highly sensitive to prompt wording. However, popular automatic prompt search methods, including InstructZero, often degrade under distribution shift and adversarial evaluation because they optimize expected performance under a single evaluation distribution. Consequently, prompts that work in one setting frequently fail to transfer. To address this, DRO-InstructZero formulates zero-shot prompt optimization as robust Bayesian optimization. Specifically, an f-divergence ball defines an ambiguity set around the evaluation distribution, and a robust acquisition rule maximizes worst-case expected utility while retaining the query efficiency of Bayesian search. Therefore, the search explicitly targets reliability under distribution shift rather than average behavior alone. Experiments follow the instruction-induction protocol with matched query budgets across formality rewriting, code debugging, and translation. For example, on BIG-Bench informative-to-formal rewriting, accuracy improves from 61.3 +/- 0.7% to approximately 85-90%, yielding an absolute gain of about 25-30 points. Moreover, auto-debugging shows about +25-point gains under domain shift. Meanwhile, stable tasks such as cause-and-effect remain above 96%, indicating no loss on in-distribution cases. Furthermore, improvements are consistent across divergence choices and decoding temperatures. Overall, DRO-InstructZero connects distributionally robust optimization with prompt learning, offering a plug-and-play and general approach for reliable, transferable prompt alignment under real-world uncertainty.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.046531"
    },
    {
        "index": "#62",
        "title": "Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions",
        "link": "/arxiv/2510.15258",
        "arxiv_id": "2510.15258",
        "authors": "Xi Wang, Xianyao Ling, Kun Li, Gang Yin, Liang Zhang, Jiang Wu, Jun Xu, Fu Zhang, Wenbo Lei, Annie Wang, Peng Gong",
        "summary": "In the current era of big data, extracting deep insights from massive, heterogeneous, and complexly associated multi-dimensional data has become a significant challenge. Large Language Models (LLMs) perform well in natural language understanding and generation, but still suffer from \"hallucination\" issues when processing structured knowledge and are difficult to update in real-time. Although Knowledge Graphs (KGs) can explicitly store structured knowledge, their static nature limits dynamic interaction and analytical capabilities. Therefore, this paper proposes a multi-dimensional data analysis method based on the interactions between LLM agents and KGs, constructing a dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to automatically extract product data from unstructured data, constructs and visualizes the KG in real-time, and supports users in deep exploration and analysis of graph nodes through an interactive platform. Experimental results show that this method has significant advantages in product ecosystem analysis, relationship mining, and user-driven exploratory analysis, providing new ideas and tools for multi-dimensional data analysis.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.047251"
    },
    {
        "index": "#63",
        "title": "FinTrust: A Comprehensive Benchmark of Trustworthiness Evaluation in Finance Domain",
        "link": "/arxiv/2510.15232",
        "arxiv_id": "2510.15232",
        "authors": "Tiansheng Hu, Tongyan Hu, Liuyang Bai, Yilun Zhao, Arman Cohan, Chen Zhao",
        "summary": "Recent LLMs have demonstrated promising ability in solving finance related problems. However, applying LLMs in real-world finance application remains challenging due to its high risk and high stakes property. This paper introduces FinTrust, a comprehensive benchmark specifically designed for evaluating the trustworthiness of LLMs in finance applications. Our benchmark focuses on a wide range of alignment issues based on practical context and features fine-grained tasks for each dimension of trustworthiness evaluation. We assess eleven LLMs on FinTrust and find that proprietary models like o4-mini outperforms in most tasks such as safety while open-source models like DeepSeek-V3 have advantage in specific areas like industry-level fairness. For challenging task like fiduciary alignment and disclosure, all LLMs fall short, showing a significant gap in legal awareness. We believe that FinTrust can be a valuable benchmark for LLMs' trustworthiness evaluation in finance domain.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.047909"
    },
    {
        "index": "#64",
        "title": "Soundness-Aware Level: A Microscopic Signature that Predicts LLM Reasoning Potential",
        "link": "/arxiv/2510.15216",
        "arxiv_id": "2510.15216",
        "authors": "Xuansheng Wu, Xiaoman Pan, Wenlin Yao, Jianshu Chen",
        "summary": "Reinforcement learning with verifiable rewards (RLVR) can elicit strong reasoning in large language models (LLMs), while their performance after RLVR varies dramatically across different base models. This raises a fundamental question: what microscopic property of pre-trained models leads to this variation? To investigate, we formalize reasoning as chains of Horn clauses (\"if-then\" rules) built from features extracted from the LLM's latent space via cross-layer sparse autoencoders (SAEs). We estimate the transition probabilities between its features, and further categorize each rule by its semantic soundness level (e.g., strict, plausible, noisy) with an LLM. Our key discovery is that high-potential models are inherently soundness-aware: their internal probability distributions systematically shift across rules' soundness levels, becoming highly distinct for \"strict\" versus \"noisy\" rules. In contrast, weaker models are soundness-agnostic, collapsing to one distribution regardless of soundness levels. To quantify this, we introduce the Soundness-Aware Level (SAL), a microscopic metric using the Jensen-Shannon Divergence to measure the separation between these distributions. We show that SAL's predictions of post-RLVR reasoning performance follow a precise empirical law (R^2=0.87) across diverse model families (Qwen, Mistral, Llama, DeepSeek) and scales (0.5B-14B). This reveals that a model's reasoning potential is tied to its intrinsic, pre-trained ability to distinguish sound knowledge from unsound ones. These findings underscore the critical role of model pre-training in shaping reasoning and offer a practical metric grounded in the model's internal mechanisms for selecting/designing stronger base models.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-10-17",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.048508"
    },
    {
        "index": "#65",
        "title": "MAGPIE: A benchmark for Multi-AGent contextual PrIvacy Evaluation",
        "link": "/arxiv/2510.15186",
        "arxiv_id": "2510.15186",
        "authors": "Gurusha Juneja, Jayanth Naga Sai Pasupulati, Alon Albalak, Wenyue Hua, William Yang Wang",
        "summary": "A core challenge for autonomous LLM agents in collaborative settings is balancing robust privacy understanding and preservation alongside task efficacy. Existing privacy benchmarks only focus on simplistic, single-turn interactions where private information can be trivially omitted without affecting task outcomes. In this paper, we introduce MAGPIE (Multi-AGent contextual PrIvacy Evaluation), a novel benchmark of 200 high-stakes tasks designed to evaluate privacy understanding and preservation in multi-agent collaborative, non-adversarial scenarios. MAGPIE integrates private information as essential for task resolution, forcing agents to balance effective collaboration with strategic information control. Our evaluation reveals that state-of-the-art agents, including GPT-5 and Gemini 2.5-Pro, exhibit significant privacy leakage, with Gemini 2.5-Pro leaking up to 50.7% and GPT-5 up to 35.1% of the sensitive information even when explicitly instructed not to. Moreover, these agents struggle to achieve consensus or task completion and often resort to undesirable behaviors such as manipulation and power-seeking (e.g., Gemini 2.5-Pro demonstrating manipulation in 38.2% of the cases). These findings underscore that current LLM agents lack robust privacy understanding and are not yet adequately aligned to simultaneously preserve privacy and maintain effective collaboration in complex environments.",
        "subjects": "Cryptography and Security, Computation and Language",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.049128"
    },
    {
        "index": "#66",
        "title": "Train a Unified Multimodal Data Quality Classifier with Synthetic Data",
        "link": "/arxiv/2510.15162",
        "arxiv_id": "2510.15162",
        "authors": "Weizhi Wang, Rongmei Lin, Shiyang Li, Colin Lockard, Ritesh Sarkhel, Sanket Lokegaonkar, Jingbo Shang, Xifeng Yan, Nasser Zalmout, Xian Li",
        "summary": "The Multimodal Large Language Models (MLLMs) are continually pre-trained on a mixture of image-text caption data and interleaved document data, while the high-quality data filtering towards image-text interleaved document data is under-explored. We propose to train an efficient MLLM as a Unified Mulitmodal Data Quality Classifier to Filter both high-quality image-text caption and interleaved data (UniFilter). To address the challenge of collecting diverse labeled multimodal data, we introduce a semi-synthetic approach that leverages readily available raw images and generates corresponding text across four quality levels. This method enables efficient creation of sample-score pairs for both caption and interleaved document data to train UniFilter. We apply UniFilter to curate high-quality caption data from DataComp caption dataset and interleaved data from the OBELICS image-text interleaved dataset. MLLMs pre-trained on the filtered data demonstrate significantly enhanced capabilities compared to those trained on baseline-filtered data, achieving stronger zero-shot reasoning and in-context learning capabilities. After visual supervised fine-tuning, these UniFilter-induced MLLMs achieve stronger performance on various benchmarks, highlighting the downstream benefits of high-quality multimodal pre-training. We release the synthetic training data used for training UniFilter, the UniFilter model checkpoints, and the high-quality interleaved document subset OBELICS-HQ, curated by UniFilter, to the community for reproduction and further development.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.049837"
    },
    {
        "index": "#67",
        "title": "HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks",
        "link": "/arxiv/2510.15144",
        "arxiv_id": "2510.15144",
        "authors": "Chance Jiajie Li, Zhenze Mo, Yuhan Tang, Ao Qu, Jiayi Wu, Kaiya Ivy Zhao, Yulu Gan, Jie Fan, Jiangbo Yu, Hang Jiang, Paul Pu Liang, Jinhua Zhao, Luis Alberto Alonso Pastor, Kent Larson",
        "summary": "Simulating human reasoning in open-ended tasks has been a long-standing aspiration in AI and cognitive science. While large language models now approximate human responses at scale, they remain tuned to population-level consensus, often erasing the individuality of reasoning styles and belief trajectories. To advance the vision of more human-like reasoning in machines, we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for average-to-individual reasoning adaptation. The task is to predict how a specific person would reason and update their beliefs in novel scenarios, given partial evidence of their past views. HugAgent adopts a dual-track design: a synthetic track for scale and systematic stress tests, and a human track for ecologically valid, \"out-loud\" reasoning data. This design enables scalable, reproducible evaluation of intra-agent fidelity: whether models can capture not just what people believe, but how their reasoning evolves. Experiments with state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent as the first extensible benchmark for aligning machine reasoning with the individuality of human thought. Our benchmark and chatbot are open-sourced as HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking (https://anonymous.4open.science/r/trace-your-thinking).",
        "subjects": "Artificial Intelligence, Computation and Language, Computers and Society",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.065987"
    },
    {
        "index": "#68",
        "title": "DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning",
        "link": "/arxiv/2510.15110",
        "arxiv_id": "2510.15110",
        "authors": "Shih-Yang Liu, Xin Dong, Ximing Lu, Shizhe Diao, Mingjie Liu, Min-Hung Chen, Hongxu Yin, Yu-Chiang Frank Wang, Kwang-Ting Cheng, Yejin Choi, Jan Kautz, Pavlo Molchanov",
        "summary": "Reasoning language models such as OpenAI-o1, DeepSeek-R1, and Qwen achieve strong performance via extended chains of thought but often generate unnecessarily long outputs. Maximizing intelligence per token--accuracy relative to response length--remains an open problem. We revisit reinforcement learning (RL) with the simplest length penalty--truncation--and show that accuracy degradation arises not from the lack of sophisticated penalties but from inadequate RL optimization. We identify three key challenges: (i) large bias in advantage estimation, (ii) entropy collapse, and (iii) sparse reward signal. We address them with Doing Length pEnalty Right (DLER), a training recipe combining batch-wise reward normalization, higher clipping, dynamic sampling, and a simple truncation length penalty. DLER achieves state-of-the-art accuracy--efficiency trade-offs, cutting output length by over 70 percent while surpassing all previous baseline accuracy. It also improves test-time scaling: compared to DeepSeek-R1-7B, DLER-7B generates multiple concise responses in parallel with 28 percent higher accuracy and lower latency. We further introduce Difficulty-Aware DLER, which adaptively tightens truncation on easier questions for additional efficiency gains. We also propose an update-selective merging method that preserves baseline accuracy while retaining the concise reasoning ability of the DLER model, which is useful for scenarios where RL training data is scarce.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.066782"
    },
    {
        "index": "#69",
        "title": "Antislop: A Comprehensive Framework for Identifying and Eliminating Repetitive Patterns in Language Models",
        "link": "/arxiv/2510.15061",
        "arxiv_id": "2510.15061",
        "authors": "Samuel Paech, Allen Roush, Judah Goldfeder, Ravid Shwartz-Ziv",
        "summary": "Widespread LLM adoption has introduced characteristic repetitive phraseology, termed ``slop,'' which degrades output quality and makes AI-generated text immediately recognizable. We present Antislop, a comprehensive framework providing tools to both detect and eliminate these overused patterns. Our approach combines three innovations: (1) The Antislop Sampler, which uses backtracking to suppress unwanted strings at inference time without destroying vocabulary; (2) An automated pipeline that profiles model-specific slop against human baselines and generates training data; (3) Final Token Preference Optimization (FTPO), a novel fine-tuning method that operates on individual tokens, surgically adjusting logits wherever a banned pattern has appeared in an inference trace. We demonstrate that some slop patterns appear over 1,000$\\times$ more frequently in LLM output than human text. The Antislop Sampler successfully suppresses 8,000+ patterns while maintaining quality, whereas token banning becomes unusable at just 2,000. Most importantly, FTPO achieves 90\\% slop reduction while maintaining or improving performance in cross-domain evals including GSM8K, MMLU, and creative writing tasks. In contrast, DPO suffers significant degradation in writing quality and lexical diversity despite achieving weaker suppression. We release all code and results under MIT license: https://github.com/sam-paech/auto-antislop.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.067394"
    },
    {
        "index": "#70",
        "title": "Internalizing World Models via Self-Play Finetuning for Agentic RL",
        "link": "/arxiv/2510.15047",
        "arxiv_id": "2510.15047",
        "authors": "Shiqi Chen, Tongyao Zhu, Zian Wang, Jinghan Zhang, Kangrui Wang, Siyang Gao, Teng Xiao, Yee Whye Teh, Junxian He, Manling Li",
        "summary": "Large Language Models (LLMs) as agents often struggle in out-of-distribution (OOD) scenarios. Real-world environments are complex and dynamic, governed by task-specific rules and stochasticity, which makes it difficult for LLMs to ground their internal knowledge in those dynamics. Under such OOD conditions, vanilla RL training often fails to scale; we observe Pass@k--the probability that at least one of (k) sampled trajectories succeeds--drops markedly across training steps, indicating brittle exploration and limited generalization. Inspired by model-based reinforcement learning, we hypothesize that equipping LLM agents with an internal world model can better align reasoning with environmental dynamics and improve decision-making. We show how to encode this world model by decomposing it into two components: state representation and transition modeling. Building on this, we introduce SPA, a simple reinforcement learning framework that cold-starts the policy via a Self-Play supervised finetuning (SFT) stage to learn the world model by interacting with the environment, then uses it to simulate future states prior to policy optimization. This simple initialization outperforms the online world-modeling baseline and greatly boosts the RL-based agent training performance. Experiments across diverse environments like Sokoban, FrozenLake, and Sudoku show that our approach significantly improves performance. For example, SPA boosts the Sokoban success rate from 25.6% to 59.8% and raises the FrozenLake score from 22.1% to 70.9% for the Qwen2.5-1.5B-Instruct model.",
        "subjects": "Machine Learning, Computation and Language",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.068126"
    },
    {
        "index": "#71",
        "title": "Composition-Grounded Instruction Synthesis for Visual Reasoning",
        "link": "/arxiv/2510.15040",
        "arxiv_id": "2510.15040",
        "authors": "Xinyi Gu, Jiayuan Mao, Zhang-Wei Hong, Zhuoran Yu, Pengyuan Li, Dhiraj Joshi, Rogerio Feris, Zexue He",
        "summary": "Pretrained multi-modal large language models (MLLMs) demonstrate strong performance on diverse multimodal tasks, but remain limited in reasoning capabilities for domains where annotations are difficult to collect. In this work, we focus on artificial image domains such as charts, rendered documents, and webpages, which are abundant in practice yet lack large-scale human annotated reasoning datasets. We introduce COGS (COmposition-Grounded instruction Synthesis), a data-efficient framework for equipping MLLMs with advanced reasoning abilities from a small set of seed questions. The key idea is to decompose each seed question into primitive perception and reasoning factors, which can then be systematically recomposed with new images to generate large collections of synthetic question-answer pairs. Each generated question is paired with subquestions and intermediate answers, enabling reinforcement learning with factor-level process rewards. Experiments on chart reasoning show that COGS substantially improves performance on unseen questions, with the largest gains on reasoning-heavy and compositional questions. Moreover, training with a factor-level mixture of different seed data yields better transfer across multiple datasets, suggesting that COGS induces generalizable capabilities rather than dataset-specific overfitting. We further demonstrate that the framework extends beyond charts to other domains such as webpages.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.068839"
    },
    {
        "index": "#72",
        "title": "The Coverage Principle: How Pre-training Enables Post-Training",
        "link": "/arxiv/2510.15020",
        "arxiv_id": "2510.15020",
        "authors": "Fan Chen, Audrey Huang, Noah Golowich, Sadhika Malladi, Adam Block, Jordan T. Ash, Akshay Krishnamurthy, Dylan J. Foster",
        "summary": "Language models demonstrate remarkable abilities when pre-trained on large text corpora and fine-tuned for specific tasks, but how and why pre-training shapes the success of the final model remains poorly understood. Notably, although pre-training success is often quantified by cross entropy loss, cross-entropy can be a poor predictor of downstream performance. Instead, we provide a theoretical perspective on this relationship through the lens of \\emph{coverage}, which quantifies the probability mass the pre-trained model places on high-quality responses and which is necessary and sufficient for post-training and test-time scaling methods such as Best-of-N to succeed. Our main results develop an understanding of \\emph{the coverage principle}, a phenomenon whereby next-token prediction implicitly optimizes toward a model with good coverage. In particular, we uncover a mechanism that explains the power of coverage in predicting downstream performance: \\emph{coverage generalizes faster than cross entropy}, avoiding spurious dependence on problem-dependent parameters such as the sequence length. We also study practical algorithmic interventions with provable benefits for improving coverage, including (i) model/checkpoint selection procedures, (ii) gradient normalization schemes, and (iii) test-time decoding strategies.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language, Machine Learning, Statistics Theory",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.069581"
    },
    {
        "index": "#73",
        "title": "DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models",
        "link": "/arxiv/2510.15015",
        "arxiv_id": "2510.15015",
        "authors": "Mor Ventura, Michael Toker, Or Patashnik, Yonatan Belinkov, Roi Reichart",
        "summary": "Text-to-Image (T2I) models have advanced rapidly, yet they remain vulnerable to semantic leakage, the unintended transfer of semantically related features between distinct entities. Existing mitigation strategies are often optimization-based or dependent on external inputs. We introduce DeLeaker, a lightweight, optimization-free inference-time approach that mitigates leakage by directly intervening on the model's attention maps. Throughout the diffusion process, DeLeaker dynamically reweights attention maps to suppress excessive cross-entity interactions while strengthening the identity of each entity. To support systematic evaluation, we introduce SLIM (Semantic Leakage in IMages), the first dataset dedicated to semantic leakage, comprising 1,130 human-verified samples spanning diverse scenarios, together with a novel automatic evaluation framework. Experiments demonstrate that DeLeaker consistently outperforms all baselines, even when they are provided with external information, achieving effective leakage mitigation without compromising fidelity or quality. These results underscore the value of attention control and pave the way for more semantically precise T2I models.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-10-16",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.070236"
    },
    {
        "index": "#74",
        "title": "Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI",
        "link": "/arxiv/2502.17092",
        "arxiv_id": "2502.17092",
        "authors": "Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi",
        "summary": "We introduce Shakti VLM, a family of vision-language models in the capacity of 1B and 4B parameters designed to address data efficiency challenges in multimodal learning. While recent VLMs achieve strong performance through extensive training data, Shakti models leverage architectural innovations to attain competitive results with fewer tokens. Key advancements include QK-Normalization for attention stability, hybrid normalization techniques, and enhanced positional encoding. A three-stage training strategy further optimizes learning efficiency. Evaluations show that Shakti-Shakti-VLM-1B and Shakti-VLM-4B excel in document understanding, Visual Reasoning, OCR extraction, and general multimodal reasoning. Our results highlight that high performance can be achieved through model design and training strategy rather than sheer data volume, making Shakti an efficient solution for enterprise-scale multimodal tasks.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-02-24",
        "category": "cs.CL",
        "crawl_time": "2025-10-20T11:00:05.075920"
    },
    {
        "index": "#1",
        "title": "Self-Certifying Primal-Dual Optimization Proxies for Large-Scale Batch Economic Dispatch",
        "link": "/arxiv/2510.15850",
        "arxiv_id": "2510.15850",
        "authors": "Michael Klamkin, Mathieu Tanneau, Pascal Van Hentenryck",
        "summary": "Recent research has shown that optimization proxies can be trained to high fidelity, achieving average optimality gaps under 1% for large-scale problems. However, worst-case analyses show that there exist in-distribution queries that result in orders of magnitude higher optimality gap, making it difficult to trust the predictions in practice. This paper aims at striking a balance between classical solvers and optimization proxies in order to enable trustworthy deployments with interpretable speed-optimality tradeoffs based on a user-defined optimality threshold. To this end, the paper proposes a hybrid solver that leverages duality theory to efficiently bound the optimality gap of predictions, falling back to a classical solver for queries where optimality cannot be certified. To improve the achieved speedup of the hybrid solver, the paper proposes an alternative training procedure that combines the primal and dual proxy training. Experiments on large-scale transmission systems show that the hybrid solver is highly scalable. The proposed hybrid solver achieves speedups of over 1000x compared to a parallelized simplex-based solver while guaranteeing a maximum optimality gap of 2%.",
        "subjects": "Machine Learning, Artificial Intelligence, Optimization and Control",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.320754"
    },
    {
        "index": "#2",
        "title": "Learning Correlated Reward Models: Statistical Barriers and Opportunities",
        "link": "/arxiv/2510.15839",
        "arxiv_id": "2510.15839",
        "authors": "Yeshwanth Cherapanamjeri, Constantinos Daskalakis, Gabriele Farina, Sobhan Mohammadpour",
        "summary": "Random Utility Models (RUMs) are a classical framework for modeling user preferences and play a key role in reward modeling for Reinforcement Learning from Human Feedback (RLHF). However, a crucial shortcoming of many of these techniques is the Independence of Irrelevant Alternatives (IIA) assumption, which collapses \\emph{all} human preferences to a universal underlying utility function, yielding a coarse approximation of the range of human preferences. On the other hand, statistical and computational guarantees for models avoiding this assumption are scarce. In this paper, we investigate the statistical and computational challenges of learning a \\emph{correlated} probit model, a fundamental RUM that avoids the IIA assumption. First, we establish that the classical data collection paradigm of pairwise preference data is \\emph{fundamentally insufficient} to learn correlational information, explaining the lack of statistical and computational guarantees in this setting. Next, we demonstrate that \\emph{best-of-three} preference data provably overcomes these shortcomings, and devise a statistically and computationally efficient estimator with near-optimal performance. These results highlight the benefits of higher-order preference data in learning correlated utilities, allowing for more fine-grained modeling of human preferences. Finally, we validate these theoretical guarantees on several real-world datasets, demonstrating improved personalization of human preferences.",
        "subjects": "Machine Learning, Econometrics, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.321119"
    },
    {
        "index": "#3",
        "title": "Transfer Orthology Networks",
        "link": "/arxiv/2510.15837",
        "arxiv_id": "2510.15837",
        "authors": "Vikash Singh",
        "summary": "We present Transfer Orthology Networks (TRON), a novel neural network architecture designed for cross-species transfer learning. TRON leverages orthologous relationships, represented as a bipartite graph between species, to guide knowledge transfer. Specifically, we prepend a learned species conversion layer, whose weights are masked by the biadjacency matrix of this bipartite graph, to a pre-trained feedforward neural network that predicts a phenotype from gene expression data in a source species. This allows for efficient transfer of knowledge to a target species by learning a linear transformation that maps gene expression from the source to the target species' gene space. The learned weights of this conversion layer offer a potential avenue for interpreting functional orthology, providing insights into how genes across species contribute to the phenotype of interest. TRON offers a biologically grounded and interpretable approach to cross-species transfer learning, paving the way for more effective utilization of available transcriptomic data. We are in the process of collecting cross-species transcriptomic/phenotypic data to gain experimental validation of the TRON architecture.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.321394"
    },
    {
        "index": "#4",
        "title": "FIDDLE: Reinforcement Learning for Quantum Fidelity Enhancement",
        "link": "/arxiv/2510.15833",
        "arxiv_id": "2510.15833",
        "authors": "Hoang M. Ngo, Tamer Kahveci, My T. Thai",
        "summary": "Quantum computing has the potential to revolutionize fields like quantum optimization and quantum machine learning. However, current quantum devices are hindered by noise, reducing their reliability. A key challenge in gate-based quantum computing is improving the reliability of quantum circuits, measured by process fidelity, during the transpilation process, particularly in the routing stage. In this paper, we address the Fidelity Maximization in Routing Stage (FMRS) problem by introducing FIDDLE, a novel learning framework comprising two modules: a Gaussian Process-based surrogate model to estimate process fidelity with limited training samples and a reinforcement learning module to optimize routing. Our approach is the first to directly maximize process fidelity, outperforming traditional methods that rely on indirect metrics such as circuit depth or gate count. We rigorously evaluate FIDDLE by comparing it with state-of-the-art fidelity estimation techniques and routing optimization methods. The results demonstrate that our proposed surrogate model is able to provide a better estimation on the process fidelity compared to existing learning techniques, and our end-to-end framework significantly improves the process fidelity of quantum circuits across various noise models.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.321689"
    },
    {
        "index": "#5",
        "title": "SNOO: Step-K Nesterov Outer Optimizer - The Surprising Effectiveness of Nesterov Momentum Applied to Pseudo-Gradients",
        "link": "/arxiv/2510.15830",
        "arxiv_id": "2510.15830",
        "authors": "Dominik Kallusky, Vinay Rao, Vishal Nandavanam, Hao-Jun Michael Shi",
        "summary": "The rapid development of large language models (LLMs) has driven the demand for more efficient optimization techniques. Among these, the Lookahead family of optimizers employs a two-loop framework, maintaining fast and slow sets of model weights. Multiple inner optimizer steps on the fast weights produce a trajectory - the pseudo-gradient - that is used to update the slow weights. DiLoCo, a notable example originally designed for distributed training, applies Nesterov momentum to the averaged pseudo-gradient from multiple workers, claiming to even outperform AdamW in a non-distributed setup. In this paper, we empirically show that DiLoCo's surprising effectiveness stems primarily from applying Nesterov momentum to the pseudo-gradient, which improves training in a non-distributed setting. We call this Lookahead variant the Step-$K$ Nesterov Outer Optimizer (SNOO). We demonstrate that SNOO achieves compute factor gains of 1.5 - 2.5$\\times$ in a non-distributed setting up to a scale of 1e23 training FLOPs, with improvements that increase with model size. Because of its minimal compute and memory overhead and compatibility with model sharding, SNOO is a practical enhancement for a variety of inner optimizers, including AdamW and Muon.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.322003"
    },
    {
        "index": "#6",
        "title": "Chronos-2: From Univariate to Universal Forecasting",
        "link": "/arxiv/2510.15821",
        "arxiv_id": "2510.15821",
        "authors": "Abdul Fatir Ansari, Oleksandr Shchur, Jaris Küken, Andreas Auer, Boran Han, Pedro Mercado, Syama Sundar Rangapuram, Huibin Shen, Lorenzo Stella, Xiyuan Zhang, Mononito Goswami, Shubham Kapoor, Danielle C. Maddix, Pablo Guerron, Tony Hu, Junming Yin, Nick Erickson, Prateek Mutalik Desai, Hao Wang, Huzefa Rangwala, George Karypis, Yuyang Wang, Michael Bohlke-Schneider",
        "summary": "Pretrained time series models have enabled inference-only forecasting systems that produce accurate predictions without task-specific training. However, existing approaches largely focus on univariate forecasting, limiting their applicability in real-world scenarios where multivariate data and covariates play a crucial role. We present Chronos-2, a pretrained model capable of handling univariate, multivariate, and covariate-informed forecasting tasks in a zero-shot manner. Chronos-2 employs a group attention mechanism that facilitates in-context learning (ICL) through efficient information sharing across multiple time series within a group, which may represent sets of related series, variates of a multivariate series, or targets and covariates in a forecasting task. These general capabilities are achieved through training on synthetic datasets that impose diverse multivariate structures on univariate series. Chronos-2 delivers state-of-the-art performance across three comprehensive benchmarks: fev-bench, GIFT-Eval, and Chronos Benchmark II. On fev-bench, which emphasizes multivariate and covariate-informed forecasting, Chronos-2's universal ICL capabilities lead to substantial improvements over existing models. On tasks involving covariates, it consistently outperforms baselines by a wide margin. Case studies in the energy and retail domains further highlight its practical advantages. The in-context learning capabilities of Chronos-2 establish it as a general-purpose forecasting model that can be used \"as is\" in real-world forecasting pipelines.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.322525"
    },
    {
        "index": "#7",
        "title": "AB-UPT for Automotive and Aerospace Applications",
        "link": "/arxiv/2510.15808",
        "arxiv_id": "2510.15808",
        "authors": "Benedikt Alkin, Richard Kurle, Louis Serrano, Dennis Just, Johannes Brandstetter",
        "summary": "The recently proposed Anchored-Branched Universal Physics Transformers (AB-UPT) shows strong capabilities to replicate automotive computational fluid dynamics simulations requiring orders of magnitudes less compute than traditional numerical solvers. In this technical report, we add two new datasets to the body of empirically evaluated use-cases of AB-UPT, combining high-quality data generation with state-of-the-art neural surrogates. Both datasets were generated with the Luminary Cloud platform containing automotives (SHIFT-SUV) and aircrafts (SHIFT-Wing). We start by detailing the data generation. Next, we show favorable performances of AB-UPT against previous state-of-the-art transformer-based baselines on both datasets, followed by extensive qualitative and quantitative evaluations of our best AB-UPT model. AB-UPT shows strong performances across the board. Notably, it obtains near perfect prediction of integrated aerodynamic forces within seconds from a simple isotopically tesselate geometry representation and is trainable within a day on a single GPU, paving the way for industry-scale applications.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.322852"
    },
    {
        "index": "#8",
        "title": "Cavity Duplexer Tuning with 1d Resnet-like Neural Networks",
        "link": "/arxiv/2510.15796",
        "arxiv_id": "2510.15796",
        "authors": "Anton Raskovalov",
        "summary": "This paper presents machine learning method for tuning of cavity duplexer with a large amount of adjustment screws. After testing we declined conventional reinforcement learning approach and reformulated our task in the supervised learning setup. The suggested neural network architecture includes 1d ResNet-like backbone and processing of some additional information about S-parameters, like the shape of curve and peaks positions and amplitudes. This neural network with external control algorithm is capable to reach almost the tuned state of the duplexer within 4-5 rotations per screw.",
        "subjects": "Machine Learning, Systems and Control",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.323136"
    },
    {
        "index": "#9",
        "title": "Poultry Farm Intelligence: An Integrated Multi-Sensor AI Platform for Enhanced Welfare and Productivity",
        "link": "/arxiv/2510.15757",
        "arxiv_id": "2510.15757",
        "authors": "Pieris Panagi, Savvas Karatsiolis, Kyriacos Mosphilis, Nicholas Hadjisavvas, Andreas Kamilaris, Nicolas Nicolaou, Efstathios Stavrakis, Vassilis Vassiliades",
        "summary": "Poultry farming faces increasing pressure to meet productivity targets while ensuring animal welfare and environmental compliance. Yet many small and medium-sized farms lack affordable, integrated tools for continuous monitoring and decision-making, relying instead on manual, reactive inspections. This paper presents Poultry Farm Intelligence (PoultryFI) - a modular, cost-effective platform that integrates six AI-powered modules: Camera Placement Optimizer, Audio-Visual Monitoring, Analytics & Alerting, Real-Time Egg Counting, Production & Profitability Forecasting, and a Recommendation Module. Camera layouts are first optimized offline using evolutionary algorithms for full poultry house coverage with minimal hardware. The Audio-Visual Monitoring module extracts welfare indicators from synchronized video, audio, and feeding data. Analytics & Alerting produces daily summaries and real-time notifications, while Real-Time Egg Counting uses an edge vision model to automate production tracking. Forecasting models predict egg yield and feed consumption up to 10 days in advance, and the Recommendation Module integrates forecasts with weather data to guide environmental and operational adjustments. This is among the first systems to combine low-cost sensing, edge analytics, and prescriptive AI to continuously monitor flocks, predict production, and optimize performance. Field trials demonstrate 100% egg-count accuracy on Raspberry Pi 5, robust anomaly detection, and reliable short-term forecasting. PoultryFI bridges the gap between isolated pilot tools and scalable, farm-wide intelligence, empowering producers to proactively safeguard welfare and profitability.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Neural and Evolutionary Computing",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.323498"
    },
    {
        "index": "#10",
        "title": "SAMix: Calibrated and Accurate Continual Learning via Sphere-Adaptive Mixup and Neural Collapse",
        "link": "/arxiv/2510.15751",
        "arxiv_id": "2510.15751",
        "authors": "Trung-Anh Dang, Vincent Nguyen, Ngoc-Son Vu, Christel Vrain",
        "summary": "While most continual learning methods focus on mitigating forgetting and improving accuracy, they often overlook the critical aspect of network calibration, despite its importance. Neural collapse, a phenomenon where last-layer features collapse to their class means, has demonstrated advantages in continual learning by reducing feature-classifier misalignment. Few works aim to improve the calibration of continual models for more reliable predictions. Our work goes a step further by proposing a novel method that not only enhances calibration but also improves performance by reducing overconfidence, mitigating forgetting, and increasing accuracy. We introduce Sphere-Adaptive Mixup (SAMix), an adaptive mixup strategy tailored for neural collapse-based methods. SAMix adapts the mixing process to the geometric properties of feature spaces under neural collapse, ensuring more robust regularization and alignment. Experiments show that SAMix significantly boosts performance, surpassing SOTA methods in continual learning while also improving model calibration. SAMix enhances both across-task accuracy and the broader reliability of predictions, making it a promising advancement for robust continual learning systems.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.323810"
    },
    {
        "index": "#11",
        "title": "A Comprehensive Evaluation of Graph Neural Networks and Physics Informed Learning for Surrogate Modelling of Finite Element Analysis",
        "link": "/arxiv/2510.15750",
        "arxiv_id": "2510.15750",
        "authors": "Nayan Kumar Singh",
        "summary": "Although Finite Element Analysis (FEA) is an integral part of the product design lifecycle, the analysis is computationally expensive, making it unsuitable for many design optimization problems. The deep learning models can be a great solution. However, selecting the architecture that emulates the FEA with great accuracy is a challenge. This paper presents a comprehensive evaluation of graph neural networks (GNNs) and 3D U-Nets as surrogates for FEA of parametric I-beams. We introduce a Physics-Informed Neural Network (PINN) framework, governed by the Navier Cauchy equations, to enforce physical laws. Crucially, we demonstrate that a curriculum learning strategy, pretraining on data followed by physics informed fine tuning, is essential for stabilizing training. Our results show that GNNs fundamentally outperform the U-Net. Even the worst performer among GNNs, the GCN framework, achieved a relative L2 error of 8.7% while the best framework among U Net, U Net with attention mechanism trained on high resolution data, achieved 13.0% score. Among the graph-based architectures, the Message Passing Neural Networks (MPNN) and Graph Transformers achieved the highest accuracy, achieving a relative L2 score of 3.5% and 2.6% respectively. The inclusion of physics fundamental laws (PINN) significantly improved the generalization, reducing error by up to 11.3% on high-signal tasks. While the Graph Transformer is the most accurate model, it is more 37.5% slower during inference when compared to second best model, MPNN PINN. The PINN enhanced MPNN (MPNN PINN) provides the most practical solution. It offers a good compromise between predictive performance, model size, and inference speed.",
        "subjects": "Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.324083"
    },
    {
        "index": "#12",
        "title": "RLAF: Reinforcement Learning from Automaton Feedback",
        "link": "/arxiv/2510.15728",
        "arxiv_id": "2510.15728",
        "authors": "Mahyar Alinejad, Alvaro Velasquez, Yue Wang, George Atia",
        "summary": "Reinforcement Learning (RL) in environments with complex, history-dependent reward structures poses significant challenges for traditional methods. In this work, we introduce a novel approach that leverages automaton-based feedback to guide the learning process, replacing explicit reward functions with preferences derived from a deterministic finite automaton (DFA). Unlike conventional approaches that use automata for direct reward specification, our method employs the structure of the DFA to generate preferences over trajectories that are used to learn a reward function, eliminating the need for manual reward engineering. Our framework introduces a static approach that uses the learned reward function directly for policy optimization and a dynamic approach that involves continuous refining of the reward function and policy through iterative updates until convergence. Our experiments in both discrete and continuous environments demonstrate that our approach enables the RL agent to learn effective policies for tasks with temporal dependencies, outperforming traditional reward engineering and automaton-based baselines such as reward machines and LTL-guided methods. Our results highlight the advantages of automaton-based preferences in handling non-Markovian rewards, offering a scalable, efficient, and human-independent alternative to traditional reward modeling. We also provide a convergence guarantee showing that under standard assumptions our automaton-guided preference-based framework learns a policy that is near-optimal with respect to the true non-Markovian objective.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.324398"
    },
    {
        "index": "#13",
        "title": "ProSh: Probabilistic Shielding for Model-free Reinforcement Learning",
        "link": "/arxiv/2510.15720",
        "arxiv_id": "2510.15720",
        "authors": "Edwin Hamel-De le Court, Gaspard Ohlmann, Francesco Belardinelli",
        "summary": "Safety is a major concern in reinforcement learning (RL): we aim at developing RL systems that not only perform optimally, but are also safe to deploy by providing formal guarantees about their safety. To this end, we introduce Probabilistic Shielding via Risk Augmentation (ProSh), a model-free algorithm for safe reinforcement learning under cost constraints. ProSh augments the Constrained MDP state space with a risk budget and enforces safety by applying a shield to the agent's policy distribution using a learned cost critic. The shield ensures that all sampled actions remain safe in expectation. We also show that optimality is preserved when the environment is deterministic. Since ProSh is model-free, safety during training depends on the knowledge we have acquired about the environment. We provide a tight upper-bound on the cost in expectation, depending only on the backup-critic accuracy, that is always satisfied during training. Under mild, practically achievable assumptions, ProSh guarantees safety even at training time, as shown in the experiments.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.324700"
    },
    {
        "index": "#14",
        "title": "ProofOptimizer: Training Language Models to Simplify Proofs without Human Demonstrations",
        "link": "/arxiv/2510.15700",
        "arxiv_id": "2510.15700",
        "authors": "Alex Gu, Bartosz Piotrowski, Fabian Gloeckle, Kaiyu Yang, Aram H. Markosyan",
        "summary": "Neural theorem proving has advanced rapidly in the past year, reaching IMO gold-medalist capabilities and producing formal proofs that span thousands of lines. Although such proofs are mechanically verified by formal systems like Lean, their excessive length renders them difficult for humans to comprehend and limits their usefulness for mathematical insight. Proof simplification is therefore a critical bottleneck. Yet, training data for this task is scarce, and existing methods -- mainly agentic scaffolding with off-the-shelf LLMs -- struggle with the extremely long proofs generated by RL-trained provers. We introduce ProofOptimizer, the first language model trained to simplify Lean proofs without requiring additional human supervision. ProofOptimizer is trained via expert iteration and reinforcement learning, using Lean to verify simplifications and provide training signal. At inference time, it operates within an iterative proof-shortening workflow, progressively reducing proof length. Experiments show that ProofOptimizer substantially compresses proofs generated by state-of-the-art RL-trained provers on standard benchmarks, reducing proof length by 87% on miniF2F, 57% on PutnamBench, and 49% on Seed-Prover's IMO 2025 proofs. Beyond conciseness, the simplified proofs check faster in Lean and further improve downstream prover performance when reused as training data for supervised finetuning.",
        "subjects": "Machine Learning, Artificial Intelligence, Programming Languages",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.325043"
    },
    {
        "index": "#15",
        "title": "Constrained Adversarial Perturbation",
        "link": "/arxiv/2510.15699",
        "arxiv_id": "2510.15699",
        "authors": "Virendra Nishad, Bhaskar Mukhoty, Hilal AlQuabeh, Sandeep K. Shukla, Sayak Ray Chowdhury",
        "summary": "Deep neural networks have achieved remarkable success in a wide range of classification tasks. However, they remain highly susceptible to adversarial examples - inputs that are subtly perturbed to induce misclassification while appearing unchanged to humans. Among various attack strategies, Universal Adversarial Perturbations (UAPs) have emerged as a powerful tool for both stress testing model robustness and facilitating scalable adversarial training. Despite their effectiveness, most existing UAP methods neglect domain specific constraints that govern feature relationships. Violating such constraints, such as debt to income ratios in credit scoring or packet flow invariants in network communication, can render adversarial examples implausible or easily detectable, thereby limiting their real world applicability. In this work, we advance universal adversarial attacks to constrained feature spaces by formulating an augmented Lagrangian based min max optimization problem that enforces multiple, potentially complex constraints of varying importance. We propose Constrained Adversarial Perturbation (CAP), an efficient algorithm that solves this problem using a gradient based alternating optimization strategy. We evaluate CAP across diverse domains including finance, IT networks, and cyber physical systems, and demonstrate that it achieves higher attack success rates while significantly reducing runtime compared to existing baselines. Our approach also generalizes seamlessly to individual adversarial perturbations, where we observe similar strong performance gains. Finally, we introduce a principled procedure for learning feature constraints directly from data, enabling broad applicability across domains with structured input spaces.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.330537"
    },
    {
        "index": "#16",
        "title": "KS-Net: Multi-layer network model for determining the rotor type from motor parameters in interior PMSMs",
        "link": "/arxiv/2510.15688",
        "arxiv_id": "2510.15688",
        "authors": "Kivanc Dogan, Ahmet Orhan",
        "summary": "The demand for high efficiency and precise control in electric drive systems has led to the widespread adoption of Interior Permanent Magnet Synchronous Motors (IPMSMs). The performance of these motors is significantly influenced by rotor geometry. Traditionally, rotor shape analysis has been conducted using the finite element method (FEM), which involves high computational costs. This study aims to classify the rotor shape (2D type, V type, Nabla type) of IPMSMs using electromagnetic parameters through machine learning-based methods and to demonstrate the applicability of this approach as an alternative to classical methods. In this context, a custom deep learning model, KS-Net, developed by the user, was comparatively evaluated against Cubic SVM, Quadratic SVM, Fine KNN, Cosine KNN, and Fine Tree algorithms. The balanced dataset, consisting of 9,000 samples, was tested using 10-fold cross-validation, and performance metrics such as accuracy, precision, recall, and F1-score were employed. The results indicate that the Cubic SVM and Quadratic SVM algorithms classified all samples flawlessly, achieving 100% accuracy, while the KS-Net model achieved 99.98% accuracy with only two misclassifications, demonstrating competitiveness with classical methods. This study shows that the rotor shape of IPMSMs can be predicted with high accuracy using data-driven approaches, offering a fast and cost-effective alternative to FEM-based analyses. The findings provide a solid foundation for accelerating motor design processes, developing automated rotor identification systems, and enabling data-driven fault diagnosis in engineering applications.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.330911"
    },
    {
        "index": "#17",
        "title": "CarBoN: Calibrated Best-of-N Sampling Improves Test-time Reasoning",
        "link": "/arxiv/2510.15674",
        "arxiv_id": "2510.15674",
        "authors": "Yung-Chen Tang, Pin-Yu Chen, Andrea Cavallaro",
        "summary": "Allocating more computation during inference time (test-time scaling) improves language model performance, especially for reasoning tasks. However, popular methods like Best-of-$N$ sampling often show diminishing returns as $N$ increases. To address this inefficiency, we introduce a general test-time calibration framework that adaptively modifies the model toward high-reward reasoning paths, with theoretical guarantees of improving the lower bound of expected reward under finite sampling, all without large language model (LLM) retraining. Within this framework, we propose CarBoN (Calibrated Best-of-$N$), a two-phase method that first explores the solution space and then learns a calibration of the logits via an input-specific temperature $T$ and additive shift vector $\\delta$, guiding generation toward more reliable reasoning. Experiments on MATH-500 and AIME-2024 show that CarBoN improves efficiency, with up to $4\\times$ fewer rollouts to reach the same accuracy, while often achieving higher accuracy under fixed budgets. We also analyze the complementary roles of $T$ and $\\delta$ in balancing output diversity and correctness, and demonstrate that the framework also generalizes to step-level sampling strategies such as beam search. For more information, please refer to our project page at huggingface.co/spaces/TrustSafeAI/Test-Time-Calibration.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.331290"
    },
    {
        "index": "#18",
        "title": "WARP-LUTs - Walsh-Assisted Relaxation for Probabilistic Look Up Tables",
        "link": "/arxiv/2510.15655",
        "arxiv_id": "2510.15655",
        "authors": "Lino Gerlach, Liv Våge, Thore Gerlach, Elliott Kauffman",
        "summary": "Fast and efficient machine learning is of growing interest to the scientific community and has spurred significant research into novel model architectures and hardware-aware design. Recent hard? and software co-design approaches have demonstrated impressive results with entirely multiplication-free models. Differentiable Logic Gate Networks (DLGNs), for instance, provide a gradient-based framework for learning optimal combinations of low-level logic gates, setting state-of-the-art trade-offs between accuracy, resource usage, and latency. However, these models suffer from high computational cost during training and do not generalize well to logic blocks with more inputs. In this work, we introduce Walsh-Assisted Relaxation for Probabilistic Look-Up Tables (WARP-LUTs) - a novel gradient-based method that efficiently learns combinations of logic gates with substantially fewer trainable parameters. We demonstrate that WARP-LUTs achieve significantly faster convergence on CIFAR-10 compared to DLGNs, while maintaining comparable accuracy. Furthermore, our approach suggests potential for extension to higher-input logic blocks, motivating future research on extremely efficient deployment on modern FPGAs and its real-time science applications.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.331656"
    },
    {
        "index": "#19",
        "title": "Fast and Compact Tsetlin Machine Inference on CPUs Using Instruction-Level Optimization",
        "link": "/arxiv/2510.15653",
        "arxiv_id": "2510.15653",
        "authors": "Yefan Zeng, Shengyu Duan, Rishad Shafik, Alex Yakovlev",
        "summary": "The Tsetlin Machine (TM) offers high-speed inference on resource-constrained devices such as CPUs. Its logic-driven operations naturally lend themselves to parallel execution on modern CPU architectures. Motivated by this, we propose an efficient software implementation of the TM by leveraging instruction-level bitwise operations for compact model representation and accelerated processing. To further improve inference speed, we introduce an early exit mechanism, which exploits the TM's AND-based clause evaluation to avoid unnecessary computations. Building upon this, we propose a literal Reorder strategy designed to maximize the likelihood of early exits. This strategy is applied during a post-training, pre-inference stage through statistical analysis of all literals and the corresponding actions of their associated Tsetlin Automata (TA), introducing negligible runtime overhead. Experimental results using the gem5 simulator with an ARM processor show that our optimized implementation reduces inference time by up to 96.71% compared to the conventional integer-based TM implementations while maintaining comparable code density.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.332045"
    },
    {
        "index": "#20",
        "title": "Deep Neural ODE Operator Networks for PDEs",
        "link": "/arxiv/2510.15651",
        "arxiv_id": "2510.15651",
        "authors": "Ziqian Li, Kang Liu, Yongcun Song, Hangrui Yue, Enrique Zuazua",
        "summary": "Operator learning has emerged as a promising paradigm for developing efficient surrogate models to solve partial differential equations (PDEs). However, existing approaches often overlook the domain knowledge inherent in the underlying PDEs and hence suffer from challenges in capturing temporal dynamics and generalization issues beyond training time frames. This paper introduces a deep neural ordinary differential equation (ODE) operator network framework, termed NODE-ONet, to alleviate these limitations. The framework adopts an encoder-decoder architecture comprising three core components: an encoder that spatially discretizes input functions, a neural ODE capturing latent temporal dynamics, and a decoder reconstructing solutions in physical spaces. Theoretically, error analysis for the encoder-decoder architecture is investigated. Computationally, we propose novel physics-encoded neural ODEs to incorporate PDE-specific physical properties. Such well-designed neural ODEs significantly reduce the framework's complexity while enhancing numerical efficiency, robustness, applicability, and generalization capacity. Numerical experiments on nonlinear diffusion-reaction and Navier-Stokes equations demonstrate high accuracy, computational efficiency, and prediction capabilities beyond training time frames. Additionally, the framework's flexibility to accommodate diverse encoders/decoders and its ability to generalize across related PDE families further underscore its potential as a scalable, physics-encoded tool for scientific machine learning.",
        "subjects": "Machine Learning, Numerical Analysis, Optimization and Control",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.332468"
    },
    {
        "index": "#21",
        "title": "Decentralized Parameter-Free Online Learning",
        "link": "/arxiv/2510.15644",
        "arxiv_id": "2510.15644",
        "authors": "Tomas Ortega, Hamid Jafarkhani",
        "summary": "We propose the first parameter-free decentralized online learning algorithms with network regret guarantees, which achieve sublinear regret without requiring hyperparameter tuning. This family of algorithms connects multi-agent coin-betting and decentralized online learning via gossip steps. To enable our decentralized analysis, we introduce a novel \"betting function\" formulation for coin-betting that simplifies the multi-agent regret analysis. Our analysis shows sublinear network regret bounds and is validated through experiments on synthetic and real datasets. This family of algorithms is applicable to distributed sensing, decentralized optimization, and collaborative ML applications.",
        "subjects": "Machine Learning, Signal Processing, Optimization and Control",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.332853"
    },
    {
        "index": "#22",
        "title": "CQD-SHAP: Explainable Complex Query Answering via Shapley Values",
        "link": "/arxiv/2510.15623",
        "arxiv_id": "2510.15623",
        "authors": "Parsa Abbasi, Stefan Heindorf",
        "summary": "Complex query answering (CQA) goes beyond the well-studied link prediction task by addressing more sophisticated queries that require multi-hop reasoning over incomplete knowledge graphs (KGs). Research on neural and neurosymbolic CQA methods is still an emerging field. Almost all of these methods can be regarded as black-box models, which may raise concerns about user trust. Although neurosymbolic approaches like CQD are slightly more interpretable, allowing intermediate results to be tracked, the importance of different parts of the query remains unexplained. In this paper, we propose CQD-SHAP, a novel framework that computes the contribution of each query part to the ranking of a specific answer. This contribution explains the value of leveraging a neural predictor that can infer new knowledge from an incomplete KG, rather than a symbolic approach relying solely on existing facts in the KG. CQD-SHAP is formulated based on Shapley values from cooperative game theory and satisfies all the fundamental Shapley axioms. Automated evaluation of these explanations in terms of necessary and sufficient explanations, and comparisons with various baselines, shows the effectiveness of this approach for most query types.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.333212"
    },
    {
        "index": "#23",
        "title": "GRATING: Low-Latency and Memory-Efficient Semantic Selection on Device",
        "link": "/arxiv/2510.15620",
        "arxiv_id": "2510.15620",
        "authors": "Jiahao Zhou, Chengliang Lin, Dingji Li, Mingkai Dong, Haibo Chen",
        "summary": "Semantic top-K selection with cross-encoder rerankers underpins of on-device AI services, such as retrieval-augmented generation, agent memory, and personalized recommendation. However, its latency and memory demands dominate end-to-end budgets on edge hardware. Revisiting the objective of top-K selection, we reveal that only relative rankings matter, not exact per-candidate scores. We further observe sequence-level sparsity: relative rankings stabilize early in intermediate layers, allowing pruning opportunities prior to completing full inference. Building on this insight, we propose monolithic forwarding and develop a training-free inference system, GRATING. By maintaining a global view of all candidates, it reduces latency through progressive cluster pruning. It also bounds peak memory usage by strategically overlapping I/O with computation via dual-layer sliding window and chunked execution. We evaluate GRATING against state-of-the-art baselines on rerankers from 0.6B to 8B parameters across Apple M2 and RTX 5070. GRATING consistently reduces latency by up to 89.0% and peak memory by up to 94.9% in microbenchmarks, without any loss in precision. Across three real-world on-device AI applications, GRATING lowers latency by 11.6%-51.0% and peak memory by 18.6%-77.8%, demonstrating substantial improvements in efficiency and deployability.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.333588"
    },
    {
        "index": "#24",
        "title": "Attn-JGNN: Attention Enhanced Join-Graph Neural Networks",
        "link": "/arxiv/2510.15583",
        "arxiv_id": "2510.15583",
        "authors": "Jixin Zhang, Yong Lai",
        "summary": "We propose an Attention Enhanced Join-Graph Neural Networks(Attn-JGNN) model for solving #SAT problems, which significantly improves the solving accuracy. Inspired by the Iterative Join Graph Propagation (IJGP) algorithm, Attn-JGNN uses tree decomposition to encode the CNF formula into a join-graph, then performs iterative message passing on the join-graph, and finally approximates the model number by learning partition functions. In order to further improve the accuracy of the solution, we apply the attention mechanism in and between clusters of the join-graphs, which makes Attn-JGNN pay more attention to the key variables and clusters in probabilistic inference, and reduces the redundant calculation. Finally, our experiments show that our Attn-JGNN model achieves better results than other neural network methods.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.333926"
    },
    {
        "index": "#25",
        "title": "On the Neural Feature Ansatz for Deep Neural Networks",
        "link": "/arxiv/2510.15563",
        "arxiv_id": "2510.15563",
        "authors": "Edward Tansley, Estelle Massart, Coralia Cartis",
        "summary": "Understanding feature learning is an important open question in establishing a mathematical foundation for deep neural networks. The Neural Feature Ansatz (NFA) states that after training, the Gram matrix of the first-layer weights of a deep neural network is proportional to some power $\\alpha>0$ of the average gradient outer product (AGOP) of this network with respect to its inputs. Assuming gradient flow dynamics with balanced weight initialization, the NFA was proven to hold throughout training for two-layer linear networks with exponent $\\alpha = 1/2$ (Radhakrishnan et al., 2024). We extend this result to networks with $L \\geq 2$ layers, showing that the NFA holds with exponent $\\alpha = 1/L$, thus demonstrating a depth dependency of the NFA. Furthermore, we prove that for unbalanced initialization, the NFA holds asymptotically through training if weight decay is applied. We also provide counterexamples showing that the NFA does not hold for some network architectures with nonlinear activations, even when these networks fit arbitrarily well the training data. We thoroughly validate our theoretical results through numerical experiments across a variety of optimization algorithms, weight decay rates and initialization schemes.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.334283"
    },
    {
        "index": "#26",
        "title": "Doubly Robust Estimation of Causal Effects in Strategic Equilibrium Systems",
        "link": "/arxiv/2510.15555",
        "arxiv_id": "2510.15555",
        "authors": "Sibo Xiao",
        "summary": "We introduce the Strategic Doubly Robust (SDR) estimator, a novel framework that integrates strategic equilibrium modeling with doubly robust estimation for causal inference in strategic environments. SDR addresses endogenous treatment assignment arising from strategic agent behavior, maintaining double robustness while incorporating strategic considerations. Theoretical analysis confirms SDR's consistency and asymptotic normality under strategic unconfoundedness. Empirical evaluations demonstrate SDR's superior performance over baseline methods, achieving 7.6\\%-29.3\\% bias reduction across varying strategic strengths and maintaining robust scalability with agent populations. The framework provides a principled approach for reliable causal inference when agents respond strategically to interventions.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.334607"
    },
    {
        "index": "#27",
        "title": "An Empirical Study on MC Dropout--Based Uncertainty--Error Correlation in 2D Brain Tumor Segmentation",
        "link": "/arxiv/2510.15541",
        "arxiv_id": "2510.15541",
        "authors": "Saumya B",
        "summary": "Accurate brain tumor segmentation from MRI is vital for diagnosis and treatment planning. Although Monte Carlo (MC) Dropout is widely used to estimate model uncertainty, its effectiveness in identifying segmentation errors -- especially near tumor boundaries -- remains unclear. This study empirically examines the relationship between MC Dropout--based uncertainty and segmentation error in 2D brain tumor MRI segmentation using a U-Net trained under four augmentation settings: none, horizontal flip, rotation, and scaling. Uncertainty was computed from 50 stochastic forward passes and correlated with pixel-wise errors using Pearson and Spearman coefficients. Results show weak global correlations ($r \\approx 0.30$--$0.38$) and negligible boundary correlations ($|r| < 0.05$). Although differences across augmentations were statistically significant ($p < 0.001$), they lacked practical relevance. These findings suggest that MC Dropout uncertainty provides limited cues for boundary error localization, underscoring the need for alternative or hybrid uncertainty estimation methods in medical image segmentation.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Image and Video Processing",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.334978"
    },
    {
        "index": "#28",
        "title": "Compressive Modeling and Visualization of Multivariate Scientific Data using Implicit Neural Representation",
        "link": "/arxiv/2510.15535",
        "arxiv_id": "2510.15535",
        "authors": "Abhay Kumar Dwivedi, Shanu Saklani, Soumya Dutta",
        "summary": "The extensive adoption of Deep Neural Networks has led to their increased utilization in challenging scientific visualization tasks. Recent advancements in building compressed data models using implicit neural representations have shown promising results for tasks like spatiotemporal volume visualization and super-resolution. Inspired by these successes, we develop compressed neural representations for multivariate datasets containing tens to hundreds of variables. Our approach utilizes a single network to learn representations for all data variables simultaneously through parameter sharing. This allows us to achieve state-of-the-art data compression. Through comprehensive evaluations, we demonstrate superior performance in terms of reconstructed data quality, rendering and visualization quality, preservation of dependency information among variables, and storage efficiency.",
        "subjects": "Machine Learning, Graphics",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.340470"
    },
    {
        "index": "#29",
        "title": "Revisiting Knowledge Distillation: The Hidden Role of Dataset Size",
        "link": "/arxiv/2510.15516",
        "arxiv_id": "2510.15516",
        "authors": "Giulia Lanzillotta, Felix Sarnthein, Gil Kur, Thomas Hofmann, Bobby He",
        "summary": "The concept of knowledge distillation (KD) describes the training of a student model from a teacher model and is a widely adopted technique in deep learning. However, it is still not clear how and why distillation works. Previous studies focus on two central aspects of distillation: model size, and generalisation. In this work we study distillation in a third dimension: dataset size. We present a suite of experiments across a wide range of datasets, tasks and neural architectures, demonstrating that the effect of distillation is not only preserved but amplified in low-data regimes. We call this newly discovered property the data efficiency of distillation. Equipped with this new perspective, we test the predictive power of existing theories of KD as we vary the dataset size. Our results disprove the hypothesis that distillation can be understood as label smoothing, and provide further evidence in support of the dark knowledge hypothesis. Finally, we analyse the impact of modelling factors such as the objective, scale and relative number of samples on the observed phenomenon. Ultimately, this work reveals that the dataset size may be a fundamental but overlooked variable in the mechanisms underpinning distillation.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.340893"
    },
    {
        "index": "#30",
        "title": "Language Models are Injective and Hence Invertible",
        "link": "/arxiv/2510.15511",
        "arxiv_id": "2510.15511",
        "authors": "Giorgos Nikolaou, Tommaso Mencattini, Donato Crisostomi, Andrea Santilli, Yannis Panagakis, Emanuele Rodola'",
        "summary": "Transformer components such as non-linear activations and normalization are inherently non-injective, suggesting that different inputs could map to the same output and prevent exact recovery of the input from a model's representations. In this paper, we challenge this view. First, we prove mathematically that transformer language models mapping discrete input sequences to their corresponding sequence of continuous representations are injective and therefore lossless, a property established at initialization and preserved during training. Second, we confirm this result empirically through billions of collision tests on six state-of-the-art language models, and observe no collisions. Third, we operationalize injectivity: we introduce SipIt, the first algorithm that provably and efficiently reconstructs the exact input text from hidden activations, establishing linear-time guarantees and demonstrating exact invertibility in practice. Overall, our work establishes injectivity as a fundamental and exploitable property of language models, with direct implications for transparency, interpretability, and safe deployment.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.341296"
    },
    {
        "index": "#31",
        "title": "Theoretical Refinement of CLIP by Utilizing Linear Structure of Optimal Similarity",
        "link": "/arxiv/2510.15508",
        "arxiv_id": "2510.15508",
        "authors": "Naoki Yoshida, Satoshi Hayakawa, Yuhta Takida, Toshimitsu Uesaka, Hiromi Wakaki, Yuki Mitsufuji",
        "summary": "In this study, we propose an enhancement to the similarity computation mechanism in multi-modal contrastive pretraining frameworks such as CLIP. Prior theoretical research has demonstrated that the optimal similarity metrics between paired modalities should correspond to the pointwise mutual information (PMI) between the two modalities. However, the current implementations of CLIP and its variants fail to fully utilize the underlying linear structure of PMI. We therefore propose KME-CLIP, which leverages this structure through the inner product in a reproducing kernel Hilbert space. We theoretically prove that our method can approximate PMI with arbitrary accuracy and empirically demonstrate that our approach overall outperforms the standard CLIP formulation across several retrieval and classification tasks.",
        "subjects": "Machine Learning, Numerical Analysis, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.341714"
    },
    {
        "index": "#32",
        "title": "The Road Less Traveled: Enhancing Exploration in LLMs via Sequential Sampling",
        "link": "/arxiv/2510.15502",
        "arxiv_id": "2510.15502",
        "authors": "Shijia Kang, Muhan Zhang",
        "summary": "Reinforcement learning (RL) has been pivotal in enhancing the reasoning capabilities of large language models (LLMs), but it often suffers from limited exploration and entropy collapse, where models exploit a narrow set of solutions, leading to a loss of sampling diversity and subsequently preventing RL from further improving performance. This issue is exacerbated in parallel sampling methods, where multiple outputs are drawn from the same distribution, potentially causing the model to converge to similar solutions. We propose SESA, a novel SEquential SAmpling framework that mitigates this challenge by generating diverse solution sketches sequentially before expanding them into full reasoning paths. This approach ensures broader exploration by conditioning each new output on previous ones, promoting diversity throughout the process and preventing policy collapse. Our experiments on a synthetic task show that sequential sampling consistently outperforms traditional RL methods in terms of path diversity and recovery from collapse. Further evaluations on real-world tasks demonstrate that SESA improves both the exploration of valid strategies and the overall performance of LLMs. On three agent benchmarks, SESA lifts success rates by $+0.25$, $+0.42$, and $+0.07$ absolute over the base model (up to an additional $211\\%$ relative improvement over baseline RL), underscoring its exploration advantage. This work introduces a structured approach to exploration, paving the way for more effective and diverse reasoning in RL-trained LLMs. Our code is released at https://github.com/MuLabPKU/sesa.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.342072"
    },
    {
        "index": "#33",
        "title": "OffSim: Offline Simulator for Model-based Offline Inverse Reinforcement Learning",
        "link": "/arxiv/2510.15495",
        "arxiv_id": "2510.15495",
        "authors": "Woo-Jin Ahn, Sang-Ryul Baek, Yong-Jun Lee, Hyun-Duck Choi, Myo-Taeg Lim",
        "summary": "Reinforcement learning algorithms typically utilize an interactive simulator (i.e., environment) with a predefined reward function for policy training. Developing such simulators and manually defining reward functions, however, is often time-consuming and labor-intensive. To address this, we propose an Offline Simulator (OffSim), a novel model-based offline inverse reinforcement learning (IRL) framework, to emulate environmental dynamics and reward structure directly from expert-generated state-action trajectories. OffSim jointly optimizes a high-entropy transition model and an IRL-based reward function to enhance exploration and improve the generalizability of the learned reward. Leveraging these learned components, OffSim can subsequently train a policy offline without further interaction with the real environment. Additionally, we introduce OffSim$^+$, an extension that incorporates a marginal reward for multi-dataset settings to enhance exploration. Extensive MuJoCo experiments demonstrate that OffSim achieves substantial performance gains over existing offline IRL methods, confirming its efficacy and robustness.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.342457"
    },
    {
        "index": "#34",
        "title": "Adversary-Free Counterfactual Prediction via Information-Regularized Representations",
        "link": "/arxiv/2510.15479",
        "arxiv_id": "2510.15479",
        "authors": "Shiqin Tang, Rong Feng, Shuxin Zhuang, Hongzong Li, Youzhi Zhang",
        "summary": "We study counterfactual prediction under assignment bias and propose a mathematically grounded, information-theoretic approach that removes treatment-covariate dependence without adversarial training. Starting from a bound that links the counterfactual-factual risk gap to mutual information, we learn a stochastic representation Z that is predictive of outcomes while minimizing I(Z; T). We derive a tractable variational objective that upper-bounds the information term and couples it with a supervised decoder, yielding a stable, provably motivated training criterion. The framework extends naturally to dynamic settings by applying the information penalty to sequential representations at each decision time. We evaluate the method on controlled numerical simulations and a real-world clinical dataset, comparing against recent state-of-the-art balancing, reweighting, and adversarial baselines. Across metrics of likelihood, counterfactual error, and policy evaluation, our approach performs favorably while avoiding the training instabilities and tuning burden of adversarial schemes.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.342847"
    },
    {
        "index": "#35",
        "title": "Learning to Answer from Correct Demonstrations",
        "link": "/arxiv/2510.15464",
        "arxiv_id": "2510.15464",
        "authors": "Nirmit Joshi, Gene Li, Siddharth Bhandari, Shiva Prasad Kasiviswanathan, Cong Ma, Nathan Srebro",
        "summary": "We study the problem of learning to generate an answer (or completion) to a question (or prompt), where there could be multiple correct answers, any one of which is acceptable at test time. Learning is based on demonstrations of some correct answer to each training question, as in Supervised Fine Tuning (SFT). We formalize the problem as offline imitation learning in contextual bandits, with demonstrations from some optimal policy, without explicitly observed rewards. Prior work assumes that the demonstrator belongs to a low-complexity policy class, which motivates maximum likelihood estimation (i.e., log-loss minimization). In contrast, we propose relying only on the reward model (specifying which answers are correct) being in a low-cardinality class, which we argue is a weaker assumption. We show that likelihood maximization methods can fail in this case, and instead devise an alternative novel approach that learns with sample complexity logarithmic in the cardinality of the reward class. Our work motivates looking beyond likelihood maximization when learning from correct demonstrations.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.343273"
    },
    {
        "index": "#36",
        "title": "Expediting Reinforcement Learning by Incorporating Knowledge About Temporal Causality in the Environment",
        "link": "/arxiv/2510.15456",
        "arxiv_id": "2510.15456",
        "authors": "Jan Corazza, Hadi Partovi Aria, Daniel Neider, Zhe Xu",
        "summary": "Reinforcement learning (RL) algorithms struggle with learning optimal policies for tasks where reward feedback is sparse and depends on a complex sequence of events in the environment. Probabilistic reward machines (PRMs) are finite-state formalisms that can capture temporal dependencies in the reward signal, along with nondeterministic task outcomes. While special RL algorithms can exploit this finite-state structure to expedite learning, PRMs remain difficult to modify and design by hand. This hinders the already difficult tasks of utilizing high-level causal knowledge about the environment, and transferring the reward formalism into a new domain with a different causal structure. This paper proposes a novel method to incorporate causal information in the form of Temporal Logic-based Causal Diagrams into the reward formalism, thereby expediting policy learning and aiding the transfer of task specifications to new environments. Furthermore, we provide a theoretical result about convergence to optimal policy for our method, and demonstrate its strengths empirically.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.343655"
    },
    {
        "index": "#37",
        "title": "Particle Dynamics for Latent-Variable Energy-Based Models",
        "link": "/arxiv/2510.15447",
        "arxiv_id": "2510.15447",
        "authors": "Shiqin Tang, Shuxin Zhuang, Rong Feng, Runsheng Yu, Hongzong Li, Youzhi Zhang",
        "summary": "Latent-variable energy-based models (LVEBMs) assign a single normalized energy to joint pairs of observed data and latent variables, offering expressive generative modeling while capturing hidden structure. We recast maximum-likelihood training as a saddle problem over distributions on the latent and joint manifolds and view the inner updates as coupled Wasserstein gradient flows. The resulting algorithm alternates overdamped Langevin updates for a joint negative pool and for conditional latent particles with stochastic parameter ascent, requiring no discriminator or auxiliary networks. We prove existence and convergence under standard smoothness and dissipativity assumptions, with decay rates in KL divergence and Wasserstein-2 distance. The saddle-point view further yields an ELBO strictly tighter than bounds obtained with restricted amortized posteriors. Our method is evaluated on numerical approximations of physical systems and performs competitively against comparable approaches.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.344070"
    },
    {
        "index": "#38",
        "title": "A Theoretical Study on Bridging Internal Probability and Self-Consistency for LLM Reasoning",
        "link": "/arxiv/2510.15444",
        "arxiv_id": "2510.15444",
        "authors": "Zhi Zhou, Yuhao Tan, Zenan Li, Yuan Yao, Lan-Zhe Guo, Yu-Feng Li, Xiaoxing Ma",
        "summary": "Test-time scaling seeks to improve the reasoning performance of large language models (LLMs) by adding computational resources. A prevalent approach within the field is sampling-based test-time scaling methods, which enhance reasoning by generating multiple reasoning paths for a given input during inference. However, despite its practical success, the theoretical foundations remain underexplored. In this paper, we provide the first theoretical framework for analyzing sampling-based test-time scaling methods, grounded in the perspective of confidence estimation. Based on the framework, we analyze two dominant paradigms: self-consistency and perplexity, and reveal key limitations: self-consistency suffers from high estimation error while perplexity exhibits substantial modeling error and possible degradation of the estimation error convergence. To address these limitations, we introduce RPC, a hybrid method that leverages our theoretical insights through two key components: Perplexity Consistency and Reasoning Pruning. Perplexity Consistency combines the strengths of self-consistency and perplexity, boosting the convergence rate of estimation error from linear to exponential while preserving model error. Reasoning Pruning prevents degradation by eliminating low-probability reasoning paths. Both theoretical analysis and empirical results across seven benchmark datasets demonstrate that RPC has a strong potential for reducing reasoning error. Notably, RPC achieves reasoning performance comparable to self-consistency while not only enhancing confidence reliability but also reducing sampling costs by 50%. The code and resources are available at https://wnjxyk.github.io/RPC.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.344493"
    },
    {
        "index": "#39",
        "title": "Safe, Efficient, and Robust Reinforcement Learning for Ranking and Diffusion Models",
        "link": "/arxiv/2510.15429",
        "arxiv_id": "2510.15429",
        "authors": "Shashank Gupta",
        "summary": "This dissertation investigates how reinforcement learning (RL) methods can be designed to be safe, sample-efficient, and robust. Framed through the unifying perspective of contextual-bandit RL, the work addresses two major application domains - ranking and recommendation, and text-to-image diffusion models. The first part of the thesis develops theory and algorithms for safe deployment in ranking systems. An exposure-based generalisation bound is derived, leading to a counterfactual risk-minimisation objective whose solution is guaranteed not to underperform the logging policy, even with sparse feedback. This guarantee is extended to doubly robust estimators, enabling safety even under adversarial or misspecified user models and offering practitioners explicit control over permissible utility loss. The second part turns to single-action bandits, where various off-policy estimators are unified within a baseline-correction framework. A closed-form optimal baseline is proposed and shown to minimise both evaluation and policy-gradient variance, thereby improving off-policy learning reliability. The final part examines the trade-offs between efficiency and effectiveness in generative RL. A systematic study of PPO and REINFORCE motivates the Leave-One-Out PPO (LOOP) algorithm, which combines multiple diffusion trajectories with a REINFORCE-style baseline inside PPO's clipped objective. LOOP achieves PPO-level sample efficiency while producing generations that align more faithfully with textual attributes.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.344814"
    },
    {
        "index": "#40",
        "title": "ParaFormer: Shallow Parallel Transformers with Progressive Approximation",
        "link": "/arxiv/2510.15425",
        "arxiv_id": "2510.15425",
        "authors": "Wei Wang, Xiao-Yong Wei, Qing Li",
        "summary": "The widespread 'deeper is better' philosophy has driven the creation of architectures like ResNet and Transformer, which achieve high performance by stacking numerous layers. However, increasing model depth comes with challenges such as longer training times, higher inference latency, and impracticality on resource-constrained devices. To address these issues, we propose ParaFormer, a shallow Transformer architecture designed for true parallelism in both structure and computation. By formulating standard Transformers as function approximators in closed-form, our theoretical analysis shows that their performance relies on inter-layer collaboration for progressive approximation, rather than depth itself. While deep Transformers enforce this collaboration through sequential designs, we demonstrate that such collaboration is not inherently tied to sequential structures. ParaFormer removes the sequential constraint by organizing layers into parallel branches, enforcing inter-layer collaboration algorithmically. Specifically, we implement progressive approximation, ensuring that each new branch further reduces the loss from preceding branches, enabling faster convergence. Extensive experiments validate ParaFormer's effectiveness, outperforming standard Transformers like ViT. Moreover, ParaFormer supports up to 15.07x model compression and facilitates model expansion for adaptive continuous learning. Experimental results on multi-GPU deployment demonstrate that ParaFormer is 3.30x faster than widely used parallelism solutions such as FairScale. These advancements stem from our closed-form formulation of Transformers based on the Universal Approximation Theorem, which not only explains the ``depth belief'' but also opens new avenues for designing efficient Transformer architectures. Source code: https://(open-upon-acceptance)",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.345160"
    },
    {
        "index": "#41",
        "title": "Online Kernel Dynamic Mode Decomposition for Streaming Time Series Forecasting with Adaptive Windowing",
        "link": "/arxiv/2510.15404",
        "arxiv_id": "2510.15404",
        "authors": "Christopher Salazar, Krithika Manohar, Ashis G. Banerjee",
        "summary": "Real-time forecasting from streaming data poses critical challenges: handling non-stationary dynamics, operating under strict computational limits, and adapting rapidly without catastrophic forgetting. However, many existing approaches face trade-offs between accuracy, adaptability, and efficiency, particularly when deployed in constrained computing environments. We introduce WORK-DMD (Windowed Online Random Kernel Dynamic Mode Decomposition), a method that combines Random Fourier Features with online Dynamic Mode Decomposition to capture nonlinear dynamics through explicit feature mapping, while preserving fixed computational cost and competitive predictive accuracy across evolving data. WORK-DMD employs Sherman-Morrison updates within rolling windows, enabling continuous adaptation to evolving dynamics from only current data, eliminating the need for lengthy training or large storage requirements for historical data. Experiments on benchmark datasets across several domains show that WORK-DMD achieves higher accuracy than several state-of-the-art online forecasting methods, while requiring only a single pass through the data and demonstrating particularly strong performance in short-term forecasting. Our results show that combining kernel evaluations with adaptive matrix updates achieves strong predictive performance with minimal data requirements. This sample efficiency offers a practical alternative to deep learning for streaming forecasting applications.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.345505"
    },
    {
        "index": "#42",
        "title": "Geometric Mixture Models for Electrolyte Conductivity Prediction",
        "link": "/arxiv/2510.15403",
        "arxiv_id": "2510.15403",
        "authors": "Anyi Li, Jiacheng Cen, Songyou Li, Mingze Li, Yang Yu, Wenbing Huang",
        "summary": "Accurate prediction of ionic conductivity in electrolyte systems is crucial for advancing numerous scientific and technological applications. While significant progress has been made, current research faces two fundamental challenges: (1) the lack of high-quality standardized benchmarks, and (2) inadequate modeling of geometric structure and intermolecular interactions in mixture systems. To address these limitations, we first reorganize and enhance the CALiSol and DiffMix electrolyte datasets by incorporating geometric graph representations of molecules. We then propose GeoMix, a novel geometry-aware framework that preserves Set-SE(3) equivariance-an essential but challenging property for mixture systems. At the heart of GeoMix lies the Geometric Interaction Network (GIN), an equivariant module specifically designed for intermolecular geometric message passing. Comprehensive experiments demonstrate that GeoMix consistently outperforms diverse baselines (including MLPs, GNNs, and geometric GNNs) across both datasets, validating the importance of cross-molecular geometric interactions and equivariant message passing for accurate property prediction. This work not only establishes new benchmarks for electrolyte research but also provides a general geometric learning framework that advances modeling of mixture systems in energy materials, pharmaceutical development, and beyond.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.351026"
    },
    {
        "index": "#43",
        "title": "Iterative Refinement of Flow Policies in Probability Space for Online Reinforcement Learning",
        "link": "/arxiv/2510.15388",
        "arxiv_id": "2510.15388",
        "authors": "Mingyang Sun, Pengxiang Ding, Weinan Zhang, Donglin Wang",
        "summary": "While behavior cloning with flow/diffusion policies excels at learning complex skills from demonstrations, it remains vulnerable to distributional shift, and standard RL methods struggle to fine-tune these models due to their iterative inference process and the limitations of existing workarounds. In this work, we introduce the Stepwise Flow Policy (SWFP) framework, founded on the key insight that discretizing the flow matching inference process via a fixed-step Euler scheme inherently aligns it with the variational Jordan-Kinderlehrer-Otto (JKO) principle from optimal transport. SWFP decomposes the global flow into a sequence of small, incremental transformations between proximate distributions. Each step corresponds to a JKO update, regularizing policy changes to stay near the previous iterate and ensuring stable online adaptation with entropic regularization. This decomposition yields an efficient algorithm that fine-tunes pre-trained flows via a cascade of small flow blocks, offering significant advantages: simpler/faster training of sub-models, reduced computational/memory costs, and provable stability grounded in Wasserstein trust regions. Comprehensive experiments demonstrate SWFP's enhanced stability, efficiency, and superior adaptation performance across diverse robotic control benchmarks.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.351397"
    },
    {
        "index": "#44",
        "title": "Towards Robust Zero-Shot Reinforcement Learning",
        "link": "/arxiv/2510.15382",
        "arxiv_id": "2510.15382",
        "authors": "Kexin Zheng, Lauriane Teyssier, Yinan Zheng, Yu Luo, Xiayuan Zhan",
        "summary": "The recent development of zero-shot reinforcement learning (RL) has opened a new avenue for learning pre-trained generalist policies that can adapt to arbitrary new tasks in a zero-shot manner. While the popular Forward-Backward representations (FB) and related methods have shown promise in zero-shot RL, we empirically found that their modeling lacks expressivity and that extrapolation errors caused by out-of-distribution (OOD) actions during offline learning sometimes lead to biased representations, ultimately resulting in suboptimal performance. To address these issues, we propose Behavior-REgularizEd Zero-shot RL with Expressivity enhancement (BREEZE), an upgraded FB-based framework that simultaneously enhances learning stability, policy extraction capability, and representation learning quality. BREEZE introduces behavioral regularization in zero-shot RL policy learning, transforming policy optimization into a stable in-sample learning paradigm. Additionally, BREEZE extracts the policy using a task-conditioned diffusion model, enabling the generation of high-quality and multimodal action distributions in zero-shot RL settings. Moreover, BREEZE employs expressive attention-based architectures for representation modeling to capture the complex relationships between environmental dynamics. Extensive experiments on ExORL and D4RL Kitchen demonstrate that BREEZE achieves the best or near-the-best performance while exhibiting superior robustness compared to prior offline zero-shot RL methods. The official implementation is available at: https://github.com/Whiterrrrr/BREEZE.",
        "subjects": "Machine Learning, Artificial Intelligence, Robotics",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.351819"
    },
    {
        "index": "#45",
        "title": "Sequence Modeling with Spectral Mean Flows",
        "link": "/arxiv/2510.15366",
        "arxiv_id": "2510.15366",
        "authors": "Jinwoo Kim, Max Beier, Petar Bevanda, Nayun Kim, Seunghoon Hong",
        "summary": "A key question in sequence modeling with neural networks is how to represent and learn highly nonlinear and probabilistic state dynamics. Operator theory views such dynamics as linear maps on Hilbert spaces containing mean embedding vectors of distributions, offering an appealing but currently overlooked perspective. We propose a new approach to sequence modeling based on an operator-theoretic view of a hidden Markov model (HMM). Instead of materializing stochastic recurrence, we embed the full sequence distribution as a tensor in the product Hilbert space. A generative process is then defined as maximum mean discrepancy (MMD) gradient flow in the space of sequences. To overcome challenges with large tensors and slow sampling convergence, we introduce spectral mean flows, a novel tractable algorithm integrating two core concepts. First, we propose a new neural architecture by leveraging spectral decomposition of linear operators to derive a scalable tensor network decomposition of sequence mean embeddings. Second, we extend MMD gradient flows to time-dependent Hilbert spaces and connect them to flow matching via the continuity equation, enabling simulation-free learning and faster sampling. We demonstrate competitive results on a range of time-series modeling datasets. Code is available at https://github.com/jw9730/spectral-mean-flow.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.352187"
    },
    {
        "index": "#46",
        "title": "Backdoor or Manipulation? Graph Mixture of Experts Can Defend Against Various Graph Adversarial Attacks",
        "link": "/arxiv/2510.15333",
        "arxiv_id": "2510.15333",
        "authors": "Yuyuan Feng, Bin Ma, Enyan Dai",
        "summary": "Extensive research has highlighted the vulnerability of graph neural networks (GNNs) to adversarial attacks, including manipulation, node injection, and the recently emerging threat of backdoor attacks. However, existing defenses typically focus on a single type of attack, lacking a unified approach to simultaneously defend against multiple threats. In this work, we leverage the flexibility of the Mixture of Experts (MoE) architecture to design a scalable and unified framework for defending against backdoor, edge manipulation, and node injection attacks. Specifically, we propose an MI-based logic diversity loss to encourage individual experts to focus on distinct neighborhood structures in their decision processes, thus ensuring a sufficient subset of experts remains unaffected under perturbations in local structures. Moreover, we introduce a robustness-aware router that identifies perturbation patterns and adaptively routes perturbed nodes to corresponding robust experts. Extensive experiments conducted under various adversarial settings demonstrate that our method consistently achieves superior robustness against multiple graph adversarial attacks.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.352541"
    },
    {
        "index": "#47",
        "title": "On the Generalization Properties of Learning the Random Feature Models with Learnable Activation Functions",
        "link": "/arxiv/2510.15327",
        "arxiv_id": "2510.15327",
        "authors": "Zailin Ma, Jiansheng Yang, Yaodong Yang",
        "summary": "This paper studies the generalization properties of a recently proposed kernel method, the Random Feature models with Learnable Activation Functions (RFLAF). By applying a data-dependent sampling scheme for generating features, we provide by far the sharpest bounds on the required number of features for learning RFLAF in both the regression and classification tasks. We provide a unified theorem that describes the complexity of the feature number $s$, and discuss the results for the plain sampling scheme and the data-dependent leverage weighted scheme. Through weighted sampling, the bound on $s$ in the MSE loss case is improved from $\\Omega(1/\\epsilon^2)$ to $\\tilde{\\Omega}((1/\\epsilon)^{1/t})$ in general $(t\\geq 1)$, and even to $\\Omega(1)$ when the Gram matrix has a finite rank. For the Lipschitz loss case, the bound is improved from $\\Omega(1/\\epsilon^2)$ to $\\tilde{\\Omega}((1/\\epsilon^2)^{1/t})$. To learn the weighted RFLAF, we also propose an algorithm to find an approximate kernel and then apply the leverage weighted sampling. Empirical results show that the weighted RFLAF achieves the same performances with a significantly fewer number of features compared to the plainly sampled RFLAF, validating our theories and the effectiveness of this method.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.352889"
    },
    {
        "index": "#48",
        "title": "DFCA: Decentralized Federated Clustering Algorithm",
        "link": "/arxiv/2510.15300",
        "arxiv_id": "2510.15300",
        "authors": "Jonas Kirch, Sebastian Becker, Tiago Koketsu Rodrigues, Stefan Harmeling",
        "summary": "Clustered Federated Learning has emerged as an effective approach for handling heterogeneous data across clients by partitioning them into clusters with similar or identical data distributions. However, most existing methods, including the Iterative Federated Clustering Algorithm (IFCA), rely on a central server to coordinate model updates, which creates a bottleneck and a single point of failure, limiting their applicability in more realistic decentralized learning settings. In this work, we introduce DFCA, a fully decentralized clustered FL algorithm that enables clients to collaboratively train cluster-specific models without central coordination. DFCA uses a sequential running average to aggregate models from neighbors as updates arrive, providing a communication-efficient alternative to batch aggregation while maintaining clustering performance. Our experiments on various datasets demonstrate that DFCA outperforms other decentralized algorithms and performs comparably to centralized IFCA, even under sparse connectivity, highlighting its robustness and practicality for dynamic real-world decentralized networks.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.353251"
    },
    {
        "index": "#49",
        "title": "Identifying internal patterns in (1+1)-dimensional directed percolation using neural networks",
        "link": "/arxiv/2510.15294",
        "arxiv_id": "2510.15294",
        "authors": "Danil Parkhomenko, Pavel Ovchinnikov, Konstantin Soldatov, Vitalii Kapitan, Gennady Y. Chitov",
        "summary": "In this paper we present a neural network-based method for the automatic detection of phase transitions and classification of hidden percolation patterns in a (1+1)-dimensional replication process. The proposed network model is based on the combination of CNN, TCN and GRU networks, which are trained directly on raw configurations without any manual feature extraction. The network reproduces the phase diagram and assigns phase labels to configurations. It shows that deep architectures are capable of extracting hierarchical structures from the raw data of numerical experiments.",
        "subjects": "Machine Learning, Disordered Systems and Neural Networks, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.353656"
    },
    {
        "index": "#50",
        "title": "Small Ensemble-based Data Assimilation: A Machine Learning-Enhanced Data Assimilation Method with Limited Ensemble Size",
        "link": "/arxiv/2510.15284",
        "arxiv_id": "2510.15284",
        "authors": "Zhilin Li, Yao Zhou, Xianglong Li, Zeng Liu, Zhaokuan Lu, Shanlin Xu, Seungnam Kim, Guangyao Wang",
        "summary": "Ensemble-based data assimilation (DA) methods have become increasingly popular due to their inherent ability to address nonlinear dynamic problems. However, these methods often face a trade-off between analysis accuracy and computational efficiency, as larger ensemble sizes required for higher accuracy also lead to greater computational cost. In this study, we propose a novel machine learning-based data assimilation approach that combines the traditional ensemble Kalman filter (EnKF) with a fully connected neural network (FCNN). Specifically, our method uses a relatively small ensemble size to generate preliminary yet suboptimal analysis states via EnKF. A FCNN is then employed to learn and predict correction terms for these states, thereby mitigating the performance degradation induced by the limited ensemble size. We evaluate the performance of our proposed EnKF-FCNN method through numerical experiments involving Lorenz systems and nonlinear ocean wave field simulations. The results consistently demonstrate that the new method achieves higher accuracy than traditional EnKF with the same ensemble size, while incurring negligible additional computational cost. Moreover, the EnKF-FCNN method is adaptable to diverse applications through coupling with different models and the use of alternative ensemble-based DA methods.",
        "subjects": "Machine Learning, Statistics Theory",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.354086"
    },
    {
        "index": "#51",
        "title": "Foundation Models for Scientific Discovery: From Paradigm Enhancement to Paradigm Transition",
        "link": "/arxiv/2510.15280",
        "arxiv_id": "2510.15280",
        "authors": "Fan Liu, Jindong Han, Tengfei Lyu, Weijia Zhang, Zhe-Rui Yang, Lu Dai, Cancheng Liu, Hao Liu",
        "summary": "Foundation models (FMs), such as GPT-4 and AlphaFold, are reshaping the landscape of scientific research. Beyond accelerating tasks such as hypothesis generation, experimental design, and result interpretation, they prompt a more fundamental question: Are FMs merely enhancing existing scientific methodologies, or are they redefining the way science is conducted? In this paper, we argue that FMs are catalyzing a transition toward a new scientific paradigm. We introduce a three-stage framework to describe this evolution: (1) Meta-Scientific Integration, where FMs enhance workflows within traditional paradigms; (2) Hybrid Human-AI Co-Creation, where FMs become active collaborators in problem formulation, reasoning, and discovery; and (3) Autonomous Scientific Discovery, where FMs operate as independent agents capable of generating new scientific knowledge with minimal human intervention. Through this lens, we review current applications and emerging capabilities of FMs across existing scientific paradigms. We further identify risks and future directions for FM-enabled scientific discovery. This position paper aims to support the scientific community in understanding the transformative role of FMs and to foster reflection on the future of scientific discovery. Our project is available at https://github.com/usail-hkust/Awesome-Foundation-Models-for-Scientific-Discovery.",
        "subjects": "Machine Learning, Artificial Intelligence, Digital Libraries",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.354521"
    },
    {
        "index": "#52",
        "title": "Semi-Supervised Regression with Heteroscedastic Pseudo-Labels",
        "link": "/arxiv/2510.15266",
        "arxiv_id": "2510.15266",
        "authors": "Xueqing Sun, Renzhen Wang, Quanziang Wang, Yichen Wu, Xixi Jia, Deyu Meng",
        "summary": "Pseudo-labeling is a commonly used paradigm in semi-supervised learning, yet its application to semi-supervised regression (SSR) remains relatively under-explored. Unlike classification, where pseudo-labels are discrete and confidence-based filtering is effective, SSR involves continuous outputs with heteroscedastic noise, making it challenging to assess pseudo-label reliability. As a result, naive pseudo-labeling can lead to error accumulation and overfitting to incorrect labels. To address this, we propose an uncertainty-aware pseudo-labeling framework that dynamically adjusts pseudo-label influence from a bi-level optimization perspective. By jointly minimizing empirical risk over all data and optimizing uncertainty estimates to enhance generalization on labeled data, our method effectively mitigates the impact of unreliable pseudo-labels. We provide theoretical insights and extensive experiments to validate our approach across various benchmark SSR datasets, and the results demonstrate superior robustness and performance compared to existing methods. Our code is available at https://github.com/sxq/Heteroscedastic-Pseudo-Labels.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.354903"
    },
    {
        "index": "#53",
        "title": "Causal Time Series Modeling of Supraglacial Lake Evolution in Greenland under Distribution Shift",
        "link": "/arxiv/2510.15265",
        "arxiv_id": "2510.15265",
        "authors": "Emam Hossain, Muhammad Hasan Ferdous, Devon Dunmire, Aneesh Subramanian, Md Osman Gani",
        "summary": "Causal modeling offers a principled foundation for uncovering stable, invariant relationships in time-series data, thereby improving robustness and generalization under distribution shifts. Yet its potential is underutilized in spatiotemporal Earth observation, where models often depend on purely correlational features that fail to transfer across heterogeneous domains. We propose RIC-TSC, a regionally-informed causal time-series classification framework that embeds lag-aware causal discovery directly into sequence modeling, enabling both predictive accuracy and scientific interpretability. Using multi-modal satellite and reanalysis data-including Sentinel-1 microwave backscatter, Sentinel-2 and Landsat-8 optical reflectance, and CARRA meteorological variables-we leverage Joint PCMCI+ (J-PCMCI+) to identify region-specific and invariant predictors of supraglacial lake evolution in Greenland. Causal graphs are estimated globally and per basin, with validated predictors and their time lags supplied to lightweight classifiers. On a balanced benchmark of 1000 manually labeled lakes from two contrasting melt seasons (2018-2019), causal models achieve up to 12.59% higher accuracy than correlation-based baselines under out-of-distribution evaluation. These results show that causal discovery is not only a means of feature selection but also a pathway to generalizable and mechanistically grounded models of dynamic Earth surface processes.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.355277"
    },
    {
        "index": "#54",
        "title": "Robust Layerwise Scaling Rules by Proper Weight Decay Tuning",
        "link": "/arxiv/2510.15262",
        "arxiv_id": "2510.15262",
        "authors": "Zhiyuan Fan, Yifeng Liu, Qingyue Zhao, Angela Yuan, Quanquan Gu",
        "summary": "Empirical scaling laws prescribe how to allocate parameters, data, and compute, while maximal-update parameterization ($\\mu$P) enables learning-rate transfer across widths by equalizing early-time update magnitudes. However, in modern scale-invariant architectures, training quickly enters an optimizer-governed steady state where normalization layers create backward scale sensitivity and the effective learning rate becomes width dependent, degrading $\\mu$P transfer. We address this by introducing a weight-decay scaling rule for AdamW that preserves sublayer gain across widths. Empirically, the singular-value spectrum of each matrix parameter scales in norm as $\\sqrt{\\eta/\\lambda}$ with an approximately invariant shape; under width scaling $d$, we observe that the top singular value scales approximately as $\\sqrt{\\eta/\\lambda}\\cdot d^{0.75}$. Combining this observation with the $\\mu$P learning-rate rule $\\eta_2\\propto d^{-1}$ for matrix-like parameters implies an empirical weight-decay scaling rule $\\lambda_2\\propto \\sqrt{d}$ that approximately keeps sublayer gains width invariant. Together with vector-like parameters trained at $\\eta_1=\\Theta_d(1)$ and $\\lambda_1=0$, this yields \\emph{zero-shot} transfer of both learning rate and weight decay from proxy to target widths, removing per-width sweeps. We validate the rule on LLaMA-style Transformers and in a minimal synthetic setting, and we provide a simple diagnostic, matching top singular values, to check sublayer-gain invariance. Our results extend $\\mu$P beyond the near-init regime by explicitly controlling steady-state scales set by the optimizer, offering a practical recipe for width-robust hyperparameter transfer under AdamW.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.355682"
    },
    {
        "index": "#56",
        "title": "Spatiotemporal Transformers for Predicting Avian Disease Risk from Migration Trajectories",
        "link": "/arxiv/2510.15254",
        "arxiv_id": "2510.15254",
        "authors": "Dingya Feng, Dingyuan Xue",
        "summary": "Accurate forecasting of avian disease outbreaks is critical for wildlife conservation and public health. This study presents a Transformer-based framework for predicting the disease risk at the terminal locations of migratory bird trajectories. We integrate multi-source datasets, including GPS tracking data from Movebank, outbreak records from the World Organisation for Animal Health (WOAH), and geospatial context from GADM and Natural Earth. The raw coordinates are processed using H3 hierarchical geospatial encoding to capture spatial patterns. The model learns spatiotemporal dependencies from bird movement sequences to estimate endpoint disease risk. Evaluation on a held-out test set demonstrates strong predictive performance, achieving an accuracy of 0.9821, area under the ROC curve (AUC) of 0.9803, average precision (AP) of 0.9299, and an F1-score of 0.8836 at the optimal threshold. These results highlight the potential of Transformer architectures to support early-warning systems for avian disease surveillance, enabling timely intervention and prevention strategies.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.361511"
    },
    {
        "index": "#57",
        "title": "Dual-Weighted Reinforcement Learning for Generative Preference Modeling",
        "link": "/arxiv/2510.15242",
        "arxiv_id": "2510.15242",
        "authors": "Shengyu Feng, Yun He, Shuang Ma, Beibin Li, Yuanhao Xiong, Vincent Li, Karishma Mandyam, Julian Katz-Samuels, Shengjie Bi, Licheng Yu, Hejia Zhang, Karthik Abinav Sankararaman, Han Fang, Riham Mansour, Yiming Yang, Manaal Faruqui",
        "summary": "Reinforcement learning (RL) has recently proven effective at scaling chain-of-thought (CoT) reasoning in large language models on tasks with verifiable answers. However, extending RL to more general non-verifiable tasks, typically in the format of human preference pairs, remains both challenging and underexplored. In this work, we propose Dual-Weighted Reinforcement Learning (DWRL), a new framework for preference modeling that integrates CoT reasoning with the Bradley-Terry (BT) model via a dual-weighted RL objective that preserves preference-modeling inductive bias. DWRL approximates the maximum-likelihood objective of the BT model with two complementary weights: an instance-wise misalignment weight, which emphasizes under-trained pairs misaligned with human preference, and a group-wise (self-normalized) conditional preference score, which promotes promising thoughts. In this paper, we apply DWRL to preference modeling by training generative preference models (GPMs) to first generate a thought and then predict the human preference score. Across multiple benchmarks and model scales (Llama3 and Qwen2.5), DWRL consistently outperforms both GPM baselines and scalar models, while producing coherent, interpretable thoughts. In summary, our results position DWRL as a general framework for reasoning-enhanced preference learning beyond verifiable tasks.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.362015"
    },
    {
        "index": "#58",
        "title": "Adaptive Individual Uncertainty under Out-Of-Distribution Shift with Expert-Routed Conformal Prediction",
        "link": "/arxiv/2510.15233",
        "arxiv_id": "2510.15233",
        "authors": "Amitesh Badkul, Lei Xie",
        "summary": "Reliable, informative, and individual uncertainty quantification (UQ) remains missing in current ML community. This hinders the effective application of AI/ML to risk-sensitive domains. Most methods either fail to provide coverage on new data, inflate intervals so broadly that they are not actionable, or assign uncertainties that do not track actual error, especially under a distribution shift. In high-stakes drug discovery, protein-ligand affinity (PLI) prediction is especially challenging as assay noise is heterogeneous, chemical space is imbalanced and large, and practical evaluations routinely involve distribution shift. In this work, we introduce a novel uncertainty quantification method, Trustworthy Expert Split-conformal with Scaled Estimation for Efficient Reliable Adaptive intervals (TESSERA), that provides per-sample uncertainty with reliable coverage guarantee, informative and adaptive prediction interval widths that track the absolute error. We evaluate on protein-ligand binding affinity prediction under both independent and identically distributed (i.i.d.) and scaffold-based out-of-distribution (OOD) splits, comparing against strong UQ baselines. TESSERA attains near-nominal coverage and the best coverage-width trade-off as measured by the Coverage-Width Criterion (CWC), while maintaining competitive adaptivity (lowest Area Under the Sparsification Error (AUSE)). Size-Stratified Coverage (SSC) further confirms that intervals are right-sized, indicating width increases when data are scarce or noisy, and remain tight when predictions are reliable. By unifying Mixture of Expert (MoE) diversity with conformal calibration, TESSERA delivers trustworthy, tight, and adaptive uncertainties that are well-suited to selective prediction and downstream decision-making in the drug-discovery pipeline and other applications.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.362372"
    },
    {
        "index": "#60",
        "title": "Stress-Aware Learning under KL Drift via Trust-Decayed Mirror Descent",
        "link": "/arxiv/2510.15222",
        "arxiv_id": "2510.15222",
        "authors": "Gabriel Nixon Raj",
        "summary": "We study sequential decision-making under distribution drift. We propose entropy-regularized trust-decay, which injects stress-aware exponential tilting into both belief updates and mirror-descent decisions. On the simplex, a Fenchel-dual equivalence shows that belief tilt and decision tilt coincide. We formalize robustness via fragility (worst-case excess risk in a KL ball), belief bandwidth (radius sustaining a target excess), and a decision-space Fragility Index (drift tolerated at $O(\\sqrt{T})$ regret). We prove high-probability sensitivity bounds and establish dynamic-regret guarantees of $\\tilde{O}(\\sqrt{T})$ under KL-drift path length $S_T = \\sum_{t\\ge2}\\sqrt{{\\rm KL}(D_t|D_{t-1})/2}$. In particular, trust-decay achieves $O(1)$ per-switch regret, while stress-free updates incur $\\Omega(1)$ tails. A parameter-free hedge adapts the tilt to unknown drift, whereas persistent over-tilting yields an $\\Omega(\\lambda^2 T)$ stationary penalty. We further obtain calibrated-stress bounds and extensions to second-order updates, bandit feedback, outliers, stress variation, distributed optimization, and plug-in KL-drift estimation. The framework unifies dynamic-regret analysis, distributionally robust objectives, and KL-regularized control within a single stress-adaptive update.",
        "subjects": "Machine Learning, Statistics Theory",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.363118"
    },
    {
        "index": "#61",
        "title": "Integrating Product Coefficients for Improved 3D LiDAR Data Classification (Part II)",
        "link": "/arxiv/2510.15219",
        "arxiv_id": "2510.15219",
        "authors": "Patricia Medina, Rasika Karkare",
        "summary": "This work extends our previous study on enhancing 3D LiDAR point-cloud classification with product coefficients \\cite{medina2025integratingproductcoefficientsimproved}, measure-theoretic descriptors that complement the original spatial Lidar features. Here, we show that combining product coefficients with an autoencoder representation and a KNN classifier delivers consistent performance gains over both PCA-based baselines and our earlier framework. We also investigate the effect of adding product coefficients level by level, revealing a clear trend: richer sets of coefficients systematically improve class separability and overall accuracy. The results highlight the value of combining hierarchical product-coefficient features with autoencoders to push LiDAR classification performance further.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.363448"
    },
    {
        "index": "#62",
        "title": "Machine Learning for Early Detection of Meningitis: Stacked Ensemble Learning with EHR data",
        "link": "/arxiv/2510.15218",
        "arxiv_id": "2510.15218",
        "authors": "Han Ouyang, Jesse Hamilton, Saeed Amal",
        "summary": "We utilized a cohort of 214 meningitis patients and 46,303 non-meningitis patients from the MIMIC-III database. After extensive data preprocessing, which included ICD-based cohort selection, one-hot encoding of coding, and a two-stage feature selection process (for both the training set and the testing sets), clinically relevant features such as gender and high-risk ICD codes (including subarachnoid hemorrhage, secondary malignant neoplasm of the brain, and generalized epilepsy) are selected. Overall, these clinically reasonable and temporally adherent features provided excellent modeling performance. Three models (Random Forest, LightGBM, and Deep Neural Networks (DNN) are trained as base models for Ensemble Learning. Base model outputs are aggregated and stacked into a meta model (Logistic Regression) that uses the base model outputs as input values in training. Ultimately, soldier outputs (AUC of Testing Set 1: 0.9637, AUC of Testing Set 2: 0.9472) are obtained through ensemble learning. We created a challenging condition for diagnosing meningitis, simulating a real-world ER (Emergency Room) scenario to enhance clinical use in real-world applications. While directly deploying a diagnostic tool that clinicians can use is challenging, this paper paves the way for a potential future AI-driven diagnostic approach for meningitis using Ensemble Learning.",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.363821"
    },
    {
        "index": "#63",
        "title": "Reflections from Research Roundtables at the Conference on Health, Inference, and Learning (CHIL) 2025",
        "link": "/arxiv/2510.15217",
        "arxiv_id": "2510.15217",
        "authors": "Emily Alsentzer, Marie-Laure Charpignon, Bill Chen, Niharika D'Souza, Jason Fries, Yixing Jiang, Aparajita Kashyap, Chanwoo Kim, Simon Lee, Aishwarya Mandyam, Ashery Christopher Mbilinyi, Nikita Mehandru, Nitish Nagesh, Brighton Nuwagira, Emma Pierson, Arvind Pillai, Akane Sano, Tanveer Syeda-Mahmood, Shashank Yadav, Elias Adhanom, Muhammad Umar Afza, Amelia Archer, Suhana Bedi, Vasiliki Bikia, Trenton Chang, George H. Chen, Winston Chen, Erica Chiang, Edward Choi, Octavia Ciora, Paz Dozie-Nnamah, Shaza Elsharief, Matthew Engelhard, Ali Eshragh, Jean Feng, Josh Fessel, Scott Fleming, Kei Sen Fong, Thomas Frost, Soham Gadgil, Judy Gichoya, Leeor Hershkovich, Sujeong Im, Bhavya Jain, Vincent Jeanselme, Furong Jia, Qixuan, Jin, Yuxuan Jin, Daniel Kapash, Geetika Kapoor, Behdokht Kiafar, Matthias Kleiner, Stefan Kraft, Annika Kumar, Daeun Kyung, Zhongyuan Liang, Joanna Lin, Qianchu, Liu, Chang Liu, Hongzhou Luan, Chris Lunt, Leopoldo Julían Lechuga López, Matthew B. A. McDermott, Shahriar Noroozizadeh, Connor O'Brien, YongKyung Oh, Mixail Ota, Stephen Pfohl, Meagan Pi, Tanmoy Sarkar Pias, Emma Rocheteau, Avishaan Sethi, Toru Shirakawa, Anita Silver, Neha Simha, Kamile Stankeviciute, Max Sunog, Peter Szolovits, Shengpu Tang, Jialu Tang, Aaron Tierney, John Valdovinos, Byron Wallace, Will Ke Wang, Peter Washington, Jeremy Weiss, Daniel Wolfe, Emily Wong, Hye Sun Yun, Xiaoman Zhang, Xiao Yu Cindy Zhang, Hayoung Jeong, Kaveri A. Thakoor",
        "summary": "The 6th Annual Conference on Health, Inference, and Learning (CHIL 2025), hosted by the Association for Health Learning and Inference (AHLI), was held in person on June 25-27, 2025, at the University of California, Berkeley, in Berkeley, California, USA. As part of this year's program, we hosted Research Roundtables to catalyze collaborative, small-group dialogue around critical, timely topics at the intersection of machine learning and healthcare. Each roundtable was moderated by a team of senior and junior chairs who fostered open exchange, intellectual curiosity, and inclusive engagement. The sessions emphasized rigorous discussion of key challenges, exploration of emerging opportunities, and collective ideation toward actionable directions in the field. In total, eight roundtables were held by 19 roundtable chairs on topics of \"Explainability, Interpretability, and Transparency,\" \"Uncertainty, Bias, and Fairness,\" \"Causality,\" \"Domain Adaptation,\" \"Foundation Models,\" \"Learning from Small Medical Data,\" \"Multimodal Methods,\" and \"Scalable, Translational Healthcare Solutions.\"",
        "subjects": "Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.365268"
    },
    {
        "index": "#65",
        "title": "ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning",
        "link": "/arxiv/2510.15211",
        "arxiv_id": "2510.15211",
        "authors": "Yongchan Kwon, Shang Zhu, Federico Bianchi, Kaitlyn Zhou, James Zou",
        "summary": "The ability of large language models (LLMs) to follow user instructions is central to their reliability, safety, and usefulness. While prior studies assess instruction adherence in the model's main responses, we argue that it is also critical for large reasoning models (LRMs) to follow user instructions throughout their reasoning process. Reasoning instruction following makes LRMs more controllable and transparent, while reducing risks of undesirable shortcuts, hallucinations, or reward hacking within reasoning traces. To evaluate this dimension, we introduce ReasonIF, a systematic benchmark for assessing reasoning instruction following. ReasonIF includes six categories of instruction prompts, spanning multilingual reasoning, formatting and length control. Across many open-source LRMs including GPT-OSS, Qwen3, and DeepSeek-R1, we find substantial failures in reasoning instruction adherence: the highest instruction following score (IFS) remains below 0.25, meaning that fewer than $25\\%$ of reasoning traces comply with the given instructions. Notably, as task difficulty increases, reasoning instruction following degrades further. We also explore two strategies to enhance reasoning instruction fidelity. (1) multi-turn reasoning and (2) Reasoning Instruction Finetuning (RIF) using synthetic data. RIF improves the IFS of $GPT-OSS-20B$ from 0.11 to 0.27, indicating measurable progress but leaving ample room for improvement.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.371170"
    },
    {
        "index": "#66",
        "title": "Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection",
        "link": "/arxiv/2510.15202",
        "arxiv_id": "2510.15202",
        "authors": "Denis Janiak, Jakub Binkowski, Tomasz Kajdanowicz",
        "summary": "Out-of-distribution (OOD) detection is critical for the reliable deployment of deep learning models. hile Mahalanobis distance methods are widely used, the impact of representation geometry and normalization on their performance is not fully understood, which may limit their downstream application. To address this gap, we conducted a comprehensive empirical study across diverse image foundation models, datasets, and distance normalization schemes. First, our analysis shows that Mahalanobis-based methods aren't universally reliable. Second, we define the ideal geometry for data representations and demonstrate that spectral and intrinsic-dimensionality metrics can accurately predict a model's OOD performance. Finally, we analyze how normalization impacts OOD performance. Building upon these studies, we propose radially scaled $\\ell_2$ normalization, a method that generalizes the standard $\\ell_2$ normalization recently applied to Mahalanobis-based OOD detection. Our approach introduces a tunable parameter to directly control the radial geometry of the feature space, systematically contracting or expanding representations to significantly improve OOD detection performance. By bridging the gap between representation geometry, normalization, and OOD performance, our findings offer new insights into the design of more effective and reliable deep learning models.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.371549"
    },
    {
        "index": "#67",
        "title": "Automotive Crash Dynamics Modeling Accelerated with Machine Learning",
        "link": "/arxiv/2510.15201",
        "arxiv_id": "2510.15201",
        "authors": "Mohammad Amin Nabian, Sudeep Chavare, Deepak Akhare, Rishikesh Ranade, Ram Cherukuri, Srinivas Tadepalli",
        "summary": "Crashworthiness assessment is a critical aspect of automotive design, traditionally relying on high-fidelity finite element (FE) simulations that are computationally expensive and time-consuming. This work presents an exploratory comparative study on developing machine learning-based surrogate models for efficient prediction of structural deformation in crash scenarios using the NVIDIA PhysicsNeMo framework. Given the limited prior work applying machine learning to structural crash dynamics, the primary contribution lies in demonstrating the feasibility and engineering utility of the various modeling approaches explored in this work. We investigate two state-of-the-art neural network architectures for modeling crash dynamics: MeshGraphNet, and Transolver. Additionally, we examine three strategies for modeling transient dynamics: time-conditional, the standard Autoregressive approach, and a stability-enhanced Autoregressive scheme incorporating rollout-based training. The models are evaluated on a comprehensive Body-in-White (BIW) crash dataset comprising 150 detailed FE simulations using LS-DYNA. The dataset represents a structurally rich vehicle assembly with over 200 components, including 38 key components featuring variable thickness distributions to capture realistic manufacturing variability. Each model utilizes the undeformed mesh geometry and component characteristics as inputs to predict the spatiotemporal evolution of the deformed mesh during the crash sequence. Evaluation results show that the models capture the overall deformation trends with reasonable fidelity, demonstrating the feasibility of applying machine learning to structural crash dynamics. Although not yet matching full FE accuracy, the models achieve orders-of-magnitude reductions in computational cost, enabling rapid design exploration and early-stage optimization in crashworthiness evaluation.",
        "subjects": "Machine Learning, Artificial Intelligence, Numerical Analysis, Applied Physics, Computational Physics",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.372030"
    },
    {
        "index": "#68",
        "title": "An Advanced Two-Stage Model with High Sensitivity and Generalizability for Prediction of Hip Fracture Risk Using Multiple Datasets",
        "link": "/arxiv/2510.15179",
        "arxiv_id": "2510.15179",
        "authors": "Shuo Sun, Meiling Zhou, Chen Zhao, Joyce H. Keyak, Nancy E. Lane, Jeffrey D. Deng, Kuan-Jui Su, Hui Shen, Hong-Wen Deng, Kui Zhang, Weihua Zhou",
        "summary": "Hip fractures are a major cause of disability, mortality, and healthcare burden in older adults, underscoring the need for early risk assessment. However, commonly used tools such as the DXA T-score and FRAX often lack sensitivity and miss individuals at high risk, particularly those without prior fractures or with osteopenia. To address this limitation, we propose a sequential two-stage model that integrates clinical and imaging information to improve prediction accuracy. Using data from the Osteoporotic Fractures in Men Study (MrOS), the Study of Osteoporotic Fractures (SOF), and the UK Biobank, Stage 1 (Screening) employs clinical, demographic, and functional variables to estimate baseline risk, while Stage 2 (Imaging) incorporates DXA-derived features for refinement. The model was rigorously validated through internal and external testing, showing consistent performance and adaptability across cohorts. Compared to T-score and FRAX, the two-stage framework achieved higher sensitivity and reduced missed cases, offering a cost-effective and personalized approach for early hip fracture risk assessment. Keywords: Hip Fracture, Two-Stage Model, Risk Prediction, Sensitivity, DXA, FRAX",
        "subjects": "Machine Learning, Medical Physics",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.372497"
    },
    {
        "index": "#69",
        "title": "Finding geodesics with the Deep Ritz method",
        "link": "/arxiv/2510.15177",
        "arxiv_id": "2510.15177",
        "authors": "Conor Rowan",
        "summary": "Geodesic problems involve computing trajectories between prescribed initial and final states to minimize a user-defined measure of distance, cost, or energy. They arise throughout physics and engineering -- for instance, in determining optimal paths through complex environments, modeling light propagation in refractive media, and the study of spacetime trajectories in control theory and general relativity. Despite their ubiquity, the scientific machine learning (SciML) community has given relatively little attention to investigating its methods in the context of these problems. In this work, we argue that given their simple geometry, variational structure, and natural nonlinearity, geodesic problems are particularly well-suited for the Deep Ritz method. We substantiate this claim with three numerical examples drawn from path planning, optics, and solid mechanics. Our goal is not to provide an exhaustive study of geodesic problems, but rather to identify a promising application of the Deep Ritz method and a fruitful direction for future SciML research.",
        "subjects": "Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.372828"
    },
    {
        "index": "#70",
        "title": "A simple mean field model of feature learning",
        "link": "/arxiv/2510.15174",
        "arxiv_id": "2510.15174",
        "authors": "Niclas Göring, Chris Mingard, Yoonsoo Nam, Ard Louis",
        "summary": "Feature learning (FL), where neural networks adapt their internal representations during training, remains poorly understood. Using methods from statistical physics, we derive a tractable, self-consistent mean-field (MF) theory for the Bayesian posterior of two-layer non-linear networks trained with stochastic gradient Langevin dynamics (SGLD). At infinite width, this theory reduces to kernel ridge regression, but at finite width it predicts a symmetry breaking phase transition where networks abruptly align with target functions. While the basic MF theory provides theoretical insight into the emergence of FL in the finite-width regime, semi-quantitatively predicting the onset of FL with noise or sample size, it substantially underestimates the improvements in generalisation after the transition. We trace this discrepancy to a key mechanism absent from the plain MF description: \\textit{self-reinforcing input feature selection}. Incorporating this mechanism into the MF theory allows us to quantitatively match the learning curves of SGLD-trained networks and provides mechanistic insight into FL.",
        "subjects": "Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.373196"
    },
    {
        "index": "#71",
        "title": "Policy Transfer Ensures Fast Learning for Continuous-Time LQR with Entropy Regularization",
        "link": "/arxiv/2510.15165",
        "arxiv_id": "2510.15165",
        "authors": "Xin Guo, Zijiu Lyu",
        "summary": "Reinforcement Learning (RL) enables agents to learn optimal decision-making strategies through interaction with an environment, yet training from scratch on complex tasks can be highly inefficient. Transfer learning (TL), widely successful in large language models (LLMs), offers a promising direction for enhancing RL efficiency by leveraging pre-trained models. This paper investigates policy transfer, a TL approach that initializes learning in a target RL task using a policy from a related source task, in the context of continuous-time linear quadratic regulators (LQRs) with entropy regularization. We provide the first theoretical proof of policy transfer for continuous-time RL, proving that a policy optimal for one LQR serves as a near-optimal initialization for closely related LQRs, while preserving the original algorithm's convergence rate. Furthermore, we introduce a novel policy learning algorithm for continuous-time LQRs that achieves global linear and local super-linear convergence. Our results demonstrate both theoretical guarantees and algorithmic benefits of transfer learning in continuous-time RL, addressing a gap in existing literature and extending prior work from discrete to continuous time settings. As a byproduct of our analysis, we derive the stability of a class of continuous-time score-based diffusion models via their connection with LQRs.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.373547"
    },
    {
        "index": "#72",
        "title": "Predicting the Unpredictable: Reproducible BiLSTM Forecasting of Incident Counts in the Global Terrorism Database (GTD)",
        "link": "/arxiv/2510.15136",
        "arxiv_id": "2510.15136",
        "authors": "Oluwasegun Adegoke",
        "summary": "We study short-horizon forecasting of weekly terrorism incident counts using the Global Terrorism Database (GTD, 1970--2016). We build a reproducible pipeline with fixed time-based splits and evaluate a Bidirectional LSTM (BiLSTM) against strong classical anchors (seasonal-naive, linear/ARIMA) and a deep LSTM-Attention baseline. On the held-out test set, the BiLSTM attains RMSE 6.38, outperforming LSTM-Attention (9.19; +30.6\\%) and a linear lag-regression baseline (+35.4\\% RMSE gain), with parallel improvements in MAE and MAPE. Ablations varying temporal memory, training-history length, spatial grain, lookback size, and feature groups show that models trained on long historical data generalize best; a moderate lookback (20--30 weeks) provides strong context; and bidirectional encoding is critical for capturing both build-up and aftermath patterns within the window. Feature-group analysis indicates that short-horizon structure (lagged counts and rolling statistics) contributes most, with geographic and casualty features adding incremental lift. We release code, configs, and compact result tables, and provide a data/ethics statement documenting GTD licensing and research-only use. Overall, the study offers a transparent, baseline-beating reference for GTD incident forecasting.",
        "subjects": "Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.373877"
    },
    {
        "index": "#73",
        "title": "A Simple Method for PMF Estimation on Large Supports",
        "link": "/arxiv/2510.15132",
        "arxiv_id": "2510.15132",
        "authors": "Alex Shtoff",
        "summary": "We study nonparametric estimation of a probability mass function (PMF) on a large discrete support, where the PMF is multi-modal and heavy-tailed. The core idea is to treat the empirical PMF as a signal on a line graph and apply a data-dependent low-pass filter. Concretely, we form a symmetric tri-diagonal operator, the path graph Laplacian perturbed with a diagonal matrix built from the empirical PMF, then compute the eigenvectors, corresponding to the smallest feq eigenvalues. Projecting the empirical PMF onto this low dimensional subspace produces a smooth, multi-modal estimate that preserves coarse structure while suppressing noise. A light post-processing step of clipping and re-normalizing yields a valid PMF. Because we compute the eigenpairs of a symmetric tridiagonal matrix, the computation is reliable and runs time and memory proportional to the support times the dimension of the desired low-dimensional supspace. We also provide a practical, data-driven rule for selecting the dimension based on an orthogonal-series risk estimate, so the method \"just works\" with minimal tuning. On synthetic and real heavy-tailed examples, the approach preserves coarse structure while suppressing sampling noise, compares favorably to logspline and Gaussian-KDE baselines in the intended regimes. However, it has known failure modes (e.g., abrupt discontinuities). The method is short to implement, robust across sample sizes, and suitable for automated pipelines and exploratory analysis at scale because of its reliability and speed.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.374217"
    },
    {
        "index": "#74",
        "title": "Navigating the consequences of mechanical ventilation in clinical intensive care settings through an evolutionary game-theoretic framework",
        "link": "/arxiv/2510.15127",
        "arxiv_id": "2510.15127",
        "authors": "David J. Albers, Tell D. Bennett, Jana de Wiljes, Bradford J. Smith, Peter D. Sottile, J. N. Stroh",
        "summary": "Identifying the effects of mechanical ventilation strategies and protocols in critical care requires analyzing data from heterogeneous patient-ventilator systems within the context of the clinical decision-making environment. This research develops a framework to help understand the consequences of mechanical ventilation (MV) and adjunct care decisions on patient outcome from observations of critical care patients receiving MV. Developing an understanding of and improving critical care respiratory management requires the analysis of existing secondary-use clinical data to generate hypotheses about advantageous variations and adaptations of current care. This work introduces a perspective of the joint patient-ventilator-care systems (so-called J6) to develop a scalable method for analyzing data and trajectories of these complex systems. To that end, breath behaviors are analyzed using evolutionary game theory (EGT), which generates the necessary quantitative precursors for deeper analysis through probabilistic and stochastic machinery such as reinforcement learning. This result is one step along the pathway toward MV optimization and personalization. The EGT-based process is analytically validated on synthetic data to reveal potential caveats before proceeding to real-world ICU data applications that expose complexities of the data-generating process J6. The discussion includes potential developments toward a state transition model for the simulating effects of MV decision using empirical and game-theoretic elements.",
        "subjects": "Machine Learning, Optimization and Control, Quantitative Methods",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.374632"
    },
    {
        "index": "#76",
        "title": "Operator Flow Matching for Timeseries Forecasting",
        "link": "/arxiv/2510.15101",
        "arxiv_id": "2510.15101",
        "authors": "Yolanne Yi Ran Lee, Kyriakos Flouris",
        "summary": "Forecasting high-dimensional, PDE-governed dynamics remains a core challenge for generative modeling. Existing autoregressive and diffusion-based approaches often suffer cumulative errors and discretisation artifacts that limit long, physically consistent forecasts. Flow matching offers a natural alternative, enabling efficient, deterministic sampling. We prove an upper bound on FNO approximation error and propose TempO, a latent flow matching model leveraging sparse conditioning with channel folding to efficiently process 3D spatiotemporal fields using time-conditioned Fourier layers to capture multi-scale modes with high fidelity. TempO outperforms state-of-the-art baselines across three benchmark PDE datasets, and spectral analysis further demonstrates superior recovery of multi-scale dynamics, while efficiency studies highlight its parameter- and memory-light design compared to attention-based or convolutional regressors.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.375476"
    },
    {
        "index": "#77",
        "title": "Online Correlation Clustering: Simultaneously Optimizing All $\\ell_p$-norms",
        "link": "/arxiv/2510.15076",
        "arxiv_id": "2510.15076",
        "authors": "Sami Davies, Benjamin Moseley, Heather Newman",
        "summary": "The $\\ell_p$-norm objectives for correlation clustering present a fundamental trade-off between minimizing total disagreements (the $\\ell_1$-norm) and ensuring fairness to individual nodes (the $\\ell_\\infty$-norm). Surprisingly, in the offline setting it is possible to simultaneously approximate all $\\ell_p$-norms with a single clustering. Can this powerful guarantee be achieved in an online setting? This paper provides the first affirmative answer. We present a single algorithm for the online-with-a-sample (AOS) model that, given a small constant fraction of the input as a sample, produces one clustering that is simultaneously $O(\\log^4 n)$-competitive for all $\\ell_p$-norms with high probability, $O(\\log n)$-competitive for the $\\ell_\\infty$-norm with high probability, and $O(1)$-competitive for the $\\ell_1$-norm in expectation. This work successfully translates the offline \"all-norms\" guarantee to the online world. Our setting is motivated by a new hardness result that demonstrates a fundamental separation between these objectives in the standard random-order (RO) online model. Namely, while the $\\ell_1$-norm is trivially $O(1)$-approximable in the RO model, we prove that any algorithm in the RO model for the fairness-promoting $\\ell_\\infty$-norm must have a competitive ratio of at least $\\Omega(n^{1/3})$. This highlights the necessity of a different beyond-worst-case model. We complement our algorithm with lower bounds, showing our competitive ratios for the $\\ell_1$- and $\\ell_\\infty$- norms are nearly tight in the AOS model.",
        "subjects": "Machine Learning, Discrete Mathematics, Data Structures and Algorithms",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.375866"
    },
    {
        "index": "#78",
        "title": "Physics-informed data-driven machine health monitoring for two-photon lithography",
        "link": "/arxiv/2510.15075",
        "arxiv_id": "2510.15075",
        "authors": "Sixian Jia, Zhiqiao Dong, Chenhui Shao",
        "summary": "Two-photon lithography (TPL) is a sophisticated additive manufacturing technology for creating three-dimensional (3D) micro- and nano-structures. Maintaining the health of TPL systems is critical for ensuring consistent fabrication quality. Current maintenance practices often rely on experience rather than informed monitoring of machine health, resulting in either untimely maintenance that causes machine downtime and poor-quality fabrication, or unnecessary maintenance that leads to inefficiencies and avoidable downtime. To address this gap, this paper presents three methods for accurate and timely monitoring of TPL machine health. Through integrating physics-informed data-driven predictive models for structure dimensions with statistical approaches, the proposed methods are able to handle increasingly complex scenarios featuring different levels of generalizability. A comprehensive experimental dataset that encompasses six process parameter combinations and six structure dimensions under two machine health conditions was collected to evaluate the effectiveness of the proposed approaches. Across all test scenarios, the approaches are shown to achieve high accuracies, demonstrating excellent effectiveness, robustness, and generalizability. These results represent a significant step toward condition-based maintenance for TPL systems.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.381380"
    },
    {
        "index": "#80",
        "title": "Learn to Change the World: Multi-level Reinforcement Learning with Model-Changing Actions",
        "link": "/arxiv/2510.15056",
        "arxiv_id": "2510.15056",
        "authors": "Ziqing Lu, Babak Hassibi, Lifeng Lai, Weiyu Xu",
        "summary": "Reinforcement learning usually assumes a given or sometimes even fixed environment in which an agent seeks an optimal policy to maximize its long-term discounted reward. In contrast, we consider agents that are not limited to passive adaptations: they instead have model-changing actions that actively modify the RL model of world dynamics itself. Reconfiguring the underlying transition processes can potentially increase the agents' rewards. Motivated by this setting, we introduce the multi-layer configurable time-varying Markov decision process (MCTVMDP). In an MCTVMDP, the lower-level MDP has a non-stationary transition function that is configurable through upper-level model-changing actions. The agent's objective consists of two parts: Optimize the configuration policies in the upper-level MDP and optimize the primitive action policies in the lower-level MDP to jointly improve its expected long-term reward.",
        "subjects": "Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.382128"
    },
    {
        "index": "#82",
        "title": "IQNN-CS: Interpretable Quantum Neural Network for Credit Scoring",
        "link": "/arxiv/2510.15044",
        "arxiv_id": "2510.15044",
        "authors": "Abdul Samad Khan, Nouhaila Innan, Aeysha Khalique, Muhammad Shafique",
        "summary": "Credit scoring is a high-stakes task in financial services, where model decisions directly impact individuals' access to credit and are subject to strict regulatory scrutiny. While Quantum Machine Learning (QML) offers new computational capabilities, its black-box nature poses challenges for adoption in domains that demand transparency and trust. In this work, we present IQNN-CS, an interpretable quantum neural network framework designed for multiclass credit risk classification. The architecture combines a variational QNN with a suite of post-hoc explanation techniques tailored for structured data. To address the lack of structured interpretability in QML, we introduce Inter-Class Attribution Alignment (ICAA), a novel metric that quantifies attribution divergence across predicted classes, revealing how the model distinguishes between credit risk categories. Evaluated on two real-world credit datasets, IQNN-CS demonstrates stable training dynamics, competitive predictive performance, and enhanced interpretability. Our results highlight a practical path toward transparent and accountable QML models for financial decision-making.",
        "subjects": "Machine Learning, Quantum Physics",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.382959"
    },
    {
        "index": "#83",
        "title": "AlignFlow: Improving Flow-based Generative Models with Semi-Discrete Optimal Transport",
        "link": "/arxiv/2510.15038",
        "arxiv_id": "2510.15038",
        "authors": "Lingkai Kong, Molei Tao, Yang Liu, Bryan Wang, Jinmiao Fu, Chien-Chih Wang, Huidong Liu",
        "summary": "Flow-based Generative Models (FGMs) effectively transform noise into complex data distributions. Incorporating Optimal Transport (OT) to couple noise and data during FGM training has been shown to improve the straightness of flow trajectories, enabling more effective inference. However, existing OT-based methods estimate the OT plan using (mini-)batches of sampled noise and data points, which limits their scalability to large and high-dimensional datasets in FGMs. This paper introduces AlignFlow, a novel approach that leverages Semi-Discrete Optimal Transport (SDOT) to enhance the training of FGMs by establishing an explicit, optimal alignment between noise distribution and data points with guaranteed convergence. SDOT computes a transport map by partitioning the noise space into Laguerre cells, each mapped to a corresponding data point. During FGM training, i.i.d. noise samples are paired with data points via the SDOT map. AlignFlow scales well to large datasets and model architectures with negligible computational overhead. Experimental results show that AlignFlow improves the performance of a wide range of state-of-the-art FGM algorithms and can be integrated as a plug-and-play component. Code is available at: https://github.com/konglk1203/AlignFlow.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.383375"
    },
    {
        "index": "#84",
        "title": "Hybrid Autoencoder-Based Framework for Early Fault Detection in Wind Turbines",
        "link": "/arxiv/2510.15010",
        "arxiv_id": "2510.15010",
        "authors": "Rekha R Nair, Tina Babu, Alavikunhu Panthakkan, Balamurugan Balusamy, Wathiq Mansoor",
        "summary": "Wind turbine reliability is critical to the growing renewable energy sector, where early fault detection significantly reduces downtime and maintenance costs. This paper introduces a novel ensemble-based deep learning framework for unsupervised anomaly detection in wind turbines. The method integrates Variational Autoencoders (VAE), LSTM Autoencoders, and Transformer architectures, each capturing different temporal and contextual patterns from high-dimensional SCADA data. A unique feature engineering pipeline extracts temporal, statistical, and frequency-domain indicators, which are then processed by the deep models. Ensemble scoring combines model predictions, followed by adaptive thresholding to detect operational anomalies without requiring labeled fault data. Evaluated on the CARE dataset containing 89 years of real-world turbine data across three wind farms, the proposed method achieves an AUC-ROC of 0.947 and early fault detection up to 48 hours prior to failure. This approach offers significant societal value by enabling predictive maintenance, reducing turbine failures, and enhancing operational efficiency in large-scale wind energy deployments.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.383780"
    },
    {
        "index": "#85",
        "title": "ES-C51: Expected Sarsa Based C51 Distributional Reinforcement Learning Algorithm",
        "link": "/arxiv/2510.15006",
        "arxiv_id": "2510.15006",
        "authors": "Rijul Tandon, Peter Vamplew, Cameron Foale",
        "summary": "In most value-based reinforcement learning (RL) algorithms, the agent estimates only the expected reward for each action and selects the action with the highest reward. In contrast, Distributional Reinforcement Learning (DRL) estimates the entire probability distribution of possible rewards, providing richer information about uncertainty and variability. C51 is a popular DRL algorithm for discrete action spaces. It uses a Q-learning approach, where the distribution is learned using a greedy Bellman update. However, this can cause problems if multiple actions at a state have similar expected reward but with different distributions, as the algorithm may not learn a stable distribution. This study presents a modified version of C51 (ES-C51) that replaces the greedy Q-learning update with an Expected Sarsa update, which uses a softmax calculation to combine information from all possible actions at a state rather than relying on a single best action. This reduces instability when actions have similar expected rewards and allows the agent to learn higher-performing policies. This approach is evaluated on classic control environments from Gym, and Atari-10 games. For a fair comparison, we modify the standard C51's exploration strategy from e-greedy to softmax, which we refer to as QL-C51 (Q- Learning based C51). The results demonstrate that ES-C51 outperforms QL-C51 across many environments.",
        "subjects": "Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.384126"
    },
    {
        "index": "#86",
        "title": "TangledFeatures: Robust Feature Selection in Highly Correlated Spaces",
        "link": "/arxiv/2510.15005",
        "arxiv_id": "2510.15005",
        "authors": "Allen Daniel Sunny",
        "summary": "Feature selection is a fundamental step in model development, shaping both predictive performance and interpretability. Yet, most widely used methods focus on predictive accuracy, and their performance degrades in the presence of correlated predictors. To address this gap, we introduce TangledFeatures, a framework for feature selection in correlated feature spaces. It identifies representative features from groups of entangled predictors, reducing redundancy while retaining explanatory power. The resulting feature subset can be directly applied in downstream models, offering a more interpretable and stable basis for analysis compared to traditional selection techniques. We demonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying it to the prediction of backbone torsional angles and show that the selected features correspond to structurally meaningful intra-atomic distances that explain variation in these angles.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.384465"
    },
    {
        "index": "#87",
        "title": "Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators",
        "link": "/arxiv/2510.14983",
        "arxiv_id": "2510.14983",
        "authors": "Oskar Triebe, Fletcher Passow, Simon Wittner, Leonie Wagner, Julio Arend, Tao Sun, Chad Zanocco, Marek Miltner, Arezou Ghesmati, Chen-Hao Tsai, Christoph Bergmeir, Ram Rajagopal",
        "summary": "The reliability of local power grid infrastructure is challenged by sustainable energy developments increasing electric load uncertainty. Transmission System Operators (TSOs) need load forecasts of higher spatial resolution, extending current forecasting operations from zonal aggregates to individual nodes. However, nodal loads are less accurate to forecast and require a large number of individual forecasts, which are hard to manage for the human experts assessing risks in the control room's daily operations (operator). In collaboration with a TSO, we design a multi-level system that meets the needs of operators for hourly day-ahead load forecasting. Utilizing a uniquely extensive dataset of zonal and nodal net loads, we experimentally evaluate our system components. First, we develop an interpretable and scalable forecasting model that allows for TSOs to gradually extend zonal operations to include nodal forecasts. Second, we evaluate solutions to address the heterogeneity and volatility of nodal load, subject to a trade-off. Third, our system is manageable with a fully parallelized single-model forecasting workflow. Our results show accuracy and interpretability improvements for zonal forecasts, and substantial improvements for nodal forecasts. In practice, our multi-level forecasting system allows operators to adjust forecasts with unprecedented confidence and accuracy, and to diagnose otherwise opaque errors precisely.",
        "subjects": "Machine Learning, Human-Computer Interaction, Systems and Control",
        "date": "2025-09-02",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.384957"
    },
    {
        "index": "#89",
        "title": "Blackwell's Approachability for Sequential Conformal Inference",
        "link": "/arxiv/2510.15824",
        "arxiv_id": "2510.15824",
        "authors": "Guillaume Principato, Gilles Stoltz",
        "summary": "We study conformal inference in non-exchangeable environments through the lens of Blackwell's theory of approachability. We first recast adaptive conformal inference (ACI, Gibbs and Candès, 2021) as a repeated two-player vector-valued finite game and characterize attainable coverage--efficiency tradeoffs. We then construct coverage and efficiency objectives under potential restrictions on the adversary's play, and design a calibration-based approachability strategy to achieve these goals. The resulting algorithm enjoys strong theoretical guarantees and provides practical insights, though its computational burden may limit deployment in practice.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.385668"
    },
    {
        "index": "#90",
        "title": "Error analysis of a compositional score-based algorithm for simulation-based inference",
        "link": "/arxiv/2510.15817",
        "arxiv_id": "2510.15817",
        "authors": "Camille Touron, Gabriel V. Cardoso, Julyan Arbel, Pedro L. C. Rodrigues",
        "summary": "Simulation-based inference (SBI) has become a widely used framework in applied sciences for estimating the parameters of stochastic models that best explain experimental observations. A central question in this setting is how to effectively combine multiple observations in order to improve parameter inference and obtain sharper posterior distributions. Recent advances in score-based diffusion methods address this problem by constructing a compositional score, obtained by aggregating individual posterior scores within the diffusion process. While it is natural to suspect that the accumulation of individual errors may significantly degrade sampling quality as the number of observations grows, this important theoretical issue has so far remained unexplored. In this paper, we study the compositional score produced by the GAUSS algorithm of Linhart et al. (2024) and establish an upper bound on its mean squared error in terms of both the individual score errors and the number of observations. We illustrate our theoretical findings on a Gaussian example, where all analytical expressions can be derived in a closed form.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.386046"
    },
    {
        "index": "#91",
        "title": "On Universality of Deep Equivariant Networks",
        "link": "/arxiv/2510.15814",
        "arxiv_id": "2510.15814",
        "authors": "Marco Pacini, Mircea Petrache, Bruno Lepri, Shubhendu Trivedi, Robin Walters",
        "summary": "Universality results for equivariant neural networks remain rare. Those that do exist typically hold only in restrictive settings: either they rely on regular or higher-order tensor representations, leading to impractically high-dimensional hidden spaces, or they target specialized architectures, often confined to the invariant setting. This work develops a more general account. For invariant networks, we establish a universality theorem under separation constraints, showing that the addition of a fully connected readout layer secures approximation within the class of separation-constrained continuous functions. For equivariant networks, where results are even scarcer, we demonstrate that standard separability notions are inadequate and introduce the sharper criterion of $\\textit{entry-wise separability}$. We show that with sufficient depth or with the addition of appropriate readout layers, equivariant networks attain universality within the entry-wise separable regime. Together with prior results showing the failure of universality for shallow models, our findings identify depth and readout layers as a decisive mechanism for universality, additionally offering a unified perspective that subsumes and extends earlier specialized results.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.391576"
    },
    {
        "index": "#92",
        "title": "DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation",
        "link": "/arxiv/2510.15786",
        "arxiv_id": "2510.15786",
        "authors": "Xinyue Xu, Jieqiang Sun, Jing, Dai, Siyuan Chen, Lanjie Ma, Ke Sun, Bin Zhao, Jianbo Yuan, Yiwen Lu",
        "summary": "We present DexCanvas, a large-scale hybrid real-synthetic human manipulation dataset containing 7,000 hours of dexterous hand-object interactions seeded from 70 hours of real human demonstrations, organized across 21 fundamental manipulation types based on the Cutkosky taxonomy. Each entry combines synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters, and per-frame contact points with physically consistent force profiles. Our real-to-sim pipeline uses reinforcement learning to train policies that control an actuated MANO hand in physics simulation, reproducing human demonstrations while discovering the underlying contact forces that generate the observed object motion. DexCanvas is the first manipulation dataset to combine large-scale real demonstrations, systematic skill coverage based on established taxonomies, and physics-validated contact annotations. The dataset can facilitate research in robotic manipulation learning, contact-rich control, and skill transfer across different hand morphologies.",
        "subjects": "Robotics, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.392048"
    },
    {
        "index": "#93",
        "title": "Enhanced Renewable Energy Forecasting using Context-Aware Conformal Prediction",
        "link": "/arxiv/2510.15780",
        "arxiv_id": "2510.15780",
        "authors": "Alireza Moradi, Mathieu Tanneau, Reza Zandehshahvar, Pascal Van Hentenryck",
        "summary": "Accurate forecasting is critical for reliable power grid operations, particularly as the share of renewable generation, such as wind and solar, continues to grow. Given the inherent uncertainty and variability in renewable generation, probabilistic forecasts have become essential for informed operational decisions. However, such forecasts frequently suffer from calibration issues, potentially degrading decision-making performance. Building on recent advances in Conformal Predictions, this paper introduces a tailored calibration framework that constructs context-aware calibration sets using a novel weighting scheme. The proposed framework improves the quality of probabilistic forecasts at the site and fleet levels, as demonstrated by numerical experiments on large-scale datasets covering several systems in the United States. The results demonstrate that the proposed approach achieves higher forecast reliability and robustness for renewable energy applications compared to existing baselines.",
        "subjects": "Applications, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.392424"
    },
    {
        "index": "#94",
        "title": "Towards more holistic interpretability: A lightweight disentangled Concept Bottleneck Model",
        "link": "/arxiv/2510.15770",
        "arxiv_id": "2510.15770",
        "authors": "Gaoxiang Huang, Songning Lai, Yutao Yue",
        "summary": "Concept Bottleneck Models (CBMs) enhance interpretability by predicting human-understandable concepts as intermediate representations. However, existing CBMs often suffer from input-to-concept mapping bias and limited controllability, which restricts their practical value, directly damage the responsibility of strategy from concept-based methods. We propose a lightweight Disentangled Concept Bottleneck Model (LDCBM) that automatically groups visual features into semantically meaningful components without region annotation. By introducing a filter grouping loss and joint concept supervision, our method improves the alignment between visual patterns and concepts, enabling more transparent and robust decision-making. Notably, Experiments on three diverse datasets demonstrate that LDCBM achieves higher concept and class accuracy, outperforming previous CBMs in both interpretability and classification performance. By grounding concepts in visual evidence, our method overcomes a fundamental limitation of prior models and enhances the reliability of interpretable AI.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.392796"
    },
    {
        "index": "#96",
        "title": "QSilk: Micrograin Stabilization and Adaptive Quantile Clipping for Detail-Friendly Latent Diffusion",
        "link": "/arxiv/2510.15761",
        "arxiv_id": "2510.15761",
        "authors": "Denis Rychkovskiy",
        "summary": "We present QSilk, a lightweight, always-on stabilization layer for latent diffusion that improves high-frequency fidelity while suppressing rare activation spikes. QSilk combines (i) a per-sample micro clamp that gently limits extreme values without washing out texture, and (ii) Adaptive Quantile Clip (AQClip), which adapts the allowed value corridor per region. AQClip can operate in a proxy mode using local structure statistics or in an attention entropy guided mode (model confidence). Integrated into the CADE 2.5 rendering pipeline, QSilk yields cleaner, sharper results at low step counts and ultra-high resolutions with negligible overhead. It requires no training or fine-tuning and exposes minimal user controls. We report consistent qualitative improvements across SD/SDXL backbones and show synergy with CFG/Rescale, enabling slightly higher guidance without artifacts.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.393513"
    },
    {
        "index": "#97",
        "title": "Semantic segmentation with coarse annotations",
        "link": "/arxiv/2510.15756",
        "arxiv_id": "2510.15756",
        "authors": "Jort de Jong, Mike Holenderski",
        "summary": "Semantic segmentation is the task of classifying each pixel in an image. Training a segmentation model achieves best results using annotated images, where each pixel is annotated with the corresponding class. When obtaining fine annotations is difficult or expensive, it may be possible to acquire coarse annotations, e.g. by roughly annotating pixels in an images leaving some pixels around the boundaries between classes unlabeled. Segmentation with coarse annotations is difficult, in particular when the objective is to optimize the alignment of boundaries between classes. This paper proposes a regularization method for models with an encoder-decoder architecture with superpixel based upsampling. It encourages the segmented pixels in the decoded image to be SLIC-superpixels, which are based on pixel color and position, independent of the segmentation annotation. The method is applied to FCN-16 fully convolutional network architecture and evaluated on the SUIM, Cityscapes, and PanNuke data sets. It is shown that the boundary recall improves significantly compared to state-of-the-art models when trained on coarse annotations.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.393880"
    },
    {
        "index": "#98",
        "title": "A Split-Client Approach to Second-Order Optimization",
        "link": "/arxiv/2510.15714",
        "arxiv_id": "2510.15714",
        "authors": "El Mahdi Chayti, Martin Jaggi",
        "summary": "Second-order methods promise faster convergence but are rarely used in practice because Hessian computations and decompositions are far more expensive than gradients. We propose a \\emph{split-client} framework where gradients and curvature are computed asynchronously by separate clients. This abstraction captures realistic delays and inexact Hessian updates while avoiding the manual tuning required by Lazy Hessian methods. Focusing on cubic regularization, we show that our approach retains strong convergence guarantees and achieves a provable wall-clock speedup of order $\\sqrt{\\tau}$, where $\\tau$ is the relative time needed to compute and decompose the Hessian compared to a gradient step. Since $\\tau$ can be orders of magnitude larger than one in high-dimensional problems, this improvement is practically significant. Experiments on synthetic and real datasets confirm the theory: asynchronous curvature consistently outperforms vanilla and Lazy Hessian baselines, while maintaining second-order accuracy.",
        "subjects": "Optimization and Control, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.394231"
    },
    {
        "index": "#100",
        "title": "Disentanglement of Sources in a Multi-Stream Variational Autoencoder",
        "link": "/arxiv/2510.15669",
        "arxiv_id": "2510.15669",
        "authors": "Veranika Boukun, Jörg Lücke",
        "summary": "Variational autoencoders (VAEs) are a leading approach to address the problem of learning disentangled representations. Typically a single VAE is used and disentangled representations are sought in its continuous latent space. Here we explore a different approach by using discrete latents to combine VAE-representations of individual sources. The combination is done based on an explicit model for source combination, and we here use a linear combination model which is well suited, e.g., for acoustic data. We formally define such a multi-stream VAE (MS-VAE) approach, derive its inference and learning equations, and we numerically investigate its principled functionality. The MS-VAE is domain-agnostic, and we here explore its ability to separate sources into different streams using superimposed hand-written digits, and mixed acoustic sources in a speaker diarization task. We observe a clear separation of digits, and on speaker diarization we observe an especially low rate of missed speakers. Numerical experiments further highlight the flexibility of the approach across varying amounts of supervision and training data.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.394966"
    },
    {
        "index": "#101",
        "title": "Bayesian Inference for PDE-based Inverse Problems using the Optimization of a Discrete Loss",
        "link": "/arxiv/2510.15664",
        "arxiv_id": "2510.15664",
        "authors": "Lucas Amoudruz, Sergey Litvinov, Costas Papadimitriou, Petros Koumoutsakos",
        "summary": "Inverse problems are crucial for many applications in science, engineering and medicine that involve data assimilation, design, and imaging. Their solution infers the parameters or latent states of a complex system from noisy data and partially observable processes. When measurements are an incomplete or indirect view of the system, additional knowledge is required to accurately solve the inverse problem. Adopting a physical model of the system in the form of partial differential equations (PDEs) is a potent method to close this gap. In particular, the method of optimizing a discrete loss (ODIL) has shown great potential in terms of robustness and computational cost. In this work, we introduce B-ODIL, a Bayesian extension of ODIL, that integrates the PDE loss of ODIL as prior knowledge and combines it with a likelihood describing the data. B-ODIL employs a Bayesian formulation of PDE-based inverse problems to infer solutions with quantified uncertainties. We demonstrate the capabilities of B-ODIL in a series of synthetic benchmarks involving PDEs in one, two, and three dimensions. We showcase the application of B-ODIL in estimating tumor concentration and its uncertainty in a patient's brain from MRI scans using a three-dimensional tumor growth model.",
        "subjects": "Methodology, Machine Learning, Computational Physics",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.395354"
    },
    {
        "index": "#102",
        "title": "GOGH: Correlation-Guided Orchestration of GPUs in Heterogeneous Clusters",
        "link": "/arxiv/2510.15652",
        "arxiv_id": "2510.15652",
        "authors": "Ahmad Raeisi, Mahdi Dolati, Sina Darabi, Sadegh Talebi, Patrick Eugster, Ahmad Khonsari",
        "summary": "The growing demand for computational resources in machine learning has made efficient resource allocation a critical challenge, especially in heterogeneous hardware clusters where devices vary in capability, age, and energy efficiency. Upgrading to the latest hardware is often infeasible, making sustainable use of existing, mixed-generation resources essential. In this paper, we propose a learning-based architecture for managing machine learning workloads in heterogeneous clusters. The system operates online, allocating resources to incoming training or inference requests while minimizing energy consumption and meeting performance requirements. It uses two neural networks: the first provides initial estimates of how well a new model will utilize different hardware types and how it will affect co-located models. An optimizer then allocates resources based on these estimates. After deployment, the system monitors real performance and uses this data to refine its predictions via a second neural network. This updated model improves estimates not only for the current hardware but also for hardware not initially allocated and for co-location scenarios not yet observed. The result is an adaptive, iterative approach that learns over time to make more effective resource allocation decisions in heterogeneous deep learning clusters.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.395765"
    },
    {
        "index": "#104",
        "title": "Stochastic Optimization with Random Search",
        "link": "/arxiv/2510.15610",
        "arxiv_id": "2510.15610",
        "authors": "El Mahdi Chayti, Taha El Bakkali El Kadi, Omar Saadi, Martin Jaggi",
        "summary": "We revisit random search for stochastic optimization, where only noisy function evaluations are available. We show that the method works under weaker smoothness assumptions than previously considered, and that stronger assumptions enable improved guarantees. In the finite-sum setting, we design a variance-reduced variant that leverages multiple samples to accelerate convergence. Our analysis relies on a simple translation invariance property, which provides a principled way to balance noise and reduce variance.",
        "subjects": "Optimization and Control, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.402099"
    },
    {
        "index": "#105",
        "title": "Kernel-Based Evaluation of Conditional Biological Sequence Models",
        "link": "/arxiv/2510.15601",
        "arxiv_id": "2510.15601",
        "authors": "Pierre Glaser, Steffanie Paul, Alissa M. Hummer, Charlotte M. Deane, Debora S. Marks, Alan N. Amin",
        "summary": "We propose a set of kernel-based tools to evaluate the designs and tune the hyperparameters of conditional sequence models, with a focus on problems in computational biology. The backbone of our tools is a new measure of discrepancy between the true conditional distribution and the model's estimate, called the Augmented Conditional Maximum Mean Discrepancy (ACMMD). Provided that the model can be sampled from, the ACMMD can be estimated unbiasedly from data to quantify absolute model fit, integrated within hypothesis tests, and used to evaluate model reliability. We demonstrate the utility of our approach by analyzing a popular protein design model, ProteinMPNN. We are able to reject the hypothesis that ProteinMPNN fits its data for various protein families, and tune the model's temperature hyperparameter to achieve a better fit.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.402508"
    },
    {
        "index": "#107",
        "title": "Geometric Convergence Analysis of Variational Inference via Bregman Divergences",
        "link": "/arxiv/2510.15548",
        "arxiv_id": "2510.15548",
        "authors": "Sushil Bohara, Amedeo Roberto Esposito",
        "summary": "Variational Inference (VI) provides a scalable framework for Bayesian inference by optimizing the Evidence Lower Bound (ELBO), but convergence analysis remains challenging due to the objective's non-convexity and non-smoothness in Euclidean space. We establish a novel theoretical framework for analyzing VI convergence by exploiting the exponential family structure of distributions. We express negative ELBO as a Bregman divergence with respect to the log-partition function, enabling a geometric analysis of the optimization landscape. We show that this Bregman representation admits a weak monotonicity property that, while weaker than convexity, provides sufficient structure for rigorous convergence analysis. By deriving bounds on the objective function along rays in parameter space, we establish properties governed by the spectral characteristics of the Fisher information matrix. Under this geometric framework, we prove non-asymptotic convergence rates for gradient descent algorithms with both constant and diminishing step sizes.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.403264"
    },
    {
        "index": "#108",
        "title": "Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors",
        "link": "/arxiv/2510.15547",
        "arxiv_id": "2510.15547",
        "authors": "Usman Ali, Ali Zia, Waqas Ali, Umer Ramzan, Abdul Rehman, Muhammad Tayyab Chaudhry, Wei Xiang",
        "summary": "Reliable induction motor (IM) fault diagnosis is vital for industrial safety and operational continuity, mitigating costly unplanned downtime. Conventional approaches often struggle to capture complex multimodal signal relationships, are constrained to unimodal data or single fault types, and exhibit performance degradation under noisy or cross-domain conditions. This paper proposes the Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is the first to integrate contrastive learning within a hypergraph topology specifically designed for multimodal sensor fusion, enabling the joint modelling of intra- and inter-modal dependencies and enhancing generalisation beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis of bearing, stator, and rotor faults, addressing the engineering need for consolidated di- agnostic capabilities. Evaluated on three real-world benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain generalisation and resilience to noise, demonstrating its suitability for real-world deployment. An ablation study validates the contribution of each component. MM-HCAN provides a scalable and robust solution for comprehensive multi-fault diagnosis, supporting predictive maintenance and extended asset longevity in industrial environments.",
        "subjects": "Artificial Intelligence, Emerging Technologies, Machine Learning, Signal Processing, Systems and Control",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.403740"
    },
    {
        "index": "#109",
        "title": "SpikeFit: Towards Optimal Deployment of Spiking Networks on Neuromorphic Hardware",
        "link": "/arxiv/2510.15542",
        "arxiv_id": "2510.15542",
        "authors": "Ivan Kartashov, Mariia Pushkareva, Iakov Karandashev",
        "summary": "This paper introduces SpikeFit, a novel training method for Spiking Neural Networks (SNNs) that enables efficient inference on neuromorphic hardware, considering all its stringent requirements: the number of neurons and synapses that can fit on a single device, and lower bit-width representations (e.g., 4-bit, 8-bit). Unlike conventional compressing approaches that address only a subset of these requirements (limited numerical precision and limited number of neurons in the network), SpikeFit treats the allowed weights' discrete values themselves as learnable parameters co-optimized with the model, allowing for optimal Clusterization-Aware Training (CAT) of the model's weights at low precision (2-, 4-, or 8-bit) which results in higher network compression efficiency, as well as limiting the number of unique synaptic connections to a value required by neuromorphic processor. This joint optimization allows SpikeFit to find a discrete weight set aligned with hardware constraints, enabling the most complete deployment across a broader range of neuromorphic processors than existing methods of SNN compression support. Moreover, SpikeFit introduces a new hardware-friendly Fisher Spike Contribution (FSC) pruning method showing the state-of-the-art performance. We demonstrate that for spiking neural networks constrained to only four unique synaptic weight values (M = 4), our SpikeFit method not only outperforms state-of-the-art SNNs compression methods and conventional baselines combining extreme quantization schemes and clustering algorithms, but also meets a wider range of neuromorphic hardware requirements and provides the lowest energy use in experiments.",
        "subjects": "Neural and Evolutionary Computing, Machine Learning, Neurons and Cognition",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.404123"
    },
    {
        "index": "#110",
        "title": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation",
        "link": "/arxiv/2510.15530",
        "arxiv_id": "2510.15530",
        "authors": "Zehao Ni, Yonghao He, Lingfeng Qian, Jilei Mao, Fa Fu, Wei Sui, Hu Su, Junran Peng, Zhipeng Wang, Bin He",
        "summary": "In the context of imitation learning, visuomotor-based diffusion policy learning is one of the main directions in robotic manipulation. Most of these approaches rely on point clouds as observation inputs and construct scene representations through point clouds feature learning, which enables them to achieve remarkable accuracy. However, the existing literature lacks an in-depth exploration of vision-only solutions that have significant potential. In this paper, we propose a Vision-Only and single-view Diffusion Policy learning method (VO-DP) that leverages pretrained visual foundation models to achieve effective fusion of semantic and geometric features. We utilize intermediate features from VGGT incorporating semantic features from DINOv2 and geometric features from Alternating Attention blocks. Features are fused via cross-attention and spatially compressed with a CNN to form the input to the policy head. Extensive experiments demonstrate that VO-DP not only outperforms the vision-only baseline DP significantly but also exhibits distinct performance trends against the point cloud-based method DP3: in simulation tasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0% and far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%, outperforming both DP3 67.5% and DP 11.2% by a notable margin. Further robustness evaluations confirm that VO-DP remains highly stable under varying conditions including color, size, background, and lighting. Lastly, we open-source a training library for robotic manipulation. Built on Accelerate, this library supports multi-machine and multi-GPU parallel training, as well as mixed precision training. It is compatible with visuomotor policies such as DP, DP3 and VO-DP, and also supports the RoboTwin simulator.",
        "subjects": "Robotics, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.404590"
    },
    {
        "index": "#111",
        "title": "Latent Feature Alignment: Discovering Biased and Interpretable Subpopulations in Face Recognition Models",
        "link": "/arxiv/2510.15520",
        "arxiv_id": "2510.15520",
        "authors": "Ignacio Serna",
        "summary": "Modern face recognition models achieve high overall accuracy but continue to exhibit systematic biases that disproportionately affect certain subpopulations. Conventional bias evaluation frameworks rely on labeled attributes to form subpopulations, which are expensive to obtain and limited to predefined categories. We introduce Latent Feature Alignment (LFA), an attribute-label-free algorithm that uses latent directions to identify subpopulations. This yields two main benefits over standard clustering: (i) semantically coherent grouping, where faces sharing common attributes are grouped together more reliably than by proximity-based methods, and (ii) discovery of interpretable directions, which correspond to semantic attributes such as age, ethnicity, or attire. Across four state-of-the-art recognition models (ArcFace, CosFace, ElasticFace, PartialFC) and two benchmarks (RFW, CelebA), LFA consistently outperforms k-means and nearest-neighbor search in intra-group semantic coherence, while uncovering interpretable latent directions aligned with demographic and contextual attributes. These results position LFA as a practical method for representation auditing of face recognition models, enabling practitioners to identify and interpret biased subpopulations without predefined attribute annotations.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.404933"
    },
    {
        "index": "#113",
        "title": "AI and analytics in sports: Leveraging BERTopic to map the past and chart the future",
        "link": "/arxiv/2510.15487",
        "arxiv_id": "2510.15487",
        "authors": "Manit Mishra",
        "summary": "Purpose: The purpose of this study is to map the body of scholarly literature at the intersection of artificial intelligence (AI), analytics and sports and thereafter, leverage the insights generated to chart guideposts for future research. Design/methodology/approach: The study carries out systematic literature review (SLR). Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) protocol is leveraged to identify 204 journal articles pertaining to utilization of AI and analytics in sports published during 2002 to 2024. We follow it up with extraction of the latent topics from sampled articles by leveraging the topic modelling technique of BERTopic. Findings: The study identifies the following as predominant areas of extant research on usage of AI and analytics in sports: performance modelling, physical and mental health, social media sentiment analysis, and tactical tracking. Each extracted topic is further examined in terms of its relative prominence, representative studies, and key term associations. Drawing on these insights, the study delineates promising avenues for future inquiry. Research limitations/implications: The study offers insights to academicians and sports administrators on transformational impact of AI and analytics in sports. Originality/value: The study introduces BERTopic as a novel approach for extracting latent structures in sports research, thereby advancing both scholarly understanding and the methodological toolkit of the field.",
        "subjects": "Applications, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.405681"
    },
    {
        "index": "#114",
        "title": "Online Policy Learning via a Self-Normalized Maximal Inequality",
        "link": "/arxiv/2510.15483",
        "arxiv_id": "2510.15483",
        "authors": "Samuel Girard, Aurélien Bibaut, Houssam Zenati",
        "summary": "Adaptive experiments produce dependent data that break i.i.d. assumptions that underlie classical concentration bounds and invalidate standard learning guarantees. In this paper, we develop a self-normalized maximal inequality for martingale empirical processes. Building on this, we first propose an adaptive sample-variance penalization procedure which balances empirical loss and sample variance, valid for general dependent data. Next, this allows us to derive a new variance-regularized pessimistic off-policy learning objective, for which we establish excess-risk guarantees. Subsequently, we show that, when combined with sequential updates and under standard complexity and margin conditions, the resulting estimator achieves fast convergence rates in both parametric and nonparametric regimes, improving over the usual $1/\\sqrt{n}$ baseline. We complement our theoretical findings with numerical simulations that illustrate the practical gains of our approach.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.406035"
    },
    {
        "index": "#115",
        "title": "Robust Optimization in Causal Models and G-Causal Normalizing Flows",
        "link": "/arxiv/2510.15458",
        "arxiv_id": "2510.15458",
        "authors": "Gabriele Visentin, Patrick Cheridito",
        "summary": "In this paper, we show that interventionally robust optimization problems in causal models are continuous under the $G$-causal Wasserstein distance, but may be discontinuous under the standard Wasserstein distance. This highlights the importance of using generative models that respect the causal structure when augmenting data for such tasks. To this end, we propose a new normalizing flow architecture that satisfies a universal approximation property for causal structural models and can be efficiently trained to minimize the $G$-causal Wasserstein distance. Empirically, we demonstrate that our model outperforms standard (non-causal) generative models in data augmentation for causal regression and mean-variance portfolio optimization in causal factor models.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning, Portfolio Management",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.406418"
    },
    {
        "index": "#116",
        "title": "Nonlinear Dimensionality Reduction Techniques for Bayesian Optimization",
        "link": "/arxiv/2510.15435",
        "arxiv_id": "2510.15435",
        "authors": "Luo Long, Coralia Cartis, Paz Fink Shustin",
        "summary": "Bayesian optimisation (BO) is a standard approach for sample-efficient global optimisation of expensive black-box functions, yet its scalability to high dimensions remains challenging. Here, we investigate nonlinear dimensionality reduction techniques that reduce the problem to a sequence of low-dimensional Latent-Space BO (LSBO). While early LSBO methods used (linear) random projections (Wang et al., 2013), building on Grosnit et al. (2021), we employ Variational Autoencoders (VAEs) for LSBO, focusing on deep metric loss for structured latent manifolds and VAE retraining to adapt the encoder-decoder to newly sampled regions. We propose some changes in their implementation, originally designed for tasks such as molecule generation, and reformulate the algorithm for broader optimisation purposes. We then couple LSBO with Sequential Domain Reduction (SDR) directly in the latent space (SDR-LSBO), yielding an algorithm that narrows the latent search domains as evidence accumulates. Implemented in a GPU-accelerated BoTorch stack with Matern-5/2 Gaussian process surrogates, our numerical results show improved optimisation quality across benchmark tasks and that structured latent manifolds improve BO performance. Additionally, we compare random embeddings and VAEs as two mechanisms for dimensionality reduction, showing that the latter outperforms the former. To the best of our knowledge, this is the first study to combine SDR with VAE-based LSBO, and our analysis clarifies design choices for metric shaping and retraining that are critical for scalable latent space BO. For reproducibility, our source code is available at https://github.com/L-Lok/Nonlinear-Dimensionality-Reduction-Techniques-for-Bayesian-Optimization.git.",
        "subjects": "Optimization and Control, Machine Learning, Numerical Analysis",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.406802"
    },
    {
        "index": "#117",
        "title": "Semantic4Safety: Causal Insights from Zero-shot Street View Imagery Segmentation for Urban Road Safety",
        "link": "/arxiv/2510.15434",
        "arxiv_id": "2510.15434",
        "authors": "Huan Chen, Ting Han, Siyu Chen, Zhihao Guo, Yiping Chen, Meiliu Wu",
        "summary": "Street-view imagery (SVI) offers a fine-grained lens on traffic risk, yet two fundamental challenges persist: (1) how to construct street-level indicators that capture accident-related features, and (2) how to quantify their causal impacts across different accident types. To address these challenges, we propose Semantic4Safety, a framework that applies zero-shot semantic segmentation to SVIs to derive 11 interpretable streetscape indicators, and integrates road type as contextual information to analyze approximately 30,000 accident records in Austin. Specifically, we train an eXtreme Gradient Boosting (XGBoost) multi-class classifier and use Shapley Additive Explanations (SHAP) to interpret both global and local feature contributions, and then apply Generalized Propensity Score (GPS) weighting and Average Treatment Effect (ATE) estimation to control confounding and quantify causal effects. Results uncover heterogeneous, accident-type-specific causal patterns: features capturing scene complexity, exposure, and roadway geometry dominate predictive power; larger drivable area and emergency space reduce risk, whereas excessive visual openness can increase it. By bridging predictive modeling with causal inference, Semantic4Safety supports targeted interventions and high-risk corridor diagnosis, offering a scalable, data-informed tool for urban road safety planning.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.412318"
    },
    {
        "index": "#118",
        "title": "Information Theory in Open-world Machine Learning Foundations, Frameworks, and Future Direction",
        "link": "/arxiv/2510.15422",
        "arxiv_id": "2510.15422",
        "authors": "Lin Wang",
        "summary": "Open world Machine Learning (OWML) aims to develop intelligent systems capable of recognizing known categories, rejecting unknown samples, and continually learning from novel information. Despite significant progress in open set recognition, novelty detection, and continual learning, the field still lacks a unified theoretical foundation that can quantify uncertainty, characterize information transfer, and explain learning adaptability in dynamic, nonstationary environments. This paper presents a comprehensive review of information theoretic approaches in open world machine learning, emphasizing how core concepts such as entropy, mutual information, and Kullback Leibler divergence provide a mathematical language for describing knowledge acquisition, uncertainty suppression, and risk control under open world conditions. We synthesize recent studies into three major research axes: information theoretic open set recognition enabling safe rejection of unknowns, information driven novelty discovery guiding new concept formation, and information retentive continual learning ensuring stable long term adaptation. Furthermore, we discuss theoretical connections between information theory and provable learning frameworks, including PAC Bayes bounds, open-space risk theory, and causal information flow, to establish a pathway toward provable and trustworthy open world intelligence. Finally, the review identifies key open problems and future research directions, such as the quantification of information risk, development of dynamic mutual information bounds, multimodal information fusion, and integration of information theory with causal reasoning and world model learning.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.412670"
    },
    {
        "index": "#119",
        "title": "LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding",
        "link": "/arxiv/2510.15392",
        "arxiv_id": "2510.15392",
        "authors": "Peng Ren, Hai Yang",
        "summary": "Generating long and stylized human motions in real time is critical for applications that demand continuous and responsive character control. Despite its importance, existing streaming approaches often operate directly in the raw motion space, leading to substantial computational overhead and making it difficult to maintain temporal stability. In contrast, latent-space VAE-Diffusion-based frameworks alleviate these issues and achieve high-quality stylization, but they are generally confined to offline processing. To bridge this gap, LILAC (Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding) builds upon a recent high-performing offline framework for arbitrary motion stylization and extends it to an online setting through a latent-space streaming architecture with a sliding-window causal design and the injection of decoded motion features to ensure smooth motion transitions. This architecture enables long-sequence real-time arbitrary stylization without relying on future frames or modifying the diffusion model architecture, achieving a favorable balance between stylization quality and responsiveness as demonstrated by experiments on benchmark datasets. Supplementary video and examples are available at the project page: https://pren1.github.io/lilac/",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.413025"
    },
    {
        "index": "#120",
        "title": "Recursive Inference for Heterogeneous Multi-Output GP State-Space Models with Arbitrary Moment Matching",
        "link": "/arxiv/2510.15390",
        "arxiv_id": "2510.15390",
        "authors": "Tengjie Zheng, Jilan Mei, Di Wu, Lin Cheng, Shengping Gong",
        "summary": "Accurate learning of system dynamics is becoming increasingly crucial for advanced control and decision-making in engineering. However, real-world systems often exhibit multiple channels and highly nonlinear transition dynamics, challenging traditional modeling methods. To enable online learning for these systems, this paper formulates the system as Gaussian process state-space models (GPSSMs) and develops a recursive learning method. The main contributions are threefold. First, a heterogeneous multi-output kernel is designed, allowing each output dimension to adopt distinct kernel types, hyperparameters, and input variables, improving expressiveness in multi-dimensional dynamics learning. Second, an inducing-point management algorithm enhances computational efficiency through independent selection and pruning for each output dimension. Third, a unified recursive inference framework for GPSSMs is derived, supporting general moment matching approaches, including the extended Kalman filter (EKF), unscented Kalman filter (UKF), and assumed density filtering (ADF), enabling accurate learning under strong nonlinearity and significant noise. Experiments on synthetic and real-world datasets show that the proposed method matches the accuracy of SOTA offline GPSSMs with only 1/100 of the runtime, and surpasses SOTA online GPSSMs by around 70% in accuracy under heavy noise while using only 1/20 of the runtime.",
        "subjects": "Machine Learning, Machine Learning, Systems and Control",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.413422"
    },
    {
        "index": "#121",
        "title": "Towards Flash Thinking via Decoupled Advantage Policy Optimization",
        "link": "/arxiv/2510.15374",
        "arxiv_id": "2510.15374",
        "authors": "Zezhong Tan, Hang Gao, Xinhong Ma, Feng Zhang, Ziqiang Dong",
        "summary": "Recent Large Reasoning Models (LRMs) have achieved remarkable performance in solving complex problems via supervised fine-tuning (SFT) and reinforcement learning (RL). Although existing RL algorithms significantly enhance model accuracy, they still suffer from excessively lengthy responses and overthinking issues, resulting in increased inference latency and computational consumption, especially for simple tasks that require minimal reasoning. To address this, we propose a novel RL framework, DEPO, to reduce inefficient reasoning for models. Our method mainly consists of three core components: (1) an innovative advantage decoupled algorithm to guide model reduction of inefficient tokens; (2) a difficulty-aware length penalty to lower the overall length of model responses; (3) an advantage clipping method to prevent bias in policy optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant reduction in sequence length by 39% and reduces excessive reasoning paths in inefficient tokens, while outperforming the base model in overall accuracy.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.413799"
    },
    {
        "index": "#123",
        "title": "Kernel Regression in Structured Non-IID Settings: Theory and Implications for Denoising Score Learning",
        "link": "/arxiv/2510.15363",
        "arxiv_id": "2510.15363",
        "authors": "Dechen Zhang, Zhenmei Shi, Yi Zhang, Yingyu Liang, Difan Zou",
        "summary": "Kernel ridge regression (KRR) is a foundational tool in machine learning, with recent work emphasizing its connections to neural networks. However, existing theory primarily addresses the i.i.d. setting, while real-world data often exhibits structured dependencies - particularly in applications like denoising score learning where multiple noisy observations derive from shared underlying signals. We present the first systematic study of KRR generalization for non-i.i.d. data with signal-noise causal structure, where observations represent different noisy views of common signals. By developing a novel blockwise decomposition method that enables precise concentration analysis for dependent data, we derive excess risk bounds for KRR that explicitly depend on: (1) the kernel spectrum, (2) causal structure parameters, and (3) sampling mechanisms (including relative sample sizes for signals and noises). We further apply our results to denoising score learning, establishing generalization guarantees and providing principled guidance for sampling noisy data points. This work advances KRR theory while providing practical tools for analyzing dependent data in modern machine learning applications.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.414710"
    },
    {
        "index": "#124",
        "title": "RankSEG-RMA: An Efficient Segmentation Algorithm via Reciprocal Moment Approximation",
        "link": "/arxiv/2510.15362",
        "arxiv_id": "2510.15362",
        "authors": "Zixun Wang, Ben Dai",
        "summary": "Semantic segmentation labels each pixel in an image with its corresponding class, and is typically evaluated using the Intersection over Union (IoU) and Dice metrics to quantify the overlap between predicted and ground-truth segmentation masks. In the literature, most existing methods estimate pixel-wise class probabilities, then apply argmax or thresholding to obtain the final prediction. These methods have been shown to generally lead to inconsistent or suboptimal results, as they do not directly maximize segmentation metrics. To address this issue, a novel consistent segmentation framework, RankSEG, has been proposed, which includes RankDice and RankIoU specifically designed to optimize the Dice and IoU metrics, respectively. Although RankSEG almost guarantees improved performance, it suffers from two major drawbacks. First, it is its computational expense-RankDice has a complexity of O(d log d) with a substantial constant factor (where d represents the number of pixels), while RankIoU exhibits even higher complexity O(d^2), thus limiting its practical application. For instance, in LiTS, prediction with RankSEG takes 16.33 seconds compared to just 0.01 seconds with the argmax rule. Second, RankSEG is only applicable to overlapping segmentation settings, where multiple classes can occupy the same pixel, which contrasts with standard benchmarks that typically assume non-overlapping segmentation. In this paper, we overcome these two drawbacks via a reciprocal moment approximation (RMA) of RankSEG with the following contributions: (i) we improve RankSEG using RMA, namely RankSEG-RMA, reduces the complexity of both algorithms to O(d) while maintaining comparable performance; (ii) inspired by RMA, we develop a pixel-wise score function that allows efficient implementation for non-overlapping segmentation settings.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.415078"
    },
    {
        "index": "#125",
        "title": "Singularity-free dynamical invariants-based quantum control",
        "link": "/arxiv/2510.15340",
        "arxiv_id": "2510.15340",
        "authors": "Ritik Sareen, Akram Youssry, Alberto Peruzzo",
        "summary": "State preparation is a cornerstone of quantum technologies, underpinning applications in computation, communication, and sensing. Its importance becomes even more pronounced in non-Markovian open quantum systems, where environmental memory and model uncertainties pose significant challenges to achieving high-fidelity control. Invariant-based inverse engineering provides a principled framework for synthesizing analytic control fields, yet existing parameterizations often lead to experimentally infeasible, singular pulses and are limited to simplified noise models such as those of Lindblad form. Here, we introduce a generalized invariant-based protocol for single-qubit state preparation under arbitrary noise conditions. The control proceeds in two-stages: first, we construct a family of bounded pulses that achieve perfect state preparation in a closed system; second, we identify the optimal member of this family that minimizes the effect of noise. The framework accommodates both (i) characterized noise, enabling noise-aware control synthesis, and (ii) uncharacterized noise, where a noise-agnostic variant preserves robustness without requiring a master-equation description. Numerical simulations demonstrate high-fidelity state preparation across diverse targets while producing smooth, hardware-feasible control fields. This singularity-free framework extends invariant-based control to realistic open-system regimes, providing a versatile route toward robust quantum state engineering on NISQ hardware and other platforms exhibiting non-Markovian dynamics.",
        "subjects": "Quantum Physics, Machine Learning, Systems and Control",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.415455"
    },
    {
        "index": "#126",
        "title": "Transfer Learning for Benign Overfitting in High-Dimensional Linear Regression",
        "link": "/arxiv/2510.15337",
        "arxiv_id": "2510.15337",
        "authors": "Yeichan Kim, Ilmun Kim, Seyoung Park",
        "summary": "Transfer learning is a key component of modern machine learning, enhancing the performance of target tasks by leveraging diverse data sources. Simultaneously, overparameterized models such as the minimum-$\\ell_2$-norm interpolator (MNI) in high-dimensional linear regression have garnered significant attention for their remarkable generalization capabilities, a property known as benign overfitting. Despite their individual importance, the intersection of transfer learning and MNI remains largely unexplored. Our research bridges this gap by proposing a novel two-step Transfer MNI approach and analyzing its trade-offs. We characterize its non-asymptotic excess risk and identify conditions under which it outperforms the target-only MNI. Our analysis reveals free-lunch covariate shift regimes, where leveraging heterogeneous data yields the benefit of knowledge transfer at limited cost. To operationalize our findings, we develop a data-driven procedure to detect informative sources and introduce an ensemble method incorporating multiple informative Transfer MNIs. Finite-sample experiments demonstrate the robustness of our methods to model and data heterogeneity, confirming their advantage.",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.415845"
    },
    {
        "index": "#127",
        "title": "Layer as Puzzle Pieces: Compressing Large Language Models through Layer Concatenation",
        "link": "/arxiv/2510.15304",
        "arxiv_id": "2510.15304",
        "authors": "Fei Wang, Li Shen, Liang Ding, Chao Xue, Ye Liu, Changxing Ding",
        "summary": "Large Language Models excel at natural language processing tasks, but their massive size leads to high computational and storage demands. Recent works have sought to reduce their model size through layer-wise structured pruning. However, they tend to ignore retaining the capabilities in the pruned part. In this work, we re-examine structured pruning paradigms and uncover several key limitations: 1) notable performance degradation due to direct layer removal, 2) incompetent linear weight layer aggregation, and 3) the lack of effective post-training recovery mechanisms. To address these limitations, we propose CoMe, including a progressive layer pruning framework with a Concatenation-based Merging technology and a hierarchical distillation post-training process. Specifically, we introduce a channel sensitivity metric that utilizes activation intensity and weight norms for fine-grained channel selection. Subsequently, we employ a concatenation-based layer merging method to fuse the most critical channels across adjacent layers, enabling progressive model size reduction. Finally, we propose a hierarchical distillation protocol that leverages the correspondences between the original and pruned model layers established during pruning, thereby enabling efficient knowledge transfer. Experiments on seven benchmarks show that CoMe achieves state-of-the-art performance; when pruning 30% of LLaMA-2-7b's parameters, the pruned model retains 83% of its original average accuracy. Our code is available at https://github.com/MPI-Lab/CoMe.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.416238"
    },
    {
        "index": "#128",
        "title": "Hyperbolic Structured Classification for Robust Single Positive Multi-label Learning",
        "link": "/arxiv/2510.15296",
        "arxiv_id": "2510.15296",
        "authors": "Yiming Lin, Shang Wang, Junkai Zhou, Qiufeng Wang, Xiao-Bo Jin, Kaizhu Huang",
        "summary": "Single Positive Multi-Label Learning (SPMLL) addresses the challenging scenario where each training sample is annotated with only one positive label despite potentially belonging to multiple categories, making it difficult to capture complex label relationships and hierarchical structures. While existing methods implicitly model label relationships through distance-based similarity, lacking explicit geometric definitions for different relationship types. To address these limitations, we propose the first hyperbolic classification framework for SPMLL that represents each label as a hyperbolic ball rather than a point or vector, enabling rich inter-label relationship modeling through geometric ball interactions. Our ball-based approach naturally captures multiple relationship types simultaneously: inclusion for hierarchical structures, overlap for co-occurrence patterns, and separation for semantic independence. Further, we introduce two key component innovations: a temperature-adaptive hyperbolic ball classifier and a physics-inspired double-well regularization that guides balls toward meaningful configurations. To validate our approach, extensive experiments on four benchmark datasets (MS-COCO, PASCAL VOC, NUS-WIDE, CUB-200-2011) demonstrate competitive performance with superior interpretability compared to existing methods. Furthermore, statistical analysis reveals strong correlation between learned embeddings and real-world co-occurrence patterns, establishing hyperbolic geometry as a more robust paradigm for structured classification under incomplete supervision.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.416631"
    },
    {
        "index": "#129",
        "title": "Post-Processing Methods for Improving Accuracy in MRI Inpainting",
        "link": "/arxiv/2510.15282",
        "arxiv_id": "2510.15282",
        "authors": "Nishad Kulkarni, Krithika Iyer, Austin Tapp, Abhijeet Parida, Daniel Capellán-Martín, Zhifan Jiang, María J. Ledesma-Carbayo, Syed Muhammad Anwar, Marius George Linguraru",
        "summary": "Magnetic Resonance Imaging (MRI) is the primary imaging modality used in the diagnosis, assessment, and treatment planning for brain pathologies. However, most automated MRI analysis tools, such as segmentation and registration pipelines, are optimized for healthy anatomies and often fail when confronted with large lesions such as tumors. To overcome this, image inpainting techniques aim to locally synthesize healthy brain tissues in tumor regions, enabling the reliable application of general-purpose tools. In this work, we systematically evaluate state-of-the-art inpainting models and observe a saturation in their standalone performance. In response, we introduce a methodology combining model ensembling with efficient post-processing strategies such as median filtering, histogram matching, and pixel averaging. Further anatomical refinement is achieved via a lightweight U-Net enhancement stage. Comprehensive evaluation demonstrates that our proposed pipeline improves the anatomical plausibility and visual fidelity of inpainted regions, yielding higher accuracy and more robust outcomes than individual baseline models. By combining established models with targeted post-processing, we achieve improved and more accessible inpainting outcomes, supporting broader clinical deployment and sustainable, resource-conscious research. Our 2025 BraTS inpainting docker is available at https://hub.docker.com/layers/aparida12/brats2025/inpt.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.417076"
    },
    {
        "index": "#130",
        "title": "Foresighted Online Policy Optimization with Interference",
        "link": "/arxiv/2510.15273",
        "arxiv_id": "2510.15273",
        "authors": "Liner Xiang, Jiayi Wang, Hengrui Cai",
        "summary": "Contextual bandits, which leverage the baseline features of sequentially arriving individuals to optimize cumulative rewards while balancing exploration and exploitation, are critical for online decision-making. Existing approaches typically assume no interference, where each individual's action affects only their own reward. Yet, such an assumption can be violated in many practical scenarios, and the oversight of interference can lead to short-sighted policies that focus solely on maximizing the immediate outcomes for individuals, which further results in suboptimal decisions and potentially increased regret over time. To address this significant gap, we introduce the foresighted online policy with interference (FRONT) that innovatively considers the long-term impact of the current decision on subsequent decisions and rewards. The proposed FRONT method employs a sequence of exploratory and exploitative strategies to manage the intricacies of interference, ensuring robust parameter inference and regret minimization. Theoretically, we establish a tail bound for the online estimator and derive the asymptotic distribution of the parameters of interest under suitable conditions on the interference network. We further show that FRONT attains sublinear regret under two distinct definitions, capturing both the immediate and consequential impacts of decisions, and we establish these results with and without statistical inference. The effectiveness of FRONT is further demonstrated through extensive simulations and a real-world application to urban hotel profits.",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory, Methodology",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.422619"
    },
    {
        "index": "#131",
        "title": "Minimisation of Submodular Functions Using Gaussian Zeroth-Order Random Oracles",
        "link": "/arxiv/2510.15257",
        "arxiv_id": "2510.15257",
        "authors": "Amir Ali Farzin, Yuen-Man Pun, Philipp Braun, Tyler Summers, Iman Shames",
        "summary": "We consider the minimisation problem of submodular functions and investigate the application of a zeroth-order method to this problem. The method is based on exploiting a Gaussian smoothing random oracle to estimate the smoothed function gradient. We prove the convergence of the algorithm to a global $\\epsilon$-approximate solution in the offline case and show that the algorithm is Hannan-consistent in the online case with respect to static regret. Moreover, we show that the algorithm achieves $O(\\sqrt{NP_N^\\ast})$ dynamic regret, where $N$ is the number of iterations and $P_N^\\ast$ is the path length. The complexity analysis and hyperparameter selection are presented for all the cases. The theoretical results are illustrated via numerical examples.",
        "subjects": "Optimization and Control, Machine Learning, Numerical Analysis",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.428259"
    },
    {
        "index": "#133",
        "title": "HOB: A Holistically Optimized Bidding Strategy under Heterogeneous Auction Mechanisms with Organic Traffic",
        "link": "/arxiv/2510.15238",
        "arxiv_id": "2510.15238",
        "authors": "Qi Li, Wendong Huang, Qichen Ye, Wutong Xu, Cheems Wang, Rongquan Bai, Wei Yuan, Guan Wang, Chuan Yu, Jian Xu",
        "summary": "The E-commerce advertising platforms typically sell commercial traffic through either second-price auction (SPA) or first-price auction (FPA). SPA was historically prevalent due to its dominant strategy incentive-compatible (DSIC) for bidders with quasi-linear utilities, especially when budgets are not a binding constraint, while FPA has gained more prominence for offering higher revenue potential to publishers and avoiding the possibility for discriminatory treatment in personalized reserve prices. Meanwhile, on the demand side, advertisers are increasingly adopting platform-wide marketing solutions akin to QuanZhanTui, shifting from spending budgets solely on commercial traffic to bidding on the entire traffic for the purpose of maximizing overall sales. For automated bidding systems, such a trend poses a critical challenge: determining optimal strategies across heterogeneous auction channels to fulfill diverse advertiser objectives, such as maximizing return (MaxReturn) or meeting target return on ad spend (TargetROAS). To overcome this challenge, this work makes two key contributions. First, we derive an efficient solution for optimal bidding under FPA channels, which takes into account the presence of organic traffic - traffic can be won for free. Second, we introduce a marginal cost alignment (MCA) strategy that provably secures bidding efficiency across heterogeneous auction mechanisms. To validate performance of our developed framework, we conduct comprehensive offline experiments on public datasets and large-scale online A/B testing, which demonstrate consistent improvements over existing methods.",
        "subjects": "Computer Science and Game Theory, Information Retrieval, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.429137"
    },
    {
        "index": "#134",
        "title": "WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing",
        "link": "/arxiv/2510.15221",
        "arxiv_id": "2510.15221",
        "authors": "Xiao Sun",
        "summary": "Automated emotion recognition in real-world workplace settings remains a challenging problem in affective computing due to the scarcity of large-scale, longitudinal datasets collected in naturalistic environments. We present a novel dataset comprising 733,651 facial expression records from 38 employees collected over 30.5 months (November 2021 to May 2024) in an authentic office environment. Each record contains seven emotion probabilities (neutral, happy, sad, surprised, fear, disgusted, angry) derived from deep learning-based facial expression recognition, along with comprehensive metadata including job roles, employment outcomes, and personality traits. The dataset uniquely spans the COVID-19 pandemic period, capturing emotional responses to major societal events including the Shanghai lockdown and policy changes. We provide 32 extended emotional metrics computed using established affective science methods, including valence, arousal, volatility, predictability, inertia, and emotional contagion strength. Technical validation demonstrates high data quality through successful replication of known psychological patterns (weekend effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and perfect predictive validity for employee turnover (AUC=1.0). Baseline experiments using Random Forest and LSTM models achieve 91.2% accuracy for emotion classification and R2 = 0.84 for valence prediction. This is the largest and longest longitudinal workplace emotion dataset publicly available, enabling research in emotion recognition, affective dynamics modeling, emotional contagion, turnover prediction, and emotion-aware system design.",
        "subjects": "Artificial Intelligence, Computers and Society, Machine Learning",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.429487"
    },
    {
        "index": "#135",
        "title": "How to Sell High-Dimensional Data Optimally",
        "link": "/arxiv/2510.15214",
        "arxiv_id": "2510.15214",
        "authors": "Andrew Li, R. Ravi, Karan Singh, Zihong Yi, Weizhong Zhang",
        "summary": "Motivated by the problem of selling large, proprietary data, we consider an information pricing problem proposed by Bergemann et al. that involves a decision-making buyer and a monopolistic seller. The seller has access to the underlying state of the world that determines the utility of the various actions the buyer may take. Since the buyer gains greater utility through better decisions resulting from more accurate assessments of the state, the seller can therefore promise the buyer supplemental information at a price. To contend with the fact that the seller may not be perfectly informed about the buyer's private preferences (or utility), we frame the problem of designing a data product as one where the seller designs a revenue-maximizing menu of statistical experiments. Prior work by Cai et al. showed that an optimal menu can be found in time polynomial in the state space, whereas we observe that the state space is naturally exponential in the dimension of the data. We propose an algorithm which, given only sampling access to the state space, provably generates a near-optimal menu with a number of samples independent of the state space. We then analyze a special case of high-dimensional Gaussian data, showing that (a) it suffices to consider scalar Gaussian experiments, (b) the optimal menu of such experiments can be found efficiently via a semidefinite program, and (c) full surplus extraction occurs if and only if a natural separation condition holds on the set of potential preferences of the buyer.",
        "subjects": "Computer Science and Game Theory, Machine Learning, Theoretical Economics",
        "date": "2025-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.429887"
    },
    {
        "index": "#136",
        "title": "HyperAIRI: a plug-and-play algorithm for precise hyperspectral image reconstruction in radio interferometry",
        "link": "/arxiv/2510.15198",
        "arxiv_id": "2510.15198",
        "authors": "Chao Tang, Arwa Dabbech, Adrian Jackson, Yves Wiaux",
        "summary": "The next-generation radio-interferometric (RI) telescopes require imaging algorithms capable of forming high-resolution high-dynamic-range images from large data volumes spanning wide frequency bands. Recently, AIRI, a plug-and-play (PnP) approach taking the forward-backward algorithmic structure (FB), has demonstrated state-of-the-art performance in monochromatic RI imaging by alternating a data-fidelity step with a regularisation step via learned denoisers. In this work, we introduce HyperAIRI, its hyperspectral extension, underpinned by learned hyperspectral denoisers enforcing a power-law spectral model. For each spectral channel, the HyperAIRI denoiser takes as input its current image estimate, alongside estimates of its two immediate neighbouring channels and the spectral index map, and provides as output its associated denoised image. To ensure convergence of HyperAIRI, the denoisers are trained with a Jacobian regularisation enforcing non-expansiveness. To accommodate varying dynamic ranges, we assemble a shelf of pre-trained denoisers, each tailored to a specific dynamic range. At each HyperAIRI iteration, the spectral channels of the target image cube are updated in parallel using dynamic-range-matched denoisers from the pre-trained shelf. The denoisers are also endowed with a spatial image faceting functionality, enabling scalability to varied image sizes. Additionally, we formally introduce Hyper-uSARA, a variant of the optimisation-based algorithm HyperSARA, promoting joint sparsity across spectral channels via the l2,1-norm, also adopting FB. We evaluate HyperAIRI's performance on simulated and real observations. We showcase its superior performance compared to its optimisation-based counterpart Hyper-uSARA, CLEAN's hyperspectral variant in WSClean, and the monochromatic imaging algorithms AIRI and uSARA.",
        "subjects": "Instrumentation and Methods for Astrophysics, Machine Learning, Image and Video Processing",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.430285"
    },
    {
        "index": "#137",
        "title": "OCR-APT: Reconstructing APT Stories from Audit Logs using Subgraph Anomaly Detection and LLMs",
        "link": "/arxiv/2510.15188",
        "arxiv_id": "2510.15188",
        "authors": "Ahmed Aly, Essam Mansour, Amr Youssef",
        "summary": "Advanced Persistent Threats (APTs) are stealthy cyberattacks that often evade detection in system-level audit logs. Provenance graphs model these logs as connected entities and events, revealing relationships that are missed by linear log representations. Existing systems apply anomaly detection to these graphs but often suffer from high false positive rates and coarse-grained alerts. Their reliance on node attributes like file paths or IPs leads to spurious correlations, reducing detection robustness and reliability. To fully understand an attack's progression and impact, security analysts need systems that can generate accurate, human-like narratives of the entire attack. To address these challenges, we introduce OCR-APT, a system for APT detection and reconstruction of human-like attack stories. OCR-APT uses Graph Neural Networks (GNNs) for subgraph anomaly detection, learning behavior patterns around nodes rather than fragile attributes such as file paths or IPs. This approach leads to a more robust anomaly detection. It then iterates over detected subgraphs using Large Language Models (LLMs) to reconstruct multi-stage attack stories. Each stage is validated before proceeding, reducing hallucinations and ensuring an interpretable final report. Our evaluations on the DARPA TC3, OpTC, and NODLINK datasets show that OCR-APT outperforms state-of-the-art systems in both detection accuracy and alert interpretability. Moreover, OCR-APT reconstructs human-like reports that comprehensively capture the attack story.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.430578"
    },
    {
        "index": "#138",
        "title": "Beyond PCA: Manifold Dimension Estimation via Local Graph Structure",
        "link": "/arxiv/2510.15141",
        "arxiv_id": "2510.15141",
        "authors": "Zelong Bi, Pierre Lafaye de Micheaux",
        "summary": "Local principal component analysis (Local PCA) has proven to be an effective tool for estimating the intrinsic dimension of a manifold. More recently, curvature-adjusted PCA (CA-PCA) has improved upon this approach by explicitly accounting for the curvature of the underlying manifold, rather than assuming local flatness. Building on these insights, we propose a general framework for manifold dimension estimation that captures the manifold's local graph structure by integrating PCA with regression-based techniques. Within this framework, we introduce two representative estimators: quadratic embedding (QE) and total least squares (TLS). Experiments on both synthetic and real-world datasets demonstrate that these methods perform competitively with, and often outperform, state-of-the-art alternatives.",
        "subjects": "Machine Learning, Machine Learning, Applications",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.430872"
    },
    {
        "index": "#139",
        "title": "Towards Error Centric Intelligence I, Beyond Observational Learning",
        "link": "/arxiv/2510.15128",
        "arxiv_id": "2510.15128",
        "authors": "Marcus A. Thomas",
        "summary": "We argue that progress toward AGI is theory limited rather than data or scale limited. Building on the critical rationalism of Popper and Deutsch, we challenge the Platonic Representation Hypothesis. Observationally equivalent worlds can diverge under interventions, so observational adequacy alone cannot guarantee interventional competence. We begin by laying foundations, definitions of knowledge, learning, intelligence, counterfactual competence and AGI, and then analyze the limits of observational learning that motivate an error centric shift. We recast the problem as three questions about how explicit and implicit errors evolve under an agent's actions, which errors are unreachable within a fixed hypothesis space, and how conjecture and criticism expand that space. From these questions we propose Causal Mechanics, a mechanisms first program in which hypothesis space change is a first class operation and probabilistic structure is used when useful rather than presumed. We advance structural principles that make error discovery and correction tractable, including a differential Locality and Autonomy Principle for modular interventions, a gauge invariant form of Independent Causal Mechanisms for separability, and the Compositional Autonomy Principle for analogy preservation, together with actionable diagnostics. The aim is a scaffold for systems that can convert unreachable errors into reachable ones and correct them.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.431143"
    },
    {
        "index": "#141",
        "title": "Deep generative priors for 3D brain analysis",
        "link": "/arxiv/2510.15119",
        "arxiv_id": "2510.15119",
        "authors": "Ana Lawry Aguila, Dina Zemlyanker, You Cheng, Sudeshna Das, Daniel C. Alexander, Oula Puonti, Annabel Sorby-Adams, W. Taylor Kimberly, Juan Eugenio Iglesias",
        "summary": "Diffusion models have recently emerged as powerful generative models in medical imaging. However, it remains a major challenge to combine these data-driven models with domain knowledge to guide brain imaging problems. In neuroimaging, Bayesian inverse problems have long provided a successful framework for inference tasks, where incorporating domain knowledge of the imaging process enables robust performance without requiring extensive training data. However, the anatomical modeling component of these approaches typically relies on classical mathematical priors that often fail to capture the complex structure of brain anatomy. In this work, we present the first general-purpose application of diffusion models as priors for solving a wide range of medical imaging inverse problems. Our approach leverages a score-based diffusion prior trained extensively on diverse brain MRI data, paired with flexible forward models that capture common image processing tasks such as super-resolution, bias field correction, inpainting, and combinations thereof. We further demonstrate how our framework can refine outputs from existing deep learning methods to improve anatomical fidelity. Experiments on heterogeneous clinical and research MRI data show that our method achieves state-of-the-art performance producing consistent, high-quality solutions without requiring paired training datasets. These results highlight the potential of diffusion priors as versatile tools for brain MRI analysis.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.431834"
    },
    {
        "index": "#142",
        "title": "Polarization based direction of arrival estimation using a radio interferometric array",
        "link": "/arxiv/2510.15116",
        "arxiv_id": "2510.15116",
        "authors": "Sarod Yatawatta",
        "summary": "Direction of arrival (DOA) estimation is mostly performed using specialized arrays that have carefully designed receiver spacing and layouts to match the operating frequency range. In contrast, radio interferometric arrays are designed to optimally sample the Fourier space data for making high quality images of the sky. Therefore, using existing radio interferometric arrays (with arbitrary geometry and wide frequency variation) for DOA estimation is practically infeasible except by using images made by such interferometers. In this paper, we focus on low cost DOA estimation without imaging, using a subset of a radio interferometric array, using a fraction of the data collected by the full array, and, enabling early determination of DOAs. The proposed method is suitable for transient and low duty cycle source detection. Moreover, the proposed method is an ideal follow-up step to online radio frequency interference (RFI) mitigation, enabling the early estimation of the DOA of the detected RFI.",
        "subjects": "Instrumentation and Methods for Astrophysics, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.432106"
    },
    {
        "index": "#143",
        "title": "Targeted Attacks and Defenses for Distributed Federated Learning in Vehicular Networks",
        "link": "/arxiv/2510.15109",
        "arxiv_id": "2510.15109",
        "authors": "Utku Demir, Tugba Erpek, Yalin E. Sagduyu, Sastry Kompella, Mengran Xue",
        "summary": "In emerging networked systems, mobile edge devices such as ground vehicles and unmanned aerial system (UAS) swarms collectively aggregate vast amounts of data to make machine learning decisions such as threat detection in remote, dynamic, and infrastructure-constrained environments where power and bandwidth are scarce. Federated learning (FL) addresses these constraints and privacy concerns by enabling nodes to share local model weights for deep neural networks instead of raw data, facilitating more reliable decision-making than individual learning. However, conventional FL relies on a central server to coordinate model updates in each learning round, which imposes significant computational burdens on the central node and may not be feasible due to the connectivity constraints. By eliminating dependence on a central server, distributed federated learning (DFL) offers scalability, resilience to node failures, learning robustness, and more effective defense strategies. Despite these advantages, DFL remains vulnerable to increasingly advanced and stealthy cyberattacks. In this paper, we design sophisticated targeted training data poisoning and backdoor (Trojan) attacks, and characterize the emerging vulnerabilities in a vehicular network. We analyze how DFL provides resilience against such attacks compared to individual learning and present effective defense mechanisms to further strengthen DFL against the emerging cyber threats.",
        "subjects": "Networking and Internet Architecture, Artificial Intelligence, Distributed, Parallel, and Cluster Computing, Machine Learning, Signal Processing",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.432455"
    },
    {
        "index": "#144",
        "title": "PoTS: Proof-of-Training-Steps for Backdoor Detection in Large Language Models",
        "link": "/arxiv/2510.15106",
        "arxiv_id": "2510.15106",
        "authors": "Issam Seddik, Sami Souihi, Mohamed Tamaazousti, Sara Tucci Piergiovanni",
        "summary": "As Large Language Models (LLMs) gain traction across critical domains, ensuring secure and trustworthy training processes has become a major concern. Backdoor attacks, where malicious actors inject hidden triggers into training data, are particularly insidious and difficult to detect. Existing post-training verification solutions like Proof-of-Learning are impractical for LLMs due to their requirement for full retraining, lack of robustness against stealthy manipulations, and inability to provide early detection during training. Early detection would significantly reduce computational costs. To address these limitations, we introduce Proof-of-Training Steps, a verification protocol that enables an independent auditor (Alice) to confirm that an LLM developer (Bob) has followed the declared training recipe, including data batches, architecture, and hyperparameters. By analyzing the sensitivity of the LLMs' language modeling head (LM-Head) to input perturbations, our method can expose subtle backdoor injections or deviations in training. Even with backdoor triggers in up to 10 percent of the training data, our protocol significantly reduces the attacker's ability to achieve a high attack success rate (ASR). Our method enables early detection of attacks at the injection step, with verification steps being 3x faster than training steps. Our results highlight the protocol's potential to enhance the accountability and security of LLM development, especially against insider threats.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.432750"
    },
    {
        "index": "#145",
        "title": "OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data",
        "link": "/arxiv/2510.15096",
        "arxiv_id": "2510.15096",
        "authors": "Alana Renda, Jillian Ross, Michael Cafarella, Jacob Andreas",
        "summary": "Real-world settings where language models (LMs) are deployed -- in domains spanning healthcare, finance, and other forms of knowledge work -- require models to grapple with incomplete information and reason under uncertainty. Yet most LM evaluations focus on problems with well-defined answers and success criteria. This gap exists in part because natural problems involving uncertainty are difficult to construct: given that LMs have access to most of the same knowledge as humans, it is non-trivial to design questions for which LMs will struggle to produce correct answers, but which humans can answer reliably. As a result, LM performance on reasoning under uncertainty remains poorly characterized. To address this gap, we introduce OpenEstimate, an extensible, multi-domain benchmark for evaluating LMs on numerical estimation tasks that require models to synthesize significant amounts of background information and express predictions as probabilistic priors. We assess these priors for accuracy and calibration, quantifying their usefulness relative to samples from the true distribution of interest. Across six frontier LMs, we find that LM-elicited priors are often inaccurate and overconfident. Performance improves modestly depending on how uncertainty is elicited from the model, but is largely unaffected by changes in sampling strategy, reasoning effort, or prompt design. The OpenEstimate benchmark thus offers a challenging evaluation for frontier LMs and a platform for developing models that are better at probabilistic estimation and reasoning under uncertainty.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.436636"
    },
    {
        "index": "#146",
        "title": "The Minimax Lower Bound of Kernel Stein Discrepancy Estimation",
        "link": "/arxiv/2510.15058",
        "arxiv_id": "2510.15058",
        "authors": "Jose Cribeiro-Ramallo, Agnideep Aich, Florian Kalinke, Ashit Baran Aich, Zoltán Szabó",
        "summary": "Kernel Stein discrepancies (KSDs) have emerged as a powerful tool for quantifying goodness-of-fit over the last decade, featuring numerous successful applications. To the best of our knowledge, all existing KSD estimators with known rate achieve $\\sqrt n$-convergence. In this work, we present two complementary results (with different proof strategies), establishing that the minimax lower bound of KSD estimation is $n^{-1/2}$ and settling the optimality of these estimators. Our first result focuses on KSD estimation on $\\mathbb R^d$ with the Langevin-Stein operator; our explicit constant for the Gaussian kernel indicates that the difficulty of KSD estimation may increase exponentially with the dimensionality $d$. Our second result settles the minimax lower bound for KSD estimation on general domains.",
        "subjects": "Machine Learning, Machine Learning, Statistics Theory",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.436963"
    },
    {
        "index": "#147",
        "title": "Comprehensive language-image pre-training for 3D medical image understanding",
        "link": "/arxiv/2510.15042",
        "arxiv_id": "2510.15042",
        "authors": "Tassilo Wald, Ibrahim Ethem Hamamci, Yuan Gao, Sam Bond-Taylor, Harshita Sharma, Maximilian Ilse, Cynthia Lo, Olesya Melnichenko, Noel C. F. Codella, Maria Teodora Wetscherek, Klaus H. Maier-Hein, Panagiotis Korfiatis, Valentina Salvatelli, Javier Alvarez-Valle, Fernando Pérez-García",
        "summary": "Vision-language pre-training, i.e., aligning images with paired text, is a powerful paradigm to create encoders that can be directly used for tasks such as classification and retrieval, and for downstream tasks such as segmentation and report generation. In the 3D medical image domain, these capabilities allow vision-language encoders (VLEs) to support radiologists by retrieving patients with similar abnormalities or predicting likelihoods of abnormality. While the methodology holds promise, data availability limits the capabilities of current 3D VLEs. In this paper, we alleviate the lack of data by injecting additional inductive biases: introducing a report generation objective and pairing vision-language pre-training with vision-only pre-training. This allows us to leverage both image-only and paired image-text 3D datasets, increasing the total amount of data to which our model is exposed. Through these additional inductive biases, paired with best practices of the 3D medical imaging domain, we develop the Comprehensive Language-image Pre-training (COLIPRI) encoder family. Our COLIPRI encoders achieve state-of-the-art performance in report generation, classification probing, and zero-shot classification, and remain competitive for semantic segmentation.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.437362"
    },
    {
        "index": "#150",
        "title": "The Tree-SNE Tree Exists",
        "link": "/arxiv/2510.15014",
        "arxiv_id": "2510.15014",
        "authors": "Jack Kendrick",
        "summary": "The clustering and visualisation of high-dimensional data is a ubiquitous task in modern data science. Popular techniques include nonlinear dimensionality reduction methods like t-SNE or UMAP. These methods face the `scale-problem' of clustering: when dealing with the MNIST dataset, do we want to distinguish different digits or do we want to distinguish different ways of writing the digits? The answer is task dependent and depends on scale. We revisit an idea of Robinson & Pierce-Hoffman that exploits an underlying scaling symmetry in t-SNE to replace 2-dimensional with (2+1)-dimensional embeddings where the additional parameter accounts for scale. This gives rise to the t-SNE tree (short: tree-SNE). We prove that the optimal embedding depends continuously on the scaling parameter for all initial conditions outside a set of measure 0: the tree-SNE tree exists. This idea conceivably extends to other attraction-repulsion methods and is illustrated on several examples.",
        "subjects": "Machine Learning, Machine Learning, Optimization and Control",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.438381"
    },
    {
        "index": "#151",
        "title": "Reliable data clustering with Bayesian community detection",
        "link": "/arxiv/2510.15013",
        "arxiv_id": "2510.15013",
        "authors": "Magnus Neuman, Jelena Smiljanić, Martin Rosvall",
        "summary": "From neuroscience and genomics to systems biology and ecology, researchers rely on clustering similarity data to uncover modular structure. Yet widely used clustering methods, such as hierarchical clustering, k-means, and WGCNA, lack principled model selection, leaving them susceptible to noise. A common workaround sparsifies a correlation matrix representation to remove noise before clustering, but this extra step introduces arbitrary thresholds that can distort the structure and lead to unreliable results. To detect reliable clusters, we capitalize on recent advances in network science to unite sparsification and clustering with principled model selection. We test two Bayesian community detection methods, the Degree-Corrected Stochastic Block Model and the Regularized Map Equation, both grounded in the Minimum Description Length principle for model selection. In synthetic data, they outperform traditional approaches, detecting planted clusters under high-noise conditions and with fewer samples. Compared to WGCNA on gene co-expression data, the Regularized Map Equation identifies more robust and functionally coherent gene modules. Our results establish Bayesian community detection as a principled and noise-resistant framework for uncovering modular structure in high-dimensional data across fields.",
        "subjects": "Machine Learning, Machine Learning, Data Analysis, Statistics and Probability, Methodology",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.438701"
    },
    {
        "index": "#152",
        "title": "From Universal Approximation Theorem to Tropical Geometry of Multi-Layer Perceptrons",
        "link": "/arxiv/2510.15012",
        "arxiv_id": "2510.15012",
        "authors": "Yi-Shan Chu, Yueh-Cheng Kuo",
        "summary": "We revisit the Universal Approximation Theorem(UAT) through the lens of the tropical geometry of neural networks and introduce a constructive, geometry-aware initialization for sigmoidal multi-layer perceptrons (MLPs). Tropical geometry shows that Rectified Linear Unit (ReLU) networks admit decision functions with a combinatorial structure often described as a tropical rational, namely a difference of tropical polynomials. Focusing on planar binary classification, we design purely sigmoidal MLPs that adhere to the finite-sum format of UAT: a finite linear combination of shifted and scaled sigmoids of affine functions. The resulting models yield decision boundaries that already align with prescribed shapes at initialization and can be refined by standard training if desired. This provides a practical bridge between the tropical perspective and smooth MLPs, enabling interpretable, shape-driven initialization without resorting to ReLU architectures. We focus on the construction and empirical demonstrations in two dimensions; theoretical analysis and higher-dimensional extensions are left for future work.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-10-16",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.439001"
    },
    {
        "index": "#153",
        "title": "Estimand framework and intercurrent events handling for clinical trials with time-to-event outcomes",
        "link": "/arxiv/2510.15000",
        "arxiv_id": "2510.15000",
        "authors": "Yixin Fang, Man Jin",
        "summary": "The ICH E9(R1) guideline presents a framework of estimand for clinical trials, proposes five strategies for handling intercurrent events (ICEs), and provides a comprehensive discussion and many real-life clinical examples for quantitative outcomes and categorical outcomes. However, in ICH E9(R1) the discussion is lacking for time-to-event (TTE) outcomes. In this paper, we discuss how to define estimands and how to handle ICEs for clinical trials with TTE outcomes. Specifically, we discuss six ICE handling strategies, including those five strategies proposed by ICH E9(R1) and a new strategy, the competing-risk strategy. Compared with ICH E9(R1), the novelty of this paper is three-fold: (1) the estimands are defined in terms of potential outcomes, (2) the methods can utilize time-dependent covariates straightforwardly, and (3) the efficient estimators are discussed accordingly.",
        "subjects": "Methodology, Machine Learning, Machine Learning",
        "date": "2025-10-15",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.439296"
    },
    {
        "index": "#154",
        "title": "Evaluation and Implementation of Machine Learning Algorithms to Predict Early Detection of Kidney and Heart Disease in Diabetic Patients",
        "link": "/arxiv/2510.14997",
        "arxiv_id": "2510.14997",
        "authors": "Syed Ibad Hasnain",
        "summary": "Cardiovascular disease and chronic kidney disease are major complications of diabetes, leading to high morbidity and mortality. Early detection of these conditions is critical, yet traditional diagnostic markers often lack sensitivity in the initial stages. This study integrates conventional statistical methods with machine learning approaches to improve early diagnosis of CKD and CVD in diabetic patients. Descriptive and inferential statistics were computed in SPSS to explore associations between diseases and clinical or demographic factors. Patients were categorized into four groups: Group A both CKD and CVD, Group B CKD only, Group C CVD only, and Group D no disease. Statistical analysis revealed significant correlations: Serum Creatinine and Hypertension with CKD, and Cholesterol, Triglycerides, Myocardial Infarction, Stroke, and Hypertension with CVD. These results guided the selection of predictive features for machine learning models. Logistic Regression, Support Vector Machine, and Random Forest algorithms were implemented, with Random Forest showing the highest accuracy, particularly for CKD prediction. Ensemble models outperformed single classifiers in identifying high-risk diabetic patients. SPSS results further validated the significance of the key parameters integrated into the models. While challenges such as interpretability and class imbalance remain, this hybrid statistical machine learning framework offers a promising advancement toward early detection and risk stratification of diabetic complications compared to conventional diagnostic approaches.",
        "subjects": "Other Quantitative Biology, Artificial Intelligence, Machine Learning",
        "date": "2025-10-12",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.439578"
    },
    {
        "index": "#155",
        "title": "Constrained Diffusion for Protein Design with Hard Structural Constraints",
        "link": "/arxiv/2510.14989",
        "arxiv_id": "2510.14989",
        "authors": "Jacob K. Christopher, Austin Seamann, Jingyi Cui, Sagar Khare, Ferdinando Fioretto",
        "summary": "Diffusion models offer a powerful means of capturing the manifold of realistic protein structures, enabling rapid design for protein engineering tasks. However, existing approaches observe critical failure modes when precise constraints are necessary for functional design. To this end, we present a constrained diffusion framework for structure-guided protein design, ensuring strict adherence to functional requirements while maintaining precise stereochemical and geometric feasibility. The approach integrates proximal feasibility updates with ADMM decomposition into the generative process, scaling effectively to the complex constraint sets of this domain. We evaluate on challenging protein design tasks, including motif scaffolding and vacancy-constrained pocket design, while introducing a novel curated benchmark dataset for motif scaffolding in the PDZ domain. Our approach achieves state-of-the-art, providing perfect satisfaction of bonding and geometric constraints with no degradation in structural diversity.",
        "subjects": "Biomolecules, Artificial Intelligence, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.439921"
    },
    {
        "index": "#156",
        "title": "End-to-End Multi-Modal Diffusion Mamba",
        "link": "/arxiv/2510.13253",
        "arxiv_id": "2510.13253",
        "authors": "Chunhao Lu, Qiang Lu, Meichen Dong, Jake Luo",
        "summary": "Current end-to-end multi-modal models utilize different encoders and decoders to process input and output information. This separation hinders the joint representation learning of various modalities. To unify multi-modal processing, we propose a novel architecture called MDM (Multi-modal Diffusion Mamba). MDM utilizes a Mamba-based multi-step selection diffusion model to progressively generate and refine modality-specific information through a unified variational autoencoder for both encoding and decoding. This innovative approach allows MDM to achieve superior performance when processing high-dimensional data, particularly in generating high-resolution images and extended text sequences simultaneously. Our evaluations in areas such as image generation, image captioning, visual question answering, text comprehension, and reasoning tasks demonstrate that MDM significantly outperforms existing end-to-end models (MonoFormer, LlamaGen, and Chameleon etc.) and competes effectively with SOTA models like GPT-4V, Gemini Pro, and Mistral. Our results validate MDM's effectiveness in unifying multi-modal processes while maintaining computational efficiency, establishing a new direction for end-to-end multi-modal architectures.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-10-15",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.440207"
    },
    {
        "index": "#157",
        "title": "FIRE: Fact-checking with Iterative Retrieval and Verification",
        "link": "/arxiv/2411.00784",
        "arxiv_id": "2411.00784",
        "authors": "Zhuohan Xie, Rui Xing, Yuxia Wang, Jiahui Geng, Hasan Iqbal, Dhruv Sahnan, Iryna Gurevych, Preslav Nakov",
        "summary": "Fact-checking long-form text is challenging, and it is therefore common practice to break it down into multiple atomic claims. The typical approach to fact-checking these atomic claims involves retrieving a fixed number of pieces of evidence, followed by a verification step. However, this method is usually not cost-effective, as it underutilizes the verification model's internal knowledge of the claim and fails to replicate the iterative reasoning process in human search strategies. To address these limitations, we propose FIRE, a novel agent-based framework that integrates evidence retrieval and claim verification in an iterative manner. Specifically, FIRE employs a unified mechanism to decide whether to provide a final answer or generate a subsequent search query, based on its confidence in the current judgment. We compare FIRE with other strong fact-checking frameworks and find that it achieves slightly better performance while reducing large language model (LLM) costs by an average of 7.6 times and search costs by 16.5 times. These results indicate that FIRE holds promise for application in large-scale fact-checking operations. Our code is available at https://github.com/mbzuai-nlp/fire.git.",
        "subjects": "Information Retrieval, Artificial Intelligence, Computation and Language",
        "date": "2024-10-17",
        "category": "cs.LG",
        "crawl_time": "2025-10-20T11:00:05.440558"
    },
    {
        "index": "#1",
        "title": "PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold",
        "link": "/arxiv/2510.15862",
        "arxiv_id": "2510.15862",
        "authors": "Yi Wan, Jiuqi Wang, Liam Li, Jinsong Liu, Ruihao Zhu, Zheqing Zhu",
        "summary": "Tool-augmented large language models (LLMs) are emerging as deep research agents, systems that decompose complex queries, retrieve external evidence, and synthesize grounded responses. Yet current agents remain limited by shallow retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce PokeeResearch-7B, a 7B-parameter deep research agent built under a unified reinforcement learning framework for robustness, alignment, and scalability. PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from AI Feedback (RLAIF) framework to optimize policies using LLM-based reward signals that capture factual accuracy, citation faithfulness, and instruction adherence. A chain-of-thought-driven multi-call reasoning scaffold further enhances robustness through self-verification and adaptive recovery from tool failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves state-of-the-art performance among 7B-scale deep research agents. This highlights that careful reinforcement learning and reasoning design can produce efficient, resilient, and research-grade AI agents. The model and inference code is open-sourced under MIT license at https://github.com/Pokee-AI/PokeeResearchOSS.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.441746"
    },
    {
        "index": "#2",
        "title": "Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID",
        "link": "/arxiv/2510.15782",
        "arxiv_id": "2510.15782",
        "authors": "Philip DiGiacomo, Haoyang Wang, Jinrui Fang, Yan Leng, W Michael Brode, Ying Ding",
        "summary": "As AI chatbots gain adoption in clinical medicine, developing effective frameworks for complex, emerging diseases presents significant challenges. We developed and evaluated six Retrieval-Augmented Generation (RAG) corpus configurations for Long COVID (LC) clinical question answering, ranging from expert-curated sources to large-scale literature databases. Our evaluation employed an LLM-as-a-judge framework across faithfulness, relevance, and comprehensiveness metrics using LongCOVID-CQ, a novel dataset of expert-generated clinical questions. Our RAG corpus configuration combining clinical guidelines with high-quality systematic reviews consistently outperformed both narrow single-guideline approaches and large-scale literature databases. Our findings suggest that for emerging diseases, retrieval grounded in curated secondary reviews provides an optimal balance between narrow consensus documents and unfiltered primary literature, supporting clinical decision-making while avoiding information overload and oversimplified guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation framework that integrates both curated expert knowledge and comprehensive literature databases to effectively answer LC clinical questions.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.442276"
    },
    {
        "index": "#3",
        "title": "Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL",
        "link": "/arxiv/2510.15772",
        "arxiv_id": "2510.15772",
        "authors": "Richard M. Bailey",
        "summary": "So-called `wicked problems', those involving complex multi-dimensional settings, non-verifiable outcomes, heterogeneous impacts and a lack of single objectively correct answers, have plagued humans throughout history. Modern examples include decisions over justice frameworks, solving environmental pollution, planning for pandemic resilience and food security. The use of state-of-the-art artificial intelligence systems (notably Large Language Model-based agents) collaborating with humans on solving such problems is being actively explored. While the abilities of LLMs can be improved by, for example, fine-tuning, hand-crafted system prompts and scaffolding with external tools, LLMs lack endogenous mechanisms to develop expertise through experience in such settings. This work address this gap with Dialectica, a framework where agents engage in structured dialogue on defined topics, augmented by memory, self-reflection, and policy-constrained context editing. Formally, discussion is viewed as an implicit meta-reinforcement learning process. The `dialogue-trained' agents are evaluated post-hoc using judged pairwise comparisons of elicited responses. Across two model architectures (locally run Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based context editing during discussion produces agents which dominate their baseline counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and AlphaRank mass. The predicted signatures of learning are observed qualitatively in statement and reflection logs, where reflections identify weaknesses and reliably shape subsequent statements. Agreement between quantitative and qualitative evidence supports dialogue-driven context evolution as a practical path to targeted expertise amplification in open non-verifiable domains.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.442694"
    },
    {
        "index": "#4",
        "title": "Preliminary Quantitative Study on Explainability and Trust in AI Systems",
        "link": "/arxiv/2510.15769",
        "arxiv_id": "2510.15769",
        "authors": "Allen Daniel Sunny",
        "summary": "Large-scale AI models such as GPT-4 have accelerated the deployment of artificial intelligence across critical domains including law, healthcare, and finance, raising urgent questions about trust and transparency. This study investigates the relationship between explainability and user trust in AI systems through a quantitative experimental design. Using an interactive, web-based loan approval simulation, we compare how different types of explanations, ranging from basic feature importance to interactive counterfactuals influence perceived trust. Results suggest that interactivity enhances both user engagement and confidence, and that the clarity and relevance of explanations are key determinants of trust. These findings contribute empirical evidence to the growing field of human-centered explainable AI, highlighting measurable effects of explainability design on user perception",
        "subjects": "Artificial Intelligence, Human-Computer Interaction",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.443119"
    },
    {
        "index": "#5",
        "title": "Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment",
        "link": "/arxiv/2510.15748",
        "arxiv_id": "2510.15748",
        "authors": "Minlin Zeng, Zhipeng Zhou, Yang Qiu, Zhiqi Shen",
        "summary": "Parkinson's disease assessment has garnered growing interest in recent years, particularly with the advent of sensor data and machine learning techniques. Among these, multimodal approaches have demonstrated strong performance by effectively integrating complementary information from various data sources. However, two major limitations hinder their practical application: (1) the need to synchronize all modalities during training, and (2) the dependence on all modalities during inference. To address these issues, we propose the first Parkinson's assessment system that formulates multimodal learning as a multi-objective optimization (MOO) problem. This not only allows for more flexible modality requirements during both training and inference, but also handles modality collapse issue during multimodal information fusion. In addition, to mitigate the imbalance within individual modalities, we introduce a margin-based class rebalancing strategy to enhance category learning. We conduct extensive experiments on three public datasets under both synchronous and asynchronous settings. The results show that our framework-Towards Relaxed InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous setting, and by 4.86 and 2.30 percentage points in the synchronous setting, highlighting its effectiveness and adaptability.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.443574"
    },
    {
        "index": "#7",
        "title": "Invoice Information Extraction: Methods and Performance Evaluation",
        "link": "/arxiv/2510.15727",
        "arxiv_id": "2510.15727",
        "authors": "Sai Yashwant, Anurag Dubey, Praneeth Paikray, Gantala Thulsiram",
        "summary": "This paper presents methods for extracting structured information from invoice documents and proposes a set of evaluation metrics (EM) to assess the accuracy of the extracted data against annotated ground truth. The approach involves pre-processing scanned or digital invoices, applying Docling and LlamaCloud Services to identify and extract key fields such as invoice number, date, total amount, and vendor details. To ensure the reliability of the extraction process, we establish a robust evaluation framework comprising field-level precision, consistency check failures, and exact match accuracy. The proposed metrics provide a standardized way to compare different extraction methods and highlight strengths and weaknesses in field-specific performance.",
        "subjects": "Artificial Intelligence, Databases",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.444532"
    },
    {
        "index": "#8",
        "title": "Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences",
        "link": "/arxiv/2510.15716",
        "arxiv_id": "2510.15716",
        "authors": "Keertana Chidambaram, Karthik Vinary Seetharaman, Vasilis Syrgkanis",
        "summary": "Reinforcement Learning from Human Feedback (RLHF) has become central to aligning large language models with human values, typically by first learning a reward model from preference data which is then used to update the model with reinforcement learning. Recent alternatives such as Direct Preference Optimization (DPO) simplify this pipeline by directly optimizing on preferences. However, both approaches often assume uniform annotator preferences and rely on binary comparisons, overlooking two key limitations: the diversity of human evaluators and the limitations of pairwise feedback. In this work, we address both these issues. First, we connect preference learning in RLHF with the econometrics literature and show that binary comparisons are insufficient for identifying latent user preferences from finite user data and infinite users, while (even incomplete) rankings over three or more responses ensure identifiability. Second, we introduce methods to incorporate heterogeneous preferences into alignment algorithms. We develop an Expectation-Maximization adaptation of DPO that discovers latent annotator types and trains a mixture of LLMs accordingly. Then we propose an aggregation algorithm using a min-max regret fairness criterion to produce a single generative policy with equitable performance guarantees. Together, these contributions establish a theoretical and algorithmic framework for fairness and personalization for diverse users in generative model alignment.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.444975"
    },
    {
        "index": "#11",
        "title": "Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment",
        "link": "/arxiv/2510.15591",
        "arxiv_id": "2510.15591",
        "authors": "Lavanya Umapathy, Patricia M Johnson, Tarun Dutt, Angela Tong, Madhur Nayan, Hersh Chandarana, Daniel K Sodickson",
        "summary": "Temporal context in medicine is valuable in assessing key changes in patient health over time. We developed a machine learning framework to integrate diverse context from prior visits to improve health monitoring, especially when prior visits are limited and their frequency is variable. Our model first estimates initial risk of disease using medical data from the most recent patient visit, then refines this assessment using information digested from previously collected imaging and/or clinical biomarkers. We applied our framework to prostate cancer (PCa) risk prediction using data from a large population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931 blood tests) collected over nearly a decade. For predictions of the risk of clinically significant PCa at the time of the visit, integrating prior context directly converted false positives to true negatives, increasing overall specificity while preserving high sensitivity. False positive rates were reduced progressively from 51% to 33% when integrating information from up to three prior imaging examinations, as compared to using data from a single visit, and were further reduced to 24% when also including additional context from prior clinical data. For predicting the risk of PCa within five years of the visit, incorporating prior context reduced false positive rates still further (64% to 9%). Our findings show that information collected over time provides relevant context to enhance the specificity of medical risk prediction. For a wide range of progressive conditions, sufficient reduction of false positive rates using context could offer a pathway to expand longitudinal health monitoring programs to large populations with comparatively low baseline risk of disease, leading to earlier detection and improved health outcomes.",
        "subjects": "Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.446988"
    },
    {
        "index": "#12",
        "title": "JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament",
        "link": "/arxiv/2510.15560",
        "arxiv_id": "2510.15560",
        "authors": "Jiayuan Bai, Xuan-guang Pan, Chongyang Tao, Shuai Ma",
        "summary": "Text-to-SQL is a pivotal task that bridges natural language understanding and structured data access, yet it remains fundamentally challenging due to semantic ambiguity and complex compositional reasoning. While large language models (LLMs) have greatly advanced SQL generation though prompting, supervised finetuning and reinforced tuning, the shift toward test-time scaling exposes a new bottleneck: selecting the correct query from a diverse candidate pool. Existing selection approaches, such as self-consistency or best-of-$N$ decoding, provide only shallow signals, making them prone to inconsistent scoring, fragile reasoning chains, and a failure to capture fine-grained semantic distinctions between closely related SQL candidates. To this end, we introduce JudgeSQL, a principled framework that redefines SQL candidate selection through structured reasoning and weighted consensus tournament mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills reasoning traces with reinforcement learning guided by verifiable rewards, enabling accurate and interpretable judgments. Building on this, a weighted consensus tournament integrates explicit reasoning preferences with implicit generator confidence, yielding selections that are both more reliable and more efficient. Extensive experiments on the BIRD benchmark demonstrate that JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale generalization and robustness to generator capacity.",
        "subjects": "Artificial Intelligence, Databases",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.447464"
    },
    {
        "index": "#14",
        "title": "Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning",
        "link": "/arxiv/2510.15514",
        "arxiv_id": "2510.15514",
        "authors": "Boyin Liu, Zhuo Zhang, Sen Huang, Lipeng Xie, Qingxu Fu, Haoran Chen, LI YU, Tianyi Hu, Zhaoyang Liu, Bolin Ding, Dongbin Zhao",
        "summary": "However, this method often faces judgment inconsistencies that can destabilize reinforcement learning. While prior research has focused on the accuracy of judgments, the critical issue of logical coherence especially issues such as preference cycles hasn't been fully addressed. To fill this gap, we introduce a comprehensive framework designed to systematically detect and resolve these inconsistencies during the reinforcement learning training process. Our framework includes two main contributions: first, the Conflict Detection Rate (CDR), a new metric that quantifies judgment conflicts, and second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by removing cycles before policy optimization. DGR constructs preference graphs from the initial judgments, transforms them into conflict-free Directed Acyclic Graphs (DAGs), and generates a logically coherent reward signal that is compatible with any policy optimizer. Experimental results show that our framework significantly enhances training stability and model performance compared to strong baselines, establishing logical consistency as a crucial and now manageable dimension of AI feedback.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.448615"
    },
    {
        "index": "#15",
        "title": "Adaptive Minds: Empowering Agents with LoRA-as-Tools",
        "link": "/arxiv/2510.15416",
        "arxiv_id": "2510.15416",
        "authors": "Pavan C Shekar, Ashwanth Krishnan",
        "summary": "We present Adaptive Minds, an agentic system that treats LoRA adapters as domain-specific tools. Instead of relying on a single fine-tuned model or rigid rule-based routing, our approach empowers the base LLM itself to act as a semantic router analyzing each query and dynamically selecting the most relevant LoRA tool. This enables the agent to seamlessly switch between different domain experts on demand. By combining the flexibility of multi-agent orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive Minds delivers accurate, specialized responses while preserving conversational ability. The system is built with LangGraph for workflow management, supports both API and web interfaces, and is fully open source, providing a scalable and extensible foundation for domain-adaptive AI assistance.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.449041"
    },
    {
        "index": "#16",
        "title": "MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games",
        "link": "/arxiv/2510.15414",
        "arxiv_id": "2510.15414",
        "authors": "Huining Yuan, Zelai Xu, Zheyue Tan, Xiangmin Yi, Mo Guang, Kaiwen Long, Haojia Hui, Boxun Li, Xinlei Chen, Bo Zhao, Xiao-Ping Zhang, Chao Yu, Yu Wang",
        "summary": "Developing Large Language Models (LLMs) to cooperate and compete effectively within multi-agent systems is a critical step towards more advanced intelligence. While reinforcement learning (RL) has proven effective for enhancing reasoning in single-agent tasks, its extension to multi-turn, multi-agent scenarios remains underexplored due to the challenges of long-horizon credit assignment and agent-specific advantage estimation. To address these challenges, we introduce MARS, an end-to-end RL framework that incentivizes Multi-Agent Reasoning of LLMs through Self-play in both cooperative and competitive games. MARS features a turn-level advantage estimator that aligns learning signals with each interaction for credit assignment, and an agent-specific advantage normalization to stabilize multi-agent training. By learning with self-play across cooperative and competitive games, the MARS agent trained from Qwen3-4B develops strong strategic abilities that generalize to held-out games with up to 28.7% performance improvements. More importantly, the capability acquired through self-play generalizes beyond games, yielding consistent performance gains of multi-agent systems in reasoning benchmarks. When integrated into leading multi-agent systems, our MARS agent achieves significant performance gains of 10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL training with self-play in strategic games as a powerful approach for developing generalizable multi-agent reasoning capabilities in LLMs. Our code and models are publicly available at https://github.com/thu-nics/MARS.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.449617"
    },
    {
        "index": "#17",
        "title": "Corrigibility Transformation: Constructing Goals That Accept Updates",
        "link": "/arxiv/2510.15395",
        "arxiv_id": "2510.15395",
        "authors": "Rubi Hudson",
        "summary": "For an AI's training process to successfully impart a desired goal, it is important that the AI does not attempt to resist the training. However, partially learned goals will often incentivize an AI to avoid further goal updates, as most goals are better achieved by an AI continuing to pursue them. We say that a goal is corrigible if it does not incentivize taking actions that avoid proper goal updates or shutdown. In addition to convergence in training, corrigibility also allows for correcting mistakes and changes in human preferences, which makes it a crucial safety property. Despite this, the existing literature does not include specifications for goals that are both corrigible and competitive with non-corrigible alternatives. We provide a formal definition for corrigibility, then introduce a transformation that constructs a corrigible version of any goal that can be made corrigible, without sacrificing performance. This is done by myopically eliciting predictions of reward conditional on costlessly preventing updates, which then also determine the reward when updates are accepted. The transformation can be modified to recursively extend corrigibility to any new agents created by corrigible agents, and to prevent agents from deliberately modifying their goals. Two gridworld experiments demonstrate that these corrigible goals can be learned effectively, and that they lead to the desired behavior.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.450035"
    },
    {
        "index": "#18",
        "title": "Advancing Routing-Awareness in Analog ICs Floorplanning",
        "link": "/arxiv/2510.15387",
        "arxiv_id": "2510.15387",
        "authors": "Davide Basso, Luca Bortolussi, Mirjana Videnovic-Misic, Husni Habal",
        "summary": "The adoption of machine learning-based techniques for analog integrated circuit layout, unlike its digital counterpart, has been limited by the stringent requirements imposed by electric and problem-specific constraints, along with the interdependence of floorplanning and routing steps. In this work, we address a prevalent concern among layout engineers regarding the need for readily available routing-aware floorplanning solutions. To this extent, we develop an automatic floorplanning engine based on reinforcement learning and relational graph convolutional neural network specifically tailored to condition the floorplan generation towards more routable outcomes. A combination of increased grid resolution and precise pin information integration, along with a dynamic routing resource estimation technique, allows balancing routing and area efficiency, eventually meeting industrial standards. When analyzing the place and route effectiveness in a simulated environment, the proposed approach achieves a 13.8% reduction in dead space, a 40.6% reduction in wirelength and a 73.4% increase in routing success when compared to past learning-based state-of-the-art techniques.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.450488"
    },
    {
        "index": "#20",
        "title": "VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data",
        "link": "/arxiv/2510.15317",
        "arxiv_id": "2510.15317",
        "authors": "Tingqiao Xu, Ziru Zeng, Jiayu Chen",
        "summary": "The quality of supervised fine-tuning (SFT) data is crucial for the performance of large multimodal models (LMMs), yet current data enhancement methods often suffer from factual errors and hallucinations due to inadequate visual perception. To address this challenge, we propose VERITAS, a pipeline that systematically integrates vision priors and multiple state-of-the-art LMMs with statistical methods to enhance SFT data quality. VERITAS leverages visual recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured vision priors, which are combined with images, questions, and answers. Three LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers, providing critique rationales and scores that are statistically fused into a high-confidence consensus score serving as ground truth. Using this consensus, we train a lightweight critic model via Group Relative Policy Optimization (GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the original answers based on the critiques, generating new candidate answers; we select the highest-scoring one as the final refined answer. Experiments across six multimodal benchmarks demonstrate that models fine-tuned with data processed by VERITAS consistently outperform those using raw data, particularly in text-rich and fine-grained reasoning tasks. Our critic model exhibits enhanced capability comparable to state-of-the-art LMMs while being significantly more efficient. We release our pipeline, datasets, and model checkpoints to advance research in multimodal data optimization.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.451426"
    },
    {
        "index": "#21",
        "title": "WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation",
        "link": "/arxiv/2510.15306",
        "arxiv_id": "2510.15306",
        "authors": "Kuang-Da Wang, Zhao Wang, Yotaro Shimose, Wei-Yao Wang, Shingo Takamatsu",
        "summary": "Witnessed by the recent advancements on leveraging LLM for coding and multimodal understanding, we present WebGen-V, a new benchmark and framework for instruction-to-HTML generation that enhances both data quality and evaluation granularity. WebGen-V contributes three key innovations: (1) an unbounded and extensible agentic crawling framework that continuously collects real-world webpages and can leveraged to augment existing benchmarks; (2) a structured, section-wise data representation that integrates metadata, localized UI screenshots, and JSON-formatted text and image assets, explicit alignment between content, layout, and visual components for detailed multimodal supervision; and (3) a section-level multimodal evaluation protocol aligning text, layout, and visuals for high-granularity assessment. Experiments with state-of-the-art LLMs and ablation studies validate the effectiveness of our structured data and section-wise evaluation, as well as the contribution of each component. To the best of our knowledge, WebGen-V is the first work to enable high-granularity agentic crawling and evaluation for instruction-to-HTML generation, providing a unified pipeline from real-world data acquisition and webpage generation to structured multimodal assessment.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.452028"
    },
    {
        "index": "#22",
        "title": "AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory",
        "link": "/arxiv/2510.15261",
        "arxiv_id": "2510.15261",
        "authors": "Jitesh Jain, Shubham Maheshwari, Ning Yu, Wen-mei Hwu, Humphrey Shi",
        "summary": "Riding on the success of LLMs with retrieval-augmented generation (RAG), there has been a growing interest in augmenting agent systems with external memory databases. However, the existing systems focus on storing text information in their memory, ignoring the importance of multimodal signals. Motivated by the multimodal nature of human memory, we present AUGUSTUS, a multimodal agent system aligned with the ideas of human memory in cognitive science. Technically, our system consists of 4 stages connected in a loop: (i) encode: understanding the inputs; (ii) store in memory: saving important information; (iii) retrieve: searching for relevant context from memory; and (iv) act: perform the task. Unlike existing systems that use vector databases, we propose conceptualizing information into semantic tags and associating the tags with their context to store them in a graph-structured multimodal contextual memory for efficient concept-driven retrieval. Our system outperforms the traditional multimodal RAG approach while being 3.5 times faster for ImageNet classification and outperforming MemGPT on the MSC benchmark.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.452503"
    },
    {
        "index": "#23",
        "title": "Experience-Driven Exploration for Efficient API-Free AI Agents",
        "link": "/arxiv/2510.15259",
        "arxiv_id": "2510.15259",
        "authors": "Chenwei Tang, Jingyu Xing, Xinyu Liu, Zizhou Wang, Jiawei Du, Liangli Zhen, Jiancheng Lv",
        "summary": "Most existing software lacks accessible Application Programming Interfaces (APIs), requiring agents to operate solely through pixel-based Graphical User Interfaces (GUIs). In this API-free setting, large language model (LLM)-based agents face severe efficiency bottlenecks: limited to local visual experiences, they make myopic decisions and rely on inefficient trial-and-error, hindering both skill acquisition and long-term planning. To address these challenges, we propose KG-Agent, an experience-driven learning framework that structures an agent's raw pixel-level interactions into a persistent State-Action Knowledge Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking functionally similar but visually distinct GUI states, forming a rich neighborhood of experience that enables the agent to generalize from a diverse set of historical strategies. To support long-horizon reasoning, we design a hybrid intrinsic reward mechanism based on the graph topology, combining a state value reward for exploiting known high-value pathways with a novelty reward that encourages targeted exploration. This approach decouples strategic planning from pure discovery, allowing the agent to effectively value setup actions with delayed gratification. We evaluate KG-Agent in two complex, open-ended GUI-based decision-making environments (Civilization V and Slay the Spire), demonstrating significant improvements in exploration efficiency and strategic depth over the state-of-the-art methods.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.452888"
    },
    {
        "index": "#25",
        "title": "From Checklists to Clusters: A Homeostatic Account of AGI Evaluation",
        "link": "/arxiv/2510.15236",
        "arxiv_id": "2510.15236",
        "authors": "Brett Reynolds",
        "summary": "Contemporary AGI evaluations report multidomain capability profiles, yet they typically assign symmetric weights and rely on snapshot scores. This creates two problems: (i) equal weighting treats all domains as equally important when human intelligence research suggests otherwise, and (ii) snapshot testing can't distinguish durable capabilities from brittle performances that collapse under delay or stress. I argue that general intelligence -- in humans and potentially in machines -- is better understood as a homeostatic property cluster: a set of abilities plus the mechanisms that keep those abilities co-present under perturbation. On this view, AGI evaluation should weight domains by their causal centrality (their contribution to cluster stability) and require evidence of persistence across sessions. I propose two battery-compatible extensions: a centrality-prior score that imports CHC-derived weights with transparent sensitivity analysis, and a Cluster Stability Index family that separates profile persistence, durable learning, and error correction. These additions preserve multidomain breadth while reducing brittleness and gaming. I close with testable predictions and black-box protocols labs can adopt without architectural access.",
        "subjects": "Artificial Intelligence, Computers and Society",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.453487"
    },
    {
        "index": "#29",
        "title": "Procedural Game Level Design with Deep Reinforcement Learning",
        "link": "/arxiv/2510.15120",
        "arxiv_id": "2510.15120",
        "authors": "Miraç Buğra Özkan",
        "summary": "Procedural content generation (PCG) has become an increasingly popular technique in game development, allowing developers to generate dynamic, replayable, and scalable environments with reduced manual effort. In this study, a novel method for procedural level design using Deep Reinforcement Learning (DRL) within a Unity-based 3D environment is proposed. The system comprises two agents: a hummingbird agent, acting as a solver, and a floating island agent, responsible for generating and placing collectible objects (flowers) on the terrain in a realistic and context-aware manner. The hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm from the Unity ML-Agents toolkit. It learns to navigate through the terrain efficiently, locate flowers, and collect them while adapting to the ever-changing procedural layout of the island. The island agent is also trained using the Proximal Policy Optimization (PPO) algorithm. It learns to generate flower layouts based on observed obstacle positions, the hummingbird's initial state, and performance feedback from previous episodes. The interaction between these agents leads to emergent behavior and robust generalization across various environmental configurations. The results demonstrate that the approach not only produces effective and efficient agent behavior but also opens up new opportunities for autonomous game level design driven by machine learning. This work highlights the potential of DRL in enabling intelligent agents to both generate and solve content in virtual environments, pushing the boundaries of what AI can contribute to creative game development processes.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.454629"
    },
    {
        "index": "#37",
        "title": "GENESIS: A Generative Model of Episodic-Semantic Interaction",
        "link": "/arxiv/2510.15828",
        "arxiv_id": "2510.15828",
        "authors": "Marco D'Alessandro, Leo D'Amato, Mikel Elkano, Mikel Uriz, Giovanni Pezzulo",
        "summary": "A central challenge in cognitive neuroscience is to explain how semantic and episodic memory, two major forms of declarative memory, typically associated with cortical and hippocampal processing, interact to support learning, recall, and imagination. Despite significant advances, we still lack a unified computational framework that jointly accounts for core empirical phenomena across both semantic and episodic processing domains. Here, we introduce the Generative Episodic-Semantic Integration System (GENESIS), a computational model that formalizes memory as the interaction between two limited-capacity generative systems: a Cortical-VAE, supporting semantic learning and generalization, and a Hippocampal-VAE, supporting episodic encoding and retrieval within a retrieval-augmented generation (RAG) architecture. GENESIS reproduces hallmark behavioral findings, including generalization in semantic memory, recognition, serial recall effects and gist-based distortions in episodic memory, and constructive episodic simulation, while capturing their dynamic interactions. The model elucidates how capacity constraints shape the fidelity and memorability of experiences, how semantic processing introduces systematic distortions in episodic recall, and how episodic replay can recombine previous experiences. Together, these results provide a principled account of memory as an active, constructive, and resource-bounded process. GENESIS thus advances a unified theoretical framework that bridges semantic and episodic memory, offering new insights into the generative foundations of human cognition.",
        "subjects": "Neurons and Cognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.457137"
    },
    {
        "index": "#40",
        "title": "Controlling the image generation process with parametric activation functions",
        "link": "/arxiv/2510.15778",
        "arxiv_id": "2510.15778",
        "authors": "Ilia Pavlov",
        "summary": "As image generative models continue to increase not only in their fidelity but also in their ubiquity the development of tools that leverage direct interaction with their internal mechanisms in an interpretable way has received little attention In this work we introduce a system that allows users to develop a better understanding of the model through interaction and experimentation By giving users the ability to replace activation functions of a generative network with parametric ones and a way to set the parameters of these functions we introduce an alternative approach to control the networks output We demonstrate the use of our method on StyleGAN2 and BigGAN networks trained on FFHQ and ImageNet respectively.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.458108"
    },
    {
        "index": "#42",
        "title": "NDM: A Noise-driven Detection and Mitigation Framework against Implicit Sexual Intentions in Text-to-Image Generation",
        "link": "/arxiv/2510.15752",
        "arxiv_id": "2510.15752",
        "authors": "Yitong Sun, Yao Huang, Ruochen Zhang, Huanran Chen, Shouwei Ruan, Ranjie Duan, Xingxing Wei",
        "summary": "Despite the impressive generative capabilities of text-to-image (T2I) diffusion models, they remain vulnerable to generating inappropriate content, especially when confronted with implicit sexual prompts. Unlike explicit harmful prompts, these subtle cues, often disguised as seemingly benign terms, can unexpectedly trigger sexual content due to underlying model biases, raising significant ethical concerns. However, existing detection methods are primarily designed to identify explicit sexual content and therefore struggle to detect these implicit cues. Fine-tuning approaches, while effective to some extent, risk degrading the model's generative quality, creating an undesirable trade-off. To address this, we propose NDM, the first noise-driven detection and mitigation framework, which could detect and mitigate implicit malicious intention in T2I generation while preserving the model's original generative capabilities. Specifically, we introduce two key innovations: first, we leverage the separability of early-stage predicted noise to develop a noise-based detection method that could identify malicious content with high accuracy and efficiency; second, we propose a noise-enhanced adaptive negative guidance mechanism that could optimize the initial noise by suppressing the prominent region's attention, thereby enhancing the effectiveness of adaptive negative guidance for sexual mitigation. Experimentally, we validate NDM on both natural and adversarial datasets, demonstrating its superior performance over existing SOTA methods, including SLD, UCE, and RECE, etc. Code and resources are available at https://github.com/lorraine021/NDM.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.458674"
    },
    {
        "index": "#46",
        "title": "DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification",
        "link": "/arxiv/2510.15725",
        "arxiv_id": "2510.15725",
        "authors": "Tingyu Lin, Armin Dadras, Florian Kleber, Robert Sablatnig",
        "summary": "Camera movement classification (CMC) models trained on contemporary, high-quality footage often degrade when applied to archival film, where noise, missing frames, and low contrast obscure motion cues. We bridge this gap by assembling a unified benchmark that consolidates two modern corpora into four canonical classes and restructures the HISTORIAN collection into five balanced categories. Building on this benchmark, we introduce DGME-T, a lightweight extension to the Video Swin Transformer that injects directional grid motion encoding, derived from optical flow, via a learnable and normalised late-fusion layer. DGME-T raises the backbone's top-1 accuracy from 81.78% to 86.14% and its macro F1 from 82.08% to 87.81% on modern clips, while still improving the demanding World-War-II footage from 83.43% to 84.62% accuracy and from 81.72% to 82.63% macro F1. A cross-domain study further shows that an intermediate fine-tuning stage on modern data increases historical performance by more than five percentage points. These results demonstrate that structured motion priors and transformer representations are complementary and that even a small, carefully calibrated motion head can substantially enhance robustness in degraded film analysis. Related resources are available at https://github.com/linty5/DGME-T.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Image and Video Processing",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.459842"
    },
    {
        "index": "#48",
        "title": "Beyond-Diagonal RIS Under Non-Idealities: Learning-Based Architecture Discovery and Optimization",
        "link": "/arxiv/2510.15701",
        "arxiv_id": "2510.15701",
        "authors": "Binggui Zhou, Bruno Clerckx",
        "summary": "Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has recently been introduced to enable advanced control over electromagnetic waves to further increase the benefits of traditional RIS in enhancing signal quality and improving spectral and energy efficiency for next-generation wireless networks. A significant issue in designing and deploying BD-RIS is the tradeoff between its performance and circuit complexity. Despite some efforts in exploring optimal architectures with the lowest circuit complexities for ideal BD-RIS, architecture discovery for non-ideal BD-RIS remains uninvestigated. Therefore, how non-idealities and circuit complexity jointly affect the performance of BD-RIS remains unclear, making it difficult to achieve the performance - circuit complexity tradeoff in the presence of non-idealities. Essentially, architecture discovery for non-ideal BD-RIS faces challenges from both the computational complexity of global architecture search and the difficulty in achieving global optima. To tackle these challenges, we propose a learning-based two-tier architecture discovery framework (LTTADF) consisting of an architecture generator and a performance optimizer to jointly discover optimal architectures of non-ideal BD-RIS given specific circuit complexities, which can effectively explore over a large architecture space while avoiding getting trapped in poor local optima and thus achieving near-optimal solutions for the performance optimization. Numerical results provide valuable insights for deploying non-ideal BD-RIS considering the performance - circuit complexity tradeoff.",
        "subjects": "Information Theory, Artificial Intelligence, Signal Processing",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.460383"
    },
    {
        "index": "#52",
        "title": "Towards Label-Free Brain Tumor Segmentation: Unsupervised Learning with Multimodal MRI",
        "link": "/arxiv/2510.15684",
        "arxiv_id": "2510.15684",
        "authors": "Gerard Comas-Quiles, Carles Garcia-Cabrera, Julia Dietlmeier, Noel E. O'Connor, Ferran Marques",
        "summary": "Unsupervised anomaly detection (UAD) presents a complementary alternative to supervised learning for brain tumor segmentation in magnetic resonance imaging (MRI), particularly when annotated datasets are limited, costly, or inconsistent. In this work, we propose a novel Multimodal Vision Transformer Autoencoder (MViT-AE) trained exclusively on healthy brain MRIs to detect and localize tumors via reconstruction-based error maps. This unsupervised paradigm enables segmentation without reliance on manual labels, addressing a key scalability bottleneck in neuroimaging workflows. Our method is evaluated in the BraTS-GoAT 2025 Lighthouse dataset, which includes various types of tumors such as gliomas, meningiomas, and pediatric brain tumors. To enhance performance, we introduce a multimodal early-late fusion strategy that leverages complementary information across multiple MRI sequences, and a post-processing pipeline that integrates the Segment Anything Model (SAM) to refine predicted tumor contours. Despite the known challenges of UAD, particularly in detecting small or non-enhancing lesions, our method achieves clinically meaningful tumor localization, with lesion-wise Dice Similarity Coefficient of 0.437 (Whole Tumor), 0.316 (Tumor Core), and 0.350 (Enhancing Tumor) on the test set, and an anomaly Detection Rate of 89.4% on the validation set. These findings highlight the potential of transformer-based unsupervised models to serve as scalable, label-efficient tools for neuro-oncological imaging.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.461510"
    },
    {
        "index": "#53",
        "title": "Mixture of Experts Approaches in Dense Retrieval Tasks",
        "link": "/arxiv/2510.15683",
        "arxiv_id": "2510.15683",
        "authors": "Effrosyni Sokli, Pranav Kasela, Georgios Peikos, Gabriella Pasi",
        "summary": "Dense Retrieval Models (DRMs) are a prominent development in Information Retrieval (IR). A key challenge with these neural Transformer-based models is that they often struggle to generalize beyond the specific tasks and domains they were trained on. To address this challenge, prior research in IR incorporated the Mixture-of-Experts (MoE) framework within each Transformer layer of a DRM, which, though effective, substantially increased the number of additional parameters. In this paper, we propose a more efficient design, which introduces a single MoE block (SB-MoE) after the final Transformer layer. To assess the retrieval effectiveness of SB-MoE, we perform an empirical evaluation across three IR tasks. Our experiments involve two evaluation setups, aiming to assess both in-domain effectiveness and the model's zero-shot generalizability. In the first setup, we fine-tune SB-MoE with four different underlying DRMs on seven IR benchmarks and evaluate them on their respective test sets. In the second setup, we fine-tune SB-MoE on MSMARCO and perform zero-shot evaluation on thirteen BEIR datasets. Additionally, we perform further experiments to analyze the model's dependency on its hyperparameters (i.e., the number of employed and activated experts) and investigate how this variation affects SB-MoE's performance. The obtained results show that SB-MoE is particularly effective for DRMs with lightweight base models, such as TinyBERT and BERT-Small, consistently exceeding standard model fine-tuning across benchmarks. For DRMs with more parameters, such as BERT-Base and Contriever, our model requires a larger number of training samples to achieve improved retrieval performance. Our code is available online at: https://github.com/FaySokli/SB-MoE.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.461786"
    },
    {
        "index": "#54",
        "title": "ProofBridge: Auto-Formalization of Natural Language Proofs in Lean via Joint Embeddings",
        "link": "/arxiv/2510.15681",
        "arxiv_id": "2510.15681",
        "authors": "Prithwish Jana, Kaan Kale, Ahmet Ege Tanriverdi, Cruise Song, Sriram Vishwanath, Vijay Ganesh",
        "summary": "Translating human-written mathematical theorems and proofs from natural language (NL) into formal languages (FLs) like Lean 4 has long been a significant challenge for AI. Most state-of-the-art methods address this separately, first translating theorems and then generating proofs, creating a fundamental disconnect vis-a-vis true proof auto-formalization. This two-step process and its limitations were evident even in AlphaProof's silver-medal performance at the 2024 IMO, where problem statements needed manual translation before automated proof synthesis. We present ProofBridge, a unified framework for automatically translating entire NL theorems and proofs into Lean 4. At its core is a joint embedding model that aligns NL and FL (NL-FL) theorem-proof pairs in a shared semantic space, enabling cross-modal retrieval of semantically relevant FL examples to guide translation. Our training ensures that NL-FL theorems (and their proofs) are mapped close together in this space if and only if the NL-FL pairs are semantically equivalent. ProofBridge integrates retrieval-augmented fine-tuning with iterative proof repair, leveraging Lean's type checker and semantic equivalence feedback to ensure both syntactic correctness and semantic fidelity. Experiments show substantial improvements in proof auto-formalization over strong baselines (including GPT-5, Gemini-2.5, Kimina-Prover, DeepSeek-Prover), with our retrieval-augmented approach yielding significant gains in semantic correctness (SC, via proving bi-directional equivalence) and type correctness (TC, via type-checking theorem+proof) across pass@k metrics on miniF2F-Test-PF, a dataset we curated. In particular, ProofBridge improves cross-modal retrieval quality by up to 3.28x Recall@1 over all-MiniLM-L6-v2, and achieves +31.14% SC and +1.64% TC (pass@32) compared to the baseline Kimina-Prover-RL-1.7B.",
        "subjects": "Logic in Computer Science, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.462084"
    },
    {
        "index": "#56",
        "title": "Valeo Near-Field: a novel dataset for pedestrian intent detection",
        "link": "/arxiv/2510.15673",
        "arxiv_id": "2510.15673",
        "authors": "Antonyo Musabini, Rachid Benmokhtar, Jagdish Bhanushali, Victor Galizzi, Bertrand Luvison, Xavier Perrotton",
        "summary": "This paper presents a novel dataset aimed at detecting pedestrians' intentions as they approach an ego-vehicle. The dataset comprises synchronized multi-modal data, including fisheye camera feeds, lidar laser scans, ultrasonic sensor readings, and motion capture-based 3D body poses, collected across diverse real-world scenarios. Key contributions include detailed annotations of 3D body joint positions synchronized with fisheye camera images, as well as accurate 3D pedestrian positions extracted from lidar data, facilitating robust benchmarking for perception algorithms. We release a portion of the dataset along with a comprehensive benchmark suite, featuring evaluation metrics for accuracy, efficiency, and scalability on embedded systems. By addressing real-world challenges such as sensor occlusions, dynamic environments, and hardware constraints, this dataset offers a unique resource for developing and evaluating state-of-the-art algorithms in pedestrian detection, 3D pose estimation and 4D trajectory and intention prediction. Additionally, we provide baseline performance metrics using custom neural network architectures and suggest future research directions to encourage the adoption and enhancement of the dataset. This work aims to serve as a foundation for researchers seeking to advance the capabilities of intelligent vehicles in near-field scenarios.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.462657"
    },
    {
        "index": "#57",
        "title": "Enhance Large Language Models as Recommendation Systems with Collaborative Filtering",
        "link": "/arxiv/2510.15647",
        "arxiv_id": "2510.15647",
        "authors": "Zhisheng Yang, Xiaofei Xu, Ke Deng, Li Li",
        "summary": "As powerful tools in Natural Language Processing (NLP), Large Language Models (LLMs) have been leveraged for crafting recommendations to achieve precise alignment with user preferences and elevate the quality of the recommendations. The existing approaches implement both non-tuning and tuning strategies. Compared to following the tuning strategy, the approaches following the non-tuning strategy avoid the relatively costly, time-consuming, and expertise-requiring process of further training pre-trained LLMs on task-specific datasets, but they suffer the issue of not having the task-specific business or local enterprise knowledge. To the best of our knowledge, none of the existing approaches following the non-tuning strategy explicitly integrates collaborative filtering, one of the most successful recommendation techniques. This study aims to fill the gap by proposing critique-based LLMs as recommendation systems (Critic-LLM-RS). For our purpose, we train a separate machine-learning model called Critic that implements collaborative filtering for recommendations by learning from the interactions between many users and items. The Critic provides critiques to LLMs to significantly refine the recommendations. Extensive experiments have verified the effectiveness of Critic-LLM-RS on real datasets.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.462938"
    },
    {
        "index": "#59",
        "title": "Lightweight CycleGAN Models for Cross-Modality Image Transformation and Experimental Quality Assessment in Fluorescence Microscopy",
        "link": "/arxiv/2510.15579",
        "arxiv_id": "2510.15579",
        "authors": "Mohammad Soltaninezhad, Yashar Rouzbahani, Jhonatan Contreras, Rohan Chippalkatti, Daniel Kwaku Abankwa, Christian Eggeling, Thomas Bocklitz",
        "summary": "Lightweight deep learning models offer substantial reductions in computational cost and environmental impact, making them crucial for scientific applications. We present a lightweight CycleGAN for modality transfer in fluorescence microscopy (confocal to super-resolution STED/deconvolved STED), addressing the common challenge of unpaired datasets. By replacing the traditional channel-doubling strategy in the U-Net-based generator with a fixed channel approach, we drastically reduce trainable parameters from 41.8 million to approximately nine thousand, achieving superior performance with faster training and lower memory usage. We also introduce the GAN as a diagnostic tool for experimental and labeling quality. When trained on high-quality images, the GAN learns the characteristics of optimal imaging; deviations between its generated outputs and new experimental images can reveal issues such as photobleaching, artifacts, or inaccurate labeling. This establishes the model as a practical tool for validating experimental accuracy and image fidelity in microscopy workflows.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.463506"
    },
    {
        "index": "#60",
        "title": "The Spark Effect: On Engineering Creative Diversity in Multi-Agent AI Systems",
        "link": "/arxiv/2510.15568",
        "arxiv_id": "2510.15568",
        "authors": "Alexander Doudkin, Anton Voelker, Friedrich von Borries",
        "summary": "Creative services teams increasingly rely on large language models (LLMs) to accelerate ideation, yet production systems often converge on homogeneous outputs that fail to meet brand or artistic expectations. Art of X developed persona-conditioned LLM agents -- internally branded as \"Sparks\" and instantiated through a library of role-inspired system prompts -- to intentionally diversify agent behaviour within a multi-agent workflow. This white paper documents the problem framing, experimental design, and quantitative evidence behind the Spark agent programme. Using an LLM-as-a-judge protocol calibrated against human gold standards, we observe a mean diversity gain of +4.1 points (on a 1-10 scale) when persona-conditioned Spark agents replace a uniform system prompt, narrowing the gap to human experts to 1.0 point. We also surface evaluator bias and procedural considerations for future deployments.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.463801"
    },
    {
        "index": "#61",
        "title": "SpikeVox: Towards Energy-Efficient Speech Therapy Framework with Spike-driven Generative Language Models",
        "link": "/arxiv/2510.15566",
        "arxiv_id": "2510.15566",
        "authors": "Rachmad Vidya Wicaksana Putra, Aadithyan Rajesh Nair, Muhammad Shafique",
        "summary": "Speech disorders can significantly affect the patients capability to communicate, learn, and socialize. However, existing speech therapy solutions (e.g., therapist or tools) are still limited and costly, hence such solutions remain inadequate for serving millions of patients worldwide. To address this, state-of-the-art methods employ neural network (NN) algorithms to help accurately detecting speech disorders. However, these methods do not provide therapy recommendation as feedback, hence providing partial solution for patients. Moreover, these methods incur high energy consumption due to their complex and resource-intensive NN processing, hence hindering their deployments on low-power/energy platforms (e.g., smartphones). Toward this, we propose SpikeVox, a novel framework for enabling energy-efficient speech therapy solutions through spike-driven generative language model. Specifically, SpikeVox employs a speech recognition module to perform highly accurate speech-to-text conversion; leverages a spike-driven generative language model to efficiently perform pattern analysis for speech disorder detection and generates suitable exercises for therapy; provides guidance on correct pronunciation as feedback; as well as utilizes the REST API to enable seamless interaction for users. Experimental results demonstrate that SpikeVox achieves 88% confidence level on average in speech disorder recognition, while providing a complete feedback for therapy exercises. Therefore, SpikeVox provides a comprehensive framework for energy-efficient speech therapy solutions, and potentially addresses the significant global speech therapy access gap.",
        "subjects": "Sound, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.464082"
    },
    {
        "index": "#63",
        "title": "ClapperText: A Benchmark for Text Recognition in Low-Resource Archival Documents",
        "link": "/arxiv/2510.15557",
        "arxiv_id": "2510.15557",
        "authors": "Tingyu Lin, Marco Peer, Florian Kleber, Robert Sablatnig",
        "summary": "This paper presents ClapperText, a benchmark dataset for handwritten and printed text recognition in visually degraded and low-resource settings. The dataset is derived from 127 World War II-era archival video segments containing clapperboards that record structured production metadata such as date, location, and camera-operator identity. ClapperText includes 9,813 annotated frames and 94,573 word-level text instances, 67% of which are handwritten and 1,566 are partially occluded. Each instance includes transcription, semantic category, text type, and occlusion status, with annotations available as rotated bounding boxes represented as 4-point polygons to support spatially precise OCR applications. Recognizing clapperboard text poses significant challenges, including motion blur, handwriting variation, exposure fluctuations, and cluttered backgrounds, mirroring broader challenges in historical document analysis where structured content appears in degraded, non-standard forms. We provide both full-frame annotations and cropped word images to support downstream tasks. Using a consistent per-video evaluation protocol, we benchmark six representative recognition and seven detection models under zero-shot and fine-tuned conditions. Despite the small training set (18 videos), fine-tuning leads to substantial performance gains, highlighting ClapperText's suitability for few-shot learning scenarios. The dataset offers a realistic and culturally grounded resource for advancing robust OCR and document understanding in low-resource archival contexts. The dataset and evaluation code are available at https://github.com/linty5/ClapperText.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Image and Video Processing",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.464652"
    },
    {
        "index": "#70",
        "title": "AI Adoption in NGOs: A Systematic Literature Review",
        "link": "/arxiv/2510.15509",
        "arxiv_id": "2510.15509",
        "authors": "Janne Rotter, William Bailkoski",
        "summary": "AI has the potential to significantly improve how NGOs utilize their limited resources for societal benefits, but evidence about how NGOs adopt AI remains scattered. In this study, we systematically investigate the types of AI adoption use cases in NGOs and identify common challenges and solutions, contextualized by organizational size and geographic context. We review the existing primary literature, including studies that investigate AI adoption in NGOs related to social impact between 2020 and 2025 in English. Following the PRISMA protocol, two independent reviewers conduct study selection, with regular cross-checking to ensure methodological rigour, resulting in a final literature body of 65 studies. Leveraging a thematic and narrative approach, we identify six AI use case categories in NGOs - Engagement, Creativity, Decision-Making, Prediction, Management, and Optimization - and extract common challenges and solutions within the Technology-Organization-Environment (TOE) framework. By integrating our findings, this review provides a novel understanding of AI adoption in NGOs, linking specific use cases and challenges to organizational and environmental factors. Our results demonstrate that while AI is promising, adoption among NGOs remains uneven and biased towards larger organizations. Nevertheless, following a roadmap grounded in literature can help NGOs overcome initial barriers to AI adoption, ultimately improving effectiveness, engagement, and social impact.",
        "subjects": "Computers and Society, Artificial Intelligence, General Economics",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.466633"
    },
    {
        "index": "#74",
        "title": "An Experimental Study of Real-Life LLM-Proposed Performance Improvements",
        "link": "/arxiv/2510.15494",
        "arxiv_id": "2510.15494",
        "authors": "Lirong Yi, Gregory Gay, Philipp Leitner",
        "summary": "Large Language Models (LLMs) can generate code, but can they generate fast code? In this paper, we study this question using a dataset of 65 real-world tasks mined from open-source Java programs. We specifically select tasks where developers achieved significant speedups, and employ an automated pipeline to generate patches for these issues using two leading LLMs under four prompt variations. By rigorously benchmarking the results against the baseline and human-authored solutions, we demonstrate that LLM-generated code indeed improves performance over the baseline in most cases. However, patches proposed by human developers outperform LLM fixes by a statistically significant margin, indicating that LLMs often fall short of finding truly optimal solutions. We further find that LLM solutions are semantically identical or similar to the developer optimization idea in approximately two-thirds of cases, whereas they propose a more original idea in the remaining one-third. However, these original ideas only occasionally yield substantial performance gains.",
        "subjects": "Software Engineering, Artificial Intelligence, Performance",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.467781"
    },
    {
        "index": "#75",
        "title": "Selecting and Combining Large Language Models for Scalable Code Clone Detection",
        "link": "/arxiv/2510.15480",
        "arxiv_id": "2510.15480",
        "authors": "Muslim Chochlov, Gul Aftab Ahmed, James Vincent Patten, Yuanhua Han, Guoxian Lu, David Gregg, Jim Buckley",
        "summary": "Source code clones pose risks ranging from intellectual property violations to unintended vulnerabilities. Effective and efficient scalable clone detection, especially for diverged clones, remains challenging. Large language models (LLMs) have recently been applied to clone detection tasks. However, the rapid emergence of LLMs raises questions about optimal model selection and potential LLM-ensemble efficacy. This paper addresses the first question by identifying 76 LLMs and filtering them down to suitable candidates for large-scale clone detection. The candidates were evaluated on two public industrial datasets, BigCloneBench, and a commercial large-scale dataset. No uniformly 'best-LLM' emerged, though CodeT5+110M, CuBERT and SPTCode were top-performers. Analysis of LLM-candidates suggested that smaller embedding sizes, smaller tokenizer vocabularies and tailored datasets are advantageous. On commercial large-scale dataset a top-performing CodeT5+110M achieved 39.71\\% precision: twice the precision of previously used CodeBERT. To address the second question, this paper explores ensembling of the selected LLMs: effort-effective approach to improving effectiveness. Results suggest the importance of score normalization and favoring ensembling methods like maximum or sum over averaging. Also, findings indicate that ensembling approach can be statistically significant and effective on larger datasets: the best-performing ensemble achieved even higher precision of 46.91\\% over individual LLM on the commercial large-scale code.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.468091"
    },
    {
        "index": "#76",
        "title": "SoK: Taxonomy and Evaluation of Prompt Security in Large Language Models",
        "link": "/arxiv/2510.15476",
        "arxiv_id": "2510.15476",
        "authors": "Hanbin Hong, Shuya Feng, Nima Naderloui, Shenao Yan, Jingyu Zhang, Biying Liu, Ali Arastehfard, Heqing Huang, Yuan Hong",
        "summary": "Large Language Models (LLMs) have rapidly become integral to real-world applications, powering services across diverse sectors. However, their widespread deployment has exposed critical security risks, particularly through jailbreak prompts that can bypass model alignment and induce harmful outputs. Despite intense research into both attack and defense techniques, the field remains fragmented: definitions, threat models, and evaluation criteria vary widely, impeding systematic progress and fair comparison. In this Systematization of Knowledge (SoK), we address these challenges by (1) proposing a holistic, multi-level taxonomy that organizes attacks, defenses, and vulnerabilities in LLM prompt security; (2) formalizing threat models and cost assumptions into machine-readable profiles for reproducible evaluation; (3) introducing an open-source evaluation toolkit for standardized, auditable comparison of attacks and defenses; (4) releasing JAILBREAKDB, the largest annotated dataset of jailbreak and benign prompts to date; and (5) presenting a comprehensive evaluation and leaderboard of state-of-the-art methods. Our work unifies fragmented research, provides rigorous foundations for future studies, and supports the development of robust, trustworthy LLMs suitable for high-stakes deployment.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.468411"
    },
    {
        "index": "#81",
        "title": "Select Less, Reason More: Prioritizing Evidence Purity for Video Reasoning",
        "link": "/arxiv/2510.15440",
        "arxiv_id": "2510.15440",
        "authors": "Xuchen Li, Xuzhao Li, Shiyu Hu, Kaiqi Huang",
        "summary": "Long-form video reasoning remains a major challenge for Video Large Language Models (Video LLMs), as static uniform frame sampling leads to information dilution and obscures critical evidence. Furthermore, existing pixel-space video reasoning agents, which are designed to actively interact with the video to acquire new visual information, remain suboptimal due to their lack of rigorous reward mechanisms to enforce evidence purity and their inability to perform temporal information supplementation beyond pre-sampled frames. To address this critical gap, we propose a novel evidence-prioritized adaptive framework built upon our core philosophy: \"Select Less, Reason More.\" Our core contribution is the evidence-aware reinforcement learning (EARL) framework, which transforms the model into an active interrogator of evidence. EARL is precisely engineered to dynamically select the most relevant frames and, crucially, to perform localized re-sampling around the selected key frames to access fine-grained temporal detail. Extensive experiments on five demanding video reasoning benchmarks demonstrate that our EARL-trained model achieves new state-of-the-art among open-source Video LLMs, simultaneously learning an effective and high-purity visual evidence selection policy. Impressively, our 7B model achieves 59.8% on LongVideoBench, 69.0% on MVBench and 64.9% on VideoMME. These results highlight the importance of prioritizing evidence purity and the effectiveness of our framework.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.469946"
    },
    {
        "index": "#82",
        "title": "Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models",
        "link": "/arxiv/2510.15430",
        "arxiv_id": "2510.15430",
        "authors": "Shuang Liang, Zhihao Xu, Jialing Tao, Hui Xue, Xiting Wang",
        "summary": "Despite extensive alignment efforts, Large Vision-Language Models (LVLMs) remain vulnerable to jailbreak attacks, posing serious safety risks. To address this, existing detection methods either learn attack-specific parameters, which hinders generalization to unseen attacks, or rely on heuristically sound principles, which limit accuracy and efficiency. To overcome these limitations, we propose Learning to Detect (LoD), a general framework that accurately detects unknown jailbreak attacks by shifting the focus from attack-specific learning to task-specific learning. This framework includes a Multi-modal Safety Concept Activation Vector module for safety-oriented representation learning and a Safety Pattern Auto-Encoder module for unsupervised attack classification. Extensive experiments show that our method achieves consistently higher detection AUROC on diverse unknown attacks while improving efficiency. The code is available at https://anonymous.4open.science/r/Learning-to-Detect-51CB.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.470232"
    },
    {
        "index": "#84",
        "title": "Robust High-Resolution Multi-Organ Diffusion MRI Using Synthetic-Data-Tuned Prompt Learning",
        "link": "/arxiv/2510.15400",
        "arxiv_id": "2510.15400",
        "authors": "Chen Qian, Haoyu Zhang, Junnan Ma, Liuhong Zhu, Qingrui Cai, Yu Wang, Ruibo Song, Lv Li, Lin Mei, Xianwang Jiang, Qin Xu, Boyu Jiang, Ran Tao, Chunmiao Chen, Shufang Chen, Dongyun Liang, Qiu Guo, Jianzhong Lin, Taishan Kang, Mengtian Lu, Liyuan Fu, Ruibin Huang, Huijuan Wan, Xu Huang, Jianhua Wang, Di Guo, Hai Zhong, Jianjun Zhou, Xiaobo Qu",
        "summary": "Clinical adoption of multi-shot diffusion-weighted magnetic resonance imaging (multi-shot DWI) for body-wide tumor diagnostics is limited by severe motion-induced phase artifacts from respiration, peristalsis, and so on, compounded by multi-organ, multi-slice, multi-direction and multi-b-value complexities. Here, we introduce a reconstruction framework, LoSP-Prompt, that overcomes these challenges through physics-informed modeling and synthetic-data-driven prompt learning. We model inter-shot phase variations as a high-order Locally Smooth Phase (LoSP), integrated into a low-rank Hankel matrix reconstruction. Crucially, the algorithm's rank parameter is automatically set via prompt learning trained exclusively on synthetic abdominal DWI data emulating physiological motion. Validated across 10,000+ clinical images (43 subjects, 4 scanner models, 5 centers), LoSP-Prompt: (1) Achieved twice the spatial resolution of clinical single-shot DWI, enhancing liver lesion conspicuity; (2) Generalized to seven diverse anatomical regions (liver, kidney, sacroiliac, pelvis, knee, spinal cord, brain) with a single model; (3) Outperformed state-of-the-art methods in image quality, artifact suppression, and noise reduction (11 radiologists' evaluations on a 5-point scale, $p<0.05$), achieving 4-5 points (excellent) on kidney DWI, 4 points (good to excellent) on liver, sacroiliac and spinal cord DWI, and 3-4 points (good) on knee and tumor brain. The approach eliminates navigator signals and realistic data supervision, providing an interpretable, robust solution for high-resolution multi-organ multi-shot DWI. Its scanner-agnostic performance signifies transformative potential for precision oncology.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Medical Physics",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.471007"
    },
    {
        "index": "#85",
        "title": "MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment",
        "link": "/arxiv/2510.15398",
        "arxiv_id": "2510.15398",
        "authors": "Bingyu Li, Feiyu Wang, Da Zhang, Zhiyuan Zhao, Junyu Gao, Xuelong Li",
        "summary": "Most existing underwater instance segmentation approaches are constrained by close-vocabulary prediction, limiting their ability to recognize novel marine categories. To support evaluation, we introduce \\textbf{MARIS} (\\underline{Mar}ine Open-Vocabulary \\underline{I}nstance \\underline{S}egmentation), the first large-scale fine-grained benchmark for underwater Open-Vocabulary (OV) segmentation, featuring a limited set of seen categories and diverse unseen categories. Although OV segmentation has shown promise on natural images, our analysis reveals that transfer to underwater scenes suffers from severe visual degradation (e.g., color attenuation) and semantic misalignment caused by lack underwater class definitions. To address these issues, we propose a unified framework with two complementary components. The Geometric Prior Enhancement Module (\\textbf{GPEM}) leverages stable part-level and structural cues to maintain object consistency under degraded visual conditions. The Semantic Alignment Injection Mechanism (\\textbf{SAIM}) enriches language embeddings with domain-specific priors, mitigating semantic ambiguity and improving recognition of unseen categories. Experiments show that our framework consistently outperforms existing OV baselines both In-Domain and Cross-Domain setting on MARIS, establishing a strong foundation for future underwater perception research.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.471306"
    },
    {
        "index": "#86",
        "title": "DroneAudioset: An Audio Dataset for Drone-based Search and Rescue",
        "link": "/arxiv/2510.15383",
        "arxiv_id": "2510.15383",
        "authors": "Chitralekha Gupta, Soundarya Ramesh, Praveen Sasikumar, Kian Peen Yeo, Suranga Nanayakkara",
        "summary": "Unmanned Aerial Vehicles (UAVs) or drones, are increasingly used in search and rescue missions to detect human presence. Existing systems primarily leverage vision-based methods which are prone to fail under low-visibility or occlusion. Drone-based audio perception offers promise but suffers from extreme ego-noise that masks sounds indicating human presence. Existing datasets are either limited in diversity or synthetic, lacking real acoustic interactions, and there are no standardized setups for drone audition. To this end, we present DroneAudioset (The dataset is publicly available at https://huggingface.co/datasets/ahlab-drone-project/DroneAudioSet/ under the MIT license), a comprehensive drone audition dataset featuring 23.5 hours of annotated recordings, covering a wide range of signal-to-noise ratios (SNRs) from -57.2 dB to -2.5 dB, across various drone types, throttles, microphone configurations as well as environments. The dataset enables development and systematic evaluation of noise suppression and classification methods for human-presence detection under challenging conditions, while also informing practical design considerations for drone audition systems, such as microphone placement trade-offs, and development of drone noise-aware audio processing. This dataset is an important step towards enabling design and deployment of drone-audition systems.",
        "subjects": "Audio and Speech Processing, Artificial Intelligence, Sound",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.471604"
    },
    {
        "index": "#88",
        "title": "Cortical-SSM: A Deep State Space Model for EEG and ECoG Motor Imagery Decoding",
        "link": "/arxiv/2510.15371",
        "arxiv_id": "2510.15371",
        "authors": "Shuntaro Suzuki, Shunya Nagashima, Masayuki Hirata, Komei Sugiura",
        "summary": "Classification of electroencephalogram (EEG) and electrocorticogram (ECoG) signals obtained during motor imagery (MI) has substantial application potential, including for communication assistance and rehabilitation support for patients with motor impairments. These signals remain inherently susceptible to physiological artifacts (e.g., eye blinking, swallowing), which pose persistent challenges. Although Transformer-based approaches for classifying EEG and ECoG signals have been widely adopted, they often struggle to capture fine-grained dependencies within them. To overcome these limitations, we propose Cortical-SSM, a novel architecture that extends deep state space models to capture integrated dependencies of EEG and ECoG signals across temporal, spatial, and frequency domains. We validated our method across three benchmarks: 1) two large-scale public MI EEG datasets containing more than 50 subjects, and 2) a clinical MI ECoG dataset recorded from a patient with amyotrophic lateral sclerosis. Our method outperformed baseline methods on the three benchmarks. Furthermore, visual explanations derived from our model indicate that it effectively captures neurophysiologically relevant regions of both EEG and ECoG signals.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.472193"
    },
    {
        "index": "#90",
        "title": "GaussGym: An open-source real-to-sim framework for learning locomotion from pixels",
        "link": "/arxiv/2510.15352",
        "arxiv_id": "2510.15352",
        "authors": "Alejandro Escontrela, Justin Kerr, Arthur Allshire, Jonas Frey, Rocky Duan, Carmelo Sferrazza, Pieter Abbeel",
        "summary": "We present a novel approach for photorealistic robot simulation that integrates 3D Gaussian Splatting as a drop-in renderer within vectorized physics simulators such as IsaacGym. This enables unprecedented speed -- exceeding 100,000 steps per second on consumer GPUs -- while maintaining high visual fidelity, which we showcase across diverse tasks. We additionally demonstrate its applicability in a sim-to-real robotics setting. Beyond depth-based sensing, our results highlight how rich visual semantics improve navigation and decision-making, such as avoiding undesirable regions. We further showcase the ease of incorporating thousands of environments from iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs from generative video models like Veo, enabling rapid creation of realistic training worlds. This work bridges high-throughput simulation and high-fidelity perception, advancing scalable and generalizable robot learning. All code and data will be open-sourced for the community to build upon. Videos, code, and data available at https://escontrela.me/gauss_gym/.",
        "subjects": "Robotics, Artificial Intelligence, Graphics",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.472810"
    },
    {
        "index": "#93",
        "title": "ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning",
        "link": "/arxiv/2510.15331",
        "arxiv_id": "2510.15331",
        "authors": "Gahee Kim, Takamitsu Matsubara",
        "summary": "Black-box simulators are widely used in robotics, but optimizing their parameters remains challenging due to inaccessible likelihoods. Simulation-Based Inference (SBI) tackles this issue using simulation-driven approaches, estimating the posterior from offline real observations and forward simulations. However, in black-box scenarios, preparing observations that contain sufficient information for parameter estimation is difficult due to the unknown relationship between parameters and observations. In this work, we present Active Simulation-Based Inference (ASBI), a parameter estimation framework that uses robots to actively collect real-world online data to achieve accurate black-box simulator tuning. Our framework optimizes robot actions to collect informative observations by maximizing information gain, which is defined as the expected reduction in Shannon entropy between the posterior and the prior. While calculating information gain requires the likelihood, which is inaccessible in black-box simulators, our method solves this problem by leveraging Neural Posterior Estimation (NPE), which leverages a neural network to learn the posterior estimator. Three simulation experiments quantitatively verify that our method achieves accurate parameter estimation, with posteriors sharply concentrated around the true parameters. Moreover, we show a practical application using a real robot to estimate the simulation parameters of cubic particles corresponding to two real objects, beads and gravel, with a bucket pouring action.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.473637"
    },
    {
        "index": "#95",
        "title": "DSSmoothing: Toward Certified Dataset Ownership Verification for Pre-trained Language Models via Dual-Space Smoothing",
        "link": "/arxiv/2510.15303",
        "arxiv_id": "2510.15303",
        "authors": "Ting Qiao, Xing Liu, Wenke Huang, Jianbin Li, Zhaoxin Fan, Yiming Li",
        "summary": "Large web-scale datasets have driven the rapid advancement of pre-trained language models (PLMs), but unauthorized data usage has raised serious copyright concerns. Existing dataset ownership verification (DOV) methods typically assume that watermarks remain stable during inference; however, this assumption often fails under natural noise and adversary-crafted perturbations. We propose the first certified dataset ownership verification method for PLMs based on dual-space smoothing (i.e., DSSmoothing). To address the challenges of text discreteness and semantic sensitivity, DSSmoothing introduces continuous perturbations in the embedding space to capture semantic robustness and applies controlled token reordering in the permutation space to capture sequential robustness. DSSmoothing consists of two stages: in the first stage, triggers are collaboratively embedded in both spaces to generate norm-constrained and robust watermarked datasets; in the second stage, randomized smoothing is applied in both spaces during verification to compute the watermark robustness (WR) of suspicious models and statistically compare it with the principal probability (PP) values of a set of benign models. Theoretically, DSSmoothing provides provable robustness guarantees for dataset ownership verification by ensuring that WR consistently exceeds PP under bounded dual-space perturbations. Extensive experiments on multiple representative web datasets demonstrate that DSSmoothing achieves stable and reliable verification performance and exhibits robustness against potential adaptive attacks.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computers and Society",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.474268"
    },
    {
        "index": "#96",
        "title": "Latent Diffusion Model without Variational Autoencoder",
        "link": "/arxiv/2510.15301",
        "arxiv_id": "2510.15301",
        "authors": "Minglei Shi, Haolin Wang, Wenzhao Zheng, Ziyang Yuan, Xiaoshi Wu, Xintao Wang, Pengfei Wan, Jie Zhou, Jiwen Lu",
        "summary": "Recent progress in diffusion-based visual generation has largely relied on latent diffusion models with variational autoencoders (VAEs). While effective for high-fidelity synthesis, this VAE+diffusion paradigm suffers from limited training efficiency, slow inference, and poor transferability to broader vision tasks. These issues stem from a key limitation of VAE latent spaces: the lack of clear semantic separation and strong discriminative structure. Our analysis confirms that these properties are crucial not only for perception and understanding tasks, but also for the stable and efficient training of latent diffusion models. Motivated by this insight, we introduce SVG, a novel latent diffusion model without variational autoencoders, which leverages self-supervised representations for visual generation. SVG constructs a feature space with clear semantic discriminability by leveraging frozen DINO features, while a lightweight residual branch captures fine-grained details for high-fidelity reconstruction. Diffusion models are trained directly on this semantically structured latent space to facilitate more efficient learning. As a result, SVG enables accelerated diffusion training, supports few-step sampling, and improves generative quality. Experimental results further show that SVG preserves the semantic and discriminative capabilities of the underlying self-supervised representations, providing a principled pathway toward task-general, high-quality visual representations.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.474596"
    },
    {
        "index": "#97",
        "title": "VERA-MH Concept Paper",
        "link": "/arxiv/2510.15297",
        "arxiv_id": "2510.15297",
        "authors": "Luca Belli, Kate Bentley, Will Alexander, Emily Ward, Matt Hawrilenko, Kelly Johnston, Mill Brown, Adam Chekroud",
        "summary": "We introduce VERA-MH (Validation of Ethical and Responsible AI in Mental Health), an automated evaluation of the safety of AI chatbots used in mental health contexts, with an initial focus on suicide risk. Practicing clinicians and academic experts developed a rubric informed by best practices for suicide risk management for the evaluation. To fully automate the process, we used two ancillary AI agents. A user-agent model simulates users engaging in a mental health-based conversation with the chatbot under evaluation. The user-agent role-plays specific personas with pre-defined risk levels and other features. Simulated conversations are then passed to a judge-agent who scores them based on the rubric. The final evaluation of the chatbot being tested is obtained by aggregating the scoring of each conversation. VERA-MH is actively under development and undergoing rigorous validation by mental health clinicians to ensure user-agents realistically act as patients and that the judge-agent accurately scores the AI chatbot. To date we have conducted preliminary evaluation of GPT-5, Claude Opus and Claude Sonnet using initial versions of the VERA-MH rubric and used the findings for further design development. Next steps will include more robust clinical validation and iteration, as well as refining actionable scoring. We are seeking feedback from the community on both the technical and clinical aspects of our evaluation.",
        "subjects": "Computers and Society, Artificial Intelligence, Social and Information Networks",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.474932"
    },
    {
        "index": "#99",
        "title": "MTmixAtt: Integrating Mixture-of-Experts with Multi-Mix Attention for Large-Scale Recommendation",
        "link": "/arxiv/2510.15286",
        "arxiv_id": "2510.15286",
        "authors": "Xianyang Qi, Yuan Tian, Zhaoyu Hu, Zhirui Kuai, Chang Liu, Hongxiang Lin, Lei Wang",
        "summary": "Industrial recommender systems critically depend on high-quality ranking models. However, traditional pipelines still rely on manual feature engineering and scenario-specific architectures, which hinder cross-scenario transfer and large-scale deployment. To address these challenges, we propose \\textbf{MTmixAtt}, a unified Mixture-of-Experts (MoE) architecture with Multi-Mix Attention, designed for large-scale recommendation tasks. MTmixAtt integrates two key components. The \\textbf{AutoToken} module automatically clusters heterogeneous features into semantically coherent tokens, removing the need for human-defined feature groups. The \\textbf{MTmixAttBlock} module enables efficient token interaction via a learnable mixing matrix, shared dense experts, and scenario-aware sparse experts, capturing both global patterns and scenario-specific behaviors within a single framework. Extensive experiments on the industrial TRec dataset from Meituan demonstrate that MTmixAtt consistently outperforms state-of-the-art baselines including Transformer-based models, WuKong, HiFormer, MLP-Mixer, and RankMixer. At comparable parameter scales, MTmixAtt achieves superior CTR and CTCVR metrics; scaling to MTmixAtt-1B yields further monotonic gains. Large-scale online A/B tests validate the real-world impact: in the \\textit{Homepage} scenario, MTmixAtt increases Payment PV by \\textbf{+3.62\\%} and Actual Payment GTV by \\textbf{+2.54\\%}. Overall, MTmixAtt provides a unified and scalable solution for modeling arbitrary heterogeneous features across scenarios, significantly improving both user experience and commercial outcomes.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.475541"
    },
    {
        "index": "#112",
        "title": "The Economics of AI Foundation Models: Openness, Competition, and Governance",
        "link": "/arxiv/2510.15200",
        "arxiv_id": "2510.15200",
        "authors": "Fasheng Xu, Xiaoyu Wang, Wei Chen, Karen Xie",
        "summary": "The strategic choice of model \"openness\" has become a defining issue for the foundation model (FM) ecosystem. While this choice is intensely debated, its underlying economic drivers remain underexplored. We construct a two-period game-theoretic model to analyze how openness shapes competition in an AI value chain, featuring an incumbent developer, a downstream deployer, and an entrant developer. Openness exerts a dual effect: it amplifies knowledge spillovers to the entrant, but it also enhances the incumbent's advantage through a \"data flywheel effect,\" whereby greater user engagement today further lowers the deployer's future fine-tuning cost. Our analysis reveals that the incumbent's optimal first-period openness is surprisingly non-monotonic in the strength of the data flywheel effect. When the data flywheel effect is either weak or very strong, the incumbent prefers a higher level of openness; however, for an intermediate range, it strategically restricts openness to impair the entrant's learning. This dynamic gives rise to an \"openness trap,\" a critical policy paradox where transparency mandates can backfire by removing firms' strategic flexibility, reducing investment, and lowering welfare. We extend the model to show that other common interventions can be similarly ineffective. Vertical integration, for instance, only benefits the ecosystem when the data flywheel effect is strong enough to overcome the loss of a potentially more efficient competitor. Likewise, government subsidies intended to spur adoption can be captured entirely by the incumbent through strategic price and openness adjustments, leaving the rest of the value chain worse off. By modeling the developer's strategic response to competitive and regulatory pressures, we provide a robust framework for analyzing competition and designing effective policy in the complex and rapidly evolving FM ecosystem.",
        "subjects": "Theoretical Economics, Artificial Intelligence",
        "date": "2025-10-17",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.479519"
    },
    {
        "index": "#114",
        "title": "XModBench: Benchmarking Cross-Modal Capabilities and Consistency in Omni-Language Models",
        "link": "/arxiv/2510.15148",
        "arxiv_id": "2510.15148",
        "authors": "Xingrui Wang, Jiang Liu, Chao Huang, Xiaodong Yu, Ze Wang, Ximeng Sun, Jialian Wu, Alan Yuille, Emad Barsoum, Zicheng Liu",
        "summary": "Omni-modal large language models (OLLMs) aim to unify audio, vision, and text understanding within a single framework. While existing benchmarks primarily evaluate general cross-modal question-answering ability, it remains unclear whether OLLMs achieve modality-invariant reasoning or exhibit modality-specific biases. We introduce XModBench, a large-scale tri-modal benchmark explicitly designed to measure cross-modal consistency. XModBench comprises 60,828 multiple-choice questions spanning five task families and systematically covers all six modality compositions in question-answer pairs, enabling fine-grained diagnosis of an OLLM's modality-invariant reasoning, modality disparity, and directional imbalance. Experiments show that even the strongest model, Gemini 2.5 Pro, (i) struggles with spatial and temporal reasoning, achieving less than 60% accuracy, (ii) reveals persistent modality disparities, with performance dropping substantially when the same semantic content is conveyed through audio rather than text, and (iii) shows systematic directional imbalance, exhibiting lower consistency when vision serves as context compared to text. These findings indicate that current OLLMs remain far from truly modality-invariant reasoning and position XModBench as a fundamental diagnostic tool for evaluating and improving cross-modal competence. All data and evaluation tools will be available at https://xingruiwang.github.io/projects/XModBench/.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.480195"
    },
    {
        "index": "#121",
        "title": "Beyond Outcome-Based Imperfect-Recall: Higher-Resolution Abstractions for Imperfect-Information Games",
        "link": "/arxiv/2510.15094",
        "arxiv_id": "2510.15094",
        "authors": "Yanchang Fu, Qiyue Yin, Shengda Liu, Pei Xu, Kaiqi Huang",
        "summary": "Hand abstraction is crucial for scaling imperfect-information games (IIGs) such as Texas Hold'em, yet progress is limited by the lack of a formal task model and by evaluations that require resource-intensive strategy solving. We introduce signal observation ordered games (SOOGs), a subclass of IIGs tailored to hold'em-style games that cleanly separates signal from player action sequences, providing a precise mathematical foundation for hand abstraction. Within this framework, we define a resolution bound-an information-theoretic upper bound on achievable performance under a given signal abstraction. Using the bound, we show that mainstream outcome-based imperfect-recall algorithms suffer substantial losses by arbitrarily discarding historical information; we formalize this behavior via potential-aware outcome Isomorphism (PAOI) and prove that PAOI characterizes their resolution bound. To overcome this limitation, we propose full-recall outcome isomorphism (FROI), which integrates historical information to raise the bound and improve policy quality. Experiments on hold'em-style benchmarks confirm that FROI consistently outperforms outcome-based imperfect-recall baselines. Our results provide a unified formal treatment of hand abstraction and practical guidance for designing higher-resolution abstractions in IIGs.",
        "subjects": "Computer Science and Game Theory, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.482326"
    },
    {
        "index": "#122",
        "title": "DMRetriever: A Family of Models for Improved Text Retrieval in Disaster Management",
        "link": "/arxiv/2510.15087",
        "arxiv_id": "2510.15087",
        "authors": "Kai Yin, Xiangjue Dong, Chengkai Liu, Allen Lin, Lingfeng Shi, Ali Mostafavi, James Caverlee",
        "summary": "Effective and efficient access to relevant information is essential for disaster management. However, no retrieval model is specialized for disaster management, and existing general-domain models fail to handle the varied search intents inherent to disaster management scenarios, resulting in inconsistent and unreliable performance. To this end, we introduce DMRetriever, the first series of dense retrieval models (33M to 7.6B) tailored for this domain. It is trained through a novel three-stage framework of bidirectional attention adaptation, unsupervised contrastive pre-training, and difficulty-aware progressive instruction fine-tuning, using high-quality data generated through an advanced data refinement pipeline. Comprehensive experiments demonstrate that DMRetriever achieves state-of-the-art (SOTA) performance across all six search intents at every model scale. Moreover, DMRetriever is highly parameter-efficient, with 596M model outperforming baselines over 13.3 X larger and 33M model exceeding baselines with only 7.6% of their parameters. All codes, data, and checkpoints are available at https://github.com/KaiYin97/DMRETRIEVER",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.482630"
    },
    {
        "index": "#123",
        "title": "Sequential Comics for Jailbreaking Multimodal Large Language Models via Structured Visual Storytelling",
        "link": "/arxiv/2510.15068",
        "arxiv_id": "2510.15068",
        "authors": "Deyue Zhang, Dongdong Yang, Junjie Mu, Quancheng Zou, Zonghao Ying, Wenzhuo Xu, Zhao Liu, Xuan Wang, Xiangzheng Zhang",
        "summary": "Multimodal large language models (MLLMs) exhibit remarkable capabilities but remain susceptible to jailbreak attacks exploiting cross-modal vulnerabilities. In this work, we introduce a novel method that leverages sequential comic-style visual narratives to circumvent safety alignments in state-of-the-art MLLMs. Our method decomposes malicious queries into visually innocuous storytelling elements using an auxiliary LLM, generates corresponding image sequences through diffusion models, and exploits the models' reliance on narrative coherence to elicit harmful outputs. Extensive experiments on harmful textual queries from established safety benchmarks show that our approach achieves an average attack success rate of 83.5\\%, surpassing prior state-of-the-art by 46\\%. Compared with existing visual jailbreak methods, our sequential narrative strategy demonstrates superior effectiveness across diverse categories of harmful content. We further analyze attack patterns, uncover key vulnerability factors in multimodal safety mechanisms, and evaluate the limitations of current defense strategies against narrative-driven attacks, revealing significant gaps in existing protections.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.482960"
    },
    {
        "index": "#125",
        "title": "UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos",
        "link": "/arxiv/2510.15018",
        "arxiv_id": "2510.15018",
        "authors": "Mingxuan Liu, Honglin He, Elisa Ricci, Wayne Wu, Bolei Zhou",
        "summary": "Urban embodied AI agents, ranging from delivery robots to quadrupeds, are increasingly populating our cities, navigating chaotic streets to provide last-mile connectivity. Training such agents requires diverse, high-fidelity urban environments to scale, yet existing human-crafted or procedurally generated simulation scenes either lack scalability or fail to capture real-world complexity. We introduce UrbanVerse, a data-driven real-to-sim system that converts crowd-sourced city-tour videos into physics-aware, interactive simulation scenes. UrbanVerse consists of: (i) UrbanVerse-100K, a repository of 100k+ annotated urban 3D assets with semantic and physical attributes, and (ii) UrbanVerse-Gen, an automatic pipeline that extracts scene layouts from video and instantiates metric-scale 3D simulations using retrieved assets. Running in IsaacSim, UrbanVerse offers 160 high-quality constructed scenes from 24 countries, along with a curated benchmark of 10 artist-designed test scenes. Experiments show that UrbanVerse scenes preserve real-world semantics and layouts, achieving human-evaluated realism comparable to manually crafted scenes. In urban navigation, policies trained in UrbanVerse exhibit scaling power laws and strong generalization, improving success by +6.3% in simulation and +30.1% in zero-shot sim-to-real transfer comparing to prior methods, accomplishing a 300 m real-world mission with only two interventions.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Robotics",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.483602"
    },
    {
        "index": "#126",
        "title": "Active Honeypot Guardrail System: Probing and Confirming Multi-Turn LLM Jailbreaks",
        "link": "/arxiv/2510.15017",
        "arxiv_id": "2510.15017",
        "authors": "ChenYu Wu, Yi Wang, Yang Liao",
        "summary": "Large language models (LLMs) are increasingly vulnerable to multi-turn jailbreak attacks, where adversaries iteratively elicit harmful behaviors that bypass single-turn safety filters. Existing defenses predominantly rely on passive rejection, which either fails against adaptive attackers or overly restricts benign users. We propose a honeypot-based proactive guardrail system that transforms risk avoidance into risk utilization. Our framework fine-tunes a bait model to generate ambiguous, non-actionable but semantically relevant responses, which serve as lures to probe user intent. Combined with the protected LLM's safe reply, the system inserts proactive bait questions that gradually expose malicious intent through multi-turn interactions. We further introduce the Honeypot Utility Score (HUS), measuring both the attractiveness and feasibility of bait responses, and use a Defense Efficacy Rate (DER) for balancing safety and usability. Initial experiment on MHJ Datasets with recent attack method across GPT-4o show that our system significantly disrupts jailbreak success while preserving benign user experience.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.483894"
    },
    {
        "index": "#133",
        "title": "Automated Snippet-Alignment Data Augmentation for Code Translation",
        "link": "/arxiv/2510.15004",
        "arxiv_id": "2510.15004",
        "authors": "Zhiming Zhang, Qingfu Zhu, Xianzhen Luo, Yixuan Wang, Bohan Li, Wanxiang Che",
        "summary": "Code translation aims to translate the code from its source language to the target language and is used in various software development scenarios. Recent developments in Large Language Models (LLMs) have showcased their capabilities in code translation, and parallel corpora play a crucial role in training models for code translation. Parallel corpora can be categorized into program-alignment (PA) and snippet-alignment (SA) data. Although PA data has complete context and is suitable for semantic alignment learning, it may not provide adequate fine-grained training signals due to its extended length, while the brevity of SA data enables more fine-grained alignment learning. Due to limited parallel corpora, researchers explore several augmentation methods for code translation. Previous studies mainly focus on augmenting PA data. In this paper, we propose a data augmentation method that leverages LLMs to generate SA data automatically. To fully leverage both PA data and SA data, we explore a simple yet effective two-stage training strategy, which consistently enhances model performance compared to fine-tuning solely on PA data. Experiments on TransCoder-test demonstrate that our augmented SA data combined with the two-stage training approach yields consistent improvements over the baseline, achieving a maximum gain of 3.78% on pass@k.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.485975"
    },
    {
        "index": "#134",
        "title": "VaultGemma: A Differentially Private Gemma Model",
        "link": "/arxiv/2510.15001",
        "arxiv_id": "2510.15001",
        "authors": "Amer Sinha, Thomas Mesnard, Ryan McKenna, Daogao Liu, Christopher A. Choquette-Choo, Yangsibo Huang, Da Yu, George Kaissis, Zachary Charles, Ruibo Liu, Lynn Chua, Pritish Kamath, Pasin Manurangsi, Steve He, Chiyuan Zhang, Badih Ghazi, Borja De Balle Pigem, Prem Eruvbetine, Tris Warkentin, Armand Joulin, Ravi KumarAmer Sinha, Thomas Mesnard, Ryan McKenna, Daogao Liu, Christopher A. Choquette-Choo, Yangsibo Huang, Da Yu, George Kaissis, Zachary Charles, Ruibo Liu, Lynn Chua, Pritish Kamath, Pasin Manurangsi, Steve He, Chiyuan Zhang, Badih Ghazi, Borja De Balle Pigem, Prem Eruvbetine, Tris Warkentin, Armand Joulin, Ravi Kumar",
        "summary": "We introduce VaultGemma 1B, a 1 billion parameter model within the Gemma family, fully trained with differential privacy. Pretrained on the identical data mixture used for the Gemma 2 series, VaultGemma 1B represents a significant step forward in privacy-preserving large language models. We openly release this model to the community",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-10-15",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.486543"
    },
    {
        "index": "#136",
        "title": "PC-UNet: An Enforcing Poisson Statistics U-Net for Positron Emission Tomography Denoising",
        "link": "/arxiv/2510.14995",
        "arxiv_id": "2510.14995",
        "authors": "Yang Shi, Jingchao Wang, Liangsi Lu, Mingxuan Huang, Ruixin He, Yifeng Xie, Hanqian Liu, Minzhe Guo, Yangyang Liang, Weipeng Zhang, Zimeng Li, Xuhang Chen",
        "summary": "Positron Emission Tomography (PET) is crucial in medicine, but its clinical use is limited due to high signal-to-noise ratio doses increasing radiation exposure. Lowering doses increases Poisson noise, which current denoising methods fail to handle, causing distortions and artifacts. We propose a Poisson Consistent U-Net (PC-UNet) model with a new Poisson Variance and Mean Consistency Loss (PVMC-Loss) that incorporates physical data to improve image fidelity. PVMC-Loss is statistically unbiased in variance and gradient adaptation, acting as a Generalized Method of Moments implementation, offering robustness to minor data mismatches. Tests on PET datasets show PC-UNet improves physical consistency and image fidelity, proving its ability to integrate physical information effectively.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-10",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.487139"
    },
    {
        "index": "#137",
        "title": "GAZE:Governance-Aware pre-annotation for Zero-shot World Model Environments",
        "link": "/arxiv/2510.14992",
        "arxiv_id": "2510.14992",
        "authors": "Leela Krishna, Mengyang Zhao, Saicharithreddy Pasula, Harshit Rajgarhia, Abhishek Mukherji",
        "summary": "Training robust world models requires large-scale, precisely labeled multimodal datasets, a process historically bottlenecked by slow and expensive manual annotation. We present a production-tested GAZE pipeline that automates the conversion of raw, long-form video into rich, task-ready supervision for world-model training. Our system (i) normalizes proprietary 360-degree formats into standard views and shards them for parallel processing; (ii) applies a suite of AI models (scene understanding, object tracking, audio transcription, PII/NSFW/minor detection) for dense, multimodal pre-annotation; and (iii) consolidates signals into a structured output specification for rapid human validation. The GAZE workflow demonstrably yields efficiency gains (~19 minutes saved per review hour) and reduces human review volume by >80% through conservative auto-skipping of low-salience segments. By increasing label density and consistency while integrating privacy safeguards and chain-of-custody metadata, our method generates high-fidelity, privacy-aware datasets directly consumable for learning cross-modal dynamics and action-conditioned prediction. We detail our orchestration, model choices, and data dictionary to provide a scalable blueprint for generating high-quality world model training data without sacrificing throughput or governance.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.487469"
    },
    {
        "index": "#138",
        "title": "The Role of Federated Learning in Improving Financial Security: A Survey",
        "link": "/arxiv/2510.14991",
        "arxiv_id": "2510.14991",
        "authors": "Cade Houston Kennedy, Amr Hilal, Morteza Momeni",
        "summary": "With the growth of digital financial systems, robust security and privacy have become a concern for financial institutions. Even though traditional machine learning models have shown to be effective in fraud detections, they often compromise user data by requiring centralized access to sensitive information. In IoT-enabled financial endpoints such as ATMs and POS Systems that regularly produce sensitive data that is sent over the network. Federated Learning (FL) offers a privacy-preserving, decentralized model training across institutions without sharing raw data. FL enables cross-silo collaboration among banks while also using cross-device learning on IoT endpoints. This survey explores the role of FL in enhancing financial security and introduces a novel classification of its applications based on regulatory and compliance exposure levels ranging from low-exposure tasks such as collaborative portfolio optimization to high-exposure tasks like real-time fraud detection. Unlike prior surveys, this work reviews FL's practical use within financial systems, discussing its regulatory compliance and recent successes in fraud prevention and blockchain-integrated frameworks. However, FL deployment in finance is not without challenges. Data heterogeneity, adversarial attacks, and regulatory compliance make implementation far from easy. This survey reviews current defense mechanisms and discusses future directions, including blockchain integration, differential privacy, secure multi-party computation, and quantum-secure frameworks. Ultimately, this work aims to be a resource for researchers exploring FL's potential to advance secure, privacy-compliant financial systems.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.487763"
    },
    {
        "index": "#140",
        "title": "RegimeFolio: A Regime Aware ML System for Sectoral Portfolio Optimization in Dynamic Markets",
        "link": "/arxiv/2510.14986",
        "arxiv_id": "2510.14986",
        "authors": "Yiyao Zhang, Diksha Goel, Hussain Ahmad, Claudia Szabo",
        "summary": "Financial markets are inherently non-stationary, with shifting volatility regimes that alter asset co-movements and return distributions. Standard portfolio optimization methods, typically built on stationarity or regime-agnostic assumptions, struggle to adapt to such changes. To address these challenges, we propose RegimeFolio, a novel regime-aware and sector-specialized framework that, unlike existing regime-agnostic models such as DeepVol and DRL optimizers, integrates explicit volatility regime segmentation with sector-specific ensemble forecasting and adaptive mean-variance allocation. This modular architecture ensures forecasts and portfolio decisions remain aligned with current market conditions, enhancing robustness and interpretability in dynamic markets. RegimeFolio combines three components: (i) an interpretable VIX-based classifier for market regime detection; (ii) regime and sector-specific ensemble learners (Random Forest, Gradient Boosting) to capture conditional return structures; and (iii) a dynamic mean-variance optimizer with shrinkage-regularized covariance estimates for regime-aware allocation. We evaluate RegimeFolio on 34 large cap U.S. equities from 2020 to 2024. The framework achieves a cumulative return of 137 percent, a Sharpe ratio of 1.17, a 12 percent lower maximum drawdown, and a 15 to 20 percent improvement in forecast accuracy compared to conventional and advanced machine learning benchmarks. These results show that explicitly modeling volatility regimes in predictive learning and portfolio allocation enhances robustness and leads to more dependable decision-making in real markets.",
        "subjects": "Portfolio Management, Artificial Intelligence",
        "date": "2025-09-14",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.488338"
    },
    {
        "index": "#141",
        "title": "DeepAries: Adaptive Rebalancing Interval Selection for Enhanced Portfolio Selection",
        "link": "/arxiv/2510.14985",
        "arxiv_id": "2510.14985",
        "authors": "Jinkyu Kim, Hyunjung Yi, Mogan Gim, Donghee Choi, Jaewoo Kang",
        "summary": "We propose DeepAries , a novel deep reinforcement learning framework for dynamic portfolio management that jointly optimizes the timing and allocation of rebalancing decisions. Unlike prior reinforcement learning methods that employ fixed rebalancing intervals regardless of market conditions, DeepAries adaptively selects optimal rebalancing intervals along with portfolio weights to reduce unnecessary transaction costs and maximize risk-adjusted returns. Our framework integrates a Transformer-based state encoder, which effectively captures complex long-term market dependencies, with Proximal Policy Optimization (PPO) to generate simultaneous discrete (rebalancing intervals) and continuous (asset allocations) actions. Extensive experiments on multiple real-world financial markets demonstrate that DeepAries significantly outperforms traditional fixed-frequency and full-rebalancing strategies in terms of risk-adjusted returns, transaction costs, and drawdowns. Additionally, we provide a live demo of DeepAries at https://deep-aries.github.io/, along with the source code and dataset at https://github.com/dmis-lab/DeepAries, illustrating DeepAries' capability to produce interpretable rebalancing and allocation decisions aligned with shifting market regimes. Overall, DeepAries introduces an innovative paradigm for adaptive and practical portfolio management by integrating both timing and allocation into a unified decision-making process.",
        "subjects": "Portfolio Management, Artificial Intelligence, Computational Engineering, Finance, and Science",
        "date": "2025-09-11",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.488624"
    },
    {
        "index": "#142",
        "title": "Design and Analysis of Parallel Artificial Protozoa Optimizer (P-APO) using CUDA Architecture",
        "link": "/arxiv/2510.14982",
        "arxiv_id": "2510.14982",
        "authors": "Henish Soliya, Anugrah Jain",
        "summary": "Metaheuristic algorithms are widely used for solving complex problems due to their ability to provide near-optimal solutions. But the execution time of these algorithms increases with the problem size and solution space. And, to get more promising results, we have to execute these algorithms for a large number of iterations, requiring a large amount of time and this is one of the main issues found with these algorithms. To handle the same, researchers are now-adays working on design and development of parallel versions of state of the art metaheuristic optimization algorithms. We, in this paper, present a parallel implementation of state of the art Artificial Protozoa Optimizer using NVIDIA CUDA framework to leverage GPU acceleration. Our implementation optimizes the state of the art Artificial Protozoa Optimizer (APO) to achieve high performance. We implement both the existing sequential version and the proposed parallel version of Artificial Protozoa Optimizer in this paper. The experimental results calculated over benchmarks functions of CEC2022 demonstrate a significant performance gain i.e. up to 6.7 times speed up achieved in case of proposed parallel version. We also use two real world applications (1) Tension/Compression Spring Design in engineering optimization and (2) Image Thresholding using otsu method for testing the performance of proposed implementation in handling real tasks.",
        "subjects": "Neural and Evolutionary Computing, Artificial Intelligence, Emerging Technologies",
        "date": "2025-08-14",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.488885"
    },
    {
        "index": "#143",
        "title": "Reinforcement Learning with Stochastic Reward Machines",
        "link": "/arxiv/2510.14837",
        "arxiv_id": "2510.14837",
        "authors": "Jan Corazza, Ivan Gavran, Daniel Neider",
        "summary": "Reward machines are an established tool for dealing with reinforcement learning problems in which rewards are sparse and depend on complex sequences of actions. However, existing algorithms for learning reward machines assume an overly idealized setting where rewards have to be free of noise. To overcome this practical limitation, we introduce a novel type of reward machines, called stochastic reward machines, and an algorithm for learning them. Our algorithm, based on constraint solving, learns minimal stochastic reward machines from the explorations of a reinforcement learning agent. This algorithm can easily be paired with existing reinforcement learning algorithms for reward machines and guarantees to converge to an optimal policy in the limit. We demonstrate the effectiveness of our algorithm in two case studies and show that it outperforms both existing methods and a naive approach for handling noisy reward functions.",
        "subjects": "Machine Learning",
        "date": "2025-10-16",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.489138"
    },
    {
        "index": "#145",
        "title": "PulseCheck457: A Diagnostic Benchmark for Comprehensive Spatial Reasoning of Large Multimodal Models",
        "link": "/arxiv/2502.08636",
        "arxiv_id": "2502.08636",
        "authors": "Xingrui Wang, Wufei Ma, Tiezheng Zhang, Celso M de Melo, Jieneng Chen, Alan Yuille",
        "summary": "Although large multimodal models (LMMs) have demonstrated remarkable capabilities in visual scene interpretation and reasoning, their capacity for complex and precise 3-dimensional spatial reasoning remains uncertain. Existing benchmarks focus predominantly on 2D spatial understanding and lack a framework to comprehensively evaluate 6D spatial reasoning across varying complexities. To address this limitation, we present PulseCheck457, a scalable and unbiased synthetic dataset designed with 4 key capability for spatial reasoning: multi-object recognition, 2D location, 3D location, and 3D orientation. We develop a cascading evaluation structure, constructing 7 question types across 5 difficulty levels that range from basic single object recognition to our new proposed complex 6D spatial reasoning tasks. We evaluated various large multimodal models (LMMs) on PulseCheck457, observing a general decline in performance as task complexity increases, particularly in 3D reasoning and 6D spatial tasks. To quantify these challenges, we introduce the Relative Performance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoning capabilities. Leveraging the unbiased attribute design of our dataset, we also uncover prediction biases across different attributes, with similar patterns observed in real-world image settings.",
        "subjects": "Computer Vision and Pattern Recognition",
        "date": "2025-02-12",
        "category": "cs.AI",
        "crawl_time": "2025-10-20T11:00:05.489669"
    }
]