[
    {
        "index": "#1",
        "title": "R3R: Decentralized Multi-Agent Collision Avoidance with Infinite-Horizon Safety",
        "link": "/arxiv/2510.06436",
        "arxiv_id": "2510.06436",
        "authors": "Thomas Marshall Vielmetti, Devansh R. Agrawal, Dimitra Panagou",
        "summary": "Existing decentralized methods for multi-agent motion planning lack formal, infinite-horizon safety guarantees, especially for communication-constrained systems. We present R3R, to our knowledge the first decentralized and asynchronous framework for multi-agent motion planning under distance-based communication constraints with infinite-horizon safety guarantees for systems of nonlinear agents. R3R's novelty lies in combining our gatekeeper safety framework with a geometric constraint called R-Boundedness, which together establish a formal link between an agent's communication radius and its ability to plan safely. We constrain trajectories to within a fixed planning radius that is a function of the agent's communication radius, which enables trajectories to be shown provably safe for all time, using only local information. Our algorithm is fully asynchronous, and ensures the forward invariance of these guarantees even in time-varying networks where agents asynchronously join, leave, and replan. We validate our approach in simulations of up to 128 Dubins vehicles, demonstrating 100% safety in dense, obstacle rich scenarios. Our results demonstrate that R3R's performance scales with agent density rather than problem size, providing a practical solution for scalable and provably safe multi-agent systems.",
        "subjects": "Multiagent Systems",
        "date": "2025-10-07",
        "category": "cs.MA",
        "crawl_time": "2025-10-09T19:59:12.659563"
    },
    {
        "index": "#2",
        "title": "Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences",
        "link": "/arxiv/2510.07276",
        "arxiv_id": "2510.07276",
        "authors": "Pulkit Rustagi, Kyle Hollins Wray, Sandhya Saisubramanian",
        "summary": "Many real-world scenarios require multiple agents to coordinate in shared environments, while balancing trade-offs between multiple, potentially competing objectives. Current multi-objective multi-agent path finding (MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto frontiers. They do not explicitly optimize for user-defined preferences, even when the preferences are available, and scale poorly with the number of objectives. We propose a lexicographic framework for modeling MO-MAPF, along with an algorithm \\textit{Lexicographic Conflict-Based Search} (LCBS) that directly computes a single solution aligned with a lexicographic preference over objectives. LCBS integrates a priority-aware low-level $A^*$ search with conflict-based search, avoiding Pareto frontier construction and enabling efficient planning guided by preference over objectives. We provide insights into optimality and scalability, and empirically demonstrate that LCBS computes optimal solutions while scaling to instances with up to ten objectives -- far beyond the limits of existing MO-MAPF methods. Evaluations on standard and randomized MAPF benchmarks show consistently higher success rates against state-of-the-art baselines, especially with increasing number of objectives.",
        "subjects": "Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-08",
        "category": "cs.MA",
        "crawl_time": "2025-10-09T19:59:12.659882"
    },
    {
        "index": "#3",
        "title": "A Multi-Agent Framework for Stateful Inference-Time Search",
        "link": "/arxiv/2510.07147",
        "arxiv_id": "2510.07147",
        "authors": "Arshika Lalan, Rajat Ghosh, Aditya Kolsur, Debojyoti Dutta",
        "summary": "Recent work explores agentic inference-time techniques to perform structured, multi-step reasoning. However, stateless inference often struggles on multi-step tasks due to the absence of persistent state. Moreover, task-specific fine-tuning or instruction-tuning often achieve surface-level code generation but remain brittle on tasks requiring deeper reasoning and long-horizon dependencies. To address these limitations, we propose stateful multi-agent evolutionary search, a training-free framework that departs from prior stateless approaches by combining (i) persistent inference-time state, (ii) adversarial mutation, and (iii) evolutionary preservation. We demonstrate its effectiveness in automated unit test generation through the generation of edge cases. We generate robust edge cases using an evolutionary search process, where specialized agents sequentially propose, mutate, and score candidates. A controller maintains persistent state across generations, while evolutionary preservation ensures diversity and exploration across all possible cases. This yields a generalist agent capable of discovering robust, high-coverage edge cases across unseen codebases. Experiments show our stateful multi-agent inference framework achieves substantial gains in coverage over stateless single-step baselines, evaluated on prevalent unit-testing benchmarks such as HumanEval and TestGenEvalMini and using three diverse LLM families - Llama, Gemma, and GPT. These results indicate that combining persistent inference-time state with evolutionary search materially improves unit-test generation.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language, Multiagent Systems, Software Engineering",
        "date": "2025-10-08",
        "category": "cs.MA",
        "crawl_time": "2025-10-09T19:59:12.660182"
    },
    {
        "index": "#4",
        "title": "FURINA: A Fully Customizable Role-Playing Benchmark via Scalable Multi-Agent Collaboration Pipeline",
        "link": "/arxiv/2510.06800",
        "arxiv_id": "2510.06800",
        "authors": "Haotian Wu, Shufan Jiang, Chios Chen, Yiyang Feng, Hehai Lin, Heqing Zou, Yao Shu, Yanran Li, Chengwei Qin",
        "summary": "As large language models (LLMs) advance in role-playing (RP) tasks, existing benchmarks quickly become obsolete due to their narrow scope, outdated interaction paradigms, and limited adaptability across diverse application scenarios. To address this gap, we introduce FURINA-Builder, a novel multi-agent collaboration pipeline that automatically constructs fully customizable RP benchmarks at any scale. It enables evaluation of arbitrary characters across diverse scenarios and prompt formats, as the first benchmark builder in RP area for adaptable assessment. FURINA-Builder simulates dialogues between a test character and other characters drawn from a well-constructed character-scene pool, while an LLM judge selects fine-grained evaluation dimensions and adjusts the test character's responses into final test utterances. Using this pipeline, we build FURINA-Bench, a new comprehensive role-playing benchmark featuring both established and synthesized test characters, each assessed with dimension-specific evaluation criteria. Human evaluation and preliminary separability analysis justify our pipeline and benchmark design. We conduct extensive evaluations of cutting-edge LLMs and find that o3 and DeepSeek-R1 achieve the best performance on English and Chinese RP tasks, respectively. Across all models, established characters consistently outperform synthesized ones, with reasoning capabilities further amplifying this disparity. Interestingly, we observe that model scale does not monotonically reduce hallucinations. More critically, for reasoning LLMs, we uncover a novel trade-off: reasoning improves RP performance but simultaneously increases RP hallucinations. This trade-off extends to a broader Pareto frontier between RP performance and reliability for all LLMs. These findings demonstrate the effectiveness of FURINA-Builder and the challenge posed by FURINA-Bench.",
        "subjects": "Computation and Language, Artificial Intelligence, Human-Computer Interaction, Multiagent Systems",
        "date": "2025-10-08",
        "category": "cs.MA",
        "crawl_time": "2025-10-09T19:59:12.660498"
    },
    {
        "index": "#5",
        "title": "Three-dimensional Integrated Guidance and Control for Leader-Follower Flexible Formation of Fixed Wing UAVs",
        "link": "/arxiv/2510.06394",
        "arxiv_id": "2510.06394",
        "authors": "Praveen Kumar Ranjan, Abhinav Sinha, Yongcan Cao",
        "summary": "This paper presents a nonlinear integrated guidance and control (IGC) approach for flexible leader-follower formation flight of fixed-wing unmanned aerial vehicles (UAVs) while accounting for high-fidelity aerodynamics and thrust dynamics. Unlike conventional leader-follower schemes that fix the follower's position relative to the leader, the follower is steered to maintain range and bearing angles (which is the angle between its velocity vector and its line-of-sight (LOS) with respect to the leader) arbitrarily close to the prescribed values, enabling the follower to maintain formation on a hemispherical region behind the leader. The proposed IGC framework directly maps leader-follower relative range dynamics to throttle commands, and the follower's velocity orientation relative to the LOS to aerodynamic control surface deflections. This enables synergism between guidance and control subsystems. The control design uses a dynamic surface control-based backstepping approach to achieve convergence to the desired formation set, where Lyapunov barrier functions are incorporated to ensure the follower's bearing angle is constrained within specified bounds. Rigorous stability analysis guarantees uniform ultimate boundedness of all error states and strict constraint satisfaction in the presence of aerodynamic nonlinearities. The proposed flexible formation scheme allows the follower to have an orientation mismatch relative to the leader to execute anticipatory reconfiguration by transitioning between the relative positions in the admissible formation set when the leader aggressively maneuvers. The proposed IGC law relies only on relative information and onboard sensors without the information about the leader's maneuver, making it suitable for GPS-denied or non-cooperative scenarios. Finally, we present simulation results to vindicate the effectiveness and robustness of our approach.",
        "subjects": "Systems and Control, Multiagent Systems, Robotics, Dynamical Systems",
        "date": "2025-10-07",
        "category": "cs.MA",
        "crawl_time": "2025-10-09T19:59:12.660771"
    },
    {
        "index": "#6",
        "title": "Flexible Swarm Learning May Outpace Foundation Models in Essential Tasks",
        "link": "/arxiv/2510.06349",
        "arxiv_id": "2510.06349",
        "authors": "Moein E. Samadi, Andreas Schuppert",
        "summary": "Foundation models have rapidly advanced AI, raising the question of whether their decisions will ultimately surpass human strategies in real-world domains. The exponential, and possibly super-exponential, pace of AI development makes such analysis elusive. Nevertheless, many application areas that matter for daily life and society show only modest gains so far; a prominent case is diagnosing and treating dynamically evolving disease in intensive care. The common challenge is adapting complex systems to dynamic environments. Effective strategies must optimize outcomes in systems composed of strongly interacting functions while avoiding shared side effects; this requires reliable, self-adaptive modeling. These tasks align with building digital twins of highly complex systems whose mechanisms are not fully or quantitatively understood. It is therefore essential to develop methods for self-adapting AI models with minimal data and limited mechanistic knowledge. As this challenge extends beyond medicine, AI should demonstrate clear superiority in these settings before assuming broader decision-making roles. We identify the curse of dimensionality as a fundamental barrier to efficient self-adaptation and argue that monolithic foundation models face conceptual limits in overcoming it. As an alternative, we propose a decentralized architecture of interacting small agent networks (SANs). We focus on agents representing the specialized substructure of the system, where each agent covers only a subset of the full system functions. Drawing on mathematical results on the learning behavior of SANs and evidence from existing applications, we argue that swarm-learning in diverse swarms can enable self-adaptive SANs to deliver superior decision-making in dynamic environments compared with monolithic foundation models, though at the cost of reduced reproducibility in detail.",
        "subjects": "Machine Learning, Artificial Intelligence, Multiagent Systems",
        "date": "2025-10-07",
        "category": "cs.MA",
        "crawl_time": "2025-10-09T19:59:12.661034"
    },
    {
        "index": "#1",
        "title": "Artificial Hippocampus Networks for Efficient Long-Context Modeling",
        "link": "/arxiv/2510.07318",
        "arxiv_id": "2510.07318",
        "authors": "Yunhao Fang, Weihao Yu, Shu Zhong, Qinghao Ye, Xuehan Xiong, Lai Wei",
        "summary": "Long-sequence modeling faces a fundamental trade-off between the efficiency of compressive fixed-size memory in RNN-like models and the fidelity of lossless growing memory in attention-based Transformers. Inspired by the Multi-Store Model in cognitive science, we introduce a memory framework of artificial neural networks. Our method maintains a sliding window of the Transformer's KV cache as lossless short-term memory, while a learnable module termed Artificial Hippocampus Network (AHN) recurrently compresses out-of-window information into a fixed-size compact long-term memory. To validate this framework, we instantiate AHNs using modern RNN-like architectures, including Mamba2, DeltaNet, and Gated DeltaNet. Extensive experiments on long-context benchmarks LV-Eval and InfiniteBench demonstrate that AHN-augmented models consistently outperform sliding window baselines and achieve performance comparable or even superior to full-attention models, while substantially reducing computational and memory requirements. For instance, augmenting the Qwen2.5-3B-Instruct with AHNs reduces inference FLOPs by 40.5% and memory cache by 74.0%, while improving its average score on LV-Eval (128k sequence length) from 4.41 to 5.88. Code is available at: https://github.com/ByteDance-Seed/AHN.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.054678"
    },
    {
        "index": "#2",
        "title": "Vibe Checker: Aligning Code Evaluation with Human Preference",
        "link": "/arxiv/2510.07315",
        "arxiv_id": "2510.07315",
        "authors": "Ming Zhong, Xiang Zhou, Ting-Yun Chang, Qingze Wang, Nan Xu, Xiance Si, Dan Garrette, Shyam Upadhyay, Jeremiah Liu, Jiawei Han, Benoit Schillings, Jiao Sun",
        "summary": "Large Language Models (LLMs) have catalyzed vibe coding, where users leverage LLMs to generate and iteratively refine code through natural language interactions until it passes their vibe check. Vibe check is tied to real-world human preference and goes beyond functionality: the solution should feel right, read cleanly, preserve intent, and remain correct. However, current code evaluation remains anchored to pass@k and captures only functional correctness, overlooking the non-functional instructions that users routinely apply. In this paper, we hypothesize that instruction following is the missing piece underlying vibe check that represents human preference in coding besides functional correctness. To quantify models' code instruction following capabilities with measurable signals, we present VeriCode, a taxonomy of 30 verifiable code instructions together with corresponding deterministic verifiers. We use the taxonomy to augment established evaluation suites, resulting in Vibe Checker, a testbed to assess both code instruction following and functional correctness. Upon evaluating 31 leading LLMs, we show that even the strongest models struggle to comply with multiple instructions and exhibit clear functional regression. Most importantly, a composite score of functional correctness and instruction following correlates the best with human preference, with the latter emerging as the primary differentiator on real-world programming tasks. Our work identifies core factors of the vibe check, providing a concrete path for benchmarking and developing models that better align with user preferences in coding.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Software Engineering",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.055572"
    },
    {
        "index": "#3",
        "title": "Agent Bain vs. Agent McKinsey: A New Text-to-SQL Benchmark for the Business Domain",
        "link": "/arxiv/2510.07309",
        "arxiv_id": "2510.07309",
        "authors": "Yue Li, Ran Tao, Derek Hommel, Yusuf Denizay Dönder, Sungyong Chang, David Mimno, Unso Eun Seo Jo",
        "summary": "In the business domain, where data-driven decision making is crucial, text-to-SQL is fundamental for easy natural language access to structured data. While recent LLMs have achieved strong performance in code generation, existing text-to-SQL benchmarks remain focused on factual retrieval of past records. We introduce CORGI, a new benchmark specifically designed for real-world business contexts. CORGI is composed of synthetic databases inspired by enterprises such as Doordash, Airbnb, and Lululemon. It provides questions across four increasingly complex categories of business queries: descriptive, explanatory, predictive, and recommendational. This challenge calls for causal reasoning, temporal forecasting, and strategic recommendation, reflecting multi-level and multi-step agentic intelligence. We find that LLM performance drops on high-level questions, struggling to make accurate predictions and offer actionable plans. Based on execution success rate, the CORGI benchmark is about 21\\% more difficult than the BIRD benchmark. This highlights the gap between popular LLMs and the need for real-world business intelligence. We release a public dataset and evaluation framework, and a website for public submissions.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.056320"
    },
    {
        "index": "#4",
        "title": "Think Natively: Unlocking Multilingual Reasoning with Consistency-Enhanced Reinforcement Learning",
        "link": "/arxiv/2510.07300",
        "arxiv_id": "2510.07300",
        "authors": "Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Kaiyu Huang, Yufeng Chen, Jinan Xu, Jie Zhou",
        "summary": "Large Reasoning Models (LRMs) have achieved remarkable performance on complex reasoning tasks by adopting the \"think-then-answer\" paradigm, which enhances both accuracy and interpretability. However, current LRMs exhibit two critical limitations when processing non-English languages: (1) They often struggle to maintain input-output language consistency; (2) They generally perform poorly with wrong reasoning paths and lower answer accuracy compared to English. These limitations significantly degrade the user experience for non-English speakers and hinder the global deployment of LRMs. To address these limitations, we propose M-Thinker, which is trained by the GRPO algorithm that involves a Language Consistency (LC) reward and a novel Cross-lingual Thinking Alignment (CTA) reward. Specifically, the LC reward defines a strict constraint on the language consistency between the input, thought, and answer. Besides, the CTA reward compares the model's non-English reasoning paths with its English reasoning path to transfer its own reasoning capability from English to non-English languages. Through an iterative RL procedure, our M-Thinker-1.5B/7B models not only achieve nearly 100% language consistency and superior performance on two multilingual benchmarks (MMATH and PolyMath), but also exhibit excellent generalization on out-of-domain languages.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.056931"
    },
    {
        "index": "#5",
        "title": "On the Convergence of Moral Self-Correction in Large Language Models",
        "link": "/arxiv/2510.07290",
        "arxiv_id": "2510.07290",
        "authors": "Guangliang Liu, Haitao Mao, Bochuan Cao, Zhiyu Xue, Xitong Zhang, Rongrong Wang, Kristen Marie Johnson",
        "summary": "Large Language Models (LLMs) are able to improve their responses when instructed to do so, a capability known as self-correction. When instructions provide only a general and abstract goal without specific details about potential issues in the response, LLMs must rely on their internal knowledge to improve response quality, a process referred to as intrinsic self-correction. The empirical success of intrinsic self-correction is evident in various applications, but how and why it is effective remains unknown. Focusing on moral self-correction in LLMs, we reveal a key characteristic of intrinsic self-correction: performance convergence through multi-round interactions; and provide a mechanistic analysis of this convergence behavior. Based on our experimental results and analysis, we uncover the underlying mechanism of convergence: consistently injected self-correction instructions activate moral concepts that reduce model uncertainty, leading to converged performance as the activated moral concepts stabilize over successive rounds. This paper demonstrates the strong potential of moral self-correction by showing that it exhibits a desirable property of converged performance.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.057416"
    },
    {
        "index": "#6",
        "title": "Online Rubrics Elicitation from Pairwise Comparisons",
        "link": "/arxiv/2510.07284",
        "arxiv_id": "2510.07284",
        "authors": "MohammadHossein Rezaei, Robert Vacareanu, Zihao Wang, Clinton Wang, Yunzhong He, Afra Feyza Akyürek",
        "summary": "Rubrics provide a flexible way to train LLMs on open-ended long-form answers where verifiable rewards are not applicable and human preferences provide coarse signals. Prior work shows that reinforcement learning with rubric-based rewards leads to consistent gains in LLM post-training. Most existing approaches rely on rubrics that remain static over the course of training. Such static rubrics, however, are vulnerable to reward-hacking type behaviors and fail to capture emergent desiderata that arise during training. We introduce Online Rubrics Elicitation (OnlineRubrics), a method that dynamically curates evaluation criteria in an online manner through pairwise comparisons of responses from current and reference policies. This online process enables continuous identification and mitigation of errors as training proceeds. Empirically, this approach yields consistent improvements of up to 8% over training exclusively with static rubrics across AlpacaEval, GPQA, ArenaHard as well as the validation sets of expert questions and rubrics. We qualitatively analyze the elicited criteria and identify prominent themes such as transparency, practicality, organization, and reasoning.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.057921"
    },
    {
        "index": "#7",
        "title": "Don't Adapt Small Language Models for Tools; Adapt Tool Schemas to the Models",
        "link": "/arxiv/2510.07248",
        "arxiv_id": "2510.07248",
        "authors": "Jonggeun Lee, Woojung Song, Jongwook Han, Haesung Pyun, Yohan Jo",
        "summary": "Small language models (SLMs) offer significant computational advantages for tool-augmented AI systems, yet they struggle with tool-use tasks, particularly in selecting appropriate tools and identifying correct parameters. A common failure mode is schema misalignment: models hallucinate plausible but non-existent tool names that reflect naming conventions internalized during pretraining but absent from the provided tool schema. Rather than forcing models to adapt to arbitrary schemas, we propose adapting schemas to align with models' pretrained knowledge. We introduce PA-Tool (Pretraining-Aligned Tool Schema Generation), a training-free method that leverages peakedness-a signal from contamination detection indicating pretraining familiarity-to automatically rename tool components. By generating multiple candidates and selecting those with highest output concentration across samples, PA-Tool identifies pretrain-aligned naming patterns. Experiments on MetaTool and RoTBench show improvements of up to 17% points, with schema misalignment errors reduced by 80%. PA-Tool enables small models to approach state-of-the-art performance while maintaining computational efficiency for adaptation to new tools without retraining. Our work demonstrates that schema-level interventions can unlock the tool-use potential of resource-efficient models by adapting schemas to models rather than models to schemas.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.058370"
    },
    {
        "index": "#8",
        "title": "LeMAJ (Legal LLM-as-a-Judge): Bridging Legal Reasoning and LLM Evaluation",
        "link": "/arxiv/2510.07243",
        "arxiv_id": "2510.07243",
        "authors": "Joseph Enguehard, Morgane Van Ermengem, Kate Atkinson, Sujeong Cha, Arijit Ghosh Chowdhury, Prashanth Kallur Ramaswamy, Jeremy Roghair, Hannah R Marlowe, Carina Suzana Negreanu, Kitty Boxall, Diana Mincu",
        "summary": "Evaluating large language model (LLM) outputs in the legal domain presents unique challenges due to the complex and nuanced nature of legal analysis. Current evaluation approaches either depend on reference data, which is costly to produce, or use standardized assessment methods, both of which have significant limitations for legal applications. Although LLM-as-a-Judge has emerged as a promising evaluation technique, its reliability and effectiveness in legal contexts depend heavily on evaluation processes unique to the legal industry and how trustworthy the evaluation appears to the human legal expert. This is where existing evaluation methods currently fail and exhibit considerable variability. This paper aims to close the gap: a) we break down lengthy responses into 'Legal Data Points' (LDPs), self-contained units of information, and introduce a novel, reference-free evaluation methodology that reflects how lawyers evaluate legal answers; b) we demonstrate that our method outperforms a variety of baselines on both our proprietary dataset and an open-source dataset (LegalBench); c) we show how our method correlates more closely with human expert evaluations and helps improve inter-annotator agreement; and finally d) we open source our Legal Data Points for a subset of LegalBench used in our experiments, allowing the research community to replicate our results and advance research in this vital area of LLM evaluation on legal question-answering.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.064023"
    },
    {
        "index": "#9",
        "title": "Hybrid Reinforcement: When Reward Is Sparse, It's Better to Be Dense",
        "link": "/arxiv/2510.07242",
        "arxiv_id": "2510.07242",
        "authors": "Leitian Tao, Ilia Kulikov, Swarnadeep Saha, Tianlu Wang, Jing Xu, Yixuan Li, Jason E Weston, Ping Yu",
        "summary": "Post-training for reasoning of large language models (LLMs) increasingly relies on verifiable rewards: deterministic checkers that provide 0-1 correctness signals. While reliable, such binary feedback is brittle--many tasks admit partially correct or alternative answers that verifiers under-credit, and the resulting all-or-nothing supervision limits learning. Reward models offer richer, continuous feedback, which can serve as a complementary supervisory signal to verifiers. We introduce HERO (Hybrid Ensemble Reward Optimization), a reinforcement learning framework that integrates verifier signals with reward-model scores in a structured way. HERO employs stratified normalization to bound reward-model scores within verifier-defined groups, preserving correctness while refining quality distinctions, and variance-aware weighting to emphasize challenging prompts where dense signals matter most. Across diverse mathematical reasoning benchmarks, HERO consistently outperforms RM-only and verifier-only baselines, with strong gains on both verifiable and hard-to-verify tasks. Our results show that hybrid reward design retains the stability of verifiers while leveraging the nuance of reward models to advance reasoning.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.064543"
    },
    {
        "index": "#10",
        "title": "Red-Bandit: Test-Time Adaptation for LLM Red-Teaming via Bandit-Guided LoRA Experts",
        "link": "/arxiv/2510.07239",
        "arxiv_id": "2510.07239",
        "authors": "Christos Ziakas, Nicholas Loo, Nishita Jain, Alessandra Russo",
        "summary": "Automated red-teaming has emerged as a scalable approach for auditing Large Language Models (LLMs) prior to deployment, yet existing approaches lack mechanisms to efficiently adapt to model-specific vulnerabilities at inference. We introduce Red-Bandit, a red-teaming framework that adapts online to identify and exploit model failure modes under distinct attack styles (e.g., manipulation, slang). Red-Bandit post-trains a set of parameter-efficient LoRA experts, each specialized for a particular attack style, using reinforcement learning that rewards the generation of unsafe prompts via a rule-based safety model. At inference, a multi-armed bandit policy dynamically selects among these attack-style experts based on the target model's response safety, balancing exploration and exploitation. Red-Bandit achieves state-of-the-art results on AdvBench under sufficient exploration (ASR@10), while producing more human-readable prompts (lower perplexity). Moreover, Red-Bandit's bandit policy serves as a diagnostic tool for uncovering model-specific vulnerabilities by indicating which attack styles most effectively elicit unsafe behaviors.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.064970"
    },
    {
        "index": "#11",
        "title": "When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation",
        "link": "/arxiv/2510.07238",
        "arxiv_id": "2510.07238",
        "authors": "Xunyi Jiang, Dingyi Chang, Julian McAuley, Xin Xu",
        "summary": "The rapid evolution of large language models (LLMs) and the real world has outpaced the static nature of widely used evaluation benchmarks, raising concerns about their reliability for evaluating LLM factuality. While substantial works continue to rely on the popular but old benchmarks, their temporal misalignment with real-world facts and modern LLMs, and their effects on LLM factuality evaluation remain underexplored. Therefore, in this work, we present a systematic investigation of this issue by examining five popular factuality benchmarks and eight LLMs released across different years. An up-to-date fact retrieval pipeline and three metrics are tailored to quantify benchmark aging and its impact on LLM factuality evaluation. Experimental results and analysis illustrate that a considerable portion of samples in the widely used factuality benchmarks are outdated, leading to unreliable assessments of LLM factuality. We hope our work can provide a testbed to assess the reliability of a benchmark for LLM factuality evaluation and inspire more research on the benchmark aging issue. Codes are available in https://github.com/JiangXunyi/BenchAge.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.065400"
    },
    {
        "index": "#12",
        "title": "LAD-RAG: Layout-aware Dynamic RAG for Visually-Rich Document Understanding",
        "link": "/arxiv/2510.07233",
        "arxiv_id": "2510.07233",
        "authors": "Zhivar Sourati, Zheng Wang, Marianne Menglin Liu, Yazhe Hu, Mengqing Guo, Sujeeth Bharadwaj, Kyu Han, Tao Sheng, Sujith Ravi, Morteza Dehghani, Dan Roth",
        "summary": "Question answering over visually rich documents (VRDs) requires reasoning not only over isolated content but also over documents' structural organization and cross-page dependencies. However, conventional retrieval-augmented generation (RAG) methods encode content in isolated chunks during ingestion, losing structural and cross-page dependencies, and retrieve a fixed number of pages at inference, regardless of the specific demands of the question or context. This often results in incomplete evidence retrieval and degraded answer quality for multi-page reasoning tasks. To address these limitations, we propose LAD-RAG, a novel Layout-Aware Dynamic RAG framework. During ingestion, LAD-RAG constructs a symbolic document graph that captures layout structure and cross-page dependencies, adding it alongside standard neural embeddings to yield a more holistic representation of the document. During inference, an LLM agent dynamically interacts with the neural and symbolic indices to adaptively retrieve the necessary evidence based on the query. Experiments on MMLongBench-Doc, LongDocURL, DUDE, and MP-DocVQA demonstrate that LAD-RAG improves retrieval, achieving over 90% perfect recall on average without any top-k tuning, and outperforming baseline retrievers by up to 20% in recall at comparable noise levels, yielding higher QA accuracy with minimal latency.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.065925"
    },
    {
        "index": "#13",
        "title": "Benchmarking LLM Causal Reasoning with Scientifically Validated Relationships",
        "link": "/arxiv/2510.07231",
        "arxiv_id": "2510.07231",
        "authors": "Donggyu Lee, Sungwon Park, Yerin Hwang, Hyunwoo Oh, Hyoshin Kim, Jungwon Kim, Meeyoung Cha, Sangyoon Park, Jihee Kim",
        "summary": "Causal reasoning is fundamental for Large Language Models (LLMs) to understand genuine cause-and-effect relationships beyond pattern matching. Existing benchmarks suffer from critical limitations such as reliance on synthetic data and narrow domain coverage. We introduce a novel benchmark constructed from casually identified relationships extracted from top-tier economics and finance journals, drawing on rigorous methodologies including instrumental variables, difference-in-differences, and regression discontinuity designs. Our benchmark comprises 40,379 evaluation items covering five task types across domains such as health, environment, technology, law, and culture. Experimental results on eight state-of-the-art LLMs reveal substantial limitations, with the best model achieving only 57.6\\% accuracy. Moreover, model scale does not consistently translate to superior performance, and even advanced reasoning models struggle with fundamental causal relationship identification. These findings underscore a critical gap between current LLM capabilities and demands of reliable causal reasoning in high-stakes applications.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.066436"
    },
    {
        "index": "#14",
        "title": "Customer-R1: Personalized Simulation of Human Behaviors via RL-based LLM Agent in Online Shopping",
        "link": "/arxiv/2510.07230",
        "arxiv_id": "2510.07230",
        "authors": "Ziyi Wang, Yuxuan Lu, Yimeng Zhang, Jing Huang, Dakuo Wang",
        "summary": "Simulating step-wise human behavior with Large Language Models (LLMs) has become an emerging research direction, enabling applications in various practical domains. While prior methods, including prompting, supervised fine-tuning (SFT), and reinforcement learning (RL), have shown promise in modeling step-wise behavior, they primarily learn a population-level policy without conditioning on a user's persona, yielding generic rather than personalized simulations. In this work, we pose a critical question: how can LLM agents better simulate personalized user behavior? We introduce Customer-R1, an RL-based method for personalized, step-wise user behavior simulation in online shopping environments. Our policy is conditioned on an explicit persona, and we optimize next-step rationale and action generation via action correctness reward signals. Experiments on the OPeRA dataset emonstrate that Customer-R1 not only significantly outperforms prompting and SFT-based baselines in next-action prediction tasks, but also better matches users' action distribution, indicating higher fidelity in personalized behavior simulation.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.066886"
    },
    {
        "index": "#15",
        "title": "Where to Begin: Efficient Pretraining via Subnetwork Selection and Distillation",
        "link": "/arxiv/2510.07227",
        "arxiv_id": "2510.07227",
        "authors": "Arjun Krishnakumar, Rhea Sanjay Sukthanker, Hannan Javed Mahadik, Gabriela Kadlecová, Vladyslav Moroshan, Timur Carstensen, Frank Hutter, Aaron Klein",
        "summary": "Small Language models (SLMs) offer an efficient and accessible alternative to Large Language Models (LLMs), delivering strong performance while using far fewer resources. We introduce a simple and effective framework for pretraining SLMs that brings together three complementary ideas. First, we identify structurally sparse sub-network initializations that consistently outperform randomly initialized models of similar size under the same compute budget. Second, we use evolutionary search to automatically discover high-quality sub-network initializations, providing better starting points for pretraining. Third, we apply knowledge distillation from larger teacher models to speed up training and improve generalization. Together, these components make SLM pretraining substantially more efficient: our best model, discovered using evolutionary search and initialized with LLM weights, matches the validation perplexity of a comparable Pythia SLM while requiring 9.2x fewer pretraining tokens. We release all code and models at https://github.com/whittle-org/whittle/, offering a practical and reproducible path toward cost-efficient small language model development at scale.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.067395"
    },
    {
        "index": "#16",
        "title": "How much speech data is necessary for ASR in African languages? An evaluation of data scaling in Kinyarwanda and Kikuyu",
        "link": "/arxiv/2510.07221",
        "arxiv_id": "2510.07221",
        "authors": "Benjamin Akera, Evelyn Nafula, Patrick Walukagga, Gilbert Yiga, John Quinn, Ernest Mwebaze",
        "summary": "The development of Automatic Speech Recognition (ASR) systems for low-resource African languages remains challenging due to limited transcribed speech data. While recent advances in large multilingual models like OpenAI's Whisper offer promising pathways for low-resource ASR development, critical questions persist regarding practical deployment requirements. This paper addresses two fundamental concerns for practitioners: determining the minimum data volumes needed for viable performance and characterizing the primary failure modes that emerge in production systems. We evaluate Whisper's performance through comprehensive experiments on two Bantu languages: systematic data scaling analysis on Kinyarwanda using training sets from 1 to 1,400 hours, and detailed error characterization on Kikuyu using 270 hours of training data. Our scaling experiments demonstrate that practical ASR performance (WER < 13\\%) becomes achievable with as little as 50 hours of training data, with substantial improvements continuing through 200 hours (WER < 10\\%). Complementing these volume-focused findings, our error analysis reveals that data quality issues, particularly noisy ground truth transcriptions, account for 38.6\\% of high-error cases, indicating that careful data curation is as critical as data volume for robust system performance. These results provide actionable benchmarks and deployment guidance for teams developing ASR systems across similar low-resource language contexts. We release accompanying and models see https://github.com/SunbirdAI/kinyarwanda-whisper-eval",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.067863"
    },
    {
        "index": "#17",
        "title": "Language Lives in Sparse Dimensions: Toward Interpretable and Efficient Multilingual Control for Large Language Models",
        "link": "/arxiv/2510.07213",
        "arxiv_id": "2510.07213",
        "authors": "Chengzhi Zhong, Fei Cheng, Qianying Liu, Yugo Murawaki, Chenhui Chu, Sadao Kurohashi",
        "summary": "Large language models exhibit strong multilingual capabilities despite limited exposure to non-English data. Prior studies show that English-centric large language models map multilingual content into English-aligned representations at intermediate layers and then project them back into target-language token spaces in the final layer. From this observation, we hypothesize that this cross-lingual transition is governed by a small and sparse set of dimensions, which occur at consistent indices across the intermediate to final layers. Building on this insight, we introduce a simple, training-free method to identify and manipulate these dimensions, requiring only as few as 50 sentences of either parallel or monolingual data. Experiments on a multilingual generation control task reveal the interpretability of these dimensions, demonstrating that the interventions in these dimensions can switch the output language while preserving semantic content, and that it surpasses the performance of prior neuron-based approaches at a substantially lower cost.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.068343"
    },
    {
        "index": "#18",
        "title": "Sunflower: A New Approach To Expanding Coverage of African Languages in Large Language Models",
        "link": "/arxiv/2510.07203",
        "arxiv_id": "2510.07203",
        "authors": "Benjamin Akera, Evelyn Nafula Ouma, Gilbert Yiga, Patrick Walukagga, Phionah Natukunda, Trevor Saaka, Solomon Nsumba, Lilian Teddy Nabukeera, Joel Muhanguzi, Imran Sekalala, Nimpamya Janat Namara, Engineer Bainomugisha, Ernest Mwebaze, John Quinn",
        "summary": "There are more than 2000 living languages in Africa, most of which have been bypassed by advances in language technology. Current leading LLMs exhibit strong performance on a number of the most common languages (e.g. Swahili or Yoruba), but prioritise support for the languages with the most speakers first, resulting in piecemeal ability across disparate languages. We contend that a regionally focussed approach is more efficient, and present a case study for Uganda, a country with high linguistic diversity. We describe the development of Sunflower 14B and 32B, a pair of models based on Qwen 3 with state of the art comprehension in the majority of all Ugandan languages. These models are open source and can be used to reduce language barriers in a number of important practical applications.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.068895"
    },
    {
        "index": "#19",
        "title": "Biasless Language Models Learn Unnaturally: How LLMs Fail to Distinguish the Possible from the Impossible",
        "link": "/arxiv/2510.07178",
        "arxiv_id": "2510.07178",
        "authors": "Imry Ziv, Nur Lan, Emmanuel Chemla, Roni Katzir",
        "summary": "Are large language models (LLMs) sensitive to the distinction between humanly possible languages and humanly impossible languages? This question is taken by many to bear on whether LLMs and humans share the same innate learning biases. Previous work has attempted to answer it in the positive by comparing LLM learning curves on existing language datasets and on \"impossible\" datasets derived from them via various perturbation functions. Using the same methodology, we examine this claim on a wider set of languages and impossible perturbations. We find that in most cases, GPT-2 learns each language and its impossible counterpart equally easily, in contrast to previous claims. We also apply a more lenient condition by testing whether GPT-2 provides any kind of separation between the whole set of natural languages and the whole set of impossible languages. By considering cross-linguistic variance in various metrics computed on the perplexity curves, we show that GPT-2 provides no systematic separation between the possible and the impossible. Taken together, these perspectives show that LLMs do not share the human innate biases that shape linguistic typology.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.079641"
    },
    {
        "index": "#20",
        "title": "CARPAS: Towards Content-Aware Refinement of Provided Aspects for Summarization in Large Language Models",
        "link": "/arxiv/2510.07177",
        "arxiv_id": "2510.07177",
        "authors": "Yong-En Tian, Yu-Chien Tang, An-Zi Yen, Wen-Chih Peng",
        "summary": "Aspect-based summarization has attracted significant attention for its ability to generate more fine-grained and user-aligned summaries. While most existing approaches assume a set of predefined aspects as input, real-world scenarios often present challenges where these given aspects may be incomplete, irrelevant, or entirely missing from the document. Users frequently expect systems to adaptively refine or filter the provided aspects based on the actual content. In this paper, we initiate this novel task setting, termed Content-Aware Refinement of Provided Aspects for Summarization (CARPAS), with the aim of dynamically adjusting the provided aspects based on the document context before summarizing. We construct three new datasets to facilitate our pilot experiments, and by using LLMs with four representative prompting strategies in this task, we find that LLMs tend to predict an overly comprehensive set of aspects, which often results in excessively long and misaligned summaries. Building on this observation, we propose a preliminary subtask to predict the number of relevant aspects, and demonstrate that the predicted number can serve as effective guidance for the LLMs, reducing the inference difficulty, and enabling them to focus on the most pertinent aspects. Our extensive experiments show that the proposed approach significantly improves performance across all datasets. Moreover, our deeper analyses uncover LLMs' compliance when the requested number of aspects differs from their own estimations, establishing a crucial insight for the deployment of LLMs in similar real-world applications.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.080101"
    },
    {
        "index": "#21",
        "title": "Quantifying Data Contamination in Psychometric Evaluations of LLMs",
        "link": "/arxiv/2510.07175",
        "arxiv_id": "2510.07175",
        "authors": "Jongwook Han, Woojung Song, Jonggeun Lee, Yohan Jo",
        "summary": "Recent studies apply psychometric questionnaires to Large Language Models (LLMs) to assess high-level psychological constructs such as values, personality, moral foundations, and dark traits. Although prior work has raised concerns about possible data contamination from psychometric inventories, which may threaten the reliability of such evaluations, there has been no systematic attempt to quantify the extent of this contamination. To address this gap, we propose a framework to systematically measure data contamination in psychometric evaluations of LLMs, evaluating three aspects: (1) item memorization, (2) evaluation memorization, and (3) target score matching. Applying this framework to 21 models from major families and four widely used psychometric inventories, we provide evidence that popular inventories such as the Big Five Inventory (BFI-44) and Portrait Values Questionnaire (PVQ-40) exhibit strong contamination, where models not only memorize items but can also adjust their responses to achieve specific target scores.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.080554"
    },
    {
        "index": "#22",
        "title": "NurseLLM: The First Specialized Language Model for Nursing",
        "link": "/arxiv/2510.07173",
        "arxiv_id": "2510.07173",
        "authors": "Md Tawkat Islam Khondaker, Julia Harrington, Shady Shehata",
        "summary": "Recent advancements in large language models (LLMs) have significantly transformed medical systems. However, their potential within specialized domains such as nursing remains largely underexplored. In this work, we introduce NurseLLM, the first nursing-specialized LLM tailored for multiple choice question-answering (MCQ) tasks. We develop a multi-stage data generation pipeline to build the first large scale nursing MCQ dataset to train LLMs on a broad spectrum of nursing topics. We further introduce multiple nursing benchmarks to enable rigorous evaluation. Our extensive experiments demonstrate that NurseLLM outperforms SoTA general-purpose and medical-specialized LLMs of comparable size on different benchmarks, underscoring the importance of a specialized LLM for the nursing domain. Finally, we explore the role of reasoning and multi-agent collaboration systems in nursing, highlighting their promise for future research and applications.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.080986"
    },
    {
        "index": "#23",
        "title": "More Data or Better Data? A Critical Analysis of Data Selection and Synthesis for Mathematical Reasoning",
        "link": "/arxiv/2510.07169",
        "arxiv_id": "2510.07169",
        "authors": "Yike Zhao, Simin Guo, Ziqing Yang, Shifan Han, Dahua Lin, Fei Tan",
        "summary": "The reasoning capabilities of Large Language Models (LLMs) play a critical role in many downstream tasks, yet depend strongly on the quality of training data. Despite various proposed data construction methods, their practical utility in real-world pipelines remains underexplored. In this work, we conduct a comprehensive analysis of open-source datasets and data synthesis techniques for mathematical reasoning, evaluating them under a unified pipeline designed to mirror training and deployment scenarios. We further distill effective data selection strategies and identify practical methods suitable for industrial applications. Our findings highlight that structuring data in more interpretable formats, or distilling from stronger models often outweighs simply scaling up data volume. This study provides actionable guidance for integrating training data to enhance LLM capabilities, supporting both cost-effective data curation and scalable model enhancement. We hope this work will inspire further research on how to balance \"more data\" versus \"better data\" for real-world reasoning tasks.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.081450"
    },
    {
        "index": "#24",
        "title": "Reasoning for Hierarchical Text Classification: The Case of Patents",
        "link": "/arxiv/2510.07167",
        "arxiv_id": "2510.07167",
        "authors": "Lekang Jiang, Wenjun Sun, Stephan Goetz",
        "summary": "Hierarchical text classification (HTC) assigns documents to multiple levels of a pre-defined taxonomy. Automated patent subject classification represents one of the hardest HTC scenarios because of domain knowledge difficulty and a huge number of labels. Prior approaches only output a flat label set, which offers little insight into the reason behind predictions. Therefore, we propose Reasoning for Hierarchical Classification (RHC), a novel framework that reformulates HTC as a step-by-step reasoning task to sequentially deduce hierarchical labels. RHC trains large language models (LLMs) in two stages: a cold-start stage that aligns outputs with chain-of-thought (CoT) reasoning format and a reinforcement learning (RL) stage to enhance multi-step reasoning ability. RHC demonstrates four advantages in our experiments. (1) Effectiveness: RHC surpasses previous baselines and outperforms the supervised fine-tuning counterparts by approximately 3% in accuracy and macro F1. (2) Explainability: RHC produces natural-language justifications before prediction to facilitate human inspection. (3) Scalability: RHC scales favorably with model size with larger gains compared to standard fine-tuning. (4) Applicability: Beyond patents, we further demonstrate that RHC achieves state-of-the-art performance on other widely used HTC benchmarks, which highlights its broad applicability.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.081872"
    },
    {
        "index": "#25",
        "title": "Comparing human and language models sentence processing difficulties on complex structures",
        "link": "/arxiv/2510.07141",
        "arxiv_id": "2510.07141",
        "authors": "Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant",
        "summary": "Large language models (LLMs) that fluently converse with humans are a reality - but do LLMs experience human-like processing difficulties? We systematically compare human and LLM sentence comprehension across seven challenging linguistic structures. We collect sentence comprehension data from humans and five families of state-of-the-art LLMs, varying in size and training procedure in a unified experimental framework. Our results show LLMs overall struggle on the target structures, but especially on garden path (GP) sentences. Indeed, while the strongest models achieve near perfect accuracy on non-GP structures (93.7% for GPT-5), they struggle on GP structures (46.8% for GPT-5). Additionally, when ranking structures based on average performance, rank correlation between humans and models increases with parameter count. For each target structure, we also collect data for their matched baseline without the difficult structure. Comparing performance on the target vs. baseline sentences, the performance gap observed in humans holds for LLMs, with two exceptions: for models that are too weak performance is uniformly low across both sentence types, and for models that are too strong the performance is uniformly high. Together, these reveal convergence and divergence in human and LLM sentence comprehension, offering new insights into the similarity of humans and LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.082309"
    },
    {
        "index": "#26",
        "title": "TRIM: Token-wise Attention-Derived Saliency for Data-Efficient Instruction Tuning",
        "link": "/arxiv/2510.07118",
        "arxiv_id": "2510.07118",
        "authors": "Manish Nagaraj, Sakshi Choudhary, Utkarsh Saxena, Deepak Ravikumar, Kaushik Roy",
        "summary": "Instruction tuning is essential for aligning large language models (LLMs) to downstream tasks and commonly relies on large, diverse corpora. However, small, high-quality subsets, known as coresets, can deliver comparable or superior results, though curating them remains challenging. Existing methods often rely on coarse, sample-level signals like gradients, an approach that is computationally expensive and overlooks fine-grained features. To address this, we introduce TRIM (Token Relevance via Interpretable Multi-layer Attention), a forward-only, token-centric framework. Instead of using gradients, TRIM operates by matching underlying representational patterns identified via attention-based \"fingerprints\" from a handful of target samples. Such an approach makes TRIM highly efficient and uniquely sensitive to the structural features that define a task. Coresets selected by our method consistently outperform state-of-the-art baselines by up to 9% on downstream tasks and even surpass the performance of full-data fine-tuning in some settings. By avoiding expensive backward passes, TRIM achieves this at a fraction of the computational cost. These findings establish TRIM as a scalable and efficient alternative for building high-quality instruction-tuning datasets.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.082768"
    },
    {
        "index": "#27",
        "title": "Opt-ICL at LeWiDi-2025: Maximizing In-Context Signal from Rater Examples via Meta-Learning",
        "link": "/arxiv/2510.07105",
        "arxiv_id": "2510.07105",
        "authors": "Taylor Sorensen, Yejin Choi",
        "summary": "Many natural language processing (NLP) tasks involve subjectivity, ambiguity, or legitimate disagreement between annotators. In this paper, we outline our system for modeling human variation. Our system leverages language models' (LLMs) in-context learning abilities, along with a two-step meta-learning training procedure for 1) post-training on many datasets requiring in-context learning and 2) specializing the model via in-context meta-learning to the particular data distribution of interest. We also evaluate the performance of our system submission to the Learning With Disagreements (LeWiDi) competition, where it was the overall winner on both tasks. Additionally, we perform an ablation study to measure the importance of each system component. We find that including rater examples in-context is crucial for our system's performance, dataset-specific fine-tuning is helpful on the larger datasets, post-training on other in-context datasets is helpful on one of the competition datasets, and that performance improves with model scale.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.083194"
    },
    {
        "index": "#28",
        "title": "TALENT: Table VQA via Augmented Language-Enhanced Natural-text Transcription",
        "link": "/arxiv/2510.07098",
        "arxiv_id": "2510.07098",
        "authors": "Guo Yutong, Wanying Wang, Yue Wu, Zichen Miao, Haoyu Wang",
        "summary": "Table Visual Question Answering (Table VQA) is typically addressed by large vision-language models (VLMs). While such models can answer directly from images, they often miss fine-grained details unless scaled to very large sizes, which are computationally prohibitive, especially for mobile deployment. A lighter alternative is to have a small VLM perform OCR and then use a large language model (LLM) to reason over structured outputs such as Markdown tables. However, these representations are not naturally optimized for LLMs and still introduce substantial errors. We propose TALENT (Table VQA via Augmented Language-Enhanced Natural-text Transcription), a lightweight framework that leverages dual representations of tables. TALENT prompts a small VLM to produce both OCR text and natural language narration, then combines them with the question for reasoning by an LLM. This reframes Table VQA as an LLM-centric multimodal reasoning task, where the VLM serves as a perception-narration module rather than a monolithic solver. Additionally, we construct ReTabVQA, a more challenging Table VQA dataset requiring multi-step quantitative reasoning over table images. Experiments show that TALENT enables a small VLM-LLM combination to match or surpass a single large VLM at significantly lower computational cost on both public datasets and ReTabVQA.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.083646"
    },
    {
        "index": "#29",
        "title": "Making Machines Sound Sarcastic: LLM-Enhanced and Retrieval-Guided Sarcastic Speech Synthesis",
        "link": "/arxiv/2510.07096",
        "arxiv_id": "2510.07096",
        "authors": "Zhu Li, Yuqing Zhang, Xiyuan Gao, Shekhar Nayak, Matt Coler",
        "summary": "Sarcasm is a subtle form of non-literal language that poses significant challenges for speech synthesis due to its reliance on nuanced semantic, contextual, and prosodic cues. While existing speech synthesis research has focused primarily on broad emotional categories, sarcasm remains largely unexplored. In this paper, we propose a Large Language Model (LLM)-enhanced Retrieval-Augmented framework for sarcasm-aware speech synthesis. Our approach combines (1) semantic embeddings from a LoRA-fine-tuned LLaMA 3, which capture pragmatic incongruity and discourse-level cues of sarcasm, and (2) prosodic exemplars retrieved via a Retrieval Augmented Generation (RAG) module, which provide expressive reference patterns of sarcastic delivery. Integrated within a VITS backbone, this dual conditioning enables more natural and contextually appropriate sarcastic speech. Experiments demonstrate that our method outperforms baselines in both objective measures and subjective evaluations, yielding improvements in speech naturalness, sarcastic expressivity, and downstream sarcasm detection.",
        "subjects": "Computation and Language, Sound, Audio and Speech Processing",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.084159"
    },
    {
        "index": "#30",
        "title": "All Claims Are Equal, but Some Claims Are More Equal Than Others: Importance-Sensitive Factuality Evaluation of LLM Generations",
        "link": "/arxiv/2510.07083",
        "arxiv_id": "2510.07083",
        "authors": "Miriam Wanner, Leif Azzopardi, Paul Thomas, Soham Dan, Benjamin Van Durme, Nick Craswell",
        "summary": "Existing methods for evaluating the factuality of large language model (LLM) responses treat all claims as equally important. This results in misleading evaluations when vital information is missing or incorrect as it receives the same weight as peripheral details, raising the question: how can we reliably detect such differences when there are errors in key information? Current approaches that measure factuality tend to be insensitive to omitted or false key information. To investigate this lack of sensitivity, we construct VITALERRORS, a benchmark of 6,733 queries with minimally altered LLM responses designed to omit or falsify key information. Using this dataset, we demonstrate the insensitivities of existing evaluation metrics to key information errors. To address this gap, we introduce VITAL, a set of metrics that provide greater sensitivity in measuring the factuality of responses by incorporating the relevance and importance of claims with respect to the query. Our analysis demonstrates that VITAL metrics more reliably detect errors in key information than previous methods. Our dataset, metrics, and analysis provide a foundation for more accurate and robust assessment of LLM factuality.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.125617"
    },
    {
        "index": "#31",
        "title": "Accelerating Diffusion LLM Inference via Local Determinism Propagation",
        "link": "/arxiv/2510.07081",
        "arxiv_id": "2510.07081",
        "authors": "Fanheng Kong, Jingyuan Zhang, Yahui Liu, Zirui Wu, Yu Tian, Victoria W., Guorui Zhou",
        "summary": "Diffusion large language models (dLLMs) represent a significant advancement in text generation, offering parallel token decoding capabilities. However, existing open-source implementations suffer from quality-speed trade-offs that impede their practical deployment. Conservative sampling strategies typically decode only the most confident token per step to ensure quality (i.e., greedy decoding), at the cost of inference efficiency due to repeated redundant refinement iterations--a phenomenon we term delayed decoding. Through systematic analysis of dLLM decoding dynamics, we characterize this delayed decoding behavior and propose a training-free adaptive parallel decoding strategy, named LocalLeap, to address these inefficiencies. LocalLeap is built on two fundamental empirical principles: local determinism propagation centered on high-confidence anchors and progressive spatial consistency decay. By applying these principles, LocalLeap identifies anchors and performs localized relaxed parallel decoding within bounded neighborhoods, achieving substantial inference step reduction through early commitment of already-determined tokens without compromising output quality. Comprehensive evaluation on various benchmarks demonstrates that LocalLeap achieves 6.94$\\times$ throughput improvements and reduces decoding steps to just 14.2\\% of the original requirement, achieving these gains with negligible performance impact. The source codes are available at: https://github.com/friedrichor/LocalLeap.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.126359"
    },
    {
        "index": "#32",
        "title": "LuxInstruct: A Cross-Lingual Instruction Tuning Dataset For Luxembourgish",
        "link": "/arxiv/2510.07074",
        "arxiv_id": "2510.07074",
        "authors": "Fred Philippy, Laura Bernardy, Siwen Guo, Jacques Klein, Tegawendé F. Bissyandé",
        "summary": "Instruction tuning has become a key technique for enhancing the performance of large language models, enabling them to better follow human prompts. However, low-resource languages such as Luxembourgish face severe limitations due to the lack of high-quality instruction datasets. Traditional reliance on machine translation often introduces semantic misalignment and cultural inaccuracies. In this work, we address these challenges by creating a cross-lingual instruction tuning dataset for Luxembourgish, without resorting to machine-generated translations into it. Instead, by leveraging aligned data from English, French, and German, we build a high-quality dataset that preserves linguistic and cultural nuances. We provide evidence that cross-lingual instruction tuning not only improves representational alignment across languages but also the model's generative capabilities in Luxembourgish. This highlights how cross-lingual data curation can avoid the common pitfalls of machine-translated data and directly benefit low-resource language development.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.127067"
    },
    {
        "index": "#33",
        "title": "Revisiting Metric Reliability for Fine-grained Evaluation of Machine Translation and Summarization in Indian Languages",
        "link": "/arxiv/2510.07061",
        "arxiv_id": "2510.07061",
        "authors": "Amir Hossein Yari, Kalmit Kulkarni, Ahmad Raza Khan, Fajri Koto",
        "summary": "While automatic metrics drive progress in Machine Translation (MT) and Text Summarization (TS), existing metrics have been developed and validated almost exclusively for English and other high-resource languages. This narrow focus leaves Indian languages, spoken by over 1.5 billion people, largely overlooked, casting doubt on the universality of current evaluation practices. To address this gap, we introduce ITEM, a large-scale benchmark that systematically evaluates the alignment of 26 automatic metrics with human judgments across six major Indian languages, enriched with fine-grained annotations. Our extensive evaluation, covering agreement with human judgments, sensitivity to outliers, language-specific reliability, inter-metric correlations, and resilience to controlled perturbations, reveals four central findings: (1) LLM-based evaluators show the strongest alignment with human judgments at both segment and system levels; (2) outliers exert a significant impact on metric-human agreement; (3) in TS, metrics are more effective at capturing content fidelity, whereas in MT, they better reflect fluency; and (4) metrics differ in their robustness and sensitivity when subjected to diverse perturbations. Collectively, these findings offer critical guidance for advancing metric design and evaluation in Indian languages.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.127716"
    },
    {
        "index": "#34",
        "title": "Does Local News Stay Local?: Online Content Shifts in Sinclair-Acquired Stations",
        "link": "/arxiv/2510.07060",
        "arxiv_id": "2510.07060",
        "authors": "Miriam Wanner, Sophia Hager, Anjalie Field",
        "summary": "Local news stations are often considered to be reliable sources of non-politicized information, particularly local concerns that residents care about. Because these stations are trusted news sources, viewers are particularly susceptible to the information they report. The Sinclair Broadcast group is a broadcasting company that has acquired many local news stations in the last decade. We investigate the effects of local news stations being acquired by Sinclair: how does coverage change? We use computational methods to investigate changes in internet content put out by local news stations before and after being acquired by Sinclair and in comparison to national news outlets. We find that there is clear evidence that local news stations report more frequently on national news at the expense of local topics, and that their coverage of polarizing national topics increases.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.128354"
    },
    {
        "index": "#35",
        "title": "Search-R3: Unifying Reasoning and Embedding Generation in Large Language Models",
        "link": "/arxiv/2510.07048",
        "arxiv_id": "2510.07048",
        "authors": "Yuntao Gui, James Cheng",
        "summary": "Despite their remarkable natural language understanding capabilities, Large Language Models (LLMs) have been underutilized for retrieval tasks. We present Search-R3, a novel framework that addresses this limitation by adapting LLMs to generate search embeddings as a direct output of their reasoning process. Our approach exploits LLMs' chain-of-thought capabilities, allowing them to produce more effective embeddings by reasoning step-by-step through complex semantic analyses. We implement this through three complementary mechanisms. (1) a supervised learning stage enables the model's ability to produce quality embeddings, (2) a reinforcement learning (RL) methodology that optimizes embedding generation alongside reasoning, and (3) a specialized RL environment that efficiently handles evolving embedding representations without requiring complete corpus re-encoding at each training iteration. Our extensive evaluations on diverse benchmarks demonstrate that Search-R3 significantly outperforms prior methods by unifying the reasoning and embedding generation processes. This integrated post-training approach represents a substantial advancement in handling complex knowledge-intensive tasks that require both sophisticated reasoning and effective information retrieval. Project page: https://github.com/ytgui/Search-R3",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.128981"
    },
    {
        "index": "#36",
        "title": "Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models",
        "link": "/arxiv/2510.07037",
        "arxiv_id": "2510.07037",
        "authors": "Rajvee Sheth, Samridhi Raj Sinha, Mahavir Patil, Himanshu Beniwal, Mayank Singh",
        "summary": "Code-switching (CSW), the alternation of languages and scripts within a single utterance, remains a fundamental challenge for multiling ual NLP, even amidst the rapid advances of large language models (LLMs). Most LLMs still struggle with mixed-language inputs, limited CSW datasets, and evaluation biases, hindering deployment in multilingual societies. This survey provides the first comprehensive analysis of CSW-aware LLM research, reviewing \\total{unique_references} studies spanning five research areas, 12 NLP tasks, 30+ datasets, and 80+ languages. We classify recent advances by architecture, training strategy, and evaluation methodology, outlining how LLMs have reshaped CSW modeling and what challenges persist. The paper concludes with a roadmap emphasizing the need for inclusive datasets, fair evaluation, and linguistically grounded models to achieve truly multilingual intelligence. A curated collection of all resources is maintained at https://github.com/lingo-iitgn/awesome-code-mixing/.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.129655"
    },
    {
        "index": "#37",
        "title": "Mining the Mind: What 100M Beliefs Reveal About Frontier LLM Knowledge",
        "link": "/arxiv/2510.07024",
        "arxiv_id": "2510.07024",
        "authors": "Shrestha Ghosh, Luca Giordano, Yujia Hu, Tuan-Phong Nguyen, Simon Razniewski",
        "summary": "LLMs are remarkable artifacts that have revolutionized a range of NLP and AI tasks. A significant contributor is their factual knowledge, which, to date, remains poorly understood, and is usually analyzed from biased samples. In this paper, we take a deep tour into the factual knowledge (or beliefs) of a frontier LLM, based on GPTKB v1.5 (Hu et al., 2025a), a recursively elicited set of 100 million beliefs of one of the strongest currently available frontier LLMs, GPT-4.1. We find that the models' factual knowledge differs quite significantly from established knowledge bases, and that its accuracy is significantly lower than indicated by previous benchmarks. We also find that inconsistency, ambiguity and hallucinations are major issues, shedding light on future research opportunities concerning factual LLM knowledge.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.130318"
    },
    {
        "index": "#38",
        "title": "Native Hybrid Attention for Efficient Sequence Modeling",
        "link": "/arxiv/2510.07019",
        "arxiv_id": "2510.07019",
        "authors": "Jusen Du, Jiaxi Hu, Tao Zhang, Weigao Sun, Yu Cheng",
        "summary": "Transformers excel at sequence modeling but face quadratic complexity, while linear attention offers improved efficiency but often compromises recall accuracy over long contexts. In this work, we introduce Native Hybrid Attention (NHA), a novel hybrid architecture of linear and full attention that integrates both intra \\& inter-layer hybridization into a unified layer design. NHA maintains long-term context in key-value slots updated by a linear RNN, and augments them with short-term tokens from a sliding window. A single \\texttt{softmax attention} operation is then applied over all keys and values, enabling per-token and per-head context-dependent weighting without requiring additional fusion parameters. The inter-layer behavior is controlled through a single hyperparameter, the sliding window size, which allows smooth adjustment between purely linear and full attention while keeping all layers structurally uniform. Experimental results show that NHA surpasses Transformers and other hybrid baselines on recall-intensive and commonsense reasoning tasks. Furthermore, pretrained LLMs can be structurally hybridized with NHA, achieving competitive accuracy while delivering significant efficiency gains. Code is available at https://github.com/JusenD/NHA.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.136201"
    },
    {
        "index": "#39",
        "title": "Pragyaan: Designing and Curating High-Quality Cultural Post-Training Datasets for Indian Languages",
        "link": "/arxiv/2510.07000",
        "arxiv_id": "2510.07000",
        "authors": "Neel Prabhanjan Rachamalla, Aravind Konakalla, Gautam Rajeev, Ashish Kulkarni, Chandra Khatri, Shubham Agarwal",
        "summary": "The effectiveness of Large Language Models (LLMs) depends heavily on the availability of high-quality post-training data, particularly instruction-tuning and preference-based examples. Existing open-source datasets, however, often lack multilingual coverage, cultural grounding, and suffer from task diversity gaps that are especially pronounced for Indian languages. We introduce a human-in-the-loop pipeline that combines translations with synthetic expansion to produce reliable and diverse Indic post-training data. Using this pipeline, we curate two datasets: Pragyaan-IT (22.5K) and Pragyaan-Align (100K) across 10 Indian languages covering 13 broad and 56 sub-categories, leveraging 57 diverse datasets. Our dataset protocol incorporates several often-overlooked dimensions and emphasize task diversity, multi-turn dialogue, instruction fidelity, safety alignment, and preservation of cultural nuance, providing a foundation for more inclusive and effective multilingual LLMs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.136797"
    },
    {
        "index": "#40",
        "title": "Towards Reliable Retrieval in RAG Systems for Large Legal Datasets",
        "link": "/arxiv/2510.06999",
        "arxiv_id": "2510.06999",
        "authors": "Markus Reuter, Tobias Lingenberg, Rūta Liepiņa, Francesca Lagioia, Marco Lippi, Giovanni Sartor, Andrea Passerini, Burcu Sayin",
        "summary": "Retrieval-Augmented Generation (RAG) is a promising approach to mitigate hallucinations in Large Language Models (LLMs) for legal applications, but its reliability is critically dependent on the accuracy of the retrieval step. This is particularly challenging in the legal domain, where large databases of structurally similar documents often cause retrieval systems to fail. In this paper, we address this challenge by first identifying and quantifying a critical failure mode we term Document-Level Retrieval Mismatch (DRM), where the retriever selects information from entirely incorrect source documents. To mitigate DRM, we investigate a simple and computationally efficient technique which we refer to as Summary-Augmented Chunking (SAC). This method enhances each text chunk with a document-level synthetic summary, thereby injecting crucial global context that would otherwise be lost during a standard chunking process. Our experiments on a diverse set of legal information retrieval tasks show that SAC greatly reduces DRM and, consequently, also improves text-level retrieval precision and recall. Interestingly, we find that a generic summarization strategy outperforms an approach that incorporates legal expert domain knowledge to target specific legal elements. Our work provides evidence that this practical, scalable, and easily integrable technique enhances the reliability of RAG systems when applied to large-scale legal document datasets.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.137299"
    },
    {
        "index": "#41",
        "title": "Probing Social Identity Bias in Chinese LLMs with Gendered Pronouns and Social Groups",
        "link": "/arxiv/2510.06974",
        "arxiv_id": "2510.06974",
        "authors": "Geng Liu, Feng Li, Junjie Mu, Mengxiao Zhu, Francesco Pierri",
        "summary": "Large language models (LLMs) are increasingly deployed in user-facing applications, raising concerns about their potential to reflect and amplify social biases. We investigate social identity framing in Chinese LLMs using Mandarin-specific prompts across ten representative Chinese LLMs, evaluating responses to ingroup (\"We\") and outgroup (\"They\") framings, and extending the setting to 240 social groups salient in the Chinese context. To complement controlled experiments, we further analyze Chinese-language conversations from a corpus of real interactions between users and chatbots. Across models, we observe systematic ingroup-positive and outgroup-negative tendencies, which are not confined to synthetic prompts but also appear in naturalistic dialogue, indicating that bias dynamics might strengthen in real interactions. Our study provides a language-aware evaluation framework for Chinese LLMs, demonstrating that social identity biases documented in English generalize cross-linguistically and intensify in user-facing contexts.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.137739"
    },
    {
        "index": "#42",
        "title": "EDUMATH: Generating Standards-aligned Educational Math Word Problems",
        "link": "/arxiv/2510.06965",
        "arxiv_id": "2510.06965",
        "authors": "Bryan R. Christ, Penelope Molitz, Jonathan Kropko, Thomas Hartvigsen",
        "summary": "Math word problems (MWPs) are critical K-12 educational tools, and customizing them to students' interests and ability levels can increase learning outcomes. However, teachers struggle to find time to customize MWPs for each student given large class sizes and increasing burnout. We propose that LLMs can support math education by generating MWPs customized to student interests and math education standards. To this end, we use a joint human expert-LLM judge approach to evaluate over 11,000 MWPs generated by open and closed LLMs and develop the first teacher-annotated dataset for standards-aligned educational MWP generation. We show the value of our data by using it to train a 12B open model that matches the performance of larger and more capable open models. We also use our teacher-annotated data to train a text classifier that enables a 30B open LLM to outperform existing closed baselines without any training. Next, we show our models' MWPs are more similar to human-written MWPs than those from existing models. We conclude by conducting the first study of customized LLM-generated MWPs with grade school students, finding they perform similarly on our models' MWPs relative to human-written MWPs but consistently prefer our customized MWPs.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.138190"
    },
    {
        "index": "#43",
        "title": "Open ASR Leaderboard: Towards Reproducible and Transparent Multilingual and Long-Form Speech Recognition Evaluation",
        "link": "/arxiv/2510.06961",
        "arxiv_id": "2510.06961",
        "authors": "Vaibhav Srivastav, Steven Zheng, Eric Bezzam, Eustache Le Bihan, Nithin Koluguri, Piotr Żelasko, Somshubra Majumdar, Adel Moumen, Sanchit Gandhi",
        "summary": "Despite rapid progress, ASR evaluation remains saturated with short-form English, and efficiency is rarely reported. We present the Open ASR Leaderboard, a fully reproducible benchmark and interactive leaderboard comparing 60+ open-source and proprietary systems across 11 datasets, including dedicated multilingual and long-form tracks. We standardize text normalization and report both word error rate (WER) and inverse real-time factor (RTFx), enabling fair accuracy-efficiency comparisons. For English transcription, Conformer encoders paired with LLM decoders achieve the best average WER but are slower, while CTC and TDT decoders deliver much better RTFx, making them attractive for long-form and offline use. Whisper-derived encoders fine-tuned for English improve accuracy but often trade off multilingual coverage. All code and dataset loaders are open-sourced to support transparent, extensible evaluation.",
        "subjects": "Computation and Language, Artificial Intelligence, Sound, Audio and Speech Processing",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.138736"
    },
    {
        "index": "#44",
        "title": "SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models",
        "link": "/arxiv/2510.06917",
        "arxiv_id": "2510.06917",
        "authors": "Cheng-Han Chiang, Xiaofei Wang, Linjie Li, Chung-Ching Lin, Kevin Lin, Shujie Liu, Zhendong Wang, Zhengyuan Yang, Hung-yi Lee, Lijuan Wang",
        "summary": "Current large language models (LLMs) and spoken language models (SLMs) begin thinking and taking actions only after the user has finished their turn. This prevents the model from interacting during the user's turn and can lead to high response latency while it waits to think. Consequently, thinking after receiving the full input is not suitable for speech-to-speech interaction, where real-time, low-latency exchange is important. We address this by noting that humans naturally \"think while listening.\" In this paper, we propose SHANKS, a general inference framework that enables SLMs to generate unspoken chain-of-thought reasoning while listening to the user input. SHANKS streams the input speech in fixed-duration chunks and, as soon as a chunk is received, generates unspoken reasoning based on all previous speech and reasoning, while the user continues speaking. SHANKS uses this unspoken reasoning to decide whether to interrupt the user and to make tool calls to complete the task. We demonstrate that SHANKS enhances real-time user-SLM interaction in two scenarios: (1) when the user is presenting a step-by-step solution to a math problem, SHANKS can listen, reason, and interrupt when the user makes a mistake, achieving 37.1% higher interruption accuracy than a baseline that interrupts without thinking; and (2) in a tool-augmented dialogue, SHANKS can complete 56.9% of the tool calls before the user finishes their turn. Overall, SHANKS moves toward models that keep thinking throughout the conversation, not only after a turn ends. Animated illustrations of Shanks can be found at https://d223302.github.io/SHANKS/",
        "subjects": "Computation and Language, Audio and Speech Processing",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.139251"
    },
    {
        "index": "#45",
        "title": "LongRM: Revealing and Unlocking the Context Boundary of Reward Modeling",
        "link": "/arxiv/2510.06915",
        "arxiv_id": "2510.06915",
        "authors": "Zecheng Tang, Baibei Ji, Quantong Qiu, Haitian Wang, Xiaobo Liang, Juntao Li, Min Zhang",
        "summary": "Reward model (RM) plays a pivotal role in aligning large language model (LLM) with human preferences. As real-world applications increasingly involve long history trajectories, e.g., LLM agent, it becomes indispensable to evaluate whether a model's responses are not only high-quality but also grounded in and consistent with the provided context. Yet, current RMs remain confined to short-context settings and primarily focus on response-level attributes (e.g., safety or helpfulness), while largely neglecting the critical dimension of long context-response consistency. In this work, we introduce Long-RewardBench, a benchmark specifically designed for long-context RM evaluation, featuring both Pairwise Comparison and Best-of-N tasks. Our preliminary study reveals that even state-of-the-art generative RMs exhibit significant fragility in long-context scenarios, failing to maintain context-aware preference judgments. Motivated by the analysis of failure patterns observed in model outputs, we propose a general multi-stage training strategy that effectively scales arbitrary models into robust Long-context RMs (LongRMs). Experiments show that our approach not only substantially improves performance on long-context evaluation but also preserves strong short-context capability. Notably, our 8B LongRM outperforms much larger 70B-scale baselines and matches the performance of the proprietary Gemini 2.5 Pro model.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.139782"
    },
    {
        "index": "#46",
        "title": "MeXtract: Light-Weight Metadata Extraction from Scientific Papers",
        "link": "/arxiv/2510.06889",
        "arxiv_id": "2510.06889",
        "authors": "Zaid Alyafeai, Maged S. Al-Shaibani, Bernard Ghanem",
        "summary": "Metadata plays a critical role in indexing, documenting, and analyzing scientific literature, yet extracting it accurately and efficiently remains a challenging task. Traditional approaches often rely on rule-based or task-specific models, which struggle to generalize across domains and schema variations. In this paper, we present MeXtract, a family of lightweight language models designed for metadata extraction from scientific papers. The models, ranging from 0.5B to 3B parameters, are built by fine-tuning Qwen 2.5 counterparts. In their size family, MeXtract achieves state-of-the-art performance on metadata extraction on the MOLE benchmark. To further support evaluation, we extend the MOLE benchmark to incorporate model-specific metadata, providing an out-of-domain challenging subset. Our experiments show that fine-tuning on a given schema not only yields high accuracy but also transfers effectively to unseen schemas, demonstrating the robustness and adaptability of our approach. We release all the code, datasets, and models openly for the research community.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.140198"
    },
    {
        "index": "#47",
        "title": "$λ$-GRPO: Unifying the GRPO Frameworks with Learnable Token Preferences",
        "link": "/arxiv/2510.06870",
        "arxiv_id": "2510.06870",
        "authors": "Yining Wang, Jinman Zhao, Chuangxin Zhao, Shuhao Guan, Gerald Penn, Shinan Liu",
        "summary": "Reinforcement Learning with Human Feedback (RLHF) has been the dominant approach for improving the reasoning capabilities of Large Language Models (LLMs). Recently, Reinforcement Learning with Verifiable Rewards (RLVR) has simplified this paradigm by replacing the reward and value models with rule-based verifiers. A prominent example is Group Relative Policy Optimization (GRPO). However, GRPO inherently suffers from a length bias, since the same advantage is uniformly assigned to all tokens of a response. As a result, longer responses distribute the reward over more tokens and thus contribute disproportionately to gradient updates. Several variants, such as DAPO and Dr. GRPO, modify the token-level aggregation of the loss, yet these methods remain heuristic and offer limited interpretability regarding their implicit token preferences. In this work, we explore the possibility of allowing the model to learn its own token preference during optimization. We unify existing frameworks under a single formulation and introduce a learnable parameter $\\lambda$ that adaptively controls token-level weighting. We use $\\lambda$-GRPO to denote our method, and we find that $\\lambda$-GRPO achieves consistent improvements over vanilla GRPO and DAPO on multiple mathematical reasoning benchmarks. On Qwen2.5 models with 1.5B, 3B, and 7B parameters, $\\lambda$-GRPO improves average accuracy by $+1.9\\%$, $+1.0\\%$, and $+1.7\\%$ compared to GRPO, respectively. Importantly, these gains come without any modifications to the training data or additional computational cost, highlighting the effectiveness and practicality of learning token preferences.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.145823"
    },
    {
        "index": "#48",
        "title": "Unlocking Latent Discourse Translation in LLMs Through Quality-Aware Decoding",
        "link": "/arxiv/2510.06866",
        "arxiv_id": "2510.06866",
        "authors": "Wafaa Mohammed, Vlad Niculae, Chrysoula Zerva",
        "summary": "Large language models (LLMs) have emerged as strong contenders in machine translation.Yet, they still struggle to adequately handle discourse phenomena, such as pronoun resolution and lexical cohesion at the document level. In this study, we thoroughly investigate the discourse phenomena performance of LLMs in context-aware translation. We demonstrate that discourse knowledge is encoded within LLMs and propose the use of quality-aware decoding (QAD) to effectively extract this knowledge, showcasing its superiority over other decoding approaches through comprehensive analysis. Furthermore, we illustrate that QAD enhances the semantic richness of translations and aligns them more closely with human preferences.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.146280"
    },
    {
        "index": "#49",
        "title": "OpenJAI-v1.0: An Open Thai Large Language Model",
        "link": "/arxiv/2510.06847",
        "arxiv_id": "2510.06847",
        "authors": "Pontakorn Trakuekul, Attapol T. Rutherford, Jullajak Karnjanaekarin, Narongkorn Panitsrisit, Sumana Sumanakul",
        "summary": "We introduce OpenJAI-v1.0, an open-source large language model for Thai and English, developed from the Qwen3-14B model. Our work focuses on boosting performance on practical tasks through carefully curated data across three key use cases: instruction following, long-context understanding, and tool use. Evaluation results show that OpenJAI-v1.0 improves on the capabilities of its base model and outperforms other leading open-source Thai models on a diverse suite of benchmarks, while avoiding catastrophic forgetting. OpenJAI-v1.0 is publicly released as another alternative NLP resource for the Thai AI community.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.146738"
    },
    {
        "index": "#50",
        "title": "SID: Multi-LLM Debate Driven by Self Signals",
        "link": "/arxiv/2510.06843",
        "arxiv_id": "2510.06843",
        "authors": "Xuhang Chen, Zhifan Song, Deyi Ji, Shuo Gao, Lanyun Zhu",
        "summary": "Large Language Models (LLMs) have exhibited impressive capabilities across diverse application domains. Recent work has explored Multi-LLM Agent Debate (MAD) as a way to enhance performance by enabling multiple LLMs to discuss and refine responses iteratively. Nevertheless, existing MAD methods predominantly focus on utilizing external structures, such as debate graphs, using LLM-as-a-Judge, while neglecting the application of self signals, such as token logits and attention, that arise during generation. This omission leads to redundant computation and potential performance degradation. In this paper, we shift the focus to the self signals of multi-LLM debate and introduce a Self-Signals Driven Multi-LLM Debate (SID), which leverages two types of self-signals: model-level confidence and token-level semantic focus, to adaptively guide the debate process. Our approach enables high-confidence agents to exit early at the model level and compress the redundant debate contents based on the attention mechanism. We evaluate our method on various LLMs and Multimodal LLMs across multiple challenging benchmarks. Experimental results demonstrate that our method not only outperforms existing MAD techniques in accuracy but also reduces token consumption, highlighting the effectiveness of utilizing self signals in enhancing both the performance and efficiency of multi-agent debate systems. Our code will be available at~\\href{https://github.com/xuhang2019/SID}{\\texttt{https://github.com/xuhang2019/SID}}.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.147202"
    },
    {
        "index": "#51",
        "title": "GAMBIT+: A Challenge Set for Evaluating Gender Bias in Machine Translation Quality Estimation Metrics",
        "link": "/arxiv/2510.06841",
        "arxiv_id": "2510.06841",
        "authors": "Giorgos Filandrianos, Orfeas Menis Mastromichalakis, Wafaa Mohammed, Giuseppe Attanasio, Chrysoula Zerva",
        "summary": "Gender bias in machine translation (MT) systems has been extensively documented, but bias in automatic quality estimation (QE) metrics remains comparatively underexplored. Existing studies suggest that QE metrics can also exhibit gender bias, yet most analyses are limited by small datasets, narrow occupational coverage, and restricted language variety. To address this gap, we introduce a large-scale challenge set specifically designed to probe the behavior of QE metrics when evaluating translations containing gender-ambiguous occupational terms. Building on the GAMBIT corpus of English texts with gender-ambiguous occupations, we extend coverage to three source languages that are genderless or natural-gendered, and eleven target languages with grammatical gender, resulting in 33 source-target language pairs. Each source text is paired with two target versions differing only in the grammatical gender of the occupational term(s) (masculine vs. feminine), with all dependent grammatical elements adjusted accordingly. An unbiased QE metric should assign equal or near-equal scores to both versions. The dataset's scale, breadth, and fully parallel design, where the same set of texts is aligned across all languages, enables fine-grained bias analysis by occupation and systematic comparisons across languages.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.147637"
    },
    {
        "index": "#52",
        "title": "Mid-Training of Large Language Models: A Survey",
        "link": "/arxiv/2510.06826",
        "arxiv_id": "2510.06826",
        "authors": "Kaixiang Mo, Yuxin Shi, Weiwei Weng, Zhiqiang Zhou, Shuman Liu, Haibo Zhang, Anxiang Zeng",
        "summary": "Large language models (LLMs) are typically developed through large-scale pre-training followed by task-specific fine-tuning. Recent advances highlight the importance of an intermediate mid-training stage, where models undergo multiple annealing-style phases that refine data quality, adapt optimization schedules, and extend context length. This stage mitigates diminishing returns from noisy tokens, stabilizes convergence, and expands model capability in late training. Its effectiveness can be explained through gradient noise scale, the information bottleneck, and curriculum learning, which together promote generalization and abstraction. Despite widespread use in state-of-the-art systems, there has been no prior survey of mid-training as a unified paradigm. We introduce the first taxonomy of LLM mid-training spanning data distribution, learning-rate scheduling, and long-context extension. We distill practical insights, compile evaluation benchmarks, and report gains to enable structured comparisons across models. We also identify open challenges and propose avenues for future research and practice.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.148137"
    },
    {
        "index": "#53",
        "title": "Adaptive Tool Generation with Models as Tools and Reinforcement Learning",
        "link": "/arxiv/2510.06825",
        "arxiv_id": "2510.06825",
        "authors": "Chenpeng Wang, Xiaojie Cheng, Chunye Wang, Linfeng Yang, Lei Zhang",
        "summary": "Tool-augmented language models have demonstrated strong capabilities, but their reliance on live API access creates scalability and reliability challenges during training and deployment. We propose MTR, a simulation-first training framework for tool-augmented reasoning. Instead of relying on live APIs, MTR learns from complete ReAct traces with schema-validated, simulated observations. Our approach operates through a multi-agent architecture where a ToolMaker generates task-specific, OpenAI-compatible tool interfaces, an AutoAgent produces structured think-act-observe sequences, and a ToolActor simulates realistic responses. Training proceeds in two stages: Stage-1 Supervised Fine-Tuning (SFT) teaches 'trace grammar' from complete reasoning sequences; Stage-2 Group Relative Policy Optimization (GRPO) optimizes strategy with a composite trace reward that balances answer correctness and internal consistency. Across four multi-hop QA benchmarks (HotpotQA, MuSiQue, 2WikiMultiHopQA, Bamboogle), MTR attains competitive Exact Match (EM) scores to live-API systems and excels on reasoning-intensive tasks, suggesting that effective tool reasoning can be learned from structured traces without live interactions.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.148586"
    },
    {
        "index": "#54",
        "title": "BlackboxNLP-2025 MIB Shared Task: Exploring Ensemble Strategies for Circuit Localization Methods",
        "link": "/arxiv/2510.06811",
        "arxiv_id": "2510.06811",
        "authors": "Philipp Mondorf, Mingyang Wang, Sebastian Gerstner, Ahmad Dawar Hakimi, Yihong Liu, Leonor Veloso, Shijia Zhou, Hinrich Schütze, Barbara Plank",
        "summary": "The Circuit Localization track of the Mechanistic Interpretability Benchmark (MIB) evaluates methods for localizing circuits within large language models (LLMs), i.e., subnetworks responsible for specific task behaviors. In this work, we investigate whether ensembling two or more circuit localization methods can improve performance. We explore two variants: parallel and sequential ensembling. In parallel ensembling, we combine attribution scores assigned to each edge by different methods-e.g., by averaging or taking the minimum or maximum value. In the sequential ensemble, we use edge attribution scores obtained via EAP-IG as a warm start for a more expensive but more precise circuit identification method, namely edge pruning. We observe that both approaches yield notable gains on the benchmark metrics, leading to a more precise circuit identification approach. Finally, we find that taking a parallel ensemble over various methods, including the sequential ensemble, achieves the best results. We evaluate our approach in the BlackboxNLP 2025 MIB Shared Task, comparing ensemble scores to official baselines across multiple model-task combinations.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.149089"
    },
    {
        "index": "#55",
        "title": "Overview of the Plagiarism Detection Task at PAN 2025",
        "link": "/arxiv/2510.06805",
        "arxiv_id": "2510.06805",
        "authors": "André Greiner-Petter, Maik Fröbe, Jan Philip Wahle, Terry Ruas, Bela Gipp, Akiko Aizawa, Martin Potthast",
        "summary": "The generative plagiarism detection task at PAN 2025 aims at identifying automatically generated textual plagiarism in scientific articles and aligning them with their respective sources. We created a novel large-scale dataset of automatically generated plagiarism using three large language models: Llama, DeepSeek-R1, and Mistral. In this task overview paper, we outline the creation of this dataset, summarize and compare the results of all participants and four baselines, and evaluate the results on the last plagiarism detection task from PAN 2015 in order to interpret the robustness of the proposed approaches. We found that the current iteration does not invite a large variety of approaches as naive semantic similarity approaches based on embedding vectors provide promising results of up to 0.8 recall and 0.5 precision. In contrast, most of these approaches underperform significantly on the 2015 dataset, indicating a lack in generalizability.",
        "subjects": "Computation and Language, Information Retrieval",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.149580"
    },
    {
        "index": "#57",
        "title": "Foundations of LLM Knowledge Materialization: Termination, Reproducibility, Robustness",
        "link": "/arxiv/2510.06780",
        "arxiv_id": "2510.06780",
        "authors": "Luca Giordano, Simon Razniewski",
        "summary": "Large Language Models (LLMs) encode substantial factual knowledge, yet measuring and systematizing this knowledge remains challenging. Converting it into structured format, for example through recursive extraction approaches such as the GPTKB methodology (Hu et al., 2025b), is still underexplored. Key open questions include whether such extraction can terminate, whether its outputs are reproducible, and how robust they are to variations. We systematically study LLM knowledge materialization using miniGPTKBs (domain-specific, tractable subcrawls), analyzing termination, reproducibility, and robustness across three categories of metrics: yield, lexical similarity, and semantic similarity. We experiment with four variations (seed, language, randomness, model) and three illustrative domains (from history, entertainment, and finance). Our findings show (i) high termination rates, though model-dependent; (ii) mixed reproducibility; and (iii) robustness that varies by perturbation type: high for seeds and temperature, lower for languages and models. These results suggest that LLM knowledge materialization can reliably surface core knowledge, while also revealing important limitations.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.150525"
    },
    {
        "index": "#58",
        "title": "Adaptive LLM-Symbolic Reasoning via Dynamic Logical Solver Composition",
        "link": "/arxiv/2510.06774",
        "arxiv_id": "2510.06774",
        "authors": "Lei Xu, Pierre Beckmann, Marco Valentino, André Freitas",
        "summary": "Neuro-symbolic NLP methods aim to leverage the complementary strengths of large language models and formal logical solvers. However, current approaches are mostly static in nature, i.e., the integration of a target solver is predetermined at design time, hindering the ability to employ diverse formal inference strategies. To address this, we introduce an adaptive, multi-paradigm, neuro-symbolic inference framework that: (1) automatically identifies formal reasoning strategies from problems expressed in natural language; and (2) dynamically selects and applies specialized formal logical solvers via autoformalization interfaces. Extensive experiments on individual and multi-paradigm reasoning tasks support the following conclusions: LLMs are effective at predicting the necessary formal reasoning strategies with an accuracy above 90 percent. This enables flexible integration with formal logical solvers, resulting in our framework outperforming competing baselines by 27 percent and 6 percent compared to GPT-4o and DeepSeek-V3.1, respectively. Moreover, adaptive reasoning can even positively impact pure LLM methods, yielding gains of 10, 5, and 6 percent on zero-shot, CoT, and symbolic CoT settings with GPT-4o. Finally, although smaller models struggle with adaptive neuro-symbolic reasoning, post-training offers a viable path to improvement. Overall, this work establishes the foundations for adaptive LLM-symbolic reasoning, offering a path forward for unifying material and formal inferences on heterogeneous reasoning challenges.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.156107"
    },
    {
        "index": "#59",
        "title": "Gold-Switch: Training-Free Superposition of Slow- and Fast- Thinking LLMs",
        "link": "/arxiv/2510.06750",
        "arxiv_id": "2510.06750",
        "authors": "Jaeseong Lee, Dayoung Kwon, seung-won hwang",
        "summary": "Large Reasoning Models (LRMs) excel in structured tasks by emulating deliberate human reasoning but often suffer from overthinking, degrading performance and wasting resources. One possible baseline is to deploy both LLM and LRM, then route input by predicting whether it requires reasoning and may cause overthinking. However, deploying multiple models can be costly or impractical. We propose a superposed deployment strategy with a lightweight, training-free regulation to optimize inference by switching one model on and off. Instead of routing, we selectively unlearn from LRM at inference, scaling down computation while preserving reasoning. By analyzing the cumulative energy of singular values, we identify optimal low-rank projections to adjust reasoning just right.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.178028"
    },
    {
        "index": "#60",
        "title": "A Formal Framework for Fluency-based Multi-Reference Evaluation in Grammatical Error Correction",
        "link": "/arxiv/2510.06749",
        "arxiv_id": "2510.06749",
        "authors": "Eitan Klinger, Zihao Huang, Tran Minh Nguyen, Emma Jayeon Park, Yige Chen, Yang Gu, Qingyu Gao, Siliang Liu, Mengyang Qiu, Jungyeul Park",
        "summary": "Evaluating grammatical error correction requires metrics that reflect the diversity of valid human corrections rather than privileging a single reference. Existing frameworks, largely edit-based and English-centric, rely on rigid alignments between system and reference edits, limiting their applicability in multilingual and generative settings. This paper introduces a formal framework for \\textit{fluency-based multi-reference evaluation}, framing $n$-gram similarity as an aggregation problem over multiple legitimate corrections. Within this formulation, we instantiate GLEU through four aggregation strategies--\\textsc{select-best}, \\textsc{simple-average}, \\textsc{weighted-average}, and \\textsc{merged-counts}--and analyze their properties of boundedness, monotonicity, and sensitivity to reference variation. Empirical results on Czech, Estonian, Ukrainian, and Chinese corpora show that these strategies capture complementary aspects of fluency and coverage. The framework unifies multi-reference evaluation into a principled, fluency-oriented approach that incorporates linguistic diversity without penalizing legitimate variation.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.178820"
    },
    {
        "index": "#61",
        "title": "TWIST: Training-free and Label-free Short Text Clustering through Iterative Vector Updating with LLMs",
        "link": "/arxiv/2510.06747",
        "arxiv_id": "2510.06747",
        "authors": "I-Fan Lin, Faegheh Hasibi, Suzan Verberne",
        "summary": "In this paper, we propose a training-free and label-free method for short text clustering that can be used on top of any existing embedder. In the context of customer-facing chatbots, companies are dealing with large amounts of user utterances that need to be clustered according to their intent. In these commercial settings, no labeled data is typically available, and the number of clusters is not known. Our method is based on iterative vector updating: it constructs sparse vectors based on representative texts, and then iteratively refines them through LLM guidance. Our method achieves comparable or superior results to state-of-the-art methods that use contrastive learning, but without assuming prior knowledge of clusters or labels. Experiments on diverse datasets and smaller LLMs show that our method is model agnostic and can be applied to any embedder, with relatively small LLMs, and different clustering methods. We also show that our method scales to large datasets, reducing the computational cost of the LLM. These low-resource, adaptable settings and the scalability of our method make it more aligned with real-world scenarios than existing clustering methods.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.179429"
    },
    {
        "index": "#62",
        "title": "AWM: Accurate Weight-Matrix Fingerprint for Large Language Models",
        "link": "/arxiv/2510.06738",
        "arxiv_id": "2510.06738",
        "authors": "Boyi Zeng, Lin Chen, Ziwei He, Xinbing Wang, Zhouhan Lin",
        "summary": "Protecting the intellectual property of large language models (LLMs) is crucial, given the substantial resources required for their training. Consequently, there is an urgent need for both model owners and third parties to determine whether a suspect LLM is trained from scratch or derived from an existing base model. However, the intensive post-training processes that models typically undergo-such as supervised fine-tuning, extensive continued pretraining, reinforcement learning, multi-modal extension, pruning, and upcycling-pose significant challenges to reliable identification. In this work, we propose a training-free fingerprinting method based on weight matrices. We leverage the Linear Assignment Problem (LAP) and an unbiased Centered Kernel Alignment (CKA) similarity to neutralize the effects of parameter manipulations, yielding a highly robust and high-fidelity similarity metric. On a comprehensive testbed of 60 positive and 90 negative model pairs, our method demonstrates exceptional robustness against all six aforementioned post-training categories while exhibiting a near-zero risk of false positives. By achieving perfect scores on all classification metrics, our approach establishes a strong basis for reliable model lineage verification. Moreover, the entire computation completes within 30s on an NVIDIA 3090 GPU. The code is available at https://github.com/LUMIA-Group/AWM.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.180102"
    },
    {
        "index": "#63",
        "title": "Are LLMs Reliable Rankers? Rank Manipulation via Two-Stage Token Optimization",
        "link": "/arxiv/2510.06732",
        "arxiv_id": "2510.06732",
        "authors": "Tiancheng Xing, Jerry Li, Yixuan Du, Xiyang Hu",
        "summary": "Large language models (LLMs) are increasingly used as rerankers in information retrieval, yet their ranking behavior can be steered by small, natural-sounding prompts. To expose this vulnerability, we present Rank Anything First (RAF), a two-stage token optimization method that crafts concise textual perturbations to consistently promote a target item in LLM-generated rankings while remaining hard to detect. Stage 1 uses Greedy Coordinate Gradient to shortlist candidate tokens at the current position by combining the gradient of the rank-target with a readability score; Stage 2 evaluates those candidates under exact ranking and readability losses using an entropy-based dynamic weighting scheme, and selects a token via temperature-controlled sampling. RAF generates ranking-promoting prompts token-by-token, guided by dual objectives: maximizing ranking effectiveness and preserving linguistic naturalness. Experiments across multiple LLMs show that RAF significantly boosts the rank of target items using naturalistic language, with greater robustness than existing methods in both promoting target items and maintaining naturalness. These findings underscore a critical security implication: LLM-based reranking is inherently susceptible to adversarial manipulation, raising new challenges for the trustworthiness and robustness of modern retrieval systems. Our code is available at: https://github.com/glad-lab/RAF.",
        "subjects": "Computation and Language, Artificial Intelligence, Information Retrieval",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.180807"
    },
    {
        "index": "#64",
        "title": "PTEB: Towards Robust Text Embedding Evaluation via Stochastic Paraphrasing at Evaluation Time with LLMs",
        "link": "/arxiv/2510.06730",
        "arxiv_id": "2510.06730",
        "authors": "Manuel Frank, Haithem Afli",
        "summary": "Current evaluations of sentence embedding models typically rely on static test beds such as the Massive Text Embedding Benchmark (MTEB). While invaluable, repeated tuning on a fixed suite can inflate reported performance and obscure real-world robustness. We introduce the Paraphrasing Text Embedding Benchmark (PTEB), a dynamic protocol that stochastically generates meaning-preserving paraphrases at evaluation time and aggregates results across multiple runs. Using a cost-efficient LLM-based method grounded in semantic textual similarity gold ratings, we show that LLMs generate token-diverse but semantically preserving, paraphrases. Across 7 MTEB tasks, we validate our hypothesis that the performance of sentence encoders is sensitive to changes in token space even when semantics remain fixed. We also observe that smaller models are not disproportionately affected relative to larger ones. Our results are statistically robust over multiple runs and we extended our experiments to 3 multilingual datasets covering 10 languages. More generally, we aim to propose a new evaluation paradigm in NLP that relies less on static, pre-defined benchmarks but shifts towards dynamic, stochastic evaluation leveraging eval-time compute.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.181402"
    },
    {
        "index": "#65",
        "title": "Scaling LLM Multi-turn RL with End-to-end Summarization-based Context Management",
        "link": "/arxiv/2510.06727",
        "arxiv_id": "2510.06727",
        "authors": "Miao Lu, Weiwei Sun, Weihua Du, Zhan Ling, Xuesong Yao, Kang Liu, Jiecao Chen",
        "summary": "We study reinforcement learning (RL) fine-tuning of large language model (LLM) agents for long-horizon multi-turn tool use, where context length quickly becomes a fundamental bottleneck. Existing RL pipelines can suffer from degraded instruction following, excessive rollout costs, and most importantly, strict context limits. To address these challenges, we introduce summarization-based context management to training. In specific, it periodically compresses the tool using history by LLM-generated summaries that retain task-relevant information to keep a compact context while enabling the agent to scale beyond the fixed context window. Building on this formulation, we derive a policy gradient representation that seamlessly enables standard LLM RL infrastructures to optimize both tool-use behaviors as well as summarization strategies in an end-to-end fashion. We instantiate this framework with \\underline{SU}mmarization augmented \\underline{P}olicy \\underline{O}ptimization (\\texttt{SUPO}), an LLM RL algorithm that enables long-horizon training beyond a fixed context limit. Experiments on interactive function calling and searching tasks demonstrate that \\texttt{SUPO} significantly improves the success rate while maintaining the same or even lower working context length compared to baselines. We also demonstrate that for complex searching tasks, \\texttt{SUPO} can further improve the evaluation performance when scaling test-time maximum round of summarization beyond that of training time. Our results establish summarization-based context management as a principled and scalable approach for training RL agents beyond a fixed context length limit.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.182153"
    },
    {
        "index": "#66",
        "title": "How Language Models Conflate Logical Validity with Plausibility: A Representational Analysis of Content Effects",
        "link": "/arxiv/2510.06700",
        "arxiv_id": "2510.06700",
        "authors": "Leonardo Bertolazzi, Sandro Pezzelle, Raffaelle Bernardi",
        "summary": "Both humans and large language models (LLMs) exhibit content effects: biases in which the plausibility of the semantic content of a reasoning problem influences judgments regarding its logical validity. While this phenomenon in humans is best explained by the dual-process theory of reasoning, the mechanisms behind content effects in LLMs remain unclear. In this work, we address this issue by investigating how LLMs encode the concepts of validity and plausibility within their internal representations. We show that both concepts are linearly represented and strongly aligned in representational geometry, leading models to conflate plausibility with validity. Using steering vectors, we demonstrate that plausibility vectors can causally bias validity judgements, and vice versa, and that the degree of alignment between these two concepts predicts the magnitude of behavioral content effects across models. Finally, we construct debiasing vectors that disentangle these concepts, reducing content effects and improving reasoning accuracy. Our findings advance understanding of how abstract logical concepts are represented in LLMs and highlight representational interventions as a path toward more logical systems.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.187879"
    },
    {
        "index": "#67",
        "title": "Learning to Rewrite Prompts for Bootstrapping LLMs on Downstream Tasks",
        "link": "/arxiv/2510.06695",
        "arxiv_id": "2510.06695",
        "authors": "Qinhao Zhou, Xiang Xiang, Kun He, John E. Hopcroft",
        "summary": "In recent years, the growing interest in Large Language Models (LLMs) has significantly advanced prompt engineering, transitioning from manual design to model-based optimization. Prompts for LLMs generally comprise two components: the \\textit{instruction}, which defines the task or objective, and the \\textit{input}, which is tailored to the instruction type. In natural language generation (NLG) tasks such as machine translation, the \\textit{input} component is particularly critical, while the \\textit{instruction} component tends to be concise. Existing prompt engineering methods primarily focus on optimizing the \\textit{instruction} component for general tasks, often requiring large-parameter LLMs as auxiliary tools. However, these approaches exhibit limited applicability for tasks like machine translation, where the \\textit{input} component plays a more pivotal role. To address this limitation, this paper introduces a novel prompt optimization method specifically designed for machine translation tasks. The proposed approach employs a small-parameter model trained using a back-translation-based strategy, significantly reducing training overhead for single-task optimization while delivering highly effective performance. With certain adaptations, this method can also be extended to other downstream tasks.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning, Audio and Speech Processing",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.188368"
    },
    {
        "index": "#68",
        "title": "Incremental Summarization for Customer Support via Progressive Note-Taking and Agent Feedback",
        "link": "/arxiv/2510.06677",
        "arxiv_id": "2510.06677",
        "authors": "Yisha Wu, Cen, Zhao, Yuanpei Cao, Xiaoqing Su, Yashar Mehdad, Mindy Ji, Claire Na Cheng",
        "summary": "We introduce an incremental summarization system for customer support agents that intelligently determines when to generate concise bullet notes during conversations, reducing agents' context-switching effort and redundant review. Our approach combines a fine-tuned Mixtral-8x7B model for continuous note generation with a DeBERTa-based classifier to filter trivial content. Agent edits refine the online notes generation and regularly inform offline model retraining, closing the agent edits feedback loop. Deployed in production, our system achieved a 3% reduction in case handling time compared to bulk summarization (with reductions of up to 9% in highly complex cases), alongside high agent satisfaction ratings from surveys. These results demonstrate that incremental summarization with continuous feedback effectively enhances summary quality and agent productivity at scale.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.188890"
    },
    {
        "index": "#69",
        "title": "PIKA: Expert-Level Synthetic Datasets for Post-Training Alignment from Scratch",
        "link": "/arxiv/2510.06670",
        "arxiv_id": "2510.06670",
        "authors": "Shangjian Yin, Shining Liang, Wenbiao Ding, Yuli Qian, Zhouxing Shi, Hongzhi Li, Yutao Xie",
        "summary": "Reinforcement Learning from Human Feedback (RLHF) has become a cornerstone for aligning large language models (LLMs). However, its effectiveness depends on high-quality instruction data. Most existing alignment datasets are either private or require costly human annotation, which limits reproducibility and scalability. Even with Reinforcement Learning from AI Feedback (RLAIF), concerns about data quality remain. Moreover, it is unclear how much data is actually required to fine-tune a base model into a strong instruction-following model. Current approaches often rely on over 300k examples even at the supervised fine-tuning (SFT) stage, yet they still underperform compared to proprietary models, creating barriers for academic and resource-limited communities. To address this gap, we introduce PiKa, a data-efficient family of expert-level alignment datasets. In particular, the PiKa-SFT dataset uses only 30k SFT examples, far fewer than state-of-the-art datasets like Magpie. Through evaluations by fine-tuning Llama-3-8B-Base on PiKa and other public datasets, we show that PiKa-SFT outperforms models trained on much larger data. On AlpacaEval 2.0 and Arena-Hard benchmarks, PiKa-SFT fine-tuning even surpasses the official Llama-3-8B-Instruct model trained on over 10 million proprietary examples. We further extend our study by training the Qwen2.5 series (0.5B to 7B) on PiKa-SFT, achieving consistent gains. These findings demonstrate that high-quality alignment can be achieved with significantly less data, offering a scalable path for open-source LLM alignment. Code and data: https://github.com/SJY8460/PiKa.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.189381"
    },
    {
        "index": "#70",
        "title": "ToolMem: Enhancing Multimodal Agents with Learnable Tool Capability Memory",
        "link": "/arxiv/2510.06664",
        "arxiv_id": "2510.06664",
        "authors": "Yunzhong Xiao, Yangmin Li, Hewei Wang, Yunlong Tang, Zora Zhiruo Wang",
        "summary": "Agents utilizing tools powered by large language models (LLMs) or vision-language models (VLMs) have demonstrated remarkable progress in diverse tasks across text and visual modalities. Unlike traditional tools such as calculators, which give deterministic outputs, neural tools perform uncertainly across task scenarios. While different tools for a task may excel in varied scenarios, existing agents typically rely on fixed tools, thus limiting the flexibility in selecting the most suitable tool for specific tasks. In contrast, humans snowball their understanding of the capabilities of different tools by interacting with them, and apply this knowledge to select the optimal tool when solving a future task. To build agents that similarly benefit from this process, we propose ToolMem that enables agents to develop memories of tool capabilities from previous interactions, by summarizing their strengths and weaknesses and storing them in memory; at inference, the agent can retrieve relevant entries from ToolMem, and select the best tool to solve individual tasks more accurately. We evaluate ToolMem on learning varied text generation and text-to-image generation neural tools. Compared to no-memory, generic agents, we find ToolMem-augmented agents predict tool performance 14.8% and 28.7% more accurately across text and multimodal generation scenarios. Moreover, ToolMem facilitates optimal tool selection among multiple choices by 21% and 24% absolute increases in respective scenarios.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.189831"
    },
    {
        "index": "#71",
        "title": "Aligning Large Language Models via Fully Self-Synthetic Data",
        "link": "/arxiv/2510.06652",
        "arxiv_id": "2510.06652",
        "authors": "Shangjian Yin, Zhepei Wei, Xinyu Zhu, Wei-Lin Chen, Yu Meng",
        "summary": "Traditional reinforcement learning from human feedback (RLHF) for large language models (LLMs) relies on expensive human-annotated datasets, while Reinforcement Learning from AI Feedback (RLAIF) also incurs significant costs, requiring the collection of diverse prompts and corresponding responses, often necessitating external reward models or proprietary models like GPT-4 to annotate preference pairs. In this work, we introduce Self-Alignment Optimization (SAO), a fully self-synthetic framework for LLM alignment, where all training data, including prompts (i.e., user queries), responses, and preferences, are generated by the model itself. Specifically, SAO first instructs the LLM to engage in persona role-play and generate diverse prompts and responses, which are then self-evaluated for preference optimization. Extensive experiments demonstrate that SAO effectively enhances the model's chat capabilities on standard benchmarks like AlpacaEval~2.0, while maintaining strong performance on downstream objective tasks (e.g., question-answering, math reasoning). Our work provides a practical solution for self-improvement in aligning LLMs, and the code for reproducing our results is available at: https://github.com/SJY8460/SAO.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.190278"
    },
    {
        "index": "#72",
        "title": "A Comparative Analysis of Contextual Representation Flow in State-Space and Transformer Architectures",
        "link": "/arxiv/2510.06640",
        "arxiv_id": "2510.06640",
        "authors": "Nhat M. Hoang, Do Xuan Long, Cong-Duy Nguyen, Min-Yen Kan, Luu Anh Tuan",
        "summary": "State Space Models (SSMs) have recently emerged as efficient alternatives to Transformer-Based Models (TBMs) for long-sequence processing, offering linear scaling and lower memory use. Yet, how contextual information flows across layers and tokens in these architectures remains understudied. We present the first unified, token- and layer-level analysis of representation propagation in SSMs and TBMs. Using centered kernel alignment, stability metrics, and probing, we characterize how representations evolve within and across layers. We find a key divergence: TBMs rapidly homogenize token representations, with diversity reemerging only in later layers, while SSMs preserve token uniqueness early but converge to homogenization deeper. Theoretical analysis and parameter randomization further reveal that oversmoothing in TBMs stems from architectural design, whereas in SSMs it arises mainly from training dynamics. These insights clarify the inductive biases of both architectures and inform future model and training designs for long-context reasoning.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.190753"
    },
    {
        "index": "#73",
        "title": "Do Internal Layers of LLMs Reveal Patterns for Jailbreak Detection?",
        "link": "/arxiv/2510.06594",
        "arxiv_id": "2510.06594",
        "authors": "Sri Durga Sai Sowmya Kadali, Evangelos E. Papalexakis",
        "summary": "Jailbreaking large language models (LLMs) has emerged as a pressing concern with the increasing prevalence and accessibility of conversational LLMs. Adversarial users often exploit these models through carefully engineered prompts to elicit restricted or sensitive outputs, a strategy widely referred to as jailbreaking. While numerous defense mechanisms have been proposed, attackers continuously develop novel prompting techniques, and no existing model can be considered fully resistant. In this study, we investigate the jailbreak phenomenon by examining the internal representations of LLMs, with a focus on how hidden layers respond to jailbreak versus benign prompts. Specifically, we analyze the open-source LLM GPT-J and the state-space model Mamba2, presenting preliminary findings that highlight distinct layer-wise behaviors. Our results suggest promising directions for further research on leveraging internal model dynamics for robust jailbreak detection and defense.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.191163"
    },
    {
        "index": "#74",
        "title": "TinyScientist: An Interactive, Extensible, and Controllable Framework for Building Research Agents",
        "link": "/arxiv/2510.06579",
        "arxiv_id": "2510.06579",
        "authors": "Haofei Yu, Keyang Xuan, Fenghai Li, Kunlun Zhu, Zijie Lei, Jiaxun Zhang, Ziheng Qi, Kyle Richardson, Jiaxuan You",
        "summary": "Automatic research with Large Language Models (LLMs) is rapidly gaining importance, driving the development of increasingly complex workflows involving multi-agent systems, planning, tool usage, code execution, and human-agent interaction to accelerate research processes. However, as more researchers and developers begin to use and build upon these tools and platforms, the complexity and difficulty of extending and maintaining such agentic workflows have become a significant challenge, particularly as algorithms and architectures continue to advance. To address this growing complexity, TinyScientist identifies the essential components of the automatic research workflow and proposes an interactive, extensible, and controllable framework that easily adapts to new tools and supports iterative growth. We provide an open-source codebase, an interactive web demonstration, and a PyPI Python package to make state-of-the-art auto-research pipelines broadly accessible to every researcher and developer.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.191657"
    },
    {
        "index": "#75",
        "title": "The Algebra of Meaning: Why Machines Need Montague More Than Moore's Law",
        "link": "/arxiv/2510.06559",
        "arxiv_id": "2510.06559",
        "authors": "Cheonkam Jeong, Sungdo Kim, Jewoo Park",
        "summary": "Contemporary language models are fluent yet routinely mis-handle the types of meaning their outputs entail. We argue that hallucination, brittle moderation, and opaque compliance outcomes are symptoms of missing type-theoretic semantics rather than data or scale limitations. Building on Montague's view of language as typed, compositional algebra, we recast alignment as a parsing problem: natural-language inputs must be compiled into structures that make explicit their descriptive, normative, and legal dimensions under context. We present Savassan, a neuro-symbolic architecture that compiles utterances into Montague-style logical forms and maps them to typed ontologies extended with deontic operators and jurisdictional contexts. Neural components extract candidate structures from unstructured inputs; symbolic components perform type checking, constraint reasoning, and cross-jurisdiction mapping to produce compliance-aware guidance rather than binary censorship. In cross-border scenarios, the system \"parses once\" (e.g., defect claim(product x, company y)) and projects the result into multiple legal ontologies (e.g., defamation risk in KR/JP, protected opinion in US, GDPR checks in EU), composing outcomes into a single, explainable decision. This paper contributes: (i) a diagnosis of hallucination as a type error; (ii) a formal Montague-ontology bridge for business/legal reasoning; and (iii) a production-oriented design that embeds typed interfaces across the pipeline. We outline an evaluation plan using legal reasoning benchmarks and synthetic multi-jurisdiction suites. Our position is that trustworthy autonomy requires compositional typing of meaning, enabling systems to reason about what is described, what is prescribed, and what incurs liability within a unified algebra of meaning.",
        "subjects": "Computation and Language, Artificial Intelligence, Logic in Computer Science",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.192133"
    },
    {
        "index": "#76",
        "title": "Flipping the Dialogue: Training and Evaluating User Language Models",
        "link": "/arxiv/2510.06552",
        "arxiv_id": "2510.06552",
        "authors": "Tarek Naous, Philippe Laban, Wei Xu, Jennifer Neville",
        "summary": "Conversations with LMs involve two participants: a human user leading the conversation, and an LM assistant responding to the user's request. To satisfy this specific role, LMs are post-trained to be helpful assistants -- optimized to produce exhaustive and well-structured responses, free of ambiguity and grammar errors. User utterances, on the other hand, are rarely perfected, with each user phrasing requests in unique ways, sometimes putting in partial effort at each turn and refining on the fly. To evaluate LM performance in realistic settings, prior work simulated users in multi-turn conversations, often prompting an LLM originally trained to be a helpful assistant to act as a user. However, we show that assistant LMs make for poor user simulators, with the surprising finding that better assistants yield worse simulators. Instead, we introduce purpose-built User Language Models (User LMs) - models post-trained to simulate human users in multi-turn conversations. Through various evaluations, we show how User LMs align better with human behavior and achieve better simulation robustness than existing simulation methods. When leveraging User LMs to simulate coding and math conversations, the performance of a strong assistant (GPT-4o) drops from 74.6% to 57.4%, confirming that more realistic simulation environments lead to assistant struggles as they fail to cope with the nuances of users in multi-turn setups.",
        "subjects": "Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.192566"
    },
    {
        "index": "#77",
        "title": "From Acceleration to Saturation: Scaling Behavior of Bootstrapped Language Model Pretraining",
        "link": "/arxiv/2510.06548",
        "arxiv_id": "2510.06548",
        "authors": "Seng Pei Liew, Takuya Kato",
        "summary": "Bootstrapped pretraining, i.e., the reuse of a pretrained base model for further pretraining, such as continual pretraining or model growth, is promising at reducing the cost of training language models from scratch. However, its effectiveness remains unclear, especially when applied to overtrained base models. In this work, we empirically study the scaling behavior of bootstrapped pretraining and find that its scaling efficiency diminishes in a predictable manner: The scaling exponent with respect to second-stage pretraining tokens decreases logarithmically with the number of tokens used to pretrain the base model. The joint dependence on first- and second-stage tokens is accurately modeled by a simple scaling law. Such saturation effect reveals a fundamental trade-off in multi-stage pretraining strategies: the more extensively a model is pretrained, the less additional benefit bootstrapping provides. Our findings provide practical insights for efficient language model training and raise important considerations for the reuse of overtrained models.",
        "subjects": "Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.198118"
    },
    {
        "index": "#78",
        "title": "Webscale-RL: Automated Data Pipeline for Scaling RL Data to Pretraining Levels",
        "link": "/arxiv/2510.06499",
        "arxiv_id": "2510.06499",
        "authors": "Zhepeng Cen, Haolin Chen, Shiyu Wang, Zuxin Liu, Zhiwei Liu, Ding Zhao, Silvio Savarese, Caiming Xiong, Huan Wang, Weiran Yao",
        "summary": "Large Language Models (LLMs) have achieved remarkable success through imitation learning on vast text corpora, but this paradigm creates a training-generation gap and limits robust reasoning. Reinforcement learning (RL) offers a more data-efficient solution capable of bridging this gap, yet its application has been constrained by a critical data bottleneck: existing RL datasets are orders of magnitude smaller and less diverse than web-scale pre-training corpora. To address this, we introduce the Webscale-RL pipeline, a scalable data engine that systematically converts large-scale pre-training documents into millions of diverse, verifiable question-answer pairs for RL. Using this pipeline, we construct the Webscale-RL dataset, containing 1.2 million examples across more than 9 domains. Our experiments show that the model trained on this dataset significantly outperforms continual pretraining and strong data refinement baselines across a suite of benchmarks. Notably, RL training with our dataset proves substantially more efficient, achieving the performance of continual pre-training with up to 100$\\times$ fewer tokens. Our work presents a viable path toward scaling RL to pre-training levels, enabling more capable and efficient language models.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.198682"
    },
    {
        "index": "#79",
        "title": "Test-Time Scaling of Reasoning Models for Machine Translation",
        "link": "/arxiv/2510.06471",
        "arxiv_id": "2510.06471",
        "authors": "Zihao Li, Shaoxiong Ji, Jörg Tiedemann",
        "summary": "Test-time scaling (TTS) has enhanced the performance of Reasoning Models (RMs) on various tasks such as math and coding, yet its efficacy in machine translation (MT) remains underexplored. This paper investigates whether increased inference-time computation improves translation quality. We evaluate 12 RMs across a diverse suite of MT benchmarks spanning multiple domains, examining three scenarios: direct translation, forced-reasoning extrapolation, and post-editing. Our findings show that for general-purpose RMs, TTS provides limited and inconsistent benefits for direct translation, with performance quickly plateauing. However, the effectiveness of TTS is unlocked by domain-specific fine-tuning, which aligns a model's reasoning process with task requirements, leading to consistent improvements up to an optimal, self-determined reasoning depth. We also find that forcing a model to reason beyond its natural stopping point consistently degrades translation quality. In contrast, TTS proves highly effective in a post-editing context, reliably turning self-correction into a beneficial process. These results indicate that the value of inference-time computation in MT lies not in enhancing single-pass translation with general models, but in targeted applications like multi-step, self-correction workflows and in conjunction with task-specialized models.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.199111"
    },
    {
        "index": "#80",
        "title": "Linguistically Informed Tokenization Improves ASR for Underresourced Languages",
        "link": "/arxiv/2510.06461",
        "arxiv_id": "2510.06461",
        "authors": "Massimo Daul, Alessio Tosolini, Claire Bowern",
        "summary": "Automatic speech recognition (ASR) is a crucial tool for linguists aiming to perform a variety of language documentation tasks. However, modern ASR systems use data-hungry transformer architectures, rendering them generally unusable for underresourced languages. We fine-tune a wav2vec2 ASR model on Yan-nhangu, a dormant Indigenous Australian language, comparing the effects of phonemic and orthographic tokenization strategies on performance. In parallel, we explore ASR's viability as a tool in a language documentation pipeline. We find that a linguistically informed phonemic tokenization system substantially improves WER and CER compared to a baseline orthographic tokenization scheme. Finally, we show that hand-correcting the output of an ASR model is much faster than hand-transcribing audio from scratch, demonstrating that ASR can work for underresourced languages.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.199537"
    },
    {
        "index": "#81",
        "title": "A Survey on Agentic Security: Applications, Threats and Defenses",
        "link": "/arxiv/2510.06445",
        "arxiv_id": "2510.06445",
        "authors": "Asif Shahriar, Md Nafiu Rahman, Sadif Ahmed, Farig Sadeque, Md Rizwan Parvez",
        "summary": "The rapid shift from passive LLMs to autonomous LLM-agents marks a new paradigm in cybersecurity. While these agents can act as powerful tools for both offensive and defensive operations, the very agentic context introduces a new class of inherent security risks. In this work we present the first holistic survey of the agentic security landscape, structuring the field around three interdependent pillars: Applications, Threats, and Defenses. We provide a comprehensive taxonomy of over 150 papers, explaining how agents are used, the vulnerabilities they possess, and the countermeasures designed to protect them. A detailed cross-cutting analysis shows emerging trends in agent architecture while revealing critical research gaps in model and modality coverage.",
        "subjects": "Computation and Language, Artificial Intelligence, Cryptography and Security",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.200048"
    },
    {
        "index": "#82",
        "title": "MathRobust-LV: Evaluation of Large Language Models' Robustness to Linguistic Variations in Mathematical Reasoning",
        "link": "/arxiv/2510.06430",
        "arxiv_id": "2510.06430",
        "authors": "Neeraja Kirtane, Yuvraj Khanna, Peter Relan",
        "summary": "Large language models excel on math benchmarks, but their math reasoning robustness to linguistic variation is underexplored. While recent work increasingly treats high-difficulty competitions like the IMO as the gold standard for evaluating reasoning, we believe in comprehensive benchmarking of high school-level math problems in real educational settings. We introduce MathRobust-LV, a test set and evaluation methodology that mirrors how instructors rephrase problems across assessments while keeping difficulty constant: we change surface details (names, contexts, variables) while preserving numerical structure and answers. In contrast to prior efforts that alter problem content or emphasize IMO-level tasks, we focus on high-school-level dataset problems at the difficulty level where models are currently deployed in educational settings: tutoring and assessment systems. In these applications, instructors rephrase identical concepts in varied ways, making linguistic robustness essential for reliable deployment. Although MATH data benchmarking is often regarded as saturated, our experiment on 34 models reveals that accuracy declines when moving from the baseline to the variants. These drops are severe for smaller models (9-11%) while stronger models also show measurable degradation. Frontier models like GPT-5, Gemini-2.5pro remain comparatively stable. Our results highlight that robustness to linguistic variation is a fundamental challenge, exposing reasoning vulnerabilities in models.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.200467"
    },
    {
        "index": "#83",
        "title": "Bridging Discourse Treebanks with a Unified Rhetorical Structure Parser",
        "link": "/arxiv/2510.06427",
        "arxiv_id": "2510.06427",
        "authors": "Elena Chistova",
        "summary": "We introduce UniRST, the first unified RST-style discourse parser capable of handling 18 treebanks in 11 languages without modifying their relation inventories. To overcome inventory incompatibilities, we propose and evaluate two training strategies: Multi-Head, which assigns separate relation classification layer per inventory, and Masked-Union, which enables shared parameter training through selective label masking. We first benchmark monotreebank parsing with a simple yet effective augmentation technique for low-resource settings. We then train a unified model and show that (1) the parameter efficient Masked-Union approach is also the strongest, and (2) UniRST outperforms 16 of 18 mono-treebank baselines, demonstrating the advantages of a single-model, multilingual end-to-end discourse parsing across diverse resources.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.200859"
    },
    {
        "index": "#84",
        "title": "FinLFQA: Evaluating Attributed Text Generation of LLMs in Financial Long-Form Question Answering",
        "link": "/arxiv/2510.06426",
        "arxiv_id": "2510.06426",
        "authors": "Yitao Long, Tiansheng Hu, Yilun Zhao, Arman Cohan, Chen Zhao",
        "summary": "Large Language Models (LLMs) frequently hallucinate to long-form questions, producing plausible yet factually incorrect answers. A common mitigation strategy is to provide attribution to LLM outputs. However, existing benchmarks primarily focus on simple attribution that retrieves supporting textual evidence as references. We argue that in real-world scenarios such as financial applications, attribution goes beyond reference retrieval. We introduce FinLFQA, a benchmark designed to evaluate the ability of LLMs to generate long-form answers to complex financial questions with reliable and nuanced attributions. FinLFQA evaluates three critical aspects of attribution through human annotations: (1) supporting evidence extracted from financial reports, (2) intermediate numerical reasoning steps, and (3) domain-specific financial knowledge that informs the reasoning process. We further provide an automatic evaluation framework covering both answer quality and attribution quality. Through extensive experiments on eight LLMs across multiple attribution-generation paradigms, we find that fine-grained metrics are important to distinguish model capabilities, that end-to-end generation achieves comparable performance to post-hoc approaches, and that iterative refinement only helps when guided by external feedback.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.201313"
    },
    {
        "index": "#85",
        "title": "Instructional Goal-Aligned Question Generation for Student Evaluation in Virtual Lab Settings: How Closely Do LLMs Actually Align?",
        "link": "/arxiv/2510.06411",
        "arxiv_id": "2510.06411",
        "authors": "R. Alexander Knipper, Indrani Dey, Souvika Sarkar, Hari Narayanan, Sadhana Puntambekar, Santu Karmaker",
        "summary": "Virtual Labs offer valuable opportunities for hands-on, inquiry-based science learning, yet teachers often struggle to adapt them to fit their instructional goals. Third-party materials may not align with classroom needs, and developing custom resources can be time-consuming and difficult to scale. Recent advances in Large Language Models (LLMs) offer a promising avenue for addressing these limitations. In this paper, we introduce a novel alignment framework for instructional goal-aligned question generation, enabling teachers to leverage LLMs to produce simulation-aligned, pedagogically meaningful questions through natural language interaction. The framework integrates four components: instructional goal understanding via teacher-LLM dialogue, lab understanding via knowledge unit and relationship analysis, a question taxonomy for structuring cognitive and pedagogical intent, and the TELeR taxonomy for controlling prompt detail. Early design choices were informed by a small teacher-assisted case study, while our final evaluation analyzed over 1,100 questions from 19 open-source LLMs. With goal and lab understanding grounding questions in teacher intent and simulation context, the question taxonomy elevates cognitive demand (open-ended formats and relational types raise quality by 0.29-0.39 points), and optimized TELeR prompts enhance format adherence (80% parsability, >90% adherence). Larger models yield the strongest gains: parsability +37.1%, adherence +25.7%, and average quality +0.8 Likert points.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.201769"
    },
    {
        "index": "#86",
        "title": "Reward Model Perspectives: Whose Opinions Do Reward Models Reward?",
        "link": "/arxiv/2510.06391",
        "arxiv_id": "2510.06391",
        "authors": "Elle",
        "summary": "Reward models (RMs) are central to the alignment of language models (LMs). An RM often serves as a proxy for human preferences to guide downstream LM behavior. However, our understanding of RM behavior is limited. Our work (i) formalizes a framework for measuring the alignment of opinions captured by RMs, (ii) investigates the extent to which RMs demonstrate sociodemographic biases, and (iii) explores the effects of prompting to steer rewards towards the preferences of a target group. We study the subjective and diverse perspectives on controversial topics, which allows us to quantify RM perspectives in terms of their opinions, attitudes, and values. We show that RMs are poorly aligned with several demographic groups and can systematically reward harmful stereotypes, and steering alone is not enough to overcome these limitations. Our findings underscore the need for more careful consideration of RM behavior in model alignment during preference learning to prevent the propagation of unwanted social biases in the language technologies that we use.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.202180"
    },
    {
        "index": "#87",
        "title": "Controllable Stylistic Text Generation with Train-Time Attribute-Regularized Diffusion",
        "link": "/arxiv/2510.06386",
        "arxiv_id": "2510.06386",
        "authors": "Fan Zhou, Chang Tian, Tim Van de Cruys",
        "summary": "Generating stylistic text with specific attributes is a key problem in controllable text generation. Recently, diffusion models have emerged as a powerful paradigm for both visual and textual generation. Existing approaches can be broadly categorized into classifier-free guidance (CFG) and classifier guidance (CG) methods. While CFG effectively preserves semantic content, it often fails to provide effective attribute control. In contrast, CG modifies the denoising trajectory using classifier gradients, enabling better attribute alignment but incurring high computational costs during sampling and suffering from classifier generalization issues. In this work, we propose RegDiff, a regularized diffusion framework that leverages attribute features without requiring a pretrained classifier during sampling, thereby achieving controllable generation with reduced computational costs. Specifically, RegDiff employs a VAE-based encoder--decoder architecture to ensure reconstruction fidelity and a latent diffusion model trained with attribute supervision to enable controllable text generation. Attribute information is injected only during training. Experiments on five datasets spanning multiple stylistic attributes demonstrate that RegDiff outperforms strong baselines in generating stylistic texts. These results validate the effectiveness of RegDiff as an efficient solution for attribute-controllable text diffusion. Our code, datasets, and resources will be released upon publication at https://github.com/xxxx.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.202610"
    },
    {
        "index": "#88",
        "title": "Protecting De-identified Documents from Search-based Linkage Attacks",
        "link": "/arxiv/2510.06383",
        "arxiv_id": "2510.06383",
        "authors": "Pierre Lison, Mark Anderson",
        "summary": "While de-identification models can help conceal the identity of the individual(s) mentioned in a document, they fail to address linkage risks, defined as the potential to map the de-identified text back to its source. One straightforward way to perform such linkages is to extract phrases from the de-identified document and then check their presence in the original dataset. This paper presents a method to counter search-based linkage attacks while preserving the semantic integrity of the text. The method proceeds in two steps. We first construct an inverted index of the N-grams occurring in the document collection, making it possible to efficiently determine which N-grams appear in less than $k$ documents (either alone or in combination with other N-grams). An LLM-based rewriter is then iteratively queried to reformulate those spans until linkage is no longer possible. Experimental results on a collection of court cases show that the method is able to effectively prevent search-based linkages while remaining faithful to the original content.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.208162"
    },
    {
        "index": "#89",
        "title": "Semantic Regexes: Auto-Interpreting LLM Features with a Structured Language",
        "link": "/arxiv/2510.06378",
        "arxiv_id": "2510.06378",
        "authors": "Angie Boggust, Donghao Ren, Yannick Assogba, Dominik Moritz, Arvind Satyanarayan, Fred Hohman",
        "summary": "Automated interpretability aims to translate large language model (LLM) features into human understandable descriptions. However, these natural language feature descriptions are often vague, inconsistent, and require manual relabeling. In response, we introduce semantic regexes, structured language descriptions of LLM features. By combining primitives that capture linguistic and semantic feature patterns with modifiers for contextualization, composition, and quantification, semantic regexes produce precise and expressive feature descriptions. Across quantitative benchmarks and qualitative analyses, we find that semantic regexes match the accuracy of natural language while yielding more concise and consistent feature descriptions. Moreover, their inherent structure affords new types of analyses, including quantifying feature complexity across layers, scaling automated interpretability from insights into individual features to model-wide patterns. Finally, in user studies, we find that semantic regex descriptions help people build accurate mental models of LLM feature activations.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.208623"
    },
    {
        "index": "#90",
        "title": "EverydayMMQA: A Multilingual and Multimodal Framework for Culturally Grounded Spoken Visual QA",
        "link": "/arxiv/2510.06371",
        "arxiv_id": "2510.06371",
        "authors": "Firoj Alam, Ali Ezzat Shahroor, Md. Arid Hasan, Zien Sheikh Ali, Hunzalah Hassan Bhatti, Mohamed Bayan Kmainasi, Shammur Absar Chowdhury, Basel Mousi, Fahim Dalvi, Nadir Durrani, Natasa Milic-Frayling",
        "summary": "Large-scale multimodal models achieve strong results on tasks like Visual Question Answering (VQA), but they often fail when queries require culturally grounded, everyday knowledge, particularly in low-resource and underrepresented languages. To bridge this gap, we introduce Everyday Multimodal and Multilingual QA (EverydayMMQA), a framework for creating large-scale, culturally-grounded datasets for spoken and visual question answering (SVQA). Using this framework, we developed OASIS, a multimodal dataset integrating speech, images, and text. With over ~0.92M images and 14.8M QA pairs, OASIS contains 3.7M spoken questions, enabling four unique input combinations: speech-only, text-only, speech+image, and text+image. Focused on English and Arabic varieties, 18 countries, the dataset content is curated to reflect diverse, real-world situations. OASIS tests models on tasks beyond object recognition that involve pragmatic, commonsense, and culturally aware reasoning. We benchmarked four closed-source models, three open-source models, and one fine-tuned model. EverydayMMQA and OASIS together provide a benchmark and training dataset for building multimodal LLMs for a comprehensive set of everyday tasks within cultural contexts. The framework and dataset will be made publicly available to the community.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.209169"
    },
    {
        "index": "#91",
        "title": "EVALUESTEER: Measuring Reward Model Steerability Towards Values and Preference",
        "link": "/arxiv/2510.06370",
        "arxiv_id": "2510.06370",
        "authors": "Kshitish Ghate, Andy Liu, Devansh Jain, Taylor Sorensen, Atoosa Kasirzadeh, Aylin Caliskan, Mona T. Diab, Maarten Sap",
        "summary": "As large language models (LLMs) are deployed globally, creating pluralistic systems that can accommodate the diverse preferences and values of users worldwide becomes essential. We introduce EVALUESTEER, a benchmark to measure LLMs' and reward models' (RMs) steerability towards users' value and stylistic preference profiles grounded in psychology and human-LLM interaction literature. To address the gap in existing datasets that do not support controlled evaluations of RM steering, we synthetically generated 165,888 preference pairs -- systematically varying pairs along 4 value dimensions (traditional, secular-rational, survival, and self-expression) and 4 style dimensions (verbosity, readability, confidence, and warmth). We use EVALUESTEER to evaluate whether, given a user profile and a pair of candidate value-laden and style-laden responses, LLMs and RMs are able to select the output that aligns with the user's preferences. We evaluate six open-source and proprietary LLMs and RMs under sixteen systematic prompting conditions and six preference comparison scenarios. Notably, our results show that, when given the user's full profile of values and stylistic preferences, the best models achieve <75% accuracy at choosing the correct response, in contrast to >99% accuracy when only relevant style and value preferences are provided. EVALUESTEER thus highlights the limitations of current RMs at identifying and adapting to relevant user profile information, and provides a challenging testbed for developing RMs that can be steered towards diverse human values and preferences.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.209660"
    },
    {
        "index": "#92",
        "title": "LLM Bias Detection and Mitigation through the Lens of Desired Distributions",
        "link": "/arxiv/2510.06354",
        "arxiv_id": "2510.06354",
        "authors": "Ingroj Shrestha, Padmini Srinivasan",
        "summary": "Although prior work on bias mitigation has focused on promoting social equality and demographic parity, less attention has been given to aligning LLM's outputs to desired distributions. For example, we might want to align a model with real-world distributions to support factual grounding. Thus, we define bias as deviation from a desired distribution, which may be an equal or real-world distribution, depending on application goals. We propose a weighted adaptive loss based fine-tuning method that aligns LLM's gender-profession output distribution with the desired distribution, while preserving language modeling capability. Using 3 profession sets -- male-dominated, female-dominated, and gender-balanced -- derived from U.S. labor statistics (2024), we assess both our adaptive method for reflecting reality and a non-adaptive variant for equality. Across three masked language models, bias is observed under both distributions. We achieve near-complete mitigation under equality and 30-75% reduction under real-world settings. Autoregressive LLMs show no bias under equality but notable bias under real-world settings, with the Llama Instruct models (3.2-3B, 3.1-8B) achieving a 50-62% reduction.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.210079"
    },
    {
        "index": "#93",
        "title": "Type and Complexity Signals in Multilingual Question Representations",
        "link": "/arxiv/2510.06304",
        "arxiv_id": "2510.06304",
        "authors": "Robin Kokot, Wessel Poelman",
        "summary": "This work investigates how a multilingual transformer model represents morphosyntactic properties of questions. We introduce the Question Type and Complexity (QTC) dataset with sentences across seven languages, annotated with type information and complexity metrics including dependency length, tree depth, and lexical density. Our evaluation extends probing methods to regression labels with selectivity controls to quantify gains in generalizability. We compare layer-wise probes on frozen Glot500-m (Imani et al., 2023) representations against subword TF-IDF baselines, and a fine-tuned model. Results show that statistical features classify questions effectively in languages with explicit marking, while neural probes capture fine-grained structural complexity patterns better. We use these results to evaluate when contextual representations outperform statistical baselines and whether parameter updates reduce the availability of pre-trained linguistic information.",
        "subjects": "Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.210491"
    },
    {
        "index": "#94",
        "title": "Reproducibility Study of \"XRec: Large Language Models for Explainable Recommendation\"",
        "link": "/arxiv/2510.06275",
        "arxiv_id": "2510.06275",
        "authors": "Ranjan Mishra, Julian I. Bibo, Quinten van Engelen, Henk Schaapman",
        "summary": "In this study, we reproduced the work done in the paper \"XRec: Large Language Models for Explainable Recommendation\" by Ma et al. (2024). The original authors introduced XRec, a model-agnostic collaborative instruction-tuning framework that enables large language models (LLMs) to provide users with comprehensive explanations of generated recommendations. Our objective was to replicate the results of the original paper, albeit using Llama 3 as the LLM for evaluation instead of GPT-3.5-turbo. We built on the source code provided by Ma et al. (2024) to achieve our goal. Our work extends the original paper by modifying the input embeddings or deleting the output embeddings of XRec's Mixture of Experts module. Based on our results, XRec effectively generates personalized explanations and its stability is improved by incorporating collaborative information. However, XRec did not consistently outperform all baseline models in every metric. Our extended analysis further highlights the importance of the Mixture of Experts embeddings in shaping the explanation structures, showcasing how collaborative signals interact with language modeling. Through our work, we provide an open-source evaluation implementation that enhances accessibility for researchers and practitioners alike. Our complete code repository can be found at https://github.com/julianbibo/xrec-reproducibility.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-06",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.210951"
    },
    {
        "index": "#95",
        "title": "Language models for longitudinal analysis of abusive content in Billboard Music Charts",
        "link": "/arxiv/2510.06266",
        "arxiv_id": "2510.06266",
        "authors": "Rohitash Chandra, Yathin Suresh, Divyansh Raj Sinha, Sanchit Jindal",
        "summary": "There is no doubt that there has been a drastic increase in abusive and sexually explicit content in music, particularly in Billboard Music Charts. However, there is a lack of studies that validate the trend for effective policy development, as such content has harmful behavioural changes in children and youths. In this study, we utilise deep learning methods to analyse songs (lyrics) from Billboard Charts of the United States in the last seven decades. We provide a longitudinal study using deep learning and language models and review the evolution of content using sentiment analysis and abuse detection, including sexually explicit content. Our results show a significant rise in explicit content in popular music from 1990 onwards. Furthermore, we find an increasing prevalence of songs with lyrics containing profane, sexually explicit, and otherwise inappropriate language. The longitudinal analysis of the ability of language models to capture nuanced patterns in lyrical content, reflecting shifts in societal norms and language use over time.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-06",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.211415"
    },
    {
        "index": "#96",
        "title": "A Comprehensive Survey of Hallucination in Large Language Models: Causes, Detection, and Mitigation",
        "link": "/arxiv/2510.06265",
        "arxiv_id": "2510.06265",
        "authors": "Aisha Alansari, Hamzah Luqman",
        "summary": "Large language models (LLMs) have transformed natural language processing, achieving remarkable performance across diverse tasks. However, their impressive fluency often comes at the cost of producing false or fabricated information, a phenomenon known as hallucination. Hallucination refers to the generation of content by an LLM that is fluent and syntactically correct but factually inaccurate or unsupported by external evidence. Hallucinations undermine the reliability and trustworthiness of LLMs, especially in domains requiring factual accuracy. This survey provides a comprehensive review of research on hallucination in LLMs, with a focus on causes, detection, and mitigation. We first present a taxonomy of hallucination types and analyze their root causes across the entire LLM development lifecycle, from data collection and architecture design to inference. We further examine how hallucinations emerge in key natural language generation tasks. Building on this foundation, we introduce a structured taxonomy of detection approaches and another taxonomy of mitigation strategies. We also analyze the strengths and limitations of current detection and mitigation approaches and review existing evaluation benchmarks and metrics used to quantify LLMs hallucinations. Finally, we outline key open challenges and promising directions for future research, providing a foundation for the development of more truthful and trustworthy LLMs.",
        "subjects": "Computation and Language",
        "date": "2025-10-05",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.211858"
    },
    {
        "index": "#97",
        "title": "Dual-stage and Lightweight Patient Chart Summarization for Emergency Physicians",
        "link": "/arxiv/2510.06263",
        "arxiv_id": "2510.06263",
        "authors": "Jiajun Wu, Swaleh Zaidi, Braden Teitge, Henry Leung, Jiayu Zhou, Jessalyn Holodinsky, Steve Drew",
        "summary": "Electronic health records (EHRs) contain extensive unstructured clinical data that can overwhelm emergency physicians trying to identify critical information. We present a two-stage summarization system that runs entirely on embedded devices, enabling offline clinical summarization while preserving patient privacy. In our approach, a dual-device architecture first retrieves relevant patient record sections using the Jetson Nano-R (Retrieve), then generates a structured summary on another Jetson Nano-S (Summarize), communicating via a lightweight socket link. The summarization output is two-fold: (1) a fixed-format list of critical findings, and (2) a context-specific narrative focused on the clinician's query. The retrieval stage uses locally stored EHRs, splits long notes into semantically coherent sections, and searches for the most relevant sections per query. The generation stage uses a locally hosted small language model (SLM) to produce the summary from the retrieved text, operating within the constraints of two NVIDIA Jetson devices. We first benchmarked six open-source SLMs under 7B parameters to identify viable models. We incorporated an LLM-as-Judge evaluation mechanism to assess summary quality in terms of factual accuracy, completeness, and clarity. Preliminary results on MIMIC-IV and de-identified real EHRs demonstrate that our fully offline system can effectively produce useful summaries in under 30 seconds.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-05",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.212346"
    },
    {
        "index": "#98",
        "title": "Prakriti200: A Questionnaire-Based Dataset of 200 Ayurvedic Prakriti Assessments",
        "link": "/arxiv/2510.06262",
        "arxiv_id": "2510.06262",
        "authors": "Aryan Kumar Singh, Janvi Singh",
        "summary": "This dataset provides responses to a standardized, bilingual (English-Hindi) Prakriti Assessment Questionnaire designed to evaluate the physical, physiological, and psychological characteristics of individuals according to classical Ayurvedic principles. The questionnaire consists of 24 multiple-choice items covering body features, appetite, sleep patterns, energy levels, and temperament. It was developed following AYUSH/CCRAS guidelines to ensure comprehensive and accurate data collection. All questions are mandatory and neutrally phrased to minimize bias, and dosha labels (Vata, Pitta, Kapha) are hidden from participants. Data were collected via a Google Forms deployment, enabling automated scoring of responses to map individual traits to dosha-specific scores. The resulting dataset provides a structured platform for research in computational intelligence, Ayurvedic studies, and personalized health analytics, supporting analysis of trait distributions, correlations, and predictive modeling. It can also serve as a reference for future Prakriti-based studies and the development of intelligent health applications.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-05",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.212794"
    },
    {
        "index": "#99",
        "title": "Scalable multilingual PII annotation for responsible AI in LLMs",
        "link": "/arxiv/2510.06250",
        "arxiv_id": "2510.06250",
        "authors": "Bharti Meena, Joanna Skubisz, Harshit Rajgarhia, Nand Dave, Kiran Ganesh, Shivali Dalmia, Abhishek Mukherji, Vasudevan Sundarababu, Olga Pospelova",
        "summary": "As Large Language Models (LLMs) gain wider adoption, ensuring their reliable handling of Personally Identifiable Information (PII) across diverse regulatory contexts has become essential. This work introduces a scalable multilingual data curation framework designed for high-quality PII annotation across 13 underrepresented locales, covering approximately 336 locale-specific PII types. Our phased, human-in-the-loop annotation methodology combines linguistic expertise with rigorous quality assurance, leading to substantial improvements in recall and false positive rates from pilot, training, and production phases. By leveraging inter-annotator agreement metrics and root-cause analysis, the framework systematically uncovers and resolves annotation inconsistencies, resulting in high-fidelity datasets suitable for supervised LLM fine-tuning. Beyond reporting empirical gains, we highlight common annotator challenges in multilingual PII labeling and demonstrate how iterative, analytics-driven pipelines can enhance both annotation quality and downstream model reliability.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-03",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.239019"
    },
    {
        "index": "#100",
        "title": "TRepLiNa: Layer-wise CKA+REPINA Alignment Improves Low-Resource Machine Translation in Aya-23 8B",
        "link": "/arxiv/2510.06249",
        "arxiv_id": "2510.06249",
        "authors": "Toshiki Nakai, Ravi Kiran Chikkala, Lena Sophie Oberkircher, Nicholas Jennings, Natalia Skachkova, Tatiana Anikina, Jesujoba Oluwadara Alabi",
        "summary": "The 2025 Multimodal Models for Low-Resource Contexts and Social Impact (MMLoSo) Language Challenge addresses one of India's most pressing linguistic gaps: the lack of resources for its diverse low-resource languages (LRLs). In this study, we investigate whether enforcing cross-lingual similarity in specific internal layers of a decoder-only multilingual large language model (LLM) can improve translation quality from LRL to high-resource language (HRL). Specifically, we combine Centered Kernel Alignment (CKA), a similarity metric that encourages representations of different languages to align, with REPINA, a regularization method that constrains parameter updates to remain close to the pretrained model, into a joint method we call TRepLiNa. In this research project, we experiment with zero-shot, few-shot, and fine-tuning settings using Aya-23 8B with QLoRA across MMLoSo shared task language pairs (Mundari, Santali, Bhili) with Hindi/English pivots. Our results show that aligning mid-level layers using TRepLiNa (CKA+REPINA) is a low-cost, practical approach to improving LRL translation, especially in data-scarce settings.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-03",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.239807"
    },
    {
        "index": "#101",
        "title": "Evaluating Embedding Frameworks for Scientific Domain",
        "link": "/arxiv/2510.06244",
        "arxiv_id": "2510.06244",
        "authors": "Nouman Ahmed, Ronin Wu, Victor Botev",
        "summary": "Finding an optimal word representation algorithm is particularly important in terms of domain specific data, as the same word can have different meanings and hence, different representations depending on the domain and context. While Generative AI and transformer architecture does a great job at generating contextualized embeddings for any given work, they are quite time and compute extensive, especially if we were to pre-train such a model from scratch. In this work, we focus on the scientific domain and finding the optimal word representation algorithm along with the tokenization method that could be used to represent words in the scientific domain. The goal of this research is two fold: 1) finding the optimal word representation and tokenization methods that can be used in downstream scientific domain NLP tasks, and 2) building a comprehensive evaluation suite that could be used to evaluate various word representation and tokenization algorithms (even as new ones are introduced) in the scientific domain. To this end, we build an evaluation suite consisting of several downstream tasks and relevant datasets for each task. Furthermore, we use the constructed evaluation suite to test various word representation and tokenization algorithms.",
        "subjects": "Computation and Language, Artificial Intelligence, Machine Learning",
        "date": "2025-10-03",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.240489"
    },
    {
        "index": "#102",
        "title": "CoT Referring: Improving Referring Expression Tasks with Grounded Reasoning",
        "link": "/arxiv/2510.06243",
        "arxiv_id": "2510.06243",
        "authors": "Qihua Dong, Luis Figueroa, Handong Zhao, Kushal Kafle, Jason Kuen, Zhihong Ding, Scott Cohen, Yun Fu",
        "summary": "Referring Expression Comprehension and Segmentation are critical tasks for assessing the integration of language understanding and image comprehension, serving as benchmarks for Multimodal Large Language Models (MLLMs) capabilities. To address these challenges, we propose a new strategy, CoT Referring, which enhances model reasoning across modalities through a structured, chain-of-thought training data structure. Our approach systematically parses textual structures to a sequential referring step, where in each step it identifies relationships and ensures consistent reference alignment, thereby improving accuracy in complex query scenarios. We restructure the training data to enforce a new output form, providing new annotations for existing datasets and compiling an evaluation benchmark from existing resources. This benchmark is designed explicitly for complex referring cases. We also integrate detection and segmentation capabilities into a unified MLLM framework, training it with a novel adaptive weighted loss to optimize performance. Experimental results on our curated benchmark and RefCOCO/+/g demonstrate the effectiveness of our approach, with a notable increase of 2.5%+ over baseline models.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-03",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.241263"
    },
    {
        "index": "#103",
        "title": "Transparent Reference-free Automated Evaluation of Open-Ended User Survey Responses",
        "link": "/arxiv/2510.06242",
        "arxiv_id": "2510.06242",
        "authors": "Subin An, Yugyeong Ji, Junyoung Kim, Heejin Kook, Yang Lu, Josh Seltzer",
        "summary": "Open-ended survey responses provide valuable insights in marketing research, but low-quality responses not only burden researchers with manual filtering but also risk leading to misleading conclusions, underscoring the need for effective evaluation. Existing automatic evaluation methods target LLM-generated text and inadequately assess human-written responses with their distinct characteristics. To address such characteristics, we propose a two-stage evaluation framework specifically designed for human survey responses. First, gibberish filtering removes nonsensical responses. Then, three dimensions-effort, relevance, and completeness-are evaluated using LLM capabilities, grounded in empirical analysis of real-world survey data. Validation on English and Korean datasets shows that our framework not only outperforms existing metrics but also demonstrates high practical applicability for real-world applications such as response quality prediction and response rejection, showing strong correlations with expert assessment.",
        "subjects": "Computation and Language, Artificial Intelligence",
        "date": "2025-10-03",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.241978"
    },
    {
        "index": "#104",
        "title": "Knowledge Graph-Guided Multi-Agent Distillation for Reliable Industrial Question Answering with Datasets",
        "link": "/arxiv/2510.06240",
        "arxiv_id": "2510.06240",
        "authors": "Jiqun Pan, Zhenke Duan, Jiani Tu, Anzhi Cheng, Yanqing Wang",
        "summary": "Industrial question-answering (QA) systems require higher safety and reliability than general-purpose dialogue models, as errors in high-risk scenarios such as equipment fault diagnosis can have severe consequences. Although multi-agent large language models enhance reasoning depth, they suffer from uncontrolled iterations and unverifiable outputs, and conventional distillation methods struggle to transfer collaborative reasoning capabilities to lightweight, deployable student models. To address these challenges, we propose Knowledge Graph-guided Multi-Agent System Distillation (KG-MASD). Our approach formulates distillation as a Markov Decision Process and incorporates a knowledge graph as a verifiable structured prior to enrich state representation and ensure convergence. By integrating collaborative reasoning with knowledge grounding, KG-MASD generates high-confidence instruction-tuning data and jointly distills reasoning depth and verifiability into compact student models suitable for edge deployment. Experiments on an industrial QA dataset show that KG-MASD improves accuracy by 2.4 per cent to 20.1 per cent over baselines and significantly enhances reliability, enabling trustworthy AI deployment in safety-critical industrial scenarios. Code and data are available at https://github.com/erwinmsmith/KG-MAD/.",
        "subjects": "Computation and Language, Artificial Intelligence, Databases",
        "date": "2025-10-03",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.242697"
    },
    {
        "index": "#105",
        "title": "OpenStaxQA: A multilingual dataset based on open-source college textbooks",
        "link": "/arxiv/2510.06239",
        "arxiv_id": "2510.06239",
        "authors": "Pranav Gupta",
        "summary": "We present OpenStaxQA, an evaluation benchmark specific to college-level educational applications based on 43 open-source college textbooks in English, Spanish, and Polish, available under a permissive Creative Commons license. We finetune and evaluate large language models (LLMs) with approximately 7 billion parameters on this dataset using quantized low rank adapters (QLoRa). Additionally we also perform a zero-shot evaluation on the AI2 reasoning challenge dev dataset in order to check if OpenStaxQA can lead to an improved performance on other tasks. We also discuss broader impacts relevant to datasets such as OpenStaxQA.",
        "subjects": "Computation and Language",
        "date": "2025-10-03",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.243296"
    },
    {
        "index": "#106",
        "title": "AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs",
        "link": "/arxiv/2510.07293",
        "arxiv_id": "2510.07293",
        "authors": "Peize He, Zichen Wen, Yubo Wang, Yuxuan Wang, Xiaoqian Liu, Jiajie Huang, Zehui Lei, Zhuangcheng Gu, Xiangqi Jin, Jiabing Yang, Kai Li, Zhifei Liu, Weijia Li, Cunxiang Wang, Conghui He, Linfeng Zhang",
        "summary": "Processing long-form audio is a major challenge for Large Audio Language models (LALMs). These models struggle with the quadratic cost of attention ($O(N^2)$) and with modeling long-range temporal dependencies. Existing audio benchmarks are built mostly from short clips and do not evaluate models in realistic long context settings. To address this gap, we introduce AudioMarathon, a benchmark designed to evaluate both understanding and inference efficiency on long-form audio. AudioMarathon provides a diverse set of tasks built upon three pillars: long-context audio inputs with durations ranging from 90.0 to 300.0 seconds, which correspond to encoded sequences of 2,250 to 7,500 audio tokens, respectively, full domain coverage across speech, sound, and music, and complex reasoning that requires multi-hop inference. We evaluate state-of-the-art LALMs and observe clear performance drops as audio length grows. We also study acceleration techniques and analyze the trade-offs of token pruning and KV cache eviction. The results show large gaps across current LALMs and highlight the need for better temporal reasoning and memory-efficient architectures. We believe AudioMarathon will drive the audio and multimodal research community to develop more advanced audio understanding models capable of solving complex audio tasks.",
        "subjects": "Sound, Artificial Intelligence, Computation and Language, Audio and Speech Processing",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.249413"
    },
    {
        "index": "#107",
        "title": "Machines in the Crowd? Measuring the Footprint of Machine-Generated Text on Reddit",
        "link": "/arxiv/2510.07226",
        "arxiv_id": "2510.07226",
        "authors": "Lucio La Cava, Luca Maria Aiello, Andrea Tagarelli",
        "summary": "Generative Artificial Intelligence is reshaping online communication by enabling large-scale production of Machine-Generated Text (MGT) at low cost. While its presence is rapidly growing across the Web, little is known about how MGT integrates into social media environments. In this paper, we present the first large-scale characterization of MGT on Reddit. Using a state-of-the-art statistical method for detection of MGT, we analyze over two years of activity (2022-2024) across 51 subreddits representative of Reddit's main community types such as information seeking, social support, and discussion. We study the concentration of MGT across communities and over time, and compared MGT to human-authored text in terms of social signals it expresses and engagement it receives. Our very conservative estimate of MGT prevalence indicates that synthetic text is marginally present on Reddit, but it can reach peaks of up to 9% in some communities in some months. MGT is unevenly distributed across communities, more prevalent in subreddits focused on technical knowledge and social support, and often concentrated in the activity of a small fraction of users. MGT also conveys distinct social signals of warmth and status giving typical of language of AI assistants. Despite these stylistic differences, MGT achieves engagement levels comparable than human-authored content and in a few cases even higher, suggesting that AI-generated text is becoming an organic component of online social discourse. This work offers the first perspective on the MGT footprint on Reddit, paving the way for new investigations involving platform governance, detection strategies, and community dynamics.",
        "subjects": "Social and Information Networks, Computation and Language, Computers and Society, Physics and Society",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.250013"
    },
    {
        "index": "#109",
        "title": "The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas",
        "link": "/arxiv/2510.07091",
        "arxiv_id": "2510.07091",
        "authors": "Baixuan Xu, Tianshi Zheng, Zhaowei Wang, Hong Ting Tsang, Weiqi Wang, Tianqing Fang, Yangqiu Song",
        "summary": "Enabling LLMs to effectively operate long-horizon task which requires long-term planning and multiple interactions is essential for open-world autonomy. Conventional methods adopt planning with actions where a executable action list would be provided as reference. However, this action representation choice would be impractical when the environment action space is combinatorial exploded (e.g., open-ended real world). This naturally leads to a question: As environmental action space scales, what is the optimal action representation for long-horizon agents? In this paper, we systematically study the effectiveness of two different action representations. The first one is conventional planning with actions (PwA) which is predominantly adopted for its effectiveness on existing benchmarks. The other one is planning with schemas (PwS) which instantiate an action schema into action lists (e.g., \"move [OBJ] to [OBJ]\" -> \"move apple to desk\") to ensure concise action space and reliable scalability. This alternative is motivated by its alignment with human cognition and its compliance with environment-imposed action format restriction. We propose cognitive bandwidth perspective as a conceptual framework to qualitatively understand the differences between these two action representations and empirically observe a representation-choice inflection point between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve as evidence of the need for scalable representations. We further conduct controlled experiments to study how the location of this inflection point interacts with different model capacities: stronger planning proficiency shifts the inflection rightward, whereas better schema instantiation shifts it leftward. Finally, noting the suboptimal performance of PwS agents, we provide an actionable guide for building more capable PwS agents for better scalable autonomy.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.251040"
    },
    {
        "index": "#110",
        "title": "RedTWIZ: Diverse LLM Red Teaming via Adaptive Attack Planning",
        "link": "/arxiv/2510.06994",
        "arxiv_id": "2510.06994",
        "authors": "Artur Horal, Daniel Pina, Henrique Paz, Iago Paulo, João Soares, Rafael Ferreira, Diogo Tavares, Diogo Glória-Silva, João Magalhães, David Semedo",
        "summary": "This paper presents the vision, scientific contributions, and technical details of RedTWIZ: an adaptive and diverse multi-turn red teaming framework, to audit the robustness of Large Language Models (LLMs) in AI-assisted software development. Our work is driven by three major research streams: (1) robust and systematic assessment of LLM conversational jailbreaks; (2) a diverse generative multi-turn attack suite, supporting compositional, realistic and goal-oriented jailbreak conversational strategies; and (3) a hierarchical attack planner, which adaptively plans, serializes, and triggers attacks tailored to specific LLM's vulnerabilities. Together, these contributions form a unified framework -- combining assessment, attack generation, and strategic planning -- to comprehensively evaluate and expose weaknesses in LLMs' robustness. Extensive evaluation is conducted to systematically assess and analyze the performance of the overall system and each component. Experimental results demonstrate that our multi-turn adversarial attack strategies can successfully lead state-of-the-art LLMs to produce unsafe generations, highlighting the pressing need for more research into enhancing LLM's robustness.",
        "subjects": "Cryptography and Security, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.251582"
    },
    {
        "index": "#111",
        "title": "VelLMes: A high-interaction AI-based deception framework",
        "link": "/arxiv/2510.06975",
        "arxiv_id": "2510.06975",
        "authors": "Muris Sladić, Veronica Valeros, Carlos Catania, Sebastian Garcia",
        "summary": "There are very few SotA deception systems based on Large Language Models. The existing ones are limited only to simulating one type of service, mainly SSH shells. These systems - but also the deception technologies not based on LLMs - lack an extensive evaluation that includes human attackers. Generative AI has recently become a valuable asset for cybersecurity researchers and practitioners, and the field of cyber-deception is no exception. Researchers have demonstrated how LLMs can be leveraged to create realistic-looking honeytokens, fake users, and even simulated systems that can be used as honeypots. This paper presents an AI-based deception framework called VelLMes, which can simulate multiple protocols and services such as SSH Linux shell, MySQL, POP3, and HTTP. All of these can be deployed and used as honeypots, thus VelLMes offers a variety of choices for deception design based on the users' needs. VelLMes is designed to be attacked by humans, so interactivity and realism are key for its performance. We evaluate the generative capabilities and the deception capabilities. Generative capabilities were evaluated using unit tests for LLMs. The results of the unit tests show that, with careful prompting, LLMs can produce realistic-looking responses, with some LLMs having a 100% passing rate. In the case of the SSH Linux shell, we evaluated deception capabilities with 89 human attackers. The results showed that about 30% of the attackers thought that they were interacting with a real system when they were assigned an LLM-based honeypot. Lastly, we deployed 10 instances of the SSH Linux shell honeypot on the Internet to capture real-life attacks. Analysis of these attacks showed us that LLM honeypots simulating Linux shells can perform well against unstructured and unexpected attacks on the Internet, responding correctly to most of the issued commands.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.252098"
    },
    {
        "index": "#112",
        "title": "Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces",
        "link": "/arxiv/2510.06953",
        "arxiv_id": "2510.06953",
        "authors": "Minju Gwak, Guijin Son, Jaehyung Kim",
        "summary": "The Uniform Information Density (UID) hypothesis suggests that effective communication maintains a stable flow of information. In this work, we revisit this principle in the context of large language model (LLM) reasoning traces, asking whether step-level uniformity reflects reasoning quality. To this end, we propose an entropy-based stepwise information density metric and introduce two complementary measures of uniformity, local and global uniformity scores. Across the experiments on six different reasoning benchmarks, we find that step-level uniformity not only provides a strong theoretical lens but also yields practical performance benefits; for example, selecting reasoning traces with more uniform information density at the step-level improves accuracy by 10-32\\% relative gains over baselines at AIME2025. Our analysis further reveals that correct reasoning traces tend to avoid sharp information density spikes, while incorrect traces exhibit irregular information bursts. These results demonstrate that UID-inspired information density measures outperform alternative internal signals as predictors of reasoning quality. Results highlight the uniformity of the information density as a robust diagnostic and selection criterion for building more reliable and accurate reasoning systems.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.252549"
    },
    {
        "index": "#113",
        "title": "Crossing Domains without Labels: Distant Supervision for Term Extraction",
        "link": "/arxiv/2510.06838",
        "arxiv_id": "2510.06838",
        "authors": "Elena Senger, Yuri Campbell, Rob van der Goot, Barbara Plank",
        "summary": "Automatic Term Extraction (ATE) is a critical component in downstream NLP tasks such as document tagging, ontology construction and patent analysis. Current state-of-the-art methods require expensive human annotation and struggle with domain transfer, limiting their practical deployment. This highlights the need for more robust, scalable solutions and realistic evaluation settings. To address this, we introduce a comprehensive benchmark spanning seven diverse domains, enabling performance evaluation at both the document- and corpus-levels. Furthermore, we propose a robust LLM-based model that outperforms both supervised cross-domain encoder models and few-shot learning baselines and performs competitively with its GPT-4o teacher on this benchmark. The first step of our approach is generating psuedo-labels with this black-box LLM on general and scientific domains to ensure generalizability. Building on this data, we fine-tune the first LLMs for ATE. To further enhance document-level consistency, oftentimes needed for downstream tasks, we introduce lightweight post-hoc heuristics. Our approach exceeds previous approaches on 5/7 domains with an average improvement of 10 percentage points. We release our dataset and fine-tuned models to support future research in this area.",
        "subjects": "Information Retrieval, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.253004"
    },
    {
        "index": "#114",
        "title": "Exposing Citation Vulnerabilities in Generative Engines",
        "link": "/arxiv/2510.06823",
        "arxiv_id": "2510.06823",
        "authors": "Riku Mochizuki, Shusuke Komatsu, Souta Noguchi, Kazuto Ataka",
        "summary": "We analyze answers generated by generative engines (GEs) from the perspectives of citation publishers and the content-injection barrier, defined as the difficulty for attackers to manipulate answers to user prompts by placing malicious content on the web. GEs integrate two functions: web search and answer generation that cites web pages using large language models. Because anyone can publish information on the web, GEs are vulnerable to poisoning attacks. Existing studies of citation evaluation focus on how faithfully answer content reflects cited sources, leaving unexamined which web sources should be selected as citations to defend against poisoning attacks. To fill this gap, we introduce evaluation criteria that assess poisoning threats using the citation information contained in answers. Our criteria classify the publisher attributes of citations to estimate the content-injection barrier thereby revealing the threat of poisoning attacks in current GEs. We conduct experiments in political domains in Japan and the United States (U.S.) using our criteria and show that citations from official party websites (primary sources) are approximately \\(25\\%\\)--\\(45\\%\\) in the U.S. and \\(60\\%\\)--\\(65\\%\\) in Japan, indicating that U.S. political answers are at higher risk of poisoning attacks. We also find that sources with low content-injection barriers are frequently cited yet are poorly reflected in answer content. To mitigate this threat, we discuss how publishers of primary sources can increase exposure of their web content in answers and show that well-known techniques are limited by language differences.",
        "subjects": "Cryptography and Security, Computation and Language, Information Retrieval",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.253488"
    },
    {
        "index": "#115",
        "title": "GPT-5 Model Corrected GPT-4V's Chart Reading Errors, Not Prompting",
        "link": "/arxiv/2510.06782",
        "arxiv_id": "2510.06782",
        "authors": "Kaichun Yang, Jian Chen",
        "summary": "We present a quantitative evaluation to understand the effect of zero-shot large-language model (LLMs) and prompting uses on chart reading tasks. We asked LLMs to answer 107 visualization questions to compare inference accuracies between the agentic GPT-5 and multimodal GPT-4V, for difficult image instances, where GPT-4V failed to produce correct answers. Our results show that model architecture dominates the inference accuracy: GPT5 largely improved accuracy, while prompt variants yielded only small effects. Pre-registration of this work is available here: https://osf.io/u78td/?view_only=6b075584311f48e991c39335c840ded3; the Google Drive materials are here:https://drive.google.com/file/d/1ll8WWZDf7cCNcfNWrLViWt8GwDNSvVrp/view.",
        "subjects": "Human-Computer Interaction, Computation and Language, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.259068"
    },
    {
        "index": "#116",
        "title": "Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration",
        "link": "/arxiv/2510.06761",
        "arxiv_id": "2510.06761",
        "authors": "Zhi Zhang, Yan Liu, Zhejing Hu, Gong Chen, Sheng-hua Zhong, Jiannong Cao",
        "summary": "Automating the end-to-end scientific research process poses a fundamental challenge: it requires both evolving high-level plans that are novel and sound, and executing these plans correctly amidst dynamic and uncertain conditions. To address this bilevel challenge, we propose a novel Double-Loop Multi-Agent (DLMA) framework to solve the given research problem automatically. The leader loop, composed of professor agents, is responsible for evolving research plans. It employs an evolutionary algorithm through involvement, improvement, and integration meetings to iteratively generate and refine a pool of research proposals, exploring the solution space effectively. The follower loop, composed of doctoral student agents, is responsible for executing the best-evolved plan. It dynamically adjusts the plan during implementation via pre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is well-supported by contextual and external observations. Extensive experiments on benchmarks like ACLAward and Laboratory show that DLMA generates research papers that achieve state-of-the-art scores in automated evaluation, significantly outperforming strong baselines. Ablation studies confirm the critical roles of both loops, with evolution driving novelty and execution ensuring soundness.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.310910"
    },
    {
        "index": "#117",
        "title": "Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities",
        "link": "/arxiv/2510.06743",
        "arxiv_id": "2510.06743",
        "authors": "Maria Levchenko",
        "summary": "Digital humanities scholars increasingly use Large Language Models for historical document digitization, yet lack appropriate evaluation frameworks for LLM-based OCR. Traditional metrics fail to capture temporal biases and period-specific errors crucial for historical corpus creation. We present an evaluation methodology for LLM-based historical OCR, addressing contamination risks and systematic biases in diplomatic transcription. Using 18th-century Russian Civil font texts, we introduce novel metrics including Historical Character Preservation Rate (HCPR) and Archaic Insertion Rate (AIR), alongside protocols for contamination control and stability testing. We evaluate 12 multimodal LLMs, finding that Gemini and Qwen models outperform traditional OCR while exhibiting over-historicization: inserting archaic characters from incorrect historical periods. Post-OCR correction degrades rather than improves performance. Our methodology provides digital humanities practitioners with guidelines for model selection and quality assessment in historical corpus digitization.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.311559"
    },
    {
        "index": "#118",
        "title": "Differentially Private Synthetic Text Generation for Retrieval-Augmented Generation (RAG)",
        "link": "/arxiv/2510.06719",
        "arxiv_id": "2510.06719",
        "authors": "Junki Mori, Kazuya Kakizaki, Taiki Miyagawa, Jun Sakuma",
        "summary": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by grounding them in external knowledge. However, its application in sensitive domains is limited by privacy risks. Existing private RAG methods typically rely on query-time differential privacy (DP), which requires repeated noise injection and leads to accumulated privacy loss. To address this issue, we propose DP-SynRAG, a framework that uses LLMs to generate differentially private synthetic RAG databases. Unlike prior methods, the synthetic text can be reused once created, thereby avoiding repeated noise injection and additional privacy costs. To preserve essential information for downstream RAG tasks, DP-SynRAG extends private prediction, which instructs LLMs to generate text that mimics subsampled database records in a DP manner. Experiments show that DP-SynRAG achieves superior performanec to the state-of-the-art private RAG systems while maintaining a fixed privacy budget, offering a scalable solution for privacy-preserving RAG.",
        "subjects": "Cryptography and Security, Computation and Language, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.312282"
    },
    {
        "index": "#119",
        "title": "XLSR-Kanformer: A KAN-Intergrated model for Synthetic Speech Detection",
        "link": "/arxiv/2510.06706",
        "arxiv_id": "2510.06706",
        "authors": "Phuong Tuan Dat, Tran Huy Dat",
        "summary": "Recent advancements in speech synthesis technologies have led to increasingly sophisticated spoofing attacks, posing significant challenges for automatic speaker verification systems. While systems based on self-supervised learning (SSL) models, particularly the XLSR-Conformer architecture, have demonstrated remarkable performance in synthetic speech detection, there remains room for architectural improvements. In this paper, we propose a novel approach that replaces the traditional Multi-Layer Perceptron (MLP) in the XLSR-Conformer model with a Kolmogorov-Arnold Network (KAN), a powerful universal approximator based on the Kolmogorov-Arnold representation theorem. Our experimental results on ASVspoof2021 demonstrate that the integration of KAN to XLSR-Conformer model can improve the performance by 60.55% relatively in Equal Error Rate (EER) LA and DF sets, further achieving 0.70% EER on the 21LA set. Besides, the proposed replacement is also robust to various SSL architectures. These findings suggest that incorporating KAN into SSL-based models is a promising direction for advances in synthetic speech detection.",
        "subjects": "Sound, Computation and Language, Audio and Speech Processing",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.312934"
    },
    {
        "index": "#120",
        "title": "Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation",
        "link": "/arxiv/2510.06605",
        "arxiv_id": "2510.06605",
        "authors": "Shuo Shao, Yiming Li, Hongwei Yao, Yifei Chen, Yuchen Yang, Zhan Qin",
        "summary": "The substantial investment required to develop Large Language Models (LLMs) makes them valuable intellectual property, raising significant concerns about copyright protection. LLM fingerprinting has emerged as a key technique to address this, which aims to verify a model's origin by extracting an intrinsic, unique signature (a \"fingerprint\") and comparing it to that of a source model to identify illicit copies. However, existing black-box fingerprinting methods often fail to generate distinctive LLM fingerprints. This ineffectiveness arises because black-box methods typically rely on model outputs, which lose critical information about the model's unique parameters due to the usage of non-linear functions. To address this, we first leverage Fisher Information Theory to formally demonstrate that the gradient of the model's input is a more informative feature for fingerprinting than the output. Based on this insight, we propose ZeroPrint, a novel method that approximates these information-rich gradients in a black-box setting using zeroth-order estimation. ZeroPrint overcomes the challenge of applying this to discrete text by simulating input perturbations via semantic-preserving word substitutions. This operation allows ZeroPrint to estimate the model's Jacobian matrix as a unique fingerprint. Experiments on the standard benchmark show ZeroPrint achieves a state-of-the-art effectiveness and robustness, significantly outperforming existing black-box methods.",
        "subjects": "Cryptography and Security, Artificial Intelligence, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.313679"
    },
    {
        "index": "#121",
        "title": "The Markovian Thinker",
        "link": "/arxiv/2510.06557",
        "arxiv_id": "2510.06557",
        "authors": "Milad Aghajohari, Kamran Chitsaz, Amirhossein Kazemnejad, Sarath Chandar, Alessandro Sordoni, Aaron Courville, Siva Reddy",
        "summary": "Reinforcement learning (RL) has recently become a strong recipe for training reasoning LLMs that produce long chains of thought (LongCoT). Yet the standard RL \"thinking environment\", where the state is the prompt plus all prior reasoning tokens, makes the state unbounded and forces attention-based policies to pay quadratic compute as thoughts lengthen. We revisit the environment itself. We propose Markovian Thinking, a paradigm in which the policy advances reasoning while conditioning on a constant-size state, decoupling thinking length from context size. As an immediate consequence this yields linear compute with constant memory. We instantiate this idea with Delethink, an RL environment that structures reasoning into fixed-size chunks. Within each chunk, the model thinks as usual; at the boundary, the environment resets the context and reinitializes the prompt with a short carryover. Through RL, the policy learns to write a textual state near the end of each chunk sufficient for seamless continuation of reasoning after reset. Trained in this environment, an R1-Distill 1.5B model reasons in 8K-token chunks yet thinks up to 24K tokens, matching or surpassing LongCoT-RL trained with a 24K budget. With test-time scaling, Delethink continues to improve where LongCoT plateaus. The effect of linear compute is substantial: we empirically estimate at 96K average thinking length LongCoT-RL costs 27 H100-months vs. 7 for Delethink. Analysis at RL initialization shows off-the-shelf reasoning models (1.5B-120B) often sample Markovian traces zero-shot across diverse benchmarks, providing positive samples that make RL effective at scale. Our results show that redesigning the thinking environment is a powerful lever: it enables very long reasoning without quadratic overhead and opens a path toward efficient, scalable reasoning LLMs.",
        "subjects": "Machine Learning, Artificial Intelligence, Computation and Language",
        "date": "2025-10-08",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.314428"
    },
    {
        "index": "#122",
        "title": "PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles",
        "link": "/arxiv/2510.06475",
        "arxiv_id": "2510.06475",
        "authors": "Yitao Long, Yuru Jiang, Hongjun Liu, Yilun Zhao, Jingchen Sun, Yiqiu Shen, Chen Zhao, Arman Cohan, Dennis Shasha",
        "summary": "This work investigates the reasoning and planning capabilities of foundation models and their scalability in complex, dynamic environments. We introduce PuzzlePlex, a benchmark designed to assess these capabilities through a diverse set of puzzles. PuzzlePlex consists of 15 types of puzzles, including deterministic and stochastic games of varying difficulty, as well as single-player and two-player scenarios. The PuzzlePlex framework provides a comprehensive environment for each game, and supports extensibility to generate more challenging instances as foundation models evolve. Additionally, we implement customized game-playing strategies for comparison. Building on this benchmark, we develop fine-grained metrics to measure performance and conduct an in-depth analysis of frontier foundation models across two settings: instruction-based and code-based. Furthermore, we systematically investigate their scaling limits. Our findings show that reasoning models outperform others in instruction-based settings, while code-based execution presents greater challenges but offers a scalable and efficient alternative. PuzzlePlex enables targeted evaluation and guides future improvements in reasoning, planning, and generalization for foundation models.",
        "subjects": "Artificial Intelligence, Computation and Language",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.315195"
    },
    {
        "index": "#123",
        "title": "Asking For It: Question-Answering for Predicting Rule Infractions in Online Content Moderation",
        "link": "/arxiv/2510.06350",
        "arxiv_id": "2510.06350",
        "authors": "Mattia Samory, Diana Pamfile, Andrew To, Shruti Phadke",
        "summary": "Online communities rely on a mix of platform policies and community-authored rules to define acceptable behavior and maintain order. However, these rules vary widely across communities, evolve over time, and are enforced inconsistently, posing challenges for transparency, governance, and automation. In this paper, we model the relationship between rules and their enforcement at scale, introducing ModQ, a novel question-answering framework for rule-sensitive content moderation. Unlike prior classification or generation-based approaches, ModQ conditions on the full set of community rules at inference time and identifies which rule best applies to a given comment. We implement two model variants - extractive and multiple-choice QA - and train them on large-scale datasets from Reddit and Lemmy, the latter of which we construct from publicly available moderation logs and rule descriptions. Both models outperform state-of-the-art baselines in identifying moderation-relevant rule violations, while remaining lightweight and interpretable. Notably, ModQ models generalize effectively to unseen communities and rules, supporting low-resource moderation settings and dynamic governance environments.",
        "subjects": "Computers and Society, Artificial Intelligence, Computation and Language, Human-Computer Interaction, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.321089"
    },
    {
        "index": "#124",
        "title": "AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning",
        "link": "/arxiv/2510.06261",
        "arxiv_id": "2510.06261",
        "authors": "Zhanke Zhou, Chentao Cao, Xiao Feng, Xuan Li, Zongze Li, Xiangyu Lu, Jiangchao Yao, Weikai Huang, Linrui Xu, Tian Cheng, Guanyu Jiang, Yiming Zheng, Brando Miranda, Tongliang Liu, Sanmi Koyejo, Masashi Sugiyama, Bo Han",
        "summary": "We present AlphaApollo, a self-evolving agentic reasoning system that aims to address two bottlenecks in foundation model (FM) reasoning-limited model-intrinsic capacity and unreliable test-time iteration. AlphaApollo orchestrates multiple models with professional tools to enable deliberate, verifiable reasoning. It couples (i) a computation tool (Python with numerical and symbolic libraries) and (ii) a retrieval tool (task-relevant external information) to execute exact calculations and ground decisions. The system further supports multi-round, multi-model solution evolution via a shared state map that records candidates, executable checks, and feedback for iterative refinement. In evaluations on AIME 2024/2025 across multiple models, AlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32 for Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for Llama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool calls are successfully executed, with consistent outperformance of non-tool baselines, thereby lifting the capability ceiling of FMs. More empirical results and implementation details will be updated at https://github.com/tmlr-group/AlphaApollo.",
        "subjects": "Artificial Intelligence, Computation and Language, Machine Learning",
        "date": "2025-10-05",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.321759"
    },
    {
        "index": "#125",
        "title": "CML-Bench: A Framework for Evaluating and Enhancing LLM-Powered Movie Scripts Generation",
        "link": "/arxiv/2510.06231",
        "arxiv_id": "2510.06231",
        "authors": "Mingzhe Zheng, Dingjie Song, Guanyu Zhou, Jun You, Jiahao Zhan, Xuran Ma, Xinyuan Song, Ser-Nam Lim, Qifeng Chen, Harry Yang",
        "summary": "Large Language Models (LLMs) have demonstrated remarkable proficiency in generating highly structured texts. However, while exhibiting a high degree of structural organization, movie scripts demand an additional layer of nuanced storytelling and emotional depth-the 'soul' of compelling cinema-that LLMs often fail to capture. To investigate this deficiency, we first curated CML-Dataset, a dataset comprising (summary, content) pairs for Cinematic Markup Language (CML), where 'content' consists of segments from esteemed, high-quality movie scripts and 'summary' is a concise description of the content. Through an in-depth analysis of the intrinsic multi-shot continuity and narrative structures within these authentic scripts, we identified three pivotal dimensions for quality assessment: Dialogue Coherence (DC), Character Consistency (CC), and Plot Reasonableness (PR). Informed by these findings, we propose the CML-Bench, featuring quantitative metrics across these dimensions. CML-Bench effectively assigns high scores to well-crafted, human-written scripts while concurrently pinpointing the weaknesses in screenplays generated by LLMs. To further validate our benchmark, we introduce CML-Instruction, a prompting strategy with detailed instructions on character dialogue and event logic, to guide LLMs to generate more structured and cinematically sound scripts. Extensive experiments validate the effectiveness of our benchmark and demonstrate that LLMs guided by CML-Instruction generate higher-quality screenplays, with results aligned with human preferences.",
        "subjects": "Computer Vision and Pattern Recognition, Computation and Language",
        "date": "2025-10-01",
        "category": "cs.CL",
        "crawl_time": "2025-10-09T19:59:14.322314"
    },
    {
        "index": "#1",
        "title": "h1: Bootstrapping LLMs to Reason over Longer Horizons via Reinforcement Learning",
        "link": "/arxiv/2510.07312",
        "arxiv_id": "2510.07312",
        "authors": "Sumeet Ramesh Motwani, Alesia Ivanova, Ziyang Cai, Philip Torr, Riashat Islam, Shital Shah, Christian Schroeder de Witt, Charles London",
        "summary": "Large language models excel at short-horizon reasoning tasks, but performance drops as reasoning horizon lengths increase. Existing approaches to combat this rely on inference-time scaffolding or costly step-level supervision, neither of which scales easily. In this work, we introduce a scalable method to bootstrap long-horizon reasoning capabilities using only existing, abundant short-horizon data. Our approach synthetically composes simple problems into complex, multi-step dependency chains of arbitrary length. We train models on this data using outcome-only rewards under a curriculum that automatically increases in complexity, allowing RL training to be scaled much further without saturating. Empirically, our method generalizes remarkably well: curriculum training on composed 6th-grade level math problems (GSM8K) boosts accuracy on longer, competition-level benchmarks (GSM-Symbolic, MATH-500, AIME) by up to 2.06x. Importantly, our long-horizon improvements are significantly higher than baselines even at high pass@k, showing that models can learn new reasoning paths under RL. Theoretically, we show that curriculum RL with outcome rewards achieves an exponential improvement in sample complexity over full-horizon training, providing training signal comparable to dense supervision. h1 therefore introduces an efficient path towards scaling RL for long-horizon problems using only existing data.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.408045"
    },
    {
        "index": "#2",
        "title": "MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline",
        "link": "/arxiv/2510.07307",
        "arxiv_id": "2510.07307",
        "authors": "Rushi Qiang, Yuchen Zhuang, Anikait Singh, Percy Liang, Chao Zhang, Sherry Yang, Bo Dai",
        "summary": "While Language Models (LMs) have made significant progress in automating machine learning engineering (MLE), the acquisition of high-quality MLE training data is significantly constrained. Current MLE benchmarks suffer from low scalability and limited applicability because they rely on static, manually curated tasks, demanding extensive time and manual effort to produce. We introduce MLE-Smith, a fully automated multi-agent pipeline, to transform raw datasets into competition-style MLE challenges through an efficient generate-verify-execute paradigm for scaling MLE tasks with verifiable quality, real-world usability, and rich diversity. The proposed multi-agent pipeline in MLE-Smith drives structured task design and standardized refactoring, coupled with a hybrid verification mechanism that enforces strict structural rules and high-level semantic soundness. It further validates empirical solvability and real-world fidelity through interactive execution. We apply MLE-Smith to 224 of real-world datasets and generate 606 tasks spanning multiple categories, objectives, and modalities, demonstrating that MLE-Smith can work effectively across a wide range of real-world datasets. Evaluation on the generated tasks shows that the performance of eight mainstream and cutting-edge LLMs on MLE-Smith tasks is strongly correlated with their performance on carefully human-designed tasks, highlighting the effectiveness of the MLE-Smith to scaling up MLE tasks, while maintaining task quality.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.408732"
    },
    {
        "index": "#3",
        "title": "MolGA: Molecular Graph Adaptation with Pre-trained 2D Graph Encoder",
        "link": "/arxiv/2510.07289",
        "arxiv_id": "2510.07289",
        "authors": "Xingtong Yu, Chang Zhou, Xinming Zhang, Yuan Fang",
        "summary": "Molecular graph representation learning is widely used in chemical and biomedical research. While pre-trained 2D graph encoders have demonstrated strong performance, they overlook the rich molecular domain knowledge associated with submolecular instances (atoms and bonds). While molecular pre-training approaches incorporate such knowledge into their pre-training objectives, they typically employ designs tailored to a specific type of knowledge, lacking the flexibility to integrate diverse knowledge present in molecules. Hence, reusing widely available and well-validated pre-trained 2D encoders, while incorporating molecular domain knowledge during downstream adaptation, offers a more practical alternative. In this work, we propose MolGA, which adapts pre-trained 2D graph encoders to downstream molecular applications by flexibly incorporating diverse molecular domain knowledge. First, we propose a molecular alignment strategy that bridge the gap between pre-trained topological representations with domain-knowledge representations. Second, we introduce a conditional adaptation mechanism that generates instance-specific tokens to enable fine-grained integration of molecular domain knowledge for downstream tasks. Finally, we conduct extensive experiments on eleven public datasets, demonstrating the effectiveness of MolGA.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.409317"
    },
    {
        "index": "#4",
        "title": "Evolutionary Profiles for Protein Fitness Prediction",
        "link": "/arxiv/2510.07286",
        "arxiv_id": "2510.07286",
        "authors": "Jigang Fan, Xiaoran Jiao, Shengdong Lin, Zhanming Liang, Weian Mao, Chenchen Jing, Hao Chen, Chunhua Shen",
        "summary": "Predicting the fitness impact of mutations is central to protein engineering but constrained by limited assays relative to the size of sequence space. Protein language models (pLMs) trained with masked language modeling (MLM) exhibit strong zero-shot fitness prediction; we provide a unifying view by interpreting natural evolution as implicit reward maximization and MLM as inverse reinforcement learning (IRL), in which extant sequences act as expert demonstrations and pLM log-odds serve as fitness estimates. Building on this perspective, we introduce EvoIF, a lightweight model that integrates two complementary sources of evolutionary signal: (i) within-family profiles from retrieved homologs and (ii) cross-family structural-evolutionary constraints distilled from inverse folding logits. EvoIF fuses sequence-structure representations with these profiles via a compact transition block, yielding calibrated probabilities for log-odds scoring. On ProteinGym (217 mutational assays; >2.5M mutants), EvoIF and its MSA-enabled variant achieve state-of-the-art or competitive performance while using only 0.15% of the training data and fewer parameters than recent large models. Ablations confirm that within-family and cross-family profiles are complementary, improving robustness across function types, MSA depths, taxa, and mutation depths. The codes will be made publicly available at https://github.com/aim-uofa/EvoIF.",
        "subjects": "Machine Learning, Artificial Intelligence, Biomolecules, Quantitative Methods",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.410035"
    },
    {
        "index": "#5",
        "title": "GTCN-G: A Residual Graph-Temporal Fusion Network for Imbalanced Intrusion Detection (Preprint)",
        "link": "/arxiv/2510.07285",
        "arxiv_id": "2510.07285",
        "authors": "Tianxiang Xu, Zhichao Wen, Xinyu Zhao, Qi Hu, Yan Li, Chang Liu",
        "summary": "The escalating complexity of network threats and the inherent class imbalance in traffic data present formidable challenges for modern Intrusion Detection Systems (IDS). While Graph Neural Networks (GNNs) excel in modeling topological structures and Temporal Convolutional Networks (TCNs) are proficient in capturing time-series dependencies, a framework that synergistically integrates both while explicitly addressing data imbalance remains an open challenge. This paper introduces a novel deep learning framework, named Gated Temporal Convolutional Network and Graph (GTCN-G), engineered to overcome these limitations. Our model uniquely fuses a Gated TCN (G-TCN) for extracting hierarchical temporal features from network flows with a Graph Convolutional Network (GCN) designed to learn from the underlying graph structure. The core innovation lies in the integration of a residual learning mechanism, implemented via a Graph Attention Network (GAT). This mechanism preserves original feature information through residual connections, which is critical for mitigating the class imbalance problem and enhancing detection sensitivity for rare malicious activities (minority classes). We conducted extensive experiments on two public benchmark datasets, UNSW-NB15 and ToN-IoT, to validate our approach. The empirical results demonstrate that the proposed GTCN-G model achieves state-of-the-art performance, significantly outperforming existing baseline models in both binary and multi-class classification tasks.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.410689"
    },
    {
        "index": "#6",
        "title": "Dynamic Regret Bounds for Online Omniprediction with Long Term Constraints",
        "link": "/arxiv/2510.07266",
        "arxiv_id": "2510.07266",
        "authors": "Yahav Bechavod, Jiuyao Lu, Aaron Roth",
        "summary": "We present an algorithm guaranteeing dynamic regret bounds for online omniprediction with long term constraints. The goal in this recently introduced problem is for a learner to generate a sequence of predictions which are broadcast to a collection of downstream decision makers. Each decision maker has their own utility function, as well as a vector of constraint functions, each mapping their actions and an adversarially selected state to reward or constraint violation terms. The downstream decision makers select actions \"as if\" the state predictions are correct, and the goal of the learner is to produce predictions such that all downstream decision makers choose actions that give them worst-case utility guarantees while minimizing worst-case constraint violation. Within this framework, we give the first algorithm that obtains simultaneous \\emph{dynamic regret} guarantees for all of the agents -- where regret for each agent is measured against a potentially changing sequence of actions across rounds of interaction, while also ensuring vanishing constraint violation for each agent. Our results do not require the agents themselves to maintain any state -- they only solve one-round constrained optimization problems defined by the prediction made at that round.",
        "subjects": "Machine Learning, Computer Science and Game Theory",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.411276"
    },
    {
        "index": "#7",
        "title": "Test-Time Graph Search for Goal-Conditioned Reinforcement Learning",
        "link": "/arxiv/2510.07257",
        "arxiv_id": "2510.07257",
        "authors": "Evgenii Opryshko, Junwei Quan, Claas Voelcker, Yilun Du, Igor Gilitschenski",
        "summary": "Offline goal-conditioned reinforcement learning (GCRL) trains policies that reach user-specified goals at test time, providing a simple, unsupervised, domain-agnostic way to extract diverse behaviors from unlabeled, reward-free datasets. Nonetheless, long-horizon decision making remains difficult for GCRL agents due to temporal credit assignment and error accumulation, and the offline setting amplifies these effects. To alleviate this issue, we introduce Test-Time Graph Search (TTGS), a lightweight planning approach to solve the GCRL task. TTGS accepts any state-space distance or cost signal, builds a weighted graph over dataset states, and performs fast search to assemble a sequence of subgoals that a frozen policy executes. When the base learner is value-based, the distance is derived directly from the learned goal-conditioned value function, so no handcrafted metric is needed. TTGS requires no changes to training, no additional supervision, no online interaction, and no privileged information, and it runs entirely at inference. On the OGBench benchmark, TTGS improves success rates of multiple base learners on challenging locomotion tasks, demonstrating the benefit of simple metric-guided test-time planning for offline GCRL.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.411927"
    },
    {
        "index": "#8",
        "title": "Discriminative Feature Feedback with General Teacher Classes",
        "link": "/arxiv/2510.07245",
        "arxiv_id": "2510.07245",
        "authors": "Omri Bar Oz, Tosca Lechner, Sivan Sabato",
        "summary": "We study the theoretical properties of the interactive learning protocol Discriminative Feature Feedback (DFF) (Dasgupta et al., 2018). The DFF learning protocol uses feedback in the form of discriminative feature explanations. We provide the first systematic study of DFF in a general framework that is comparable to that of classical protocols such as supervised learning and online learning. We study the optimal mistake bound of DFF in the realizable and the non-realizable settings, and obtain novel structural results, as well as insights into the differences between Online Learning and settings with richer feedback such as DFF. We characterize the mistake bound in the realizable setting using a new notion of dimension. In the non-realizable setting, we provide a mistake upper bound and show that it cannot be improved in general. Our results show that unlike Online Learning, in DFF the realizable dimension is insufficient to characterize the optimal non-realizable mistake bound or the existence of no-regret algorithms.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.417607"
    },
    {
        "index": "#9",
        "title": "A Broader View of Thompson Sampling",
        "link": "/arxiv/2510.07208",
        "arxiv_id": "2510.07208",
        "authors": "Yanlin Qu, Hongseok Namkoong, Assaf Zeevi",
        "summary": "Thompson Sampling is one of the most widely used and studied bandit algorithms, known for its simple structure, low regret performance, and solid theoretical guarantees. Yet, in stark contrast to most other families of bandit algorithms, the exact mechanism through which posterior sampling (as introduced by Thompson) is able to \"properly\" balance exploration and exploitation, remains a mystery. In this paper we show that the core insight to address this question stems from recasting Thompson Sampling as an online optimization algorithm. To distill this, a key conceptual tool is introduced, which we refer to as \"faithful\" stationarization of the regret formulation. Essentially, the finite horizon dynamic optimization problem is converted into a stationary counterpart which \"closely resembles\" the original objective (in contrast, the classical infinite horizon discounted formulation, that leads to the Gittins index, alters the problem and objective in too significant a manner). The newly crafted time invariant objective can be studied using Bellman's principle which leads to a time invariant optimal policy. When viewed through this lens, Thompson Sampling admits a simple online optimization form that mimics the structure of the Bellman-optimal policy, and where greediness is regularized by a measure of residual uncertainty based on point-biserial correlation. This answers the question of how Thompson Sampling balances exploration-exploitation, and moreover, provides a principled framework to study and further improve Thompson's original idea.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.418034"
    },
    {
        "index": "#10",
        "title": "Guided by the Experts: Provable Feature Learning Dynamic of Soft-Routed Mixture-of-Experts",
        "link": "/arxiv/2510.07205",
        "arxiv_id": "2510.07205",
        "authors": "Fangshuo Liao, Anastasios Kyrillidis",
        "summary": "Mixture-of-Experts (MoE) architectures have emerged as a cornerstone of modern AI systems. In particular, MoEs route inputs dynamically to specialized experts whose outputs are aggregated through weighted summation. Despite their widespread application, theoretical understanding of MoE training dynamics remains limited to either separate expert-router optimization or only top-1 routing scenarios with carefully constructed datasets. This paper advances MoE theory by providing convergence guarantees for joint training of soft-routed MoE models with non-linear routers and experts in a student-teacher framework. We prove that, with moderate over-parameterization, the student network undergoes a feature learning phase, where the router's learning process is ``guided'' by the experts, that recovers the teacher's parameters. Moreover, we show that a post-training pruning can effectively eliminate redundant neurons, followed by a provably convergent fine-tuning process that reaches global optimality. To our knowledge, our analysis is the first to bring novel insights in understanding the optimization landscape of the MoE architecture.",
        "subjects": "Machine Learning, Optimization and Control",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.418456"
    },
    {
        "index": "#11",
        "title": "An in-depth look at approximation via deep and narrow neural networks",
        "link": "/arxiv/2510.07202",
        "arxiv_id": "2510.07202",
        "authors": "Joris Dommel, Sven A. Wegner",
        "summary": "In 2017, Hanin and Sellke showed that the class of arbitrarily deep, real-valued, feed-forward and ReLU-activated networks of width w forms a dense subset of the space of continuous functions on R^n, with respect to the topology of uniform convergence on compact sets, if and only if w>n holds. To show the necessity, a concrete counterexample function f:R^n->R was used. In this note we actually approximate this very f by neural networks in the two cases w=n and w=n+1 around the aforementioned threshold. We study how the approximation quality behaves if we vary the depth and what effect (spoiler alert: dying neurons) cause that behavior.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.418868"
    },
    {
        "index": "#12",
        "title": "Poisoning Attacks on LLMs Require a Near-constant Number of Poison Samples",
        "link": "/arxiv/2510.07192",
        "arxiv_id": "2510.07192",
        "authors": "Alexandra Souly, Javier Rando, Ed Chapman, Xander Davies, Burak Hasircioglu, Ezzeldin Shereen, Carlos Mougan, Vasilios Mavroudis, Erik Jones, Chris Hicks, Nicholas Carlini, Yarin Gal, Robert Kirk",
        "summary": "Poisoning attacks can compromise the safety of large language models (LLMs) by injecting malicious documents into their training data. Existing work has studied pretraining poisoning assuming adversaries control a percentage of the training corpus. However, for large models, even small percentages translate to impractically large amounts of data. This work demonstrates for the first time that poisoning attacks instead require a near-constant number of documents regardless of dataset size. We conduct the largest pretraining poisoning experiments to date, pretraining models from 600M to 13B parameters on chinchilla-optimal datasets (6B to 260B tokens). We find that 250 poisoned documents similarly compromise models across all model and dataset sizes, despite the largest models training on more than 20 times more clean data. We also run smaller-scale experiments to ablate factors that could influence attack success, including broader ratios of poisoned to clean data and non-random distributions of poisoned samples. Finally, we demonstrate the same dynamics for poisoning during fine-tuning. Altogether, our results suggest that injecting backdoors through data poisoning may be easier for large models than previously believed as the number of poisons required does not scale up with model size, highlighting the need for more research on defences to mitigate this risk in future models.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.419419"
    },
    {
        "index": "#13",
        "title": "Bridged Clustering for Representation Learning: Semi-Supervised Sparse Bridging",
        "link": "/arxiv/2510.07182",
        "arxiv_id": "2510.07182",
        "authors": "Patrick Peixuan Ye, Chen Shani, Ellen Vitercik",
        "summary": "We introduce Bridged Clustering, a semi-supervised framework to learn predictors from any unpaired input $X$ and output $Y$ dataset. Our method first clusters $X$ and $Y$ independently, then learns a sparse, interpretable bridge between clusters using only a few paired examples. At inference, a new input $x$ is assigned to its nearest input cluster, and the centroid of the linked output cluster is returned as the prediction $\\hat{y}$. Unlike traditional SSL, Bridged Clustering explicitly leverages output-only data, and unlike dense transport-based methods, it maintains a sparse and interpretable alignment. Through theoretical analysis, we show that with bounded mis-clustering and mis-bridging rates, our algorithm becomes an effective and efficient predictor. Empirically, our method is competitive with SOTA methods while remaining simple, model-agnostic, and highly label-efficient in low-supervision settings.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.419871"
    },
    {
        "index": "#14",
        "title": "ELMUR: External Layer Memory with Update/Rewrite for Long-Horizon RL",
        "link": "/arxiv/2510.07151",
        "arxiv_id": "2510.07151",
        "authors": "Egor Cherepanov, Alexey K. Kovalev, Aleksandr I. Panov",
        "summary": "Real-world robotic agents must act under partial observability and long horizons, where key cues may appear long before they affect decision making. However, most modern approaches rely solely on instantaneous information, without incorporating insights from the past. Standard recurrent or transformer models struggle with retaining and leveraging long-term dependencies: context windows truncate history, while naive memory extensions fail under scale and sparsity. We propose ELMUR (External Layer Memory with Update/Rewrite), a transformer architecture with structured external memory. Each layer maintains memory embeddings, interacts with them via bidirectional cross-attention, and updates them through an Least Recently Used (LRU) memory module using replacement or convex blending. ELMUR extends effective horizons up to 100,000 times beyond the attention window and achieves a 100% success rate on a synthetic T-Maze task with corridors up to one million steps. In POPGym, it outperforms baselines on more than half of the tasks. On MIKASA-Robo sparse-reward manipulation tasks with visual observations, it nearly doubles the performance of strong baselines. These results demonstrate that structured, layer-local external memory offers a simple and scalable approach to decision making under partial observability.",
        "subjects": "Machine Learning, Artificial Intelligence, Robotics",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.420332"
    },
    {
        "index": "#16",
        "title": "DPMM-CFL: Clustered Federated Learning via Dirichlet Process Mixture Model Nonparametric Clustering",
        "link": "/arxiv/2510.07132",
        "arxiv_id": "2510.07132",
        "authors": "Mariona Jaramillo-Civill, Peng Wu, Pau Closas",
        "summary": "Clustered Federated Learning (CFL) improves performance under non-IID client heterogeneity by clustering clients and training one model per cluster, thereby balancing between a global model and fully personalized models. However, most CFL methods require the number of clusters K to be fixed a priori, which is impractical when the latent structure is unknown. We propose DPMM-CFL, a CFL algorithm that places a Dirichlet Process (DP) prior over the distribution of cluster parameters. This enables nonparametric Bayesian inference to jointly infer both the number of clusters and client assignments, while optimizing per-cluster federated objectives. This results in a method where, at each round, federated updates and cluster inferences are coupled, as presented in this paper. The algorithm is validated on benchmark datasets under Dirichlet and class-split non-IID partitions.",
        "subjects": "Machine Learning, Distributed, Parallel, and Cluster Computing, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.421304"
    },
    {
        "index": "#17",
        "title": "Non-Asymptotic Analysis of Efficiency in Conformalized Regression",
        "link": "/arxiv/2510.07093",
        "arxiv_id": "2510.07093",
        "authors": "Yunzhen Yao, Lie He, Michael Gastpar",
        "summary": "Conformal prediction provides prediction sets with coverage guarantees. The informativeness of conformal prediction depends on its efficiency, typically quantified by the expected size of the prediction set. Prior work on the efficiency of conformalized regression commonly treats the miscoverage level $\\alpha$ as a fixed constant. In this work, we establish non-asymptotic bounds on the deviation of the prediction set length from the oracle interval length for conformalized quantile and median regression trained via SGD, under mild assumptions on the data distribution. Our bounds of order $\\mathcal{O}(1/\\sqrt{n} + 1/(\\alpha^2 n) + 1/\\sqrt{m} + \\exp(-\\alpha^2 m))$ capture the joint dependence of efficiency on the proper training set size $n$, the calibration set size $m$, and the miscoverage level $\\alpha$. The results identify phase transitions in convergence rates across different regimes of $\\alpha$, offering guidance for allocating data to control excess prediction set length. Empirical results are consistent with our theoretical findings.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.421741"
    },
    {
        "index": "#18",
        "title": "Generative World Modelling for Humanoids: 1X World Model Challenge Technical Report",
        "link": "/arxiv/2510.07092",
        "arxiv_id": "2510.07092",
        "authors": "Riccardo Mereu, Aidan Scannell, Yuxin Hou, Yi Zhao, Aditya Jitta, Antonio Dominguez, Luigi Acerbi, Amos Storkey, Paul Chang",
        "summary": "World models are a powerful paradigm in AI and robotics, enabling agents to reason about the future by predicting visual observations or compact latent states. The 1X World Model Challenge introduces an open-source benchmark of real-world humanoid interaction, with two complementary tracks: sampling, focused on forecasting future image frames, and compression, focused on predicting future discrete latent codes. For the sampling track, we adapt the video generation foundation model Wan-2.2 TI2V-5B to video-state-conditioned future frame prediction. We condition the video generation on robot states using AdaLN-Zero, and further post-train the model using LoRA. For the compression track, we train a Spatio-Temporal Transformer model from scratch. Our models achieve 23.0 dB PSNR in the sampling task and a Top-500 CE of 6.6386 in the compression task, securing 1st place in both challenges.",
        "subjects": "Machine Learning, Artificial Intelligence, Robotics",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.422289"
    },
    {
        "index": "#19",
        "title": "Non-Stationary Online Structured Prediction with Surrogate Losses",
        "link": "/arxiv/2510.07086",
        "arxiv_id": "2510.07086",
        "authors": "Shinsaku Sakaue, Han Bao, Yuzhou Cao",
        "summary": "Online structured prediction, including online classification as a special case, is the task of sequentially predicting labels from input features. Therein the surrogate regret -- the cumulative excess of the target loss (e.g., 0-1 loss) over the surrogate loss (e.g., logistic loss) of the fixed best estimator -- has gained attention, particularly because it often admits a finite bound independent of the time horizon $T$. However, such guarantees break down in non-stationary environments, where every fixed estimator may incur the surrogate loss growing linearly with $T$. We address this by proving a bound of the form $F_T + C(1 + P_T)$ on the cumulative target loss, where $F_T$ is the cumulative surrogate loss of any comparator sequence, $P_T$ is its path length, and $C > 0$ is some constant. This bound depends on $T$ only through $F_T$ and $P_T$, often yielding much stronger guarantees in non-stationary environments. Our core idea is to synthesize the dynamic regret bound of the online gradient descent (OGD) with the technique of exploiting the surrogate gap. Our analysis also sheds light on a new Polyak-style learning rate for OGD, which systematically offers target-loss guarantees and exhibits promising empirical performance. We further extend our approach to a broader class of problems via the convolutional Fenchel--Young loss. Finally, we prove a lower bound showing that the dependence on $F_T$ and $P_T$ is tight.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.427838"
    },
    {
        "index": "#20",
        "title": "HTMformer: Hybrid Time and Multivariate Transformer for Time Series Forecasting",
        "link": "/arxiv/2510.07084",
        "arxiv_id": "2510.07084",
        "authors": "Tan Wang, Yun Wei Dong, Tao Zhang, Qi Wang",
        "summary": "Transformer-based methods have achieved impressive results in time series forecasting. However, existing Transformers still exhibit limitations in sequence modeling as they tend to overemphasize temporal dependencies. This incurs additional computational overhead without yielding corresponding performance gains. We find that the performance of Transformers is highly dependent on the embedding method used to learn effective representations. To address this issue, we extract multivariate features to augment the effective information captured in the embedding layer, yielding multidimensional embeddings that convey richer and more meaningful sequence representations. These representations enable Transformer-based forecasters to better understand the series. Specifically, we introduce Hybrid Temporal and Multivariate Embeddings (HTME). The HTME extractor integrates a lightweight temporal feature extraction module with a carefully designed multivariate feature extraction module to provide complementary features, thereby achieving a balance between model complexity and performance. By combining HTME with the Transformer architecture, we present HTMformer, leveraging the enhanced feature extraction capability of the HTME extractor to build a lightweight forecaster. Experiments conducted on eight real-world datasets demonstrate that our approach outperforms existing baselines in both accuracy and efficiency.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.428288"
    },
    {
        "index": "#21",
        "title": "Blind Construction of Angular Power Maps in Massive MIMO Networks",
        "link": "/arxiv/2510.07071",
        "arxiv_id": "2510.07071",
        "authors": "Zheng Xing, Junting Chen",
        "summary": "Channel state information (CSI) acquisition is a challenging problem in massive multiple-input multiple-output (MIMO) networks. Radio maps provide a promising solution for radio resource management by reducing online CSI acquisition. However, conventional approaches for radio map construction require location-labeled CSI data, which is challenging in practice. This paper investigates unsupervised angular power map construction based on large timescale CSI data collected in a massive MIMO network without location labels. A hidden Markov model (HMM) is built to connect the hidden trajectory of a mobile with the CSI evolution of a massive MIMO channel. As a result, the mobile location can be estimated, enabling the construction of an angular power map. We show that under uniform rectilinear mobility with Poisson-distributed base stations (BSs), the Cramer-Rao Lower Bound (CRLB) for localization error can vanish at any signal-to-noise ratios (SNRs), whereas when BSs are confined to a limited region, the error remains nonzero even with infinite independent measurements. Based on reference signal received power (RSRP) data collected in a real multi-cell massive MIMO network, an average localization error of 18 meters can be achieved although measurements are mainly obtained from a single serving cell.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.428708"
    },
    {
        "index": "#22",
        "title": "Introspection in Learned Semantic Scene Graph Localisation",
        "link": "/arxiv/2510.07053",
        "arxiv_id": "2510.07053",
        "authors": "Manshika Charvi Bissessur, Efimia Panagiotaki, Daniele De Martini",
        "summary": "This work investigates how semantics influence localisation performance and robustness in a learned self-supervised, contrastive semantic localisation framework. After training a localisation network on both original and perturbed maps, we conduct a thorough post-hoc introspection analysis to probe whether the model filters environmental noise and prioritises distinctive landmarks over routine clutter. We validate various interpretability methods and present a comparative reliability analysis. Integrated gradients and Attention Weights consistently emerge as the most reliable probes of learned behaviour. A semantic class ablation further reveals an implicit weighting in which frequent objects are often down-weighted. Overall, the results indicate that the model learns noise-robust, semantically salient relations about place definition, thereby enabling explainable registration under challenging visual and structural variations.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition, Robotics",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.429182"
    },
    {
        "index": "#23",
        "title": "Enhancing Speech Emotion Recognition via Fine-Tuning Pre-Trained Models and Hyper-Parameter Optimisation",
        "link": "/arxiv/2510.07052",
        "arxiv_id": "2510.07052",
        "authors": "Aryan Golbaghi, Shuo Zhou",
        "summary": "We propose a workflow for speech emotion recognition (SER) that combines pre-trained representations with automated hyperparameter optimisation (HPO). Using SpeechBrain wav2vec2-base model fine-tuned on IEMOCAP as the encoder, we compare two HPO strategies, Gaussian Process Bayesian Optimisation (GP-BO) and Tree-structured Parzen Estimators (TPE), under an identical four-dimensional search space and 15-trial budget, with balanced class accuracy (BCA) on the German EmoDB corpus as the objective. All experiments run on 8 CPU cores with 32 GB RAM. GP-BO achieves 0.96 BCA in 11 minutes, and TPE (Hyperopt implementation) attains 0.97 in 15 minutes. In contrast, grid search requires 143 trials and 1,680 minutes to exceed 0.9 BCA, and the best AutoSpeech 2020 baseline reports only 0.85 in 30 minutes on GPU. For cross-lingual generalisation, an EmoDB-trained HPO-tuned model improves zero-shot accuracy by 0.25 on CREMA-D and 0.26 on RAVDESS. Results show that efficient HPO with pre-trained encoders delivers competitive SER on commodity CPUs. Source code to this work is available at: https://github.com/youngaryan/speechbrain-emotion-hpo.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.429591"
    },
    {
        "index": "#24",
        "title": "COMPASS: A Multi-Turn Benchmark for Tool-Mediated Planning & Preference Optimization",
        "link": "/arxiv/2510.07043",
        "arxiv_id": "2510.07043",
        "authors": "Tian Qin, Felix Bai, Ting-Yao Hu, Raviteja Vemulapalli, Hema Swetha Koppula, Zhiyang Xu, Bowen Jin, Mert Cemri, Jiarui Lu, Zirui Wang, Meng Cao",
        "summary": "Real-world large language model (LLM) agents must master strategic tool use and user preference optimization through multi-turn interactions to assist users with complex planning tasks. We introduce COMPASS (Constrained Optimization through Multi-turn Planning and Strategic Solutions), a benchmark that evaluates agents on realistic travel-planning scenarios. We cast travel planning as a constrained preference optimization problem, where agents must satisfy hard constraints while simultaneously optimizing soft user preferences. To support this, we build a realistic travel database covering transportation, accommodation, and ticketing for 20 U.S. National Parks, along with a comprehensive tool ecosystem that mirrors commercial booking platforms. Evaluating state-of-the-art models, we uncover two critical gaps: (i) an acceptable-optimal gap, where agents reliably meet constraints but fail to optimize preferences, and (ii) a plan-coordination gap, where performance collapses on multi-service (flight and hotel) coordination tasks, especially for open-source models. By grounding reasoning and planning in a practical, user-facing domain, COMPASS provides a benchmark that directly measures an agent's ability to optimize user preferences in realistic tasks, bridging theoretical advances with real-world impact.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.430118"
    },
    {
        "index": "#25",
        "title": "Unified Molecule Pre-training with Flexible 2D and 3D Modalities: Single and Paired Modality Integration",
        "link": "/arxiv/2510.07035",
        "arxiv_id": "2510.07035",
        "authors": "Tengwei Song, Min Wu, Yuan Fang",
        "summary": "Molecular representation learning plays a crucial role in advancing applications such as drug discovery and material design. Existing work leverages 2D and 3D modalities of molecular information for pre-training, aiming to capture comprehensive structural and geometric insights. However, these methods require paired 2D and 3D molecular data to train the model effectively and prevent it from collapsing into a single modality, posing limitations in scenarios where a certain modality is unavailable or computationally expensive to generate. To overcome this limitation, we propose FlexMol, a flexible molecule pre-training framework that learns unified molecular representations while supporting single-modality input. Specifically, inspired by the unified structure in vision-language models, our approach employs separate models for 2D and 3D molecular data, leverages parameter sharing to improve computational efficiency, and utilizes a decoder to generate features for the missing modality. This enables a multistage continuous learning process where both modalities contribute collaboratively during training, while ensuring robustness when only one modality is available during inference. Extensive experiments demonstrate that FlexMol achieves superior performance across a wide range of molecular property prediction tasks, and we also empirically demonstrate its effectiveness with incomplete data. Our code and data are available at https://github.com/tewiSong/FlexMol.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.430568"
    },
    {
        "index": "#26",
        "title": "Federated Unlearning in the Wild: Rethinking Fairness and Data Discrepancy",
        "link": "/arxiv/2510.07022",
        "arxiv_id": "2510.07022",
        "authors": "ZiHeng Huang, Di Wu, Jun Bai, Jiale Zhang, Sicong Cao, Ji Zhang, Yingjie Hu",
        "summary": "Machine unlearning is critical for enforcing data deletion rights like the \"right to be forgotten.\" As a decentralized paradigm, Federated Learning (FL) also requires unlearning, but realistic implementations face two major challenges. First, fairness in Federated Unlearning (FU) is often overlooked. Exact unlearning methods typically force all clients into costly retraining, even those uninvolved. Approximate approaches, using gradient ascent or distillation, make coarse interventions that can unfairly degrade performance for clients with only retained data. Second, most FU evaluations rely on synthetic data assumptions (IID/non-IID) that ignore real-world heterogeneity. These unrealistic benchmarks obscure the true impact of unlearning and limit the applicability of current methods. We first conduct a comprehensive benchmark of existing FU methods under realistic data heterogeneity and fairness conditions. We then propose a novel, fairness-aware FU approach, Federated Cross-Client-Constrains Unlearning (FedCCCU), to explicitly address both challenges. FedCCCU offers a practical and scalable solution for real-world FU. Experimental results show that existing methods perform poorly in realistic settings, while our approach consistently outperforms them.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.431059"
    },
    {
        "index": "#27",
        "title": "Sharpness-Aware Data Generation for Zero-shot Quantization",
        "link": "/arxiv/2510.07018",
        "arxiv_id": "2510.07018",
        "authors": "Dung Hoang-Anh, Cuong Pham Trung Le, Jianfei Cai, Thanh-Toan Do",
        "summary": "Zero-shot quantization aims to learn a quantized model from a pre-trained full-precision model with no access to original real training data. The common idea in zero-shot quantization approaches is to generate synthetic data for quantizing the full-precision model. While it is well-known that deep neural networks with low sharpness have better generalization ability, none of the previous zero-shot quantization works considers the sharpness of the quantized model as a criterion for generating training data. This paper introduces a novel methodology that takes into account quantized model sharpness in synthetic data generation to enhance generalization. Specifically, we first demonstrate that sharpness minimization can be attained by maximizing gradient matching between the reconstruction loss gradients computed on synthetic and real validation data, under certain assumptions. We then circumvent the problem of the gradient matching without real validation set by approximating it with the gradient matching between each generated sample and its neighbors. Experimental evaluations on CIFAR-100 and ImageNet datasets demonstrate the superiority of the proposed method over the state-of-the-art techniques in low-bit quantization settings.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.431510"
    },
    {
        "index": "#28",
        "title": "Spiral Model Technique For Data Science & Machine Learning Lifecycle",
        "link": "/arxiv/2510.06987",
        "arxiv_id": "2510.06987",
        "authors": "Rohith Mahadevan",
        "summary": "Analytics play an important role in modern business. Companies adapt data science lifecycles to their culture to seek productivity and improve their competitiveness among others. Data science lifecycles are fairly an important contributing factor to start and end a project that are data dependent. Data science and Machine learning life cycles comprises of series of steps that are involved in a project. A typical life cycle states that it is a linear or cyclical model that revolves around. It is mostly depicted that it is possible in a traditional data science life cycle to start the process again after reaching the end of cycle. This paper suggests a new technique to incorporate data science life cycle to business problems that have a clear end goal. A new technique called spiral technique is introduced to emphasize versatility, agility and iterative approach to business processes.",
        "subjects": "Machine Learning, Information Retrieval, Software Engineering",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.431976"
    },
    {
        "index": "#29",
        "title": "Revisiting Mixout: An Overlooked Path to Robust Finetuning",
        "link": "/arxiv/2510.06982",
        "arxiv_id": "2510.06982",
        "authors": "Masih Aminbeidokhti, Heitor Rapela Medeiros, Eric Granger, Marco Pedersoli",
        "summary": "Finetuning vision foundation models often improves in-domain accuracy but comes at the cost of robustness under distribution shift. We revisit Mixout, a stochastic regularizer that intermittently replaces finetuned weights with their pretrained reference, through the lens of a single-run, weight-sharing implicit ensemble. This perspective reveals three key levers that govern robustness: the \\emph{masking anchor}, \\emph{resampling frequency}, and \\emph{mask sparsity}. Guided by this analysis, we introduce GMixout, which (i) replaces the fixed anchor with an exponential moving-average snapshot that adapts during training, and (ii) regulates masking period via an explicit resampling-frequency hyperparameter. Our sparse-kernel implementation updates only a small fraction of parameters with no inference-time overhead, enabling training on consumer-grade GPUs. Experiments on benchmarks covering covariate shift, corruption, and class imbalance, ImageNet / ImageNet-LT, DomainNet, iWildCam, and CIFAR100-C, GMixout consistently improves in-domain accuracy beyond zero-shot performance while surpassing both Model Soups and strong parameter-efficient finetuning baselines under distribution shift.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.432428"
    },
    {
        "index": "#30",
        "title": "High-Rate Mixout: Revisiting Mixout for Robust Domain Generalization",
        "link": "/arxiv/2510.06955",
        "arxiv_id": "2510.06955",
        "authors": "Masih Aminbeidokhti, Heitor Rapela Medeiros, Eric Granger, Marco Pedersoli",
        "summary": "Ensembling fine-tuned models initialized from powerful pre-trained weights is a common strategy to improve robustness under distribution shifts, but it comes with substantial computational costs due to the need to train and store multiple models. Dropout offers a lightweight alternative by simulating ensembles through random neuron deactivation; however, when applied to pre-trained models, it tends to over-regularize and disrupt critical representations necessary for generalization. In this work, we investigate Mixout, a stochastic regularization technique that provides an alternative to Dropout for domain generalization. Rather than deactivating neurons, Mixout mitigates overfitting by probabilistically swapping a subset of fine-tuned weights with their pre-trained counterparts during training, thereby maintaining a balance between adaptation and retention of prior knowledge. Our study reveals that achieving strong performance with Mixout on domain generalization benchmarks requires a notably high masking probability of 0.9 for ViTs and 0.8 for ResNets. While this may seem like a simple adjustment, it yields two key advantages for domain generalization: (1) higher masking rates more strongly penalize deviations from the pre-trained parameters, promoting better generalization to unseen domains; and (2) high-rate masking substantially reduces computational overhead, cutting gradient computation by up to 45% and gradient memory usage by up to 90%. Experiments across five domain generalization benchmarks, PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet, using ResNet and ViT architectures, show that our approach, High-rate Mixout, achieves out-of-domain accuracy comparable to ensemble-based methods while significantly reducing training costs.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.437976"
    },
    {
        "index": "#31",
        "title": "From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer Training Dynamics",
        "link": "/arxiv/2510.06954",
        "arxiv_id": "2510.06954",
        "authors": "Zheng-An Chen, Tao Luo",
        "summary": "Although transformer-based models have shown exceptional empirical performance, the fundamental principles governing their training dynamics are inadequately characterized beyond configuration-specific studies. Inspired by empirical evidence showing improved reasoning capabilities under small initialization scales in language models, we employ the gradient flow analytical framework established in [Zhou et al. NeurIPS 2022] to systematically investigate linearized Transformer training dynamics. Our theoretical analysis dissects the dynamics of attention modules into two distinct stages. In the first stage, asymmetric weight perturbations from random initialization sustain non-degenerate gradient dynamics in parameter matrices, facilitating systematic escape from small initialization regimes. Subsequently, these matrices undergo condensation, progressively aligning toward the target orientation. In the second stage, the previously static key-query matrices actively participate in training, driving the normalized matrices toward asymptotic rank collapse. This two-stage framework generalizes classical directional convergence results.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.438397"
    },
    {
        "index": "#32",
        "title": "Grouped Differential Attention",
        "link": "/arxiv/2510.06949",
        "arxiv_id": "2510.06949",
        "authors": "Junghwan Lim, Sungmin Lee, Dongseok Kim, Wai Ting Cheung, Beomgyu Kim, Taehwan Kim, Haesol Lee, Junhyeok Lee, Dongpin Oh, Eunhwan Park",
        "summary": "The self-attention mechanism, while foundational to modern Transformer architectures, suffers from a critical inefficiency: it frequently allocates substantial attention to redundant or noisy context. Differential Attention addressed this by using subtractive attention maps for signal and noise, but its required balanced head allocation imposes rigid constraints on representational flexibility and scalability. To overcome this, we propose Grouped Differential Attention (GDA), a novel approach that introduces unbalanced head allocation between signal-preserving and noise-control groups. GDA significantly enhances signal focus by strategically assigning more heads to signal extraction and fewer to noise-control, stabilizing the latter through controlled repetition (akin to GQA). This design achieves stronger signal fidelity with minimal computational overhead. We further extend this principle to group-differentiated growth, a scalable strategy that selectively replicates only the signal-focused heads, thereby ensuring efficient capacity expansion. Through large-scale pretraining and continual training experiments, we demonstrate that moderate imbalance ratios in GDA yield substantial improvements in generalization and stability compared to symmetric baselines. Our results collectively establish that ratio-aware head allocation and selective expansion offer an effective and practical path toward designing scalable, computation-efficient Transformer architectures.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.438919"
    },
    {
        "index": "#33",
        "title": "Fisher Information, Training and Bias in Fourier Regression Models",
        "link": "/arxiv/2510.06945",
        "arxiv_id": "2510.06945",
        "authors": "Lorenzo Pastori, Veronika Eyring, Mierk Schwabe",
        "summary": "Motivated by the growing interest in quantum machine learning, in particular quantum neural networks (QNNs), we study how recently introduced evaluation metrics based on the Fisher information matrix (FIM) are effective for predicting their training and prediction performance. We exploit the equivalence between a broad class of QNNs and Fourier models, and study the interplay between the \\emph{effective dimension} and the \\emph{bias} of a model towards a given task, investigating how these affect the model's training and performance. We show that for a model that is completely agnostic, or unbiased, towards the function to be learned, a higher effective dimension likely results in a better trainability and performance. On the other hand, for models that are biased towards the function to be learned a lower effective dimension is likely beneficial during training. To obtain these results, we derive an analytical expression of the FIM for Fourier models and identify the features controlling a model's effective dimension. This allows us to construct models with tunable effective dimension and bias, and to compare their training. We furthermore introduce a tensor network representation of the considered Fourier models, which could be a tool of independent interest for the analysis of QNN models. Overall, these findings provide an explicit example of the interplay between geometrical properties, model-task alignment and training, which are relevant for the broader machine learning community.",
        "subjects": "Machine Learning, Disordered Systems and Neural Networks, Data Analysis, Statistics and Probability, Quantum Physics",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.439386"
    },
    {
        "index": "#34",
        "title": "Revisiting Node Affinity Prediction in Temporal Graphs",
        "link": "/arxiv/2510.06940",
        "arxiv_id": "2510.06940",
        "authors": "Krishna Sri Ipsit Mantri, Or Feldman, Moshe Eliasof, Chaim Baskin",
        "summary": "Node affinity prediction is a common task that is widely used in temporal graph learning with applications in social and financial networks, recommender systems, and more. Recent works have addressed this task by adapting state-of-the-art dynamic link property prediction models to node affinity prediction. However, simple heuristics, such as Persistent Forecast or Moving Average, outperform these models. In this work, we analyze the challenges in training current Temporal Graph Neural Networks for node affinity prediction and suggest appropriate solutions. Combining the solutions, we develop NAViS - Node Affinity prediction model using Virtual State, by exploiting the equivalence between heuristics and state space models. While promising, training NAViS is non-trivial. Therefore, we further introduce a novel loss function for node affinity prediction. We evaluate NAViS on TGB and show that it outperforms the state-of-the-art, including heuristics. Our source code is available at https://github.com/orfeld415/NAVIS",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.439860"
    },
    {
        "index": "#35",
        "title": "DecompGAIL: Learning Realistic Traffic Behaviors with Decomposed Multi-Agent Generative Adversarial Imitation Learning",
        "link": "/arxiv/2510.06913",
        "arxiv_id": "2510.06913",
        "authors": "Ke Guo, Haochen Liu, Xiaojun Wu, Chen Lv",
        "summary": "Realistic traffic simulation is critical for the development of autonomous driving systems and urban mobility planning, yet existing imitation learning approaches often fail to model realistic traffic behaviors. Behavior cloning suffers from covariate shift, while Generative Adversarial Imitation Learning (GAIL) is notoriously unstable in multi-agent settings. We identify a key source of this instability: irrelevant interaction misguidance, where a discriminator penalizes an ego vehicle's realistic behavior due to unrealistic interactions among its neighbors. To address this, we propose Decomposed Multi-agent GAIL (DecompGAIL), which explicitly decomposes realism into ego-map and ego-neighbor components, filtering out misleading neighbor: neighbor and neighbor: map interactions. We further introduce a social PPO objective that augments ego rewards with distance-weighted neighborhood rewards, encouraging overall realism across agents. Integrated into a lightweight SMART-based backbone, DecompGAIL achieves state-of-the-art performance on the WOMD Sim Agents 2025 benchmark.",
        "subjects": "Machine Learning, Artificial Intelligence, Robotics",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.440339"
    },
    {
        "index": "#36",
        "title": "Utilizing Large Language Models for Machine Learning Explainability",
        "link": "/arxiv/2510.06912",
        "arxiv_id": "2510.06912",
        "authors": "Alexandros Vassiliades, Nikolaos Polatidis, Stamatios Samaras, Sotiris Diplaris, Ignacio Cabrera Martin, Yannis Manolopoulos, Stefanos Vrochidis, Ioannis Kompatsiaris",
        "summary": "This study explores the explainability capabilities of large language models (LLMs), when employed to autonomously generate machine learning (ML) solutions. We examine two classification tasks: (i) a binary classification problem focused on predicting driver alertness states, and (ii) a multilabel classification problem based on the yeast dataset. Three state-of-the-art LLMs (i.e. OpenAI GPT, Anthropic Claude, and DeepSeek) are prompted to design training pipelines for four common classifiers: Random Forest, XGBoost, Multilayer Perceptron, and Long Short-Term Memory networks. The generated models are evaluated in terms of predictive performance (recall, precision, and F1-score) and explainability using SHAP (SHapley Additive exPlanations). Specifically, we measure Average SHAP Fidelity (Mean Squared Error between SHAP approximations and model outputs) and Average SHAP Sparsity (number of features deemed influential). The results reveal that LLMs are capable of producing effective and interpretable models, achieving high fidelity and consistent sparsity, highlighting their potential as automated tools for interpretable ML pipeline generation. The results show that LLMs can produce effective, interpretable pipelines with high fidelity and consistent sparsity, closely matching manually engineered baselines.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.440833"
    },
    {
        "index": "#37",
        "title": "Vacuum Spiker: A Spiking Neural Network-Based Model for Efficient Anomaly Detection in Time Series",
        "link": "/arxiv/2510.06910",
        "arxiv_id": "2510.06910",
        "authors": "Iago Xabier Vázquez, Javier Sedano, Muhammad Afzal, Ángel Miguel García-Vico",
        "summary": "Anomaly detection is a key task across domains such as industry, healthcare, and cybersecurity. Many real-world anomaly detection problems involve analyzing multiple features over time, making time series analysis a natural approach for such problems. While deep learning models have achieved strong performance in this field, their trend to exhibit high energy consumption limits their deployment in resource-constrained environments such as IoT devices, edge computing platforms, and wearables. To address this challenge, this paper introduces the \\textit{Vacuum Spiker algorithm}, a novel Spiking Neural Network-based method for anomaly detection in time series. It incorporates a new detection criterion that relies on global changes in neural activity rather than reconstruction or prediction error. It is trained using Spike Time-Dependent Plasticity in a novel way, intended to induce changes in neural activity when anomalies occur. A new efficient encoding scheme is also proposed, which discretizes the input space into non-overlapping intervals, assigning each to a single neuron. This strategy encodes information with a single spike per time step, improving energy efficiency compared to conventional encoding methods. Experimental results on publicly available datasets show that the proposed algorithm achieves competitive performance while significantly reducing energy consumption, compared to a wide set of deep learning and machine learning baselines. Furthermore, its practical utility is validated in a real-world case study, where the model successfully identifies power curtailment events in a solar inverter. These results highlight its potential for sustainable and efficient anomaly detection.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.441281"
    },
    {
        "index": "#38",
        "title": "Angular Constraint Embedding via SpherePair Loss for Constrained Clustering",
        "link": "/arxiv/2510.06907",
        "arxiv_id": "2510.06907",
        "authors": "Shaojie Zhang, Ke Chen",
        "summary": "Constrained clustering integrates domain knowledge through pairwise constraints. However, existing deep constrained clustering (DCC) methods are either limited by anchors inherent in end-to-end modeling or struggle with learning discriminative Euclidean embedding, restricting their scalability and real-world applicability. To avoid their respective pitfalls, we propose a novel angular constraint embedding approach for DCC, termed SpherePair. Using the SpherePair loss with a geometric formulation, our method faithfully encodes pairwise constraints and leads to embeddings that are clustering-friendly in angular space, effectively separating representation learning from clustering. SpherePair preserves pairwise relations without conflict, removes the need to specify the exact number of clusters, generalizes to unseen data, enables rapid inference of the number of clusters, and is supported by rigorous theoretical guarantees. Comparative evaluations with state-of-the-art DCC methods on diverse benchmarks, along with empirical validation of theoretical insights, confirm its superior performance, scalability, and overall real-world effectiveness. Code is available at \\href{https://github.com/spherepaircc/SpherePairCC/tree/main}{our repository}.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.441742"
    },
    {
        "index": "#39",
        "title": "MoRE-GNN: Multi-omics Data Integration with a Heterogeneous Graph Autoencoder",
        "link": "/arxiv/2510.06880",
        "arxiv_id": "2510.06880",
        "authors": "Zhiyu Wang, Sonia Koszut, Pietro Liò, Francesco Ceccarelli",
        "summary": "The integration of multi-omics single-cell data remains challenging due to high-dimensionality and complex inter-modality relationships. To address this, we introduce MoRE-GNN (Multi-omics Relational Edge Graph Neural Network), a heterogeneous graph autoencoder that combines graph convolution and attention mechanisms to dynamically construct relational graphs directly from data. Evaluations on six publicly available datasets demonstrate that MoRE-GNN captures biologically meaningful relationships and outperforms existing methods, particularly in settings with strong inter-modality correlations. Furthermore, the learned representations allow for accurate downstream cross-modal predictions. While performance may vary with dataset complexity, MoRE-GNN offers an adaptive, scalable and interpretable framework for advancing multi-omics integration.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.442197"
    },
    {
        "index": "#40",
        "title": "SaFeR-VLM: Toward Safety-aware Fine-grained Reasoning in Multimodal Models",
        "link": "/arxiv/2510.06871",
        "arxiv_id": "2510.06871",
        "authors": "Huahui Yi, Kun Wang, Qiankun Li, Miao Yu, Liang Lin, Gongli Xi, Hao Wu, Xuming Hu, Kang Li, Yang Liu",
        "summary": "Multimodal Large Reasoning Models (MLRMs) demonstrate impressive cross-modal reasoning but often amplify safety risks under adversarial or unsafe prompts, a phenomenon we call the \\textit{Reasoning Tax}. Existing defenses mainly act at the output level and do not constrain the reasoning process, leaving models exposed to implicit risks. In this paper, we propose SaFeR-VLM, a safety-aligned reinforcement learning framework that embeds safety directly into multimodal reasoning. The framework integrates four components: (I) QI-Safe-10K, a curated dataset emphasizing safety-critical and reasoning-sensitive cases; (II) safety-aware rollout, where unsafe generations undergo reflection and correction instead of being discarded; (III) structured reward modeling with multi-dimensional weighted criteria and explicit penalties for hallucinations and contradictions; and (IV) GRPO optimization, which reinforces both safe and corrected trajectories. This unified design shifts safety from a passive safeguard to an active driver of reasoning, enabling scalable and generalizable safety-aware reasoning. SaFeR-VLM further demonstrates robustness against both explicit and implicit risks, supporting dynamic and interpretable safety decisions beyond surface-level filtering. SaFeR-VLM-3B achieves average performance $70.13$ and $78.97$ on safety and helpfulness across six benchmarks, surpassing both same-scale and $>10\\times$ larger models such as Skywork-R1V3-38B, Qwen2.5VL-72B, and GLM4.5V-106B. Remarkably, SaFeR-VLM-7B benefits from its increased scale to surpass GPT-5-mini and Gemini-2.5-Flash by \\num{6.47} and \\num{16.76} points respectively on safety metrics, achieving this improvement without any degradation in helpfulness performance. Our codes are available at https://github.com/HarveyYi/SaFeR-VLM.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.443933"
    },
    {
        "index": "#41",
        "title": "Towards Generalization of Graph Neural Networks for AC Optimal Power Flow",
        "link": "/arxiv/2510.06860",
        "arxiv_id": "2510.06860",
        "authors": "Olayiwola Arowolo, Jochen L. Cremer",
        "summary": "AC Optimal Power Flow (ACOPF) is computationally expensive for large-scale power systems, with conventional solvers requiring prohibitive solution times. Machine learning approaches offer computational speedups but struggle with scalability and topology adaptability without expensive retraining. To enable scalability across grid sizes and adaptability to topology changes, we propose a Hybrid Heterogeneous Message Passing Neural Network (HH-MPNN). HH-MPNN models buses, generators, loads, shunts, transmission lines and transformers as distinct node or edge types, combined with a scalable transformer model for handling long-range dependencies. On grids from 14 to 2,000 buses, HH-MPNN achieves less than 1% optimality gap on default topologies. Applied zero-shot to thousands of unseen topologies, HH-MPNN achieves less than 3% optimality gap despite training only on default topologies. Pre-training on smaller grids also improves results on a larger grid. Computational speedups reach 1,000x to 10,000x compared to interior point solvers. These results advance practical, generalizable machine learning for real-time power system operations.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.444380"
    },
    {
        "index": "#42",
        "title": "Enhancing Bankruptcy Prediction of Banks through Advanced Machine Learning Techniques: An Innovative Approach and Analysis",
        "link": "/arxiv/2510.06852",
        "arxiv_id": "2510.06852",
        "authors": "Zuherman Rustam, Sri Hartini, Sardar M. N. Islam, Fevi Novkaniza, Fiftitah R. Aszhari, Muhammad Rifqi",
        "summary": "Context: Financial system stability is determined by the condition of the banking system. A bank failure can destroy the stability of the financial system, as banks are subject to systemic risk, affecting not only individual banks but also segments or the entire financial system. Calculating the probability of a bank going bankrupt is one way to ensure the banking system is safe and sound. Existing literature and limitations: Statistical models, such as Altman's Z-Score, are one of the common techniques for developing a bankruptcy prediction model. However, statistical methods rely on rigid and sometimes irrelevant assumptions, which can result in low forecast accuracy. New approaches are necessary. Objective of the research: Bankruptcy models are developed using machine learning techniques, such as logistic regression (LR), random forest (RF), and support vector machines (SVM). According to several studies, machine learning is also more accurate and effective than statistical methods for categorising and forecasting banking risk management. Present Research: The commercial bank data are derived from the annual financial statements of 44 active banks and 21 bankrupt banks in Turkey from 1994 to 2004, and the rural bank data are derived from the quarterly financial reports of 43 active and 43 bankrupt rural banks in Indonesia between 2013 and 2019. Five rural banks in Indonesia have also been selected to demonstrate the feasibility of analysing bank bankruptcy trends. Findings and implications: The results of the research experiments show that RF can forecast data from commercial banks with a 90% accuracy rate. Furthermore, the three machine learning methods proposed accurately predict the likelihood of rural bank bankruptcy. Contribution and Conclusion: The proposed innovative machine learning approach help to implement policies that reduce the costs of bankruptcy.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.444875"
    },
    {
        "index": "#43",
        "title": "CNN-TFT explained by SHAP with multi-head attention weights for time series forecasting",
        "link": "/arxiv/2510.06840",
        "arxiv_id": "2510.06840",
        "authors": "Stefano F. Stefenon, João P. Matos-Carvalho, Valderi R. Q. Leithardt, Kin-Choong Yow",
        "summary": "Convolutional neural networks (CNNs) and transformer architectures offer strengths for modeling temporal data: CNNs excel at capturing local patterns and translational invariances, while transformers effectively model long-range dependencies via self-attention. This paper proposes a hybrid architecture integrating convolutional feature extraction with a temporal fusion transformer (TFT) backbone to enhance multivariate time series forecasting. The CNN module first applies a hierarchy of one-dimensional convolutional layers to distill salient local patterns from raw input sequences, reducing noise and dimensionality. The resulting feature maps are then fed into the TFT, which applies multi-head attention to capture both short- and long-term dependencies and to weigh relevant covariates adaptively. We evaluate the CNN-TFT on a hydroelectric natural flow time series dataset. Experimental results demonstrate that CNN-TFT outperforms well-established deep learning models, with a mean absolute percentage error of up to 2.2%. The explainability of the model is obtained by a proposed Shapley additive explanations with multi-head attention weights (SHAP-MHAW). Our novel architecture, named CNN-TFT-SHAP-MHAW, is promising for applications requiring high-fidelity, multivariate time series forecasts, being available for future analysis at https://github.com/SFStefenon/CNN-TFT-SHAP-MHAW .",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.445338"
    },
    {
        "index": "#44",
        "title": "Vectorized FlashAttention with Low-cost Exponential Computation in RISC-V Vector Processors",
        "link": "/arxiv/2510.06834",
        "arxiv_id": "2510.06834",
        "authors": "Vasileios Titopoulos, Kosmas Alexandridis, Giorgos Dimitrakopoulos",
        "summary": "Attention is a core operation in numerous machine learning and artificial intelligence models. This work focuses on the acceleration of attention kernel using FlashAttention algorithm, in vector processors, particularly those based on the RISC-V instruction set architecture (ISA). This work represents the first effort to vectorize FlashAttention, minimizing scalar code and simplifying the computational complexity of evaluating exponentials needed by softmax used in attention. By utilizing a low-cost approximation for exponentials in floating-point arithmetic, we reduce the cost of computing the exponential function without the need to extend baseline vector ISA with new custom instructions. Also, appropriate tiling strategies are explored with the goal to improve memory locality. Experimental results highlight the scalability of our approach, demonstrating significant performance gains with the vectorized implementations when processing attention layers in practical applications.",
        "subjects": "Machine Learning, Distributed, Parallel, and Cluster Computing, Performance",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.445810"
    },
    {
        "index": "#45",
        "title": "Early wind turbine alarm prediction based on machine learning: AlarmForecasting",
        "link": "/arxiv/2510.06831",
        "arxiv_id": "2510.06831",
        "authors": "Syed Shazaib Shah, Daoliang Tan",
        "summary": "Alarm data is pivotal in curbing fault behavior in Wind Turbines (WTs) and forms the backbone for advancedpredictive monitoring systems. Traditionally, research cohorts have been confined to utilizing alarm data solelyas a diagnostic tool, merely indicative of unhealthy status. However, this study aims to offer a transformativeleap towards preempting alarms, preventing alarms from triggering altogether, and consequently avertingimpending failures. Our proposed Alarm Forecasting and Classification (AFC) framework is designed on twosuccessive modules: first, the regression module based on long short-term memory (LSTM) for time-series alarmforecasting, and thereafter, the classification module to implement alarm tagging on the forecasted alarm. Thisway, the entire alarm taxonomy can be forecasted reliably rather than a few specific alarms. 14 Senvion MM82turbines with an operational period of 5 years are used as a case study; the results demonstrated 82%, 52%,and 41% accurate forecasts for 10, 20, and 30 min alarm forecasts, respectively. The results substantiateanticipating and averting alarms, which is significant in curbing alarm frequency and enhancing operationalefficiency through proactive intervention.",
        "subjects": "Machine Learning, Applied Physics",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.446258"
    },
    {
        "index": "#46",
        "title": "Recurrence-Complete Frame-based Action Models",
        "link": "/arxiv/2510.06828",
        "arxiv_id": "2510.06828",
        "authors": "Michael Keiblinger",
        "summary": "In recent years, attention-like mechanisms have been used to great success in the space of large language models, unlocking scaling potential to a previously unthinkable extent. \"Attention Is All You Need\" famously claims RNN cells are not needed in conjunction with attention. We challenge this view. In this paper, we point to existing proofs that architectures with fully parallelizable forward or backward passes cannot represent classes of problems specifically interesting for long-running agentic tasks. We further conjecture a critical time t beyond which non-recurrence-complete models fail to aggregate inputs correctly, with concrete implications for agentic systems (e.g., software engineering agents). To address this, we introduce a recurrence-complete architecture and train it on GitHub-derived action sequences. Loss follows a power law in the trained sequence length while the parameter count remains fixed. Moreover, longer-sequence training always amortizes its linearly increasing wall-time cost, yielding lower loss as a function of wall time.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.446685"
    },
    {
        "index": "#47",
        "title": "Efficient numeracy in language models through single-token number embeddings",
        "link": "/arxiv/2510.06824",
        "arxiv_id": "2510.06824",
        "authors": "Linus Kreitner, Paul Hager, Jonathan Mengedoht, Georgios Kaissis, Daniel Rueckert, Martin J. Menten",
        "summary": "To drive progress in science and engineering, large language models (LLMs) must be able to process large amounts of numerical data and solve long calculations efficiently. This is currently only possible through the use of external tools or extensive reasoning chains, either limiting the numerical intuition of LLMs or limiting the length of problems they can solve. We show that frontier LLMs require excessive amounts of reasoning tokens to solve even basic calculations, which is exacerbated by their tokenization strategies that split single numbers into multiple tokens. This motivates the need for efficient and effective single-token number encodings. We introduce a set of desiderata for such encodings and show that existing approaches fail to fulfill them. To address these shortcomings, we propose BitTokens, a novel tokenization strategy that embeds any number into a single token using its IEEE 754 binary floating-point representation. Through extensive experiments we show that our BitTokens allow even small language models to learn algorithms that solve basic arithmetic operations nearly perfectly. This newly gained efficiency could expand the length and complexity of problems language models can solve.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.447152"
    },
    {
        "index": "#48",
        "title": "The Unreasonable Effectiveness of Randomized Representations in Online Continual Graph Learning",
        "link": "/arxiv/2510.06819",
        "arxiv_id": "2510.06819",
        "authors": "Giovanni Donghi, Daniele Zambon, Luca Pasa, Cesare Alippi, Nicolò Navarin",
        "summary": "Catastrophic forgetting is one of the main obstacles for Online Continual Graph Learning (OCGL), where nodes arrive one by one, distribution drifts may occur at any time and offline training on task-specific subgraphs is not feasible. In this work, we explore a surprisingly simple yet highly effective approach for OCGL: we use a fixed, randomly initialized encoder to generate robust and expressive node embeddings by aggregating neighborhood information, training online only a lightweight classifier. By freezing the encoder, we eliminate drifts of the representation parameters, a key source of forgetting, obtaining embeddings that are both expressive and stable. When evaluated across several OCGL benchmarks, despite its simplicity and lack of memory buffer, this approach yields consistent gains over state-of-the-art methods, with surprising improvements of up to 30% and performance often approaching that of the joint offline-training upper bound. These results suggest that in OCGL, catastrophic forgetting can be minimized without complex replay or regularization by embracing architectural simplicity and stability.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.447611"
    },
    {
        "index": "#49",
        "title": "Get RICH or Die Scaling: Profitably Trading Inference Compute for Robustness",
        "link": "/arxiv/2510.06790",
        "arxiv_id": "2510.06790",
        "authors": "Tavish McDonald, Bo Lei, Stanislav Fort, Bhavya Kailkhura, Brian Bartoldson",
        "summary": "Models are susceptible to adversarially out-of-distribution (OOD) data despite large training-compute investments into their robustification. Zaremba et al. (2025) make progress on this problem at test time, showing LLM reasoning improves satisfaction of model specifications designed to thwart attacks, resulting in a correlation between reasoning effort and robustness to jailbreaks. However, this benefit of test compute fades when attackers are given access to gradients or multimodal inputs. We address this gap, clarifying that inference-compute offers benefits even in such cases. Our approach argues that compositional generalization, through which OOD data is understandable via its in-distribution (ID) components, enables adherence to defensive specifications on adversarially OOD inputs. Namely, we posit the Robustness from Inference Compute Hypothesis (RICH): inference-compute defenses profit as the model's training data better reflects the attacked data's components. We empirically support this hypothesis across vision language model and attack types, finding robustness gains from test-time compute if specification following on OOD data is unlocked by compositional generalization, while RL finetuning and protracted reasoning are not critical. For example, increasing emphasis on defensive specifications via prompting lowers the success rate of gradient-based multimodal attacks on VLMs robustified by adversarial pretraining, but this same intervention provides no such benefit to not-robustified models. This correlation of inference-compute's robustness benefit with base model robustness is the rich-get-richer dynamic of the RICH: attacked data components are more ID for robustified models, aiding compositional generalization to OOD data. Accordingly, we advise layering train-time and test-time defenses to obtain their synergistic benefit.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.448106"
    },
    {
        "index": "#50",
        "title": "Modeling COVID-19 Dynamics in German States Using Physics-Informed Neural Networks",
        "link": "/arxiv/2510.06776",
        "arxiv_id": "2510.06776",
        "authors": "Phillip Rothenbeck, Sai Karthikeya Vemuri, Niklas Penzel, Joachim Denzler",
        "summary": "The COVID-19 pandemic has highlighted the need for quantitative modeling and analysis to understand real-world disease dynamics. In particular, post hoc analyses using compartmental models offer valuable insights into the effectiveness of public health interventions, such as vaccination strategies and containment policies. However, such compartmental models like SIR (Susceptible-Infectious-Recovered) often face limitations in directly incorporating noisy observational data. In this work, we employ Physics-Informed Neural Networks (PINNs) to solve the inverse problem of the SIR model using infection data from the Robert Koch Institute (RKI). Our main contribution is a fine-grained, spatio-temporal analysis of COVID-19 dynamics across all German federal states over a three-year period. We estimate state-specific transmission and recovery parameters and time-varying reproduction number (R_t) to track the pandemic progression. The results highlight strong variations in transmission behavior across regions, revealing correlations with vaccination uptake and temporal patterns associated with major pandemic phases. Our findings demonstrate the utility of PINNs in localized, long-term epidemiological modeling.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.448572"
    },
    {
        "index": "#51",
        "title": "Function regression using the forward forward training and inferring paradigm",
        "link": "/arxiv/2510.06762",
        "arxiv_id": "2510.06762",
        "authors": "Shivam Padmani, Akshay Joshi",
        "summary": "Function regression/approximation is a fundamental application of machine learning. Neural networks (NNs) can be easily trained for function regression using a sufficient number of neurons and epochs. The forward-forward learning algorithm is a novel approach for training neural networks without backpropagation, and is well suited for implementation in neuromorphic computing and physical analogs for neural networks. To the best of the authors' knowledge, the Forward Forward paradigm of training and inferencing NNs is currently only restricted to classification tasks. This paper introduces a new methodology for approximating functions (function regression) using the Forward-Forward algorithm. Furthermore, the paper evaluates the developed methodology on univariate and multivariate functions, and provides preliminary studies of extending the proposed Forward-Forward regression to Kolmogorov Arnold Networks, and Deep Physical Neural Networks.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.449206"
    },
    {
        "index": "#52",
        "title": "Incorporating Expert Knowledge into Bayesian Causal Discovery of Mixtures of Directed Acyclic Graphs",
        "link": "/arxiv/2510.06735",
        "arxiv_id": "2510.06735",
        "authors": "Zachris Björkman, Jorge Loría, Sophie Wharrie, Samuel Kaski",
        "summary": "Bayesian causal discovery benefits from prior information elicited from domain experts, and in heterogeneous domains any prior knowledge would be badly needed. However, so far prior elicitation approaches have assumed a single causal graph and hence are not suited to heterogeneous domains. We propose a causal elicitation strategy for heterogeneous settings, based on Bayesian experimental design (BED) principles, and a variational mixture structure learning (VaMSL) method -- extending the earlier differentiable Bayesian structure learning (DiBS) method -- to iteratively infer mixtures of causal Bayesian networks (CBNs). We construct an informative graph prior incorporating elicited expert feedback in the inference of mixtures of CBNs. Our proposed method successfully produces a set of alternative causal models (mixture components or clusters), and achieves an improved structure learning performance on heterogeneous synthetic data when informed by a simulated expert. Finally, we demonstrate that our approach is capable of capturing complex distributions in a breast cancer database.",
        "subjects": "Machine Learning, Methodology",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.449499"
    },
    {
        "index": "#53",
        "title": "Dual Goal Representations",
        "link": "/arxiv/2510.06714",
        "arxiv_id": "2510.06714",
        "authors": "Seohong Park, Deepinder Mann, Sergey Levine",
        "summary": "In this work, we introduce dual goal representations for goal-conditioned reinforcement learning (GCRL). A dual goal representation characterizes a state by \"the set of temporal distances from all other states\"; in other words, it encodes a state through its relations to every other state, measured by temporal distance. This representation provides several appealing theoretical properties. First, it depends only on the intrinsic dynamics of the environment and is invariant to the original state representation. Second, it contains provably sufficient information to recover an optimal goal-reaching policy, while being able to filter out exogenous noise. Based on this concept, we develop a practical goal representation learning method that can be combined with any existing GCRL algorithm. Through diverse experiments on the OGBench task suite, we empirically show that dual goal representations consistently improve offline goal-reaching performance across 20 state- and pixel-based tasks.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.449785"
    },
    {
        "index": "#54",
        "title": "A Diffusion Model for Regular Time Series Generation from Irregular Data with Completion and Masking",
        "link": "/arxiv/2510.06699",
        "arxiv_id": "2510.06699",
        "authors": "Gal Fadlon, Idan Arbiv, Nimrod Berman, Omri Azencot",
        "summary": "Generating realistic time series data is critical for applications in healthcare, finance, and science. However, irregular sampling and missing values present significant challenges. While prior methods address these irregularities, they often yield suboptimal results and incur high computational costs. Recent advances in regular time series generation, such as the diffusion-based ImagenTime model, demonstrate strong, fast, and scalable generative capabilities by transforming time series into image representations, making them a promising solution. However, extending ImagenTime to irregular sequences using simple masking introduces \"unnatural\" neighborhoods, where missing values replaced by zeros disrupt the learning process. To overcome this, we propose a novel two-step framework: first, a Time Series Transformer completes irregular sequences, creating natural neighborhoods; second, a vision-based diffusion model with masking minimizes dependence on the completed values. This approach leverages the strengths of both completion and masking, enabling robust and efficient generation of realistic time series. Our method achieves state-of-the-art performance, achieving a relative improvement in discriminative score by $70\\%$ and in computational cost by $85\\%$. Code is at https://github.com/azencot-group/ImagenI2R.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.450067"
    },
    {
        "index": "#55",
        "title": "Is the Hard-Label Cryptanalytic Model Extraction Really Polynomial?",
        "link": "/arxiv/2510.06692",
        "arxiv_id": "2510.06692",
        "authors": "Akira Ito, Takayuki Miura, Yosuke Todo",
        "summary": "Deep Neural Networks (DNNs) have attracted significant attention, and their internal models are now considered valuable intellectual assets. Extracting these internal models through access to a DNN is conceptually similar to extracting a secret key via oracle access to a block cipher. Consequently, cryptanalytic techniques, particularly differential-like attacks, have been actively explored recently. ReLU-based DNNs are the most commonly and widely deployed architectures. While early works (e.g., Crypto 2020, Eurocrypt 2024) assume access to exact output logits, which are usually invisible, more recent works (e.g., Asiacrypt 2024, Eurocrypt 2025) focus on the hard-label setting, where only the final classification result (e.g., \"dog\" or \"car\") is available to the attacker. Notably, Carlini et al. (Eurocrypt 2025) demonstrated that model extraction is feasible in polynomial time even under this restricted setting. In this paper, we first show that the assumptions underlying their attack become increasingly unrealistic as the attack-target depth grows. In practice, satisfying these assumptions requires an exponential number of queries with respect to the attack depth, implying that the attack does not always run in polynomial time. To address this critical limitation, we propose a novel attack method called CrossLayer Extraction. Instead of directly extracting the secret parameters (e.g., weights and biases) of a specific neuron, which incurs exponential cost, we exploit neuron interactions across layers to extract this information from deeper layers. This technique significantly reduces query complexity and mitigates the limitations of existing model extraction approaches.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.450350"
    },
    {
        "index": "#56",
        "title": "AutoBalance: An Automatic Balancing Framework for Training Physics-Informed Neural Networks",
        "link": "/arxiv/2510.06684",
        "arxiv_id": "2510.06684",
        "authors": "Kang An, Chenhao Si, Ming Yan, Shiqian Ma",
        "summary": "Physics-Informed Neural Networks (PINNs) provide a powerful and general framework for solving Partial Differential Equations (PDEs) by embedding physical laws into loss functions. However, training PINNs is notoriously difficult due to the need to balance multiple loss terms, such as PDE residuals and boundary conditions, which often have conflicting objectives and vastly different curvatures. Existing methods address this issue by manipulating gradients before optimization (a \"pre-combine\" strategy). We argue that this approach is fundamentally limited, as forcing a single optimizer to process gradients from spectrally heterogeneous loss landscapes disrupts its internal preconditioning. In this work, we introduce AutoBalance, a novel \"post-combine\" training paradigm. AutoBalance assigns an independent adaptive optimizer to each loss component and aggregates the resulting preconditioned updates afterwards. Extensive experiments on challenging PDE benchmarks show that AutoBalance consistently outperforms existing frameworks, achieving significant reductions in solution error, as measured by both the MSE and $L^{\\infty}$ norms. Moreover, AutoBalance is orthogonal to and complementary with other popular PINN methodologies, amplifying their effectiveness on demanding benchmarks.",
        "subjects": "Machine Learning, Numerical Analysis, Optimization and Control",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.450661"
    },
    {
        "index": "#57",
        "title": "Distributed Algorithms for Multi-Agent Multi-Armed Bandits with Collision",
        "link": "/arxiv/2510.06683",
        "arxiv_id": "2510.06683",
        "authors": "Daoyuan Zhou, Xuchuang Wang, Lin Yang, Yang Gao",
        "summary": "We study the stochastic Multiplayer Multi-Armed Bandit (MMAB) problem, where multiple players select arms to maximize their cumulative rewards. Collisions occur when two or more players select the same arm, resulting in no reward, and are observed by the players involved. We consider a distributed setting without central coordination, where each player can only observe their own actions and collision feedback. We propose a distributed algorithm with an adaptive, efficient communication protocol. The algorithm achieves near-optimal group and individual regret, with a communication cost of only $\\mathcal{O}(\\log\\log T)$. Our experiments demonstrate significant performance improvements over existing baselines. Compared to state-of-the-art (SOTA) methods, our approach achieves a notable reduction in individual regret. Finally, we extend our approach to a periodic asynchronous setting, proving the lower bound for this problem and presenting an algorithm that achieves logarithmic regret.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.450949"
    },
    {
        "index": "#58",
        "title": "TimeFormer: Transformer with Attention Modulation Empowered by Temporal Characteristics for Time Series Forecasting",
        "link": "/arxiv/2510.06680",
        "arxiv_id": "2510.06680",
        "authors": "Zhipeng Liu, Peibo Duan, Xuan Tang, Baixin Li, Yongsheng Huang, Mingyang Geng, Changsheng Zhang, Bin Zhang, Binwu Wang",
        "summary": "Although Transformers excel in natural language processing, their extension to time series forecasting remains challenging due to insufficient consideration of the differences between textual and temporal modalities. In this paper, we develop a novel Transformer architecture designed for time series data, aiming to maximize its representational capacity. We identify two key but often overlooked characteristics of time series: (1) unidirectional influence from the past to the future, and (2) the phenomenon of decaying influence over time. These characteristics are introduced to enhance the attention mechanism of Transformers. We propose TimeFormer, whose core innovation is a self-attention mechanism with two modulation terms (MoSA), designed to capture these temporal priors of time series under the constraints of the Hawkes process and causal masking. Additionally, TimeFormer introduces a framework based on multi-scale and subsequence analysis to capture semantic dependencies at different temporal scales, enriching the temporal dependencies. Extensive experiments conducted on multiple real-world datasets show that TimeFormer significantly outperforms state-of-the-art methods, achieving up to a 7.45% reduction in MSE compared to the best baseline and setting new benchmarks on 94.04\\% of evaluation metrics. Moreover, we demonstrate that the MoSA mechanism can be broadly applied to enhance the performance of other Transformer-based models.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.451279"
    },
    {
        "index": "#59",
        "title": "XRPO: Pushing the limits of GRPO with Targeted Exploration and Exploitation",
        "link": "/arxiv/2510.06672",
        "arxiv_id": "2510.06672",
        "authors": "Udbhav Bamba, Minghao Fang, Yifan Yu, Haizhong Zheng, Fan Lai",
        "summary": "Reinforcement learning algorithms such as GRPO have driven recent advances in large language model (LLM) reasoning. While scaling the number of rollouts stabilizes training, existing approaches suffer from limited exploration on challenging prompts and leave informative feedback signals underexploited, due to context-independent rollout allocation across prompts (e.g., generating 16 rollouts per prompt) and relying heavily on sparse rewards. This paper presents XRPO(eXplore - eXploit GRPO), a unified framework that recasts policy optimization through the principled lens of rollout exploration-exploitation. To enhance exploration, XRPO introduces a mathematically grounded rollout allocator that adaptively prioritizes prompts with higher potential for uncertainty reduction. It further addresses stagnation on zero-reward prompts through an in-context seeding strategy that injects curated exemplars, steering the model into more difficult reasoning trajectories. To strengthen exploitation, XRPO develops a group-relative, novelty-aware advantage sharpening mechanism that leverages sequence likelihoods to amplify low-probability yet correct responses, thereby extending the policy's reach beyond sparse rewards. Experiments across diverse math and coding benchmarks on both reasoning and non-reasoning models demonstrate that XRPO outperforms existing advances (e.g., GRPO and GSPO) up to 4% pass@1 and 6% cons@32, while accelerating training convergence by up to 2.7X.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.451579"
    },
    {
        "index": "#60",
        "title": "The Effect of Attention Head Count on Transformer Approximation",
        "link": "/arxiv/2510.06662",
        "arxiv_id": "2510.06662",
        "authors": "Penghao Yu, Haotian Jiang, Zeyu Bao, Ruoxi Yu, Qianxiao Li",
        "summary": "Transformer has become the dominant architecture for sequence modeling, yet a detailed understanding of how its structural parameters influence expressive power remains limited. In this work, we study the approximation properties of transformers, with particular emphasis on the role of the number of attention heads. Our analysis begins with the introduction of a generalized $D$-retrieval task, which we prove to be dense in the space of continuous functions, thereby providing the basis for our theoretical framework. We then establish both upper and lower bounds on the parameter complexity required for $\\epsilon$-approximation. Specifically, we show that transformers with sufficiently many heads admit efficient approximation, whereas with too few heads, the number of parameters must scale at least as $O(1/\\epsilon^{cT})$, for some constant $c$ and sequence length $T$. To the best of our knowledge, this constitutes the first rigorous lower bound of this type in a nonlinear and practically relevant setting. We further examine the single-head case and demonstrate that an embedding dimension of order $O(T)$ allows complete memorization of the input, where approximation is entirely achieved by the feed-forward block. Finally, we validate our theoretical findings with experiments on both synthetic data and real-world tasks, illustrating the practical relevance of our results.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.451905"
    },
    {
        "index": "#61",
        "title": "Rethinking Nonlinearity: Trainable Gaussian Mixture Modules for Modern Neural Architectures",
        "link": "/arxiv/2510.06660",
        "arxiv_id": "2510.06660",
        "authors": "Weiguo Lu, Gangnan Yuan, Hong-kun Zhang, Shangyang Li",
        "summary": "Neural networks in general, from MLPs and CNNs to attention-based Transformers, are constructed from layers of linear combinations followed by nonlinear operations such as ReLU, Sigmoid, or Softmax. Despite their strength, these conventional designs are often limited in introducing non-linearity by the choice of activation functions. In this work, we introduce Gaussian Mixture-Inspired Nonlinear Modules (GMNM), a new class of differentiable modules that draw on the universal density approximation Gaussian mixture models (GMMs) and distance properties (metric space) of Gaussian kernal. By relaxing probabilistic constraints and adopting a flexible parameterization of Gaussian projections, GMNM can be seamlessly integrated into diverse neural architectures and trained end-to-end with gradient-based methods. Our experiments demonstrate that incorporating GMNM into architectures such as MLPs, CNNs, attention mechanisms, and LSTMs consistently improves performance over standard baselines. These results highlight GMNM's potential as a powerful and flexible module for enhancing efficiency and accuracy across a wide range of machine learning applications.",
        "subjects": "Machine Learning, Probability",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.452199"
    },
    {
        "index": "#62",
        "title": "Local Reinforcement Learning with Action-Conditioned Root Mean Squared Q-Functions",
        "link": "/arxiv/2510.06649",
        "arxiv_id": "2510.06649",
        "authors": "Frank Wu, Mengye Ren",
        "summary": "The Forward-Forward (FF) Algorithm is a recently proposed learning procedure for neural networks that employs two forward passes instead of the traditional forward and backward passes used in backpropagation. However, FF remains largely confined to supervised settings, leaving a gap at domains where learning signals can be yielded more naturally such as RL. In this work, inspired by FF's goodness function using layer activity statistics, we introduce Action-conditioned Root mean squared Q-Functions (ARQ), a novel value estimation method that applies a goodness function and action conditioning for local RL using temporal difference learning. Despite its simplicity and biological grounding, our approach achieves superior performance compared to state-of-the-art local backprop-free RL methods in the MinAtar and the DeepMind Control Suite benchmarks, while also outperforming algorithms trained with backpropagation on most tasks. Code can be found at https://github.com/agentic-learning-ai-lab/arq.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.452485"
    },
    {
        "index": "#63",
        "title": "The False Promise of Zero-Shot Super-Resolution in Machine-Learned Operators",
        "link": "/arxiv/2510.06646",
        "arxiv_id": "2510.06646",
        "authors": "Mansi Sakarvadia, Kareem Hegazy, Amin Totounferoush, Kyle Chard, Yaoqing Yang, Ian Foster, Michael W. Mahoney",
        "summary": "A core challenge in scientific machine learning, and scientific computing more generally, is modeling continuous phenomena which (in practice) are represented discretely. Machine-learned operators (MLOs) have been introduced as a means to achieve this modeling goal, as this class of architecture can perform inference at arbitrary resolution. In this work, we evaluate whether this architectural innovation is sufficient to perform \"zero-shot super-resolution,\" namely to enable a model to serve inference on higher-resolution data than that on which it was originally trained. We comprehensively evaluate both zero-shot sub-resolution and super-resolution (i.e., multi-resolution) inference in MLOs. We decouple multi-resolution inference into two key behaviors: 1) extrapolation to varying frequency information; and 2) interpolating across varying resolutions. We empirically demonstrate that MLOs fail to do both of these tasks in a zero-shot manner. Consequently, we find MLOs are not able to perform accurate inference at resolutions different from those on which they were trained, and instead they are brittle and susceptible to aliasing. To address these failure modes, we propose a simple, computationally-efficient, and data-driven multi-resolution training protocol that overcomes aliasing and that provides robust multi-resolution generalization.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.452827"
    },
    {
        "index": "#64",
        "title": "Control-Augmented Autoregressive Diffusion for Data Assimilation",
        "link": "/arxiv/2510.06637",
        "arxiv_id": "2510.06637",
        "authors": "Prakhar Srivastava, Farrin Marouf Sofian, Francesco Immorlano, Kushagra Pandey, Stephan Mandt",
        "summary": "Despite recent advances in test-time scaling and finetuning of diffusion models, guidance in Auto-Regressive Diffusion Models (ARDMs) remains underexplored. We introduce an amortized framework that augments pretrained ARDMs with a lightweight controller network, trained offline by previewing future ARDM rollouts and learning stepwise controls that anticipate upcoming observations under a terminal cost objective. We evaluate this framework in the context of data assimilation (DA) for chaotic spatiotemporal partial differential equations (PDEs), a setting where existing methods are often computationally prohibitive and prone to forecast drift under sparse observations. Our approach reduces DA inference to a single forward rollout with on-the-fly corrections, avoiding expensive adjoint computations and/or optimizations during inference. We demonstrate that our method consistently outperforms four state-of-the-art baselines in stability, accuracy, and physical fidelity across two canonical PDEs and six observation regimes. We will release code and checkpoints publicly.",
        "subjects": "Machine Learning, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.453150"
    },
    {
        "index": "#65",
        "title": "StruSR: Structure-Aware Symbolic Regression with Physics-Informed Taylor Guidance",
        "link": "/arxiv/2510.06635",
        "arxiv_id": "2510.06635",
        "authors": "Yunpeng Gong, Sihan Lan, Can Yang, Kunpeng Xu, Min Jiang",
        "summary": "Symbolic regression aims to find interpretable analytical expressions by searching over mathematical formula spaces to capture underlying system behavior, particularly in scientific modeling governed by physical laws. However, traditional methods lack mechanisms for extracting structured physical priors from time series observations, making it difficult to capture symbolic expressions that reflect the system's global behavior. In this work, we propose a structure-aware symbolic regression framework, called StruSR, that leverages trained Physics-Informed Neural Networks (PINNs) to extract locally structured physical priors from time series data. By performing local Taylor expansions on the outputs of the trained PINN, we obtain derivative-based structural information to guide symbolic expression evolution. To assess the importance of expression components, we introduce a masking-based attribution mechanism that quantifies each subtree's contribution to structural alignment and physical residual reduction. These sensitivity scores steer mutation and crossover operations within genetic programming, preserving substructures with high physical or structural significance while selectively modifying less informative components. A hybrid fitness function jointly minimizes physics residuals and Taylor coefficient mismatch, ensuring consistency with both the governing equations and the local analytical behavior encoded by the PINN. Experiments on benchmark PDE systems demonstrate that StruSR improves convergence speed, structural fidelity, and expression interpretability compared to conventional baselines, offering a principled paradigm for physics-grounded symbolic discovery.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.453465"
    },
    {
        "index": "#66",
        "title": "Three Forms of Stochastic Injection for Improved Distribution-to-Distribution Generative Modeling",
        "link": "/arxiv/2510.06634",
        "arxiv_id": "2510.06634",
        "authors": "Shiye Su, Yuhui Zhang, Linqi Zhou, Rajesh Ranganath, Serena Yeung-Levy",
        "summary": "Modeling transformations between arbitrary data distributions is a fundamental scientific challenge, arising in applications like drug discovery and evolutionary simulation. While flow matching offers a natural framework for this task, its use has thus far primarily focused on the noise-to-data setting, while its application in the general distribution-to-distribution setting is underexplored. We find that in the latter case, where the source is also a data distribution to be learned from limited samples, standard flow matching fails due to sparse supervision. To address this, we propose a simple and computationally efficient method that injects stochasticity into the training process by perturbing source samples and flow interpolants. On five diverse imaging tasks spanning biology, radiology, and astronomy, our method significantly improves generation quality, outperforming existing baselines by an average of 9 FID points. Our approach also reduces the transport cost between input and generated samples to better highlight the true effect of the transformation, making flow matching a more practical tool for simulating the diverse distribution transformations that arise in science.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.453768"
    },
    {
        "index": "#67",
        "title": "Chem-NMF: Multi-layer $α$-divergence Non-Negative Matrix Factorization for Cardiorespiratory Disease Clustering, with Improved Convergence Inspired by Chemical Catalysts and Rigorous Asymptotic Analysis",
        "link": "/arxiv/2510.06632",
        "arxiv_id": "2510.06632",
        "authors": "Yasaman Torabi, Shahram Shirani, James P. Reilly",
        "summary": "Non-Negative Matrix Factorization (NMF) is an unsupervised learning method offering low-rank representations across various domains such as audio processing, biomedical signal analysis, and image recognition. The incorporation of $\\alpha$-divergence in NMF formulations enhances flexibility in optimization, yet extending these methods to multi-layer architectures presents challenges in ensuring convergence. To address this, we introduce a novel approach inspired by the Boltzmann probability of the energy barriers in chemical reactions to theoretically perform convergence analysis. We introduce a novel method, called Chem-NMF, with a bounding factor which stabilizes convergence. To our knowledge, this is the first study to apply a physical chemistry perspective to rigorously analyze the convergence behaviour of the NMF algorithm. We start from mathematically proven asymptotic convergence results and then show how they apply to real data. Experimental results demonstrate that the proposed algorithm improves clustering accuracy by 5.6% $\\pm$ 2.7% on biomedical signals and 11.1% $\\pm$ 7.2% on face images (mean $\\pm$ std).",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.454068"
    },
    {
        "index": "#68",
        "title": "AI-Driven Forecasting and Monitoring of Urban Water System",
        "link": "/arxiv/2510.06631",
        "arxiv_id": "2510.06631",
        "authors": "Qiming Guo, Bishal Khatri, Hua Zhang, Wenlu Wang",
        "summary": "Underground water and wastewater pipelines are vital for city operations but plagued by anomalies like leaks and infiltrations, causing substantial water loss, environmental damage, and high repair costs. Conventional manual inspections lack efficiency, while dense sensor deployments are prohibitively expensive. In recent years, artificial intelligence has advanced rapidly and is increasingly applied to urban infrastructure. In this research, we propose an integrated AI and remote-sensor framework to address the challenge of leak detection in underground water pipelines, through deploying a sparse set of remote sensors to capture real-time flow and depth data, paired with HydroNet - a dedicated model utilizing pipeline attributes (e.g., material, diameter, slope) in a directed graph for higher-precision modeling. Evaluations on a real-world campus wastewater network dataset demonstrate that our system collects effective spatio-temporal hydraulic data, enabling HydroNet to outperform advanced baselines. This integration of edge-aware message passing with hydraulic simulations enables accurate network-wide predictions from limited sensor deployments. We envision that this approach can be effectively extended to a wide range of underground water pipeline networks.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.454583"
    },
    {
        "index": "#69",
        "title": "POME: Post Optimization Model Edit via Muon-style Projection",
        "link": "/arxiv/2510.06627",
        "arxiv_id": "2510.06627",
        "authors": "Yong Liu, Di Fu, Yang Luo, Zirui Zhu, Minhao Cheng, Cho-Jui Hsieh, Yang You",
        "summary": "We introduce Post-Optimization Model Edit (POME), a new algorithm that enhances the performance of fine-tuned large language models using only their pretrained and fine-tuned checkpoints, without requiring extra data or further optimization. The core idea is to apply a muon-style projection to $\\Delta W$, the difference between the fine-tuned and pretrained weights. This projection uses truncated singular value decomposition (SVD) to equalize the influence of dominant update directions and prune small singular values, which often represent noise. As a simple post-processing step, POME is completely decoupled from the training pipeline. It requires zero modifications and imposes no overhead, making it universally compatible with any optimizer or distributed framework. POME delivers consistent gains, boosting average performance by +2.5\\% on GSM8K and +1.0\\% on code generation. Its broad applicability -- from 7B foundation models to 72B RLHF-instructed models -- establishes it as a practical, zero-cost enhancement for any fine-tuning pipeline. Code is available at https://github.com/NUS-HPC-AI-Lab/POME.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.454903"
    },
    {
        "index": "#70",
        "title": "DPA-Net: A Dual-Path Attention Neural Network for Inferring Glycemic Control Metrics from Self-Monitored Blood Glucose Data",
        "link": "/arxiv/2510.06623",
        "arxiv_id": "2510.06623",
        "authors": "Canyu Lei, Benjamin Lobo, Jianxin Xie",
        "summary": "Continuous glucose monitoring (CGM) provides dense and dynamic glucose profiles that enable reliable estimation of Ambulatory Glucose Profile (AGP) metrics, such as Time in Range (TIR), Time Below Range (TBR), and Time Above Range (TAR). However, the high cost and limited accessibility of CGM restrict its widespread adoption, particularly in low- and middle-income regions. In contrast, self-monitoring of blood glucose (SMBG) is inexpensive and widely available but yields sparse and irregular data that are challenging to translate into clinically meaningful glycemic metrics. In this work, we propose a Dual-Path Attention Neural Network (DPA-Net) to estimate AGP metrics directly from SMBG data. DPA-Net integrates two complementary paths: (1) a spatial-channel attention path that reconstructs a CGM-like trajectory from sparse SMBG observations, and (2) a multi-scale ResNet path that directly predicts AGP metrics. An alignment mechanism between the two paths is introduced to reduce bias and mitigate overfitting. In addition, we develop an active point selector to identify realistic and informative SMBG sampling points that reflect patient behavioral patterns. Experimental results on a large, real-world dataset demonstrate that DPA-Net achieves robust accuracy with low errors while reducing systematic bias. To the best of our knowledge, this is the first supervised machine learning framework for estimating AGP metrics from SMBG data, offering a practical and clinically relevant decision-support tool in settings where CGM is not accessible.",
        "subjects": "Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.455181"
    },
    {
        "index": "#71",
        "title": "The Framework That Survives Bad Models: Human-AI Collaboration For Clinical Trials",
        "link": "/arxiv/2510.06567",
        "arxiv_id": "2510.06567",
        "authors": "Yao Chen, David Ohlssen, Aimee Readie, Gregory Ligozio, Ruvie Martin, Thibaud Coroller",
        "summary": "Artificial intelligence (AI) holds great promise for supporting clinical trials, from patient recruitment and endpoint assessment to treatment response prediction. However, deploying AI without safeguards poses significant risks, particularly when evaluating patient endpoints that directly impact trial conclusions. We compared two AI frameworks against human-only assessment for medical image-based disease evaluation, measuring cost, accuracy, robustness, and generalization ability. To stress-test these frameworks, we injected bad models, ranging from random guesses to naive predictions, to ensure that observed treatment effects remain valid even under severe model degradation. We evaluated the frameworks using two randomized controlled trials with endpoints derived from spinal X-ray images. Our findings indicate that using AI as a supporting reader (AI-SR) is the most suitable approach for clinical trials, as it meets all criteria across various model types, even with bad models. This method consistently provides reliable disease estimation, preserves clinical trial treatment effect estimates and conclusions, and retains these advantages when applied to different populations.",
        "subjects": "Machine Learning, Artificial Intelligence, Image and Video Processing",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.455524"
    },
    {
        "index": "#73",
        "title": "Incoherence in goal-conditioned autoregressive models",
        "link": "/arxiv/2510.06545",
        "arxiv_id": "2510.06545",
        "authors": "Jacek Karwowski, Raymond Douglas",
        "summary": "We investigate mathematically the notion of incoherence: a structural issue with reinforcement learning policies derived by naive goal-conditioning of autoregressive models. We focus on the process of re-training models on their own actions, that is, fine-tuning offline-learned policies with online RL. We prove that it decreases incoherence and leads to an improvement in return, and we aim to characterize the resulting trajectory of policies. By re-framing standard notions of control-as-inference and soft Q learning, we establish a three-way correspondence with two other ways of understanding the iterative re-training process: as folding the posterior into the reward and, in the deterministic case, as decreasing the temperature parameter; the correspondence has computational content via the training-inference trade-off. Through soft-conditioning generative models, we discuss the link between incoherence and the effective horizon.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.456224"
    },
    {
        "index": "#74",
        "title": "Scalable Policy-Based RL Algorithms for POMDPs",
        "link": "/arxiv/2510.06540",
        "arxiv_id": "2510.06540",
        "authors": "Ameya Anjarlekar, Rasoul Etesami, R Srikant",
        "summary": "The continuous nature of belief states in POMDPs presents significant computational challenges in learning the optimal policy. In this paper, we consider an approach that solves a Partially Observable Reinforcement Learning (PORL) problem by approximating the corresponding POMDP model into a finite-state Markov Decision Process (MDP) (called Superstate MDP). We first derive theoretical guarantees that improve upon prior work that relate the optimal value function of the transformed Superstate MDP to the optimal value function of the original POMDP. Next, we propose a policy-based learning approach with linear function approximation to learn the optimal policy for the Superstate MDP. Consequently, our approach shows that a POMDP can be approximately solved using TD-learning followed by Policy Optimization by treating it as an MDP, where the MDP state corresponds to a finite history. We show that the approximation error decreases exponentially with the length of this history. To the best of our knowledge, our finite-time bounds are the first to explicitly quantify the error introduced when applying standard TD learning to a setting where the true dynamics are not Markovian.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.456522"
    },
    {
        "index": "#75",
        "title": "Wide Neural Networks as a Baseline for the Computational No-Coincidence Conjecture",
        "link": "/arxiv/2510.06527",
        "arxiv_id": "2510.06527",
        "authors": "John Dunbar, Scott Aaronson",
        "summary": "We establish that randomly initialized neural networks, with large width and a natural choice of hyperparameters, have nearly independent outputs exactly when their activation function is nonlinear with zero mean under the Gaussian measure: $\\mathbb{E}_{z \\sim \\mathcal{N}(0,1)}[\\sigma(z)]=0$. For example, this includes ReLU and GeLU with an additive shift, as well as tanh, but not ReLU or GeLU by themselves. Because of their nearly independent outputs, we propose neural networks with zero-mean activation functions as a promising candidate for the Alignment Research Center's computational no-coincidence conjecture -- a conjecture that aims to measure the limits of AI interpretability.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.456795"
    },
    {
        "index": "#76",
        "title": "Text-to-Image Models Leave Identifiable Signatures: Implications for Leaderboard Security",
        "link": "/arxiv/2510.06525",
        "arxiv_id": "2510.06525",
        "authors": "Ali Naseh, Anshuman Suri, Yuefeng Peng, Harsh Chaudhari, Alina Oprea, Amir Houmansadr",
        "summary": "Generative AI leaderboards are central to evaluating model capabilities, but remain vulnerable to manipulation. Among key adversarial objectives is rank manipulation, where an attacker must first deanonymize the models behind displayed outputs -- a threat previously demonstrated and explored for large language models (LLMs). We show that this problem can be even more severe for text-to-image leaderboards, where deanonymization is markedly easier. Using over 150,000 generated images from 280 prompts and 19 diverse models spanning multiple organizations, architectures, and sizes, we demonstrate that simple real-time classification in CLIP embedding space identifies the generating model with high accuracy, even without prompt control or historical data. We further introduce a prompt-level separability metric and identify prompts that enable near-perfect deanonymization. Our results indicate that rank manipulation in text-to-image leaderboards is easier than previously recognized, underscoring the need for stronger defenses.",
        "subjects": "Machine Learning, Cryptography and Security",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.457111"
    },
    {
        "index": "#77",
        "title": "A Median Perspective on Unlabeled Data for Out-of-Distribution Detection",
        "link": "/arxiv/2510.06505",
        "arxiv_id": "2510.06505",
        "authors": "Momin Abbas, Ali Falahati, Hossein Goli, Mohammad Mohammadi Amiri",
        "summary": "Out-of-distribution (OOD) detection plays a crucial role in ensuring the robustness and reliability of machine learning systems deployed in real-world applications. Recent approaches have explored the use of unlabeled data, showing potential for enhancing OOD detection capabilities. However, effectively utilizing unlabeled in-the-wild data remains challenging due to the mixed nature of both in-distribution (InD) and OOD samples. The lack of a distinct set of OOD samples complicates the task of training an optimal OOD classifier. In this work, we introduce Medix, a novel framework designed to identify potential outliers from unlabeled data using the median operation. We use the median because it provides a stable estimate of the central tendency, as an OOD detection mechanism, due to its robustness against noise and outliers. Using these identified outliers, along with labeled InD data, we train a robust OOD classifier. From a theoretical perspective, we derive error bounds that demonstrate Medix achieves a low error rate. Empirical results further substantiate our claims, as Medix outperforms existing methods across the board in open-world settings, confirming the validity of our theoretical insights.",
        "subjects": "Machine Learning, Artificial Intelligence, Optimization and Control, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.457430"
    },
    {
        "index": "#78",
        "title": "ATLO-ML: Adaptive Time-Length Optimizer for Machine Learning -- Insights from Air Quality Forecasting",
        "link": "/arxiv/2510.06503",
        "arxiv_id": "2510.06503",
        "authors": "I-Hsi Kao, Kanji Uchino",
        "summary": "Accurate time-series predictions in machine learning are heavily influenced by the selection of appropriate input time length and sampling rate. This paper introduces ATLO-ML, an adaptive time-length optimization system that automatically determines the optimal input time length and sampling rate based on user-defined output time length. The system provides a flexible approach to time-series data pre-processing, dynamically adjusting these parameters to enhance predictive performance. ATLO-ML is validated using air quality datasets, including both GAMS-dataset and proprietary data collected from a data center, both in time series format. Results demonstrate that utilizing the optimized time length and sampling rate significantly improves the accuracy of machine learning models compared to fixed time lengths. ATLO-ML shows potential for generalization across various time-sensitive applications, offering a robust solution for optimizing temporal input parameters in machine learning workflows.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.457712"
    },
    {
        "index": "#79",
        "title": "GUIDE: Guided Initialization and Distillation of Embeddings",
        "link": "/arxiv/2510.06502",
        "arxiv_id": "2510.06502",
        "authors": "Khoa Trinh, Gaurav Menghani, Erik Vee",
        "summary": "Algorithmic efficiency techniques such as distillation (\\cite{hinton2015distillation}) are useful in improving model quality without increasing serving costs, provided a larger teacher model is available for a smaller student model to learn from during training. Standard distillation methods are limited to only forcing the student to match the teacher's outputs. Given the costs associated with training a large model, we believe we should be extracting more useful information from a teacher model than by just making the student match the teacher's outputs. In this paper, we introduce \\guide (Guided Initialization and Distillation of Embeddings). \\guide can be considered a distillation technique that forces the student to match the teacher in the parameter space. Using \\guide we show 25-26\\% reduction in the teacher-student quality gap when using large student models (400M - 1B parameters) trained on $\\approx$ 20B tokens. We also present a thorough analysis demonstrating that \\guide can be combined with knowledge distillation with near additive improvements. Furthermore, we show that applying \\guide alone leads to substantially better model quality than applying knowledge distillation by itself. Most importantly, \\guide introduces no training or inference overhead and hence any model quality gains from our method are virtually free.",
        "subjects": "Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.457981"
    },
    {
        "index": "#80",
        "title": "Valid Stopping for LLM Generation via Empirical Dynamic Formal Lift",
        "link": "/arxiv/2510.06478",
        "arxiv_id": "2510.06478",
        "authors": "Sanjeda Akter, Ibne Farabi Shihab, Anuj Sharma",
        "summary": "We introduce Sequential-EDFL (Empirical Dynamic Formal Lift), applying anytime-valid sequential testing to language model generation stopping. Our approach tracks information lift -- the log-likelihood ratio between full models and deliberately weakened \"skeleton\" baselines -- using self-normalized empirical-Bernstein e-processes that provide formal delta-level error control regardless of stopping time. We handle unknown centering through online mean estimation, combine multiple parameters via mixture e-processes, and support adaptive resets under distributional drift. On six benchmarks, Sequential-EDFL reduces generation by 22-28% vs. sequential baselines while maintaining delta-level control with 12% computational overhead. We introduce automated skeletons (distilled submodels, randomized logits) and show robustness across skeleton families. Composing EDFL with a lightweight correctness gate (sentence boundaries + verifier) improves end-task correctness while preserving anytime-valid guarantees by only delaying stopping. Our certificates control information sufficiency, not factual correctness -- 10.9% of stopped sequences remain incorrect even with the gate (13.2-22.7% without it). EDFL serves as a first-stage filter reducing verification burden by 83%, not as a standalone solution for safety-critical domains.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.458264"
    },
    {
        "index": "#81",
        "title": "Attention Sinks and Compression Valleys in LLMs are Two Sides of the Same Coin",
        "link": "/arxiv/2510.06477",
        "arxiv_id": "2510.06477",
        "authors": "Enrique Queipo-de-Llano, Álvaro Arroyo, Federico Barbero, Xiaowen Dong, Michael Bronstein, Yann LeCun, Ravid Shwartz-Ziv",
        "summary": "Attention sinks and compression valleys have attracted significant attention as two puzzling phenomena in large language models, but have been studied in isolation. In this work, we present a surprising connection between attention sinks and compression valleys, tracing both to the formation of massive activations in the residual stream. We prove theoretically that massive activations necessarily produce representational compression and establish bounds on the resulting entropy reduction. Through experiments across several models (410M-120B parameters), we confirm that when the beginning-of-sequence token develops extreme activation norms in the middle layers, both compression valleys and attention sinks emerge simultaneously. Targeted ablation studies validate our theoretical predictions. This unified view motivates us to propose the Mix-Compress-Refine theory of information flow, as an attempt to explain how LLMs organize their computation in depth by controlling attention and representational compression via massive activations. Specifically, we posit that Transformer-based LLMs process tokens in three distinct phases: (1) broad mixing in the early layers, (2) compressed computation with limited mixing in the middle layers, and (3) selective refinement in the late layers. Our framework helps explain why embedding tasks perform best at intermediate layers, whereas generation tasks benefit from full-depth processing, clarifying differences in task-dependent representations.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.458581"
    },
    {
        "index": "#82",
        "title": "How NOT to benchmark your SITE metric: Beyond Static Leaderboards and Towards Realistic Evaluation",
        "link": "/arxiv/2510.06448",
        "arxiv_id": "2510.06448",
        "authors": "Prabhant Singh, Sibylle Hess, Joaquin Vanschoren",
        "summary": "Transferability estimation metrics are used to find a high-performing pre-trained model for a given target task without fine-tuning models and without access to the source dataset. Despite the growing interest in developing such metrics, the benchmarks used to measure their progress have gone largely unexamined. In this work, we empirically show the shortcomings of widely used benchmark setups to evaluate transferability estimation metrics. We argue that the benchmarks on which these metrics are evaluated are fundamentally flawed. We empirically demonstrate that their unrealistic model spaces and static performance hierarchies artificially inflate the perceived performance of existing metrics, to the point where simple, dataset-agnostic heuristics can outperform sophisticated methods. Our analysis reveals a critical disconnect between current evaluation protocols and the complexities of real-world model selection. To address this, we provide concrete recommendations for constructing more robust and realistic benchmarks to guide future research in a more meaningful direction.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.458861"
    },
    {
        "index": "#83",
        "title": "Context-Aware Inference via Performance Forecasting in Decentralized Learning Networks",
        "link": "/arxiv/2510.06444",
        "arxiv_id": "2510.06444",
        "authors": "Joel Pfeffer, J. M. Diederik Kruijssen, Clément Gossart, Mélanie Chevance, Diego Campo Millan, Florian Stecker, Steven N. Longmore",
        "summary": "In decentralized learning networks, predictions from many participants are combined to generate a network inference. While many studies have demonstrated performance benefits of combining multiple model predictions, existing strategies using linear pooling methods (ranging from simple averaging to dynamic weight updates) face a key limitation. Dynamic prediction combinations that rely on historical performance to update weights are necessarily reactive. Due to the need to average over a reasonable number of epochs (with moving averages or exponential weighting), they tend to be slow to adjust to changing circumstances (phase or regime changes). In this work, we develop a model that uses machine learning to forecast the performance of predictions by models at each epoch in a time series. This enables `context-awareness' by assigning higher weight to models that are likely to be more accurate at a given time. We show that adding a performance forecasting worker in a decentralized learning network, following a design similar to the Allora network, can improve the accuracy of network inferences. Specifically, we find forecasting models that predict regret (performance relative to the network inference) or regret z-score (performance relative to other workers) show greater improvement than models predicting losses, which often do not outperform the naive network inference (historically weighted average of all inferences). Through a series of optimization tests, we show that the performance of the forecasting model can be sensitive to choices in the feature set and number of training epochs. These properties may depend on the exact problem and should be tailored to each domain. Although initially designed for a decentralized learning network, using performance forecasting for prediction combination may be useful in any situation where predictive rather than reactive model weighting is needed.",
        "subjects": "Machine Learning, Artificial Intelligence, Distributed, Parallel, and Cluster Computing",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.459190"
    },
    {
        "index": "#84",
        "title": "Bayesian Optimization under Uncertainty for Training a Scale Parameter in Stochastic Models",
        "link": "/arxiv/2510.06439",
        "arxiv_id": "2510.06439",
        "authors": "Akash Yadav, Ruda Zhang",
        "summary": "Hyperparameter tuning is a challenging problem especially when the system itself involves uncertainty. Due to noisy function evaluations, optimization under uncertainty can be computationally expensive. In this paper, we present a novel Bayesian optimization framework tailored for hyperparameter tuning under uncertainty, with a focus on optimizing a scale- or precision-type parameter in stochastic models. The proposed method employs a statistical surrogate for the underlying random variable, enabling analytical evaluation of the expectation operator. Moreover, we derive a closed-form expression for the optimizer of the random acquisition function, which significantly reduces computational cost per iteration. Compared with a conventional one-dimensional Monte Carlo-based optimization scheme, the proposed approach requires 40 times fewer data points, resulting in up to a 40-fold reduction in computational cost. We demonstrate the effectiveness of the proposed method through two numerical examples in computational engineering.",
        "subjects": "Machine Learning, Computational Engineering, Finance, and Science, Optimization and Control, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.459478"
    },
    {
        "index": "#85",
        "title": "Nearly Instance-Optimal Parameter Recovery from Many Trajectories via Hellinger Localization",
        "link": "/arxiv/2510.06434",
        "arxiv_id": "2510.06434",
        "authors": "Eliot Shekhtman, Yichen Zhou, Ingvar Ziemann, Nikolai Matni, Stephen Tu",
        "summary": "Learning from temporally-correlated data is a core facet of modern machine learning. Yet our understanding of sequential learning remains incomplete, particularly in the multi-trajectory setting where data consists of many independent realizations of a time-indexed stochastic process. This important regime both reflects modern training pipelines such as for large foundation models, and offers the potential for learning without the typical mixing assumptions made in the single-trajectory case. However, instance-optimal bounds are known only for least-squares regression with dependent covariates; for more general models or loss functions, the only broadly applicable guarantees result from a reduction to either i.i.d. learning, with effective sample size scaling only in the number of trajectories, or an existing single-trajectory result when each individual trajectory mixes, with effective sample size scaling as the full data budget deflated by the mixing-time. In this work, we significantly broaden the scope of instance-optimal rates in multi-trajectory settings via the Hellinger localization framework, a general approach for maximum likelihood estimation. Our method proceeds by first controlling the squared Hellinger distance at the path-measure level via a reduction to i.i.d. learning, followed by localization as a quadratic form in parameter space weighted by the trajectory Fisher information. This yields instance-optimal bounds that scale with the full data budget under a broad set of conditions. We instantiate our framework across four diverse case studies: a simple mixture of Markov chains, dependent linear regression under non-Gaussian noise, generalized linear models with non-monotonic activations, and linear-attention sequence models. In all cases, our bounds nearly match the instance-optimal rates from asymptotic normality, substantially improving over standard reductions.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.459907"
    },
    {
        "index": "#86",
        "title": "Test-Time Efficient Pretrained Model Portfolios for Time Series Forecasting",
        "link": "/arxiv/2510.06419",
        "arxiv_id": "2510.06419",
        "authors": "Mert Kayaalp, Caner Turkmen, Oleksandr Shchur, Pedro Mercado, Abdul Fatir Ansari, Michael Bohlke-Schneider, Bernie Wang",
        "summary": "Is bigger always better for time series foundation models? With the question in mind, we explore an alternative to training a single, large monolithic model: building a portfolio of smaller, pretrained forecasting models. By applying ensembling or model selection over these portfolios, we achieve competitive performance on large-scale benchmarks using much fewer parameters. We explore strategies for designing such portfolios and find that collections of specialist models consistently outperform portfolios of independently trained generalists. Remarkably, we demonstrate that post-training a base model is a compute-effective approach for creating sufficiently diverse specialists, and provide evidences that ensembling and model selection are more compute-efficient than test-time fine-tuning.",
        "subjects": "Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.460209"
    },
    {
        "index": "#87",
        "title": "The Effect of Label Noise on the Information Content of Neural Representations",
        "link": "/arxiv/2510.06401",
        "arxiv_id": "2510.06401",
        "authors": "Ali Hussaini Umar, Franky Kevin Nando Tezoh, Jean Barbier, Santiago Acevedo, Alessandro Laio",
        "summary": "In supervised classification tasks, models are trained to predict a label for each data point. In real-world datasets, these labels are often noisy due to annotation errors. While the impact of label noise on the performance of deep learning models has been widely studied, its effects on the networks' hidden representations remain poorly understood. We address this gap by systematically comparing hidden representations using the Information Imbalance, a computationally efficient proxy of conditional mutual information. Through this analysis, we observe that the information content of the hidden representations follows a double descent as a function of the number of network parameters, akin to the behavior of the test error. We further demonstrate that in the underparameterized regime, representations learned with noisy labels are more informative than those learned with clean labels, while in the overparameterized regime, these representations are equally informative. Our results indicate that the representations of overparameterized networks are robust to label noise. We also found that the information imbalance between the penultimate and pre-softmax layers decreases with cross-entropy loss in the overparameterized regime. This offers a new perspective on understanding generalization in classification tasks. Extending our analysis to representations learned from random labels, we show that these perform worse than random features. This indicates that training on random labels drives networks much beyond lazy learning, as weights adapt to encode labels information.",
        "subjects": "Machine Learning, Information Theory, Neural and Evolutionary Computing, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.460533"
    },
    {
        "index": "#88",
        "title": "Geometry-Aware Backdoor Attacks: Leveraging Curvature in Hyperbolic Embeddings",
        "link": "/arxiv/2510.06397",
        "arxiv_id": "2510.06397",
        "authors": "Ali Baheri",
        "summary": "Non-Euclidean foundation models increasingly place representations in curved spaces such as hyperbolic geometry. We show that this geometry creates a boundary-driven asymmetry that backdoor triggers can exploit. Near the boundary, small input changes appear subtle to standard input-space detectors but produce disproportionately large shifts in the model's representation space. Our analysis formalizes this effect and also reveals a limitation for defenses: methods that act by pulling points inward along the radius can suppress such triggers, but only by sacrificing useful model sensitivity in that same direction. Building on these insights, we propose a simple geometry-adaptive trigger and evaluate it across tasks and architectures. Empirically, attack success increases toward the boundary, whereas conventional detectors weaken, mirroring the theoretical trends. Together, these results surface a geometry-specific vulnerability in non-Euclidean models and offer analysis-backed guidance for designing and understanding the limits of defenses.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.460801"
    },
    {
        "index": "#89",
        "title": "Making and Evaluating Calibrated Forecasts",
        "link": "/arxiv/2510.06388",
        "arxiv_id": "2510.06388",
        "authors": "Yuxuan Lu, Yifan Wu, Jason Hartline, Lunjia Hu",
        "summary": "Calibrated predictions can be reliably interpreted as probabilities. An important step towards achieving better calibration is to design an appropriate calibration measure to meaningfully assess the miscalibration level of a predictor. A recent line of work initiated by Haghtalab et al. [2024] studies the design of truthful calibration measures: a truthful measure is minimized when a predictor outputs the true probabilities, whereas a non-truthful measure incentivizes the predictor to lie so as to appear more calibrated. All previous calibration measures were non-truthful until Hartline et al. [2025] introduced the first perfectly truthful calibration measures for binary prediction tasks in the batch setting. We introduce a perfectly truthful calibration measure for multi-class prediction tasks, generalizing the work of Hartline et al. [2025] beyond binary prediction. We study common methods of extending calibration measures from binary to multi-class prediction and identify ones that do or do not preserve truthfulness. In addition to truthfulness, we mathematically prove and empirically verify that our calibration measure exhibits superior robustness: it robustly preserves the ordering between dominant and dominated predictors, regardless of the choice of hyperparameters (bin sizes). This result addresses the non-robustness issue of binned ECE, which has been observed repeatedly in prior work.",
        "subjects": "Machine Learning, Data Structures and Algorithms, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.461101"
    },
    {
        "index": "#90",
        "title": "Monte Carlo Permutation Search",
        "link": "/arxiv/2510.06381",
        "arxiv_id": "2510.06381",
        "authors": "Tristan Cazenave",
        "summary": "We propose Monte Carlo Permutation Search (MCPS), a general-purpose Monte Carlo Tree Search (MCTS) algorithm that improves upon the GRAVE algorithm. MCPS is relevant when deep reinforcement learning is not an option, or when the computing power available before play is not substantial, such as in General Game Playing, for example. The principle of MCPS is to include in the exploration term of a node the statistics on all the playouts that contain all the moves on the path from the root to the node. We extensively test MCPS on a variety of games: board games, wargame, investment game, video game and multi-player games. MCPS has better results than GRAVE in all the two-player games. It has equivalent results for multi-player games because these games are inherently balanced even when players have different strengths. We also show that using abstract codes for moves instead of exact codes can be beneficial to both MCPS and GRAVE, as they improve the permutation statistics and the AMAF statistics. We also provide a mathematical derivation of the formulas used for weighting the three sources of statistics. These formulas are an improvement on the GRAVE formula since they no longer use the bias hyperparameter of GRAVE. Moreover, MCPS is not sensitive to the ref hyperparameter.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.461367"
    },
    {
        "index": "#91",
        "title": "Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data",
        "link": "/arxiv/2510.06377",
        "arxiv_id": "2510.06377",
        "authors": "Rishabh Ranjan, Valter Hudovernik, Mark Znidar, Charilaos Kanatsoulis, Roshan Upendra, Mahmoud Mohammadi, Joe Meyer, Tom Palczewski, Carlos Guestrin, Jure Leskovec",
        "summary": "Pretrained transformers readily adapt to new sequence modeling tasks via zero-shot prompting, but relational domains still lack architectures that transfer across datasets and tasks. The core challenge is the diversity of relational data, with varying heterogeneous schemas, graph structures and functional dependencies. In this paper, we present the Relational Transformer (RT) architecture, which can be pretrained on diverse relational databases and directly applied to unseen datasets and tasks without task- or dataset-specific fine-tuning, or retrieval of in-context examples. RT (i) tokenizes cells with table/column metadata, (ii) is pretrained via masked token prediction, and (iii) utilizes a novel \\textit{Relational Attention} mechanism over columns, rows, and primary-foreign key links. Pretrained on RelBench datasets spanning tasks such as churn and sales forecasting, RT attains strong zero-shot performance, averaging 94% of fully supervised AUROC on binary classification tasks with a single forward pass of a 22M parameter model, as opposed to 84% for a 27B LLM. Fine-tuning yields state-of-the-art results with high sample efficiency. Our experiments show that RT's zero-shot transfer harnesses task-table context, relational attention patterns and schema semantics. Overall, RT provides a practical path toward foundation models for relational data.",
        "subjects": "Machine Learning, Artificial Intelligence, Databases",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.461718"
    },
    {
        "index": "#92",
        "title": "Lagrangian neural ODEs: Measuring the existence of a Lagrangian with Helmholtz metrics",
        "link": "/arxiv/2510.06367",
        "arxiv_id": "2510.06367",
        "authors": "Luca Wolf, Tobias Buck, Bjoern Malte Schaefer",
        "summary": "Neural ODEs are a widely used, powerful machine learning technique in particular for physics. However, not every solution is physical in that it is an Euler-Lagrange equation. We present Helmholtz metrics to quantify this resemblance for a given ODE and demonstrate their capabilities on several fundamental systems with noise. We combine them with a second order neural ODE to form a Lagrangian neural ODE, which allows to learn Euler-Lagrange equations in a direct fashion and with zero additional inference cost. We demonstrate that, using only positional data, they can distinguish Lagrangian and non-Lagrangian systems and improve the neural ODE solutions.",
        "subjects": "Machine Learning, Dynamical Systems, Computational Physics, Data Analysis, Statistics and Probability",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.462040"
    },
    {
        "index": "#93",
        "title": "PIKAN: Physics-Inspired Kolmogorov-Arnold Networks for Explainable UAV Channel Modelling",
        "link": "/arxiv/2510.06355",
        "arxiv_id": "2510.06355",
        "authors": "Kürşat Tekbıyık, Güneş Karabulut Kurt, Antoine Lesage-Landry",
        "summary": "Unmanned aerial vehicle (UAV) communications demand accurate yet interpretable air-to-ground (A2G) channel models that can adapt to nonstationary propagation environments. While deterministic models offer interpretability and deep learning (DL) models provide accuracy, both approaches suffer from either rigidity or a lack of explainability. To bridge this gap, we propose the Physics-Inspired Kolmogorov-Arnold Network (PIKAN) that embeds physical principles (e.g., free-space path loss, two-ray reflections) into the learning process. Unlike physics-informed neural networks (PINNs), PIKAN is more flexible for applying physical information because it introduces them as flexible inductive biases. Thus, it enables a more flexible training process. Experiments on UAV A2G measurement data show that PIKAN achieves comparable accuracy to DL models while providing symbolic and explainable expressions aligned with propagation laws. Remarkably, PIKAN achieves this performance with only 232 parameters, making it up to 37 times lighter than multilayer perceptron (MLP) baselines with thousands of parameters, without sacrificing correlation with measurements and also providing symbolic expressions. These results highlight PIKAN as an efficient, interpretable, and scalable solution for UAV channel modelling in beyond-5G and 6G networks.",
        "subjects": "Machine Learning, Signal Processing",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.462335"
    },
    {
        "index": "#95",
        "title": "SDAR: A Synergistic Diffusion-AutoRegression Paradigm for Scalable Sequence Generation",
        "link": "/arxiv/2510.06303",
        "arxiv_id": "2510.06303",
        "authors": "Shuang Cheng, Yihan Bian, Dawei Liu, Yuhua Jiang, Yihao Liu, Linfeng Zhang, Wenhai Wang, Qipeng Guo, Kai Chen, Biqing Qi, Bowen Zhou",
        "summary": "We propose SDAR, a Synergistic Diffusion-Autoregression paradigm that unifies the training efficiency of autoregressive models with the parallel inference capability of diffusion. Instead of costly end-to-end diffusion training, SDAR performs a lightweight paradigm conversion that transforms a well-trained autoregressive (AR) model into a blockwise diffusion model through brief, data-efficient adaptation. During inference, SDAR generates sequences autoregressively across blocks for global coherence while decoding all tokens within each block in parallel via a discrete diffusion process. Extensive experiments show that AR models remain substantially more compute-efficient than masked diffusion models, providing a strong foundation for adaptation. Building on this insight, SDAR achieves efficient AR-to-diffusion conversion with minimal cost, preserving AR-level performance while enabling parallel generation. Scaling studies across dense and Mixture-of-Experts architectures confirm that SDAR scales without compromise: larger models exhibit stronger robustness to block size and decoding thresholds, yielding greater speedups without accuracy loss. Beyond efficiency, SDAR demonstrates enhanced reasoning and domain adaptability. Our 30B MoE model surpasses its AR counterpart on challenging scientific reasoning benchmarks such as GPQA and ChemBench, and gains further improvements under test-time scaling methods like majority voting and pass@k. Together, these results establish SDAR as a practical paradigm that combines the strengths of autoregression and diffusion for scalable, high-throughput reasoning.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.463008"
    },
    {
        "index": "#96",
        "title": "BlockGPT: Spatio-Temporal Modelling of Rainfall via Frame-Level Autoregression",
        "link": "/arxiv/2510.06293",
        "arxiv_id": "2510.06293",
        "authors": "Cristian Meo, Varun Sarathchandran, Avijit Majhi, Shao Hung, Carlo Saccardi, Ruben Imhoff, Roberto Deidda, Remko Uijlenhoet, Justin Dauwels",
        "summary": "Predicting precipitation maps is a highly complex spatiotemporal modeling task, critical for mitigating the impacts of extreme weather events. Short-term precipitation forecasting, or nowcasting, requires models that are not only accurate but also computationally efficient for real-time applications. Current methods, such as token-based autoregressive models, often suffer from flawed inductive biases and slow inference, while diffusion models can be computationally intensive. To address these limitations, we introduce BlockGPT, a generative autoregressive transformer using batched tokenization (Block) method that predicts full two-dimensional fields (frames) at each time step. Conceived as a model-agnostic paradigm for video prediction, BlockGPT factorizes space-time by using self-attention within each frame and causal attention across frames; in this work, we instantiate it for precipitation nowcasting. We evaluate BlockGPT on two precipitation datasets, viz. KNMI (Netherlands) and SEVIR (U.S.), comparing it to state-of-the-art baselines including token-based (NowcastingGPT) and diffusion-based (DiffCast+Phydnet) models. The results show that BlockGPT achieves superior accuracy, event localization as measured by categorical metrics, and inference speeds up to 31x faster than comparable baselines.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.463355"
    },
    {
        "index": "#97",
        "title": "Traj-Transformer: Diffusion Models with Transformer for GPS Trajectory Generation",
        "link": "/arxiv/2510.06291",
        "arxiv_id": "2510.06291",
        "authors": "Zhiyang Zhang, Ningcong Chen, Xin Zhang, Yanhua Li, Shen Su, Hui Lu, Jun Luo",
        "summary": "The widespread use of GPS devices has driven advances in spatiotemporal data mining, enabling machine learning models to simulate human decision making and generate realistic trajectories, addressing both data collection costs and privacy concerns. Recent studies have shown the promise of diffusion models for high-quality trajectory generation. However, most existing methods rely on convolution based architectures (e.g. UNet) to predict noise during the diffusion process, which often results in notable deviations and the loss of fine-grained street-level details due to limited model capacity. In this paper, we propose Trajectory Transformer, a novel model that employs a transformer backbone for both conditional information embedding and noise prediction. We explore two GPS coordinate embedding strategies, location embedding and longitude-latitude embedding, and analyze model performance at different scales. Experiments on two real-world datasets demonstrate that Trajectory Transformer significantly enhances generation quality and effectively alleviates the deviation issues observed in prior approaches.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.463679"
    },
    {
        "index": "#98",
        "title": "On knot detection via picture recognition",
        "link": "/arxiv/2510.06284",
        "arxiv_id": "2510.06284",
        "authors": "Anne Dranowski, Yura Kabkov, Daniel Tubbenhauer",
        "summary": "Our goal is to one day take a photo of a knot and have a phone automatically recognize it. In this expository work, we explain a strategy to approximate this goal, using a mixture of modern machine learning methods (in particular convolutional neural networks and transformers for image recognition) and traditional algorithms (to compute quantum invariants like the Jones polynomial). We present simple baselines that predict crossing number directly from images, showing that even lightweight CNN and transformer architectures can recover meaningful structural information. The longer-term aim is to combine these perception modules with symbolic reconstruction into planar diagram (PD) codes, enabling downstream invariant computation for robust knot classification. This two-stage approach highlights the complementarity between machine learning, which handles noisy visual data, and invariants, which enforce rigorous topological distinctions.",
        "subjects": "Machine Learning, Computer Vision and Pattern Recognition, Geometric Topology",
        "date": "2025-10-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.463988"
    },
    {
        "index": "#99",
        "title": "RVFL-X: A Novel Randomized Network Based on Complex Transformed Real-Valued Tabular Datasets",
        "link": "/arxiv/2510.06278",
        "arxiv_id": "2510.06278",
        "authors": "M. Sajid, Mushir Akhtar, A. Quadir, M. Tanveer",
        "summary": "Recent advancements in neural networks, supported by foundational theoretical insights, emphasize the superior representational power of complex numbers. However, their adoption in randomized neural networks (RNNs) has been limited due to the lack of effective methods for transforming real-valued tabular datasets into complex-valued representations. To address this limitation, we propose two methods for generating complex-valued representations from real-valued datasets: a natural transformation and an autoencoder-driven method. Building on these mechanisms, we propose RVFL-X, a complex-valued extension of the random vector functional link (RVFL) network. RVFL-X integrates complex transformations into real-valued datasets while maintaining the simplicity and efficiency of the original RVFL architecture. By leveraging complex components such as input, weights, and activation functions, RVFL-X processes complex representations and produces real-valued outputs. Comprehensive evaluations on 80 real-valued UCI datasets demonstrate that RVFL-X consistently outperforms both the original RVFL and state-of-the-art (SOTA) RNN variants, showcasing its robustness and effectiveness across diverse application domains.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.464277"
    },
    {
        "index": "#100",
        "title": "MCCE: A Framework for Multi-LLM Collaborative Co-Evolution",
        "link": "/arxiv/2510.06270",
        "arxiv_id": "2510.06270",
        "authors": "Nian Ran, Zhongzheng Li, Yue Wang, Qingsong Ran, Xiaoyuan Zhang, Shikun Feng, Richard Allmendinger, Xiaoguang Zhao",
        "summary": "Multi-objective discrete optimization problems, such as molecular design, pose significant challenges due to their vast and unstructured combinatorial spaces. Traditional evolutionary algorithms often get trapped in local optima, while expert knowledge can provide crucial guidance for accelerating convergence. Large language models (LLMs) offer powerful priors and reasoning ability, making them natural optimizers when expert knowledge matters. However, closed-source LLMs, though strong in exploration, cannot update their parameters and thus cannot internalize experience. Conversely, smaller open models can be continually fine-tuned but lack broad knowledge and reasoning strength. We introduce Multi-LLM Collaborative Co-evolution (MCCE), a hybrid framework that unites a frozen closed-source LLM with a lightweight trainable model. The system maintains a trajectory memory of past search processes; the small model is progressively refined via reinforcement learning, with the two models jointly supporting and complementing each other in global exploration. Unlike model distillation, this process enhances the capabilities of both models through mutual inspiration. Experiments on multi-objective drug design benchmarks show that MCCE achieves state-of-the-art Pareto front quality and consistently outperforms baselines. These results highlight a new paradigm for enabling continual evolution in hybrid LLM systems, combining knowledge-driven exploration with experience-driven learning.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.464609"
    },
    {
        "index": "#101",
        "title": "RareGraph-Synth: Knowledge-Guided Diffusion Models for Generating Privacy-Preserving Synthetic Patient Trajectories in Ultra-Rare Diseases",
        "link": "/arxiv/2510.06267",
        "arxiv_id": "2510.06267",
        "authors": "Khartik Uppalapati, Shakeel Abdulkareem, Bora Yimenicioglu",
        "summary": "We propose RareGraph-Synth, a knowledge-guided, continuous-time diffusion framework that generates realistic yet privacy-preserving synthetic electronic-health-record (EHR) trajectories for ultra-rare diseases. RareGraph-Synth unifies five public resources: Orphanet/Orphadata, the Human Phenotype Ontology (HPO), the GARD rare-disease KG, PrimeKG, and the FDA Adverse Event Reporting System (FAERS) into a heterogeneous knowledge graph comprising approximately 8 M typed edges. Meta-path scores extracted from this 8-million-edge KG modulate the per-token noise schedule in the forward stochastic differential equation, steering generation toward biologically plausible lab-medication-adverse-event co-occurrences while retaining score-based diffusion model stability. The reverse denoiser then produces timestamped sequences of lab-code, medication-code, and adverse-event-flag triples that contain no protected health information. On simulated ultra-rare-disease cohorts, RareGraph-Synth lowers categorical Maximum Mean Discrepancy by 40 percent relative to an unguided diffusion baseline and by greater than 60 percent versus GAN counterparts, without sacrificing downstream predictive utility. A black-box membership-inference evaluation using the DOMIAS attacker yields AUROC approximately 0.53, well below the 0.55 safe-release threshold and substantially better than the approximately 0.61 plus or minus 0.03 observed for non-KG baselines, demonstrating strong resistance to re-identification. These results suggest that integrating biomedical knowledge graphs directly into diffusion noise schedules can simultaneously enhance fidelity and privacy, enabling safer data sharing for rare-disease research.",
        "subjects": "Machine Learning, Artificial Intelligence",
        "date": "2025-10-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.470214"
    },
    {
        "index": "#104",
        "title": "Cocoon: A System Architecture for Differentially Private Training with Correlated Noises",
        "link": "/arxiv/2510.07304",
        "arxiv_id": "2510.07304",
        "authors": "Donghwan Kim, Xin Gu, Jinho Baek, Timothy Lo, Younghoon Min, Kwangsik Shin, Jongryool Kim, Jongse Park, Kiwan Maeng",
        "summary": "Machine learning (ML) models memorize and leak training data, causing serious privacy issues to data owners. Training algorithms with differential privacy (DP), such as DP-SGD, have been gaining attention as a solution. However, DP-SGD adds a noise at each training iteration, which degrades the accuracy of the trained model. To improve accuracy, a new family of approaches adds carefully designed correlated noises, so that noises cancel out each other across iterations. We performed an extensive characterization study of these new mechanisms, for the first time to the best of our knowledge, and show they incur non-negligible overheads when the model is large or uses large embedding tables. Motivated by the analysis, we propose Cocoon, a hardware-software co-designed framework for efficient training with correlated noises. Cocoon accelerates models with embedding tables through pre-computing and storing correlated noises in a coalesced format (Cocoon-Emb), and supports large models through a custom near-memory processing device (Cocoon-NMP). On a real system with an FPGA-based NMP device prototype, Cocoon improves the performance by 2.33-10.82x(Cocoon-Emb) and 1.55-3.06x (Cocoon-NMP).",
        "subjects": "Hardware Architecture, Artificial Intelligence, Cryptography and Security, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.471776"
    },
    {
        "index": "#108",
        "title": "Accelerating Inference for Multilayer Neural Networks with Quantum Computers",
        "link": "/arxiv/2510.07195",
        "arxiv_id": "2510.07195",
        "authors": "Arthur G. Rattew, Po-Wei Huang, Naixu Guo, Lirandë Pira, Patrick Rebentrost",
        "summary": "Fault-tolerant Quantum Processing Units (QPUs) promise to deliver exponential speed-ups in select computational tasks, yet their integration into modern deep learning pipelines remains unclear. In this work, we take a step towards bridging this gap by presenting the first fully-coherent quantum implementation of a multilayer neural network with non-linear activation functions. Our constructions mirror widely used deep learning architectures based on ResNet, and consist of residual blocks with multi-filter 2D convolutions, sigmoid activations, skip-connections, and layer normalizations. We analyse the complexity of inference for networks under three quantum data access regimes. Without any assumptions, we establish a quadratic speedup over classical methods for shallow bilinear-style networks. With efficient quantum access to the weights, we obtain a quartic speedup over classical methods. With efficient quantum access to both the inputs and the network weights, we prove that a network with an $N$-dimensional vectorized input, $k$ residual block layers, and a final residual-linear-pooling layer can be implemented with an error of $\\epsilon$ with $O(\\text{polylog}(N/\\epsilon)^k)$ inference cost.",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.473029"
    },
    {
        "index": "#109",
        "title": "Covert Quantum Learning: Privately and Verifiably Learning from Quantum Data",
        "link": "/arxiv/2510.07193",
        "arxiv_id": "2510.07193",
        "authors": "Abhishek Anand, Matthias C. Caro, Ari Karchmer, Saachi Mutreja",
        "summary": "Quantum learning from remotely accessed quantum compute and data must address two key challenges: verifying the correctness of data and ensuring the privacy of the learner's data-collection strategies and resulting conclusions. The covert (verifiable) learning model of Canetti and Karchmer (TCC 2021) provides a framework for endowing classical learning algorithms with such guarantees. In this work, we propose models of covert verifiable learning in quantum learning theory and realize them without computational hardness assumptions for remote data access scenarios motivated by established quantum data advantages. We consider two privacy notions: (i) strategy-covertness, where the eavesdropper does not gain information about the learner's strategy; and (ii) target-covertness, where the eavesdropper does not gain information about the unknown object being learned. We show: Strategy-covert algorithms for making quantum statistical queries via classical shadows; Target-covert algorithms for learning quadratic functions from public quantum examples and private quantum statistical queries, for Pauli shadow tomography and stabilizer state learning from public multi-copy and private single-copy quantum measurements, and for solving Forrelation and Simon's problem from public quantum queries and private classical queries, where the adversary is a unidirectional or i.i.d. ancilla-free eavesdropper. The lattermost results in particular establish that the exponential separation between classical and quantum queries for Forrelation and Simon's problem survives under covertness constraints. Along the way, we design covert verifiable protocols for quantum data acquisition from public quantum queries which may be of independent interest. Overall, our models and corresponding algorithms demonstrate that quantum advantages are privately and verifiably achievable even with untrusted, remote data.",
        "subjects": "Quantum Physics, Cryptography and Security, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.473328"
    },
    {
        "index": "#110",
        "title": "Resolution scaling governs DINOv3 transfer performance in chest radiograph classification",
        "link": "/arxiv/2510.07191",
        "arxiv_id": "2510.07191",
        "authors": "Soroosh Tayebi Arasteh, Mina Shaigan, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn",
        "summary": "Self-supervised learning (SSL) has advanced visual representation learning, but its value in chest radiography, a high-volume imaging modality with fine-grained findings, remains unclear. Meta's DINOv3 extends earlier SSL models through Gram-anchored self-distillation. Whether these design choices improve transfer learning for chest radiography has not been systematically tested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization across seven datasets (n>814,000). Two representative backbones were evaluated: ViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and 1024x1024 pixels. We additionally assessed frozen features from a 7B model. The primary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2 achieved comparable performance on adult datasets. Increasing resolution to 512x512 yielded consistent improvements for DINOv3 over both DINOv2 and ImageNet. In contrast, results in pediatric cohort showed no differences across initializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Models using frozen DINOv3-7B features underperformed relative to fully finetuned 86-89M-parameter backbones, highlighting the importance of domain adaptation. Scaling to 1024x1024 did not further improve accuracy. Resolution-related gains were most evident for boundary-dependent and small focal abnormalities. In chest radiography, higher input resolution is critical for leveraging the benefits of modern self-supervised models. 512x512 pixels represent a practical upper limit where DINOv3-initialized ConvNeXt-B networks provide the strongest performance, while larger inputs offer minimal return on cost. Clinically, these findings support use of finetuned, mid-sized backbones at 512x512 for chest radiograph interpretation, with the greatest gains expected in detecting subtle or boundary-centered lesions relevant to emergency and critical care settings.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.473654"
    },
    {
        "index": "#111",
        "title": "Split Conformal Classification with Unsupervised Calibration",
        "link": "/arxiv/2510.07185",
        "arxiv_id": "2510.07185",
        "authors": "Santiago Mazuelas",
        "summary": "Methods for split conformal prediction leverage calibration samples to transform any prediction rule into a set-prediction rule that complies with a target coverage probability. Existing methods provide remarkably strong performance guarantees with minimal computational costs. However, they require to use calibration samples composed by labeled examples different to those used for training. This requirement can be highly inconvenient, as it prevents the use of all labeled examples for training and may require acquiring additional labels solely for calibration. This paper presents an effective methodology for split conformal prediction with unsupervised calibration for classification tasks. In the proposed approach, set-prediction rules are obtained using unsupervised calibration samples together with supervised training samples previously used to learn the classification rule. Theoretical and experimental results show that the presented methods can achieve performance comparable to that with supervised calibration, at the expenses of a moderate degradation in performance guarantees and computational efficiency.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.473916"
    },
    {
        "index": "#112",
        "title": "Bayesian Portfolio Optimization by Predictive Synthesis",
        "link": "/arxiv/2510.07180",
        "arxiv_id": "2510.07180",
        "authors": "Masahiro Kato, Kentaro Baba, Hibiki Kaibuchi, Ryo Inokuchi",
        "summary": "Portfolio optimization is a critical task in investment. Most existing portfolio optimization methods require information on the distribution of returns of the assets that make up the portfolio. However, such distribution information is usually unknown to investors. Various methods have been proposed to estimate distribution information, but their accuracy greatly depends on the uncertainty of the financial markets. Due to this uncertainty, a model that could well predict the distribution information at one point in time may perform less accurately compared to another model at a different time. To solve this problem, we investigate a method for portfolio optimization based on Bayesian predictive synthesis (BPS), one of the Bayesian ensemble methods for meta-learning. We assume that investors have access to multiple asset return prediction models. By using BPS with dynamic linear models to combine these predictions, we can obtain a Bayesian predictive posterior about the mean rewards of assets that accommodate the uncertainty of the financial markets. In this study, we examine how to construct mean-variance portfolios and quantile-based portfolios based on the predicted distribution information.",
        "subjects": "Econometrics, Machine Learning, Computational Finance, Portfolio Management, Applications",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.474243"
    },
    {
        "index": "#115",
        "title": "Spectral Graph Clustering under Differential Privacy: Balancing Privacy, Accuracy, and Efficiency",
        "link": "/arxiv/2510.07136",
        "arxiv_id": "2510.07136",
        "authors": "Mohamed Seif, Antti Koskela, H. Vincent Poor, Andrea J. Goldsmith",
        "summary": "We study the problem of spectral graph clustering under edge differential privacy (DP). Specifically, we develop three mechanisms: (i) graph perturbation via randomized edge flipping combined with adjacency matrix shuffling, which enforces edge privacy while preserving key spectral properties of the graph. Importantly, shuffling considerably amplifies the guarantees: whereas flipping edges with a fixed probability alone provides only a constant epsilon edge DP guarantee as the number of nodes grows, the shuffled mechanism achieves (epsilon, delta) edge DP with parameters that tend to zero as the number of nodes increase; (ii) private graph projection with additive Gaussian noise in a lower-dimensional space to reduce dimensionality and computational complexity; and (iii) a noisy power iteration method that distributes Gaussian noise across iterations to ensure edge DP while maintaining convergence. Our analysis provides rigorous privacy guarantees and a precise characterization of the misclassification error rate. Experiments on synthetic and real-world networks validate our theoretical analysis and illustrate the practical privacy-utility trade-offs.",
        "subjects": "Information Theory, Cryptography and Security, Machine Learning, Social and Information Networks",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.480420"
    },
    {
        "index": "#117",
        "title": "The Contingencies of Physical Embodiment Allow for Open-Endedness and Care",
        "link": "/arxiv/2510.07117",
        "arxiv_id": "2510.07117",
        "authors": "Leonardo Christov-Moore, Arthur Juliani, Alex Kiefer, Nicco Reggente, B. Scott Rousse, Adam Safron, Nicol'as Hinrichs, Daniel Polani, Antonio Damasio",
        "summary": "Physical vulnerability and mortality are often seen as obstacles to be avoided in the development of artificial agents, which struggle to adapt to open-ended environments and provide aligned care. Meanwhile, biological organisms survive, thrive, and care for each other in an open-ended physical world with relative ease and efficiency. Understanding the role of the conditions of life in this disparity can aid in developing more robust, adaptive, and caring artificial agents. Here we define two minimal conditions for physical embodiment inspired by the existentialist phenomenology of Martin Heidegger: being-in-the-world (the agent is a part of the environment) and being-towards-death (unless counteracted, the agent drifts toward terminal states due to the second law of thermodynamics). We propose that from these conditions we can obtain both a homeostatic drive - aimed at maintaining integrity and avoiding death by expending energy to learn and act - and an intrinsic drive to continue to do so in as many ways as possible. Drawing inspiration from Friedrich Nietzsche's existentialist concept of will-to-power, we examine how intrinsic drives to maximize control over future states, e.g., empowerment, allow agents to increase the probability that they will be able to meet their future homeostatic needs, thereby enhancing their capacity to maintain physical integrity. We formalize these concepts within a reinforcement learning framework, which enables us to examine how intrinsically driven embodied agents learning in open-ended multi-agent environments may cultivate the capacities for open-endedness and care.ov",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.481514"
    },
    {
        "index": "#118",
        "title": "GNN-enhanced Traffic Anomaly Detection for Next-Generation SDN-Enabled Consumer Electronics",
        "link": "/arxiv/2510.07109",
        "arxiv_id": "2510.07109",
        "authors": "Guan-Yan Yang, Farn Wang, Kuo-Hui Yeh",
        "summary": "Consumer electronics (CE) connected to the Internet of Things are susceptible to various attacks, including DDoS and web-based threats, which can compromise their functionality and facilitate remote hijacking. These vulnerabilities allow attackers to exploit CE for broader system attacks while enabling the propagation of malicious code across the CE network, resulting in device failures. Existing deep learning-based traffic anomaly detection systems exhibit high accuracy in traditional network environments but are often overly complex and reliant on static infrastructure, necessitating manual configuration and management. To address these limitations, we propose a scalable network model that integrates Software-defined Networking (SDN) and Compute First Networking (CFN) for next-generation CE networks. In this network model, we propose a Graph Neural Networks-based Network Anomaly Detection framework (GNN-NAD) that integrates SDN-based CE networks and enables the CFN architecture. GNN-NAD uniquely fuses a static, vulnerability-aware attack graph with dynamic traffic features, providing a holistic view of network security. The core of the framework is a GNN model (GSAGE) for graph representation learning, followed by a Random Forest (RF) classifier. This design (GSAGE+RF) demonstrates superior performance compared to existing feature selection methods. Experimental evaluations on CE environment reveal that GNN-NAD achieves superior metrics in accuracy, recall, precision, and F1 score, even with small sample sizes, exceeding the performance of current network anomaly detection methods. This work advances the security and efficiency of next-generation intelligent CE networks.",
        "subjects": "Cryptography and Security, Machine Learning, Networking and Internet Architecture",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.482001"
    },
    {
        "index": "#119",
        "title": "Active Control of Turbulent Airfoil Flows Using Adjoint-based Deep Learning",
        "link": "/arxiv/2510.07106",
        "arxiv_id": "2510.07106",
        "authors": "Xuemin Liu, Tom Hickling, Jonathan F. MacArt",
        "summary": "We train active neural-network flow controllers using a deep learning PDE augmentation method to optimize lift-to-drag ratios in turbulent airfoil flows at Reynolds number $5\\times10^4$ and Mach number 0.4. Direct numerical simulation and large eddy simulation are employed to model compressible, unconfined flow over two- and three-dimensional semi-infinite NACA 0012 airfoils at angles of attack $\\alpha = 5^\\circ$, $10^\\circ$, and $15^\\circ$. Control actions, implemented through a blowing/suction jet at a fixed location and geometry on the upper surface, are adaptively determined by a neural network that maps local pressure measurements to optimal jet total pressure, enabling a sensor-informed control policy that responds spatially and temporally to unsteady flow conditions. The sensitivities of the flow to the neural network parameters are computed using the adjoint Navier-Stokes equations, which we construct using automatic differentiation applied to the flow solver. The trained flow controllers significantly improve the lift-to-drag ratios and reduce flow separation for both two- and three-dimensional airfoil flows, especially at $\\alpha = 5^\\circ$ and $10^\\circ$. The 2D-trained models remain effective when applied out-of-sample to 3D flows, which demonstrates the robustness of the adjoint-trained control approach. The 3D-trained models capture the flow dynamics even more effectively, which leads to better energy efficiency and comparable performance for both adaptive (neural network) and offline (simplified, constant-pressure) controllers. These results underscore the effectiveness of this learning-based approach in improving aerodynamic performance.",
        "subjects": "Fluid Dynamics, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.482445"
    },
    {
        "index": "#120",
        "title": "Diffusion-Augmented Reinforcement Learning for Robust Portfolio Optimization under Stress Scenarios",
        "link": "/arxiv/2510.07099",
        "arxiv_id": "2510.07099",
        "authors": "Himanshu Choudhary, Arishi Orra, Manoj Thakur",
        "summary": "In the ever-changing and intricate landscape of financial markets, portfolio optimisation remains a formidable challenge for investors and asset managers. Conventional methods often struggle to capture the complex dynamics of market behaviour and align with diverse investor preferences. To address this, we propose an innovative framework, termed Diffusion-Augmented Reinforcement Learning (DARL), which synergistically integrates Denoising Diffusion Probabilistic Models (DDPMs) with Deep Reinforcement Learning (DRL) for portfolio management. By leveraging DDPMs to generate synthetic market crash scenarios conditioned on varying stress intensities, our approach significantly enhances the robustness of training data. Empirical evaluations demonstrate that DARL outperforms traditional baselines, delivering superior risk-adjusted returns and resilience against unforeseen crises, such as the 2025 Tariff Crisis. This work offers a robust and practical methodology to bolster stress resilience in DRL-driven financial applications.",
        "subjects": "Machine Learning, Computational Engineering, Finance, and Science, Machine Learning, Computational Finance",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.482923"
    },
    {
        "index": "#121",
        "title": "Explaining Models under Multivariate Bernoulli Distribution via Hoeffding Decomposition",
        "link": "/arxiv/2510.07088",
        "arxiv_id": "2510.07088",
        "authors": "Baptiste Ferrere, Nicolas Bousquet, Fabrice Gamboa, Jean-Michel Loubes, Joseph Muré",
        "summary": "Explaining the behavior of predictive models with random inputs can be achieved through sub-models decomposition, where such sub-models have easier interpretable features. Arising from the uncertainty quantification community, recent results have demonstrated the existence and uniqueness of a generalized Hoeffding decomposition for such predictive models when the stochastic input variables are correlated, based on concepts of oblique projection onto L 2 subspaces. This article focuses on the case where the input variables have Bernoulli distributions and provides a complete description of this decomposition. We show that in this case the underlying L 2 subspaces are one-dimensional and that the functional decomposition is explicit. This leads to a complete interpretability framework and theoretically allows reverse engineering. Explicit indicators of the influence of inputs on the output prediction (exemplified by Sobol' indices and Shapley effects) can be explicitly derived. Illustrated by numerical experiments, this type of analysis proves useful for addressing decision-support problems, based on binary decision diagrams, Boolean networks or binary neural networks. The article outlines perspectives for exploring high-dimensional settings and, beyond the case of binary inputs, extending these findings to models with finite countable inputs.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.483397"
    },
    {
        "index": "#122",
        "title": "Pseudo-MDPs: A Novel Framework for Efficiently Optimizing Last Revealer Seed Manipulations in Blockchains",
        "link": "/arxiv/2510.07080",
        "arxiv_id": "2510.07080",
        "authors": "Maxime Reynouard",
        "summary": "This study tackles the computational challenges of solving Markov Decision Processes (MDPs) for a restricted class of problems. It is motivated by the Last Revealer Attack (LRA), which undermines fairness in some Proof-of-Stake (PoS) blockchains such as Ethereum (\\$400B market capitalization). We introduce pseudo-MDPs (pMDPs) a framework that naturally models such problems and propose two distinct problem reductions to standard MDPs. One problem reduction provides a novel, counter-intuitive perspective, and combining the two problem reductions enables significant improvements in dynamic programming algorithms such as value iteration. In the case of the LRA which size is parameterized by $\\kappa$ (in Ethereum's case $\\kappa$ = 32), we reduce the computational complexity from O(2^$\\kappa$ $\\kappa$^2^($\\kappa$+2)) to O($\\kappa$^4) (per iteration). This solution also provide the usual benefits from Dynamic Programming solutions: exponentially fast convergence toward the optimal solution is guaranteed. The dual perspective also simplifies policy extraction, making the approach well-suited for resource-constrained agents who can operate with very limited memory and computation once the problem has been solved. Furthermore, we generalize those results to a broader class of MDPs, enhancing their applicability. The framework is validated through two case studies: a fictional card game and the LRA on the Ethereum random seed consensus protocol. These applications demonstrate the framework's ability to solve large-scale problems effectively while offering actionable insights into optimal strategies. This work advances the study of MDPs and contributes to understanding security vulnerabilities in blockchain systems.",
        "subjects": "Cryptography and Security, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.483850"
    },
    {
        "index": "#123",
        "title": "Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications",
        "link": "/arxiv/2510.07077",
        "arxiv_id": "2510.07077",
        "authors": "Kento Kawaharazuka, Jihoon Oh, Jun Yamada, Ingmar Posner, Yuke Zhu",
        "summary": "Amid growing efforts to leverage advances in large language models (LLMs) and vision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models have recently gained significant attention. By unifying vision, language, and action data at scale, which have traditionally been studied separately, VLA models aim to learn policies that generalise across diverse tasks, objects, embodiments, and environments. This generalisation capability is expected to enable robots to solve novel downstream tasks with minimal or no additional task-specific data, facilitating more flexible and scalable real-world deployment. Unlike previous surveys that focus narrowly on action representations or high-level model architectures, this work offers a comprehensive, full-stack review, integrating both software and hardware components of VLA systems. In particular, this paper provides a systematic review of VLAs, covering their strategy and architectural transition, architectures and building blocks, modality-specific processing techniques, and learning paradigms. In addition, to support the deployment of VLAs in real-world robotic applications, we also review commonly used robot platforms, data collection strategies, publicly available datasets, data augmentation methods, and evaluation benchmarks. Throughout this comprehensive survey, this paper aims to offer practical guidance for the robotics community in applying VLAs to real-world robotic systems. All references categorized by training approach, evaluation method, modality, and dataset are available in the table on our project website: https://vla-survey.github.io .",
        "subjects": "Robotics, Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.484373"
    },
    {
        "index": "#125",
        "title": "Root Cause Analysis of Outliers in Unknown Cyclic Graphs",
        "link": "/arxiv/2510.06995",
        "arxiv_id": "2510.06995",
        "authors": "Daniela Schkoda, Dominik Janzing",
        "summary": "We study the propagation of outliers in cyclic causal graphs with linear structural equations, tracing them back to one or several \"root cause\" nodes. We show that it is possible to identify a short list of potential root causes provided that the perturbation is sufficiently strong and propagates according to the same structural equations as in the normal mode. This shortlist consists of the true root causes together with those of its parents lying on a cycle with the root cause. Notably, our method does not require prior knowledge of the causal graph.",
        "subjects": "Machine Learning, Machine Learning, Methodology",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.490508"
    },
    {
        "index": "#126",
        "title": "Relational Database Distillation: From Structured Tables to Condensed Graph Data",
        "link": "/arxiv/2510.06980",
        "arxiv_id": "2510.06980",
        "authors": "Xinyi Gao, Jingxi Zhang, Lijian Chen, Tong Chen, Lizhen Cui, Hongzhi Yin",
        "summary": "Relational databases (RDBs) underpin the majority of global data management systems, where information is structured into multiple interdependent tables. To effectively use the knowledge within RDBs for predictive tasks, recent advances leverage graph representation learning to capture complex inter-table relations as multi-hop dependencies. Despite achieving state-of-the-art performance, these methods remain hindered by the prohibitive storage overhead and excessive training time, due to the massive scale of the database and the computational burden of intensive message passing across interconnected tables. To alleviate these concerns, we propose and study the problem of Relational Database Distillation (RDD). Specifically, we aim to distill large-scale RDBs into compact heterogeneous graphs while retaining the predictive power (i.e., utility) required for training graph-based models. Multi-modal column information is preserved through node features, and primary-foreign key relations are encoded via heterogeneous edges, thereby maintaining both data fidelity and relational structure. To ensure adaptability across diverse downstream tasks without engaging the traditional, inefficient bi-level distillation framework, we further design a kernel ridge regression-guided objective with pseudo-labels, which produces quality features for the distilled graph. Extensive experiments on multiple real-world RDBs demonstrate that our solution substantially reduces the data size while maintaining competitive performance on classification and regression tasks, creating an effective pathway for scalable learning with RDBs.",
        "subjects": "Databases, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.490997"
    },
    {
        "index": "#127",
        "title": "Falsification-Driven Reinforcement Learning for Maritime Motion Planning",
        "link": "/arxiv/2510.06970",
        "arxiv_id": "2510.06970",
        "authors": "Marlon Müller, Florian Finkeldei, Hanna Krasowski, Murat Arcak, Matthias Althoff",
        "summary": "Compliance with maritime traffic rules is essential for the safe operation of autonomous vessels, yet training reinforcement learning (RL) agents to adhere to them is challenging. The behavior of RL agents is shaped by the training scenarios they encounter, but creating scenarios that capture the complexity of maritime navigation is non-trivial, and real-world data alone is insufficient. To address this, we propose a falsification-driven RL approach that generates adversarial training scenarios in which the vessel under test violates maritime traffic rules, which are expressed as signal temporal logic specifications. Our experiments on open-sea navigation with two vessels demonstrate that the proposed approach provides more relevant training scenarios and achieves more consistent rule compliance.",
        "subjects": "Systems and Control, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.491467"
    },
    {
        "index": "#128",
        "title": "Accelerating Sparse Ternary GEMM for Quantized LLM inference on Apple Silicon",
        "link": "/arxiv/2510.06957",
        "arxiv_id": "2510.06957",
        "authors": "Baraq Lipshitz, Alessio Melone, Charalampos Maraziaris, Muhammed Bilal",
        "summary": "Sparse Ternary General Matrix-Matrix Multiplication (GEMM) remains under-optimized in existing libraries for Apple Silicon CPUs. We present a Sparse Ternary GEMM kernel optimized specifically for Apple's M-series processors. We propose a set of architecture-aware optimizations, including a novel blocked and interleaved sparse data format to improve memory locality, strategies to increase Instruction-Level Parallelism (ILP), and NEON-based Single Instruction Multiple Data (SIMD) vectorization to exploit data-level parallelism. Our scalar implementation achieves up to a 5.98x performance increase over a traditional Ternary Compressed Sparse Column (TCSC) baseline for large matrices with 50% ternary nonzero values (sparsity), reaching up to a 50.2% of the processor's theoretical peak performance, and remains stable across varying sparsity levels. Our vectorized implementation delivers up to a 5.59x performance increase for large matrices with 25% sparsity, and remains stable across varying sparsity levels.",
        "subjects": "Performance, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.491956"
    },
    {
        "index": "#129",
        "title": "PyCFRL: A Python library for counterfactually fair offline reinforcement learning via sequential data preprocessing",
        "link": "/arxiv/2510.06935",
        "arxiv_id": "2510.06935",
        "authors": "Jianhan Zhang, Jitao Wang, Chengchun Shi, John D. Piette, Donglin Zeng, Zhenke Wu",
        "summary": "Reinforcement learning (RL) aims to learn and evaluate a sequential decision rule, often referred to as a \"policy\", that maximizes the population-level benefit in an environment across possibly infinitely many time steps. However, the sequential decisions made by an RL algorithm, while optimized to maximize overall population benefits, may disadvantage certain individuals who are in minority or socioeconomically disadvantaged groups. To address this problem, we introduce PyCFRL, a Python library for ensuring counterfactual fairness in offline RL. PyCFRL implements a novel data preprocessing algorithm for learning counterfactually fair RL policies from offline datasets and provides tools to evaluate the values and counterfactual unfairness levels of RL policies. We describe the high-level functionalities of PyCFRL and demonstrate one of its major use cases through a data example. The library is publicly available on PyPI and Github (https://github.com/JianhanZhang/PyCFRL), and detailed tutorials can be found in the PyCFRL documentation (https://pycfrl-documentation.netlify.app).",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.492440"
    },
    {
        "index": "#130",
        "title": "Textual interpretation of transient image classifications from large language models",
        "link": "/arxiv/2510.06931",
        "arxiv_id": "2510.06931",
        "authors": "Fiorenzo Stoppa, Turan Bulmus, Steven Bloemen, Stephen J. Smartt, Paul J. Groot, Paul Vreeswijk, Ken W. Smith",
        "summary": "Modern astronomical surveys deliver immense volumes of transient detections, yet distinguishing real astrophysical signals (for example, explosive events) from bogus imaging artefacts remains a challenge. Convolutional neural networks are effectively used for real versus bogus classification; however, their reliance on opaque latent representations hinders interpretability. Here we show that large language models (LLMs) can approach the performance level of a convolutional neural network on three optical transient survey datasets (Pan-STARRS, MeerLICHT and ATLAS) while simultaneously producing direct, human-readable descriptions for every candidate. Using only 15 examples and concise instructions, Google's LLM, Gemini, achieves a 93% average accuracy across datasets that span a range of resolution and pixel scales. We also show that a second LLM can assess the coherence of the output of the first model, enabling iterative refinement by identifying problematic cases. This framework allows users to define the desired classification behaviour through natural language and examples, bypassing traditional training pipelines. Furthermore, by generating textual descriptions of observed features, LLMs enable users to query classifications as if navigating an annotated catalogue, rather than deciphering abstract latent spaces. As next-generation telescopes and surveys further increase the amount of data available, LLM-based classification could help bridge the gap between automated detection and transparent, human-level understanding.",
        "subjects": "Instrumentation and Methods for Astrophysics, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.492940"
    },
    {
        "index": "#131",
        "title": "Quantum Sparse Recovery and Quantum Orthogonal Matching Pursuit",
        "link": "/arxiv/2510.06925",
        "arxiv_id": "2510.06925",
        "authors": "Armando Bellante, Stefano Vanerio, Stefano Zanero",
        "summary": "We study quantum sparse recovery in non-orthogonal, overcomplete dictionaries: given coherent quantum access to a state and a dictionary of vectors, the goal is to reconstruct the state up to $\\ell_2$ error using as few vectors as possible. We first show that the general recovery problem is NP-hard, ruling out efficient exact algorithms in full generality. To overcome this, we introduce Quantum Orthogonal Matching Pursuit (QOMP), the first quantum analogue of the classical OMP greedy algorithm. QOMP combines quantum subroutines for inner product estimation, maximum finding, and block-encoded projections with an error-resetting design that avoids iteration-to-iteration error accumulation. Under standard mutual incoherence and well-conditioned sparsity assumptions, QOMP provably recovers the exact support of a $K$-sparse state in polynomial time. As an application, we give the first framework for sparse quantum tomography with non-orthogonal dictionaries in $\\ell_2$ norm, achieving query complexity $\\widetilde{O}(\\sqrt{N}/\\epsilon)$ in favorable regimes and reducing tomography to estimating only $K$ coefficients instead of $N$ amplitudes. In particular, for pure-state tomography with $m=O(N)$ dictionary vectors and sparsity $K=\\widetilde{O}(1)$ on a well-conditioned subdictionary, this circumvents the $\\widetilde{\\Omega}(N/\\epsilon)$ lower bound that holds in the dense, orthonormal-dictionary setting, without contradiction, by leveraging sparsity together with non-orthogonality. Beyond tomography, we analyze QOMP in the QRAM model, where it yields polynomial speedups over classical OMP implementations, and provide a quantum algorithm to estimate the mutual incoherence of a dictionary of $m$ vectors in $O(m/\\epsilon)$ queries, improving over both deterministic and quantum-inspired classical methods.",
        "subjects": "Quantum Physics, Data Structures and Algorithms, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.493401"
    },
    {
        "index": "#132",
        "title": "Bayesian Nonparametric Dynamical Clustering of Time Series",
        "link": "/arxiv/2510.06919",
        "arxiv_id": "2510.06919",
        "authors": "Adrián Pérez-Herrero, Paulo Félix, Jesús Presedo, Carl Henrik Ek",
        "summary": "We present a method that models the evolution of an unbounded number of time series clusters by switching among an unknown number of regimes with linear dynamics. We develop a Bayesian non-parametric approach using a hierarchical Dirichlet process as a prior on the parameters of a Switching Linear Dynamical System and a Gaussian process prior to model the statistical variations in amplitude and temporal alignment within each cluster. By modeling the evolution of time series patterns, the method avoids unnecessary proliferation of clusters in a principled manner. We perform inference by formulating a variational lower bound for off-line and on-line scenarios, enabling efficient learning through optimization. We illustrate the versatility and effectiveness of the approach through several case studies of electrocardiogram analysis using publicly available databases.",
        "subjects": "Machine Learning, Artificial Intelligence, Machine Learning, Applications",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.493896"
    },
    {
        "index": "#133",
        "title": "Multi-Dimensional Autoscaling of Stream Processing Services on Edge Devices",
        "link": "/arxiv/2510.06882",
        "arxiv_id": "2510.06882",
        "authors": "Boris Sedlak, Philipp Raith, Andrea Morichetta, Víctor Casamayor Pujol, Schahram Dustdar",
        "summary": "Edge devices have limited resources, which inevitably leads to situations where stream processing services cannot satisfy their needs. While existing autoscaling mechanisms focus entirely on resource scaling, Edge devices require alternative ways to sustain the Service Level Objectives (SLOs) of competing services. To address these issues, we introduce a Multi-dimensional Autoscaling Platform (MUDAP) that supports fine-grained vertical scaling across both service- and resource-level dimensions. MUDAP supports service-specific scaling tailored to available parameters, e.g., scale data quality or model size for a particular service. To optimize the execution across services, we present a scaling agent based on Regression Analysis of Structural Knowledge (RASK). The RASK agent efficiently explores the solution space and learns a continuous regression model of the processing environment for inferring optimal scaling actions. We compared our approach with two autoscalers, the Kubernetes VPA and a reinforcement learning agent, for scaling up to 9 services on a single Edge device. Our results showed that RASK can infer an accurate regression model in merely 20 iterations (i.e., observe 200s of processing). By increasingly adding elasticity dimensions, RASK sustained the highest request load with 28% less SLO violations, compared to baselines.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Machine Learning, Performance",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.494401"
    },
    {
        "index": "#134",
        "title": "Multi-hop Deep Joint Source-Channel Coding with Deep Hash Distillation for Semantically Aligned Image Retrieval",
        "link": "/arxiv/2510.06868",
        "arxiv_id": "2510.06868",
        "authors": "Didrik Bergström, Deniz Gündüz, Onur Günlü",
        "summary": "We consider image transmission via deep joint source-channel coding (DeepJSCC) over multi-hop additive white Gaussian noise (AWGN) channels by training a DeepJSCC encoder-decoder pair with a pre-trained deep hash distillation (DHD) module to semantically cluster images, facilitating security-oriented applications through enhanced semantic consistency and improving the perceptual reconstruction quality. We train the DeepJSCC module to both reduce mean square error (MSE) and minimize cosine distance between DHD hashes of source and reconstructed images. Significantly improved perceptual quality as a result of semantic alignment is illustrated for different multi-hop settings, for which classical DeepJSCC may suffer from noise accumulation, measured by the learned perceptual image patch similarity (LPIPS) metric.",
        "subjects": "Information Theory, Artificial Intelligence, Cryptography and Security, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.494880"
    },
    {
        "index": "#135",
        "title": "Reconquering Bell sampling on qudits: stabilizer learning and testing, quantum pseudorandomness bounds, and more",
        "link": "/arxiv/2510.06848",
        "arxiv_id": "2510.06848",
        "authors": "Jonathan Allcock, Joao F. Doriguello, Gábor Ivanyos, Miklos Santha",
        "summary": "Bell sampling is a simple yet powerful tool based on measuring two copies of a quantum state in the Bell basis, and has found applications in a plethora of problems related to stabiliser states and measures of magic. However, it was not known how to generalise the procedure from qubits to $d$-level systems -- qudits -- for all dimensions $d > 2$ in a useful way. Indeed, a prior work of the authors (arXiv'24) showed that the natural extension of Bell sampling to arbitrary dimensions fails to provide meaningful information about the quantum states being measured. In this paper, we overcome the difficulties encountered in previous works and develop a useful generalisation of Bell sampling to qudits of all $d\\geq 2$. At the heart of our primitive is a new unitary, based on Lagrange's four-square theorem, that maps four copies of any stabiliser state $|\\mathcal{S}\\rangle$ to four copies of its complex conjugate $|\\mathcal{S}^\\ast\\rangle$ (up to some Pauli operator), which may be of independent interest. We then demonstrate the utility of our new Bell sampling technique by lifting several known results from qubits to qudits for any $d\\geq 2$: 1. Learning stabiliser states in $O(n^3)$ time with $O(n)$ samples; 2. Solving the Hidden Stabiliser Group Problem in $\\tilde{O}(n^3/\\varepsilon)$ time with $\\tilde{O}(n/\\varepsilon)$ samples; 3. Testing whether $|\\psi\\rangle$ has stabiliser size at least $d^t$ or is $\\varepsilon$-far from all such states in $\\tilde{O}(n^3/\\varepsilon)$ time with $\\tilde{O}(n/\\varepsilon)$ samples; 4. Clifford circuits with at most $n/2$ single-qudit non-Clifford gates cannot prepare pseudorandom states; 5. Testing whether $|\\psi\\rangle$ has stabiliser fidelity at least $1-\\varepsilon_1$ or at most $1-\\varepsilon_2$ with $O(d^2/\\varepsilon_2)$ samples if $\\varepsilon_1 = 0$ or $O(d^2/\\varepsilon_2^2)$ samples if $\\varepsilon_1 = O(d^{-2})$.",
        "subjects": "Quantum Physics, Computational Complexity, Data Structures and Algorithms, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.500491"
    },
    {
        "index": "#136",
        "title": "Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking",
        "link": "/arxiv/2510.06820",
        "arxiv_id": "2510.06820",
        "authors": "Mitchell Keren Taraday, Shahaf Wagner, Chaim Baskin",
        "summary": "Multimodal retrieval still leans on embedding-based models like CLIP for fast vector search over pre-computed image embeddings. Yet, unlike text retrieval, where joint-encoder rerankers are standard, comparable vision--language rerankers are largely absent. We find that seminal joint encoders such as BLIP are severely bottlenecked by an expensive visual feature-extraction stage, preventing practical deployment at scale. Motivated by this bottleneck, we introduce EDJE, an Efficient Discriminative Joint Encoder that precomputes vision tokens offline and compresses them via a lightweight attention-based adapter, so online inference runs only a compact joint encoder over a small set of visual tokens plus the text. EDJE preserves strong retrieval performance while drastically reducing storage and online compute, enabling high-throughput inference. Specifically, EDJE processes 50k image--text pairs/second while requiring 49kB of disk storage per image, matching prior art on Flickr (zero-shot) and COCO (fine-tuned) retrieval. The implementation and checkpoints will be made publicly available shortly.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.500938"
    },
    {
        "index": "#138",
        "title": "Quantum Computing Methods for Malware Detection",
        "link": "/arxiv/2510.06803",
        "arxiv_id": "2510.06803",
        "authors": "Eliška Krátká, Aurél Gábor Gábris",
        "summary": "In this paper, we explore the potential of quantum computing in enhancing malware detection through the application of Quantum Machine Learning (QML). Our main objective is to investigate the performance of the Quantum Support Vector Machine (QSVM) algorithm compared to SVM. A publicly available dataset containing raw binaries of Portable Executable (PE) files was used for the classification. The QSVM algorithm, incorporating quantum kernels through different feature maps, was implemented and evaluated on a local simulator within the Qiskit SDK and IBM quantum computers. Experimental results from simulators and quantum hardware provide insights into the behavior and performance of quantum computers, especially in handling large-scale computations for malware detection tasks. The work summarizes the practical experience with using quantum hardware via the Qiskit interfaces. We describe in detail the critical issues encountered, as well as the fixes that had to be developed and applied to the base code of the Qiskit Machine Learning library. These issues include missing transpilation of the circuits submitted to IBM Quantum systems and exceeding the maximum job size limit due to the submission of all the circuits in one job.",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.501896"
    },
    {
        "index": "#139",
        "title": "MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models",
        "link": "/arxiv/2510.06742",
        "arxiv_id": "2510.06742",
        "authors": "Ali Sarabadani, Kheirolah Rahsepar Fard",
        "summary": "The advent of large language models (LLMs) has revolutionized the integration of knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming limitations in traditional machine learning methods for capturing intricate semantic links among genes, diseases, and cognitive processes. We introduce MultiCNKG, an innovative framework that merges three key knowledge sources: the Cognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges across 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes and 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO) comprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types. Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity computation, and graph augmentation to create a cohesive KG that interconnects genetic mechanisms, neurological disorders, and cognitive functions. The resulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes, Diseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes, Associated with, Regulates), facilitating a multi-layered view from molecular to behavioral domains. Assessments using metrics such as precision (85.20%), recall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty detection (40.28%), and expert validation (89.50%) affirm its robustness and coherence. Link prediction evaluations with models like TransE (MR: 391, MRR: 0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against benchmarks like FB15k-237 and WN18RR. This KG advances applications in personalized medicine, cognitive disorder diagnostics, and hypothesis formulation in cognitive neuroscience.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.502322"
    },
    {
        "index": "#142",
        "title": "Inefficiencies of Meta Agents for Agent Design",
        "link": "/arxiv/2510.06711",
        "arxiv_id": "2510.06711",
        "authors": "Batu El, Mert Yuksekgonul, James Zou",
        "summary": "Recent works began to automate the design of agentic systems using meta-agents that propose and iteratively refine new agent architectures. In this paper, we examine three key challenges in a common class of meta-agents. First, we investigate how a meta-agent learns across iterations and find that simply expanding the context with all previous agents, as proposed by previous works, performs worse than ignoring prior designs entirely. We show that the performance improves with an evolutionary approach. Second, although the meta-agent designs multiple agents during training, it typically commits to a single agent at test time. We find that the designed agents have low behavioral diversity, limiting the potential for their complementary use. Third, we assess when automated design is economically viable. We find that only in a few cases--specifically, two datasets--the overall cost of designing and deploying the agents is lower than that of human-designed agents when deployed on over 15,000 examples. In contrast, the performance gains for other datasets do not justify the design cost, regardless of scale.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.503799"
    },
    {
        "index": "#144",
        "title": "Latent Representation Learning in Heavy-Ion Collisions with MaskPoint Transformer",
        "link": "/arxiv/2510.06691",
        "arxiv_id": "2510.06691",
        "authors": "Jing-Zong Zhang, Shuang Guo, Li-Lin Zhu, Lingxiao Wang, Guo-Liang Ma",
        "summary": "A central challenge in high-energy nuclear physics is to extract informative features from the high-dimensional final-state data of heavy-ion collisions (HIC) in order to enable reliable downstream analyses. Traditional approaches often rely on selected observables, which may miss subtle but physically relevant structures in the data. To address this, we introduce a Transformer-based autoencoder trained with a two-stage paradigm: self-supervised pre-training followed by supervised fine-tuning. The pretrained encoder learns latent representations directly from unlabeled HIC data, providing a compact and information-rich feature space that can be adapted to diverse physics tasks. As a case study, we apply the method to distinguish between large and small collision systems, where it achieves significantly higher classification accuracy than PointNet. Principal component analysis and SHAP interpretation further demonstrate that the autoencoder captures complex nonlinear correlations beyond individual observables, yielding features with strong discriminative and explanatory power. These results establish our two-stage framework as a general and robust foundation for feature learning in HIC, opening the door to more powerful analyses of quark--gluon plasma properties and other emergent phenomena. The implementation is publicly available at https://github.com/Giovanni-Sforza/MaskPoint-AMPT.",
        "subjects": "High Energy Physics - Phenomenology, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.504759"
    },
    {
        "index": "#145",
        "title": "Gaussian Equivalence for Self-Attention: Asymptotic Spectral Analysis of Attention Matrix",
        "link": "/arxiv/2510.06685",
        "arxiv_id": "2510.06685",
        "authors": "Tomohiro Hayase, Benoît Collins, Ryo Karakida",
        "summary": "Self-attention layers have become fundamental building blocks of modern deep neural networks, yet their theoretical understanding remains limited, particularly from the perspective of random matrix theory. In this work, we provide a rigorous analysis of the singular value spectrum of the attention matrix and establish the first Gaussian equivalence result for attention. In a natural regime where the inverse temperature remains of constant order, we show that the singular value distribution of the attention matrix is asymptotically characterized by a tractable linear model. We further demonstrate that the distribution of squared singular values deviates from the Marchenko-Pastur law, which has been believed in previous work. Our proof relies on two key ingredients: precise control of fluctuations in the normalization term and a refined linearization that leverages favorable Taylor expansions of the exponential. This analysis also identifies a threshold for linearization and elucidates why attention, despite not being an entrywise operation, admits a rigorous Gaussian equivalence in this regime.",
        "subjects": "Machine Learning, Machine Learning, Probability",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.505228"
    },
    {
        "index": "#147",
        "title": "Fitzpatrick Thresholding for Skin Image Segmentation",
        "link": "/arxiv/2510.06655",
        "arxiv_id": "2510.06655",
        "authors": "Duncan Stothers, Sophia Xu, Carlie Reeves, Lia Gracey",
        "summary": "Accurate estimation of the body surface area (BSA) involved by a rash, such as psoriasis, is critical for assessing rash severity, selecting an initial treatment regimen, and following clinical treatment response. Attempts at segmentation of inflammatory skin disease such as psoriasis perform markedly worse on darker skin tones, potentially impeding equitable care. We assembled a psoriasis dataset sourced from six public atlases, annotated for Fitzpatrick skin type, and added detailed segmentation masks for every image. Reference models based on U-Net, ResU-Net, and SETR-small are trained without tone information. On the tuning split we sweep decision thresholds and select (i) global optima and (ii) per Fitzpatrick skin tone optima for Dice and binary IoU. Adapting Fitzpatrick specific thresholds lifted segmentation performance for the darkest subgroup (Fitz VI) by up to +31 % bIoU and +24 % Dice on UNet, with consistent, though smaller, gains in the same direction for ResU-Net (+25 % bIoU, +18 % Dice) and SETR-small (+17 % bIoU, +11 % Dice). Because Fitzpatrick skin tone classifiers trained on Fitzpatrick-17k now exceed 95 % accuracy, the cost of skin tone labeling required for this technique has fallen dramatically. Fitzpatrick thresholding is simple, model-agnostic, requires no architectural changes, no re-training, and is virtually cost free. We demonstrate the inclusion of Fitzpatrick thresholding as a potential future fairness baseline.",
        "subjects": "Image and Video Processing, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.527049"
    },
    {
        "index": "#148",
        "title": "Q-Learning with Fine-Grained Gap-Dependent Regret",
        "link": "/arxiv/2510.06647",
        "arxiv_id": "2510.06647",
        "authors": "Haochen Zhang, Zhong Zheng, Lingzhou Xue",
        "summary": "We study fine-grained gap-dependent regret bounds for model-free reinforcement learning in episodic tabular Markov Decision Processes. Existing model-free algorithms achieve minimax worst-case regret, but their gap-dependent bounds remain coarse and fail to fully capture the structure of suboptimality gaps. We address this limitation by establishing fine-grained gap-dependent regret bounds for both UCB-based and non-UCB-based algorithms. In the UCB-based setting, we develop a novel analytical framework that explicitly separates the analysis of optimal and suboptimal state-action pairs, yielding the first fine-grained regret upper bound for UCB-Hoeffding (Jin et al., 2018). To highlight the generality of this framework, we introduce ULCB-Hoeffding, a new UCB-based algorithm inspired by AMB (Xu et al.,2021) but with a simplified structure, which enjoys fine-grained regret guarantees and empirically outperforms AMB. In the non-UCB-based setting, we revisit the only known algorithm AMB, and identify two key issues in its algorithm design and analysis: improper truncation in the $Q$-updates and violation of the martingale difference condition in its concentration argument. We propose a refined version of AMB that addresses these issues, establishing the first rigorous fine-grained gap-dependent regret for a non-UCB-based method, with experiments demonstrating improved performance over AMB.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.527651"
    },
    {
        "index": "#150",
        "title": "Unsupervised Backdoor Detection and Mitigation for Spiking Neural Networks",
        "link": "/arxiv/2510.06629",
        "arxiv_id": "2510.06629",
        "authors": "Jiachen Li, Bang Wu, Xiaoyu Xia, Xiaoning Liu, Xun Yi, Xiuzhen Zhang",
        "summary": "Spiking Neural Networks (SNNs) have gained increasing attention for their superior energy efficiency compared to Artificial Neural Networks (ANNs). However, their security aspects, particularly under backdoor attacks, have received limited attention. Existing defense methods developed for ANNs perform poorly or can be easily bypassed in SNNs due to their event-driven and temporal dependencies. This paper identifies the key blockers that hinder traditional backdoor defenses in SNNs and proposes an unsupervised post-training detection framework, Temporal Membrane Potential Backdoor Detection (TMPBD), to overcome these challenges. TMPBD leverages the maximum margin statistics of temporal membrane potential (TMP) in the final spiking layer to detect target labels without any attack knowledge or data access. We further introduce a robust mitigation mechanism, Neural Dendrites Suppression Backdoor Mitigation (NDSBM), which clamps dendritic connections between early convolutional layers to suppress malicious neurons while preserving benign behaviors, guided by TMP extracted from a small, clean, unlabeled dataset. Extensive experiments on multiple neuromorphic benchmarks and state-of-the-art input-aware dynamic trigger attacks demonstrate that TMPBD achieves 100% detection accuracy, while NDSBM reduces the attack success rate from 100% to 8.44%, and to 2.81% when combined with detection, without degrading clean accuracy.",
        "subjects": "Cryptography and Security, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.528981"
    },
    {
        "index": "#151",
        "title": "FEAorta: A Fully Automated Framework for Finite Element Analysis of the Aorta From 3D CT Images",
        "link": "/arxiv/2510.06621",
        "arxiv_id": "2510.06621",
        "authors": "Jiasong Chen, Linchen Qian, Ruonan Gong, Christina Sun, Tongran Qin, Thuy Pham, Caitlin Martin, Mohammad Zafar, John Elefteriades, Wei Sun, Liang Liang",
        "summary": "Aortic aneurysm disease ranks consistently in the top 20 causes of death in the U.S. population. Thoracic aortic aneurysm is manifested as an abnormal bulging of thoracic aortic wall and it is a leading cause of death in adults. From the perspective of biomechanics, rupture occurs when the stress acting on the aortic wall exceeds the wall strength. Wall stress distribution can be obtained by computational biomechanical analyses, especially structural Finite Element Analysis. For risk assessment, probabilistic rupture risk of TAA can be calculated by comparing stress with material strength using a material failure model. Although these engineering tools are currently available for TAA rupture risk assessment on patient specific level, clinical adoption has been limited due to two major barriers: labor intensive 3D reconstruction current patient specific anatomical modeling still relies on manual segmentation, making it time consuming and difficult to scale to a large patient population, and computational burden traditional FEA simulations are resource intensive and incompatible with time sensitive clinical workflows. The second barrier was successfully overcome by our team through the development of the PyTorch FEA library and the FEA DNN integration framework. By incorporating the FEA functionalities within PyTorch FEA and applying the principle of static determinacy, we reduced the FEA based stress computation time to approximately three minutes per case. Moreover, by integrating DNN and FEA through the PyTorch FEA library, our approach further decreases the computation time to only a few seconds per case. This work focuses on overcoming the first barrier through the development of an end to end deep neural network capable of generating patient specific finite element meshes of the aorta directly from 3D CT images.",
        "subjects": "Image and Video Processing, Computational Engineering, Finance, and Science, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.529754"
    },
    {
        "index": "#152",
        "title": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation",
        "link": "/arxiv/2510.06596",
        "arxiv_id": "2510.06596",
        "authors": "Ayush Zenith, Arnold Zumbrun, Neel Raut, Jing Lin",
        "summary": "The performance of machine learning models depends heavily on training data. The scarcity of large-scale, well-annotated datasets poses significant challenges in creating robust models. To address this, synthetic data generated through simulations and generative models has emerged as a promising solution, enhancing dataset diversity and improving the performance, reliability, and resilience of models. However, evaluating the quality of this generated data requires an effective metric. This paper introduces the Synthetic Dataset Quality Metric (SDQM) to assess data quality for object detection tasks without requiring model training to converge. This metric enables more efficient generation and selection of synthetic datasets, addressing a key challenge in resource-constrained object detection tasks. In our experiments, SDQM demonstrated a strong correlation with the mean Average Precision (mAP) scores of YOLOv11, a leading object detection model, while previous metrics only exhibited moderate or weak correlations. Additionally, it provides actionable insights for improving dataset quality, minimizing the need for costly iterative training. This scalable and efficient metric sets a new standard for evaluating synthetic data. The code for SDQM is available at https://github.com/ayushzenith/SDQM",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Information Theory, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.530411"
    },
    {
        "index": "#153",
        "title": "Adapting Quantum Machine Learning for Energy Dissociation of Bonds",
        "link": "/arxiv/2510.06563",
        "arxiv_id": "2510.06563",
        "authors": "Swathi Chandrasekhar, Shiva Raj Pokhrel, Navneet Singh",
        "summary": "Accurate prediction of bond dissociation energies (BDEs) underpins mechanistic insight and the rational design of molecules and materials. We present a systematic, reproducible benchmark comparing quantum and classical machine learning models for BDE prediction using a chemically curated feature set encompassing atomic properties (atomic numbers, hybridization), bond characteristics (bond order, type), and local environmental descriptors. Our quantum framework, implemented in Qiskit Aer on six qubits, employs ZZFeatureMap encodings with variational ansatz (RealAmplitudes) across multiple architectures Variational Quantum Regressors (VQR), Quantum Support Vector Regressors (QSVR), Quantum Neural Networks (QNN), Quantum Convolutional Neural Networks (QCNN), and Quantum Random Forests (QRF). These are rigorously benchmarked against strong classical baselines, including Support Vector Regression (SVR), Random Forests (RF), and Multi-Layer Perceptrons (MLP). Comprehensive evaluation spanning absolute and relative error metrics, threshold accuracies, and error distributions shows that top-performing quantum models (QCNN, QRF) match the predictive accuracy and robustness of classical ensembles and deep networks, particularly within the chemically prevalent mid-range BDE regime. These findings establish a transparent baseline for quantum-enhanced molecular property prediction and outline a practical foundation for advancing quantum computational chemistry toward near chemical accuracy.",
        "subjects": "Quantum Physics, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.531005"
    },
    {
        "index": "#155",
        "title": "Cluster Paths: Navigating Interpretability in Neural Networks",
        "link": "/arxiv/2510.06541",
        "arxiv_id": "2510.06541",
        "authors": "Nicholas M. Kroeger, Vincent Bindschaedler",
        "summary": "While modern deep neural networks achieve impressive performance in vision tasks, they remain opaque in their decision processes, risking unwarranted trust, undetected biases and unexpected failures. We propose cluster paths, a post-hoc interpretability method that clusters activations at selected layers and represents each input as its sequence of cluster IDs. To assess these cluster paths, we introduce four metrics: path complexity (cognitive load), weighted-path purity (class alignment), decision-alignment faithfulness (predictive fidelity), and path agreement (stability under perturbations). In a spurious-cue CIFAR-10 experiment, cluster paths identify color-based shortcuts and collapse when the cue is removed. On a five-class CelebA hair-color task, they achieve 90% faithfulness and maintain 96% agreement under Gaussian noise without sacrificing accuracy. Scaling to a Vision Transformer pretrained on ImageNet, we extend cluster paths to concept paths derived from prompting a large language model on minimal path divergences. Finally, we show that cluster paths can serve as an effective out-of-distribution (OOD) detector, reliably flagging anomalous samples before the model generates over-confident predictions. Cluster paths uncover visual concepts, such as color palettes, textures, or object contexts, at multiple network depths, demonstrating that cluster paths scale to large vision models while generating concise and human-readable explanations.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.537230"
    },
    {
        "index": "#156",
        "title": "Auto-Prompt Ensemble for LLM Judge",
        "link": "/arxiv/2510.06538",
        "arxiv_id": "2510.06538",
        "authors": "Jiajie Li, Huayi Zhang, Peng Lin, Jinjun Xiong, Wei Xu",
        "summary": "We present a novel framework that improves the reliability of LLM judges by selectively augmenting LLM with auxiliary evaluation dimensions. Existing LLM judges often miss crucial evaluation dimensions because they fail to recognize the implicit standards underlying human assessments. To address this challenge, we propose the Auto-Prompt Ensemble (APE), an adaptive framework that automatically learns evaluation dimensions from its failure cases. APE incorporates a confidence-based ensemble mechanism to decide when to adopt the judgments from additional evaluation dimensions through a novel confidence estimation approach called Collective Confidence. Extensive experiments demonstrate that APE improves the reliability of LLM Judge across diverse standard benchmarks. For instance, APE enhances GPT-4o agreement rate on Reward Bench from 87.2% to 90.5% in the zero-shot setting. Overall, APE provides a principled approach for LLM Judge to leverage test-time computation, and bridge the evaluation gap between human and LLM judges.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.537717"
    },
    {
        "index": "#157",
        "title": "Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them",
        "link": "/arxiv/2510.06534",
        "arxiv_id": "2510.06534",
        "authors": "Jiahe Jin, Abhijay Paladugu, Chenyan Xiong",
        "summary": "Agentic search leverages large language models (LLMs) to interpret complex user information needs and execute a multi-step process of planning, searching, and synthesizing information to provide answers. This paradigm introduces unique challenges for LLMs' reasoning and agentic capabilities when interacting with retrieval systems and the broader web. In this paper, we propose a reasoning-driven LLM-based pipeline to study effective reasoning behavior patterns in agentic search. Using this pipeline, we analyze successful agentic search trajectories and identify four beneficial reasoning behaviors: Information Verification, Authority Evaluation, Adaptive Search, and Error Recovery. Based on these findings, we propose a technique called Behavior Priming to train more effective agentic search models. It synthesizes agentic search trajectories that exhibit these four behaviors and integrates them into the agentic search model through supervised fine-tuning (SFT), followed by standard reinforcement learning (RL). Experiments on three benchmarks (GAIA, WebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in Llama3.2-3B and Qwen3-1.7B compared to directly training agentic search models with RL. Crucially, we demonstrate that the desired reasoning behaviors in the SFT data, rather than the correctness of the final answer, is the critical factor for achieving strong final performance after RL: fine-tuning on trajectories with desirable reasoning behaviors but incorrect answers leads to better performance than fine-tuning on trajectories with correct answers. Our analysis further reveals the underlying mechanism: the introduced reasoning behaviors endow models with more effective exploration (higher pass@k and entropy) and test-time scaling (longer trajectories) capabilities, providing a strong foundation for RL. Our code will be released as open source.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.538185"
    },
    {
        "index": "#158",
        "title": "From Description to Detection: LLM based Extendable O-RAN Compliant Blind DoS Detection in 5G and Beyond",
        "link": "/arxiv/2510.06530",
        "arxiv_id": "2510.06530",
        "authors": "Thusitha Dayaratne, Ngoc Duy Pham, Viet Vo, Shangqi Lai, Sharif Abuadbba, Hajime Suzuki, Xingliang Yuan, Carsten Rudolph",
        "summary": "The quality and experience of mobile communication have significantly improved with the introduction of 5G, and these improvements are expected to continue beyond the 5G era. However, vulnerabilities in control-plane protocols, such as Radio Resource Control (RRC) and Non-Access Stratum (NAS), pose significant security threats, such as Blind Denial of Service (DoS) attacks. Despite the availability of existing anomaly detection methods that leverage rule-based systems or traditional machine learning methods, these methods have several limitations, including the need for extensive training data, predefined rules, and limited explainability. Addressing these challenges, we propose a novel anomaly detection framework that leverages the capabilities of Large Language Models (LLMs) in zero-shot mode with unordered data and short natural language attack descriptions within the Open Radio Access Network (O-RAN) architecture. We analyse robustness to prompt variation, demonstrate the practicality of automating the attack descriptions and show that detection quality relies on the semantic completeness of the description rather than its phrasing or length. We utilise an RRC/NAS dataset to evaluate the solution and provide an extensive comparison of open-source and proprietary LLM implementations to demonstrate superior performance in attack detection. We further validate the practicality of our framework within O-RAN's real-time constraints, illustrating its potential for detecting other Layer-3 attacks.",
        "subjects": "Cryptography and Security, Emerging Technologies, Machine Learning, Networking and Internet Architecture",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.538773"
    },
    {
        "index": "#159",
        "title": "BACHI: Boundary-Aware Symbolic Chord Recognition Through Masked Iterative Decoding on Pop and Classical Music",
        "link": "/arxiv/2510.06528",
        "arxiv_id": "2510.06528",
        "authors": "Mingyang Yao, Ke Chen, Shlomo Dubnov, Taylor Berg-Kirkpatrick",
        "summary": "Automatic chord recognition (ACR) via deep learning models has gradually achieved promising recognition accuracy, yet two key challenges remain. First, prior work has primarily focused on audio-domain ACR, while symbolic music (e.g., score) ACR has received limited attention due to data scarcity. Second, existing methods still overlook strategies that are aligned with human music analytical practices. To address these challenges, we make two contributions: (1) we introduce POP909-CL, an enhanced version of POP909 dataset with tempo-aligned content and human-corrected labels of chords, beats, keys, and time signatures; and (2) We propose BACHI, a symbolic chord recognition model that decomposes the task into different decision steps, namely boundary detection and iterative ranking of chord root, quality, and bass (inversion). This mechanism mirrors the human ear-training practices. Experiments demonstrate that BACHI achieves state-of-the-art chord recognition performance on both classical and pop music benchmarks, with ablation studies validating the effectiveness of each module.",
        "subjects": "Sound, Machine Learning, Audio and Speech Processing",
        "date": "2025-10-08",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.539251"
    },
    {
        "index": "#160",
        "title": "Online Matching via Reinforcement Learning: An Expert Policy Orchestration Strategy",
        "link": "/arxiv/2510.06515",
        "arxiv_id": "2510.06515",
        "authors": "Chiara Mignacco, Matthieu Jonckheere, Gilles Stoltz",
        "summary": "Online matching problems arise in many complex systems, from cloud services and online marketplaces to organ exchange networks, where timely, principled decisions are critical for maintaining high system performance. Traditional heuristics in these settings are simple and interpretable but typically tailored to specific operating regimes, which can lead to inefficiencies when conditions change. We propose a reinforcement learning (RL) approach that learns to orchestrate a set of such expert policies, leveraging their complementary strengths in a data-driven, adaptive manner. Building on the Adv2 framework (Jonckheere et al., 2024), our method combines expert decisions through advantage-based weight updates and extends naturally to settings where only estimated value functions are available. We establish both expectation and high-probability regret guarantees and derive a novel finite-time bias bound for temporal-difference learning, enabling reliable advantage estimation even under constant step size and non-stationary dynamics. To support scalability, we introduce a neural actor-critic architecture that generalizes across large state spaces while preserving interpretability. Simulations on stochastic matching models, including an organ exchange scenario, show that the orchestrated policy converges faster and yields higher system level efficiency than both individual experts and conventional RL baselines. Our results highlight how structured, adaptive learning can improve the modeling and management of complex resource allocation and decision-making processes.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.539696"
    },
    {
        "index": "#161",
        "title": "Road Surface Condition Detection with Machine Learning using New York State Department of Transportation Camera Images and Weather Forecast Data",
        "link": "/arxiv/2510.06440",
        "arxiv_id": "2510.06440",
        "authors": "Carly Sutter, Kara J. Sulia, Nick P. Bassill, Christopher D. Wirz, Christopher D. Thorncroft, Jay C. Rothenberger, Vanessa Przybylo, Mariana G. Cains, Jacob Radford, David Aaron Evans",
        "summary": "The New York State Department of Transportation (NYSDOT) has a network of roadside traffic cameras that are used by both the NYSDOT and the public to observe road conditions. The NYSDOT evaluates road conditions by driving on roads and observing live cameras, tasks which are labor-intensive but necessary for making critical operational decisions during winter weather events. However, machine learning models can provide additional support for the NYSDOT by automatically classifying current road conditions across the state. In this study, convolutional neural networks and random forests are trained on camera images and weather data to predict road surface conditions. Models are trained on a hand-labeled dataset of ~22,000 camera images, each classified by human labelers into one of six road surface conditions: severe snow, snow, wet, dry, poor visibility, or obstructed. Model generalizability is prioritized to meet the operational needs of the NYSDOT decision makers, and the weather-related road surface condition model in this study achieves an accuracy of 81.5% on completely unseen cameras.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.540281"
    },
    {
        "index": "#162",
        "title": "A General Constructive Upper Bound on Shallow Neural Nets Complexity",
        "link": "/arxiv/2510.06372",
        "arxiv_id": "2510.06372",
        "authors": "Frantisek Hakl, Vit Fojtik",
        "summary": "We provide an upper bound on the number of neurons required in a shallow neural network to approximate a continuous function on a compact set with a given accuracy. This method, inspired by a specific proof of the Stone-Weierstrass theorem, is constructive and more general than previous bounds of this character, as it applies to any continuous function on any compact set.",
        "subjects": "Machine Learning, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.540719"
    },
    {
        "index": "#163",
        "title": "Diffusion-Guided Renormalization of Neural Systems via Tensor Networks",
        "link": "/arxiv/2510.06361",
        "arxiv_id": "2510.06361",
        "authors": "Nathan X. Kodama",
        "summary": "Far from equilibrium, neural systems self-organize across multiple scales. Exploiting multiscale self-organization in neuroscience and artificial intelligence requires a computational framework for modeling the effective non-equilibrium dynamics of stochastic neural trajectories. Non-equilibrium thermodynamics and representational geometry offer theoretical foundations, but we need scalable data-driven techniques for modeling collective properties of high-dimensional neural networks from partial subsampled observations. Renormalization is a coarse-graining technique central to studying emergent scaling properties of many-body and nonlinear dynamical systems. While widely applied in physics and machine learning, coarse-graining complex dynamical networks remains unsolved, affecting many computational sciences. Recent diffusion-based renormalization, inspired by quantum statistical mechanics, coarse-grains networks near entropy transitions marked by maximal changes in specific heat or information transmission. Here I explore diffusion-based renormalization of neural systems by generating symmetry-breaking representations across scales and offering scalable algorithms using tensor networks. Diffusion-guided renormalization bridges microscale and mesoscale dynamics of dissipative neural systems. For microscales, I developed a scalable graph inference algorithm for discovering community structure from subsampled neural activity. Using community-based node orderings, diffusion-guided renormalization generates renormalization group flow through metagraphs and joint probability functions. Towards mesoscales, diffusion-guided renormalization targets learning the effective non-equilibrium dynamics of dissipative neural trajectories occupying lower-dimensional subspaces, enabling coarse-to-fine control in systems neuroscience and artificial intelligence.",
        "subjects": "Neurons and Cognition, Statistical Mechanics, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.541188"
    },
    {
        "index": "#164",
        "title": "TransFIRA: Transfer Learning for Face Image Recognizability Assessment",
        "link": "/arxiv/2510.06353",
        "arxiv_id": "2510.06353",
        "authors": "Allen Tu, Kartik Narayan, Joshua Gleason, Jennifer Xu, Matthew Meyn, Tom Goldstein, Vishal M. Patel",
        "summary": "Face recognition in unconstrained environments such as surveillance, video, and web imagery must contend with extreme variation in pose, blur, illumination, and occlusion, where conventional visual quality metrics fail to predict whether inputs are truly recognizable to the deployed encoder. Existing FIQA methods typically rely on visual heuristics, curated annotations, or computationally intensive generative pipelines, leaving their predictions detached from the encoder's decision geometry. We introduce TransFIRA (Transfer Learning for Face Image Recognizability Assessment), a lightweight and annotation-free framework that grounds recognizability directly in embedding space. TransFIRA delivers three advances: (i) a definition of recognizability via class-center similarity (CCS) and class-center angular separation (CCAS), yielding the first natural, decision-boundary--aligned criterion for filtering and weighting; (ii) a recognizability-informed aggregation strategy that achieves state-of-the-art verification accuracy on BRIAR and IJB-C while nearly doubling correlation with true recognizability, all without external labels, heuristics, or backbone-specific training; and (iii) new extensions beyond faces, including encoder-grounded explainability that reveals how degradations and subject-specific factors affect recognizability, and the first recognizability-aware body recognition assessment. Experiments confirm state-of-the-art results on faces, strong performance on body recognition, and robustness under cross-dataset shifts. Together, these contributions establish TransFIRA as a unified, geometry-driven framework for recognizability assessment -- encoder-specific, accurate, interpretable, and extensible across modalities -- significantly advancing FIQA in accuracy, explainability, and scope.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.546824"
    },
    {
        "index": "#166",
        "title": "Conditional Denoising Diffusion Model-Based Robust MR Image Reconstruction from Highly Undersampled Data",
        "link": "/arxiv/2510.06335",
        "arxiv_id": "2510.06335",
        "authors": "Mohammed Alsubaie, Wenxi Liu, Linxia Gu, Ovidiu C. Andronesi, Sirani M. Perera, Xianqi Li",
        "summary": "Magnetic Resonance Imaging (MRI) is a critical tool in modern medical diagnostics, yet its prolonged acquisition time remains a critical limitation, especially in time-sensitive clinical scenarios. While undersampling strategies can accelerate image acquisition, they often result in image artifacts and degraded quality. Recent diffusion models have shown promise for reconstructing high-fidelity images from undersampled data by learning powerful image priors; however, most existing approaches either (i) rely on unsupervised score functions without paired supervision or (ii) apply data consistency only as a post-processing step. In this work, we introduce a conditional denoising diffusion framework with iterative data-consistency correction, which differs from prior methods by embedding the measurement model directly into every reverse diffusion step and training the model on paired undersampled-ground truth data. This hybrid design bridges generative flexibility with explicit enforcement of MRI physics. Experiments on the fastMRI dataset demonstrate that our framework consistently outperforms recent state-of-the-art deep learning and diffusion-based methods in SSIM, PSNR, and LPIPS, with LPIPS capturing perceptual improvements more faithfully. These results demonstrate that integrating conditional supervision with iterative consistency updates yields substantial improvements in both pixel-level fidelity and perceptual realism, establishing a principled and practical advance toward robust, accelerated MRI reconstruction.",
        "subjects": "Image and Video Processing, Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.547992"
    },
    {
        "index": "#167",
        "title": "Scalable deep fusion of spaceborne lidar and synthetic aperture radar for global forest structural complexity mapping",
        "link": "/arxiv/2510.06299",
        "arxiv_id": "2510.06299",
        "authors": "Tiago de Conto, John Armston, Ralph Dubayah",
        "summary": "Forest structural complexity metrics integrate multiple canopy attributes into a single value that reflects habitat quality and ecosystem function. Spaceborne lidar from the Global Ecosystem Dynamics Investigation (GEDI) has enabled mapping of structural complexity in temperate and tropical forests, but its sparse sampling limits continuous high-resolution mapping. We present a scalable, deep learning framework fusing GEDI observations with multimodal Synthetic Aperture Radar (SAR) datasets to produce global, high-resolution (25 m) wall-to-wall maps of forest structural complexity. Our adapted EfficientNetV2 architecture, trained on over 130 million GEDI footprints, achieves high performance (global R2 = 0.82) with fewer than 400,000 parameters, making it an accessible tool that enables researchers to process datasets at any scale without requiring specialized computing infrastructure. The model produces accurate predictions with calibrated uncertainty estimates across biomes and time periods, preserving fine-scale spatial patterns. It has been used to generate a global, multi-temporal dataset of forest structural complexity from 2015 to 2022. Through transfer learning, this framework can be extended to predict additional forest structural variables with minimal computational cost. This approach supports continuous, multi-temporal monitoring of global forest structural dynamics and provides tools for biodiversity conservation and ecosystem management efforts in a changing climate.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning, Applications",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.548510"
    },
    {
        "index": "#168",
        "title": "Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive Tiling",
        "link": "/arxiv/2510.06295",
        "arxiv_id": "2510.06295",
        "authors": "Young D. Kwon, Abhinav Mehrotra, Malcolm Chadwick, Alberto Gil Ramos, Sourav Bhattacharya",
        "summary": "High-resolution (4K) image-to-image synthesis has become increasingly important for mobile applications. Existing diffusion models for image editing face significant challenges, in terms of memory and image quality, when deployed on resource-constrained devices. In this paper, we present MobilePicasso, a novel system that enables efficient image editing at high resolutions, while minimising computational cost and memory usage. MobilePicasso comprises three stages: (i) performing image editing at a standard resolution with hallucination-aware loss, (ii) applying latent projection to overcome going to the pixel space, and (iii) upscaling the edited image latent to a higher resolution with adaptive context-preserving tiling. Our user study with 46 participants reveals that MobilePicasso not only improves image quality by 18-48% but reduces hallucinations by 14-51% over existing methods. MobilePicasso demonstrates significantly lower latency, e.g., up to 55.8$\\times$ speed-up, yet with a small increase in runtime memory, e.g., a mere 9% increase over prior work. Surprisingly, the on-device runtime of MobilePicasso is observed to be faster than a server-based high-resolution image editing model running on an A100 GPU.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.549012"
    },
    {
        "index": "#169",
        "title": "Soft-Evidence Fused Graph Neural Network for Cancer Driver Gene Identification across Multi-View Biological Graphs",
        "link": "/arxiv/2510.06290",
        "arxiv_id": "2510.06290",
        "authors": "Bang Chen, Lijun Guo, Houli Fan, Wentao He, Rong Zhang",
        "summary": "Identifying cancer driver genes (CDGs) is essential for understanding cancer mechanisms and developing targeted therapies. Graph neural networks (GNNs) have recently been employed to identify CDGs by capturing patterns in biological interaction networks. However, most GNN-based approaches rely on a single protein-protein interaction (PPI) network, ignoring complementary information from other biological networks. Some studies integrate multiple networks by aligning features with consistency constraints to learn unified gene representations for CDG identification. However, such representation-level fusion often assumes congruent gene relationships across networks, which may overlook network heterogeneity and introduce conflicting information. To address this, we propose Soft-Evidence Fusion Graph Neural Network (SEFGNN), a novel framework for CDG identification across multiple networks at the decision level. Instead of enforcing feature-level consistency, SEFGNN treats each biological network as an independent evidence source and performs uncertainty-aware fusion at the decision level using Dempster-Shafer Theory (DST). To alleviate the risk of overconfidence from DST, we further introduce a Soft Evidence Smoothing (SES) module that improves ranking stability while preserving discriminative performance. Experiments on three cancer datasets show that SEFGNN consistently outperforms state-of-the-art baselines and exhibits strong potential in discovering novel CDGs.",
        "subjects": "Genomics, Artificial Intelligence, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.549516"
    },
    {
        "index": "#170",
        "title": "BuilderBench -- A benchmark for generalist agents",
        "link": "/arxiv/2510.06288",
        "arxiv_id": "2510.06288",
        "authors": "Raj Ghugare, Catherine Ji, Kathryn Wantlin, Jin Schofield, Benjamin Eysenbach",
        "summary": "Today's AI models learn primarily through mimicry and sharpening, so it is not surprising that they struggle to solve problems beyond the limits set by existing data. To solve novel problems, agents should acquire skills for exploring and learning through experience. Finding a scalable learning mechanism for developing agents that learn through interaction remains a major open problem. In this work, we introduce BuilderBench, a benchmark to accelerate research into agent pre-training that centers open-ended exploration. BuilderBench requires agents to learn how to build any structure using blocks. BuilderBench is equipped with $(1)$ a hardware accelerated simulator of a robotic agent interacting with various physical blocks, and $(2)$ a task-suite with over 42 diverse target structures that are carefully curated to test an understanding of physics, mathematics, and long-horizon planning. During training, agents have to explore and learn general principles about the environment without any external supervision. During evaluation, agents have to build the unseen target structures from the task suite. Solving these tasks requires a sort of \\emph{embodied reasoning} that is not reflected in words but rather in actions, experimenting with different strategies and piecing them together. Our experiments show that many of these tasks challenge the current iteration of algorithms. Hence, we also provide a ``training wheels'' protocol, in which agents are trained and evaluated to build a single target structure from the task suite. Finally, we provide single-file implementations of six different algorithms as a reference point for researchers.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.549987"
    },
    {
        "index": "#171",
        "title": "Mass Conservation on Rails - Rethinking Physics-Informed Learning of Ice Flow Vector Fields",
        "link": "/arxiv/2510.06286",
        "arxiv_id": "2510.06286",
        "authors": "Kim Bente, Roman Marchant, Fabio Ramos",
        "summary": "To reliably project future sea level rise, ice sheet models require inputs that respect physics. Embedding physical principles like mass conservation into models that interpolate Antarctic ice flow vector fields from sparse & noisy measurements not only promotes physical adherence but can also improve accuracy and robustness. While physics-informed neural networks (PINNs) impose physics as soft penalties, offering flexibility but no physical guarantees, we instead propose divergence-free neural networks (dfNNs), which enforce local mass conservation exactly via a vector calculus trick. Our comparison of dfNNs, PINNs, and unconstrained NNs on ice flux interpolation over Byrd Glacier suggests that \"mass conservation on rails\" yields more reliable estimates, and that directional guidance, a learning strategy leveraging continent-wide satellite velocity data, boosts performance across models.",
        "subjects": "Atmospheric and Oceanic Physics, Machine Learning, Computational Physics, Fluid Dynamics, Geophysics, Machine Learning",
        "date": "2025-10-07",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.550514"
    },
    {
        "index": "#172",
        "title": "General and Efficient Visual Goal-Conditioned Reinforcement Learning using Object-Agnostic Masks",
        "link": "/arxiv/2510.06277",
        "arxiv_id": "2510.06277",
        "authors": "Fahim Shahriar, Cheryl Wang, Alireza Azimi, Gautham Vasan, Hany Hamed Elanwar, A. Rupam Mahmood, Colin Bellinger",
        "summary": "Goal-conditioned reinforcement learning (GCRL) allows agents to learn diverse objectives using a unified policy. The success of GCRL, however, is contingent on the choice of goal representation. In this work, we propose a mask-based goal representation system that provides object-agnostic visual cues to the agent, enabling efficient learning and superior generalization. In contrast, existing goal representation methods, such as target state images, 3D coordinates, and one-hot vectors, face issues of poor generalization to unseen objects, slow convergence, and the need for special cameras. Masks can be processed to generate dense rewards without requiring error-prone distance calculations. Learning with ground truth masks in simulation, we achieved 99.9% reaching accuracy on training and unseen test objects. Our proposed method can be utilized to perform pick-up tasks with high accuracy, without using any positional information of the target. Moreover, we demonstrate learning from scratch and sim-to-real transfer applications using two different physical robots, utilizing pretrained open vocabulary object detection models for mask generation.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-10-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.551052"
    },
    {
        "index": "#173",
        "title": "Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization",
        "link": "/arxiv/2510.06274",
        "arxiv_id": "2510.06274",
        "authors": "Mohammad Mahdi Samiei Paqaleh, Arash Marioriyad, Arman Tahmasebi-Zadeh, Mohamadreza Fereydooni, Mahdi Ghaznavai, Mahdieh Soleymani Baghshah",
        "summary": "Recent progress has pushed AI frontiers from pattern recognition tasks toward problems that require step by step, System2 style reasoning, especially with large language models. Yet, unlike learning, where generalization and out of distribution (OoD) evaluation concepts are well formalized, there is no clear, consistent definition or metric for reasoning ability. We propose Complexity Out of Distribution (Complexity OoD) generalization as a framework and problem setting to define and measure reasoning. A model exhibits Complexity OoD generalization when it maintains performance on test instances whose minimal required solution complexity, either representational (richer solution structure) or computational (more reasoning steps/program length), exceeds that of all training examples. We formalize complexity via solution description Kolmogorov complexity and operational proxies (e.g., object/relation counts; reasoning step counts), clarifying how Complexity OoD differs from length and compositional OoD. This lens unifies learning and reasoning: many cases solvable with System1 like processing at low complexity become System2 like under complexity pressure, while System2 can be viewed as generalization over solution structures. We translate this perspective into practice with recommendations for operationalizing Complexity OoD across the stack: incorporating complexity into benchmark and evaluation metric design, rethinking supervision to target solution traces, seeking and designing inductive biases for Complexity OoD generalization, addressing learning to reason spillovers such as spurious shortcuts, semantic robustness, catastrophic forgetting, and step wise calibration. Because Complexity OoD cannot be solved by scaling data alone, progress toward robust reasoning will require architectures and training regimes that explicitly model and allocate computation with respect to complexity.",
        "subjects": "Artificial Intelligence, Machine Learning",
        "date": "2025-10-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.551543"
    },
    {
        "index": "#174",
        "title": "Vision Transformer for Transient Noise Classification",
        "link": "/arxiv/2510.06273",
        "arxiv_id": "2510.06273",
        "authors": "Divyansh Srivastava, Andrzej Niedzielski",
        "summary": "Transient noise (glitches) in LIGO data hinders the detection of gravitational waves (GW). The Gravity Spy project has categorized these noise events into various classes. With the O3 run, there is the inclusion of two additional noise classes and thus a need to train new models for effective classification. We aim to classify glitches in LIGO data into 22 existing classes from the first run plus 2 additional noise classes from O3a using the Vision Transformer (ViT) model. We train a pre-trained Vision Transformer (ViT-B/32) model on a combined dataset consisting of the Gravity Spy dataset with the additional two classes from the LIGO O3a run. We achieve a classification efficiency of 92.26%, demonstrating the potential of Vision Transformer to improve the accuracy of gravitational wave detection by effectively distinguishing transient noise. Key words: gravitational waves --vision transformer --machine learning",
        "subjects": "Computer Vision and Pattern Recognition, Instrumentation and Methods for Astrophysics, Machine Learning, General Relativity and Quantum Cosmology",
        "date": "2025-10-06",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.557135"
    },
    {
        "index": "#175",
        "title": "A Mixed-Methods Analysis of Repression and Mobilization in Bangladesh's July Revolution Using Machine Learning and Statistical Modeling",
        "link": "/arxiv/2510.06264",
        "arxiv_id": "2510.06264",
        "authors": "Md. Saiful Bari Siddiqui, Anupam Debashis Roy",
        "summary": "The 2024 July Revolution in Bangladesh represents a landmark event in the study of civil resistance. This study investigates the central paradox of the success of this student-led civilian uprising: how state violence, intended to quell dissent, ultimately fueled the movement's victory. We employ a mixed-methods approach. First, we develop a qualitative narrative of the conflict's timeline to generate specific, testable hypotheses. Then, using a disaggregated, event-level dataset, we employ a multi-method quantitative analysis to dissect the complex relationship between repression and mobilisation. We provide a framework to analyse explosive modern uprisings like the July Revolution. Initial pooled regression models highlight the crucial role of protest momentum in sustaining the movement. To isolate causal effects, we specify a Two-Way Fixed Effects panel model, which provides robust evidence for a direct and statistically significant local suppression backfire effect. Our Vector Autoregression (VAR) analysis provides clear visual evidence of an immediate, nationwide mobilisation in response to increased lethal violence. We further demonstrate that this effect was non-linear. A structural break analysis reveals that the backfire dynamic was statistically insignificant in the conflict's early phase but was triggered by the catalytic moral shock of the first wave of lethal violence, and its visuals circulated around July 16th. A complementary machine learning analysis (XGBoost, out-of-sample R$^{2}$=0.65) corroborates this from a predictive standpoint, identifying \"excessive force against protesters\" as the single most dominant predictor of nationwide escalation. We conclude that the July Revolution was driven by a contingent, non-linear backfire, triggered by specific catalytic moral shocks and accelerated by the viral reaction to the visual spectacle of state brutality.",
        "subjects": "Applications, Computers and Society, Machine Learning, Methodology, Machine Learning",
        "date": "2025-10-05",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.557634"
    },
    {
        "index": "#178",
        "title": "Ensemble Deep Learning and LLM-Assisted Reporting for Automated Skin Lesion Diagnosis",
        "link": "/arxiv/2510.06260",
        "arxiv_id": "2510.06260",
        "authors": "Sher Khan, Raz Muhammad, Adil Hussain, Muhammad Sajjad, Muhammad Rashid",
        "summary": "Cutaneous malignancies demand early detection for favorable outcomes, yet current diagnostics suffer from inter-observer variability and access disparities. While AI shows promise, existing dermatological systems are limited by homogeneous architectures, dataset biases across skin tones, and fragmented approaches that treat natural language processing as separate post-hoc explanations rather than integral to clinical decision-making. We introduce a unified framework that fundamentally reimagines AI integration for dermatological diagnostics through two synergistic innovations. First, a purposefully heterogeneous ensemble of architecturally diverse convolutional neural networks provides complementary diagnostic perspectives, with an intrinsic uncertainty mechanism flagging discordant cases for specialist review -- mimicking clinical best practices. Second, we embed large language model capabilities directly into the diagnostic workflow, transforming classification outputs into clinically meaningful assessments that simultaneously fulfill medical documentation requirements and deliver patient-centered education. This seamless integration generates structured reports featuring precise lesion characterization, accessible diagnostic reasoning, and actionable monitoring guidance -- empowering patients to recognize early warning signs between visits. By addressing both diagnostic reliability and communication barriers within a single cohesive system, our approach bridges the critical translational gap that has prevented previous AI implementations from achieving clinical impact. The framework represents a significant advancement toward deployable dermatological AI that enhances diagnostic precision while actively supporting the continuum of care from initial detection through patient education, ultimately improving early intervention rates for skin lesions.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning",
        "date": "2025-10-05",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.559261"
    },
    {
        "index": "#179",
        "title": "Beyond Static Knowledge Messengers: Towards Adaptive, Fair, and Scalable Federated Learning for Medical AI",
        "link": "/arxiv/2510.06259",
        "arxiv_id": "2510.06259",
        "authors": "Jahidul Arafat, Fariha Tasmin, Sanjaya Poudel, Ahsan Habib Tareq, Iftekhar Haider",
        "summary": "Medical AI faces challenges in privacy-preserving collaborative learning while ensuring fairness across heterogeneous healthcare institutions. Current federated learning approaches suffer from static architectures, slow convergence (45-73 rounds), fairness gaps marginalizing smaller institutions, and scalability constraints (15-client limit). We propose Adaptive Fair Federated Learning (AFFL) through three innovations: (1) Adaptive Knowledge Messengers dynamically scaling capacity based on heterogeneity and task complexity, (2) Fairness-Aware Distillation using influence-weighted aggregation, and (3) Curriculum-Guided Acceleration reducing rounds by 60-70%. Our theoretical analysis provides convergence guarantees with epsilon-fairness bounds, achieving O(T^{-1/2}) + O(H_max/T^{3/4}) rates. Projected results show 55-75% communication reduction, 56-68% fairness improvement, 34-46% energy savings, and 100+ institution support. The framework enables multi-modal integration across imaging, genomics, EHR, and sensor data while maintaining HIPAA/GDPR compliance. We propose MedFedBench benchmark suite for standardized evaluation across six healthcare dimensions: convergence efficiency, institutional fairness, privacy preservation, multi-modal integration, scalability, and clinical deployment readiness. Economic projections indicate 400-800% ROI for rural hospitals and 15-25% performance gains for academic centers. This work presents a seven-question research agenda, 24-month implementation roadmap, and pathways toward democratizing healthcare AI.",
        "subjects": "Computers and Society, Machine Learning",
        "date": "2025-10-05",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.559760"
    },
    {
        "index": "#180",
        "title": "Developing a Sequential Deep Learning Pipeline to Model Alaskan Permafrost Thaw Under Climate Change",
        "link": "/arxiv/2510.06258",
        "arxiv_id": "2510.06258",
        "authors": "Addina Rahaman",
        "summary": "Changing climate conditions threaten the natural permafrost thaw-freeze cycle, leading to year-round soil temperatures above 0{\\deg}C. In Alaska, the warming of the topmost permafrost layer, known as the active layer, signals elevated greenhouse gas release due to high carbon storage. Accurate soil temperature prediction is therefore essential for risk mitigation and stability assessment; however, many existing approaches overlook the numerous factors driving soil thermal dynamics. This study presents a proof-of-concept latitude-based deep learning pipeline for modeling yearly soil temperatures across multiple depths. The framework employs dynamic reanalysis feature data from the ERA5-Land dataset, static geologic and lithological features, sliding-window sequences for seasonal context, a derived scenario signal feature for long-term climate forcing, and latitude band embeddings for spatial sensitivity. Five deep learning models were tested: a Temporal Convolutional Network (TCN), a Transformer, a 1-Dimensional Convolutional Long-Short Term Memory (Conv1DLSTM), a Gated-Recurrent Unit (GRU), and a Bidirectional Long-Short Term Memory (BiLSTM). Results showed solid recognition of latitudinal and depth-wise temperature discrepancies, with the GRU performing best in sequential temperature pattern detection. Bias-corrected CMIP5 RCP data enabled recognition of sinusoidal temperature trends, though limited divergence between scenarios were observed. This study establishes an end-to-end framework for adopting deep learning in active layer temperature modeling, offering seasonal, spatial, and vertical temperature context without intrinsic restrictions on feature selection.",
        "subjects": "Atmospheric and Oceanic Physics, Machine Learning",
        "date": "2025-10-05",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.560200"
    },
    {
        "index": "#181",
        "title": "Toward Uncertainty-Aware and Generalizable Neural Decoding for Quantum LDPC Codes",
        "link": "/arxiv/2510.06257",
        "arxiv_id": "2510.06257",
        "authors": "Xiangjun Mi, Frank Mueller",
        "summary": "Quantum error correction (QEC) is essential for scalable quantum computing, yet decoding errors via conventional algorithms result in limited accuracy (i.e., suppression of logical errors) and high overheads, both of which can be alleviated by inference-based decoders. To date, such machine-learning (ML) decoders lack two key properties crucial for practical fault tolerance: reliable uncertainty quantification and robust generalization to previously unseen codes. To address this gap, we propose \\textbf{QuBA}, a Bayesian graph neural decoder that integrates attention to both dot-product and multi-head, enabling expressive error-pattern recognition alongside calibrated uncertainty estimates. Building on QuBA, we further develop \\textbf{SAGU }\\textbf{(Sequential Aggregate Generalization under Uncertainty)}, a multi-code training framework with enhanced cross-domain robustness enabling decoding beyond the training set. Experiments on bivariate bicycle (BB) codes and their coprime variants demonstrate that (i) both QuBA and SAGU consistently outperform the classical baseline belief propagation (BP), achieving a reduction of on average \\emph{one order of magnitude} in logical error rate (LER), and up to \\emph{two orders of magnitude} under confident-decision bounds on the coprime BB code $[[154, 6, 16]]$; (ii) QuBA also surpasses state-of-the-art neural decoders, providing an advantage of roughly \\emph{one order of magnitude} (e.g., for the larger BB code $[[756, 16, \\leq34]]$) even when considering conservative (safe) decision bounds; (iii) SAGU achieves decoding performance comparable to or even outperforming QuBA's domain-specific training approach.",
        "subjects": "Quantum Physics, Information Theory, Machine Learning",
        "date": "2025-10-05",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.560661"
    },
    {
        "index": "#182",
        "title": "Dream2Image : An Open Multimodal EEG Dataset for Decoding and Visualizing Dreams with Artificial Intelligence",
        "link": "/arxiv/2510.06252",
        "arxiv_id": "2510.06252",
        "authors": "Yann Bellec",
        "summary": "Dream2Image is the world's first dataset combining EEG signals, dream transcriptions, and AI-generated images. Based on 38 participants and more than 31 hours of dream EEG recordings, it contains 129 samples offering: the final seconds of brain activity preceding awakening (T-15, T-30, T-60, T-120), raw reports of dream experiences, and an approximate visual reconstruction of the dream. This dataset provides a novel resource for dream research, a unique resource to study the neural correlates of dreaming, to develop models for decoding dreams from brain activity, and to explore new approaches in neuroscience, psychology, and artificial intelligence. Available in open access on Hugging Face and GitHub, Dream2Image provides a multimodal resource designed to support research at the interface of artificial intelligence and neuroscience. It was designed to inspire researchers and extend the current approaches to brain activity decoding. Limitations include the relatively small sample size and the variability of dream recall, which may affect generalizability.",
        "subjects": "Neurons and Cognition, Artificial Intelligence, Machine Learning",
        "date": "2025-10-03",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.561107"
    },
    {
        "index": "#184",
        "title": "Uncertainty Quantification In Surface Landmines and UXO Classification Using MC Dropout",
        "link": "/arxiv/2510.06238",
        "arxiv_id": "2510.06238",
        "authors": "Sagar Lekhak, Emmett J. Ientilucci, Dimah Dera, Susmita Ghosh",
        "summary": "Detecting surface landmines and unexploded ordnances (UXOs) using deep learning has shown promise in humanitarian demining. However, deterministic neural networks can be vulnerable to noisy conditions and adversarial attacks, leading to missed detection or misclassification. This study introduces the idea of uncertainty quantification through Monte Carlo (MC) Dropout, integrated into a fine-tuned ResNet-50 architecture for surface landmine and UXO classification, which was tested on a simulated dataset. Integrating the MC Dropout approach helps quantify epistemic uncertainty, providing an additional metric for prediction reliability, which could be helpful to make more informed decisions in demining operations. Experimental results on clean, adversarially perturbed, and noisy test images demonstrate the model's ability to flag unreliable predictions under challenging conditions. This proof-of-concept study highlights the need for uncertainty quantification in demining, raises awareness about the vulnerability of existing neural networks in demining to adversarial threats, and emphasizes the importance of developing more robust and reliable models for practical applications.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence, Machine Learning, Other Statistics",
        "date": "2025-10-03",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.570567"
    },
    {
        "index": "#185",
        "title": "Neu-RadBERT for Enhanced Diagnosis of Brain Injuries and Conditions",
        "link": "/arxiv/2510.06232",
        "arxiv_id": "2510.06232",
        "authors": "Manpreet Singh, Sean Macrae, Pierre-Marc Williams, Nicole Hung, Sabrina Araujo de Franca, Laurent Letourneau-Guillon, François-Martin Carrier, Bang Liu, Yiorgos Alexandros Cavayas",
        "summary": "Objective: We sought to develop a classification algorithm to extract diagnoses from free-text radiology reports of brain imaging performed in patients with acute respiratory failure (ARF) undergoing invasive mechanical ventilation. Methods: We developed and fine-tuned Neu-RadBERT, a BERT-based model, to classify unstructured radiology reports. We extracted all the brain imaging reports (computed tomography and magnetic resonance imaging) from MIMIC-IV database, performed in patients with ARF. Initial manual labelling was performed on a subset of reports for various brain abnormalities, followed by fine-tuning Neu-RadBERT using three strategies: 1) baseline RadBERT, 2) Neu-RadBERT with Masked Language Modeling (MLM) pretraining, and 3) Neu-RadBERT with MLM pretraining and oversampling to address data skewness. We compared the performance of this model to Llama-2-13B, an autoregressive LLM. Results: The Neu-RadBERT model, particularly with oversampling, demonstrated significant improvements in diagnostic accuracy compared to baseline RadBERT for brain abnormalities, achieving up to 98.0% accuracy for acute brain injuries. Llama-2-13B exhibited relatively lower performance, peaking at 67.5% binary classification accuracy. This result highlights potential limitations of current autoregressive LLMs for this specific classification task, though it remains possible that larger models or further fine-tuning could improve performance. Conclusion: Neu-RadBERT, enhanced through target domain pretraining and oversampling techniques, offered a robust tool for accurate and reliable diagnosis of neurological conditions from radiology reports. This study underscores the potential of transformer-based NLP models in automatically extracting diagnoses from free text reports with potential applications to both research and patient care.",
        "subjects": "Tissues and Organs, Machine Learning",
        "date": "2025-10-01",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.571208"
    },
    {
        "index": "#186",
        "title": "Milestone Determination for Autonomous Railway Operation",
        "link": "/arxiv/2510.06229",
        "arxiv_id": "2510.06229",
        "authors": "Josh Hunter, John McDermid, Simon Burton, Poppy Fynes, Mia Dempster",
        "summary": "In the field of railway automation, one of the key challenges has been the development of effective computer vision systems due to the limited availability of high-quality, sequential data. Traditional datasets are restricted in scope, lacking the spatio temporal context necessary for real-time decision-making, while alternative solutions introduce issues related to realism and applicability. By focusing on route-specific, contextually relevant cues, we can generate rich, sequential datasets that align more closely with real-world operational logic. The concept of milestone determination allows for the development of targeted, rule-based models that simplify the learning process by eliminating the need for generalized recognition of dynamic components, focusing instead on the critical decision points along a route. We argue that this approach provides a practical framework for training vision agents in controlled, predictable environments, facilitating safer and more efficient machine learning systems for railway automation.",
        "subjects": "Computer Vision and Pattern Recognition, Machine Learning",
        "date": "2025-09-30",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.571716"
    },
    {
        "index": "#187",
        "title": "Layerwise Federated Learning for Heterogeneous Quantum Clients using Quorus",
        "link": "/arxiv/2510.06228",
        "arxiv_id": "2510.06228",
        "authors": "Jason Han, Nicholas S. DiBrita, Daniel Leeds, Jianqiang Li, Jason Ludmir, Tirthak Patel",
        "summary": "Quantum machine learning (QML) holds the promise to solve classically intractable problems, but, as critical data can be fragmented across private clients, there is a need for distributed QML in a quantum federated learning (QFL) format. However, the quantum computers that different clients have access to can be error-prone and have heterogeneous error properties, requiring them to run circuits of different depths. We propose a novel solution to this QFL problem, Quorus, that utilizes a layerwise loss function for effective training of varying-depth quantum models, which allows clients to choose models for high-fidelity output based on their individual capacity. Quorus also presents various model designs based on client needs that optimize for shot budget, qubit count, midcircuit measurement, and optimization space. Our simulation and real-hardware results show the promise of Quorus: it increases the magnitude of gradients of higher depth clients and improves testing accuracy by 12.4% on average over the state-of-the-art.",
        "subjects": "Quantum Physics, Distributed, Parallel, and Cluster Computing, Emerging Technologies, Machine Learning",
        "date": "2025-09-30",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.572287"
    },
    {
        "index": "#188",
        "title": "Enhancing Resilience for IoE: A Perspective of Networking-Level Safeguard",
        "link": "/arxiv/2508.20504",
        "arxiv_id": "2508.20504",
        "authors": "Guan-Yan Yang, Jui-Ning Chen, Farn Wang, Kuo-Hui Yeh",
        "summary": "The Internet of Energy (IoE) integrates IoT-driven digital communication with power grids to enable efficient and sustainable energy systems. Still, its interconnectivity exposes critical infrastructure to sophisticated cyber threats, including adversarial attacks designed to bypass traditional safeguards. Unlike general IoT risks, IoE threats have heightened public safety consequences, demanding resilient solutions. From the networking-level safeguard perspective, we propose a Graph Structure Learning (GSL)-based safeguards framework that jointly optimizes graph topology and node representations to resist adversarial network model manipulation inherently. Through a conceptual overview, architectural discussion, and case study on a security dataset, we demonstrate GSL's superior robustness over representative methods, offering practitioners a viable path to secure IoE networks against evolving attacks. This work highlights the potential of GSL to enhance the resilience and reliability of future IoE networks for practitioners managing critical infrastructure. Lastly, we identify key open challenges and propose future research directions in this novel research area.",
        "subjects": "Cryptography and Security, Networking and Internet Architecture",
        "date": "2025-08-28",
        "category": "cs.LG",
        "crawl_time": "2025-10-09T19:59:14.572778"
    },
    {
        "index": "#1",
        "title": "Agentic generative AI for media content discovery at the national football league",
        "link": "/arxiv/2510.07297",
        "arxiv_id": "2510.07297",
        "authors": "Henry Wang, Sirajus Salekin, Jake Lee, Ross Claytor, Shinan Zhang, Michael Chi",
        "summary": "Generative AI has unlocked new possibilities in content discovery and management. Through collaboration with the National Football League (NFL), we demonstrate how a generative-AI based workflow enables media researchers and analysts to query relevant historical plays using natural language rather than traditional filter-and-click interfaces. The agentic workflow takes a user query as input, breaks it into elements, and translates them into the underlying database query language. Accuracy and latency are further improved through carefully designed semantic caching. The solution achieves over 95 percent accuracy and reduces the average time to find relevant videos from 10 minutes to 30 seconds, significantly increasing the NFL's operational efficiency and allowing users to focus on producing creative content and engaging storylines.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.465414"
    },
    {
        "index": "#3",
        "title": "NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents",
        "link": "/arxiv/2510.07172",
        "arxiv_id": "2510.07172",
        "authors": "Tianshi Zheng, Kelvin Kiu-Wai Tam, Newt Hue-Nam K. Nguyen, Baixuan Xu, Zhaowei Wang, Jiayang Cheng, Hong Ting Tsang, Weiqi Wang, Jiaxin Bai, Tianqing Fang, Yangqiu Song, Ginny Y. Wong, Simon See",
        "summary": "Large language models are emerging as powerful tools for scientific law discovery, a foundational challenge in AI-driven science. However, existing benchmarks for this task suffer from a fundamental methodological trilemma, forcing a trade-off between scientific relevance, scalability, and resistance to memorization. Furthermore, they oversimplify discovery as static function fitting, failing to capture the authentic scientific process of uncovering embedded laws through the interactive exploration of complex model systems. To address these critical gaps, we introduce NewtonBench, a benchmark comprising 324 scientific law discovery tasks across 12 physics domains. Our design mitigates the evaluation trilemma by using metaphysical shifts - systematic alterations of canonical laws - to generate a vast suite of problems that are scalable, scientifically relevant, and memorization-resistant. Moreover, we elevate the evaluation from static function fitting to interactive model discovery, requiring agents to experimentally probe simulated complex systems to uncover hidden principles. Our extensive experiment reveals a clear but fragile capability for discovery in frontier LLMs: this ability degrades precipitously with increasing system complexity and exhibits extreme sensitivity to observational noise. Notably, we uncover a paradoxical effect of tool assistance: providing a code interpreter can hinder more capable models by inducing a premature shift from exploration to exploitation, causing them to satisfice on suboptimal solutions. These results demonstrate that robust, generalizable discovery in complex, interactive environments remains the core challenge. By providing a scalable, robust, and scientifically authentic testbed, NewtonBench offers a crucial tool for measuring true progress and guiding the development of next-generation AI agents capable of genuine scientific discovery.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.466755"
    },
    {
        "index": "#4",
        "title": "Integrating Domain Knowledge into Process Discovery Using Large Language Models",
        "link": "/arxiv/2510.07161",
        "arxiv_id": "2510.07161",
        "authors": "Ali Norouzifar, Humam Kourani, Marcus Dees, Wil van der Aalst",
        "summary": "Process discovery aims to derive process models from event logs, providing insights into operational behavior and forming a foundation for conformance checking and process improvement. However, models derived solely from event data may not accurately reflect the real process, as event logs are often incomplete or affected by noise, and domain knowledge, an important complementary resource, is typically disregarded. As a result, the discovered models may lack reliability for downstream tasks. We propose an interactive framework that incorporates domain knowledge, expressed in natural language, into the process discovery pipeline using Large Language Models (LLMs). Our approach leverages LLMs to extract declarative rules from textual descriptions provided by domain experts. These rules are used to guide the IMr discovery algorithm, which recursively constructs process models by combining insights from both the event log and the extracted rules, helping to avoid problematic process structures that contradict domain knowledge. The framework coordinates interactions among the LLM, domain experts, and a set of backend services. We present a fully implemented tool that supports this workflow and conduct an extensive evaluation of multiple LLMs and prompt engineering strategies. Our empirical study includes a case study based on a real-life event log with the involvement of domain experts, who assessed the usability and effectiveness of the framework.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.467343"
    },
    {
        "index": "#7",
        "title": "VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems",
        "link": "/arxiv/2510.07073",
        "arxiv_id": "2510.07073",
        "authors": "André Hottung, Federico Berto, Chuanbo Hua, Nayeli Gast Zepeda, Daniel Wetzel, Michael Römer, Haoran Ye, Davide Zago, Michael Poli, Stefano Massaroli, Jinkyoo Park, Kevin Tierney",
        "summary": "Designing high-performing heuristics for vehicle routing problems (VRPs) is a complex task that requires both intuition and deep domain knowledge. Large language model (LLM)-based code generation has recently shown promise across many domains, but it still falls short of producing heuristics that rival those crafted by human experts. In this paper, we propose VRPAgent, a framework that integrates LLM-generated components into a metaheuristic and refines them through a novel genetic search. By using the LLM to generate problem-specific operators, embedded within a generic metaheuristic framework, VRPAgent keeps tasks manageable, guarantees correctness, and still enables the discovery of novel and powerful strategies. Across multiple problems, including the capacitated VRP, the VRP with time windows, and the prize-collecting VRP, our method discovers heuristic operators that outperform handcrafted methods and recent learning-based approaches while requiring only a single CPU core. To our knowledge, \\VRPAgent is the first LLM-based paradigm to advance the state-of-the-art in VRPs, highlighting a promising future for automated heuristics discovery.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.469295"
    },
    {
        "index": "#8",
        "title": "Inductive Learning for Possibilistic Logic Programs Under Stable Models",
        "link": "/arxiv/2510.07069",
        "arxiv_id": "2510.07069",
        "authors": "Hongbo Hu, Yisong Wang, Yi Huang, Kewen Wang",
        "summary": "Possibilistic logic programs (poss-programs) under stable models are a major variant of answer set programming (ASP). While its semantics (possibilistic stable models) and properties have been well investigated, the problem of inductive reasoning has not been investigated yet. This paper presents an approach to extracting poss-programs from a background program and examples (parts of intended possibilistic stable models). To this end, the notion of induction tasks is first formally defined, its properties are investigated and two algorithms ilpsm and ilpsmmin for computing induction solutions are presented. An implementation of ilpsmmin is also provided and experimental results show that when inputs are ordinary logic programs, the prototype outperforms a major inductive learning system for normal logic programs from stable models on the datasets that are randomly generated.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.469756"
    },
    {
        "index": "#9",
        "title": "Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations",
        "link": "/arxiv/2510.07064",
        "arxiv_id": "2510.07064",
        "authors": "Manh Hung Nguyen, Sebastian Tschiatschek, Adish Singla",
        "summary": "The difficulty and expense of obtaining large-scale human responses make Large Language Models (LLMs) an attractive alternative and a promising proxy for human behavior. However, prior work shows that LLMs often produce homogeneous outputs that fail to capture the rich diversity of human perspectives and behaviors. Thus, rather than trying to capture this diversity with a single LLM agent, we propose a novel framework to construct a set of agents that collectively capture the diversity of a given human population. Each agent is an LLM whose behavior is steered by conditioning on a small set of human demonstrations (task-response pairs) through in-context learning. The central challenge is therefore to select a representative set of LLM agents from the exponentially large space of possible agents. We tackle this selection problem from the lens of submodular optimization. In particular, we develop methods that offer different trade-offs regarding time complexity and performance guarantees. Extensive experiments in crowdsourcing and educational domains demonstrate that our approach constructs agents that more effectively represent human populations compared to baselines. Moreover, behavioral analyses on new tasks show that these agents reproduce the behavior patterns and perspectives of the students and annotators they are designed to represent.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.475297"
    },
    {
        "index": "#10",
        "title": "Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning",
        "link": "/arxiv/2510.07038",
        "arxiv_id": "2510.07038",
        "authors": "Wenxun Wu, Yuanyang Li, Guhan Chen, Linyue Wang, Hongyang Chen",
        "summary": "Recent advances in large language models (LLMs) have popularized test-time scaling, where models generate additional reasoning tokens before producing final answers. These approaches have demonstrated significant performance improvements on benchmarks involving mathematical reasoning. However, language models relying solely on direct inference still struggle with tasks demanding up-to-date knowledge or computational tools such as calculators and code interpreters for complex arithmetic operations. To overcome these limitations, we propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement learning framework that systematically integrates multi-hop reasoning with adaptive tool-calling capabilities. Our approach employs a modified version of Dynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm, which we adapt specifically for tool invocation scenarios, enabling models to dynamically interleave complex reasoning with on-demand tool usage (including search APIs and Python interpreters). To support this research, we introduce two new datasets: TAPO-easy-60K and TAPO-hard-18K, specifically designed to train and evaluate both fact-based reasoning and mathematical calculation capabilities. Our experiments on Qwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach, with both models achieving state-of-the-art performance on tasks requiring external knowledge and mathematical computation among methods with comparable parameters. Notably, TAPO achieves more efficient tool utilization than baseline methods while preventing excessive calls caused by reward hacking. These results highlight the significant potential of combining advanced reasoning with tool usage to enhance model performance in knowledge-intensive and computationally demanding tasks.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.475848"
    },
    {
        "index": "#12",
        "title": "LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN",
        "link": "/arxiv/2510.06911",
        "arxiv_id": "2510.06911",
        "authors": "Hacane Hechehouche, Andre Antakli, Matthias Klusch",
        "summary": "There are many established semantic Web standards for implementing multi-agent driven applications. The AJAN framework allows to engineer multi-agent systems based on these standards. In particular, agent knowledge is represented in RDF/RDFS and OWL, while agent behavior models are defined with Behavior Trees and SPARQL to access and manipulate this knowledge. However, the appropriate definition of RDF/RDFS and SPARQL-based agent behaviors still remains a major hurdle not only for agent modelers in practice. For example, dealing with URIs is very error-prone regarding typos and dealing with complex SPARQL queries in large-scale environments requires a high learning curve. In this paper, we present an integrated development environment to overcome such hurdles of modeling AJAN agents and at the same time to extend the user community for AJAN by the possibility to leverage Large Language Models for agent engineering.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.476790"
    },
    {
        "index": "#13",
        "title": "TGPR: Tree-Guided Policy Refinement for Robust Self-Debugging of LLMs",
        "link": "/arxiv/2510.06878",
        "arxiv_id": "2510.06878",
        "authors": "Daria Ozerova, Ekaterina Trofimova",
        "summary": "Iterative refinement has been a promising paradigm to enable large language models (LLMs) to resolve difficult reasoning and problem-solving tasks. One of the key challenges, however, is how to effectively search through the enormous search space of possible refinements. Existing methods typically fall back on predefined heuristics, which are troubled by the exploration-exploitation dilemma and cannot adapt based on past refinement outcomes. We introduce Tree-Guided Policy Refinement (TGPR), a novel framework that combines GRPO with a Thompson-Sampling-based tree search. TGPR explores both failed and successful refinement paths actively, with denser training trajectories and more adaptive policies. On HumanEval, MBPP, and APPS benchmarks, our method achieves up to +4.2 percentage points absolute improvement in pass@1 (on MBPP) and up to +12.51 percentage points absolute improvement in pass@10 (on APPS) compared to a competitive GRPO baseline. Apart from debugging code, TGPR focuses on a principled approach to combining learned policies with structured search methods, offering a general framework for enhancing iterative refinement and stateful reasoning in LLMs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.477222"
    },
    {
        "index": "#14",
        "title": "Autoformalizer with Tool Feedback",
        "link": "/arxiv/2510.06857",
        "arxiv_id": "2510.06857",
        "authors": "Qi Guo, Jianing Wang, Jianfei Zhang, Deyang Kong, Xiangzhou Huang, Xiangyu Xi, Wei Wang, Jingang Wang, Xunliang Cai, Shikun Zhang, Wei Ye",
        "summary": "Autoformalization addresses the scarcity of data for Automated Theorem Proving (ATP) by translating mathematical problems from natural language into formal statements. Efforts in recent work shift from directly prompting large language models to training an end-to-end formalizer model from scratch, achieving remarkable advancements. However, existing formalizer still struggles to consistently generate valid statements that meet syntactic validity and semantic consistency. To address this issue, we propose the Autoformalizer with Tool Feedback (ATF), a novel approach that incorporates syntactic and consistency information as tools into the formalization process. By integrating Lean 4 compilers for syntax corrections and employing a multi-LLMs-as-judge approach for consistency validation, the model is able to adaptively refine generated statements according to the tool feedback, enhancing both syntactic validity and semantic consistency. The training of ATF involves a cold-start phase on synthetic tool-calling data, an expert iteration phase to improve formalization capabilities, and Direct Preference Optimization to alleviate ineffective revisions. Experimental results show that ATF markedly outperforms a range of baseline formalizer models, with its superior performance further validated by human evaluations. Subsequent analysis reveals that ATF demonstrates excellent inference scaling properties. Moreover, we open-source Numina-ATF, a dataset containing 750K synthetic formal statements to facilitate advancements in autoformalization and ATP research.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.477747"
    },
    {
        "index": "#16",
        "title": "Verifying Memoryless Sequential Decision-making of Large Language Models",
        "link": "/arxiv/2510.06756",
        "arxiv_id": "2510.06756",
        "authors": "Dennis Gross, Helge Spieker, Arnaud Gotlieb",
        "summary": "We introduce a tool for rigorous and automated verification of large language model (LLM)- based policies in memoryless sequential decision-making tasks. Given a Markov decision process (MDP) representing the sequential decision-making task, an LLM policy, and a safety requirement expressed as a PCTL formula, our approach incrementally constructs only the reachable portion of the MDP guided by the LLM's chosen actions. Each state is encoded as a natural language prompt, the LLM's response is parsed into an action, and reachable successor states by the policy are expanded. The resulting formal model is checked with Storm to determine whether the policy satisfies the specified safety property. In experiments on standard grid world benchmarks, we show that open source LLMs accessed via Ollama can be verified when deterministically seeded, but generally underperform deep reinforcement learning baselines. Our tool natively integrates with Ollama and supports PRISM-specified tasks, enabling continuous benchmarking in user-specified sequential decision-making tasks and laying a practical foundation for formally verifying increasingly capable LLMs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.478651"
    },
    {
        "index": "#19",
        "title": "Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support",
        "link": "/arxiv/2510.06674",
        "arxiv_id": "2510.06674",
        "authors": "Cen, Zhao, Tiantian Zhang, Hanchen Su, Yufeng, Zhang, Shaowei Su, Mingzhi Xu, Yu, Liu, Wei Han, Jeremy Werner, Claire Na Cheng, Yashar Mehdad",
        "summary": "We introduce an Agent-in-the-Loop (AITL) framework that implements a continuous data flywheel for iteratively improving an LLM-based customer support system. Unlike standard offline approaches that rely on batch annotations, AITL integrates four key types of annotations directly into live customer operations: (1) pairwise response preferences, (2) agent adoption and rationales, (3) knowledge relevance checks, and (4) identification of missing knowledge. These feedback signals seamlessly feed back into models' updates, reducing retraining cycles from months to weeks. Our production pilot involving US-based customer support agents demonstrated significant improvements in retrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality (+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore the effectiveness of embedding human feedback loops directly into operational workflows to continuously refine LLM-based customer support system.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.485303"
    },
    {
        "index": "#20",
        "title": "Fine-Grained Emotion Recognition via In-Context Learning",
        "link": "/arxiv/2510.06600",
        "arxiv_id": "2510.06600",
        "authors": "Zhaochun Ren, Zhou Yang, Chenglong Ye, Haizhou Sun, Chao Chen, Xiaofei Zhu, Xiangwen Liao",
        "summary": "Fine-grained emotion recognition aims to identify the emotional type in queries through reasoning and decision-making processes, playing a crucial role in various systems. Recent methods use In-Context Learning (ICL), enhancing the representation of queries in the reasoning process through semantically similar examples, while further improving emotion recognition by explaining the reasoning mechanisms. However, these methods enhance the reasoning process but overlook the decision-making process. This paper investigates decision-making in fine-grained emotion recognition through prototype theory. We show that ICL relies on similarity matching between query representations and emotional prototypes within the model, where emotion-accurate representations are critical. However, semantically similar examples often introduce emotional discrepancies, hindering accurate representations and causing errors. To address this, we propose Emotion In-Context Learning (EICL), which introduces emotionally similar examples and uses a dynamic soft-label strategy to improve query representations in the emotion reasoning process. A two-stage exclusion strategy is then employed to assess similarity from multiple angles, further optimizing the decision-making process. Extensive experiments show that EICL significantly outperforms ICL on multiple datasets.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.485789"
    },
    {
        "index": "#21",
        "title": "WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks",
        "link": "/arxiv/2510.06587",
        "arxiv_id": "2510.06587",
        "authors": "Jingbo Yang, Bairu Hou, Wei Wei, Shiyu Chang, Yujia Bao",
        "summary": "Large language model (LLM) agents are becoming competent at straightforward web tasks, such as opening an item page or submitting a form, but still struggle with objectives that require long horizon navigation, large scale information extraction, and reasoning under constraints. We present WebDART, a general framework that enables a single LLM to handle such complex chores. WebDART (i) dynamically decomposes each objective into three focused subtasks: navigation, information extraction, and execution, so the model concentrates on one skill at a time, and (ii) continuously replans the decomposition as new webpages are revealed, taking advantage of newly discovered filters or shortcuts and avoiding redundant exploration. Evaluated on WebChoreArena, WebDART lifts success rates by up to 13.7 percentage points over previous SOTA agents, while matching their performance on the easier WebArena suite and completing tasks with up to 14.7 fewer navigation steps.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.486232"
    },
    {
        "index": "#25",
        "title": "Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay Between Food and Health",
        "link": "/arxiv/2510.06433",
        "arxiv_id": "2510.06433",
        "authors": "Aryan Singh Dalal, Yinglun Zhang, Duru Doğan, Atalay Mert İleri, Hande Küçük McGinty",
        "summary": "The focus on \"food as medicine\" is gaining traction in the field of health and several studies conducted in the past few years discussed this aspect of food in the literature. However, very little research has been done on representing the relationship between food and health in a standardized, machine-readable format using a semantic web that can help us leverage this knowledge effectively. To address this gap, this study aims to create a knowledge graph to link food and health through the knowledge graph's ability to combine information from various platforms focusing on flavonoid contents of food found in the USDA databases and cancer connections found in the literature. We looked closely at these relationships using KNARM methodology and represented them in machine-operable format. The proposed knowledge graph serves as an example for researchers, enabling them to explore the complex interplay between dietary choices and disease management. Future work for this study involves expanding the scope of the knowledge graph by capturing nuances, adding more related data, and performing inferences on the acquired knowledge to uncover hidden relationships.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.488130"
    },
    {
        "index": "#26",
        "title": "Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?",
        "link": "/arxiv/2510.06410",
        "arxiv_id": "2510.06410",
        "authors": "Aochong Oliver Li, Tanya Goyal",
        "summary": "Reasoning LLMs are trained to verbalize their reasoning process, yielding strong gains on complex tasks. This transparency also opens a promising direction: multiple reasoners can directly collaborate on each other's thinking within a shared trajectory, yielding better inference efficiency and exploration. A key prerequisite, however, is the ability to assess the usefulness and build on another model's partial thinking -- we call this off-trajectory reasoning. Our paper investigates a critical question: can standard solo-reasoning training pipelines deliver desired off-trajectory behaviors? We propose twin tests that capture the two extremes of the off-trajectory spectrum, namely Recoverability, which tests whether LLMs can backtrack from \"distractions\" induced by misleading reasoning traces, and Guidability, which tests their ability to build upon correct reasoning from stronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and reveals a counterintuitive finding -- \"stronger\" LLMs on benchmarks are often more fragile under distraction. Moreover, all models tested fail to effectively leverage guiding steps from collaborators on problems beyond their inherent capabilities with solve rates remaining under 9.2%. Finally, we conduct control studies to isolate the effects of three factors in post-training on these behaviors: the choice of distillation teacher, the use of RL, and data selection strategy. Our results provide actionable insights for training natively strong reasoning collaborators; e.g., we find that suboptimal recoverability behaviors of teacher models are transferred to distilled students even if the distillation trajectories are correct. Taken together, this work lays the groundwork for evaluating multi-model collaborations in shared reasoning trajectories and highlights the limitations of off-the-shelf reasoning LLMs.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.488552"
    },
    {
        "index": "#27",
        "title": "Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks",
        "link": "/arxiv/2510.06307",
        "arxiv_id": "2510.06307",
        "authors": "Wentao Deng, Jiahuan Pei, Zhiwei Xu, Zhaochun Ren, Zhumin Chen, Pengjie Ren",
        "summary": "A multi-agent system (MAS) enhances its capacity to solve complex natural language processing (NLP) tasks through collaboration among multiple agents, where consensus-seeking serves as a fundamental mechanism. However, existing consensus-seeking approaches typically rely on voting mechanisms to judge consensus, overlooking contradictions in system-internal beliefs that destabilize the consensus. Moreover, these methods often involve agents updating their results through indiscriminate collaboration with every other agent. Such uniform interaction fails to identify the optimal collaborators for each agent, hindering the emergence of a stable consensus. To address these challenges, we provide a theoretical framework for selecting optimal collaborators that maximize consensus stability. Based on the theorems, we propose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate stable consensus via selecting optimal collaborators and calibrating the consensus judgment by system-internal beliefs. Experimental results on the MATH and MMLU benchmark datasets demonstrate that the proposed BCCS framework outperforms the best existing results by 2.23% and 3.95% of accuracy on challenging tasks, respectively. Our code and data are available at https://github.com/dengwentao99/BCCS.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.489027"
    },
    {
        "index": "#28",
        "title": "Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration",
        "link": "/arxiv/2510.06302",
        "arxiv_id": "2510.06302",
        "authors": "Ksenija Lace, Marite Kirikova",
        "summary": "Post-merger integration states unique challenges for professionals responsible for information system integration aimed on alignment and combination diverse system architectures of merging organizations. Although the theoretical and practical guidance exists for post-merger integration on the business level, there is a significant gap in training for information system integration in this context. In prior research specific methods AMILI (Support method for informed decision identification) and AMILP (Support method for informed decision-making) were introduced for the support of information system integration decisions in the post-merger integration. But during the practical application was reported high learning curve and low learner motivation. This paper explores how game-based learning design can address these limitations by transforming static method training into engaging learning experience. The study analyzes foundational learning theories, cognitive load and motivation models, and serious game design frameworks to identify the essential requirements for a game-based learning design framework tailored to information system integration in post-merger integration. Requirements are structured in two components: the transformation process and resulting learning experience. The paper concludes with a plan for developing and evaluating the proposed framework through iterative design and real-world validation.",
        "subjects": "Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.489440"
    },
    {
        "index": "#34",
        "title": "GyroSwin: 5D Surrogates for Gyrokinetic Plasma Turbulence Simulations",
        "link": "/arxiv/2510.07314",
        "arxiv_id": "2510.07314",
        "authors": "Fabian Paischer, Gianluca Galletti, William Hornsby, Paul Setinek, Lorenzo Zanisi, Naomi Carey, Stanislas Pamela, Johannes Brandstetter",
        "summary": "Nuclear fusion plays a pivotal role in the quest for reliable and sustainable energy production. A major roadblock to viable fusion power is understanding plasma turbulence, which significantly impairs plasma confinement, and is vital for next-generation reactor design. Plasma turbulence is governed by the nonlinear gyrokinetic equation, which evolves a 5D distribution function over time. Due to its high computational cost, reduced-order models are often employed in practice to approximate turbulent transport of energy. However, they omit nonlinear effects unique to the full 5D dynamics. To tackle this, we introduce GyroSwin, the first scalable 5D neural surrogate that can model 5D nonlinear gyrokinetic simulations, thereby capturing the physical phenomena neglected by reduced models, while providing accurate estimates of turbulent heat transport.GyroSwin (i) extends hierarchical Vision Transformers to 5D, (ii) introduces cross-attention and integration modules for latent 3D$\\leftrightarrow$5D interactions between electrostatic potential fields and the distribution function, and (iii) performs channelwise mode separation inspired by nonlinear physics. We demonstrate that GyroSwin outperforms widely used reduced numerics on heat flux prediction, captures the turbulent energy cascade, and reduces the cost of fully resolved nonlinear gyrokinetics by three orders of magnitude while remaining physically verifiable. GyroSwin shows promising scaling laws, tested up to one billion parameters, paving the way for scalable neural surrogates for gyrokinetic simulations of plasma turbulence.",
        "subjects": "Plasma Physics, Artificial Intelligence, Machine Learning",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.497806"
    },
    {
        "index": "#42",
        "title": "On the false election between regulation and innovation. Ideas for regulation through the responsible use of artificial intelligence in research and education.[Spanish version]",
        "link": "/arxiv/2510.07268",
        "arxiv_id": "2510.07268",
        "authors": "Pompeu Casanovas",
        "summary": "This short essay is a reworking of the answers offered by the author at the Debate Session of the AIHUB (CSIC) and EduCaixa Summer School, organized by Marta Garcia-Matos and Lissette Lemus, and coordinated by Albert Sabater (OEIAC, UG), with the participation of Vanina Martinez-Posse (IIIA-CSIC), Eulalia Soler (Eurecat) and Pompeu Casanovas (IIIA-CSIC) on July 4th 2025. Albert Sabater posed three questions: (1) How can regulatory frameworks priori-tise the protection of fundamental rights (privacy, non-discrimination, autonomy, etc.) in the development of AI, without falling into the false dichotomy between regulation and innova-tion? (2) Given the risks of AI (bias, mass surveillance, manipulation), what examples of regu-lations or policies have demonstrated that it is possible to foster responsible innovation, putting the public interest before profitability, without giving in to competitive pressure from actors such as China or the US? (3) In a scenario where the US prioritizes flexibility, what mecha-nisms could ensure that international cooperation in AI does not become a race to the bottom in rights, but rather a global standard of accountability? The article attempts to answer these three questions and concludes with some reflections on the relevance of the answers for education and research.",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.507136"
    },
    {
        "index": "#46",
        "title": "GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in Image Generation",
        "link": "/arxiv/2510.07217",
        "arxiv_id": "2510.07217",
        "authors": "Wen Ye, Zhaocheng Liu, Yuwei Gui, Tingyu Yuan, Yunyue Su, Bowen Fang, Chaoyang Zhao, Qiang Liu, Liang Wang",
        "summary": "Text-to-image synthesis has made remarkable progress, yet accurately interpreting complex and lengthy prompts remains challenging, often resulting in semantic inconsistencies and missing details. Existing solutions, such as fine-tuning, are model-specific and require training, while prior automatic prompt optimization (APO) approaches typically lack systematic error analysis and refinement strategies, resulting in limited reliability and effectiveness. Meanwhile, test-time scaling methods operate on fixed prompts and on noise or sample numbers, limiting their interpretability and adaptability. To solve these, we introduce a flexible and efficient test-time prompt optimization strategy that operates directly on the input text. We propose a plug-and-play multi-agent system called GenPilot, integrating error analysis, clustering-based adaptive exploration, fine-grained verification, and a memory module for iterative optimization. Our approach is model-agnostic, interpretable, and well-suited for handling long and complex prompts. Simultaneously, we summarize the common patterns of errors and the refinement strategy, offering more experience and encouraging further exploration. Experiments on DPG-bench and Geneval with improvements of up to 16.9% and 5.7% demonstrate the strong capability of our methods in enhancing the text and image consistency and structural coherence of generated images, revealing the effectiveness of our test-time prompt optimization strategy. The code is available at https://github.com/27yw/GenPilot.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.509261"
    },
    {
        "index": "#48",
        "title": "HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving",
        "link": "/arxiv/2510.07210",
        "arxiv_id": "2510.07210",
        "authors": "Donald Pfaffmann, Matthias Klusch, Marcel Steinmetz",
        "summary": "We present a novel hybrid learning-assisted planning method, named HyPlan, for solving the collision-free navigation problem for self-driving cars in partially observable traffic environments. HyPlan combines methods for multi-agent behavior prediction, deep reinforcement learning with proximal policy optimization and approximated online POMDP planning with heuristic confidence-based vertical pruning to reduce its execution time without compromising safety of driving. Our experimental performance analysis on the CARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealed that HyPlan may navigate safer than selected relevant baselines and perform significantly faster than considered alternative online POMDP planners.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.510197"
    },
    {
        "index": "#50",
        "title": "TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics",
        "link": "/arxiv/2510.07181",
        "arxiv_id": "2510.07181",
        "authors": "Yi Han, Cheng Chi, Enshen Zhou, Shanyu Rong, Jingkun An, Pengwei Wang, Zhongyuan Wang, Lu Sheng, Shanghang Zhang",
        "summary": "Vision-Language Models (VLMs) have shown remarkable capabilities in spatial reasoning, yet they remain fundamentally limited to qualitative precision and lack the computational precision required for real-world robotics. Current approaches fail to leverage metric cues from depth sensors and camera calibration, instead reducing geometric problems to pattern recognition tasks that cannot deliver the centimeter-level accuracy essential for robotic manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel framework that transforms VLMs from perceptual estimators to geometric computers by enabling them to generate and execute precise geometric computations through external tools. Rather than attempting to internalize complex geometric operations within neural networks, TIGeR empowers models to recognize geometric reasoning requirements, synthesize appropriate computational code, and invoke specialized libraries for exact calculations. To support this paradigm, we introduce TIGeR-300K, a comprehensive tool-invocation-oriented dataset covering point transformations, pose estimation, trajectory generation, and spatial compatibility verification, complete with tool invocation sequences and intermediate computations. Through a two-stage training pipeline combining supervised fine-tuning (SFT) and reinforcement fine-tuning (RFT) with our proposed hierarchical reward design, TIGeR achieves SOTA performance on geometric reasoning benchmarks while demonstrating centimeter-level precision in real-world robotic manipulation tasks.",
        "subjects": "Robotics, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.511620"
    },
    {
        "index": "#54",
        "title": "TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking",
        "link": "/arxiv/2510.07134",
        "arxiv_id": "2510.07134",
        "authors": "Jiahang Liu, Yunpeng Qi, Jiazhao Zhang, Minghan Li, Shaoan Wang, Kui Wu, Hanjing Ye, Hong Zhang, Zhibo Chen, Fangwei Zhong, Zhizheng Zhang, He Wang",
        "summary": "Embodied Visual Tracking (EVT) is a fundamental ability that underpins practical applications, such as companion robots, guidance robots and service assistants, where continuously following moving targets is essential. Recent advances have enabled language-guided tracking in complex and unstructured scenes. However, existing approaches lack explicit spatial reasoning and effective temporal memory, causing failures under severe occlusions or in the presence of similar-looking distractors. To address these challenges, we present TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances embodied visual tracking with two key modules, a spatial reasoning mechanism and a Target Identification Memory (TIM). The reasoning module introduces a Chain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative position and encodes it as a compact polar-coordinate token for action prediction. Guided by these spatial priors, the TIM employs a gated update strategy to preserve long-horizon target memory, ensuring spatiotemporal consistency and mitigating target loss during extended occlusions. Extensive experiments show that TrackVLA++ achieves state-of-the-art performance on public benchmarks across both egocentric and multi-camera settings. On the challenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading approach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong zero-shot generalization, enabling robust real-world tracking in dynamic and occluded scenarios.",
        "subjects": "Robotics, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.513636"
    },
    {
        "index": "#55",
        "title": "A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model",
        "link": "/arxiv/2510.07133",
        "arxiv_id": "2510.07133",
        "authors": "Tony Zhang, Burak Kantarci, Umair Siddique",
        "summary": "Ensuring the safety of self-driving cars remains a major challenge due to the complexity and unpredictability of real-world driving environments. Traditional testing methods face significant limitations, such as the oracle problem, which makes it difficult to determine whether a system's behavior is correct, and the inability to cover the full range of scenarios an autonomous vehicle may encounter. In this paper, we introduce a digital twin-driven metamorphic testing framework that addresses these challenges by creating a virtual replica of the self-driving system and its operating environment. By combining digital twin technology with AI-based image generative models such as Stable Diffusion, our approach enables the systematic generation of realistic and diverse driving scenes. This includes variations in weather, road topology, and environmental features, all while maintaining the core semantics of the original scenario. The digital twin provides a synchronized simulation environment where changes can be tested in a controlled and repeatable manner. Within this environment, we define three metamorphic relations inspired by real-world traffic rules and vehicle behavior. We validate our framework in the Udacity self-driving simulator and demonstrate that it significantly enhances test coverage and effectiveness. Our method achieves the highest true positive rate (0.719), F1 score (0.689), and precision (0.662) compared to baseline approaches. This paper highlights the value of integrating digital twins with AI-powered scenario generation to create a scalable, automated, and high-fidelity testing solution for autonomous vehicle safety.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.514083"
    },
    {
        "index": "#56",
        "title": "Graph Conditioned Diffusion for Controllable Histopathology Image Generation",
        "link": "/arxiv/2510.07129",
        "arxiv_id": "2510.07129",
        "authors": "Sarah Cechnicka, Matthew Baugh, Weitong Zhang, Mischa Dombrowski, Zhe Li, Johannes C. Paetzold, Candice Roufosse, Bernhard Kainz",
        "summary": "Recent advances in Diffusion Probabilistic Models (DPMs) have set new standards in high-quality image synthesis. Yet, controlled generation remains challenging, particularly in sensitive areas such as medical imaging. Medical images feature inherent structure such as consistent spatial arrangement, shape or texture, all of which are critical for diagnosis. However, existing DPMs operate in noisy latent spaces that lack semantic structure and strong priors, making it difficult to ensure meaningful control over generated content. To address this, we propose graph-based object-level representations for Graph-Conditioned-Diffusion. Our approach generates graph nodes corresponding to each major structure in the image, encapsulating their individual features and relationships. These graph representations are processed by a transformer module and integrated into a diffusion model via the text-conditioning mechanism, enabling fine-grained control over generation. We evaluate this approach using a real-world histopathology use case, demonstrating that our generated data can reliably substitute for annotated patient data in downstream segmentation tasks. The code is available here.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.514597"
    },
    {
        "index": "#69",
        "title": "The Limits of Goal-Setting Theory in LLM-Driven Assessment",
        "link": "/arxiv/2510.06997",
        "arxiv_id": "2510.06997",
        "authors": "Mrityunjay Kumar",
        "summary": "Many users interact with AI tools like ChatGPT using a mental model that treats the system as human-like, which we call Model H. According to goal-setting theory, increased specificity in goals should reduce performance variance. If Model H holds, then prompting a chatbot with more detailed instructions should lead to more consistent evaluation behavior. This paper tests that assumption through a controlled experiment in which ChatGPT evaluated 29 student submissions using four prompts with increasing specificity. We measured consistency using intra-rater reliability (Cohen's Kappa) across repeated runs. Contrary to expectations, performance did not improve consistently with increased prompt specificity, and performance variance remained largely unchanged. These findings challenge the assumption that LLMs behave like human evaluators and highlight the need for greater robustness and improved input integration in future model development.",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.519417"
    },
    {
        "index": "#71",
        "title": "Learning Global Representation from Queries for Vectorized HD Map Construction",
        "link": "/arxiv/2510.06969",
        "arxiv_id": "2510.06969",
        "authors": "Shoumeng Qiu, Xinrun Li, Yang Long, Xiangyang Xue, Varun Ojha, Jian Pu",
        "summary": "The online construction of vectorized high-definition (HD) maps is a cornerstone of modern autonomous driving systems. State-of-the-art approaches, particularly those based on the DETR framework, formulate this as an instance detection problem. However, their reliance on independent, learnable object queries results in a predominantly local query perspective, neglecting the inherent global representation within HD maps. In this work, we propose \\textbf{MapGR} (\\textbf{G}lobal \\textbf{R}epresentation learning for HD \\textbf{Map} construction), an architecture designed to learn and utilize a global representations from queries. Our method introduces two synergistic modules: a Global Representation Learning (GRL) module, which encourages the distribution of all queries to better align with the global map through a carefully designed holistic segmentation task, and a Global Representation Guidance (GRG) module, which endows each individual query with explicit, global-level contextual information to facilitate its optimization. Evaluations on the nuScenes and Argoverse2 datasets validate the efficacy of our approach, demonstrating substantial improvements in mean Average Precision (mAP) compared to leading baselines.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.520035"
    },
    {
        "index": "#72",
        "title": "Generating Surface for Text-to-3D using 2D Gaussian Splatting",
        "link": "/arxiv/2510.06967",
        "arxiv_id": "2510.06967",
        "authors": "Huanning Dong, Fan Li, Ping Kuang, Jianwen Min",
        "summary": "Recent advancements in Text-to-3D modeling have shown significant potential for the creation of 3D content. However, due to the complex geometric shapes of objects in the natural world, generating 3D content remains a challenging task. Current methods either leverage 2D diffusion priors to recover 3D geometry, or train the model directly based on specific 3D representations. In this paper, we propose a novel method named DirectGaussian, which focuses on generating the surfaces of 3D objects represented by surfels. In DirectGaussian, we utilize conditional text generation models and the surface of a 3D object is rendered by 2D Gaussian splatting with multi-view normal and texture priors. For multi-view geometric consistency problems, DirectGaussian incorporates curvature constraints on the generated surface during optimization process. Through extensive experiments, we demonstrate that our framework is capable of achieving diverse and high-fidelity 3D content creation.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.520323"
    },
    {
        "index": "#76",
        "title": "Expressive and Scalable Quantum Fusion for Multimodal Learning",
        "link": "/arxiv/2510.06938",
        "arxiv_id": "2510.06938",
        "authors": "Tuyen Nguyen, Trong Nghia Hoang, Phi Le Nguyen, Hai L. Vu, Truong Cong Thang",
        "summary": "The aim of this paper is to introduce a quantum fusion mechanism for multimodal learning and to establish its theoretical and empirical potential. The proposed method, called the Quantum Fusion Layer (QFL), replaces classical fusion schemes with a hybrid quantum-classical procedure that uses parameterized quantum circuits to learn entangled feature interactions without requiring exponential parameter growth. Supported by quantum signal processing principles, the quantum component efficiently represents high-order polynomial interactions across modalities with linear parameter scaling, and we provide a separation example between QFL and low-rank tensor-based methods that highlights potential quantum query advantages. In simulation, QFL consistently outperforms strong classical baselines on small but diverse multimodal tasks, with particularly marked improvements in high-modality regimes. These results suggest that QFL offers a fundamentally new and scalable approach to multimodal fusion that merits deeper exploration on larger systems.",
        "subjects": "Quantum Physics, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.521687"
    },
    {
        "index": "#80",
        "title": "Emotionally Vulnerable Subtype of Internet Gaming Disorder: Measuring and Exploring the Pathology of Problematic Generative AI Use",
        "link": "/arxiv/2510.06908",
        "arxiv_id": "2510.06908",
        "authors": "Haocan Sun, Di Wua, Weizi Liu, Guoming Yua, Mike Yao",
        "summary": "Concerns over the potential over-pathologization of generative AI (GenAI) use and the lack of conceptual clarity surrounding GenAI addiction call for empirical tools and theoretical refinement. This study developed and validated the PUGenAIS-9 (Problematic Use of Generative Artificial Intelligence Scale-9 items) and examined whether PUGenAIS reflects addiction-like patterns under the Internet Gaming Disorder (IGD) framework. Using samples from China and the United States (N = 1,508), we conducted confirmatory factor analysis and identified a robust 31-item structure across nine IGD-based dimensions. We then derived the PUGenAIS-9 by selecting the highest-loading items from each dimension and validated its structure in an independent sample (N = 1,426). Measurement invariance tests confirmed its stability across nationality and gender. Person-centered (latent profile analysis) and variable-centered (network analysis) approaches found that PUGenAIS matches the traits of the emotionally vulnerable subtype of IGD, not the competence-based kind. These results support using PUGenAIS-9 to identify problematic GenAI use and show the need to rethink digital addiction with an ICD (infrastructures, content, and device) model. This keeps addiction research responsive to new media while avoiding over-pathologizing.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Computers and Society",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.522952"
    },
    {
        "index": "#82",
        "title": "M3Retrieve: Benchmarking Multimodal Retrieval for Medicine",
        "link": "/arxiv/2510.06888",
        "arxiv_id": "2510.06888",
        "authors": "Arkadeep Acharya, Akash Ghosh, Pradeepika Verma, Kitsuchart Pasupa, Sriparna Saha, Priti Singh",
        "summary": "With the increasing use of RetrievalAugmented Generation (RAG), strong retrieval models have become more important than ever. In healthcare, multimodal retrieval models that combine information from both text and images offer major advantages for many downstream tasks such as question answering, cross-modal retrieval, and multimodal summarization, since medical data often includes both formats. However, there is currently no standard benchmark to evaluate how well these models perform in medical settings. To address this gap, we introduce M3Retrieve, a Multimodal Medical Retrieval Benchmark. M3Retrieve, spans 5 domains,16 medical fields, and 4 distinct tasks, with over 1.2 Million text documents and 164K multimodal queries, all collected under approved licenses. We evaluate leading multimodal retrieval models on this benchmark to explore the challenges specific to different medical specialities and to understand their impact on retrieval performance. By releasing M3Retrieve, we aim to enable systematic evaluation, foster model innovation, and accelerate research toward building more capable and reliable multimodal retrieval systems for medical applications. The dataset and the baselines code are available in this github page https://github.com/AkashGhosh/M3Retrieve.",
        "subjects": "Information Retrieval, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.523565"
    },
    {
        "index": "#87",
        "title": "Explaining raw data complexity to improve satellite onboard processing",
        "link": "/arxiv/2510.06858",
        "arxiv_id": "2510.06858",
        "authors": "Adrien Dorise, Marjorie Bellizzi, Adrien Girard, Benjamin Francesconi, Stéphane May",
        "summary": "With increasing processing power, deploying AI models for remote sensing directly onboard satellites is becoming feasible. However, new constraints arise, mainly when using raw, unprocessed sensor data instead of preprocessed ground-based products. While current solutions primarily rely on preprocessed sensor images, few approaches directly leverage raw data. This study investigates the effects of utilising raw data on deep learning models for object detection and classification tasks. We introduce a simulation workflow to generate raw-like products from high-resolution L1 imagery, enabling systemic evaluation. Two object detection models (YOLOv11s and YOLOX-S) are trained on both raw and L1 datasets, and their performance is compared using standard detection metrics and explainability tools. Results indicate that while both models perform similarly at low to medium confidence thresholds, the model trained on raw data struggles with object boundary identification at high confidence levels. It suggests that adapting AI architectures with improved contouring methods can enhance object detection on raw images, improving onboard AI for remote sensing.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.525121"
    },
    {
        "index": "#94",
        "title": "Extreme Amodal Face Detection",
        "link": "/arxiv/2510.06791",
        "arxiv_id": "2510.06791",
        "authors": "Changlin Song, Yunzhong Hou, Michael Randall Barnes, Rahul Shome, Dylan Campbell",
        "summary": "Extreme amodal detection is the task of inferring the 2D location of objects that are not fully visible in the input image but are visible within an expanded field-of-view. This differs from amodal detection, where the object is partially visible within the input image, but is occluded. In this paper, we consider the sub-problem of face detection, since this class provides motivating applications involving safety and privacy, but do not tailor our method specifically to this class. Existing approaches rely on image sequences so that missing detections may be interpolated from surrounding frames or make use of generative models to sample possible completions. In contrast, we consider the single-image task and propose a more efficient, sample-free approach that makes use of the contextual cues from the image to infer the presence of unseen faces. We design a heatmap-based extreme amodal object detector that addresses the problem of efficiently predicting a lot (the out-of-frame region) from a little (the image) with a selective coarse-to-fine decoder. Our method establishes strong results for this new task, even outperforming less efficient generative approaches.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.532423"
    },
    {
        "index": "#100",
        "title": "LLM Company Policies and Policy Implications in Software Organizations",
        "link": "/arxiv/2510.06718",
        "arxiv_id": "2510.06718",
        "authors": "Ranim Khojah, Mazen Mohamad, Linda Erlenhov, Francisco Gomes de Oliveira Neto, Philipp Leitner",
        "summary": "The risks associated with adopting large language model (LLM) chatbots in software organizations highlight the need for clear policies. We examine how 11 companies create these policies and the factors that influence them, aiming to help managers safely integrate chatbots into development workflows.",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.534201"
    },
    {
        "index": "#102",
        "title": "AISysRev - LLM-based Tool for Title-abstract Screening",
        "link": "/arxiv/2510.06708",
        "arxiv_id": "2510.06708",
        "authors": "Aleksi Huotala, Miikka Kuutila, Olli-Pekka Turtio, Mika Mäntylä",
        "summary": "Systematic reviews are a standard practice for summarizing the state of evidence in software engineering. Conducting systematic reviews is laborious, especially during the screening or study selection phase, where the number of papers can be overwhelming. During this phase, papers are assessed against inclusion and exclusion criteria based on their titles and abstracts. Recent research has demonstrated that large language models (LLMs) can perform title-abstract screening at a level comparable to that of a master's student. While LLMs cannot be fully trusted, they can help, for example, in Rapid Reviews, which try to expedite the review process. Building on recent research, we developed AiSysRev, an LLM-based screening tool implemented as a web application running in a Docker container. The tool accepts a CSV file containing paper titles and abstracts. Users specify inclusion and exclusion criteria. One can use multiple LLMs for screening via OpenRouter. AiSysRev supports both zero-shot and few-shot screening, and also allows for manual screening through interfaces that display LLM results as guidance for human reviewers.We conducted a trial study with 137 papers using the tool. Our findings indicate that papers can be classified into four categories: Easy Includes, Easy Excludes, Boundary Includes, and Boundary Excludes. The Boundary cases, where LLMs are prone to errors, highlight the need for human intervention. While LLMs do not replace human judgment in systematic reviews, they can significantly reduce the burden of assessing large volumes of scientific literature. Video: https://www.youtube.com/watch?v=jVbEj4Y4tQI Tool: https://github.com/EvoTestOps/AISysRev",
        "subjects": "Software Engineering, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.534787"
    },
    {
        "index": "#104",
        "title": "Semantic Segmentation Algorithm Based on Light Field and LiDAR Fusion",
        "link": "/arxiv/2510.06687",
        "arxiv_id": "2510.06687",
        "authors": "Jie Luo, Yuxuan Jiang, Xin Jin, Mingyu Liu, Yihui Fan",
        "summary": "Semantic segmentation serves as a cornerstone of scene understanding in autonomous driving but continues to face significant challenges under complex conditions such as occlusion. Light field and LiDAR modalities provide complementary visual and spatial cues that are beneficial for robust perception; how- ever, their effective integration is hindered by limited viewpoint diversity and inherent modality discrepancies. To address these challenges, the first multimodal semantic segmentation dataset integrating light field data and point cloud data is proposed. Based on this dataset, we proposed a multi-modal light field point-cloud fusion segmentation network(Mlpfseg), incorporating feature completion and depth perception to segment both camera images and LiDAR point clouds simultaneously. The feature completion module addresses the density mismatch between point clouds and image pixels by performing differential re- construction of point-cloud feature maps, enhancing the fusion of these modalities. The depth perception module improves the segmentation of occluded objects by reinforcing attention scores for better occlusion awareness. Our method outperforms image- only segmentation by 1.71 Mean Intersection over Union(mIoU) and point cloud-only segmentation by 2.38 mIoU, demonstrating its effectiveness.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.535415"
    },
    {
        "index": "#106",
        "title": "Heptapod: Language Modeling on Visual Signals",
        "link": "/arxiv/2510.06673",
        "arxiv_id": "2510.06673",
        "authors": "Yongxin Zhu, Jiawei Chen, Yuanzhe Chen, Zhuo Chen, Dongya Jia, Jian Cong, Xiaobin Zhuang, Yuping Wang, Yuxuan Wang",
        "summary": "We introduce Heptapod, an image autoregressive model that adheres to the foundational principles of language modeling. Heptapod employs \\textbf{causal attention}, \\textbf{eliminates reliance on CFG}, and \\textbf{eschews the trend of semantic tokenizers}. Our key innovation is \\textit{next 2D distribution prediction}: a causal Transformer with reconstruction-focused visual tokenizer, learns to predict the distribution over the entire 2D spatial grid of images at each timestep. This learning objective unifies the sequential modeling of autoregressive framework with the holistic self-supervised learning of masked autoencoding, enabling the model to capture comprehensive image semantics via generative training. On the ImageNet generation benchmark, Heptapod achieves an FID of $2.70$, significantly outperforming previous causal autoregressive approaches. We hope our work inspires a principled rethinking of language modeling on visual signals and beyond.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.536135"
    },
    {
        "index": "#107",
        "title": "Automated Neural Architecture Design for Industrial Defect Detection",
        "link": "/arxiv/2510.06669",
        "arxiv_id": "2510.06669",
        "authors": "Yuxi Liu, Yunfeng Ma, Yi Tang, Min Liu, Shuai Jiang, Yaonan Wang",
        "summary": "Industrial surface defect detection (SDD) is critical for ensuring product quality and manufacturing reliability. Due to the diverse shapes and sizes of surface defects, SDD faces two main challenges: intraclass difference and interclass similarity. Existing methods primarily utilize manually designed models, which require extensive trial and error and often struggle to address both challenges effectively. To overcome this, we propose AutoNAD, an automated neural architecture design framework for SDD that jointly searches over convolutions, transformers, and multi-layer perceptrons. This hybrid design enables the model to capture both fine-grained local variations and long-range semantic context, addressing the two key challenges while reducing the cost of manual network design. To support efficient training of such a diverse search space, AutoNAD introduces a cross weight sharing strategy, which accelerates supernet convergence and improves subnet performance. Additionally, a searchable multi-level feature aggregation module (MFAM) is integrated to enhance multi-scale feature learning. Beyond detection accuracy, runtime efficiency is essential for industrial deployment. To this end, AutoNAD incorporates a latency-aware prior to guide the selection of efficient architectures. The effectiveness of AutoNAD is validated on three industrial defect datasets and further applied within a defect imaging and detection platform. Code will be available at https://github.com/Yuxi104/AutoNAD.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.536445"
    },
    {
        "index": "#108",
        "title": "Delay Independent Safe Control with Neural Networks: Positive Lur'e Certificates for Risk Aware Autonomy",
        "link": "/arxiv/2510.06661",
        "arxiv_id": "2510.06661",
        "authors": "Hamidreza Montazeri Hedesh, Milad Siami",
        "summary": "We present a risk-aware safety certification method for autonomous, learning enabled control systems. Focusing on two realistic risks, state/input delays and interval matrix uncertainty, we model the neural network (NN) controller with local sector bounds and exploit positivity structure to derive linear, delay-independent certificates that guarantee local exponential stability across admissible uncertainties. To benchmark performance, we adopt and implement a state-of-the-art IQC NN verification pipeline. On representative cases, our positivity-based tests run orders of magnitude faster than SDP-based IQC while certifying regimes the latter cannot-providing scalable safety guarantees that complement risk-aware control.",
        "subjects": "Systems and Control, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.541879"
    },
    {
        "index": "#111",
        "title": "Distilling Lightweight Language Models for C/C++ Vulnerabilities",
        "link": "/arxiv/2510.06645",
        "arxiv_id": "2510.06645",
        "authors": "Zhiyuan Wei, Xiaoxuan Yang, Jing Sun, Zijian Zhang",
        "summary": "The increasing complexity of modern software systems exacerbates the prevalence of security vulnerabilities, posing risks of severe breaches and substantial economic loss. Consequently, robust code vulnerability detection is essential for software security. While Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language processing, their potential for automated code vulnerability detection remains underexplored. This paper presents FineSec, a novel framework that harnesses LLMs through knowledge distillation to enable efficient and precise vulnerability identification in C/C++ codebases. FineSec utilizes knowledge distillation to transfer expertise from large teacher models to compact student models, achieving high accuracy with minimal computational cost. By integrating data preparation, training, evaluation, and continuous learning into a unified, single-task workflow, FineSec offers a streamlined approach. Extensive evaluations on C/C++ codebases demonstrate its superiority over both base models and larger LLMs in identifying complex vulnerabilities and logical flaws, establishing FineSec as a practical and scalable solution for real-world software security. To facilitate reproducibility, the datasets, source code, and experimental results are made publicly available at: https://github.com/yangxiaoxuan123/FineSec_detect.",
        "subjects": "Cryptography and Security, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.543313"
    },
    {
        "index": "#112",
        "title": "StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual Question Answering",
        "link": "/arxiv/2510.06638",
        "arxiv_id": "2510.06638",
        "authors": "Zhihao Wen, Wenkang Wei, Yuan Fang, Xingtong Yu, Hui Zhang, Weicheng Zhu, Xin Zhang",
        "summary": "Knowledge-based Visual Question Answering (KVQA) requires models to ground entities in images and reason over factual knowledge. We study its implicit-knowledge variant, IK-KVQA, where a multimodal large language model (MLLM) is the sole knowledge source, without external retrieval. Yet, MLLMs lack explicit reasoning supervision and produce inconsistent justifications, and generalize poorly after standard supervised fine-tuning (SFT). We present StaR-KVQA (Structured Reasoning Traces for IK-KVQA), which supervises structured traces - dual symbolic relation paths plus path-grounded natural-language explanations - so that reasoning becomes transparent and verifiable. With one open-source MLLM, StaR-KVQA constructs and selects path-grounded reasoning traces to form a trace-enriched dataset, then fine-tunes via structured self-distillation to align generation with supervision; no external retrievers, verifiers, or curated knowledge bases (KBs) are used, traces are built offline, and inference is a single autoregressive pass. Across benchmarks, StaR-KVQA improves both accuracy and interpretability, achieving up to +11.3% higher answer accuracy on OK-VQA over the strongest baseline while exhibiting robust cross-domain generalization.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.543863"
    },
    {
        "index": "#118",
        "title": "HSNet: Heterogeneous Subgraph Network for Single Image Super-resolution",
        "link": "/arxiv/2510.06564",
        "arxiv_id": "2510.06564",
        "authors": "Qiongyang Hu, Wenyang Liu, Wenbin Zou, Yuejiao Su, Lap-Pui Chau, Yi Wang",
        "summary": "Existing deep learning approaches for image super-resolution, particularly those based on CNNs and attention mechanisms, often suffer from structural inflexibility. Although graph-based methods offer greater representational adaptability, they are frequently impeded by excessive computational complexity. To overcome these limitations, this paper proposes the Heterogeneous Subgraph Network (HSNet), a novel framework that efficiently leverages graph modeling while maintaining computational feasibility. The core idea of HSNet is to decompose the global graph into manageable sub-components. First, we introduce the Constructive Subgraph Set Block (CSSB), which generates a diverse set of complementary subgraphs. Rather than relying on a single monolithic graph, CSSB captures heterogeneous characteristics of the image by modeling different relational patterns and feature interactions, producing a rich ensemble of both local and global graph structures. Subsequently, the Subgraph Aggregation Block (SAB) integrates the representations embedded across these subgraphs. Through adaptive weighting and fusion of multi-graph features, SAB constructs a comprehensive and discriminative representation that captures intricate interdependencies. Furthermore, a Node Sampling Strategy (NSS) is designed to selectively retain the most salient features, thereby enhancing accuracy while reducing computational overhead. Extensive experiments demonstrate that HSNet achieves state-of-the-art performance, effectively balancing reconstruction quality with computational efficiency. The code will be made publicly available.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.552113"
    },
    {
        "index": "#123",
        "title": "CLAQS: Compact Learnable All-Quantum Token Mixer with Shared-ansatz for Text Classification",
        "link": "/arxiv/2510.06532",
        "arxiv_id": "2510.06532",
        "authors": "Junhao Chen, Yifan Zhou, Hanqi Jiang, Yi Pan, Yiwei Li, Huaqin Zhao, Wei Zhang, Yingfeng Wang, Tianming Liu",
        "summary": "Quantum compute is scaling fast, from cloud QPUs to high throughput GPU simulators, making it timely to prototype quantum NLP beyond toy tasks. However, devices remain qubit limited and depth limited, training can be unstable, and classical attention is compute and memory heavy. This motivates compact, phase aware quantum token mixers that stabilize amplitudes and scale to long sequences. We present CLAQS, a compact, fully quantum token mixer for text classification that jointly learns complex-valued mixing and nonlinear transformations within a unified quantum circuit. To enable stable end-to-end optimization, we apply l1 normalization to regulate amplitude scaling and introduce a two-stage parameterized quantum architecture that decouples shared token embeddings from a window-level quantum feed-forward module. Operating under a sliding-window regime with document-level aggregation, CLAQS requires only eight data qubits and shallow circuits, yet achieves 91.64% accuracy on SST-2 and 87.08% on IMDB, outperforming both classical Transformer baselines and strong hybrid quantum-classical counterparts.",
        "subjects": "Quantum Physics, Artificial Intelligence",
        "date": "2025-10-08",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.554575"
    },
    {
        "index": "#124",
        "title": "Visualizing Multimodality in Combinatorial Search Landscapes",
        "link": "/arxiv/2510.06517",
        "arxiv_id": "2510.06517",
        "authors": "Xavier F. C. Sánchez-Díaz, Ole Jakob Mengshoel",
        "summary": "This work walks through different visualization techniques for combinatorial search landscapes, focusing on multimodality. We discuss different techniques from the landscape analysis literature, and how they can be combined to provide a more comprehensive view of the search landscape. We also include examples and discuss relevant work to show how others have used these techniques in practice, based on the geometric and aesthetic elements of the Grammar of Graphics. We conclude that there is no free lunch in visualization, and provide recommendations for future work as there are several paths to continue the work in this field.",
        "subjects": "Graphics, Artificial Intelligence, Neural and Evolutionary Computing",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.555100"
    },
    {
        "index": "#125",
        "title": "LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval",
        "link": "/arxiv/2510.06512",
        "arxiv_id": "2510.06512",
        "authors": "Avishree Khare, Hideki Okamoto, Bardh Hoxha, Georgios Fainekos, Rajeev Alur",
        "summary": "Neural models such as YOLO and HuBERT can be used to detect local properties such as objects (\"car\") and emotions (\"angry\") in individual frames of videos and audio clips respectively. The likelihood of these detections is indicated by scores in [0, 1]. Lifting these scores to temporal properties over sequences can be useful for several downstream applications such as query matching (e.g., \"does the speaker eventually sound happy in this audio clip?\"), and ranked retrieval (e.g., \"retrieve top 5 videos with a 10 second scene where a car is detected until a pedestrian is detected\"). In this work, we formalize this problem of assigning Scores for TempOral Properties (STOPs) over sequences, given potentially noisy score predictors for local properties. We then propose a scoring function called LogSTOP that can efficiently compute these scores for temporal properties represented in Linear Temporal Logic. Empirically, LogSTOP, with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and other Temporal Logic-based baselines by at least 16% on query matching with temporal properties over objects-in-videos and emotions-in-speech respectively. Similarly, on ranked retrieval with temporal properties over objects and actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a 19% and 16% increase in mean average precision and recall over zero-shot text-to-video retrieval baselines respectively.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.555610"
    },
    {
        "index": "#131",
        "title": "Deep Generative Model for Human Mobility Behavior",
        "link": "/arxiv/2510.06473",
        "arxiv_id": "2510.06473",
        "authors": "Ye Hong, Yatao Zhang, Konrad Schindler, Martin Raubal",
        "summary": "Understanding and modeling human mobility is central to challenges in transport planning, sustainable urban design, and public health. Despite decades of effort, simulating individual mobility remains challenging because of its complex, context-dependent, and exploratory nature. Here, we present MobilityGen, a deep generative model that produces realistic mobility trajectories spanning days to weeks at large spatial scales. By linking behavioral attributes with environmental context, MobilityGen reproduces key patterns such as scaling laws for location visits, activity time allocation, and the coupled evolution of travel mode and destination choices. It reflects spatio-temporal variability and generates diverse, plausible, and novel mobility patterns consistent with the built environment. Beyond standard validation, MobilityGen yields insights not attainable with earlier models, including how access to urban space varies across travel modes and how co-presence dynamics shape social exposure and segregation. Our work establishes a new framework for mobility simulation, paving the way for fine-grained, data-driven studies of human behavior and its societal implications.",
        "subjects": "Physics and Society, Artificial Intelligence, Social and Information Networks",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.563789"
    },
    {
        "index": "#132",
        "title": "Evaluating Node-tree Interfaces for AI Explainability",
        "link": "/arxiv/2510.06457",
        "arxiv_id": "2510.06457",
        "authors": "Lifei Wang, Natalie Friedman, Chengchao Zhu, Zeshu Zhu, S. Joy Mountford",
        "summary": "As large language models (LLMs) become ubiquitous in workplace tools and decision-making processes, ensuring explainability and fostering user trust are critical. Although advancements in LLM engineering continue, human-centered design is still catching up, particularly when it comes to embedding transparency and trust into AI interfaces. This study evaluates user experiences with two distinct AI interfaces - node-tree interfaces and chatbot interfaces - to assess their performance in exploratory, follow-up inquiry, decision-making, and problem-solving tasks. Our design-driven approach introduces a node-tree interface that visually structures AI-generated responses into hierarchically organized, interactive nodes, allowing users to navigate, refine, and follow up on complex information. In a comparative study with n=20 business users, we observed that while the chatbot interface effectively supports linear, step-by-step queries, it is the node-tree interface that enhances brainstorming. Quantitative and qualitative findings indicate that node-tree interfaces not only improve task performance and decision-making support but also promote higher levels of user trust by preserving context. Our findings suggest that adaptive AI interfaces capable of switching between structured visualizations and conversational formats based on task requirements can significantly enhance transparency and user confidence in AI-powered systems. This work contributes actionable insights to the fields of human-robot interaction and AI design, particularly for enterprise applications where trust-building is critical for teams.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.564260"
    },
    {
        "index": "#137",
        "title": "Adaptive Protein Design Protocols and Middleware",
        "link": "/arxiv/2510.06396",
        "arxiv_id": "2510.06396",
        "authors": "Aymen Alsaadi, Jonathan Ash, Mikhail Titov, Matteo Turilli, Andre Merzky, Shantenu Jha, Sagar Khare",
        "summary": "Computational protein design is experiencing a transformation driven by AI/ML. However, the range of potential protein sequences and structures is astronomically vast, even for moderately sized proteins. Hence, achieving convergence between generated and predicted structures demands substantial computational resources for sampling. The Integrated Machine-learning for Protein Structures at Scale (IMPRESS) offers methods and advanced computing systems for coupling AI to high-performance computing tasks, enabling the ability to evaluate the effectiveness of protein designs as they are developed, as well as the models and simulations used to generate data and train models. This paper introduces IMPRESS and demonstrates the development and implementation of an adaptive protein design protocol and its supporting computing infrastructure. This leads to increased consistency in the quality of protein design and enhanced throughput of protein design due to dynamic resource allocation and asynchronous workload execution.",
        "subjects": "Distributed, Parallel, and Cluster Computing, Artificial Intelligence, Performance, Software Engineering",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.566892"
    },
    {
        "index": "#143",
        "title": "Constrained Natural Language Action Planning for Resilient Embodied Systems",
        "link": "/arxiv/2510.06357",
        "arxiv_id": "2510.06357",
        "authors": "Grayson Byrd, Corban Rivera, Bethany Kemp, Meghan Booker, Aurora Schmidt, Celso M de Melo, Lalithkumar Seenivasan, Mathias Unberath",
        "summary": "Replicating human-level intelligence in the execution of embodied tasks remains challenging due to the unconstrained nature of real-world environments. Novel use of large language models (LLMs) for task planning seeks to address the previously intractable state/action space of complex planning tasks, but hallucinations limit their reliability, and thus, viability beyond a research context. Additionally, the prompt engineering required to achieve adequate system performance lacks transparency, and thus, repeatability. In contrast to LLM planning, symbolic planning methods offer strong reliability and repeatability guarantees, but struggle to scale to the complexity and ambiguity of real-world tasks. We introduce a new robotic planning method that augments LLM planners with symbolic planning oversight to improve reliability and repeatability, and provide a transparent approach to defining hard constraints with considerably stronger clarity than traditional prompt engineering. Importantly, these augmentations preserve the reasoning capabilities of LLMs and retain impressive generalization in open-world environments. We demonstrate our approach in simulated and real-world environments. On the ALFWorld planning benchmark, our approach outperforms current state-of-the-art methods, achieving a near-perfect 99% success rate. Deployment of our method to a real-world quadruped robot resulted in 100% task success compared to 50% and 30% for pure LLM and symbolic planners across embodied pick and place tasks. Our approach presents an effective strategy to enhance the reliability, repeatability and transparency of LLM-based robot planners while retaining their key strengths: flexibility and generalizability to complex real-world environments. We hope that this work will contribute to the broad goal of building resilient embodied intelligent systems.",
        "subjects": "Robotics, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.569897"
    },
    {
        "index": "#147",
        "title": "Leveraging Large Language Models for Cybersecurity Risk Assessment -- A Case from Forestry Cyber-Physical Systems",
        "link": "/arxiv/2510.06343",
        "arxiv_id": "2510.06343",
        "authors": "Fikret Mert Gültekin, Oscar Lilja, Ranim Khojah, Rebekka Wohlrab, Marvin Damschen, Mazen Mohamad",
        "summary": "In safety-critical software systems, cybersecurity activities become essential, with risk assessment being one of the most critical. In many software teams, cybersecurity experts are either entirely absent or represented by only a small number of specialists. As a result, the workload for these experts becomes high, and software engineers would need to conduct cybersecurity activities themselves. This creates a need for a tool to support cybersecurity experts and engineers in evaluating vulnerabilities and threats during the risk assessment process. This paper explores the potential of leveraging locally hosted large language models (LLMs) with retrieval-augmented generation to support cybersecurity risk assessment in the forestry domain while complying with data protection and privacy requirements that limit external data sharing. We performed a design science study involving 12 experts in interviews, interactive sessions, and a survey within a large-scale project. The results demonstrate that LLMs can assist cybersecurity experts by generating initial risk assessments, identifying threats, and providing redundancy checks. The results also highlight the necessity for human oversight to ensure accuracy and compliance. Despite trust concerns, experts were willing to utilize LLMs in specific evaluation and assistance roles, rather than solely relying on their generative capabilities. This study provides insights that encourage the use of LLM-based agents to support the risk assessment process of cyber-physical systems in safety-critical domains.",
        "subjects": "Software Engineering, Artificial Intelligence, Cryptography and Security",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.573822"
    },
    {
        "index": "#149",
        "title": "RGBD Gaze Tracking Using Transformer for Feature Fusion",
        "link": "/arxiv/2510.06298",
        "arxiv_id": "2510.06298",
        "authors": "Tobias J. Bauer",
        "summary": "Subject of this thesis is the implementation of an AI-based Gaze Tracking system using RGBD images that contain both color (RGB) and depth (D) information. To fuse the features extracted from the images, a module based on the Transformer architecture is used. The combination of RGBD input images and Transformers was chosen because it has not yet been investigated. Furthermore, a new dataset is created for training the AI models as existing datasets either do not contain depth information or only contain labels for Gaze Point Estimation that are not suitable for the task of Gaze Angle Estimation. Various model configurations are trained, validated and evaluated on a total of three different datasets. The trained models are then to be used in a real-time pipeline to estimate the gaze direction and thus the gaze point of a person in front of a computer screen. The AI model architecture used in this thesis is based on an earlier work by Lian et al. It uses a Generative Adversarial Network (GAN) to simultaneously remove depth map artifacts and extract head pose features. Lian et al. achieve a mean Euclidean error of 38.7mm on their own dataset ShanghaiTechGaze+. In this thesis, a model architecture with a Transformer module for feature fusion achieves a mean Euclidean error of 55.3mm on the same dataset, but we show that using no pre-trained GAN module leads to a mean Euclidean error of 30.1mm. Replacing the Transformer module with a Multilayer Perceptron (MLP) improves the error to 26.9mm. These results are coherent with the ones on the other two datasets. On the ETH-XGaze dataset, the model with Transformer module achieves a mean angular error of 3.59{\\deg} and without Transformer module 3.26{\\deg}, whereas the fundamentally different model architecture used by the dataset authors Zhang et al. achieves a mean angular error of 2.04{\\deg}. On the OTH-Gaze-Estimation dataset created for...",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.574444"
    },
    {
        "index": "#150",
        "title": "VeriEquivBench: An Equivalence Score for Ground-Truth-Free Evaluation of Formally Verifiable Code",
        "link": "/arxiv/2510.06296",
        "arxiv_id": "2510.06296",
        "authors": "Lingfei Zeng, Fengdi Che, Xuhan Huang, Fei Ye, Xu Xu, Binhang Yuan, Jie Fu",
        "summary": "Formal verification is the next frontier for ensuring the correctness of code generated by Large Language Models (LLMs). While methods that co-generate code and formal specifications in formal languages, like Dafny, can, in principle, prove alignment with user intent, progress is bottlenecked by specification quality evaluation. Current benchmarks rely on matching against ground-truth specifications, a manual and expertise-intensive process that has limited existing datasets to a few hundred simple problems and also suffers from a reliability issue. To address this, we introduce VeriEquivBench, a new benchmark with $2,389$ complex algorithmic problems that probe the limitations of current models in both code generation and formal reasoning. Our evaluation framework replaces ground-truth matching with a formally grounded metric, the equivalence score, and rigorously verifies the quality of generated specifications and code. Our results show that generating formally verifiable code remains a profound challenge for state-of-the-art LLMs. This underscores both the difficulty of the task and the need for benchmarks like VeriEquivBench to drive progress toward scalable and reliable coding agents.",
        "subjects": "Programming Languages, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.574763"
    },
    {
        "index": "#153",
        "title": "ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations",
        "link": "/arxiv/2510.06292",
        "arxiv_id": "2510.06292",
        "authors": "Yike Wu, Yiwei Wang, Yujun Cai",
        "summary": "While Large Vision-Language Models (LVLMs) achieve strong performance in multimodal tasks, hallucinations continue to hinder their reliability. Among the three categories of hallucinations, which include object, attribute, and relation, relation hallucinations account for the largest proportion but have received the least attention. To address this issue, we propose ChainMPQ (Multi-Perspective Questions guided Interleaved Chain of Image and Text), a training-free method that improves relational inference in LVLMs by utilizing accumulated textual and visual memories. ChainMPQ first extracts subject and object keywords from the question to enhance the corresponding image regions. It then constructs multi-perspective questions that focus on the three core components of a relationship: the subject, the object, and the relation that links them. These questions are sequentially input to the model, with textual and visual memories from earlier steps providing supporting context for subsequent ones, thereby forming an interleaved chain of images and text that guides progressive relational reasoning. Experiments on multiple LVLMs and benchmarks show that ChainMPQ substantially reduces relation hallucinations, while ablation studies further validate the effectiveness of its three core modules.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.575691"
    },
    {
        "index": "#156",
        "title": "SER-Diff: Synthetic Error Replay Diffusion for Incremental Brain Tumor Segmentation",
        "link": "/arxiv/2510.06283",
        "arxiv_id": "2510.06283",
        "authors": "Sashank Makanaboyina",
        "summary": "Incremental brain tumor segmentation is critical for models that must adapt to evolving clinical datasets without retraining on all prior data. However, catastrophic forgetting, where models lose previously acquired knowledge, remains a major obstacle. Recent incremental learning frameworks with knowledge distillation partially mitigate forgetting but rely heavily on generative replay or auxiliary storage. Meanwhile, diffusion models have proven effective for refining tumor segmentations, but have not been explored in incremental learning contexts. We propose Synthetic Error Replay Diffusion (SER-Diff), the first framework that unifies diffusion-based refinement with incremental learning. SER-Diff leverages a frozen teacher diffusion model to generate synthetic error maps from past tasks, which are replayed during training on new tasks. A dual-loss formulation combining Dice loss for new data and knowledge distillation loss for replayed errors ensures both adaptability and retention. Experiments on BraTS2020, BraTS2021, and BraTS2023 demonstrate that SER-Diff consistently outperforms prior methods. It achieves the highest Dice scores of 95.8\\%, 94.9\\%, and 94.6\\%, along with the lowest HD95 values of 4.4 mm, 4.7 mm, and 4.9 mm, respectively. These results indicate that SER-Diff not only mitigates catastrophic forgetting but also delivers more accurate and anatomically coherent segmentations across evolving datasets.",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-06",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.576599"
    },
    {
        "index": "#157",
        "title": "Improving the Spatial Resolution of GONG Solar Images to GST Quality Using Deep Learning",
        "link": "/arxiv/2510.06281",
        "arxiv_id": "2510.06281",
        "authors": "Chenyang Li, Qin Li, Haimin Wang, Bo Shen",
        "summary": "High-resolution (HR) solar imaging is crucial for capturing fine-scale dynamic features such as filaments and fibrils. However, the spatial resolution of the full-disk H$\\alpha$ images is limited and insufficient to resolve these small-scale structures. To address this, we propose a GAN-based superresolution approach to enhance low-resolution (LR) full-disk H$\\alpha$ images from the Global Oscillation Network Group (GONG) to a quality comparable with HR observations from the Big Bear Solar Observatory/Goode Solar Telescope (BBSO/GST). We employ Real-ESRGAN with Residual-in-Residual Dense Blocks and a relativistic discriminator. We carefully aligned GONG-GST pairs. The model effectively recovers fine details within sunspot penumbrae and resolves fine details in filaments and fibrils, achieving an average mean squared error (MSE) of 467.15, root mean squared error (RMSE) of 21.59, and cross-correlation (CC) of 0.7794. Slight misalignments between image pairs limit quantitative performance, which we plan to address in future work alongside dataset expansion to further improve reconstruction quality.",
        "subjects": "Computer Vision and Pattern Recognition, Artificial Intelligence",
        "date": "2025-10-06",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.576893"
    },
    {
        "index": "#158",
        "title": "Surgeons Are Indian Males and Speech Therapists Are White Females: Auditing Biases in Vision-Language Models for Healthcare Professionals",
        "link": "/arxiv/2510.06280",
        "arxiv_id": "2510.06280",
        "authors": "Zohaib Hasan Siddiqui, Dayam Nadeem, Mohammad Masudur Rahman, Mohammad Nadeem, Shahab Saquib Sohail, Beenish Moalla Chaudhry",
        "summary": "Vision language models (VLMs), such as CLIP and OpenCLIP, can encode and reflect stereotypical associations between medical professions and demographic attributes learned from web-scale data. We present an evaluation protocol for healthcare settings that quantifies associated biases and assesses their operational risk. Our methodology (i) defines a taxonomy spanning clinicians and allied healthcare roles (e.g., surgeon, cardiologist, dentist, nurse, pharmacist, technician), (ii) curates a profession-aware prompt suite to probe model behavior, and (iii) benchmarks demographic skew against a balanced face corpus. Empirically, we observe consistent demographic biases across multiple roles and vision models. Our work highlights the importance of bias identification in critical domains such as healthcare as AI-enabled hiring and workforce analytics can have downstream implications for equity, compliance, and patient trust.",
        "subjects": "Computers and Society, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-06",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.577212"
    },
    {
        "index": "#160",
        "title": "A Total Variation Regularized Framework for Epilepsy-Related MRI Image Segmentation",
        "link": "/arxiv/2510.06276",
        "arxiv_id": "2510.06276",
        "authors": "Mehdi Rabiee, Sergio Greco, Reza Shahbazian, Irina Trubitsyna",
        "summary": "Focal Cortical Dysplasia (FCD) is a primary cause of drug-resistant epilepsy and is difficult to detect in brain {magnetic resonance imaging} (MRI) due to the subtle and small-scale nature of its lesions. Accurate segmentation of FCD regions in 3D multimodal brain MRI images is essential for effective surgical planning and treatment. However, this task remains highly challenging due to the limited availability of annotated FCD datasets, the extremely small size and weak contrast of FCD lesions, the complexity of handling 3D multimodal inputs, and the need for output smoothness and anatomical consistency, which is often not addressed by standard voxel-wise loss functions. This paper presents a new framework for segmenting FCD regions in 3D brain MRI images. We adopt state-of-the-art transformer-enhanced encoder-decoder architecture and introduce a novel loss function combining Dice loss with an anisotropic {Total Variation} (TV) term. This integration encourages spatial smoothness and reduces false positive clusters without relying on post-processing. The framework is evaluated on a public FCD dataset with 85 epilepsy patients and demonstrates superior segmentation accuracy and consistency compared to standard loss formulations. The model with the proposed TV loss shows an 11.9\\% improvement on the Dice coefficient and 13.3\\% higher precision over the baseline model. Moreover, the number of false positive clusters is reduced by 61.6%",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition",
        "date": "2025-10-06",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.577796"
    },
    {
        "index": "#168",
        "title": "LLM-Driven Rubric-Based Assessment of Algebraic Competence in Multi-Stage Block Coding Tasks with Design and Field Evaluation",
        "link": "/arxiv/2510.06253",
        "arxiv_id": "2510.06253",
        "authors": "Yong Oh Lee, Byeonghun Bang, Sejun Oh",
        "summary": "As online education platforms continue to expand, there is a growing need for assessment methods that not only measure answer accuracy but also capture the depth of students' cognitive processes in alignment with curriculum objectives. This study proposes and evaluates a rubric-based assessment framework powered by a large language model (LLM) for measuring algebraic competence, real-world-context block coding tasks. The problem set, designed by mathematics education experts, aligns each problem segment with five predefined rubric dimensions, enabling the LLM to assess both correctness and quality of students' problem-solving processes. The system was implemented on an online platform that records all intermediate responses and employs the LLM for rubric-aligned achievement evaluation. To examine the practical effectiveness of the proposed framework, we conducted a field study involving 42 middle school students engaged in multi-stage quadratic equation tasks with block coding. The study integrated learner self-assessments and expert ratings to benchmark the system's outputs. The LLM-based rubric evaluation showed strong agreement with expert judgments and consistently produced rubric-aligned, process-oriented feedback. These results demonstrate both the validity and scalability of incorporating LLM-driven rubric assessment into online mathematics and STEM education platforms.",
        "subjects": "Computers and Society, Artificial Intelligence",
        "date": "2025-10-04",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.580228"
    },
    {
        "index": "#172",
        "title": "DynBenchmark: Customizable Ground Truths to Benchmark Community Detection and Tracking in Temporal Networks",
        "link": "/arxiv/2510.06245",
        "arxiv_id": "2510.06245",
        "authors": "Laurent Brisson, Cécile Bothorel, Nicolas Duminy",
        "summary": "Graph models help understand network dynamics and evolution. Creating graphs with controlled topology and embedded partitions is a common strategy for evaluating community detection algorithms. However, existing benchmarks often overlook the need to track the evolution of communities in real-world networks. To address this, a new community-centered model is proposed to generate customizable evolving community structures where communities can grow, shrink, merge, split, appear or disappear. This benchmark also generates the underlying temporal network, where nodes can appear, disappear, or move between communities. The benchmark has been used to test three methods, measuring their performance in tracking nodes' cluster membership and detecting community evolution. Python libraries, drawing utilities, and validation metrics are provided to compare ground truth with algorithm results for detecting dynamic communities.",
        "subjects": "Social and Information Networks, Artificial Intelligence",
        "date": "2025-10-03",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.581424"
    },
    {
        "index": "#178",
        "title": "Stacked Regression using Off-the-shelf, Stimulus-tuned and Fine-tuned Neural Networks for Predicting fMRI Brain Responses to Movies (Algonauts 2025 Report)",
        "link": "/arxiv/2510.06235",
        "arxiv_id": "2510.06235",
        "authors": "Robert Scholz, Kunal Bagga, Christine Ahrends, Carlo Alberto Barbano",
        "summary": "We present our submission to the Algonauts 2025 Challenge, where the goal is to predict fMRI brain responses to movie stimuli. Our approach integrates multimodal representations from large language models, video encoders, audio models, and vision-language models, combining both off-the-shelf and fine-tuned variants. To improve performance, we enhanced textual inputs with detailed transcripts and summaries, and we explored stimulus-tuning and fine-tuning strategies for language and vision models. Predictions from individual models were combined using stacked regression, yielding solid results. Our submission, under the team name Seinfeld, ranked 10th. We make all code and resources publicly available, contributing to ongoing efforts in developing multimodal encoding models for brain activity.",
        "subjects": "Image and Video Processing, Artificial Intelligence, Computer Vision and Pattern Recognition, Neurons and Cognition",
        "date": "2025-10-02",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.583281"
    },
    {
        "index": "#179",
        "title": "Generalized Multi-agent Social Simulation Framework",
        "link": "/arxiv/2510.06225",
        "arxiv_id": "2510.06225",
        "authors": "Gang Li, Jie Lin, Yining Tang, Ziteng Wang, Yirui Huang, Junyu Zhang, Shuang Luo, Chao Wu, Yike Guo",
        "summary": "Multi-agent social interaction has clearly benefited from Large Language Models. However, current simulation systems still face challenges such as difficulties in scaling to diverse scenarios and poor reusability due to a lack of modular design. To address these issues, we designed and developed a modular, object-oriented framework that organically integrates various base classes through a hierarchical structure, harvesting scalability and reusability. We inherited the framework to realize common derived classes. Additionally, a memory summarization mechanism is proposed to filter and distill relevant information from raw memory data, prioritizing contextually salient events and interactions. By selecting and combining some necessary derived classes, we customized a specific simulated environment. Utilizing this simulated environment, we successfully simulated human interactions on social media, replicating real-world online social behaviors. The source code for the project will be released and evolve.",
        "subjects": "Physics and Society, Artificial Intelligence",
        "date": "2025-09-26",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.583613"
    },
    {
        "index": "#180",
        "title": "Exploring Human-AI Collaboration Using Mental Models of Early Adopters of Multi-Agent Generative AI Tools",
        "link": "/arxiv/2510.06224",
        "arxiv_id": "2510.06224",
        "authors": "Suchismita Naik, Austin L. Toombs, Amanda Snellinger, Scott Saponas, Amanda K. Hall",
        "summary": "With recent advancements in multi-agent generative AI (Gen AI), technology organizations like Microsoft are adopting these complex tools, redefining AI agents as active collaborators in complex workflows rather than as passive tools. In this study, we investigated how early adopters and developers conceptualize multi-agent Gen AI tools, focusing on how they understand human-AI collaboration mechanisms, general collaboration dynamics, and transparency in the context of AI tools. We conducted semi-structured interviews with 13 developers, all early adopters of multi-agent Gen AI technology who work at Microsoft. Our findings revealed that these early adopters conceptualize multi-agent systems as \"teams\" of specialized role-based and task-based agents, such as assistants or reviewers, structured similar to human collaboration models and ranging from AI-dominant to AI-assisted, user-controlled interactions. We identified key challenges, including error propagation, unpredictable and unproductive agent loop behavior, and the need for clear communication to mitigate the layered transparency issues. Early adopters' perspectives about the role of transparency underscored its importance as a way to build trust, verify and trace errors, and prevent misuse, errors, and leaks. The insights and design considerations we present contribute to CSCW research about collaborative mechanisms with capabilities ranging from AI-dominant to AI-assisted interactions, transparency and oversight strategies in human-agent and agent-agent interactions, and how humans make sense of these multi-agent systems as dynamic, role-diverse collaborators which are customizable for diverse needs and workflows. We conclude with future research directions that extend CSCW approaches to the design of inter-agent and human mediation interactions.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence, Computers and Society",
        "date": "2025-09-10",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.583939"
    },
    {
        "index": "#181",
        "title": "A Multimodal GUI Architecture for Interfacing with LLM-Based Conversational Assistants",
        "link": "/arxiv/2510.06223",
        "arxiv_id": "2510.06223",
        "authors": "Hans G. W. van Dam",
        "summary": "Advances in large language models (LLMs) and real-time speech recognition now make it possible to issue any graphical user interface (GUI) action through natural language and receive the corresponding system response directly through the GUI. Most production applications were never designed with speech in mind. This article provides a concrete architecture that enables GUIs to interface with LLM-based speech-enabled assistants. The architecture makes an application's navigation graph and semantics available through the Model Context Protocol (MCP). The ViewModel, part of the MVVM (Model-View-ViewModel) pattern, exposes the application's capabilities to the assistant by supplying both tools applicable to a currently visible view and application-global tools extracted from the GUI tree router. This architecture facilitates full voice accessibility while ensuring reliable alignment between spoken input and the visual interface, accompanied by consistent feedback across modalities. It future-proofs apps for upcoming OS super assistants that employ computer use agents (CUAs) and natively consume MCP if an application provides it. To address concerns about privacy and data security, the practical effectiveness of locally deployable, open-weight LLMs for speech-enabled multimodal UIs is evaluated. Findings suggest that recent smaller open-weight models approach the performance of leading proprietary models in overall accuracy and require enterprise-grade hardware for fast responsiveness.",
        "subjects": "Human-Computer Interaction, Artificial Intelligence",
        "date": "2025-08-31",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.584200"
    },
    {
        "index": "#182",
        "title": "WeatherArchive-Bench: Benchmarking Retrieval-Augmented Reasoning for Historical Weather Archives",
        "link": "/arxiv/2510.05336",
        "arxiv_id": "2510.05336",
        "authors": "Yongan Yu, Xianda Du, Qingchen Hu, Jiahao Liang, Jingwei Ni, Dan Qiang, Kaiyu Huang, Grant McKenzie, Renee Sieber, Fengran Mo",
        "summary": "Historical archives on weather events are collections of enduring primary source records that offer rich, untapped narratives of how societies have experienced and responded to extreme weather events. These qualitative accounts provide insights into societal vulnerability and resilience that are largely absent from meteorological records, making them valuable for climate scientists to understand societal responses. However, their vast scale, noisy digitized quality, and archaic language make it difficult to transform them into structured knowledge for climate research. To address this challenge, we introduce WeatherArchive-Bench, the first benchmark for evaluating retrieval-augmented generation (RAG) systems on historical weather archives. WeatherArchive-Bench comprises two tasks: WeatherArchive-Retrieval, which measures a system's ability to locate historically relevant passages from over one million archival news segments, and WeatherArchive-Assessment, which evaluates whether Large Language Models (LLMs) can classify societal vulnerability and resilience indicators from extreme weather narratives. Extensive experiments across sparse, dense, and re-ranking retrievers, as well as a diverse set of LLMs, reveal that dense retrievers often fail on historical terminology, while LLMs frequently misinterpret vulnerability and resilience concepts. These findings highlight key limitations in reasoning about complex societal indicators and provide insights for designing more robust climate-focused RAG systems from archival contexts. The constructed dataset and evaluation framework are publicly available at https://anonymous.4open.science/r/WeatherArchive-Bench/.",
        "subjects": "Computation and Language",
        "date": "2025-10-06",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.584536"
    },
    {
        "index": "#183",
        "title": "AgentBuilder: Exploring Scaffolds for Prototyping User Experiences of Interface Agents",
        "link": "/arxiv/2510.04452",
        "arxiv_id": "2510.04452",
        "authors": "Jenny T. Liang, Titus Barik, Jeffrey Nichols, Eldon Schoop, Ruijia Cheng",
        "summary": "Interface agents powered by generative AI models (referred to as \"agents\") can automate actions based on user commands. An important aspect of developing agents is their user experience (i.e., agent experience). There is a growing need to provide scaffolds for a broader set of individuals beyond AI engineers to prototype agent experiences, since they can contribute valuable perspectives to designing agent experiences. In this work, we explore the affordances agent prototyping systems should offer by conducting a requirements elicitation study with 12 participants with varying experience with agents. We identify key activities in agent experience prototyping and the desired capabilities of agent prototyping systems. We instantiate those capabilities in the AgentBuilder design probe for agent prototyping. We conduct an in situ agent prototyping study with 14 participants using AgentBuilder to validate the design requirements and elicit insights on how developers prototype agents and what their needs are in this process.",
        "subjects": "Human-Computer Interaction",
        "date": "2025-10-06",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.584824"
    },
    {
        "index": "#184",
        "title": "TiltXter: CNN-based Electro-tactile Rendering of Tilt Angle for Telemanipulation of Pasteur Pipettes",
        "link": "/arxiv/2409.15838",
        "arxiv_id": "2409.15838",
        "authors": "Miguel Altamirano Cabrera, Jonathan Tirado, Aleksey Fedoseev, Oleg Sautenkov, Vladimir Poliakov, Pavel Kopanev, Dzmitry Tsetserukou",
        "summary": "The shape of deformable objects can change drastically during grasping by robotic grippers, causing an ambiguous perception of their alignment and hence resulting in errors in robot positioning and telemanipulation. Rendering clear tactile patterns is fundamental to increasing users' precision and dexterity through tactile haptic feedback during telemanipulation. Therefore, different methods have to be studied to decode the sensors' data into haptic stimuli. This work presents a telemanipulation system for plastic pipettes that consists of a Force Dimension Omega.7 haptic interface endowed with two electro-stimulation arrays and two tactile sensor arrays embedded in the 2-finger Robotiq gripper. We propose a novel approach based on convolutional neural networks (CNN) to detect the tilt of deformable objects. The CNN generates a tactile pattern based on recognized tilt data to render further electro-tactile stimuli provided to the user during the telemanipulation. The study has shown that using the CNN algorithm, tilt recognition by users increased from 23.13\\% with the downsized data to 57.9%, and the success rate during teleoperation increased from 53.12% using the downsized data to 92.18% using the tactile patterns generated by the CNN.",
        "subjects": "Robotics",
        "date": "2024-09-24",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.585128"
    },
    {
        "index": "#185",
        "title": "DeepXPalm: Tilt and Position Rendering using Palm-worn Haptic Display and CNN-based Tactile Pattern Recognition",
        "link": "/arxiv/2204.03521",
        "arxiv_id": "2204.03521",
        "authors": "Altamirano Cabrera Miguel, Sautenkov Oleg, Tirado Jonathan, Fedoseev Aleksey, Kopanev Pavel, Kajimoto Hiroyuki, Tsetserukou Dzmitry",
        "summary": "Telemanipulation of deformable objects requires high precision and dexterity from the users, which can be increased by kinesthetic and tactile feedback. However, the object shape can change dynamically, causing ambiguous perception of its alignment and hence errors in the robot positioning. Therefore, the tilt angle and position classification problem has to be solved to present a clear tactile pattern to the user. This work presents a telemanipulation system for plastic pipettes consisting of a multi-contact haptic device LinkGlide to deliver haptic feedback at the users' palm and two tactile sensors array embedded in the 2-finger Robotiq gripper. We propose a novel approach based on Convolutional Neural Networks (CNN) to detect the tilt and position while grasping deformable objects. The CNN generates a mask based on recognized tilt and position data to render further multi-contact tactile stimuli provided to the user during the telemanipulation. The study has shown that using the CNN algorithm and the preset mask, tilt, and position recognition by users is increased from 9.67% using the direct data to 82.5%.",
        "subjects": "Robotics",
        "date": "2022-04-07",
        "category": "cs.AI",
        "crawl_time": "2025-10-09T19:59:14.585431"
    }
]