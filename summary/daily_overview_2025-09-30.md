### 今日AI论文速览 (2025-09-30)

今日AI研究呈现出多方向并进的繁荣景象，其中多智能体系统的自进化架构、推理模型的训练优化、新型记忆机制设计以及对齐方法的创新成为最突出的研究方向。这些研究不仅探索了模型能力边界的拓展，还关注了效率提升和认知机制模拟，展现了从架构创新到训练策略的全方位突破。

## 一、多智能体系统的自进化与交互

多智能体系统正朝着更加自主、自适应和可交互的方向发展，研究者们探索了如何让智能体系统实现自我生成、自我配置和自我修正。

* **MAS²**提出了一种基于递归自生成的多智能体系统范式，通过"**生成器-实现器-修正器**"三智能体团队动态组合和自适应修正目标智能体系统。在七个基准测试中，MAS²比最先进的多智能体系统性能提升高达**19.6%**，并展现出卓越的跨主干泛化能力。(2509.24323 [cs.MA])

* **AIPOM**引入了一种支持人机在环规划的系统，通过对话和基于图形的界面使用户能够透明地检查、完善和协同指导LLM生成的计划。AIPOM显著增强了用户对多智能体工作流程的控制和信任，解决了现有LLM方法缺乏有效机制让用户检查、理解和控制其行为的问题。(2509.24826 [cs.MA])

* **Diagnose, Localize, Align**提出了一个三层框架来解决多智能体系统在指令冲突下的层次合规性问题：诊断（**CRAS评分指标**）、定位（注意力漂移分析）和对齐（**SAIL方法**）。该方法在标准基准和多智能体框架上提高了指令层次合规性，无需全模型微调。(2509.23188 [cs.CL])

## 二、推理模型的训练与优化

推理能力作为大语言模型的核心竞争力，今日研究在训练方法、计算效率和推理架构上均有重要突破，特别是在小模型推理能力提升方面成果显著。

* **MobileLLM-R1**挑战了推理能力需要在大规模数据集上训练的假设，证明仅需约**2T token**的高质量数据就足以开发出强大的推理模型。MobileLLM-R1-950M在AIME上得分15.5，远超OLMo-2-1.48B的0.6分和SmolLM-2-1.7B的0.3分，尽管训练token数量仅为Qwen3的11.7%。(2509.24945 [cs.CL])

* **SIRI**提出了一种简单而有效的RL方法，通过在训练期间动态调整最大滚动长度来迭代交替**压缩和扩展推理预算**。在DeepSeek-R1-Distill-Qwen-1.5B上训练后，SIRI-low在AIME24上性能提升43.2%，同时token使用减少46.9%。(2509.25176 [cs.CL])

* **MARCOS**重新构想LLM中的推理，将其建模为连续高维"思想"的**隐马尔可夫链**，而不是自回归生成token序列。在三个基准测试中，MARCOS优于现有的连续推理方法，首次实现了与基于token的CoT相当的性能，在GSM8K上甚至超过4.7%，推理速度提高15.7倍。(2509.25020 [cs.LG])

* **CLPO**提出了一种动态教学反馈循环算法，利用模型自身的滚动性能进行实时难度评估，构建**在线课程**。CLPO在八个具有挑战性的数学和一般推理基准上实现了最先进的性能，平均pass@1比其他方法提高6.96%。(2509.25004 [cs.AI])

## 三、记忆架构与认知机制

如何让AI智能体拥有更接近人类的记忆和认知能力是今日研究的热点，多种新型记忆架构被提出，旨在实现更自然的信息处理和自我进化能力。

* **MemGen**提出了一种动态生成记忆框架，配备类人认知能力，包括**记忆触发器**和**记忆编织器**，使智能体能够回忆和增强潜在记忆。在八个基准测试中，MemGen超过了领先的外部记忆系统如ExpeL和AWM高达38.22%，超过了GRPO高达13.44%，并展现出强大的跨领域泛化能力。(2509.24704 [cs.CL])

* **ReasoningBank**提出了一种记忆框架，从智能体自判断的成功和失败经验中提炼可泛化的**推理策略**。在网页浏览和软件工程基准测试中，ReasoningBank始终优于存储原始轨迹或仅成功任务例程的现有记忆机制。(2509.25140 [cs.CL])

* **Identity Bridge**通过监督模型执行零跳身份任务解决了组合性差距，使模型能够成功执行分布外两跳推理。理论分析表明，身份监督通过优化过程中隐含的**核范数正则化**重塑了模型的潜在几何，诱导有利于低秩解决方案的潜在空间对齐。(2509.24653 [cs.LG])

## 四、对齐与偏好学习的新方法

模型对齐技术持续创新，研究者们探索了更高效、更鲁棒的偏好学习方法，以解决传统对齐方法中的分布不匹配和噪声敏感问题。

* **UniAPL**重新将对齐定义为约束优化问题，提出**统一对抗偏好学习**框架，动态地将策略的分布与专家的分布对齐。在Qwen3-0.6B上比强GRPO基线提高5.77%，在Qwen3-4B上提高3.75%，甚至在某些任务上超越了教师模型。(2509.25148 [cs.AI])

* **Robust Preference Optimization**提出了一种鲁棒偏好优化方法，使用**期望最大化算法**推断每个标签正确性的后验概率，自适应地重新权衡训练损失中的每个数据点。实验证明RPO作为元框架的一致有效性，持续增强了四种最先进对齐算法（DPO、IPO、SimPO和CPO）。(2509.24159 [cs.AI])

* **Why Alignment Must Precede Distillation**论证了标准KD->Align工作流程削弱了模型对齐罕见但理想行为的能力，即使在强偏好信号下也是如此。理论和实验证明，反转流水线（即**Align->KD**）是必不可少的：对齐必须首先在高召回参考模型上执行，然后再进行蒸馏。(2509.23667 [cs.LG])

## 五、工具增强智能体与信息检索

工具使用能力作为智能体的核心竞争力，今日研究在工具集成推理、信息检索和深度研究方面取得了显著进展，特别是在提升小模型工具使用效率方面。

* **InfoAgent**引入了一种由创新数据合成管道和编排的网络搜索工具驱动的**深度研究智能体**。InfoAgent在BrowseComp上达到15.3%准确率，在BrowseComp-ZH上达到29.2%，在Xbench-DS上达到40.4%，优于先前的开源深度研究智能体。(2509.25189 [cs.CL])

* **Fathom-DeepResearch**引入了一个由两个专门模型组成的智能体系统：**Fathom-Search-4B**（通过实时网络搜索和针对性网页查询进行基于证据的调查）和**Fathom-Synthesizer-4B**（将多轮DeepSearch轨迹转换为结构化的引用密集型DeepResearch报告）。该系统在DeepSearch基准测试和DeepResearch-Bench上实现了开放权重类别中最先进的性能。(2509.24107 [cs.LG])

* **Learning to Use Tools, Not Just When**识别了工具集成推理中的两种常见模式：**计算器模式**（使用代码进行直接计算）和**算法模式**（将问题编码为程序）。在具有挑战性的数学数据集上，这种模式感知方法显著提高了代码使用率和准确性，例如将MATH500上的Code@1从64.0%提高到70.5%。(2509.23292 [cs.CL])

## 六、模型架构与训练创新

基础模型架构和训练方法持续创新，研究者们探索了替代传统自回归生成的新方法，以及更高效的模型训练和优化技术。

* **Alternatives To Next Token Prediction In Text Generation - A Survey**调查了替代下一个token预测(NTP)的新兴生态系统，将方法分为五个主要家族：**多Token预测**、**计划后生成**、**潜在推理**、**连续生成方法**和**非Transformer架构**。该调查为开发解决token级生成已知局限性、为自然语言处理开发新变革性模型的模型提供了分类法。(2509.24435 [cs.CL])

* **LLaDA-MoE**引入了一种具有**混合专家(MoE)架构**的大语言扩散模型，从零开始在约20T token上训练。LLaDA-MoE在推理时仅激活1.4B参数，实现了显著减少的计算开销下的竞争性能，在多个基准测试上超越了之前的扩散语言模型。(2509.24389 [cs.CL])

* **Evolution Strategies at Scale**报告了首次成功将**进化策略(ES)**扩展用于微调LLM的全部参数，证明ES可以在数十亿参数上有效搜索，并在多个方面优于现有的RL微调方法。ES在样本效率、对长时程奖励的容忍度、对不同基础LLM的鲁棒性、对奖励黑客的抵抗能力以及运行间性能稳定性方面表现出优势。(2509.24372 [cs.LG])

### 今日看点

1. **小模型推理能力的重大突破**：MobileLLM-R1和SIRI等研究证明，通过精心设计的高质量数据和创新的训练策略，亚十亿参数的小模型也能实现强大的推理能力，挑战了"推理能力仅在大模型中涌现"的传统认知，为资源受限场景下的AI应用开辟了新路径。

2. **多智能体系统的自进化趋势**：MAS²和MemGen等研究展示了多智能体系统从静态配置向动态自演进的转变，这些系统能够根据任务需求自主生成、配置和修正自身架构，展现出接近组织的自适应能力，为构建更复杂、更灵活的AI系统提供了新范式。

3. **推理架构的多元化探索**：从MARCOS的连续思想链到SIRI的压缩-扩展交替训练，研究者们正在突破传统自回归token生成的限制，探索更高效、更接近人类认知过程的推理架构，这些创新不仅提高了推理效率，还为理解AI推理机制提供了新视角。

4. **对齐技术的效率与鲁棒性并重**：UniAPL和Robust Preference Optimization等研究在对齐方法上实现了重要突破，既解决了传统方法中的分布不匹配问题，又提高了对噪声数据的鲁棒性，同时降低了对大规模人工标注的依赖，为构建更可靠、更高效的AI对齐系统提供了新思路。