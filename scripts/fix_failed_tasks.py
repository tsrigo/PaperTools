#!/usr/bin/env python3
"""
ä¿®å¤å¤±è´¥ä»»åŠ¡çš„è„šæœ¬
Fix failed tasks script

æ£€æµ‹å¹¶é‡æ–°å¤„ç†é‚£äº›çµæ„Ÿæº¯æºã€ç¿»è¯‘æˆ–æ€»ç»“å¤±è´¥çš„è®ºæ–‡
"""

import json
import os
import sys
import argparse
from pathlib import Path
from typing import List, Dict
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.abspath(os.path.dirname(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.core.generate_summary import (
    generate_summary,
    generate_inspiration_trace,
    translate_summary,
    fetch_paper_content_from_jinja
)
from src.utils.config import API_KEY, BASE_URL, MODEL, TEMPERATURE
from src.utils.cache_manager import CacheManager
from openai import OpenAI


def detect_failed_tasks(summary_file: str) -> Dict:
    """
    æ£€æµ‹å¤±è´¥çš„ä»»åŠ¡

    Args:
        summary_file: summary JSON æ–‡ä»¶è·¯å¾„

    Returns:
        åŒ…å«å¤±è´¥ä»»åŠ¡ä¿¡æ¯çš„å­—å…¸
    """
    with open(summary_file, 'r', encoding='utf-8') as f:
        papers = json.load(f)

    failed_tasks = {
        'inspiration_trace': [],  # çµæ„Ÿæº¯æºå¤±è´¥
        'translation': [],        # ç¿»è¯‘å¤±è´¥
        'summary': [],           # æ€»ç»“å¤±è´¥
        'all_failed': []         # å…¨éƒ¨å¤±è´¥
    }

    for paper in papers:
        arxiv_id = paper.get('arxiv_id', 'unknown')
        title = paper.get('title', 'Unknown')

        # æ£€æŸ¥çµæ„Ÿæº¯æºï¼ˆé¡¶å±‚å­—æ®µï¼‰
        inspiration_trace = paper.get('inspiration_trace', '')
        if not inspiration_trace or 'å¤±è´¥' in inspiration_trace or 'é”™è¯¯' in inspiration_trace:
            failed_tasks['inspiration_trace'].append({
                'arxiv_id': arxiv_id,
                'title': title,
                'link': paper.get('link', '')
            })

        # æ£€æŸ¥ç¿»è¯‘ï¼ˆé¡¶å±‚å­—æ®µï¼‰
        summary_translation = paper.get('summary_translation', '')
        if not summary_translation or 'å¤±è´¥' in summary_translation:
            failed_tasks['translation'].append({
                'arxiv_id': arxiv_id,
                'title': title,
                'link': paper.get('link', '')
            })

        # æ£€æŸ¥æ€»ç»“ï¼ˆsummary2 å­—æ®µï¼‰
        summary2 = paper.get('summary2', '')
        if not summary2 or 'å¤±è´¥' in summary2:
            failed_tasks['summary'].append({
                'arxiv_id': arxiv_id,
                'title': title,
                'link': paper.get('link', '')
            })

        # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨å¤±è´¥
        if (not inspiration_trace or 'å¤±è´¥' in inspiration_trace or 'é”™è¯¯' in inspiration_trace) and \
           (not summary_translation or 'å¤±è´¥' in summary_translation) and \
           (not summary2 or 'å¤±è´¥' in summary2):
            failed_tasks['all_failed'].append({
                'arxiv_id': arxiv_id,
                'title': title,
                'link': paper.get('link', '')
            })

    return failed_tasks


def fix_failed_tasks(summary_file: str, task_type: str = 'all', dry_run: bool = False):
    """
    ä¿®å¤å¤±è´¥çš„ä»»åŠ¡

    Args:
        summary_file: summary JSON æ–‡ä»¶è·¯å¾„
        task_type: ä»»åŠ¡ç±»å‹ (all, inspiration, translation, summary)
        dry_run: æ˜¯å¦åªæ£€æµ‹ä¸ä¿®å¤
    """
    print(f"ğŸ“‚ è¯»å–æ–‡ä»¶: {summary_file}")

    # æ£€æµ‹å¤±è´¥ä»»åŠ¡
    failed_tasks = detect_failed_tasks(summary_file)

    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š å¤±è´¥ä»»åŠ¡ç»Ÿè®¡:")
    print(f"  - çµæ„Ÿæº¯æºå¤±è´¥: {len(failed_tasks['inspiration_trace'])} ç¯‡")
    print(f"  - ç¿»è¯‘å¤±è´¥: {len(failed_tasks['translation'])} ç¯‡")
    print(f"  - æ€»ç»“å¤±è´¥: {len(failed_tasks['summary'])} ç¯‡")
    print(f"  - å…¨éƒ¨å¤±è´¥: {len(failed_tasks['all_failed'])} ç¯‡")

    if dry_run:
        print("\nğŸ” Dry run æ¨¡å¼ï¼Œä»…æ£€æµ‹ä¸ä¿®å¤")
        return

    # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯å’Œç¼“å­˜ç®¡ç†å™¨
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    cache_manager = CacheManager()

    # è¯»å–å®Œæ•´çš„è®ºæ–‡æ•°æ®
    with open(summary_file, 'r', encoding='utf-8') as f:
        papers = json.load(f)

    # æ ¹æ®ä»»åŠ¡ç±»å‹ä¿®å¤
    print(f"\nğŸ”§ å¼€å§‹ä¿®å¤ä»»åŠ¡ (ç±»å‹: {task_type})...")

    fixed_count = 0
    failed_count = 0

    for paper in tqdm(papers, desc="å¤„ç†è®ºæ–‡"):
        arxiv_id = paper.get('arxiv_id', 'unknown')
        title = paper.get('title', 'Unknown')
        link = paper.get('link', '')

        needs_update = False

        # ä¿®å¤çµæ„Ÿæº¯æº
        if task_type in ['all', 'inspiration']:
            inspiration_trace = paper.get('inspiration_trace', '')
            if not inspiration_trace or 'å¤±è´¥' in inspiration_trace or 'é”™è¯¯' in inspiration_trace:
                try:
                    # è·å–è®ºæ–‡å†…å®¹
                    paper_content = fetch_paper_content_from_jinja(link, cache_manager)
                    if paper_content:
                        # ç”Ÿæˆçµæ„Ÿæº¯æº
                        new_inspiration = generate_inspiration_trace(
                            paper_content, client, MODEL, TEMPERATURE, title, cache_manager
                        )
                        paper['inspiration_trace'] = new_inspiration
                        needs_update = True
                        print(f"\nâœ… ä¿®å¤çµæ„Ÿæº¯æº: {title[:50]}...")
                except Exception as e:
                    print(f"\nâŒ ä¿®å¤çµæ„Ÿæº¯æºå¤±è´¥ {title[:30]}: {e}")
                    failed_count += 1

        # ä¿®å¤ç¿»è¯‘
        if task_type in ['all', 'translation']:
            summary_translation = paper.get('summary_translation', '')
            summary2 = paper.get('summary2', '')
            if summary2 and (not summary_translation or 'å¤±è´¥' in summary_translation):
                try:
                    # ç¿»è¯‘æ‘˜è¦
                    new_translation = translate_summary(
                        summary2, client, MODEL, TEMPERATURE, title, cache_manager
                    )
                    paper['summary_translation'] = new_translation
                    needs_update = True
                    print(f"\nâœ… ä¿®å¤ç¿»è¯‘: {title[:50]}...")
                except Exception as e:
                    print(f"\nâŒ ä¿®å¤ç¿»è¯‘å¤±è´¥ {title[:30]}: {e}")
                    failed_count += 1

        # ä¿®å¤æ€»ç»“
        if task_type in ['all', 'summary']:
            summary2 = paper.get('summary2', '')
            if not summary2 or 'å¤±è´¥' in summary2:
                try:
                    # è·å–è®ºæ–‡å†…å®¹
                    paper_content = fetch_paper_content_from_jinja(link, cache_manager)
                    if paper_content:
                        # ç”Ÿæˆæ€»ç»“
                        new_summary = generate_summary(
                            paper_content, client, MODEL, TEMPERATURE, title, cache_manager
                        )
                        paper['summary2'] = new_summary
                        needs_update = True
                        print(f"\nâœ… ä¿®å¤æ€»ç»“: {title[:50]}...")
                except Exception as e:
                    print(f"\nâŒ ä¿®å¤æ€»ç»“å¤±è´¥ {title[:30]}: {e}")
                    failed_count += 1

        if needs_update:
            fixed_count += 1

    # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
    if fixed_count > 0:
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(papers, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ å·²ä¿å­˜æ›´æ–°: {summary_file}")

    print(f"\nğŸ“Š ä¿®å¤å®Œæˆ!")
    print(f"  - æˆåŠŸä¿®å¤: {fixed_count} ç¯‡")
    print(f"  - ä¿®å¤å¤±è´¥: {failed_count} ç¯‡")


def main():
    parser = argparse.ArgumentParser(description='ä¿®å¤å¤±è´¥ä»»åŠ¡')
    parser.add_argument('--file', type=str, help='æŒ‡å®šè¦ä¿®å¤çš„ summary JSON æ–‡ä»¶')
    parser.add_argument('--dir', type=str, default='summary', help='summary ç›®å½•è·¯å¾„ (é»˜è®¤: summary)')
    parser.add_argument('--type', type=str, default='all',
                       choices=['all', 'inspiration', 'translation', 'summary'],
                       help='è¦ä¿®å¤çš„ä»»åŠ¡ç±»å‹ (é»˜è®¤: all)')
    parser.add_argument('--dry-run', action='store_true', help='åªæ£€æµ‹ä¸ä¿®å¤')
    parser.add_argument('--pattern', type=str, help='æ–‡ä»¶ååŒ¹é…æ¨¡å¼ (ä¾‹å¦‚: 2025-12-*)')

    args = parser.parse_args()

    print("ğŸ”§ å¯åŠ¨å¤±è´¥ä»»åŠ¡ä¿®å¤å·¥å…·")
    print("=" * 60)

    if args.file:
        # ä¿®å¤å•ä¸ªæ–‡ä»¶
        if not os.path.exists(args.file):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {args.file}")
            return
        fix_failed_tasks(args.file, args.type, args.dry_run)
    else:
        # æ‰¹é‡ä¿®å¤ç›®å½•ä¸­çš„æ–‡ä»¶
        summary_dir = Path(args.dir)
        if not summary_dir.exists():
            print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.dir}")
            return

        # æŸ¥æ‰¾æ‰€æœ‰ summary JSON æ–‡ä»¶
        pattern = args.pattern or '*_with_summary2.json'
        summary_files = sorted(summary_dir.glob(pattern))

        if not summary_files:
            print(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–‡ä»¶: {pattern}")
            return

        print(f"ğŸ“ æ‰¾åˆ° {len(summary_files)} ä¸ªæ–‡ä»¶")

        for summary_file in summary_files:
            print(f"\n{'=' * 60}")
            fix_failed_tasks(str(summary_file), args.type, args.dry_run)


if __name__ == '__main__':
    main()
