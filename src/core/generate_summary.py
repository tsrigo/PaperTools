#!/usr/bin/env python3
"""
è®ºæ–‡æ€»ç»“ç”Ÿæˆè„šæœ¬ - ç›´æ¥æ·»åŠ åˆ°JSONæ–‡ä»¶
Paper summary generation script - adds summary2 field to JSON file
"""

import json
import os
import re
import requests
import time
import argparse
from pathlib import Path
from typing import Optional, Dict, List
from tqdm import tqdm
from openai import OpenAI, OpenAIError
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from functools import wraps

# å¯¼å…¥é…ç½®
import sys
import os
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from src.utils.config import (
    API_KEY, BASE_URL, MODEL, SUMMARY_DIR, TEMPERATURE, REQUEST_DELAY, REQUEST_TIMEOUT, MAX_WORKERS,
    ENABLE_CACHE, JINA_MAX_REQUESTS_PER_MINUTE, JINA_MAX_RETRIES, JINA_BACKOFF_FACTOR, JINA_API_TOKEN
)
from src.utils.cache_manager import CacheManager


class JinaRateLimiter:
    """Jina APIé€Ÿç‡é™åˆ¶å™¨ - 20 RPM"""
    
    def __init__(self, max_requests_per_minute: int = 20):
        self.max_requests_per_minute = max_requests_per_minute
        self.min_interval = 60.0 / max_requests_per_minute  # æ¯ä¸ªè¯·æ±‚ä¹‹é—´çš„æœ€å°é—´éš”ï¼ˆç§’ï¼‰
        self.last_request_time = 0
        self.lock = threading.Lock()
    
    def wait_if_needed(self):
        """å¦‚æœéœ€è¦çš„è¯ï¼Œç­‰å¾…ä»¥æ»¡è¶³é€Ÿç‡é™åˆ¶"""
        with self.lock:
            current_time = time.time()
            time_since_last = current_time - self.last_request_time
            
            if time_since_last < self.min_interval:
                wait_time = self.min_interval - time_since_last
                time.sleep(wait_time)
            
            self.last_request_time = time.time()


# å…¨å±€Jinaé€Ÿç‡é™åˆ¶å™¨å®ä¾‹
jina_rate_limiter = JinaRateLimiter(max_requests_per_minute=JINA_MAX_REQUESTS_PER_MINUTE)


def retry_on_failure(max_retries: int = None, backoff_factor: float = None):
    """é‡è¯•è£…é¥°å™¨"""
    if max_retries is None:
        max_retries = JINA_MAX_RETRIES
    if backoff_factor is None:
        backoff_factor = JINA_BACKOFF_FACTOR
        
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except requests.exceptions.RequestException as e:
                    last_exception = e
                    if attempt < max_retries - 1:  # ä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•
                        wait_time = backoff_factor ** attempt
                        print(f"âš ï¸ Jina APIè¯·æ±‚å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰ï¼Œ{wait_time}ç§’åé‡è¯•: {e}")
                        time.sleep(wait_time)
                    else:
                        print(f"âŒ Jina APIè¯·æ±‚å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                except Exception as e:
                    # å¯¹äºéç½‘ç»œç›¸å…³çš„å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡º
                    raise e
            
            # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªå¼‚å¸¸
            raise last_exception
        
        return wrapper
    return decorator


@retry_on_failure()
def fetch_paper_content_from_jinja(arxiv_url: str, cache_manager: Optional[CacheManager] = None) -> Optional[str]:
    """
    ä½¿ç”¨jinja.aiè·å–è®ºæ–‡å®Œæ•´å†…å®¹ï¼Œæ”¯æŒç¼“å­˜
    
    Args:
        arxiv_url: arXivè®ºæ–‡é“¾æ¥
        cache_manager: ç¼“å­˜ç®¡ç†å™¨
    
    Returns:
        è®ºæ–‡çš„å®Œæ•´æ–‡æœ¬å†…å®¹ï¼Œå¦‚æœè·å–å¤±è´¥åˆ™è¿”å›None
    """
    # ğŸš€ ä¼˜åŒ–ï¼šé¦–å…ˆæ£€æŸ¥ç¼“å­˜
    if cache_manager and ENABLE_CACHE:
        cached_paper = cache_manager.get_paper_cache(arxiv_url)
        if cached_paper and cached_paper.get('data', {}).get('content'):
            # print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„è®ºæ–‡å†…å®¹: {arxiv_url}")
            return cached_paper['data']['content']
    
    # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œæ‰è°ƒç”¨jina.ai API
    print(f"ğŸŒ ä»jina.aiè·å–è®ºæ–‡å†…å®¹: {arxiv_url}")
    
    # åº”ç”¨é€Ÿç‡é™åˆ¶
    jina_rate_limiter.wait_if_needed()
    
    # å¤„ç†ä¸åŒæ ¼å¼çš„é“¾æ¥
    if arxiv_url.startswith('/arxiv/'):
        # ç›¸å¯¹è·¯å¾„æ ¼å¼: /arxiv/2509.18083
        arxiv_id = arxiv_url.replace('/arxiv/', '')
        pdf_url = f'https://arxiv.org/pdf/{arxiv_id}'
    elif '/abs/' in arxiv_url:
        # å®Œæ•´absé“¾æ¥è½¬æ¢ä¸ºpdfé“¾æ¥
        pdf_url = arxiv_url.replace('/abs/', '/pdf/')
    elif '/pdf/' in arxiv_url:
        # å·²ç»æ˜¯pdfé“¾æ¥
        pdf_url = arxiv_url
    else:
        # å‡è®¾æ˜¯arXiv ID
        pdf_url = f'https://arxiv.org/pdf/{arxiv_url}'
        
    # ä½¿ç”¨jinja.ai API
    jinja_url = f'https://r.jina.ai/{pdf_url}'
    headers = {}
    try:
        from src.utils.config import JINA_API_TOKEN as _JINA_TOKEN
    except Exception:
        _JINA_TOKEN = ""
    if _JINA_TOKEN:
        headers["Authorization"] = f"Bearer {_JINA_TOKEN}"
    
    response = requests.get(jinja_url, headers=headers or None, timeout=REQUEST_TIMEOUT)
    
    if response.status_code == 200:
        content = response.content.decode('utf-8')
        
        # ğŸš€ ä¼˜åŒ–ï¼šä¿å­˜åˆ°ç¼“å­˜
        if cache_manager and ENABLE_CACHE:
            cache_manager.set_paper_cache(arxiv_url, {'content': content})
            print(f"ğŸ’¾ å·²ç¼“å­˜è®ºæ–‡å†…å®¹: {arxiv_url}")
        
        return content
    else:
        # å¯¹äºHTTPé”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘é‡è¯•æœºåˆ¶
        raise requests.exceptions.HTTPError(f"jinja.aiè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")


def extract_arxiv_id_from_link(link: str) -> Optional[str]:
    """ä»arXivé“¾æ¥ä¸­æå–è®ºæ–‡ID"""
    patterns = [
        r'arxiv\.org/abs/(\d+\.\d+)',
        r'arxiv\.org/pdf/(\d+\.\d+)',
        r'(\d{4}\.\d{4,5})'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, link)
        if match:
            return match.group(1)
    return None


def translate_summary(summary: str, client: OpenAI, model: str, temperature: float, paper_title: str = "", cache_manager: Optional[CacheManager] = None) -> str:
    """
    ç¿»è¯‘è‹±æ–‡æ‘˜è¦ä¸ºä¸­æ–‡
    
    Args:
        summary: è‹±æ–‡æ‘˜è¦
        client: OpenAIå®¢æˆ·ç«¯
        model: ä½¿ç”¨çš„æ¨¡å‹
        temperature: ç”Ÿæˆæ¸©åº¦
        paper_title: è®ºæ–‡æ ‡é¢˜ï¼ˆç”¨äºç¼“å­˜ï¼‰
        cache_manager: ç¼“å­˜ç®¡ç†å™¨
    
    Returns:
        ä¸­æ–‡ç¿»è¯‘
    """
    # å°è¯•ä»ç¼“å­˜è·å–
    if cache_manager and ENABLE_CACHE:
        cache_key = f"translation_{paper_title}_{summary[:100]}"
        cached_translation = cache_manager.get_summary_cache(cache_key, summary)
        if cached_translation:
            # print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„ç¿»è¯‘: {paper_title[:50]}...")
            return cached_translation

    # æ„å»ºç¿»è¯‘prompt
    prompt = f"""è¯·å°†ä»¥ä¸‹è‹±æ–‡å­¦æœ¯è®ºæ–‡æ‘˜è¦ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¦æ±‚ï¼š

1. ä¿æŒå­¦æœ¯æ€§å’Œå‡†ç¡®æ€§
2. ä¸“ä¸šæœ¯è¯­ä¿æŒè‹±æ–‡åŸæ–‡ï¼Œç”¨æ‹¬å·æ ‡æ³¨ä¸­æ–‡è§£é‡Š
3. è¯­è¨€æµç•…è‡ªç„¶ï¼Œç¬¦åˆä¸­æ–‡å­¦æœ¯è¡¨è¾¾ä¹ æƒ¯
4. ä¿æŒåŸæ–‡çš„é€»è¾‘ç»“æ„å’Œé‡ç‚¹

è‹±æ–‡æ‘˜è¦ï¼š
{summary}

è¯·æä¾›ä¸­æ–‡ç¿»è¯‘ï¼š"""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡ç¿»è¯‘åŠ©æ‰‹ï¼Œæ“…é•¿å°†è‹±æ–‡å­¦æœ¯è®ºæ–‡æ‘˜è¦å‡†ç¡®ç¿»è¯‘æˆä¸­æ–‡ã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=temperature
        )
        translation = response.choices[0].message.content
        
        # ä¿å­˜åˆ°ç¼“å­˜
        if cache_manager and ENABLE_CACHE:
            cache_key = f"translation_{paper_title}_{summary[:100]}"
            cache_manager.set_summary_cache(cache_key, summary, translation)
        
        return translation
        
    except Exception as e:
        print(f"âŒ ç¿»è¯‘æ‘˜è¦æ—¶å‡ºé”™: {e}")
        return "ç¿»è¯‘å¤±è´¥"


def generate_summary(paper_content: str, client: OpenAI, model: str, temperature: float, paper_title: str = "", cache_manager: Optional[CacheManager] = None) -> str:
    """
    ä½¿ç”¨å¤§æ¨¡å‹ç”Ÿæˆè®ºæ–‡æ€»ç»“ï¼Œæ”¯æŒç¼“å­˜
    
    Args:
        paper_content: è®ºæ–‡å®Œæ•´å†…å®¹
        client: OpenAIå®¢æˆ·ç«¯
        model: ä½¿ç”¨çš„æ¨¡å‹
        temperature: ç”Ÿæˆæ¸©åº¦
        paper_title: è®ºæ–‡æ ‡é¢˜ï¼ˆç”¨äºç¼“å­˜ï¼‰
        cache_manager: ç¼“å­˜ç®¡ç†å™¨
    
    Returns:
        ç”Ÿæˆçš„æ€»ç»“
    """
    # å°è¯•ä»ç¼“å­˜è·å–
    if cache_manager and ENABLE_CACHE:
        cached_summary = cache_manager.get_summary_cache(paper_title, paper_content)
        if cached_summary:
            # print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„æ€»ç»“: {paper_title[:50]}...")
            return cached_summary
    # æ„å»ºprompt
    prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è®ºæ–‡å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯æ€»ç»“ã€‚

è®ºæ–‡å†…å®¹:
{paper_content}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆæ€»ç»“ï¼Œä½¿ç”¨ä¸­æ–‡å›å¤ï¼š

æœ¬æ–‡æ—¨åœ¨ [è§£å†³ä»€ä¹ˆé—®é¢˜æˆ–å®ç°ä»€ä¹ˆç›®æ ‡]ã€‚é’ˆå¯¹ [ç‰¹å®šçš„è¾“å…¥ã€æ•°æ®æˆ–åœºæ™¯]ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ [æè¿°æ ¸å¿ƒæ–¹æ³•]ï¼Œå¹¶åœ¨ [æŸæ•°æ®é›†ã€benchmarkã€å®éªŒç¯å¢ƒ] ä¸Šé€šè¿‡ [å…·ä½“è¯„ä¼°æŒ‡æ ‡] éªŒè¯äº†å…¶æœ‰æ•ˆæ€§ã€‚

è¦æ±‚ï¼š
1. æ€»ç»“åº”å½“ç®€æ´æ˜äº†ï¼Œçªå‡ºæ ¸å¿ƒè´¡çŒ®
2. ä½¿ç”¨ä¸­æ–‡è¡¨è¿°ï¼Œä¸“ä¸šæœ¯è¯­ä¿æŒè‹±æ–‡
3. é‡ç‚¹å…³æ³¨æ–¹æ³•åˆ›æ–°å’Œå®éªŒéªŒè¯
4. æ§åˆ¶åœ¨200å­—ä»¥å†…"""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system", 
                    "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡æ€»ç»“åŠ©æ‰‹ï¼Œèƒ½å¤Ÿå‡†ç¡®ç†è§£è®ºæ–‡å†…å®¹å¹¶ç”Ÿæˆé«˜è´¨é‡çš„ä¸­æ–‡æ€»ç»“ã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=temperature
            # ç§»é™¤max_tokensé™åˆ¶ï¼Œè®©æ¨¡å‹ç”Ÿæˆæ›´å®Œæ•´çš„æ€»ç»“
        )
        summary = response.choices[0].message.content
        
        # ä¿å­˜åˆ°ç¼“å­˜
        if cache_manager and ENABLE_CACHE:
            cache_manager.set_summary_cache(paper_title, paper_content, summary)
        
        return summary
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™: {e}")
        return "æ€»ç»“ç”Ÿæˆå¤±è´¥"


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è®ºæ–‡æ€»ç»“ç”Ÿæˆå·¥å…·')
    parser.add_argument('--input-file', required=True,
                       help='è¾“å…¥çš„JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', default=SUMMARY_DIR,
                       help=f'è¾“å‡ºç›®å½•ï¼ˆJSONæ–‡ä»¶ä¿å­˜ä½ç½®ï¼Œé»˜è®¤: {SUMMARY_DIR})')
    parser.add_argument('--api-key', default=API_KEY,
                       help='APIå¯†é’¥')
    parser.add_argument('--base-url', default=BASE_URL,
                       help='APIåŸºç¡€URL')
    parser.add_argument('--model', default=MODEL,
                       help='ä½¿ç”¨çš„æ¨¡å‹')
    parser.add_argument('--temperature', type=float, default=TEMPERATURE,
                       help='ç”Ÿæˆæ¸©åº¦')
    parser.add_argument('--max-papers', type=int, default=0,
                       help='æœ€å¤§å¤„ç†è®ºæ–‡æ•°é‡ï¼Œ0è¡¨ç¤ºå¤„ç†æ‰€æœ‰ï¼ˆæ¨èå¤„ç†æ‰€æœ‰ï¼‰')
    parser.add_argument('--skip-existing', action='store_true',
                       help='è·³è¿‡å·²æœ‰summary2å­—æ®µçš„è®ºæ–‡')
    parser.add_argument('--max-workers', type=int, default=MAX_WORKERS,
                       help=f'æœ€å¤§çº¿ç¨‹æ•° (é»˜è®¤: {MAX_WORKERS})')
    parser.add_argument('--disable-cache', action='store_true',
                       help='ç¦ç”¨ç¼“å­˜æœºåˆ¶')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = None
    if not args.disable_cache and ENABLE_CACHE:
        cache_manager = CacheManager()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶æœªæ‰¾åˆ°: {args.input_file}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    client = OpenAI(
        api_key=args.api_key,
        base_url=args.base_url
    )
    
    print(f"ğŸ“ å¼€å§‹ç”Ÿæˆè®ºæ–‡æ€»ç»“")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input_file}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {args.model}")
    print("=" * 50)
    
    # åŠ è½½è®ºæ–‡æ•°æ®
    try:
        with open(args.input_file, 'r', encoding='utf-8') as f:
            papers = json.load(f)
        print(f"ğŸ“š æˆåŠŸåŠ è½½ {len(papers)} ç¯‡è®ºæ–‡")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return
    
    # é™åˆ¶å¤„ç†æ•°é‡
    if args.max_papers > 0:
        papers = papers[:args.max_papers]
        print(f"ğŸ”¢ é™åˆ¶å¤„ç†æ•°é‡ä¸º: {args.max_papers}")
    
    # å¤šçº¿ç¨‹å¤„ç†è®ºæ–‡
    def process_paper_wrapper(paper_with_index):
        """åŒ…è£…å‡½æ•°ï¼Œç”¨äºå¤šçº¿ç¨‹å¤„ç†"""
        index, paper = paper_with_index
        paper_title = paper.get('title', 'Untitled Paper')
        paper_link = paper.get('link', '')
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰summary2å­—æ®µä¸”ä¸ä¸ºç©º
        if args.skip_existing and paper.get('summary2'):
            return 'skipped', index, paper, f"â­ï¸ è·³è¿‡å·²æœ‰æ€»ç»“çš„è®ºæ–‡: {paper_title[:50]}..."
        
        try:
            # ä¼˜åŒ–ï¼šå…ˆæ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„æ€»ç»“å’Œç¿»è¯‘ï¼Œé¿å…ä¸å¿…è¦çš„å†…å®¹è·å–
            original_summary = paper.get('summary', '')
            
            # æ£€æŸ¥æ€»ç»“ç¼“å­˜ï¼ˆä½¿ç”¨è™šæ‹Ÿå†…å®¹å…ˆæ£€æŸ¥ï¼‰
            cached_summary = None
            cached_translation = None
            
            if cache_manager and ENABLE_CACHE:
                # å…ˆç”¨è®ºæ–‡é“¾æ¥ä½œä¸ºé”®æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„å†…å®¹
                paper_content_cache = cache_manager.get_paper_cache(paper_link)
                if paper_content_cache and paper_content_cache.get('data', {}).get('content'):
                    cached_paper_content = paper_content_cache['data']['content']
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æ€»ç»“ç¼“å­˜
                    cached_summary = cache_manager.get_summary_cache(paper_title, cached_paper_content)
                    if original_summary:
                        cache_key = f"translation_{paper_title}_{original_summary[:100]}"
                        cached_translation = cache_manager.get_summary_cache(cache_key, original_summary)
                    
                    # å¦‚æœéƒ½æœ‰ç¼“å­˜ï¼Œç›´æ¥è¿”å›
                    if cached_summary and (not original_summary or cached_translation):
                        paper_copy = paper.copy()
                        paper_copy['summary2'] = cached_summary
                        paper_copy['summary_translation'] = cached_translation or "æ— éœ€ç¿»è¯‘"
                        paper_copy['summary_generated_time'] = time.strftime('%Y-%m-%d %H:%M:%S')
                        paper_copy['summary_model'] = args.model
                        return 'success', index, paper_copy, f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜: {paper_title[:50]}..."
            
            # å¦‚æœæ²¡æœ‰å®Œæ•´ç¼“å­˜ï¼Œæ‰è·å–è®ºæ–‡å†…å®¹
            paper_content = None
            
            # å…ˆå°è¯•ä»ç¼“å­˜è·å–è®ºæ–‡å†…å®¹
            if cache_manager and ENABLE_CACHE:
                paper_cache = cache_manager.get_paper_cache(paper_link)
                if paper_cache and paper_cache.get('data', {}).get('content'):
                    paper_content = paper_cache['data']['content']
                    # print(f"ğŸ“‹ ä½¿ç”¨ç¼“å­˜çš„è®ºæ–‡å†…å®¹: {paper_title[:50]}...")
            
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰å†…å®¹ï¼Œæ‰ä»jina.aiè·å–
            if not paper_content:
                paper_content = fetch_paper_content_from_jinja(paper_link, cache_manager)
                if not paper_content:
                    return 'failed', index, paper, f"âŒ æ— æ³•è·å–è®ºæ–‡å†…å®¹: {paper_title}"
            
            # æ£€æŸ¥å†…å®¹é•¿åº¦å¹¶æˆªæ–­
            if len(paper_content) > 200000:
                paper_content = paper_content[:200000] + "\n\n[å†…å®¹å·²æˆªæ–­...]"
            
            # ç”Ÿæˆæ€»ç»“ï¼ˆè¿™é‡Œä¼šå†æ¬¡æ£€æŸ¥ç¼“å­˜ï¼‰
            summary = generate_summary(paper_content, client, args.model, args.temperature, paper.get('title', ''), cache_manager)
            
            # ç¿»è¯‘åŸå§‹æ‘˜è¦ï¼ˆè¿™é‡Œä¹Ÿä¼šæ£€æŸ¥ç¼“å­˜ï¼‰
            summary_translation = ""
            if original_summary:
                try:
                    summary_translation = translate_summary(original_summary, client, args.model, args.temperature, paper.get('title', ''), cache_manager)
                except Exception as e:
                    print(f"âš ï¸ ç¿»è¯‘æ‘˜è¦å¤±è´¥ {paper_title[:30]}: {e}")
                    summary_translation = "ç¿»è¯‘å¤±è´¥"
            
            # æ·»åŠ æ€»ç»“åˆ°è®ºæ–‡æ•°æ®ä¸­
            paper_copy = paper.copy()
            paper_copy['summary2'] = summary
            paper_copy['summary_translation'] = summary_translation
            paper_copy['summary_generated_time'] = time.strftime('%Y-%m-%d %H:%M:%S')
            paper_copy['summary_model'] = args.model
            
            return 'success', index, paper_copy, f"âœ… æˆåŠŸç”Ÿæˆæ€»ç»“å’Œç¿»è¯‘: {paper_title[:50]}..."
            
        except Exception as e:
            return 'failed', index, paper, f"âŒ å¤„ç†è®ºæ–‡æ—¶å‡ºé”™ {paper_title}: {e}"
    
    print(f"ğŸ”„ ä½¿ç”¨ {args.max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œç”Ÿæˆæ€»ç»“...")
    
    processed = 0
    skipped = 0
    failed = 0
    updated_papers = papers.copy()  # åˆ›å»ºå‰¯æœ¬ç”¨äºæ›´æ–°
    
    with ThreadPoolExecutor(max_workers=args.max_workers) as executor:
        # æäº¤æ‰€æœ‰å¤„ç†ä»»åŠ¡ï¼Œä¼ å…¥ç´¢å¼•å’Œè®ºæ–‡æ•°æ®
        futures = [executor.submit(process_paper_wrapper, (i, paper)) for i, paper in enumerate(papers)]
        
        # æ”¶é›†ç»“æœ
        for future in tqdm(as_completed(futures), total=len(papers), desc="ç”Ÿæˆæ€»ç»“"):
            try:
                status, index, updated_paper, message = future.result()
                # print(message)
                
                if status == 'success':
                    processed += 1
                    updated_papers[index] = updated_paper  # æ›´æ–°å¯¹åº”ä½ç½®çš„è®ºæ–‡æ•°æ®
                elif status == 'skipped':
                    skipped += 1
                else:  # failed
                    failed += 1
                
                # æ·»åŠ å»¶æ—¶é¿å…APIè¯·æ±‚è¿‡å¿«
                time.sleep(REQUEST_DELAY / args.max_workers)
                
            except Exception as e:
                print(f"âŒ è·å–å¤„ç†ç»“æœæ—¶å‡ºé”™: {e}")
                failed += 1
                continue
    
    # ä¿å­˜æ›´æ–°åçš„JSONæ–‡ä»¶
    if processed > 0:
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        input_filename = os.path.basename(args.input_file)
        name_without_ext = os.path.splitext(input_filename)[0]
        output_filename = f"{name_without_ext}_with_summary2.json"
        output_path = os.path.join(args.output_dir, output_filename)
        
        # ä¿å­˜æ›´æ–°åçš„æ•°æ®
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(updated_papers, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å·²ä¿å­˜æ›´æ–°åçš„JSONæ–‡ä»¶: {output_path}")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ€»ç»“ç”Ÿæˆå®Œæˆï¼")
    print(f"âœ… å·²å¤„ç†: {processed} ç¯‡è®ºæ–‡")
    print(f"â­ï¸ å·²è·³è¿‡: {skipped} ç¯‡è®ºæ–‡")
    print(f"âŒ å¤±è´¥: {failed} ç¯‡è®ºæ–‡")
    if processed > 0:
        print(f"ğŸ“‚ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print("ğŸ‰ å¤„ç†å®Œæˆï¼")


def generate_papers_list_html(filtered_papers, output_dir):
    """ç”Ÿæˆè¿‡æ»¤åè®ºæ–‡åˆ—è¡¨çš„HTMLé¡µé¢"""
    import os
    os.makedirs(output_dir, exist_ok=True)
    
    # HTMLæ¨¡æ¿ï¼ˆä½¿ç”¨å ä½ç¬¦é¿å… .format è¯¯å¤„ç† JS/CSS èŠ±æ‹¬å·ï¼‰
    html_template = """<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç­›é€‰è®ºæ–‡åˆ—è¡¨</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }}
        .container {{
            background-color: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            text-align: center;
        }}
        .stats {{
            text-align: center;
            margin: 20px 0;
            font-size: 1.1em;
            color: #7f8c8d;
        }}
        .paper-item {{
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            background-color: #fafafa;
        }}
        .paper-title {{
            font-size: 1.3em;
            font-weight: bold;
            color: #2c3e50;
            margin-bottom: 10px;
        }}
        .paper-meta {{
            color: #7f8c8d;
            font-size: 0.9em;
            margin: 5px 0;
        }}
        .paper-authors {{
            font-style: italic;
            margin: 10px 0;
        }}
        .paper-category {{
            display: inline-block;
            background-color: #3498db;
            color: white;
            padding: 3px 8px;
            border-radius: 3px;
            font-size: 0.8em;
            margin: 5px 0;
        }}
        .paper-summary {{
            background-color: #fff3cd;
            border-left: 4px solid #ffc107;
            padding: 10px;
            margin: 15px 0;
            font-size: 0.95em;
        }}
        .paper-original-summary {{
            background-color: #e8f5e8;
            border-left: 4px solid #28a745;
            padding: 10px;
            margin: 15px 0;
            font-size: 0.95em;
        }}
        .filter-reason {{
            background-color: #d1ecf1;
            border-left: 4px solid #17a2b8;
            padding: 10px;
            margin: 15px 0;
            font-size: 0.9em;
        }}
        .paper-links {{
            margin-top: 15px;
        }}
        .paper-links a {{
            display: inline-block;
            background-color: #e74c3c;
            color: white;
            padding: 8px 15px;
            text-decoration: none;
            border-radius: 4px;
            margin-right: 10px;
            margin-bottom: 5px;
            font-size: 0.9em;
        }}
        .paper-links a:hover {{
            background-color: #c0392b;
        }}
        .papers-cool-link {{
            background-color: #9b59b6 !important;
        }}
        .papers-cool-link:hover {{
            background-color: #8e44ad !important;
        }}
        .hidden {{ display: none; }}
        .toast {{
            position: fixed;
            left: 50%;
            bottom: 24px;
            transform: translateX(-50%);
            background: rgba(0,0,0,0.85);
            color: #fff;
            padding: 12px 16px;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.2);
            z-index: 9999;
            display: flex;
            align-items: center;
            gap: 12px;
            font-size: 14px;
        }}
        .toast button {{
            background: #3498db;
            color: #fff;
            border: none;
            border-radius: 4px;
            padding: 6px 10px;
            cursor: pointer;
        }}
        .toast .countdown {{
            opacity: 0.8;
        }}
    </style>
    <script>
    // é¡µé¢æ‰€å±æ—¥æœŸï¼ˆç”±ç”Ÿæˆå™¨æ³¨å…¥ï¼‰
    const PAGE_DATE = '__DATE_STR__';

    async function loadState(dateStr) {{
        try {{
            const res = await fetch(`/api/state?date=${{encodeURIComponent(dateStr)}}`);
            if (!res.ok) return {{deleted_ids: [], read_ids: []}};
            return await res.json();
        }} catch (e) {{
            return {{deleted_ids: [], read_ids: []}};
        }}
    }}

    const pendingDeletes = new Map(); // arxivId -> timeoutId

    function ensureToast() {{
        let toast = document.getElementById('undo-toast');
        if (!toast) {{
            toast = document.createElement('div');
            toast.id = 'undo-toast';
            toast.className = 'toast hidden';
            toast.innerHTML = '<span class="msg"></span> <span class="countdown"></span> <button class="undo">æ’¤é”€</button>';
            document.body.appendChild(toast);
        }}
        return toast;
    }}

    function showUndoToast(message, seconds, onUndo, onExpire) {{
        const toast = ensureToast();
        const msgEl = toast.querySelector('.msg');
        const cdEl = toast.querySelector('.countdown');
        const undoBtn = toast.querySelector('.undo');
        msgEl.textContent = message;
        let remaining = seconds;
        cdEl.textContent = `(${remaining}s)`;
        toast.classList.remove('hidden');

        let intervalId = setInterval(() => {{
            remaining -= 1;
            cdEl.textContent = `(${remaining}s)`;
            if (remaining <= 0) {{
                clearInterval(intervalId);
            }}
        }}, 1000);

        const cleanup = () => {{
            clearInterval(intervalId);
            toast.classList.add('hidden');
        }};

        const expireTimer = setTimeout(() => {{
            cleanup();
            try {{ onExpire && onExpire(); }} catch (e) {{}}
        }}, seconds * 1000);

        const onUndoClick = () => {{
            cleanup();
            clearTimeout(expireTimer);
            undoBtn.removeEventListener('click', onUndoClick);
            try {{ onUndo && onUndo(); }} catch (e) {{}}
        }};
        undoBtn.addEventListener('click', onUndoClick);
    }}

    function updateStatsCount() {
        const visibleCount = Array.from(document.querySelectorAll('[data-arxiv-id]')).filter(el => !el.classList.contains('hidden')).length;
        const statsEl = document.querySelector('.stats');
        if (statsEl) {
            statsEl.textContent = `å…±ç­›é€‰å‡º ${visibleCount} ç¯‡è®ºæ–‡`;
        }
    }

    function deletePaper(dateStr, arxivId, paperDir, title) {{
        const el = document.querySelector(`[data-arxiv-id="${CSS.escape(arxivId)}"]`);
        if (!el) return;
        // å…ˆéšè—ï¼Œæä¾›æ’¤é”€
        el.classList.add('hidden');
        updateStatsCount();
        
        const seconds = 5;
        let apiSucceeded = false;
        showUndoToast('å·²åˆ é™¤ï¼Œ5ç§’å†…å¯æ’¤é”€', seconds, () => {
            // æ’¤é”€ï¼šæ¢å¤æ˜¾ç¤º
            el.classList.remove('hidden');
            const t = pendingDeletes.get(arxivId);
            if (t) { clearTimeout(t); pendingDeletes.delete(arxivId); }
            updateStatsCount();
        }, async () => {
            // å€’è®¡æ—¶ç»“æŸï¼ŒçœŸæ­£è°ƒç”¨åˆ é™¤API
            const payload = { date: dateStr, arxiv_id: arxivId };
            if (paperDir) payload.paper_dir = paperDir;
            if (title) payload.title = title;
            try {
                const res = await fetch('/api/delete', { method: 'POST', headers: { 'Content-Type': 'application/json' }, body: JSON.stringify(payload) });
                apiSucceeded = res.ok;
                if (!res.ok) {
                    // å¤±è´¥åˆ™æ¢å¤æ˜¾ç¤º
                    el.classList.remove('hidden');
                }
            } catch (e) {
                el.classList.remove('hidden');
            } finally {
                pendingDeletes.delete(arxivId);
                if (apiSucceeded) {
                    // ç¡®è®¤åˆ é™¤åï¼Œä»DOMå½»åº•ç§»é™¤ï¼Œé¿å…æœç´¢å¯è§
                    el.remove();
                }
                updateStatsCount();
            }
        });

        // é¢å¤–çš„ä¿é™©timerå¼•ç”¨ï¼ˆä¾¿äºæ‰‹åŠ¨æ¸…ç†ï¼‰
        const timerId = setTimeout(() => {}, seconds * 1000);
        pendingDeletes.set(arxivId, timerId);
    }}

    async function toggleRead(dateStr, arxivId, checkbox) {{
        const payload = {{ date: dateStr, arxiv_id: arxivId, read: checkbox.checked }};
        const res = await fetch('/api/toggle-read', {{ method: 'POST', headers: {{ 'Content-Type': 'application/json' }}, body: JSON.stringify(payload) }});
        if (!res.ok) {{
            alert('ä¿å­˜é˜…è¯»çŠ¶æ€å¤±è´¥');
            checkbox.checked = !checkbox.checked;
        }}
    }}

    document.addEventListener('DOMContentLoaded', async () => {{
        try {{
            // ä¼˜å…ˆä»è·¯å¾„ä¸­è§£æ /YYYY-MM-DD/index.htmlï¼›è‹¥æœåŠ¡æ ¹ç›®å½•å³æ—¥æœŸç›®å½•ï¼Œåˆ™å›é€€åˆ° PAGE_DATE
            const parts = location.pathname.split('/').filter(Boolean);
            let dateStr = parts.length >= 2 ? parts[parts.length - 2] : '';
            if (!dateStr && typeof PAGE_DATE === 'string' && PAGE_DATE) {{
                dateStr = PAGE_DATE;
            }}
            if (!dateStr) return;
            const state = await loadState(dateStr);
            const deleted = new Set(state.deleted_ids || []);
            const read = new Set(state.read_ids || []);
            // ç§»é™¤å·²åˆ é™¤çš„é¡¹
            document.querySelectorAll('[data-arxiv-id]').forEach(el => {{
                const id = el.getAttribute('data-arxiv-id');
                if (deleted.has(id)) {{
                    el.remove();
                }} else {{
                    // è®¾ç½®å·²è¯»å‹¾é€‰
                    const checkbox = el.querySelector('input[type="checkbox"]');
                    if (checkbox && read.has(id)) {{
                        checkbox.checked = true;
                    }}
                }}
            }});
            // æ›´æ–°é¡¶éƒ¨ç»Ÿè®¡æ•°é‡
            updateStatsCount();
        }} catch (e) {{
            console.warn('åˆå§‹åŒ–çŠ¶æ€å¤±è´¥', e);
        }}
    }});
    </script>
</head>
<body>
    <div class="container">
        <h1>ç­›é€‰è®ºæ–‡åˆ—è¡¨</h1>
        <div class="stats">å…±ç­›é€‰å‡º __PAPER_COUNT__ ç¯‡è®ºæ–‡</div>
        
        __PAPERS_HTML__
    </div>
</body>
</html>"""
    # è¿˜åŸ CSS/JS èŠ±æ‹¬å·ä¸ºå•æ‹¬å·
    html_template = html_template.replace("{{", "{").replace("}}", "}")
    
    # ç”Ÿæˆæ¯ç¯‡è®ºæ–‡çš„HTML
    papers_html = ""
    for idx, paper in enumerate(filtered_papers, 1):
        arxiv_id = paper.get('arxiv_id', 'Unknown')
        papers_cool_url = f"https://papers.cool/arxiv/{arxiv_id}"
        title = paper.get('title', 'Unknown Title')
        safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)[:100]
        paper_dir_name = f"{idx:03d}_{safe_title}"
        
        paper_html = f"""
        <div class="paper-item" data-arxiv-id="{arxiv_id}">
            <div class="paper-title">{title}
                <span style=\"float:right; cursor:pointer; color:#e74c3c;\" title=\"åˆ é™¤\" onclick=\"deletePaper('{os.path.basename(output_dir)}','{arxiv_id}','{os.path.basename(output_dir)}/{paper_dir_name}','{title.replace('"','&quot;')}')\">âœ–</span>
            </div>
            <div class="paper-meta">ArXiv ID: {arxiv_id}</div>
            <div class="paper-authors">ä½œè€…: {paper.get('authors', 'Unknown')}</div>
            <div class="paper-category">{paper.get('category', 'Unknown')}</div>
            <div class=\"paper-meta\">
                <label><input type=\"checkbox\" onchange=\"toggleRead('{os.path.basename(output_dir)}','{arxiv_id}', this)\"> å·²é˜…è¯»</label>
            </div>
            
            <div class="filter-reason">
                <strong>ç­›é€‰åŸå› :</strong> {paper.get('filter_reason', 'æ— ç‰¹å®šåŸå› ')}
            </div>
            
            <div class="paper-summary">
                <strong>AIæ‘˜è¦:</strong> {paper.get('summary2', 'æš‚æ— AIæ‘˜è¦')}
            </div>
            
            <div class="paper-original-summary">
                <strong>åŸå§‹æ‘˜è¦ï¼ˆä¸­æ–‡ç¿»è¯‘ï¼‰:</strong> {paper.get('summary_translation', paper.get('summary', 'æš‚æ— æ‘˜è¦ç¿»è¯‘'))}
            </div>
            
            <div class="paper-links">
                <a href="https://arxiv.org/abs/{arxiv_id}" target="_blank">ArXivåŸæ–‡</a>
                <a href="https://arxiv.org/pdf/{arxiv_id}.pdf" target="_blank">ä¸‹è½½PDF</a>
                <a href="{papers_cool_url}" target="_blank" class="papers-cool-link">Papers.cool</a>
            </div>
        </div>
        """
        papers_html += paper_html
    
    # å¡«å……æ¨¡æ¿ï¼ˆé¿å… str.format è§£æ JS æ¨¡æ¿ä¸­çš„ {remaining} ç­‰ï¼‰
    html_content = (
        html_template
        .replace("__PAPER_COUNT__", str(len(filtered_papers)))
        .replace("__PAPERS_HTML__", papers_html)
        .replace("__DATE_STR__", os.path.basename(output_dir))
    )
    
    # å†™å…¥HTMLæ–‡ä»¶
    html_file = os.path.join(output_dir, 'index.html')
    with open(html_file, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    return html_file


if __name__ == "__main__":
    main()
