#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆè®ºæ–‡ç­›é€‰è„šæœ¬
Enhanced paper filtering script with improved functionality
"""

import json
import os
import sys
import argparse
from datetime import datetime
from typing import List, Dict, Optional
from tqdm import tqdm
from openai import OpenAI, OpenAIError
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# å¯¼å…¥é…ç½®
try:
    from src.utils.config import API_KEY, BASE_URL, MODEL, DOMAIN_PAPER_DIR, TEMPERATURE, REQUEST_DELAY, PAPER_FILTER_PROMPT, MAX_WORKERS
except ImportError:
    raise ImportError("âš ï¸ é”™è¯¯: æœªæ‰¾åˆ°config.py")

def query_llm(title: str, summary: str, client: OpenAI, model: str, temperature: float = TEMPERATURE) -> tuple[bool, str]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­è®ºæ–‡æ˜¯å¦ç¬¦åˆç­›é€‰æ¡ä»¶
    
    Args:
        title: è®ºæ–‡æ ‡é¢˜
        summary: è®ºæ–‡æ‘˜è¦
        client: OpenAIå®¢æˆ·ç«¯
        model: ä½¿ç”¨çš„æ¨¡å‹
        temperature: ç”Ÿæˆæ¸©åº¦
    
    Returns:
        tuple[bool, str]: (æ˜¯å¦ç¬¦åˆç­›é€‰æ¡ä»¶, ç­›é€‰ç†ç”±)
    """
    messages = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡ç­›é€‰åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç»™å®šçš„ç­›é€‰æ¡ä»¶ï¼Œå‡†ç¡®åˆ¤æ–­è®ºæ–‡æ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚"
        },
        {
            "role": "user",
            "content": PAPER_FILTER_PROMPT.format(title=title, summary=summary)
        }
    ]
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            # ä¸è®¾ç½®max_tokensï¼Œè®©æ¨¡å‹è‡ªç”±ç”Ÿæˆ
            temperature=temperature
        )
        response_text = response.choices[0].message.content.strip()
        
        # è§£æç»“æœå’Œç†ç”±
        result = False
        reason = "è§£æå¤±è´¥"
        
        # å¯»æ‰¾ç»“æœå’Œç†ç”±çš„ä½ç½®
        result_index = -1
        reason_index = -1
        
        lines = response_text.split('\n')
        for i, line in enumerate(lines):
            line = line.strip()
            if line.startswith('ç»“æœ:') or line.startswith('ç»“æœï¼š'):
                result_part = line.split(':', 1)[1].strip().lower()
                result = result_part == 'true'
                result_index = i
            elif line.startswith('ç†ç”±:') or line.startswith('ç†ç”±ï¼š'):
                reason_index = i
                break
        
        # å¦‚æœæ‰¾åˆ°ç†ç”±æ ‡è¯†ï¼Œè·å–åé¢çš„æ‰€æœ‰å†…å®¹ä½œä¸ºç†ç”±
        if reason_index >= 0:
            reason_lines = []
            # å…ˆè·å–ç†ç”±è¡Œå†’å·åé¢çš„å†…å®¹
            first_line = lines[reason_index].split(':', 1)[1].strip()
            if first_line:
                reason_lines.append(first_line)
            
            # è·å–åç»­æ‰€æœ‰è¡Œä½œä¸ºç†ç”±çš„ä¸€éƒ¨åˆ†
            for i in range(reason_index + 1, len(lines)):
                line = lines[i].strip()
                if line:  # è·³è¿‡ç©ºè¡Œ
                    reason_lines.append(line)
            
            if reason_lines:
                reason = ' '.join(reason_lines)
        
        return result, reason
        
    except OpenAIError as e:
        error_msg = f"APIè°ƒç”¨é”™è¯¯: {e}"
        print(f"âŒ {error_msg}")
        return False, error_msg
    except Exception as e:
        error_msg = f"æœªçŸ¥é”™è¯¯: {e}"
        print(f"âŒ {error_msg}")
        return False, error_msg

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆè®ºæ–‡ç­›é€‰å·¥å…·')
    parser.add_argument('--input-file', required=True, 
                       help='è¾“å…¥çš„JSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', default=DOMAIN_PAPER_DIR,
                       help=f'è¾“å‡ºç›®å½• (é»˜è®¤: {DOMAIN_PAPER_DIR})')
    parser.add_argument('--api-key', default=API_KEY,
                       help='APIå¯†é’¥')
    parser.add_argument('--base-url', default=BASE_URL,
                       help='APIåŸºç¡€URL')
    parser.add_argument('--model', default=MODEL,
                       help='ä½¿ç”¨çš„æ¨¡å‹')
    parser.add_argument('--temperature', type=float, default=TEMPERATURE,
                       help='ç”Ÿæˆæ¸©åº¦')
    parser.add_argument('--max-papers', type=int, default=0,
                       help='æœ€å¤§å¤„ç†è®ºæ–‡æ•°é‡ï¼Œ0è¡¨ç¤ºå¤„ç†æ‰€æœ‰ï¼ˆæ¨èå¤„ç†æ‰€æœ‰ï¼‰')
    parser.add_argument('--max-workers', type=int, default=MAX_WORKERS,
                       help=f'æœ€å¤§çº¿ç¨‹æ•° (é»˜è®¤: {MAX_WORKERS})')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶æœªæ‰¾åˆ°: {args.input_file}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
    client = OpenAI(
        api_key=args.api_key,
        base_url=args.base_url
    )
    
    print(f"ğŸ” å¼€å§‹è®ºæ–‡ç­›é€‰")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {args.input_file}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {args.model}")
    print("=" * 50)
    
    # åŠ è½½è®ºæ–‡æ•°æ®
    try:
        with open(args.input_file, 'r', encoding='utf-8') as f:
            papers = json.load(f)
        print(f"ğŸ“š æˆåŠŸåŠ è½½ {len(papers)} ç¯‡è®ºæ–‡")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²ç­›é€‰çš„ç»“æœï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    current_date = datetime.now().strftime('%Y%m%d')
    input_filename = os.path.basename(args.input_file)
    date_part = input_filename.split('_')[-1].split('.json')[0] if '_' in input_filename else current_date
    
    output_filename = f"filtered_papers_{date_part}.json"
    output_filepath = os.path.join(args.output_dir, output_filename)
    excluded_filename = f"excluded_papers_{date_part}.json"
    excluded_filepath = os.path.join(args.output_dir, excluded_filename)
    
    # åŠ è½½å·²ç­›é€‰çš„è®ºæ–‡
    existing_filtered = []
    existing_excluded = []
    processed_arxiv_ids = set()
    
    if os.path.exists(output_filepath):
        try:
            with open(output_filepath, 'r', encoding='utf-8') as f:
                existing_filtered = json.load(f)
            for paper in existing_filtered:
                processed_arxiv_ids.add(paper.get('arxiv_id', ''))
            print(f"ğŸ”„ å‘ç°å·²ç­›é€‰ç»“æœ: {len(existing_filtered)} ç¯‡è®ºæ–‡")
        except Exception as e:
            print(f"âš ï¸ è¯»å–å·²ç­›é€‰æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    if os.path.exists(excluded_filepath):
        try:
            with open(excluded_filepath, 'r', encoding='utf-8') as f:
                existing_excluded = json.load(f)
            for paper in existing_excluded:
                processed_arxiv_ids.add(paper.get('arxiv_id', ''))
            print(f"ğŸ”„ å‘ç°å·²æ’é™¤ç»“æœ: {len(existing_excluded)} ç¯‡è®ºæ–‡")
        except Exception as e:
            print(f"âš ï¸ è¯»å–å·²æ’é™¤æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    # è¿‡æ»¤å‡ºå°šæœªå¤„ç†çš„è®ºæ–‡
    unprocessed_papers = []
    for paper in papers:
        arxiv_id = paper.get('arxiv_id', '')
        if arxiv_id not in processed_arxiv_ids:
            unprocessed_papers.append(paper)
    
    if processed_arxiv_ids:
        print(f"ğŸ“Š æ–­ç‚¹ç»­ä¼ : è·³è¿‡å·²å¤„ç†çš„ {len(processed_arxiv_ids)} ç¯‡ï¼Œå¤„ç†å‰©ä½™ {len(unprocessed_papers)} ç¯‡")
        papers = unprocessed_papers
    
    if not papers:
        print("âœ… æ‰€æœ‰è®ºæ–‡éƒ½å·²å¤„ç†å®Œæˆï¼")
        return
    
    # é™åˆ¶å¤„ç†æ•°é‡
    if args.max_papers > 0:
        papers = papers[:args.max_papers]
        print(f"ğŸ”¢ é™åˆ¶å¤„ç†æ•°é‡ä¸º: {args.max_papers}")
    
    # å¤šçº¿ç¨‹ç­›é€‰è®ºæ–‡
    def filter_paper_wrapper(paper):
        """åŒ…è£…å‡½æ•°ï¼Œç”¨äºå¤šçº¿ç¨‹ç­›é€‰"""
        title = paper.get('title', '').strip()
        summary = paper.get('summary', '') or paper.get('abstract', '')
        
        if not title or not summary:
            return 'skip', paper, f"è·³è¿‡è®ºæ–‡ (ç¼ºå°‘æ ‡é¢˜æˆ–æ‘˜è¦): {title[:50]}...", "ç¼ºå°‘æ ‡é¢˜æˆ–æ‘˜è¦"
        
        try:
            is_match, reason = query_llm(title, summary, client, args.model, args.temperature)
            # æ·»åŠ ç­›é€‰ç†ç”±åˆ°è®ºæ–‡æ•°æ®ä¸­
            paper_with_reason = paper.copy()
            paper_with_reason['filter_reason'] = reason
            
            if is_match:
                return 'include', paper_with_reason, f"âœ… åŒ¹é…: {title[:50]}...", reason
            else:
                return 'exclude', paper_with_reason, f"â­ï¸ ä¸åŒ¹é…: {title[:50]}...", reason
            
        except Exception as e:
            return 'error', paper, f"âŒ å¤„ç†è®ºæ–‡æ—¶å‡ºé”™: {e}", f"å¤„ç†é”™è¯¯: {e}"
    
    print(f"ğŸ”„ ä½¿ç”¨ {args.max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œç­›é€‰...")
    print(f"ğŸ“Š å¼€å§‹å¤„ç† {len(papers)} ç¯‡è®ºæ–‡...")
    
    filtered_papers = []  # åŒ¹é…çš„è®ºæ–‡
    excluded_papers = []  # è¢«æ’é™¤çš„è®ºæ–‡ï¼ˆç”¨äºäººå·¥å®¡æ ¸ï¼‰
    
    with ThreadPoolExecutor(max_workers=args.max_workers) as executor:
        # æäº¤æ‰€æœ‰ç­›é€‰ä»»åŠ¡
        futures = [executor.submit(filter_paper_wrapper, paper) for paper in papers]
        
        # æ”¶é›†ç»“æœ
        processed_count = 0
        matched_count = 0
        
        for future in tqdm(as_completed(futures), total=len(papers), desc="ç­›é€‰è®ºæ–‡", 
                          unit="ç¯‡", ncols=80):
            try:
                status, paper, message, reason = future.result()
                
                processed_count += 1
                
                if status == 'include':
                    filtered_papers.append(paper)
                    matched_count += 1
                    # print(f"âœ… [{matched_count}/{processed_count}] {message}")
                elif status == 'exclude':
                    # ç§»é™¤summaryå­—æ®µä»¥èŠ‚çœç©ºé—´ï¼Œä½†ä¿ç•™ç­›é€‰ç†ç”±
                    excluded_paper = paper.copy()
                    if 'summary' in excluded_paper:
                        del excluded_paper['summary']
                    if 'abstract' in excluded_paper:
                        del excluded_paper['abstract']
                    excluded_papers.append(excluded_paper)
                    # print(f"â­ï¸ [{matched_count}/{processed_count}] {message}")
                elif status == 'skip':
                    # print(f"â¸ï¸ [{matched_count}/{processed_count}] {message}")
                    pass
                else:  # error
                    print(f"âŒ [{matched_count}/{processed_count}] {message}")
                
                # æ·»åŠ å°å»¶æ—¶é¿å…APIè¯·æ±‚è¿‡å¿«
                time.sleep(REQUEST_DELAY / args.max_workers)  # æ ¹æ®çº¿ç¨‹æ•°è°ƒæ•´å»¶æ—¶
                
            except Exception as e:
                print(f"âŒ è·å–ç­›é€‰ç»“æœæ—¶å‡ºé”™: {e}")
                continue
    
    # æ‰“å°ç­›é€‰ç»“æœ
    print(f"\nğŸ“Š ç­›é€‰å®Œæˆï¼")
    print(f"ğŸ“ˆ æ€»è®ºæ–‡æ•°: {len(papers)}")
    print(f"ğŸ¯ ç­›é€‰åè®ºæ–‡æ•°: {len(filtered_papers)}")
    print(f"ğŸš« è¢«æ’é™¤è®ºæ–‡æ•°: {len(excluded_papers)}")
    print(f"ğŸ“Š ç­›é€‰ç‡: {len(filtered_papers)/len(papers)*100:.1f}%")
    
    if filtered_papers:
        print(f"\nğŸ“‹ ç­›é€‰å‡ºçš„è®ºæ–‡:")
        for i, paper in enumerate(filtered_papers[:10], 1):  # åªæ˜¾ç¤ºå‰10ç¯‡
            print(f"{i:2d}. {paper['title']}")
        if len(filtered_papers) > 10:
            print(f"    ... è¿˜æœ‰ {len(filtered_papers) - 10} ç¯‡")
    
    # åˆå¹¶æ–°ç­›é€‰ç»“æœä¸å·²æœ‰ç»“æœ
    all_filtered_papers = existing_filtered + filtered_papers
    all_excluded_papers = existing_excluded + excluded_papers
    
    # ä¿å­˜ç­›é€‰ç»“æœ
    try:
        with open(output_filepath, 'w', encoding='utf-8') as f:
            json.dump(all_filtered_papers, f, ensure_ascii=False, indent=4)
        print(f"\nğŸ’¾ ç­›é€‰ç»“æœå·²ä¿å­˜åˆ°: {output_filepath}")
        print(f"ğŸ“Š æ€»è®¡: {len(all_filtered_papers)} ç¯‡ç­›é€‰é€šè¿‡çš„è®ºæ–‡ (æœ¬æ¬¡æ–°å¢: {len(filtered_papers)} ç¯‡)")
    except Exception as e:
        print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return
    
    # ä¿å­˜è¢«æ’é™¤çš„è®ºæ–‡ï¼ˆç”¨äºäººå·¥å®¡æ ¸ï¼‰
    if all_excluded_papers:
        try:
            with open(excluded_filepath, 'w', encoding='utf-8') as f:
                json.dump(all_excluded_papers, f, ensure_ascii=False, indent=4)
            print(f"ğŸ” è¢«æ’é™¤è®ºæ–‡å·²ä¿å­˜åˆ°: {excluded_filepath} (æ€»è®¡: {len(all_excluded_papers)} ç¯‡)")
        except Exception as e:
            print(f"âŒ ä¿å­˜è¢«æ’é™¤è®ºæ–‡æ—¶å‡ºé”™: {e}")
    
    print("ğŸ‰ ç­›é€‰å®Œæˆï¼")


if __name__ == "__main__":
    main()