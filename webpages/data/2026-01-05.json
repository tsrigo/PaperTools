{"date": "2026-01-05", "categories": [{"name": "Artificial Intelligence", "count": 1, "papers": [{"index": "#26", "title": "CaveAgent: Transforming LLMs into Stateful Runtime Operators", "link": "/arxiv/2601.01569", "arxiv_id": "2601.01569", "authors": "Maohao Ran, Zhenglin Wan, Cooper Lin, Yanting Zhang, Hongyu Xin, Hongwei Fan, Yibo Xu, Beier Luo, Yaxin Zhou, Wangbo Zhao, Lijie Yang, Lang Feng, Fuchao Yang, Jingxuan Wu, Yiqiao Huang, Chendong Ma, Dailing Jiang, Jianbo Deng, Sihui Han, Bo An, Yike Guo, Jun Song", "summary": "LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from \"LLM-as-Text-Generator\" to \"LLM-as-Runtime-Operator.\" We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \\textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\\% success rate improvement on retail tasks and reduces total token consumption by 28.4\\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.", "subjects": "Artificial Intelligence, Software Engineering", "date": "2026-01-04", "category": "cs.AI", "crawl_time": "2026-01-07T11:00:06.343092", "filter_reason": "这篇论文完全符合筛选标准，属于核心研究范围内的“单智能体”方向。 1.  **核心判断**: *   论文的核心贡献是提出了 **CaveAgent**，这是一个新的 **LLM智能体框架**。它旨在解决现有智能体系统在处理长时程任务时面临的上下文漂移和脆弱依赖问题。 *   这不是一篇将现有智能体简单应用到特定领域的应用论文，而是对智能体底层架构和运行机制的改进。 *   它不属于基础设施优化或非Agentic的基础推理研究。 2.  **正面指标匹配**: *   **Agentic AI / LLM-based Agents**: 论文明确致力于改进基于LLM的智能体系统。 *   **Memory (记忆)**: 论文的核心创新点之一是 **Stateful Runtime Management**（有状态运行时管理）。通过注入、操作和检索持久的Python对象（如DataFrames），它构建了一个高保真的 **外部记忆** 机制，以消除上下文漂移和灾难性遗忘。这直接对应了单智能体研究中的“记忆”能力。 *   **Tool Use / Tool Augmentation**: 框架利用代码生成作为工具，通过Python Runtime流来执行任务，超越了传统的JSON函数调用，属于工具使用能力的增强。 *   **Planning (规划)**: 论文提到利用代码生成高效解决相互依赖的子任务（如循环、条件判断），这涉及智能体在复杂任务中的多步规划和执行能力。 3.  **排除标准检查**: *   论文不涉及安全、对齐、多模态视觉或图技术等排除项。 **结论**: 该论文通过引入双流上下文架构和有状态运行时管理，显著增强了LLM智能体的记忆保持和任务执行能力，是对单智能体架构的重要改进，完全符合“构建、改进或演化 LLM智能体”的核心目标。", "summary2": "本文旨在解决传统基于JSON的LLM Agent在长周期任务中面临的上下文漂移和效率低下问题。针对复杂的工具调用和数据处理场景，我们提出了一种名为CaveAgent的框架，采用双流上下文架构和有状态运行时管理，实现对象级交互。我们在Tau 2-bench、BFCL及数据密集型任务上通过成功率和Token消耗验证了其有效性，显著提升了任务表现并降低了成本。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "翻译失败", "summary_generated_time": "2026-01-09 18:28:16", "summary_model": "z-ai/glm-4.7"}]}, {"name": "Computation and Language", "count": 1, "papers": [{"index": "#22", "title": "Agentic Memory: Learning Unified Long-Term and Short-Term Memory Management for Large Language Model Agents", "link": "/arxiv/2601.01885", "arxiv_id": "2601.01885", "authors": "Yi Yu, Liuyi Yao, Yuexiang Xie, Qingquan Tan, Jiaqi Feng, Yaliang Li, Libing Wu", "summary": "Large language model (LLM) agents face fundamental limitations in long-horizon reasoning due to finite context windows, making effective memory management critical. Existing methods typically handle long-term memory (LTM) and short-term memory (STM) as separate components, relying on heuristics or auxiliary controllers, which limits adaptability and end-to-end optimization. In this paper, we propose Agentic Memory (AgeMem), a unified framework that integrates LTM and STM management directly into the agent's policy. AgeMem exposes memory operations as tool-based actions, enabling the LLM agent to autonomously decide what and when to store, retrieve, update, summarize, or discard information. To train such unified behaviors, we propose a three-stage progressive reinforcement learning strategy and design a step-wise GRPO to address sparse and discontinuous rewards induced by memory operations. Experiments on five long-horizon benchmarks demonstrate that AgeMem consistently outperforms strong memory-augmented baselines across multiple LLM backbones, achieving improved task performance, higher-quality long-term memory, and more efficient context usage.", "subjects": "Computation and Language", "date": "2026-01-05", "category": "cs.CL", "crawl_time": "2026-01-07T11:00:05.401131", "filter_reason": "这篇论文完全符合我的研究范围，属于“单智能体”方向的核心研究。 1.  **核心判断（第一步）**：论文的核心贡献是构建了一个名为 \"Agentic Memory (AgeMem)\" 的新框架，旨在解决LLM智能体在长程推理中的记忆管理问题。这属于对LLM智能体内部机制的构建和改进，而非将智能体作为工具应用到特定领域（如医疗、金融），也非基础设施或基础模型能力的提升。 2.  **正面指标匹配（第二步）**： *   **核心范式**：明确属于 `LLM-based Agents` 和 `Agentic AI`。 *   **智能体能力**：论文的核心焦点是 `Memory`（记忆），这是智能体的关键能力之一。同时，它将记忆操作（存储、检索、更新等）定义为 `Tool Use / Tool Augmentation`（基于工具的动作），使智能体能自主决策。 *   **演化机制**：论文提出了一种三阶段渐进式强化学习（RL）策略来训练智能体的记忆管理策略，这涉及智能体通过环境反馈进行 `Self-Improvement`（自我完善）和策略优化。 3.  **排除标准检查（第三步）**：论文不涉及安全对齐、多模态视觉核心或图技术，因此不在排除之列。 综上所述，该论文通过引入统一的记忆管理框架和强化学习训练方法，显著增强了LLM智能体的自主性和适应性，是对Agentic AI核心能力的直接贡献，因此予以保留。", "summary2": "本文旨在解决LLM智能体在长视界推理中因有限上下文窗口导致的记忆管理限制问题。针对LTM和STM分离且依赖启发式规则的现状，我们提出了一种名为Agentic Memory (AgeMem)的统一框架，通过基于工具的动作接口实现端到端的记忆管理，并采用三阶段渐进式RL策略进行训练。在ALFWorld、SciWorld等五个长视界基准测试上，通过Success Rate和Memory Quality等指标验证了其有效性，显著提升了任务性能和记忆质量。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "大语言模型智能体由于上下文窗口有限，在长程推理方面面临根本性局限，这使得有效的记忆管理变得至关重要。现有方法通常将长期记忆和短期记忆视为独立的组件进行处理，并依赖于启发式方法或辅助控制器，这限制了系统的适应性和端到端优化能力。在本文中，我们提出了 Agentic Memory (AgeMem，智能体记忆)，这是一个将长期记忆和短期记忆管理直接整合到智能体策略中的统一框架。AgeMem 将记忆操作呈现为基于工具的动作，使大语言模型智能体能够自主决定存储、检索、更新、总结或丢弃何种信息以及何时执行这些操作。为了训练这种统一行为，我们提出了一种三阶段渐进式强化学习策略，并设计了分步 GRPO，以解决由记忆操作引起的奖励稀疏和不连续问题。在五个长程基准测试上的实验表明，AgeMem 在多种大语言模型骨干网络上始终优于强大的记忆增强基线模型，实现了更优的任务性能、更高质量的长期记忆以及更高效的上下文利用率。", "summary_generated_time": "2026-01-09 18:26:34", "summary_model": "z-ai/glm-4.7"}]}], "overview": "# 今日AI论文速览 (2026-01-05)\n\n生成每日速览时发生错误: Connection error."}