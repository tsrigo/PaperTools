{"date": "2026-01-07", "categories": [{"name": "Artificial Intelligence", "count": 6, "papers": [{"index": "#3", "title": "MobileDreamer: Generative Sketch World Model for GUI Agent", "link": "/arxiv/2601.04035", "arxiv_id": "2601.04035", "authors": "Yilin Cao, Yufeng Zhong, Zhixiong Zeng, Liming Zheng, Jing Huang, Haibo Qiu, Peng Shi, Wenji Mao, Wan Guanglu", "summary": "Mobile GUI agents have shown strong potential in real-world automation and practical applications. However, most existing agents remain reactive, making decisions mainly from current screen, which limits their performance on long-horizon tasks. Building a world model from repeated interactions enables forecasting action outcomes and supports better decision making for mobile GUI agents. This is challenging because the model must predict post-action states with spatial awareness while remaining efficient enough for practical deployment. In this paper, we propose MobileDreamer, an efficient world-model-based lookahead framework to equip the GUI agents based on the future imagination provided by the world model. It consists of textual sketch world model and rollout imagination for GUI agent. Textual sketch world model forecasts post-action states through a learning process to transform digital images into key task-related sketches, and designs a novel order-invariant learning strategy to preserve the spatial information of GUI elements. The rollout imagination strategy for GUI agent optimizes the action-selection process by leveraging the prediction capability of world model. Experiments on Android World show that MobileDreamer achieves state-of-the-art performance and improves task success by 5.25%. World model evaluations further verify that our textual sketch modeling accurately forecasts key GUI elements.", "subjects": "Artificial Intelligence", "date": "2026-01-07", "category": "cs.AI", "crawl_time": "2026-01-09T11:00:09.221593", "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（符合）**： 论文的核心贡献在于提出了 **MobileDreamer**，这是一个基于世界模型的前瞻框架，旨在装备和增强移动 GUI 智能体。它不仅仅是将现有的智能体框架应用到一个新领域，而是针对现有 GUI 智能体“反应式”的局限性，提出了一种新的架构（包含文本草图世界模型和推演想象策略），以提升智能体的决策能力。这属于构建和改进 LLM 智能体的范畴。 2.  **正面指标（符合）**： *   **Agentic AI**: 论文明确聚焦于 GUI Agent 的构建。 *   **Planning**: 论文的核心在于通过世界模型预测行动结果，从而支持智能体进行更好的决策制定和行动选择，这属于智能体规划能力的增强。 3.  **排除标准（未触发）**： *   **多模态与视觉**: 虽然论文涉及处理屏幕图像和生成草图，但这属于“智能体感知环境的工具”。论文的核心贡献不是提出一种新的视觉算法或图像生成模型，而是利用视觉转换来构建辅助智能体规划的“世界模型”。因此，符合“除非它们被用作智能体感知环境的工具”这一例外条款。 4.  **特殊与模糊情况（符合）**： *   **推理/规划**: 论文通过引入世界模型，让智能体能够进行“前瞻”和“想象”，这属于智能体在复杂任务中进行多步推理和规划的高级形式，符合保留条件。 综上所述，该论文通过引入世界模型机制显著增强了单智能体的规划与决策能力，属于 Agentic AI 的核心研究范畴。", "summary2": "本文旨在解决移动GUI代理在长视界任务中缺乏前瞻性规划的问题。针对移动设备屏幕交互场景，我们提出了一种基于文本草图世界模型的高效前瞻框架MobileDreamer。该方法通过文本草图世界模型预测未来状态，并利用推演想象策略构建预测树以优化动作选择。在Android World基准测试上，通过任务成功率（SR）验证了其有效性，显著提升了代理的性能。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "翻译失败", "summary_generated_time": "2026-01-09 19:33:23", "summary_model": "z-ai/glm-4.7"}, {"index": "#20", "title": "SCRIBE: Structured Mid-Level Supervision for Tool-Using Language Models", "link": "/arxiv/2601.03555", "arxiv_id": "2601.03555", "authors": "Yuxuan Jiang, Francis Ferraro", "summary": "Training reliable tool-augmented agents remains a significant challenge, largely due to the difficulty of credit assignment in multi-step reasoning. While process-level reward models offer a promising direction, existing LLM-based judges often produce noisy and inconsistent signals because they lack fine-grained, task-specific rubrics to distinguish high-level planning from low-level execution. In this work, we introduce SCRIBE (Skill-Conditioned Reward with Intermediate Behavioral Evaluation), a reinforcement learning framework that intervenes at a novel mid-level abstraction. SCRIBE grounds reward modeling in a curated library of skill prototypes, transforming open-ended LLM evaluation into a constrained verification problem. By routing each subgoal to a corresponding prototype, the reward model is equipped with precise, structured rubrics that substantially reduce reward variance. Experimental results show that SCRIBE achieves state-of-the-art performance across a range of reasoning and tool-use benchmarks. In particular, it improves the AIME25 accuracy of a Qwen3-4B model from 43.3% to 63.3%, and significantly increases success rates in complex multi-turn tool interactions. Further analysis of training dynamics reveals a co-evolution across abstraction levels, where mastery of mid-level skills consistently precedes the emergence of effective high-level planning behaviors. Finally, we demonstrate that SCRIBE is additive to low-level tool optimizations, providing a scalable and complementary pathway toward more autonomous and reliable tool-using agents.", "subjects": "Artificial Intelligence", "date": "2026-01-07", "category": "cs.AI", "crawl_time": "2026-01-09T11:00:09.227099", "filter_reason": "1.  **核心判断 (第一步)**: *   该论文的核心贡献是提出了 **SCRIBE**，这是一个用于训练**工具增强型智能体** 的强化学习框架。 *   论文明确指出其目标是解决训练可靠智能体时的“信用分配”难题，并致力于提升智能体的“高层规划”和“低层执行”能力。 *   这完全符合“构建、改进或演化 LLM智能体”的核心目标，属于 Agentic AI 的范畴，因此应予以保留。 2.  **正面指标匹配 (第二步)**: *   **智能体能力**: 论文重点涉及 `Tool Use` (工具使用) 和 `Planning` (规划)，特别是区分了高层规划与低层执行。 *   **演化机制**: 摘要中明确提到了“co-evolution across abstraction levels”（跨抽象层的协同演化）以及“emergence of effective high-level planning behaviors”（有效高层规划行为的涌现），这与研究焦点中的“自我演化”高度契合。 3.  **排除标准检查 (第三步)**: *   论文不涉及安全、对齐、多模态视觉或图神经网络等排除领域。 4.  **特殊情况处理 (第四步)**: *   **推理/规划**: 论文虽然涉及推理，但它是通过强化学习框架来训练智能体在多步任务中进行规划和工具使用，属于智能体的架构与训练方法，而非单纯提升LLM基础Token预测能力的数学或逻辑微调，因此符合保留条件。 **结论**: 该论文提出了一种新的训练框架来改进LLM智能体的工具使用和规划能力，并探讨了技能与规划之间的协同演化机制，精准契合“LLM智能体及其演化”的研究课题。", "summary2": "本文旨在解决工具增强模型在多步推理中因信用分配困难导致的训练不可靠问题。针对多步推理和复杂工具交互场景，我们提出了一种SCRIBE框架，利用Skill Prototypes库进行中间层抽象，将开放式LLM评估转化为基于原型的约束验证任务。并在MATH、AIME25和BFCL V4基准上通过准确率和成功率验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "翻译失败", "summary_generated_time": "2026-01-09 19:34:04", "summary_model": "z-ai/glm-4.7"}, {"index": "#2", "title": "ComfySearch: Autonomous Exploration and Reasoning for ComfyUI Workflows", "link": "/arxiv/2601.04060", "arxiv_id": "2601.04060", "authors": "Jinwei Su, Qizhen Lan, Zeyu Wang, Yinghui Xia, Hairu Wen, Yiqun Duan, Xi Xiao, Tianyu Shi, Yang Jingsong, Lewei He", "summary": "AI-generated content has progressed from monolithic models to modular workflows, especially on platforms like ComfyUI, allowing users to customize complex creative pipelines. However, the large number of components in ComfyUI and the difficulty of maintaining long-horizon structural consistency under strict graph constraints frequently lead to low pass rates and workflows of limited quality. To tackle these limitations, we present ComfySearch, an agentic framework that can effectively explore the component space and generate functional ComfyUI pipelines via validation-guided workflow construction. Experiments demonstrate that ComfySearch substantially outperforms existing methods on complex and creative tasks, achieving higher executability (pass) rates, higher solution rates, and stronger generalization.", "subjects": "Artificial Intelligence", "date": "2026-01-07", "category": "cs.AI", "crawl_time": "2026-01-09T11:00:09.221255", "filter_reason": "这篇论文符合我的研究范围，核心依据如下： 1.  **核心贡献符合 Agentic AI 定义 (第一步 & 第二步)**: *   论文明确提出了 \"ComfySearch, an **agentic framework**\"（一个智能体框架）。这不仅仅是将现有的LLM作为工具简单应用，而是构建了一个新的智能体架构来解决特定问题。 *   该框架的核心能力涉及 **Autonomous Exploration**（自主探索）和 **Reasoning**（推理），这直接对应了筛选标准中的“单智能体”方向，特别是 **Planning**（规划）和 **Tool Use**（工具使用，即操作ComfyUI组件）。 2.  **属于智能体规划与构建范畴 (第四步)**: *   论文解决的问题是如何在复杂的图约束下构建长视距的工作流。这属于智能体如何在复杂任务中进行多步规划和决策的研究范畴，而非单纯的LLM基础推理能力提升（如数学或逻辑题）。它关注的是智能体如何通过 \"validation-guided workflow construction\"（验证引导的工作流构建）来完成任务，这是一种典型的 Agentic 行为模式。 3.  **非简单的应用型论文 (第一步 & 第四步)**: *   虽然论文的应用场景是 ComfyUI（一个视觉生成平台），但论文的核心贡献在于**提出了一种能够自主探索组件空间并生成功能性工作流的智能体机制**，而不是仅仅展示LLM在生成图片上的效果。根据第四步的规则，只要核心是提出新的智能体机制（在此处是探索和构建机制），即使应用在特定领域，也应保留。 4.  **排除标准检查 (第三步)**: *   虽然涉及视觉内容生成，但论文的研究焦点不在于改进视觉模型本身，而在于控制生成流程的智能体框架，因此不属于被排除的“多模态与视觉”核心研究。 *   不涉及安全、对齐或基础设施问题。 综上所述，该论文提出了一种新的智能体框架来解决复杂的规划和构建问题，属于 Agentic AI 的核心研究范畴。", "summary2": "本文旨在解决ComfyUI工作流生成中因组件复杂和图约束严格导致的低通过率和质量问题。针对ComfyUI工作流构建场景，我们提出了一种名为ComfySearch的智能体框架，采用Reasoning-as-action范式，结合State-aware validation和In-place repair确保结构正确性，并引入Entropy-adaptive branching处理长视距不确定性。我们在ComfyBench和GenEval上通过%Pass、%Resolve及GenEval分数验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "AI生成内容已从单体模型演进至模块化工作流，特别是在 ComfyUI 等平台上，使用户能够定制复杂的创意流水线。然而，ComfyUI 中组件数量庞大，且在严格的图约束下难以保持长视距结构一致性，这往往导致通过率低下且生成的工作流质量有限。为解决上述局限性，我们提出了 ComfySearch，这是一个智能体框架，能够通过验证引导的工作流构建，有效探索组件空间并生成功能完备的 ComfyUI 流水线。实验表明，在复杂和创意任务中，ComfySearch 的性能显著优于现有方法，实现了更高的可执行性（通过）率、更高的解决率以及更强的泛化能力。", "summary_generated_time": "2026-01-09 19:35:14", "summary_model": "z-ai/glm-4.7"}, {"index": "#17", "title": "Architecting Agentic Communities using Design Patterns", "link": "/arxiv/2601.03624", "arxiv_id": "2601.03624", "authors": "Zoran Milosevic, Fethi Rabhi", "summary": "The rapid evolution of Large Language Models (LLM) and subsequent Agentic AI technologies requires systematic architectural guidance for building sophisticated, production-grade systems. This paper presents an approach for architecting such systems using design patterns derived from enterprise distributed systems standards, formal methods, and industry practice. We classify these patterns into three tiers: LLM Agents (task-specific automation), Agentic AI (adaptive goal-seekers), and Agentic Communities (organizational frameworks where AI agents and human participants coordinate through formal roles, protocols, and governance structures). We focus on Agentic Communities - coordination frameworks encompassing LLM Agents, Agentic AI entities, and humans - most relevant for enterprise and industrial applications. Drawing on established coordination principles from distributed systems, we ground these patterns in a formal framework that specifies collaboration agreements where AI agents and humans fill roles within governed ecosystems. This approach provides both practical guidance and formal verification capabilities, enabling expression of organizational, legal, and ethical rules through accountability mechanisms that ensure operational and verifiable governance of inter-agent communication, negotiation, and intent modeling. We validate this framework through a clinical trial matching case study. Our goal is to provide actionable guidance to practitioners while maintaining the formal rigor essential for enterprise deployment in dynamic, multi-agent ecosystems.", "subjects": "Artificial Intelligence", "date": "2026-01-07", "category": "cs.AI", "crawl_time": "2026-01-09T11:00:09.226129", "filter_reason": "这篇论文完全符合筛选标准，属于“多智能体”方向的核心研究。 1.  **核心判断（第一步）**：论文的核心贡献在于提出了一种用于构建“Agentic Communities”（智能体社区）的架构方法和设计模式。这不仅仅是将LLM作为工具应用，而是构建了一个包含LLM智能体、Agentic AI实体和人类的复杂多智能体系统框架。它定义了智能体社区的组织结构、角色和协议，属于构建和改进LLM智能体系统的方法论。 2.  **正面指标匹配（第二步）**： *   **核心范式**：论文明确涉及 `Agentic AI` 和 `Multi-Agent Systems (MAS)`，特别是提出了“Agentic Communities”这一概念。 *   **多智能体能力**：摘要中详细讨论了智能体之间以及智能体与人类之间的 `Coordination`（协调）、`Communication`（通信）、`Negotiation`（谈判）以及 `Governance`（治理）机制。这些都是多智能体系统研究中的核心议题。 3.  **排除标准检查（第三步）**： *   虽然论文提到了“法律和伦理规则”以及“问责机制”，但其主要贡献是**架构框架**，而非单纯的安全算法或对齐技术研究。 *   虽然使用了“临床试验匹配”作为案例研究，但这仅用于验证框架的有效性，论文本质并非解决医疗领域的特定问题，而是提供通用的系统架构指导。 综上所述，该论文为构建复杂的多智能体协作系统提供了新的架构视角和设计模式，直接契合研究课题中关于“多智能体”的焦点，因此予以保留。", "summary2": "本文旨在为构建生产级Agentic AI系统提供系统的架构指导。针对多智能体协调与治理的挑战，我们提出了一种基于ODP Enterprise Language (ODP-EL) 形式主义的设计模式框架，涵盖LLM Agents、Agentic AI及Agentic Communities三类模式。我们在临床试验匹配案例中验证了其有效性，实现了可验证的治理属性与问责机制。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "大语言模型 (Large Language Models, LLM) 及随后的 Agentic AI（智能体 AI）技术的快速演进，为构建复杂的、生产级系统提出了系统化架构指导的需求。本文提出了一种架构此类系统的方法，该方法采用了源于企业分布式系统标准、形式化方法和行业实践的设计模式。我们将这些模式划分为三个层级：LLM Agents（大语言模型智能体，即特定任务的自动化）、Agentic AI（智能体 AI，即自适应的目标寻求者）以及 Agentic Communities（智能体社区，即 AI 智能体和人类参与者通过正式角色、协议和治理结构进行协调的组织框架）。我们重点关注 Agentic Communities——这是一种包含 LLM Agents、Agentic AI 实体和人类的协调框架——其与企业及工业应用最为相关。借鉴分布式系统中既定的协调原则，我们将这些模式建立在一个形式框架之上，该框架明确了协作协议，规定了 AI 智能体和人类如何在受治理的生态系统中承担特定角色。该方法不仅提供了实用指导，还具备形式化验证能力，能够通过问责机制来表达组织、法律和伦理规则，从而确保对智能体间通信、谈判和意图建模进行可操作且可验证的治理。我们通过一项临床试验匹配的案例研究验证了该框架。我们的目标是为从业者提供切实可行的指导，同时保持企业部署在动态多智能体生态系统中所必需的形式严谨性。", "summary_generated_time": "2026-01-09 19:36:57", "summary_model": "z-ai/glm-4.7"}, {"index": "#29", "title": "Enhancing LLM Instruction Following: An Evaluation-Driven Multi-Agentic Workflow for Prompt Instructions Optimization", "link": "/arxiv/2601.03359", "arxiv_id": "2601.03359", "authors": "Alberto Purpura, Li Wang, Sahil Badyal, Eugenio Beaufrand, Adam Faulkner", "summary": "Large Language Models (LLMs) often generate substantively relevant content but fail to adhere to formal constraints, leading to outputs that are conceptually correct but procedurally flawed. Traditional prompt refinement approaches focus on rephrasing the description of the primary task an LLM has to perform, neglecting the granular constraints that function as acceptance criteria for its response. We propose a novel multi-agentic workflow that decouples optimization of the primary task description from its constraints, using quantitative scores as feedback to iteratively rewrite and improve them. Our evaluation demonstrates this method produces revised prompts that yield significantly higher compliance scores from models like Llama 3.1 8B and Mixtral-8x 7B.", "subjects": "Artificial Intelligence", "date": "2026-01-06", "category": "cs.AI", "crawl_time": "2026-01-09T11:00:09.230116", "filter_reason": "这篇论文完全符合我的研究范围，属于“多智能体”和“自我演化”方向的交叉研究。 1.  **核心判断（符合）**：论文的核心贡献是提出了一种“新颖的多智能体工作流”，用于优化提示词指令。这属于构建和改进 LLM 智能体系统的方法论研究，而非将现有智能体简单应用到特定垂直领域（如医疗、金融）。 2.  **正面指标匹配**： *   **多智能体**：标题和摘要中明确提到了“Multi-Agentic Workflow”，涉及多个智能体协同工作。 *   **自我演化/自我完善**：论文描述了使用“定量分数作为反馈来迭代地重写和改进”提示词，这符合自我演化中的“迭代改进”和“自我修正”机制。 *   **智能体能力**：该工作流体现了智能体的规划（解耦任务描述与约束）和工具使用（利用评估分数）能力。 3.  **排除标准检查**： *   论文不涉及安全、对齐、多模态视觉或图技术等排除项。 *   虽然目标是“指令遵循”，但其手段是构建一个多智能体系统，这属于 Agentic AI 的范畴，而非单纯的非 Agentic 推理或数据集构建。 综上所述，该论文通过构建多智能体协作框架来实现任务的自我迭代优化，精准契合我对“LLM智能体及其演化”的研究课题。", "summary2": "本文旨在解决 LLMs 难以严格遵守输出约束的问题。针对 InfoBench 数据集，我们提出了一种 evaluation-driven multi-agentic workflow，将任务描述与约束解耦，并利用定量反馈迭代优化约束。我们在 Llama 3.1 8B 和 Mixtral-8x 7B 上通过 compliance scores 验证了其有效性，显著提升了模型的指令遵循能力。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "大语言模型 (Large Language Models, LLMs) 虽然常能生成实质相关的内容，但往往未能遵守形式约束 (formal constraints)，从而导致输出结果在概念上正确，但在程序上存在缺陷。传统的提示词优化 (prompt refinement) 方法主要侧重于改写大语言模型需执行的主要任务描述，而忽视了那些作为响应验收标准 (acceptance criteria) 的细粒度约束 (granular constraints)。我们提出了一种新颖的多智能体工作流 (multi-agentic workflow)，该工作流将主要任务描述的优化与其约束解耦，并利用定量分数 (quantitative scores) 作为反馈，对二者进行迭代重写和改进。我们的评估表明，该方法生成的修订提示词能够使 Llama 3.1 8B 和 Mixtral-8x 7B 等模型产生显著更高的合规分数 (compliance scores)。", "summary_generated_time": "2026-01-09 19:36:24", "summary_model": "z-ai/glm-4.7"}, {"index": "#24", "title": "Evolving Programmatic Skill Networks", "link": "/arxiv/2601.03509", "arxiv_id": "2601.03509", "authors": "Haochen Shi, Xingdi Yuan, Bang Liu", "summary": "We study continual skill acquisition in open-ended embodied environments where an agent must construct, refine, and reuse an expanding library of executable skills. We introduce the Programmatic Skill Network (PSN), a framework in which skills are executable symbolic programs forming a compositional network that evolves through experience. PSN defines three core mechanisms instantiated via large language models: (1)REFLECT for structured fault localization over skill compositions, (2) progressive optimization with maturity-aware update gating that stabilizes reliable skills while maintaining plasticity for uncertain ones, and (3) canonical structural refactoring under rollback validation that maintains network compactness. We further show that PSN's learning dynamics exhibit structural parallels to neural network training. Experiments on MineDojo and Crafter demonstrate robust skill reuse, rapid adaptation, and strong generalization across open-ended task distributions.\\footnote{We plan to open-source the code.", "subjects": "Artificial Intelligence, Neural and Evolutionary Computing", "date": "2026-01-07", "category": "cs.AI", "crawl_time": "2026-01-09T11:00:09.228393", "filter_reason": "这篇论文完全符合研究范围，属于“自我演化”和“单智能体”方向的交叉研究。 1.  **核心贡献符合“自我演化”**: 论文提出了 Programmatic Skill Network (PSN) 框架，其核心在于智能体如何通过经验构建、细化和重用技能库。摘要中明确指出技能库是“evolves through experience”（通过经验演化），并包含“progressive optimization”（渐进式优化）和“structural refactoring”（结构重构）等机制，这直接对应了筛选标准中的“Self-Evolving”、“Self-Improvement”和“Iterative Improvement”。 2.  **具备核心智能体能力**: 论文详细描述了智能体的自我反思和自我修正能力。具体而言，它利用 LLM 实例化了“REFLECT”机制进行结构化故障定位，以及“成熟度感知更新门控”来平衡技能的稳定性与可塑性。这符合筛选标准中的“Self-Correction”、“Self-Reflection”和“Memory”（技能库作为长期记忆）。 3.  **符合特殊处理规则**: 尽管论文是在 MineDojo 和 Crafter（具身/游戏环境）中进行实验，但根据第四步的规则，只要论文的核心贡献是提出一种新的“自我演化”机制（即 PSN 框架），即使应用在特定领域，也应予以保留。该论文并非单纯将 LLM 应用于游戏，而是提出了一套通用的技能演化算法。 综上所述，该论文不仅涉及 LLM 智能体的构建，更深入探讨了智能体如何通过反思和反馈实现自我演化和技能积累，高度契合“LLM智能体及其演化”的研究课题。", "summary2": "本文旨在解决开放具身环境中智能体持续获取、细化和重用技能的问题。针对开放任务流，我们提出了一种Programmatic Skill Network (PSN)框架，通过REFLECT机制进行结构化故障定位、成熟度感知更新门控及规范化结构重构，实现技能网络的持续演化。并在MineDojo和Crafter环境上通过技术树掌握迭代次数、累积奖励及技能保持率验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "翻译失败", "summary_generated_time": "2026-01-09 19:37:41", "summary_model": "z-ai/glm-4.7"}]}, {"name": "Computation and Language", "count": 4, "papers": [{"index": "#35", "title": "Membox: Weaving Topic Continuity into Long-Range Memory for LLM Agents", "link": "/arxiv/2601.03785", "arxiv_id": "2601.03785", "authors": "Dehao Tao, Guoliang Ma, Yongfeng Huang, Minghu Jiang", "summary": "Human-agent dialogues often exhibit topic continuity-a stable thematic frame that evolves through temporally adjacent exchanges-yet most large language model (LLM) agent memory systems fail to preserve it. Existing designs follow a fragmentation-compensation paradigm: they first break dialogue streams into isolated utterances for storage, then attempt to restore coherence via embedding-based retrieval. This process irreversibly damages narrative and causal flow, while biasing retrieval towards lexical similarity. We introduce membox, a hierarchical memory architecture centered on a Topic Loom that continuously monitors dialogue in a sliding-window fashion, grouping consecutive same-topic turns into coherent \"memory boxes\" at storage time. Sealed boxes are then linked by a Trace Weaver into long-range event-timeline traces, recovering macro-topic recurrences across discontinuities. Experiments on LoCoMo demonstrate that Membox achieves up to 68% F1 improvement on temporal reasoning tasks, outperforming competitive baselines (e.g., Mem0, A-MEM). Notably, Membox attains these gains while using only a fraction of the context tokens required by existing methods, highlighting a superior balance between efficiency and effectiveness. By explicitly modeling topic continuity, Membox offers a cognitively motivated mechanism for enhancing both coherence and efficiency in LLM agents.", "subjects": "Computation and Language, Artificial Intelligence", "date": "2026-01-07", "category": "cs.CL", "crawl_time": "2026-01-09T11:00:08.978708", "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（第一步）：** 论文的核心贡献是提出了一种名为 \"Membox\" 的分层记忆架构，旨在解决 LLM 智能体在长程记忆中保持主题连续性的问题。这属于对 LLM 智能体核心组件（记忆系统）的构建与改进，而非将智能体作为工具应用到特定领域（非演化型应用），也非基础设施或基础模型推理能力的提升。 2.  **正面指标匹配（第二步）：** *   **核心范式：** 论文明确聚焦于 `LLM-based Agents`。 *   **智能体能力：** 论文的核心贡献点在于 `Memory`（记忆）。它通过引入 \"Topic Loom\" 和 \"Trace Weaver\" 等机制，优化了智能体存储和检索对话历史的能力，这直接对应了筛选标准中单智能体方向下的“记忆”子方向。 3.  **排除标准检查（第三步）：** 论文不涉及安全与对齐、多模态视觉技术或图神经网络，因此未触犯任何排除规则。 4.  **总结：** 该论文致力于通过改进记忆机制来增强 LLM 智能体的连贯性和效率，属于单智能体研究中对基础能力（记忆）的深化，完全符合“构建、改进 LLM 智能体”的核心目标。", "summary2": "本文旨在解决现有LLM Agent记忆系统因碎片化存储导致的话题连续性丢失问题。针对长对话场景，我们提出了一种名为Membox的分层记忆架构，利用Topic Loom将连续同话题对话分组为“记忆盒”，并通过Trace Weaver链接宏观话题以恢复事件时间线。我们在LoCoMo数据集上通过F1和BLEU指标验证了其有效性，在Temporal Reasoning任务上实现了高达68%的F1提升，且显著降低了上下文Token消耗。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "人机对话通常表现出话题连续性——一种通过时间上相邻的交互演变的稳定主题框架——然而大多数大语言模型 (LLM) 智能体记忆系统未能保留这一特性。现有设计遵循一种碎片化-补偿范式：它们首先将对话流分解为孤立的话语进行存储，然后试图通过基于嵌入的检索来重建连贯性。这一过程不可逆地破坏了叙事和因果流，同时导致检索偏向于词汇相似性。我们介绍了 membox，这是一种以 Topic Loom (话题编织器) 为中心的分层记忆架构，它以滑动窗口的方式持续监控对话，在存储时将连续的同一话题轮次分组为连贯的“记忆盒”。封装后的记忆盒随后由 Trace Weaver (轨迹编织器) 链接成长程事件时间轴轨迹，从而跨越对话间隔恢复宏观话题的重现。在 LoCoMo 数据集上的实验表明，Membox 在时序推理任务上实现了高达 68% 的 F1 值提升，优于竞争性基线模型（如 Mem0, A-MEM）。值得注意的是，Membox 在仅使用现有方法所需的一小部分上下文 token 的情况下取得了这些提升，突显了其在效率与有效性之间取得了卓越的平衡。通过显式建模话题连续性，Membox 为增强 LLM 智能体的连贯性和效率提供了一种受认知启发的机制。", "summary_generated_time": "2026-01-09 19:29:52", "summary_model": "z-ai/glm-4.7"}, {"index": "#58", "title": "Agent-Dice: Disentangling Knowledge Updates via Geometric Consensus for Agent Continual Learning", "link": "/arxiv/2601.03641", "arxiv_id": "2601.03641", "authors": "Zheng Wu, Xingyu Lou, Xinbei Ma, Yansi Li, Weiwen Liu, Weinan Zhang, Jun Wang, Zhuosheng Zhang", "summary": "Large Language Model (LLM)-based agents significantly extend the utility of LLMs by interacting with dynamic environments. However, enabling agents to continually learn new tasks without catastrophic forgetting remains a critical challenge, known as the stability-plasticity dilemma. In this work, we argue that this dilemma fundamentally arises from the failure to explicitly distinguish between common knowledge shared across tasks and conflicting knowledge introduced by task-specific interference. To address this, we propose Agent-Dice, a parameter fusion framework based on directional consensus evaluation. Concretely, Agent-Dice disentangles knowledge updates through a two-stage process: geometric consensus filtering to prune conflicting gradients, and curvature-based importance weighting to amplify shared semantics. We provide a rigorous theoretical analysis that establishes the validity of the proposed fusion scheme and offers insight into the origins of the stability-plasticity dilemma. Extensive experiments on GUI agents and tool-use agent domains demonstrate that Agent-Dice exhibits outstanding continual learning performance with minimal computational overhead and parameter updates.", "subjects": "Computation and Language", "date": "2026-01-07", "category": "cs.CL", "crawl_time": "2026-01-09T11:00:09.000273", "filter_reason": "这篇论文完全符合我的研究范围，属于“自我演化”方向的核心论文。 1.  **核心贡献判断 (第一步)**: 论文的核心贡献是提出了 **Agent-Dice**，这是一个专门用于解决 **LLM智能体持续学习** 问题的参数融合框架。它旨在解决智能体在动态环境中学习新任务时遇到的“灾难性遗忘”和“稳定性-可塑性困境”。这直接对应了我研究目标中的“自我演化”，即智能体通过经验、反思或环境反馈进行自我完善和迭代。这不是将智能体作为工具的应用，而是对智能体底层学习机制的改进。 2.  **符合正面指标 (第二步)**: *   **核心范式**: 论文明确关注 `LLM-based Agents`。 *   **演化机制**: 论文的核心主题是 `Continual Learning`（持续学习），这是 `Self-Evolving`（自我演化）的重要组成部分。它涉及 `Knowledge Updates`（知识更新）和 `Iterative Improvement`（迭代改进）。 *   **智能体能力**: 论文在 `GUI agents` 和 `tool-use agents` 领域进行了验证，体现了智能体与环境的交互能力。 3.  **排除标准检查 (第三步)**: *   论文不涉及安全、对齐或水印问题。 *   虽然提到了 GUI agents（可能涉及视觉），但视觉仅作为智能体感知环境的工具，而非研究的核心（核心是参数融合和持续学习算法），因此不违反多模态排除规则。 *   不涉及图技术。 4.  **特殊情况处理 (第四步)**: 论文提出了一种新的“自我演化”机制（通过几何共识和曲率加权实现持续学习），即使它在特定的 GUI 或工具使用领域进行了实验，根据规则“如果论文的核心是提出一种新的‘自我演化’机制……也应该保留”，这篇论文应当被保留。 综上所述，Agent-Dice 通过改进智能体的知识更新机制，实现了智能体在连续任务中的自我演化，精准契合“LLM智能体及其演化”这一课题。", "summary2": "本文旨在解决LLM智能体持续学习中的稳定性-可塑性困境。针对GUI和工具使用智能体场景，我们提出了一种基于方向一致性评估的参数融合框架Agent-Dice，通过几何一致性过滤和基于曲率的重要性加权解耦知识更新。在AITZ、AndroidControl、GUI-Odyssey和ToolACE数据集上，通过平均Z-score等指标验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "基于 Large Language Model (LLM) 的 agents（智能体）通过与动态环境交互，显著扩展了 LLMs 的效用。然而，使 agents 能够在不发生 catastrophic forgetting（灾难性遗忘）的情况下持续学习新任务，仍然是一个关键挑战，即所谓的 stability-plasticity dilemma（稳定性-可塑性困境）。在这项工作中，我们认为这一困境根本源于未能明确区分跨任务共享的 common knowledge（通用知识）与由 task-specific interference（任务特定干扰）引入的 conflicting knowledge（冲突知识）。为解决这一问题，我们提出了 Agent-Dice，这是一种基于 directional consensus evaluation（方向一致性评估）的 parameter fusion framework（参数融合框架）。具体而言，Agent-Dice 通过两阶段过程解耦知识更新：利用 geometric consensus filtering（几何一致性过滤）剪枝 conflicting gradients（冲突梯度），并利用 curvature-based importance weighting（基于曲率的重要性加权）增强 shared semantics（共享语义）。我们提供了严格的理论分析，确立了所提出的 fusion scheme（融合方案）的有效性，并深入探讨了 stability-plasticity dilemma（稳定性-可塑性困境）的起源。在 GUI agents（图形用户界面智能体）和 tool-use agent（工具使用智能体）领域的大量实验表明，Agent-Dice 展现出了卓越的 continual learning performance（持续学习性能），且仅需极少的 computational overhead（计算开销）和 parameter updates（参数更新）。", "summary_generated_time": "2026-01-09 19:29:54", "summary_model": "z-ai/glm-4.7"}, {"index": "#108", "title": "DeepResearch-Slice: Bridging the Retrieval-Utilization Gap via Explicit Text Slicing", "link": "/arxiv/2601.03261", "arxiv_id": "2601.03261", "authors": "Shuo Lu, Yinuo Xu, Jianjie Cheng, Lingxiao He, Meng Wang, Jian Liang", "summary": "Deep Research agents predominantly optimize search policies to maximize retrieval probability. However, we identify a critical bottleneck: the retrieval-utilization gap, where models fail to use gold evidence even after it is retrieved, due to context blindness in noisy environments. To bridge this gap, we propose DeepResearch-Slice, a simple yet effective neuro-symbolic framework. Unlike implicit attention, our approach predicts precise span indices to perform a deterministic hard filter before reasoning. Extensive evaluations across six benchmarks show substantial robustness gains. Applying our method to frozen backbones yields a 73 percent relative improvement, from 19.1 percent to 33.0 percent, effectively mitigating noise without requiring parameter updates to the reasoning model. These results highlight the need for explicit grounding mechanisms in open-ended research.", "subjects": "Computation and Language, Artificial Intelligence", "date": "2025-12-16", "category": "cs.CL", "crawl_time": "2026-01-09T11:00:09.085498", "filter_reason": "1.  **核心判断**: 论文明确以 \"Deep Research agents\"（深度研究智能体）为研究对象，提出了 DeepResearch-Slice 这一神经符号框架。这属于构建和改进 LLM 智能体的方法论，符合“单智能体”的研究范畴。 2.  **正面指标**: 论文涉及智能体的核心能力，特别是工具使用后的信息处理。它解决了智能体在嘈杂环境中利用检索证据的瓶颈，改进了智能体的推理鲁棒性，属于对智能体内部机制的优化。 3.  **排除标准**: 论文不涉及安全、对齐、多模态或图技术；也不是针对特定垂直领域（如生物、金融）的单纯应用，而是提出了通用的改进框架。 4.  **特殊处理**: 虽然涉及推理，但这是在智能体框架下对“检索-利用”过程的改进，而非单纯提升模型的基础数学或逻辑预测能力，因此不属于“非Agentic的推理”。", "summary2": "本文旨在解决Deep Research中模型因上下文盲区无法利用已检索证据的Retrieval-Utilization Gap问题。针对噪声环境下的检索文档，我们提出了一种名为DeepResearch-Slice的神经符号框架，通过预测精确的span索引执行显式文本切片和硬过滤。在六个基准测试上，通过任务准确率验证了其有效性，在冻结骨干网络上实现了73%的相对性能提升。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "Deep Research agents (深度研究智能体) 主要致力于优化 search policies (搜索策略)，以最大化 retrieval probability (检索概率)。然而，我们发现了一个关键瓶颈：retrieval-utilization gap (检索-利用差距)，即由于 noisy environments (噪声环境) 中的 context blindness (上下文盲区)，模型即使在成功检索到 gold evidence (黄金证据) 后，仍无法有效利用这些证据。为弥合这一差距，我们提出了 DeepResearch-Slice，这是一个简单而有效的 neuro-symbolic framework (神经符号框架)。与 implicit attention (隐式注意力) 机制不同，我们的方法通过预测精确的 span indices (片段索引)，在 reasoning (推理) 过程之前执行 deterministic hard filter (确定性硬过滤)。在六个 benchmarks (基准测试) 上进行的广泛评估表明，该方法带来了显著的 robustness gains (鲁棒性提升)。将该方法应用于 frozen backbones (冻结骨干网络) 时，实现了 73% 的相对性能提升（从 19.1% 提升至 33.0%），有效缓解了噪声干扰，且无需对 reasoning model (推理模型) 进行 parameter updates (参数更新)。这些结果凸显了在 open-ended research (开放式研究) 中引入 explicit grounding mechanisms (显式定位机制) 的必要性。", "summary_generated_time": "2026-01-09 19:32:29", "summary_model": "z-ai/glm-4.7"}, {"index": "#116", "title": "Current Agents Fail to Leverage World Model as Tool for Foresight", "link": "/arxiv/2601.03905", "arxiv_id": "2601.03905", "authors": "Cheng Qian, Emre Can Acikgoz, Bingxuan Li, Xiusi Chen, Yuji Zhang, Bingxiang He, Qinyu Luo, Dilek Hakkani-Tür, Gokhan Tur, Yunzhu Li, Heng Ji, Heng Ji", "summary": "Agents built on vision-language models increasingly face tasks that demand anticipating future states rather than relying on short-horizon reasoning. Generative world models offer a promising remedy: agents could use them as external simulators to foresee outcomes before acting. This paper empirically examines whether current agents can leverage such world models as tools to enhance their cognition. Across diverse agentic and visual question answering tasks, we observe that some agents rarely invoke simulation (fewer than 1%), frequently misuse predicted rollouts (approximately 15%), and often exhibit inconsistent or even degraded performance (up to 5%) when simulation is available or enforced. Attribution analysis further indicates that the primary bottleneck lies in the agents' capacity to decide when to simulate, how to interpret predicted outcomes, and how to integrate foresight into downstream reasoning. These findings underscore the need for mechanisms that foster calibrated, strategic interaction with world models, paving the way toward more reliable anticipatory cognition in future agent systems.", "subjects": "Artificial Intelligence, Computation and Language, Machine Learning", "date": "2026-01-07", "category": "cs.CL", "crawl_time": "2026-01-09T11:00:09.095223", "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（第一步）**：论文的核心贡献在于实证研究LLM智能体如何利用“世界模型”作为外部工具来进行“前瞻”规划。这直接属于“单智能体”研究范畴中的“工具使用”和“规划”能力。虽然论文主要揭示了当前智能体的局限性（即未能有效利用），但其目的是为了指导未来构建具有更强认知能力的智能体系统，属于对智能体构建和改进机制的探索，而非单纯的应用。 2.  **正面指标匹配（第二步）**：论文高度符合核心关注点。 *   **Agentic AI**: 明确以“Agents”为研究对象。 *   **Tool Use / Tool Augmentation**: 研究的核心是智能体如何将生成式世界模型作为“外部模拟器”工具来使用。 *   **Planning**: 论文聚焦于“anticipating future states”（前瞻）和“foresight”，这是智能体规划能力的高级形式。 3.  **排除标准与特殊情况处理（第三、四步）**： *   **多模态问题**: 尽管摘要提到了“vision-language models”和“visual question answering”，但视觉内容在此处是智能体感知的环境或工具（世界模型）的一部分，而非论文的研究核心。论文的核心在于智能体与该工具的交互机制，而非改进视觉模型本身，因此符合“作为工具使用”的例外情况。 *   **推理/规划**: 论文讨论的是智能体如何通过模拟进行多步推理和决策，属于Agentic层面的规划，而非单纯的LLM内部逻辑推理优化。 综上所述，该论文深入探讨了单智能体在工具使用和前瞻规划方面的关键问题，对构建和改进LLM智能体具有直接的指导意义，完全符合“单智能体”方向的研究目标。", "summary2": "本文旨在探究当前智能体利用世界模型进行前瞻认知的能力。针对多样化的智能体决策和视觉问答任务，我们提出了一种“世界模型即工具”的评估框架，并在FrozenLake、Navigation等任务及VQA基准上通过成功率、准确率和调用率验证了其有效性。研究发现当前智能体很少调用世界模型，且强制使用会降低性能，核心瓶颈在于前瞻治理机制。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "翻译失败", "summary_generated_time": "2026-01-09 19:33:56", "summary_model": "z-ai/glm-4.7"}]}, {"name": "Multiagent Systems", "count": 2, "papers": [{"index": "#3", "title": "LLM-Enabled Multi-Agent Systems: Empirical Evaluation and Insights into Emerging Design Patterns & Paradigms", "link": "/arxiv/2601.03328", "arxiv_id": "2601.03328", "authors": "Harri Renney, Maxim N Nethercott, Nathan Renney, Peter Hayes", "summary": "This paper formalises the literature on emerging design patterns and paradigms for Large Language Model (LLM)-enabled multi-agent systems (MAS), evaluating their practical utility across various domains. We define key architectural components, including agent orchestration, communication mechanisms, and control-flow strategies, and demonstrate how these enable rapid development of modular, domain-adaptive solutions. Three real-world case studies are tested in controlled, containerised pilots in telecommunications security, national heritage asset management, and utilities customer service automation. Initial empirical results show that, for these case studies, prototypes were delivered within two weeks and pilot-ready solutions within one month, suggesting reduced development overhead compared to conventional approaches and improved user accessibility. However, findings also reinforce limitations documented in the literature, including variability in LLM behaviour that leads to challenges in transitioning from prototype to production maturity. We conclude by outlining critical research directions for improving reliability, scalability, and governance in MAS architectures and the further work needed to mature MAS design patterns to mitigate the inherent challenges.", "subjects": "Multiagent Systems", "date": "2026-01-06", "category": "cs.MA", "crawl_time": "2026-01-09T11:00:08.133653", "filter_reason": "1.  **核心判断 (符合)**: 论文的核心贡献在于形式化了LLM驱动的多智能体系统（MAS）的设计模式和范式，并定义了包括智能体编排、通信机制和控制流策略在内的关键架构组件。这属于“构建”和“改进”LLM智能体（特别是多智能体系统）的方法论研究，符合第一步中关于保留“构建LLM智能体”或“多智能体系统”方法论的要求。 2.  **正面指标 (匹配)**: 论文明确涉及 `Multi-Agent Systems (MAS)` 这一核心范式，并深入探讨了 `Agent Orchestration`（智能体编排）和 `Communication mechanisms`（通信机制），这些都是多智能体研究中的关键能力和正面指标。 3.  **排除标准 (未触发)**: *   **非演化型应用**: 尽管论文使用了电信、遗产管理等领域的案例研究，但其主要目的不是为了解决这些领域的具体业务问题，而是为了评估MAS架构和设计模式的实用性及开发效率。因此，它不属于仅将LLM作为工具应用到特定领域的“非演化型应用”。 *   **安全与对齐**: 论文虽然提到了治理和可靠性，但这并非其核心贡献，核心在于系统架构和设计模式。 *   **多模态与视觉**: 论文未涉及视觉或多模态内容。 4.  **综合结论**: 该论文提供了关于如何构建、设计和评估多智能体系统的实证见解和架构框架，直接服务于“LLM智能体及其演化”中关于多智能体方向的研究目标。", "summary2": "本文旨在形式化LLM赋能的多智能体系统（MAS）的设计模式并评估其实用性。针对电信安全、国家遗产资产管理和公用事业客户服务等真实场景，我们提出了一种基于ReAct智能体和动态编排的MAS设计范式，并在三个受控的容器化试点项目中通过开发周期、利益相关者反馈及UAT评分验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "翻译失败", "summary_generated_time": "2026-01-09 19:30:42", "summary_model": "z-ai/glm-4.7"}, {"index": "#1", "title": "When Numbers Start Talking: Implicit Numerical Coordination Among LLM-Based Agents", "link": "/arxiv/2601.03846", "arxiv_id": "2601.03846", "authors": "Alessio Buscemi, Daniele Proverbio, Alessandro Di Stefano, The Anh Han, German Castignani, Pietro Liò", "summary": "LLMs-based agents increasingly operate in multi-agent environments where strategic interaction and coordination are required. While existing work has largely focused on individual agents or on interacting agents sharing explicit communication, less is known about how interacting agents coordinate implicitly. In particular, agents may engage in covert communication, relying on indirect or non-linguistic signals embedded in their actions rather than on explicit messages. This paper presents a game-theoretic study of covert communication in LLM-driven multi-agent systems. We analyse interactions across four canonical game-theoretic settings under different communication regimes, including explicit, restricted, and absent communication. Considering heterogeneous agent personalities and both one-shot and repeated games, we characterise when covert signals emerge and how they shape coordination and strategic outcomes.", "subjects": "Multiagent Systems, Artificial Intelligence", "date": "2026-01-07", "category": "cs.MA", "crawl_time": "2026-01-09T11:00:08.133016", "filter_reason": "这篇论文完全符合筛选标准，属于“多智能体”方向的核心研究。 1.  **核心判断（第一步）**：论文的本质是研究 LLM 智能体在多智能体环境中的行为机制。它不是将智能体作为工具去解决生物、医疗等特定领域的应用问题，而是深入探讨智能体之间如何进行“隐式协调”和“隐蔽通信”。这属于构建和理解多智能体系统（Multi-Agent Systems）的方法论研究，因此应予以保留。 2.  **正面指标匹配（第二步）**： *   **核心范式**：明确涉及 `Multi-Agent Systems (MAS)`。 *   **多智能体能力**：论文重点研究了智能体间的 `Communication`（特别是非显式的、隐蔽的通信）和 `Collaboration`（协调）。 *   **博弈与互动**：通过博弈论设置分析智能体间的战略互动，这属于多智能体研究中的社会行为和博弈范畴。 3.  **排除标准检查（第三步）**：论文不涉及安全对齐、多模态视觉或图技术等排除项。 **总结**：该论文的核心贡献在于揭示了 LLM 智能体在缺乏显式语言通道时，如何通过行动（如数字信号）进行隐式协调。这直接拓展了对于多智能体通信机制和协作行为的理解，符合“多智能体”这一研究焦点。", "summary2": "本文旨在探究LLM智能体在多智能体环境中的隐式通信与协调机制。针对四种经典博弈论场景（Prisoner's Dilemma等），我们提出了一种基于数值序列的隐式通信机制，并在FAIRGAME框架下通过GPT-4o智能体进行了实验。通过分析不同通信条件下的合作水平与熵值，验证了隐式信号能产生结构化模式并有效影响战略结果。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "基于LLMs（大语言模型）的智能体越来越多地在需要strategic interaction（策略互动）和协调的multi-agent environments（多智能体环境）中运行。尽管现有工作主要集中在个体智能体或共享explicit communication（显式通信）的交互智能体上，但对于交互智能体如何进行隐式协调的研究尚不充分。特别是，智能体可能会进行covert communication（隐蔽通信），即依赖于嵌入在其行动中的间接或非语言信号，而非显式消息。本文对LLM驱动的多智能体系统中的隐蔽通信进行了game-theoretic（博弈论）研究。我们分析了在不同communication regimes（通信机制）下，包括显式、受限和缺失通信，四种典型博弈论设定中的互动。考虑到heterogeneous agent personalities（异构智能体人格）以及one-shot games（单次博弈）和repeated games（重复博弈），我们刻画了隐蔽信号何时涌现，以及它们如何塑造协调和策略结果。", "summary_generated_time": "2026-01-09 19:29:07", "summary_model": "z-ai/glm-4.7"}]}], "overview": "# 今日AI论文速览 (2026-01-07)\n\n生成每日速览时发生错误: Connection error."}