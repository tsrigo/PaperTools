{"date": "2026-01-06", "categories": [{"name": "Artificial Intelligence", "count": 7, "papers": [{"index": "#1", "title": "MAGMA: A Multi-Graph based Agentic Memory Architecture for AI Agents", "link": "/arxiv/2601.03236", "arxiv_id": "2601.03236", "authors": "Dongming Jiang, Yi Li, Guanpeng Li, Bingzhe Li", "summary": "Memory-Augmented Generation (MAG) extends Large Language Models with external memory to support long-context reasoning, but existing approaches largely rely on semantic similarity over monolithic memory stores, entangling temporal, causal, and entity information. This design limits interpretability and alignment between query intent and retrieved evidence, leading to suboptimal reasoning accuracy. In this paper, we propose MAGMA, a multi-graph agentic memory architecture that represents each memory item across orthogonal semantic, temporal, causal, and entity graphs. MAGMA formulates retrieval as policy-guided traversal over these relational views, enabling query-adaptive selection and structured context construction. By decoupling memory representation from retrieval logic, MAGMA provides transparent reasoning paths and fine-grained control over retrieval. Experiments on LoCoMo and LongMemEval demonstrate that MAGMA consistently outperforms state-of-the-art agentic memory systems in long-horizon reasoning tasks.", "subjects": "Artificial Intelligence", "date": "2026-01-06", "category": "cs.AI", "crawl_time": "2026-01-08T11:00:05.383657", "filter_reason": "1.  **核心判断符合 (第一步)**: 该论文的核心贡献是提出了一种名为 MAGMA 的“智能体记忆架构”。这属于构建和改进 LLM 智能体的方法论范畴，旨在解决智能体在长视界推理中的记忆检索和表示问题。它不是将现有智能体简单应用于特定领域，也不是单纯的基础设施优化，而是直接针对智能体核心组件（记忆）的架构创新。 2.  **包含核心关注点 (第二步)**: 论文明确涉及 `Agentic AI` 和 `LLM-based Agents` 的核心能力——`Memory`（记忆）。它探讨了如何通过多图结构（语义、时间、因果、实体）来优化智能体的记忆存储和检索，从而提升推理能力。这完全符合单智能体方向中关于“记忆”机制的子方向。 3.  **排除标准检查 (第三步)**: *   **安全与对齐**: 虽然摘要提到了“alignment between query intent and retrieved evidence”（查询意图与检索证据的对齐），但这指的是信息检索层面的语义匹配，而非 AI 安全领域的“对齐”。论文主要贡献不在于 Safety 或 Alignment。 *   **多模态与视觉**: 论文未涉及视觉或多模态内容。 *   **图**: 尽管论文使用了“Multi-Graph”（多图）技术，但这是作为实现智能体记忆架构的**手段**，而非研究图算法本身。论文的主题是“Agentic Memory Architecture”，属于智能体研究，因此不应被排除。 综上所述，这篇论文通过改进智能体的记忆机制来提升其性能，属于构建和演化 LLM 智能体的核心研究范围，符合筛选标准。", "summary2": "本文旨在解决现有Memory-Augmented Generation系统因依赖单一语义相似度而限制长时程推理准确性和可解释性的问题。针对长上下文推理场景，我们提出了一种名为MAGMA的多图智能体记忆架构，通过语义、时间、因果和实体四个正交关系图解耦记忆表示，并采用策略引导的图遍历进行检索。在LoCoMo和LongMemEval数据集上通过LLM-as-a-Judge、F1及系统延迟等指标验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "Memory-Augmented Generation (MAG，记忆增强生成) 通过引入外部记忆扩展了大语言模型，以支持长上下文推理。然而，现有方法主要依赖于单一整体记忆存储上的语义相似度，导致时间、因果和实体信息相互纠缠。这种设计限制了可解释性以及查询意图与检索证据之间的对齐，从而导致推理准确率不理想。在本文中，我们提出了 MAGMA，这是一种多图智能体记忆架构，它在正交的语义、时间、因果和实体图中表示每个记忆项。MAGMA 将检索过程构建为在这些关系视图上的策略引导遍历，从而实现查询自适应的选择和结构化上下文构建。通过将记忆表示与检索逻辑解耦，MAGMA 提供了透明的推理路径以及对检索过程的细粒度控制。在 LoCoMo 和 LongMemEval 数据集上的实验表明，MAGMA 在长视界推理任务中始终优于最先进的智能体记忆系统。", "summary_generated_time": "2026-01-09 18:57:01", "summary_model": "z-ai/glm-4.7"}, {"index": "#7", "title": "Batch-of-Thought: Cross-Instance Learning for Enhanced LLM Reasoning", "link": "/arxiv/2601.02950", "arxiv_id": "2601.02950", "authors": "Xuan Yang, Furong Jia, Roy Xie, Xiong Xi, Hengwei Bian, Jian Li, Monica Agrawal", "summary": "Current Large Language Model reasoning systems process queries independently, discarding valuable cross-instance signals such as shared reasoning patterns and consistency constraints. We introduce Batch-of-Thought (BoT), a training-free method that processes related queries jointly to enable cross-instance learning. By performing comparative analysis across batches, BoT identifies high-quality reasoning templates, detects errors through consistency checks, and amortizes computational costs. We instantiate BoT within a multi-agent reflection architecture (BoT-R), where a Reflector performs joint evaluation to unlock mutual information gain unavailable in isolated processing. Experiments across three model families and six benchmarks demonstrate that BoT-R consistently improves accuracy and confidence calibration while reducing inference costs by up to 61%. Our theoretical and experimental analysis reveals when and why batch-aware reasoning benefits LLM systems.", "subjects": "Artificial Intelligence", "date": "2026-01-06", "category": "cs.AI", "crawl_time": "2026-01-08T11:00:05.388304", "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（符合 Agentic AI 范畴）**： 虽然论文标题侧重于“推理”，但其核心贡献不仅仅是提出一种新的思维链变体，而是构建了一个名为 **BoT-R (Batch-of-Thought with Reflection)** 的架构。摘要明确指出，该方法是在 **\"multi-agent reflection architecture\"（多智能体反思架构）** 中实例化的。这表明论文的本质是构建了一个包含特定角色（Reflector 智能体）的智能体系统，而非单纯的模型推理能力提升。 2.  **符合正面指标（多智能体与自我反思）**： *   **多智能体**：论文明确提到了 \"multi-agent reflection architecture\"，涉及智能体之间的协作与信息交互（Reflector 执行联合评估以解锁互信息增益）。 *   **自我反思/修正**：论文的核心机制涉及 \"reflection\"（反思）和 \"detects errors\"（检测错误），这属于智能体的自我反思和自我修正能力范畴。 *   **Agentic 框架**：BoT-R 是一种新的 Agentic 框架，用于处理复杂任务，符合“构建、改进 LLM 智能体”的目标。 3.  **排除标准检查**： *   该论文不属于特定领域的非演化型应用（如医疗、法律），而是一种通用的推理架构改进。 *   虽然涉及推理，但它通过多智能体架构来实现，不属于“非 Agentic 的推理”排除项。 *   不涉及安全、对齐、多模态或图等排除领域。 综上所述，该论文通过引入多智能体反思架构来增强 LLM 的推理能力，属于 Agentic AI 和 Multi-Agent Systems 的研究范畴，符合筛选要求。", "summary2": "本文旨在解决现有LLM推理系统独立处理查询导致跨实例信号丢失的问题。针对相关查询批次，我们提出了一种名为Batch-of-Thought (BoT) 的免训练方法，利用Reflector进行联合评估以实现跨实例学习。在六个基准和三个模型家族上，通过准确率、置信度校准和Token成本验证了其有效性，实现了性能提升和高达61%的成本降低。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "当前的 Large Language Model (大语言模型) 推理系统独立处理查询，忽略了诸如共享推理模式和一致性约束等有价值的 cross-instance signals (跨实例信号)。我们提出了 Batch-of-Thought (BoT)，这是一种 training-free (无需训练) 的方法，通过联合处理相关查询来实现 cross-instance learning (跨实例学习)。通过在批次间执行 comparative analysis (比较分析)，BoT 能够识别高质量的 reasoning templates (推理模板)，通过 consistency checks (一致性检查) 检测错误，并分摊 computational costs (计算成本)。我们在 multi-agent reflection architecture (多智能体反思架构) 中实例化了 BoT (BoT-R)，其中 Reflector (反思者) 执行 joint evaluation (联合评估)，以释放 isolated processing (孤立处理) 中无法获得的 mutual information gain (互信息增益)。在三个模型系列和六个基准测试上的实验表明，BoT-R 在将 inference costs (推理成本) 降低高达 61% 的同时，持续提高了 accuracy (准确性) 和 confidence calibration (置信度校准)。我们的理论和实验分析揭示了 batch-aware reasoning (批感知推理) 在何时以及为何能使 Large Language Model (大语言模型) 系统受益。", "summary_generated_time": "2026-01-09 18:58:22", "summary_model": "z-ai/glm-4.7"}, {"index": "#19", "title": "Learning User Preferences Through Interaction for Long-Term Collaboration", "link": "/arxiv/2601.02702", "arxiv_id": "2601.02702", "authors": "Shuhaib Mehri, Priyanka Kargupta, Tal August, Dilek Hakkani-Tür", "summary": "As conversational agents accumulate experience collaborating with users, adapting to user preferences is essential for fostering long-term relationships and improving collaboration quality over time. We introduce MultiSessionCollab, a benchmark that evaluates how well agents can learn user preferences and leverage them to improve collaboration quality throughout multiple sessions. To develop agents that succeed in this setting, we present long-term collaborative agents equipped with a memory that persists and refines user preference as interaction experience accumulates. Moreover, we demonstrate that learning signals can be derived from user simulator behavior in MultiSessionCollab to train agents to generate more comprehensive reflections and update their memory more effectively. Extensive experiments show that equipping agents with memory improves long-term collaboration, yielding higher task success rates, more efficient interactions, and reduced user effort. Finally, we conduct a human user study that demonstrates that memory helps improve user experience in real-world settings.", "subjects": "Artificial Intelligence", "date": "2026-01-06", "category": "cs.AI", "crawl_time": "2026-01-08T11:00:05.394842", "filter_reason": "这篇论文完全符合我的研究范围，属于“单智能体”与“自我演化”的交叉领域。 1.  **核心贡献符合要求**：论文的核心在于构建了一种“长期协作智能体”，并提出了相应的基准测试。这不仅仅是应用现有模型，而是提出了一种新的智能体框架，旨在解决智能体如何适应环境（用户）的问题。 2.  **符合“单智能体”方向**：论文明确聚焦于智能体的关键能力——**记忆**和**自我反思**。它详细描述了如何通过持久化的记忆来存储用户偏好，以及如何通过反思机制来更新记忆，这直接对应筛选标准中的“Agentic: 记忆、自我反思”。 3.  **符合“自我演化”方向**：论文强调智能体随着交互经验的积累，能够不断细化用户偏好并改进协作质量。这种通过经验反馈进行迭代改进和自我完善的过程，正是“自我演化”的核心体现。 4.  **排除标准检查**：论文不属于特定领域的非演化型应用（其核心是智能体机制的通用改进），也不涉及安全对齐、多模态或图技术等排除领域。 综上所述，该论文在构建具备记忆和自我演化能力的LLM智能体方面做出了实质性贡献，应予保留。", "summary2": "本文旨在解决对话代理在多会话协作中学习并利用用户偏好以提升协作质量的问题。针对多会话协作问题求解场景，我们提出了一种配备持久化记忆的长期协作代理及基于强化学习的记忆更新框架，并在MULTI SESSION COLLAB基准上通过Task Success、User Effort和Conversation Length验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "随着 conversational agents (对话智能体) 积累与用户协作的经验，适应用户偏好对于建立长期关系以及随着时间的推移提升协作质量至关重要。我们介绍了 MultiSessionCollab，这是一个 benchmark (基准测试)，旨在评估智能体在跨多个会话的过程中学习用户偏好并利用这些偏好提升协作质量的能力。为了开发能够在此类场景中取得成功的智能体，我们提出了 long-term collaborative agents (长期协作智能体)，该智能体配备了 memory (记忆)，能够随着交互经验的积累而持久保存并细化用户偏好。此外，我们证明了可以从 MultiSessionCollab 中的 user simulator (用户模拟器) 行为中提取 learning signals (学习信号)，从而训练智能体生成更全面的 reflections (反思内容) 并更有效地更新其 memory (记忆)。大量实验表明，为智能体配备 memory (记忆) 能够改善长期协作效果，从而带来更高的任务成功率、更高效的交互以及更低的用户负担。最后，我们进行了一项人类用户研究，结果表明 memory (记忆) 有助于在真实场景中提升用户体验。", "summary_generated_time": "2026-01-09 18:59:39", "summary_model": "z-ai/glm-4.7"}, {"index": "#22", "title": "AWARE-US: Benchmark for Preference-Aware Resolution in Tool-Calling Agents", "link": "/arxiv/2601.02643", "arxiv_id": "2601.02643", "authors": "Mehmet Kurmaz", "summary": "Tool-calling conversational agents querying structured databases often face two linked failures: underspecification (missing constraints needed to run a precise query) and infeasibility (the fully specified query returns an empty set because no item satisfies all constraints). Existing work often responds with \"no results\" or relaxes constraints using ad hoc rules, which can violate user intent by discarding requirements the user cares about most. We frame infeasibility handling as a preference-aware query repair problem: when a query is unsatisfiable, the agent should relax the least important constraints to the user. We propose three LLM-based methods for inferring relative constraint importance from dialogue: (1) local weighting, (2) global one-shot weighting, and (3) pairwise ranking. Experiments show local weighting achieves the best preference alignment, while global weighting performs best on correct constraint relaxation. We also introduce AWARE-US, a benchmark of persona-grounded queries requiring agents to disambiguate requests via conversation and resolve infeasibility in a way consistent with persona-implied preferences.", "subjects": "Artificial Intelligence", "date": "2026-01-06", "category": "cs.AI", "crawl_time": "2026-01-08T11:00:05.396220", "filter_reason": "这篇论文完全符合我的研究范围，属于“单智能体”方向中的“工具使用”和“规划”子方向。 1.  **核心判断 (第一步)**: *   论文的核心贡献在于提出了一种新的方法论（偏好感知查询修复）和一个基准（AWARE-US），旨在解决“工具调用智能体”在查询结构化数据库时遇到的“不可行性”问题。 *   这不是将智能体简单应用于特定领域（如医疗或金融）的应用型论文，而是针对智能体在工具使用过程中的通用能力缺陷（查询失败处理）进行改进和构建。 *   它不属于基础设施优化，也不是非Agentic的基础推理提升。 2.  **正面指标匹配 (第二步)**: *   论文明确涉及 `LLM-based Agents` 和 `Tool Use / Tool Augmentation`。 *   它关注智能体如何根据对话上下文推断用户意图，并动态调整查询策略（放松约束），这属于智能体的 `Planning` 和决策能力范畴。 3.  **排除标准检查 (第三步)**: *   虽然论文提到了“preference alignment”（偏好对齐），但这里的对齐是指智能体在执行任务时对用户具体约束条件的偏好（例如用户更看重价格还是速度），而非AI安全、伦理或价值观层面的“对齐”。因此，不应被排除。 *   论文不涉及多模态视觉、图技术或安全防御机制。 4.  **特殊处理 (第四步)**: *   论文关于智能体如何处理工具调用失败并进行自我修正（查询修复），属于Agentic的推理与规划范畴，符合保留条件。 综上所述，该论文致力于改进LLM智能体的工具使用鲁棒性和交互规划能力，符合“构建、改进LLM智能体”的核心目标。", "summary2": "本文旨在解决Tool-calling agents在查询结构化数据库时面临的infeasibility问题。针对基于personas的对话场景，我们提出了一种Preference-Aware Resolution框架，包含local weighting、global one-shot weighting和pairwise ranking三种约束重要性推断方法。我们在AWARE-US benchmark上通过Relax match和Car match等指标验证了其有效性，结果显示Local weighting方法在汽车推荐中与用户偏好一致性达到48%。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "调用工具查询结构化数据库的对话代理通常面临两个相互关联的问题：underspecification（约束不足，即缺乏运行精确查询所需的约束）和 infeasibility（不可行性，即完全指定的查询返回空集，因为没有项目满足所有约束）。现有研究通常以“无结果”作为回应，或利用 ad hoc rules（特设规则）放宽约束，这可能会因丢弃用户最关心的需求而违背用户意图。我们将 infeasibility handling（不可行性处理）构建为一个 preference-aware query repair（感知偏好的查询修复）问题：当查询不可满足时，代理应当放宽对用户而言重要性最低的约束。我们提出了三种基于 LLM（大语言模型）的方法，用于从对话中推断相对约束重要性：(1) local weighting（局部加权），(2) global one-shot weighting（全局一次性加权），以及 (3) pairwise ranking（成对排序）。实验结果表明，local weighting（局部加权）实现了最佳的 preference alignment（偏好对齐），而 global weighting（全局加权）在正确的 constraint relaxation（约束放宽）方面表现最佳。我们还介绍了 AWARE-US，这是一个包含 persona-grounded queries（基于人设的查询）的基准数据集，要求代理通过对话消除请求歧义，并以与 persona-implied preferences（人设隐含偏好）一致的方式解决 infeasibility（不可行性）。", "summary_generated_time": "2026-01-09 18:59:20", "summary_model": "z-ai/glm-4.7"}, {"index": "#25", "title": "SimpleMem: Efficient Lifelong Memory for LLM Agents", "link": "/arxiv/2601.02553", "arxiv_id": "2601.02553", "authors": "Jiaqi Liu, Yaofeng Su, Peng Xia, Siwei Han, Zeyu Zheng, Cihang Xie, Mingyu Ding, Huaxiu Yao", "summary": "To support reliable long-term interaction in complex environments, LLM agents require memory systems that efficiently manage historical experiences. Existing approaches either retain full interaction histories via passive context extension, leading to substantial redundancy, or rely on iterative reasoning to filter noise, incurring high token costs. To address this challenge, we introduce SimpleMem, an efficient memory framework based on semantic lossless compression. We propose a three-stage pipeline designed to maximize information density and token utilization: (1) \\textit{Semantic Structured Compression}, which applies entropy-aware filtering to distill unstructured interactions into compact, multi-view indexed memory units; (2) \\textit{Recursive Memory Consolidation}, an asynchronous process that integrates related units into higher-level abstract representations to reduce redundancy; and (3) \\textit{Adaptive Query-Aware Retrieval}, which dynamically adjusts retrieval scope based on query complexity to construct precise context efficiently. Experiments on benchmark datasets show that our method consistently outperforms baseline approaches in accuracy, retrieval efficiency, and inference cost, achieving an average F1 improvement of 26.4% while reducing inference-time token consumption by up to 30-fold, demonstrating a superior balance between performance and efficiency. Code is available at https://github.com/aiming-lab/SimpleMem.", "subjects": "Artificial Intelligence", "date": "2026-01-05", "category": "cs.AI", "crawl_time": "2026-01-08T11:00:05.397879", "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（第一步）**： *   论文的核心贡献是提出了 **SimpleMem**，这是一个专门为 **LLM智能体** 设计的高效记忆框架。 *   它属于 **构建/改进 LLM智能体** 的范畴，旨在解决智能体在长期交互中的记忆管理问题，而非将智能体作为工具应用到特定领域（如医疗、金融等），也不是关于基础设施或硬件加速的研究。 2.  **正面指标匹配（第二步）**： *   论文直接涉及 **Agentic AI** 和 **LLM-based Agents** 的核心范式。 *   论文重点解决了智能体的 **Memory（记忆）** 能力，这是单智能体方向的关键子方向之一。摘要中提到的“管理历史经验”、“语义结构化压缩”和“递归记忆整合”都是为了增强智能体的记忆机制，使其能更好地支持长期交互。 3.  **排除标准检查（第三步）**： *   论文不涉及安全、对齐、多模态视觉或图技术等排除项。 综上所述，该论文致力于改进LLM智能体的核心组件（记忆系统），属于单智能体研究范畴，符合“构建、改进或演化 LLM智能体”的核心目标。", "summary2": "本文旨在解决LLM Agent在长期交互中因上下文限制和冗余信息导致的记忆管理低效问题。针对复杂环境下的长上下文交互场景，我们提出了一种基于语义无损压缩的SimpleMem框架，包含语义结构化压缩、递归记忆整合和自适应查询感知检索三阶段流程。我们在LoCoMo benchmark上通过F1 score和Token Cost验证了其有效性，实现了平均F1提升26.4%且推理Token消耗降低30倍。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "为了在复杂环境中支持可靠的长期交互，LLM agents（大语言模型智能体）需要能够高效管理历史经验的 memory systems（记忆系统）。现有方法要么通过 passive context extension（被动上下文扩展）保留完整的交互历史，导致大量冗余，要么依赖 iterative reasoning（迭代推理）来过滤噪声，从而产生高昂的 token costs（Token 成本）。为了应对这一挑战，我们提出了 SimpleMem，这是一种基于 semantic lossless compression（语义无损压缩）的高效 memory framework（记忆框架）。我们提出了一个旨在最大化 information density（信息密度）和 token utilization（Token 利用率）的 three-stage pipeline（三阶段流水线）：(1) \\textit{Semantic Structured Compression}（语义结构化压缩），该阶段应用 entropy-aware filtering（熵感知过滤）将非结构化交互提炼为紧凑的 multi-view indexed memory units（多视图索引记忆单元）；(2) \\textit{Recursive Memory Consolidation}（递归记忆整合），这是一个异步过程，将相关单元整合为 higher-level abstract representations（高层抽象表示）以减少冗余；以及 (3) \\textit{Adaptive Query-Aware Retrieval}（自适应查询感知检索），该阶段根据 query complexity（查询复杂度）动态调整 retrieval scope（检索范围），以高效构建精确的上下文。在 benchmark datasets（基准数据集）上的实验表明，我们的方法在准确性、retrieval efficiency（检索效率）和 inference cost（推理成本）方面始终优于 baseline approaches（基线方法），实现了平均 26.4% 的 F1 提升，同时将 inference-time token consumption（推理时 Token 消耗）减少了多达 30 倍，展示了性能与效率之间的卓越平衡。代码可在 https://github.com/aiming-lab/SimpleMem 获取。", "summary_generated_time": "2026-01-09 18:59:23", "summary_model": "z-ai/glm-4.7"}, {"index": "#88", "title": "Agentic Memory Enhanced Recursive Reasoning for Root Cause Localization in Microservices", "link": "/arxiv/2601.02732", "arxiv_id": "2601.02732", "authors": "Lingzhe Zhang, Tong Jia, Yunpeng Zhai, Leyi Pan, Chiming Duan, Minghua He, Mengxi Jia, Ying Li", "summary": "As contemporary microservice systems become increasingly popular and complex-often comprising hundreds or even thousands of fine-grained, interdependent subsystems-they are experiencing more frequent failures. Ensuring system reliability thus demands accurate root cause localization. While many traditional graph-based and deep learning approaches have been explored for this task, they often rely heavily on pre-defined schemas that struggle to adapt to evolving operational contexts. Consequently, a number of LLM-based methods have recently been proposed. However, these methods still face two major limitations: shallow, symptom-centric reasoning that undermines accuracy, and a lack of cross-alert reuse that leads to redundant reasoning and high latency. In this paper, we conduct a comprehensive study of how Site Reliability Engineers (SREs) localize the root causes of failures, drawing insights from professionals across multiple organizations. Our investigation reveals that expert root cause analysis exhibits three key characteristics: recursiveness, multi-dimensional expansion, and cross-modal reasoning. Motivated by these findings, we introduce AMER-RCL, an agentic memory enhanced recursive reasoning framework for root cause localization in microservices. AMER-RCL employs the Recursive Reasoning RCL engine, a multi-agent framework that performs recursive reasoning on each alert to progressively refine candidate causes, while Agentic Memory incrementally accumulates and reuses reasoning from prior alerts within a time window to reduce redundant exploration and lower inference latency. Experimental results demonstrate that AMER-RCL consistently outperforms state-of-the-art methods in both localization accuracy and inference efficiency.", "subjects": "Software Engineering, Artificial Intelligence", "date": "2026-01-06", "category": "cs.AI", "crawl_time": "2026-01-08T11:00:05.454481", "filter_reason": "这篇论文符合筛选标准，应予以保留。判断依据如下： 1.  **核心贡献符合“构建LLM智能体”的目标**： 尽管论文的应用场景是微服务中的根因定位（特定领域），但其核心贡献并非简单地将现有LLM作为工具应用，而是提出了一个新的框架 **AMER-RCL**。该框架包含两个关键的智能体组件： *   **Recursive Reasoning RCL engine**：明确被定义为一个**多智能体框架**，用于执行递归推理。 *   **Agentic Memory**：一种智能体记忆机制，用于增量累积和重用推理过程。 2.  **高度匹配“正面指标”**： *   **多智能体**：论文明确提出了多智能体框架来处理告警和细化候选原因。 *   **智能体能力**：涉及 `Memory`（智能体记忆）、`Reasoning`（递归推理）以及 `Multi-Agent` 协作。 *   **核心范式**：论文标题和摘要中多次强调 \"Agentic Memory\" 和 \"Agentic\"，完全符合 Agentic AI 的研究焦点。 3.  **通过“排除标准”和“特殊情况”检查**： *   虽然涉及特定领域（微服务），但根据第四步的“自我演化的应用”逻辑（此处虽非演化，但同理），如果论文的核心是提出一种新的智能体机制（如这里的递归推理+记忆机制），即使应用在特定领域，也应保留。这区别于仅仅调用API解决领域问题的“非演化型应用”。 *   论文不涉及安全、对齐、多模态视觉或图神经网络等排除内容。 综上所述，该论文在构建多智能体框架和智能体记忆机制方面做出了实质性贡献，属于 Agentic AI 和 Multi-Agent Systems 的前沿研究。", "summary2": "本文旨在解决现有LLM方法在微服务根因定位中推理浅显及缺乏跨告警复用的问题。针对微服务系统中的多告警场景，我们提出了一种名为AMER-RCL的智能体记忆增强递归推理框架。该框架利用递归推理引擎进行深度分析，并通过智能体记忆复用历史推理结果。在AIOPS 2022、Train-Ticket和FAMOS-Mall数据集上，通过Recall@k、MRR及推理延迟验证了其有效性，显著优于现有方法。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "随着当代微服务系统日益普及且日趋复杂——通常由数百甚至数千个细粒度、相互依赖的子系统组成——其故障发生频率也随之增加。因此，确保系统可靠性需要准确的根因定位。尽管针对该任务已探索了许多传统的基于图和深度学习的方法，但它们往往严重依赖预定义模式，难以适应不断演变的运行环境。因此，近期提出了多种基于大语言模型的方法。然而，这些方法仍面临两大主要局限：一是浅层的、以症状为中心的推理损害了准确性；二是缺乏跨告警重用，导致推理冗余和高延迟。本文对站点可靠性工程师如何定位故障根因进行了全面研究，汲取了来自多个组织的专业人士的见解。调查结果显示，专家根因分析表现出三个关键特征：递归性、多维扩展和跨模态推理。基于这些发现，我们提出了 AMER-RCL，一种用于微服务根因定位的智能体记忆增强递归推理框架。AMER-RCL 采用了递归推理 RCL 引擎，这是一个多智能体框架，通过对每个告警执行递归推理来逐步细化候选原因；同时，智能体记忆增量地积累并重用时间窗口内先前告警的推理结果，以减少冗余探索并降低推理延迟。实验结果表明，AMER-RCL 在定位准确性和推理效率方面均持续优于最先进的方法。", "summary_generated_time": "2026-01-09 19:00:50", "summary_model": "z-ai/glm-4.7"}, {"index": "#118", "title": "The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance", "link": "/arxiv/2601.02454", "arxiv_id": "2601.02454", "authors": "Saba Naqvi, Mohammad Baqar, Nawaz Ali Mohammad", "summary": "Software testing has progressed toward intelligent automation, yet current AI-based test generators still suffer from static, single-shot outputs that frequently produce invalid, redundant, or non-executable tests due to the lack of execution aware feedback. This paper introduces an agentic multi-model testing framework a closed-loop, self-correcting system in which a Test Generation Agent, an Execution and Analysis Agent, and a Review and Optimization Agent collaboratively generate, execute, analyze, and refine tests until convergence. By using sandboxed execution, detailed failure reporting, and iterative regeneration or patching of failing tests, the framework autonomously improves test quality and expands coverage. Integrated into a CI/CD-compatible pipeline, it leverages reinforcement signals from coverage metrics and execution outcomes to guide refinement. Empirical evaluations on microservice based applications show up to a 60% reduction in invalid tests, 30% coverage improvement, and significantly reduced human effort compared to single-model baselines demonstrating that multi-agent, feedback-driven loops can evolve software testing into an autonomous, continuously learning quality assurance ecosystem for self-healing, high-reliability codebases.", "subjects": "Software Engineering, Artificial Intelligence", "date": "2026-01-05", "category": "cs.AI", "crawl_time": "2026-01-08T11:00:05.468007", "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心贡献符合“多智能体”与“自我演化”方向**： 论文的核心贡献是提出了一种“智能体多模型测试框架”。这不仅仅是一个应用，而是一个新的**多智能体系统（MAS）**架构。该系统包含三个具有不同角色的智能体（测试生成、执行与分析、审查与优化），它们通过协作完成任务，这直接对应了筛选标准中的“多智能体”方向。 2.  **具备明确的“自我演化”机制**： 摘要中明确提到这是一个“闭环、自我修正系统”，利用“沙箱执行”和“强化信号”进行“迭代再生或修补”。这种通过环境反馈（执行结果、覆盖率指标）来引导智能体自主改进和迭代的过程，完全符合“自我演化”中关于自我完善、自我修正和迭代改进的定义。 3.  **属于Agentic AI的构建而非单纯应用**： 虽然论文的应用场景是软件测试（特定领域），但根据筛选标准第四步的“自我演化的应用”例外规则，只要论文的核心是提出一种新的“自我演化”机制或Agentic框架，即使应用在特定领域也应保留。本文重点在于构建了一个能够自主规划、协作和反思的智能体框架，而非简单地将现有LLM作为工具生成测试代码。 综上所述，该论文在多智能体协作、自我修正机制以及闭环演化方面具有明确的方法论贡献，符合“LLM智能体及其演化”的研究课题。", "summary2": "本文旨在解决现有AI测试生成缺乏执行反馈导致测试无效的问题。针对微服务应用，我们提出了一种Agentic Testing Architecture (ATA)，即包含Test Generation Agent、Execution and Analysis Agent和Review and Optimization Agent的多智能体闭环协作框架。在开源及企业应用数据集上，通过代码覆盖率、无效测试率和人工工作量等指标验证了其有效性，实现了无效测试减少60%及覆盖率提升30%。", "inspiration_trace": "基于论文《The Rise of Agentic Testing: Multi-Agent Systems for Robust Software Quality Assurance》，以下是对作者产出该核心方法逻辑链的系统性推演，旨在还原其从宏观观察到微观实现的思考过程：\n\n### 1. 宏观背景：软件复杂性与自动化瓶颈\n**观察：**\n现代软件工程已转向云原生、微服务架构和DevOps模式，代码迭代速度极快，依赖关系复杂。传统的手工测试或基于规则的自动化脚本已无法跟上这种交付节奏，成为效率瓶颈。\n\n**思考：**\n必须引入更高阶的智能化手段。近年来，大语言模型（LLMs）在代码理解和生成方面表现出色，似乎为解决这一瓶颈提供了契机。学术界和工业界开始尝试利用LLMs自动生成测试用例。\n\n### 2. 核心痛点：LLM的“静态生成”与“执行盲区”\n**深入观察：**\n尽管现有的基于LLM的测试生成工具（如Codex, GPT-4）能够快速产出代码，但作者发现了一个关键问题：**这些生成是“一次性”的**。LLM像是在真空中写作，它不知道生成的代码在真实环境中能否运行。\n\n**逻辑断层：**\n实证数据显示，超过40%的LLM生成的测试用例在首次执行时就会失败（如缺少依赖、语法错误、逻辑不匹配）。这是因为现有方法缺乏“执行感知”的反馈机制。LLM无法从自己的错误中学习，导致产生了大量无效、冗余的垃圾代码，反而增加了人工清理的成本。\n\n**假设提出：**\n如果能让测试生成系统具备“自我反省”和“自我修正”的能力，即像人类测试人员一样——写代码 -> 运行 -> 报错 -> 修改 -> 再运行，那么测试的质量和有效性将大幅提升。\n\n### 3. 概念跃迁：从“单点工具”到“多智能体协作”\n**灵感来源：**\n作者观察到AI领域正在兴起“Agentic AI”（智能体AI）和多智能体系统（如AutoGen, SWE-Agent）。这些系统通过让多个专门的AI角色相互协作、对话来解决复杂任务，而非依赖单一模型。\n\n**类比推理：**\n软件测试本身就是一个团队协作过程：有人写测试，有人执行测试，有人分析结果。为什么不让AI也模仿这种社会分工？\n\n**方法论雏形：**\n不再使用一个单一的LLM模型完成所有工作，而是设计一个**多智能体系统**。将测试流程拆解为不同的专业角色，让它们各司其职，形成一个流水线。\n\n### 4. 方法论构建：闭环反馈与收敛机制\n**架构设计：**\n为了实现上述假设，作者构建了三个核心智能体，形成了一个闭环：\n1.  **生成者：** 负责根据需求编写初始测试。\n2.  **执行者：** 负责在沙盒环境中运行测试，并收集覆盖率数据和报错信息。\n3.  **审查与优化者：** 负责分析执行结果，诊断失败原因，并指导生成者进行修复。\n\n**逻辑核心：**\n这个系统的核心不在于单个智能体的能力，而在于它们之间的**交互循环**。作者引入了“收敛”的概念：系统不是无限循环，而是设定了明确的停止条件（如覆盖率>95%，失败率<2%）。这将其从简单的“尝试”转变为一种“优化过程”。\n\n**关键创新点：**\n作者意识到，只有当“执行反馈”被转化为“自然语言指令”并重新输入给LLM时，真正的自我修正才发生。因此，必须建立一个共享的记忆库，让智能体能记住之前的错误，避免重蹈覆辙。\n\n### 5. 最终愿景：迈向自主演进的QA生态系统\n**验证与结论：**\n通过实验，作者验证了这种多智能体闭环模式确实能显著降低无效测试比例，提高覆盖率。这证明了“反馈驱动”优于“静态生成”。\n\n**思想升华：**\n最终，作者将这一方法定义为“Agentic Testing”。这不仅仅是一个工具，而是一个**自主的质量保证生态系统**。它标志着软件测试从“人类辅助AI”转向了“AI自主协作”，测试系统具备了类似生物的“自愈”和“适应”能力，能够随着代码库的演变而自动演进。\n\n---\n\n**总结：**\n作者的思考路径遵循了 **“发现问题（静态生成无效） -> 寻找类比（人类协作流程） -> 引入范式（多智能体系统） -> 构建机制（闭环反馈与收敛） -> 实现愿景（自主QA）”** 的完整逻辑链条。其核心洞察在于：**没有反馈的生成是盲目的，只有引入执行反馈和多智能体协作，AI测试才能真正落地。**", "summary_translation": "软件测试正迈向智能自动化，但现有的 AI-based test generators（基于AI的测试生成器）仍受限于静态、单次输出的模式。由于缺乏 execution aware feedback（执行感知反馈），这些工具常生成无效、冗余或不可执行的测试用例。本文提出了一种 agentic multi-model testing framework（代理多模型测试框架），这是一个闭环、自纠正系统。在该系统中，Test Generation Agent（测试生成代理）、Execution and Analysis Agent（执行与分析代理）以及 Review and Optimization Agent（审查与优化代理）协同工作，生成、执行、分析并完善测试，直至达到收敛状态。通过利用 sandboxed execution（沙箱执行）、详细的 failure reporting（失败报告）以及对失败测试的 iterative regeneration（迭代重新生成）或 patching（修补），该框架能够自主提升测试质量并扩大覆盖率。该框架集成于 CI/CD-compatible pipeline（兼容CI/CD的流水线）中，利用来自 coverage metrics（覆盖率指标）和 execution outcomes（执行结果）的 reinforcement signals（强化信号）来指导测试的完善过程。针对 microservice based applications（基于微服务的应用程序）进行的实证评估表明，与 single-model baselines（单模型基线）相比，该框架将无效测试减少了高达 60%，覆盖率提升了 30%，并显著降低了人工投入。这证明了 multi-agent（多代理）、feedback-driven loops（反馈驱动循环）能够将软件测试演变为一个自主的、持续学习的 quality assurance ecosystem（质量保证生态系统），以支持 self-healing（自愈）和 high-reliability codebases（高可靠性代码库）。", "summary_generated_time": "2026-01-09 19:02:08", "summary_model": "z-ai/glm-4.7"}]}, {"name": "Computation and Language", "count": 4, "papers": [{"index": "#8", "title": "MemRL: Self-Evolving Agents via Runtime Reinforcement Learning on Episodic Memory", "link": "/arxiv/2601.03192", "arxiv_id": "2601.03192", "authors": "Shengtao Zhang, Jiaqian Wang, Ruiwen Zhou, Junwei Liao, Yuchen Feng, Weinan Zhang, Ying Wen, Zhiyu Li, Feiyu Xiong, Yutao Qi, Bo Tang, Muning Wen", "summary": "The hallmark of human intelligence is the ability to master new skills through Constructive Episodic Simulation-retrieving past experiences to synthesize solutions for novel tasks. While Large Language Models possess strong reasoning capabilities, they struggle to emulate this self-evolution: fine-tuning is computationally expensive and prone to catastrophic forgetting, while existing memory-based methods rely on passive semantic matching that often retrieves noise. To address these challenges, we propose MemRL, a framework that enables agents to self-evolve via non-parametric reinforcement learning on episodic memory. MemRL explicitly separates the stable reasoning of a frozen LLM from the plastic, evolving memory. Unlike traditional methods, MemRL employs a Two-Phase Retrieval mechanism that filters candidates by semantic relevance and then selects them based on learned Q-values (utility). These utilities are continuously refined via environmental feedback in an trial-and-error manner, allowing the agent to distinguish high-value strategies from similar noise. Extensive experiments on HLE, BigCodeBench, ALFWorld, and Lifelong Agent Bench demonstrate that MemRL significantly outperforms state-of-the-art baselines. Our analysis experiments confirm that MemRL effectively reconciles the stability-plasticity dilemma, enabling continuous runtime improvement without weight updates.", "subjects": "Computation and Language", "date": "2026-01-06", "category": "cs.CL", "crawl_time": "2026-01-08T11:00:05.297263", "filter_reason": "这篇论文完全符合筛选标准，应予以保留。具体判断依据如下： 1.  **核心判断（符合）**： 论文的核心贡献是提出了 **MemRL**，这是一个旨在实现 **Self-Evolving Agents（自我演化智能体）** 的框架。它解决的是智能体如何通过经验进行自我完善和迭代的问题，而非仅仅是将LLM作为工具应用到特定领域。这直接对应了研究目标中的“自我演化”方向。 2.  **正面指标（高度匹配）**： *   **核心范式**：论文标题和摘要中明确提到了 `Self-Evolving Agents` 和 `Reinforcement Learning`，属于核心关注点。 *   **智能体能力**：论文重点研究了 `Memory`（情景记忆 Episodic Memory）和 `Self-Improvement`（通过环境反馈持续改进）。 *   **演化机制**：论文提出了一种非参数强化学习机制，通过环境反馈在运行时迭代改进 Q-values（效用），从而实现智能体的持续演化，符合 `Iterative Improvement` 和 `Self-Refine` 的定义。 3.  **排除标准（未触发）**： *   论文不涉及安全、对齐、多模态视觉或图技术等排除项。 *   虽然论文在 HLE、BigCodeBench 等基准上进行了实验，但这些是用于验证智能体能力的通用任务，不属于“非演化型应用”的排除范畴。 4.  **特殊与模糊情况处理**： *   论文属于典型的 **自我演化** 机制研究。它提出了一种新的“在情景记忆上进行运行时强化学习”的方法，使智能体能够在不更新模型权重的情况下解决稳定性-可塑性困境并实现持续改进。这完全符合“保留：如果论文的核心是提出一种新的‘自我演化’机制”的规则。 综上所述，该论文专注于构建新的框架以实现LLM智能体的自我演化和记忆优化，是“LLM智能体及其演化”课题下的高质量相关论文。", "summary2": "本文旨在解决LLM在部署后难以持续自我进化及避免灾难性遗忘的问题。针对需要Runtime Continuous Learning的场景，我们提出了一种MemRL框架，通过非参数强化学习优化情节记忆，采用基于Q值的Two-Phase Retrieval机制区分高价值策略与噪声。并在HLE、BigCodeBench、ALFWorld及Lifelong Agent Bench上通过Last Epoch Accuracy和Cumulative Success Rate验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "人类智能的显著特征在于通过 Constructive Episodic Simulation（建设性情景模拟）掌握新技能的能力——即检索过往经验以综合解决新颖任务的方案。尽管 Large Language Models（大语言模型）拥有强大的推理能力，但它们难以模拟这种自我进化：Fine-tuning（微调）计算成本高昂且容易导致 Catastrophic Forgetting（灾难性遗忘），而现有的基于记忆的方法依赖于被动语义匹配，往往会检索到噪声。为了应对这些挑战，我们提出了 MemRL，这是一个通过在 Episodic Memory（情景记忆）上进行 Non-parametric Reinforcement Learning（非参数强化学习）来使智能体实现自我进化的框架。MemRL 明确地将冻结 LLM 的稳定推理与具有可塑性且不断进化的记忆分离开来。与传统方法不同，MemRL 采用了一种 Two-Phase Retrieval（两阶段检索）机制，首先根据语义相关性过滤候选，然后基于学习到的 Q-values（效用）进行选择。这些效用通过环境反馈以试错的方式不断优化，使智能体能够区分高价值策略与相似的噪声。在 HLE、BigCodeBench、ALFWorld 和 Lifelong Agent Bench 上进行的广泛实验表明，MemRL 显著优于 State-of-the-art（最先进的）基线。我们的分析实验证实，MemRL 有效调和了 Stability-Plasticity Dilemma（稳定性-可塑性困境），能够在不进行权重更新的情况下实现持续的运行时改进。", "summary_generated_time": "2026-01-09 18:53:35", "summary_model": "z-ai/glm-4.7"}, {"index": "#55", "title": "TiMem: Temporal-Hierarchical Memory Consolidation for Long-Horizon Conversational Agents", "link": "/arxiv/2601.02845", "arxiv_id": "2601.02845", "authors": "Kai Li, Xuanqing Yu, Ziyi Ni, Yi Zeng, Yao Xu, Zheqing Zhang, Xin Li, Jitao Sang, Xiaogang Duan, Xuelei Wang, Chengbao Liu, Jie Tan", "summary": "Long-horizon conversational agents have to manage ever-growing interaction histories that quickly exceed the finite context windows of large language models (LLMs). Existing memory frameworks provide limited support for temporally structured information across hierarchical levels, often leading to fragmented memories and unstable long-horizon personalization. We present TiMem, a temporal--hierarchical memory framework that organizes conversations through a Temporal Memory Tree (TMT), enabling systematic memory consolidation from raw conversational observations to progressively abstracted persona representations. TiMem is characterized by three core properties: (1) temporal--hierarchical organization through TMT; (2) semantic-guided consolidation that enables memory integration across hierarchical levels without fine-tuning; and (3) complexity-aware memory recall that balances precision and efficiency across queries of varying complexity. Under a consistent evaluation setup, TiMem achieves state-of-the-art accuracy on both benchmarks, reaching 75.30% on LoCoMo and 76.88% on LongMemEval-S. It outperforms all evaluated baselines while reducing the recalled memory length by 52.20% on LoCoMo. Manifold analysis indicates clear persona separation on LoCoMo and reduced dispersion on LongMemEval-S. Overall, TiMem treats temporal continuity as a first-class organizing principle for long-horizon memory in conversational agents.", "subjects": "Computation and Language, Artificial Intelligence", "date": "2026-01-06", "category": "cs.CL", "crawl_time": "2026-01-08T11:00:05.380678", "filter_reason": "这篇论文完全符合我的研究范围，理由如下： 1.  **核心贡献符合第一步判断**：论文的核心是提出了一种名为 TiMem 的时间-分层记忆框架，旨在解决长视界对话智能体在管理不断增长的交互历史时面临的上下文窗口限制问题。这属于“构建、改进或演化 LLM智能体”的范畴，而非将智能体作为工具应用到特定领域（如医疗、金融等）的非演化型应用。 2.  **精准命中第二步正面指标**：我的研究焦点明确包含“单智能体”方向下的“记忆”能力。该论文专门针对智能体的“记忆”机制进行了创新，提出了时间记忆树（TMT）和语义引导的整合机制，这正是对智能体核心组件的改进。 3.  **不触犯第三步排除标准**：论文主要关注智能体的记忆架构，不涉及安全与对齐、多模态视觉技术或知识图谱等被明确排除的领域。 综上所述，该论文致力于改进LLM智能体的记忆能力，属于单智能体研究的关键子方向，符合筛选要求。", "summary2": "本文旨在解决长周期对话代理中记忆碎片化及个性化不稳定的问题。针对不断增长的交互历史，我们提出了一种TiMem框架，该框架利用Temporal Memory Tree实现时间分层记忆整合与复杂度感知检索，并在LoCoMo和LongMemEval-S基准上通过准确率和记忆长度验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "长程对话智能体必须管理不断增长的交互历史，这些历史很快就会超过大语言模型（large language models, LLMs，大语言模型）的有限上下文窗口。现有的记忆框架对跨层级的时间结构化信息支持有限，往往导致记忆碎片化和不稳定的长程个性化。我们提出了 TiMem，一个时间-层级记忆框架，它通过时间记忆树（Temporal Memory Tree, TMT，时间记忆树）组织对话，实现了从原始对话观察到逐步抽象的人设表征的系统性记忆整合。TiMem 具有三个核心特征：（1）通过 TMT 进行的时间-层级组织；（2）语义引导的整合，能够在无需微调的情况下实现跨层级的记忆整合；（3）复杂度感知的记忆召回，在不同复杂度的查询中平衡精确度和效率。在一致的评估设置下，TiMem 在两个基准测试中都达到了最先进的准确率，在 LoCoMo 上达到 75.30%，在 LongMemEval-S 上达到 76.88%。它优于所有评估的基线模型，同时在 LoCoMo 上将召回记忆长度减少了 52.20%。流形分析表明，在 LoCoMo 上存在清晰的人设分离，在 LongMemEval-S 上离散度有所降低。总的来说，TiMem 将时间连续性视为对话智能体长程记忆的首要组织原则。", "summary_generated_time": "2026-01-09 18:56:14", "summary_model": "z-ai/glm-4.7"}, {"index": "#61", "title": "SYNAPSE: Empowering LLM Agents with Episodic-Semantic Memory via Spreading Activation", "link": "/arxiv/2601.02744", "arxiv_id": "2601.02744", "authors": "Hanqi Jiang, Junhao Chen, Yi Pan, Ling Chen, Weihang You, Yifan Zhou, Ruidong Zhang, Yohannes Abate, Tianming Liu", "summary": "While Large Language Models (LLMs) excel at generalized reasoning, standard retrieval-augmented approaches fail to address the disconnected nature of long-term agentic memory. To bridge this gap, we introduce Synapse (Synergistic Associative Processing Semantic Encoding), a unified memory architecture that transcends static vector similarity. Drawing from cognitive science, Synapse models memory as a dynamic graph where relevance emerges from spreading activation rather than pre-computed links. By integrating lateral inhibition and temporal decay, the system dynamically highlights relevant sub-graphs while filtering interference. We implement a Triple Hybrid Retrieval strategy that fuses geometric embeddings with activation-based graph traversal. Comprehensive evaluations on the LoCoMo benchmark show that Synapse significantly outperforms state-of-the-art methods in complex temporal and multi-hop reasoning tasks, offering a robust solution to the \"Contextual Tunneling\" problem. Our code and data will be made publicly available upon acceptance.", "subjects": "Computation and Language", "date": "2026-01-06", "category": "cs.CL", "crawl_time": "2026-01-08T11:00:05.406202", "filter_reason": "1.  **核心判断 (第一步)**: 该论文的核心贡献是提出了一种名为 Synapse 的统一记忆架构，旨在解决 LLM 智能体在长期记忆中的“不连贯”问题。这属于对 LLM 智能体核心组件（记忆）的构建与改进，而非将智能体作为工具应用到特定领域（如医疗、金融），也非基础设施或基础模型推理能力的提升。因此，符合“保留”标准。 2.  **正面指标匹配 (第二步)**: 论文直接涉及 `LLM-based Agents` 的核心能力——`Memory`（记忆）。它引入了基于认知科学的扩散激活机制来优化智能体的记忆检索，这直接提升了智能体处理复杂时序和多跳推理任务的能力，属于单智能体方向的关键技术突破。 3.  **排除标准检查 (第三步)**: *   **安全与对齐**: 论文不涉及安全、对齐或可解释性问题。 *   **多模态**: 论文专注于文本记忆架构，不涉及视觉或多模态内容。 *   **图技术**: 尽管论文中提到了“动态图”和“图遍历”，但其核心目的是构建智能体的记忆系统，而非研究图神经网络（GNN）或知识图谱算法本身。图在这里是作为智能体内部存储和检索信息的机制，服务于智能体的功能，因此不应被排除。 4.  **综合结论**: 该论文通过改进智能体的记忆机制，直接增强了 LLM 智能体的自主性和任务处理能力，完全符合“单智能体”方向中关于“记忆”的研究焦点。", "summary2": "本文旨在解决LLM智能体长期记忆中的上下文隔离问题。针对长对话中的复杂推理场景，我们提出了一种基于Spreading Activation的SYNAPSE架构，构建Unified Episodic-Semantic Graph并结合Lateral Inhibition实现动态检索。我们在LoCoMo benchmark上通过F1 Score和Token消耗验证了其有效性，显著提升了多跳推理精度并降低了95%的Token使用量。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "尽管 Large Language Models (LLMs，大型语言模型) 在 generalized reasoning (泛化推理) 方面表现出色，但标准的 retrieval-augmented approaches (检索增强方法) 未能解决 long-term agentic memory (长期智能体记忆) 的割裂特性。为弥合这一差距，我们提出了 Synapse (Synergistic Associative Processing Semantic Encoding，协同联想处理语义编码)，这是一种超越 static vector similarity (静态向量相似度) 的 unified memory architecture (统一记忆架构)。借鉴 cognitive science (认知科学)，Synapse 将记忆建模为一个 dynamic graph (动态图)，其中相关性源于 spreading activation (扩散激活) 而非 pre-computed links (预计算链接)。通过整合 lateral inhibition (侧抑制) 和 temporal decay (时间衰减)，该系统能够动态突显相关的 sub-graphs (子图)，同时过滤干扰信息。我们实施了一种 Triple Hybrid Retrieval strategy (三重混合检索策略)，该策略将 geometric embeddings (几何嵌入) 与 activation-based graph traversal (基于激活的图遍历) 相融合。在 LoCoMo benchmark (LoCoMo 基准测试) 上的全面评估表明，Synapse 在复杂的 temporal and multi-hop reasoning tasks (时序和多跳推理任务) 中显著优于 state-of-the-art methods (最先进方法)，为 \"Contextual Tunneling\" (上下文隧道) 问题提供了稳健的解决方案。我们的代码和数据将在论文录用后公开发布。", "summary_generated_time": "2026-01-09 18:56:23", "summary_model": "z-ai/glm-4.7"}, {"index": "#95", "title": "ReTreVal: Reasoning Tree with Validation - A Hybrid Framework for Enhanced LLM Multi-Step Reasoning", "link": "/arxiv/2601.02880", "arxiv_id": "2601.02880", "authors": "Abhishek HS, Pavan C Shekar, Arpit Jain, Ashwanth Krishnan", "summary": "Multi-step reasoning remains a key challenge for Large Language Models (LLMs), particularly in complex domains such as mathematics and creative writing. While recent approaches including ReAct, Reflexion, and Self-Refine improve reasoning through iterative refinement and reflection, they often lack structured exploration of alternative solution paths and persistent learning across problems. We propose ReTreVal (Reasoning Tree with Validation), a hybrid framework that integrates Tree-of-Thoughts exploration, self-refinement, LLM-based critique scoring, and reflexion memory to enable bounded and validated multi-step reasoning. ReTreVal constructs a structured reasoning tree with adaptive depth based on problem complexity, where each node undergoes iterative self-critique and refinement guided by explicit LLM-generated feedback. A dual validation mechanism evaluates reasoning quality, coherence, and correctness at each node while persistently storing insights from successful reasoning paths and failure patterns in a reflexion memory buffer, enabling cross-problem learning. Critique-based pruning retains only the top-k highest-scoring nodes at each level, controlling computational cost while preserving high-quality solution paths. We evaluate ReTreVal against ReAct, Reflexion, and Self-Refine across 500 mathematical problems and creative writing tasks using Qwen 2.5 7B as the underlying LLM, and demonstrate that ReTreVal consistently outperforms existing methods through its combination of structured exploration, critique-driven refinement, and cross-problem memory, making it particularly effective for tasks requiring exploratory reasoning, rigorous verification, and knowledge transfer.", "subjects": "Artificial Intelligence, Computation and Language", "date": "2026-01-06", "category": "cs.CL", "crawl_time": "2026-01-08T11:00:05.444912", "filter_reason": "这篇论文完全符合筛选标准，属于核心研究范围内的“单智能体”与“自我演化”交叉领域。 1.  **核心判断**: *   论文的核心贡献是提出了 **ReTreVal** 这一混合框架，旨在构建和改进 LLM 智能体的多步推理能力。 *   它不是简单的应用型论文，而是提出了一种新的方法论，结合了 Tree-of-Thoughts (ToT)、自我细化和 Reflexion 记忆机制。 *   它不属于非演化型应用，也不属于基础设施或基础模型推理能力的微调，而是专注于智能体的架构设计。 2.  **符合研究焦点**: *   **单智能体**: 论文深入探讨了智能体的核心能力，包括 **Planning** (通过构建推理树进行结构化探索)、**Memory** (Reflexion memory buffer 用于持久化存储见解) 和 **Self-Reflection** (self-critique and refinement)。 *   **自我演化**: 论文明确提到了 \"persistent learning across problems\"（跨问题的持久学习）和 \"cross-problem memory\"（跨问题记忆）。智能体通过存储成功路径和失败模式的见解，利用这些经验在后续问题中进行改进，这完全符合“通过经验、反思进行自我完善”的自我演化定义。 3.  **排除标准检查**: *   论文不涉及安全、对齐、多模态或图技术等排除项。 *   虽然在数学和创意写作任务上进行了评估，但这只是验证框架有效性的实验场景，论文的核心在于框架本身的机制（验证、剪枝、记忆），而非特定领域的应用。 4.  **特殊规则处理**: *   根据“推理/规划”规则，该论文属于保留范畴。它不仅仅是提出一种新的 CoT 变体，而是构建了一个包含验证、记忆和树搜索的完整 **Agentic 框架**，与 ReAct 和 Reflexion 等经典 Agentic 方法进行对比和改进。 综上所述，该论文通过引入记忆机制和结构化探索，增强了 LLM 智能体的规划和自我演化能力，高度契合“LLM智能体及其演化”的研究课题。", "summary2": "本文旨在解决大语言模型在复杂多步推理任务中的局限性。针对数学和创意写作场景，我们提出了一种名为 ReTreVal 的混合框架，该框架集成了 Tree-of-Thoughts 探索、Self-Refinement、LLM-based critique scoring 和 reflexion memory。我们在 500 个数学问题和创意写作任务上，基于 Qwen 2.5 7B 模型，通过准确性和 GPT-4o mini 评分验证了其有效性。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "多步推理仍然是大型语言模型面临的一个关键挑战，特别是在数学和创意写作等复杂领域。尽管包括 ReAct、Reflexion 和 Self-Refine 在内的近期方法通过迭代优化和反思改进了推理能力，但它们往往缺乏对替代解题路径的结构化探索以及跨问题的持久学习能力。我们提出了 ReTreVal (Reasoning Tree with Validation，带验证的推理树)，这是一个集成了思维树探索、自我优化、基于 LLM 的批评评分以及反思记忆的混合框架，旨在实现有界且经过验证的多步推理。ReTreVal 构建了一个具有基于问题复杂度的自适应深度的结构化推理树，其中每个节点都在明确的 LLM 生成反馈指导下，经历迭代的自我批评和优化。双重验证机制评估每个节点的推理质量、连贯性和正确性，同时将来自成功推理路径的见解和失败模式持久地存储在反思记忆缓冲区中，从而实现跨问题学习。基于批评的剪枝策略在每一层仅保留得分最高的 top-k 个节点，在控制计算成本的同时保留了高质量的解题路径。我们使用 Qwen 2.5 7B 作为底层 LLM，在 500 个数学问题和创意写作任务上对 ReTreVal 与 ReAct、Reflexion 和 Self-Refine 进行了评估，结果表明 ReTreVal 通过结合结构化探索、批评驱动的优化以及跨问题记忆，始终优于现有方法，使其在需要探索性推理、严格验证和知识迁移的任务中尤为有效。", "summary_generated_time": "2026-01-09 18:55:53", "summary_model": "z-ai/glm-4.7"}]}, {"name": "Machine Learning", "count": 1, "papers": [{"index": "#25", "title": "From Memorization to Creativity: LLM as a Designer of Novel Neural-Architectures", "link": "/arxiv/2601.02997", "arxiv_id": "2601.02997", "authors": "Waleed Khalid, Dmitry Ignatov, Radu Timofte", "summary": "Large language models (LLMs) excel in program synthesis, yet their ability to autonomously navigate neural architecture design--balancing syntactic reliability, performance, and structural novelty--remains underexplored. We address this by placing a code-oriented LLM within a closed-loop synthesis framework, analyzing its evolution over 22 supervised fine-tuning cycles. The model synthesizes PyTorch convolutional networks which are validated, evaluated via low-fidelity performance signals (single-epoch accuracy), and filtered using a MinHash-Jaccard criterion to prevent structural redundancy. High-performing, novel architectures are converted into prompt-code pairs for iterative fine-tuning via parameter-efficient LoRA adaptation, initialized from the LEMUR dataset. Across cycles, the LLM internalizes empirical architectural priors, becoming a robust generator. The valid generation rate stabilizes at 50.6 percent (peaking at 74.5 percent), while mean first-epoch accuracy rises from 28.06 percent to 50.99 percent, and the fraction of candidates exceeding 40 percent accuracy grows from 2.04 percent to 96.81 percent. Analyses confirm the model moves beyond replicating existing motifs, synthesizing 455 high-performing architectures absent from the original corpus. By grounding code synthesis in execution feedback, this work provides a scalable blueprint for transforming stochastic generators into autonomous, performance-driven neural designers, establishing that LLMs can internalize empirical, non-textual rewards to transcend their training data.", "subjects": "Machine Learning, Computer Vision and Pattern Recognition", "date": "2026-01-06", "category": "cs.LG", "crawl_time": "2026-01-08T11:00:05.211267", "filter_reason": "这篇论文完全符合筛选标准，属于“自我演化”和“Agentic AI”的核心研究范畴。 1.  **核心判断（符合自我演化机制）**： 论文的核心贡献在于构建了一个“闭环合成框架”，让LLM能够通过环境反馈（执行结果和性能评估）进行自我完善。论文详细描述了LLM经过22个监督微调周期的演化过程，通过迭代微调，模型内化了经验性的架构先验，从而提升了生成质量和性能。这完全符合“自我演化”中定义的“智能体通过经验、反思或环境反馈进行自我完善和迭代”。 2.  **符合Agentic AI特征**： 论文将LLM定位为一个“自主的、性能驱动的神经设计者”。它不仅仅是生成代码，而是通过“验证-评估-过滤-更新”的循环，展示了智能体利用工具（代码执行）和反馈机制来优化自身输出的能力，这属于Agentic AI的高级形态。 3.  **特殊情况处理（自我演化的应用）**： 虽然论文的应用场景是“神经架构设计”（NAS），属于特定领域的应用，但根据第四步的规则，只要论文的核心是提出一种新的“自我演化”机制，即使应用在特定领域也应保留。本文的重点在于证明LLM如何通过反馈循环“从记忆走向创造”，其演化机制具有通用性和研究价值，而非单纯的应用落地。 综上所述，该论文在自我演化和智能体框架构建上具有显著贡献，符合研究课题要求。", "summary2": "本文旨在探索LLM能否通过迭代微调成为自主的神经网络架构设计师。针对CIFAR-10图像分类任务，我们提出了一种基于闭环合成框架的方法，结合了MinHash-Jaccard新颖性过滤和低保真性能信号（单轮准确率）。在22个微调周期中，我们使用DeepSeek-Coder-7B-Instruct-v1.5模型，通过有效生成率、首轮准确率和结构新颖性等指标验证了其有效性。结果显示模型性能显著提升，且保持了结构多样性。", "inspiration_trace": "基于论文《From Memorization to Creativity: LLM as a Designer of Novel Neural-Architectures》，以下是对作者核心方法论产出过程的逻辑推演：\n\n### 第一阶段：宏观观察与问题定位\n**逻辑起点：LLM的代码能力与NAS的高昂成本之间的矛盾。**\n1.  **观察现状**：传统神经架构搜索（NAS）虽然能自动化设计网络，但依赖强化学习或进化算法，计算成本极高（通常需要训练大量模型）。\n2.  **技术契机**：大型语言模型（LLM）在代码合成方面表现出色，能够生成复杂的PyTorch代码。\n3.  **提出核心问题**：现有的LLM辅助NAS研究多将LLM视为静态的“代码生成器”，仅关注最终搜索结果的精度。作者试图转换视角——**如果将LLM视为一个可进化的“智能体”，通过自我迭代，它能否从单纯的代码生成者转变为具备设计直觉的“架构设计师”？**\n\n### 第二阶段：假设形成与关键挑战\n**逻辑推演：从“死记硬背”到“举一反三”的可能性。**\n1.  **核心假设**：如果让LLM在一个闭环中不断生成架构、接收反馈并基于自身的高质量产出进行微调，它将逐渐内化出一种“经验性的架构先验”，而不仅仅是记忆训练数据中的代码片段。\n2.  **面临的挑战**：\n    *   **可靠性**：生成的代码往往无法运行（语法错误、维度不匹配）。\n    *   **性能评估**：如果对每个生成的模型都进行完整训练，计算成本将不可接受。\n    *   **模式崩塌**：模型可能会陷入局部最优，反复生成相似的“高分”架构，失去探索新结构的能力。\n\n### 第三阶段：策略性简化与代理指标设计\n**逻辑转折：为了可行性，必须降低评估成本。**\n1.  **引入低保真代理**：为了解决计算成本问题，作者决定不追求模型的最终收敛精度，而是采用**“单轮训练后的准确率”**作为性能代理。\n    *   *思考逻辑*：一个优秀的架构通常在训练初期就能快速学习。这个指标既便宜又能反映架构的“学习潜力”。\n2.  **定义目标函数**：将优化目标从“最终精度”转化为“初始学习速度”与“语法有效性”的结合。\n\n### 第四阶段：闭环机制与多样性约束\n**逻辑构建：如何确保“进化”而非“退化”？**\n1.  **构建闭环**：设计了一个“生成-评估-筛选-微调”的迭代循环。\n    *   *生成*：LLM产出PyTorch代码。\n    *   *评估*：检查代码可执行性，并跑一轮训练获取代理分数。\n    *   *筛选*：这是关键步骤，必须同时满足三个条件：**代码可运行**、**代理分数达标**、**结构新颖**。\n2.  **引入新颖性过滤**：为了防止模型陷入重复生成已知好架构的陷阱（即过拟合），作者引入了**MinHash-Jaccard相似度**作为去重机制。\n    *   *思考逻辑*：只有那些“既好用又没见过”的架构，才有资格被加入下一轮的微调数据集。这迫使LLM不断探索设计空间的新区域，而不是在舒适区里打转。\n\n### 第五阶段：验证与结论\n**逻辑闭环：从假设到现实的映射。**\n1.  **实验验证**：通过22个周期的迭代，观察LLM的行为变化。\n2.  **结果解读**：\n    *   **可靠性提升**：有效生成率从低位稳定在50%以上，说明LLM学会了如何写“能跑的代码”。\n    *   **性能提升**：单轮准确率显著提高，说明LLM学会了什么样的结构更容易学习。\n    *   **创造力涌现**：发现了大量不在原始数据集中的高性能架构，证明了模型超越了简单的记忆，具备了设计能力。\n\n**总结：**\n作者的思考路径是从**利用LLM写代码**（工具属性），进化到**利用反馈机制训练LLM**（进化属性），最后通过**约束多样性**（探索属性），成功将一个通用的代码模型重塑为一个专用的、具备创造力的神经网络设计专家。", "summary_translation": "大型语言模型在程序合成方面表现出色，但其在自主导航神经架构设计——即在句法可靠性、性能和结构新颖性之间取得平衡——方面的能力仍有待探索。我们通过将面向代码的LLM置于闭环合成框架中来解决这一问题，并分析了其在22个监督微调周期中的演变过程。该模型合成PyTorch卷积网络，这些网络经过验证，通过低保真性能信号（单轮准确率）进行评估，并使用MinHash-Jaccard标准进行过滤以防止结构冗余。高性能且新颖的架构被转换为提示-代码对，用于通过参数高效的LoRA适配进行迭代微调，该过程初始化自LEMUR数据集。在各个周期中，LLM内化了经验性架构先验，成为了一个鲁棒生成器。有效生成率稳定在50.6%（峰值达到74.5%），而平均首轮准确率从28.06%上升到50.99%，准确率超过40%的候选者比例从2.04%增长到96.81%。分析证实，该模型超越了复制现有模式的阶段，合成了455个原始语料库中不存在的高性能架构。通过将代码合成建立在执行反馈的基础上，这项工作提供了一个可扩展蓝图，用于将随机生成器转化为自主的、性能驱动的神经设计器，确立了LLM能够内化经验性的、非文本奖励从而超越其训练数据的结论。", "summary_generated_time": "2026-01-09 18:53:14", "summary_model": "z-ai/glm-4.7"}]}, {"name": "Multiagent Systems", "count": 2, "papers": [{"index": "#9", "title": "EvoRoute: Experience-Driven Self-Routing LLM Agent Systems", "link": "/arxiv/2601.02695", "arxiv_id": "2601.02695", "authors": "Guibin Zhang, Haiyang Yu, Kaiming Yang, Bingli Wu, Fei Huang, Yongbin Li, Shuicheng Yan", "summary": "Complex agentic AI systems, powered by a coordinated ensemble of Large Language Models (LLMs), tool and memory modules, have demonstrated remarkable capabilities on intricate, multi-turn tasks. However, this success is shadowed by prohibitive economic costs and severe latency, exposing a critical, yet underexplored, trade-off. We formalize this challenge as the \\textbf{Agent System Trilemma}: the inherent tension among achieving state-of-the-art performance, minimizing monetary cost, and ensuring rapid task completion. To dismantle this trilemma, we introduce EvoRoute, a self-evolving model routing paradigm that transcends static, pre-defined model assignments. Leveraging an ever-expanding knowledge base of prior experience, EvoRoute dynamically selects Pareto-optimal LLM backbones at each step, balancing accuracy, efficiency, and resource use, while continually refining its own selection policy through environment feedback. Experiments on challenging agentic benchmarks such as GAIA and BrowseComp+ demonstrate that EvoRoute, when integrated into off-the-shelf agentic systems, not only sustains or enhances system performance but also reduces execution cost by up to $80\\%$ and latency by over $70\\%$.", "subjects": "Computation and Language, Multiagent Systems", "date": "2026-01-06", "category": "cs.MA", "crawl_time": "2026-01-08T11:00:03.902305", "filter_reason": "这篇论文完全符合筛选标准，属于核心研究范围内的“自我演化”方向。 1.  **核心贡献符合第一步判断**: 论文的核心贡献是提出了 **EvoRoute**，这是一种**自我演化**的模型路由范式。它不是将现有的智能体简单应用到某个垂直领域（非演化型应用），也不是单纯的基础设施优化，而是针对LLM智能体系统本身提出了一种新的架构和演化机制，旨在解决智能体系统中的性能、成本和延迟之间的权衡问题。 2.  **精准命中“自我演化”与“Agentic AI”焦点**: *   **自我演化**: 论文明确提到这是一个“self-evolving”范式，并且详细描述了其机制：利用不断扩大的先验经验知识库，通过环境反馈持续完善其自身的选择策略。这完全符合筛选标准中关于“智能体通过经验、反思或环境反馈进行自我完善和迭代”的定义。 *   **Agentic AI**: 论文的研究对象是“Complex agentic AI systems”，涉及LLM、工具和记忆模块的协调集成，这直接对应了研究课题中的LLM智能体构建。 3.  **符合正面指标**: 论文包含了大量核心关键词，如 `Self-Evolving`、`Agentic AI`、`LLM-based Agents`、`Iterative Improvement`（通过反馈持续完善）以及 `Tool and memory modules`。 4.  **排除标准检查**: 论文不涉及安全对齐、多模态视觉核心研究或图技术。虽然它关注了成本和延迟（通常属于基础设施范畴），但其解决手段是通过智能体的自我演化策略来实现的，因此属于智能体架构的改进，而非单纯的底层硬件或部署优化。 综上所述，该论文提出了一种新的智能体自我演化机制，属于构建和改进LLM智能体的前沿研究，应予以保留。", "summary2": "本文旨在解决Agent System Trilemma，即性能、成本与效率之间的权衡问题。针对复杂的多轮LLM Agent系统，我们提出了一种名为EvoRoute的自进化模型路由范式，利用多方面检索和帕累托最优过滤动态选择LLM。我们在GAIA和BrowseComp+等基准上通过性能、成本和延迟指标验证了其有效性，在维持高性能的同时将成本降低了80%，延迟降低了70%。", "inspiration_trace": "", "summary_translation": "由大语言模型、工具和记忆模块的协调集成所驱动的复杂智能体 AI 系统，在复杂的多轮任务中展现出了卓越的能力。然而，这一成就伴随着高昂的经济成本和严重的延迟，从而揭示了一个关键但尚未被充分探索的权衡问题。我们将这一挑战形式化为 **Agent System Trilemma**（智能体系统三难困境）：即在实现最先进的性能、最小化货币成本以及确保快速任务完成这三者之间存在的内在张力。为了打破这一三难困境，我们提出了 EvoRoute，这是一种超越静态、预定义模型分配的自进化模型路由范式。EvoRoute 利用不断扩展的先验经验知识库，在每一步动态选择 Pareto-optimal（帕累托最优）的 LLM backbones（大语言模型骨干网络），在准确性、效率和资源使用之间取得平衡，同时通过环境反馈持续优化其自身的选择策略。在 GAIA 和 BrowseComp+ 等具有挑战性的智能体基准上进行的实验表明，当将 EvoRoute 集成到现成的智能体系统中时，它不仅保持甚至提升了系统性能，还将执行成本降低了高达 80%，延迟降低了超过 70%。", "summary_generated_time": "2026-01-09 18:53:41", "summary_model": "z-ai/glm-4.7"}, {"index": "#3", "title": "InfiAgent: An Infinite-Horizon Framework for General-Purpose Autonomous Agents", "link": "/arxiv/2601.03204", "arxiv_id": "2601.03204", "authors": "Chenglin Yu, Yuchen Wang, Songmiao Wang, Hongxia Yang, Ming Li", "summary": "LLM agents can reason and use tools, but they often break down on long-horizon tasks due to unbounded context growth and accumulated errors. Common remedies such as context compression or retrieval-augmented prompting introduce trade-offs between information fidelity and reasoning stability. We present InfiAgent, a general-purpose framework that keeps the agent's reasoning context strictly bounded regardless of task duration by externalizing persistent state into a file-centric state abstraction. At each step, the agent reconstructs context from a workspace state snapshot plus a fixed window of recent actions. Experiments on DeepResearch and an 80-paper literature review task show that, without task-specific fine-tuning, InfiAgent with a 20B open-source model is competitive with larger proprietary systems and maintains substantially higher long-horizon coverage than context-centric baselines. These results support explicit state externalization as a practical foundation for stable long-horizon agents. Github Repo:https://github.com/ChenglinPoly/infiAgent", "subjects": "Artificial Intelligence, Multiagent Systems", "date": "2026-01-06", "category": "cs.MA", "crawl_time": "2026-01-08T11:00:03.900452", "filter_reason": "这篇论文完全符合筛选标准，应予以保留。判断依据如下： 1.  **核心判断（第一步）：** *   论文的核心贡献是提出了 **InfiAgent**，这是一个用于通用自主智能体的**新框架**。 *   它解决的是 LLM 智能体在长视界任务中面临的上下文增长和误差累积问题，属于**构建和改进 LLM 智能体**的方法论研究。 *   它不是将现有智能体简单应用到特定领域（如医疗、金融），而是提出了底层的架构改进（状态外部化），因此不属于“非演化型应用”。 *   它关注的是智能体的系统架构和状态管理，而非模型的基础设施或硬件加速。 2.  **正面指标匹配（第二步）：** *   **核心范式**：明确属于 `Agentic AI` 和 `LLM-based Agents`。 *   **智能体能力**：论文重点解决了智能体的 **`Memory`**（通过文件中心的状态抽象外部化持久状态）和 **`Planning`**（在长视界任务中保持推理稳定性）能力。这是单智能体研究中的关键子方向。 3.  **排除标准检查（第三步）：** *   论文不涉及安全、对齐、多模态或图技术，未触发任何排除标准。 4.  **特殊情况处理（第四步）：** *   论文关于长视界任务中的推理稳定性，属于智能体如何在复杂任务中进行规划和多步推理的范畴，符合保留条件。 **总结**：该论文通过引入显式的状态外部化机制，改进了 LLM 智能体处理长视界任务的能力，是对智能体架构和记忆机制的重要创新，直接契合“单智能体”方向中的规划与记忆研究焦点。", "summary2": "本文旨在解决LLM agents在长视界任务中因上下文无界增长导致的稳定性问题。针对长视界推理场景，我们提出了一种InfiAgent框架，采用File-Centric State Abstraction将持久状态外部化，并结合分层代理架构保持上下文有界。在DeepResearch benchmark和80篇论文综述任务上，通过综合评分和覆盖率指标验证了其有效性，证明其能以20B开源模型达到与大型专有系统相当的性能。", "inspiration_trace": "生成灵感溯源时发生错误", "summary_translation": "LLM agents (大语言模型智能体) 虽然具备推理和使用工具的能力，但在长视界任务中，往往因上下文的无界增长和误差累积而失效。常见的解决方案，如上下文压缩或 retrieval-augmented prompting (检索增强提示)，往往在信息保真度与推理稳定性之间引入了权衡。我们提出了 InfiAgent，这是一个通用框架，通过将持久状态外部化到 file-centric state abstraction (以文件为中心的状态抽象) 中，无论任务持续时间长短，都能将智能体的推理上下文严格限制在固定范围内。在每一步中，智能体通过结合 workspace state snapshot (工作区状态快照) 和近期操作的固定窗口来重构上下文。在 DeepResearch 数据集和一项包含 80 篇论文的文献综述任务上的实验表明，无需进行 task-specific fine-tuning (针对特定任务的微调)，配备 20B 开源模型的 InfiAgent 的性能可与更大的专有系统相媲美，并且相比 context-centric baselines (以上下文为中心的基线方法)，其长视界覆盖率显著更高。这些结果验证了 explicit state externalization (显式状态外部化) 作为构建稳定长视界智能体的实用基础的可行性。\n\nGithub 代码库：https://github.com/ChenglinPoly/infiAgent", "summary_generated_time": "2026-01-09 18:53:34", "summary_model": "z-ai/glm-4.7"}]}], "overview": "# 今日AI论文速览 (2026-01-06)\n\n生成每日速览时发生错误: Connection error."}